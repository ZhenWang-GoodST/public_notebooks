TY  - CONF
TI  - Solving Markov Decision Processes with Reachability Characterization from Mean First Passage Times
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7063
EP  - 7070
AU  - S. Debnath
AU  - L. Liu
AU  - G. Sukhatme
PY  - 2018
KW  - decision making
KW  - decision theory
KW  - iterative methods
KW  - Markov processes
KW  - reachability analysis
KW  - robots
KW  - Markov decision processes
KW  - reachability characterization
KW  - reachability landscape
KW  - MFPT-VI
KW  - MFPT-PI
KW  - mean first passage time based value iteration
KW  - mean first passage time based policy iteration
KW  - robotic decision-making
KW  - numerical evaluation
KW  - Convergence
KW  - Markov processes
KW  - Mathematical model
KW  - Approximation algorithms
KW  - Planning
KW  - Linear systems
KW  - Standards
DO  - 10.1109/IROS.2018.8594383
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A new mechanism for efficiently solving the Markov decision processes (MDPs) is proposed in this paper. We introduce the notion of reachability landscape where we use the Mean First Passage Time (MFPT) as a means to characterize the reachability of every state in the state space. We show that such reachability characterization very well assesses the importance of states and thus provides a natural basis for effectively prioritizing states and approximating policies. Built on such a novel observation, we design two new algorithms - Mean First Passage Time based Value Iteration (MFPT-VI) and Mean First Passage Time based Policy Iteration (MFPT-PI) - that have been modified from the state-of-the-art solution methods. To validate our design, we have performed numerical evaluations in robotic decision-making scenarios, by comparing the proposed new methods with corresponding classic baseline mechanisms. The evaluation results showed that MFPT-VI and MFPT-PI have outperformed the state-of-the-art solutions in terms of both practical runtime and number of iterations. Aside from the advantage of fast convergence, this new solution method is intuitively easy to understand and practically simple to implement.
ER  - 

TY  - CONF
TI  - Hybrid Bio-Inspired Architecture for Walking Robots Through Central Pattern Generators Using Open Source FPGAs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7071
EP  - 7076
AU  - J. C. Linares
AU  - A. Barrientos
AU  - E. M. Márquez
PY  - 2018
KW  - control engineering computing
KW  - data acquisition
KW  - field programmable gate arrays
KW  - gait analysis
KW  - legged locomotion
KW  - microprocessor chips
KW  - public domain software
KW  - hybrid bio-inspired architecture
KW  - central pattern generators
KW  - robotic control approach
KW  - animal nervous system control
KW  - CNS-PNS
KW  - high level control
KW  - low level control
KW  - open source tools
KW  - binomial brain-peripheral nervous system
KW  - open source FPGA
KW  - digital circuits
KW  - microprocessors
KW  - Field programmable gate arrays
KW  - Level control
KW  - Legged locomotion
KW  - Microprocessors
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594288
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present a new robotic control approach inspired in the animal nervous system control. The system implements the binomial Brain-Peripheral Nervous System (CNS-PNS) combining the use of microprocessors as the high level control, or brain, and FPGAs as the low level control, or nervous system. Thanks to the new open source tools for FPGAs, we are able to apply them in the field of robotics in new ways that were impossible before. In this paper, we will demonstrate that our approach is not only able to control the movements of robots using digital circuits built inside an FPGA, but is also capable of generating, synthesizing and uploading them inside the FPGA in real time and on demand.
ER  - 

TY  - CONF
TI  - Towards an Autonomous Robotic Dragonfly: At-Scale Lift Experiments Modeling Dragonfly Forewings
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. A. K. Szabo
AU  - G. M. T. D'Eleuterio
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - bending
KW  - carbon fibres
KW  - design engineering
KW  - mobile robots
KW  - piezoelectric actuators
KW  - polymer films
KW  - robot kinematics
KW  - sensors
KW  - hindwing pair
KW  - Sympetrum san-guineum
KW  - flapping kinematics
KW  - carbon-fiber support structure
KW  - polyester film
KW  - polymide-film joints
KW  - piezoelectric bending-beam actuator
KW  - lift sensor
KW  - Sympetrum sanguineum
KW  - autonomous robotic dragonfly
KW  - artificial dragonfly forewings
KW  - Insects
KW  - Aerodynamics
KW  - Actuators
KW  - Resonant frequency
KW  - Frequency measurement
KW  - Carbon
KW  - Power supplies
DO  - 10.1109/IROS.2018.8594331
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We report on lift experiments conducted at scale for an artificial platform mimicking the dragonfly species: Sympetrum sanguineum. The platform, as well as the lift sensor, was custom designed and built. The flapping mechanism consisted of a piezoelectric bending-beam actuator, transmission using carbon-fiber elements and polymide-film joints, and wings constructed of polyester film with carbon-fiber support structure. The flapping kinematics of the Sympetrum san-guineum was replicated as closely as possible although only a pair of forewings were used in these experiments. The lift generated, when accounting for the addition of a pair of hindwings, is sufficient to allow for the hovering of a real-life dragonfly. The results, the first at-scale fully transient measurements of artificial dragonfly forewings, show that the lift curves quantitatively as well as qualitatively validate existing 2D and 3D computer simulations of dragonfly forewings.
ER  - 

TY  - CONF
TI  - Ultrasonic and Electrostatic Self-Cleaning Microstructured Adhesives for Robotic Grippers
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7083
EP  - 7088
AU  - V. Alizadehyazdi
AU  - E. McQueney
AU  - K. Tanaka
AU  - M. Spenko
PY  - 2018
KW  - adhesion
KW  - adhesives
KW  - cleaning
KW  - dust
KW  - electrostatics
KW  - glass
KW  - grippers
KW  - industrial robots
KW  - mobile robots
KW  - ultrasonic cleaning
KW  - perching robots
KW  - electrostatic cleaning
KW  - electrostatic repulsion
KW  - climbing robots
KW  - ultrasonic cleaning
KW  - noncontact cleaning method
KW  - robotic gripper
KW  - contaminated directional gecko-like adhesive
KW  - Cleaning
KW  - Electrostatics
KW  - Surface contamination
KW  - Grippers
KW  - Electrodes
KW  - Substrates
KW  - Rough surfaces
DO  - 10.1109/IROS.2018.8594091
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces electrostatic and ultrasonic techniques to clean dust and other contaminants from the surface of a gecko-like, microstrutured adhesive. The result is a non-destructive, non-contact cleaning method that will afford robotic grippers, climbing robots, and perching robots the ability to operate in real-world environments. Experimental results show that the cleaning efficiency for three different sizes of glass beads, 53-75 μm, 75-90 μm, and 90-106 μm, ranges between 75-99% when using a combination of electrostatic and ultrasonic cleaning. This is a far higher efficiency than when using electrostatic repulsion alone. Experiments also demonstrate an approximately 33% recovery in shear stress on a flat glass for a contaminated directional gecko-like adhesive after contact with a dusty table when electrostatic/ultrasonic cleaning was used. Finally, by applying this method on a robotic gripper, we observed an 18% recovery in normal adhesion on a flat glass substrate.
ER  - 

TY  - CONF
TI  - Evolving a Sensory-Motor Interconnection for Dynamic Quadruped Robot Locomotion Behavior
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7089
EP  - 7095
AU  - A. Aulia Saputra
AU  - W. Hong Chin
AU  - J. Botzheim
AU  - N. Kubota
PY  - 2018
KW  - legged locomotion
KW  - optimisation
KW  - robot dynamics
KW  - trees (mathematics)
KW  - dynamic quadruped robot locomotion
KW  - sensory-motor coordination model
KW  - sensory neurons
KW  - neural oscillator
KW  - bacterial programming
KW  - sensory-motor interconnection structure
KW  - tree structure optimization
KW  - gene transfer process
KW  - bacterial mutation
KW  - Neurons
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Microorganisms
KW  - Robot kinematics
KW  - Optimization
DO  - 10.1109/IROS.2018.8593671
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a novel biologically inspired evolving neural oscillator for quadruped robot locomotion to minimize constraints during the locomotion process. The proposed sensory-motor coordination model is formed by the interconnection between motor and sensory neurons. The model utilizes Bacterial Programming to reconstruct the number of joints and neurons in each joint based on environmental conditions. Bacterial Programming is inspired by the evolutionary process of bacteria that includes bacterial mutation and gene transfer process. In this system, either the number of joints, the number of neurons, or the interconnection structure are changing dynamically depending on the sensory information from sensors equipped on the robot. The proposed model is simulated in computer for realizing the optimization process and the optimized structure is then applied to a real quadruped robot for locomotion process. The optimizing process is based on tree structure optimization to simplify the sensory-motor interconnection structure. The proposed model was validated by series of real robot experiments in different environmental conditions.
ER  - 

TY  - CONF
TI  - Learning-based Path Tracking Control of a Flapping-wing Micro Air Vehicle
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7096
EP  - 7102
AU  - J. Lee
AU  - S. Ryu
AU  - T. Kim
AU  - W. Kim
AU  - H. J. Kim
PY  - 2018
KW  - aerodynamics
KW  - aerospace simulation
KW  - autonomous aerial vehicles
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - predictive control
KW  - vehicle dynamics
KW  - autonomous flight
KW  - neural network
KW  - MPC
KW  - Reynolds number
KW  - model predictive control
KW  - model-based control strategy
KW  - FWMAV
KW  - flapping-wing microair vehicle
KW  - path tracking control
KW  - Batteries
KW  - Training
KW  - Neural networks
KW  - Dynamics
KW  - Data models
KW  - Trajectory
KW  - Vehicle dynamics
DO  - 10.1109/IROS.2018.8594387
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Flapping-wing micro air vehicles (FWMAVs) become promising research platforms due to their advantages such as various maneuverability, and concealment. However, unsteady flow at low Reynolds number around the wings makes their dynamics time-varying and highly non-linear. It makes autonomous flight of FWMAV as a big challenge. In this paper, we suggest a model-based control strategy for FWMAV using learning architecture. For this task, we construct a ground station for logging flight data and control inputs, and train dynamics with a neural network. Then, we apply model predictive control (MPC) to the trained model. We validate our method by hardware experiments.
ER  - 

TY  - CONF
TI  - Improving the Parallel Execution of Behavior Trees
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7103
EP  - 7110
AU  - M. Colledanchise
AU  - L. Natale
PY  - 2018
KW  - computer games
KW  - control system synthesis
KW  - finite state machines
KW  - mobile robots
KW  - trees (mathematics)
KW  - control architectures
KW  - concurrent programming
KW  - CBTs
KW  - autonomous agents
KW  - computer game
KW  - robotics industry
KW  - finite state machines
KW  - parallel execution
KW  - concurrent BTs
KW  - parallel operator
KW  - behavior trees
KW  - Task analysis
KW  - Robots
KW  - Synchronization
KW  - Games
KW  - Programming
KW  - Monitoring
KW  - Concurrent computing
DO  - 10.1109/IROS.2018.8593504
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Behavior Trees (BTs) have become a popular framework for designing controllers of autonomous agents in the computer game and in the robotics industry. One of the key advantages of BTs lies in their modularity, where independent modules can be composed to create more complex ones. In the classical formulation of BTs, modules can be composed using one of the three operators: Sequence, Fallback, and Parallel. The Parallel operator is rarely used despite its strong potential against other control architectures such as Finite State Machines. This is due to the fact that concurrent actions may lead to unexpected problems similar to the ones experienced in concurrent programming. In this paper, we outline how to tackle the aforementioned problem by introducing Concurrent BTs (CBTs) as a generalization of BTs in which we include the notions of progress and resource usage. We show how CBTs allow safe concurrent executions of actions and we analyze the approach from a mathematical standpoint. To illustrate the use of CBTs, we provide a set of use cases in realistic robotics scenarios.
ER  - 

TY  - CONF
TI  - Guess What I Attend: Interface-Free Object Selection Using Brain Signals
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7111
EP  - 7116
AU  - H. Kolkhorst
AU  - M. Tangermann
AU  - W. Burgard
PY  - 2018
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - signal detection
KW  - user training
KW  - event-related potentials
KW  - interface-free object selection
KW  - brain signals
KW  - brain activity
KW  - user goals
KW  - intuitive communication
KW  - human-robot cooperation scenarios
KW  - natural brain responses
KW  - target object detection
KW  - object selection
KW  - information geometry
KW  - Electroencephalography
KW  - Covariance matrices
KW  - Task analysis
KW  - Information geometry
KW  - Switches
KW  - Mobile robots
DO  - 10.1109/IROS.2018.8593992
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Interpreting the brain activity to identify user goals or to ground a robot's hypotheses about them is a promising direction for non-intrusive and intuitive communication. Such a capability can be of particular relevance in the context of human-robot cooperation scenarios. This paper proposes a novel approach to utilize the natural brain responses to highlighted objects in the scene for object selection. By this, it circumvents the need for additional interfaces or user training. Our approach uses methods from information geometry to classify the target/non-target response of these event-related potentials. Online experiments carried out with a real robot demonstrate an accurate detection of target objects solely based on the user's attention.
ER  - 

TY  - CONF
TI  - Mobile Continuum Robot with Unlimited Extensible Sections
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7117
EP  - 7122
AU  - A. Kanada
AU  - T. Mashimo
PY  - 2018
KW  - bending
KW  - buckling
KW  - DC motors
KW  - force control
KW  - gears
KW  - mobile robots
KW  - motion control
KW  - pulleys
KW  - typical continuum robots
KW  - restricted section length
KW  - locomotion
KW  - mobile continuum robot design
KW  - virtually unlimited extensible sections
KW  - driving unit
KW  - gear
KW  - long flexible tube
KW  - traveling distance
KW  - multiple driving units
KW  - DC motors
KW  - crawling locomotion performance
KW  - 3D printer
KW  - helical groove
KW  - tendon-driven robots
KW  - Electron tubes
KW  - DC motors
KW  - Gears
KW  - Trajectory
KW  - Springs
KW  - End effectors
DO  - 10.1109/IROS.2018.8594340
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Typical continuum robots, such as pneumatic and tendon-driven robots, have a restricted section length and require a large external component for pulleys and a compressor, making them unsuitable for locomotion. This paper presents a new mobile continuum robot design with virtually unlimited extensible sections. A driving unit, which has a mechanism similar to the rack-and-pinion, consists of three DC motors with gears, each of which moves each flexible tube. The rotation of the motor translates the flexible tube, which has a helical groove on the surface that meshes with the gear. The long flexible tube provides a large traveling distance as long as it does not buckle. The elongation and bending motion of each section may be controlled during operation by varying the speed of each flexible tube. This design not only allows the expansion of the robot to otherwise unreachable work areas but also improves the locomotion velocity by generating a large traveling distance of the flexible tubes. The most important point in this paper is to use multiple driving units for locomotion. Since all the driving units can be mounted on the same tubes, by increasing the number of them, the robot can take various forms without expanding its diameter. A preliminary prototype was built, and its crawling locomotion performance was tested using two operating sequences. The results indicate that earthworm-like locomotion can be achieved with good performance by elongating the sections even when the ground is slippery. The proposed design can be easily be rebuilt by anyone with access to a basic 3D printer.
ER  - 

TY  - CONF
TI  - Multi-Stage Learning of Selective Dual-Arm Grasping Based on Obtaining and Pruning Grasping Points Through the Robot Experience in the Real World
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7123
EP  - 7130
AU  - S. Kitagawa
AU  - K. Wada
AU  - S. Hasegawa
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - control engineering computing
KW  - convolutional neural nets
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - selective dual-arm grasping
KW  - pruning grasping points
KW  - robot experience
KW  - robot grasping
KW  - dual-arm robots
KW  - humanoid robots
KW  - dual-arm manipulation
KW  - single-arm limitation
KW  - multistage learning method
KW  - self-supervised approach
KW  - convolutional neural networks
KW  - CNN
KW  - semantic segmentation
KW  - automatic annotation
KW  - Grasping
KW  - Semantics
KW  - Image segmentation
KW  - Manipulators
KW  - Task analysis
KW  - Learning systems
DO  - 10.1109/IROS.2018.8593752
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Recently, self-supervised approach is common for robot grasping. Although this approach improves success rate, it requires a long time to execute a number of grasp trials, and single-arm grasping is only considered. However, robots can grasp more various objects with two arms, and dual-arm robots such as humanoid robots are expected to execute dual-arm manipulation and overcome the single-arm limitation. In this paper, we introduce dual-arm grasping as another possible strategy and propose a multi-stage learning method for selective dual-arm grasping using Convolutional Neural Networks (CNN)for grasping point prediction and semantic segmentation. In the first stage, the network learns grasping points with the automatic annotation. Although a robot learns both single-arm and dual-arm grasping efficiently with the annotation, the robot may not be able to grasp it because the annotation algorithm is designed by human. Therefore, for the second stage, the robot samples various grasping points with both grasping strategies and learns how to grasp in the real world. In this stage, the robot obtains new possible grasping points and prunes unsuccessful ones for both grasping strategies through the robot experience. In the experiments in the real world, the adapted network achieved high success rate 76.7% in 90 trials. Since the network trained with no adaptation stage resulted in lower success rate 56.7%, this result also shows the network was refined with less than 250 times of grasp sampling. As an application of our method, we demonstrated that our system worked well in warehouse picking task.
ER  - 

TY  - CONF
TI  - Bimanual Assembly of Two Parts with Relative Motion Generation and Task Related Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7131
EP  - 7136
AU  - S. Stavridis
AU  - Z. Doulgeri
PY  - 2018
KW  - collision avoidance
KW  - end effectors
KW  - motion control
KW  - optimisation
KW  - robotic assembly
KW  - end-effector frame
KW  - stack-of- tasks hierarchical solver
KW  - collision avoidance
KW  - optimization
KW  - relative motion generation
KW  - bimanual assembly
KW  - YuMi bimanual robot
KW  - task priority strategy
KW  - Task analysis
KW  - Collision avoidance
KW  - End effectors
KW  - Ellipsoids
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593928
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Bimanual assembly of two parts require that a relative target pose is reached prior to the joining operation. Rather than utilizing one arm as a fixture for holding one of the parts while the other performs the assembly, motion generation in the relative end-effector frame is proposed that involves both arms. The proposed approach considers bimanual motion in a dynamic and uncertain environment addressing avoidance of collision with obstacles as well as the robot itself and the environment. Moreover, configurations that optimize the motion and force capabilities for the sucessful and efficient completion of the task are taken into account. A task priority strategy is adopted achieving online performance. Experimental results on the YuMi bimanual robot using the Stack-Of- Tasks hierarchical solver validate the performance of the proposed approach in a folding assembly task.
ER  - 

TY  - CONF
TI  - Dual-Arm Coordinated Motion Planning and Compliance Control for Capturing Moving Objects with Large Momentum
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7137
EP  - 7144
AU  - L. Yan
AU  - Y. Yang
AU  - W. Xu
AU  - S. Vijayakumar
PY  - 2018
KW  - compliance control
KW  - force control
KW  - Jacobian matrices
KW  - manipulators
KW  - motion control
KW  - optimal control
KW  - path planning
KW  - trajectory control
KW  - dual-arm coordinated motion planning
KW  - dual-arm robot
KW  - operational force control
KW  - dual-arm capturing motion
KW  - object tracking
KW  - compliance control
KW  - null-space projected relative Jacobian
KW  - collocation trajectory optimization
KW  - Planning
KW  - Force
KW  - Robot kinematics
KW  - Jacobian matrices
KW  - Trajectory
KW  - Tracking
DO  - 10.1109/IROS.2018.8593853
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Capturing a moving object with large momentum by a dual-arm robot is especially challenging because of the requirement of dual-arm coordinated motion planning for tracking the moving object, and the operational force control for contact and momentum transfer. In this paper, we present a dual-arm coordinated motion planning and compliance control method with a unique null-space projected relative Jacobian and relative operational force between the two arms. The proposed method is able to plan dual-arm capturing motion and control the capturing force without disturbing the tracking motion. We have also adopted a direct collocation trajectory optimization method to generate optimal trajectory to decrease the object's momentum with minimum effort. Simulation and experiment of dual-arm robots picking up a moving box on a mobile platform are carried out to verify the proposed method.
ER  - 

TY  - CONF
TI  - A Model Predictive Control Approach for Vision-Based Object Grasping via Mobile Manipulator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - M. Logothetis
AU  - G. C. Karras
AU  - S. Heshmati-Alamdari
AU  - P. Vlantis
AU  - K. J. Kyriakopoulos
PY  - 2018
KW  - collision avoidance
KW  - dexterous manipulators
KW  - end effectors
KW  - grippers
KW  - image colour analysis
KW  - image sensors
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - path planning
KW  - predictive control
KW  - robot vision
KW  - reach-to-grasp motion
KW  - optimal grasping regions
KW  - vision-based object grasping
KW  - motion control architecture
KW  - mobile manipulator system
KW  - partial point cloud
KW  - onboard RGB-D sensor system
KW  - KUKA Youbot
KW  - static obstacles
KW  - reach-to-grasp scenarios
KW  - model predictive control approach
KW  - nonlinear model predictive control scheme
KW  - Grasping
KW  - Three-dimensional displays
KW  - Manipulators
KW  - Grippers
KW  - Robot sensing systems
KW  - Predictive control
DO  - 10.1109/IROS.2018.8593759
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design of a vision-based object grasping and motion control architecture for a mobile manipulator system. The optimal grasping areas of the object are estimated using the partial point cloud acquired from an onboard RGB-D sensor system. The reach-to-grasp motion of the mobile manipulator is handled via a Nonlinear Model Predictive Control scheme. The controller is formulated accordingly in order to allow the system to operate in a constrained workspace with static obstacles. The goal of the proposed scheme is to guide the robot's end-effector towards the optimal grasping regions with guaranteed input and state constraints such as occlusion and obstacle avoidance, workspace boundaries and field of view constraints. The performance of the proposed strategy is experimentally verified using an 8 Degrees of Freedom KUKA Youbot in different reach-to-grasp scenarios.
ER  - 

TY  - CONF
TI  - A Bayesian Framework for Simultaneous Robot Localization and Target Detection and Engagement
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7151
EP  - 7157
AU  - T. Furukawa
AU  - G. Dissanayake
AU  - T. Attia
AU  - J. Hodges
PY  - 2018
KW  - Bayes methods
KW  - image fusion
KW  - image sensors
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - object detection
KW  - probability
KW  - remotely operated vehicles
KW  - robot vision
KW  - mobile robot
KW  - multistage Bayesian approaches
KW  - multistage localization approach
KW  - global coordinate frame
KW  - multistage target observation approach
KW  - target engagement
KW  - multiple sensors
KW  - Bayesian framework
KW  - simultaneous robot localization
KW  - sensors on-board
KW  - target detection
KW  - associated detection probability
KW  - extended Kalman filter
KW  - unmanned ground vehicle
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Bayes methods
KW  - Mobile robots
KW  - Uncertainty
DO  - 10.1109/IROS.2018.8593747
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a framework for engaging a target while approaching it from a long distance, using observation from sensors on-board a mobile robot. The proposed framework consists of two multi-stage Bayesian approaches to reliably detect and accurately engage with the target under uncertainties. The multi-stage localization approach localizes the robot and the target in a global coordinate frame. Their locations are estimated sequentially when the robot is at a long distance from the target, whereas they are localized simultaneously when the target is in the close vicinity. In the multi-stage target observation approach, a level of confidence and the associated probability of detection of the sensor are defined to make the target detectable in maximal occasions. This allows the extended Kalman filter to be implemented for the target engagement. The proposed framework was implemented on an unmanned ground vehicle equipped with multiple sensors. Results show the effectiveness of the proposed framework in solving real-world problems.
ER  - 

TY  - CONF
TI  - Coupling Mobile Base and End-Effector Motion in Task Space
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - T. Welschehold
AU  - C. Dornhege
AU  - F. Paus
AU  - T. Asfour
AU  - W. Burgard
PY  - 2018
KW  - approximation theory
KW  - collision avoidance
KW  - end effectors
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - couple robot base
KW  - kinematic constraints
KW  - mobile manipulators
KW  - model-based dynamic systems
KW  - in-depth knowledge
KW  - motion planning
KW  - task space
KW  - end-effector motion
KW  - coupling mobile base
KW  - kinematically feasible trajectories
KW  - robots kinematic design
KW  - arbitrary dynamical systems
KW  - End effectors
KW  - Trajectory
KW  - Task analysis
KW  - Grippers
KW  - Dynamics
KW  - Planning
DO  - 10.1109/IROS.2018.8593534
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Dynamic systems are a practical alternative to motion planning in executing robot actions. They are of particular interest in Learning from Demonstration, as here we aim to carry out actions in a certain fashion, without a model or in-depth knowledge about the world, which might be difficult to achieve with a planner. Using model-based dynamic systems in task space enables robots to flexibly reproduce demonstrated actions. Nevertheless, when dealing with mobile manipulators, we face the challenge of including the kinematic constraints of the robot in the action models. In this paper we propose to couple robot base and end-effector motions generated by arbitrary dynamical systems modulating the base velocity, while respecting the robots kinematic design. To this end we learn an approximation of the inverse reachability in closed form. In real-world robot experiments we demonstrate that we are able to maintain kinematically feasible trajectories in the presence of obstacles and in configurations differing profoundly from the training scene.
ER  - 

TY  - CONF
TI  - Motion Planning for an Underwater Mobile Manipulator by Exploiting Loose Coupling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7164
EP  - 7171
AU  - D. Youakim
AU  - A. Dornbush
AU  - M. Likhachev
AU  - P. Ridao
PY  - 2018
KW  - autonomous underwater vehicles
KW  - manipulators
KW  - motion control
KW  - path planning
KW  - trajectory control
KW  - intervention autonomous underwater vehicle
KW  - MR-MHA *
KW  - multirepresentation multiheuristic A*
KW  - realistic simulated underwater intervention environment
KW  - intervention mission
KW  - generated trajectories
KW  - high-dimensional underwater manipulator
KW  - search-based planner
KW  - motion coordination
KW  - complex manipulation tasks
KW  - floating-based intervention
KW  - task-priority redundancy control framework
KW  - GIRONA 500
KW  - SAUVIM
KW  - autonomous manipulation skills
KW  - I-AUV
KW  - underwater mobile manipulator
KW  - motion planning
KW  - Task analysis
KW  - Planning
KW  - Manipulators
KW  - Search problems
KW  - Trajectory
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593604
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Intervention Autonomous Underwater Vehicle or I-AUV has recently started to grab researchers attention in the last 20 years. Only three I-AUVs have demonstrated autonomous manipulation skills: ALIVE, SAUVIM and GIRONA 500. While prior systems rely on variations of the task-priority redundancy control framework, our recent research showed preliminary results using motion planning for floating-based intervention in the presence of obstacles. With the increasing need for autonomously performing more complex manipulation tasks, two main challenges need to be addressed: the high-dimensionality of the system, and the motion coordination between the mobile base and the working arm. The latter challenge is of high importance if accurate execution is required, especially considering the floating nature of the AUV and the control challenges that come with it. Our approach relies on exploiting the loose coupling between the AUV and the arm. In particular we present an approach based on MR-MHA * (Multi-Representation, Multi-Heuristic A*), and we show how it can generate efficient trajectories by exploiting decoupling. We show for the first time the use of a search-based planner on a high-dimensional underwater manipulator. In addition, we support our claims with experimental analysis of the generated trajectories with respect to various metrics in different environments. Furthermore, we demonstrate the ability of our approach to conduct a full intervention mission in a realistic simulated underwater intervention environment.
ER  - 

TY  - CONF
TI  - Dynamic Model Learning and Manipulation Planning for Objects in Hospitals Using a Patient Assistant Mobile (PAM)Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - R. S. Novin
AU  - A. Yazdani
AU  - T. Hermans
AU  - A. Merryweather
PY  - 2018
KW  - collision avoidance
KW  - hospitals
KW  - manipulator dynamics
KW  - medical robotics
KW  - mobile robots
KW  - predictive control
KW  - probability
KW  - PAM robot
KW  - probabilistic method
KW  - 2-wheel walker
KW  - autonomous learning
KW  - fall prevention
KW  - maneuvers mobility aids
KW  - patient assistant mobile robot
KW  - dynamic model learning
KW  - collision-free manipulation
KW  - 4-legged walker
KW  - hybrid MPC-based manipulation planning algorithm
KW  - one-wheel point-mass model
KW  - hybrid control system
KW  - motion interactions
KW  - minimal force
KW  - approximate dynamic model
KW  - Legged locomotion
KW  - Dynamics
KW  - Planning
KW  - Manipulator dynamics
KW  - Grippers
DO  - 10.1109/IROS.2018.8593989
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One of the most concerning and costly problems in hospitals is patients falls. We address this problem by introducing PAM, a patient assistant mobile robot, that maneuvers mobility aids to assist with fall prevention. Common objects found inside hospitals include objects with legs (i.e. walkers, tables, chairs, equipment stands). For a mobile robot operating in such environments, safely maneuvering these objects without collision is essential. Since providing the robot with dynamic models of all possible legged objects that may exist in such environments is not feasible, autonomous learning of an approximate dynamic model for these objects would significantly improve manipulation planning. We describe a probabilistic method to do this by fitting pre-categorized object models learned from minimal force and motion interactions with an object. In addition, we account for multiple manipulation strategies, which requires a hybrid control system comprised of discrete grasps on legs and continuous applied forces. To do this, we use a simple one-wheel point-mass model. A hybrid MPC-based manipulation planning algorithm was developed to compensate for modeling errors. While the proposed algorithm applies to a broad range of legged objects, we only show results for the case of a 2-wheel, 4-legged walker in this paper. Simulation and experimental tests show that the obtained dynamic model is sufficiently accurate for safe and collision-free manipulation. When combined with the proposed manipulation planning algorithm, the robot can successfully move the object to a desired position without collision.
ER  - 

TY  - CONF
TI  - Capacitive Proximity Sensor Skin for Contactless Material Detection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7179
EP  - 7184
AU  - Y. Ding
AU  - H. Zhang
AU  - U. Thomas
PY  - 2018
KW  - capacitance measurement
KW  - capacitive sensors
KW  - distance measurement
KW  - electric impedance measurement
KW  - frequency measurement
KW  - signal processing
KW  - time-of-flight sensors
KW  - capacitance based sensor system
KW  - characteristic impedance spectrum measurement
KW  - absolute distance based capacitance measurement capabilities
KW  - ToF sensors
KW  - human-machine-interaction
KW  - signal processing
KW  - frequency based capacitance measurement capabilities
KW  - distance sensing methods
KW  - capacitive proximity sensing skins
KW  - contactless material detection
KW  - Robot sensing systems
KW  - Impedance
KW  - Frequency measurement
KW  - Electrodes
KW  - Current measurement
KW  - Impedance measurement
DO  - 10.1109/IROS.2018.8594376
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a method for contactless material detection with capacitive proximity sensing skins. Our new approach extends the current state-of-the-art proximity and distance sensing methods and measures the characteristic impedance spectrum of an object to obtain material properties. By this, we gain further material information besides of the near field information in a contactless and non-destructive way. The measurement method requires sensors that provide absolute distance and frequency based capacitance measurement capabilities and can be applied to similar systems. The sensor system described in this paper measures proximity with a capacitance based sensor and absolute distance based on time-of-flight (ToF)sensors. Attached on a robot, we gain information about the robot's near field environment. The information is important not only for human- machine- interaction, but also for grasping and manipulation. We focus on signal processing and evaluate our method with measurements of numerous different materials and present a solution to differentiate between them.
ER  - 

TY  - CONF
TI  - Teaching a Robot to Grasp Real Fish by Imitation Learning from a Human Supervisor in Virtual Reality
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7185
EP  - 7192
AU  - J. S. Dyrstad
AU  - E. Ruud Øye
AU  - A. Stahl
AU  - J. Reidar Mathiassen
PY  - 2018
KW  - convolutional neural nets
KW  - grippers
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pose estimation
KW  - virtual reality
KW  - teaching
KW  - gripper
KW  - domain randomization approach
KW  - depth imaging
KW  - 3D occupancy grid
KW  - robot imitation learning
KW  - deep 3D convolutional neural network
KW  - virtual robot
KW  - grasp real fish
KW  - virtual reality
KW  - human supervisor
KW  - Robots
KW  - Task analysis
KW  - Three-dimensional displays
KW  - Grippers
KW  - Grasping
KW  - Cameras
KW  - Virtual reality
DO  - 10.1109/IROS.2018.8593954
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We teach a real robot to grasp real fish, by training a virtual robot exclusively in virtual reality. Our approach implements robot imitation learning from a human supervisor in virtual reality. A deep 3D convolutional neural network computes grasps from a 3D occupancy grid obtained from depth imaging at multiple viewpoints. In virtual reality, a human supervisor can easily and intuitively demonstrate examples of how to grasp an object, such as a fish. From a few dozen of these demonstrations, we use domain randomization to generate a large synthetic training data set consisting of 100 000 example grasps of fish. Using this data set for training purposes, the network is able to guide a real robot and gripper to grasp real fish with good success rates. The newly proposed domain randomization approach constitutes the first step in how to efficiently perform robot imitation learning from a human supervisor in virtual reality in a way that transfers well to the real world.
ER  - 

TY  - CONF
TI  - Seeing Behind the Scene: Using Symmetry to Reason About Objects in Cluttered Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7193
EP  - 7200
AU  - A. Ecins
AU  - C. Fermüller
AU  - Y. Aloimonos
PY  - 2018
KW  - feature extraction
KW  - geometry
KW  - image reconstruction
KW  - image segmentation
KW  - natural scenes
KW  - object detection
KW  - cluttered scenes
KW  - scene extraction
KW  - 3D reconstructions
KW  - objects segment
KW  - symmetry axes-planes
KW  - geometry
KW  - pointclouds
KW  - foreground segmentation problem
KW  - smooth surfaces
KW  - reflectional symmetries
KW  - natural scenes
KW  - symmetric objects
KW  - cluttered environments
KW  - Three-dimensional displays
KW  - Shape
KW  - Task analysis
KW  - Two dimensional displays
KW  - Pipelines
KW  - Surface treatment
KW  - Object segmentation
DO  - 10.1109/IROS.2018.8593822
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Symmetry is a common property shared by the majority of man-made objects. This paper presents a novel bottom-up approach for segmenting symmetric objects and recovering their symmetries from 3D pointclouds of natural scenes. Candidate rotational and reflectional symmetries are detected by fitting symmetry axes/planes to the geometry of the smooth surfaces extracted from the scene. Individual symmetries are used as constraints for the foreground segmentation problem that uses symmetry as a global grouping principle. Evaluation on a challenging dataset shows that our approach can reliably segment objects and extract their symmetries from incomplete 3D reconstructions of highly cluttered scenes, outperforming state-of-the-art methods by a wide margin.
ER  - 

TY  - CONF
TI  - Efficient Pose Estimation from Single RGB-D Image via Hough Forest with Auto-Context
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7201
EP  - 7206
AU  - H. Dong
AU  - Dilip K. Prasad
AU  - Q. Yuan
AU  - J. Zhou
AU  - E. Asadi
AU  - I. Chen
PY  - 2018
KW  - feature extraction
KW  - image classification
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - object detection
KW  - pose estimation
KW  - probability
KW  - regression analysis
KW  - 6D pose
KW  - public datasets
KW  - high efficient learning approach
KW  - robotic grasps
KW  - cascaded Hough forests
KW  - pose distribution
KW  - classification framework
KW  - joint regression
KW  - Hough space
KW  - object class probability
KW  - random forest
KW  - cluttered environment
KW  - textured texture-less
KW  - auto-context
KW  - single RGB-D image
KW  - efficient pose estimation
KW  - Training
KW  - Forestry
KW  - Vegetation
KW  - Three-dimensional displays
KW  - Reservoirs
KW  - Pose estimation
KW  - Covariance matrices
DO  - 10.1109/IROS.2018.8594064
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a high efficient learning approach to estimating 6D (Degree of Freedom) pose of the textured or texture-less objects for grasping purposes in a cluttered environment where the objects might be partially occluded. The method comprises three main steps. Given a single RGB-D image, we first deploy appropriate features and the random forest to deduce the object class probability and cast votes for the 6D pose in Hough space by joint regression and classification framework, adopting reservoir sampling and summarizing the pose distribution by clustering. Next, we integrate the auto-context into cascaded Hough forests to improve the efficiency of learning. Extensive experiments on various public datasets and robotic grasps indicate that our method presents some improvements over the state-of-art and reveals the capability for estimating poses in practical applications efficiently.
ER  - 

TY  - CONF
TI  - Plenoptic Monte Carlo Object Localization for Robot Grasping Under Layered Translucency
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 8
AU  - Z. Zhou
AU  - Z. Sui
AU  - O. C. Jenkins
PY  - 2018
KW  - approximation theory
KW  - cameras
KW  - Gaussian distribution
KW  - image colour analysis
KW  - manipulators
KW  - Monte Carlo methods
KW  - robot vision
KW  - stained glass panels
KW  - object poses
KW  - Monte Carlo object localization algorithm
KW  - localizing objects
KW  - manipulating objects
KW  - translucent materials
KW  - Lytro first generation light field camera
KW  - robot grasping
KW  - layered translucency
KW  - human environments
KW  - robot perception
KW  - open challenges
KW  - transparent objects
KW  - drinking glasses
KW  - refractive media
KW  - partial occlusions
KW  - Michigan progress fetch robot
KW  - plenoptic Monte Carlo object localization
KW  - depth likelihood volume
KW  - PMCL
KW  - Three-dimensional displays
KW  - Cameras
KW  - Glass
KW  - Monte Carlo methods
KW  - Pose estimation
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593629
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In order to fully function in human environments, robot perception needs to account for the uncertainty caused by translucent materials. Translucency poses several open challenges in the form of transparent objects (e.g., drinking glasses), refractive media (e.g., water), and diffuse partial occlusions (e.g., objects behind stained glass panels). This paper presents Plenoptic Monte Carlo Localization (PMCL)as a method for localizing object poses in the presence of translucency using plenoptic (light-field)observations. We propose a new depth descriptor, the Depth Likelihood Volume (DLV), and its use within a Monte Carlo object localization algorithm. We present results of localizing and manipulating objects with translucent materials and objects occluded by layers of translucency. Our PMCL implementation uses observations from a Lytro first generation light field camera to allow a Michigan Progress Fetch robot to perform grasping.
ER  - 

TY  - CONF
TI  - Pose Estimation for Objects with Rotational Symmetry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7215
EP  - 7222
AU  - E. Corona
AU  - K. Kundu
AU  - S. Fidler
PY  - 2018
KW  - CAD
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pose estimation
KW  - solid modelling
KW  - neural network
KW  - test time
KW  - symmetry-labeled objects
KW  - unlabeled CAD models
KW  - pose estimation
KW  - widely explored problem
KW  - poses
KW  - training time
KW  - 3D CAD models
KW  - rotational symmetry
KW  - Solid modeling
KW  - Three-dimensional displays
KW  - Pose estimation
KW  - Training
KW  - Shape
KW  - Neural networks
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8594282
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Pose estimation is a widely explored problem, enabling many robotic tasks such as grasping and manipulation. In this paper, we tackle the problem of pose estimation for objects that exhibit rotational symmetry, which are common in man-made and industrial environments. In particular, our aim is to infer poses for objects not seen at training time, but for which their 3D CAD models are available at test time. Previous work has tackled this problem by learning to compare captured views of real objects with the rendered views of their 3D CAD models, by embedding them in a joint latent space using neural networks. We show that sidestepping the issue of symmetry in this scenario during training leads to poor performance at test time. We propose a model that reasons about rotational symmetry during training by having access to only a small set of symmetry-labeled objects, whereby exploiting a large collection of unlabeled CAD models. We demonstrate that our approach significantly outperforms a naively trained neural network on a new pose dataset containing images of tools and hardware.
ER  - 

TY  - CONF
TI  - Fully Convolutional Grasp Detection Network with Oriented Anchor Box
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7223
EP  - 7230
AU  - X. Zhou
AU  - X. Lan
AU  - H. Zhang
AU  - Z. Tian
AU  - Y. Zhang
AU  - N. Zheng
PY  - 2018
KW  - feature extraction
KW  - feedforward neural nets
KW  - grippers
KW  - human-robot interaction
KW  - image classification
KW  - image colour analysis
KW  - image matching
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object recognition
KW  - regression analysis
KW  - robot vision
KW  - parallel-plate robotic gripper
KW  - RGB images
KW  - oriented anchor box mechanism
KW  - matching strategy
KW  - end-to-end fully convolutional neural network
KW  - feature extractor
KW  - deep convolutional neural network
KW  - multigrasp predictor regresses
KW  - predefined oriented rectangles
KW  - anchor boxes
KW  - standard Cornell Grasp Dataset
KW  - image-wise split
KW  - object-wise split
KW  - latest state-of-the-art approach
KW  - grasping poses
KW  - convolutional grasp detection network
KW  - Feature extraction
KW  - Robots
KW  - Computational modeling
KW  - Grippers
KW  - Solid modeling
KW  - Computer architecture
KW  - Predictive models
DO  - 10.1109/IROS.2018.8594116
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a real-time approach to predict multiple grasping poses for a parallel-plate robotic gripper using RGB images. A model with oriented anchor box mechanism is proposed and a new matching strategy is used during the training process. An end-to-end fully convolutional neural network is employed in our work. The network consists of two parts: the feature extractor and multi-grasp predictor. The feature extractor is a deep convolutional neural network. The multi-grasp predictor regresses grasp rectangles from predefined oriented rectangles, called oriented anchor boxes, and classifies the rectangles into graspable and ungraspable. On the standard Cornell Grasp Dataset, our model achieves an accuracy of 97.74% and 96.61% on image-wise split and object-wise split respectively, and outperforms the latest state-of-the-art approach by 1.74% on image-wise split and 0.51% on object-wise split.
ER  - 

TY  - CONF
TI  - A Probabilistic Approach to Benchmarking and Performance Evaluation of Robot Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7231
EP  - 7236
AU  - P. U. Lima
PY  - 2018
KW  - path planning
KW  - probability
KW  - robots
KW  - performance degradation
KW  - probabilistic approach
KW  - performance evaluation
KW  - robot system
KW  - human-robot interaction
KW  - task planning
KW  - robotics
KW  - benchmarking evaluation
KW  - performance assessment problem
KW  - Task analysis
KW  - Robots
KW  - Benchmark testing
KW  - Reliability
KW  - Measurement
KW  - Approximation algorithms
KW  - Probabilistic logic
DO  - 10.1109/IROS.2018.8594345
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Problem benchmarks are used in experimental science as a reference against which results of experiments using distinct approaches to solve the problem are compared and evaluated in relative terms. In Robotics, just formulating a general performance assessment problem is difficult per se, as robot systems are composed of very diverse subsystems (e.g., localisation, human-robot interaction, task planning, motion planning). This paper introduces a probabilistic approach to benchmarking and evaluating performance of robot systems, which uses probability theory as the common language to quantify the performance of distinct functionalities of a robot system and their impact on the performance of a task carried out by that system. The approach can be used to analyse the performance of a task plan from the performances if its composing functionalities, or to (re)plan when a performance degradation in functionality is predicted to cause performance degradation of the task plan beyond acceptable limits.
ER  - 

TY  - CONF
TI  - Improving Repeatability of Experiments by Automatic Evaluation of SLAM Algorithms
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7237
EP  - 7243
AU  - F. Amigoni
AU  - V. Castelli
AU  - M. Luperto
PY  - 2018
KW  - robot vision
KW  - SLAM (robots)
KW  - SLAM algorithms
KW  - robotics
KW  - repeatability
KW  - Simultaneous Localization And Mapping
KW  - Simultaneous localization and mapping
KW  - Buildings
KW  - Measurement
KW  - Data models
KW  - Lasers
DO  - 10.1109/IROS.2018.8594189
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The development of good experimental methodologies for robotics takes often inspiration from general principles of experimental practice. Repeatability prescribes that experiments should involve several trials in order to guarantee that results are not achieved by chance, but are systematic, and statistically significant trends can be identified. In this paper, we propose an approach to improve the repeatability of experiments performed in robotics. In particular, we focus on the domain of SLAM (Simultaneous Localization And Mapping) and we introduce a system that exploits simulations to generate a large number of test data on which SLAM algorithms are automatically evaluated in order to obtain consistent results, according to the principle of repeatability.
ER  - 

TY  - CONF
TI  - A Tutorial on Quantitative Trajectory Evaluation for Visual(-Inertial) Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7244
EP  - 7251
AU  - Z. Zhang
AU  - D. Scaramuzza
PY  - 2018
KW  - distance measurement
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - quantitative trajectory evaluation
KW  - trajectory alignment
KW  - specific sensing modality
KW  - error metrics
KW  - absolute trajectory error
KW  - relative error
KW  - visual odometry
KW  - Trajectory
KW  - Cameras
KW  - Noise measurement
KW  - Tutorials
KW  - Sensors
KW  - Visualization
DO  - 10.1109/IROS.2018.8593941
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this tutorial, we provide principled methods to quantitatively evaluate the quality of an estimated trajectory from visual(-inertial) odometry (VO/VIO), which is the foundation of benchmarking the accuracy of different algorithms. First, we show how to determine the transformation type to use in trajectory alignment based on the specific sensing modality (i.e., monocular, stereo and visual-inertial). Second, we describe commonly used error metrics (i.e., the absolute trajectory error and the relative error) and their strengths and weaknesses. To make the methodology presented for VO/VIO applicable to other setups, we also generalize our formulation to any given sensing modality. To facilitate the reproducibility of related research, we publicly release our implementation of the methods described in this tutorial.
ER  - 

TY  - CONF
TI  - Long-Duration Autonomy for Small Rotorcraft UAS Including Recharging
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7252
EP  - 7258
AU  - C. Brommer
AU  - D. Malyuta
AU  - D. Hentzen
AU  - R. Brockers
PY  - 2018
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - mobile robots
KW  - surveillance
KW  - autonomous small rotorcraft
KW  - autonomous operation
KW  - UAS
KW  - recharging station
KW  - vision-based precision landing
KW  - human operators
KW  - mission execution
KW  - emergency response
KW  - unmanned aerial vehicle surveillance
KW  - Global Positioning System
KW  - Batteries
KW  - Magnetometers
KW  - Sensors
KW  - Monitoring
KW  - Three-dimensional displays
KW  - State estimation
DO  - 10.1109/IROS.2018.8594111
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many unmanned aerial vehicle surveillance and monitoring applications require observations at precise locations over long periods of time, ideally days or weeks at a time (e.g. ecosystem monitoring), which has been impractical due to limited endurance and the requirement of humans in the loop for operation. To overcome these limitations, we propose a fully autonomous small rotorcraft UAS that is capable of performing repeated sorties for long-term observation missions without any human intervention. We address two key technologies that are critical for such a system: full platform autonomy including emergency response to enable mission execution independently from human operators, and the ability of vision-based precision landing on a recharging station for automated energy replenishment. Experimental results of up to 11 hours of fully autonomous operation in indoor and outdoor environments illustrate the capability of our system.
ER  - 

TY  - CONF
TI  - Real-Time Feature Depth Estimation for Image-Based Visual ServOing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7314
EP  - 7320
AU  - X. Li
AU  - H. Zhao
AU  - H. Ding
PY  - 2018
KW  - cameras
KW  - feature selection
KW  - nonlinear control systems
KW  - observability
KW  - observers
KW  - reduced order systems
KW  - robot vision
KW  - stability
KW  - visual servoing
KW  - nonlinear reduced-order observer structure
KW  - global asymptotic convergence property
KW  - restrictive observability condition
KW  - depth observer
KW  - camera calibration error
KW  - image-based visual servoing schemes
KW  - interaction matrix
KW  - real-time feature depth estimation
KW  - Observers
KW  - Cameras
KW  - Convergence
KW  - Visual servoing
KW  - Acceleration
DO  - 10.1109/IROS.2018.8593402
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Without the 3-D geometry of the target and robust to camera calibration error, image-based visual servoing schemes have gained a lot of attention. However, the depth of the selected feature, which is involved in the interaction matrix relating the time variation of the feature to the velocity twist of the camera, must be estimated correctly to guarantee the stability of the controller. To this end, this paper proposes a new nonlinear reduced-order observer structure to recover the feature depth in real time. Compared with the existing works, the proposed observer has a global asymptotic convergence property and fast convergence rate, and the convergence rate can be easily adjusted only using a single gain parameter. In addition, the proposed observer has a less restrictive observability condition and stronger robustness to noisy measurements. Extensive comparative numerical simulations are carried out to validate the effectiveness of the proposed depth observer.
ER  - 

TY  - CONF
TI  - Fast Convergence for Object Detection by Learning how to Combine Error Functions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7329
EP  - 7335
AU  - B. Schnieders
AU  - K. Tuvls
PY  - 2018
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - neural nets
KW  - object detection
KW  - union metric
KW  - estimated pickup rate
KW  - convergence time
KW  - optimally weighted Euclidean distance loss
KW  - object detection network
KW  - robotic pickup operation
KW  - approximate measure
KW  - detecting objects
KW  - fully convolutional segmentation network
KW  - RoboCup@Work challenge environment
KW  - on-line trained auxiliary network
KW  - dependent loss metrics
KW  - Converge-fast-auxnet
KW  - object detection neural networks
KW  - convergence speed
KW  - error functions
KW  - fast convergence
KW  - Object detection
KW  - Training
KW  - Convergence
KW  - Task analysis
KW  - Mathematical model
KW  - Euclidean distance
DO  - 10.1109/IROS.2018.8594179
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we introduce an innovative method to improve the convergence speed and accuracy of object detection neural networks. Our approach, Converge-fast-auxnet, is based on employing multiple, dependent loss metrics and weighting them optimally using an on-line trained auxiliary network. Experiments are performed in the well-known RoboCup@Work challenge environment. A fully convolutional segmentation network is trained on detecting objects' pickup points. We empirically obtain an approximate measure for the rate of success of a robotic pickup operation based on the accuracy of the object detection network. Our experiments show that adding an optimally weighted Euclidean distance loss to a network trained on the commonly used Intersection over Union (IoU) metric reduces the convergence time by 42.48%. The estimated pickup rate is improved by 39.90%. Compared to state-of-the-art task weighting methods, the improvement is 24.5% in convergence, and 15.8% on the estimated pickup rate.
ER  - 

TY  - CONF
TI  - Towards Real-Time Physical Human-Robot Interaction Using Skeleton Information and Hand Gestures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - O. Mazhar
AU  - S. Ramdani
AU  - B. Navarro
AU  - R. Passama
AU  - A. Cherubini
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - feedforward neural nets
KW  - gesture recognition
KW  - human-robot interaction
KW  - robot vision
KW  - l physical human-robot interaction
KW  - dynamic gestures
KW  - human-robot interaction scenarios
KW  - intelligent human intention detection
KW  - hand gesture recognition
KW  - hand images
KW  - 3D skeletal joint coordinates
KW  - state-of-the-art 2D skeleton extraction library
KW  - time-of-flight depth camera
KW  - meaningful gesture
KW  - reliable 3D skeleton extraction
KW  - human operator
KW  - skeleton information
KW  - towards real-time physical human-robot interaction
KW  - Robot sensing systems
KW  - Skeleton
KW  - Robot kinematics
KW  - Gesture recognition
KW  - Human-robot interaction
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594385
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - For successful physical human-robot interaction, the capability of a robot to understand its environment is imperative. More importantly, the robot should extract from the human operator as much information as possible. A reliable 3D skeleton extraction is essential for a robot to predict the intentions of the operator while s/he moves toward the robot or performs a meaningful gesture. For this purpose, we have integrated a time-of-flight depth camera with a state-of-the-art 2D skeleton extraction library namely Openpose, to obtain 3D skeletal joint coordinates reliably. We have also developed a robust and rotation invariant (in the coronal plane)hand gesture detector using a convolutional neural network. At run time (after having been trained)the detector does not require any pre-processing of the hand images. A complete pipeline for skeleton extraction and hand gesture recognition is developed and employed for real-time physical human-robot interaction, demonstrating the promising capability of the designed framework. This work establishes a firm basis and will be extended for the development of intelligent human intention detection in physical human-robot interaction scenarios, to efficiently recognize a variety of static as well as dynamic gestures.
ER  - 

TY  - CONF
TI  - LiDAR and Camera Calibration Using Motions Estimated by Sensor Fusion Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7342
EP  - 7349
AU  - R. Ishikawa
AU  - T. Oishi
AU  - K. Ikeuchi
PY  - 2018
KW  - calibration
KW  - cameras
KW  - distance measurement
KW  - image sensors
KW  - motion estimation
KW  - motion measurement
KW  - optical radar
KW  - sensor fusion
KW  - camera imaging
KW  - automatic targetless camera-LiDAR calibration method
KW  - 2D-3D calibration
KW  - scaled camera motion calculation
KW  - three-dimensional point cloud
KW  - motion estimation
KW  - sensor-fusion odometry method
KW  - hand-eye calibration framework
KW  - LiDAR reflectance data
KW  - Cameras
KW  - Calibration
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Two dimensional displays
KW  - Estimation
KW  - Sensor fusion
DO  - 10.1109/IROS.2018.8593360
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a targetless and automatic camera-LiDAR calibration method. Our approach extends the hand-eye calibration framework to 2D-3D calibration. The scaled camera motions are accurately calculated using a sensor-fusion odometry method. We also clarify the suitable motions for our calibration method. Whereas other calibrations require the LiDAR reflectance data and an initial extrinsic parameter, the proposed method requires only the three-dimensional point cloud and the camera image. The effectiveness of the method is demonstrated in experiments using several sensor configurations in indoor and outdoor scenes. Our method achieved higher accuracy than comparable state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Edge and Corner Detection for Unorganized 3D Point Clouds with Application to Robotic Welding
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7350
EP  - 7355
AU  - S. M. Ahmed
AU  - Y. Z. Tan
AU  - C. M. Chew
AU  - A. A. Mamun
AU  - F. S. Wong
PY  - 2018
KW  - computer vision
KW  - edge detection
KW  - feature extraction
KW  - image recognition
KW  - image representation
KW  - image segmentation
KW  - stereo image processing
KW  - robotic welding
KW  - weld seams
KW  - point cloud
KW  - welding paths
KW  - Harris 3D
KW  - unorganized point clouds
KW  - edge detection method
KW  - local neighborhood
KW  - adaptive density
KW  - corner detector
KW  - clusters curvature vectors
KW  - RGB-D semantic segmentation
KW  - 3D washer models
KW  - recall scores
KW  - automatic weld seam detection
KW  - Three-dimensional displays
KW  - Image edge detection
KW  - Welding
KW  - Feature extraction
KW  - Corner detection
KW  - Clustering algorithms
KW  - Detectors
DO  - 10.1109/IROS.2018.8593910
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose novel edge and corner detection algorithms for unorganized point clouds. Our edge detection method evaluates symmetry in a local neighborhood and uses an adaptive density based threshold to differentiate 3D edge points. We extend this algorithm to propose a novel corner detector that clusters curvature vectors and uses their geometrical statistics to classify a point as corner. We perform rigorous evaluation of the algorithms on RGB-D semantic segmentation and 3D washer models from the ShapeNet dataset and report higher precision and recall scores. Finally, we also demonstrate how our edge and corner detectors can be used as a novel approach towards automatic weld seam detection for robotic welding. We propose to generate weld seams directly from a point cloud as opposed to using 3D models for offline planning of welding paths. For this application, we show a comparison between Harris 3D and our proposed approach on a panel workpiece.
ER  - 

TY  - CONF
TI  - Automatic Fall Risk Assessment for Challenged Users Obtained from a Rollator Equipped with Force Sensors and a RGB-D Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7356
EP  - 7361
AU  - J. Ballesteros
AU  - J. M. Peula
AU  - A. B. Martinez
AU  - C. Urdiales
PY  - 2018
KW  - force sensors
KW  - gait analysis
KW  - handicapped aids
KW  - patient rehabilitation
KW  - risk management
KW  - medical staff
KW  - rehabilitation process
KW  - preferred environments
KW  - assistive navigation
KW  - imminent fall risk estimator
KW  - automatic fall risk assessment
KW  - challenged users
KW  - force sensors
KW  - RGB-d camera
KW  - rollator
KW  - cognitive disability
KW  - physical disability
KW  - Tinetti mobility test
KW  - walking speed
KW  - Wearable sensors
KW  - Force sensors
KW  - Senior citizens
KW  - Foot
KW  - Legged locomotion
KW  - Assistive devices
DO  - 10.1109/IROS.2018.8594122
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Fall risk assessments provide a useful tool to prevent morbidity and mortality provoked by falls. Nowadays, these assessments are usually performed manually by the medical staff. This approach has three main drawbacks: (i) it is time consuming, so it is only performed a few times per volunteer during their rehabilitation process; (ii) it requires supervision by medical staff, so assessment at home or preferred environments is not feasible; and (iii) fall risk is evaluated in a global way, so imminent fall risk is not available for decision making in assistive navigation. In this paper we propose an imminent fall risk estimator for rollator's users that can be automatically obtained on the fly. Its main advantages are: (i) it can be used in everyday conditions in any environment; (ii) it does not require assistance of medical staff; and (iii) it is suitable for a variety of users with minimal configuration changes. We have validated our estimator with a set of volunteers (n=10) presenting different physical and cognitive disabilities. Although the number of volunteer is limited, results show that our estimator is coherent to two traditional, well accepted assessments: the Tinetti Mobility Test and the walking speed.
ER  - 

TY  - CONF
TI  - ARIADNE with Ambiguity Resolution: Visual Marker Based Rapid Initialization of PPP-AR
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7362
EP  - 7368
AU  - K. Watanabe
PY  - 2018
KW  - agriculture
KW  - Global Positioning System
KW  - carrier phase ambiguity resolution
KW  - precise point positioning
KW  - real-time kinematic positioning
KW  - accurate fiducial marker
KW  - ARIADNE
KW  - Earth-fixed coordinates
KW  - mining
KW  - precise agriculture
KW  - ground base station
KW  - visual marker
KW  - PPP-AR
KW  - initialization process
KW  - positioning accuracy
KW  - initial convergence time
KW  - Global navigation satellite system
KW  - Position measurement
KW  - Antenna measurements
KW  - Antennas
KW  - Convergence
KW  - Cameras
DO  - 10.1109/IROS.2018.8593863
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Precise Point Positioning (PPP) offers advantages over Real-Time Kinematic (RTK) positioning in that it needs no ground base station or a rover to provide a communication channel with the base station. Therefore, PPP is expected to be applied in various fields, such as precise agriculture, intelligent transportation, construction, and mining. One major drawback of PPP is that it takes several tens of minutes for initial convergence to reach an adequate level of accuracy, and how to shorten the convergence time remains the key issue regarding the proliferation of PPP. In our previous work, we proposed a method of drastically reducing this initial convergence time of PPP (called “ARIADNE”) by using an accurate fiducial marker whose position in Earth-fixed coordinates has been accurately measured using an onboard camera. In this contribution, in order to improve both the positioning accuracy and reliability, we introduce some new techniques to ARIADNE: (1) carrier phase ambiguity resolution (AR); and (2) estimating displacement of the marker's orientation. AR results in doubling the positioning accuracy, while displacement estimation enables the detection of any change in the marker's installation orientation and compensation for the effect thereof in the initialization process. Analytical results based on actual data acquired with a prototype system show that the above method and techniques work very well with a realistic setup of PPP-AR and marker performance, and successfully reduce the initial convergence time from tens of minutes to less than a minute.
ER  - 

TY  - CONF
TI  - Fast Trajectory Planning for Automated Vehicles Using Gradient-Based Nonlinear Model Predictive Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7369
EP  - 7374
AU  - F. Gritschneder
AU  - K. Graichen
AU  - K. Dietmayer
PY  - 2018
KW  - gradient methods
KW  - mobile robots
KW  - nonlinear control systems
KW  - optimisation
KW  - path planning
KW  - predictive control
KW  - road vehicles
KW  - automated vehicles
KW  - motion trajectory planning
KW  - dynamically changing environment
KW  - nonlinear system dynamics
KW  - automated driving
KW  - nonlinear system model
KW  - optimization algorithms
KW  - gradient-based nonlinear model predictive control
KW  - standard PC
KW  - Mathematical model
KW  - Planning
KW  - Vehicle dynamics
KW  - Trajectory
KW  - Optimization
KW  - Task analysis
KW  - Heuristic algorithms
DO  - 10.1109/IROS.2018.8593913
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion trajectory planning is one crucial aspect for automated vehicles, as it governs the own future behavior in a dynamically changing environment. A good utilization of a vehicle's characteristics requires the consideration of the nonlinear system dynamics within the optimization problem to be solved. In particular, real-time feasibility is essential for automated driving, in order to account for the fast changing surrounding, e.g. for moving objects. The key contributions of this paper are the presentation of a fast optimization algorithm for trajectory planning including the nonlinear system model. Further, a new concurrent operation scheme for two optimization algorithms is derived and investigated. The proposed algorithm operates in the submillisecond range on a standard PC. As an exemplary scenario, the task of driving along a challenging reference course is demonstrated.
ER  - 

TY  - CONF
TI  - Humanoid Navigation Planning in Large Unstructured Environments Using Traversability - Based Segmentation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7375
EP  - 7382
AU  - Y. Lin
AU  - D. Berenson
PY  - 2018
KW  - collision avoidance
KW  - humanoid robots
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - planning (artificial intelligence)
KW  - robot kinematics
KW  - humanoid navigation planning
KW  - unstructured environments
KW  - disaster response efforts
KW  - navigation planners
KW  - considering palm contacts
KW  - impractical planning times
KW  - library-based method
KW  - easy-to-traverse part
KW  - discrete planners
KW  - easily-traversable segments
KW  - discrete-search planner
KW  - motion plans
KW  - standard discrete planning
KW  - navigation planning problems
KW  - traversability -based segmentation
KW  - Planning
KW  - Motion segmentation
KW  - Torso
KW  - Navigation
KW  - Humanoid robots
KW  - Foot
DO  - 10.1109/IROS.2018.8593694
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Humanoids' abilities to navigate stairs and uneven terrain make them well-suited for disaster response efforts. However, humanoid navigation in such environments is currently limited by the capabilities of navigation planners. Such planners typically consider only footstep locations, but planning with palm contacts may be necessary to cross a gap, avoid an obstacle, or maintain balance. However, considering palm contacts greatly increases the branching factor of the search, leading to impractical planning times for large environments. In previous work we explored using library-based methods to address difficult navigation planning problems requiring palm contacts, but such methods are not efficient when navigating an easy-to-traverse part of the environment. To maximize planning efficiency, we would like to use discrete planners when an area is easy to traverse and switch to the library-based method only when traversal becomes difficult. Thus, in this paper we present a method that 1) Plans a guiding torso path which accounts for the difficulty of traversing the environment as predicted by learned regressors; and 2) Decomposes the guiding path into a set of segments, each of which is assigned a motion mode (i.e. a set of feet and hands to use) and a planning method. Easily-traversable segments are assigned a discrete-search planner, while other segments are assigned a library-based method that fits existing motion plans to the environment near the given segment. Our results suggest that this segmentation approach greatly outperforms standard discrete planning and that using the library-based method for more difficult segments gives a benefit over using discrete planning.
ER  - 

TY  - CONF
TI  - Guaranteed Coverage with a Blind Unreliable Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7383
EP  - 7390
AU  - J. S. Lewis
AU  - D. A. Feshbach
AU  - J. M. O'Kane
PY  - 2018
KW  - graph theory
KW  - mobile robots
KW  - path planning
KW  - guaranteed coverage
KW  - blind unreliable robot
KW  - coverage planning
KW  - simple mobile robot
KW  - heuristic algorithm
KW  - specially-constructed graph
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Planning
KW  - Navigation
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8594048
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We consider the problem of coverage planning for a particular type of very simple mobile robot. The robot must be able to translate in a commanded direction (specified in a global reference frame), with bounded error on the motion direction, until reaching the environment boundary. The objective, for a given environment map, is to generate a sequence of motions that is guaranteed to cover as large a portion of that environment as possible, in spite of the severe limits on the robot's sensing and actuation abilities. We show how to model the knowledge available to this kind of robot about its own position within the environment, show how to compute the region whose coverage can be guaranteed for a given plan, and characterize regions whose coverage cannot be guaranteed by any plan. We also describe a heuristic algorithm that generates coverage plans for this robot, based on a search across a specially-constructed graph. Simulation results demonstrate the effectiveness of the approach.
ER  - 

TY  - CONF
TI  - Single Leg Dynamic Motion Planning with Mixed-Integer Convex Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 6
AU  - Y. Ding
AU  - C. Li
AU  - H. Park
PY  - 2018
KW  - actuators
KW  - approximation theory
KW  - convex programming
KW  - integer programming
KW  - Jacobian matrices
KW  - legged locomotion
KW  - path planning
KW  - quadratic programming
KW  - robot dynamics
KW  - trigonometrical terms
KW  - Jacobian matrix
KW  - optimization problem
KW  - mixed-integer quadratically-constrained program
KW  - convex outer approximation
KW  - torque ellipsoid
KW  - semidefinite program
KW  - bilinear terms
KW  - McCormick envelope convex relaxation
KW  - actuator torque
KW  - leg dynamic motion planning
KW  - MIQCP
KW  - SDP
KW  - mixed-integer convex programming
KW  - Torque
KW  - Dynamics
KW  - Planning
KW  - Legged locomotion
KW  - Ellipsoids
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594161
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper proposes a mixed-integer convex programming formulation for dynamic motion planning. Many dynamic constraints such as the actuator torque constraint are nonlinear and non-convex due to the trigonometrical terms from the Jacobian matrix. This often causes the optimization problem to converge to local optima or even infeasible set. In this paper, we convexify the torque constraint by formulating a mixed-integer quadratically-constrained program (MIQCP). More specifically, the workspace is discretized into a union of disjoint polytopes and torque constraint is enforced upon a convex outer approximation of the torque ellipsoid, obtained by solving a semidefinite program (SDP). Bilinear terms are approximated by McCormick envelope convex relaxation. The proposed MIQCP framework could be solved efficiently to global optimum and the generated trajectories could exploit the rich features of the rough terrain without any initial guess from the designer. The demonstrated experiment results prove that this approach is currently capable of planning consecutive jumps that navigates a single-legged robot through challenging terrains.
ER  - 

TY  - CONF
TI  - Multi-Layer Coverage Path Planner for Autonomous Structural Inspection of High-Rise Structures
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Jung
AU  - S. Song
AU  - P. Youn
AU  - H. Myung
PY  - 2018
KW  - autonomous aerial vehicles
KW  - inspection
KW  - path planning
KW  - structural engineering
KW  - travelling salesman problems
KW  - autonomous structural inspection
KW  - high-rise structures
KW  - buildings
KW  - towers
KW  - unmanned aerial vehicle
KW  - multi-layer coverage path planner
KW  - 3D coverage path planning
KW  - traveling salesman problem
KW  - Inspection
KW  - Three-dimensional displays
KW  - Path planning
KW  - Planning
KW  - Unmanned aerial vehicles
KW  - Solid modeling
KW  - Spirals
DO  - 10.1109/IROS.2018.8593537
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a novel 3D coverage path planning method, which is efficient and practical for inspection of high-rise structures such as buildings or towers, using an unmanned aerial vehicle (UAV) is presented. Our approach basically focuses on developing a model-based path planner for structural inspection with a prior map, which is opposite to a non-model based exploration. The proposed method uses a volumetric map which is made before the path planning. With the map, the whole structure is divided into several layers for efficient path planning. Firstly, in each layer, a set of the normal vectors of the center point of every voxel is calculated, and then the opposing vectors become viewpoints. Due to too many viewpoints and an overlapped inspection surface, we down-sample them with a voxel grid filter. Then, the shortest tour connecting the reduced viewpoints must be computed with the Traveling Salesman Problem (TSP) solver. Lastly, all the paths in each layer are combined to form the complete path. The results are verified using simulations with a rotary wing UAV and compared with other state-of-the-art algorithm. It is proven that our method performs much better for structural inspection with respect to computation time as well as the coverage completeness.
ER  - 

TY  - CONF
TI  - Down the CLiFF: Flow-Aware Trajectory Planning Under Motion Pattern Uncertainty
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7403
EP  - 7409
AU  - C. S. Swaminathan
AU  - T. P. Kucner
AU  - M. Magnusson
AU  - L. Palmieri
AU  - A. J. Lilienthal
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - flow-aware tralatory planning
KW  - motion pattern uncertainty
KW  - flow-aware trajectory
KW  - dynamic environments
KW  - flow model uncertainty
KW  - flow-aware planning
KW  - statistical model
KW  - map flow patterns
KW  - biasing functions
KW  - RRT* planning algorithm
KW  - CLiFF-map model
KW  - flow-compliant trajectories
KW  - flow motion patterns
KW  - Trajectory
KW  - Robots
KW  - Planning
KW  - Cost function
KW  - Uncertainty
KW  - Vehicle dynamics
KW  - Aerospace electronics
DO  - 10.1109/IROS.2018.8593905
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we address the problem of flow-aware trajectory planning in dynamic environments considering flow model uncertainty. Flow-aware planning aims to plan trajectories that adhere to existing flow motion patterns in the environment, with the goal to make robots more efficient, less intrusive and safer. We use a statistical model called CLiFF-map that can map flow patterns for both continuous media and discrete objects. We propose novel cost and biasing functions for an RRT* planning algorithm, which exploits all the information available in the CLiFF-map model, including uncertainties due to flow variability or partial observability. Qualitatively, a benefit of our approach is that it can also be tuned to yield trajectories with different qualities such as exploratory or cautious, depending on application requirements. Quantitatively, we demonstrate that our approach produces more flow-compliant trajectories, compared to two baselines.
ER  - 

TY  - CONF
TI  - Efficient and Asymptotically Optimal Kinodynamic Motion Planning via Dominance-Informed Regions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Z. Littlefield
AU  - K. E. Bekris
PY  - 2018
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - robot dynamics
KW  - sampling methods
KW  - search problems
KW  - trees (mathematics)
KW  - dominance-informed regions
KW  - high quality path
KW  - search-based methods
KW  - sampling-based methods
KW  - DIRT
KW  - dominance-informed region tree
KW  - spatial exploration
KW  - robot dynamics
KW  - collision checking
KW  - informed search principles
KW  - asymptotically optimal kinodynamic motion planner
KW  - physics-based simulation
KW  - successful successor state
KW  - Task analysis
KW  - Trajectory
KW  - Planning
KW  - Aerospace electronics
KW  - Robots
KW  - Dynamics
KW  - Cost function
DO  - 10.1109/IROS.2018.8593672
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion planners have been recently developed that provide path quality guarantees for robots with dynamics. This work aims to improve upon their efficiency, while maintaining their properties. Inspired by informed search principles, one objective is to use heuristics. Nevertheless, comprehensive and fast spatial exploration of the state space is still important in robotics. For this reason, this work introduces Dominance-Informed Regions (DIR), which express both whether parts of the space are unexplored and whether they lies along a high quality path. Furthermore, to speed up the generation of a successful successor state, which involves collision checking or physics-based simulation, a proposed strategy generates the most promising successor in an informed way, while maintaing properties. Overall, this paper introduces a new informed and asymptotically optimal kinodynamic motion planner, the Dominance-Informed Region Tree (DIRT). The method balances exploration-exploitation tradeoffs without many explicit parameters. It is shown to outperform sampling-based and search-based methods for robots to significant dynamics.
ER  - 

TY  - CONF
TI  - High-Speed and Intelligent Pre-Grasp Motion by a Robotic Hand Equipped with Hierarchical Proximity Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7424
EP  - 7431
AU  - Y. Hirai
AU  - Y. Suzuki
AU  - T. Tsuji
AU  - T. Watanabe
PY  - 2018
KW  - manipulators
KW  - motion measurement
KW  - optical sensors
KW  - photodetectors
KW  - shape measurement
KW  - size measurement
KW  - high-speed intelligent pre-grasp motion
KW  - hierarchical optical proximity sensor
KW  - robotic hand manipulation
KW  - shape recognition
KW  - size recognition
KW  - photodetectors
KW  - high-speed feedback control
KW  - robot fingertips
KW  - vision sensors
KW  - time 1.0 s
KW  - Robot sensing systems
KW  - Phototransistors
KW  - Grasping
KW  - Photoconductivity
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594261
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Quickness, preciseness and robustness are required in manipulation tasks of robotic hands for automation of manufacturing sites. Previous researches have found that sensing from fingertips equipped with proximity sensors is available for the requirements, because it complements blind areas of vision sensors. In this paper, we develop a novel optical proximity sensor for robot fingertips which provides two levels of proximity information with different purposes, sampling rates, information quantity and quality. The lower-level information from the sensor is for high-speed feedback control of a robotic hand, and the higher-level information is for recognizing the shape and size of an object. A prototype of the sensor with 5 × 5 matrix of photo detectors is presented, and its availability is shown through basic characteristic tests. A motion experiment using a robotic hand equipped with the prototype sensors is also conducted. The result confirms that the robotic hand can adjust the position and orientation of the fingertips to various objects and then correct the grasping form according to the object size within 1s.
ER  - 

TY  - CONF
TI  - Dynamic Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Di Carlo
AU  - P. M. Wensing
AU  - B. Katz
AU  - G. Bledt
AU  - S. Kim
PY  - 2018
KW  - convex programming
KW  - legged locomotion
KW  - predictive control
KW  - robot dynamics
KW  - torque control
KW  - torque-controlled quadruped robot
KW  - convex model-predictive control
KW  - MIT cheetah 3
KW  - dynamic locomotion
KW  - ground reaction force planning problems
KW  - convex optimization
KW  - robot dynamics
KW  - Robot kinematics
KW  - Legged locomotion
KW  - Dynamics
KW  - Predictive control
KW  - Convex functions
KW  - Predictive models
DO  - 10.1109/IROS.2018.8594448
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an implementation of model predictive control (MPC) to determine ground reaction forces for a torque-controlled quadruped robot. The robot dynamics are simplified to formulate the problem as convex optimization while still capturing the full 3D nature of the system. With the simplified model, ground reaction force planning problems are formulated for prediction horizons of up to 0.5 seconds, and are solved to optimality in under 1 ms at a rate of 20-30 Hz. Despite using a simplified model, the robot is capable of robust locomotion at a variety of speeds. Experimental results demonstrate control of gaits including stand, trot, flying-trot, pronk, bound, pace, a 3-legged gait, and a full 3D gallop. The robot achieved forward speeds of up to 3 m/s, lateral speeds up to 1 m/s, and angular speeds up to 180 deg/sec. Our approach is general enough to perform all these behaviors with the same set of gains and weights.
ER  - 

TY  - CONF
TI  - Towards an Adaptive-Compliance Aerial Manipulator for Contact- Based Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - S. Hamaza
AU  - I. Georgilas
AU  - T. Richardson
PY  - 2018
KW  - actuators
KW  - autonomous aerial vehicles
KW  - inspection
KW  - manipulators
KW  - adaptive-compliance aerial manipulator
KW  - contact-based interaction
KW  - unmanned aerial vehicles
KW  - UAV
KW  - initial flight tests
KW  - novel adaptively compliant actuator
KW  - pick placement
KW  - remote sensors
KW  - structural testing
KW  - contact-based inspection
KW  - key results
KW  - active compliant manipulator
KW  - manipulator controller gains
KW  - physical pulses
KW  - vibration sensors
KW  - initial results
KW  - compliant aerial actuator
KW  - Manipulator dynamics
KW  - End effectors
KW  - Sensors
KW  - Force
KW  - Task analysis
KW  - Inspection
DO  - 10.1109/IROS.2018.8593576
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - As roles for unmanned aerial vehicles (UAVs)continue to diversify, the ability to sense and interact closely with the environment becomes increasingly important. Within this paper we report on the initial flight tests of a novel adaptively compliant actuator which will allow a UAV to carry out such tasks as the “pick and placement” of remote sensors, structural testing and contact-based inspection. Three key results are discussed and presented; the ability to physically apply forces with the UAV through the use of an active compliant manipulator; the ability to tailor these forces through tuning of the manipulator controller gains; and the ability to apply a rapid series of physical pulses in order to excite remotely placed sensors, e.g. vibration sensors. A series of over sixty flight tests have been used to generate initial results which clearly demonstrate the potential of this new type of compliant aerial actuator.
ER  - 

TY  - CONF
TI  - Optimal Input Waveform for an Indirectly Controlled Limit Cycle Walker
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7454
EP  - 7459
AU  - L. Li
AU  - I. Tokuda
AU  - F. Asano
PY  - 2018
KW  - control system synthesis
KW  - gait analysis
KW  - legged locomotion
KW  - limit cycles
KW  - numerical analysis
KW  - optimal control
KW  - oscillators
KW  - robot dynamics
KW  - torque
KW  - wheels
KW  - control mechanisms
KW  - limit cycle walker
KW  - forcing energy reduction
KW  - gait interval
KW  - Arnold tongues
KW  - optimal control design
KW  - numerical analysis
KW  - phase response curve
KW  - phase oscillators
KW  - rimless wheels
KW  - active wobbling mass
KW  - joint torques
KW  - underactuated locomotion robot
KW  - optimal input waveform
KW  - optimal forcing waveform
KW  - Wheels
KW  - Perturbation methods
KW  - Limit-cycles
KW  - Legged locomotion
KW  - Trajectory
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8594488
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Precisely manipulating the center of mass (CoM) of the underactuated locomotion robot can't be easily achieved by common control mechanisms which apply only joint torques. A novel and indirect method has been recently introduced using an active wobbling mass attached to limit cycle walkers. The next important issue is to design an optimal control input to reduce the forcing energy. In this paper, we use combined rimless wheels as a simplified example to apply our method, which is based on the theory of phase oscillators. First, we introduce the typical modeling and control of this underactuated robot. Second, we obtain the phase response curve by numerically applying perturbations at different phases of the walker's gait interval and calculating the deviations from the unperturbed. Third, we analytically derive an optimal forcing waveform for the wobbling mass to entrain the combined rimless wheel based on the phase response curve. As an ecological extension, an ideal forcing waveform for m: 1 entrainment was further generated. Finally, the proposed method was evaluated by locking range of the Arnold tongues. The results show that the optimal forcing waveform we derived achieves the best performance for 1:1 entrainment among all the candidates. One of the strongest advantages of our method is the easiness of its implementation, prompting its applicability to a wide variety of locomotion systems.
ER  - 

TY  - CONF
TI  - A Comparative Study on Sigma-Point Kalman Filters for Trajectory Estimation of Hybrid Aerial-Aquatic Vehicles
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7460
EP  - 7465
AU  - R. T. S. da Rosa
AU  - P. J. D. O. Evald
AU  - P. L. J. Drews
AU  - A. A. Neto
AU  - A. C. Horn
AU  - R. Z. Azzolin
AU  - S. S. C. Botelho
PY  - 2018
KW  - autonomous aerial vehicles
KW  - autonomous underwater vehicles
KW  - Kalman filters
KW  - Monte Carlo methods
KW  - nonlinear filters
KW  - robot dynamics
KW  - state estimation
KW  - detailed dynamic model simulation
KW  - nonlinear algorithm
KW  - derivative-free nonlinear Kalman Filters
KW  - Cubature Kalman Filter
KW  - CKF
KW  - nonlinear probabilistic estimators
KW  - average execution time
KW  - Monte Carlo simulations
KW  - in-production HUAUV prototype
KW  - state augmentation
KW  - sensor data filtering
KW  - trajectory estimation
KW  - high dimensional state spaces
KW  - comparative study
KW  - sigma-point Kalman
KW  - aerial-aquatic vehicles
KW  - nonlinear state estimation methods
KW  - transformed unscented Kalman filter
KW  - root-mean square error
KW  - hybrid unmanned aerial underwater vehicles
KW  - HUAUV
KW  - Kalman filters
KW  - Trajectory tracking
KW  - State estimation
KW  - Vehicle dynamics
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593556
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a study on nonlinear state estimation methods for Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs) is presented. Based on a detailed dynamic model simulation, we analyse and elect the best nonlinear algorithm among those presented in the state-of-the-art literature addressing local derivative-free nonlinear Kalman Filters (KFs): the Unscented Kalman Filter (UKF), the Cubature Kalman Filter (CKF) and the Transformed Unscented Kalman Filter (TUKF). Here, these three nonlinear probabilistic estimators were compared in terms of the Root Mean Square Error (RMSE) and the average execution time over Monte Carlo simulations. We simulated real-world conditions for our in-production HUAUV prototype using Inertial Measurement Unit (IMU) data and state augmentation for sensor data filtering and trajectory estimation. We have concluded that the CKF proved to be the most interesting KF to low-cost on-board applications for high dimensional state spaces.
ER  - 

TY  - CONF
TI  - Constrained Motion Cueing for Driving Simulators Using a Real-Time Nonlinear MPC Scheme
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7466
EP  - 7471
AU  - A. Lamprecht
AU  - J. Haecker
AU  - K. Graichen
PY  - 2018
KW  - nonlinear control systems
KW  - optimisation
KW  - predictive control
KW  - road traffic control
KW  - real-time nonlinear MPC scheme
KW  - motion cueing algorithm
KW  - MCA
KW  - nonlinear model predictive control
KW  - realistic motion feeling
KW  - realtime gradient algorithm
KW  - augmented Lagrangian method
KW  - constrained motion cueing
KW  - driving simulators
KW  - Acceleration
KW  - Fasteners
KW  - Real-time systems
KW  - Trajectory
KW  - Vehicles
KW  - Software algorithms
KW  - Minimization
DO  - 10.1109/IROS.2018.8594246
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This contribution presents a motion cueing algorithm (MCA) for driving simulators using nonlinear model predictive control (MPC). The goal of the MCA is to generate a realistic motion feeling while keeping the simulator within its workspace limits. The approach relies on a realtime gradient algorithm in combination with the augmented Lagrangian method in order to directly incorporate the system constraints into the optimization. Simulation results for a reference trajectory with typical driving situations demonstrate the performance as well as the computational efficiency of the approach.
ER  - 

TY  - CONF
TI  - Robust Humanoid Control Using a QP Solver with Integral Gains
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7472
EP  - 7479
AU  - R. Cisneros
AU  - M. Benallegue
AU  - A. Benallegue
AU  - M. Morisawa
AU  - H. Audren
AU  - P. Gergondet
AU  - A. Escande
AU  - A. Kheddar
AU  - F. Kanehiro
PY  - 2018
KW  - humanoid robots
KW  - Lyapunov methods
KW  - quadratic programming
KW  - robot dynamics
KW  - robust control
KW  - torque control
KW  - low-frequency bounded disturbances
KW  - Lyapunov-stable torque control
KW  - dynamical model
KW  - dynamic constraints
KW  - QP solver
KW  - kinetic joint friction
KW  - robust humanoid control
KW  - torque controlled humanoid robots
KW  - multiobjective weighted tasks
KW  - optimal dynamically-feasible reference
KW  - exponential convergence
KW  - joint torque feedback
KW  - nonmodelled torque bias
KW  - quadratic programming
KW  - HRP-5P robot
KW  - Torque
KW  - Humanoid robots
KW  - Convergence
KW  - Acceleration
KW  - Torque control
KW  - Task analysis
KW  - Robust control
KW  - Torque control
KW  - Passivity
KW  - Quadratic programming
KW  - Humanoid robots
DO  - 10.1109/IROS.2018.8593417
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a control framework for torque controlled humanoid robots that efficiently minimizes the tracking error in a Quadratic Programming (QP)formulated as multiobjective weighted tasks with constraints. It results in an optimal dynamically-feasible reference that can be tracked robustly, with exponential convergence, without joint torque feedback, in the presence of non modelled torque bias and low-frequency bounded disturbances. This is achieved by introducing integral gains in a Lyapunov-stable torque control, which exploit the passivity properties of the dynamical model of the robot and their effect on the dynamic constraints of the QP solver. The robustness of this framework is demonstrated in simulation by commanding our robot, the HRP-5P, to achieve simultaneously several objectives in the configuration and the Cartesian spaces, in the presence of non-modeled static and kinetic joint friction, as well as an uncertain torque scale.
ER  - 

TY  - CONF
TI  - Contact Localization and Force Estimation of Soft Tactile Sensors Using Artificial Intelligence
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7480
EP  - 7485
AU  - D. Kim
AU  - Y. Park
PY  - 2018
KW  - intelligent sensors
KW  - nearest neighbour methods
KW  - recurrent neural nets
KW  - skin
KW  - tactile sensors
KW  - recurrent neural network
KW  - Preisach model
KW  - multiple contact locations
KW  - k-nearest neighbors algorithm
KW  - artificial neural network
KW  - machine learning techniques
KW  - soft robotics applications
KW  - soft artificial skin sensors
KW  - artificial intelligence
KW  - soft tactile sensors
KW  - Sensors
KW  - Force
KW  - Hysteresis
KW  - Microchannels
KW  - Estimation
KW  - Wires
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8593440
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Soft artificial skin sensors that can detect contact forces as well as their locations are attractive in various soft robotics applications. However, soft sensors made of polymer materials have inherent limitations of hysteresis and nonlinearity in response, which makes it highly difficult to implement traditional calibration techniques and yields poor estimation performance. In this paper, we propose intelligent algorithms based on machine learning and logics that can improve the performance of soft sensors. The proposed methods in this paper could be solutions to the aforementioned long-standing problems. They can also be used to simplify the system complexity by reducing the number of signal wires. Three machine learning techniques are discussed in this paper: an artificial neural network (ANN), the k-nearest neighbors (k-NN) algorithm, and a recurrent neural network (RNN). The Preisach model of hysteresis and simple logics were used to support these algorithms. We proved that classifying contact locations on a soft sensor is possible using simple algorithms in real time. Also, force estimation of a single contact was possible using an ANN with the Preisach method. Finally, we successfully estimated forces of multiple contact locations by predicting the outputs of mixed RNN results.
ER  - 

TY  - CONF
TI  - A Biomimetic Soft Robot for Inspecting Pipeline with Significant Diameter Variation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7486
EP  - 7491
AU  - X. Zhang
AU  - T. Pan
AU  - H. L. Heung
AU  - P. W. Y. Chiu
AU  - Z. Li
PY  - 2018
KW  - biomimetics
KW  - diseases
KW  - industrial robots
KW  - inspection
KW  - pipelines
KW  - central pattern generator-based control system
KW  - pipeline inspection robots
KW  - earthworm-like soft robot
KW  - CPG-based control system
KW  - pipeline navigation
KW  - gastrointestinal tract inspection
KW  - tubular environment
KW  - biomimetic soft robot
KW  - Pipelines
KW  - Inspection
KW  - Actuators
KW  - Soft robotics
KW  - Mobile robots
KW  - Valves
DO  - 10.1109/IROS.2018.8594390
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Navigation through tubular environment is fundamental in tasks such as pipeline inspection, gastrointestinal tract inspection, etc. Conventional pipeline inspection robots are mostly made by rigid materials and could not well adapt to the large size variation of the environment. Soft robots provide an additional solution for inspection of pipelines, especially with significant size variation. In this work, we present a soft robot for pipeline inspection, which consists of an earthworm-like soft robot and a Central Pattern Generator (CPG)-based control system. An analytical model is developed to predict the maximum pipe diameter that the robot could adapt to. For the current prototype, the robot could adapt to size change of three times. Experimental results show that this robot could navigate through pipelines with sharp turnings and with large diameter change.
ER  - 

TY  - CONF
TI  - Continuum Manipulator with Redundant Backbones and Constrained Bending Curvature for Continuously Variable Stiffness
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7492
EP  - 7499
AU  - B. Zhao
AU  - W. Zhang
AU  - Z. Zhang
AU  - X. Zhu
AU  - K. Xu
PY  - 2018
KW  - bending
KW  - design engineering
KW  - elasticity
KW  - medical robotics
KW  - redundant manipulators
KW  - continuously constrained bending curvature
KW  - hyper-redundant articulated vertebrate structure
KW  - slender manipulators
KW  - surgical robots
KW  - snake-like manipulators
KW  - continuously variable stiffness
KW  - redundant backbones
KW  - redundantly arranged elastic backbones
KW  - simple continuum manipulator design
KW  - Manipulators
KW  - Electron tubes
KW  - Kinematics
KW  - Friction
KW  - Tendons
KW  - Strips
KW  - Lead
DO  - 10.1109/IROS.2018.8593437
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Snake-like manipulators can navigate and perform manipulation in confined spaces. Their recent implementations in surgical robots attracted a lot of attentions. These slender manipulators usually possess either a hyper-redundant articulated vertebrate structure or a continuum one. Primary design considerations usually converge to a balance between proper workspace and acceptable stiffness. Efforts have hence been constantly made to achieve higher or adjustable stiffness for a manipulator to widen its applications. This paper presents a simple continuum manipulator design with variable stiffness based on redundantly arranged elastic backbones and continuously constrained bending curvature. The design concepts, kinematics, a preliminary formulation for stiffness adjustment, system construction and experimental characterizations are elaborated. The results showed that the manipulator's stiffness can be increased up to 4.71 times of the value without the curvature constraining rod, indicating the efficacy of the proposed idea.
ER  - 

TY  - CONF
TI  - A Multisegment Electro-Active Polymer Based Milli-Continuum Soft Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7500
EP  - 7506
AU  - A. Benouhiba
AU  - K. Rabenorosoa
AU  - P. Rougeot
AU  - M. Ouisse
AU  - N. Andreff
PY  - 2018
KW  - cantilevers
KW  - electroactive polymer actuators
KW  - manipulator kinematics
KW  - polymers
KW  - millicontinuum soft robots
KW  - active flexible polymer actuator
KW  - multisegment robot
KW  - 3D arrangement
KW  - robot capability
KW  - three-segment CSR
KW  - two-segment CSR
KW  - single segment robot
KW  - multiphysics model
KW  - millimeter-size Continuum Soft Robot
KW  - multisegment electro-active polymer
KW  - Strain
KW  - Nonhomogeneous media
KW  - Soft robotics
KW  - Fabrication
KW  - Deformable models
KW  - Microactuators
DO  - 10.1109/IROS.2018.8593609
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design, modeling and fabrication of a millimeter-size Continuum Soft Robot (CSR). The robot consists of active flexible polymer actuator-based multisegment robot. A multiphysics model based on multilayer cantilever for large displacement is established between the input voltages to the distal tip position of a single segment robot. The extension of the model to multisegment CSR is derived. The proposed model is validated experimentally then a two-segment CSR and three-segment CSR in 3D arrangement are investigated, demonstrating the model efficiency for obtaining complex configuration. Moreover, various configurations can be explored to derive complex kinematics then increasing the robot capability.
ER  - 

TY  - CONF
TI  - A Compact Wheeled Robot that Can Jump while Rolling
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7507
EP  - 7512
AU  - K. Misu
AU  - A. Yoshii
AU  - H. Mochiyama
PY  - 2018
KW  - buckling
KW  - elasticity
KW  - mobile robots
KW  - robot dynamics
KW  - strips
KW  - wheels
KW  - elastic strip
KW  - snap-through buckling
KW  - jumping angle
KW  - jumping mechanism
KW  - wheels
KW  - robot jumping
KW  - animals jump
KW  - rolling
KW  - compact wheeled robot
KW  - Mobile robots
KW  - Strips
KW  - Blades
KW  - Wheels
KW  - Force
KW  - Steel
DO  - 10.1109/IROS.2018.8593895
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we study a compact wheeled robot that can jump while rolling. Some robots are capable of jumping or rolling, but as far as we know, those robots are not focused on jumping while rolling. We know that animals jump while running to escape from predators. Robots can move quickly by jumping while rolling. We consider a model of a robot jumping while rolling and evaluate the proposed robot. The proposed robot has two wheels and a jumping mechanism based on snap-through buckling of an elastic strip. The proposed robot can jump about 5.9 cm high and 22 cm wide on average while maintaining a traveling speed of about 1.2 m/s. The proposed robot can change the jumping angle without greatly decreasing the impulse for the moving speed.
ER  - 

TY  - CONF
TI  - Soft LEGO: Bottom-Up Design Platform for Soft Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7513
EP  - 7520
AU  - J. Lee
AU  - J. Eom
AU  - W. Choi
AU  - K. Cho
PY  - 2018
KW  - assembling
KW  - bending
KW  - design engineering
KW  - finite element analysis
KW  - grippers
KW  - mobile robots
KW  - pneumatic actuators
KW  - rapid prototyping (industrial)
KW  - Taguchi methods
KW  - three-dimensional printing
KW  - soft LEGO bricks
KW  - soft robotics
KW  - pneumatically inflatable soft brick
KW  - assembled soft bricks
KW  - bottom-up design platform
KW  - flexible bending brick
KW  - air channel brick
KW  - Taguchi method
KW  - finite-element analysis
KW  - multimaterial 3-dimensional printer
KW  - Soft robotics
KW  - Hoses
KW  - Actuators
KW  - Pins
KW  - Toy manufacturing industry
KW  - Joining processes
DO  - 10.1109/IROS.2018.8593546
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces soft LEGO for bottom-up design platform of soft robotics that can be used for various purposes, ranging from research and fast prototyping of soft robots to toys and entertainment. We integrated the interlocking mechanism of LEGO into a modular soft robot. With this design, soft robots could be built by a simple and play-like assembling process. Three kinds of components were proposed to make soft robotics compatible with LEGO: pneumatically inflatable soft brick, flexible bending brick, and channel brick. The soft brick has an air chamber and can generate motions when inflated. The bending brick has flexure and is bendable for generating motion when the assembled soft bricks are pneumatically actuated. The air channel brick has an air channel inside and works as an interface between air hoses and soft LEGO bricks. Detailed design parameters of the soft brick were optimized based on the Taguchi method with finite-element analysis to improve robustness. Design of the bending brick was selected based on experimental results to enhance the robustness of the flexure. Thanks to the multi-material 3-dimensional printer, the soft LEGO bricks could be fabricated with a single printing process. To see the feasibility of soft LEGO as a bottom-up design platform, a simple toy robot for children and a gripper that had a hybrid mechanism of hard and soft materials were built and tested. We hope this soft LEGO could lower the hurdle of soft robotics for children, researchers from other fields, and the public interest in robotics.
ER  - 

TY  - CONF
TI  - Soft Snake Robots: Investigating the Effects of Gait Parameters on Locomotion in Complex Terrains
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - C. Branyan
AU  - Y. Menğüç
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - gait-curvature combination
KW  - half-activation gait
KW  - soft robot
KW  - soft-bodied robots
KW  - locomotion strategies
KW  - compliant materials
KW  - complex terrains
KW  - gait parameters
KW  - soft snake robot
KW  - Actuators
KW  - Soft robotics
KW  - Snake robots
KW  - Navigation
KW  - Friction
KW  - Solenoids
DO  - 10.1109/IROS.2018.8593404
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Compliant materials used to create soft robots can better replicate biological structures than typical rigid materials. We can look to nature for developing locomotion strategies for these soft-bodied robots. In this work, snakes were used as inspiration to create an inextensible, soft robot which was used as a platform to test gaits in terrain composed of granular media ranging from fine sand to stone. Snakes vary the speed and amplitude of the traveling wave used in lateral undulation to navigate different environments. We used these gait parameters to develop and test a set of custom gaits that varied the phase offset of the sequence of waves as well as using the best performing gait to test how the amplitude of the wave effects locomotion over the selected terrains. These tests provide preliminary evidence that altering these parameters effects the robot's ability to traverse different terrains. The developed robot is also tested in environments specific to applications for snake robots to show how a soft snake robot can be potentially more effective in these environment. The highest performing gait-curvature combination was the half-activation gait (where the back actuator was activated half as long as the front)with a 135° swept angle. It reached a velocity of 2.2 mm/s or 0.011 body-lengths/s on paper, which was the best performing terrain.
ER  - 

TY  - CONF
TI  - Inverse Error Function Trajectories for Image Reconstruction*This material is based upon work supported by the National Science Foundation under Grant No. 1662029
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7527
EP  - 7532
AU  - R. Katoch
AU  - B. Fusaro
AU  - J. Ueda
PY  - 2018
KW  - cameras
KW  - error analysis
KW  - Gaussian processes
KW  - image motion analysis
KW  - image restoration
KW  - mobile robots
KW  - optical transfer function
KW  - inverse error function trajectories
KW  - image reconstruction
KW  - mobile robots
KW  - visual stimuli
KW  - camera trajectories
KW  - camera motion
KW  - motion blur effects
KW  - image quality
KW  - Gaussian blur kernel
KW  - image capturing
KW  - linear error
KW  - polynomial error
KW  - time analysis
KW  - point-spread function
KW  - Trajectory
KW  - Cameras
KW  - Image reconstruction
KW  - Robot vision systems
KW  - Optical imaging
KW  - Optical sensors
DO  - 10.1109/IROS.2018.8594315
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Capturing clear images while a camera is moving fast, is integral to the development of mobile robots that can respond quickly and effectively to visual stimuli. This paper proposes to generate camera trajectories, with position and time constraints, that result in higher reconstructed image quality. The degradation in of an image captured during motion is known as motion blur. Three main methods exist for mitigating the effects of motion blur: (i) controlling optical parameters, (ii) controlling camera motion, and (iii) image reconstruction. Given control of a camera's motion, trajectories can be generated that result in an expected blur kernel or point-spread function. This work compares the motion blur effects and reconstructed image quality of three trajectories: (i) linear, (ii) polynomial, and (iii) inverse error. Where inverse error trajectories result in Gaussian blur kernels. Residence time analysis provides a basis for characterizing the motion blur effects of the trajectories.
ER  - 

TY  - CONF
TI  - Faster Collision Checks for Car-Like Robot Motion Planning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7533
EP  - 7538
AU  - B. C. Heinrich
AU  - D. Fassbender
AU  - H. Wuensche
PY  - 2018
KW  - collision avoidance
KW  - geometry
KW  - mobile robots
KW  - motion control
KW  - rear disc
KW  - faster collision checks
KW  - system knowledge
KW  - nonholonomic motion
KW  - motion planning
KW  - frontal disc
KW  - car-like robot motion planning
KW  - predictive algorithm
KW  - Collision avoidance
KW  - Trajectory
KW  - Shape
KW  - Planning
KW  - Robot kinematics
KW  - Tuning
DO  - 10.1109/IROS.2018.8594454
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we describe how collision checking for car-like robots can be sped up utilizing system knowledge. Their non-holonomic motion, while being a challenge for motion planning, is utilized here to place discs which are used as an approximation of the robot's shape in a predictive manner. For ease of comparison, we assume the robot to be rectangular, i. e., we use bounding boxes. Our algorithm is compared to a widely-used baseline and shows similar performance in terms of under- and oversampling while being approximately 20-40 % faster. Another feature of the algorithm is its predictive nature: with the frontal disc, we already check for collisions that would occur with the rear disc in the next sample, assuming near-constant curvature. While this might be conservative in some cases where large steering rates are necessary, in our evaluation even tight corridors could be navigated without negative effects.
ER  - 

TY  - CONF
TI  - C-MPDM: Continuously-Parameterized Risk-Aware MPDM by Quickly Discovering Contextual Policies
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7547
EP  - 7554
AU  - D. Mehta
AU  - G. Ferrer
AU  - E. Olson
PY  - 2018
KW  - decision making
KW  - gradient methods
KW  - operations research
KW  - optimisation
KW  - continuously-parameterized risk-aware MPDM
KW  - on-line forward roll-out process
KW  - computational cost
KW  - continuous-valued parameters
KW  - iterative gradient-based algorithm
KW  - multipolicy decision making systems
KW  - social environment
KW  - promising policy parameters
KW  - contextual policies
KW  - Robots
KW  - Cost function
KW  - Real-time systems
KW  - Trajectory
KW  - Decision making
KW  - Backpropagation
DO  - 10.1109/IROS.2018.8593642
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Risk-aware Multi-Policy Decision Making (MPDM)is a powerful framework for reliable navigation in a dynamic social environment where rather than evaluating individual trajectories, a “library” of policies (reactive controllers)is evaluated by anticipating potentially dangerous future outcomes using an on-line forward roll-out process. There is a core tension in Multi-Policy Decision Making (MPDM)systems - it is desirable to add more policies to the system for flexibility in finding good policies, however, this increases computational cost. As a result, MPDM was limited to small (perhaps 5-10)discrete policies - a significant performance bottleneck. In this paper, we radically enhance the expressivity of MPDM by allowing policies to have continuous-valued parameters, while simultaneously satisfying real-time constraints by quickly discovering promising policy parameters through a novel iterative gradient-based algorithm. Our evaluation includes results from extensive simulation and real-world experiments in semi-crowded environments.
ER  - 

TY  - CONF
TI  - Skating with a Force Controlled Quadrupedal Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7555
EP  - 7561
AU  - M. Bjelonic
AU  - C. Dario Bellicoso
AU  - M. Efe Tiryaki
AU  - M. Hutter
PY  - 2018
KW  - end effectors
KW  - force control
KW  - legged locomotion
KW  - locomotives
KW  - motion control
KW  - robot dynamics
KW  - torque control
KW  - wheels
KW  - motion planner
KW  - legged robot
KW  - gliding motions
KW  - Virtual Model Controller
KW  - optimal contact force distribution
KW  - torque-controllable robot ANY mal
KW  - passive wheels
KW  - ice skates
KW  - flat terrain
KW  - inclined terrain
KW  - skating motions
KW  - force controlled quadrupedal robot
KW  - wheeled systems
KW  - flat environments
KW  - locomotion domains
KW  - end-effectors
KW  - motion controller
KW  - Legged locomotion
KW  - Force
KW  - Torso
KW  - Wheels
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594504
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Traditional legged robots are capable of traversing challenging terrain, but lack of energy efficiency when compared to wheeled systems operating on flat environments. The combination of both locomotion domains overcomes the trade-off between mobility and efficiency. Therefore, this paper presents a novel motion planner and controller which together enable a legged robot equipped with skates to perform skating maneuvers. These are achieved by an appropriate combination of planned reaction forces and gliding motions. Our novel motion controller formulates a Virtual Model Controller and an optimal contact force distribution which takes into account the nonholonomic constraints introduced by the skates. This approach has been tested on the torque-controllable robot ANY mal equipped with passive wheels and ice skates as end-effectors. We conducted experiments on flat and inclined terrain, whereby we show that skating motions reduces the cost of transport by up to 80 % with respect to traditional walking gaits.
ER  - 

TY  - CONF
TI  - A Comparative Analysis of Contact Models in Trajectory Optimization for Manipulation*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - A. O. Onol
AU  - P. Long
AU  - T. Padlr
PY  - 2018
KW  - manipulators
KW  - optimisation
KW  - manipulation
KW  - contact-implicit trajectory optimization
KW  - variable smooth contact model
KW  - optimization process
KW  - Task analysis
KW  - Robots
KW  - Force
KW  - Trajectory optimization
KW  - Computational modeling
KW  - Dynamics
DO  - 10.1109/IROS.2018.8594284
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we analyze the effects of contact models on contact-implicit trajectory optimization for manipulation. We consider three different approaches: (1)a contact model that is based on complementarity constraints, (2)a smooth contact model, and our proposed method (3) a variable smooth contact model. We compare these models in simulation in terms of physical accuracy, quality of motions, and computation time. In each case, the optimization process is initialized by setting all torque variables to zero, namely, without a meaningful initial guess. For simulations, we consider a pushing task with varying complexity for a 7 degrees-of-freedom robot arm. Our results demonstrate that the optimization based on the proposed variable smooth contact model provides a good trade-off between the physical fidelity and quality of motions at the cost of increased computation time.
ER  - 

TY  - CONF
TI  - Combining Method of Alternating Projections and Augmented Lagrangian for Task Constrained Trajectory Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7568
EP  - 7575
AU  - A. Kumar Singh
AU  - R. Ghabcheloo
AU  - A. Muller
AU  - H. Pandya
PY  - 2018
KW  - collision avoidance
KW  - convex programming
KW  - optimisation
KW  - path planning
KW  - robot dynamics
KW  - similar nature trajectory
KW  - off-the-shelf nonlinear solver
KW  - similar task constraint residuals
KW  - SciPy alternative
KW  - alternating projections
KW  - Augmented Lagrangian
KW  - task constrained trajectory optimization
KW  - task space constraints
KW  - joint configurations
KW  - implicitly defined manifold
KW  - task constrained motion planning
KW  - optimization problem
KW  - nonlinear equality constraints
KW  - nonlinear optimization techniques
KW  - custom optimizer
KW  - task constraints
KW  - efficient convex optimization
KW  - feasible solution
KW  - common robotic benchmark problems
KW  - cyclic motion
KW  - joint space
KW  - Task analysis
KW  - Planning
KW  - Trajectory optimization
KW  - Cost function
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593557
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion planning for manipulators under task space constraints is difficult as it constrains the joint configurations to always lie on an implicitly defined manifold. It is possible to view task constrained motion planning as an optimization problem with non-linear equality constraints, which can be solved by general non-linear optimization techniques. In this paper, we present a novel custom optimizer which exploits the underlying structure present in many task constraints. At the core of our approach are some simple reformulations, which when coupled with the method of alternating projection, leads to an efficient convex optimization based routine for computing a feasible solution to the task constraints. We subsequently build on this result and use the concept of Augmented Lagrangian to guide the feasible solutions towards those that also minimize the user defined cost function. We show that the proposed optimizer is fully distributive and thus, can be easily parallelized. We validate our formulation on some common robotic benchmark problems. In particular, we show that the proposed optimizer achieves cyclic motion in the joint space corresponding to a similar nature trajectory in the task space. Furthermore, as a baseline, we compare the proposed optimizer with an off-the-shelf non-linear solver provide in open source package SciPy. We show that for similar task constraint residuals and smoothness cost, it can be upto more than three times faster than the SciPy alternative.
ER  - 

TY  - CONF
TI  - A Software Framework for Planning Under Partial Observability
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - M. Hoerger
AU  - H. Kurniawati
AU  - A. Elfes
PY  - 2018
KW  - application program interfaces
KW  - decision theory
KW  - Markov processes
KW  - mobile robots
KW  - path planning
KW  - planning (artificial intelligence)
KW  - software tools
KW  - robotics tasks
KW  - software tools
KW  - software toolkit
KW  - POMDP solvers
KW  - robot motion planning
KW  - partial observability problems
KW  - software framework
KW  - reliable robot operation
KW  - partially observable Markov decision process
KW  - abstract solver API
KW  - online POMDP planning toolkit
KW  - OPPT
KW  - Planning
KW  - Robot sensing systems
KW  - Computational modeling
KW  - Observability
KW  - Computer architecture
KW  - Standards
DO  - 10.1109/IROS.2018.8593714
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Planning under partial observability is both challenging and critical for reliable robot operation. The past decade has seen substantial advances in this domain: The mathematically principled approach for addressing such problems, namely the Partially Observable Markov Decision Process (POMDP), has started to become practical for various robotics tasks. Good approximate solutions for problems framed as POMDPs can now be computed on-line, with a few classes of problems being solved in near real-time. However, applications of these more recent advances are often hindered by the lack of easy-to-use software tools. Implementation of state of the art algorithms exist, but most (if not all)require the POMDP model to be hard-coded inside the program, increasing the difficulty of applying them. To alleviate this problem, we propose a software toolkit, called On-line POMDP Planning Toolkit (OPPT)(downloadable from http://robotics.itee.uq.edu.au/~oppt). By providing a well-defined and general abstract solver API, OPPT enables the user to quickly implement new POMDP solvers. Furthermore, OPPT provides an easy-to-use plug-in architecture with interfaces to the high-fidelity simulator Gazebo that, in conjunction with user-friendly configuration files, allows users to specify POMDP models of a standard class of robot motion planning under partial observability problems with no additional coding effort.
ER  - 

TY  - CONF
TI  - Adaptive Path Following of Snake Robot on Ground with Unknown and Varied Friction Coefficients
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7583
EP  - 7588
AU  - G. Wang
AU  - W. Yang
AU  - Y. Shen
AU  - H. Shao
PY  - 2018
KW  - adaptive control
KW  - control nonlinearities
KW  - control system synthesis
KW  - friction
KW  - mobile robots
KW  - motion control
KW  - parameter estimation
KW  - varied friction coefficients
KW  - underactuated bio-inspired snake robots
KW  - adaptive controller
KW  - 8-link snake robot
KW  - adaptive path following
KW  - backstepping technique
KW  - parameter estimation
KW  - control design input
KW  - LaSalle-Yoshizawa theorem
KW  - Snake robots
KW  - Friction
KW  - Tuning
KW  - Backstepping
KW  - Adaptation models
KW  - Stability analysis
DO  - 10.1109/IROS.2018.8594466
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper investigates the straight path following problem for a class of underactuated bio-inspired snake robots on ground with unknown and varied friction coefficients. Existing works usually design control input requiring the exact values of these friction coefficients, which however rely on the specific operating terrain and may not always be known a priori. By virtue of backstepping technique, we present a novel adaptive controller that can compensate for unknown and varied friction coefficients in real-time. Moreover, it is proved via LaSalle-Yoshizawa theorem that the path following errors converge to zero asymptotically and all the parameter estimates are bounded. Simulations and experiments on an 8-link snake robot are carried out to illustrate the effectiveness of the proposed controller.
ER  - 

TY  - CONF
TI  - Analytical Model of Thermal Soaring: Towards Energy Efficient Path Planning for Flying Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7589
EP  - 7594
AU  - J. Khaghani
AU  - M. Nekoui
AU  - R. Nasiri
AU  - M. N. Ahmadabadi
PY  - 2018
KW  - aerospace robotics
KW  - biomimetics
KW  - continuous systems
KW  - discrete systems
KW  - mobile robots
KW  - path planning
KW  - simple hybrid control strategy
KW  - flying robot
KW  - energy efficient flying
KW  - thermal soaring behavior
KW  - energy efficient locomotion types
KW  - flying animals
KW  - energy efficient path planning
KW  - Mathematical model
KW  - Birds
KW  - Thermal loading
KW  - Analytical models
KW  - Robots
KW  - Aerodynamics
KW  - Thermal variables control
KW  - Bio-inspired model
KW  - Thermal soaring
KW  - Path planning
KW  - Flying locomotion
KW  - Hybrid controller
DO  - 10.1109/IROS.2018.8593907
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Developing analytical models of efficient locomotion in biology is one of the most interesting goals in bio- inspired robotics. This paper presents a mathematical framework in order to model one of the most energy efficient locomotion types in flying animals; i.e., thermal soaring. Unlike the legged locomotion, in flying, modeling the environmental effects on animals' behaviors is very important. In doing so, we develop our model by assuming thermals as bubbles of rising air. According to pieces of real evidence, this kind of modeling is more compatible with the nature of thermal soaring. Moreover, we present a simple hybrid control strategy for obtaining the optimal path in order to maximize benefit from the updraft of air-flow. By using this control strategy, the flying robot can plan a path for traveling between thermals without flapping; i.e., energy efficient flying. So as to investigate the compatibility of presented model and controller with reality, we set their parameters based on the biological evidences. As a result, in simulations, it is observed that the generated flying behavior is comparable with the thermal soaring behavior of real birds. This observation provides a confirmation for generality and applicability of the presented approach.
ER  - 

TY  - CONF
TI  - Atmospheric-Operable 3D Printed Walking Bio-Robot Powered by Muscle-Tissue of Earthworm* Resrach supported by Grants-in-Aid for Scientific Research from Japan Society for the Promotion of Science (JSPS).
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7595
EP  - 7600
AU  - Y. Yalikun
AU  - Y. Noguchi
AU  - N. Kamamichi
AU  - Y. Tanaka
PY  - 2018
KW  - microactuators
KW  - microrobots
KW  - mobile robots
KW  - muscle
KW  - robot dynamics
KW  - stimulation frequency
KW  - atmospheric-operable walking robot
KW  - maximum walking speed
KW  - bio actuated walker
KW  - biological microbio-actuator
KW  - grants-in-aid
KW  - output force
KW  - stimulation voltage
KW  - muscle-tissue of earthworm
KW  - Japan society
KW  - atmospheric-operable 3d printed walking bio-robot
KW  - control property
KW  - Legged locomotion
KW  - Force
KW  - Muscles
KW  - Actuators
KW  - Strain measurement
KW  - Force measurement
DO  - 10.1109/IROS.2018.8594343
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Muscle-tissue of earthworms is an excellent actuator due to its membranous structure, strong force, short response time, and controllability. In this paper, we first investigated the output force, control property including stimulation voltage, stimulation frequency, and duty. Secondly, we designed, fabricated, and demonstrated an atmospheric-operable walking robot by using a muscle-tissue of earthworms. The maximum walking speed was about 0.56 mm/s, which is about 2 times faster than other types of bio actuated walker. The maximum atmospheric driven time was over 45 minutes. These demonstrated results indicated that the muscle-tissue of earthworm has a high potential for using as a biological micro bio-actuator for multiple purposes.
ER  - 

TY  - CONF
TI  - PiRat: An Autonomous Framework for Studying Social Behaviour in Rats and Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7601
EP  - 7608
AU  - S. Heath
AU  - C. A. Ramirez-Brinez
AU  - J. Arnold
AU  - O. Olsson
AU  - J. Taufatofua
AU  - P. Pounds
AU  - J. Wiles
AU  - E. Leonardis
AU  - E. Gygi
AU  - E. Leija
AU  - L. K. Quinn
AU  - A. A. Chiba
PY  - 2018
KW  - mobile robots
KW  - position control
KW  - social stimulus
KW  - rat-robot studies
KW  - social behaviour
KW  - rat-robot interaction studies
KW  - novel rat-sized robot
KW  - PiRat
KW  - robotic behavior
KW  - robot rat
KW  - reproducible behaviour
KW  - closed-loop rat-robot framework
KW  - autonomous framework
KW  - Rats
KW  - Robot sensing systems
KW  - Brushless DC motors
DO  - 10.1109/IROS.2018.8594060
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The use of robots, as a social stimulus, provides several advantages over using another animal. In particular, for rat-robot studies, robots can produce social behaviour that is reproducible across trials. In the current work, we outline a framework for rat-robot interaction studies, that consists of a novel rat-sized robot (PiRat), models of robotic behavior, and a position tracking system for both robot and rat. We present the design of the framework, including constraints on autonomy, latency, and control. We pilot tested our framework by individually running the robot rat with eight different rats, first through a habituation stage, and then with PiRat performing two different types of behaviour - avoiding and frequently approaching. We evaluate the performance of the framework on latency and autonomy, and on the ability to influence the behaviour of individual rats. We find that the framework performs well on its constraints, engages some of the rats (according to the number of meetings), and features a control scheme that produces reproducible behaviour in rats. These features represent a first demonstration of a closed-loop rat-robot framework.
ER  - 

TY  - CONF
TI  - Tarzan: Design, Prototyping, and Testing of a Wire-Borne Brachiating Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7609
EP  - 7614
AU  - E. Davies
AU  - A. Garlow
AU  - S. Farzan
AU  - J. Rogers
AU  - A. Hu
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - swing-up maneuver
KW  - distributed electronics packages
KW  - brachiating robot design
KW  - prototype robot
KW  - remote sensing packages
KW  - payload mounting point
KW  - minimal power consumption
KW  - locking hand design
KW  - ladder brachiation modes
KW  - parallel wires
KW  - elevated wire networks
KW  - wire-borne brachiating robot
KW  - ladder locomotion modes
KW  - Wires
KW  - Grippers
KW  - Wrist
KW  - Thumb
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593823
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A novel brachiating robot design is presented for the purpose of traversing elevated wire networks. The robot is capable of moving along a single wire and between parallel wires, thereby enabling traversal of a two-dimensional space. Several novel features distinguish this design compared to previous brachiating robots. These include the ability to transition to and from both “rope” and “ladder” brachiation modes through an integrated wrist, a locking hand design for minimal power consumption, and distributed electronics packages that communicate wirelessly. A payload mounting point is installed, offering space for a variety of remote sensing packages. Experimental results using a prototype robot demonstrate that the system can reliably brachiate along a single wire, and can also reliably perform a swing-up maneuver after failed swing attempts or when transitioning between the rope and ladder locomotion modes. Energy expenditure for a single swing is quantified using experimental data. Overall, the proposed robot design is shown to provide a promising platform for traversal of wire networks in two dimensions.
ER  - 

TY  - CONF
TI  - Online Foot-Strike Detection Using Inertial Measurements for Multi-Legged Walking Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7622
EP  - 7627
AU  - P. Čížek
AU  - J. Kubík
AU  - J. Faigl
PY  - 2018
KW  - accelerometers
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - position control
KW  - terrain mapping
KW  - interrupt mode
KW  - hexapod walking robot
KW  - inertial measurements
KW  - multilegged walking robots
KW  - proprioceptive terrain sensing
KW  - terrain irregularities
KW  - inertial data
KW  - online foot strike detection
KW  - foot strike event detector
KW  - data processing
KW  - accelerometers
KW  - terrain traversal
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Accelerometers
KW  - Servomotors
KW  - Reliability
DO  - 10.1109/IROS.2018.8594010
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Proprioceptive terrain sensing is essential for rough terrain traversal because it helps legged robots to negotiate individual steps by reacting to terrain irregularities. In this work, we propose to utilize inertial data in the detection of the contact between the leg and the terrain during the stride phase of the leg. We show that relatively cheap accelerometers can be utilized to reliably detect a foot-strike, and thus allow the robot to crawl irregular terrains. The continuous data processing is compared with the interrupt mode in which data are provided only around the foot-strike event. The interrupt mode exhibits significantly better performance, and it also supports generalization of the foot-strike event detector learned from data collected in slow locomotion to faster locomotion where the signals slightly change. The proposed solution is experimentally validated using a real hexapod walking robot for which the walking speed has been improved in comparison to the previous adaptive motion gait based on a force threshold-based position controller for the foot-strike detection.
ER  - 

TY  - CONF
TI  - TacWhiskers: Biomimetic Optical Tactile Whiskered Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7628
EP  - 7634
AU  - N. F. Lepora
AU  - M. Pearson
AU  - L. Cramphorn
PY  - 2018
KW  - biomimetics
KW  - mobile robots
KW  - tactile sensors
KW  - optical cutaneous tactile sensor
KW  - static Tac Whisker array
KW  - immotile tactile vibrissae
KW  - dynamic Tac Whisker array
KW  - dynamic sensor output
KW  - Tac Whiskers
KW  - biomimetic optical tactile whiskered robots
KW  - vibrissal tactile sensor
KW  - 3D-printed optical cutaneous tactile sensor
KW  - TacTip
KW  - active object localization task
KW  - Pins
KW  - Rodents
KW  - Tendons
KW  - Dynamics
KW  - Tactile sensors
DO  - 10.1109/IROS.2018.8593653
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Here we propose and investigate a novel vibrissal tactile sensor - the Tac Whisker array - based on modifying a 3D-printed optical cutaneous (fingertip) tactile sensor - the TacTip. Two versions are considered: a static Tac Whisker array analogous to immotile tactile vibrissae (e.g. rodent microvib-rissae) and a dynamic Tac Whisker array analogous to motile tactile vibrissae (e.g. rodent macrovibrissae). Performance is assessed on an active object localization task. The whisking motion of the dynamic Tac Whisker leads to millimetre-scale location perception, whereas perception with the static Tac Whisker array is relatively poor when making dabbing contacts. The dynamic sensor output is dominated by a self-generated motion signal, which can be compensated by comparing to a reference signal. Overall, the Tac Whisker arrays give a new class of tactile whiskered robots that benefit from being relatively inexpensive and customizable. Furthermore, the biomimetic basis for the Tac Whiskers fits well with building an embodied model of the rodent sensory system for investigating animal perception.
ER  - 

TY  - CONF
TI  - Multisensor Online Transfer Learning for 3D LiDAR-Based Human Detection with a Mobile Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7635
EP  - 7640
AU  - Z. Yan
AU  - L. Sun
AU  - T. Duckctr
AU  - N. Bellotto
PY  - 2018
KW  - image classification
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - object tracking
KW  - optical radar
KW  - probability
KW  - radar tracking
KW  - robot vision
KW  - service robots
KW  - stereo image processing
KW  - online transfer learning
KW  - 3D LiDAR-based human detection
KW  - mobile robot
KW  - service robots
KW  - multisensor tracking system
KW  - 2D LiDAR
KW  - human trajectory
KW  - 3D LiDAR-based human classification
KW  - trajectory probability
KW  - RGB-D camera
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Detectors
KW  - Robot sensing systems
KW  - Cameras
DO  - 10.1109/IROS.2018.8593899
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Human detection and tracking is an essential task for service robots, where the combined use of multiple sensors has potential advantages that are yet to be fully exploited. In this paper, we introduce a framework allowing a robot to learn a new 3D LiDAR-based human classifier from other sensors over time, taking advantage of a multisensor tracking system. The main innovation is the use of different detectors for existing sensors (i.e. RGB-D camera, 2D LiDAR) to train, online, a new 3D LiDAR-based human classifier based on a new “trajectory probability”. Our framework uses this probability to check whether new detection belongs to a human trajectory, estimated by different sensors and/or detectors, and to learn a human classifier in a semi-supervised fashion. The framework has been implemented and tested on a real-world dataset collected by a mobile robot. We present experiments illustrating that our system is able to effectively learn from different sensors and from the environment, and that the performance of the 3D LiDAR-based human classification improves with the number of sensors/detectors used.
ER  - 

TY  - CONF
TI  - An Everyday Robotic System that Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 7
AU  - Y. Furuta
AU  - K. Okada
AU  - Y. Kakiuchi
AU  - M. Inaba
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - robot agent
KW  - local-rule-aware home assistive tasks
KW  - semantic map
KW  - long-term episodic memory
KW  - home environments
KW  - global society
KW  - probabilistic object localization map
KW  - Fetch robots
KW  - semantic common knowledge
KW  - PR2 robot
KW  - robotic system
KW  - time 41.0 d
KW  - Task analysis
KW  - Probabilistic logic
KW  - Semantics
KW  - Planning
KW  - Robot sensing systems
KW  - Solid modeling
KW  - Service Robots
KW  - Learning and Adaptive Systems
KW  - Big Data in Robotics and Automation
DO  - 10.1109/IROS.2018.8594481
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.
ER  - 

TY  - CONF
TI  - Dynamic Dumbbell - Novel Muscle Training Robot with Programmable Exercise Load
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - C. Lee
AU  - S. Oh
PY  - 2018
KW  - actuators
KW  - elasticity
KW  - force control
KW  - gears
KW  - medical robotics
KW  - muscle
KW  - patient rehabilitation
KW  - high performance force control algorithm
KW  - rotary series elastic actuator
KW  - planetary-geared elastic actuator
KW  - mechanical engineering
KW  - muscle training robot
KW  - exercise load model
KW  - advanced muscular exercise
KW  - Dynamic Dumbbell
KW  - programmable exercise load
KW  - Dynamic dumbbell
KW  - Dynamics
KW  - Muscles
KW  - Torque
KW  - Robots
KW  - Force
KW  - Load modeling
KW  - Gears
DO  - 10.1109/IROS.2018.8593779
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, Dynamic Dumbbell, a novel robotic device for advanced muscular exercise of upper limb is presented. The type of exercise load is classified and designed in terms of mechanical engineering to be implemented in Dynamic Dumbbell. The exercise load model, which is named as programmable exercise load, is realized by Dynamic Dumbbell. To generate the programmable exercise load, two of compact Planetary-geared Elastic Actuator, which is a rotary Series Elastic Actuator (SEA), are utilized in Dynamic Dumbbell. The SEAs are controlled using high performance force control algorithm. Experimental results verifies the effectiveness of the proposed Dynamic Dumbbell and programmable exercise load.
ER  - 

TY  - CONF
TI  - Autonomous Navigation Using Multimodal Potential Field to Initiate Interaction with Multiple People
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7654
EP  - 7659
AU  - Y. Kawasaki
AU  - A. Yorozu
AU  - M. Takahashi
PY  - 2018
KW  - human-robot interaction
KW  - image recognition
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - sensors
KW  - path-planning
KW  - sensor characteristics
KW  - autonomous navigation
KW  - sensor data
KW  - human recognition reliability
KW  - human-robot interaction
KW  - multiple people
KW  - initiate interaction
KW  - multimodal potential field
KW  - Robot sensing systems
KW  - Reliability
KW  - Task analysis
KW  - Character recognition
KW  - Robot kinematics
KW  - Cameras
DO  - 10.1109/IROS.2018.8594289
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In a human-robot interaction, a robot needs to move to a position where the robot can obtain high reliability data of people, such as positions, postures, and voice. This is because the human recognition reliability depends on the positional relation between the people and the robot. In addition, the robot should choose the sensor data which is necessary to perform the interaction task. Therefore, it is necessary to navigate the robot to the position to obtain the data for initiation of the interaction task. Accordingly, we need to design a path-planning method considering sensor characteristics, human recognition reliability, and task contents. Although previous studies proposed path-planning methods using an interaction potential considering sensor characteristics, they did not consider the task contents and the human recognition reliability, which are important for practical application and did not applied to interaction with multiple people. Consequently, we present a path-planning method considering the task contents and the human recognition reliability using multimodal potential field integrating these information. We verified effectiveness of the path-planning method for interaction with multiple people.
ER  - 

TY  - CONF
TI  - Estimating Door Shape and Manipulation Model for Daily Assistive Robots Based on the Integration of Visual and Touch Information
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7660
EP  - 7666
AU  - K. Nagahama
AU  - K. Takeshita
AU  - H. Yaguchi
AU  - K. Yamazaki
AU  - T. Yamamoto
AU  - M. Inaba
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - service robots
KW  - visual touch information
KW  - door manipulation
KW  - door candidates
KW  - target door
KW  - appropriate shape
KW  - single click
KW  - single user instruction
KW  - unknown door
KW  - daily assistive robots
KW  - manipulation model
KW  - door shape
KW  - Shape
KW  - Robot kinematics
KW  - Trajectory
KW  - Visualization
KW  - Robot vision systems
DO  - 10.1109/IROS.2018.8593391
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a method for a robot to manipulate an unknown door based on a single user instruction. The primary contributions of this paper are (i) to reduce the user instruction to a single click and (ii) to develop an efficient method to estimate an appropriate shape and manipulation model for a target door by integrating visual and touch information obtained by a robot. The proposed method first detects door candidates using a 3-D camera and then estimates the manipulation model of each candidate based on prior learning results. During door manipulation, the system integrates visual and touch information to estimate the shape and manipulation model to generate an appropriate motion. We evaluated the proposed method experimentally, and the results prove that the proposed method is effective.
ER  - 

TY  - CONF
TI  - Designing for Robust Movement in a Child-Friendly Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7667
EP  - 7674
AU  - J. Taufatofua
AU  - S. Heath
AU  - C. A. Ramirez-Brinez
AU  - K. Sommer
AU  - G. Durantin
AU  - W. Kong
AU  - J. Wiles
AU  - P. Pounds
PY  - 2018
KW  - design
KW  - humanoid robots
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - safety
KW  - torque-limited stepper motors
KW  - robotic agents
KW  - social interaction
KW  - mechanical features
KW  - child-friendly robot
KW  - social robot
KW  - mechanical design
KW  - torso-mounted
KW  - back-drivable
KW  - Safety
KW  - Manipulators
KW  - Actuators
KW  - Prototypes
KW  - Torque
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593414
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion is a critical aspect of communication, required to create natural interactions between humans and robots. Robots for the classroom pose several constraints on motion, which make them challenging to design, including maintaining the safety of the child and the robot, responding in a timely fashion, and creating motions that are expressive and not scary. In this paper we present the mechanical design of a social robot and demonstrate that it is capable of safe motion within the proximity of children through analysis and empirical testing of the arms. The robot has a novel mechanical design for its two arms, which include torso-mounted, back-drivable, torque-limited stepper motors. The results suggest that our design succeeds at increasing safety levels while enabling the use of socially acceptable speeds of motion during the interaction. This study implies that the design of robotic agents for social interaction with children should consider the design of mechanical features that enable safe contact between the human and the robot while not limiting the robot to slow motions that would impair the timing of the interaction.
ER  - 

TY  - CONF
TI  - Development of the Research Platform of a Domestic Mobile Manipulator Utilized for International Competition and Field Test
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7675
EP  - 7682
AU  - T. Yamamoto
AU  - K. Terada
AU  - A. Ochiai
AU  - F. Saito
AU  - Y. Asahara
AU  - K. Murase
PY  - 2018
KW  - home computing
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - wheels
KW  - international competition
KW  - aging population
KW  - intelligent sensing
KW  - household work
KW  - actual home environment
KW  - HSR users
KW  - technical knowledge
KW  - standard platform
KW  - international robot competitions
KW  - HSR's development background
KW  - omnidirectional mobile base
KW  - domestic mobile manipulator
KW  - human support robot
KW  - whole body motion control system
KW  - field test
KW  - quality of life
KW  - intelligent software
KW  - World Robot Summit
KW  - dual-wheel caster-drive mechanism
KW  - RoboCup@Home
KW  - HSR's operational movement
KW  - Robot kinematics
KW  - Manipulators
KW  - Task analysis
KW  - Sensors
KW  - Software
KW  - Hardware
DO  - 10.1109/IROS.2018.8593798
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - There has been an increasing interest in mobile manipulators that are capable of performing physical work in living spaces worldwide, corresponding to an aging population with declining birth rates with the expectation of improving quality of life (QoL). Research and development is a must in intelligent sensing and software which will enable advanced recognition, judgment, and motion to realize household work by robots. In order to accelerate this research, we have developed a compact and safe research platform, Human Support Robot (HSR), which can be operated in an actual home environment. We assume that overall R&D will accelerate by using a common robot platform among many researchers since that enables them to share their research results. Currently, the number of HSR users is expanding to 33 sites in 8 countries worldwide (as of February 15, 2018). Software and technical knowledge of all users is shared through a community website. HSR has been adopted as a standard platform for international robot competitions such as RoboCup@Home and World Robot Summit (WRS). HSR is provided to participants of those competitions through public offering. In this paper, we describe HSR's development background, and technical detail of its hardware and software. Specifically, we describe its omnidirectional mobile base using the dual-wheel caster-drive mechanism, which is the basis of HSR's operational movement and a novel whole body motion control system. Finally, we describe the results of utilization in RoboCup@Home and field tests in order to demonstrate the effect of introducing the platform.
ER  - 

TY  - CONF
TI  - Robot Artist Performs Cartoon Style Facial Portrait Painting
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7683
EP  - 7688
AU  - R. C. Luo
AU  - Y. J. Liu
PY  - 2018
KW  - art
KW  - face recognition
KW  - image colour analysis
KW  - painting
KW  - rendering (computer graphics)
KW  - facial features
KW  - hand-painted strokes
KW  - painting strategy
KW  - basic colors
KW  - eye-in-hand system
KW  - cartoon facial components
KW  - face detection
KW  - human portrait photos
KW  - cartoon style transformation stage
KW  - colorful painting
KW  - stages-cartoon style transformation
KW  - robot cartoonist
KW  - human cartoonist
KW  - visual feedback system
KW  - cartoon stylization painting
KW  - robot artist
KW  - cartoon style facial portrait painting
KW  - face portrait
KW  - Painting
KW  - Image color analysis
KW  - Face
KW  - Shape
KW  - Facial features
KW  - Image segmentation
KW  - Cartoon face
KW  - robot painting
DO  - 10.1109/IROS.2018.8594147
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a face portrait with cartoon stylization painting and associated algorithms with the visual feedback system to paint like a human cartoonist. The robot cartoonist creates the artwork in two stages-cartoon style transformation and robot artist for colorful painting. In the cartoon style transformation stage, it transfers human portrait photos to cartoon style by face detection and alignment, which can effectively decompose the face into individual components then replace by cartoon facial components. In the second stage, the robot uses an eye-in-hand system to obtain five basic colors (cyan, magenta, yellow, white and black) to automatically mix a variety of colors automatically. For painting strategy, we start with the outline of the face, which we use non-photorealistic rendering (NPR) to generate hand-painted strokes. After that, the robot artist will implement painting the facial features. We also demonstrate the success of this proposed research.
ER  - 

TY  - CONF
TI  - Robust Plant Phenotyping via Model-Based Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7689
EP  - 7696
AU  - P. Sodhi
AU  - H. Sun
AU  - B. Póczos
AU  - D. Wettergreen
PY  - 2018
KW  - agriculture
KW  - biology computing
KW  - botany
KW  - crops
KW  - genetic algorithms
KW  - genetics
KW  - industrial plants
KW  - probability
KW  - solid modelling
KW  - robust plant phenotyping
KW  - observable plant traits
KW  - labour intensive error prone
KW  - automated manner
KW  - noninvasive manner
KW  - plant breeding methods
KW  - nonideal sensing conditions
KW  - high throughput plant phenotyping
KW  - state-of-the-art 3D phenotyping algorithms
KW  - hand-tuned parameters
KW  - novel model-based optimization approach
KW  - estimating plant physical traits
KW  - plant units
KW  - plant models
KW  - probability distribution approach
KW  - phenotyping objective
KW  - plant structure
KW  - work furthers field-based robotic phenotyping capabilities
KW  - plant biologists
KW  - crop yields
KW  - Three-dimensional displays
KW  - Imaging
KW  - Optimization
KW  - Robot sensing systems
KW  - Green products
KW  - Image reconstruction
KW  - Solid modeling
DO  - 10.1109/IROS.2018.8594245
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Plant phenotyping is the measurement of observable plant traits. Current methods for phenotyping in the field are labour intensive and error prone. High throughput plant phenotyping in an automated and noninvasive manner is crucial to accelerating plant breeding methods. Occlusions and non-ideal sensing conditions is a major problem for high throughput plant phenotyping with most state-of-the-art 3D phenotyping algorithms relying heavily on heuristics or hand-tuned parameters. To address this problem, we present a novel model-based optimization approach for estimating plant physical traits from plant units called phytomers. The proposed approach involves sampling parameterized 3D plant models from an underlying probability distribution. It then optimizes, making the mass of this probability distribution approach true parameters of the model. Reformulating the phenotyping objective as a search in the space of plant models lets us reason about the plant structure in a holistic manner without having to rely on hand-tuned parameters. This makes our approach robust to noise and occlusions as frequently encountered in real world environments. We evaluate our approach for plant units taken across simulated, greenhouse and field environments. This work furthers field-based robotic phenotyping capabilities paving the way for plant biologists to study the coupled effect of genetics and environment on improving crop yields.
ER  - 

TY  - CONF
TI  - Registering Reconstructions of the Two Sides of Fruit Tree Rows
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - P. Roy
AU  - W. Dong
AU  - V. Isler
PY  - 2018
KW  - agricultural products
KW  - feature extraction
KW  - image reconstruction
KW  - image registration
KW  - three dimensionalreconstructions
KW  - reconstruction registeration
KW  - partial reconstructions
KW  - side-views
KW  - measuring traits
KW  - yield mapping
KW  - orchard rows
KW  - fruit tree
KW  - Image reconstruction
KW  - Three-dimensional displays
KW  - Vegetation
KW  - Principal component analysis
KW  - Shape
KW  - Semantics
KW  - Cameras
DO  - 10.1109/IROS.2018.8594167
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We consider the problem of building accurate three dimensional (3D)reconstructions of orchard rows. This problem arises in many applications including yield mapping and measuring traits (e.g. trunk diameters)for phenotyping. While 3D reconstructions of side views can be obtained using standard methods, merging the two side-views is difficult due to the lack of overlap between the two partial reconstructions. We present a novel method that utilizes global features to constrain the solution. Specifically, we use information from the silhouettes and the ground plane for alignment. The method is evaluated using multiple simulated and real datasets. For additional information and demonstration of experimental results please see https://www.youtube.com/watch?v=6mGMF2gFv4M.
ER  - 

TY  - CONF
TI  - Design of an Autonomous Precision Pollination Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7711
EP  - 7718
AU  - N. Ohi
AU  - K. Lassak
AU  - R. Watson
AU  - J. Strader
AU  - Y. Du
AU  - C. Yang
AU  - G. Hedrick
AU  - J. Nguyen
AU  - S. Harper
AU  - D. Reynolds
AU  - C. Kilic
AU  - J. Hikes
AU  - S. Mills
AU  - C. Castle
AU  - B. Buzzo
AU  - N. Waterland
AU  - J. Gross
AU  - Y. Park
AU  - X. Li
AU  - Y. Gu
PY  - 2018
KW  - greenhouses
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - precision robotic pollination systems
KW  - natural pollinators
KW  - uniformity
KW  - human population
KW  - ongoing development
KW  - autonomous robot
KW  - BrambleBee
KW  - ecology
KW  - visual perception
KW  - robust autonomous pollination system
KW  - autonomous precision pollination robot
KW  - Cameras
KW  - End effectors
KW  - Agriculture
KW  - Robot vision systems
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8594444
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Precision robotic pollination systems can not only fill the gap of declining natural pollinators, but can also surpass them in efficiency and uniformity, helping to feed the fast-growing human population on Earth. This paper presents the design and ongoing development of an autonomous robot named “BrambleBee”, which aims at pollinating bramble plants in a greenhouse environment. Partially inspired by the ecology and behavior of bees, BrambleBee employs state-of-the-art localization and mapping, visual perception, path planning, motion control, and manipulation techniques to create an efficient and robust autonomous pollination system.
ER  - 

TY  - CONF
TI  - Close Coordination of Mobile Robots Using Radio Beacons: A New Concept Aimed at Smart Spraying in Agriculture
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7727
EP  - 7734
AU  - T. Tourrette
AU  - M. Deremetz
AU  - O. Naud
AU  - R. Lenain
AU  - J. Laneurit
AU  - V. De Rudnicki
PY  - 2018
KW  - agricultural safety
KW  - agriculture
KW  - environmental factors
KW  - hazardous materials
KW  - mobile robots
KW  - off-road vehicles
KW  - soil
KW  - spraying
KW  - ultra wideband technology
KW  - UWB
KW  - Ultra Wide Band technology
KW  - soil compaction
KW  - safety aspects
KW  - chemical products
KW  - human activities
KW  - environmental impact
KW  - autonomous robots
KW  - hazardous products
KW  - agricultural application
KW  - off-road mobile robots
KW  - production levels
KW  - human health
KW  - human operators
KW  - smart spraying
KW  - radio beacons
KW  - Mobile robots
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Spraying
KW  - Agriculture
DO  - 10.1109/IROS.2018.8593978
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Many agricultural tasks are known to be dangerous for human operators, the environment, and human health in general. The increasing pressure both on safety and on production levels motivates the development of new methodologies and technologies. The rising of off-road mobile robots for agricultural application appears to be a promising contribution to required innovations. It both permits to limit the exposure of people to hazardous products and to achieve difficult and repetitive tasks. Nevertheless, to be fully efficient, autonomous robots have to ensure a high level of accuracy, while carrying potentially heavy tools, possibly in harsh conditions. It is especially the case of spraying, for which accuracy is a key challenge for reducing environmental impacts. The use of huge robots for spraying might seem to be a straightforward solution, by simply automating existing machines. Nevertheless, a simple automation does not reduce directly the environmental impact of human activities (soil compaction, energy, reduction of the use of chemical products). Moreover, huge machines are not necessarily an advantage when considering safety aspects (rollover risk and maneuverability). As a result, a solution based on the cooperation of at least two mobile robots, moving from either side of a vine row, is investigated in this paper thanks to Ultra Wide Band (UWB) technology.
ER  - 

TY  - CONF
TI  - Diversity in Pedestrian Safety for Industrial Environments Using 3D Lidar Sensors and Neural Networks*Research supported by the New Zealand Ministry for Business Innovation and Employment (MBIE) on contract UOAX1414.
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7743
EP  - 7749
AU  - J. Bell
AU  - B. A. MacDonald
AU  - H. SeokAhn
PY  - 2018
KW  - neural nets
KW  - object detection
KW  - optical radar
KW  - pedestrians
KW  - road safety
KW  - high visibility clothing
KW  - neural networksresearch
KW  - detection methods
KW  - lidar range data
KW  - lidar intensity data
KW  - lidar sensor
KW  - pedestrian detection
KW  - strong cue
KW  - retro-reflective strips
KW  - contract UOAX1414
KW  - business innovation
KW  - new zealand ministry
KW  - 3D lidar sensors
KW  - industrial environments
KW  - pedestrian safety
KW  - Laser radar
KW  - Safety
KW  - Sensors
KW  - Neural networks
KW  - Three-dimensional displays
KW  - Clothing
KW  - Strips
DO  - 10.1109/IROS.2018.8593835
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The motivation of the work presented here is to create a component of a safety system based on 3D lidar sensors, specifically for industrial environments where some rules can be set for people who will be in close proximity to working robots. Specifically, the operating procedure that is put in place in the workplace is that all people must wear the provided high visibility clothing, which has retro-reflective strips attached. It is shown here that the retro-reflective strips provide a strong cue for pedestrian detection in the intensity data from a lidar sensor within a range of 4 metres. We present and compare multiple methods of exploiting this cue and provide a recommendation for how a safety system should be architected in order to best exploit the lidar intensity data in combination with more common approaches for detection of objects from the lidar range data. Amongst these detection methods is the use of neural networks, which present challenges for key components of standardized safety system development-in particular, for programming methodology control, interpretability of testing and diagnostic coverage. We propose methods for how to start to address these challenges and how to integrate neural networks into safety systems.
ER  - 

TY  - CONF
TI  - UNDERWORLDS: Cascading Situation Assessment for Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7750
EP  - 7757
AU  - S. Lemaignan
AU  - Y. Sallami
AU  - C. Wallhridge
AU  - A. Clodic
AU  - T. Belpaeme
AU  - R. Alami
PY  - 2018
KW  - manipulators
KW  - mobile robots
KW  - spatio-temporal situation assessment
KW  - novel lightweight framework
KW  - cascading situation assessment
KW  - temporal granularities
KW  - cascading representations
KW  - temporal events
KW  - real-time distributed data structures
KW  - UNDERWORLDS
KW  - Robots
KW  - Three-dimensional displays
KW  - Solid modeling
KW  - Computer architecture
KW  - Tools
KW  - Software
KW  - Task analysis
DO  - 10.1109/IROS.2018.8594094
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We introduce UNDERWORLDS, a novel lightweight framework for cascading spatio-temporal situation assessment in robotics. UNDERWORLDS allows programmers to represent the robot's environment as real-time distributed data structures, containing both scene graphs (for representation of 3D geometries) and timelines (for representation of temporal events). UNDERWORLDS supports cascading representations: the environment is viewed as a set of worlds that can each have different spatial and temporal granularities, and may inherit from each other. UNDERWORLDS also provides a set of high-level client libraries and tools to introspect and manipulate the environment models. This article presents the design and architecture of this open-source tool, and explores some applications, along with examples of use.
ER  - 

TY  - CONF
TI  - OpenSeqSLAM2.0: An Open Source Toolbox for Visual Place Recognition Under Changing Conditions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7758
EP  - 7765
AU  - B. Talbot
AU  - S. Garg
AU  - M. Milford
PY  - 2018
KW  - image recognition
KW  - mobile robots
KW  - navigation
KW  - object recognition
KW  - public domain software
KW  - robot vision
KW  - SLAM (robots)
KW  - open source toolbox
KW  - changing conditions
KW  - traversed route
KW  - inclement conditions
KW  - navigating robots
KW  - robotic systems
KW  - environmental conditions
KW  - fully open-source toolbox
KW  - open access
KW  - source code
KW  - visual place recognition problem
KW  - open source platform
KW  - OpenSeqSLAM2.0
KW  - Visualization
KW  - Robots
KW  - Tools
KW  - Open source software
KW  - Search methods
KW  - Trajectory
KW  - Heuristic algorithms
DO  - 10.1109/IROS.2018.8593761
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visually recognising a traversed route - regardless of whether seen during the day or night, in clear or inclement conditions, or in summer or winter - is an important capability for navigating robots. Since SeqSLAM was introduced in 2012, a large body of work has followed exploring how robotic systems can use the algorithm to meet the challenges posed by navigation in changing environmental conditions. The following paper describes OpenSeqSLAM2.0, a fully open-source toolbox for visual place recognition under changing conditions. Beyond the benefits of open access to the source code, OpenSeqSLAM2.0 provides a number of tools to facilitate exploration of the visual place recognition problem and interactive parameter tuning. Using the new open source platform, it is shown for the first time how comprehensive parameter characterisations provide new insights into many of the system components previously presented in ad hoc ways and provide users with a guide to what system component options should be used under what circumstances and why.
ER  - 

TY  - CONF
TI  - HERO: Accelerating Autonomous Robotic Tasks with FPGA
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7766
EP  - 7772
AU  - X. Shi
AU  - L. Cao
AU  - D. Wang
AU  - L. Liu
AU  - G. You
AU  - S. Liu
AU  - C. Wang
PY  - 2018
KW  - convolutional neural nets
KW  - field programmable gate arrays
KW  - mobile robots
KW  - path planning
KW  - SLAM (robots)
KW  - motion planning tasks
KW  - HERO platform
KW  - CNN inference
KW  - autonomous robotic tasks
KW  - Heterogeneous Extensible Robot Open platform
KW  - OpenCL programming
KW  - SLAM
KW  - convolutional neural network inference
KW  - FPGA acceleration
KW  - heterogeneous computing
KW  - simultaneous localization and mapping
KW  - VGG-16
KW  - ResNet-50
KW  - Field programmable gate arrays
KW  - Kernel
KW  - Acceleration
KW  - Simultaneous localization and mapping
KW  - Task analysis
KW  - Planning
DO  - 10.1109/IROS.2018.8593522
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The Heterogeneous Extensible Robot Open (HERO) platform is designed for autonomous robotic research. While bringing in the flexible computational capacities by CPU and FPGA, it addresses the challenges of heterogeneous computing by embracing OpenCL programming. We propose heterogeneous computing approaches for three fundamental robotic tasks: simultaneous localization and mapping (SLAM), motion planning and convolutional neural network (CNN) inference. With FPGA acceleration, the SLAM and motion planning tasks are performed 2-4 times faster on the HERO platform against fine-tuned software implementation. For CNN inference, it can process 20-30 images per second with the network of VGG-16 or ResNet-50. We expect the open platform and the developing experiences shared in this paper can facilitate future robotic research, especially for those compute intensive tasks of perception, movement and manipulation.
ER  - 

TY  - CONF
TI  - Procedurally Provisioned Access Control for Robotic Systems
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - R. White
AU  - H. I. Christensen
AU  - G. Caiazza
AU  - A. Cortesi
PY  - 2018
KW  - authorisation
KW  - Internet of Things
KW  - middleware
KW  - public domain software
KW  - robot programming
KW  - robotic systems
KW  - industrial IoT
KW  - domestic IoT
KW  - development lifecycle
KW  - ROS2
KW  - secure real world robotic deployments
KW  - procedural provisioning access control policies
KW  - secure DDS
KW  - middleware infrastructures
KW  - next generation open source robotic software stack
KW  - Service robots
KW  - Access control
KW  - Middleware
KW  - Tools
KW  - Cryptography
DO  - 10.1109/IROS.2018.8594462
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Security of robotics systems, as well as of the related middleware infrastructures, is a critical issue for industrial and domestic IoT, and it needs to be continuously assessed throughout the whole development lifecycle. The next generation open source robotic software stack, ROS2, is now targeting support for Secure DDS, providing the community with valuable tools for secure real world robotic deployments. In this work, we introduce a framework for procedural provisioning access control policies for robotic software, as well as for verifying the compliance of generated transport artifacts and decision point implementations.
ER  - 

TY  - CONF
TI  - XBotCloud: A Scalable Cloud Computing Infrastructure for XBot Powered Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - L. Muratore
AU  - B. Lennox
AU  - N. G. Tsagarakis
PY  - 2018
KW  - cloud computing
KW  - control engineering computing
KW  - software agents
KW  - Web services
KW  - computational resources
KW  - robotic platforms
KW  - Amazon Web Services Cloud Security
KW  - XBotCloud
KW  - cross-robot flexibility
KW  - XBotCloud performances
KW  - robot local control unit
KW  - Real-Time modules
KW  - moderate execution time constraints
KW  - cloud services
KW  - cloud server
KW  - XBotCore Real-Time cross-robot software component
KW  - hard Real-Time execution/communication performance
KW  - soft Time execution/communication performance
KW  - XBot framework
KW  - cloud robotics concept
KW  - mobile robots
KW  - untethered robots
KW  - on-board computational resources
KW  - scalable cloud computing infrastructure
KW  - Cloud computing
KW  - Robot sensing systems
KW  - Software as a service
KW  - Task analysis
KW  - Servers
DO  - 10.1109/IROS.2018.8593587
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Limitations with the on-board computational resources installed on untethered robots such as humanoids and mobile robots in general affects significantly the performance and capabilities of these machines. An approach to address this issue is to make use of the cloud robotics concept and take advantage of the extensive computational resources of the cloud. XBotCloud is a recently developed component of the XBot framework. It tackles the above challenges by introducing the tools and mechanisms to enable users and robots to exploit the computational resources of the cloud allowing the execution of services with low, soft or hard Real-Time execution/communication performance. The latter is ensured thanks to the functionality provided by the XBotCore Real-Time cross-robot software component of the XBot framework. XBotCloud addresses also one of the main challenges related with cloud robotics: security. To avoid remote attacks it takes advantage of the Amazon Web Services (AWS)Cloud Security and it uses an internal VPN Network to handle the connectivity between the robot and the cloud server. The full implementation of the framework is presented and its functionality is demonstrated in realistic tasks involving pipelines that mix the execution of cloud services with moderate execution time constraints and Real-Time modules running on the robot local control unit. XBotCloud performances and cross-robot flexibility are experimentally validated on two different robotic platforms, the WALK-MAN humanoid and the CENTAURO upper body/full-body.
ER  - 

TY  - CONF
TI  - Learning to Touch Objects Through Stage-Wise Deep Reinforcement Learning
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - F. de La Bourdonnaye
AU  - C. Teulière
AU  - J. Triesch
AU  - T. Chateau
PY  - 2018
KW  - end effectors
KW  - learning (artificial intelligence)
KW  - stage-wise deep reinforcement learning
KW  - complex behaviors
KW  - manipulation robotics
KW  - high-level modules
KW  - object palm-touching task
KW  - weakly-supervised learning
KW  - informative shaping reward
KW  - informative supervised reward
KW  - efficient learning
KW  - Task analysis
KW  - Robot kinematics
KW  - End effectors
KW  - Cameras
KW  - Robot vision systems
KW  - Kinematics
DO  - 10.1109/IROS.2018.8593362
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Learning complex behaviors through reinforcement learning is particularly challenging when reward is only available upon successful completion of the full behavior. In manipulation robotics, so-called shaping rewards are often used to overcome this problem. However, these usually require human engineering or (partial)world models describing, e.g., the kinematics of the robot or high-level modules for perception. Here we propose an alternative method to learn an object palm-touching task through a weakly-supervised and stagewise learning of simpler tasks. First, the robot learns to fixate the object with its cameras. Second, the robot learns eye-hand coordination by learning to fixate its end effector. Third, using the previously acquired skills an informative shaping reward can be computed which facilitates efficient learning of the object palm-touching task. We demonstrate in simulation that learning the full task with this shaping reward is comparable to learning with an informative supervised reward.
ER  - 

TY  - CONF
TI  - Bayesian Information Recovery from CNN for Probabilistic Inference
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7795
EP  - 7802
AU  - D. Kopitkov
AU  - V. Indelman
PY  - 2018
KW  - Bayes methods
KW  - Gaussian distribution
KW  - image classification
KW  - image fusion
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - neural nets
KW  - pose estimation
KW  - probability
KW  - robot vision
KW  - target tracking
KW  - probabilistic inference approach
KW  - light conditions
KW  - trajectory estimation
KW  - simulated unreal engine environment
KW  - uncertainty covariance
KW  - robot localization problem
KW  - robot pose
KW  - hidden state mean prediction
KW  - high-level state information
KW  - inference task
KW  - CNN feature likelihood
KW  - Bayesian framework
KW  - spatially-varying Gaussian distribution
KW  - generative viewpoint-dependent model
KW  - CNN classifier
KW  - visual observations
KW  - system hidden state
KW  - combinatorial data association
KW  - hand-engineered image features
KW  - high-dimensional visual measurements
KW  - Bayesian information recovery
KW  - Robots
KW  - Trajectory
KW  - Cameras
KW  - Bayes methods
KW  - Estimation
KW  - Uncertainty
KW  - Neural networks
DO  - 10.1109/IROS.2018.8594506
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Typical inference approaches that work with high-dimensional visual measurements use hand-engineered image features (e.g, SIFT) that require combinatorial data association, or predict only hidden state mean without considering its uncertainty and multi-modality aspects. We develop a novel approach to infer system hidden state from visual observations via CNN features which are outputs of a CNN classifier. To that end, at pre-deployment stage we use neural networks to learn a generative viewpoint-dependent model of CNN features given the robot pose and approximate this model by a spatially-varying Gaussian distribution. Further, at deployment this model is utilized within a Bayesian framework for probabilistic inference, considering a robot localization problem. Our method does not involve data association and provides uncertainty covariance of the final estimation. Moreover, we show empirically that the CNN feature likelihood is unimodal which simplifies the inference task. We test our method in a simulated Unreal Engine environment, where we succeed to retrieve high-level state information from CNN features and produce trajectory estimation with high accuracy. Additionally, we analyze robustness of our approach to different light conditions.
ER  - 

TY  - CONF
TI  - Catenary Tether Shape Analysis for a UAV - USV Team
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7803
EP  - 7809
AU  - K. A. Talke
AU  - M. De Oliveira
AU  - T. Bewley
PY  - 2018
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - hydrodynamics
KW  - marine vehicles
KW  - polynomials
KW  - position control
KW  - dynamic heave events
KW  - tether length
KW  - convenient curves
KW  - nondimensional relative position parameter
KW  - catenary analysis
KW  - catenary tether shape analysis
KW  - UAV - USV team
KW  - quasistatic catenary curve
KW  - semislack tether
KW  - unmanned surface vehicle
KW  - empirical analysis
KW  - system robustness
KW  - vertical heave
KW  - optimum condition
KW  - cable length
KW  - stationary unmanned air vehicle
KW  - heave robustness analysis
KW  - lookup table
KW  - Unmanned aerial vehicles
KW  - Winches
KW  - Robustness
KW  - Mathematical model
KW  - Shape
KW  - Vehicle dynamics
KW  - Sea surface
DO  - 10.1109/IROS.2018.8594280
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The quasi-static catenary curve of a semi-slack tether between an essentially stationary unmanned air vehicle (UAV) and a small unmanned surface vehicle (USV) is investigated and characterized. An empirical analysis, performed over a discretized space of vertical and horizontal separations of the two vehicles, determines an optimum cable length & tension for maximizing system robustness during the vertical heave of the USV due to high seas. Operating at this optimum condition allows for equal displacements of the USV in the up and down directions, minimizing the possibility of both fouling (with the tether touching the water) and excessive downforce on the UAV (with the tether pulled taut) during dynamic heave events. Scaling the horizontal offset, tether length, and tension by the flying height collapses all empirical results into convenient curves depending only on a nondimensional relative position parameter (Δx/Δy), accurately fit by low order polynomials. This eliminates the need for a lookup table, and decreases computation time during implementation. The heave robustness analysis results in a recommended operating relative position of Δx/Δy ≈ .46. Experimental results are presented and confirm the catenary analysis for the proposed tether.
ER  - 

TY  - CONF
TI  - Inertial Velocity and Attitude Estimation for Quadrotors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - J. Svacha
AU  - K. Mohta
AU  - M. Watterson
AU  - G. Loianno
AU  - V. Kumar
PY  - 2018
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - drag
KW  - helicopters
KW  - inertial navigation
KW  - Kalman filters
KW  - linear drag parameters
KW  - drag forces
KW  - linear drag model
KW  - IMU
KW  - inertial measurement unit
KW  - quadrotor UAV
KW  - body-fixed z axis
KW  - attitude estimation
KW  - inertial velocity
KW  - Aerodynamics
KW  - Sensors
KW  - Accelerometers
KW  - Estimation
KW  - Magnetometers
KW  - Kalman filters
KW  - Velocity measurement
DO  - 10.1109/IROS.2018.8593616
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work addresses the design and implementation of a filter that estimates the orientation of the body-fixed z axis and the velocity of a quadrotor UAV from the inertial measurement unit (IMU) given a known yaw. The velocity and attitude estimation is possible since the filter employs a linear drag model measuring the drag forces on the quadrotor through the IMU. These forces are functions of the robot's velocity and attitude. In addition, the filter estimates the linear drag parameters and thrust coefficient for the propellers. These parameters may be fed back into a controller to improve tracking performance. Experimental results are used to validate the proposed approach.
ER  - 

TY  - CONF
TI  - Quadtree-Accelerated Real-Time Monocular Dense Mapping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - K. Wang
AU  - W. Ding
AU  - S. Shen
PY  - 2018
KW  - autonomous aerial vehicles
KW  - image fusion
KW  - image motion analysis
KW  - image reconstruction
KW  - image resolution
KW  - mobile robots
KW  - path planning
KW  - quadtrees
KW  - robot vision
KW  - stereo image processing
KW  - real-time monocular dense mapping
KW  - truncated signed distance function
KW  - dense 3D maps
KW  - resolution depth maps
KW  - pixels
KW  - dynamic belief propagation
KW  - pixel selection
KW  - depth map
KW  - intensity image
KW  - quadtree structure
KW  - single localized moving camera
KW  - high-quality dense depth maps
KW  - robotic navigation
KW  - Cameras
KW  - Three-dimensional displays
KW  - Belief propagation
KW  - Estimation
KW  - Optimization
KW  - Real-time systems
KW  - Image resolution
DO  - 10.1109/IROS.2018.8594101
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a novel mapping method for robotic navigation. High-quality dense depth maps are estimated and fused into 3D reconstructions in real-time using a single localized moving camera. The quadtree structure of the intensity image is used to reduce the computation burden by estimating the depth map in multiple resolutions. Both the quadtree-based pixel selection and the dynamic belief propagation are proposed to speed up the mapping process: pixels are selected and optimized with the computation resource according to their levels in the quadtree. Solved depth estimations are further interpolated and fused temporally into full resolution depth maps and fused into dense 3D maps using truncated signed distance function (TSDF). We compare our method with other state-of-the-art methods using the public datasets. Onboard UAV autonomous flight is also used to further prove the usability and efficiency of our method on portable devices. For the benefit of the community, the implementation is also released as open source at https://github.com/HKUST-Aerial-Robotics/open_quadtree_mapping.
ER  - 

TY  - CONF
TI  - The Deformable Quad-Rotor Enabled and Wasp-Pedal-Carrying Inspired Aerial Gripper
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - N. Zhao
AU  - Y. Luo
AU  - H. Deng
AU  - Y. Shen
AU  - H. Xu
PY  - 2018
KW  - aerodynamics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - controllability
KW  - deformation
KW  - grippers
KW  - helicopters
KW  - mobile robots
KW  - stability
KW  - aerial gripper design
KW  - REMS
KW  - quadrotor body
KW  - quadrotor deformation
KW  - rigid elements based morphing structure
KW  - aerodynamic flow
KW  - wasp grasping behavior
KW  - stability
KW  - unmanned aerial vehicles
KW  - Grippers
KW  - Grasping
KW  - Strain
KW  - Payloads
KW  - Rotors
KW  - Manipulators
KW  - Gravity
DO  - 10.1109/IROS.2018.8594330
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The paper presents the development of a novel deformable quad-rotor enabled aerial gripper. The mechanism of our deformable quad-rotor is based on simultaneous expansion or contraction of the quad-rotor body, which is generated by controlling a rigid elements based morphing structure (REMS). Such deformation results in a highly deformable quad-rotor that can not only perform morphological adaptation in response to environmental changes and obstacles, but also improve the flight performance by contracting to facilitate the agility/maneuverability or by expanding to enhance the stability. Meanwhile, inspired by the wasp grasping behavior, such controllable expansion and contraction from the REMS ingeniously enable a new function of aerial gripper. In this paper, we start to detail the mechanism and design of the REMS based deformable quad-rotor, then present the quad-rotor deformation enabled aerial gripper design, its dynamics modeling, the grasping function and analysis. The simulation was conducted in order to graphically show the elicited aerodynamic flow situation during expansion or contraction of the quad-rotor with and without carrying payload. Experiments were further implemented to validate the grasping function of the gripper and the flight performance of the quad-rotor. Finally, two case studies on the new aerial gripper were performed. All results demonstrate the excellent performance of the deformable quad-rotor enabled aerial gripper, that is, it has the advantages of both flight maneuverability and grasping capability during performing tasks.
ER  - 

TY  - CONF
TI  - Adaptive Model Predictive Control for High-Accuracy Trajectory Tracking in Changing Conditions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7831
EP  - 7837
AU  - K. Pereida
AU  - A. P. Schoellig
PY  - 2018
KW  - adaptive control
KW  - helicopters
KW  - mobile robots
KW  - optimisation
KW  - predictive control
KW  - robust control
KW  - trajectory control
KW  - uncertain systems
KW  - wind disturbances
KW  - cost function
KW  - optimal reference input
KW  - quadrotor
KW  - MPC
KW  - trajectory tracking error
KW  - predictive approach
KW  - adaptive control strategies
KW  - unmodeled dynamics
KW  - dynamic environments
KW  - automated systems
KW  - adaptive model predictive control
KW  - nonadaptive approach
KW  - Adaptation models
KW  - Predictive models
KW  - Trajectory tracking
KW  - Uncertainty
KW  - Adaptive control
KW  - Vehicle dynamics
DO  - 10.1109/IROS.2018.8594267
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots and automated systems are increasingly being introduced to unknown and dynamic environments where they are required to handle disturbances, unmodeled dynamics, and parametric uncertainties. Robust and adaptive control strategies are required to achieve high performance in these dynamic environments. In this paper, we propose a novel adaptive model predictive controller that combines model predictive control (MPC) with an underlying L1 adaptive controller to improve trajectory tracking of a system subject to unknown and changing disturbances. The L1 adaptive controller forces the system to behave in a predefined way, as specified by a reference model. A higher-level model predictive controller then uses this reference model to calculate the optimal reference input based on a cost function, while taking into account input and state constraints. We focus on the experimental validation of the proposed approach and demonstrate its effectiveness in experiments on a quadrotor. We show that the proposed approach has a lower trajectory tracking error compared to non-predictive, adaptive approaches and a predictive, nonadaptive approach, even when external wind disturbances are applied.
ER  - 

TY  - CONF
TI  - Methods for Autonomous Wristband Placement with a Search-and-Rescue Aerial Manipulator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7838
EP  - 7844
AU  - J. M. Gómez-de-Gabriel
AU  - J. M. Gandarias
AU  - F. J. Pérez-Maldonado
AU  - F. J. García-Núñcz
AU  - E. J. Fernández-García
AU  - A. J. García-Cerezo
PY  - 2018
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - convolutional neural nets
KW  - grippers
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - path planning
KW  - rescue robots
KW  - robot vision
KW  - SLAM (robots)
KW  - autonomous wristband placement
KW  - robotic system
KW  - automatic wristband placement
KW  - remote sensor readings
KW  - continuous health monitoring
KW  - unmanned aerial manipulator
KW  - automatic wrist detection
KW  - RGB-D camera
KW  - convolutional neural network
KW  - Faster R-CNN
KW  - passive detachable gripper
KW  - VGG-16 neural network
KW  - target localization
KW  - trajectory planning
KW  - machine learning
KW  - parallel delta manipulator
KW  - search-and-rescue aerial manipulator
KW  - search and rescue operations
KW  - unmanned aerial vehicles
KW  - Manipulators
KW  - Wrist
KW  - Cameras
KW  - Grippers
KW  - Robot kinematics
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8594202
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A new robotic system for Search And Rescue (SAR) operations based on the automatic wristband placement on the victims' arm, which may provide identification, beaconing and remote sensor readings for continuous health monitoring. This paper focuses on the development of the automatic target localization and the device placement using an unmanned aerial manipulator. The automatic wrist detection and localization system uses an RGB-D camera and a convolutional neural network based on the region faster method (Faster R-CNN). A lightweight parallel delta manipulator with a large workspace has been built, and a new design of a wristband in the form of a passive detachable gripper, is presented, which, under contact, automatically attaches to the human, while disengages from the manipulator. A new trajectory planning method has been used to minimize the torques caused by the external forces during contact, which cause attitude perturbations. Experiments have been done to evaluate the machine learning method for detection and location, and for the assessment of the performance of the trajectory planning method. The results show how the VGG-16 neural network provides a detection accuracy of 67.99%. Moreover, simulation experiments have been done to show that the new trajectories minimize the perturbations to the aerial platform.
ER  - 

TY  - CONF
TI  - Nonlinear Adaptive Control of Quadrotor Multi-Flipping Maneuvers in the Presence of Time-Varying Torque Latency
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1
EP  - 9
AU  - Y. Chen
AU  - N. O. Pérez-Arancibia
PY  - 2018
KW  - adaptive control
KW  - aerodynamics
KW  - aircraft control
KW  - closed loop systems
KW  - control nonlinearities
KW  - control system synthesis
KW  - delays
KW  - helicopters
KW  - least squares approximations
KW  - linear systems
KW  - nonlinear control systems
KW  - position control
KW  - robust control
KW  - time-varying systems
KW  - torque control
KW  - recursive least-squares algorithm
KW  - high-performance linear controller
KW  - adaptive controller
KW  - nonlinear adaptive control scheme
KW  - linear time-varying model
KW  - linear time-invariant model
KW  - backstepping-based control scheme
KW  - LTV latency model
KW  - time-varying angular speed
KW  - torque delay
KW  - backstepping-based nonlinear controller
KW  - controller synthesis methods
KW  - high-speed multiflips
KW  - aerobatic maneuvers
KW  - closed-loop control schemes
KW  - stability robustness
KW  - time-varying torque
KW  - quadrotor multiflipping maneuvers
KW  - Torque
KW  - Aerodynamics
KW  - Linear systems
KW  - Adaptation models
KW  - Vehicle dynamics
KW  - Angular velocity
KW  - Propellers
DO  - 10.1109/IROS.2018.8594265
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The dynamics of quadrotors are affected by time-varying torque latency, which can greatly alter the stability robustness and performance of the closed-loop control schemes employed for flight; this issue is especially relevant during the execution of aerobatic maneuvers such as high-speed multi-flips. To address this problem, we propose two controller synthesis methods associated with two different modeling approaches. In the first approach, we describe torque latency with a linear time-invariant (LTI)model, identified through ground experiments, which is then used to design a backstepping-based nonlinear controller. In the second approach, we employ an improved linear time-varying (LTV)model with a priori unknown parameters, which is used to synthesize and implement a novel nonlinear adaptive control scheme updated in real time using the recursive least-squares (RLS)algorithm. Empirical observations suggest that the torque delay affecting the system depends on the time-varying angular speed of the flyer and its derivative. This phenomenon is explained by the fact that the aerodynamic forces produced by, and acting on, the rotating propellers vary with the local velocity of the incident flows. Hence, in the proposed adaptive structure, we define the parameters of the LTV latency model as linear functions of the angular speed reference and its derivative. Experimental results compellingly demonstrate the efficacy of the methods introduced in this paper; compared to the highperformance linear controller in [1]-[3], the backstepping-based control scheme and adaptive controller decrease the average root mean square (RMS)value of the control error by 17.82 % and 38.42 %, respectively.
ER  - 

TY  - CONF
TI  - NDVI Point Cloud Generator Tool Using Low-Cost RGB-D Sensor
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7860
EP  - 7865
AU  - D. Calero
AU  - E. Fernández
AU  - M. E. Parés
AU  - E. Angelats
PY  - 2018
KW  - cameras
KW  - geophysical image processing
KW  - image colour analysis
KW  - image sensors
KW  - vegetation mapping
KW  - vegetation index estimation
KW  - Microsoft Kinect V2
KW  - vegetation monitoring purposes
KW  - ROS point cloud generation tools
KW  - active IR camera
KW  - active RGB-D sensor technology
KW  - RGB camera
KW  - NDVI point cloud generator tool
KW  - 3D NDVI maps
KW  - Conferences
KW  - Intelligent robots
DO  - 10.1109/IROS.2018.8594175
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this manuscript, a NDVI point cloud generator tool based on low-cost active RGB-D sensor is presented. Taking advantage of currently available ROS point cloud generation tools and RGB-D sensor technology (like Microsoft Kinect), that includes an inbuilt active IR camera and a RGB camera, 3D NDVI maps can be quickly and easily generated for vegetation monitoring purposes. When using low-cost sensors for vegetation index estimation, it is necessary to apply a rigorous methodology for extracting reliable information. In this paper, the methodology for NDVI generation using a low-cost sensor as well as experiments to evaluate its performance is presented. The experiments performed show that it is possible to obtain a reliable NDVI point cloud from a Kinect V2.
ER  - 

TY  - CONF
TI  - Unsupervised Object Proposal Using Depth Boundary Density and Density Uniformity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7866
EP  - 7871
AU  - T. Hosono
AU  - S. Tarashima
AU  - J. Shimamura
AU  - T. Kinebuchi
PY  - 2018
KW  - feature extraction
KW  - image colour analysis
KW  - image texture
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object recognition
KW  - RGB-D object proposal methods
KW  - robot-computer vision area
KW  - bounding box
KW  - object recognition
KW  - density uniformity
KW  - unsupervised object proposal
KW  - depth boundary density difference
KW  - depth images
KW  - overlapping objects
KW  - texture objects
KW  - RGB images
KW  - object region extraction methods
KW  - window scoring
KW  - Proposals
KW  - Computational efficiency
KW  - Microsoft Windows
KW  - Object detection
KW  - Feature extraction
KW  - Search problems
KW  - Image edge detection
DO  - 10.1109/IROS.2018.8594408
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Object proposal that detects candidate bounding boxes of objects in images is an effective way of accelerating object recognition in the robot/computer vision area. We propose an accurate and fast object proposal method using depth images. Existing proposal methods can be roughly divided into two categories: window scoring and object region extraction. The window scoring methods usually have higher efficiency than object region extraction methods. The previous methods using RGB images detect an excessive number of boxes due to edges of texture objects. These methods also may misdetect overlapping objects as one candidate bounding box. To tackle these problems, we propose a novel and effective objectness measure using depth images. The proposed method evaluates objectness by using depth boundary density difference between inner and outer regions of a candidate bounding box. We also consider the uniformity of the outer boundary density in a candidate bounding box to divide overlapping objects into individual candidate bounding boxes. Our reasonable assumption here is that the depth boundary of an object has a closed loop. Our experiments show significant performance gains over existing RGB and RGB-D object proposal methods on the challenging toy-dataset [1] of complex crowded scenes.
ER  - 

TY  - CONF
TI  - LIMO: Lidar-Monocular Visual Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 7872
EP  - 7879
AU  - J. Graeter
AU  - A. Wilczynski
AU  - M. Lauer
PY  - 2018
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - mobile robots
KW  - motion estimation
KW  - object tracking
KW  - optical radar
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - visual localization
KW  - depth extraction algorithm
KW  - camera feature tracks
KW  - outlier rejection
KW  - sensor combination
KW  - LIMO
KW  - lidar-monocular visual odometry
KW  - higher level functionality
KW  - autonomous driving
KW  - precise motion estimate
KW  - powerful algorithms
KW  - great majority
KW  - binocular imagery
KW  - bundle adjustment
KW  - LIDAR measurements
KW  - Feature extraction
KW  - Laser radar
KW  - Cameras
KW  - Estimation
KW  - Three-dimensional displays
KW  - Calibration
KW  - Visual odometry
DO  - 10.1109/IROS.2018.8594394
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Higher level functionality in autonomous driving depends strongly on a precise motion estimate of the vehicle. Powerful algorithms have been developed. However, their great majority focuses on either binocular imagery or pure LIDAR measurements. The promising combination of camera and LIDAR for visual localization has mostly been unattended. In this work we fill this gap, by proposing a depth extraction algorithm from LIDAR measurements for camera feature tracks and estimating motion by robustified keyframe based Bundle Adjustment. Semantic labeling is used for outlier rejection and weighting of vegetation landmarks. The capability of this sensor combination is demonstrated on the competitive KITTI dataset, achieving a placement among the top 15. The code is released to the community.
ER  - 


