TY  - CONF
TI  - Conductive Knit-covered Pneumatic Artificial Muscle (k-PAM) Actuator
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1476
EP  - 1481
AU  - B. Jamil
AU  - S. Lee
AU  - Y. Choi
PY  - 2018
KW  - durability
KW  - fabrics
KW  - pneumatic actuators
KW  - silver
KW  - yarn
KW  - stitch methods
KW  - semipermanent conductive knit
KW  - high repetitive operation environment
KW  - nonconductive yarn
KW  - external force
KW  - actuator body
KW  - k-PAM
KW  - conductive knit-covered pneumatic artificial muscle
KW  - Actuators
KW  - Yarn
KW  - Bladder
KW  - Fabrication
KW  - Force
KW  - Sensors
KW  - Resistance
DO  - 10.1109/IROS.2018.8594510
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The paper presents design, fabrication and characteristics of two kinds of conductive Knit-covered Pneumatic Artificial Muscle (it is called as k-PAM in the paper) actuators, in which two different knits are made by braiding silver-coated (conductive) yarn and spandex (non-conductive) yarn with different stitch methods. The k-PAM is able to measure the change in length of the actuator body according to the applied air pressures as well as the strain due to external force. A complete fabrication method is presented to make the actuator work for higher pressure (≥ 300[kPa]). Since the force generated by the actuator is decoupled from the external force, ultimately, it can be directly used to measure not only the length but also the force. Experimental validations are performed describing the characteristics of two different types of k-PAMs. It is expected that the k-PAM can be used directly for robotic applications in higher pressure condition, while the semi-permanent conductive knit provides the actuator with durability in high repetitive operation environment.
ER  - 

TY  - CONF
TI  - Underwater Robot Navigation for Maintenance and Inspection of Flooded Mine Shafts
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1482
EP  - 1487
AU  - O. Álvarez-Tuñón
AU  - Á. Rodríguez
AU  - A. Jardón
AU  - C. Balaguer
PY  - 2018
KW  - coal
KW  - floods
KW  - inspection
KW  - maintenance engineering
KW  - mining
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - sensors
KW  - shafts
KW  - underwater vehicles
KW  - flooded shafts
KW  - EU project STAMS
KW  - autonomous underwater robotic system
KW  - periodic monitoring
KW  - underwater robot navigation
KW  - flooded mine shafts inspection
KW  - flooded mine shafts maintenance
KW  - sensor information
KW  - Robot sensing systems
KW  - Shafts
KW  - Three-dimensional displays
KW  - Sonar
KW  - Navigation
KW  - Visual odometry
DO  - 10.1109/IROS.2018.8594445
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The maintenance and inspection of the flooded shafts, specially coal ones, is an important environmental problem. There are thousands of shafts of this type in Europe with the danger of pollution, flood and collapse. This paper presents some of the main ongoing works of the EU project STAMS that develop an autonomous underwater robotic system for periodic monitoring of flooded shafts in hazardous and complex conditions. The accurate navigation is very cluttered at 1.000 m depth conditions, where minimum visibility and unexpected obstacles are some of the difficulties to overcome. We are going beyond classical navigation approaches using only few sensor information. Another innovation is the installation of Reference Points (RPs) in the shaft's walls by the robot using a special fixation mechanism. The specially designed cases of the RPs allow to house specific sensors and help in the navigation, and will be used in periodic monitoring and assessment of the mine shafts. The positioning and attachment of these RPs is another contribution of this paper.
ER  - 

TY  - CONF
TI  - Mechanical subsystems integration and structural analysis for the autonomous underwater explorer
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1488
EP  - 1493
AU  - J. Villa
AU  - A. Heininen
AU  - S. Zavari
AU  - T. Salomaa
AU  - O. Usenius
AU  - J. Laitinen
AU  - J. Aaltonen
AU  - K. T. Koskinen
PY  - 2018
KW  - autonomous underwater vehicles
KW  - finite element analysis
KW  - mechanical strength
KW  - mobile robots
KW  - robot dynamics
KW  - strain gauges
KW  - position requirements
KW  - finite element method
KW  - perception unit
KW  - FEM
KW  - strain gauge locations
KW  - modular mechanical design
KW  - autonomous underwater explorer
KW  - structural analysis
KW  - mechanical subsystems integration
KW  - hull endures pressures
KW  - deep dives
KW  - hull strength
KW  - structural strength analysis
KW  - orientation requirements
KW  - navigation systems
KW  - propulsion unit
KW  - ballast system
KW  - UX-1
KW  - Shape
KW  - Robots
KW  - Electronic ballasts
KW  - Manifolds
KW  - Propulsion
KW  - Finite element analysis
KW  - Cameras
DO  - 10.1109/IROS.2018.8593393
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The aim of this study is to analyse the modular mechanical design and integration of all three low-level modules in UX-1 (pendulum, ballast system and propulsion unit). The components of the perception and navigation systems have position and orientation requirements that dictate the shape of the hull. A structural strength analysis using Finite Element method (FEM) was made to study the hull strength during deep dives. The results are presented here, which indicates that the hull endures pressures related to deep dives. Also for validation, strain gauge locations were defined.
ER  - 

TY  - CONF
TI  - UX 1 system design - A robotic system for underwater mining exploration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1494
EP  - 1500
AU  - A. Martins
AU  - J. Almeida
AU  - C. Almeida
AU  - A. Dias
AU  - N. Dias
AU  - J. Aaltonen
AU  - A. Heininen
AU  - K. T. Koskinen
AU  - C. Rossi
AU  - S. Dominguez
AU  - C. Vörös
AU  - S. Henley
AU  - M. McLoughlin
AU  - H. van Moerkerk
AU  - J. Tweedie
AU  - B. Bodo
AU  - N. Zajzon
AU  - E. Silva
PY  - 2018
KW  - cameras
KW  - control system synthesis
KW  - innovation management
KW  - mining
KW  - mobile robots
KW  - robot vision
KW  - sonar
KW  - underwater vehicles
KW  - UX 1 system design
KW  - underwater mining exploration
KW  - UX-1 underwater mine exploration robotic system
KW  - UNEXMIN project
KW  - international innovation action
KW  - EU H2020 program
KW  - flooded underground mines
KW  - UX-1 robot prototype
KW  - recovery system
KW  - post-processing computational infrastructure
KW  - spherical robot
KW  - rotating laser line structured light systems
KW  - comprehensive mine model
KW  - robot design
KW  - UV-light
KW  - natural gamma-ray detector
KW  - multi-spectral camera
KW  - electro-conductivity
KW  - magnetic field sensors
KW  - high resolution imagery
KW  - Robot sensing systems
KW  - Sonar
KW  - Cameras
KW  - Payloads
KW  - Three-dimensional displays
DO  - 10.1109/IROS.2018.8593999
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes the UX-1 underwater mine exploration robotic system under development in the context of the UNEXMIN project. UNEXMIN is an international innovation action funded under the EU H2020 program, aiming to develop new technologies and services allowing the exploration of flooded underground mines. The system is comprised by the UX-1 robot prototype, launch and recovery system, command and control subsystem and a data management and post-processing computational infrastructure. The UX-1 robot is a small spherical robot equipped with a multibeam sonar, five digital cameras and rotating laser line structured light systems. It is capable of obtaining an accurate point cloud of the surrounding environment along with high resolution imagery. A set of mineralogy, water parameters and geophysical sensors was also developed in order to obtain a more comprehensive mine model. These comprise a multi-spectral camera, electro-conductivity, pH, magnetic field sensors, a subbottom sonar, total natural gamma-ray detector, UV-light for fluorescent observation and a water sampling unit. The design of the system is presented along with the robot design. Some preliminary results are also presented and discussed.
ER  - 

TY  - CONF
TI  - Automation in sensing and raw material characterization - a conceptual framework
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1501
EP  - 1506
AU  - F. S. Desta
AU  - M. W. N. Buxton
PY  - 2018
KW  - hyperspectral imaging
KW  - image fusion
KW  - image sensors
KW  - infrared spectra
KW  - infrared spectroscopy
KW  - statistical analysis
KW  - raw material characterization
KW  - material identification process
KW  - technological maturity
KW  - data fusion
KW  - sensor combinations approach
KW  - sensors signals
KW  - sensor technologies
KW  - real-time mining project concept
KW  - red green blue imaging
KW  - short wave infrared hyperspectral imaging
KW  - sensing automation
KW  - sensor signal
KW  - sensor data combinations
KW  - RTM
KW  - RGB imaging
KW  - visible near infrared hyperspectral imaging
KW  - VNIR
KW  - SWIR
KW  - Fourier-transform infrared spectroscopy
KW  - FTIR
KW  - laser induced breakdown spectroscopy
KW  - LIBS
KW  - multi-variate statistical interpretation
KW  - Minerals
KW  - Data integration
KW  - Automation
KW  - Robot sensing systems
KW  - Hyperspectral imaging
KW  - Raw materials
KW  - sensors data
KW  - data fusion
KW  - automation
KW  - material characterization
KW  - polymetallic sulphides
DO  - 10.1109/IROS.2018.8593774
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The use of sensor technologies for material characterization is rapidly growing and innovative advancement is observed. However, the use of sensor combinations for a raw material characterization in mining is very limited and automation of the material identification process using a combined sensor signal is not defined. Potential sensor technologies for raw material characterization were evaluated based on the applicability and technological maturity. To ensure a rapid implementation of the Real-time mining (RTM) project concept, mature technologies such as Red Green Blue (RGB) imaging, Visible Near Infrared (VNIR) hyperspectral imaging, Short Wave Infrared (SWIR) hyperspectral imaging, Fourier-Transform Infrared Spectroscopy (FTIR), Laser Induced Breakdown Spectroscopy (LIBS) and Raman were selected. Each selected technology was assessed for automation in sensing and applicability (for characterization of the test case materials). Based on the results the sensor data were further considered for data fusion. The proposed sensor combinations approach encompasses three levels of data fusion: low-level, mid-level and high-level. The data of the different sensors are fused together in order to acquire a wide range of mineral properties within each lithotype and an improved classification and predictive models. The preferred level of data fusion and preferred sensor data combinations will be used to develop a multi-variate statistical interpretation rule which relates combination of sensors signals with raw material properties. Thus a tool which integrates the combined sensor signal with materials properties will be developed and used to automate the material characterization process.
ER  - 

TY  - CONF
TI  - The benefits and challenges of robotics in the mineral raw materials sector - an overview
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1507
EP  - 1512
AU  - L. Lopes
AU  - T. Miklovicz
AU  - E. Bakker
AU  - Z. Milosevic
PY  - 2018
KW  - industrial robots
KW  - mineral processing industry
KW  - mining industry
KW  - raw materials
KW  - mineral raw materials sector
KW  - material transport
KW  - robotic digging
KW  - robotic loading
KW  - mining industry
KW  - Service robots
KW  - Minerals
KW  - Productivity
KW  - Fuel processing industries
KW  - Robot sensing systems
KW  - Raw materials
DO  - 10.1109/IROS.2018.8594218
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotics applications in the raw materials sector are becoming increasingly common due to their many perceived benefits. In mining, the extended use of robotics is especially seen in the exploration and exploitation phases, where mineral resources are discovered, extracted and processed. The use of robotics in the mining industry started in the 60s and today it is seen in the automation of material transport or in robotic digging and loading. Potential benefits include improved productivity, decreased production costs, better operational efficiency, increased safety, reduced waste and, ultimately, more value creation. The increasing amount of robotics used in the raw materials sector is coupled with a series of ethical and legal issues, regulatory challenges and policy requirements that affect both producers and end-users of robotic technologies. The benefits and challenges of robotics applications, often overlooked by the stakeholders, can hinder both their integration in the sector and the further development of mining activities, if not properly addressed.
ER  - 

TY  - CONF
TI  - Design, Modeling and Control of a Spherical Autonomous Underwater Vehicle for Mine Exploration
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1513
EP  - 1519
AU  - R. A. S. Fernandez
AU  - E. A. Parra R.
AU  - Z. Milosevic
AU  - S. Dominguez
AU  - C. Rossi
PY  - 2018
KW  - autonomous underwater vehicles
KW  - control system synthesis
KW  - intelligent control
KW  - motion control
KW  - oceanographic equipment
KW  - position control
KW  - three-term control
KW  - flooded mine tunnel networks
KW  - unique mechanical hardware design
KW  - electrical hardware design
KW  - high-fidelity dynamic model
KW  - underwater experiments
KW  - controlled environment
KW  - standard motion patterns
KW  - Proportional-Integral-Derivative controller
KW  - PID controller
KW  - advanced control schemes
KW  - spherical AUV
KW  - tested underwater motions
KW  - spherical autonomous underwater vehicle
KW  - vehicle prototype
KW  - novel spherical autonomous
KW  - Prototypes
KW  - DC motors
KW  - Manifolds
KW  - Mathematical model
KW  - Robots
KW  - Propulsion
KW  - Shape
DO  - 10.1109/IROS.2018.8594016
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the design, implementation and validation of a novel spherical Autonomous Underwater Vehicle (AUV) prototype, developed for inspection and exploration of flooded mine tunnel networks. The unique mechanical, electrical and hardware design is presented, as well as the development of a theoretical 6 degree-of-freedom (DOF) high-fidelity dynamic model of the system. A series of underwater experiments were carried out in a controlled environment to test the standard motion patterns of the AUV with a Proportional-Integral-Derivative (PID) controller. The performance of the PID controller will be used as the baseline for comparison of more advanced control schemes. The experimental results demonstrated that the spherical AUV was able to realize the tested underwater motions with notable performance.
ER  - 

TY  - CONF
TI  - ίVAMOS! Underwater Mining Machine Navigation System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1520
EP  - 1526
AU  - J. Almeida
AU  - A. Ferreira
AU  - B. Matias
AU  - C. Lomba
AU  - A. Martins
AU  - E. Silva
PY  - 2018
KW  - autonomous underwater vehicles
KW  - Kalman filters
KW  - mining
KW  - mining equipment
KW  - mobile robots
KW  - nonlinear filters
KW  - satellite navigation
KW  - sensor fusion
KW  - underwater acoustic communication
KW  - underwater mining machine navigation system
KW  - data fusion approach
KW  - sensor information
KW  - extended kalman filter
KW  - EKF
KW  - ¡VAMOS
KW  - multiple antenna GNSS system
KW  - inverted ultra-short baseline
KW  - surface vessel
KW  - underwater mining vehicle
KW  - multiple vehicle underwater localization solution
KW  - Position measurement
KW  - Global navigation satellite system
KW  - Receivers
KW  - Transponders
KW  - Accelerometers
KW  - Data mining
KW  - Gravity
DO  - 10.1109/IROS.2018.8593773
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Limited perception capabilities underwater shrink the envelope of effective localization techniques that can be applied in this environment. Long-term localization in six degrees of freedom can only be achieved by combining different sources of information. A multiple vehicle underwater localization solution, for localizing an underwater mining vehicle and its support vessel, is presented in this paper. The surface vessel carries a short baseline network, that interact with the inverted ultra-short baseline, carried by the underwater mining vehicle. A multiple antenna GNSS system provides data for localizing the surface vessel and to georeference the short baseline array. Localization of the mining vehicle results from a data fusion approach, that combines multiple sources of sensor information using the Extended Kalman Filter (EKF) framework. The developed solutions were applied in the context of the ¡VAMOS! European project. Long-term real time position errors below 0.2 meters, for the underwater machine, and 0.02 meters, for the surface vessel, were accomplished in the field. All presented results are based on data acquired in a real scenario.
ER  - 

TY  - CONF
TI  - Positioning. Navigation and Awareness of the !VAMOS! Underwater Robotic Mining System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1527
EP  - 1533
AU  - J. Almeida
AU  - A. Martins
AU  - C. Almeida
AU  - A. Dias
AU  - B. Matias
AU  - A. Ferreira
AU  - P. Jorge
AU  - R. Martins
AU  - M. Bleier
AU  - A. Nuchter
AU  - J. Pidgeon
AU  - S. Kapusniak
AU  - E. Silva
PY  - 2018
KW  - control engineering computing
KW  - mining
KW  - mobile robots
KW  - position control
KW  - virtual reality
KW  - global architecture
KW  - real-time grade system
KW  - 3D virtual reality HMI
KW  - realtime mine modeling
KW  - ¡VAMOS!
KW  - underwater robotic mining system
KW  - navigation
KW  - mining field trial
KW  - PNA system
KW  - PNA sensors
KW  - Three-dimensional displays
KW  - Sensor systems
KW  - Solid modeling
KW  - Presence network agents
KW  - Virtual reality
KW  - Real-time systems
DO  - 10.1109/IROS.2018.8593869
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents the positioning, navigation and awareness (PNA) system developed for the Underwater Robotic Mining System of the !VAMOS! project [1]. It describes the main components of the !VAMOS! system, the PNA sensors in each of those components, the global architecture of the PNA system, and its main subsystems: Position and Navigation, Realtime Mine Modeling, 3D Virtual reality HMI and Real-time grade system. General results and lessons learn during the first mining field trial in Lee Moor, Devon, UK during the months of September and October 2017 are presented.
ER  - 

TY  - CONF
TI  - Multi-Agent Imitation Learning for Driving Simulation
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1534
EP  - 1539
AU  - R. P. Bhattacharyya
AU  - D. J. Phillips
AU  - B. Wulfe
AU  - J. Morton
AU  - A. Kuefler
AU  - M. J. Kochenderfer
PY  - 2018
KW  - intelligent transportation systems
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - multiagent Imitation Learning
KW  - human drivers
KW  - multiagent setting
KW  - PS-GAIL method
KW  - single-agent GAIL policies
KW  - curriculum learning
KW  - multiple agents
KW  - test time
KW  - multiagent driving scenarios
KW  - single-agent environments
KW  - representative human driver models
KW  - Generative Adversarial Imitation Learning
KW  - autonomous vehicles
KW  - appealing option
KW  - Vehicles
KW  - Training
KW  - Trajectory
KW  - Optimization
KW  - Biological system modeling
KW  - Testing
KW  - Markov processes
DO  - 10.1109/IROS.2018.8593758
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Simulation is an appealing option for validating the safety of autonomous vehicles. Generative Adversarial Imitation Learning (GAIL) has recently been shown to learn representative human driver models. These human driver models were learned through training in single-agent environments, but they have difficulty in generalizing to multi-agent driving scenarios. We argue these difficulties arise because observations at training and test time are sampled from different distributions. This difference makes such models unsuitable for the simulation of driving scenes, where multiple agents must interact realistically over long time horizons. We extend GAIL to address these shortcomings through a parameter-sharing approach grounded in curriculum learning. Compared with single-agent GAIL policies, policies generated by our PS-GAIL method prove superior at interacting stably in a multi-agent setting and capturing the emergent behavior of human drivers.
ER  - 

TY  - CONF
TI  - Model-Based Action Exploration for Learning Dynamic Motion Skills
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1540
EP  - 1546
AU  - G. Berseth
AU  - A. Kyriazis
AU  - I. Zinin
AU  - W. Choi
AU  - M. van de Panne
PY  - 2018
KW  - Gaussian distribution
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - model-based action exploration
KW  - dynamic motion skills
KW  - deep reinforcement learning
KW  - Gaussian distribution
KW  - forward dynamics model
KW  - motion control tasks
KW  - internal lookahead prediction
KW  - robotic locomotion
KW  - juggling
KW  - Computational modeling
KW  - Stochastic processes
KW  - Robots
KW  - Predictive models
KW  - Task analysis
KW  - Training
KW  - Generative adversarial networks
DO  - 10.1109/IROS.2018.8593588
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deep reinforcement learning has achieved great strides in solving challenging motion control tasks. Recently, there has been significant work on methods for exploiting the data gathered during training, but there has been less work on how to best generate the data to learn from. For continuous action domains, the most common method for generating exploratory actions involves sampling from a Gaussian distribution centred around the mean action output by a policy. Although these methods can be quite capable, they do not scale well with the dimensionality of the action space, and can be dangerous to apply on hardware. We consider learning a forward dynamics model to predict the result, (xt+1), of taking a particular action, (u), given a specific observation of the state, (xt). With this model we perform internal lookahead predictions of outcomes and seek actions we believe have a reasonable chance of success. This method alters the exploratory action space, thereby increasing learning speed and enables higher quality solutions to difficult problems, such as robotic locomotion and juggling.
ER  - 

TY  - CONF
TI  - Active Learning based on Data Uncertainty and Model Sensitivity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1547
EP  - 1554
AU  - N. Chen
AU  - A. Klushyn
AU  - A. Paraschos
AU  - D. Benbouzid
AU  - P. Van der Smagt
PY  - 2018
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - pendulums
KW  - elementary skills
KW  - smooth movements
KW  - newly acquired knowledge
KW  - additional demonstration
KW  - nonsmooth transitions
KW  - latent space
KW  - metric learning
KW  - deep generative models
KW  - smooth trajectories
KW  - abrupt movements
KW  - missing information
KW  - necessary knowledge
KW  - fundamentally different skills
KW  - model sensitivity
KW  - data uncertainty
KW  - active learning
KW  - Uncertainty
KW  - Jacobian matrices
KW  - Manifolds
KW  - Data models
KW  - Measurement
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593552
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots can rapidly acquire new skills from demonstrations. However, during generalisation of skills or transitioning across fundamentally different skills, it is unclear whether the robot has the necessary knowledge to perform the task. Failing to detect missing information often leads to abrupt movements or to collisions with the environment. Active learning can quantify the uncertainty of performing the task and, in general, locate regions of missing information. We introduce a novel algorithm for active learning and demonstrate its utility for generating smooth trajectories. Our approach is based on deep generative models and metric learning in latent spaces. It relies on the Jacobian of the likelihood to detect non-smooth transitions in the latent space, i.e., transitions that lead to abrupt changes in the movement of the robot. When non-smooth transitions are detected, our algorithm asks for an additional demonstration from that specific region. The newly acquired knowledge modifies the data manifold and allows for learning a latent representation for generating smooth movements. We demonstrate the efficacy of our approach on generalising elementary skills, transitioning across different skills, and implicitly avoiding collisions with the environment. For our experiments, we use a simulated pendulum where we observe its motion from images and a 7-DoF anthropomorphic arm.
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning for Audio-Visual Gaze Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1555
EP  - 1562
AU  - S. Lathuilière
AU  - B. Massé
AU  - P. Mesejo
AU  - R. Horaud
PY  - 2018
KW  - gaze tracking
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - deep reinforcement
KW  - audio-visual gaze control
KW  - human-robot interaction
KW  - controlled robot motions
KW  - visual observations
KW  - acoustic observations
KW  - robot head
KW  - robotic head
KW  - reinforcement learning formulation
KW  - gaze control problem
KW  - audio data
KW  - visual data
KW  - audio-visual fusion framework
KW  - RL
KW  - microphone observations
KW  - deep architectures
KW  - Visualization
KW  - Cameras
KW  - Robot vision systems
KW  - Robot kinematics
KW  - Reinforcement learning
DO  - 10.1109/IROS.2018.8594327
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We address the problem of audio-visual gaze control in the specific context of human-robot interaction, namely how controlled robot motions are combined with visual and acoustic observations in order to direct the robot head towards targets of interest. The paper has the following contributions: (i) a novel audio-visual fusion framework that is well suited for controlling the gaze of a robotic head; (ii) a reinforcement learning (RL) formulation for the gaze control problem, using a reward function based on the available temporal sequence of camera and microphone observations; and (iii) several deep architectures that allow to experiment with early and late fusion of audio and visual data. We introduce a simulated environment that enables us to learn the proposed deep RL model without the need of spending hours of tedious interaction. By thoroughly experimenting on a publicly available dataset and on a real robot, we provide empirical evidence that our method achieves state-of-the-art performance.
ER  - 

TY  - CONF
TI  - An Ensemble with Shared Representations Based on Convolutional Networks for Continually Learning Facial Expressions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1563
EP  - 1568
AU  - H. Siqueira
AU  - P. Barros
AU  - S. Magg
AU  - S. Wermter
PY  - 2018
KW  - convolutional neural nets
KW  - emotion recognition
KW  - face recognition
KW  - feature extraction
KW  - human-robot interaction
KW  - robot vision
KW  - supervised learning
KW  - ensemble-based systems
KW  - human-robot interactions
KW  - unlabelled facial expressions
KW  - emotion recognition capability
KW  - social robots
KW  - continually learning facial expressions
KW  - shared representations
KW  - ensemble predictions
KW  - convolutional branches
KW  - low-level feature extractors
KW  - convolutional networks
KW  - Training
KW  - Feature extraction
KW  - Robots
KW  - Computer architecture
KW  - Face recognition
KW  - Convolution
KW  - Redundancy
DO  - 10.1109/IROS.2018.8594276
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Social robots able to continually learn facial expressions could progressively improve their emotion recognition capability towards people interacting with them. Semi-supervised learning through ensemble predictions is an efficient strategy to leverage the high exposure of unlabelled facial expressions during human-robot interactions. Traditional ensemble-based systems, however, are composed of several independent classifiers leading to a high degree of redundancy, and unnecessary allocation of computational resources. In this paper, we proposed an ensemble based on convolutional networks where the early layers are strong low-level feature extractors, and their representations shared with an ensemble of convolutional branches. This results in a significant drop in redundancy of low-level features processing. Training in a semi-supervised setting, we show that our approach is able to continually learn facial expressions through ensemble predictions using unlabelled samples from different data distributions.
ER  - 

TY  - CONF
TI  - Deep Q-Learning for Dry Stacking Irregular Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1569
EP  - 1576
AU  - Y. Liu
AU  - S. M. Shamsi
AU  - L. Fang
AU  - C. Chen
AU  - N. Napp
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - motion control
KW  - neurocontrollers
KW  - state-action pairs
KW  - Q-network
KW  - robot arm
KW  - generated stacking plans
KW  - physical constraints
KW  - geometric constraints
KW  - action space
KW  - deep neural network
KW  - learned Q-function
KW  - reinforcement learning algorithm
KW  - local geometric considerations
KW  - reinforcement learning approach
KW  - dry stacking irregular objects
KW  - deep Q-learning
KW  - Stacking
KW  - Buildings
KW  - Robots
KW  - Planning
KW  - Shape
KW  - Stability analysis
KW  - Reinforcement learning
DO  - 10.1109/IROS.2018.8593619
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose a reinforcement learning approach for automatically building dry stacked (i.e. no mortar) structures with irregular objects. Stacking irregular objects is a challenging problem since each assembly action can be drawn from a continuous space of poses for an object, and several local geometric and physical considerations strongly affect the stability. To tackle this challenge, we concentrate on a simplified 2D version of the problem. We present a reinforcement learning algorithm based on deep Q-learning, where the learned Q-function, which maps state-action pairs into expected long-term rewards, is represented by a deep neural network. As the action space is continuous the Q-network is trained by sampling a finite number of actions that consider both geometric and physical constraints to approximate the target Q-values, Experiments show that the proposed method outperforms previous heuristics-based planning, leading to super construction with objects containing a significant amount of variations. We validate the generated stacking plans by executing them using a robot arm and manufactured, irregular objects.
ER  - 

TY  - CONF
TI  - Learning Actionable Representations from Visual Observations
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1577
EP  - 1584
AU  - D. Dwibedi
AU  - J. Tompson
AU  - C. Lynch
AU  - P. Sermanet
PY  - 2018
KW  - learning (artificial intelligence)
KW  - video coding
KW  - learning task-agnostic representations
KW  - continuous control tasks
KW  - multiple frames
KW  - single frame
KW  - self-supervised approach
KW  - reinforcement learning setting
KW  - random actions
KW  - continuous control policies
KW  - Proximal Policy Optimization
KW  - learned embeddings
KW  - real-world Pouring dataset
KW  - single-frame baseline
KW  - learning actionable representations
KW  - time-contrastive networks
KW  - Task analysis
KW  - Robots
KW  - Visualization
KW  - Reinforcement learning
KW  - Aerospace electronics
KW  - Solid modeling
KW  - Semantics
DO  - 10.1109/IROS.2018.8593951
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work we explore a new approach for robots to teach themselves about the world simply by observing it. In particular we investigate the effectiveness of learning task-agnostic representations for continuous control tasks. We extend Time-Contrastive Networks (TCN) that learn from visual observations by embedding multiple frames jointly in the embedding space as opposed to a single frame. We show that by doing so, we are now able to encode both position and velocity attributes significantly more accurately. We test the usefulness of this self-supervised approach in a reinforcement learning setting. We show that the representations learned by agents observing themselves take random actions, or other agents perform tasks successfully, can enable the learning of continuous control policies using algorithms like Proximal Policy Optimization (PPO) using only the learned embeddings as input. We also demonstrate significant improvements on the real-world Pouring dataset with a relative error reduction of 39.4% for motion attributes and 11.1% for static attributes compared to the single-frame baseline. Video results are available at https://sites.google.com/view/actionablerepresentations.
ER  - 

TY  - CONF
TI  - Efficient Distributed Torque Computation for Large Scale Robot Skin
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1593
EP  - 1599
AU  - F. Bergner
AU  - E. Dean-Leon
AU  - G. Cheng
PY  - 2018
KW  - computational complexity
KW  - control engineering computing
KW  - mobile robots
KW  - real-time systems
KW  - sensor fusion
KW  - skin
KW  - tactile sensors
KW  - torque control
KW  - skin information
KW  - reactive skin torque controller
KW  - kinesthetic robot behavior
KW  - scale robot skin
KW  - efficient distributed torque computation
KW  - real-time control loop
KW  - skin joint torques
KW  - computational delay
KW  - control PC
KW  - distributed skin joint torque computation
KW  - local microcontrollers
KW  - skin joint torque computations
KW  - real-time loop
KW  - complex computations
KW  - distributed skin cells
KW  - scale skin
KW  - appropriate skin joint torque
KW  - Skin
KW  - Torque
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594144
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The realization of a kinesthetic robot behavior using robot skin requires a reactive skin torque controller, which fuses skin information and robot information to an appropriate skin joint torque in real-time. This fusion of information in real-time is challenging when deploying large scale skin. In this paper, we present a system which efficiently computes the torque of distributed skin cells locally at the point of contacts, completely removing this complex computations from the real-time loop. We demonstrate the feasibility of realizing the skin joint torque computations on the local micro-controllers of the skin cells. Conducting experiments with a real robot, we compare the accuracy of the distributed skin joint torque computation with the computation on the control PC. We also show that the novel distributed approach completely eliminates the computational delay of computing skin joint torques in the robot's real-time control loop. As a result, this approach removes any limits for the maximum number of skin cells in control.
ER  - 

TY  - CONF
TI  - A Robust and Efficient Dynamic Network Protocol for a large-scale artificial robotic skin
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1600
EP  - 1605
AU  - C. Bader
AU  - F. Bergner
AU  - G. Cheng
PY  - 2018
KW  - protocols
KW  - robots
KW  - skin
KW  - telecommunication network reliability
KW  - protocol converges
KW  - skin network
KW  - artificial robot skin
KW  - dynamic network protocol
KW  - static network protocol approach
KW  - skin cells
KW  - artificial robotic skins
KW  - large-scale artificial robotic skin
KW  - Skin
KW  - Routing protocols
KW  - Robot sensing systems
KW  - Routing
KW  - Heuristic algorithms
DO  - 10.1109/IROS.2018.8594499
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Artificial robotic skins are continuously in contact with their environment, and therefore highly rely on proper connections in their skin cells' network. With a static network protocol approach, the affected skin area is unusable after a connection failure. Therefore, we developed a dynamic network protocol for large-scale artificial robotic skins, which re-routes the network upon connection failures to keep the whole skin in operation. Furthermore, the protocol balances the load for driving larger skins without packet loss. For verification, we validated the protocol on a large artificial robot skin we have developed and analyzed its performance with a skin network consisting of up to 204 cells. The failure recovery of the protocol converges in at most 50ms. We showed that the balancing method achieves a packet loss reduction of over 30% compared to the previously used protocol.
ER  - 

TY  - CONF
TI  - 3D Shape Perception from Monocular Vision, Touch, and Shape Priors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1606
EP  - 1613
AU  - S. Wang
AU  - J. Wu
AU  - X. Sun
AU  - W. Yuan
AU  - W. T. Freeman
AU  - J. B. Tenenbaum
AU  - E. H. Adelson
PY  - 2018
KW  - cameras
KW  - computational geometry
KW  - feature extraction
KW  - image colour analysis
KW  - image reconstruction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - object detection
KW  - object recognition
KW  - robot vision
KW  - shape recognition
KW  - solid modelling
KW  - tactile sensors
KW  - visual perception
KW  - 3D object shape
KW  - precise local shape information
KW  - monocular camera
KW  - visual observations
KW  - physical world
KW  - perceiving accurate 3D object shape
KW  - touch
KW  - monocular vision
KW  - real-world objects
KW  - visual prediction
KW  - object regions
KW  - learned shape priors
KW  - large-scale shape repositories
KW  - common object shapes
KW  - tactile observations
KW  - Shape
KW  - Three-dimensional displays
KW  - Image reconstruction
KW  - Surface reconstruction
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593430
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Perceiving accurate 3D object shape is important for robots to interact with the physical world. Current research along this direction has been primarily relying on visual observations. Vision, however useful, has inherent limitations due to occlusions and the 2D-3D ambiguities, especially for perception with a monocular camera. In contrast, touch gets precise local shape information, though its efficiency for reconstructing the entire shape could be low. In this paper, we propose a novel paradigm that efficiently perceives accurate 3D object shape by incorporating visual and tactile observations, as well as prior knowledge of common object shapes learned from large-scale shape repositories. We use vision first, applying neural networks with learned shape priors to predict an object's 3D shape from a single-view color image. We then use tactile sensing to refine the shape; the robot actively touches the object regions where the visual prediction has high uncertainty. Our method efficiently builds the 3D shape of common objects from a color image and a small number of tactile explorations (around 10). Our setup is easy to apply and has potentials to help robots better perform grasping or manipulation tasks on real-world objects.
ER  - 

TY  - CONF
TI  - Exploration and Reconstruction of Unknown Objects using a Novel Normal and Contact Sensor
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1614
EP  - 1620
AU  - S. Ottenhaus
AU  - P. Weiner
AU  - L. Kaul
AU  - A. Tulbure
AU  - T. Asfour
PY  - 2018
KW  - humanoid robots
KW  - manipulators
KW  - object recognition
KW  - pressure sensors
KW  - tactile sensors
KW  - tactile sensors
KW  - contact measurement
KW  - surface orientation
KW  - surface reconstruction
KW  - unknown objects
KW  - pressure sensor
KW  - contact force
KW  - developed sensor prototype
KW  - contact detection capability
KW  - normal estimation accuracy
KW  - contact sensor
KW  - surface normals
KW  - inertial measurement unit
KW  - IMU
KW  - mean reconstruction accuracy
KW  - Surface reconstruction
KW  - Surface treatment
KW  - Tactile sensors
KW  - Force
DO  - 10.1109/IROS.2018.8594272
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Tactile sensing of surface normals is essential for exploration of unknown objects. Many tactile sensors have been developed for contact measurement. However, few of these sensors provide surface orientation, and only up to a limited degree. This paper presents a novel contact and surface orientation sensor concept and its application for surface reconstruction of unknown objects. The sensor is comprised of an Inertial Measurement Unit (IMU) and a pressure sensor to accurately estimate the surface orientation in a wide range, while at the same time measuring contact force. We describe the developed sensor prototype and evaluate its performance regarding contact detection capability and normal estimation accuracy. We use this to reconstruct the surface of unknown objects using the humanoid robot ARMAR-III resulting in a mean reconstruction accuracy of 3.6 mm.
ER  - 

TY  - CONF
TI  - Soft Curvature and Contact Force Sensors for Deep-Sea Grasping via Soft Optical Waveguides
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1621
EP  - 1627
AU  - C. B. Teeple
AU  - K. P. Becker
AU  - R. J. Wood
PY  - 2018
KW  - actuators
KW  - force sensors
KW  - grippers
KW  - optical sensors
KW  - optical waveguides
KW  - remotely operated vehicles
KW  - soft robotic hand
KW  - optical sensing elements
KW  - proprioception
KW  - curvature sensing elements
KW  - contact force sensors
KW  - normal force
KW  - sensor design decisions
KW  - simulated deep-sea environments
KW  - curvature sensors
KW  - soft finger actuators
KW  - soft curvature
KW  - deep-sea grasping
KW  - intentionally-lossy optical waveguides
KW  - soft robotic grasping applications
KW  - subNewton force sensitivity
KW  - temperature -10.0 degC to 50.0 degC
KW  - Optical waveguides
KW  - Optical sensors
KW  - Optical device fabrication
KW  - Optical losses
KW  - Optical refraction
KW  - Optical variables control
DO  - 10.1109/IROS.2018.8594270
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this work, we show that sensors based on soft, intentionally-lossy optical waveguides are well-suited for soft robotic grasping applications in the deep-sea. Each finger of a soft robotic hand is outfitted with a 2×1 array of optical sensing elements to enable proprioception and contact force sensing. Curvature sensing elements are integrated directly into the structure of a finger, while contact force sensors are fabricated as standalone units and attached afterward. Along with considerations for interfacing with deep-sea remotely operated vehicles (ROVs), models for the effect of bending on light loss and the effect of normal force on strain were used to inform sensor design decisions. Our sensors show sensitivity to curvature over a range of diameters from 8 mm to 76 mm, and sub-Newton force sensitivity. Additionally, sensors were characterized in simulated deep-sea environments at temperatures from -10°C to 50°C and hydrostatic pressures up to 4000 psi. The sensitivity of our curvature sensors is invariant to the temperatures and pressure ranges tested, though contact force sensors decreased in sensitivity as temperatures decreased. Finally, we successfully demonstrate that sensors onboard soft finger actuators can provide informative state feedback during grasping operations in air and water.
ER  - 

TY  - CONF
TI  - Realtime State Estimation with Tactile and Visual Sensing for Inserting a Suction-held Object
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1628
EP  - 1635
AU  - K. Yu
AU  - A. Rodriguez
PY  - 2018
KW  - mobile robots
KW  - robot kinematics
KW  - robot vision
KW  - state estimation
KW  - tactile sensors
KW  - visual sensing
KW  - suction-held object
KW  - real-time state estimation system
KW  - robotic packaging
KW  - tactile sensing
KW  - on-line estimation technique
KW  - contact geometry
KW  - complex contact interactions
KW  - iSAM
KW  - robot kinematic measurement
KW  - planar settings
KW  - data-driven method
KW  - Robot sensing systems
KW  - Visualization
KW  - State estimation
KW  - Task analysis
KW  - Containers
DO  - 10.1109/IROS.2018.8594077
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We develop a real-time state estimation system to recover the pose and contact formation of an object relative to its environment. In this paper, we focus on the application of inserting an object picked by a suction cup into a tight space, a key technology for robotic packaging. We propose a framework that fuses tactile and visual sensing. Visual sensing is versatile and non-intrusive, but suffers from occlusions and limited accuracy, especially for tasks involving contact. Tactile sensing is local, but provides accuracy and robustness to occlusions. The proposed algorithm to fuse them is based on iSAM, an on-line estimation technique, which we use to incorporate kinematic measurements from the robot, contact geometry of the object and the container, and visual tracking. In this paper, we generalize previous results in planar settings [1] to a 3D task with more complex contact interactions. A key challenge is that we do not observe contact locations between the suction-held object and the container directly. We propose a data-driven method to infer the contact formation, which is then used in real-time by the state estimator. We demonstrate and evaluate the algorithm in a setup instrumented to provide groundtruth.
ER  - 

TY  - CONF
TI  - Mechanical and Perceptual Characterizations of the Localized Shearing using a Novel Haptic Display
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1636
EP  - 1642
AU  - H. Van Anh
AU  - S. Hirai
PY  - 2018
KW  - display devices
KW  - haptic interfaces
KW  - haptic pins
KW  - lateral localized displacement
KW  - localized shearing
KW  - perceptual characterizations
KW  - haptic display devices
KW  - human slip perception
KW  - mechanical response
KW  - human fingertip
KW  - Pins
KW  - Haptic interfaces
KW  - Force
KW  - Skin
KW  - Mathematical model
KW  - Numerical models
KW  - Strain
DO  - 10.1109/IROS.2018.8593958
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Previously, we presented the concept of a novel haptic display device that could generate lateral localized displacement on a human fingertip. This device is characterized by a bundle of haptic pins whose ends gently make contact with a human fingertip. In this paper, we proposed a dynamic model of interaction between haptic pins and finger for investigation of mechanical response of stress or strain on human fingertip under operation of the proposed haptic device. We also conducted preliminary experiment to determine the possible setups that maximizes the sense of partial slippage. The results presented in this paper may help assess human slip perception for the development of haptic display devices.
ER  - 

TY  - CONF
TI  - Finding safe 3D robot grasps through efficient haptic exploration with unscented Bayesian optimization and collision penalty
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1643
EP  - 1648
AU  - J. Castanheira
AU  - P. Vicente
AU  - R. Martinez-Cantin
AU  - L. Jamone
AU  - A. Bernardino
PY  - 2018
KW  - approximation theory
KW  - Bayes methods
KW  - collision avoidance
KW  - grippers
KW  - haptic interfaces
KW  - Kalman filters
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - unscented Bayesian optimization
KW  - novel collision penalty
KW  - exploration steps
KW  - safe 3D robot grasps
KW  - efficient haptic exploration
KW  - robust grasping
KW  - accurate models
KW  - known objects
KW  - approximate models
KW  - familiar objects
KW  - partial point clouds
KW  - unknown objects
KW  - sensing inaccuracies
KW  - local exploration
KW  - grasp execution
KW  - 3D haptic exploration strategy
KW  - Grasping
KW  - Three-dimensional displays
KW  - Optimization
KW  - Robot sensing systems
KW  - Bayes methods
DO  - 10.1109/IROS.2018.8594009
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robust grasping is a major, and still unsolved, problem in robotics. Information about the 3D shape of an object can be obtained either from prior knowledge (e.g., accurate models of known objects or approximate models of familiar objects) or real-time sensing (e.g., partial point clouds of unknown objects) and can be used to identify good potential grasps. However, due to modeling and sensing inaccuracies, local exploration is often needed to refine such grasps and successfully apply them in the real world. The recently proposed unscented Bayesian optimization technique can make such exploration safer by selecting grasps that are robust to uncertainty in the input space (e.g., inaccuracies in the grasp execution). Extending our previous work on 2D optimization, in this paper we propose a 3D haptic exploration strategy that combines unscented Bayesian optimization with a novel collision penalty heuristic to find safe grasps in a very efficient way: while by augmenting the search-space to 3D we are able to find better grasps, the collision penalty heuristic allows us to do so without increasing the number of exploration steps.
ER  - 

TY  - CONF
TI  - Indoor Mapping and Localization for Pedestrians using Opportunistic Sensing with Smartphones
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1649
EP  - 1656
AU  - Q. Liang
AU  - L. Wang
AU  - Y. Li
AU  - M. Liu
PY  - 2018
KW  - Bayes methods
KW  - Gaussian processes
KW  - indoor radio
KW  - mobile computing
KW  - mobile robots
KW  - optimisation
KW  - particle filtering (numerical methods)
KW  - path planning
KW  - radionavigation
KW  - regression analysis
KW  - SLAM (robots)
KW  - smart phones
KW  - wireless LAN
KW  - Gaussian Processes Regression
KW  - real-time localization
KW  - GPR variance map
KW  - pseudowall constraints
KW  - magnetic fields
KW  - globally consistent trajectories
KW  - opportunistic magnetic headings
KW  - WiFi signal similarity validation
KW  - magnetic sequence matching
KW  - loop-closure constraints
KW  - pedestrian dead-reckoning
KW  - motion constraints
KW  - GraphSLAM front-end
KW  - signal maps
KW  - Bayesian filtering-based online localization
KW  - GraphSLAM-based offline mapping
KW  - ambient indoor environments
KW  - low-cost indoor mapping
KW  - indoor localization
KW  - smartphone
KW  - size 2.3 m
KW  - size 3.41 m
KW  - Wireless fidelity
KW  - Trajectory
KW  - Smart phones
KW  - Simultaneous localization and mapping
KW  - Ground penetrating radar
KW  - Legged locomotion
DO  - 10.1109/IROS.2018.8594254
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Indoor localization for pedestrians has gained increasing popularity among the rich body of literature for the last decade. In this paper, a low-cost indoor mapping and localization solution is proposed using the opportunistic signals from ambient indoor environments with a smartphone. It is composed of GraphSLAM-based offline mapping and Bayesian filtering-based online localization using generated signal maps. The GraphSLAM front-end is constructed by motion constraints from pedestrian dead-reckoning (PDR), loop-closure constraints identified by magnetic sequence matching with WiFi signal similarity validation, and observation constraints from opportunistic magnetic headings after error rejection. Globally consistent trajectories are created by graph optimization, after which signal maps (e.g., WiFi, magnetic fields, lights) are generated by Gaussian Processes Regression (GPR) for later localization. We propose to use the pseudo-wall constraints from the GPR variance map of magnetic fields and the lights measurements as observations for particle filtering. The proposed method is evaluated on several datasets collected from both the in-compass office buildings and outside public areas. Real-time localization is demonstrated on a smartphone in an office building covering 2000 square meters with the 50- and 90-percentile accuracies being 2.30 m and 3.41 m, respectively.
ER  - 

TY  - CONF
TI  - Navigation without localisation: reliable teach and repeat based on the convergence theorem
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1657
EP  - 1664
AU  - T. Krajník
AU  - F. Majer
AU  - L. Halodová
AU  - T. Vintr
PY  - 2018
KW  - calibration
KW  - cameras
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - velocity control
KW  - mobile robot
KW  - taught path
KW  - learned velocities
KW  - camera information
KW  - position error model
KW  - mathematical proof
KW  - camera calibration
KW  - navigation system
KW  - mathematical model
KW  - explicit localisation
KW  - teach-and-repeat navigation scenarios
KW  - teach-and-repeat visual navigation
KW  - Robot kinematics
KW  - Navigation
KW  - Cameras
KW  - Robot vision systems
KW  - Simultaneous localization and mapping
KW  - Feature extraction
DO  - 10.1109/IROS.2018.8593803
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a novel concept for teach-and-repeat visual navigation. The proposed concept is based on a mathematical model, which indicates that in teach-and-repeat navigation scenarios, mobile robots do not need to perform explicit localisation. Rather than that, a mobile robot which repeats a previously taught path can simply “replay” the learned velocities, while using its camera information only to correct its heading relative to the intended path. To support our claim, we establish a position error model of a robot, which traverses a taught path by only correcting its heading. Then, we outline a mathematical proof which shows that this position error does not diverge over time. Based on the insights from the model, we present a simple monocular teach-and-repeat navigation method. The method is computationally efficient, it does not require camera calibration, and it can learn and autonomously traverse arbitrarily-shaped paths. In a series of experiments, we demonstrate that the method can reliably guide mobile robots in realistic indoor and outdoor conditions, and can cope with imperfect odometry, landmark deficiency, illumination variations and naturally-occurring environment changes. Furthermore, we provide the navigation system and the datasets gathered at www.github.com/gestom/stroll_bearnav.
ER  - 

TY  - CONF
TI  - Accurate Mix-Norm-Based Scan Matching
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1665
EP  - 1671
AU  - D. Wang
AU  - J. Xue
AU  - Z. Tao
AU  - Y. Zhong
AU  - D. Cui
AU  - S. Du
AU  - N. Zheng
PY  - 2018
KW  - expectation-maximisation algorithm
KW  - image matching
KW  - learning (artificial intelligence)
KW  - least squares approximations
KW  - mobile robots
KW  - optimisation
KW  - pose estimation
KW  - exponential power distributions
KW  - convergence characteristic
KW  - mix-norm-based scan matching
KW  - robust objective function design
KW  - MoEP-based residual error model
KW  - EM-like algorithm
KW  - likelihood field model
KW  - iteratively reweighted least squares phase
KW  - LFM
KW  - IRLS
KW  - on-line parameter learning
KW  - MiNoM optimization
KW  - mobile robotics
KW  - Iterative closest point algorithm
KW  - Linear programming
KW  - Gaussian distribution
KW  - Standards
KW  - Convergence
KW  - Optimization
KW  - Heuristic algorithms
DO  - 10.1109/IROS.2018.8594278
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Highly accurate mapping and localization is of prime importance for mobile robotics, and its core lies in efficient scan matching. Previous research are focusing on designing a robust objective function and the residual error distribution is often ignored or simply assumed as unitary or mixture of simple distributions. In this paper, a mixture of exponential power (MoEP) distributions is proposed to approximate the residual error distribution. The objective function induced by MoEP-based residual error modelling ensembles a mix-norm-based scan matching (MiNoM), which enhances the matching accuracy and convergence characteristic. Both the parameters of transformation (rotation and translation) and residual error distribution are estimated efficiently via an EM-like algorithm. The optimization of MiNoM is iteratively achieved via two phases: An on-line parameter learning (OPL) phase to learn residual error distribution for better representation according to the likelihood field model (LFM), and an iteratively reweighted least squares (IRLS) phase to attain transformation for accuracy and efficiency. Extensive experimental results validate that the proposed MiNoM out-performs several state-of-the-art scan matching algorithms in both convergence characteristic and matching accuracy.
ER  - 

TY  - CONF
TI  - StreetMap - Mapping and Localization on Ground Planes using a Downward Facing Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1672
EP  - 1679
AU  - X. Chen
AU  - A. S. Vempati
AU  - P. Beardsley
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - image filtering
KW  - image texture
KW  - mobile robots
KW  - robot vision
KW  - rectilinear textures
KW  - indoor tiling
KW  - ground plane texture
KW  - globally consistent map
KW  - complete working pipeline
KW  - absolute localization
KW  - indoor tiles
KW  - general texture
KW  - ground textures
KW  - mobile robot
KW  - downward facing camera
KW  - Cameras
KW  - Robot vision systems
KW  - Feature extraction
KW  - Robot kinematics
KW  - Slabs
DO  - 10.1109/IROS.2018.8594157
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a system to map a ground-plane, and to subsequently use the map for localization of a mobile robot. The robot has a downward-facing camera, and works on a variety of ground textures including general texture like tarmac, man-made designs like carpet, and rectilinear textures like indoor tiles or outdoor slabs. Such textures provide a basis for measuring relative motion (i.e. computer mouse functionality). But the goal here is the more challenging one of absolute localization. The paper describes a complete working pipeline to build a globally consistent map of a given ground-plane and subsequently to localize within this map at real-time. Two algorithms are described. The first is a feature-based approach which is general to any ground plane texture. The second algorithm takes advantage of the extra constraints available for common rectilinear textures like indoor tiling, paving slabs, and laid brickwork. Quantitative and qualitative experimental results are shown for mapping and localization on a variety of ground-planes.
ER  - 

TY  - CONF
TI  - The TUM VI Benchmark for Evaluating Visual-Inertial Odometry
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1680
EP  - 1687
AU  - D. Schubert
AU  - T. Goll
AU  - N. Demmel
AU  - V. Usenko
AU  - J. Stückler
AU  - D. Cremers
PY  - 2018
KW  - augmented reality
KW  - calibration
KW  - cameras
KW  - distance measurement
KW  - image capture
KW  - image sensors
KW  - image sequences
KW  - mobile robots
KW  - optical tracking
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - synchronisation
KW  - visual-inertial odometry
KW  - photometric calibration
KW  - motion capture system
KW  - IMU measurements
KW  - pose ground truth
KW  - inertial measurements
KW  - vision sensors
KW  - augmented reality
KW  - SLAM methods
KW  - visual odometry
KW  - IMU sensors
KW  - camera images
KW  - TUM VI benchmark
KW  - frequency 20.0 Hz
KW  - frequency 200.0 Hz
KW  - frequency 120.0 Hz
KW  - Cameras
KW  - Calibration
KW  - Simultaneous localization and mapping
KW  - Benchmark testing
KW  - Visual odometry
KW  - Time measurement
DO  - 10.1109/IROS.2018.8593419
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visual odometry and SLAM methods have a large variety of applications in domains such as augmented reality or robotics. Complementing vision sensors with inertial measurements tremendously improves tracking accuracy and robustness, and thus has spawned large interest in the development of visual-inertial (VI) odometry approaches. In this paper, we propose the TUM VI benchmark, a novel dataset with a diverse set of sequences in different scenes for evaluating VI odometry. It provides camera images with 1024×1024 resolution at 20 Hz, high dynamic range and photometric calibration. An IMU measures accelerations and angular velocities on 3 axes at 200 Hz, while the cameras and IMU sensors are time-synchronized in hardware. For trajectory evaluation, we also provide accurate pose ground truth from a motion capture system at high frequency (120 Hz) at the start and end of the sequences which we accurately aligned with the camera and IMU measurements. The full dataset with raw and calibrated data is publicly available. We also evaluate state-of-the-art VI odometry approaches on our dataset.
ER  - 

TY  - CONF
TI  - Scale-Robust Localization Using General Object Landmarks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1688
EP  - 1694
AU  - A. Holliday
AU  - G. Dudek
PY  - 2018
KW  - distance measurement
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - deep-learning-based object features
KW  - KITTI Odometry benchmark
KW  - outdoor images
KW  - scale-robust localization
KW  - visual localization
KW  - robotic mapping applications
KW  - object landmarks
KW  - SIFT point-features
KW  - Visualization
KW  - Measurement
KW  - Simultaneous localization and mapping
KW  - Robustness
KW  - Databases
KW  - Search problems
DO  - 10.1109/IROS.2018.8594011
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Visual localization under large changes in scale is an important capability in many robotic mapping applications, such as localizing at low altitudes in maps built at high altitudes, or performing loop closure over long distances. Existing approaches, however, are robust only up to about a 3× difference in scale between map and query images. We propose a novel combination of deep-learning-based object features and state-of-the-art SIFT point-features that yields improved robustness to scale change. This technique is training-free and class-agnostic, and in principle can be deployed in any environment out-of-the-box. We evaluate the proposed technique on the KITTI Odometry benchmark and on a novel dataset of outdoor images exhibiting changes in visual scale of 7× and greater, which we have released to the public. Our technique consistently outperforms localization using either SIFT features or the proposed object features alone, achieving both greater accuracy and much lower failure rates under large changes in scale.
ER  - 

TY  - CONF
TI  - Localization of an Acoustic Fish-Tag using the Time-of-Arrival Measurements: Preliminary results using eXogenous Kalman Filter
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1695
EP  - 1702
AU  - R. P. Jain
AU  - A. P. Aguiar
AU  - J. B. de Sousa
AU  - A. Zolich
AU  - T. A. Johansen
AU  - J. A. Alfredsen
AU  - E. Erstorp
AU  - J. Kuttenkeuler
PY  - 2018
KW  - Kalman filters
KW  - remotely operated vehicles
KW  - time-varying systems
KW  - time-of-arrival measurement
KW  - eXogenous Kalman filter
KW  - three stage estimation strategy
KW  - time-of-transmission
KW  - acoustic fish-tag localization
KW  - uniformly globally asymptotically stable
KW  - UGAS
KW  - unmanned surface vessels
KW  - Kalman Filter based estimator
KW  - quasilinear time-varying measurement model
KW  - pseudorange measurement equation
KW  - acoustic receiver
KW  - acoustic signal
KW  - source localization problem
KW  - Acoustics
KW  - Mathematical model
KW  - Receivers
KW  - Acoustic measurements
KW  - Kalman filters
KW  - Estimation
KW  - Measurement uncertainty
DO  - 10.1109/IROS.2018.8593659
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper addresses the source localization problem of an acoustic fish-tag using the Time-of-Arrival measurement of an acoustic signal, transmitted by the fish-tag. The Time-of-Arrival measurements denote the pseudo-range information between the acoustic receiver and the fish-tag, except that the Time-of-Transmission of the acoustic signal is unknown. Starting with the pseudo-range measurement equation, a globally valid quasi-linear time-varying measurement model is presented that is independent of the Time-of-Transmission of the acoustic signal. Using this measurement model, an Uniformly Globally Asymptotically Stable (UGAS), three stage estimation strategy (eXogenous Kalman Filter) is designed to estimate the position of an acoustic fish-tag and evaluated against a benchmark Extended Kalman Filter based estimator. The efficacy of the developed estimation method is demonstrated experimentally, in presence of intermittent observations using an array of receivers mounted on three Unmanned Surface Vessels (USVs).
ER  - 

TY  - CONF
TI  - Invariant smoothing on Lie Groups
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1703
EP  - 1710
AU  - P. Chauchat
AU  - A. Barrau
AU  - S. Bonnabel
PY  - 2018
KW  - estimation theory
KW  - Kalman filters
KW  - Lie groups
KW  - linearisation techniques
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - smoothing methods
KW  - linearizations
KW  - invariant Kalman filtering
KW  - robot localization
KW  - posteriori estimator
KW  - nonlinear smoothing methods
KW  - group-affine observation systems
KW  - Lie groups
KW  - invariant smoothing
KW  - Smoothing methods
KW  - Manifolds
KW  - Simultaneous localization and mapping
KW  - Kalman filters
KW  - Random variables
KW  - Estimation
KW  - Robot localization
DO  - 10.1109/IROS.2018.8594068
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we propose a (non-linear) smoothing algorithm for group-affine observation systems, a recently introduced class of estimation problems on Lie groups that bear a particular structure. As most non-linear smoothing methods, the proposed algorithm is based on a maximum a posteriori estimator, determined by optimization. But owing to the specific properties of the considered class of problems, the involved linearizations are proved to have a form of independence with respect to the current estimates, leveraged to avoid (partially or sometimes totally) the need to relinearize. The method is validated on a robot localization example, both in simulations and on real experimental data.
ER  - 

TY  - CONF
TI  - Online Self-body Image Acquisition Considering Changes in Muscle Routes Caused by Softness of Body Tissue for Tendon-driven Musculoskeletal Humanoids
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1711
EP  - 1717
AU  - K. Kawaharazuka
AU  - S. Makino
AU  - M. Kawamura
AU  - A. Fujii
AU  - Y. Asano
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - biomechanics
KW  - bone
KW  - data acquisition
KW  - humanoid robots
KW  - muscle
KW  - robot vision
KW  - body tissue
KW  - joint-muscle model
KW  - muscle-route change model
KW  - geometric model
KW  - tendon-driven musculoskeletal humanoid Kengoro
KW  - muscle routes
KW  - tendon-driven musculoskeletal humanoids
KW  - flexible spine
KW  - body complexity
KW  - muscle lengths
KW  - muscle route changes
KW  - internal muscle tension
KW  - online self-body image acquisition
KW  - multiple degrees of freedom
KW  - controllability
KW  - neural network
KW  - Muscles
KW  - Robot sensing systems
KW  - Humanoid robots
KW  - Solid modeling
KW  - Training
DO  - 10.1109/IROS.2018.8593428
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Tendon-driven musculoskeletal humanoids have many benefits in terms of the flexible spine, multiple degrees of freedom, and variable stiffness. At the same time, because of its body complexity, there are problems in controllability. First, due to the large difference between the actual robot and its geometric model, it cannot move as intended and large internal muscle tension may emerge. Second, movements which do not appear as changes in muscle lengths may emerge, because of the muscle route changes caused by softness of body tissue. To solve these problems, we construct two models: ideal joint-muscle model and muscle-route change model, using a neural network. We initialize these models by a man-made geometric model and update them online using the sensor information of the actual robot. We validate that the tendon-driven musculoskeletal humanoid Kengoro is able to obtain a correct self-body image through several experiments.
ER  - 

TY  - CONF
TI  - A Combined RGB and Depth Descriptor for SLAM with Humanoids
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1718
EP  - 1724
AU  - R. Sheikh
AU  - S. OBwald
AU  - M. Bennewitz
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - humanoid robots
KW  - image colour analysis
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - feature tracking
KW  - codebooks
KW  - reproducibility
KW  - humanoid robots
KW  - visual simultaneous localization
KW  - depth descriptor
KW  - ORB-SLAM
KW  - visual SLAM system
KW  - track features
KW  - DLab
KW  - RGB-D camera
KW  - Nao humanoid
KW  - binary descriptor
KW  - FAB-MAP
KW  - place recognition module
KW  - Simultaneous localization and mapping
KW  - Image color analysis
KW  - Cameras
KW  - Three-dimensional displays
KW  - Humanoid robots
KW  - Visualization
DO  - 10.1109/IROS.2018.8593768
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a visual simultaneous localization and mapping (SLAM) system for humanoid robots. We introduce a new binary descriptor called DLab that exploits the combined information of color, depth, and intensity to achieve robustness with respect to uniqueness, reproducibility, and stability. We use DLab within ORB-SLAM, where we replaced the place recognition module with a modification of FAB-MAP that works with newly built codebooks using our binary descriptor. In experiments carried out in simulation and with a real Nao humanoid equipped with an RGB-D camera, we show that DLab has a superior performance in comparison to other descriptors. The application to feature tracking and place recognition reveal that the new descriptor is able to reliably track features even in sequences with seriously blurred images and that it has a higher percentage of correctly identified similar images. As a result, our new visual SLAM system has a lower absolute trajectory error in comparison to ORB-SLAM and is able to accurately track the robot's trajectory.
ER  - 

TY  - CONF
TI  - Neural-Network-Controlled Spring Mass Template for Humanoid Running
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1725
EP  - 1731
AU  - S. Xin
AU  - B. Delhaisse
AU  - Y. You
AU  - C. Zhou
AU  - M. Shahbazi
AU  - N. Tsagarakis
PY  - 2018
KW  - humanoid robots
KW  - interpolation
KW  - legged locomotion
KW  - neurocontrollers
KW  - pendulums
KW  - robot dynamics
KW  - springs (mechanical)
KW  - table lookup
KW  - lookup tables
KW  - data-driven approach
KW  - deep neural network
KW  - simulation data
KW  - SLIP model
KW  - humanoid robot
KW  - whole-body model
KW  - QP-based inverse dynamics controller
KW  - WALK-MAN robot
KW  - robust running motions
KW  - neural-network-controlled spring mass template
KW  - humanoid running
KW  - legged robots
KW  - model-based approaches
KW  - whole-body robot
KW  - controlled SLIP-like behaviors
KW  - online incompatibility
KW  - interpolations
KW  - spring-loaded inverted pendulum model
KW  - Legged locomotion
KW  - Neural networks
KW  - Data models
KW  - Training
KW  - Biological system modeling
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593403
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - To generate dynamic motions such as hopping and running on legged robots, model-based approaches are usually used to embed the well studied spring-loaded inverted pendulum (SLIP) model into the whole-body robot. In producing controlled SLIP-like behaviors, existing methods either suffer from online incompatibility or resort to classical interpolations based on lookup tables. Alternatively, this paper presents the application of a data-driven approach which obviates the need for solving the inverse of the running return map online. Specifically, a deep neural network is trained offline with a large amount of simulation data based on the SLIP model to learn its dynamics. The trained network is applied online to generate reference foot placements for the humanoid robot. The references are then mapped to the whole-body model through a QP-based inverse dynamics controller. Simulation experiments on the WALK-MAN robot are conducted to evaluate the effectiveness of the proposed approach in generating bio-inspired and robust running motions.
ER  - 

TY  - CONF
TI  - Quadruped Locomotion Control Based on Two Bipeds Jointly Carrying Model
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1732
EP  - 1738
AU  - G. Zhang
AU  - S. Ma
AU  - F. Liang
AU  - Y. Li
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - quadruped locomotion control
KW  - novel gait planning
KW  - control framework
KW  - quadruped robot
KW  - rear ends
KW  - joint torques
KW  - support legs
KW  - bipedal sub-robots
KW  - quadruped body forces
KW  - bipedal torso forces
KW  - operating modes
KW  - virtual forces
KW  - support leg torques
KW  - gait generators
KW  - gait parameters
KW  - hind legs
KW  - Legged locomotion
KW  - Robot kinematics
KW  - Torso
KW  - Radio frequency
KW  - Hip
KW  - Mathematical model
DO  - 10.1109/IROS.2018.8593413
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - A novel gait planning and control framework was developed for quadruped locomotion of a robot. It modeled the quadruped robot as two bipeds carrying the body from the front and rear ends. We first mapped the relationship between the joint torques of support legs and the torso forces of the bipedal sub-robots. Then the equations describing the relationship between the quadruped body forces and the bipedal torso forces under various operating modes of the robot were deduced and solved. Virtual forces were generated on the quadruped body to manipulate its velocity and orientation. Then these virtual forces were distributed to the front and hind sub-robots to generate support leg torques. The state machines and gait generators for the two bipedal sub-robots were designed individually, resulting in the decoupling of the gait parameters in the front legs and hind legs. The effectiveness of the controller was validated through dynamic simulations.
ER  - 

TY  - CONF
TI  - An Investigation of 2nd-Order Fixed Point SLIP Behavior
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1739
EP  - 1744
AU  - I. Kontolatis
AU  - E. Papadopoulos
PY  - 2018
KW  - approximation theory
KW  - collision avoidance
KW  - friction
KW  - legged locomotion
KW  - nonlinear control systems
KW  - pendulums
KW  - 1st-order fixed points
KW  - 2nd-order fixed points
KW  - 2nd-order fixed point SLIP behavior
KW  - analytical stance phase approximation
KW  - friction cone constraints
KW  - obstacle avoidance
KW  - SLIP model behavior analysis
KW  - nondimensional leg stiffness
KW  - numerical return map search scheme
KW  - nondimensional SLIP model
KW  - Legged locomotion
KW  - Springs
KW  - Friction
KW  - Mathematical model
KW  - Numerical models
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594375
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces alternative behaviors described by the SLIP model when it is subject to a range of initial conditions. A non-dimensional SLIP model and a numerical return map search scheme are used to determine fixed points as a function of non-dimensional leg stiffness and vertical displacement under friction constraints. A SLIP model behavior analysis is performed, using an analytical stance phase approximation, by diverging from the fixed points, i.e. by increasing/decreasing initial horizontal velocity, and/or touchdown angle. The results show that beyond the regular fixed points, the SLIP model performs an alternative, stable behavior that repeats itself every two cycles of motion. We call these 2nd-order fixed points and the regular ones 1st-order fixed points. A numerical simulation scheme was developed to investigate 2nd-order fixed points for a wide range of horizontal velocities and touchdown angles. Results show that 2nd-order fixed points respecting the friction cone constraints exist that can lead to a number of different behaviors such as high jumps, obstacle avoidance of different heights, or backward motion.
ER  - 

TY  - CONF
TI  - Cost of Transport Estimation for Legged Robot Based on Terrain Features Inference from Aerial Scan
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1745
EP  - 1750
AU  - M. Prágr
AU  - P. Čížek
AU  - J. Faigl
PY  - 2018
KW  - feature extraction
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - robot vision
KW  - terrain mapping
KW  - multilegged robot
KW  - crawled terrain
KW  - hexapod robot
KW  - legged robot
KW  - terrain features inference
KW  - aerial scan
KW  - robot locomotion
KW  - incremental learning
KW  - geometrical data
KW  - visual data
KW  - terrain learning
KW  - extraterrestrial missions
KW  - robot deployment
KW  - robot motion planning
KW  - cost of transport estimation
KW  - terrain descriptors
KW  - mechanical properties
KW  - Robots
KW  - Feature extraction
KW  - Image color analysis
KW  - Estimation
KW  - Unmanned aerial vehicles
KW  - Three-dimensional displays
KW  - Visualization
DO  - 10.1109/IROS.2018.8593374
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The effectiveness of the robot locomotion can be measured using the cost of transport (CoT) which represents the amount of energy that is needed for traversing from one place to another. Terrains excerpt different mechanical properties when crawled by a multi-legged robot, and thus different values of the CoT. It is therefore desirable to estimate the CoT in advance and plan the robot motion accordingly. However, the CoT might not be known prior the robot deployment, e.g., in extraterrestrial missions; hence, a robot has to learn different terrains as it crawls through the environment incrementally. In this work, we focus on estimating the CoT from visual and geometrical data of the crawled terrain. A thorough analysis of different terrain descriptors within the context of incremental learning is presented to select the best performing approach. We report on the achieved results and experimental verification of the selected approaches with a real hexapod robot crawling over six different terrains.
ER  - 

TY  - CONF
TI  - Determining Optimal Gait Parameters for a Statically Stable Walking Human Assistive Quadruped Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1751
EP  - 1756
AU  - E. W. McClain
AU  - S. Meek
PY  - 2018
KW  - legged locomotion
KW  - optimal control
KW  - optimisation
KW  - robot dynamics
KW  - stability
KW  - optimal gait parameters
KW  - statically stable walking human assistive quadruped robot
KW  - optimal statically stable gait
KW  - quadruped robot walking
KW  - energy efficient gait
KW  - energy efficient quadruped gait
KW  - cost function
KW  - energy term
KW  - stability term
KW  - quasistatic analysis
KW  - human assistive device
KW  - optimization
KW  - Legged locomotion
KW  - Foot
KW  - Cost function
KW  - Stability analysis
KW  - Gravity
DO  - 10.1109/IROS.2018.8593979
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we propose a method to determine an optimal statically stable gait for a quadruped robot walking in the presence of an expected disturbance. There exists a tradeoff between a stable gait and an energy efficient gait. Our goal is to determine an energy efficient quadruped gait that will maintain stability while a human uses the device to stabilize themselves while walking. In order to determine an optimal gait, we present a cost function consisting of an energy term and a stability term. A method of evaluating the cost function using dynamics and quasi-static analysis is demonstrated. The optimization is implemented for a human assistive device currently being designed and the results are verified in simulation.
ER  - 

TY  - CONF
TI  - An Adaptive Landing Gear for Extending the Operational Range of Helicopters
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1757
EP  - 1763
AU  - B. Stolz
AU  - T. Brödermann
AU  - E. Castiello
AU  - G. Englberger
AU  - D. Erne
AU  - J. Gasser
AU  - E. Hayoz
AU  - S. Müller
AU  - L. Muhlebach
AU  - T. Löw
AU  - D. Scheuer
AU  - L. Vandeventer
AU  - M. Bjelonic
AU  - F. Günther
AU  - H. Kolvenbach
AU  - M. Hopflinger
AU  - M. Hutter
PY  - 2018
KW  - actuators
KW  - adaptive control
KW  - aircraft landing guidance
KW  - autonomous aerial vehicles
KW  - force control
KW  - gears
KW  - helicopters
KW  - legged locomotion
KW  - shock absorbers
KW  - springs (mechanical)
KW  - vibration control
KW  - off-field landing
KW  - skid based helicopter landing gears
KW  - mountain rescue
KW  - economic practicability
KW  - innovative actuation
KW  - brake
KW  - motor
KW  - spring-damper system
KW  - force control
KW  - tipping
KW  - aircraft
KW  - unmanned helicopter
KW  - landing phase
KW  - optimal load distribution
KW  - leg
KW  - wheel based helicopter landing gears
KW  - adaptive landing gear
KW  - Legged locomotion
KW  - Gears
KW  - Helicopters
KW  - Foot
KW  - Brakes
KW  - Rotors
KW  - Damping
DO  - 10.1109/IROS.2018.8594062
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Conventional skid or wheel based helicopter landing gears severely limit off-field landing possibilities, which are crucial when operating in scenarios such as mountain rescue. In this context, slopes beyond 8° and small obstacles can already pose a substantial hazard. An adaptive landing gear is proposed to overcome these limitations. It consists of four legs with one degree of freedom each. The total weight was minimized to demonstrate economic practicability. This was achieved by an innovative actuation, composed of a parallel arrangement of motor and brake, which relieves the motor from large impact loads during hard landings. The loads are alleviated by a spring-damper system acting in series to the actuation. Each leg is individually force controlled for optimal load distribution on compliant ground and to avoid tipping. The operation of the legs is fully autonomous during the landing phase. A prototype was designed and successfully tested on an unmanned helicopter with a maximum take-off weight of 78 kg. Finally, the implementation of the landing gear concept on aircraft of various scales was discussed.
ER  - 

TY  - CONF
TI  - Designing Concentric Tube Manipulators for Stability Using Topology Optimization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1764
EP  - 1769
AU  - K. A. Xin Jue Luo
AU  - T. Looi
AU  - S. Sabetian
AU  - J. Drake
PY  - 2018
KW  - bending
KW  - finite element analysis
KW  - manipulator dynamics
KW  - medical robotics
KW  - pipes
KW  - surgery
KW  - torsion
KW  - snapping problem
KW  - concentric tube robotic system
KW  - topology optimization
KW  - concentric tube continuum robots
KW  - surgical environments
KW  - BTSR
KW  - tube design
KW  - concentric tube manipulators
KW  - surgical environment
KW  - bending to torsional stiffness ratio
KW  - finite element analysis
KW  - Electron tubes
KW  - Optimization
KW  - Topology
KW  - Stress
KW  - Manipulators
KW  - Load modeling
DO  - 10.1109/IROS.2018.8593806
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - One of the major problems facing the development and road to practical usage of concentric tube continuum robots in surgical environments is that of instability. This issue, also known as the snapping problem, is caused by a tube having a high bending to torsional stiffness ratio (BTSR). Past efforts have shown that by cutting patterns on the tubes, this problem can be avoided. This paper seeks to redesign the topology of the tubes so that BTSR is decreased and the snapping problem is resolved in a particular tube set. The generated designs are then tested through finite element analysis as well as experimental testing to demonstrate the elimination of the snapping problem. Using this novel tube design on a concentric tube robotic system can increase its stable workspace because it allows the usage of greater tube curvatures and/or curve lengths.
ER  - 

TY  - CONF
TI  - Haptic Feedback and Dynamic Active Constraints for Robot-Assisted Endovascular Catheterization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1770
EP  - 1775
AU  - G. Dagnino
AU  - J. Liu
AU  - M. E. M. K. Abdelaziz
AU  - W. Chi
AU  - C. Riga
AU  - G. -. Yang
PY  - 2018
KW  - blood vessels
KW  - catheters
KW  - ergonomics
KW  - force feedback
KW  - haptic interfaces
KW  - manipulators
KW  - medical robotics
KW  - phantoms
KW  - surgery
KW  - robot-assisted endovascular catheterization
KW  - computer assistance
KW  - reduced radiation doses
KW  - tortuous anatomy
KW  - natural bedside manipulation skills
KW  - dexterity
KW  - clinical usability
KW  - robotic platform
KW  - ergonomic master-slave system
KW  - navigation system
KW  - integrated vision-based haptic feedback
KW  - natural bedside skills
KW  - dynamic motion tracking
KW  - catheterization tasks
KW  - phantom
KW  - mean force
KW  - maximum force
KW  - force feedback
KW  - vision-based dynamic active constraints
KW  - ergonomic robotic catheter manipulator
KW  - robot-assisted endovascular procedures
KW  - CathBot
KW  - vessel walls
KW  - vascular surgeon
KW  - catheter tip
KW  - Catheters
KW  - Surgery
KW  - Navigation
KW  - Force feedback
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593628
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic and computer assistance can bring significant benefits to endovascular procedures in terms of precision and stability, reduced radiation doses, improved comfort and access to difficult and tortuous anatomy. However, the design of current commercially available platforms tends to alter the natural bedside manipulation skills of the operator, so that the manually acquired experience and dexterity are not well utilized. Furthermore, most of these systems lack of haptic feedback, preventing their acceptance and limiting the clinical usability. In this paper a new robotic platform for endovascular catheterization, the CathBot, is presented. It is an ergonomic master-slave system with navigation system and integrated vision-based haptic feedback, designed to maintain the natural bedside skills of the vascular surgeon. Unlike previous work reported in literature, dynamic motion tracking of both the vessel walls the catheter tip is incorporated to create dynamic active constraints. The system was evaluated through a combined quantitative and qualitative user study simulating catheterization tasks on a phantom. Forces exerted on the phantom were measured. The results showed a 70% decrease in mean force and 61% decrease in maximum force when force feedback is provided. This research provides the first integration of vision-based dynamic active constraints within an ergonomic robotic catheter manipulator. The technological advances presented here, demonstrates that vision-based haptic feedback can improve the effectiveness, precision, and safety of robot-assisted endovascular procedures.
ER  - 

TY  - CONF
TI  - Intuitive Gaze-Control of a Robotized Flexible Endoscope
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1776
EP  - 1782
AU  - T. J. C. O. Vrielink
AU  - J. G. Puyal
AU  - A. Kogkas
AU  - A. Darzi
AU  - G. Mylonas
PY  - 2018
KW  - endoscopes
KW  - manipulators
KW  - medical robotics
KW  - visual servoing
KW  - intuitive gaze-control
KW  - robotized flexible endoscope
KW  - flexible endoscopy
KW  - intuitive platform
KW  - ergonomic platform
KW  - standard endoscope
KW  - gaze control system
KW  - eye-tracking
KW  - hands-free manipulation
KW  - system characteristics
KW  - robotized system
KW  - manually controlled endoscope
KW  - gaze controlled endoscope
KW  - lower task load
KW  - hands-free gaze control
KW  - visual servoing
KW  - Endoscopes
KW  - Robots
KW  - Optical imaging
KW  - Task analysis
KW  - Gears
KW  - Control systems
KW  - Cameras
DO  - 10.1109/IROS.2018.8594426
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Flexible endoscopy is a routinely performed procedure that has predominantly remained unchanged for decades despite its many challenges. This paper introduces a novel, more intuitive and ergonomic platform that can be used with any flexible endoscope, allowing easier navigation and manipulation. A standard endoscope is robotized and a gaze control system based on eye-tracking is developed and implemented, allowing hands-free manipulation. The system characteristics and step response has been evaluated using visual servoing. Further, the robotized system has been compared with a manually controlled endoscope during a user study. The users (n=11) showed a preference for the gaze controlled endoscope and a lower task load when the task was performed with the gaze control. In addition, gaze control was related to a higher success rate and a lower time to perform the task. The results presented validate the system's technical performance and demonstrate the intuitiveness of hands-free gaze control in flexible endoscopy.
ER  - 

TY  - CONF
TI  - A Soft Robot to Navigate the Lumens of the Body Using Undulatory Locomotion Generated by a Rotating Magnetic Dipole Field
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1783
EP  - 1788
AU  - L. N. Pham
AU  - J. J. Abbott
PY  - 2018
KW  - blood vessels
KW  - magnetic actuators
KW  - magnetic fields
KW  - magnetic sensors
KW  - medical robotics
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - numerical analysis
KW  - path planning
KW  - permanent magnets
KW  - rotating magnetic dipole field
KW  - soft-robotic actuation concept
KW  - mesoscale medical robot
KW  - natural lumens
KW  - blood vessels
KW  - embedded permanent magnets
KW  - magnetic polarity
KW  - rotating dipole magnetic field
KW  - traveling-wave undulatory motion
KW  - soft-actuation technology
KW  - nonuniform dipole fields
KW  - undulatory locomotion
KW  - uniform dipole fields
KW  - diagnostic context
KW  - therapeutic context
KW  - numerical simulation
KW  - Coils
KW  - Magnetic resonance imaging
KW  - Magnetic separation
KW  - Soft robotics
KW  - Permanent magnets
KW  - Magnetic moments
DO  - 10.1109/IROS.2018.8594247
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we describe a soft-robotic actuation concept to enable a mesoscale medical robot to navigate the natural lumens of the body, such as blood vessels and intestines. The concept comprises a simple soft robot with two embedded permanent magnets with alternating magnetic polarity, and a rotating (nonuniform) dipole magnetic field that is swept over the robot, resulting in a traveling-wave undulatory motion that propels the robot forward and backward. This soft-actuation technology can be fabricated in a wide range of sizes due to its simplicity, and has the potential to be applied in a variety of diagnostic and therapeutic contexts. We conduct experiments and numerical simulations to verify the movement of the soft robot. Then, we confirm the benefits of using nonuniform dipole fields over using uniform fields, as well as the benefits of alternating the polarity of the magnets embedded in the device.
ER  - 

TY  - CONF
TI  - A Robot System for Automated Wound Filling with Jetted Materials
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1789
EP  - 1794
AU  - B. H. Jafari
AU  - L. Namhyung
AU  - R. Thompson
AU  - J. Schellhorn
AU  - B. Antohe
AU  - N. Gans
PY  - 2018
KW  - computer vision
KW  - control engineering computing
KW  - diseases
KW  - medical robotics
KW  - nozzles
KW  - path planning
KW  - patient treatment
KW  - proteins
KW  - skin
KW  - surgery
KW  - tissue engineering
KW  - wounds
KW  - robot system
KW  - automated wound filling
KW  - jetted materials
KW  - skin surface wounds
KW  - chronic illness
KW  - tissue engineering
KW  - 3D machine vision system
KW  - skin wound
KW  - 3D point set
KW  - path planning algorithm
KW  - robot manipulator
KW  - ink-jet nozzle
KW  - biomaterials
KW  - cell growth promoters
KW  - Wounds
KW  - Three-dimensional displays
KW  - Robot kinematics
KW  - Cameras
KW  - Machine vision
KW  - Manuals
DO  - 10.1109/IROS.2018.8594252
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Skin surface wounds due to burns, surgeries and chronic illness affect millions of people worldwide. Tissue engineering has become an increasingly popular treatment, but it is a highly manual process. Increasing the automation in tissue engineering could increase the rate of treatment for patients and improve outcomes. We present an initial investigation into an automated in-situ treatment. In our proposed method, a 3D machine vision system detects a skin wound to be treated and then determines the 3D point set corresponding to the wound. The 3D point set is then passed to path planning algorithm for a robot manipulator to move an ink-jet nozzle over the wound and fill the cavity with quick-curing/gelling fluids such collagen and other biomaterials and cell growth promoters. This paper details initial results and experimental validation of each of the proposed steps.
ER  - 

TY  - CONF
TI  - State Estimation for MRI-Actuated Cathers via Catadioptric Stereo Camera
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1795
EP  - 1800
AU  - T. Greigarn
AU  - R. Jackson
AU  - M. C. Çavuşoğlu
PY  - 2018
KW  - biomedical MRI
KW  - cameras
KW  - catheters
KW  - image segmentation
KW  - medical robotics
KW  - particle filtering (numerical methods)
KW  - particle filter
KW  - catadioptric camera system
KW  - tracking algorithm
KW  - MRI-actuated cathers
KW  - catadioptric stereo camera
KW  - MRI-actuated catheter
KW  - novel robotic catheter system
KW  - MR tracking system
KW  - alternative catheter tracking method
KW  - Catheters
KW  - Cameras
KW  - Actuators
KW  - Tracking
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Mirrors
DO  - 10.1109/IROS.2018.8594153
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - An MRI-actuated catheter is a novel robotic catheter system that utilizes the MR scanner for both remote steering and catheter tracking. In order to develop the mathematical model and the planning algorithm of the catheter in parallel to the MR tracking system, an alternative catheter tracking method is needed. This paper presents a catheter tracking algorithm based on the particle filter and the catadioptric camera system. The motion model of the particle filter is based on the quasi-static kinematics of the catheter. The measurement model calculates the weights of the particles according to the normalized crosscorrelation of the segmented image from camera and a virtual rendering of the catheter. The efficacy of the tracking algorithm is demonstrates via experimental results.
ER  - 

TY  - CONF
TI  - Unsupervised Odometry and Depth Learning for Endoscopic Capsule Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1801
EP  - 1807
AU  - M. Turan
AU  - E. P. Ornek
AU  - N. Ibrahimli
AU  - C. Giracoglu
AU  - Y. Almalioglu
AU  - M. F. Yanik
AU  - M. Sitti
PY  - 2018
KW  - biomedical optical imaging
KW  - diseases
KW  - endoscopes
KW  - image sequences
KW  - medical image processing
KW  - medical robotics
KW  - motion estimation
KW  - unsupervised learning
KW  - single-view depth estimation network
KW  - passive capsule endoscopes
KW  - minimally invasive diagnostic technology
KW  - realtime odometry
KW  - monocular endoscopic capsule robots
KW  - multiview pose estimation
KW  - endoscopic capsule robots
KW  - disease detection
KW  - drug delivery
KW  - gastrointestinal tract
KW  - reprojection minimization
KW  - unsupervised odometry
KW  - depth learning
KW  - biopsy-like operations
KW  - ex-vivo porcine stomach datasets
KW  - motion estimation
KW  - Cameras
KW  - Robots
KW  - Endoscopes
KW  - Reliability
KW  - Sensors
KW  - Pose estimation
DO  - 10.1109/IROS.2018.8593623
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In the last decade, many medical companies and research groups have tried to convert passive capsule endoscopes as an emerging and minimally invasive diagnostic technology into actively steerable endoscopic capsule robots which will provide more intuitive disease detection, targeted drug delivery and biopsy-like operations in the gastrointestinal(GI) tract. In this study, we introduce a fully unsupervised, realtime odometry and depth learner for monocular endoscopic capsule robots. We establish the supervision by warping view sequences and assigning the re-projection minimization to the loss function, which we adopt in multi-view pose estimation and single-view depth estimation network. Detailed quantitative and qualitative analyses of the proposed framework performed on non-rigidly deformable ex-vivo porcine stomach datasets proves the effectiveness of the method in terms of motion estimation and depth recovery.
ER  - 

TY  - CONF
TI  - Bayesian-inferred Flexible Path Generation in Human-Robot Collaborative Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1816
EP  - 1822
AU  - W. Bentz
AU  - D. Panagou
PY  - 2018
KW  - Bayes methods
KW  - computational geometry
KW  - human-robot interaction
KW  - inference mechanisms
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - position control
KW  - probability
KW  - stochastic processes
KW  - flexible path human-robot collaborative network
KW  - weighted Euclidean distance
KW  - potentially optimal tasks
KW  - single task
KW  - optimal trajectory
KW  - task selection
KW  - human intent
KW  - Bayesian inference
KW  - human-robot collaborative networks
KW  - Bayesian-inferred flexible path generation
KW  - highly impulsive humans
KW  - Task analysis
KW  - Trajectory
KW  - Robot kinematics
KW  - Bayes methods
KW  - Collaboration
KW  - Cost function
DO  - 10.1109/IROS.2018.8593611
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a novel method for generating the trajectory of a robot assisting a human in servicing a set of tasks embedded in a convex 2-D domain. This method makes use of Bayesian inference to predict human intent in task selection. Rather than following optimal trajectory towards a single task, the robot computes a set of potentially optimal tasks each weighted by the human's posterior probability and superimposes them into a cost function that is designed to minimize the weighted Euclidean distance relative to set. The effect is a flexible path human-robot collaborative network that is shown in simulation to complete all tasks in a given domain in less time than existing methods for a certain class of highly impulsive humans, i.e., humans that tend to randomly switch tasks at times generated by a Poisson counting process. The algorithm is also illustrated through an experimental demonstration.
ER  - 

TY  - CONF
TI  - Head-Mounted Augmented Reality for Explainable Robotic Wheelchair Assistance
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1823
EP  - 1829
AU  - M. Zolotas
AU  - J. Elsdon
AU  - Y. Demiris
PY  - 2018
KW  - augmented reality
KW  - handicapped aids
KW  - human-robot interaction
KW  - medical robotics
KW  - mobile robots
KW  - wheelchairs
KW  - robotic wheelchair assistance
KW  - visual feedback
KW  - wheelchair navigation
KW  - head-mounted aid
KW  - Microsoft Hololens
KW  - mental model
KW  - severely disabled individuals
KW  - robotic wheelchairs
KW  - head-mounted augmented reality
KW  - augmented information acquisition
KW  - assistive navigation
KW  - immersive wheelchair training regime
KW  - learning curve
KW  - Wheelchairs
KW  - Mobile robots
KW  - Navigation
KW  - Visualization
KW  - Collision avoidance
KW  - Trajectory
DO  - 10.1109/IROS.2018.8594002
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robotic wheelchairs with built-in assistive features, such as shared control, are an emerging means of providing independent mobility to severely disabled individuals. However, patients often struggle to build a mental model of their wheelchair's behaviour under different environmental conditions. Motivated by the desire to help users bridge this gap in perception, we propose a novel augmented reality system using a Microsoft Hololens as a head-mounted aid for wheelchair navigation. The system displays visual feedback to the wearer as a way of explaining the underlying dynamics of the wheelchair's shared controller and its predicted future states. To investigate the influence of different interface design options, a pilot study was also conducted. We evaluated the acceptance rate and learning curve of an immersive wheelchair training regime, revealing preliminary insights into the potential beneficial and adverse nature of different augmented reality cues for assistive navigation. In particular, we demonstrate that care should be taken in the presentation of information, with effort-reducing cues for augmented information acquisition (for example, a rear-view display) being the most appreciated.
ER  - 

TY  - CONF
TI  - Robot Programming Through Augmented Trajectories in Augmented Reality
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1838
EP  - 1844
AU  - C. P. Quintero
AU  - S. Li
AU  - M. K. Pan
AU  - W. P. Chan
AU  - H. F. Machiel Van der Loos
AU  - E. Croft
PY  - 2018
KW  - augmented reality
KW  - helmet mounted displays
KW  - human-robot interaction
KW  - industrial robots
KW  - motion control
KW  - robot programming
KW  - teaching
KW  - augmented trajectories
KW  - augmented reality
KW  - mixed reality head-mounted display
KW  - robotic interface
KW  - robot programming task
KW  - robot motion
KW  - AR-robot teaching interface
KW  - kinesthetic teaching interface
KW  - 7-DOF robot arm
KW  - Microsoft Hololens
KW  - carbon-fiber-reinforcement-polymer vacuum bagging process
KW  - AR manufacturing paradigm
KW  - Task analysis
KW  - Trajectory
KW  - Service robots
KW  - Visualization
KW  - End effectors
DO  - 10.1109/IROS.2018.8593700
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a future-focused approach for robot programming based on augmented trajectories. Using a mixed reality head-mounted display (Microsoft Hololens) and a 7-DOF robot arm, we designed an augmented reality (AR) robotic interface with four interactive functions to ease the robot programming task: 1) Trajectory specification. 2) Virtual previews of robot motion. 3) Visualization of robot parameters. 4) Online reprogramming during simulation and execution. We validate our AR-robot teaching interface by comparing it with a kinesthetic teaching interface in two different scenarios as part of a pilot study: creation of contact surface path and free space path. Furthermore, we present an industrial case study that illustrates our AR manufacturing paradigm by interacting with a 7-DOF robot arm to reduce wrinkles during the pleating step of the carbon-fiber-reinforcement-polymer vacuum bagging process in a simulated scenario.
ER  - 

TY  - CONF
TI  - The HRC Model Set for Human-Robot Collaboration Research
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1845
EP  - 1852
AU  - S. Zeylikman
AU  - S. Widder
AU  - A. Roncone
AU  - O. Mangin
AU  - B. Scassellati
PY  - 2018
KW  - human-robot interaction
KW  - HRC model set
KW  - human-robot collaboration research
KW  - human-robot collaboration experiments
KW  - HRC experiments
KW  - Robots
KW  - Task analysis
KW  - Collaboration
KW  - Robotic assembly
KW  - Complexity theory
KW  - Standards
DO  - 10.1109/IROS.2018.8593858
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we present a model set for designing human-robot collaboration (HRC) experiments. It targets a common scenario in HRC, which is the collaborative assembly of furniture, and it consists of a combination of standard components and custom designs. With this work, we aim at reducing the amount of work required to set up and reproduce HRC experiments, and we provide a unified framework to facilitate the comparison and integration of contributions to the field. The model set is designed to be modular, extendable, and easy to distribute. Importantly, it covers the majority of relevant research in HRC, and it allows tuning of a number of experimental variables that are particularly valuable to the field. Additionally, we provide a set of software libraries for perception, control and interaction, with the goal of encouraging other researchers to proactively contribute to our work.
ER  - 

TY  - CONF
TI  - Band of Brothers and Bolts: Caring About Your Robot Teammate
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1853
EP  - 1858
AU  - J. Wen
AU  - A. Stewart
AU  - M. Billinghurst
AU  - C. Tossell
PY  - 2018
KW  - computer games
KW  - human-robot interaction
KW  - consequential behavioral pattern
KW  - empathic response
KW  - robot teammate
KW  - robot companion
KW  - Robots
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Computer bugs
KW  - Time measurement
KW  - Bonding
DO  - 10.1109/IROS.2018.8594324
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - It has been observed that a robot shown as suffering is enough to cause an empathic response from a person. Whether the response is a fleeting reaction with no consequences or a meaningful perspective change with associated behavior modifications is not clear. Existing work has been limited to measurements made at the end of empathy inducing experimental trials rather measurements made over time to capture consequential behavioral pattern. We report on preliminary results collected from a study that attempts to measure how the actions of a participant may be altered by empathy for a robot companion. Our findings suggest that induced empathy can in fact have a significant impact on a person's behavior to the extent that the ability to fulfill a mission may be affected.
ER  - 

TY  - CONF
TI  - DNN-based Speech Recognition System dealing with Motor State as Auxiliary Information of DNN for Head Shaking Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1859
EP  - 1863
AU  - M. Lee
AU  - J. Chang
PY  - 2018
KW  - acoustic signal processing
KW  - neural nets
KW  - robots
KW  - signal denoising
KW  - speech processing
KW  - speech recognition
KW  - motor state
KW  - head shaking robot
KW  - deep neural network
KW  - acoustic modeling
KW  - speech recognition algorithm
KW  - feature mapping model
KW  - acoustic model
KW  - phoneme recognition
KW  - feature enhancement model
KW  - speech recognition system
KW  - auxiliary information
KW  - DNN
KW  - background noise suppression
KW  - Robots
KW  - Speech recognition
KW  - Speech enhancement
KW  - Noise measurement
KW  - Feature extraction
KW  - Mel frequency cepstral coefficient
DO  - 10.1109/IROS.2018.8593396
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a deep neural network (DNN) based integrated background noise suppression and acoustic modeling for speech recognition proposed in which on/off state of the motor for the head shaking robot is employed as the relevant auxiliary information of the DNN input. Since the motor sound being generated when the robot is moving or shaking its head severely degrades the performance of the speech recognition accuracy, we propose to use the motor on/off state as additional information when designing the DNN-based recognition system. Our speech recognition algorithm consists of two parts including the feature mapping model for feature enhancement and the acoustic model for phoneme recognition. As for the feature mapping, the stacked DNN is designed for the precise feature enhancement such that the lower DNN and upper DNN are trained separately and combined after which the motor state is plugged into both the lower DNN and upper DNN in addition to the input noisy speech. Then, the acoustic model is trained upon the feature enhancement model in which the motor state is again used as the augmented feature. The proposed technique to suppress the acoustic and motor noises was evaluated in term of the phoneme error rate (PER) and showed a significant improvement over the conventional system.
ER  - 

TY  - CONF
TI  - The Power of a Hand-shake in Human-Robot Interactions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1864
EP  - 1869
AU  - J. Avelino
AU  - F. Correia
AU  - J. Catarino
AU  - P. Ribeiro
AU  - P. Moreno
AU  - A. Bernardino
AU  - A. Paiva
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - nonhandshake conditions
KW  - human-robot interactions
KW  - human emotional bond
KW  - human willingness
KW  - social robot Vizzy
KW  - handshake conditions
KW  - Task analysis
KW  - Navigation
KW  - Haptic interfaces
KW  - Human-robot interaction
KW  - Tactile sensors
DO  - 10.1109/IROS.2018.8593980
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we study the influence of a handshake in the human emotional bond to a robot. In particular, we evaluate the human willingness to help a robot whether the robot first introduces itself to the human with or without a handshake. In the tested paradigm the robot and the human have to perform a joint task, but at a certain stage, the robot needs help to navigate through an obstacle. Without requesting explicit help from the human, the robot performs some attempts to navigate through the obstacle, suggesting to the human that it requires help. In a study with 45 participants, we measure the human's perceptions of the social robot Vizzy, comparing the handshake vs non-handshake conditions. In addition, we evaluate the influence of a handshake in the pro-social behaviour of helping it and the willingness to help it in the future. The results show that a handshake increases the perception of Warmth, Animacy, Likeability, and the tendency to help the robot more, by removing the obstacle.
ER  - 

TY  - CONF
TI  - Received Signal Strength of Electromagnetic Waves Aided Integrated Inertial Navigation System for Underwater Vehicle
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1870
EP  - 1876
AU  - D. Park
AU  - J. Jung
AU  - K. Kwak
AU  - J. Kim
AU  - W. K. Chung
PY  - 2018
KW  - inertial navigation
KW  - Kalman filters
KW  - mobile robots
KW  - navigation
KW  - position measurement
KW  - remotely operated vehicles
KW  - sensor fusion
KW  - underwater vehicles
KW  - wireless sensor networks
KW  - Kalman filter
KW  - Earth-fixed reference sensors
KW  - EM waves attenuation
KW  - long-term navigation
KW  - basin environment
KW  - underwater wireless sensor networks
KW  - EM waves sensors
KW  - sensor-fusion-based localization scheme
KW  - electromagnetic waves sensors
KW  - sensor fusion
KW  - underwater localization scheme
KW  - strong signal attenuation
KW  - signal uncertainties
KW  - underwater environment
KW  - unmanned underwater vehicle
KW  - sensory information
KW  - integrated inertial navigation system
KW  - Manganese
KW  - Attenuation
KW  - Sensor fusion
KW  - Robot sensing systems
KW  - Noise measurement
KW  - Time measurement
DO  - 10.1109/IROS.2018.8593675
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Sensory information from an Earth-fixed reference is necessary to guarantee a high localization accuracy of an unmanned underwater vehicle (UUV). However, the implementation of these sensors in an underwater environment is challenging because of signal uncertainties and strong signal attenuation. In this paper, we propose an underwater localization scheme with a sensor fusion of inertial navigation system (INS) and received signal strength of electromagnetic (EM) waves sensors. In the proposed sensor-fusion-based localization scheme, the UUV predicts its location by using INS based on dead-reckoning and corrects the predicted position by Kalman filter using EM waves sensor information when the UUV receives the signals of EM waves sensors in underwater wireless sensor networks. The proposed scheme enables localization with high accuracy and high sampling rate during a long-term task. The results of an experiment performed in a basin environment shows the feasibility of the proposed scheme. The scheme achieved reliable localization accuracy by comparing the pre-measured ground-truth position and long-term navigation. These results show the feasibility of exploiting EM waves attenuation as Earth-fixed reference sensors.
ER  - 

TY  - CONF
TI  - Multibeam Data Processing for Underwater Mapping
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1877
EP  - 1884
AU  - P. V. Teixeira
AU  - F. S. Hover
AU  - J. J. Leonard
AU  - M. Kaess
PY  - 2018
KW  - image segmentation
KW  - oceanographic techniques
KW  - sonar
KW  - sonar detection
KW  - sonar imaging
KW  - underwater vehicles
KW  - balanced trade-off
KW  - underwater mapping literature
KW  - underwater mapping literature
KW  - local thresholding techniques
KW  - subsea structures
KW  - multibeam data processing
KW  - DIDSON imaging sonar
KW  - map accuracy
KW  - sonar-based underwater mapping
KW  - sonar artifacts
KW  - range measurements
KW  - occupied regions
KW  - free regions
KW  - received acoustic echos
KW  - sonars output
KW  - underwater mapping platforms
KW  - primary sensor
KW  - multibeam sonars
KW  - Sonar measurements
KW  - Robot sensing systems
KW  - Acoustic beams
KW  - Image segmentation
KW  - Mathematical model
KW  - Acoustics
DO  - 10.1109/IROS.2018.8594128
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - From archaeology to the inspection of subsea structures, underwater mapping has become critical to many applications. Because of the balanced trade-off between range and resolution, multibeam sonars are often used as the primary sensor in underwater mapping platforms. These sonars output an image representing the intensity of the received acoustic echos over space, which must be classified into free and occupied regions before range measurements are determined and spatially registered. Most classifiers found in the underwater mapping literature use local thresholding techniques, which are highly sensitive to noise, outliers, and sonar artifacts typically found in these images. In this paper we present an overview of some of the techniques developed in the scope of our work on sonar-based underwater mapping, with the aim of improving map accuracy through better segmentation performance. We also provide experimental results using data collected with a DIDSON imaging sonar that show that these techniques improve both segmentation accuracy and robustness to outliers.
ER  - 

TY  - CONF
TI  - Vision-Based Autonomous Underwater Swimming in Dense Coral for Combined Collision Avoidance and Target Selection
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1885
EP  - 1891
AU  - T. Manderson
AU  - J. C. G. Higuera
AU  - R. Cheng
AU  - G. Dudek
PY  - 2018
KW  - autonomous underwater vehicles
KW  - cameras
KW  - collision avoidance
KW  - convolutional neural nets
KW  - mobile robots
KW  - navigation
KW  - object detection
KW  - robot vision
KW  - supervised learning
KW  - proportional controller
KW  - vision-based autonomous underwater swimming
KW  - computer vision
KW  - visual target selection
KW  - coral-deprived regions
KW  - monocular image data
KW  - convolutional neural network
KW  - supervised learning
KW  - motor controller
KW  - collision avoidance
KW  - autonomous robot swimming
KW  - autonomous coral reef navigation
KW  - obstacle-avoidance
KW  - forward-facing camera
KW  - Navigation
KW  - Cameras
KW  - Robot vision systems
KW  - Task analysis
KW  - Visualization
KW  - Neural networks
DO  - 10.1109/IROS.2018.8594410
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We address the problem of learning vision-based, collision-avoiding, and target-selecting controllers in 3D, specifically in underwater environments densely populated with coral reefs. Using a highly maneuverable, dynamic, six-legged (or flippered) vehicle to swim underwater, we exploit real time visual feedback to make close-range navigation decisions that would be hard to achieve with other sensors. Our approach uses computer vision as the sole mechanism for both collision avoidance and visual target selection. In particular, we seek to swim close to the reef to make observations while avoiding both collisions and barren, coral-deprived regions. To carry out path selection while avoiding collisions, we use monocular image data processed in real time. The proposed system uses a convolutional neural network that takes an image from a forward-facing camera as input and predicts unscaled and relative path changes. The network is trained to encode our desired obstacle-avoidance and reef-exploration objectives via supervised learning from human-labeled data. The predictions from the network are transformed into absolute path changes via a combination of a temporally-smoothed proportional controller for heading targets and a low-level motor controller. This system enables safe and autonomous coral reef navigation in underwater environments. We validate our approach using an untethered and fully autonomous robot swimming through coral reef in the open ocean. Our robot successfully traverses 1000 m of the ocean floor collision-free while collecting close-up footage of coral reefs.
ER  - 

TY  - CONF
TI  - Robust Continuous System Integration for Critical Deep-Sea Robot Operations Using Knowledge-Enabled Simulation in the Loop
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1892
EP  - 1899
AU  - C. A. Mueller
AU  - T. Doernbach
AU  - A. G. Chavez
AU  - D. Köhntopp
AU  - A. Birk
PY  - 2018
KW  - autonomous underwater vehicles
KW  - data acquisition
KW  - marine safety
KW  - mobile robots
KW  - perception
KW  - robust continuous system integration
KW  - critical deep-sea robot operations
KW  - knowledge-enabled simulation
KW  - reliability
KW  - self-localization
KW  - system components
KW  - safety
KW  - simulation in the loop methodology
KW  - SIL methodology
KW  - Task analysis
KW  - Robot sensing systems
KW  - Data models
KW  - Benchmark testing
KW  - Continuous time systems
DO  - 10.1109/IROS.2018.8594392
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Deep-sea robot operations demand a high level of safety, efficiency and reliability. As a consequence, measures within the development stage have to be implemented to extensively evaluate and benchmark system components ranging from data acquisition, perception and localization to control. We present an approach based on high-fidelity simulation that embeds spatial and environmental conditions from recorded real-world data. This simulation in the loop (SIL) methodology allows for mitigating the discrepancy between simulation and real-world conditions, e.g. regarding sensor noise. As a result, this work provides a platform to thoroughly investigate and benchmark behaviors of system components concurrently under real and simulated conditions. The conducted evaluation shows the benefit of the proposed work in tasks related to perception and self-localization under changing spatial and environmental conditions.
ER  - 

TY  - CONF
TI  - Reliable fusion of black-box estimates of underwater localization
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1900
EP  - 1905
AU  - H. F. Chame
AU  - M. M. dos Santos
AU  - S. S. da Costa Botelho
PY  - 2018
KW  - estimation theory
KW  - Kalman filters
KW  - mobile robots
KW  - Monte Carlo methods
KW  - sensor fusion
KW  - underwater vehicles
KW  - inertial sensory
KW  - Kalman filter
KW  - augmented Monte Carlo localization algorithms
KW  - geophysical sensory
KW  - task context
KW  - localization signal
KW  - heuristic model
KW  - underwater robot localization
KW  - un-modeled noise
KW  - adaptive fusion policy
KW  - redundant parametric estimations
KW  - information fusion
KW  - robot tracking
KW  - black-box estimates
KW  - reliable fusion
KW  - Estimation
KW  - Task analysis
KW  - Reliability
KW  - Robot sensing systems
KW  - Global Positioning System
KW  - Computational modeling
DO  - 10.1109/IROS.2018.8593593
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The research on robot tracking has focused on the problem of information fusion from redundant parametric estimations, though the aspect of choosing an adaptive fusion policy, that is computationally efficient, and is able to reduce the impact of un-modeled noise, are still open issues. The objective of this work is to study the problem of underwater robot localization. For this, we have considered a task relying on inertial and geophysical sensory. We propose an heuristic model that performs adaptable fusion of information based on the principle of contextually anticipating the localization signal within an ordered neighborhood, such that a set of nodes properties is related to the task context, and the confidence on individual estimates is evaluated before fusing information. The results obtained show that our model outperforms the Kalman filter and the Augmented Monte Carlo Localization algorithms in the task.
ER  - 

TY  - CONF
TI  - Coverage Optimization with Non-Actuated, Floating Mobile Sensors using Iterative Trajectory Planning in Marine Flow Fields
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1906
EP  - 1912
AU  - J. Hansen
AU  - G. Dudek
PY  - 2018
KW  - oceanographic equipment
KW  - oceanographic techniques
KW  - passive nodes
KW  - coverage optimization
KW  - mobile sensors
KW  - iterative trajectory planning
KW  - marine flow fields
KW  - spatial coverage problem
KW  - passive floating sensors
KW  - iterative measurement
KW  - modeling scheme
KW  - initial sample point
KW  - survey area
KW  - ambient surface currents
KW  - computational tool
KW  - autonomous marine surveying system
KW  - ocean drifters
KW  - spatial distribution
KW  - ocean flow fields
KW  - Trajectory
KW  - Sensors
KW  - Oceans
KW  - Planning
KW  - Sea measurements
KW  - Computational modeling
KW  - Robots
DO  - 10.1109/IROS.2018.8594281
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper considers a spatial coverage problem in which a network of passive floating sensors is used to collect samples in a body of water. We employ an iterative measurement and modeling scheme to incrementally deploy sensors so as to achieve spatial coverage, despite only controlling the initial sample point. Once deployed, sensors are moved about a survey area by ambient surface currents. We demonstrate our results in simulation on 40 different ocean flow fields and compare against several baselines. This work provides a computational tool for scientists seeking a low-cost, autonomous marine surveying system. Although in this paper, we concentrate on ocean drifters, our approach can be extended to other domains where a spatial distribution of passive nodes in a flow field can be modeled.
ER  - 

TY  - CONF
TI  - A Deformable Spiral Based Algorithm to Smooth Coverage Path Planning for Marine Growth Removal
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1913
EP  - 1918
AU  - M. Hassan
AU  - D. Liu
PY  - 2018
KW  - autonomous underwater vehicles
KW  - bridges (structures)
KW  - inspection
KW  - multi-robot systems
KW  - path planning
KW  - underwater structures
KW  - DSCPP
KW  - smooth paths
KW  - spiral path
KW  - popular boustrophedon-based coverage approach
KW  - intervention autonomous underwater vehicle
KW  - deformable spiral coverage path planning algorithm
KW  - smooth coverage path planning
KW  - deformable spiral-based algorithm
KW  - Spirals
KW  - Cleaning
KW  - Path planning
KW  - Fatigue
KW  - Underwater structures
KW  - Manipulators
KW  - Poles and towers
DO  - 10.1109/IROS.2018.8593563
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Marine growths that flourish on the surfaces of underwater structures, such as bridge pylons, make the inspection and maintenance of these structures challenging. A robotic solution, using an Intervention Autonomous Underwater Vehicle (I-AUV), is developed for removing marine growth. This paper presents a Deformable Spiral Coverage Path Planning (DSCPP) algorithm for marine growth removal. DSCPP generates smooth paths to prevent damage to the surfaces of the structures and to avoid frequent or aggressive decelerations and accelerations due to sharp turns. DSCPP generates a spiral path within a circle and analytically maps the path to a minimum bounding rectangle which encompasses an area of a surface with marine growth. It aims to achieve a spiral path with minimal length while preventing missed areas of coverage. Several case studies are presented to validate the algorithm. Comparison results show that DSCPP outperforms the popular boustrophedon-based coverage approach when considering the requirements for the application under consideration.
ER  - 

TY  - CONF
TI  - Acoustic Tag State Estimation with Unsynchronized Hydrophones on AUVs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1919
EP  - 1926
AU  - J. Shi
AU  - T. Ma
AU  - C. Lee
AU  - E. Shimelis
AU  - C. Van Eijk
AU  - C. M. Clark
AU  - C. G. Lowe
PY  - 2018
KW  - autonomous underwater vehicles
KW  - calibration
KW  - clocks
KW  - Global Positioning System
KW  - hydrophones
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - sensors
KW  - synchronisation
KW  - time-of-arrival estimation
KW  - underwater sound
KW  - underwater acoustic transmitter
KW  - real-time calibration algorithms
KW  - TOF measurements
KW  - temperature variation
KW  - mixed integer linear program
KW  - AUV
KW  - TDOA filtering methods
KW  - mean localization errors
KW  - acoustic tag state estimation
KW  - unsynchronized hydrophones
KW  - underwater robotic sensor system
KW  - marine animals
KW  - time difference of arrival
KW  - autonomous underwater vehicle
KW  - nonlinear clock skews
KW  - time of flight
KW  - GPS data
KW  - TOF filtering methods
KW  - standard deviation
KW  - Clocks
KW  - Sonar equipment
KW  - Acoustics
KW  - Temperature measurement
KW  - Acoustic measurements
KW  - Estimation
DO  - 10.1109/IROS.2018.8593589
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents an underwater robotic sensor system for localizing acoustic transmitters when the robot's hydrophones cannot be time-synchronized. The development of the system is motivated by applications where tracking of marine animals that are tagged with an underwater acoustic transmitter is required. The system uses two novel real-time calibration algorithms that improve the accuracy of time of flight (TOF) and time difference of arrival (TDOA) measurements. The first algorithm corrects non-linear clock skews in TOF measurements based on temperature variation. The second algorithm compensates the localized relative clock skew between clocks using a mixed integer linear program. To validate the system's performance, an Autonomous Underwater Vehicle (AUV) was deployed to track a moving tag where GPS data was used as ground truth. Compared to traditional TOF and TDOA filtering methods, the results show that the proposed system can achieve reduction of mean localization errors by 59%, and a reduction of the standard deviation of measurements by 44%.
ER  - 

TY  - CONF
TI  - GelSlim: A High-Resolution, Compact, Robust, and Calibrated Tactile-sensing Finger
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1927
EP  - 1934
AU  - E. Donlon
AU  - S. Dong
AU  - M. Liu
AU  - J. Li
AU  - E. Adelson
AU  - A. Rodriguez
PY  - 2018
KW  - calibration
KW  - dexterous manipulators
KW  - grippers
KW  - robot vision
KW  - tactile sensors
KW  - calibrated tactile-sensing finger
KW  - high-resolution tactile-sensing finger
KW  - robot grasping
KW  - previous GelSight sensing techniques
KW  - Adelson 2009
KW  - homogeneous output
KW  - previous vision-based tactile sensors
KW  - compact integration
KW  - optical path
KW  - illumination source
KW  - geometric design variables
KW  - finger thickness
KW  - tactile sensing area
KW  - grasping tasks
KW  - compliant gel
KW  - calibration process
KW  - homogeneous illumination
KW  - tactile images
KW  - Tactile sensors
KW  - Cameras
KW  - Three-dimensional displays
KW  - Grasping
DO  - 10.1109/IROS.2018.8593661
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work describes the development of a high-resolution tactile-sensing finger for robot grasping. This finger, inspired by previous GelSight sensing techniques (Johnson and Adelson 2009), features an integration that is slimmer, more robust, and with more homogeneous output than previous vision-based tactile sensors. To achieve a compact integration, we redesign the optical path from illumination source to camera by combining light guides and an arrangement of mirror reflections. We parameterize the optical path with geometric design variables and describe the tradeoffs between the finger thickness, camera depth of field, and size of the tactile sensing area. The sensor sustains the wear from continuous use - and abuse - in grasping tasks by combining tougher materials for the compliant gel, a textured fabric skin, a structurally rigid body, and a calibration process that maintains homogeneous illumination and contrast of the tactile images during use. Finally, we evaluate the sensor's durability along four metrics that track the signal quality during more than 3000 grasping experiments.
ER  - 

TY  - CONF
TI  - Single-Grasp, Model-Free Object Classification using a Hyper-Adaptive Hand, Google Soli, and Tactile Sensors
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1943
EP  - 1950
AU  - Z. Flintoff
AU  - B. Johnston
AU  - M. Liarokapis
PY  - 2018
KW  - end effectors
KW  - force measurement
KW  - grippers
KW  - position control
KW  - tactile sensors
KW  - object exploration
KW  - Google Soli readings
KW  - grasping process
KW  - stable grasps
KW  - single-grasp
KW  - model-free object classification
KW  - hyper-adaptive hand
KW  - tactile sensors
KW  - end-effectors
KW  - object identification
KW  - robotics applications
KW  - autonomous object
KW  - quality inspection
KW  - hyper-adaptive robot hand
KW  - model objects
KW  - adaptive grasping mechanisms
KW  - tactile modules
KW  - barometric sensors
KW  - Google Soli sensor
KW  - everyday objects
KW  - random forests classifier
KW  - Robot sensing systems
KW  - Thumb
KW  - Google
KW  - Pins
DO  - 10.1109/IROS.2018.8594166
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Robots need to use their end-effectors not only to grasp and manipulate objects but also to understand the environment surrounding them. Object identification is of paramount importance in robotics applications, as it facilitates autonomous object handling, sorting, and quality inspection. In this paper, we present a new hyper-adaptive robot hand that is capable of discriminating between different everyday objects, as well as `model' objects with the same external geometry but varying material, density, or volume, with a single grasp. This work leverages all the benefits of simple, adaptive grasping mechanisms (robustness, simplicity, low weight, adaptability), a Random Forests classifier, tactile modules based on barometric sensors, and radar technology offered by the Google Soli sensor. Unlike prior work, the method does not rely on object exploration, object release or re-grasping and works for a wide variety of everyday objects. The feature space used consists of the Google Soli readings, the motor positions and the contact forces measured at different time instances of the grasping process. The whole approach is model-free and the hand is controlled in an open-loop fashion, achieving stable grasps with minimal complexity. The efficiency of the designs, sensors, and methods has been experimentally validated with experimental paradigms involving model and everyday objects.
ER  - 

TY  - CONF
TI  - Encoding Guidelines for a Culturally Competent Robot for Elderly Care
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1988
EP  - 1995
AU  - A. Sgorbissa
AU  - I. Papadopoulos
AU  - B. Bruno
AU  - C. Koulouglioti
AU  - C. Recchiuto
PY  - 2018
KW  - geriatrics
KW  - handicapped aids
KW  - human-robot interaction
KW  - man-machine systems
KW  - service robots
KW  - encoding guidelines
KW  - culturally competent robot
KW  - elderly care
KW  - socially assistive robots
KW  - older people
KW  - runtime adaptation
KW  - assisted person
KW  - invaluable enabling technology
KW  - culturally competent assistive behaviours
KW  - pepper robot
KW  - Indian persona
KW  - Guidelines
KW  - Cultural differences
KW  - Robot sensing systems
KW  - Motion pictures
KW  - Medical services
KW  - Encoding
DO  - 10.1109/IROS.2018.8594089
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The functionalities and behaviours of socially assistive robots for the care of older people are usually defined by the robot's designers with limited room for runtime adaptation to meet the preferences, expectations and needs of the assisted person. However, adaptation plays a crucial role for the robot's acceptability and ultimately for its effectiveness. Culture, which deeply influences a person's preferences and habits, can be viewed as an invaluable “enabling technology” to achieve such level of adaptation. This paper discusses how guidelines describing culturally competent assistive behaviours can be encoded in a robot to effectively tune its actions, gestures and words. The proposed system is implemented on a Pepper robot and tested with an Indian persona, whose habits and preferences the robot discovers and adapts to at runtime.
ER  - 

TY  - CONF
TI  - Embedding Ethics in the Design of Culturally Competent Socially Assistive Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 1996
EP  - 2001
AU  - L. Battistuzzi
AU  - A. Sgorbissa
AU  - C. Papadopoulos
AU  - I. Papadopoulos
AU  - C. Koulouglioti
PY  - 2018
KW  - ethical aspects
KW  - geriatrics
KW  - medical robotics
KW  - CARESSES robot
KW  - ethical thinking
KW  - VSD
KW  - international multidisciplinary project
KW  - culturally competent SAR
KW  - ethical concepts
KW  - value sensitive design
KW  - culturally competent socially assistive robots
KW  - Robots
KW  - Task analysis
KW  - Ethics
KW  - Guidelines
KW  - Cultural differences
KW  - Assistive technology
KW  - Medical services
DO  - 10.1109/IROS.2018.8594361
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Research focusing on the development of socially assistive robots (SARs) for the care of older adults has grown in recent years, prompting a great deal of ethical analysis and reflection on the future of SARs in caring roles. Much of this ethical thinking, however, has taken place far from the settings where technological innovation is practiced. Different frameworks have been proposed to bridge this gap and enable researchers to handle the ethical dimension of technology from within the design and development process, including Value Sensitive Design (VSD). VSD has been defined as a “theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process”. Inspired in part by VSD, we have developed a process geared towards embedding ethics at the core of CARESSES, an international multidisciplinary project that aims to design the first culturally competent SAR for the care of older adults. Here we describe that process, which included extracting key ethical concepts from relevant ethical guidelines and applying those concepts to scenarios that describe how the CARESSES robot will interact with individuals belonging to different cultures. This approach highlights the ethical implications of the robot's behavior early in the design process, thus enabling researchers to identify and engage with ethical problems proactively.
ER  - 

TY  - CONF
TI  - Developing a New Brand of Culturally-Aware Personal Robots Based on Local Cultural Practices in the Danish Health Care System
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2002
EP  - 2007
AU  - M. Rehm
AU  - K. Rodil
AU  - A. L. Krummheuer
PY  - 2018
KW  - brain
KW  - cultural aspects
KW  - health care
KW  - human-robot interaction
KW  - medical robotics
KW  - mobile robots
KW  - good starting point
KW  - concrete application fields
KW  - national culture
KW  - concrete applications
KW  - local cultural practices
KW  - culturally-aware personal robots
KW  - human robot interaction
KW  - Danish health care system
KW  - brain damage
KW  - learning processes
KW  - Cultural differences
KW  - Global communication
KW  - Robot sensing systems
KW  - Task analysis
KW  - Conferences
KW  - Programming
DO  - 10.1109/IROS.2018.8594478
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In earlier work it has been shown how culture can be used as a parameter influencing human robot interaction in general (e.g. [1]). While this is a good starting point, in our work with concrete application fields we encounter that culture in its usual definition as national culture (e.g. [2]; [3]) is too general a concept to be useful in these concrete applications. Thus, we shifted our focus instead to a concept of local cultural practices, which is derived from situated practices as in Wengers communities of practice [4] and grounded loosely in Sperbers idea of an epidemiology of representations [5], i.e. culture or rather cultural practices as an emergent phenomenon from learning processes in a given group. Developing this new kind of culture-aware robots can then not start from a general definition of culture like Hofstede [2], Schwartz and Sagiv [6], etc. but has to take the actual group of users (and stakeholders) into account. We exemplify this approach with our work in a residency for citizens with acquired brain damage.
ER  - 

TY  - CONF
TI  - Emotional Bodily Expressions for Culturally Competent Robots through Long Term Human-Robot Interaction
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2008
EP  - 2013
AU  - N. T. Viet Tuyen
AU  - S. Jeong
AU  - N. Y. Chong
PY  - 2018
KW  - emotion recognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - multiculture society
KW  - incremental learning model
KW  - habitual emotional behaviors
KW  - social robot
KW  - emotional bodily expressions
KW  - imitated robot motions
KW  - cultural background
KW  - culturally competent robots
KW  - long term human-robot interaction
KW  - Robot kinematics
KW  - Neurons
KW  - Self-organizing feature maps
KW  - Trajectory
KW  - Training
KW  - Collision avoidance
DO  - 10.1109/IROS.2018.8593974
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Generating emotional bodily expressions for culturally competent robots has been gaining increased attention to enhance the engagement and empathy between robots and humans in a multi-culture society. In this paper, we propose an incremental learning model for selecting the user's representative or habitual emotional behaviors which place emphasis on individual users' cultural traits identified through long term interaction. Furthermore, a transformation model is proposed to convert the obtained emotional behaviors into a specific robot's motion space. To validate the proposed approach, the models were evaluated by two example scenarios of interaction. The experimental results confirmed that the proposed approach endows a social robot with the capability to learn emotional behaviors from individual users, and to generate its emotional bodily expressions. It was also verified that the imitated robot motions are rated emotionally acceptable by the demonstrator and recognizable by the subjects from the same cultural background with the demonstrator.
ER  - 

TY  - CONF
TI  - Identification of the User's Habits based on Activity Information
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2014
EP  - 2019
AU  - N. Melo
AU  - J. Lee
AU  - R. Suzuki
PY  - 2018
KW  - Fourier series
KW  - home automation
KW  - service robots
KW  - k-means method
KW  - Fourier series representation
KW  - activity recognition module
KW  - habit estimation system
KW  - smart house
KW  - user habits
KW  - activity information
KW  - user personality traits
KW  - habit representation
KW  - Activity recognition
KW  - Robot kinematics
KW  - TV
KW  - Radiofrequency identification
KW  - Receivers
KW  - Senior citizens
DO  - 10.1109/IROS.2018.8593873
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This work proposes a system able to recognize the user habits based on his daily activities in a smart house. The habit estimation system uses the information provided by an activity recognition module, which provides the sequence and the duration of the activities performed by the user. Based on those parameters, the activities are represented as a signal by using Fourier series representation. Several output signals from different users are clustered into groups using the k-means method, where each cluster corresponds to a specific habit from a group of people. The proposed system was tested with dataset from the experiment that took place in an environment similar to a smart house. The users were asked to perform a set of 6 activities in any desired orders. In total, twenty-four subjects took part in the experiments. All activities were successfully recognized by the system and three different habits were found. The proposed system along with its habit representation can be potentially used to trace the relationships between the habits observed and some aspects of the user personality traits.
ER  - 

TY  - CONF
TI  - AIBO Robot Mortuary Rites in the Japanese Cultural Context*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2020
EP  - 2025
AU  - E. Knox
AU  - K. Watanabe
PY  - 2018
KW  - biomimetics
KW  - robots
KW  - AIBO Robot mortuary rites
KW  - Japanese cultural context
KW  - AlBO Entertainment Robot
KW  - Japanese tech-repair company
KW  - Buddhist funeral ceremony
KW  - A-Fun's maintenance services
KW  - AIBO funerals
KW  - human-machine relations
KW  - robot design
KW  - pet-like robots
KW  - zoomorphism
KW  - Companies
KW  - Maintenance engineering
KW  - Animals
KW  - Robot sensing systems
KW  - Medical treatment
KW  - Toy manufacturing industry
DO  - 10.1109/IROS.2018.8594066
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In 1999 Sony released the AlBO Entertainment Robot, selling more than 150,000 units worldwide until 2006. By 2014, Sony had stopped offering upgrades and maintenance for the product, and owners were faced with the fact their pet-like robots would “die”. Some shrines and temples in Japan hold ningyo kuyo̅ or mass funerals for dolls and other toys. At the suggestion of a small Japanese tech-repair company called A-Fun, one temple began offering a Buddhist funeral ceremony for AIBOs. Approximately 700 AIBOs have so far received a funeral service. This paper surveys A-Fun`s maintenance services for old AIBOs, the AIBO funerals, and Sony's new 2018 AIBO release, in the cross-disciplinary context of human-machine relations in Japan and elsewhere. Drawing on the author's interviews with key actors, it articulates links between philosophy and neuroscience to explain tendencies toward zoomorphism in robot design. Perceiving presence (sonzai kan) and sensibility (kansei) in objects is a culturally contingent phenomenon. Whereas ways of conceiving the partly animate are largely absent from Western philosophy, in the case of AIBO ownership in Japan there is a reverential mindfulness of the technology's inherent contradictions.
ER  - 

TY  - CONF
TI  - Social Robots as a Means of Integration? an Explorative Acceptance Study considering Gender and Non-verbal Behaviour
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2026
EP  - 2032
AU  - B. Lugrin
AU  - J. Dippold
AU  - K. Bergmann
PY  - 2018
KW  - computer aided instruction
KW  - educational robots
KW  - gender issues
KW  - human-robot interaction
KW  - culture-specific behaviours
KW  - social robot
KW  - german female nonverbal behaviour
KW  - educational robot
KW  - culture-specific manipulations
KW  - European states
KW  - gender-specific behaviours
KW  - Robot sensing systems
KW  - Mouth
KW  - Cultural differences
KW  - Training
KW  - Europe
DO  - 10.1109/IROS.2018.8593818
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The integration of migrants and refugees is currently a severe challenge for European states. Especially the imparting of culture- and gender-specific behaviours is an important issue. Social robots might be a valuable tool to introduce refugees to culture-specific behaviours of their host country. In this paper, we investigate the general acceptance of a social robot as well as users' perception of a robot presenting stereo-typical Arabic vs. German female non-verbal behaviour to Syrian newcomers to Germany. Our preliminary study revealed a generally positive attitude towards robots and the idea of an educational robot. Culture-specific manipulations were reflected in participants' partial preference for the Arabic version, but not in participants' perceptual ratings.
ER  - 

TY  - CONF
TI  - Do I act familiar? Investigating the Similarity-Attraction Principle on Culture-specific Communicative behaviour for Social Robots
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2033
EP  - 2039
AU  - B. Lugrin
AU  - A. Bartl
AU  - H. Striepe
AU  - J. Lax
AU  - T. Toriizuka
PY  - 2018
KW  - behavioural sciences computing
KW  - cultural aspects
KW  - human-robot interaction
KW  - mobile robots
KW  - social robots conversation
KW  - cultural dichotomy
KW  - human-human interactions
KW  - culture-specific communicative behaviour
KW  - similarity-attraction principle
KW  - Cultural differences
KW  - Observers
KW  - Computational modeling
KW  - Global communication
KW  - Service robots
KW  - Senior citizens
DO  - 10.1109/IROS.2018.8594035
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Culture, amongst other individual and social factors, plays a crucial role in human-human interactions. If robots should become a part of our society, they should be able to act in culture-specific manners as well. In this paper, we showcase the implementation of a cultural dichotomy, namely individualism vs. collectivism, in a social robots' conversation. Presenting these conversations to human observers from Germany and Japan, we investigate whether the implemented differences are recognized as such, and whether stereotypical culture-specific behaviours that correspond to the observers' cultural background is preferred. Results suggest that the manipulations in behaviour had the intended effect, but are not reflected in personal preferences.
ER  - 

TY  - CONF
TI  - Dexterous Manipulation Graphs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2040
EP  - 2047
AU  - S. Cruciani
AU  - C. Smith
AU  - D. Kragic
AU  - K. Hang
PY  - 2018
KW  - dexterous manipulators
KW  - end effectors
KW  - graph theory
KW  - grippers
KW  - Dexterous Manipulation graphs
KW  - in-hand manipulation
KW  - end-effector
KW  - dual arm robot
KW  - end pose
KW  - parallel grippers
KW  - Grippers
KW  - End effectors
KW  - Planning
KW  - Dynamics
KW  - Shape
DO  - 10.1109/IROS.2018.8594303
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We propose the Dexterous Manipulation Graph as a tool to address in-hand manipulation and reposition an object inside a robot's end-effector. This graph is used to plan a sequence of manipulation primitives so to bring the object to the desired end pose. This sequence of primitives is translated into motions of the robot to move the object held by the end-effector. We use a dual arm robot with parallel grippers to test our method on a real system and show successful planning and execution of in-hand manipulation.
ER  - 

TY  - CONF
TI  - Instance Segmentation of Visible and Occluded Regions for Finding and Picking Target from a Pile of Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2048
EP  - 2055
AU  - K. Wada
AU  - S. Kitagawa
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - image motion analysis
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object detection
KW  - target object
KW  - robotic system
KW  - human-annotated dataset
KW  - human annotations
KW  - image synthesis
KW  - inter-instance relationship
KW  - novel relook architecture
KW  - instance occlusion segmentation
KW  - occluded masks
KW  - Image segmentation
KW  - Robots
KW  - Feature extraction
KW  - Object segmentation
KW  - Image generation
KW  - Task analysis
KW  - Predictive models
DO  - 10.1109/IROS.2018.8593690
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present a robotic system for picking a target from a pile of objects that is capable of finding and grasping the target object by removing obstacles in the appropriate order. The fundamental idea is to segment instances with both visible and occluded masks, which we call `instance occlusion segmentation'. To achieve this, we extend an existing instance segmentation model with a novel `relook' architecture, in which the model explicitly learns the inter-instance relationship. Also, by using image synthesis, we make the system capable of handling new objects without human annotations. The experimental results show the effectiveness of the relook architecture when compared with a conventional model and of the image synthesis when compared to a human-annotated dataset. We also demonstrate the capability of our system to achieve picking a target in a cluttered environment with a real robot.
ER  - 

TY  - CONF
TI  - Online prediction of threading task failure using Convolutional Neural Networks
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2056
EP  - 2061
AU  - G. R. Moreira
AU  - G. J. G. Lahr
AU  - T. Boaventura
AU  - J. O. Savazzi
AU  - G. A. P. Caurin
PY  - 2018
KW  - assembling
KW  - convolutional neural nets
KW  - fasteners
KW  - fault diagnosis
KW  - flexible manufacturing systems
KW  - force sensors
KW  - grippers
KW  - industrial robots
KW  - pattern classification
KW  - production engineering computing
KW  - supervised learning
KW  - online prediction
KW  - fasteners assembly automation
KW  - flexible systems
KW  - industrial robot
KW  - force-torque sensor
KW  - pneumatic gripper
KW  - supervised machine learning algorithm
KW  - threading task execution time
KW  - task failure
KW  - FDI techniques
KW  - convolutional neural network classifier
KW  - fault detection and isolation
KW  - CNN
KW  - Fasteners
KW  - Task analysis
KW  - Robot sensing systems
KW  - Instruction sets
KW  - Force
KW  - Service robots
DO  - 10.1109/IROS.2018.8594501
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Fasteners assembly automation in different industries require flexible systems capable of dealing with faulty situations. Fault detection and isolation (FDI) techniques are used to detect failure and deal with them, avoiding losses on parts, tools or robots. However, FDI usually deals with the faults after or at the moment they occur. Thus, we propose a method that predicts potential failures online, based on the forces and torques signatures captured during the task. We demonstrate the approach experimentally using an industrial robot, equipped with a force-torque sensor and a pneumatic gripper, used to align and thread nuts into bolts. All effort information is fed into a supervised machine learning algorithm, based on a Convolutional Neural Network (CNN) classifier. The network was able to predict and classify the threading task outcomes in 3 groups: mounted, not mounted or jammed. Our approach was able to reduce in 10.9% the threading task execution time when compared to a reference without FDI, but had problem to predict jammed cases. The same experiment was also performed with other two additional learning algorithms, and the results were systematically compared.
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning for Robotic Assembly of Mixed Deformable and Rigid Objects
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2062
EP  - 2069
AU  - J. Luo
AU  - E. Solowjow
AU  - C. Wen
AU  - J. A. Ojea
AU  - A. M. Agogino
PY  - 2018
KW  - control engineering computing
KW  - feedback
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - position control
KW  - robot programming
KW  - robotic assembly
KW  - torque control
KW  - torque measurement
KW  - neural network
KW  - force torque measurements
KW  - passive mechanical compliance
KW  - deep reinforcement learning
KW  - torque control
KW  - robot control algorithms
KW  - assembly tasks
KW  - feedback control methods
KW  - robotic assembly
KW  - industrial robot
KW  - robot learning
KW  - admittance controller
KW  - policy learning process
KW  - robot arm wrist sensor
KW  - deformable hole
KW  - rigid peg
KW  - Robot sensing systems
KW  - Task analysis
KW  - Reinforcement learning
KW  - Neural networks
KW  - Service robots
KW  - Robotic assembly
DO  - 10.1109/IROS.2018.8594353
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Reinforcement learning for assembly tasks can yield powerful robot control algorithms for applications that are challenging or even impossible for “conventional” feedback control methods. Insertion of a rigid peg into a deformable hole of smaller diameter is such a task. In this contribution we solve this task with Deep Reinforcement Learning. Force-torque measurements from a robot arm wrist sensor are thereby incorporated two-fold; they are integrated into the policy learning process and they are exploited in an admittance controller that is coupled to the neural network. This enables robot learning of contact-rich assembly tasks without explicit joint torque control or passive mechanical compliance. We demonstrate our approach in experiments with an industrial robot.
ER  - 

TY  - CONF
TI  - A Sensor-less Catheter Contact Force Estimation Approach in Endovascular Intervention Procedures*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2100
EP  - 2106
AU  - M. Razban
AU  - J. Dargahi
AU  - B. Boulet
PY  - 2018
KW  - bending
KW  - blood vessels
KW  - catheters
KW  - finite element analysis
KW  - medical image processing
KW  - force estimation accuracy
KW  - endovascular intervention procedures
KW  - multiple catheter
KW  - sensor-less catheter contact force estimation approach
KW  - vessel wall
KW  - embolization
KW  - navigation process safety
KW  - robotic vascular interventions
KW  - sensor-less sensing solution
KW  - multiple contact point forces
KW  - image feedback
KW  - catheter-vessel interaction
KW  - real-time image processing algorithms
KW  - interaction contact points
KW  - image-based deflection measurement
KW  - nonlinear finite element beam model
KW  - three-point-bending tests
KW  - catheter-guidewire-vessel interaction contact forces
KW  - catheter-guidewire manipulation
KW  - bending modulus property
KW  - under-actuated catheter-guidewire
KW  - catheter-guidewire-vessel interaction
KW  - Catheters
KW  - Force
KW  - Robot sensing systems
KW  - Estimation
KW  - Force measurement
KW  - Phantoms
KW  - Finite element analysis
DO  - 10.1109/IROS.2018.8593387
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Catheter/guidewire manipulation in endovascu-lar intervention procedures are associated with risks of injury on vessel wall and embolization. Determination of catheter/guidewire-vessel interaction contact forces can improve the navigation process safety and efficiency which prevent injuries in both manual and robotic vascular interventions. This study proposes a sensor-less sensing solution to estimate multiple contact point forces at the side of catheter/guidewire exerted on the vasculature. This goal is achieved by using image feedback of catheter-vessel interaction and numerical finite element modeling (FEM). Real-time image processing algorithms are implemented to track interaction contact points on catheter/guidewire. Image-based deflection measurement and contact points tracking data are given to a nonlinear finite element beam model to estimate the forces. The variable equivalent bending modulus of the guidewire is found through a series of three-point-bending tests. To directly measure contact point forces, an experimental platform is prepared which simulates catheter/guidewire-vessel interaction with two, three and four contact points. The effectiveness of the proposed approach is tested in six scenarios in which force estimation accuracy of more than 87.9% is achieved. The proposed approach can be applied to various types of under-actuated catheter/guidewire in endovascular intervention procedures. This study proves that multiple catheter/guidewire side contact forces can be estimated by using the deflected shape and equivalent bending modulus property without embedding any force sensor.
ER  - 

TY  - CONF
TI  - Contact Force Control of an Aerial Manipulator in Pressing an Emergency Switch Process
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2107
EP  - 2113
AU  - X. Meng
AU  - Y. He
AU  - Q. Li
AU  - F. Gu
AU  - L. Yang
AU  - T. Yan
AU  - J. Han
PY  - 2018
KW  - aerospace robotics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - force control
KW  - manipulators
KW  - position control
KW  - springs (mechanical)
KW  - vibration control
KW  - emergency switch process
KW  - dangerous work situation
KW  - industrial leakage accidents
KW  - flexible robot
KW  - small robot
KW  - aerial manipulator system
KW  - hexa-rotor UAV
KW  - UAV platform
KW  - hover flight
KW  - impedance control algorithm
KW  - force-sensorless contact force control method
KW  - one-DOF manipulator
KW  - spring-mass-damper system model
KW  - Manipulators
KW  - Force
KW  - Contacts
KW  - Attitude control
KW  - Force control
KW  - Pressing
DO  - 10.1109/IROS.2018.8593535
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The dangerous work situation in industrial leakage accidents urgently needs a flexible and small robot to help workers perform operations and to protect them from being injured. An aerial manipulator system consisting of a hexa-rotor UAV and a one-DOF manipulator is developed, and is used to press an emergency switch to shut off machinery in an emergency. In practical application, an aerial manipulator usually performs contact operations as the UAV platform is in hover flight. The hovering UAV acting as a spring-mass-damper system is firstly proved. Then, based on the derived spring-mass-damper system model and the impedance control algorithm, the force-sensorless contact force control method is presented. That is, the force is indirectly controlled through controlling the UAV's position error and pitch angle simultaneously. The practical operation experiment of pressing an emergency button shows that the proposed method is able to control the contact force as the aerial manipulator interacts with the external environment.
ER  - 

TY  - CONF
TI  - Mechatronic fingernail with static and dynamic force sensing
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2114
EP  - 2119
AU  - R. Kõiva
AU  - T. Schwank
AU  - G. Walck
AU  - R. Haschke
AU  - H. J. Ritter
PY  - 2018
KW  - force control
KW  - force sensors
KW  - manipulators
KW  - mechatronics
KW  - motion control
KW  - compact working prototype
KW  - multicell tactile fingertip sensor
KW  - distal phalange
KW  - robotic hand
KW  - mechatronic fingernail
KW  - static force sensing
KW  - dynamic force sensing
KW  - sensorized fingernail
KW  - mechatronic hands
KW  - static interaction forces
KW  - dynamic interaction forces
KW  - Nails
KW  - Robot sensing systems
KW  - Force
KW  - Force measurement
KW  - Delays
DO  - 10.1109/IROS.2018.8594207
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Our fingernails help us to accomplish a variety of manual tasks, but surprisingly only a few robotic hands are equipped with nails. In this paper, we present a sensorized fingernail for mechatronic hands that can capture static and dynamic interaction forces with the nail. Over the course of several iterations, we have developed a very compact working prototype that fits together with our previously developed multi-cell tactile fingertip sensor into the cavity of the distal phalange of a human-sized robotic hand. We present the construction details, list the key performance characteristics and demonstrate an example application of finding the end of an adhesive tape roll using the signals captured by the sensors integrated in the nail. We conclude with a discussion about improvement ideas for future versions.
ER  - 

TY  - CONF
TI  - Pose Estimation and Map Formation with Spiking Neural Networks: towards Neuromorphic SLAM
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2159
EP  - 2166
AU  - R. Kreiser
AU  - A. Renner
AU  - Y. Sandamirskaya
AU  - P. Pienroj
PY  - 2018
KW  - mixed analogue-digital integrated circuits
KW  - mobile robots
KW  - neural nets
KW  - neurophysiology
KW  - pose estimation
KW  - SLAM (robots)
KW  - pose estimation
KW  - spiking neural networks
KW  - neuromorphic SLAM
KW  - biologically inspired neuronal path integration
KW  - mobile robot
KW  - neuronal map formation architecture
KW  - simultaneous localization and mapping
KW  - mixed signal analog-digital neuromorphic hardware
KW  - ultra low-power neuromorphic hardware
KW  - robotic vehicle simulation
KW  - on-board plasticity
KW  - Neurons
KW  - Neuromorphics
KW  - Collision avoidance
KW  - Simultaneous localization and mapping
KW  - Synapses
DO  - 10.1109/IROS.2018.8594228
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we investigate the use of ultra low-power, mixed signal analog/digital neuromorphic hardware for implementation of biologically inspired neuronal path integration and map formation for a mobile robot. We perform spiking network simulations of the developed architecture, interfaced to a simulated robotic vehicle. We then port the neuronal map formation architecture on two connected neuromorphic devices, one of which features on-board plasticity, and demonstrate the feasibility of a neuromorphic realization of simultaneous localization and mapping (SLAM).
ER  - 

TY  - CONF
TI  - Precise Localization in High-Definition Road Maps for Urban Regions
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2167
EP  - 2174
AU  - F. Poggenhans
AU  - N. O. Salscheider
AU  - C. Stiller
PY  - 2018
KW  - cameras
KW  - image resolution
KW  - Kalman filters
KW  - nonlinear filters
KW  - road vehicles
KW  - satellite navigation
KW  - stereo image processing
KW  - traffic engineering computing
KW  - high-resolution road maps
KW  - road borders
KW  - Unscented Kalman Filter
KW  - narrow urban roads
KW  - highly automated driving
KW  - precise localization
KW  - high-definition road maps
KW  - sensor specific feature layers
KW  - stereo camera
KW  - vehicle odometry
KW  - low-cost GNSS module
KW  - size 5.0 km
KW  - size 0.08 m
KW  - Roads
KW  - Global navigation satellite system
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Urban areas
KW  - Receivers
DO  - 10.1109/IROS.2018.8594414
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The future of automated driving in urban areas will most probably rely on highly accurate road maps. However, the necessary precision of a localization in such maps has so far only been reached using extra, sensor specific feature layers for localization. In this paper we want to show that it is possible to achieve sufficient accuracy without a separate localization layer. Instead, elements are used that are already contained in high-resolution road maps, such as markings and road borders. For this, we introduce a modular approach in which detections from different detection algorithms are associated with elements in the map and then fused to an absolute pose using an Unscented Kalman Filter. We evaluate our approach using a sensor setup that employs a stereo camera, vehicle odometry and a low-cost GNSS module on a 5km test route covering both narrow urban roads and multi-lane main roads under varying weather conditions. The results show that this approach is capable to be used for highly automated driving, showing an accuracy of 0.08m in typical road scenarios and a is available 98% of the time.
ER  - 

TY  - CONF
TI  - Virtual Occupancy Grid Map for Submap-based Pose Graph SLAM and Planning in 3D Environments
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2175
EP  - 2182
AU  - B. Ho
AU  - P. Sodhi
AU  - P. Teixeira
AU  - M. Hsiao
AU  - T. Kusnur
AU  - M. Kaess
PY  - 2018
KW  - graph theory
KW  - image reconstruction
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - 3D scene reconstructions
KW  - virtual occupancy grid map
KW  - mobile robots
KW  - VOG-map
KW  - submap-based pose graph SLAM
KW  - underwater SLAM system
KW  - path planning
KW  - free space information
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Path planning
KW  - Robot kinematics
KW  - Casting
DO  - 10.1109/IROS.2018.8594234
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, we propose a mapping approach that constructs a globally deformable virtual occupancy grid map (VOG-map) based on local submaps. Such a representation allows pose graph SLAM systems to correct globally accumulated drift via loop closures while maintaining free space information for the purpose of path planning. We demonstrate use of such a representation for implementing an underwater SLAM system in which the robot actively plans paths to generate accurate 3D scene reconstructions. We evaluate performance on simulated as well as real-world experiments. Our work furthers capabilities of mobile robots actively mapping and exploring unstructured, three dimensional environments.
ER  - 

TY  - CONF
TI  - Decentralized Localization Framework using Heterogeneous Map-matchings
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2183
EP  - 2189
AU  - S. Lee
AU  - J. Kim
AU  - J. Kim
AU  - G. Oh
AU  - S. W. Seo
PY  - 2018
KW  - decentralised control
KW  - mobile robots
KW  - road vehicles
KW  - sensor fusion
KW  - stability
KW  - stochastic processes
KW  - decentralized localization framework
KW  - heterogeneous map-matchings
KW  - system stability
KW  - localization methods
KW  - map matchings
KW  - stochastic situational analysis model
KW  - heterogeneous map-matching sources
KW  - dissimilar sensors
KW  - fusion methods
KW  - multienvironment sensors
KW  - single environmental sensor
KW  - autonomous driving applications
KW  - robust real-time localization
KW  - Roads
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Cameras
KW  - Feature extraction
KW  - Sensor fusion
DO  - 10.1109/IROS.2018.8593948
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Highly accurate and robust real-time localization is an essential technique for various autonomous driving applications. Numerous localization methods have been proposed that combine various types of sensors, including an environmental sensor, IMU and GPS. However, the usage of a single environmental sensor is rather fragile. Although the use of multi-environment sensors is a better alternative, fusion methods from previous studies have not adequately compensated for shortcomings in dissimilar sensors or have not considered errors in the pre-built map. In this paper, we propose a decentralized localization framework using heterogeneous map-matching sources. Decentralized localization performs two independent map-matchings and integrates them with a stochastic situational analysis model. By applying a stochastic model, the reliability of the two map matchings is collected and system stability is verified. A number of experiments with autonomous vehicles within the actual driving environment have shown that combining multiple map-matching sources ensures more robust results than the use of a single environmental sensor.
ER  - 

TY  - CONF
TI  - LDSO: Direct Sparse Odometry with Loop Closure
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2198
EP  - 2204
AU  - X. Gao
AU  - R. Wang
AU  - N. Demmel
AU  - D. Cremers
PY  - 2018
KW  - feature extraction
KW  - graph theory
KW  - mobile robots
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - intensity gradient
KW  - DSO sliding window optimization
KW  - Sim(3) relative pose constraints
KW  - image pixel
KW  - loop closure detection
KW  - monocular visual SLAM system
KW  - Direct Sparse Odometry
KW  - state-of-the-art feature-based systems
KW  - pose-graph optimization
KW  - modified point selection strategy
KW  - relative poses
KW  - co-visibility graph
KW  - 3D geometric error terms
KW  - conventional feature-based bag-of-words approach
KW  - loop closure candidates
KW  - tracking frontend
KW  - corner features
KW  - LDSO
KW  - featureless areas
KW  - Optimization
KW  - Feature extraction
KW  - Microsoft Windows
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Bundle adjustment
KW  - Robustness
DO  - 10.1109/IROS.2018.8593376
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present an extension of Direct Sparse Odometry (DSO) [1] to a monocular visual SLAM system with loop closure detection and pose-graph optimization (LDSO). As a direct technique, DSO can utilize any image pixel with sufficient intensity gradient, which makes it robust even in featureless areas. LDSO retains this robustness, while at the same time ensuring repeatability of some of these points by favoring corner features in the tracking frontend. This repeatability allows to reliably detect loop closure candidates with a conventional feature-based bag-of-words (BoW) approach. Loop closure candidates are verified geometrically and Sim(3) relative pose constraints are estimated by jointly minimizing 2D and 3D geometric error terms. These constraints are fused with a co-visibility graph of relative poses extracted from DSO's sliding window optimization. Our evaluation on publicly available datasets demonstrates that the modified point selection strategy retains the tracking accuracy and robustness, and the integrated pose-graph optimization significantly reduces the accumulated rotation-, translation- and scale-drift, resulting in an overall performance comparable to state-of-the-art feature-based systems, even without global bundle adjustment.
ER  - 

TY  - CONF
TI  - Energetic Efficiency of a Compositional Controller on a Monoped With an Articulated Leg and SLIP Dynamics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2221
EP  - 2228
AU  - J. Yu
AU  - D. Hong
AU  - M. Haberland
PY  - 2018
KW  - design engineering
KW  - energy conservation
KW  - legged locomotion
KW  - motion control
KW  - nonlinear control systems
KW  - optimal control
KW  - optimisation
KW  - pendulums
KW  - robot dynamics
KW  - springs (mechanical)
KW  - trajectory control
KW  - energetic efficiency
KW  - compositional controller
KW  - articulated leg
KW  - SLIP dynamics
KW  - dynamic legged robot locomotion control
KW  - jumping robots
KW  - Raibert-style controller
KW  - SLIP-Raibert approach
KW  - trajectory-optimized controller
KW  - robot design
KW  - spring loaded inverted pendulum
KW  - three-link monoped model
KW  - Legged locomotion
KW  - Aerospace electronics
KW  - Actuators
KW  - Dynamics
KW  - Optimization
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8593638
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Embedding the dynamics of the Spring Loaded Inverted Pendulum (SLIP) and applying a compositional controller around it can simplify dynamic legged robot locomotion control, but what is the energetic cost of this convenience? This paper measures the magnitude of this effect in such a way that the results are applicable to a wide class of jumping robots. A three-link monoped model with revolute joints is used to compare the energetic costs of locomotion using two different control approaches: 1) SLIP-embedding with a Raibert-style controller optimized for energetic efficiency, and 2) a trajectory optimized only for energetic efficiency. By performing this comparison in simulation for a large number of different monopeds randomly sampled from a space of realistic robot designs, it is found that the SLIP-Raibert approach requires, on average, almost twice the energy of the trajectory-optimized controller to traverse a given distance. Furthermore, the increase in energetic cost does not depend much on the particulars of the robot design, as the SLIP-Raibert approach requires at least 50% more energy for approximately 88% of realistic robot designs.
ER  - 

TY  - CONF
TI  - Precision Jumping Limits from Flight-phase Control in Salto-1P
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2229
EP  - 2236
AU  - J. K. Yim
AU  - R. S. Fearing
PY  - 2018
KW  - approximation theory
KW  - attitude control
KW  - control system synthesis
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - position control
KW  - robot dynamics
KW  - velocity control
KW  - running velocity
KW  - precision results
KW  - height increases
KW  - foot placement precision degrades
KW  - attitude error
KW  - attitude control accuracy
KW  - error standard deviation
KW  - random walk
KW  - aggressive changes
KW  - precise foot placement
KW  - physical platform
KW  - offline dynamic model
KW  - order Taylor series approximation
KW  - untethered monopedal robot
KW  - deadbeat foot placement
KW  - Salto-1P
KW  - flight-phase control
KW  - precision jumping limits
KW  - Foot
KW  - Legged locomotion
KW  - Trajectory
KW  - Attitude control
KW  - Mathematical model
KW  - Robot kinematics
DO  - 10.1109/IROS.2018.8594154
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We developed a deadbeat foot placement hopping controller for an untethered monopedal robot, Salto-1P. The controller uses a third order Taylor series approximation to an offline dynamic model and performs well on the physical platform. The robot demonstrated precise foot placement even on trajectories with aggressive changes in speed, direction, and height: in a random walk, its error standard deviation was 0.10 m. We establish how foot placement precision is tightly limited by attitude control accuracy, requiring attitude error less than 0.7 degrees for some tasks. We also show how foot placement precision degrades linearly as hopping height increases. These precision results apply to the large class of controllers that prescribe touchdown angle to control running velocity.
ER  - 

TY  - CONF
TI  - Analytically-Guided Design of a Tailed Bipedal Hopping Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2237
EP  - 2244
AU  - A. Shamsah
AU  - A. De
AU  - D. E. Koditschek
PY  - 2018
KW  - actuators
KW  - design engineering
KW  - legged locomotion
KW  - robot dynamics
KW  - robot kinematics
KW  - hybrid averaging analysis
KW  - conjectured closed form representation
KW  - approximate hopping limit cycle
KW  - physical control
KW  - dynamical design choices affords
KW  - tailed bipedal hopping robot
KW  - template dynamics
KW  - actuator template
KW  - spatial hopping gait
KW  - Actuators
KW  - Legged locomotion
KW  - Damping
KW  - Kinematics
KW  - Limit-cycles
KW  - Stability analysis
DO  - 10.1109/IROS.2018.8593677
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We present the first fully spatial hopping gait of a 12 DoF tailed biped driven by only 4 actuators. The control of this physical machine is built up from parallel compositions of controllers for progressively higher DoF extensions of a simple 2 DoF, 1 actuator template. These template dynamics are still not themselves integrable, but a new hybrid averaging analysis yields a conjectured closed form representation of the approximate hopping limit cycle as a function of its physical and control parameters. The resulting insight into the role of the machines kinematic and dynamical design choices affords a redesign leading to the newly achieved behavior.
ER  - 

TY  - CONF
TI  - MIT Cheetah 3: Design and Control of a Robust, Dynamic Quadruped Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2245
EP  - 2252
AU  - G. Bledt
AU  - M. J. Powell
AU  - B. Katz
AU  - J. Di Carlo
AU  - P. M. Wensing
AU  - S. Kim
PY  - 2018
KW  - actuators
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - robust control
KW  - control architecture
KW  - legged locomotion
KW  - abduction-adduction degrees
KW  - gait modification
KW  - cost of transport
KW  - CoT
KW  - proprioceptive actuation
KW  - leg design
KW  - mechanical design
KW  - dynamic quadruped robot
KW  - robust robot
KW  - MIT cheetah 3
KW  - Legged locomotion
KW  - Actuators
KW  - Torque
KW  - Force
KW  - Knee
KW  - Robot sensing systems
DO  - 10.1109/IROS.2018.8593885
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper introduces a new robust, dynamic quadruped, the MIT Cheetah 3. Like its predecessor, the Cheetah 3 exploits tailored mechanical design to enable simple control strategies for dynamic locomotion and features high-bandwidth proprioceptive actuators to manage physical interaction with the environment. A new leg design is presented that includes proprioceptive actuation on the abduction/adduction degrees of freedom in addition to an expanded range of motion on the hips and knees. To make full use of these new capabilities, general balance and locomotion controllers for Cheetah 3 are presented. These controllers are embedded into a modular control architecture that allows the robot to handle unexpected terrain disturbances through reactive gait modification and without the need for external sensors or prior environment knowledge. The efficiency of the robot is demonstrated by a low Cost of Transport (CoT) over multiple gaits at moderate speeds, with the lowest CoT of 0.45 found during trotting. Experiments showcase the ability to blindly climb up stairs as a result of the full system integration. These results collectively represent a promising step toward a platform capable of generalized dynamic legged locomotion.
ER  - 

TY  - CONF
TI  - Magneto: A Versatile Multi-Limbed Inspection Robot
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2253
EP  - 2260
AU  - T. Bandyopadhyay
AU  - R. Steindl
AU  - F. Talbot
AU  - N. Kottege
AU  - R. Dungavell
AU  - B. Wood
AU  - J. Barker
AU  - K. Hoehn
AU  - A. Elfes
PY  - 2018
KW  - actuators
KW  - design engineering
KW  - inspection
KW  - legged locomotion
KW  - manipulator kinematics
KW  - quadruped climbing robot
KW  - high dimensional system design
KW  - human entry portholes
KW  - three degrees of freedom actuated limbs
KW  - 3-DOF compliant magnetic foot
KW  - locomotion
KW  - complex 3-D structures
KW  - industrial confined spaces
KW  - body shape
KW  - multilimbed inspection robot
KW  - legged climbing robots
KW  - confined space openings
KW  - manipulation mode mid-climb
KW  - limb function
KW  - Magneto
KW  - compact foot design
KW  - Adhesives
KW  - Legged locomotion
KW  - Magnetic separation
KW  - Foot
KW  - Inspection
KW  - Soft magnetic materials
DO  - 10.1109/IROS.2018.8593891
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper we present the design and control strategies of a novel quadruped climbing robot (named Magneto) with three degrees of freedom (3-DOF) actuated limbs and a 3-DOF compliant magnetic foot. By exploiting its high degrees of freedom, Magneto is able to deform its body shape to squeeze through gaps of 23cm, which is smaller than standard human entry portholes of industrial confined spaces. Its compact foot design of footprint 4cm allows Magneto to walk on narrow beams of thickness less than 5cm, even at varying separation. The inherent high dimensional system design enables the body to be positioned in a wide range of orientations and seamlessly switch a limb function from locomotion to manipulation mode mid-climb. This capability enables access to confined space openings and occluded pockets and navigation through complex 3-D structures previously not demonstrated on legged climbing robots.
ER  - 

TY  - CONF
TI  - Data-Driven Discrete Planning for Targeted Hopping of Compliantly Actuated Robotic Legs
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2261
EP  - 2266
AU  - D. Seidel
AU  - D. Lakatos
AU  - A. Albu-Schäffer
PY  - 2018
KW  - actuators
KW  - elasticity
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - robot dynamics
KW  - planar hopping leg prototype validate
KW  - hopping trials
KW  - data-driven manner
KW  - serial elastic actuation
KW  - planar leg
KW  - discrete-time planning problem
KW  - simple controller structure
KW  - time-continuous trajectories
KW  - considerable real-time problems
KW  - fast locomotion
KW  - motion planning
KW  - compliantly actuated robotic legs
KW  - targeted hopping
KW  - data-driven discrete planning
KW  - Legged locomotion
KW  - Planning
KW  - Springs
KW  - Switches
KW  - Hardware
DO  - 10.1109/IROS.2018.8593819
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Motion planning for fast locomotion of compliantly actuated robotic legs is generally considered to be a challenging issue, posing considerable real-time problems. This is at least the case if time-continuous trajectories need to be generated online. In this paper we take advantage of a simple controller structure, which reduces the motion planning to a discrete-time planning problem, in which only a small set of input parameters need to be determined for each step. We show that for a planar leg with serial elastic actuation, hopping on a ground with stairs of irregular length and height can be planned online, based on a parameter mapping which has been learned in a data-driven manner by performing hopping trials with an adaptive exploration algorithm to evenly sample the parameter space. Experiments on a planar hopping leg prototype validate the approach.
ER  - 

TY  - CONF
TI  - Quadrupedal walking motion and footstep placement through Linear Model Predictive Control
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2267
EP  - 2273
AU  - A. Laurenzi
AU  - E. M. Hoffman
AU  - N. G. Tsagarakis
PY  - 2018
KW  - convex programming
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - predictive control
KW  - robot dynamics
KW  - linear model predictive control framework
KW  - quadrupedal walking motion
KW  - auxiliary states
KW  - bipedal locomotion
KW  - hybrid wheeled-legged quadruped
KW  - humanoid upper-body
KW  - joint optimization problem
KW  - nonconvex programming framework
KW  - quadrupedal robot
KW  - automatic footstep placement
KW  - walking gait
KW  - CENTAURO robot
KW  - control inputs
KW  - linear constraints
KW  - approximate QP
KW  - Legged locomotion
KW  - Robot kinematics
KW  - Optimization
KW  - Stability analysis
KW  - Planning
DO  - 10.1109/IROS.2018.8593692
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - The present work addresses the generation of a walking gait with automatic footstep placement for a quadrupedal robot, within a Linear Model Predictive Control framework. Existing work has shown how this is only possible within a non-convex programming framework, finding a solution of which is well-known to be very hard. We propose a way to formulate the joint optimization problem as an approximate QP with linear constraints, whose global optimum can be quickly found with off-the-shelf solvers. More specifically, this is done by introducing auxiliary states and control inputs, each of which is subject to linear constraints that are inspired from the literature on bipedal locomotion. Finally, we validate our method on the CENTAURO robot, a hybrid wheeled-legged quadruped with a humanoid upper-body.
ER  - 

TY  - CONF
TI  - A Synergetic Voluntary Control for Exoskeleton based on Spinal Cord Mapping of Peripheral Bioelectric Activity
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2274
EP  - 2279
AU  - S. Ishikawa
AU  - H. Kadone
AU  - K. Suzuki
PY  - 2018
KW  - bioelectric phenomena
KW  - electromyography
KW  - gait analysis
KW  - injuries
KW  - matrix decomposition
KW  - medical robotics
KW  - neurophysiology
KW  - patient rehabilitation
KW  - synergetic voluntary control
KW  - spinal cord mapping
KW  - peripheral bioelectric activity
KW  - voluntary motion intention
KW  - control method
KW  - exoskeleton robot control
KW  - voluntary lower limb muscle activities
KW  - spinal cord injury
KW  - muscle synergy
KW  - walking motion
KW  - spinal cord map level
KW  - reliable cord levels
KW  - unreliable spinal cord levels
KW  - maximally voluntary locomotion
KW  - whole-body muscle activity
KW  - intended lower limb muscle activity
KW  - spinal cord activity
KW  - walking rehabilitation
KW  - nonnegative matrix factorization
KW  - transformation matrix
KW  - hybrid assistive limb
KW  - walking experiments
KW  - Muscles
KW  - Legged locomotion
KW  - Spinal cord
KW  - Exoskeletons
KW  - Robot kinematics
KW  - Estimation
DO  - 10.1109/IROS.2018.8593695
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Walking rehabilitation must be performed based on voluntary motion intention, and for this purpose, the development of a control method for an exoskeleton robot based on voluntary intention is investigated. This study proposes a method of exoskeleton robot control to estimate the voluntary lower limb muscle activities lost after a spinal cord injury (SCI). This method is based on the spinal cord mapping of the remaining muscle activities and its matching to the one obtained from healthy participants considering the muscle synergy of the whole body during the walking motion. By implementing the matching procedure at the spinal cord map level and incorporating information of reliable and unreliable spinal cord levels based on a diagnosis, the method has the potential to provide a maximally voluntary locomotion for people with SCI. We report an analysis of the synergy of the whole-body muscle activity during walking and its spinal cord mapping using non-negative matrix factorization and the computation of the transformation matrix to estimate the intended lower limb muscle activity from the remaining spinal cord activity. The implementation of the proposed method using the right leg of the hybrid assistive limb and walking experiments with a healthy participant are also reported.
ER  - 

TY  - CONF
TI  - Learning-based Walking Assistance Control Strategy for a Lower Limb Exoskeleton with Hemiplegia Patients
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2280
EP  - 2285
AU  - R. Huang
AU  - Z. Peng
AU  - H. Cheng
AU  - J. Hu
AU  - J. Qiu
AU  - C. Zou
AU  - Q. Chen
PY  - 2018
KW  - adaptive control
KW  - dynamic programming
KW  - gait analysis
KW  - handicapped aids
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - motion control
KW  - multi-agent systems
KW  - patient rehabilitation
KW  - hemiplegia patient
KW  - lower limb exoskeleton
KW  - learning-based walking assistance control strategy
KW  - paraplegia patients
KW  - leader-follower multi-agent system
KW  - LF-MAS
KW  - reinforcement learning framework
KW  - policy iteration adaptive dynamic programming algorithm
KW  - PI-ADP algorithm
KW  - tracking control
KW  - Legged locomotion
KW  - Exoskeletons
KW  - Reinforcement learning
KW  - Control systems
KW  - Heuristic algorithms
KW  - Multi-agent systems
KW  - Cost function
KW  - Walking Assistance Strategy
KW  - Leader-Follower Multi-Agent System
KW  - Reinforcement Learning
KW  - Lower Exoskeleton
KW  - Hemiplegia
DO  - 10.1109/IROS.2018.8594464
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Lower exoskeleton has gained considerable interests in walking assistance applications for both paraplegia and hemiplegia patients. In walking assistance of hemiplegia patients, the exoskeleton should have the ability to control the affected leg to follow the unaffected leg's motion naturally. One critical issue of walking assistance for hemiplegia patients is how to adapt the controller of both lower limbs with different patients. This paper presents a novel learning-based walking assistance control strategy for lower exoskeleton with hemiplegia patients. In the proposed control strategy, we modeled the control system of lower exoskeleton with hemiplegia patient as a Leader-Follower Multi-Agent System (LF-MAS). In order to adapt different patients with different conditions, reinforcement learning framework is utilized to adapt controllers online. In reinforcement learning framework with LF-MAS, we employed a Policy Iteration Adaptive Dynamic Programming (PI-ADP) algorithm, which aims to achieve better tracking control performance for lower exoskeleton with hemiplegia patient. We demonstrate the efficiency of proposed learning-based walking assistance control strategy in an exoskeleton system with healthy subjects who simulate hemiplegia patients. Experimental results indicate that the proposed control strategy can adapt different pilots with good tracking performance.
ER  - 

TY  - CONF
TI  - Similarity of the Impact of Humanoid and In-Person Communications on Frontal Brain Activity of Older People
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2286
EP  - 2291
AU  - S. Keshmiri
AU  - H. Sumioka
AU  - R. Yamazaki
AU  - M. Okubo
AU  - H. Ishiguro
PY  - 2018
KW  - brain
KW  - geriatrics
KW  - handicapped aids
KW  - humanoid robots
KW  - human-robot interaction
KW  - medical robotics
KW  - older people
KW  - in-person communication
KW  - brain information
KW  - frontal brain activity
KW  - humanoid robot
KW  - video-chat
KW  - speaker
KW  - brain activation
KW  - storytelling experiment
KW  - sensory gateway
KW  - behavioural responses
KW  - human-robot interaction
KW  - Brain
KW  - Humanoid robots
KW  - Time series analysis
KW  - Media
KW  - Senior citizens
KW  - Data acquisition
DO  - 10.1109/IROS.2018.8594521
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - We report results of the analyses of the effect of communication through a humanoid robot in comparison with in-person, video-chat, and speaker on frontal brain activity of older people during an storytelling experiment. Our results suggest that whereas communicating through a physically embodied medium potentially induces a significantly higher pattern of brain activation with respect to video-chat and speaker, its difference is non-significant in comparison with in-person communication. These results imply that communicating through a humanoid robot induces a pattern of brain activity in older people that is potentially similar to in-person communication. Our findings benefit researchers and practitioners in rehabilitation and elderly care facilities in search of effective means of communication with their patients to increase their involvement in the incremental steps of their treatments. Moreover, they imply the utility of brain information as a promising sensory gateway in characterization of the behavioural responses in human-robot interaction.
ER  - 

TY  - CONF
TI  - A Phase Variable Approach to Volitional Control of Powered Knee-Ankle Prostheses
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2292
EP  - 2298
AU  - S. Rezazadeh
AU  - D. Quintero
AU  - N. Divekar
AU  - R. D. Gregg
PY  - 2018
KW  - artificial limbs
KW  - finite state machines
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - motion control
KW  - trajectory control
KW  - volitional control
KW  - powered knee-ankle prostheses
KW  - multijoint prosthetic legs
KW  - periodic walking
KW  - piecewise holonomic phase variable
KW  - finite state machine
KW  - nominal reference gait trajectory
KW  - high-speed walking
KW  - backward walking
KW  - phase variable approach
KW  - volitional leg motions
KW  - Legged locomotion
KW  - Thigh
KW  - Trajectory
KW  - Task analysis
KW  - Prosthetics
KW  - Sensors
KW  - Foot
DO  - 10.1109/IROS.2018.8594023
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Although there has been recent progress in control of multi-joint prosthetic legs for periodic tasks such as walking, volitional control of these systems for non-periodic maneuvers is still an open problem. In this paper, we develop a new controller that is capable of both periodic walking and common volitional leg motions based on a piecewise holonomic phase variable through a finite state machine. The phase variable is constructed by measuring the thigh angle, and the transitions in the finite state machine are formulated through sensing foot contact together with attributes of a nominal reference gait trajectory. The controller was implemented on a powered knee-ankle prosthesis and tested with a transfemoral amputee subject, who successfully performed a wide range of periodic and non-periodic tasks, including low- and high-speed walking, quick start and stop, backward walking, walking over obstacles, and kicking a soccer ball. The proposed approach is expected to provide better understanding of volitional motions and lead to more reliable control of multi-joint prostheses for a wider range of tasks.
ER  - 

TY  - CONF
TI  - Pre-clinical validation of the UHP multifunctional upper-limb rehabilitation robot based platform
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2299
EP  - 2304
AU  - A. Mancisidor
AU  - A. Zubizarreta
AU  - I. Cabanes
AU  - A. Brull
AU  - A. Rodriguez
AU  - J. H. Jung
PY  - 2018
KW  - biomechanics
KW  - force control
KW  - medical robotics
KW  - patient rehabilitation
KW  - position control
KW  - robotic device interacts
KW  - pre-clinical validation
KW  - upper-limb rehabilitation robotic platform
KW  - UHP multifunctional upper-limb rehabilitation robot
KW  - rehabilitation therapies
KW  - UHP rehabilitation robot
KW  - multifunctional device
KW  - robotized therapies
KW  - advanced position-force control approaches
KW  - Rehabilitation robotics
KW  - Training
KW  - Games
KW  - Software
KW  - Robot sensing systems
KW  - Elbow
DO  - 10.1109/IROS.2018.8593527
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Interest in robotic devices for rehabilitation has increased in the last years, due to the increasing number of patients that require rehabilitation therapies, and the need to optimize existing resources. The UHP rehabilitation robot is a multifunctional device that allows to execute robotized therapies for the upper-limb using a simple pantograph based reconfigurable structure and the implementation of advanced position/force control approaches. However, in applications such as rehabilitation, where the robotic device interacts directly with the user, complying with the demands of the users is as important as complying with the functional requirements. Otherwise, the patient will reject the robotic device. Therefore, in this work the pre-clinical validation of the UHP upper-limb rehabilitation robotic platform is presented. 25 subjects of different physical characteristics have participated in the evaluation of the device, evaluating not only the correct behaviour of the device, but also its safety and adaptativity. Results show the correct behaviour of the platform, and a good acceptance rate of the device.
ER  - 

TY  - CONF
TI  - Cable Actuated Dexterous (CADEX) Glove for Effective Rehabilitation of the Hand for Patients with Neurological diseases
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2305
EP  - 2310
AU  - D. H. Kim
AU  - H. Park
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - bone
KW  - dexterous manipulators
KW  - diseases
KW  - medical disorders
KW  - medical robotics
KW  - neurophysiology
KW  - patient rehabilitation
KW  - decoupled opposition-reposition
KW  - functional recovery
KW  - CADEX glove
KW  - consistent motion
KW  - actuated cables
KW  - exotendons
KW  - dexterous motion
KW  - carpometacarpal joint
KW  - simple thumb motions
KW  - compact design
KW  - soft robotic devices
KW  - wearable robotic devices
KW  - hands
KW  - larger motor cortical area
KW  - recovery motor function
KW  - motor cortex
KW  - neuroplastic change
KW  - neurological disease
KW  - effective rehabilitation
KW  - cable actuated dexterous glove
KW  - Thumb
KW  - Force
KW  - Routing
KW  - Silicon
KW  - Tendons
KW  - IP networks
DO  - 10.1109/IROS.2018.8594336
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - Neuroplastic changes in motor cortex is essential for the recovery motor function of patients with neurological diseases. To enlarge neuroplastic change, various movements should be provided to stimulate larger motor cortical area, and because hands occupy the largest area, it is especially important. Many wearable robotic devices have been developed for rehabilitation of the hand, and soft robotic devices in particular have drawn attention for their compact design. However, most soft devices provide simple thumb motions, which flex or extend all joints without assistance of opposition/reposition of the carpometacarpal joint although the importance in producing various grasps. In this study, the design of a cable actuated dexterous (CADEX) glove is proposed. For dexterous motion, the structure and orientation of major finger tendons were replicated with exotendons (actuated cables), and four exotendons were used for the thumb with the path optimized to provide flexion/extension of the thumb and decoupled opposition/reposition of the carpometacarpal with other joints. To provide consistent motion, silicon was used for stable anchoring of exotendons while preventing slippage and reducing deformation. The motion generated by the CADEX glove was experimentally evaluated for a single healthy subject. The result shows that the CADEX glove could flex and extend the finger with various ratios among joints, and the opposition/reposition of carpometacarpal joint of the thumb could be achieved consistently with minimal effect on the other joints. The CADEX glove is expected to help providing various tasks which is expected to enhance the functional recovery of patients with neurological disease.
ER  - 

TY  - CONF
TI  - Modified Adaptive Control of an Actuated Ankle Foot Orthosis to assist Paretic Patients
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2311
EP  - 2317
AU  - V. Arnez-Paniagua
AU  - H. Rifaï
AU  - Y. Amirat
AU  - S. Mohammed
AU  - M. Ghedira
AU  - J. M. Gracies
PY  - 2018
KW  - actuators
KW  - closed loop systems
KW  - gait analysis
KW  - Lyapunov methods
KW  - medical control systems
KW  - model reference adaptive control systems
KW  - muscle
KW  - orthotics
KW  - stability
KW  - modified adaptive control
KW  - actuated ankle foot orthosis
KW  - saturated proportional derivative action
KW  - active ankle foot orthosis
KW  - classical model-based controllers
KW  - prior estimation
KW  - AAFO system
KW  - residual human torque
KW  - ankle joint
KW  - ankle reference trajectory
KW  - AAFO-wearer system
KW  - bounded human muscular torque
KW  - model reference adaptive control
KW  - AAFO actuator
KW  - paretic patient gait
KW  - self-selected walking speed
KW  - Lyapunov analysis
KW  - closed-loop
KW  - gait cycle
KW  - input-to-state stability
KW  - Torque
KW  - Foot
KW  - Legged locomotion
KW  - Lyapunov methods
KW  - Adaptation models
KW  - Trajectory
KW  - Muscles
DO  - 10.1109/IROS.2018.8594046
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - In this paper, a model reference adaptive control with saturated proportional derivative (PD) action for an active ankle foot orthosis (AAFO) to assist the gait of paretic patients, is studied. Unlike most classical model-based controllers, the proposed controller does not require any prior estimation of the system's model parameters. The AAFO system is actively driven by the residual human torque delivered by muscles spanning the ankle joint and the AAFO's actuator's torque. The ankle reference trajectory is updated online based on the self-selected walking speed of the wearer. The input-to-state stability of the AAFO-wearer system with respect to a bounded human muscular torque is proved in closed-loop based on a Lyapunov analysis. Experimental results, obtained from one healthy subject and one paretic patient, show satisfactory results in terms of tracking performance and ankle joint assistance throughout the full gait cycle.
ER  - 

TY  - CONF
TI  - SMA based wrist exoskeleton for rehabilitation therapy*
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2318
EP  - 2323
AU  - D. Serrano
AU  - D. Copaci
AU  - L. Moreno
AU  - D. Blanco
PY  - 2018
KW  - biomechanics
KW  - electroactive polymer actuators
KW  - medical robotics
KW  - patient rehabilitation
KW  - pneumatic actuators
KW  - shape memory effects
KW  - wearable robots
KW  - SMA based wrist exoskeleton
KW  - rehabilitation therapy
KW  - rehabilitation wearable exoskeleton
KW  - wrist joint
KW  - flexion-extension
KW  - adduction-abduction
KW  - Shape Memory Alloy based actuators
KW  - SMA actuator technology
KW  - rehabilitation robotic devices
KW  - Wrist
KW  - Actuators
KW  - Exoskeletons
KW  - Wires
KW  - Medical treatment
KW  - Robots
KW  - Biological system modeling
DO  - 10.1109/IROS.2018.8593987
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper presents a rehabilitation wearable exoskeleton for wrist joint with two degrees of freedom (DOF), flexion-extension and adduction-abduction (radial and ulnar deviation), actuated with Shape Memory Alloy (SMA) based actuators. Thanks to this type of actuators, the proposed device presents a very light weight and noiseless operation, in comparison with similar devices. The preliminary results obtained over real tests with the wrist exoskeleton are presented. This prototype demonstrates that SMA actuator technology is a viable alternative when investigating possible improvement of rehabilitation robotic devices in terms of weight, size and cost.
ER  - 

TY  - CONF
TI  - Utility Model Re-description within a Motivational System for Cognitive Robotics
T2  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
SP  - 2324
EP  - 2329
AU  - A. Romero
AU  - F. Bellas
AU  - A. Prieto
AU  - R. J. Duro
PY  - 2018
KW  - cognition
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - motivational system
KW  - cognitive architecture
KW  - interaction traces
KW  - robotic setup
KW  - cognitive robotics
KW  - value functions
KW  - redescriptive approach
KW  - utility model redescription
KW  - precise utility models
KW  - MotivEn model
KW  - robot coordination
KW  - Robot sensing systems
KW  - Cognitive systems
KW  - Robot kinematics
KW  - Space exploration
KW  - Instruments
KW  - Drives
DO  - 10.1109/IROS.2018.8593799
JO  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
IS  - 
SN  - 2153-0866
VO  - 
VL  - 
JA  - 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
Y1  - 1-5 Oct. 2018
AB  - This paper describes a re-descriptive approach to the efficient acquisition of ever higher level and more precise utility models within the motivational system (MotivEn) of a cognitive architecture. The approach is based on a two-step process whereby, as a first step, simple imprecise sensor correlation related utility models are obtained from the interaction traces of the robot. These utility models allow the robot to increase the frequency of achieving goals, and thus, provide lots of traces that can be used to try to train precise value functions implemented as artificial neural networks. The approach is tested experimentally on a real robotic setup that involves the coordination of two robots.
ER  - 


