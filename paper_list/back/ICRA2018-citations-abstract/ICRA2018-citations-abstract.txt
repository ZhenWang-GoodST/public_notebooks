TY  - CONF
TI  - Welcome Message from the General Chair
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 2
AU  - A. Zelinsky
PY  - 2018
DO  - 10.1109/ICRA.2018.8461171
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - On behalf of the ICRA 2018 Organising Committee we extend a warm welcome to the world's foremost conference in robotics & automation, where you will be in the company of the best and brightest researchers and engineers from around our planet! ICRA started in 1984 and has become the leading international conference attended by thousands. The conference has played a leading role in shaping the future of robotics and automation. There has never been a better time than now to be working in robotics and automation field. Today we are witnessing explosive growth in the field with significant opportunities for both research and industry. ICRA is the meeting place where science, technology, innovation comes together to understand the latest advances in order to push for the next frontiers of development. As our technology matures and takes its place amongst the everyday lives of people it is important that this is done in a considered, safe and ethical manner.
ER  - 

TY  - CONF
TI  - ICRA 2018 Program Chair Report
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 3
AU  - P. Corke
PY  - 2018
DO  - 10.1109/ICRA.2018.8461126
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This year a record number of papers were submitted directly to ICRA (1981) and to RA-L with the ICRA option (605). This represents an increase of 4% and 48% over last year respectively - clearly the RA-L/ICRA option is growing in popularity. The long-term average is a growth rate of around 60 papers per year. The submission process accommodated, as much as possible, the hardships inflicted on authors by hurricanes and earthquakes in the days prior to the deadline.
ER  - 

TY  - CONF
TI  - Organizing Committee
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 12
PY  - 2018
DO  - 10.1109/ICRA.2018.8460932
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Provides a listing of current committee members and society officers.
ER  - 

TY  - CONF
TI  - Conference Editorial Committee
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 48
PY  - 2018
DO  - 10.1109/ICRA.2018.8460808
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Provides a listing of current committee members and society officers.
ER  - 

TY  - CONF
TI  - Plenary and Keynote Talks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 20
PY  - 2018
DO  - 10.1109/ICRA.2018.8460801
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Plenary Talks
ER  - 

TY  - CONF
TI  - Awards
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 8
PY  - 2018
DO  - 10.1109/ICRA.2018.8460803
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - ICRA 2018 will support the following awards
ER  - 

TY  - CONF
TI  - ICRA 2018 Youtube Channel
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 1
PY  - 2018
DO  - 10.1109/ICRA.2018.8461158
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - ICRA 2018 Youtube Channel
ER  - 

TY  - CONF
TI  - Workshops & Tutorials
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 3
PY  - 2018
KW  - Conferences
KW  - Tutorials
KW  - Service robots
KW  - Machine learning
KW  - Soft robotics
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460509
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Full Day Workshops & Tutorials
ER  - 

TY  - CONF
TI  - Sponsors and Exhibitors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 7
PY  - 2018
DO  - 10.1109/ICRA.2018.8460540
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We thank all sponsors for their generous support and contribution.
ER  - 

TY  - CONF
TI  - Automatic Optimized 3D Path Planner for Steerable Catheters with Heuristic Search and Uncertainty Tolerance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9
EP  - 16
AU  - A. Favaro
AU  - L. Cerri
AU  - S. Galvan
AU  - F. R. Y. Baena
AU  - E. De Momi
PY  - 2018
KW  - catheters
KW  - drugs
KW  - medical robotics
KW  - needles
KW  - path planning
KW  - surgery
KW  - RRT-Connect
KW  - sample-based algorithms
KW  - obstacle occupancy
KW  - insertion procedure
KW  - catheter modeling
KW  - asymptotically-optimal solution
KW  - BIT* algorithm
KW  - sample-based heuristic search
KW  - drug delivery
KW  - multisegment steerable probe
KW  - programmable bevel-tip needle
KW  - EDEN2020
KW  - neurosurgeon
KW  - minimally invasive neurosurgery
KW  - automatic planner
KW  - steerable catheters
KW  - Neurosurgery
KW  - Catheters
KW  - Three-dimensional displays
KW  - Kinematics
KW  - Needles
KW  - Planning
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8461262
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, an automatic planner for minimally invasive neurosurgery is presented. The solution provides the neurosurgeon with the best path to connect a user-defined entry point with a target in accordance with a specific cost function. The approach guarantees the avoidance of obstacles which can be found along the insertion pathway. The method is tailored to the EDEN2020* programmable bevel-tip needle, a multisegment steerable probe intended to be used to perform drug delivery for the treatment of glioblastomas. A sample-based heuristic search inspired by the BIT* algorithm is used to define the asymptotically-optimal solution in terms of path length, followed by a smoothing phase to meet the required kinematic constraints of the needle. To account for inaccuracies in catheter modeling, which could determine unexpected control errors over the insertion procedure, an uncertainty margin is defined in order to increase the algorithm's safety. The feasibility of the proposed solution was demonstrated by testing the method in simulated neurosurgical scenarios with different degrees of obstacle occupancy and against other sample-based algorithms present in literature: RRT, RRT* and an enhanced version of the RRT-Connect.
ER  - 

TY  - CONF
TI  - Design and kinematics characterization of a laser-profiled continuum manipulator for the guidance of bronchoscopic instruments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 25
EP  - 31
AU  - N. Liu
AU  - M. E. M. K. Abdelaziz
AU  - M. Shen
AU  - G. Yang
PY  - 2018
KW  - dexterous manipulators
KW  - diseases
KW  - lung
KW  - manipulator kinematics
KW  - medical robotics
KW  - patient treatment
KW  - kinematics characterization
KW  - laser-profiled continuum manipulator
KW  - bronchoscopic instruments
KW  - bronchoscopic intervention
KW  - minimally invasive method
KW  - lung diseases
KW  - endobronchial instruments
KW  - peripheral airways
KW  - precision laser profiling
KW  - commercial bronchoscopes
KW  - distal airways
KW  - kinematic models
KW  - manipulator configuration
KW  - actuation wires
KW  - manipulator joints
KW  - instrument guidance robot
KW  - wire-driven dexterous manipulator
KW  - Manipulators
KW  - Wires
KW  - Instruments
KW  - Electron tubes
KW  - Surgery
KW  - Kinematics
DO  - 10.1109/ICRA.2018.8460849
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Bronchoscopic intervention, as a minimally invasive method for the diagnosis and treatment of lung diseases, has attracted more and more attention in recent years. However, existing endobronchial instruments lack the steerability accessing the peripheral airways with difficult bifurcations. This paper presents a novel wire-driven dexterous manipulator for the guidance of such instruments. Precision laser profiling is used to cut a stainless steel tube into multiple interlocked segments with revolute joints. The outer diameter of the manipulator is 2.20 mm which is small enough to be inserted into the working channels of most commercial bronchoscopes and distal airways, while keeping a large inner lumen with a diameter of 1.44 mm for passing various bronchoscopic instruments. The small bending radius provides enough flexibility to navigate inside the complex bronchial tree. Two kinematic models are proposed to predict the manipulator configuration from the translation of actuation wires. The former model is geometrically derived with the assumption of constant curvature bending and the latter one is statistically driven by capturing the motion trajectories of manipulator joints. A prototype of our low-cost add-on instrument guidance robot for bronchoscopic intervention is presented which can be easily integrated into current clinical routine.
ER  - 

TY  - CONF
TI  - Design, Modeling and Control of a 2-DoF Robotic Guidewire
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 32
EP  - 37
AU  - Y. Chitalia
AU  - X. Wang
AU  - J. P. Desai
PY  - 2018
KW  - actuators
KW  - blood vessels
KW  - catheters
KW  - diseases
KW  - medical robotics
KW  - surgery
KW  - two-degree-of-freedom robotic guidewire
KW  - joints laser micromachining
KW  - Nitinol tube
KW  - catheters
KW  - arteries
KW  - tendon force
KW  - shape sensing mechanism
KW  - peripheral arterial disease
KW  - size 0.78 mm
KW  - Tendons
KW  - Electron tubes
KW  - Arteries
KW  - Catheters
KW  - Robot kinematics
KW  - Kinematics
DO  - 10.1109/ICRA.2018.8462694
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In most cases of peripheral arterial disease (PAD), the operating surgeon must use a variety of catheters riding on a thin wire known as a `guidewire'. This guidewire must be manually navigated through a tortuous pathway of arteries to arrive at the diseased area. Automation of the guidewire therefore reduces surgeon effort and minimizes the time required for a PAD procedure, but is restricted by the size constraints of a standard guidewire. This work presents the design of a robotically actuated 2 degree-of-freedom (DoF) guidewire tip comprised of joints laser micro-machined into a 0.78 mm (<; 2.4 Fr) Nitinol tube. We present an analysis of the notch joint used as a building block in the robot and a control strategy for this type of a joint. The experimental results show that tendon force is an important observable quantity that can be used as a shape sensing mechanism for this type of a joint in practical control applications.
ER  - 

TY  - CONF
TI  - A Self-propelled Catheter Capable of Generating Travelling Waves with Steering Function by Mono-Line Drive
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 38
EP  - 43
AU  - H. Tsukagoshi
AU  - K. Terashima
AU  - Y. Takai
PY  - 2018
KW  - catheters
KW  - muscle
KW  - pneumatic actuators
KW  - catheter capable
KW  - branch pipe
KW  - McKibben chambers
KW  - inner tube equips
KW  - travelling waves
KW  - McKibben artificial muscles
KW  - bronchi
KW  - moving steering
KW  - mono-line drive
KW  - steering function
KW  - Electron tubes
KW  - Propulsion
KW  - Muscles
KW  - Actuators
KW  - Catheters
KW  - Prototypes
DO  - 10.1109/ICRA.2018.8461159
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper discusses the design method of a self-propelled catheter with thin diameter of 2.6mm, aimed for moving and steering in the bronchi. As the basic configuration, the proposed catheter is composed of an inner tube and McKibben artificial muscles. It can propel by generating travelling waves by a single supply line driven by pneumatics. Since the inner tube equips with orifices of different size, several McKibben chambers can deform with the time delay. We also propose the method to steer the direction at the branch pipe, whose angle can be adjusted by PWM control of pressuring. Besides, we also introduce the design method of how to deal with the pipes with different diameters. The validity of these proposed methods are verified by the prototype through the experiments in the bronchial model.
ER  - 

TY  - CONF
TI  - Towards a Modular Suturing Catheter for Minimally Invasive Vascular Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 44
EP  - 49
AU  - E. H. Murai
AU  - S. Homer-Vanniasinkam
AU  - P. G. Silveira
AU  - J. S. Dai
AU  - D. Martins
AU  - H. A. Wurdemann
PY  - 2018
KW  - blood vessels
KW  - cardiovascular system
KW  - catheters
KW  - diseases
KW  - phantoms
KW  - stents
KW  - surgery
KW  - electromagnetic connector
KW  - phantom vessel
KW  - silicone material
KW  - single-sided suturing catheter
KW  - open surgery
KW  - abdominal aortic aneurysm treatment
KW  - endovascular aneurysm repair
KW  - minimally invasive vascular surgery
KW  - modular suturing catheter
KW  - suturing module
KW  - abdominal aorta
KW  - stent graft migration
KW  - general anesthesia
KW  - Catheters
KW  - Needles
KW  - Arteries
KW  - Surgery
KW  - Prototypes
KW  - Yarn
KW  - Shafts
DO  - 10.1109/ICRA.2018.8460823
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Endovascular aneurysm repair (EVAR) is a minimally invasive approach for abdominal aortic aneurysm (AAA) treatment. Compared to open surgery, the benefits of EVAR include faster recovery and shorter time in hospital as well as no general anesthesia (in most cases). Though EVAR has become a preferred way to treat AAA with an increasing number of procedures, there are persisting complications, e.g. stent graft migration. Suturing the stent graft to the aorta increases the displacement force necessary to move the implant. This paper describes the design of a suturing catheter for EVAR. The suturing device consist of two modules which can be inserted through the femoral arteries into the abdominal aorta where both join using an electro-magnetic connector. The positioning module provides an anchor inside the aorta for the suturing module and new sequential positions for each stitch. Our large-scale prototype is validated inside a phantom vessel made of silicone material. We are able to successfully prove the concept of this novel single-sided suturing catheter for EVAR.
ER  - 

TY  - CONF
TI  - An Observer-Based Fusion Method Using Multicore Optical Shape Sensors and Ultrasound Images for Magnetically-Actuated Catheters
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 50
EP  - 57
AU  - A. Denasi
AU  - F. Khan
AU  - K. J. Boskma
AU  - M. Kaya
AU  - C. Hennersperger
AU  - R. Göbl
AU  - M. Tirindelli
AU  - N. Navab
AU  - S. Misra
PY  - 2018
KW  - biomedical ultrasonics
KW  - catheters
KW  - endoscopes
KW  - feedforward neural nets
KW  - image fusion
KW  - Kalman filters
KW  - medical image processing
KW  - medical robotics
KW  - observers
KW  - state estimation
KW  - surgery
KW  - multicore optical shape sensors
KW  - ultrasound images
KW  - magnetically-actuated catheters
KW  - minimally invasive surgery
KW  - flexible medical instruments
KW  - endoscopes
KW  - magnetically actuated catheters
KW  - steering precision
KW  - conventional catheters
KW  - actuation method
KW  - accurate tip position
KW  - precise control
KW  - robust sensor fusion algorithm
KW  - template-based tracker
KW  - convolutional neural network based tracker
KW  - observer-based fusion
KW  - Euclidean error
KW  - Luenberger observer
KW  - Kalman filter
KW  - Catheters
KW  - Fiber gratings
KW  - Optical sensors
KW  - Shape
KW  - Multicore processing
DO  - 10.1109/ICRA.2018.8462695
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Minimally invasive surgery involves using flexible medical instruments such as endoscopes and catheters. Magnetically actuated catheters can provide improved steering precision over conventional catheters. However, besides the actuation method, an accurate tip position is required for precise control of the medical instruments. In this study, the tip position obtained from transverse 2D ultrasound images and multicore optical shape sensors are combined using a robust sensor fusion algorithm. The tip position is tracked in the ultrasound images using a template-based tracker and a convolutional neural network based tracker, respectively. Experimental results for a rhombus path are presented, where data obtained from both tracking sources are fused using Luenberger and Kalman state estimators. The mean and standard deviation of the Euclidean error for the Luenberger observer is 0.2 ± 0.11 [mm] whereas for the Kalman filter it is 0.18 ± 0.13 [mm], respectively.
ER  - 

TY  - CONF
TI  - Reflection-Aware Sound Source Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 66
EP  - 73
AU  - I. An
AU  - M. Son
AU  - D. Manocha
AU  - S. Yoon
PY  - 2018
KW  - acoustic signal processing
KW  - array signal processing
KW  - microphone arrays
KW  - mobile robots
KW  - Monte Carlo methods
KW  - ray tracing
KW  - direct acoustic paths
KW  - direct sound signal
KW  - 3D sound localization
KW  - single frame
KW  - reflected acoustic paths
KW  - 3D sound source position
KW  - nonline-of-sight sound source
KW  - mobile sound source
KW  - localization accuracy
KW  - mobile source
KW  - intermittent sound signals
KW  - cube-shaped microphone array
KW  - Monte Carlo localization
KW  - inverse acoustic ray tracing
KW  - indirect sound signals
KW  - stationary source
KW  - continuous sound signals
KW  - indoor environments
KW  - reflection-aware method
KW  - reflection-aware sound source localization
KW  - direct acoustic rays
KW  - time 3.0 d
KW  - size 0.8 m
KW  - size 7.0 m
KW  - size 3.0 m
KW  - Acoustics
KW  - Ray tracing
KW  - Microphone arrays
KW  - Three-dimensional displays
KW  - Robots
KW  - Indoor environments
DO  - 10.1109/ICRA.2018.8461268
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a novel, reflection-aware method for 3D sound localization in indoor environments. Unlike prior approaches, which are mainly based on continuous sound signals from a stationary source, our formulation is designed to localize the position instantaneously from signals within a single frame. We consider direct sound and indirect sound signals that reach the microphones after reflecting off surfaces such as ceilings or walls. We then generate and trace direct and reflected acoustic paths using inverse acoustic ray tracing and utilize these paths with Monte Carlo localization to estimate a 3D sound source position. We have implemented our method on a robot with a cube-shaped microphone array and tested it against different settings with continuous and intermittent sound signals with a stationary or a mobile source. Across different settings, our approach can localize the sound with an average distance error of 0.8 m tested in a room of 7 m by 7 m area with 3 m height, including a mobile and non-line-of-sight sound source. We also reveal that the modeling of indirect rays increases the localization accuracy by 40% compared to only using direct acoustic rays.
ER  - 

TY  - CONF
TI  - Deep Neural Networks for Multiple Speaker Detection and Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 74
EP  - 79
AU  - W. He
AU  - P. Motlicek
AU  - J. Odobez
PY  - 2018
KW  - acoustic generators
KW  - encoding
KW  - human-robot interaction
KW  - microphone arrays
KW  - neural nets
KW  - speaker recognition
KW  - deep neural networks
KW  - multiple speaker detection
KW  - simultaneous detection
KW  - multiple sound sources
KW  - human-robot interaction
KW  - neural network-based sound source localization methods
KW  - single sound source
KW  - likelihood-based encoding
KW  - network output
KW  - sound mixtures
KW  - spatial spectrum-based approaches
KW  - Encoding
KW  - Delays
KW  - Robots
KW  - Artificial neural networks
KW  - Microphones
KW  - Estimation
DO  - 10.1109/ICRA.2018.8461267
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose to use neural networks for simultaneous detection and localization of multiple sound sources in human-robot interaction. In contrast to conventional signal processing techniques, neural network-based sound source localization methods require fewer strong assumptions about the environment. Previous neural network-based methods have been focusing on localizing a single sound source, which do not extend to multiple sources in terms of detection and localization. In this paper, we thus propose a likelihood-based encoding of the network output, which naturally allows the detection of an arbitrary number of sources. In addition, we investigate the use of sub-band cross-correlation information as features for better localization in sound mixtures, as well as three different network architectures based on different motivations. Experiments on real data recorded from a robot show that our proposed methods significantly outperform the popular spatial spectrum-based approaches.
ER  - 

TY  - CONF
TI  - DroneEARS: Robust Acoustic Source Localization with Aerial Drones
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 80
EP  - 85
AU  - P. Misra
AU  - A. A. Kumar
AU  - P. Mohapatra
AU  - P. Balamuralidhar
PY  - 2018
KW  - acoustic signal processing
KW  - array signal processing
KW  - autonomous aerial vehicles
KW  - sensor arrays
KW  - DroneEARS
KW  - robust acoustic source localization
KW  - aerial drones
KW  - microaerial vehicles
KW  - high value mobile sensing assets
KW  - external sensing scene
KW  - acoustic clues
KW  - MAV auditory system
KW  - robust acoustic localization system
KW  - MAV propeller units
KW  - sensor arrays
KW  - binaural sensing system
KW  - geo-locating sound sources
KW  - sparse sensor array design
KW  - platform constraints
KW  - severe ego-noise
KW  - received signal-to-noise ratio
KW  - source localization accuracy
KW  - physical space-of-interest
KW  - mobility-aided beamforming
KW  - Acoustics
KW  - Robot sensing systems
KW  - Sensor arrays
KW  - Signal to noise ratio
KW  - Array signal processing
KW  - Propellers
DO  - 10.1109/ICRA.2018.8461223
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Micro aerial vehicles (MAVs), an emerging class of aerial drones, are fast turning into high value mobile sensing assets. While MAVs have a large sensory gamut at their disposal; vision continues to dominate the external sensing scene, with limited usability in scenarios that offer acoustic clues. Therefore, we endeavor to provision a MAV auditory system (i.e., ears); and as part of this goal, our preliminary aim is to develop a robust acoustic localization system for detecting sound sources in the physical space-of-interest. However, devising this capability is extremely challenging due to strong ego-noise from the MAV propeller units, which is both wideband and non-stationary. It is well known that beamformers with large sensor arrays can overcome high noise levels; but in an attempt to cater to the platform (i.e., space, payload and computation) constraints of a MAV, we propose DroneEARS: a binaural sensing system for geo-locating sound sources. It combines the benefits of sparse (two elements) sensor array design (for meeting the platform constraints), and our proposed mobility-aided beamforming (for overcoming the severe ego-noise and its other complex characteristics) to significantly enhance the received signal-to-noise ratio (SNR). We demonstrate the efficacy of DroneEARS by empirical evaluations, and show that it provides a SNR improvement of 15-18 dB compared to many conventional and widely used techniques. This SNR gain translates to a source localization accuracy of approximately 40 cm within a scan region of 6m × 3m , that is, one order of magnitude better than competing methodologies.
ER  - 

TY  - CONF
TI  - Ultra-Wideband Radar for Robust Inspection Drone in Underground Coal Mines
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 86
EP  - 92
AU  - F. Cunha
AU  - K. Youcef-Toumi
PY  - 2018
KW  - coal
KW  - dust
KW  - inspection
KW  - mining
KW  - mining industry
KW  - personnel
KW  - safety
KW  - ultra wideband radar
KW  - walls
KW  - ultra-wideband radar
KW  - robust inspection drone
KW  - underground coal mine
KW  - human workers
KW  - autonomous inspection drone
KW  - coal dust
KW  - robust sensing solution
KW  - safety risk
KW  - Coal mining
KW  - Ultra wideband radar
KW  - Robustness
KW  - Drones
KW  - Coal
KW  - Sensors
DO  - 10.1109/ICRA.2018.8461191
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Coal mines pose a high safety risk for human workers. An autonomous inspection drone would enable a coal mine operation to reduce this risk by minimizing the time spent by workers inside the mine. This inspection drone must be highly robust to the harsh and dangerous environment of an underground coal mine, with high levels of coal dust and humidity that can obstruct many conventional sensing methods. For high functionality, the drone must sense and avoid potential obstacles and as well as inspect and map the mining wall face. The objective of this paper is to present ultra-wideband (UWB) radar as a robust sensing solution to this challenging environment and validate its performance experimentally in the typical coal mine environment, both statically and dynamically.
ER  - 

TY  - CONF
TI  - Inertial Machine Monitoring System for Automated Failure Detection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 93
EP  - 98
AU  - J. Windau
AU  - L. Itti
PY  - 2018
KW  - condition monitoring
KW  - failure analysis
KW  - neural nets
KW  - production engineering computing
KW  - productivity
KW  - sensors
KW  - support vector machines
KW  - support vector machines
KW  - combine industrial equipment failure
KW  - inertial machine monitoring system
KW  - manufacturing productivity
KW  - 3D printer
KW  - neural networks
KW  - smart manufacturing technologies
KW  - automated failure detection
KW  - Internet-of-Things sensors
KW  - Feature extraction
KW  - Robot sensing systems
KW  - Vibrations
KW  - Monitoring
KW  - Accelerometers
KW  - Databases
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8461266
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Smart manufacturing technologies are emerging which combine industrial equipment with Internet-of-Things (IoT) sensors to monitor and improve productivity of manufacturing. This allows for new opportunities to explore algorithms for predicting machine failures from attached sensor data. This paper presents a solution to non-invasively upgrade an existing machine with an Inertial Machine Monitoring System (IMMS) to detect and classify equipment failure or degraded state. We also provide a strategy to optimize the amount, placement locations, and efficiency of the sensors. In experiments, the system collected data from 36 inertial sensors placed at multiple locations on a 3D printer. Normal operation vs. 10 types of realworld abnormal equipment behavior (loose belt, failures of machine components) were detected and classified by Support Vector Machines and Neural Networks. Using under 1 minute of recording while running a test print, a recursively discovered best subset of 4 to 9 sensors yielded 11-way classification accuracy over 99%. Our results suggest that even a small sensor network and short test program can yield effective detection of machine degraded state and can facilitate early remediation.
ER  - 

TY  - CONF
TI  - iMag: Accurate and Rapidly Deployable Inertial Magneto-Inductive Localisation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 99
EP  - 106
AU  - B. Wei
AU  - N. Trigoni
AU  - A. Markham
PY  - 2018
KW  - Global Positioning System
KW  - sensor placement
KW  - SLAM (robots)
KW  - wireless sensor networks
KW  - inertial magneto-inductive localisation
KW  - short-term construction work
KW  - iMag
KW  - robust simultaneous localisation
KW  - inertial measurement units
KW  - Transmitters
KW  - Robustness
KW  - Simultaneous localization and mapping
KW  - Magnetic resonance imaging
KW  - Distortion
KW  - Trajectory
KW  - Magneto-inductive device
KW  - Inertial measurements
KW  - Localisation
KW  - SLAM
DO  - 10.1109/ICRA.2018.8460804
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Localisation is of importance for many applications. Our motivating scenarios are short-term construction work and emergency rescue. Not only is accuracy necessary, these scenarios also require rapid setup and robustness to environmental conditions. These requirements preclude the use of many traditional methods e.g. vision-based, laser-based, Ultra-wide band (UWB) and Global Positioning System (GPS)-based localisation systems. To solve these challenges, we introduce iMag, an accurate and rapidly deployable inertial magneto-inductive (MI) localisation system. It localises monitored workers using a single MI transmitter and inertial measurement units with minimal setup effort. However, MI location estimates can be distorted and ambiguous. To solve this problem, we suggest a novel method to use MI devices for sensing environmental distortions, and use these to correctly close inertial loops. By applying robust simultaneous localisation and mapping (SLAM), our proposed localisation method achieves excellent tracking accuracy, and can improve performance significantly compared with only using an inertial measurement unit (IMU) and MI device for localisation.
ER  - 

TY  - CONF
TI  - Parallel Pick and Place Using Two Independent Untethered Mobile Magnetic Microgrippers
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 123
EP  - 128
AU  - J. Zhang
AU  - M. Salehizadeh
AU  - E. Diller
PY  - 2018
KW  - end effectors
KW  - freight handling
KW  - grippers
KW  - industrial robots
KW  - micromanipulators
KW  - microrobots
KW  - mobile robots
KW  - position control
KW  - independent untethered mobile magnetic microgrippers
KW  - parallel targeted cargo delivery
KW  - two-microgripper pair
KW  - local magnetic interactions
KW  - global magnetic field
KW  - end effectors
KW  - parallel pick and place
KW  - 3D microgrippers configuration
KW  - Grippers
KW  - Magnetic separation
KW  - Barium
KW  - Magnetic hysteresis
KW  - Magnetoelasticity
KW  - Micromagnetics
KW  - Task analysis
KW  - magnetic microgripper
KW  - multi-agent control at microscales
KW  - soft robotics
KW  - targeted cargo delivery
DO  - 10.1109/ICRA.2018.8462861
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Untethered mobile microgrippers exhibit flexibility and agility in small and constrained environments as precise and accurate robotic end-effectors, with promising potential applications in cell manipulation and microassembly. Here, we propose the first scheme to independently and simultaneously position two microgrippers on a horizontal plane for parallel targeted cargo delivery using a single global input. The separation and orientation of the two-microgripper pair are modulated by the local magnetic interactions between the two microgrippers, which are governed by a global magnetic field. The microgripper action of grasping or releasing cargoes is fully controlled by the global magnetic field without requiring additional thermal, chemical, or other stimuli. Thus, the proposed strategy only requires a single input, i.e., a global magnetic field, to control two microgrippers and therefore is simple to implement and fast-acting. As a demonstration, two microgrippers are maneuvered by a global magnetic field to pick up two cargoes and deliver them to their respective destinations. The parallel operation of two microgrippers can potentially double the overall throughput and enable the tasks that require team cooperations. The two 3D microgrippers configuration is intuitive in teleoperations, since it imitates the two-hand case of human beings.
ER  - 

TY  - CONF
TI  - Development and Experimental Validation of a Combined FBG Force and OCT Distance Sensing Needle for Robot-Assisted Retinal Vein Cannulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 129
EP  - 134
AU  - J. Smits
AU  - M. Ourak
AU  - A. Gijbels
AU  - L. Esteveny
AU  - G. Borghesan
AU  - L. Schoevaerdts
AU  - K. Willekens
AU  - P. Stalmans
AU  - E. Lankenau
AU  - H. Schulz-Hildebrandt
AU  - G. Hüttmann
AU  - D. Reynaerts
AU  - E. B. Vander Poorten
PY  - 2018
KW  - biomedical optical imaging
KW  - blood vessels
KW  - Bragg gratings
KW  - calibration
KW  - coagulation
KW  - distance measurement
KW  - eye
KW  - fibre optic sensors
KW  - force sensors
KW  - manipulators
KW  - medical disorders
KW  - medical robotics
KW  - needles
KW  - optical tomography
KW  - surgery
KW  - vision defects
KW  - real-time distance estimation algorithm
KW  - calibration method
KW  - manufacturing process
KW  - Fiber Bragg grating
KW  - Fiber Bragg grating
KW  - depth estimation
KW  - anticoagulant
KW  - robot-assisted procedure
KW  - retinal vascular disorder
KW  - FBG force
KW  - Optical Coherence Tomography A-scan technology
KW  - distance sensing cannulation needle
KW  - instrument-tissue interaction forces
KW  - Retinal Vein Occlusion
KW  - robot-assisted retinal Vein cannulation
KW  - OCT distance sensing needle
KW  - Retina
KW  - Robot sensing systems
KW  - Force
KW  - Needles
KW  - Instruments
KW  - Veins
DO  - 10.1109/ICRA.2018.8460983
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Retinal Vein Occlusion is a common retinal vascular disorder which can cause severe loss of vision. Retinal vein cannulation followed by injection of an anti-coagulant into the affected vein is a promising treatment. However, given the scale and fragility of the surgical workfield, this procedure is considered too high-risk to perform manually. A first successful robot-assisted procedure has been demonstrated. Even though successful, the procedure remains extremely challenging. This paper aims at providing a solution for the limited perception of instrument-tissue interaction forces as well as depth estimation during retinal vein cannulation. The development of a novel combined force and distance sensing cannulation needle relying on Fiber Bragg grating (FBG) and Optical Coherence Tomography (OCT) A-scan technology is reported. The design, the manufacturing process, the calibration method, and the experimental characterization of the produced sensor are discussed. The functionality of the combined sensing modalities and the real-time distance estimation algorithm are validated respectively on in-vitro and ex-vivo models.
ER  - 

TY  - CONF
TI  - Requirements Based Design and End-to-End Dynamic Modeling of a Robotic Tool for Vitreoretinal Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 135
EP  - 141
AU  - A. Mablekos-Alexiou
AU  - S. Ourselin
AU  - L. Da Cruz
AU  - C. Bergeles
PY  - 2018
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - medical robotics
KW  - motion control
KW  - surgery
KW  - end-to-end dynamic modeling
KW  - robotic tool
KW  - vitreoretinal surgery
KW  - sub-optimal motor selection
KW  - microprecise surgery
KW  - surgical tool
KW  - 3-link surgical manipulator
KW  - anti-backlash lead screw assembly
KW  - multi-Degree of Freedom robotic system
KW  - dynamics analysis
KW  - rigorous kinematics analysis
KW  - Euler-Lagrange equations of motion
KW  - Surgery
KW  - Manipulator dynamics
KW  - Tools
KW  - Mathematical model
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460921
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Despite several robots having been proposed for vitreoretinal surgery, there is limited information on their dynamic modeling. This gap leads to sub-optimal motor selection and hinders the application of advanced control schemes that would fulfill the goal of micro-precise surgery. This paper presents the design process and a dynamics study of a multi-Degree of Freedom (DoF) robotic system, which is inspired by established co-manipulation architectures. A rigorous kinematics and dynamics analysis of the robot's part that is responsible for manipulating the surgical tool during the retinal surgery phase is provided. In particular, the Euler-Lagrange equations of motion, which describe the dynamics of the 3-link surgical manipulator, are combined with novel analytical models of each link's corresponding transmission mechanism, including an anti-backlash lead screw assembly and a worm drive. The resulting models, transferable to existing manipulators, provide a meticulous analysis of the robot's performance that can be used both for mechanical design and control purposes.
ER  - 

TY  - CONF
TI  - ESD CYCLOPS: A New Robotic Surgical System for GI Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 150
EP  - 157
AU  - T. J. C. O. Vrielink
AU  - M. Zhao
AU  - A. Darzi
AU  - G. P. Mylonas
PY  - 2018
KW  - biomedical optical imaging
KW  - cancer
KW  - endoscopes
KW  - laser applications in medicine
KW  - medical robotics
KW  - surgery
KW  - tumours
KW  - endoscopic submucosal dissection
KW  - robotic surgical system
KW  - therapeutic endoscopy technique
KW  - GI surgery
KW  - GI surgeon
KW  - bimanual surgical robotic attachment
KW  - ESD CYCLOPS system
KW  - surgical systems
KW  - gastrointestinal cancers
KW  - Instruments
KW  - Endoscopes
KW  - Electrostatic discharges
KW  - Surgery
KW  - Tendons
KW  - Robots
KW  - Cancer
DO  - 10.1109/ICRA.2018.8462698
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Gastrointestinal (GI) cancers account for 1.5 million deaths worldwide. Endoscopic Submucosal Dissection (ESD) is an advanced therapeutic endoscopy technique with superior clinical outcome due to the minimally invasive and en bloc removal of tumours. In the western world, ESD is seldom carried out, due to its complex and challenging nature. Various surgical systems are being developed to make this therapy accessible, however, these solutions have shown limited operational workspace, dexterity, or low force exertion capabilities. The current paper shows the ESD CYCLOPS system, a bimanual surgical robotic attachment that can be mounted at the end of any flexible endoscope. The system is able to achieve forces of up to 46N, and showed a mean error of 0.217mm during an elliptical tracing task. The workspace and instrument dexterity is shown by pre-clinical ex vivo trials, in which ESD is successfully performed by a GI surgeon. The system is currently undergoing pre-clinical in vivo validation.
ER  - 

TY  - CONF
TI  - Differentiation of C2C12 Myoblasts and Characterization of Electro-Responsive Beating Behavior of Myotubes Using Circularly Distributed Multiple Electrodes for Bio-Syncretic Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 158
EP  - 163
AU  - C. Zhang
AU  - W. Wang
AU  - N. Xi
AU  - Y. Wang
AU  - L. Liu
PY  - 2018
KW  - biomechanics
KW  - cellular biophysics
KW  - electromechanical actuators
KW  - medical robotics
KW  - microrobots
KW  - muscle
KW  - physiological models
KW  - tissue engineering
KW  - ultrasonic therapy
KW  - electrical stimulation
KW  - myotubes
KW  - bio-syncretic robot
KW  - circularly distributed multiple electrodes
KW  - C2C12 myoblasts
KW  - electro-responsive beating behavior
KW  - biomedical field
KW  - C2C12 differentiation
KW  - muscle tissue engineering
KW  - Electrodes
KW  - Electrical stimulation
KW  - Muscles
KW  - Robots
KW  - Electric fields
KW  - Biological materials
KW  - Force
DO  - 10.1109/ICRA.2018.8461225
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Micro-robots have a great application prospect in the biomedical field due to the feature of small size. To solve the issues of energy supply and bio-compatibility of micro-robots, bio-syncretic micro-robots composed of biological materials and electromechanical systems have been studied widely. The skeletal muscle is a potential material to develop bio-actuator for the bio-syncretic robots on account of the great contraction force and the controllability. However, the low differentiation quality of C2C12s and the control of the bio-syncretic robots are the two of the main challenges for the development of the bio-syncretic robots based on the skeleton muscle. In this paper, an approach based on circularly distributed multiple electrodes (CDMEs) was proposed to improve the differentiation of C2C12 myoblast cells and characterize the electro-responsive beating behavior of myotubes for the development of bio-syncretic robots. Three groups of C2C12 blasts were used to fulfill the differentiation experiments without electrical stimulation and with electrical stimulation using parallel electrodes and CDMEs respectively, for evaluating the effect of CDMEs on C2C12 differentiation. It was demonstrated that electrical field through CDMEs can improve the differentiation quality of C2C12 blasts into myotubes in terms of intensity, length, and widths. Then, the effect of electrical stimulation on the beating behaviors of myotubes was also investigated with CDMEs, and it was shown that the beating amplitudes of myotubes were significantly affected by the frequencies, amplitude and direction of electrical stimulation with respect to the myotubes, which is fundamental for the control of the micro-robot based on skeletal muscle cells. The proposed approach is useful for not only the development of the bio-syncretic robots, but also the study of muscle tissue engineering.
ER  - 

TY  - CONF
TI  - String Untying Planning Based on Knot Theory and Proposal of Algorithms to Generate the Motion of a Manipulator
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 180
EP  - 186
AU  - T. Matsuno
AU  - T. Shirakawa
AU  - T. Watanabe
AU  - M. Minami
PY  - 2018
KW  - manipulators
KW  - path planning
KW  - deformable object manipulation
KW  - string untying planning method
KW  - motion generation
KW  - optimal string shape operation
KW  - knot theory
KW  - Shape
KW  - Planning
KW  - Manipulators
KW  - Robot motion
KW  - Three-dimensional displays
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460477
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recently, the demand to manipulate deformable objects such as a string and cloth by robots is growing. The reason is that it has the possibility of making our lives more convenient in many domains. The manipulation of deformable objects, however, is more difficult than that of rigid objects, because deformable objects have diversity of shape and behavior. Therefore, our research group has been focusing on the string shape operation. This paper describes planning method of string untying operation based on knot theory and algorithms to generate the motion of a manipulator. The novel contribution of our planning method is automatic selection of optimal shape operation based on cost function. At final, the results of string untying experiments are reported.
ER  - 

TY  - CONF
TI  - Compliant Low Profile Multi-Axis Force Sensors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 187
EP  - 192
AU  - O. A. Araromi
AU  - S. Castellanos
AU  - C. J. Walsh
AU  - R. J. Wood
PY  - 2018
KW  - carbon fibre reinforced composites
KW  - compliant mechanisms
KW  - deformation
KW  - elastomers
KW  - force sensors
KW  - strain sensors
KW  - multiaxis force sensors
KW  - soft force sensors
KW  - compliant force sensors
KW  - microscale meanders
KW  - elastomers layers
KW  - sensor contact mechanics
KW  - differential measurement
KW  - laser-machined carbon fiber composite micro-structures
KW  - mechanical compliance
KW  - Robot sensing systems
KW  - Resistance
KW  - Fabrication
KW  - Geometry
KW  - Force sensors
KW  - Contacts
KW  - Carbon
KW  - Soft Material Robotics
KW  - Wearable Robots
DO  - 10.1109/ICRA.2018.8460189
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The development of soft, compliant force sensors is greatly sought after in areas such as soft robotics and prosthetics. Nevertheless, solutions for measuring forces in multiple axes, while being mechanically compliant, have been few and far between. Here we present a compliant sensor able to detect forces tangential and normal to the sensor surface. The transduction mechanism is based on the deformation of laser-machined carbon fiber composite (CFC) micro-scale meanders, encapsulated within elastomers layers. Strains in the elastomer are transmitted to the meanders, causing changes in the electrical resistance of the sensor contact mechanics. Configuring the meanders in a radial pattern, segmenting them into quadrants (two antagonist pairs) and biasing the center of the sensor out-of-plane enables detection of forces in multiple axis via differential measurement. Sensors were manufactured using a custom fabrication process and exhibited high mechanical compliance with a very low form factor. The sensors were experimentally characterized and demonstrated large differential changes in resistance (up to 26 kΩ for tangential forces applied to the sensor surface). We integrated our sensor onto a soft robotic gripper finger and demonstrated the ability to detect changes in friction at the actuator surface, thus demonstrating their potential for real world applications.
ER  - 

TY  - CONF
TI  - A Novel Approach to Under-Actuated Control of Fluidic Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 193
EP  - 199
AU  - A. Di Lallo
AU  - M. Catalano
AU  - M. Garabini
AU  - G. Grioli
AU  - M. Gabiccini
AU  - A. Bicchi
PY  - 2018
KW  - actuators
KW  - flow control
KW  - fluidics
KW  - under-actuated control
KW  - fluidic actuation
KW  - Fluidic Systems
KW  - Robots
KW  - Pneumatic systems
KW  - Valves
KW  - Pistons
KW  - Damping
KW  - Task analysis
KW  - Inspection
DO  - 10.1109/ICRA.2018.8460859
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Thanks to the growing interest in soft robotics, hydropneumatics and inflatable system dynamics are attracting renewed attention from the scientific community. Typical fluidic systems are composed of several chambers and require a complex and bulky network of active components for their control. This paper presents a novel approach to fluidic actuation, which consists in the co-design of both the mechanical parameters of the system and of custom input signals, to enable the elicitation of different behaviors of the system with fewer control components. The principle is presented in theory and simulation and then experimentally validated through the application to a case study, an in-pipe inchworm-like robot. It is shown that it is possible to obtain forward and backward movements by modulating a unique input.
ER  - 

TY  - CONF
TI  - Introducing PneuAct: Parametrically-Designed MRI-Compatible Pneumatic Stepper Actuator
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 200
EP  - 205
AU  - F. S. Farimani
AU  - S. Misra
PY  - 2018
KW  - biomedical MRI
KW  - electromagnetic actuators
KW  - medical robotics
KW  - motion control
KW  - pneumatic actuators
KW  - stepping motors
KW  - MR compatible robotics
KW  - proof-of-concept-prototypes
KW  - rotational pneumatic stepper motors
KW  - parametrically-designed MRI-compatible pneumatic stepper actuator
KW  - motion control
KW  - general purpose nonelectromagnetic actuation
KW  - PneuAct
KW  - Pistons
KW  - Synchronous motors
KW  - Electron tubes
KW  - Pneumatic systems
KW  - Force
KW  - Actuators
KW  - Robots
DO  - 10.1109/ICRA.2018.8462697
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Pneumatic stepper motors are one of the promising alternative actuation methods for motion control in environments where electromagnetic (EM) motors cannot be used. Due to the lack of commercial off-the-shelf products, researchers working on MR compatible robotics have to develop their own pneumatic actuators. This imposes extensive costs and delays on the development process. Additionally, the current solutions are limited in their range of specifications and are difficult to manufacture. In this paper, proof-of-concept-prototypes for a family of parametrically designed, electromagnetically stealth, rotational pneumatic stepper motors are presented. The main objective of the paper is to demonstrate a general purpose non-electromagnetic actuation method, which can be customized and integrated into any design. Customizability, miniaturization, safety and affordability are some of the key features of the presented work. The developed prototypes are entirely 3D-printed and contain no sealing, bearing or lubrication. Thanks to the low production cost, the motor can be used as a disposable part in surgical applications. Experiments demonstrate effectiveness of the design in terms of cost-efficiency, versatility, MRI-compatibility, speed and performance. In order to optimize the design and control algorithm, empirical equations are presented describing response time of a pneumatic system to sequential pressure signals. A rotational speed of 800 rpm, total volume of 4.6 cm3 and resolution of 3° are some of the design attributes. The effects of clearance on stick-slip effect and leakage in a 3D printed cylinder-piston are also presented.
ER  - 

TY  - CONF
TI  - Efficient Planning for Near-Optimal Compliant Manipulation Leveraging Environmental Contact
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 215
EP  - 222
AU  - C. Guan
AU  - W. Vega-Brown
AU  - N. Roy
PY  - 2018
KW  - large-scale systems
KW  - manipulators
KW  - optimisation
KW  - path planning
KW  - robot kinematics
KW  - path planning
KW  - assembly tasks
KW  - action uncertainty
KW  - optimal manipulation
KW  - leverage environmental contact
KW  - complex kinematics
KW  - action space
KW  - contact manifold
KW  - problem complexity
KW  - near-optimal compliant manipulation
KW  - environmental contact
KW  - discretization
KW  - Aerospace electronics
KW  - Uncertainty
KW  - Kinematics
KW  - Mathematical model
KW  - Manifolds
KW  - Task analysis
KW  - Complexity theory
DO  - 10.1109/ICRA.2018.8462696
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Path planning classically focuses on avoiding environmental contact. However, some assembly tasks permit contact through compliance, and such contact may allow for more efficient and reliable solutions under action uncertainty. But, optimal manipulation plans that leverage environmental contact are difficult to compute. Environmental contact produces complex kinematics that create difficulties for planning. This complexity is usually addressed by discretization over state and action space, but discretization quickly becomes computationally intractable. To overcome the challenge, we use the insight that only actions on configurations near the contact manifold are likely to involve complex kinematics, while segments of the plan through free space do not. Leveraging this structure can greatly reduce the number of states considered and scales much better with problem complexity. We develop an algorithm based on this idea and show that it performs comparably to full MDP solutions at a fraction of the computational cost.
ER  - 

TY  - CONF
TI  - Constrained Sampling-Based Planning for Grasping and Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 223
EP  - 230
AU  - J. Huh
AU  - B. Lee
AU  - D. D. Lee
PY  - 2018
KW  - manipulator dynamics
KW  - motion control
KW  - path planning
KW  - position control
KW  - redundant manipulators
KW  - sampling methods
KW  - sensors
KW  - trees (mathematics)
KW  - constrained sampling-based planning
KW  - sampling-based motion
KW  - transport tasks
KW  - redundant robotic manipulator
KW  - planning margin
KW  - grasp configuration
KW  - approach direction
KW  - sensor uncertainty
KW  - execution errors
KW  - soft constraints
KW  - computational efficiency
KW  - studied approaches
KW  - target position
KW  - grasp tasks
KW  - optimal grasp pose
KW  - Rapidly-exploring Random Tree algorithm
KW  - RRT algorithm
KW  - Planning
KW  - Grasping
KW  - Task analysis
KW  - Manipulators
KW  - Jacobian matrices
KW  - Robustness
KW  - Manifolds
DO  - 10.1109/ICRA.2018.8461265
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel constrained, sampling-based motion planning method for grasp and transport tasks with a redundant robotic manipulator. We utilize a planning margin for grasping with constraints that allow the best grasp configuration and approach direction to be determined automatically. For manipulators with many degrees of freedom, our method efficiently chooses the optimal grasp pose when there are many redundant solutions. The method also introduces a parameterized intermediate pose that is optimized to determine the approach direction, increasing robustness under sensor uncertainty and execution errors. Our method also considers transporting the grasped object to the desired target position using a Rapidly-exploring Random Tree (RRT) algorithm that incorporates soft constraints via appropriate cost penalties. We demonstrate the effectiveness and efficiency of our algorithms on a number of simulated and experimental applications. Our experimental results show a marked improvement in computational efficiency in comparison to previously studied approaches.
ER  - 

TY  - CONF
TI  - Geometric In-Hand Regrasp Planning: Alternating Optimization of Finger Gaits and In-Grasp Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 231
EP  - 238
AU  - B. Sundaralingam
AU  - T. Hermans
PY  - 2018
KW  - dexterous manipulators
KW  - gait analysis
KW  - manipulator kinematics
KW  - mesh generation
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - finger gaiting
KW  - in-grasp manipulation
KW  - contact location
KW  - finger gaits
KW  - object reposing actions
KW  - optimization
KW  - geometric in-hand regrasp planning
KW  - robots fingers
KW  - objects geometry
KW  - hands kinematic structure
KW  - kinematic feasibility
KW  - collision free
KW  - Planning
KW  - Robots
KW  - Optimization
KW  - Task analysis
KW  - Thumb
KW  - Collision avoidance
DO  - 10.1109/ICRA.2018.8460496
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper explores the problem of autonomous, in-hand regrasping-the problem of moving from an initial grasp on an object to a desired grasp using the dexterity of a robot's fingers. We propose a planner for this problem which alternates between finger gaiting, and in-grasp manipulation. Finger gaiting enables the robot to move a single finger to a new contact location on the object, while the remaining fingers stably hold the object. In-grasp manipulation moves the object to a new pose relative to the robot's palm, while maintaining the contact locations between the hand and object. Given the object's geometry (as a mesh), the hand's kinematic structure, and the initial and desired grasps, we plan a sequence of finger gaits and object reposing actions to reach the desired grasp without dropping the object. We propose an optimization based approach and report in-hand regrasping plans for 5 objects over 5 in-hand regrasp goals each. The plans generated by our planner are collision free and guarantee kinematic feasibility.
ER  - 

TY  - CONF
TI  - Manipulating Highly Deformable Materials Using a Visual Feedback Dictionary
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 239
EP  - 246
AU  - B. Jia
AU  - Z. Hu
AU  - J. Pan
AU  - D. Manocha
PY  - 2018
KW  - feature extraction
KW  - manipulators
KW  - mobile robots
KW  - robot vision
KW  - visual servoing
KW  - complex physical properties
KW  - autonomous robotic manipulation systems
KW  - visual feedback dictionary-based method
KW  - deformable objects
KW  - visual servoing
KW  - RGB sensor stream
KW  - deformable model features
KW  - histogram features
KW  - high-level representations
KW  - deformable material
KW  - manipulation data
KW  - robotic end-effectors
KW  - complex manipulation tasks
KW  - human-robot manipulation tasks
KW  - material characteristics
KW  - deformable materials
KW  - Visualization
KW  - Dictionaries
KW  - Feature extraction
KW  - Task analysis
KW  - Visual servoing
KW  - Deformable models
DO  - 10.1109/ICRA.2018.8461264
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The complex physical properties of highly deformable materials such as clothes pose significant challenges for autonomous robotic manipulation systems. We present a novel visual feedback dictionary-based method for manipulating deformable objects towards a desired configuration. Our approach is based on visual servoing and we use an efficient technique to extract key features from the RGB sensor stream in the form of a histogram of deformable model features. These histogram features serve as high-level representations of the state of the deformable material. Next, we collect manipulation data and use a visual feedback dictionary that maps the velocity in the high-dimensional feature space to the velocity of the robotic end-effectors for manipulation. We have evaluated our approach on a set of complex manipulation tasks and human-robot manipulation tasks on different cloth pieces with varying material characteristics.
ER  - 

TY  - CONF
TI  - Reactive Planar Manipulation with Convex Hybrid MPC
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 247
EP  - 253
AU  - F. R. Hogan
AU  - E. R. Grau
AU  - A. Rodriguez
PY  - 2018
KW  - closed loop systems
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - optimal control
KW  - optimisation
KW  - predictive control
KW  - Model Predictive Control formulation
KW  - optimal sequence
KW  - robot motions
KW  - desired object motion
KW  - multiple contact modes
KW  - frictional interactions
KW  - combinatorial complexity
KW  - optimal mode sequences offline
KW  - optimal control inputs
KW  - convex hybrid MPC program
KW  - planar manipulation experimental setup
KW  - convex hybrid MPC formulation
KW  - closed-loop performance
KW  - reactive planar manipulation
KW  - reactive controller
KW  - planar manipulation tasks
KW  - optimization program
KW  - machine learning
KW  - Task analysis
KW  - Force
KW  - Schedules
KW  - Friction
KW  - Predictive control
KW  - Manipulators
KW  - Optimization
DO  - 10.1109/ICRA.2018.8461175
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a reactive controller for planar manipulation tasks that leverages machine learning to achieve real-time performance. The approach is based on a Model Predictive Control (MPC) formulation, where the goal is to find an optimal sequence of robot motions to achieve a desired object motion. Due to the multiple contact modes associated with frictional interactions, the resulting optimization program suffers from combinatorial complexity when tasked with determining the optimal sequence of modes. To overcome this difficulty, we formulate the search for the optimal mode sequences offline, separately from the search for optimal control inputs online. Using tools from machine learning, this leads to a convex hybrid MPC program that can be solved in real-time. We validate our algorithm on a planar manipulation experimental setup where results show that the convex hybrid MPC formulation with learned modes achieves good closed-loop performance on a trajectory tracking problem.
ER  - 

TY  - CONF
TI  - Stable Prehensile Pushing: In-Hand Manipulation with Alternating Sticking Contacts
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 254
EP  - 261
AU  - N. Chavan-Dafle
AU  - A. Rodriguez
PY  - 2018
KW  - dexterous manipulators
KW  - friction
KW  - manipulator dynamics
KW  - mechanical contact
KW  - motion control
KW  - path planning
KW  - frictional coefficients
KW  - pushing strategy
KW  - in-hand manipulation planning
KW  - dynamics formulation
KW  - object grasping
KW  - alternating sticking contacts
KW  - prehensile pushing stability
KW  - Planning
KW  - Dynamics
KW  - Grippers
KW  - Friction
KW  - Robots
KW  - Geometry
KW  - Force
DO  - 10.1109/ICRA.2018.8461243
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents an approach to in-hand manipulation planning that exploits the mechanics of alternating sticking contact. Particularly, we consider the problem of manipulating a grasped object using external pushes for which the pusher sticks to the object. Given the physical properties of the object, frictional coefficients at contacts and a desired regrasp on the object, we propose a sampling-based planning framework that builds a pushing strategy concatenating different feasible stable pushes to achieve the desired regrasp. An efficient dynamics formulation allows us to plan in-hand manipulations 100-1000 times faster than our previous work which builds upon a complementarity formulation. Experimental observations for the generated plans show that the object precisely moves in the grasp as expected by the planner.
ER  - 

TY  - CONF
TI  - Rearrangement with Nonprehensile Manipulation Using Deep Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 270
EP  - 277
AU  - W. Yuan
AU  - J. A. Stork
AU  - D. Kragic
AU  - M. Y. Wang
AU  - K. Hang
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - potential field-based heuristic exploration strategy
KW  - deep Q-network
KW  - nonprehensile rearrangement strategy
KW  - physical environment
KW  - physical world
KW  - skillful interaction
KW  - tabletop surface
KW  - rearranging objects
KW  - deep reinforcement learning
KW  - nonprehensile manipulation
KW  - quicker learning
KW  - training process
KW  - Planning
KW  - Task analysis
KW  - Robots
KW  - Tools
KW  - Cameras
KW  - Visualization
KW  - Training
DO  - 10.1109/ICRA.2018.8462863
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Rearranging objects on a tabletop surface by means of nonprehensile manipulation is a task which requires skillful interaction with the physical world. Usually, this is achieved by precisely modeling physical properties of the objects, robot, and the environment for explicit planning. In contrast, as explicitly modeling the physical environment is not always feasible and involves various uncertainties, we learn a nonprehensile rearrangement strategy with deep reinforcement learning based on only visual feedback. For this, we model the task with rewards and train a deep Q-network. Our potential field-based heuristic exploration strategy reduces the amount of collisions which lead to suboptimal outcomes and we actively balance the training set to avoid bias towards poor examples. Our training process leads to quicker learning and better performance on the task as compared to uniform exploration and standard experience replay. We demonstrate empirical evidence from simulation that our method leads to a success rate of 85%, show that our system can cope with sudden changes of the environment, and compare our performance with human level performance.
ER  - 

TY  - CONF
TI  - Decentralized Adaptive Control for Collaborative Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 278
EP  - 285
AU  - P. Culbertson
AU  - M. Schwager
PY  - 2018
KW  - adaptive control
KW  - decentralised control
KW  - Lyapunov methods
KW  - manipulators
KW  - multi-robot systems
KW  - stability
KW  - center-of-mass measurements
KW  - angular velocity
KW  - local measurements
KW  - collaborative manipulation
KW  - decentralized adaptive controller
KW  - common payload
KW  - agent positions
KW  - payload properties
KW  - Lyapunov-style analysis
KW  - stability
KW  - convergence
KW  - Payloads
KW  - Robots
KW  - Collaboration
KW  - Angular velocity
KW  - Velocity measurement
KW  - Task analysis
KW  - Stability analysis
DO  - 10.1109/ICRA.2018.8461263
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a design for a decentralized adaptive controller that allows a team of agents to manipulate a common payload in $\mathbb{R}^{2}$ or $\mathbb{R}^{3}$. The controller requires no communication between agents and requires no a priori knowledge of agent positions or payload properties. The agents can control the payload to track a reference trajectory in linear and angular velocity with center-of-mass measurements, in angular velocity using only local measurements and a common frame, and can stabilize its rotation with only local measurements. The controller is designed via a Lyapunov-style analysis and has proven stability and convergence. The controller is validated in simulation and experimentally with four robots manipulating an object in the plane.
ER  - 

TY  - CONF
TI  - Trajectory Generation for Minimum Closed-Loop State Sensitivity
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 286
EP  - 293
AU  - P. R. Giordano
AU  - Q. Delamare
AU  - A. Franchi
PY  - 2018
KW  - autonomous aerial vehicles
KW  - closed loop systems
KW  - mobile robots
KW  - Monte Carlo methods
KW  - optimisation
KW  - controller dynamics
KW  - reference trajectory
KW  - system trajectories
KW  - trajectory optimization problems
KW  - closed-loop sensitivity
KW  - trajectory generation
KW  - minimum closed-loop state sensitivity
KW  - dynamical system fulfil
KW  - nominal parameters
KW  - closed-loop trajectory
KW  - system/controller pair
KW  - control inputs
KW  - system states
KW  - robotic systems
KW  - Monte Carlo simulations
KW  - unicycle
KW  - quadrotor UAV
KW  - Trajectory
KW  - Sensitivity
KW  - Task analysis
KW  - Optimization
KW  - Uncertainty
KW  - Robots
KW  - Robustness
DO  - 10.1109/ICRA.2018.8460546
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a novel general method to let a dynamical system fulfil at best a control task when the nominal parameters are not perfectly known. The approach is based on the introduction of the novel concept of closed-loop sensitivity, a quantity that relates parameter variations to deviations of the closed-loop trajectory of the system/controller pair. This new definition takes into account the dependency of the control inputs from the system states and nominal parameters as well as from the controller dynamics. The reference trajectory to be tracked is taken as optimization variable, and the dynamics of both the sensitivity and of its gradient are computed analytically along the system trajectories. We then show how this computation can be effectively exploited for solving trajectory optimization problems aimed at generating a reference trajectory that minimizes a norm of the closed-loop sensitivity. The theoretical results are validated via an extensive campaign of Monte Carlo simulations for two relevant robotic systems: a unicycle and a quadrotor UAV.
ER  - 

TY  - CONF
TI  - Modeling and Control of Multi-Arm and Multi-Leg Robots: Compensating for Object Dynamics During Grasping
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 294
EP  - 301
AU  - N. Dehio
AU  - J. Smith
AU  - D. L. Wigand
AU  - G. Xin
AU  - H. Lin
AU  - J. J. Steil
AU  - M. Mistry
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - humanoid robots
KW  - legged locomotion
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - object dynamics compensation
KW  - ANYmal
KW  - free-floating robot link
KW  - KUKA LWR IV+ representing fingers
KW  - contact wrenches control
KW  - floating-base multileg robots control
KW  - virtual DOF
KW  - enormous robot hand
KW  - underactuated robots
KW  - contact consistent motion generation
KW  - Projected Inverse Dynamics Control approach
KW  - underactuated system
KW  - multiarm robot
KW  - modeling approach
KW  - grasping scenarios
KW  - virtual manipulator
KW  - mass 9.0 kg
KW  - Grasping
KW  - Dynamics
KW  - Task analysis
KW  - Jacobian matrices
KW  - Manipulator dynamics
DO  - 10.1109/ICRA.2018.8462872
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider a virtual manipulator in grasping scenarios which allows us to capture the effect of the object dynamics. This modeling approach turns a multi-arm robot into an underactuated system. We observe that controlling floating-base multi-leg robots is fundamentally similar. The Projected Inverse Dynamics Control approach is employed for decoupling contact consistent motion generation and controlling contact wrenches. The proposed framework for underactuated robots has been evaluated on an enormous robot hand composed of four KUKA LWR IV+ representing fingers cooperatively manipulating a 9kg box with total 28 actuated DOF and six virtual DOF representing the object as additional free-floating robot link. Finally, we validate the same approach on ANYmal, a floating-base quadruped with 12 actuated DOF. Experiments are performed both in simulation and real world.
ER  - 

TY  - CONF
TI  - Multi-Priority Cartesian Impedance Control Based on Quadratic Programming Optimization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 309
EP  - 315
AU  - E. M. Hoffman
AU  - A. Laurenzi
AU  - L. Muratore
AU  - N. G. Tsagarakis
AU  - D. G. Caldwell
PY  - 2018
KW  - collision avoidance
KW  - humanoid robots
KW  - human-robot interaction
KW  - motion control
KW  - quadratic programming
KW  - robot dynamics
KW  - service robots
KW  - torque control
KW  - prioritized Cartesian impedance control
KW  - inverse dynamics
KW  - matrix pseudoinversion
KW  - inverse kinematics computation
KW  - QP optimization
KW  - QP implementation
KW  - classical Cartesian impedance controller
KW  - humanoid upper-body torque controlled robot
KW  - quadratic programming optimization
KW  - inequality constraints
KW  - multipriority Cartesian impedance control
KW  - algebraic implementation
KW  - joint torque limits
KW  - virtual model control
KW  - Task analysis
KW  - Impedance
KW  - Robots
KW  - Force
KW  - Torque
KW  - Optimization
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8462877
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work we introduced a prioritized Cartesian impedance control under the framework of the Quadratic Programming (QP) optimization. In particular, we present a formulation which is simpler than full inverse dynamics, avoids any matrix pseudo-inversion, inverse kinematics computation and considers strict priorities among tasks. Our formulation is based on QP optimization permitting to take into account also explicit inequality constraints. We compare in simulation the tracking results obtained with a classical algebraic implementation against those derived from the proposed QP implementation taking into account joint torque limits. We consider the classical Cartesian impedance controller and a simplified version, also known as Virtual Model Control. Finally the proposed method was implemented and validated on a humanoid upper-body torque controlled robot. Experimental trials involving various physical interaction conditions were executed to demonstrate the performance of the proposed method.
ER  - 

TY  - CONF
TI  - Responsive and Reactive Dual-Arm Robot Coordination
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 316
EP  - 322
AU  - F. Beuke
AU  - S. Alatartsev
AU  - S. Jessen
AU  - A. Verl
PY  - 2018
KW  - collision avoidance
KW  - control engineering computing
KW  - industrial robots
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - path planning
KW  - dual-arm robot coordination
KW  - temporal coordination
KW  - spatial coordination
KW  - shared workspace
KW  - industrial service-oriented robotics
KW  - user experience
KW  - execution performance
KW  - independently planned motions
KW  - dual-arm manipulator
KW  - motion commands
KW  - robot motion
KW  - ABB YuMi robot
KW  - Robot kinematics
KW  - Trajectory
KW  - Collision avoidance
KW  - Task analysis
KW  - Service robots
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8462868
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The need for temporal and spatial coordination of two robot arms moving independently in a shared workspace frequently arises in industrial and service-oriented robotics alike. Today, this problem is often solved manually, leading to a negative impact on user experience as well as on execution performance. In this paper, we present an algorithm that is able to automatically coordinate independently planned motions of a dual-arm manipulator during execution. In addition, the algorithm is capable of refining the plan upon receiving new motion commands during the robot motion. We demonstrate the effectiveness and efficiency of the proposed approach on an ABB YuMi robot working on an industrial palletizing task.
ER  - 

TY  - CONF
TI  - Contact Point Localization for Articulated Manipulators with Proprioceptive Sensors and Machine Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 323
EP  - 329
AU  - A. Zwiener
AU  - C. Geckeler
AU  - A. Zell
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - multilayer perceptrons
KW  - optimisation
KW  - position control
KW  - contact point localization
KW  - articulated manipulators
KW  - proprioceptive sensors
KW  - machine learning
KW  - joint positions
KW  - one-dimensional joint torques
KW  - robot arm
KW  - RFs
KW  - contact link
KW  - contact points
KW  - Kinova Jaco 2 manipulator
KW  - optimization based approach
KW  - ML approach
KW  - serial manipulator
KW  - random forests
KW  - multilayer perceptrons
KW  - MLP
KW  - Force
KW  - Torque
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Manipulator dynamics
DO  - 10.1109/ICRA.2018.8462869
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A model-based Machine Learning (ML) approach is presented to detect and localize external contacts on a 6 degree of freedom (DoF) serial manipulator. This approach only requires the use of proprioceptive sensors (joint positions, velocities and one-dimensional (ID) joint torques already available in the robot arm). Good results are obtained with Random Forests (RFs) and Multi-Layer-Perceptrons (MLPs) leading to a precise localization of the contact link and its orientation. Apart from the link in contact and the orientation of the force, RFs and MLPs are also able to differentiate between contact points on the same link and orientation but with different distances to the joint axis. We experimentally verify this approach on simulated and real data obtained from the Kinova Jaco 2 manipulator and compare it to an optimization based approach.
ER  - 

TY  - CONF
TI  - $L_{1}$ Robustness of Computed Torque Method for Robot Manipulators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 330
EP  - 335
AU  - J. H. Kim
AU  - S. Hur
AU  - Y. Oh
PY  - 2018
KW  - continuous time systems
KW  - linear systems
KW  - manipulators
KW  - robust control
KW  - stability
KW  - time-varying systems
KW  - torque control
KW  - uncertain systems
KW  - robot manipulator
KW  - L1 robustness
KW  - L1 robust stability condition
KW  - performance measure
KW  - induced norm bounded model uncertainty
KW  - continuous-time linear time-invariant nominal plant
KW  - multiplicative model uncertainty
KW  - exogenous disturbance
KW  - modelling errors
KW  - computed torque controller
KW  - model uncertainties
KW  - computed torque method
KW  - Torque
KW  - Manipulator dynamics
KW  - Computational modeling
KW  - Uncertainty
KW  - Robustness
DO  - 10.1109/ICRA.2018.8461170
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper revisits computed torque method for robot manipulators and aims at developing its new framework based on the L1 robustness, in which the L∞ norm together with its induced norm is employed to characterize model uncertainties and a performance measure. More precisely, we consider the L1 robust stability and performance for a given robot manipulator with a computed torque controller. We first show that the modelling errors in the computed torque method can be divided into an exogenous disturbance and a multiplicative model uncertainty, which are bounded in terms of the L∞ norm and its induced norm, respectively. It is next shown that the robot manipulator with the computed torque controller can be equivalently represented by an interconnection of a continuous-time linear time-invariant (LTI) nominal plant and a stabilizing controller together with the L∞-induced norm bounded model uncertainty. Based on the interconnected representation, the L1 robust stability condition and an upper bound of the L1 performance against the exogenous disturbance with respect to all model uncertainties in a class of a bounded L∞-induced norm are dealt with by using the small-gain theorem. Finally, the effectiveness of the theoretical results is demonstrated through some experiment results.
ER  - 

TY  - CONF
TI  - Online Safe Trajectory Generation for Quadrotors Using Fast Marching Method and Bernstein Basis Polynomial
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 344
EP  - 351
AU  - F. Gao
AU  - W. Wu
AU  - Y. Lin
AU  - S. Shen
PY  - 2018
KW  - autonomous aerial vehicles
KW  - clutter
KW  - computational geometry
KW  - convex programming
KW  - helicopters
KW  - indoor environment
KW  - mobile robots
KW  - path planning
KW  - polynomials
KW  - search problems
KW  - state estimation
KW  - trajectory control
KW  - online safe trajectory generation
KW  - Bernstein basis polynomial
KW  - onboard state estimation
KW  - velocity field
KW  - Euclidean signed distance field
KW  - time allocation
KW  - flight corridor
KW  - piecewise Bézier curves
KW  - outdoor environments
KW  - convex programs
KW  - autonomous navigation
KW  - marching-based path searching method
KW  - light-weight quadrotor platform
KW  - online quadrotor motion planning
KW  - cluttered indoor environments
KW  - ESDF
KW  - open-source package
KW  - Resource management
KW  - Planning
KW  - Trajectory optimization
KW  - Safety
KW  - Autonomous robots
DO  - 10.1109/ICRA.2018.8462878
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we propose a framework for online quadrotor motion planning for autonomous navigation in unknown environments. Based on the onboard state estimation and environment perception, we adopt a fast marching-based path searching method to find a path on a velocity field induced by the Euclidean signed distance field (ESDF) of the map, to achieve better time allocation. We generate a flight corridor for the quadrotor to travel through by inflating the path against the environment. We represent the trajectory as piecewise Bézier curves by using Bernstein polynomial basis and formulate the trajectory generation problem as typical convex programs. By using Bézier curves, we are able to bound positions and higher order dynamics of the trajectory entirely within safe regions. The proposed motion planning method is integrated into a customized light-weight quadrotor platform and is validated by presenting fully autonomous navigation in unknown cluttered indoor and outdoor environments. We also release our code for trajectory generation as an open-source package.
ER  - 

TY  - CONF
TI  - Coverage Path Planning Under the Energy Constraint
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 368
EP  - 373
AU  - M. Wei
AU  - V. Isler
PY  - 2018
KW  - approximation theory
KW  - geometry
KW  - mobile robots
KW  - path planning
KW  - energy constraint
KW  - coverage path planning problem
KW  - battery limitations
KW  - working environment
KW  - geometric version
KW  - polygonal grid
KW  - single charging station
KW  - energy consumption
KW  - constant-factor approximation algorithm
KW  - contour-connected environments
KW  - aerial robot
KW  - mobile robot systems
KW  - Robots
KW  - Charging stations
KW  - Approximation algorithms
KW  - Path planning
KW  - Batteries
KW  - Partitioning algorithms
KW  - Energy consumption
DO  - 10.1109/ICRA.2018.8462867
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the coverage path planning problem, a common assumption is that the robot can fully cover the environment without recharging. However, in reality most mobile robot systems operate under battery limitations. To incorporate this constraint, we consider the problem when the working environment is large and the robot needs to recharge multiple times to fully cover the environment. We focus on a geometric version where the environment is represented as a polygonal grid with a single charging station. Energy consumption throughout the environment is assumed to be uniform and proportional to the distance traveled. We first present a constant-factor approximation algorithm for contour-connected environments. We then extend the algorithm for general environments. We also validate the results in experiments performed with an aerial robot.
ER  - 

TY  - CONF
TI  - The Dubins Traveling Salesman Problem with Neighborhoods in the Three-Dimensional Space
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 374
EP  - 379
AU  - P. Váňa
AU  - J. Sláma
AU  - J. Faigl
PY  - 2018
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Atmospheric modeling
KW  - Airplanes
KW  - Solid modeling
KW  - Two dimensional displays
KW  - Optimization
DO  - 10.1109/ICRA.2018.8460957
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We introduce an extension of the Dubins Traveling Salesman Problem with Neighborhoods into the 3D space in which a fixed-wing aerial vehicle is requested to visit a set of target regions while the vehicle motion constraints are satisfied, i.e., the minimum turning radius and maximum climb and dive angles. The primary challenge is to address both the combinatorial optimization part of finding the sequence of target visits and the continuous optimization part of the final trajectory determination. Due to its high complexity, we propose to address both parts of the problem separately by a decoupled approach in which the sequence is determined by a new distance function designed explicitly for the utilized 3D Dubins Airplane model. The final trajectory is then found by a local optimization which improves the solution quality. The proposed approach provides significantly better solutions than using Euclidean distance in the sequencing part of the problem. Moreover, the found solutions are of the competitive quality to the sampling-based algorithm while its computational requirements are about two orders of magnitude lower.
ER  - 

TY  - CONF
TI  - The Dubins Car and Other Arm-Like Mobile Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 380
EP  - 386
AU  - D. Balkcom
AU  - A. Furtuna
AU  - W. Wang
PY  - 2018
KW  - force control
KW  - Jacobian matrices
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - robot kinematics
KW  - torque control
KW  - Dubins car
KW  - lagrange multipliers
KW  - external force
KW  - equal torques
KW  - arm Jacobian yields
KW  - optimal paths
KW  - arm-like mobile robots
KW  - robots arm kinematics
KW  - geometric interpretations
KW  - rotation center locations
KW  - Kinematics
KW  - Mobile robots
KW  - Trajectory
KW  - Automobiles
KW  - Manipulators
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8461017
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper investigates the connection between the kinematics of robots arms and the shortest paths for mobile robots. Lagrange multipliers are used to show that the shortest paths are equivalent to arms in configurations that balance an external force, while applying equal torques and forces at each joint. Analysis of the arm Jacobian yields a further geometric interpretations of optimal paths, constraining the locations of rotation centers and the directions of translations that may occur along optimal paths.
ER  - 

TY  - CONF
TI  - Planning, Fast and Slow: A Framework for Adaptive Real-Time Safe Trajectory Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 387
EP  - 394
AU  - D. Fridovich-Keil
AU  - S. L. Herbert
AU  - J. F. Fisac
AU  - S. Deglurkar
AU  - C. J. Tomlin
PY  - 2018
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - trajectory control
KW  - motion planning
KW  - robotics community
KW  - FaSTrack
KW  - sensor measurements
KW  - meta-planning notion
KW  - Crazyflie 2.0 quadrotor
KW  - adaptive realtime safe trajectory planning
KW  - safety guarantee
KW  - online planner
KW  - offline computation
KW  - motion plans
KW  - modular safety guarantee
KW  - Planning
KW  - Trajectory
KW  - Safety
KW  - Real-time systems
KW  - Robustness
KW  - Navigation
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460863
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Motion planning is an extremely well-studied problem in the robotics community, yet existing work largely falls into one of two categories: computationally efficient but with few if any safety guarantees, or able to give stronger guarantees but at high computational cost. This work builds on a recent development called FaSTrack in which a slow offline computation provides a modular safety guarantee for a faster online planner. We introduce the notion of “meta-planning” in which a refined offline computation enables safe switching between different online planners. This provides autonomous systems with the ability to adapt motion plans to a priori unknown environments in real-time as sensor measurements detect new obstacles, and the flexibility to maneuver differently in the presence of obstacles than they would in free space, all while maintaining a strict safety guarantee. We demonstrate the meta-planning algorithm both in simulation and in hardware using a small Crazyflie 2.0 quadrotor.
ER  - 

TY  - CONF
TI  - Reactive Bipedal Walking Method for Torque Controlled Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 395
EP  - 402
AU  - Y. Lee
AU  - J. Park
PY  - 2018
KW  - collision avoidance
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - stability
KW  - torque control
KW  - walking algorithm
KW  - whole-body control algorithm
KW  - operational space control framework
KW  - compliant task behavior
KW  - robust walking
KW  - unexpected obstacle
KW  - reactive bipedal walking method
KW  - torque controlled robot
KW  - unexpected situations
KW  - reactive biped robot walking method
KW  - time plan
KW  - trajectory tracking control
KW  - reactive behavior
KW  - unexpected contact
KW  - 12-DoF torque controlled biped robot
KW  - Legged locomotion
KW  - Foot
KW  - Acceleration
KW  - Trajectory tracking
KW  - Humanoid robots
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8460668
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Reactivity to unexpected situations is one of the most important characteristics of walking for real world applications. In this study, we introduce a reactive biped robot walking method that reflects only the current state of the robot. Therefore, time plan and trajectory tracking control are not required for robot walking, and this enables reactive behavior to unexpected contact or disturbance. The walking algorithm is realized through a whole-body control algorithm based on the operational space control framework, that possesses the capability to command the required force for tasks and also implement compliant task behavior by adjusting corresponding task gains. The performance of the proposed method is verified by experiments with a 12-DoF torque controlled biped robot. Robust walking is demonstrated when the foot is stopped by an unexpected obstacle or when the lateral motion is unexpectedly blocked and released by a human.
ER  - 

TY  - CONF
TI  - Disturbance Observer Based Linear Feedback Controller for Compliant Motion of Humanoid Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 403
EP  - 410
AU  - M. Kim
AU  - J. H. Kim
AU  - S. Kim
AU  - J. Sim
AU  - J. Park
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - elasticity
KW  - feedback
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - observers
KW  - position control
KW  - robot dynamics
KW  - stability
KW  - linear feedback controller
KW  - humanoid robot
KW  - industrial robots
KW  - position-controlled humanoid robots
KW  - disturbance observer based estimator
KW  - flexible joint model
KW  - joint elasticity
KW  - DYROS-JET robot
KW  - compliant motion
KW  - Elasticity
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Gravity
KW  - Vibrations
KW  - Torque
DO  - 10.1109/ICRA.2018.8460618
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Actuator modules of humanoid robots have relatively higher joint elasticity than those of industrial robots. Such joint elasticity could lead to negative effects on both the tracking performance and stability for walking. Especially, unstable contact between the foot and ground caused by joint elasticity is a critical problem, as it decreases the stability of position-controlled humanoid robots. To address this problem, this paper introduces a novel control scheme for position-controlled humanoid robots by which we can obtain not only enhance compliance capability for unknown contact but also suppress the vibration caused by joint elasticity. To estimate the disturbance caused by external forces and modeling errors between the actual system and nominal system, a disturbance observer based estimator is designed at each joint. Furthermore, a linear feedback controller for the flexible joint model and a gravity compensator is considered to reduce vibration and deflection due to the joint elasticity. The proposed control scheme was implemented on our humanoid robot, DYROS-JET, and its performance was demonstrated by improved stability during dynamic walking and stepping on objects.
ER  - 

TY  - CONF
TI  - Unsupervised Contact Learning for Humanoid Estimation and Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 411
EP  - 417
AU  - N. Rotella
AU  - S. Schaal
AU  - L. Righetti
PY  - 2018
KW  - end effectors
KW  - friction
KW  - humanoid robots
KW  - legged locomotion
KW  - pattern clustering
KW  - probability
KW  - robot kinematics
KW  - state estimation
KW  - unsupervised learning
KW  - humanoid estimation
KW  - contact state estimation
KW  - fuzzy clustering
KW  - six-dimensional humanoid contacts
KW  - proprioceptive sensors - endeffector contact wrench sensors
KW  - inertial measurement units
KW  - clustering-based contact probability estimator
KW  - kinematics-based base state estimator
KW  - sensor noise
KW  - unsupervised contact learning
KW  - IMUs
KW  - DoFs
KW  - Friction
KW  - Sensors
KW  - Force
KW  - Foot
KW  - State estimation
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8462864
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work presents a method for contact state estimation using fuzzy clustering to learn contact probability for full, six-dimensional humanoid contacts. The data required for training is solely from proprioceptive sensors - endeffector contact wrench sensors and inertial measurement units (IMUs) - and the method is completely unsupervised. The resulting cluster means are used to efficiently compute the probability of contact in each of the six endeffector degrees of freedom (DoFs) independently. This clustering-based contact probability estimator is validated in a kinematics-based base state estimator in a simulation environment with realistic added sensor noise for locomotion over rough, low-friction terrain on which the robot is subject to foot slip and rotation. The proposed base state estimator which utilizes these six DoF contact probability estimates is shown to perform considerably better than that which determines kinematic contact constraints purely based on measured normal force.
ER  - 

TY  - CONF
TI  - Robust Control of Dynamic Walking Robots Using Transverse H∞
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 418
EP  - 425
AU  - F. Fan
AU  - I. R. Manchester
PY  - 2018
KW  - control system synthesis
KW  - gait analysis
KW  - legged locomotion
KW  - linear quadratic control
KW  - motion control
KW  - robot dynamics
KW  - robust control
KW  - H∞ control
KW  - LQR controllers
KW  - compass gait walker
KW  - gait sensitivity norm
KW  - disturbance rejection
KW  - transverse coordinates
KW  - robust controllers
KW  - dynamic walkers
KW  - unstructured environments
KW  - dynamic walking robots
KW  - robust control
KW  - Legged locomotion
KW  - Robot kinematics
KW  - Robustness
KW  - Sensitivity
KW  - Robot sensing systems
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460744
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The control of walking robots has been a long-studied problem as researchers attempt to bring robots out of the lab and into unstructured environments. In particular, there is significant interest in dynamic walkers: a class of walking robots that exhibit highly efficient gaits, but are sensitive to disturbances. This paper develops robust controllers for dynamic walkers in transverse coordinates using H∞ control, with a focus on rejecting disturbances at foot impact. The optimization objective is a measure of disturbance rejection known as the gait sensitivity norm. The controller was used to stabilise a compass gait walker in simulation for various disturbances. Simulation results demonstrate the advantages of phase-tracking and H∞ control for robustness compared to time-varying and LQR controllers.
ER  - 

TY  - CONF
TI  - Investigation of a Bipedal Platform for Rapid Acceleration and Braking Manoeuvres
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 426
EP  - 432
AU  - A. Blom
AU  - A. Patel
PY  - 2018
KW  - braking
KW  - legged locomotion
KW  - optimisation
KW  - time optimal control
KW  - rapid acceleration manoeuvres
KW  - optimal control
KW  - time optimal sprint
KW  - realistic linkage morphology
KW  - pre-specified actuator
KW  - nominal leg length
KW  - optimisation problem
KW  - brute force approach
KW  - unique motion trajectories
KW  - time optimal behaviour
KW  - steady state motion
KW  - braking manoeuvres
KW  - physical bipedal robotic platform
KW  - bipedal platform
KW  - Legged locomotion
KW  - Couplings
KW  - Mathematical model
KW  - Actuators
KW  - Acceleration
KW  - Force
DO  - 10.1109/ICRA.2018.8462879
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Rapid acceleration manoeuvres have been avoided by researchers due to the aperiodicity and complexities of this motion. With the recent improvements in optimal control, this paper presents the first examination of a biped completing a time optimal sprint, starting and ending in rest, to provide insight for parameter choices of a robotic platform. In particular, a realistic linkage morphology is used with the limitation of a pre-specified actuator to choose the nominal leg length and gear ratio. Due to the size of the optimisation problem, a brute force approach is used rather than including these parameters as free variables. The results provided unique motion trajectories for time optimal behaviour with the models reaching near steady state motion and performing manoeuvres that are seen in a biped's biological counterpart. We then show that access to a higher mass-specific force does not improve the rapid acceleration manoeuvres, rather the friction coefficient and keeping the feet near the ground act as the limiting factor given sufficiently powerful actuators. A parabolic relationship emerged for sprint time versus linkage lengths providing valuable insight into the parameters to use for the platform design. To the authors knowledge, no prior research has focused on rapid acceleration and braking manoeuvres of a biped in one optimisation problem, let alone providing insight for the physical bipedal robotic platform.
ER  - 

TY  - CONF
TI  - Comparison Study of Nonlinear Optimization of Step Durations and Foot Placement for Dynamic Walking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 433
EP  - 439
AU  - W. Hu
AU  - I. Chatzinikolaidis
AU  - K. Yuan
AU  - Z. Li
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - nonlinear control systems
KW  - optimisation
KW  - pendulums
KW  - robot dynamics
KW  - dynamic walking
KW  - nonlinear optimization problem
KW  - continuous dynamics
KW  - discrete dynamics
KW  - remaining step duration
KW  - foot location
KW  - motion model captures
KW  - mass dynamics
KW  - low-dimensionality
KW  - holistic approach
KW  - three-dimensional parametric space
KW  - computational efficiency
KW  - sequential approach
KW  - customized optimization
KW  - current step duration
KW  - optimal solutions
KW  - bipedal locomotion
KW  - Optimization
KW  - Foot
KW  - Legged locomotion
KW  - Robustness
KW  - Lips
KW  - Dynamics
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8461101
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper studies bipedal locomotion as a nonlinear optimization problem based on continuous and discrete dynamics, by simultaneously optimizing the remaining step duration, the next step duration and the foot location to achieve robustness. The linear inverted pendulum as the motion model captures the center of mass dynamics and its low-dimensionality makes the problem more tractable. We first formulate a holistic approach to search for optimality in the three-dimensional parametric space and use these results as baseline. To further improve computational efficiency, our study investigates a sequential approach with two stages of customized optimization that first optimizes the current step duration, and subsequently the duration and location of the next step. The effectiveness of both approaches is successfully demonstrated in simulation by applying different perturbations. The comparison study shows that these two approaches find mostly the same optimal solutions, but the latter requires considerably less computational time, which suggests that the proposed sequential approach is well suited for real-time implementation with a minor trade-off in optimality.
ER  - 

TY  - CONF
TI  - Torque-Based Dynamic Walking - A Long Way from Simulation to Experiment
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 440
EP  - 447
AU  - J. Englsberger
AU  - G. Mesesan
AU  - A. Werner
AU  - C. Ott
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - torque control
KW  - torque-based dynamic walking - a long way
KW  - torque-controlled robots
KW  - trajectory generation
KW  - DCM controller
KW  - whole-body controller
KW  - WBC
KW  - full-body walking behavior
KW  - sophisticated walking gaits
KW  - original control framework
KW  - divergent component
KW  - Legged locomotion
KW  - Task analysis
KW  - Foot
KW  - Trajectory
KW  - Force
KW  - Torque
DO  - 10.1109/ICRA.2018.8462862
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents methods that facilitate the implementation of dynamic walking on torque-controlled robots in real world experiments. The work uses the Divergent Component of Motion (DCM) for walking trajectory generation and control. The DCM controller is embedded into a whole-body controller (WBC) that produces a full-body walking behavior. While in simulation the combination of DCM and WBC is sufficient for achieving sophisticated walking gaits, during our initial experiments several real-world issues, detailed in this paper, prevented the original control framework from functioning. This work presents the improvements to the original control framework that enabled a breakthrough on the way to achieving torque-based dynamic walking on a real robot.
ER  - 

TY  - CONF
TI  - Online Falling-Over Control of Humanoids Exploiting Energy Shaping and Distribution Methods
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 448
EP  - 454
AU  - R. Subburaman
AU  - J. Lee
AU  - D. G. Caldwell
AU  - N. G. Tsagarakis
PY  - 2018
KW  - end effectors
KW  - humanoid robots
KW  - nonlinear control systems
KW  - position control
KW  - energy distribution polygons
KW  - humanoid robot
KW  - lateral falls
KW  - sagittal falls
KW  - EDP concepts
KW  - total energy
KW  - impact forces
KW  - online falling-over control
KW  - fall control technique
KW  - energy concepts
KW  - orientation control
KW  - energy shaping
KW  - nonlinear control
KW  - ES concepts
KW  - humanoids
KW  - end effectors
KW  - Force
KW  - Numerical models
KW  - Energy conversion
KW  - Robot kinematics
KW  - Position control
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8462880
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes a novel fall control technique based on energy concepts, which can be applied online to mitigate the impact forces incurred during the falling over of humanoids. The technique reduces the total energy using a nonlinear control tool, called energy shaping (ES), and further distributes the reduced energy over multiple contacts by means of energy distribution polygons (EDP). We also include an effective orientation control to safeguard the end-effectors in the event of ground impacts. The performance of the proposed method is numerically evaluated by dynamic simulations under the sudden falling over scenario of the humanoid robot for both lateral and sagittal falls. The effectiveness of the proposed ES and EDP concepts are verified by diverse comparative simulations with total energy, distribution, and impact forces.
ER  - 

TY  - CONF
TI  - Low-Cost Electromechanical Actuator Arrays for Tactile Display Applications
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 471
EP  - 476
AU  - M. Karpelson
AU  - R. Peña
AU  - R. J. Wood
PY  - 2018
KW  - electromechanical actuators
KW  - handicapped aids
KW  - haptic interfaces
KW  - low-cost electromechanical actuator array
KW  - tactile display applications
KW  - dynamic tactile displays
KW  - compact tactile display
KW  - low-displacement bistable actuators
KW  - haptic devices
KW  - visually impaired
KW  - blind
KW  - low-force bistable actuators
KW  - 6-dot Braille cell
KW  - Actuators
KW  - Force
KW  - Ball bearings
KW  - Inductors
KW  - Magnetic levitation
KW  - Prototypes
KW  - Magnetic flux
KW  - haptics
KW  - tactile display
KW  - actuator array
KW  - low cost
KW  - Braille
KW  - visually impaired
KW  - assistive device
DO  - 10.1109/ICRA.2018.8460909
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Dynamic tactile displays represent a class of haptic devices of particular interest to the blind and visually impaired. Despite many years of research and development efforts, the low-cost, low-power, compact tactile display remains elusive. This paper describes a low-cost electromechanical actuator array based on low-force, low-displacement bistable actuators that can be realized using inexpensive, commercially available components and high-volume manufacturing processes. The array is applicable to several types of tactile displays; as an initial proof of concept, we demonstrate a 6-dot Braille cell with a 3mm pitch that requires less than 50mJ per actuator per transition.
ER  - 

TY  - CONF
TI  - High Stiffness in Teleoperated Comanipulation: Necessity or Luxury?
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 477
EP  - 483
AU  - L. Roche
AU  - L. Saint-Bauzel
PY  - 2018
KW  - decision making
KW  - elastic constants
KW  - human-robot interaction
KW  - manipulators
KW  - telerobotics
KW  - teleoperated comanipulation
KW  - high stiffness controllers
KW  - human dyads
KW  - comanipulative tasks
KW  - low-level interactions
KW  - high-level interactions
KW  - decision-making
KW  - teleoperated control
KW  - physical human-human interaction
KW  - Task analysis
KW  - Force
KW  - Haptic interfaces
KW  - Visualization
KW  - Impedance
KW  - Measurement
KW  - Robots
DO  - 10.1109/ICRA.2018.8461005
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The present paper investigates if and in which conditions does the implementation of high stiffness controllers increase the performances of human dyads during comanipulative tasks in physical Human-Human Interaction (pHHI) settings. Two experiments are conducted which cover two fundamental aspects of pHHI: low-level interactions allowing interpersonal coordination, and high-level interactions allowing common decision-making and negotiation of strategies. The results of these experiments show that high stiffness is not necessary for good performances when the task only requires low-level interactions. On the contrary, when dealing with high-level interactions, higher stiffness increases task performance. The results presented highlight the importance of the quality of teleoperated control in setups used for the study of pHHI.
ER  - 

TY  - CONF
TI  - Scaling Inertial Forces to Alter Weight Perception in Virtual Reality
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 484
EP  - 489
AU  - J. M. Suchoski
AU  - S. Martinez
AU  - A. M. Okamura
PY  - 2018
KW  - force feedback
KW  - haptic interfaces
KW  - rendering (computer graphics)
KW  - virtual reality
KW  - force output
KW  - haptic device
KW  - wearable devices
KW  - user-grounded feedback modality
KW  - force-output saturation
KW  - virtual environment
KW  - virtual object
KW  - scaled inertial forces
KW  - virtual weight perception
KW  - haptic feedback
KW  - wearable skin deformation feedback devices
KW  - virtual blocks
KW  - inertial scaling factors
KW  - virtual reality
KW  - kinesthetic force feedback devices
KW  - haptic rendering algorithm
KW  - inertial force scaling
KW  - point of subjective equality
KW  - mass 200.0 g
KW  - mass 171.0 g
KW  - mass 151.0 g
KW  - Skin
KW  - Haptic interfaces
KW  - Strain
KW  - Force
KW  - Virtual environments
KW  - Training
DO  - 10.1109/ICRA.2018.8462874
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - As the field of haptics in virtual reality expands, wearable devices are being explored as alternatives to traditional kinesthetic force feedback devices, which are often limited in workspace. Skin deformation feedback offers a user-grounded feedback modality that mimics cutaneous interactions with the real world but can suffer from force-output saturation due to the actuation constraints required to achieve a small form factor. Saturation of haptic devices limits the mechanical properties and interactions that can be rendered in a virtual environment, specifically the weight that can be rendered when a user manipulates a virtual object. We use scaled inertial forces to alter virtual weight perception during a dynamic grasp-lift-and-place task in a virtual environment with haptic feedback via two wearable skin deformation feedback devices. A study was conducted, beginning with an open response exercise to assess how participants interpreted scaled inertial forces when interacting with virtual blocks. Participants then performed a series of trials to measure the Point of Subjective Equality of virtual weight with scaled inertial forces, using a reference of 200 g under the normal (no scaling) condition. PSEs for inertial scaling factors of 2 and 3 were 171 g and 151 g, respectively. These results demonstrate the effectiveness of a unique haptic rendering algorithm that can convey larger weights without saturating the force output of the haptic device.
ER  - 

TY  - CONF
TI  - Effects of Latency and Refresh Rate on Force Perception via Sensory Substitution by Force-Controlled Skin Deformation Feedback
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 506
EP  - 511
AU  - Z. A. Zook
AU  - A. M. Okamura
AU  - Y. Kamikawa
PY  - 2018
KW  - control engineering computing
KW  - damping
KW  - force feedback
KW  - haptic interfaces
KW  - medical robotics
KW  - robot kinematics
KW  - skin
KW  - telerobotics
KW  - sensory substitution
KW  - force-controlled skin deformation feedback device
KW  - 3-degree-of-freedom kinesthetic force feedback device
KW  - damping
KW  - reference object
KW  - human force perception
KW  - latency
KW  - refresh rate
KW  - Skin
KW  - Strain
KW  - Force
KW  - Force feedback
KW  - Damping
KW  - Delay effects
DO  - 10.1109/ICRA.2018.8462883
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Latency and refresh rate are known to adversely affect human force perception in bilateral teleoperators and virtual environments using kinesthetic force feedback, motivating the use of sensory substitution of force. The purpose of this study is to quantify the effects of latency and refresh rate on force perception using sensory substitution by skin deformation feedback. A force-controlled skin deformation feedback device was attached to a 3-degree-of-freedom kinesthetic force feedback device used for position tracking and gravity support. A human participant study was conducted to determine the effects of latency and refresh rate on perceived stiffness and damping with skin deformation feedback. Participants compared two virtual objects: a comparison object with stiffness or damping that could be tuned by the participant, and a reference object with either added latency or reduced refresh rate. Participants modified the stiffness or damping of the tunable object until it resembled the stiffness or damping of the reference object. We found that added latency and reduced refresh rate both increased perceived stiffness but had no effect on perceived damping. Specifically, participants felt significantly different stiffness when the latency exceeded 300 ms and the refresh rate dropped below 16.6 Hz. The impact of latency and refresh rate on force perception via skin deformation feedback was significantly less than what has been previously shown for kinesthetic force feedback.
ER  - 

TY  - CONF
TI  - Know Rob 2.0 — A 2nd Generation Knowledge Processing Framework for Cognition-Enabled Robotic Agents
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 512
EP  - 519
AU  - M. Beetz
AU  - D. Beßler
AU  - A. Haidu
AU  - M. Pomarlan
AU  - A. K. Bozcuoğlu
AU  - G. Bartels
PY  - 2018
KW  - knowledge based systems
KW  - knowledge representation
KW  - manipulator kinematics
KW  - manipulators
KW  - service robots
KW  - complex manipulation tasks
KW  - chemical experiments
KW  - first-order time interval logic knowledge base
KW  - logical expressions
KW  - robotics algorithms
KW  - motion planning
KW  - open-ended manipulation skills
KW  - commonsense knowledge
KW  - 2nd generation knowledge processing framework
KW  - cognition-enabled robotic agents
KW  - generation knowledge representation
KW  - advanced knowledge
KW  - inverse kinematic problem solving
KW  - KnowRob2.0
KW  - Robots
KW  - Cognition
KW  - Data structures
KW  - Ontologies
KW  - Task analysis
KW  - Knowledge based systems
KW  - Physics
DO  - 10.1109/ICRA.2018.8460964
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present KnowRob2, a second generation knowledge representation and reasoning framework for robotic agents. KnowRob2 is an extension and partial redesign of KnowRob, currently one of the most advanced knowledge processing systems for robots that has enabled them to successfully perform complex manipulation tasks such as making pizza, conducting chemical experiments, and setting tables. The knowledge base appears to be a conventional first-order time interval logic knowledge base, but it exists to a large part only virtually: many logical expressions are constructed on demand from data structures of the control program, computed through robotics algorithms including ones for motion planning and solving inverse kinematics problems, and log data stored in noSQL databases. Novel features and extensions of KnowRob2 substantially increase the capabilities of robotic agents of acquiring open-ended manipulation skills and competence, reasoning about how to perform manipulation actions more realistically, and acquiring commonsense knowledge.
ER  - 

TY  - CONF
TI  - Intuitive Constraint-Based Robot Programming for Robotic Assembly Tasks* The research leading to these results has received funding from the European Unions Seventh Framework Programme FP7/2013-2017 under grant agreement n 608604 (LIAA: Lean Intelligent Assembly Automation) and Horizon 2020 Research and Innovation Programme under grant agreement n 688642 (RAMPup).
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 520
EP  - 526
AU  - L. Halt
AU  - F. Nagele
AU  - P. Tenbrock
AU  - A. Pott
PY  - 2018
KW  - assembling
KW  - manipulators
KW  - mobile robots
KW  - robot programming
KW  - robotic assembly
KW  - intuitive constraint-based robot programming
KW  - robotic assembly tasks
KW  - recent intuitive robot programming approaches
KW  - encapsulating robot capabilities
KW  - general guidelines
KW  - assembly process descriptions
KW  - German Engineers VDI
KW  - particular addressing assembly applications
KW  - constraint-based approach iTaSC
KW  - elementary processes
KW  - exemplarily assembly tasks
KW  - instantaneous task specification
KW  - Task analysis
KW  - Robot sensing systems
KW  - Robot programming
KW  - Guidelines
KW  - Robotic assembly
DO  - 10.1109/ICRA.2018.8462882
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recent intuitive robot programming approaches operate on task level, enabling programmers to intuitively arrange or compose encapsulating robot capabilities (skills). This paper presents an approach to intuitively create (sub-)skills. General guidelines for assembly process descriptions #2860 provided by the Association of German Engineers VDI are applied to robot programming, in particular addressing assembly applications. The guidelines are exemplarily applied to the constraint-based approach iTaSC (instantaneous Task Specification using Constraints), presenting a procedure to hierarchically combine elementary processes to (sub-)skills. Six elementary processes are identified to be sufficient to implement a wide variety of assembly tasks. An iTaSC implementation was developed and two exemplarily assembly tasks were realized to evaluate the approach.
ER  - 

TY  - CONF
TI  - MaestROB: A Robotics Framework for Integrated Orchestration of Low-Level Control and High-Level Reasoning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 527
EP  - 534
AU  - A. Munawar
AU  - G. De Magistris
AU  - T. Pham
AU  - D. Kimura
AU  - M. Tatsubori
AU  - T. Moriyama
AU  - R. Tachibana
AU  - G. Booch
PY  - 2018
KW  - humanoid robots
KW  - human-robot interaction
KW  - industrial robots
KW  - inference mechanisms
KW  - intelligent robots
KW  - middleware
KW  - multi-robot systems
KW  - ontologies (artificial intelligence)
KW  - robot programming
KW  - service robots
KW  - MaestROB
KW  - integrated orchestration
KW  - low-level control
KW  - high-level reasoning
KW  - MaestROBe
KW  - complex tasks
KW  - simple high-level instructions
KW  - hierarchical structure
KW  - ontology
KW  - actuation control
KW  - symbolic planner
KW  - Watson APIs
KW  - cognitive capabilities
KW  - semantic understanding
KW  - open source robot middleware
KW  - complex scenario
KW  - communication robot
KW  - industrial robot
KW  - common industrial task
KW  - assembly task
KW  - humanoid robot
KW  - SoftBank Robotics
KW  - natural language conversation
KW  - human demonstration
KW  - collaborative robot arm
KW  - Universal Robots
KW  - robotic framework
KW  - Task analysis
KW  - Service robots
KW  - Natural languages
KW  - Robot kinematics
KW  - Middleware
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8462870
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes a framework called MaestROBe It is designed to make the robots perform complex tasks with high precision by simple high-level instructions given by natural language or demonstration. To realize this, it handles a hierarchical structure by using the knowledge stored in the forms of ontology and rules for bridging among different levels of instructions. Accordingly, the framework has multiple layers of processing components; perception and actuation control at the low level, symbolic planner and Watson APIs for cognitive capabilities and semantic understanding, and orchestration of these components by a new open source robot middleware called Project Intu at its core. We show how this framework can be used in a complex scenario where multiple actors (human, a communication robot, and an industrial robot) collaborate to perform a common industrial task. Human teaches an assembly task to Pepper (a humanoid robot from SoftBank Robotics) using natural language conversation and demonstration. Our framework helps Pepper perceive the human demonstration and generate a sequence of actions for UR5 (collaborative robot arm from Universal Robots), which ultimately performs the assembly (e.g. insertion) task.
ER  - 

TY  - CONF
TI  - Ctrl-MORE: A Framework to Integrate Controllers of Multi-DoF Robot for Developers and Users
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 543
EP  - 549
AU  - J. A. Castano
AU  - P. Kryczka
AU  - B. Delhaisse
AU  - C. Zhou
AU  - N. G. Tsagarakis
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - robust control
KW  - software architecture
KW  - trajectory control
KW  - multiDoF robot
KW  - robotic applications
KW  - modular framework
KW  - software architecture
KW  - control developers
KW  - feedback controllers
KW  - coupling
KW  - software modules
KW  - Ctrl-MORE
KW  - manipulation
KW  - locomotion
KW  - vision
KW  - stabilizers
KW  - trajectory planners
KW  - robustness
KW  - Robots
KW  - Documentation
KW  - Software
KW  - Task analysis
KW  - Computer architecture
KW  - Hardware
KW  - Tools
DO  - 10.1109/ICRA.2018.8460947
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In recent years, many different feedback controllers for robotic applications have been proposed and implemented. However, the high coupling between the different software modules made their integration into one common architecture difficult. Consequently, this has hindered the ability of a user to employ the different controllers into a single, general and modular framework. To address this problem, we present Ctrl-MORE, a software architecture developed to fill the gap between control developers and other users in robotic applications. On one hand, Ctrl-MORE aims to provide developers with an opportunity to integrate easily and share their controllers with other roboticists working in different areas. For example, manipulation, locomotion, vision and so on. On the other hand, it provides to end-users a tool to apply the additional control strategies that guarantee the execution of desired behaviors in a transparent, yet efficient way. The proposed control architecture allows an easier integration of general purpose feedback controllers, such as stabilizers, with higher control layers such as trajectory planners, increasing the robustness of the overall system.
ER  - 

TY  - CONF
TI  - Cross-Layer Retrofitting of UAVs Against Cyber-Physical Attacks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 550
EP  - 557
AU  - F. Fei
AU  - Z. Tu
AU  - R. Yu
AU  - T. Kim
AU  - X. Zhang
AU  - D. Xu
AU  - X. Deng
PY  - 2018
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - security of data
KW  - vehicle dynamics
KW  - BlueBox
KW  - cyber-physical attacks
KW  - cyber-physical platform
KW  - unmanned aerial vehicles
KW  - security threats
KW  - sophisticated attacks
KW  - generic security framework
KW  - vehicle dynamics
KW  - cross-layer retrofitting
KW  - UAV
KW  - off-the-shelf quadcopter
KW  - controller
KW  - motors
KW  - operating system
KW  - vehicle control system
KW  - Software
KW  - Hardware
KW  - Security
KW  - Sensor fusion
KW  - Vehicle dynamics
KW  - Control systems
DO  - 10.1109/ICRA.2018.8462886
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - As a rapidly growing cyber-physical platform, unmanned aerial vehicles are facing more security threats as their capabilities and applications continue to expand. Adversaries with detailed knowledge about the vehicle could orchestrate sophisticated attacks that are not easily detected or handled by the vehicle's control system. In this work, we purpose a generic security framework, termed BlueBox, capable of detecting and handling a variety of cyber-physical attacks. To demonstrate an application of BlueBox in practice, we retrofitted an off-the-shelf quadcopter. A series of attacks were then launched by embedding malicious code in the control software and by altering the vehicle's hardware with the specific targeting of sensors, controller, motors, vehicle dynamics, and operating system. Experimental results verified that BlueBox was capable of both detecting a variety of cyber-physical attacks, while also providing the means in which to recover from such attacks.
ER  - 

TY  - CONF
TI  - A Prototype-Based Skill Model for Specifying Robotic Assembly Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 558
EP  - 565
AU  - F. Nägele
AU  - L. Halt
AU  - P. Tenbrock
AU  - A. Pott
PY  - 2018
KW  - robot programming
KW  - robotic assembly
KW  - specification languages
KW  - industrial assembly applications
KW  - Task Function Approach
KW  - Task Frame Formalism
KW  - model robot task description
KW  - robot tasks
KW  - model-based manipulation skills
KW  - robotic assembly tasks
KW  - prototype-based skill model
KW  - prototype-based inheritance
KW  - reuse
KW  - domain-specific languages
KW  - model coordination mechanisms
KW  - Task analysis
KW  - Robot kinematics
KW  - Kinematics
KW  - DSL
KW  - Libraries
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8462885
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In recent years, a number of publications described approaches for model-based manipulation skills and their applicability to a variety of robot tasks-be it assembly, industrial robotics in general, or service robotics. These approaches roughly follow the same pattern: They model robot task description based on the Task Frame Formalism, the Task Function Approach, or iTaSC. They model coordination mechanisms in form of statecharts or Petri nets. And almost all models are accompanied by domain-specific languages (DSLs) that facilitate creating applications based on those models. While one advantage of using models is their reusability across applications, how to explicitly model the reuse itself has not been fully addressed by these publications. Our paper contributes to this field of research by investigating how reuse can be explicitly modeled using prototype-based inheritance. We base our model on iTaSC and provide a simple yet effective DSL for populating the model and creating applications. We demonstrate our approach by creating a comprehensive library of skills, and by showing the use, reuse and incremental refinement of skills for diverse industrial assembly applications.
ER  - 

TY  - CONF
TI  - Facilitating Model-Based Control Through Software-Hardware Co-Design
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 566
EP  - 572
AU  - J. Ramos
AU  - B. Katz
AU  - M. Y. M. Chuah
AU  - S. Kim
PY  - 2018
KW  - actuators
KW  - control engineering computing
KW  - force control
KW  - hardware-software codesign
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - robot dynamics
KW  - model-based control
KW  - design process
KW  - legged machines
KW  - dynamic behaviors
KW  - high performance robots
KW  - design requirements
KW  - control algorithm
KW  - physical robot
KW  - actuation
KW  - natural dynamic behavior
KW  - physical machine
KW  - legged robots
KW  - high bandwidth force control
KW  - software-hardware codesign processes
KW  - robotic control
KW  - robotic platforms
KW  - hardware design choices
KW  - model-based balance controller
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Actuators
KW  - Hardware
KW  - Torque
DO  - 10.1109/ICRA.2018.8460575
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper exemplifies the design process for legged machines capable of dynamic behaviors. In order to achieve high performance robots, it is crucial to guarantee harmonious integration between software and hardware. Hence, the development of such capable robotic platforms must address design requirements that meet the assumptions of typical model-based controllers but also respect the physical limitations of a real system. First, we show that proper hardware design choices can greatly aid the control algorithm by approximating the physical robot to the template assumptions. We include actuation and sensing design examples that allows a simple model to capture a major portion of the natural dynamic behavior of the physical machine. Results are applied to a real robot (Figure 1) and we show that the adopted methodology is able to address typical problems in legged robots such as high bandwidth force control and robustness to impact. Finally, a simple model-based balance controller that takes advantage of the fidelity of the template model to the real machine is implemented. These are examples of software-hardware codesign processes that vastly facilitate robotic control.
ER  - 

TY  - CONF
TI  - Multilayered Kinodynamics Simulation for Detailed Whole-Body Motion Generation and Analysis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 581
EP  - 587
AU  - A. Murai
AU  - M. Tada
PY  - 2018
KW  - biomedical measurement
KW  - fracture
KW  - gait analysis
KW  - injuries
KW  - kinematics
KW  - Monte Carlo methods
KW  - whole-body motions
KW  - whole-body motion generation
KW  - vertical contact force
KW  - human motion mechanisms
KW  - whole-body human model
KW  - MLKD Sim
KW  - multilayered kinodynamics simulation
KW  - Dynamics
KW  - Computational modeling
KW  - Force
KW  - Legged locomotion
KW  - Kinematics
KW  - Data models
KW  - Analytical models
DO  - 10.1109/ICRA.2018.8460719
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This study generates and analyzes unsafe human motions that cannot be measured experimentally in laboratories with dynamic consistency. Detailed whole-body motions are generated by a multilayered kinodynamics simulation (MLKD Sim) that uses a detailed digital whole-body human model and a simple motion-representation model that parametrically represents human motion mechanisms. First, we develop the simple motion-representation model that represents human motion and contact force data that are experimentally measured in a laboratory, and we identify this model's parameters based on these experimental data. Forward dynamics computation of this motion-representation model with changing model and/or environmental parameters simulates motion modification as well as a contact force with dynamic consistency. Finally, the mapping function from the motion-representation model's motion to the detailed motion identified from the experimental data is used to reconstruct the detailed whole-body motion. MLKD Sim reconstructs a vertical contact force with average error of 2.18E+02 N, center of mass trajectory with average error of 3.31E-02 m, ankle joint angle with average error of 1.11E-01 rad (2.95E+00%), and ankle joint torque with average error of 6.13E+01 Nm (1.93E+01%). Unsafe motion simulation results show that the physical load on the hip, knee, and ankle joints increases by 9.23E+01%, 5.42E+02%, and 1.45E+02% respectively with 0.5-m level difference in a running surface. These results imply that when sprinting in an unknown environment, we need to protect, in order, the knee ankle, and hip joints. This study conducts detailed dynamics and kinematics analysis of unsafe human motions that cannot be measured experimentally in laboratories to prevent injuries, falls, and fatigue, and these results should find applications in the fields of medicine and welfare.
ER  - 

TY  - CONF
TI  - Inference of User Qualities in Shared Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 588
EP  - 595
AU  - U. Acharya
AU  - S. Kunde
AU  - L. Hall
AU  - B. A. Duncan
AU  - J. M. Bradley
PY  - 2018
KW  - groupware
KW  - human-robot interaction
KW  - telerobotics
KW  - Human-Robot Interaction
KW  - shared control
KW  - telepresence robot
KW  - locus of control
KW  - teleoperation controllers
KW  - collaborative performance
KW  - robotic systems
KW  - Robots
KW  - Telepresence
KW  - Collision avoidance
KW  - Task analysis
KW  - Force
KW  - Human-robot interaction
KW  - System performance
DO  - 10.1109/ICRA.2018.8461193
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Users play an integral role in the performance of many robotic systems, and robotic systems must account for differences in users to improve collaborative performance. Much of the work in adapting to users has focused on designing teleoperation controllers that adjust to extrinsic user indicators such as force, or intent, but do not adjust to intrinsic user qualities. In contrast, the Human-Robot Interaction community has extensively studied intrinsic user qualities, but results may not rapidly be fed back into autonomy design. Here we provide foundational evidence for a new strategy that augments current shared control, and provide a mechanism to directly feed back results from the HRI community into autonomy design. Our evidence is based on a study examining the impact of the user quality “locus of control” on telepresence robot performance. Our results support our hypothesis that key user qualities can be inferred from human-robot interactions (such as through path deviation or time to completion) and that switching or adaptive autonomies might improve shared control performance.
ER  - 

TY  - CONF
TI  - Sample and Feedback Efficient Hierarchical Reinforcement Learning from Human Preferences
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 596
EP  - 601
AU  - R. Pinsler
AU  - R. Akrour
AU  - T. Osa
AU  - J. Peters
AU  - G. Neumann
PY  - 2018
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - human feedback
KW  - reward function
KW  - bi-perspective reward learning
KW  - simulated robot grasping task
KW  - general hierarchical reinforcement learning framework
KW  - robot perspective
KW  - feedback efficiency
KW  - physical robot
KW  - informative reward function
KW  - human preferences
KW  - Robots
KW  - Grasping
KW  - Task analysis
KW  - Trajectory
KW  - Learning (artificial intelligence)
KW  - Context modeling
KW  - Customer relationship management
DO  - 10.1109/ICRA.2018.8460907
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - While reinforcement learning has led to promising results in robotics, defining an informative reward function is challenging. Prior work considered including the human in the loop to jointly learn the reward function and the optimal policy. Generating samples from a physical robot and requesting human feedback are both taxing efforts for which efficiency is critical. We propose to learn reward functions from both the robot and the human perspectives to improve on both efficiency metrics. Learning a reward function from the human perspective increases feedback efficiency by assuming that humans rank trajectories according to a low-dimensional outcome space. Learning a reward function from the robot perspective circumvents the need for a dynamics model while retaining the sample efficiency of model-based approaches. We provide an algorithm that incorporates bi-perspective reward learning into a general hierarchical reinforcement learning framework and demonstrate the merits of our approach on a toy task and a simulated robot grasping task.
ER  - 

TY  - CONF
TI  - Investigation of Communicative Flight Paths for Small Unmanned Aerial Systems * This work was supported by NSF NRI 1638099
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 602
EP  - 609
AU  - B. A. Duncan
AU  - E. Beachly
AU  - A. Bevins
AU  - S. Elbaum
AU  - C. Detweiler
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - humanoid robots
KW  - human-robot interaction
KW  - human-humanoid robot interactions
KW  - avian flight paths
KW  - sUAS manufacturers
KW  - sUAS flight paths
KW  - human-robot interaction
KW  - small Unmanned Aerial System flight paths
KW  - human-human interactions
KW  - Biology
KW  - Humanoid robots
KW  - Stakeholders
KW  - Batteries
KW  - Aerospace electronics
KW  - Service robots
DO  - 10.1109/ICRA.2018.8462871
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This project seeks to generate small Unmanned Aerial System (sUAS) flight paths that are broadly understood by the general population and can communicate states about both the sUAS and its understanding of the world. Previous work in sUAS flight paths has sought to communicate intent, destination, or emotion of the system without focusing on concrete states (e.g., low battery, landing, etc.). This work leverages biologically-based flight paths and experimental methodologies from human-human and human-humanoid robot interactions to assess the understanding of avian flight paths to communicate sUAS states to novice users. If successful, this work should inform: the human-robot interaction community about the perception of flight paths, sUAS manufacturers on how their systems could communicate with both operators and bystanders, and end users on ways to communicate with others when flying systems in public spaces. General design implications and future directions of work are suggested to build on the results here, which suggest that novice users gravitate towards labels they understand (draw attention and landing) while avoiding more technical labels (lost sensor).
ER  - 

TY  - CONF
TI  - Inverse Reinforcement Learning via Function Approximation for Clinical Motion Analysis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 610
EP  - 617
AU  - K. Li
AU  - M. Rath
AU  - J. W. Burdick
PY  - 2018
KW  - function approximation
KW  - image motion analysis
KW  - injuries
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - neurophysiology
KW  - Bellman Optimality Equation
KW  - reward learning
KW  - inverse reinforcement learning
KW  - learned reward function
KW  - computationally expensive reinforcement learning problems
KW  - function approximation method
KW  - clinical motion analysis
KW  - Learning (artificial intelligence)
KW  - Mathematical model
KW  - Trajectory
KW  - Function approximation
KW  - Spinal cord injury
KW  - Markov processes
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460563
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces a new method for inverse reinforcement learning in large state spaces, where the learned reward function can be used to control high-dimensional robot systems and analyze complex human movement. To avoid solving the computationally expensive reinforcement learning problems in reward learning, we propose a function approximation method to ensure that the Bellman Optimality Equation always holds, and then estimate a function to maximize the likelihood of the observed motion. The time complexity of the proposed method is linearly proportional to the cardinality of the action set, thus it can handle large state spaces efficiently. We test the proposed method in a simulated environment on reward learning, and show that it is more accurate than existing methods and significantly better in scalability. We also show that the proposed method can extend many existing methods to large state spaces. We then apply the method to evaluating the effect of rehabilitative stimulations on patients with spinal cord injuries based on the observed patient motions.
ER  - 

TY  - CONF
TI  - Learning User Preferences in Robot Motion Planning Through Interaction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 619
EP  - 626
AU  - N. Wilde
AU  - D. Kulić
AU  - S. L. Smith
PY  - 2018
KW  - human-robot interaction
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - user preferences
KW  - robot motion planning
KW  - complex task specifications
KW  - human-robot interaction
KW  - temporal constraints
KW  - complex robot tasks
KW  - user constraint
KW  - user-optimal path
KW  - spatial constraints
KW  - Task analysis
KW  - Service robots
KW  - Roads
KW  - Robot motion
KW  - Planning
KW  - Shortest path problem
DO  - 10.1109/ICRA.2018.8460586
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we develop an approach for learning user preferences for complex task specifications through human-robot interaction. We consider the problem of planning robot motion in a known environment, but where a user has specified additional spatial and temporal constraints on allowable robot motions. To illustrate the impact of the user's constraints on performance, we iteratively present users with alternative solutions on an interface. The user provides a ranking of alternate paths, and from this we learn about the importance of different constraints. This allows for an accessible method for specifying complex robot tasks. We present an algorithm that iteratively builds a set of constraints on the relative importance of each user constraint, and prove that with sufficient interaction, the algorithm determines a user-optimal path. We demonstrate the practical performance by simulating realistic material transport scenarios in industrial facilities.
ER  - 

TY  - CONF
TI  - Deep-LK for Efficient Adaptive Object Tracking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 627
EP  - 634
AU  - C. Wang
AU  - H. K. Galoogahi
AU  - C. Lin
AU  - S. Lucey
PY  - 2018
KW  - feature extraction
KW  - object detection
KW  - object tracking
KW  - regression analysis
KW  - GOTURN
KW  - Siamese regression networks
KW  - IC-LK framework
KW  - Deep-LK
KW  - adaptive object tracking
KW  - regression-based object tracking
KW  - Generic Object Tracking Using Regression Networks framework
KW  - Inverse Compositional Lucas & Kanade algorithm
KW  - Object tracking
KW  - Mathematical model
KW  - Robustness
KW  - Feature extraction
KW  - Linear regression
KW  - Videos
KW  - Strain
DO  - 10.1109/ICRA.2018.8460815
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a new approach for efficient regression-based object tracking. Our approach is closely related to the Generic Object Tracking Using Regression Networks (GOTURN) framework [1]. We make the following contributions. First, we demonstrate that there is a theoretical relationship between Siamese regression networks like GOTURN and the classical Inverse Compositional Lucas & Kanade (IC-LK) algorithm. Further, we demonstrate that unlike GOTURN, IC-LK adapts its regressor to the appearance of the current tracked frame. We argue that the lack of such property in GOTURN attributes to its poor performance on unseen objects and/or viewpoints. Second, we propose a novel framework for object tracking inspired by the IC-LK framework, which we refer to as Deep-LK. Finally, we show impressive results demonstrating that Deep-LK substantially outperforms GOTURN and demonstrate comparable tracking performance against current state-of-the-art deep trackers on high frame-rate sequences whilst being an order of magnitude (100 FPS) computationally efficient.
ER  - 

TY  - CONF
TI  - End-to-end Learning of Multi-sensor 3D Tracking by Detection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 635
EP  - 642
AU  - D. Frossard
AU  - R. Urtasun
PY  - 2018
KW  - image matching
KW  - learning (artificial intelligence)
KW  - linear programming
KW  - object detection
KW  - object tracking
KW  - target tracking
KW  - 3D trajectories
KW  - multisensor 3D tracking
KW  - end-to-end learning
KW  - convolutional networks
KW  - linear program
KW  - LIDAR data
KW  - Trajectory
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Tracking
KW  - Cameras
KW  - Neural networks
KW  - Radar tracking
DO  - 10.1109/ICRA.2018.8462884
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a novel approach to tracking by detection that can exploit both cameras as well as LIDAR data to produce very accurate 3D trajectories. Towards this goal, we formulate the problem as a linear program that can be solved exactly, and learn convolutional networks for detection as well as matching in an end-to-end manner. We evaluate our model in the challenging KITTI dataset and show very competitive results.
ER  - 

TY  - CONF
TI  - Visual Articulated Tracking in the Presence of Occlusions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 643
EP  - 650
AU  - C. Rauch
AU  - T. Hospedales
AU  - J. Shotton
AU  - M. Fallon
PY  - 2018
KW  - image colour analysis
KW  - iterative methods
KW  - manipulators
KW  - object tracking
KW  - robot vision
KW  - RGB-D camera
KW  - manipulated object
KW  - per-pixel data-to-model associations
KW  - tracked object
KW  - Iterative Closest Point
KW  - visual articulated tracking
KW  - robotic manipulator
KW  - Manipulators
KW  - Data models
KW  - Visualization
KW  - Robot sensing systems
KW  - Training
KW  - Radio frequency
DO  - 10.1109/ICRA.2018.8462873
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper focuses on visual tracking of a robotic manipulator during manipulation. In this situation, tracking is prone to failure when visual distractions are created by the object being manipulated and the clutter in the environment. Current state-of-the-art approaches, which typically rely on model-fitting using Iterative Closest Point (ICP), fail in the presence of distracting data points and are unable to recover. Meanwhile, discriminative methods which are trained only to distinguish parts of the tracked object can also fail in these scenarios as data points from the occlusions are incorrectly classified as being from the manipulator. We instead propose to use the per-pixel data-to-model associations provided from a random forest to avoid local minima during model fitting. By training the random forest with artificial occlusions we can achieve increased robustness to occlusion and clutter present in the scene. We do this without specific knowledge about the type or location of the manipulated object. Our approach is demonstrated by using dense depth data from an RGB-D camera to track a robotic manipulator during manipulation and in presence of occlusions.
ER  - 

TY  - CONF
TI  - Planar Object Tracking in the Wild: A Benchmark
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 651
EP  - 658
AU  - P. Liang
AU  - Y. Wu
AU  - H. Lu
AU  - L. Wang
AU  - C. Liao
AU  - H. Ling
PY  - 2018
KW  - image motion analysis
KW  - image sequences
KW  - object detection
KW  - object tracking
KW  - robot vision
KW  - video signal processing
KW  - vision-based robotic applications
KW  - evaluating state-of-the-art algorithms
KW  - carefully designed planar object tracking benchmark
KW  - planar objects
KW  - Object tracking
KW  - Benchmark testing
KW  - Cameras
KW  - Target tracking
KW  - Robots
DO  - 10.1109/ICRA.2018.8461037
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Planar object tracking is an actively studied problem in vision-based robotic applications. While several benchmarks have been constructed for evaluating state-of-the-art algorithms, there is a lack of video sequences captured in the wild rather than in constrained laboratory environment. In this paper, we present a carefully designed planar object tracking benchmark containing 210 videos of 30 planar objects sampled in the natural environment. In particular, for each object, we shoot seven videos involving various challenging factors, namely scale change, rotation, perspective distortion, motion blur, occlusion, out-of-view, and unconstrained. The ground truth is carefully annotated semi-manually to ensure the quality. Moreover, eleven state-of-the-art algorithms are evaluated on the benchmark using two evaluation metrics, with detailed analysis provided for the evaluation results. We expect the proposed benchmark to benefit future studies on planar object tracking.
ER  - 

TY  - CONF
TI  - Constrained Confidence Matching for Planar Object Tracking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 659
EP  - 666
AU  - T. Wang
AU  - H. Ling
AU  - C. Lang
AU  - S. Feng
AU  - Y. Jin
AU  - Y. Li
PY  - 2018
KW  - image matching
KW  - image motion analysis
KW  - Kalman filters
KW  - motion estimation
KW  - object detection
KW  - object tracking
KW  - tracking
KW  - template tracking algorithms
KW  - occlusion detector
KW  - motion estimation
KW  - state-of-the-art planar object trackers
KW  - robust Kalman filter
KW  - planar object tracking
KW  - heavy motion blur
KW  - Robustness
KW  - Lighting
KW  - Perturbation methods
KW  - Object tracking
KW  - Kalman filters
KW  - Visualization
DO  - 10.1109/ICRA.2018.8460680
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Tracking planar objects has a wide range of applications in robotics. Conventional template tracking algorithms, however, often fail to observe fast object motion or drift significantly after a period of time, due to drastic object appearance change. To address such challenges, we propose a novel constrained confidence matching algorithm for motion estimation and a robust Kalman filter for template updating. Integrated with an accurate occlusion detector, our approach achieves accurate motion estimation in presence of partial occlusion, by excluding occluded pixels from computation of motion parameters. Furthermore, the proposed Kalman filter employs a novel control-input model to handle the object appearance change, which brings our tracker high robustness against sudden illumination change and heavy motion blur. For evaluation, we compare the proposed tracker with several state-of-the-art planar object trackers on two public benchmark datasets. Experimental results show that our algorithm achieves robust tracking results against various environmental variations, and outperforms baseline algorithms remarkably on both datasets.
ER  - 

TY  - CONF
TI  - Deep Forward and Inverse Perceptual Models for Tracking and Prediction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 675
EP  - 682
AU  - A. Lambert
AU  - A. Shaban
AU  - A. Raj
AU  - Z. Liu
AU  - B. Boots
PY  - 2018
KW  - deconvolution
KW  - feedforward neural nets
KW  - image sensors
KW  - Kalman filters
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - nonlinear filters
KW  - state estimation
KW  - high-dimensional images
KW  - deconvolutional methods
KW  - robotic system
KW  - robot trajectories
KW  - convolutional neural network model
KW  - photo-realistic images
KW  - image generation
KW  - video frames
KW  - perceptual model
KW  - robotics
KW  - inverse models
KW  - inverse perceptual models
KW  - Predictive models
KW  - Inverse problems
KW  - Robot sensing systems
KW  - Kinematics
KW  - Training
DO  - 10.1109/ICRA.2018.8461050
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the problems of learning forward models that map state to high-dimensional images and inverse models that map high-dimensional images to state in robotics. Specifically, we present a perceptual model for generating video frames from state with deep networks, and provide a framework for its use in tracking and prediction tasks. We show that our proposed model greatly outperforms standard deconvolutional methods and GANs for image generation, producing clear, photo-realistic images. We also develop a convolutional neural network model for state estimation and compare the result to an Extended Kalman Filter to estimate robot trajectories. We validate all models on a real robotic system.
ER  - 

TY  - CONF
TI  - ModQuad: The Flying Modular Structure that Self-Assembles in Midair
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 691
EP  - 698
AU  - D. Saldaña
AU  - B. Gabrich
AU  - G. Li
AU  - M. Yim
AU  - V. Kumar
PY  - 2018
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multi-robot systems
KW  - robot dynamics
KW  - self-assembly
KW  - midair
KW  - modular robotic structure
KW  - self-assemble
KW  - agile flying modules
KW  - quadrotor platform
KW  - ModQuad swarm
KW  - modular flying structures
KW  - decentralized modular attitude controller
KW  - docking method
KW  - flying modular structure
KW  - flying structure assembling
KW  - cooperative flying method
KW  - Robot kinematics
KW  - Rotors
KW  - Buildings
KW  - Payloads
KW  - Shape
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461014
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We introduce ModQuad, a novel flying modular robotic structure that is able to self-assemble in midair and cooperatively fly. The structure is composed by agile flying modules that can easily move in a three dimensional environment. The module is based on a quadrotor platform within a cuboid frame which allows it to attach to other modules by matching vertical faces. Using this mechanism, a ModQuad swarm is able to rapidly assemble flying structures in midair using the robot bodies as building units. In this paper, we focus on two important tasks for modular flying structures. First, we propose a decentralized modular attitude controller to allow a team of physically connected modules to fly cooperatively. Second, we develop a docking method that drives pairs of structures to be attached in midair. Our method precisely aligns, and corrects motion errors during the docking process. In our experiments, we tested and analyzed the performance of the cooperative flying method for multiple configurations. We also tested the docking method with successful results.
ER  - 

TY  - CONF
TI  - Autonomous Battery Exchange of UAVs with a Mobile Ground Base
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 699
EP  - 705
AU  - É. Barrett
AU  - M. Reiling
AU  - S. Mirhassani
AU  - R. Meijering
AU  - J. Jager
AU  - N. Mimmo
AU  - F. Callegati
AU  - L. Marconi
AU  - R. Carloni
AU  - S. Stramigioli
PY  - 2018
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - mobile robots
KW  - multi-robot systems
KW  - planetary rovers
KW  - small scale UAV
KW  - autonomous battery exchange operation
KW  - autonomous operations
KW  - landed UAV
KW  - ground rover
KW  - autonomous outdoor experiments
KW  - collaborative software framework
KW  - robotic systems
KW  - persistence
KW  - battery exchange mechanism
KW  - service station
KW  - robotic arm
KW  - mobile ground base
KW  - Batteries
KW  - Task analysis
KW  - Actuators
KW  - Robot kinematics
KW  - Planning
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8460201
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the autonomous battery exchange operation for small scale UAVs, using a mobile ground base that carries a robotic arm and a service station containing the battery exchange mechanism. The goal of this work is to demonstrate the means to increase the autonomy and persistence of robotic systems without requiring human intervention. The design and control of the system and its components are presented in detail, as well as the collaborative software framework used to plan and execute complex missions. Finally, the results of autonomous outdoor experiments are presented, in which the ground rover successfully localizes, retrieves, services, and deploys the landed UAV, proving its capacity to extend and enhance autonomous operations.
ER  - 

TY  - CONF
TI  - A Whole Body Attitude Stabilizer for Hybrid Wheeled-Legged Quadruped Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 706
EP  - 712
AU  - J. A. Castano
AU  - E. M. Hoffman
AU  - A. Laurenzi
AU  - L. Muratore
AU  - M. Karnedula
AU  - N. G. Tsagarakis
PY  - 2018
KW  - attitude control
KW  - legged locomotion
KW  - motion control
KW  - quadratic programming
KW  - robot kinematics
KW  - stability
KW  - wheels
KW  - motion capabilities
KW  - Centauro robot
KW  - body attitude stabilizer
KW  - attitude balancing strategy
KW  - quadrupedal robot
KW  - inverse kinematics solution scheme
KW  - stable reaction response
KW  - smooth reaction response
KW  - robot hybrid wheeled-legged mobility system
KW  - quadratic programming optimization
KW  - Wheels
KW  - Legged locomotion
KW  - Task analysis
KW  - Stability analysis
KW  - Kinematics
DO  - 10.1109/ICRA.2018.8462875
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work presents a new attitude balancing strategy implemented and validated on a quadrupedal robot equipped with a custom hybrid wheel-legged mobility system. The proposed method uses an inverse kinematics solution scheme based on Quadratic Programming optimization to generate full body motions that ensure the desired balancing performances. The strategy generates a compliant behaviour to cope with the applied external forces resulting in a stable and smooth reaction response. Furthermore, the method takes advantage of the robot hybrid wheeled-legged mobility system to provide new motion capabilities and balancing reactions as it will be shown through the paper. Extensive simulation studies on the Centauro robot are presented. Results show the efficiency of the propose method demonstrating significant contribution in the rejection of the applied external disturbances.
ER  - 

TY  - CONF
TI  - Learning Motion Predictors for Smart Wheelchair Using Autoregressive Sparse Gaussian Process
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 713
EP  - 718
AU  - Z. Fan
AU  - L. Meng
AU  - T. Q. Chen
AU  - J. Li
AU  - I. M. Mitchell
PY  - 2018
KW  - adaptive control
KW  - autoregressive processes
KW  - distance measurement
KW  - Gaussian processes
KW  - handicapped aids
KW  - image capture
KW  - interactive devices
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - robot vision
KW  - wheelchairs
KW  - motion predictors
KW  - smart wheelchair
KW  - robotics
KW  - analog joystick inputs
KW  - black-box transformations
KW  - intuitive motion control
KW  - adaptable motion control
KW  - human operators
KW  - commercial PWC platform
KW  - physical modification
KW  - electronic modification
KW  - industry standard auxiliary input port
KW  - visual odometry
KW  - joystick signals
KW  - autoregressive sparse Gaussian process model
KW  - short-term path prediction experiments
KW  - powered wheelchair platform
KW  - RGB-D camera
KW  - Arduino interface board
KW  - motion data capture
KW  - standard axle mounted odometers
KW  - Cameras
KW  - Gaussian processes
KW  - Robot sensing systems
KW  - Wheelchairs
KW  - Mobile robots
KW  - Hardware
DO  - 10.1109/ICRA.2018.8460502
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Constructing a smart wheelchair on a commercially available powered wheelchair (PWC) platform avoids a host of seating, mechanical design and reliability issues but requires methods of predicting and controlling the motion of a device never intended for robotics. Analog joystick inputs are subject to black-box transformations which may produce intuitive and adaptable motion control for human operators, but complicate robotic control approaches; furthermore, installation of standard axle mounted odometers on a commercial PWC is difficult. In this work, we present an integrated hardware and software system for predicting the motion of a commercial PWC platform that does not require any physical or electronic modification of the chair beyond plugging into an industry standard auxiliary input port. This system uses an RGB-D camera and an Arduino interface board to capture motion data, including visual odometry and joystick signals, via ROS communication. Future motion is predicted using an autoregressive sparse Gaussian process model. We evaluate the proposed system on real-world short-term path prediction experiments. Experimental results demonstrate the system's efficacy when compared to a baseline neural network model.
ER  - 

TY  - CONF
TI  - Local Behavior-Based Navigation in Rough Off-Road Scenarios Based on Vehicle Kinematics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 719
EP  - 724
AU  - P. Wolf
AU  - T. Ropertz
AU  - M. Oswald
AU  - K. Berns
PY  - 2018
KW  - mobile robots
KW  - off-road vehicles
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - trajectory control
KW  - elevation grid map
KW  - robot orientation
KW  - behavior-based control paradigm
KW  - rough terrains
KW  - traversability
KW  - occupancy maps
KW  - on-road local navigation approaches
KW  - trajectory candidates
KW  - behavior-based local navigation approach
KW  - vehicle kinematics
KW  - rough off-road scenarios
KW  - Wheels
KW  - Navigation
KW  - Trajectory
KW  - Robot sensing systems
KW  - Axles
KW  - Three-dimensional displays
KW  - robotics
KW  - off-road navigation
KW  - behavior-based control
KW  - tentacles
DO  - 10.1109/ICRA.2018.8460631
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes a novel behavior-based local navigation approach for rough off-road scenarios. Trajectory candidates are generated based on vehicle kinematics and dynamics as well as the desired global trajectory. In contrast to on-road local navigation approaches, the work at hand proposes the use of a shiftable elevation grid map instead of occupancy maps since traversability in rough terrains does not only depend on location, but also on the robot's orientation. The traversability is evaluated by determining tire contact points with the terrain to take various different safety and efficiency aspects like underbody collisions and rollover risk into account. By exploiting the behavior-based control paradigm, the navigation approach can be easily extended and its robustness is shown in experimental evaluations using an Unimog U5023.
ER  - 

TY  - CONF
TI  - Controlling a Non-Holonomic Mobile Manipulator in a Constrained Floor Space
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 725
EP  - 731
AU  - M. Mashali
AU  - L. Wu
AU  - R. Alqasemi
AU  - R. Dubey
PY  - 2018
KW  - collision avoidance
KW  - end effectors
KW  - mobile robots
KW  - motion control
KW  - redundant manipulators
KW  - constrained floor space
KW  - robotic manipulators
KW  - mobile platforms
KW  - warehouse shelf stacking
KW  - assistive robots
KW  - critical time
KW  - continuous operation
KW  - experienced operator
KW  - end-effector workspace
KW  - floor obstacles
KW  - straightforward control method
KW  - time-dependent constraints
KW  - time constraints
KW  - mobile base trajectory
KW  - sensor-assisted obstacle avoidance
KW  - freedom mobility
KW  - safe obstacle-free time-independent path
KW  - 5-DoF redundant Planar Mobile Manipulator
KW  - 9-DoF redundant mobile manipulator
KW  - mobile platform motion
KW  - allowed obstacle-free path
KW  - task completion
KW  - nonholonomic mobile manipulator
KW  - Manipulators
KW  - Task analysis
KW  - Trajectory
KW  - Hardware
KW  - Kinematics
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8462866
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotic manipulators that are attached to mobile platforms are often used in workspaces that require the end-effector to mobilize beyond the manipulator's limited reach, such as in warehouse shelf stacking and similar applications. However, such assistive robots fall short of completing tasks that require the end-effector to be situated in a specific configuration at a critical time during the task. Traditionally, users control the mobile base to situate the arm such that the task can be completed through continuous operation. This requires an experienced operator who can predict the needed end-effector workspace, and can operate the base accordingly to maximize the likelihood of a successful task while avoiding any floor obstacles. In this work, we propose a straightforward control method that provides sufficient freedom to the end-effector to complete a task that is bound by time-dependent constraints. This is achieved by relaxing the time constraints on the mobile base trajectory in a floor space obstructed by obstacles. The trajectory of the platform is determined by sensor-assisted obstacle avoidance algorithm such that a single degree of freedom mobility can be represented through a safe obstacle-free time-independent path. The proposed control method is implemented in simulation and on physical hardware built in our labs. The simulation included a 5-DoF redundant Planar Mobile Manipulator (PMM). The hardware implementation and testing utilized a 9-DoF redundant mobile manipulator. The implementation results demonstrate the effectiveness of the control method in adjusting the mobile platform motion along its allowed obstacle-free path to enable the end-effector to follow its trajectory for task completion that would otherwise fail to complete when conventional control methods are used.
ER  - 

TY  - CONF
TI  - A Parametric MPC Approach to Balancing the Cost of Abstraction for Differential-Drive Mobile Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 732
EP  - 737
AU  - P. Glotfelter
AU  - M. Egerstedt
PY  - 2018
KW  - mobile robots
KW  - motion control
KW  - predictive control
KW  - Parametric MPC approach
KW  - differential-drive mobile robots
KW  - three-state unicycle model
KW  - two-state single-integrator model
KW  - maneuverability costs
KW  - control signal
KW  - Parametric Model Predictive Control method
KW  - Mobile robots
KW  - Wheels
KW  - Robot kinematics
KW  - Predictive control
KW  - Measurement
KW  - Parametric statistics
DO  - 10.1109/ICRA.2018.8461234
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When designing control strategies for differential-drive mobile robots, one standard tool is the consideration of a point at a fixed distance along a line orthogonal to the wheel axis instead of the full pose of the vehicle. This abstraction supports replacing the non-holonomic, three-state unicycle model with a much simpler two-state single-integrator model (i.e., a velocity-controlled point). Yet this transformation comes at a performance cost, through the robot's precision and maneuverability. This work contains derivations for expressions of these precision and maneuverability costs in terms of the transformation's parameters. Furthermore, these costs show that only selecting the parameter once over the course of an application may cause an undue loss of precision. Model Predictive Control (MPC) represents one such method to ameliorate this condition. However, MPC typically realizes a control signal, rather than a parameter, so this work also proposes a Parametric Model Predictive Control (PMPC) method for parameter and sampling horizon optimization. Experimental results are presented that demonstrate the effects of the parameterization on the deployment of algorithms developed for the single-integrator model on actual differential-drive mobile robots.
ER  - 

TY  - CONF
TI  - Dynamic Simulation of Planetary Rovers with Terrain Property Mapping * Research supported by National Natural Science Foundation of China (Grant No. 61370033), National Basic Research Program of China (Grant No. 2013CB035502), Foundation for Innovative Research Groups of the Natural Science Foundation of China (Grant No. 51521003), Foundation of Chinese State Key Laboratory of Robotics and Systems (Grant No. SKLRS201501B, SKLRS20164B), Harbin Applied Technology Project of Research and Development (2015RQQXJ081), and the “111 Project” (Grant No. B07018).
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 738
EP  - 743
AU  - H. Yang
AU  - L. Ding
AU  - H. Gao
AU  - L. Huang
AU  - J. Guo
AU  - C. Chen
AU  - Z. Deng
PY  - 2018
KW  - cartography
KW  - control engineering computing
KW  - geometry
KW  - Mars
KW  - mobile robots
KW  - planetary rovers
KW  - soil
KW  - wheels
KW  - digital elevation map
KW  - terrain physical properties
KW  - terrain pressure-sinkage property
KW  - contact model
KW  - soil
KW  - terramechanics model
KW  - shearing property
KW  - friction angle
KW  - Mars exploration
KW  - complex terrains
KW  - terrain property mapping
KW  - planetary rovers
KW  - dynamic simulation
KW  - three-wheel-rover
KW  - Soil
KW  - Mathematical model
KW  - Wheels
KW  - Stress
KW  - Computational modeling
KW  - Shearing
KW  - Force
DO  - 10.1109/ICRA.2018.8460755
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Simulation of planetary rovers moving on complex terrains is critical for Mars exploration. Equivalent stiffness is proposed and used to characterize the pressure-sinkage property of terrain, while friction angle to characterize the shearing property. Terramechanics model for calculating forces between rigid wheel and soil is proved to be the same with that contact model for calculating forces between rigid wheel and rock. A Digital Elevation Map with Physical Properties is developed and applied to simulate terrain physical properties along with its geometry information. The established methods are validated using simulation and experimental tests with a three-wheel-rover.
ER  - 

TY  - CONF
TI  - Development of an Fast-Omnidirectional Treadmill (F-ODT) for Immersive Locomotion Interface
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 760
EP  - 766
AU  - S. H. Pyo
AU  - H. S. Lee
AU  - B. M. Phu
AU  - S. J. Park
AU  - J. W. Yoon
PY  - 2018
KW  - belts
KW  - computer based training
KW  - gears
KW  - medical computing
KW  - patient rehabilitation
KW  - pulleys
KW  - virtual reality
KW  - power transmission performance
KW  - weight structure
KW  - power transmission efficiency
KW  - transversal treadmills
KW  - omnidirectional treadmills
KW  - fast-omnidirectional treadmill
KW  - Geared Omni-pulley
KW  - power transmission mechanism
KW  - power transmission inefficiency
KW  - omnidirectional walking
KW  - human locomotion
KW  - virtual environment
KW  - natural navigation
KW  - immersive navigation
KW  - immersive locomotion interface
KW  - virtual reality environments
KW  - locomotion interface platform
KW  - F-ODT system
KW  - independent Y-axis motion
KW  - Belts
KW  - Motion segmentation
KW  - Power transmission
KW  - Torque
KW  - Synchronous motors
KW  - Angular velocity
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8460669
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To achieve immersive and natural navigation in a virtual environment through human locomotion, it is necessary to generate a 2-dimensional infinite ground for omnidirectional walking. However, the existing omnidirectional treadmills are heavy, complex and exhibit low acceleration due to power transmission inefficiency. In this paper, we present a novel fast-omnidirectional treadmill (F-ODT) with a new power transmission mechanism called the Geared Omni-pulley. This mechanism ensures higher power transmission efficiency for driving the belts of the multiple transversal treadmills for independent Y-axis motion. Due to the improved power transmission performance combined with a simpler and relatively light-weight structure, the proposed 2D treadmill can generate a maximum speed of 3m/sec with an acceleration of 3m/sec2. Based on the improved performance, the F-ODT system can be used as a locomotion interface platform in various virtual reality environments such as training of soldiers, gaming/educational experiences and gait rehabilitation.
ER  - 

TY  - CONF
TI  - Design Considerations and Redundancy Resolution for Variable Geometry Continuum Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 767
EP  - 774
AU  - C. Abah
AU  - A. L. Orekhov
AU  - N. Simaan
PY  - 2018
KW  - Jacobian matrices
KW  - manipulator kinematics
KW  - mobile robots
KW  - redundant manipulators
KW  - design alternative
KW  - kinematic redundancy
KW  - kinematic parameter adaptation
KW  - continuum robot design
KW  - admissible design parameter values
KW  - joint forces
KW  - gradient descent redundancy resolution problem
KW  - variable geometry continuum
KW  - joint limits
KW  - multibackbone continuum robots
KW  - continuum robot segment
KW  - situational awareness
KW  - task execution performance
KW  - Couplings
KW  - Kinematics
KW  - Elbow
KW  - Robot sensing systems
KW  - Redundancy
KW  - Fasteners
KW  - Continuum robots
KW  - variable geometry robots
KW  - redundancy
KW  - angulated scissor mechanism
KW  - kinematics
DO  - 10.1109/ICRA.2018.8460722
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Current multi-backbone continuum robots are limited to a constant cross-sectional diameter. This paper proposes a design alternative that overcomes this limitation. The ability to change the diameter of a continuum robot expands the repertoire of kinematic redundancy and enables kinematic parameter adaptation to optimize performance. A continuum robot design based on the angulated scissor mechanism is presented along with its position analysis. An exploration of admissible design parameter values for a given continuum robot segment with a desired maximum curvature while maintaining an open bore along its center is also carried out. A design presenting how this mechanism can be incorporated into a continuum robot is shown and a strategy for minimizing joint forces and avoiding joint limits is formulated as a gradient descent redundancy resolution problem in a simulation case study. The simulation results show that varying the diameter can significantly reduce joint forces while preserving the workspace and avoiding joint limits. This work is a first step towards continuum robots with situational awareness that will use their sensing capabilities to adapt their structure in order to optimize task execution performance.
ER  - 

TY  - CONF
TI  - Extending a Dynamic Friction Model with Nonlinear Viscous and Thermal Dependency for a Motor and Harmonic Drive Gear
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 783
EP  - 790
AU  - S. Wolf
AU  - M. Iskandar
PY  - 2018
KW  - brushless DC motors
KW  - compensation
KW  - electric drives
KW  - friction
KW  - humanoid robots
KW  - manipulator dynamics
KW  - dynamic friction model
KW  - thermal dependency
KW  - robotic actuation
KW  - friction behavior
KW  - actuator components
KW  - friction compensation
KW  - output torque estimation
KW  - dynamic simulations
KW  - brush-less DC motor
KW  - harmonic drive gear
KW  - humanoid David
KW  - DLR Floating Spring Joint
KW  - friction models
KW  - nonlinear viscous dependency
KW  - temperature 24 degC to 50 degC
KW  - Friction
KW  - Mathematical model
KW  - Torque
KW  - Gears
KW  - Robots
KW  - Harmonic analysis
KW  - Springs
DO  - 10.1109/ICRA.2018.8460613
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In robotic actuation a well identified and modeled friction behavior of the actuator components helps to significantly improve friction compensation, output torque estimation, and dynamic simulations. The friction of two components, i.e. a brush-less DC motor and a harmonic drive gear (HD) is investigated in order to build an accurate dynamic model of the main actuator of the arms of the humanoid David namely the DLR Floating Spring Joint (FSJ). A dedicated testbed is built to precisely identify input and output torques, temperatures, positions, and elasticities of the investigated components at a controlled environment temperature. Extensive test series are performed in the full velocity operating range in a temperature interval from 24 to 50 °C. The nonlinear influences of velocity and temperature are identified to be dominant effects. It is proposed how to include these nonlinear velocity and temperature dependencies into a static and a dynamic friction model, e.g. LuGre. Dynamic models of the motor and HD are built with the proposed method and experimentally evaluated. The new models are compared to friction models with linear dependencies and show a significant improvement of correspondence with reality.
ER  - 

TY  - CONF
TI  - Eddy Current Damper Design for Vibration Suppression in Robotic Milling Process
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 799
EP  - 804
AU  - F. Chen
AU  - H. Zhao
AU  - H. Ding
PY  - 2018
KW  - damping
KW  - design engineering
KW  - eddy currents
KW  - finite element analysis
KW  - frequency response
KW  - industrial robots
KW  - machine tool spindles
KW  - machining chatter
KW  - magnetic flux
KW  - magnetic forces
KW  - mechanical stability
KW  - milling
KW  - vibration control
KW  - robotic milling process
KW  - vibration attenuation method
KW  - vibration suppression process
KW  - tool tip frequency response function
KW  - milling spindle tool
KW  - chatter stability
KW  - magnetic force
KW  - magnetic flux density
KW  - finite element method
KW  - eddy current damper design
KW  - Robots
KW  - Milling
KW  - Damping
KW  - Tools
KW  - Force
KW  - Copper
KW  - Vibrations
KW  - Robotic milling
KW  - eddy current damper
KW  - vibration suppression
KW  - chatter
DO  - 10.1109/ICRA.2018.8460693
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel eddy current damper design for chatter suppression in robotic milling process. The designed eddy current dampers are installed on a milling spindle to damp the tool tip vibrations. The structural design of the eddy current dampers and the working principle of the proposed vibration attenuation method are explained. Finite element method is used to analyze the magnetic flux density and the magnetic force generated by the designed eddy current. The dynamics of the robotic milling system without and with eddy current dampers are modeled, and the damping performance of the proposed method is verified through simulations in both frequency and time domains. The results show that the peaks of the tool tip frequency response function caused by the spindle and milling tool modes are damped by 3.2 dB and 5.3 dB, respectively, and the chatter stability is improved by about 43% in the high spindle speed zone, compared to the case without eddy current dampers.
ER  - 

TY  - CONF
TI  - Learning-Based Image Enhancement for Visual Odometry in Challenging HDR Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 805
EP  - 811
AU  - R. Gomez-Ojeda
AU  - Z. Zhang
AU  - J. Gonzalez-Jimenez
AU  - D. Scaramuzza
PY  - 2018
KW  - convolution
KW  - distance measurement
KW  - feedforward neural nets
KW  - image enhancement
KW  - image representation
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - object tracking
KW  - robot vision
KW  - SLAM (robots)
KW  - visual odometry
KW  - high dynamic range environments
KW  - interest points
KW  - bold assumptions
KW  - brightness constancy
KW  - deep learning perspective
KW  - deep neural network
KW  - long short term memory
KW  - deep networks
KW  - VO framework
KW  - convolutional neural network
KW  - image enhancement
KW  - illumination conditions
KW  - HDR environments
KW  - Robustness
KW  - Cameras
KW  - Brightness
KW  - Lighting
KW  - Training
KW  - Decoding
KW  - Estimation
DO  - 10.1109/ICRA.2018.8462876
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the main open challenges in visual odometry (VO) is the robustness to difficult illumination conditions or high dynamic range (HDR) environments. The main difficulties in these situations come from both the limitations of the sensors and the inability to perform a successful tracking of interest points because of the bold assumptions in VO, such as brightness constancy. We address this problem from a deep learning perspective, for which we first fine-tune a deep neural network with the purpose of obtaining enhanced representations of the sequences for VO. Then, we demonstrate how the insertion of long short term memory allows us to obtain temporally consistent sequences, as the estimation depends on previous states. However, the use of very deep networks enlarges the computational burden of the VO framework; therefore, we also propose a convolutional neural network of reduced size capable of performing faster. Finally, we validate the enhanced representations by evaluating the sequences produced by the two architectures in several state-of-art VO algorithms, such as ORB-SLAM and DSO.
ER  - 

TY  - CONF
TI  - Spherical Visual Gyroscope for Autonomous Robots Using the Mixture of Photometric Potentials
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 820
EP  - 827
AU  - G. Caron
AU  - F. Morbidi
PY  - 2018
KW  - aerospace components
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - cameras
KW  - end effectors
KW  - gyroscopes
KW  - image sensors
KW  - image sequences
KW  - least squares approximations
KW  - mobile robots
KW  - nonlinear programming
KW  - robot vision
KW  - robust control
KW  - spherical visual gyroscope
KW  - autonomous robots
KW  - direct omnidirectional visual gyroscope
KW  - mobile robotic platforms
KW  - camera-robot
KW  - pixel intensities
KW  - extended convergence domain
KW  - spherical image sequences
KW  - robot arm
KW  - 3D orientation
KW  - Mixture of Photometric Potentials
KW  - image-similarity measure
KW  - nonlinear least-squares optimization scheme
KW  - twin-fisheye camera
KW  - end-effector
KW  - fixed-wing UAV
KW  - robust attitude estimates
KW  - Cameras
KW  - Visualization
KW  - Gyroscopes
KW  - Robot vision systems
KW  - Three-dimensional displays
KW  - Convergence
DO  - 10.1109/ICRA.2018.8460761
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a new direct omnidirectional visual gyroscope for mobile robotic platforms. The gyroscope estimates the 3D orientation of a camera-robot by comparing the current spherical image with that acquired at a reference pose. By transforming pixel intensities into a Mixture of Photometric Potentials, we introduce a novel image-similarity measure which can be seamlessly integrated into a classical nonlinear least-squares optimization scheme, offering an extended convergence domain. Our method provides accurate and robust attitude estimates, and it is easy-to-use since it involves a single tuning parameter, the width of the photometric potentials (Gaussian functions, in this work) controlling the power of attraction of each pixel. The visual gyroscope has been successfully tested on spherical image sequences generated by a twin-fisheye camera mounted on the end-effector of a robot arm and on a fixed-wing UAV.
ER  - 

TY  - CONF
TI  - Learning Place-and-Time-Dependent Binary Descriptors for Long-Term Visual Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 828
EP  - 835
AU  - N. Zhang
AU  - M. Warren
AU  - T. D. Barfoot
PY  - 2018
KW  - computer vision
KW  - natural scenes
KW  - pose estimation
KW  - pose change
KW  - place-and-time-dependent binary descriptor
KW  - GRIEF evolution algorithm
KW  - correspondence generation
KW  - single-experience Visual Teach and Repeat system
KW  - localization failures
KW  - natural scene changes
KW  - vision-based navigation
KW  - long-term visual localization
KW  - extreme illumination changes
KW  - binary descriptors
KW  - single descriptor scheme
KW  - adaptive descriptor
KW  - descriptor generation
KW  - long-term seasonal variations
KW  - short-term illumination changes
KW  - Lighting
KW  - Visualization
KW  - Latches
KW  - Navigation
KW  - Robustness
KW  - Measurement
KW  - Evolutionary computation
DO  - 10.1109/ICRA.2018.8460674
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Vision-based navigation is extremely susceptible to natural scene changes. This can result in localization failures in less than a few hours after map creation. To combat short-term illumination changes as well as long-term seasonal variations, we propose using a place-and-time-dependent binary descriptor that adapts to different scenarios in an online fashion. This is achieved by extending the GRIEF [6] evolution algorithm in two ways: correspondence generation using a known pose change and the inclusion of LATCH triplets in addition to BRIEF comparisons for descriptor generation. We show the adaptive descriptor outperforms a single descriptor scheme for localization within a single-experience Visual Teach and Repeat (VT&R) system while maintaining the efficiency of binary descriptors. By adapting the description function to different environmental conditions, it allows the system to operate for a longer period before a new experience is required. In the presence of extreme illumination changes from day to night, we obtain 40% more inlier matches compared to SURF. In the case of seasonal variations, a 70% increase is demonstrated. The increased correspondences result in more localizable sections along the paths, amounting to a 25% and 150% increase in the lighting and seasonal cases, respectively.
ER  - 

TY  - CONF
TI  - Correlation Flow: Robust Optical Flow Using Kernel Cross-Correlators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 836
EP  - 841
AU  - C. Wang
AU  - T. Ji
AU  - T. Nguyen
AU  - L. Xie
PY  - 2018
KW  - aircraft control
KW  - aircraft navigation
KW  - autonomous aerial vehicles
KW  - cameras
KW  - helicopters
KW  - mobile robots
KW  - position control
KW  - correlation flow
KW  - reliable velocity estimation
KW  - robust trajectory estimation
KW  - robust optical flow
KW  - kernel cross-correlators
KW  - position estimation
KW  - autonomous robot navigation
KW  - autonomous navigation
KW  - kernel cross-correlator based algorithm
KW  - monocular camera
KW  - ROS framework
KW  - yaw rate
KW  - Kernel
KW  - Optical sensors
KW  - Optical imaging
KW  - Correlation
KW  - Correlators
KW  - Robustness
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460569
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robust velocity and position estimation is crucial for autonomous robot navigation. The optical flow based methods for autonomous navigation have been receiving increasing attentions in tandem with the development of micro unmanned aerial vehicles. This paper proposes a kernel cross-correlator (KCC) based algorithm to determine optical flow using a monocular camera, which is named as correlation flow (CF). Correlation flow is able to provide reliable and accurate velocity estimation and is robust to motion blur. In addition, it can also estimate the altitude velocity and yaw rate, which are not available by traditional methods. Autonomous flight tests on a quadcopter show that correlation flow can provide robust trajectory estimation with very low processing power. The source codes are released based on the ROS framework.
ER  - 

TY  - CONF
TI  - Cubic Range Error Model for Stereo Vision with Illuminators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 842
EP  - 848
AU  - M. Huber
AU  - T. Hinzmann
AU  - R. Siegwart
AU  - L. H. Matthies
PY  - 2018
KW  - cameras
KW  - image sensors
KW  - robot vision
KW  - stereo image processing
KW  - telecommunication scheduling
KW  - cubic range error model
KW  - stereo vision
KW  - low-cost depth sensors
KW  - stereo camera setup
KW  - robotics
KW  - augmented reality
KW  - map generation
KW  - sensor scheduling policy
KW  - multisensor setup
KW  - range error models
KW  - uncertainty estimates
KW  - range measurements
KW  - integrated illuminators
KW  - off-the-shelf structured light stereo system
KW  - Cameras
KW  - Robot sensing systems
KW  - Uncertainty
KW  - Lighting
KW  - Geometry
DO  - 10.1109/ICRA.2018.8461150
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Use of low-cost depth sensors, such as a stereo camera setup with illuminators, is of particular interest for numerous applications ranging from robotics and transportation to mixed and augmented reality. The ability to quantify noise is crucial for these applications, e.g., when the sensor is used for map generation or to develop a sensor scheduling policy in a multi-sensor setup. Range error models provide uncertainty estimates and help weigh the data correctly in instances where range measurements are taken from different vantage points or with different sensors. Such a model is derived in this work. We show that the range error for stereo systems with integrated illuminators is cubic and validate the proposed model experimentally with an off-the-shelf structured light stereo system. The experiments confirm the validity of the model and simplify the application of this type of sensor in robotics.
ER  - 

TY  - CONF
TI  - Fusion of Stereo and Still Monocular Depth Estimates in a Self-Supervised Learning Context
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 849
EP  - 856
AU  - D. Martins
AU  - K. Van Hecke
AU  - G. De Croon
PY  - 2018
KW  - feedforward neural nets
KW  - image colour analysis
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - monocular depth estimates
KW  - autonomous robots
KW  - self-supervised learning setup
KW  - stereo vision depth
KW  - convolutional neural network
KW  - fusion method
KW  - CNN estimates
KW  - autonomous navigation
KW  - depth estimation
KW  - self-supervised learning
KW  - Estimation
KW  - Stereo vision
KW  - Robot sensing systems
KW  - Cameras
KW  - Training
KW  - Self-supervised learning
KW  - monocular depth estimation
KW  - stereo vision
KW  - convolutional neural networks
DO  - 10.1109/ICRA.2018.8461116
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We study how autonomous robots can learn by themselves to improve their depth estimation capability. In particular, we investigate a self-supervised learning setup in which stereo vision depth estimates serve as targets for a convolutional neural network (CNN) that transforms a single still image to a dense depth map. After training, the stereo and mono estimates are fused with a novel fusion method that preserves high confidence stereo estimates, while leveraging the CNN estimates in the low-confidence regions. The main contribution of the article is that it is shown that the fused estimates lead to a higher performance than the stereo vision estimates alone. Experiments are performed on the KITTI dataset, and on board of a Parrot SLAMDunk, showing that even rather limited CNNs can help provide stereo vision equipped robots with more reliable depth maps for autonomous navigation.
ER  - 

TY  - CONF
TI  - Exposure Control Using Bayesian Optimization Based on Entropy Weighted Image Gradient
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 857
EP  - 864
AU  - J. Kim
AU  - Y. Cho
AU  - A. Kim
PY  - 2018
KW  - cameras
KW  - entropy
KW  - gradient methods
KW  - optimisation
KW  - robot vision
KW  - image degradation
KW  - exposure control scheme
KW  - image frame grab
KW  - light conditions
KW  - vision-based approaches
KW  - optimal exposure value
KW  - image information measure
KW  - dynamic lighting conditions
KW  - camera exposure
KW  - vision-based robotic applications
KW  - entropy weighted image gradient
KW  - Bayesian optimization
KW  - Entropy
KW  - Measurement
KW  - Cameras
KW  - Optimization
KW  - Bayes methods
KW  - Robot vision systems
DO  - 10.1109/ICRA.2018.8462881
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Under- and oversaturation can cause severe image degradation in many vision-based robotic applications. To control camera exposure in dynamic lighting conditions, we introduce a novel metric for image information measure. Measuring an image gradient is typical when evaluating its level of image detail. However, emphasizing more informative pixels substantially improves the measure within an image. By using this entropy weighted image gradient, we introduce an optimal exposure value for vision-based approaches. Using this newly invented metric, we also propose an effective exposure control scheme that covers a wide range of light conditions. When evaluating the function (e.g., image frame grab) is expensive, the next best estimation needs to be carefully considered. Through Bayesian optimization, the algorithm can estimate the optimal exposure value with minimal cost. We validated the proposed image information measure and exposure control scheme via a series of thorough experiments using various exposure conditions.
ER  - 

TY  - CONF
TI  - Compliant Manipulation of Free-Floating Objects
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 865
EP  - 872
AU  - S. Sharma
AU  - M. Suomalainen
AU  - V. Kyrki
PY  - 2018
KW  - force control
KW  - force sensors
KW  - manipulators
KW  - minimisation
KW  - motion control
KW  - position control
KW  - interaction forces
KW  - direct force control
KW  - implicit force control algorithms
KW  - compliant manipulation
KW  - free-floating objects
KW  - compliant motions
KW  - reaction forces
KW  - constant force
KW  - manipulator inertia
KW  - KUKA LWR4+ manipulator arm
KW  - Manipulators
KW  - Force
KW  - Force control
KW  - Impedance
KW  - Damping
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2018.8462889
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Compliant motions allow alignment of workpieces using naturally occurring interaction forces. However, free-floating objects do not have a fixed base to absorb the reaction forces caused by the interactions. Consequently, if the interaction forces are too high, objects can gain momentum and move away after contact. This paper proposes an approach based on direct force control for compliant manipulation of free-floating objects. The objective of the controller is to minimize the interaction forces while maintaining the contact. The proposed approach achieves this by maintaining small constant force along the motion direction and an apparent reduction of manipulator inertia along remaining Degrees of Freedom (DOF). Simulation results emphasize the importance of relative inertia of the robotic manipulator with respect to the free-floating object. The experiments were performed with KUKA LWR4+ manipulator arm and a two-dimensional micro-gravity emulator (object floating on an air bed), which was developed in-house. It was verified that the proposed control law is capable of controlling the interaction forces and aligning the tools without pushing the object away. We conclude that direct force control works better with a free-floating object than implicit force control algorithms, such as impedance control.
ER  - 


TY  - CONF
TI  - Validation of the Robot Rendezvous and Grasping Manoeuvre Using Microgravity Simulators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 873
EP  - 880
AU  - K. Seweryn
AU  - T. Rybus
AU  - P. Colmenarejo
AU  - G. Novelli
AU  - J. Oleś
AU  - M. Pietras
AU  - J. Z. Sasiadek
AU  - M. Scheper
AU  - K. Tarenko
PY  - 2018
KW  - aerospace robotics
KW  - artificial satellites
KW  - control system synthesis
KW  - end effectors
KW  - industrial robots
KW  - multi-robot systems
KW  - path planning
KW  - space debris
KW  - space vehicles
KW  - robot rendezvous
KW  - grasping manoeuvre
KW  - unmanned chaser satellite
KW  - performing rendezvous
KW  - grasping manoeuvres
KW  - space debris
KW  - manoeuvres high disturbances
KW  - manipulator arm end-effector
KW  - robotic subsystem
KW  - chaser rendezvous
KW  - planar air-bearing microgravity simulators
KW  - industrial robots
KW  - specified test-bed system
KW  - Manipulators
KW  - Satellites
KW  - Orbits
KW  - Space vehicles
KW  - Service robots
KW  - Control systems
DO  - 10.1109/ICRA.2018.8460475
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robots mounted on an unmanned chaser satellite could be used for performing rendezvous and grasping manoeuvres in order to repair satellites or remove space debris from orbit. Use of manipulators for such purposes is challenging, since the performed task need to be done autonomously, accurately and with high level of robustness. During manoeuvres high disturbances might appear e.g. due to contact between the manipulator arm end-effector and the target spacecraft. In this paper an approach for validation of the robotic subsystem during chaser rendezvous and grasping manoeuvre has been shown. Two type of testbed systems were used: planar air-bearing microgravity simulators and a test-bed system with industrial robots. The proposed approach took advantage of possible replacement of particular subsystem in reference model or reference hardware in specified test-bed system. The list of tests performed are included in the paper.
ER  - 

TY  - CONF
TI  - Collision-Based Contact Mode Estimation for Dynamic Rigid Body Capture
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 881
EP  - 888
AU  - H. Kato
AU  - D. Hirano
AU  - J. Ota
PY  - 2018
KW  - aerospace robotics
KW  - collision avoidance
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion estimation
KW  - multi-robot systems
KW  - particle filtering (numerical methods)
KW  - robot vision
KW  - space debris
KW  - vehicle dynamics
KW  - space debris
KW  - Brach collision model
KW  - collision-based contact mode estimation
KW  - particle filter
KW  - pre-capture phase
KW  - motion estimation error
KW  - reasonable computation resources
KW  - collision-triggered filter
KW  - moving rigid body
KW  - force-torque sensor
KW  - dynamic rigid body capture
KW  - Estimation
KW  - Robot sensing systems
KW  - Computational modeling
KW  - Collision avoidance
KW  - Predictive models
KW  - Bayes methods
DO  - 10.1109/ICRA.2018.8460806
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes real-time collision-based contact mode estimation with only a force-torque sensor for capturing a moving rigid body. The contact modes are defined for determining when to generate the signal to close the robotic hand for establishing object closure. In our particle filter approach, collision-triggered filter is used to determine the contact mode with the least amount of computation. Brach's collision model is used for our collision model-based approach for a rigid body because it is computationally light-weighted and enables the sampling of three collision properties for the particle filter. The validity of our method is experimentally demonstrated by achieving the highest success rate using the reasonable computation resources required (average of 3.9 milliseconds and worst of 6.1 milliseconds with our setup), and verifying each computation resource (or number of particles) based on the size of motion estimation error in the pre-capture phase.
ER  - 

TY  - CONF
TI  - Workspace Fixation for Free-Floating Space Robot Operations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 889
EP  - 896
AU  - A. M. Giordano
AU  - D. Calzolari
AU  - A. Albu-Schäffer
PY  - 2018
KW  - aerospace robotics
KW  - end effectors
KW  - mobile robots
KW  - CoM
KW  - degree-of-freedom
KW  - free-floating space robot operations
KW  - workspace fixation
KW  - 6DOF moving base
KW  - center-of-mass regulation
KW  - end-effector
KW  - Manipulators
KW  - Symmetric matrices
KW  - Fuels
KW  - Robot kinematics
KW  - Satellites
DO  - 10.1109/ICRA.2018.8460478
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When a space robot accidentally or voluntarily comes in contact with a target object, a workspace shift happens due to exchange of momentum between the objects. The problem of workspace adjustment is addressed herein. A novel controller is derived to simultaneously adjust the workspace and control the end-effector pose. The controller is based on a center-of-mass (CoM) regulation which fixes the workspace in the inertial space while leaving the base free to move, resulting in fuel efficiency. The control is validated on hardware using a robotic simulator composed of a seven degree-of-freedom (DOF) arm mounted on a 6DOF moving base.
ER  - 

TY  - CONF
TI  - Robust Visual Localization for Hopping Rovers on Small Bodies
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 897
EP  - 903
AU  - S. Chiodini
AU  - R. G. Reid
AU  - B. Hockman
AU  - I. A. D. Nesnas
AU  - S. Debei
AU  - M. Pavone
PY  - 2018
KW  - cameras
KW  - planetary rovers
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - space vehicles
KW  - visual SLAM algorithms
KW  - ORB-SLAM2
KW  - orbiting primary spacecraft
KW  - onboard visual simultaneous localization and mapping
KW  - visual SLAM implementation
KW  - wide field of view camera
KW  - off-nadir camera pointing angles
KW  - narrow FOV camera
KW  - orbiting spacecraft
KW  - visual appearance
KW  - high-contrast shadows
KW  - hopping rover
KW  - illumination angles
KW  - Solar System bodies
KW  - collaborative visual localization method
KW  - robust visual localization
KW  - time 1.0 hour to 12.0 hour
KW  - Cameras
KW  - Space vehicles
KW  - Visualization
KW  - Simultaneous localization and mapping
KW  - Optimization
KW  - Lighting
KW  - Solar system
DO  - 10.1109/ICRA.2018.8462865
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a collaborative visual localization method for rovers designed to hop and tumble across the surface of small Solar System bodies, such as comets and asteroids. In a two-phase approach, an orbiting primary spacecraft first maps the surface of a body by capturing images from various poses and illumination angles; these images are processed to create a prior map of 3D landmarks. In the second phase, a hopping rover is deployed to the surface where it uses a camera to relocalize to the prior map and to perform onboard visual simultaneous localization and mapping (SLAM). Small bodies present several unique challenges to existing visual SLAM algorithms, such as high-contrast shadows that move quickly over the surface due to the short (e.g. 1-12 hour) rotational periods, and large changes in visual appearance between orbit and the surface, where image scale varies by many orders of magnitude (kilometers to centimeters). In this work, we describe how to augment ORB-SLAM2-a state of the art visual SLAM implementation-to handle large variations in illumination by fusing prior images with varying illumination angles. We demonstrate how a hopping rover can use a wide field of view (FOV) camera to relocalize to prior maps captured by an orbiting spacecraft with a narrow FOV camera, and how the growth of pose and scale errors can be bounded by periodic loop closures during large hops. The proposed method is evaluated with sequences of images captured around a mock asteroid; it is shown to be robust to varying illumination angles, scene scale changes, and off-nadir camera pointing angles.
ER  - 

TY  - CONF
TI  - Wheel Design Methodology for a Lunar Exploration Rover in Order to Improve Trafficability Considering Operation Environment
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 904
EP  - 909
AU  - K. Kim
AU  - B. Sim
AU  - S. Kim
AU  - K. Yu
PY  - 2018
KW  - mobile robots
KW  - planetary rovers
KW  - wheels
KW  - wheel design methodology
KW  - lunar exploration rover
KW  - operation environment
KW  - successful mission
KW  - rover wheel
KW  - power consumption
KW  - conceptual design stage
KW  - power acquisition
KW  - terrain characteristics
KW  - lunar simulant
KW  - wheel-terrain interaction model
KW  - optimal wheel dimension
KW  - maximal trafficability
KW  - single wheel test bed
KW  - tractive performance maximization
KW  - Wheels
KW  - Moon
KW  - Mathematical model
KW  - Stress
KW  - Design methodology
KW  - Power demand
KW  - Azimuth
DO  - 10.1109/ICRA.2018.8460824
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For achieving a successful mission in lunar exploration, not only traversability of exploration rover should be predicted but also operation environment should be considered under the limited power condition. Therefore, an optimal design of rover wheel for minimizing power consumption and maximizing tractive performance is required by conducting conceptual design stage. This paper describes settlement of requirements at system level and modeling of operation environment such as power acquisition and terrain characteristics in the lunar simulant. Using the wheel-terrain interaction model, a wheel design methodology was proposed to obtain an optimal wheel dimension, which meet the limited power condition along with maximal trafficability according to the each landing site. In addition, the results from the above approach have been validated with the experimental results using a single wheel test bed on the lunar simulant.
ER  - 

TY  - CONF
TI  - Whole-Body Impedance Control for a Planetary Rover with Robotic Arm: Theory, Control Design, and Experimental Validation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 910
EP  - 917
AU  - K. Bussmann
AU  - A. Dietrich
AU  - C. Ott
PY  - 2018
KW  - aerospace robotics
KW  - control system synthesis
KW  - controllability
KW  - manipulators
KW  - mechanical variables control
KW  - motion control
KW  - optimisation
KW  - planetary rovers
KW  - position control
KW  - rescue robots
KW  - robot kinematics
KW  - wheels
KW  - planetary rover
KW  - robotic arm
KW  - control framework
KW  - versatile manipulation
KW  - planetary exploration
KW  - control design
KW  - experimental validation
KW  - planetary rovers
KW  - contact interaction
KW  - terrestrial applications
KW  - terrestrial whole-body controllers
KW  - wheel force distribution
KW  - whole-body impedance control
KW  - maneuverability
KW  - whole-body Cartesian impedance controller
KW  - global optimization
KW  - overactuation redundancy
KW  - mobile base
KW  - kinematic redundancy handling
KW  - serial kinematic subchain
KW  - DLR Lightweight Rover Unit
KW  - rough terrain
KW  - terrestrial search-and-rescue scenario
KW  - Wheels
KW  - Manipulators
KW  - Impedance
KW  - Mobile robots
KW  - Robot kinematics
KW  - Null space
DO  - 10.1109/ICRA.2018.8460533
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Future planetary rovers will gain the ability to manipulate their environment in addition to the maneuverability of current systems. For dedicated contact interaction, Cartesian impedance control is a well-established approach from numerous terrestrial applications. In this paper we will present a whole-body Cartesian impedance controller for a planetary rover equipped with a robotic arm. In contrast to classical terrestrial whole-body controllers, the issue of proper wheel force distribution will be addressed within the control framework. A global optimization solves this redundancy in the over-actuation of the mobile base while additionally handling the kinematic redundancy in the serial kinematic sub-chain of the robot. The approach is experimentally validated on the DLR Lightweight Rover Unit. It can be used for versatile manipulation in rough terrain such as encountered in planetary exploration or terrestrial search-and-rescue scenarios.
ER  - 

TY  - CONF
TI  - Kinematic Design Optimization of a Parallel Surgical Robot to Maximize Anatomical Visibility via Motion Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 926
EP  - 933
AU  - A. Kuntz
AU  - C. Bowen
AU  - C. Baykal
AU  - A. W. Mahoney
AU  - P. L. Anderson
AU  - F. Maldonado
AU  - R. J. Webster
AU  - R. Alterovitz
PY  - 2018
KW  - biological tissues
KW  - manipulator kinematics
KW  - medical robotics
KW  - motion control
KW  - needles
KW  - optimisation
KW  - path planning
KW  - simulated annealing
KW  - surgery
KW  - tissue surface
KW  - CRISP robot
KW  - parallel structure connection points
KW  - global stochastic optimization algorithm
KW  - kinematic design optimization
KW  - parallel surgical robot
KW  - Continuum Reconfigurable Incisionless Surgical Parallel robot
KW  - needle-diameter medical robot
KW  - minimally invasive procedures
KW  - motion planning
KW  - anatomical visibility
KW  - adaptive simulated annealing
KW  - ASA
KW  - Electron tubes
KW  - Kinematics
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/ICRA.2018.8461135
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We introduce a method to optimize on a patient-specific basis the kinematic design of the Continuum Reconfigurable Incisionless Surgical Parallel (CRISP) robot, a needle-diameter medical robot based on a parallel structure that is capable of performing minimally invasive procedures. Our objective is to maximize the ability of the robot's tip camera to view tissue surfaces in constrained spaces. The kinematic design of the CRISP robot, which greatly influences its ability to perform a task, includes parameters that are fixed before the procedure begins, such as entry points into the body and parallel structure connection points. We combine a global stochastic optimization algorithm, Adaptive Simulated Annealing (ASA), with a motion planner designed specifically for the CRISP robot. ASA facilitates exploration of the robot's design space while the motion planner enables evaluation of candidate designs based on their ability to successfully view target regions on a tissue surface. By leveraging motion planning, we ensure that the evaluation of a design only considers motions which do not collide with the patient's anatomy. We analytically show that the method asymptotically converges to a globally optimal solution and demonstrate our algorithm's ability to optimize kinematic designs of the CRISP robot on a patient-specific basis.
ER  - 

TY  - CONF
TI  - Workspace, Transmissibility and Dynamics of a New 3T3R Parallel Pick-and-place Robot with High Rotational Capability
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 942
EP  - 947
AU  - G. Wu
PY  - 2018
KW  - actuators
KW  - end effectors
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - 3-axis translations
KW  - rotations
KW  - robot end-effector
KW  - orientational workspace
KW  - gearbox
KW  - workspace volume
KW  - commercial Delta-type robots
KW  - high-speed parallel robot
KW  - 6-axis Delta-type robot
KW  - structural complexity
KW  - rotational capability
KW  - 3T3R parallel pick-and-place robot
KW  - commercial actuation combination
KW  - Robot kinematics
KW  - Manipulators
KW  - Actuators
KW  - Kinematics
KW  - Service robots
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460888
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a six-limb high-speed parallel robot for pick-and-place operations that is based on two Delta robots, where the two sub-platforms are connected by a gearbox. Unlike the current 6-axis Delta-type robot, all the actuators of the robot are mounted on a base platform, allowing to reduce the inertia for high dynamic performance. Besides the 3-axis translations, the three rotations of the robot end-effector are realized by the differential motions of the two sub-platforms in three directions for large orientational workspace, but without significantly increased structural complexity of gearbox, compared to the existing one. The kinematic problems are studied to reveal that the workspace volume of the robot is similar to the commercial Delta-type robots. The simplified dynamic model is established and the simulation results show that the robot can reach up to a 20G acceleration subject to the commercial actuation combination.
ER  - 

TY  - CONF
TI  - Dynamic Control of Cable Driven Parallel Robots with Unknown Cable Stiffness: a Joint Space Approach
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 948
EP  - 955
AU  - G. Pittiglio
AU  - A. Kogkas
AU  - J. O. Vrielink
AU  - G. Mylonas
PY  - 2018
KW  - cables (mechanical)
KW  - closed loop systems
KW  - control nonlinearities
KW  - control system synthesis
KW  - end effectors
KW  - feedback
KW  - linearisation techniques
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - motion control
KW  - position control
KW  - velocity control
KW  - closed-loop controllers
KW  - redundant dynamics
KW  - end effector
KW  - dynamic control
KW  - joint space approach
KW  - dynamic controller
KW  - joint variables
KW  - cable driven parallel robots
KW  - cable stiffness
KW  - observer linearization
KW  - three-tendon planar platform
KW  - backstepping technique
KW  - quasivelocity method
KW  - Observers
KW  - Kinematics
KW  - Position measurement
KW  - Velocity measurement
KW  - Jacobian matrices
KW  - Parallel robots
DO  - 10.1109/ICRA.2018.8460822
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the present paper we discuss a novel dynamic controller for Cable Driven Parallel Robots, based on the Backstepping technique. The main challenge in controlling these robots, is expressing the dynamic equilibrium with respect to the joint variables. This drawback makes the definition of closed-loop controllers more challenging, in comparison with their serial counterparts. The problem is tackled by considering redundant dynamics, expressed in both task and joints space and solved through the method of quasi-velocity. We propose the usage of the observer linearization to estimate the end effector pose and stiffness, by just measuring the motor position, velocity and torque. These variables are used in the feedback loop to control the pose of the end effector. A 3-tendon planar platform is used for the experimental analysis.
ER  - 

TY  - CONF
TI  - New Kinematic Structures for Two-Loop Generalized Parallel Mechanism Designs
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 956
EP  - 961
AU  - C. Tian
AU  - Y. Fang
AU  - Q. J. Ge
PY  - 2018
KW  - design engineering
KW  - manipulator kinematics
KW  - motion control
KW  - coupling sub-chain
KW  - two-loop mechanism
KW  - two-loop generalized parallel mechanism designs
KW  - moving platform
KW  - serial kinematic chains
KW  - kinematic structures
KW  - screw theory
KW  - rotational degrees of freedom
KW  - translational degrees of freedom
KW  - Kinematics
KW  - Couplings
KW  - Fasteners
KW  - Manipulators
KW  - Force
KW  - Mechanical engineering
KW  - Periodic structures
DO  - 10.1109/ICRA.2018.8460503
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The moving platform of a conventional parallel mechanism is typically connected to the ground link via serial kinematic chains or limbs. When interconnections are created among the limbs, they form coupling sub-chains that can provide additional constraints to the motion of the platform. The resulting complex mechanism offers the potential for improved performance and functionality of the overall mechanism. The basic building block of the parallel mechanism with coupling sub-chain is found to be a two-loop mechanism. This paper presents a screw theory based general method for synthesizing two-loop mechanism by adding an open chain on top of an existing closed chain for a specified combination of rotational and translational degrees of freedom of the end-effector. A comprehensive set of two-loop mechanisms have been presented for various combinations of rotational and translational degrees of freedom.
ER  - 

TY  - CONF
TI  - Available Wrench Set for Planar Mobile Cable-Driven Parallel Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 962
EP  - 967
AU  - T. Rasheed
AU  - P. Long
AU  - D. Marquez-Gamez
AU  - S. Caro
PY  - 2018
KW  - cables (mechanical)
KW  - end effectors
KW  - manipulator kinematics
KW  - mobile robots
KW  - robot dynamics
KW  - geometric architecture
KW  - parallel manipulators
KW  - convex hull methods
KW  - hyperplane shifting methods
KW  - point-mass end-effector
KW  - static equilibrium
KW  - mobile cable-driven parallel robots
KW  - available wrench set
KW  - Task analysis
KW  - Parallel robots
KW  - Power cables
KW  - Collision avoidance
KW  - Prototypes
KW  - Wheels
DO  - 10.1109/ICRA.2018.8461199
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Cable-Driven Parallel Robots (CDPRs) have several advantages over conventional parallel manipulators most notably a large workspace. CDPRs whose workspace can be further increased by modification of the geometric architecture are known as Reconfigurable Cable Driven Parallel Robots(RCDPRs). A novel concept of RCDPRs, known as Mobile CDPR (MCDPR) that consists of a CDPR carried by multiple mobile bases, is studied in this paper. The system is capable of autonomously navigating to a desired location then deploying to a standard CDPR. In this paper, we analyze the Static equilibrium (SE) of the mobile bases when the system is fully deployed. In contrast to classical CDPRs we show that the workspace of the MCDPR depends, not only on the tension limits, but on the SE constraints as well. We demonstrate how to construct the Available Wrench Set (AWS) for a planar MCDPR wih a point-mass end-effector using both the convex hull and Hyperplane shifting methods. The obtained results are validated in simulation and on an experimental platform consisting of two mobile bases and a CDPR with four cables.
ER  - 

TY  - CONF
TI  - Closed-form Solution for the Direct Kinematics Problem of the Planar 3-RPR Parallel Mechanism
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 968
EP  - 973
AU  - S. Schulz
AU  - A. Seibel
AU  - J. Schlattmann
PY  - 2018
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - pose estimation
KW  - robot vision
KW  - closed-form solution
KW  - direct kinematics problem
KW  - planar 3-RPR parallel mechanism
KW  - active prismatic joints
KW  - manipulator platform
KW  - pose estimations
KW  - reference drives
KW  - workspace limitations
KW  - Manipulators
KW  - Kinematics
KW  - Actuators
KW  - Sensors
KW  - Closed-form solutions
KW  - Legged locomotion
KW  - Conferences
DO  - 10.1109/ICRA.2018.8460544
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In general, it is not possible to determine the actual manipulator platform's pose of a parallel mechanism from its active joints' coordinates. This problem is usually solved by using additional numerical procedures or by additional system information from auxiliary sensors, providing several weaknesses including initial pose estimations, reference drives, or workspace limitations. In this paper, we therefore introduce a closed-form solution for the direct kinematics problem of the planar 3-RPR parallel mechanism by using only the orientations of two active joints and the manipulator platform, where P denotes active prismatic joints and R passive revolute joints.
ER  - 

TY  - CONF
TI  - Yet Another Approach to the Gough-Stewart Platform Forward Kinematics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 974
EP  - 980
AU  - J. M. Porta
AU  - F. Thomas
PY  - 2018
KW  - manipulator kinematics
KW  - matrix algebra
KW  - Gough-Stewart platform forward kinematics
KW  - leg endpoints coalesce
KW  - variable elimination methods
KW  - virtual legs
KW  - Legged locomotion
KW  - Topology
KW  - Kinematics
KW  - Distance measurement
KW  - Conferences
KW  - Automation
KW  - Australia
DO  - 10.1109/ICRA.2018.8460900
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The forward kinematics of the Gough-Stewart platform, and their simplified versions in which some leg endpoints coalesce, has been typically solved using variable elimination methods. In this paper, we cast doubts on whether this is the easiest way to solve the problem. We will see how the indirect approach in which the length of some extra virtual legs is first computed leads to important simplifications. In particular, we provide a procedure to solve 30 out of 34 possible topologies for a Gough-Stewart platform without variable elimination.
ER  - 

TY  - CONF
TI  - Bounding Drift in Cooperative Localisation Through the Sharing of Local Loop Closures
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 981
EP  - 987
AU  - L. Toohey
AU  - O. Pizarro
AU  - S. B. Williams
PY  - 2018
KW  - graph theory
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - direct intervehicle observations
KW  - fuses single vehicle SLAM
KW  - cooperative localisation
KW  - data association
KW  - map data
KW  - local subgraphs
KW  - shared states
KW  - localisation accuracy
KW  - bounding drift
KW  - local loop closures
KW  - robotic scenarios
KW  - data consistency
KW  - bandwidth limitations
KW  - single vehicle visual SLAM framework
KW  - Information matrix
KW  - Simultaneous localization and mapping
KW  - Bandwidth
KW  - Jacobian matrices
KW  - Visualization
KW  - Message systems
DO  - 10.1109/ICRA.2018.8460820
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Handling loop closures and intervehicle observations in cooperative robotic scenarios remains a challenging problem due to data consistency, bandwidth limitations and increased computation requirements. This paper develops a general cooperative localisation and single vehicle Visual SLAM framework that includes direct intervehicle observations and pose to pose loop closures on each vehicle with states shared as required. This fuses single vehicle SLAM with cooperative localisation and avoids data association of map data across limited communication networks. The base problem is developed as a factor graph with each vehicle solving local subgraphs that are split based on intervehicle observations. We modify the order of variable elimination in subgraphs through manipulation of the square-root of the Information matrix to extract updates that include the historic states involved in the loop closures and do not require transmission of other states not involved in the measurement or retransmission of previously shared states. We demonstrate the effect on localisation accuracy and bandwidth using data captured from a set of five robots observing each other and landmarks compared to both single vehicle SLAM, pure cooperative localisation and a centralised solution.
ER  - 

TY  - CONF
TI  - Monocular Visual Odometry Scale Recovery Using Geometrical Constraint
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 988
EP  - 995
AU  - X. Wang
AU  - H. Zhang
AU  - X. Yin
AU  - M. Du
AU  - Q. Chen
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - geometry
KW  - image colour analysis
KW  - image matching
KW  - image segmentation
KW  - image sequences
KW  - mesh generation
KW  - object detection
KW  - roads
KW  - stereo image processing
KW  - road detection
KW  - road geometrical model calculation
KW  - road region detection
KW  - road geometrical model estimation
KW  - visual odometry scale recovery method
KW  - geometrical constraint
KW  - monocular visual odometry scale recovery methods
KW  - color information
KW  - Delaunay Triangulation method
KW  - Roads
KW  - Cameras
KW  - Visual odometry
KW  - Three-dimensional displays
KW  - Robot vision systems
KW  - Robustness
DO  - 10.1109/ICRA.2018.8462902
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Scale recovery is one of the essential problems for monocular visual odometry. The camera height is usually used as an absolute reference to recover the scale. In this case, the precision of scale recovery depends on the accuracy of the road region detection and road geometrical model calculation. In previous works, road detection and road geometrical model calculation are solved sequentially: the road geometrical model calculation is based on the road detection and the road region detection is based on the color information. However, the color information of a road is not stable enough. In the proposed method, the estimated road geometrical model is taken into consideration to detect the road region as a feedback. Therefore, the road region detection and road geometrical model estimation can benefit each other. Delaunay Triangulation method is used to segment an input image to many triangles with the matched feature points as vertices. Every triangle region is classified as a road region or not by comparing their geometrical model with that of the road and the road geometrical model is updated online. We evaluate our visual odometry scale recovery method on the KITTI dataset and the results show that our method is achieving the best performance among all existing monocular visual odometry scale recovery methods without additional sensors.
ER  - 

TY  - CONF
TI  - Detection and Resolution of Motion Conflict in Visual Inertial Odometry
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 996
EP  - 1002
AU  - B. P. W. Babu
AU  - D. Cyganski
AU  - J. Duckworth
AU  - S. Kim
PY  - 2018
KW  - distance measurement
KW  - inertial navigation
KW  - motion estimation
KW  - motion conflict detection
KW  - motion estimation
KW  - motion conflict resolution
KW  - visual-inertial odometry
KW  - Motion Conflict aware Visual Inertial Odometry
KW  - Visualization
KW  - Cameras
KW  - Estimation
KW  - Robustness
KW  - Simultaneous localization and mapping
KW  - Hidden Markov models
DO  - 10.1109/ICRA.2018.8460870
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a novel method to detect and resolve motion conflicts in visual-inertial odometry. Recently, it has been common to integrate an IMU sensor with visual odometry in order to improve localization accuracy and robustness. However, when a disagreement between the two sensor modalities occurs, the localization accuracy reduces drastically and leads to irreversible errors. In such conditions, multiple motion estimates based on the set of observations used are possible. This creates a conflict (motion conflict) in determining which observations to use for accurate ego-motion estimation. Therefore, we present a method to detect motion conflicts based on per-frame positional estimate discrepancy and per-landmark reprojection errors. Additionally, we also present a method to resolve motion conflicts by eliminating inconsistent IMU and landmark measurements. Finally, we implement Motion Conflict aware Visual Inertial Odometry (MC-VIO) by combining both detection and resolution of motion conflicts. We perform quantitative and qualitative evaluation of MC-VIO on visually and inertially challenging datasets. Experimental results indicate that the MC-VIO algorithm reduces the increase in absolute trajectory error by 80% and the relative pose error by 60% for scenes with motion conflict, in comparison to the state-of-the-art reference VIO algorithm.
ER  - 

TY  - CONF
TI  - Predicting Alignment Risk to Prevent Localization Failure
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1003
EP  - 1010
AU  - S. Nobili
AU  - G. Tinchev
AU  - M. Fallon
PY  - 2018
KW  - feature extraction
KW  - image registration
KW  - SLAM (robots)
KW  - cluttered man-made environments
KW  - geometric constraints
KW  - spatial overlap
KW  - failed alignment
KW  - point cloud content
KW  - laser-based localization failure
KW  - geometric features
KW  - point cloud registration
KW  - alignment risk
KW  - Three-dimensional displays
KW  - Cloud computing
KW  - Robot sensing systems
KW  - Measurement
KW  - Iterative closest point algorithm
KW  - Octrees
DO  - 10.1109/ICRA.2018.8462890
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - During localization and mapping the success of point cloud registration can be compromised when there is an absence of geometric features or constraints in corridors or across doorways, or when the volumes scanned only partly overlap, due to occlusions or constrictions between subsequent observations. This work proposes a strategy to predict and prevent laser-based localization failure. Our solution relies on explicit analysis of the point cloud content prior to registration. A model predicting the risk of a failed alignment is learned by analysing the degree of spatial overlap between two input point clouds and the geometric constraints available within the region of overlap. We define a novel measure of alignability for these constraints. The method is evaluated against three real-world datasets and compared to baseline approaches. The experiments demonstrate how our approach can help improve the reliability of laser-based localization during exploration of unknown and cluttered man-made environments.
ER  - 

TY  - CONF
TI  - Adversarial Training for Adverse Conditions: Robust Metric Localisation Using Appearance Transfer
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1011
EP  - 1018
AU  - H. Porav
AU  - W. Maddern
AU  - P. Newman
PY  - 2018
KW  - feature extraction
KW  - image filtering
KW  - image recognition
KW  - adversarial training
KW  - adverse conditions
KW  - robust metric localisation
KW  - appearance transfer
KW  - visual place recognition
KW  - invertable generator
KW  - image transforming filter
KW  - feature-matching
KW  - dense descriptor maps
KW  - output synthetic images
KW  - input RGB image
KW  - generated images
KW  - multiple traversals
KW  - reliable localisation
KW  - Generators
KW  - Detectors
KW  - Measurement
KW  - Feature extraction
KW  - Computer architecture
KW  - Training
KW  - Pipelines
DO  - 10.1109/ICRA.2018.8462894
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a method of improving visual place recognition and metric localisation under very strong appearance change. We learn an invertable generator that can transform the conditions of images, e.g. from day to night, summer to winter etc. This image transforming filter is explicitly designed to aid and abet feature-matching using a new loss based on SURF detector and dense descriptor maps. A network is trained to output synthetic images optimised for feature matching given only an input RGB image, and these generated images are used to localize the robot against a previously built map using traditional sparse matching approaches. We benchmark our results using multiple traversals of the Oxford RobotCar Dataset over a year-long period, using one traversal as a map and the other to localise. We show that this method significantly improves place recognition and localisation under changing and adverse conditions, while reducing the number of mapping runs needed to successfully achieve reliable localisation.
ER  - 

TY  - CONF
TI  - Algorithm for Optimal Chance Constrained Knapsack Problem with Applications to Multi-Robot Teaming
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1043
EP  - 1049
AU  - F. Yang
AU  - N. Chakraborty
PY  - 2018
KW  - autonomous aerial vehicles
KW  - concave programming
KW  - knapsack problems
KW  - mobile robots
KW  - multi-robot systems
KW  - stochastic programming
KW  - chance-constrained 0-1 knapsack problem
KW  - variance-mean plane
KW  - deterministic knapsack problems
KW  - multirobot team selection problem
KW  - optimal chance constrained knapsack problem
KW  - 2D discrete optimization problem
KW  - risk-averse knapsack problem
KW  - Robots
KW  - Optimization
KW  - Random variables
KW  - Task analysis
KW  - Batteries
KW  - Linear programming
KW  - Approximation algorithms
DO  - 10.1109/ICRA.2018.8461040
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Motivated by applications in multirobot team selection, in this paper, we present a novel algorithm for computing optimal solution of chance-constrained 0-1 knapsack problem. In this variation of the knapsack problem, the objective function is deterministic but the weights of the items are stochastic and therefore the knapsack constraint is stochastic. We convert the chance-constrained knapsack problem to a two-dimensional discrete optimization problem on the variance-mean plane, where each point on the plane can be identified with an assignment of items to the knapsack. By exploiting the geometry of the non-convex feasible region of the chance-constrained knapsack problem in the variance-mean plane, we present a novel deterministic technique to find an optimal solution by solving a sequence of deterministic knapsack problems (called risk-averse knapsack problem). We apply our algorithm to a multirobot team selection problem to cover a given route, where the length of the route is much larger than the length each individual robot can fly and the length that an individual robot can fly is a random variable (with known mean and variance). We present simulation results on randomly generated data to demonstrate that our approach is scalable with both the number of robots and increasing uncertainty of the distance an individual robot can travel.
ER  - 

TY  - CONF
TI  - Planning-Aware Communication for Decentralised Multi-Robot Coordination
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1050
EP  - 1057
AU  - G. Best
AU  - M. Forrai
AU  - R. R. Mettu
AU  - R. Fitch
PY  - 2018
KW  - control engineering computing
KW  - mobile robots
KW  - Monte Carlo methods
KW  - multi-robot systems
KW  - path planning
KW  - planning (artificial intelligence)
KW  - statistical distributions
KW  - tree searching
KW  - decentralised multirobot coordination
KW  - coordinated multirobot missions
KW  - polynomial-time belief-space planning algorithm
KW  - informative communication planning
KW  - planning-aware communication
KW  - multirobot information gathering
KW  - robot simulation
KW  - decentralised Monte Carlo tree search
KW  - Planning
KW  - Robot kinematics
KW  - Prediction algorithms
KW  - Probability distribution
KW  - Australia
KW  - Cognition
DO  - 10.1109/ICRA.2018.8460617
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present an algorithm for selecting when to communicate during online planning phases of coordinated multi-robot missions. The key idea is that a robot decides to request communication from another robot by reasoning over the predicted information value of communication messages over a sliding time-horizon, where communication messages are probability distributions over action sequences. We formulate this problem in the context of the recently proposed decentralised Monte Carlo tree search (Dec-MCTS) algorithm for online, decentralised multi-robot coordination. We propose a particle filter for predicting the information value, and a polynomial-time belief-space planning algorithm for finding the optimal communication schedules in an online and decentralised manner. We evaluate the benefit of informative communication planning for a multi-robot information gathering scenario with 8 simulated robots. Our results show reductions in channel utilisation of up to four-fifths with surprisingly little impact on coordination performance.
ER  - 

TY  - CONF
TI  - Multi-Robot Realization Based on Goal Adjacency Constraints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1058
EP  - 1063
AU  - D. Şenel
AU  - H. I. Bozma
AU  - F. Öztürk
PY  - 2018
KW  - closed loop systems
KW  - matrix algebra
KW  - mobile robots
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - position control
KW  - velocity control
KW  - pairwise distances
KW  - velocity-controlled robot
KW  - multirobot realization
KW  - goal adjacency constraints
KW  - robot positions
KW  - exact goal positions
KW  - relative distances
KW  - pairwise adjacency constraints
KW  - multirobots
KW  - adjacency matrix
KW  - adjacency threshold
KW  - robot pairs
KW  - coordinated navigation
KW  - closed-loop dynamics
KW  - Conferences
KW  - Automation
KW  - Australia
DO  - 10.1109/ICRA.2018.8460830
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper considers the problem of multi-robot realization. A realization is a set of robot positions where pairwise distances are either bounded from above or from below by a given adjacency threshold - depending on whether the respective robot pairs are to be adjacent or not. In the realization problem, unlike the related coordinated navigation or formation control problems, exact goal positions or relative distances need not be specified. Rather, only pairwise adjacency constraints are given and the robots' positions are required to satisfy these constraints. Applications of realization problem include multi-robots involved in team games (playing soccer, etc), patrolling and area coverage. We present a novel solution to this problem in which the robots simultaneously navigate to find a realization of a given adjacency matrix without colliding with each other along the way. In this solution, complete information about pairwise distances and free configuration space are encoded using an artificial potential function over the cross product space of the robots' simultaneous positions and proximity variables. The closed-loop dynamics governing the motion of each velocity-controlled robot take the form of the appropriate projection of the gradient of this function while pairwise distances are adjusted accordingly. Our extensive simulations demonstrate that the proposed approach has considerably higher realization percentage and shorter movement distances in comparison to a standard 2-stage approach.
ER  - 

TY  - CONF
TI  - Cooperative Object Transport in 3D with Multiple Quadrotors Using No Peer Communication
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1064
EP  - 1071
AU  - Z. Wang
AU  - S. Singh
AU  - M. Pavone
AU  - M. Schwager
PY  - 2018
KW  - aerospace robotics
KW  - asymptotic stability
KW  - compensation
KW  - controllability
KW  - distributed control
KW  - helicopters
KW  - mobile robots
KW  - trajectory optimisation (aerospace)
KW  - exponential stability
KW  - distributed compensation scheme
KW  - controllability
KW  - local optimization problem
KW  - entire assembly
KW  - distributed wrench controller
KW  - rigidly attached quadrotor aerial robots
KW  - multiple quadrotors
KW  - subsequent trajectory optimization
KW  - output wrench space
KW  - control wrench
KW  - group control authority
KW  - Robot kinematics
KW  - Trajectory
KW  - Torque
KW  - Three-dimensional displays
KW  - Payloads
KW  - Unmanned aerial vehicles
DO  - 10.1109/ICRA.2018.8460742
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a framework to enable a fleet of rigidly attached quadrotor aerial robots to transport heavy objects along a known reference trajectory without inter-robot communication or centralized coordination. Leveraging a distributed wrench controller, we provide exponential stability guarantees for the entire assembly, under a mild geometric condition. This is achieved by each quadrotor independently solving a local optimization problem to counteract the biased torque effects from each robot in the assembly. We rigorously analyze the controllability of the object, design a distributed compensation scheme to address these challenges, and show that the resulting strategy collectively guarantees full group control authority. To ensure feasibility for online implementation, we derive bounds on the net desired control wrench, characterize the output wrench space of each quadrotor, and perform subsequent trajectory optimization under these input constraints. We thoroughly validate our method in simulation with eight quadrotors transporting a heavy object in a cluttered environment subject to various sources of uncertainty, and demonstrate the algorithm's resilience.
ER  - 

TY  - CONF
TI  - An Energy-Based Approach for the Multi-Rate Control of a Manipulator on an Actuated Base
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1072
EP  - 1077
AU  - M. De Stefano
AU  - R. Balachandran
AU  - A. M. Giordano
AU  - C. Ott
AU  - C. Secchi
PY  - 2018
KW  - aerospace robotics
KW  - damping
KW  - manipulators
KW  - observers
KW  - stability
KW  - vibration control
KW  - energy-based approach
KW  - multirate control
KW  - robotic system
KW  - actuated floating base
KW  - space applications
KW  - stability issues
KW  - time domain passivity approach
KW  - base-manipulator multibody simulation
KW  - passivity-based stabilizing controller
KW  - energy observer design
KW  - Manipulators
KW  - Satellites
KW  - Jacobian matrices
KW  - Stability analysis
KW  - Delays
KW  - Time-domain analysis
DO  - 10.1109/ICRA.2018.8460497
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we address the problem of controlling a robotic system mounted on an actuated floating base for space applications. In particular, we investigate the stability issues due to the low rate of the base control unit. We propose a passivity-based stabilizing controller based on the time domain passivity approach. The controller uses a variable damper regulated by a designed energy observer. The effectiveness of the proposed strategy is validated on a base-manipulator multibody simulation.
ER  - 

TY  - CONF
TI  - Optimal Intermittent Deployment and Sensor Selection for Environmental Sensing with Multi-Robot Teams
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1078
EP  - 1083
AU  - J. Liu
AU  - R. K. Williams
PY  - 2018
KW  - decision theory
KW  - Markov processes
KW  - multi-robot systems
KW  - partial environmental information
KW  - optimal policy
KW  - optimal intermittent deployment
KW  - multirobot team
KW  - environmental sensing problem
KW  - team composition
KW  - environmental process
KW  - heterogeneous robots
KW  - heterogeneous robot teams
KW  - sensor types
KW  - sensor selection policy
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Markov processes
KW  - Computational modeling
KW  - Delays
DO  - 10.1109/ICRA.2018.8460215
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we formulate an environmental sensing problem for multi-robot teams that couples intermittent deployments with the selection of team composition and sensor type over time. We suppose that a multi-robot team needs to autonomously sense an environmental process and find the optimal policy for deploying heterogeneous robots. In addition, heterogeneous robot teams can be composed in various ways by selecting different mobility and sensor types which have varying accuracies and costs, resulting in a more complex problem. The question is then how to find an optimal intermittent deployment and sensor selection policy that captures both cost and estimation accuracy based on partial environmental information. By utilizing structural results from partially observable Markov decision processes (POMDP) and exploiting submodularity, an optimal policy, which minimizes cost while maintaining a high accuracy, can be achieved in this paper. The effectiveness of this method is demonstrated by simulation results and comparisons with naive policies.
ER  - 

TY  - CONF
TI  - Cooperative Object Transportation by Multiple Ground and Aerial Vehicles: Modeling and Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1084
EP  - 1090
AU  - M. Lippi
AU  - A. Marino
PY  - 2018
KW  - cables (mechanical)
KW  - dynamic programming
KW  - mobile robots
KW  - multi-robot systems
KW  - optimal control
KW  - path planning
KW  - planning problems
KW  - aerial robots
KW  - transportation task
KW  - ground robots
KW  - nonrigid inextensible cables
KW  - heterogeneous multirobot system
KW  - multiple aerial vehicles
KW  - general constrained optimal planning problem
KW  - multiple ground vehicles
KW  - cooperative object transportation
KW  - modeling problems
KW  - dynamic programming
KW  - Vehicle dynamics
KW  - Manipulators
KW  - Load modeling
KW  - Unmanned aerial vehicles
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460778
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper the modeling and planning problems of a system composed of multiple ground and aerial robots involved in a transportation task are considered. The ground robots rigidly grasp a load, while the aerial vehicles are attached to the object through non-rigid inextensible cables. The idea behind such a heterogeneous multi-robot system is to benefit of the advantages of both types of robots that might be the precision of ground robots, the increased payload of multiple aerial vehicles and their larger workspace. The overall model of the system is derived and its expression and redundancy are exploited by setting a general constrained optimal planning problem. The problem is herein solved by dynamic programming and simulation results validated the proposed scheme.
ER  - 

TY  - CONF
TI  - Integrating Planning and Execution for a Team of Heterogeneous Robots with Time and Communication Constraints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1091
EP  - 1097
AU  - P. Bechon
AU  - M. Barbier
AU  - C. Grand
AU  - S. Lacroix
AU  - C. Lesire
AU  - C. Praiet
PY  - 2018
KW  - autonomous aerial vehicles
KW  - delays
KW  - distributed control
KW  - mobile robots
KW  - multi-robot systems
KW  - intermittent communications
KW  - high-level decision skills
KW  - distributed decision architecture
KW  - hybrid planner
KW  - distributed execution algorithm
KW  - delays
KW  - surveillance missions
KW  - ground robots
KW  - heterogeneous robots
KW  - field multirobot missions
KW  - autonomous aerial robot
KW  - unavoidable disturbances
KW  - integrating planning and execution
KW  - communication constrains
KW  - time constraints
KW  - decentralized repairs
KW  - Maintenance engineering
KW  - Planning
KW  - Computer architecture
KW  - Robot kinematics
KW  - Surveillance
KW  - Delays
DO  - 10.1109/ICRA.2018.8461024
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Field multi-robot missions face numerous unavoidable disturbances, such as delays in executing tasks and intermittent communications. Coping with such disturbances requires to endow the robots with high-level decision skills. We present a distributed decision architecture based first on a hybrid planner that can manage decentralized repairs with partial communication, and secondly on a distributed execution algorithm that efficiently propagates delays. This architecture has been successfully experimented on the field for the achievement of surveillance missions involving eight (8) real autonomous aerial and ground robots.
ER  - 

TY  - CONF
TI  - Data-Driven Approach to Simulating Realistic Human Joint Constraints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1098
EP  - 1103
AU  - Y. Jiang
AU  - C. K. Liu
PY  - 2018
KW  - backpropagation
KW  - human-robot interaction
KW  - neural nets
KW  - optimisation
KW  - physical human-robot interaction
KW  - physics simulation
KW  - implicit equation
KW  - human data
KW  - physics engine
KW  - data-driven approach
KW  - human joint limits
KW  - joint motion
KW  - realistic human joint limits
KW  - human joint configurations
KW  - realistic human joint constraints
KW  - backpropagation
KW  - optimization problem
KW  - fully connected neural network
KW  - Joints
KW  - Mathematical model
KW  - Physics
KW  - Robots
KW  - Neural networks
KW  - Elbow
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8461010
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Modeling realistic human joint limits is important for applications involving physical human-robot interaction. However, setting appropriate human joint limits is challenging because it is pose-dependent: the range of joint motion varies depending on the positions of other bones. The paper introduces a new technique to accurately simulate human joint limits in physics simulation. We propose to learn an implicit equation to represent the boundary of valid human joint configurations from real human data. The function in the implicit equation is represented by a fully connected neural network whose gradients can be efficiently computed via back-propagation. Using gradients, we can efficiently enforce realistic human joint limits through constraint forces in a physics engine or as constraints in an optimization problem.
ER  - 

TY  - CONF
TI  - Generative Adversarial Nets in Robotic Chinese Calligraphy
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1104
EP  - 1110
AU  - F. Chao
AU  - J. Lv
AU  - D. Zhou
AU  - L. Yang
AU  - C. Lin
AU  - C. Shang
AU  - C. Zhou
PY  - 2018
KW  - character sets
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - robotic chinese calligraphy
KW  - robotic writing
KW  - Chinese character strokes
KW  - font generation methods
KW  - generative adversarial nets-based calligraphic robotic framework
KW  - interactive modules
KW  - stroke generation module
KW  - stroke discriminative module
KW  - stroke generative module
KW  - calligraphic robot
KW  - human-level stroke
KW  - robotic autonomous creation ability
KW  - reinforcement learning
KW  - Writing
KW  - Trajectory
KW  - Training
KW  - Gallium nitride
KW  - Manipulators
KW  - Probability distribution
DO  - 10.1109/ICRA.2018.8460787
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Conventional approaches of robotic writing of Chinese character strokes often suffer from limited font generation methods, and thus the writing results often lack of diversity. This has seriously restricted the high quality writing ability of robots. This paper proposes a generative adversarial nets-based calligraphic robotic framework, which enables a robot to learn writing fundamental Chinese strokes with rich diversity and good originality. In particular, the framework considers the learning process of robotic writing as an adversarial procedure which is implemented by three interactive modules including a stroke generation module, a stroke discriminative module and a training module. Noting that the stroke generative module included in the conventional generative adversarial nets cannot solve the non-differentiable problem, the policy gradient commonly used in reinforcement learning is thus adapted in this work to train the generative module by regarding the outputs from the discriminative module as rewards. Experimental results demonstrate that the proposed framework allows a calligraphic robot to successfully write fundamental Chinese strokes with good quality in various styles. The experiment also suggests the proposed approach can achieve human-level stroke writing quality without the requirement of a performance evaluation system. This approach therefore significantly boosts the robotic autonomous creation ability.
ER  - 

TY  - CONF
TI  - Socially Compliant Navigation Through Raw Depth Inputs with Generative Adversarial Imitation Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1111
EP  - 1117
AU  - L. Tai
AU  - J. Zhang
AU  - M. Liu
AU  - W. Burgard
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - socially compliant navigation
KW  - raw depth inputs
KW  - mobile robots
KW  - socially compliant manner
KW  - generative adversarial imitation learning strategy
KW  - raw sensory input
KW  - GAIL-based approach
KW  - behavior cloning policy
KW  - social force model
KW  - Force
KW  - Navigation
KW  - Cloning
KW  - Sensors
KW  - Mobile robots
KW  - Learning (artificial intelligence)
KW  - Visualization
DO  - 10.1109/ICRA.2018.8460968
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present an approach for mobile robots to learn to navigate in dynamic environments with pedestrians via raw depth inputs, in a socially compliant manner. To achieve this, we adopt a generative adversarial imitation learning (GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our approach overcomes the disadvantages of previous methods, as they heavily depend on the full knowledge of the location and velocity information of nearby pedestrians, which not only requires specific sensors, but also the extraction of such state information from raw sensory input could consume much computation time. In this paper, our proposed GAIL-based model performs directly on raw depth inputs and plans in real-time. Experiments show that our GAIL-based approach greatly improves the safety and efficiency of the behavior of mobile robots from pure behavior cloning. The real-world deployment also shows that our method is capable of guiding autonomous vehicles to navigate in a socially compliant manner directly through raw depth inputs. In addition, we release a simulation plugin for modeling pedestrian behaviors based on the social force model.
ER  - 

TY  - CONF
TI  - Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1118
EP  - 1125
AU  - Y. Liu
AU  - A. Gupta
AU  - P. Abbeel
AU  - S. Levine
PY  - 2018
KW  - learning by example
KW  - robot programming
KW  - video signal processing
KW  - context translation
KW  - observation-action tuples
KW  - supervised learning algorithm
KW  - imitation-from-observation
KW  - deep reinforcement learning
KW  - video prediction
KW  - raw video
KW  - robotic skills learning
KW  - imitation learning
KW  - Task analysis
KW  - Robots
KW  - Context modeling
KW  - Learning (artificial intelligence)
KW  - Visualization
KW  - Tools
KW  - Cloning
DO  - 10.1109/ICRA.2018.8462901
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Imitation learning is an effective approach for autonomous systems to acquire control policies when an explicit reward function is unavailable, using supervision provided as demonstrations from an expert, typically a human operator. However, standard imitation learning methods assume that the agent receives examples of observation-action tuples that could be provided, for instance, to a supervised learning algorithm. This stands in contrast to how humans and animals imitate: we observe another person performing some behavior and then figure out which actions will realize that behavior, compensating for changes in viewpoint, surroundings, object positions and types, and other factors. We term this kind of imitation learning “imitation-from-observation,” and propose an imitation learning method based on video prediction with context translation and deep reinforcement learning. This lifts the assumption in imitation learning that the demonstration should consist of observations in the same environment configuration, and enables a variety of interesting applications, including learning robotic skills that involve tool use simply by observing videos of human tool use. Our experimental results show the effectiveness of our approach in learning a wide range of real-world robotic tasks modeled after common household chores from videos of a human demonstrator, including sweeping, ladling almonds, pushing objects as well as a number of tasks in simulation.
ER  - 

TY  - CONF
TI  - Incremental Task Modification via Corrective Demonstrations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1126
EP  - 1133
AU  - R. A. Gutierrez
AU  - V. Chu
AU  - A. L. Thomaz
AU  - S. Niekum
PY  - 2018
KW  - autoregressive processes
KW  - Bayes methods
KW  - finite state machines
KW  - hidden Markov models
KW  - intelligent robots
KW  - manipulators
KW  - Incremental Task Modification via Corrective Demonstrations
KW  - state transition auto-regressive hidden Markov model
KW  - probabilistic properties
KW  - simulated block sorting domain
KW  - real-world pouring task
KW  - ITMCD Model Selection
KW  - approximate Bayesian model selection
KW  - FSA
KW  - finite state automaton representation
KW  - Hidden Markov models
KW  - Task analysis
KW  - Robots
KW  - Computational modeling
KW  - Adaptation models
KW  - Probabilistic logic
KW  - Bayes methods
DO  - 10.1109/ICRA.2018.8461215
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In realistic environments, fully specifying a task model such that a robot can perform a task in all situations is impractical. In this work, we present Incremental Task Modification via Corrective Demonstrations (ITMCD), a novel algorithm that allows a robot to update a learned model by making use of corrective demonstrations from an end-user in its environment. We propose three different types of model updates that make structural changes to a finite state automaton (FSA) representation of the task by first converting the FSA into a state transition auto-regressive hidden Markov model (STARHMM). The STARHMM's probabilistic properties are then used to perform approximate Bayesian model selection to choose the best model update, if any. We evaluate ITMCD Model Selection in a simulated block sorting domain and the full algorithm on a real-world pouring task. The simulation results show our approach can choose new task models that sufficiently incorporate new demonstrations while remaining as simple as possible. The results from the pouring task show that ITMCD performs well when the modeled segments of the corrective demonstrations closely comply with the original task model.
ER  - 

TY  - CONF
TI  - Time-Contrastive Networks: Self-Supervised Learning from Video
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1134
EP  - 1141
AU  - P. Sermanet
AU  - C. Lynch
AU  - Y. Chebotar
AU  - J. Hsu
AU  - E. Jang
AU  - S. Schaal
AU  - S. Levine
AU  - G. Brain
PY  - 2018
KW  - image representation
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - robot programming
KW  - robot vision
KW  - video signal processing
KW  - time-contrastive networks
KW  - robotic behaviors
KW  - robotic imitation settings
KW  - human poses
KW  - viewpoint-invariant representation
KW  - end-effectors
KW  - reinforcement learning algorithm
KW  - self-supervised learning
KW  - robotic systems
KW  - Robots
KW  - Task analysis
KW  - Visualization
KW  - Learning (artificial intelligence)
KW  - Training
KW  - Liquids
KW  - Lighting
DO  - 10.1109/ICRA.2018.8462891
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a self-supervised approach for learning representations and robotic behaviors entirely from unlabeled videos recorded from multiple viewpoints, and study how this representation can be used in two robotic imitation settings: imitating object interactions from videos of humans, and imitating human poses. Imitation of human behavior requires a viewpoint-invariant representation that captures the relationships between end-effectors (hands or robot grippers) and the environment, object attributes, and body pose. We train our representations using a triplet loss, where multiple simultaneous viewpoints of the same observation are attracted in the embedding space, while being repelled from temporal neighbors which are often visually similar but functionally different. This signal causes our model to discover attributes that do not change across viewpoint, but do change across time, while ignoring nuisance variables such as occlusions, motion blur, lighting and background. We demonstrate that this representation can be used by a robot to directly mimic human poses without an explicit correspondence, and that it can be used as a reward function within a reinforcement learning algorithm. While representations are learned from an unlabeled collection of task-related videos, robot behaviors such as pouring are learned by watching a single 3rd-person demonstration by a human. Reward functions obtained by following the human demonstrations under the learned representation enable efficient reinforcement learning that is practical for real-world robotic systems. Video results, open-source code and dataset are available at sermanet.github.io/imitate.
ER  - 

TY  - CONF
TI  - Learning Sensor Feedback Models from Demonstrations via Phase-Modulated Neural Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1142
EP  - 1149
AU  - G. Sutanto
AU  - Z. Su
AU  - S. Schaal
AU  - F. Meier
PY  - 2018
KW  - adaptive control
KW  - feedback
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - radial basis function networks
KW  - tactile sensors
KW  - phase-modulated neural networks
KW  - feedback model maps
KW  - motion plan adaptation
KW  - radial basis function network structure
KW  - tactile sensor traces
KW  - data-driven framework
KW  - anthropomorphic robot
KW  - Robot sensing systems
KW  - Adaptation models
KW  - Task analysis
KW  - Mathematical model
KW  - Neural networks
KW  - Quaternions
DO  - 10.1109/ICRA.2018.8460986
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In order to robustly execute a task under environmental uncertainty, a robot needs to be able to reactively adapt to changes arising in its environment. The environment changes are usually reflected in deviation from expected sensory traces. These deviations in sensory traces can be used to drive the motion adaptation, and for this purpose, a feedback model is required. The feedback model maps the deviations in sensory traces to the motion plan adaptation. In this paper, we develop a general data-driven framework for learning a feedback model from demonstrations. We utilize a variant of a radial basis function network structure -with movement phases as kernel centers- which can generally be applied to represent any feedback models for movement primitives. To demonstrate the effectiveness of our framework, we test it on the task of scraping on a tilt board. In this task, we are learning a reactive policy in the form of orientation adaptation, based on deviations of tactile sensor traces. As a proof of concept of our method, we provide evaluations on an anthropomorphic robot.
ER  - 

TY  - CONF
TI  - Robot Navigation from Human Demonstration: Learning Control Behaviors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1150
EP  - 1157
AU  - M. Wigness
AU  - J. G. Rogers
AU  - L. E. Navarro-Serment
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimal control
KW  - robot navigation
KW  - human collaborators
KW  - dynamic environments
KW  - disaster recovery
KW  - unmanned ground vehicle
KW  - UGV
KW  - fast field adaptation
KW  - minimal human supervision
KW  - visual perception
KW  - inverse optimal control
KW  - minimal human supervisory examples
KW  - navigation behavior
KW  - real-world environment
KW  - minimal human demonstration
KW  - Navigation
KW  - Robots
KW  - Trajectory
KW  - Entropy
KW  - Training
KW  - Collision avoidance
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8462900
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When working alongside human collaborators in dynamic environments such as a disaster recovery, an unmanned ground vehicle (UGV) may require fast field adaptation to perform its duties or learn novel tasks. In disaster recovery situations, personnel and equipment are constrained, so training must be accomplished with minimal human supervision. In this paper, we introduce a novel framework which uses learned visual perception and inverse optimal control trained with minimal human supervisory examples. This approach is used to learn to mimic navigation behavior and is demonstrated through extensive evaluation in a real-world environment. Finally, we demonstrate the ability to learn an additional behavior with minimal human demonstration in the field.
ER  - 

TY  - CONF
TI  - Relocalization, Global Optimization and Map Merging for Monocular Visual-Inertial SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1197
EP  - 1204
AU  - T. Qin
AU  - P. Li
AU  - S. Shen
PY  - 2018
KW  - cameras
KW  - distance measurement
KW  - graph theory
KW  - inertial navigation
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - relocalization
KW  - global optimization
KW  - monocular visual-inertial SLAM
KW  - visual-inertial system
KW  - low-cost inertial measurement unit
KW  - state estimation
KW  - visual-inertial odometry
KW  - absolute pose estimation
KW  - visual-inertial SLAM system
KW  - global pose graph optimization
KW  - map merging ability
KW  - map reuse
KW  - pose graph optimization
KW  - Cameras
KW  - Optimization
KW  - Visualization
KW  - Feature extraction
KW  - Microsoft Windows
KW  - Simultaneous localization and mapping
KW  - Real-time systems
DO  - 10.1109/ICRA.2018.8460780
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The monocular visual-inertial system (VINS), which consists one camera and one low-cost inertial measurement unit (IMU), is a popular approach to achieve accurate 6-DOF state estimation. However, such locally accurate visual-inertial odometry is prone to drift and cannot provide absolute pose estimation. Leveraging history information to relocalize and correct drift has become a hot topic. In this paper, we propose a monocular visual-inertial SLAM system, which can relocalize camera and get the absolute pose in a previous-built map. Then 4-DOF pose graph optimization is performed to correct drifts and achieve global consistent. The 4-DOF contains x, y, z, and yaw angle, which is the actual drifted direction in the visual-inertial system. Furthermore, the proposed system can reuse a map by saving and loading it in an efficient way. Current map and previous map can be merged together by the global pose graph optimization. We validate the accuracy of our system on public datasets and compare against other state-of-the-art algorithms. We also evaluate the map merging ability of our system in the large-scale outdoor environment. The source code of map reuse is integrated into our public code, VINS-Monol11https://github.com/HKUST-Aerial-Robotics/VINS-Mono.
ER  - 

TY  - CONF
TI  - Elastic LiDAR Fusion: Dense Map-Centric Continuous-Time SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1206
EP  - 1213
AU  - C. Park
AU  - P. Moghadam
AU  - S. Kim
AU  - A. Elfes
AU  - C. Fookes
AU  - S. Sridharan
PY  - 2018
KW  - image reconstruction
KW  - mobile robots
KW  - optical radar
KW  - optimisation
KW  - probability
KW  - radar imaging
KW  - robot vision
KW  - sensor fusion
KW  - SLAM (robots)
KW  - dense map-centric continuous-time SLAM
KW  - CT-SLAM
KW  - computational complexity
KW  - surfel fusion
KW  - global batch trajectory optimization
KW  - probabilistic surface element fusion
KW  - map deformation
KW  - global trajectory optimization
KW  - Continuous-Time SLAM
KW  - global batch optimization
KW  - multimodal sensor fusion
KW  - continuous-time trajectory representation
KW  - elastic LiDAR fusion
KW  - Laser radar
KW  - Trajectory optimization
KW  - Simultaneous localization and mapping
KW  - Strain
KW  - Interpolation
DO  - 10.1109/ICRA.2018.8462915
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The concept of continuous-time trajectory representation has brought increased accuracy and efficiency to multi-modal sensor fusion in modern SLAM. However, regardless of these advantages, its offline property caused by the requirement of global batch optimization is critically hindering its relevance for real-time and life-long applications. In this paper, we present a dense map-centric SLAM method based on a continuous-time trajectory to cope with this problem. The proposed system locally functions in a similar fashion to conventional Continuous-Time SLAM (CT-SLAM). However, it removes the need for global trajectory optimization by introducing map deformation. The computational complexity of the proposed approach for loop closure does not depend on the operation time, but only on the size of the space it explored before the loop closure. It is therefore more suitable for long term operation compared to the conventional CT-SLAM. Furthermore, the proposed method reduces uncertainty in the reconstructed dense map by using probabilistic surface element (surfel) fusion. We demonstrate that the proposed method produces globally consistent maps without global batch trajectory optimization, and effectively reduces LiDAR noise by surfel fusion.
ER  - 

TY  - CONF
TI  - Design, modeling and control of t3-multirotor: a tilting thruster type multirotor
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1214
EP  - 1219
AU  - S. J. Lee
AU  - J. Yoo
AU  - H. J. Kim
PY  - 2018
KW  - aerospace components
KW  - attitude control
KW  - helicopters
KW  - large-scale systems
KW  - servomechanisms
KW  - tilting thruster type multirotor
KW  - mechanically separated thrusters
KW  - fuselage posture
KW  - relative attitude control
KW  - T3-multirotor
KW  - translational acceleration
KW  - servo-linkage mechanism
KW  - dynamically complex system
KW  - autonomous level flight
KW  - Servomotors
KW  - Mathematical model
KW  - Force
KW  - Torque
KW  - Dynamics
KW  - Attitude control
KW  - Analytical models
DO  - 10.1109/ICRA.2018.8462888
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a new design of multirotor, named as `Tilting Thruster Type' (T3)-multirotor. The new platform is equipped with mechanically separated thrusters, which can take any fuselage posture within a specified range regardless of any direction of translational acceleration. A specially designed servo-linkage mechanism is employed for relative attitude control between the thruster and the fuselage. Mathematical modeling and analysis of the new platform are conducted to explore the control method of the dynamically complex system. For demonstrating the potential of the new T3-multirotor, an autonomous level flight is performed where the fuselage maintains zero roll and pitch angle during the entire flight. Both simulation and experimental results are provided with detailed analysis.
ER  - 

TY  - CONF
TI  - Design and Analysis of a Fixed-Wing Unmanned Aerial-Aquatic Vehicle
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1236
EP  - 1243
AU  - J. Moore
AU  - A. Fein
AU  - W. Setzler
PY  - 2018
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - autonomous underwater vehicles
KW  - closed loop systems
KW  - mobile robots
KW  - optimisation
KW  - fixed-wing unmanned aerial-aquatic vehicle
KW  - fixed-wing vehicle
KW  - aerobatic post-stall maneuvers
KW  - water-to-air transition execution
KW  - direct hybrid trajectory optimization
KW  - closed-loop control
KW  - Propellers
KW  - Vehicle dynamics
KW  - Prototypes
KW  - Unmanned aerial vehicles
KW  - Design tools
DO  - 10.1109/ICRA.2018.8461240
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we describe the design and analysis of a fixed-wing unmanned aerial-aquatic vehicle. Inspired by prior work in aerobatic post-stall maneuvers for fixed-wing vehicles [1], we explore the feasibility of executing a water-to-air transition with a fixed-wing vehicle using almost entirely commercial off-the-shelf components (excluding the fuselage). To do this, we first propose a conceptual design based on observations about the dominant forces and dimensionless analysis. We then further refine this concept by building a design tool based on simplified models to explore the design space. To verify the results of the design tool, we use a higher fidelity model along with a direct hybrid trajectory optimization approach to show via numerical simulation that the water-to-air transition is feasible. Finally, we successfully test our design experimentally by hand-piloting a prototype vehicle through the water-to-air transition and discuss our approach for replacing the human-pilot with closed-loop control.
ER  - 

TY  - CONF
TI  - An Empirical Evaluation of Ground Effect for Small-Scale Rotorcraft
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1244
EP  - 1250
AU  - S. A. Conyers
AU  - M. J. Rutherford
AU  - K. P. Valavanis
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - propellers
KW  - rotors
KW  - helicopter ground effect
KW  - hover performance
KW  - multirotor UAV
KW  - rotor performance
KW  - single-rotor configuration
KW  - fixed propellers
KW  - propeller configuration
KW  - UAV flight controller
KW  - flight stability
KW  - ground effect
KW  - helicopter models
KW  - Cheeseman-Bennett model
KW  - small-scale rotorcraft
KW  - Rotors
KW  - Propellers
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Blades
KW  - Helicopters
DO  - 10.1109/ICRA.2018.8461035
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Ground effect refers to the apparent increase in lift that an aircraft experiences when it flies close to the ground. For helicopters, this effect has been modeled since the 1950's based on the work of Cheeseman and Bennett, perhaps the most common method for predicting hover performance due to ground effect. This model, however, is based on assumptions that do not hold for small-scale rotorcraft because it was developed specifically for conventional helicopters. It is not clear if the Cheeseman-Bennett model can be applied to today's multirotor UAVs. In this paper, we compare the Cheeseman-Bennett model to experimental results for rotor performance due to ground effect in several small-scale multirotor and single-rotor configurations. Experimental findings suggest that some of the conventional thinking surrounding helicopter ground effect cannot be applied directly to rotorcraft using fixed propellers at variable speeds (e.g. multirotors), and that it is necessary to adjust the helicopter models to better reflect the differences in such aircraft. The experimental results for multirotors presented are for multiple propeller configurations, speeds and spacings. Ultimately, this work will facilitate the development of an improved UAV flight controller that can accurately account for ground effect to improve flight stability near surfaces and structures.
ER  - 

TY  - CONF
TI  - Design, Modeling and Control of a Solar-Powered Quadcopter
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1251
EP  - 1258
AU  - N. Kingry
AU  - L. Towers
AU  - Y. Liu
AU  - Y. Zu
AU  - Y. Wang
AU  - B. Staheli
AU  - Y. Katagiri
AU  - S. Cook
AU  - R. Dai
PY  - 2018
KW  - aerodynamics
KW  - aerospace control
KW  - control system synthesis
KW  - energy harvesting
KW  - feedback
KW  - helicopters
KW  - solar powered vehicles
KW  - virtualisation
KW  - long-endurance missions
KW  - aerodynamic
KW  - feedback control system
KW  - virtual simulation
KW  - solar energy harvesting capabilities
KW  - solar-powered quadcopter
KW  - Solar panels
KW  - Prototypes
KW  - Batteries
KW  - Photovoltaic cells
KW  - Payloads
KW  - Propellers
KW  - Aerodynamics
KW  - Solar Energy
KW  - Quadcopter
KW  - System Design
KW  - Vehicle Control
DO  - 10.1109/ICRA.2018.8462896
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the design, modeling, control, and experimental test of a solar-powered quadcopter to allow for long-endurance missions. We first present the design of a large-scale quadcopter that incorporates solar energy harvesting capabilities. Based on the design results, we built the dynamical model of the customized quadcopter with analysis of the aerodynamic influence. A feedback control system is developed for the solar-powered quadcopter that takes into account the wind disturbance and is verified in virtual simulation examples. All parameters used in the modeling and simulations are based on a developed prototype of the solar-powered quadcopter. Flight tests with the prototype are presented to validate the feasibility and theoretical basis of the solar-powered quadcopter.
ER  - 

TY  - CONF
TI  - The UNAV, a Wind-Powered UAV for Ocean Monitoring: Performance, Control and Validation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1259
EP  - 1266
AU  - G. D. Bousquet
AU  - M. S. Triantafyllou
AU  - J. E. Slotine
PY  - 2018
KW  - actuators
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - autonomous underwater vehicles
KW  - drag
KW  - hydrodynamics
KW  - vehicle dynamics
KW  - UNAv
KW  - Unmanned Nautical Air-water vehicle
KW  - albatrosses
KW  - sailboats
KW  - wind power
KW  - ocean monitoring
KW  - wind-powered UAV
KW  - multiinput longitudinal flight controller
KW  - trim analysis
KW  - sailboat
KW  - airborne wings
KW  - gravity-cancelling force
KW  - high lift-to-drag ratio
KW  - albatross
KW  - span-wise axes
KW  - vertical surface-piercing hydrofoil keel
KW  - vertical wing-sail
KW  - glider-type airframe
KW  - Drag
KW  - Force
KW  - Sea surface
KW  - Aerodynamics
KW  - Wind
KW  - Atmospheric modeling
DO  - 10.1109/ICRA.2018.8462893
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Wind power is the source of propulsive energy for sailboats and albatrosses. We present the UNAv, an Unmanned Nautical Air-water vehicle, that borrows features from both. It is composed of a glider-type airframe fitted with a vertical wing-sail extending above the center of mass of the system and a vertical surface-piercing hydrofoil keel extending below. The sail and keel are both actuated in pitch about their span-wise axes. Like an albatross, the UNAv is fully streamlined, high lift-to-drag ratio and generates the gravity-cancelling force by means of its airborne wings. Like a sailboat, the UNAv interacts with water and may access the full magnitude of the wind. A trim analysis predicts that a 3.4-meter span, 3 kg system could stay airborne in winds as low as 2.8 m/s (5.5 knots), and travel several times faster than the wind speed. Trim flight requires the ability to fly at extreme low height with the keel immersed in water. For that purpose, a multi-input longitudinal flight controller that leverages fast flap actuation is presented. The flight maneuver is demonstrated experimentally.
ER  - 

TY  - CONF
TI  - Distributed Multi-Robot Cooperation for Information Gathering Under Communication Constraints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1267
EP  - 1272
AU  - A. Viseras
AU  - Z. Xu
AU  - L. Merino
PY  - 2018
KW  - cooperative systems
KW  - decision making
KW  - distributed control
KW  - Gaussian processes
KW  - multi-robot systems
KW  - path planning
KW  - Gaussian processes
KW  - path planning
KW  - path clustering
KW  - multi-robot exploration
KW  - inter-robot communication constraints
KW  - information-theoretic utility function
KW  - Max-sum algorithm
KW  - distributed decision-making algorithm
KW  - multirobot information gathering
KW  - inter-robot restrictions
KW  - distributed multirobot cooperation
KW  - Clustering algorithms
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Heuristic algorithms
KW  - Linear programming
DO  - 10.1109/ICRA.2018.8460846
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Many recent works have proposed algorithms for information gathering that benefit from multi-robot cooperation. However, most algorithms either employ discretization of the state and action spaces, which makes them computationally intractable for robotic systems with complex dynamics; or cannot deal with inter-robot restrictions like e.g. communication constraints. This paper presents an approach for multi-robot information gathering that tackles the two aforementioned issues. To this end we propose an algorithm that combines in an innovative manner Gaussian processes (GPs) to model the physical process of interest, RRT planners to plan paths in a continuous domain, and a distributed decision-making algorithm to achieve multi-robot cooperation. Specifically, we employ the Max-sum algorithm for distributed multi-robot cooperation by defining an information-theoretic utility function together with a path clustering approach. This function maximizes information gathering, subject to inter-robot communication constraints. We validate the proposed approach in simulations, and in a field experiment where three quadcopters explore a simulated wind field. Results demonstrate the effectiveness of the approach.
ER  - 

TY  - CONF
TI  - Automated Pick-Up of Suturing Needles for Robotic Surgical Assistance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1370
EP  - 1377
AU  - C. D'Ettorre
AU  - G. Dwyer
AU  - X. Du
AU  - F. Chadebecq
AU  - F. Vasconcelos
AU  - E. De Momi
AU  - D. Stoyanov
PY  - 2018
KW  - cancer
KW  - endoscopes
KW  - medical image processing
KW  - medical robotics
KW  - needles
KW  - robot vision
KW  - surgery
KW  - surgical tool
KW  - RALP
KW  - urethrovesical anastomosis
KW  - robotic surgical assistance
KW  - robot-assisted laparoscopic prostatectomy
KW  - prostate cancer
KW  - nerve sparing removal prostate tissue
KW  - bladder neck
KW  - dexterity demanding tasks
KW  - suturing instruments
KW  - robotic instruments
KW  - vision-guided needle grasping method
KW  - suturing needle
KW  - grasping process
KW  - needle detection algorithm
KW  - Needles
KW  - Grasping
KW  - Robots
KW  - Tools
KW  - Instruments
KW  - Surgery
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461200
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robot-assisted laparoscopic prostatectomy (RALP) is a treatment for prostate cancer that involves complete or nerve sparing removal prostate tissue that contains cancer. After removal the bladder neck is successively sutured directly with the urethra. The procedure is called urethrovesical anastomosis and is one of the most dexterity demanding tasks during RALP. Two suturing instruments and a pair of needles are used in combination to perform a running stitch during urethrovesical anastomosis. While robotic instruments provide enhanced dexterity to perform the anastomosis, it is still highly challenging and difficult to learn. In this paper, we presents a vision-guided needle grasping method for automatically grasping the needle that has been inserted into the patient prior to anastomosis. We aim to automatically grasp the suturing needle in a position that avoids hand-offs and immediately enables the start of suturing. The full grasping process can be broken down into: a needle detection algorithm; an approach phase where the surgical tool moves closer to the needle based on visual feedback; and a grasping phase through path planning based on observed surgical practice. Our experimental results show examples of successful autonomous grasping that has the potential to simplify and decrease the operational time in RALP by assisting a small component of urethrovesical anastomosis.
ER  - 

TY  - CONF
TI  - A Hybrid Actuated Robotic Prototype for Minimally Invasive Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1386
EP  - 1391
AU  - N. Evangeliou
AU  - A. Tzes
PY  - 2018
KW  - actuators
KW  - end effectors
KW  - graphical user interfaces
KW  - haptic interfaces
KW  - medical computing
KW  - medical robotics
KW  - motion control
KW  - shape memory effects
KW  - surgery
KW  - telerobotics
KW  - hybrid actuated robotic prototype
KW  - prototype robotic platform
KW  - minimally invasive surgical procedures
KW  - extra-operative motion
KW  - pivoting motion
KW  - 4 DoF shape memory alloy actuated probe
KW  - intra-operative dexterity
KW  - end-effector
KW  - Robot Operating System framework
KW  - interaction forces
KW  - graphical user interface
KW  - servo-actuated manipulator
KW  - operation mode switching
KW  - stereo imaging
KW  - teleoperation
KW  - haptic device
KW  - Probes
KW  - Manipulators
KW  - Actuators
KW  - Wires
KW  - Kinematics
KW  - Minimally Invasive Surgery
KW  - Robot Assisted Surgery
KW  - Shape Memory Alloy actuation
KW  - Visual Servoing
KW  - Medical Imaging
DO  - 10.1109/ICRA.2018.8460640
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This article presents the design and experimental evaluation of a prototype robotic platform for minimally invasive surgical procedures. The platform utilizes a hybrid actuation scheme, consisting of a 5 Degree-of-Freedom (DoF) servo-actuated manipulator for extra-operative and pivoting motion and a 4 DoF shape memory alloy actuated probe at the distal end, for intra-operative dexterity. The architecture targets thoracic and abdominal operations, with low interaction forces at the probe's end-effector. The system, runs under the Robot Operating System framework for easier deployment and development. Additional accompanying software is developed to aid the surgeon during deployment. Specifically, a Graphical User Interface employing modules controls for online parameter reconfiguration, operation mode switching while custom viewports for stereo imaging are implemented. Teleoperation is feasible with the integration of a haptic device. In-vitro evaluation of the robot is presented, to assess the maneuvering efficiency and further potential exploitation of the design.
ER  - 

TY  - CONF
TI  - Design and Test of an In-Vivo Robotic Camera Integrated with Optimized Illumination System for Single-port Laparoscopic Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1392
EP  - 1397
AU  - X. Liu
AU  - R. A. Yazdanpanah
AU  - T. Zuo
AU  - Y. Guan
AU  - G. J. Mancini
AU  - J. Tan
PY  - 2018
KW  - biomedical optical imaging
KW  - cameras
KW  - image sensors
KW  - lenses
KW  - light emitting diodes
KW  - medical robotics
KW  - optical design techniques
KW  - surgery
KW  - in-vivo robotic laparoscopic camera design
KW  - optical efficiency
KW  - LED
KW  - miniature optical lenses
KW  - illuminance
KW  - illumination uniformity
KW  - freeform optical lens design method
KW  - single-port laparoscopic surgery
KW  - optimized illumination system
KW  - distance 100.0 mm
KW  - Cameras
KW  - Robot vision systems
KW  - Lighting
KW  - Lenses
KW  - Laparoscopes
DO  - 10.1109/ICRA.2018.8460614
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes a novel in-vivo robotic laparo-scopic camera design with an optimized illumination system, which is a crucial component for achieving high imaging quality. The robotic camera design with three extendable wings can reserve sufficient on-board space to harbor the optimized illumination system without affecting the compactness of the camera. We contribute a freeform optical lens design method and develop three miniature optical lenses for the LEDs to achieve greater than 95% illumination uniformity, greater than 14, 000 lx illuminance on a target plane with a distance of 100 mm, and greater than 89% optical efficiency. The prototype is implemented and experimentally tested, which demonstrates great performance of the in-vivo robotic laparoscopic camera and the significance of the optimized illumination system.
ER  - 

TY  - CONF
TI  - A Novel Magnetic Anchored and Steered Camera Robot for Single Port Access Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1406
EP  - 1412
AU  - T. Cheng
AU  - X. Zhang
AU  - C. S. H. Ng
AU  - P. W. Y. Chiu
AU  - Z. Li
PY  - 2018
KW  - cameras
KW  - finite element analysis
KW  - medical robotics
KW  - robot vision
KW  - surgery
KW  - single port access surgery
KW  - minimally invasive surgery
KW  - planar pan/tilt workspace
KW  - lower robot footprint
KW  - vertical space
KW  - internal permanent magnets
KW  - IPMs
KW  - cylindrical capsule
KW  - camera module
KW  - camera view orientation
KW  - planar workspace
KW  - anchoring
KW  - intra-abdominal surface
KW  - steering
KW  - tilting panning
KW  - camera robot prototype
KW  - minimal footprint
KW  - magnetic anchored steered camera robot
KW  - size 6.0 mm
KW  - size 4.0 cm
KW  - size 7.0 mm
KW  - mass 3.6 g
KW  - Cameras
KW  - Robot vision systems
KW  - Magnetic separation
KW  - Soft magnetic materials
KW  - Surgery
KW  - Instruments
DO  - 10.1109/ICRA.2018.8460677
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel magnetic anchored and steered camera robot intended for minimally invasive surgery (MIS), particularly for single port access (SPA) surgery. The design aims to achieve both compactness and a planar pan/tilt workspace (instead of hemispheric) to lower robot footprint in vertical space. Robot comprises two 6mm×6mm diametrically magnetized internal permanent magnets (IPMs) fixed at either ends of a small cylindrical capsule, with camera module and a 45°mirror capped inside capsule. As such, camera view orientation can be steered in 2-DOF across range of 180° tilt and 360° panning, all within a planar workspace close to surface of anchor. Using only two small IPMs for all necessary functions (anchoring, translation along intra-abdominal surface, and steering) reduces bulk and length of robot. The robot is investigated first by finite element methods. Theoretical models for both tilting and panning were then built based on FEM results. The models are evaluated and verified by checking its predictions in benchtop experiments. Ex vivo evaluations was also utilized to prove feasibility of device in environment similar to human anatomy. Overall, the camera robot prototype is compact (4cm length; 7mm diameter), lightweight (3.6g), motor-free, and allow view orientation control (tilting and panning) in a planar workspace. Minimal footprint in vertical space is ideal for many MIS applications, where vertical space is extremely limited.
ER  - 

TY  - CONF
TI  - Vehicle Detection, Tracking and Behavior Analysis in Urban Driving Environments Using Road Context
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1413
EP  - 1420
AU  - S. Verma
AU  - Y. H. Eng
AU  - H. X. Kong
AU  - H. Andersen
AU  - M. Meghjani
AU  - W. K. Leong
AU  - X. Shen
AU  - C. Zhang
AU  - M. H. Ang
AU  - D. Rus
PY  - 2018
KW  - driver information systems
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object tracking
KW  - optical radar
KW  - real-time systems
KW  - road traffic
KW  - road vehicles
KW  - sensor fusion
KW  - traffic engineering computing
KW  - 2D Lidar
KW  - deep learning
KW  - vehicle tracking
KW  - Lidar sensor fusion
KW  - global map coordinate system
KW  - track management
KW  - data association
KW  - high precision range estimation
KW  - monocular camera
KW  - robust fusion system
KW  - tracking system
KW  - real-time vehicle detection
KW  - road context
KW  - urban driving environments
KW  - behavior analysis
KW  - Roads
KW  - Laser radar
KW  - Sensor fusion
KW  - Robot sensing systems
KW  - Vehicle detection
KW  - Estimation
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2018.8460951
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a real-time vehicle detection and tracking system to accomplish the complex task of driving behavior analysis in urban environments. We propose a robust fusion system that combines a monocular camera and a 2D Lidar. This system takes advantage of three key components: robust vehicle detection using deep learning techniques, high precision range estimation from Lidar, and road context from the prior map knowledge. The camera and Lidar sensor fusion, data association and track management are all performed in the global map coordinate system by taking into account the sensors' characteristics. Lastly, behavior reasoning is performed by examining the tracked vehicle states in the lane coordinate system in which the road context is encoded. We validated our approach by tracking a leading vehicle while it performed usual urban driving behaviors such as lane keeping, stop-and-go at intersections, lane changing, overtaking and turning. The leading vehicle was tracked consistently throughout the 2.3 km route and its behavior was classified reliably.
ER  - 

TY  - CONF
TI  - GOMSF: Graph-Optimization Based Multi-Sensor Fusion for robust UAV Pose estimation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1421
EP  - 1428
AU  - R. Mascaro
AU  - L. Teixeira
AU  - T. Hinzmann
AU  - R. Siegwart
AU  - M. Chli
PY  - 2018
KW  - autonomous aerial vehicles
KW  - distance measurement
KW  - graph theory
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - sensor fusion
KW  - SLAM (robots)
KW  - GOMSF
KW  - proprioceptive measurements
KW  - exteroceptive measurements
KW  - navigation algorithms
KW  - agile mobile robots
KW  - Unmanned Aerial Vehicles
KW  - UAV pose estimation
KW  - graph optimization based multisensor fusion
KW  - 6 Degree-of-Freedom visual-inertial odometry poses
KW  - extended Kalman filter
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Optimization
KW  - Pose estimation
KW  - Global Positioning System
KW  - Time measurement
DO  - 10.1109/ICRA.2018.8460193
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Achieving accurate, high-rate pose estimates from proprioceptive and/or exteroceptive measurements is the first step in the development of navigation algorithms for agile mobile robots such as Unmanned Aerial Vehicles (UAVs). In this paper, we propose a decoupled Graph-Optimization based Multi-Sensor Fusion approach (GOMSF) that combines generic 6 Degree-of-Freedom (DoF) visual-inertial odometry poses and 3 DoF globally referenced positions to infer the global 6 DoF pose of the robot in real-time. Our approach casts the fusion as a real-time alignment problem between the local base frame of the visual-inertial odometry and the global base frame. The alignment transformation that relates these coordinate systems is continuously updated by optimizing a sliding window pose graph containing the most recent robot's states. We evaluate the presented pose estimation method on both simulated data and large outdoor experiments using a small UAV that is capable to run our system onboard. Results are compared against different state-of-the-art sensor fusion frameworks, revealing that the proposed approach is substantially more accurate than other decoupled fusion strategies. We also demonstrate comparable results in relation with a finely tuned Extended Kalman Filter that fuses visual, inertial and GPS measurements in a coupled way and show that our approach is generic enough to deal with different input sources in a straightforward manner. Video - https//youtu.be/GIZNSZ2soL8.
ER  - 

TY  - CONF
TI  - Attitude, Linear Velocity and Depth Estimation of a Camera Observing a Planar Target Using Continuous Homography and Inertial Data
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1429
EP  - 1435
AU  - M. Hua
AU  - N. Manerikar
AU  - T. Hamel
AU  - C. Samson
PY  - 2018
KW  - accelerometers
KW  - cameras
KW  - image sequences
KW  - inertial navigation
KW  - Kalman filters
KW  - motion estimation
KW  - stability
KW  - state estimation
KW  - motion excitation conditions
KW  - deterministic observer
KW  - accelerometer measurements
KW  - gyrometer
KW  - optical flow
KW  - linear velocity
KW  - inertial data
KW  - continuous homography
KW  - planar target
KW  - attitude
KW  - testbed IMU-Camera system
KW  - estimation errors
KW  - observability analysis
KW  - Observers
KW  - Observability
KW  - Robot sensing systems
KW  - Accelerometers
KW  - Magnetometers
KW  - Cameras
DO  - 10.1109/ICRA.2018.8460512
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper revisits the problem of estimating the attitude, linear velocity and depth of an IMU-Camera with respect to a planar target. The considered solution relies on the measurement of the optical flow (extracted from the continuous homography) complemented with gyrometer and accelerometer measurements. The proposed deterministic observer is accompanied with an observability analysis that points out camera's motion excitation conditions whose satisfaction grants stability of the observer and convergence of the estimation errors to zero. The performance of the observer is illustrated by performing experiments on a testbed IMU-Camera system.
ER  - 

TY  - CONF
TI  - Deep Inference for Covariance Estimation: Learning Gaussian Noise Models for State Estimation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1436
EP  - 1443
AU  - K. Liu
AU  - K. Ok
AU  - W. Vega-Brown
AU  - N. Roy
PY  - 2018
KW  - covariance analysis
KW  - Gaussian noise
KW  - image representation
KW  - learning (artificial intelligence)
KW  - measurement errors
KW  - measurement uncertainty
KW  - neural nets
KW  - regression analysis
KW  - state estimation
KW  - raw sensor data
KW  - raw sensor measurement
KW  - ground-truth measurement error
KW  - measurement model
KW  - prediction performance
KW  - covariance prediction
KW  - state Estimation
KW  - measurement covariance estimation
KW  - deep neural network
KW  - Gaussian noise models
KW  - measurement uncertainty
KW  - deep inference for covariance estimation
KW  - predictive sensor modeling
KW  - hand-coded features
KW  - Robot sensing systems
KW  - Measurement uncertainty
KW  - Measurement errors
KW  - Covariance matrices
KW  - Predictive models
KW  - Estimation
KW  - Neural networks
DO  - 10.1109/ICRA.2018.8461047
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a novel method of measurement covariance estimation that models measurement uncertainty as a function of the measurement itself. Existing work in predictive sensor modeling outperforms conventional fixed models, but requires domain knowledge of the sensors that heavily influences the accuracy and the computational cost of the models. In this work, we introduce Deep Inference for Covariance Estimation (DICE), which utilizes a deep neural network to predict the covariance of a sensor measurement from raw sensor data. We show that given pairs of raw sensor measurement and ground-truth measurement error, we can learn a representation of the measurement model via supervised regression on the prediction performance of the model, eliminating the need for hand-coded features and parametric forms. Our approach is sensor-agnostic, and we demonstrate improved covariance prediction on both simulated and real data.
ER  - 

TY  - CONF
TI  - A Study on Optimal Placement of Accelerometers for Pose Estimation of a Robot Arm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1444
EP  - 1451
AU  - I. B. Wijayasinghe
AU  - M. N. Saadatzi
AU  - S. Abubakar
AU  - D. O. Popa
PY  - 2018
KW  - accelerometers
KW  - end effectors
KW  - legged locomotion
KW  - mobile robots
KW  - Monte Carlo methods
KW  - pose estimation
KW  - position control
KW  - prosthetics
KW  - sensors
KW  - optimal placement
KW  - accelerometers
KW  - inertial sensor placement
KW  - noise characteristics
KW  - joint angle encoders
KW  - end-effector positioning
KW  - legged locomotion
KW  - dual arm
KW  - prosthetic limbs
KW  - inertial measurement units
KW  - artificial skin patches
KW  - noise properties
KW  - signal-to-noise Ratio
KW  - micromachined sensors
KW  - two-link robot arm
KW  - expected estimation error metric values
KW  - accelerometer configurations
KW  - optimal number
KW  - arm pose estimation error
KW  - SNR
KW  - Monte-Carlo simulations
KW  - robot arm pose estimation
KW  - IMU
KW  - Robot sensing systems
KW  - Accelerometers
KW  - Manipulators
KW  - Pose estimation
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8460501
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This study investigates the effects of inertial sensor placement and noise characteristics on the accuracy of robot pose estimation. Of course, most robots are equipped with joint angle encoders for pose estimation and end-effector positioning. However, in some situations, it's not possible or not desirable to introduce encoders on all joints. Such common examples include legged locomotion, dual arm co-manipulation, and prosthetic limbs. To tackle such situations, one solution is to embed inertial measurement units (IMUs) into artificial skin patches placed on robots' limbs and body. This work analyzes the effects of design parameters such as the number of sensors, their placement on the robot, and noise properties on the quality of robot pose estimation and its signal-to-noise Ratio (SNR). We study the benefits of using a large number of IMUs, which is possible due to the proliferation of inexpensive micro-machined sensors. We use Monte-Carlo simulations and experiments with a two-link robot arm to obtain the distributions of expected estimation error metric values for several accelerometer configurations, which are then compared to determine the optimal number and placement for the IMUs. Results show that the placement of at least two accelerometers on each link has the most significant impact on the pose estimation error, while using a larger number of accelerometers plays a less significant role in reducing the arm pose estimation error and resultant SNR.
ER  - 

TY  - CONF
TI  - Encoder-Camera-Ground Penetrating Radar Tri-Sensor Mapping for Surface and Subsurface Transportation Infrastructure Inspection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1452
EP  - 1457
AU  - C. Chou
AU  - A. Kingery
AU  - D. Wang
AU  - H. Li
AU  - D. Song
PY  - 2018
KW  - automatic optical inspection
KW  - cameras
KW  - graph theory
KW  - ground penetrating radar
KW  - image fusion
KW  - image reconstruction
KW  - optimisation
KW  - pose estimation
KW  - structural engineering computing
KW  - transportation
KW  - GPR
KW  - wheel encoder
KW  - sensing suite
KW  - data collection scheme
KW  - ALs
KW  - types data streams
KW  - camera images
KW  - data fusion
KW  - sensory data
KW  - sensor fusion approach
KW  - encoder-camera-ground penetrating radar tri-sensor mapping
KW  - subsurface transportation infrastructure inspection
KW  - algorithmic development
KW  - multiple sensors
KW  - multimodal mapping
KW  - Ground penetrating radar
KW  - Cameras
KW  - Inspection
KW  - Synchronization
KW  - Robot sensing systems
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8461080
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We report system and algorithmic development for a sensing suite comprising multiple sensors for both surface and subsurface transportation infrastructure inspection focusing on multi-modal mapping for inspection. The sensing suite contains a camera, a ground penetrating radar (GPR), and a wheel encoder. We design the sensing suite and propose a data collection scheme using customized artificial landmarks (ALs). We use ALs to synchronize two types data streams: camera images that are temporally evenly-spaced and GPR/encoder data that are spatially evenly-spaced. We also employ pose graph optimization with synchronization as penalty functions to further refine synchronization and perform data fusion for 3D reconstruction. We have implemented the system and tested it in physical experiments. The results show that our system successfully fuses three sensory data and product metric 3D reconstruction. The sensor fusion approach reduces the end-to-end distance error from 7.45cm to 3.10cm.
ER  - 

TY  - CONF
TI  - Angle Estimation for Robotic Arms on Floating Base Using Low-Cost IMUS
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1458
EP  - 1465
AU  - X. Zhang
AU  - E. Peltola
AU  - J. Mattila
PY  - 2018
KW  - hydraulic systems
KW  - inertial navigation
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - sensor fusion
KW  - wheels
KW  - commercial mobile working machine
KW  - extended Kalman filter
KW  - complementary filter
KW  - sensors data fusion
KW  - low-cost IMUs
KW  - six degrees-of-freedom wheeled base platform
KW  - 3-DOF hydraulic anthropomorphic arm
KW  - floating base hydraulic arm
KW  - vibrational disturbances
KW  - machines diesel engine
KW  - deformation
KW  - EKF
KW  - CF
KW  - root mean square error
KW  - RMS error
KW  - floating base robotic platforms
KW  - link angles
KW  - low-cost inertial measurement units
KW  - robotic arms
KW  - angle estimation
KW  - Accelerometers
KW  - Estimation
KW  - Force
KW  - Manipulators
KW  - Hydraulic systems
KW  - Gyroscopes
DO  - 10.1109/ICRA.2018.8462898
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - An algorithm that uses low-cost inertial measurement units (IMUs) for estimating link angles for floating base robotic platforms is proposed. Each link has four IMUs attached on its surfaces, and an Extended Kalman Filter (EKF) and a Complementary Filter (CF) are used for fusing the sensors' data. The algorithm is validated with a commercial mobile working machine, which consist of six degrees-of-freedom (DOF) wheeled base platform, and a 3-DOF hydraulic anthropomorphic arm. Although there are vibrational disturbances from the machine's diesel engine and deformation of the links themselves, the measured results from the planar motion of a floating base hydraulic arm show that the accuracy of the angle estimation is impressively less than 1 degree in the root mean square (RMS) error.
ER  - 

TY  - CONF
TI  - IntuBot: Design and Prototyping of a Robotic Intubation Device
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1482
EP  - 1487
AU  - X. Cheng
AU  - G. Jiang
AU  - K. Lee
AU  - Y. N. Laker
PY  - 2018
KW  - biomedical equipment
KW  - computerised tomography
KW  - medical image processing
KW  - medical robotics
KW  - mobile robots
KW  - robot vision
KW  - servomechanisms
KW  - steering systems
KW  - robotic intubation device
KW  - endotracheal intubation
KW  - robotic prototype
KW  - hardware system
KW  - stepper motor
KW  - servo motors
KW  - stylet tip
KW  - vocal cords
KW  - pre-clinical testing
KW  - IntuBot
KW  - vision-based navigation algorithm
KW  - CT scan images
KW  - Gears
KW  - Prototypes
KW  - Servomotors
KW  - Electron tubes
KW  - Mouth
KW  - Training
KW  - Testing
DO  - 10.1109/ICRA.2018.8460779
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Endotracheal intubation is one of the most common procedures performed worldwide in emergency departments and operating rooms. It is a highly complicated procedure susceptible to failure. This paper presents a robotic prototype, called IntuBot, designed to automate this procedure. The hardware system consists of a stepper motor to steer the stylet in forward and backward motions and two servo motors to generate bending at the stylet tip to navigate through a patient's airway. A real-time vision-based navigation algorithm is also presented to guide the stylet to localize the vocal cords, which is the tubes ultimate target. For pre-clinical testing, we 3D printed and then molded a silicone model of the airway from the mouth to the vocal cords based on a series of actual CT scan images. The prototype was tested for its steering capabilities.
ER  - 

TY  - CONF
TI  - Locomotion Envelopes for Adaptive Control of Powered Ankle Prostheses
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1488
EP  - 1495
AU  - N. Dhir
AU  - H. Dallali
AU  - E. M. Ficanha
AU  - G. A. Ribeiro
AU  - M. Rastgaar
PY  - 2018
KW  - adaptive control
KW  - gait analysis
KW  - Gaussian processes
KW  - medical robotics
KW  - prosthetics
KW  - regression analysis
KW  - Gaussian process regression
KW  - human subjects walking
KW  - locomotion variables
KW  - nonlinear manifolds
KW  - anthropomorphic control
KW  - impedance control
KW  - adaptive control
KW  - powered ankle foot prosthesis
KW  - locomotion envelope
KW  - gait-cycle duration
KW  - temporal evolution
KW  - velocity range
KW  - Legged locomotion
KW  - Prosthetics
KW  - Impedance
KW  - Manifolds
KW  - Kernel
KW  - Gaussian processes
KW  - Robustness
DO  - 10.1109/ICRA.2018.8460929
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we combine Gaussian process regression and impedance control, to illicit robust, anthropomorphic, adaptive control of a powered ankle prosthesis. We learn the non-linear manifolds which guide how locomotion variables temporally evolve, and regress that surface over a velocity range to create a manifold. The joint set of manifolds, as well as the temporal evolution of the gait-cycle duration is what we term a locomotion envelope. Current powered prostheses have problems adapting across speeds. It is likely that humans rely upon a control strategy which is adaptable, can become more robust and accurate with more data and provides a nonparametric approach which allows the strategy to grow with the number of observations. We demonstrate such a strategy in this study and successfully simulate locomotion well beyond our training data. The method we propose is based on common physical features observed in numerous human subjects walking at different speeds. Based on the derived locomotion envelopes we show that ankle power increases monotonically with speed among all subjects. We demonstrate our methods in simulation and human experiments, on a powered ankle foot prosthesis to demonstrate the effectiveness of the method.
ER  - 

TY  - CONF
TI  - Modeling and Characterization of a Potential Bladder Based Orthotic Device to Mitigate Shoe Slip
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1496
EP  - 1503
AU  - K. B. Freckleton
AU  - M. A. Minor
PY  - 2018
KW  - accident prevention
KW  - footwear
KW  - friction
KW  - orthotics
KW  - physiological models
KW  - wearable robots
KW  - friction force
KW  - valves
KW  - slip event
KW  - impact force
KW  - bladder walls
KW  - contact forces
KW  - slip-mitigating potential
KW  - orthotic device
KW  - intelligent orthotic shoe
KW  - longitudinal slip
KW  - shoe slip
KW  - bladder based orthotic device
KW  - rubberized shoe sole
KW  - robotic shoes
KW  - slip-fall accidents
KW  - Bladder
KW  - Atmospheric modeling
KW  - Conferences
KW  - Automation
KW  - Australia
KW  - Friction
DO  - 10.1109/ICRA.2018.8460791
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The exploration of an “intelligent” orthotic shoe sole to negate, or minimize, longitudinal slip by momentarily increasing friction force is presented. The conceptual device takes the form of a rubberized shoe sole containing pockets of air that can be released via valves controlled by a microprocessor. During a slip event, the valves would be opened and the bladders would be collapsed by the weight of the user, which modulates contact and friction forces. The goal is to increase friction forces in this process, by creating an impact force between the user and ground surface, with the potential to increase friction and mitigate slip. Simulations of bladder walls, air flow through valves, contact forces, and friction forces are modeled and combined into a lumped parameter model to predict device behavior. Prototypes of the device are created and evaluated to validate models and slip-mitigating potential.
ER  - 

TY  - CONF
TI  - Preliminary Results of a Handheld Nerve Electrode Insertion Device
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1504
EP  - 1510
AU  - S. Yim
AU  - Y. -. Oh
AU  - W. Choi
AU  - H. Park
AU  - J. Jeong
AU  - Y. Ihn
AU  - D. Hwang
AU  - S. -. Oh
AU  - J. Kim
AU  - K. Kim
PY  - 2018
KW  - biomedical electrodes
KW  - microelectrodes
KW  - neuromuscular stimulation
KW  - surgery
KW  - handheld nerve electrode insertion device
KW  - peripheral nervous system
KW  - nerve holder
KW  - electrode inserter
KW  - intrafascicular planar electrodes
KW  - Electrodes
KW  - Springs
KW  - Force
KW  - Thumb
KW  - Polyimides
KW  - Silicon
DO  - 10.1109/ICRA.2018.8460882
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents preliminary results of a handheld device to assist the insertion of intra-fascicular planar electrodes into a peripheral nervous system. The developed device consists of two units, a nerve holder and an electrode inserter. We introduce design considerations, features, and underlying mechanisms of the device. User tests and animal experiments show that users can easily and accurately adjust the insertion position and direction of nerve electrodes while manipulating the device in 3D, and that planar electrodes are successfully inserted into sciatic nerves of rats. We hope that the proposed device will help neural engineering researchers and scientists to simplify the surgical process and produce consistent experimental results.
ER  - 

TY  - CONF
TI  - Programmable Medicine: Autonomous, Ingestible, Deployable Hydrogel Patch and Plug for Stomach Ulcer Therapy
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1511
EP  - 1518
AU  - A. du Plessis d'Argentré
AU  - S. Perry
AU  - Y. Iwata
AU  - H. Iwasaki
AU  - E. Iwase
AU  - A. Fabozzo
AU  - I. Will
AU  - D. Rus
AU  - D. D. Damian
AU  - S. Miyashita
PY  - 2018
KW  - biological organs
KW  - biomechanics
KW  - biomedical materials
KW  - diseases
KW  - drug delivery systems
KW  - drugs
KW  - hydrogels
KW  - remotely navigatable hydrogel patch
KW  - deployable ingestible hydrogel patch
KW  - stomach ulcer therapy
KW  - remotely navigatable hydrogel plug
KW  - deployable ingestible hydrogel plug
KW  - magnetic field
KW  - deployable origami design
KW  - folded configuration
KW  - dehydration
KW  - hydration
KW  - agarose hydrogel
KW  - gastric ulcer treatment
KW  - catastrophic situation
KW  - inflammatory process
KW  - stomach wall
KW  - programmable medicine
KW  - Plugs
KW  - Stomach
KW  - Navigation
KW  - Shape
KW  - Fabrication
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8460615
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Gastric ulcer is a chronic and complex (and often complete) erosion of the stomach wall that happens as a complication of a previous chronic, inflammatory process. It represents a catastrophic situation in which the patient is critical and its conditions need to be treated fast. This study presents a remotely navigatable and deployable ingestible patch and plug for gastric ulcer treatment. The patch/plug structure is made of agarose hydrogel that can change rigidity through hydration and dehydration. When dehydrated, it is rigid and can maintain a folded configuration so it can be ingested as a “pill”. This can be guided to the targeted location by a magnetic field, and be deployed instantly by hydration, namely by supplying water from the mouth. Due to the deployable origami design, it exhibits an expansion of 10 times its initial surface area, making the device suitable for the use of dressing a surface as a patch, and filling a hole as a plug.
ER  - 

TY  - CONF
TI  - Open-Loop Drug Delivery Strategy to the Cochlea Using a Permanent Magnetic Actuator
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1519
EP  - 1524
AU  - W. Amokrane
AU  - K. Belharet
AU  - M. Souissi
AU  - A. B. Grayeli
AU  - A. Ferreira
PY  - 2018
KW  - actuators
KW  - bioMEMS
KW  - diseases
KW  - drug delivery systems
KW  - drugs
KW  - electromagnetic actuators
KW  - magnetic actuators
KW  - manipulators
KW  - medical robotics
KW  - microrobots
KW  - disease locations
KW  - magnetics fields
KW  - reliable solution
KW  - innovative solution
KW  - human body
KW  - use ofrobotic devices
KW  - permanent magnetic actuator
KW  - open-loop drug delivery strategy
KW  - reliable drug administration
KW  - precise drug administration
KW  - human phantom cochlea
KW  - navigation proposed strategy
KW  - human cochlea
KW  - magnetic microparticle
KW  - freedom robotic manipulator
KW  - robotic drug delivery strategy
KW  - open-loop control way
KW  - magnetic actuator axis
KW  - pushing pulling forces
KW  - end-effector
KW  - permanent magnets
KW  - micronanorobots
KW  - Actuators
KW  - Robots
KW  - Ear
KW  - Magnetic separation
KW  - Drug delivery
KW  - Drugs
KW  - Permanent magnets
DO  - 10.1109/ICRA.2018.8460216
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The use ofrobotic devices for drug delivery in sensitive area of the human body is an innovative and reliable solution. Most of them use magnetics fields, to steer micro-nano-robots into diseases locations. In this study, we use a magnetic actuator based on two permanent magnets as an end-effector of a robotic manipulator. The actuator offers the possibility to generate both pushing and pulling forces on the magnetic actuator axis in an open-loop control way. We describe in this paper the robotic drug delivery strategy that we implemented in a 6 degree of freedom robotic manipulator to push and to steer a magnetic microparticle from the round window to the apex of the human cochlea. Different experiments have been conducted in order to demonstrate the effectiveness and robustness of the navigation proposed strategy on a human phantom cochlea. The results demonstrate clearly that precise and reliable drug administration is rendered possible.
ER  - 

TY  - CONF
TI  - Augmented Joint Stiffness and Actuation Using Architectures of Soft Pneumatic Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1533
EP  - 1538
AU  - N. Thompson
AU  - X. Zhang
AU  - F. Ayala
AU  - E. T. Hsiao-Wecksler
AU  - G. Krishnan
PY  - 2018
KW  - elastomers
KW  - pneumatic actuators
KW  - robots
KW  - helical actuators
KW  - parallel actuators
KW  - augmented joint stiffness
KW  - soft pneumatic actuators
KW  - soft robotic actuators
KW  - wearable soft robotic sleeve
KW  - fiber reinforced elastomeric enclosures
KW  - helical actuator architectures
KW  - linear actuators
KW  - linear-helical actuator configuration
KW  - FREE
KW  - Conferences
KW  - Automation
KW  - Australia
DO  - 10.1109/ICRA.2018.8460746
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft robotic actuators are well suited for use in exoskeleton applications due to their innate compliance and low weight. We have developed a wearable soft robotic sleeve that uses fiber reinforced elastomeric enclosures (FREEs) to provide actuation and stiffness at the elbow for augmented lifting and carrying ability. The sleeve includes novel linear and helical actuator architectures to induce and resist joint movement respectively, and is intended to be comfortable, lightweight, and low profile. We developed test protocols to measure actuation and stiffness performance of different helical and linear architectures, and to compare helical and linear actuator groups when used individually and together. Our findings indicate that nested linear actuators have superior contraction ratios compared to parallel linear actuators, resulting in greater angular displacement. Stiffness from helical actuators increased with pressure and number of parallel actuators. A combined linear-helical actuator configuration considerably outperformed helical and linear actuator groups when used on their own.
ER  - 

TY  - CONF
TI  - APAM: Antagonistic Pneumatic Artificial Muscle
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1539
EP  - 1546
AU  - N. S. Usevitch
AU  - A. M. Okamura
AU  - E. W. Hawkes
PY  - 2018
KW  - electroactive polymer actuators
KW  - medical robotics
KW  - motion control
KW  - muscle
KW  - pneumatic actuators
KW  - supports
KW  - internal chambers
KW  - tetrahedron apex
KW  - compliant truss robot
KW  - independent control
KW  - external chambers
KW  - pneumatic actuator
KW  - antagonistic pneumatic artificial muscle
KW  - APAM
KW  - Actuators
KW  - Shape
KW  - Electron tubes
KW  - Force
KW  - Muscles
KW  - Robots
KW  - Geometry
DO  - 10.1109/ICRA.2018.8460881
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a pneumatic actuator capable of changing length by 1000%, applying both pushing and pulling forces, and independently modulating its length and stiffness. These characteristics are enabled by individually addressable internal and external chambers that work antagonistically against one another. The high deformation with low hysteresis is achieved by wrinkling of thin materials that are assumed to be inextensible but flexible, as opposed to stretchable. A model for the actuator is presented and validated with experimental results, showing capabilities of high strain, pushing and pulling, and independent control of length and stiffness. These characteristics are motivated by the application of a compliant truss robot. Accordingly, we show a simple grounded tetrahedron with three actuator elements and three static elements. We demonstrate motion of the tetrahedron apex against external loads and the ability of the structure to vary its stiffness. The actuator offers a unique set of characteristics that could increase the capabilities of soft robotic devices.
ER  - 

TY  - CONF
TI  - Passive and Active Particle Damping in Soft Robotic Actuators *This work is funded by a Basic Research Grant from the University of Hong Kong.
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1547
EP  - 1552
AU  - Y. Li
AU  - Y. Chen
AU  - T. Ren
AU  - Y. Hu
PY  - 2018
KW  - damping
KW  - design engineering
KW  - elasticity
KW  - industrial robots
KW  - pneumatic actuators
KW  - vibration control
KW  - passive particle damping
KW  - vibration damping method
KW  - University of Hong Kong
KW  - elastic bodies
KW  - energy source
KW  - soft actuator design
KW  - soft robotic actuators
KW  - active particle damping
KW  - Actuators
KW  - Damping
KW  - Vibrations
KW  - Robots
KW  - Friction
KW  - Shock absorbers
KW  - Force
DO  - 10.1109/ICRA.2018.8462895
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft robotic actuators are highly elastic bodies that oscillate drastically once excited. This oscillation is undesirable in many applications. So far, very little studies on soft actuator damping have been reported. In this paper, we report a simple and effective vibration damping method based on passive and active particle damping. Experimental studies on the effectiveness of particle damping have been conducted. It is found that active particle damping is more effective than passive damping, nevertheless, active particle damping demands a more complicated design with extra energy source and control. Since particles are discrete matters, they can be seamless integrated into soft actuator design with only minor influence of soft actuator's compliance and softness.
ER  - 

TY  - CONF
TI  - A Fluid-Filled Tubular Dielectric Elastomer Variable Stiffness Structure Inspired by the Hydrostatic Skeleton Principle *Research supported by the National Natural Science Foundation of China (No.51675413).
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1553
EP  - 1558
AU  - T. Wang
AU  - Y. Li
AU  - Y. Li
AU  - J. Zhang
AU  - J. Hong
AU  - M. Y. Wang
PY  - 2018
KW  - dielectric materials
KW  - elastic constants
KW  - elastomers
KW  - elongation
KW  - oils
KW  - pre-stretch
KW  - tensile stiffness
KW  - fluid-filled tubular dielectric elastomer variable stiffness structure
KW  - insulating oil
KW  - fiber-constrained dielectric elastomer tube
KW  - hydrostatic skeleton principle
KW  - Electron tubes
KW  - Strain
KW  - Oils
KW  - Muscles
KW  - Hydraulic systems
KW  - Force
KW  - Soft robotics
DO  - 10.1109/ICRA.2018.8461245
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work presents a novel variable stiffness structure consisting of a fiber-constrained dielectric elastomer tube filled with insulating oil. The tensile stiffness of the structure can be adjusted by voltages and its initial value can be customized according to the initial pre-stretch of the material. The structure has a dimension of ~30 mm diameter × 50 mm length. A mathematical analysis is established to predict the initial tensile stiffness of the structure. The changes of the tensile stiffness of the structure under voltages are verified experimentally. The results show a decrease of the tensile stiffness of the device by 25% at 4 kV and the decrement is also related to the elongation of the structure. With different pre-stretches and dimensions of the dielectric elastomer, one can obtain devices with different variation ranges of tensile stiffness.
ER  - 

TY  - CONF
TI  - Stiffness Variability in Jamming of Compliant Granules and a Case Study Application in Climbing Vertical Shafts
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1559
EP  - 1566
AU  - S. Hauser
AU  - M. Mutlu
AU  - F. Freundler
AU  - A. Ijspeert
PY  - 2018
KW  - bending
KW  - biomechanics
KW  - elastic constants
KW  - elasticity
KW  - end effectors
KW  - force measurement
KW  - friction
KW  - granular materials
KW  - legged locomotion
KW  - pressure sensors
KW  - shafts
KW  - cubic shaped granules
KW  - gradual stiffness change
KW  - jamming membranes
KW  - end effectors
KW  - bending stiffness
KW  - climbing task
KW  - shaft walls
KW  - compressive stiffness variation
KW  - multimodal properties
KW  - granular material
KW  - stiffness variability
KW  - quasisolid state
KW  - packing density
KW  - compliant granules jamming
KW  - granular media jamming
KW  - bioinspired robotic platform
KW  - straight vertical shafts climbing
KW  - friction force measurement
KW  - pressure sensor
KW  - force dissipators
KW  - Jamming
KW  - Biomembranes
KW  - End effectors
KW  - Shape
KW  - Shafts
KW  - Legged locomotion
KW  - Soft robotics
KW  - variable stiffness joints
KW  - vacuum jamming
KW  - universal gripper
KW  - climbing
DO  - 10.1109/ICRA.2018.8462899
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Jamming of granular media has been shown to possess the property of stiffness variation, transitioning from a soft to a quasi-solid state depending on the packing density of the granules. Recently, a gradual stiffness change for bending has been reported by using compliant, cubic shaped granules. Here we demonstrate that the same method and material also exhibits a gradual stiffness change for compression. As a potential application of “compliant jamming”, a bio-inspired robotic platform with jamming membranes as end effectors is designed and tasked with climbing straight vertical shafts. First, the benefit of varying the bending stiffness is investigated in the climbing task by measuring the friction force that the end effectors are applying to the shaft walls, especially if the walls are irregularly shaped. Then the role of compressive stiffness variation is explored by analyzing the performance of the robot in the climbing task, showing multi-modal properties of jamming membranes: (i) enabling a pressure sensor to detect the shaft walls, acting (ii) as grippers that actively use the irregularities of the walls to climb up by state-switching the granular material and (iii) as force dissipators that can dissipate internal forces caused by closed kinematic chains.
ER  - 

TY  - CONF
TI  - A Geometric and Unified Approach for Modeling Soft-Rigid Multi-Body Systems with Lumped and Distributed Degrees of Freedom
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1567
EP  - 1574
AU  - F. Renda
AU  - L. Seneviratne
PY  - 2018
KW  - elasticity
KW  - geometry
KW  - inverse problems
KW  - Newton method
KW  - robot dynamics
KW  - discrete Cosserat approach
KW  - soft-body dynamics
KW  - geometric theory
KW  - recursive Newton-Euler algorithm
KW  - forward dynamic problems
KW  - soft robots
KW  - soft-rigid multibody systems
KW  - inverse problems
KW  - linear complexity
KW  - Kinematics
KW  - Fasteners
KW  - Strain
KW  - Heuristic algorithms
KW  - Algebra
KW  - Soft robotics
DO  - 10.1109/ICRA.2018.8461186
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, a geometric and unified model of soft-rigid multi-body systems is presented, based on a discrete Cosserat approach of the soft-body dynamics. The model is in fact a generalization to soft and hybrid systems of the geometric theory of rigid robotics characterized by the exponential map. A generalization of the recursive Newton-Euler algorithm is also presented, able to solve inverse and forward dynamic problems with linear O(N) complexity. The proposed model provides several improvements with respect to the existing flexible multi-body models, which make it particularly suitable to study the dynamics of modern soft robots as shown for a multi-body system inspired by motile bacteria.
ER  - 

TY  - CONF
TI  - Morphological Adaptation in an Energy Efficient Vibration-Based Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1575
EP  - 1582
AU  - S. Katiyar
AU  - G. Kandasamy
AU  - E. Kulatunga
AU  - M. Mustafizur
AU  - F. Iida
AU  - S. G. Nurzaman
PY  - 2018
KW  - beams (structures)
KW  - elasticity
KW  - energy conservation
KW  - legged locomotion
KW  - vibrations
KW  - adaptation ability
KW  - robot locomotion
KW  - morphological adaptation
KW  - energy efficient vibration-based robot
KW  - morphological computation
KW  - soft materials
KW  - elastic materials
KW  - low-cost robot
KW  - elastic curved beam
KW  - robots rich dynamics
KW  - robots shape
KW  - rotating frequency
KW  - Legged locomotion
KW  - DC motors
KW  - Springs
KW  - Resonant frequency
KW  - Foot
KW  - Shape
DO  - 10.1109/ICRA.2018.8461107
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Morphological computation is a concept relevant to robots made of soft and elastic materials. It states that robot's rich dynamics can be exploited to generate desirable behaviors, which can be altered when their morphology is adapted accordingly. This paper presents a low-cost robot made of elastic curved beam driven by a motor, with morphological computation and adaptation ability. Simply by changing robot's shape and the rotating frequency of the motor that vibrates the robot's body, the robot is able to shift its behavior from showing a tendency to slide when it needs to perform tasks like going under confined space, to have more tendency to hop diagonally forward when the robot stands upright. It will also be shown that based on the proposed mechanism, the energy efficiency of the robot locomotion can be maximized.
ER  - 

TY  - CONF
TI  - Bio-Inspired Octopus Robot Based on Novel Soft Fluidic Actuator
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1583
EP  - 1588
AU  - J. Fras
AU  - Y. Noh
AU  - M. Macias
AU  - H. Wurdemann
AU  - K. Althoefer
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - biomimetics
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - pneumatic actuators
KW  - robot dynamics
KW  - bio-inspired octopus robot
KW  - novel soft fluidic actuator
KW  - modern roboticists
KW  - novel robotic structures
KW  - soft robots
KW  - complex motion patterns
KW  - octopus tentacles
KW  - bio-mimetic approach
KW  - soft material
KW  - Actuators
KW  - Manipulators
KW  - Force
KW  - Robot sensing systems
KW  - Soft robotics
KW  - Fabrication
DO  - 10.1109/ICRA.2018.8460629
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Many modern roboticists take inspiration from biology to create novel robotic structures, including those that are modeled after the octopus. This paper advances this trend by creating soft robots modeling the complex motion patterns of octopus tentacles employing a bio-mimetic approach. The proposed octopus robot is entirely made from soft material and uses a novel fluidic actuation mechanism that allows the robot to advance forward, change directions and rotate around its primary axis. The paper presents the robot's design and fabrication process. An experimental study is conducted showing the feasibility of the proposed robot and actuation mechanism.
ER  - 

TY  - CONF
TI  - Completion Time Analysis for Automated Manufacturing Systems with Parallel Processing Modules
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1589
EP  - 1594
AU  - H. Kim
AU  - J. Lee
PY  - 2018
KW  - cluster tools
KW  - etching
KW  - hoists
KW  - industrial robots
KW  - lithography
KW  - lot sizing
KW  - manufacturing systems
KW  - materials testing
KW  - parallel processing
KW  - scheduling
KW  - semiconductor device manufacture
KW  - semiconductor industry
KW  - storage
KW  - semiconductor manufacturing processes
KW  - lithography
KW  - etching
KW  - materials testing
KW  - scheduling
KW  - lot finish processing
KW  - stockers
KW  - overhead hoist transports
KW  - wafer lots
KW  - transport robot
KW  - dual-armed cluster tool
KW  - parallel processing modules
KW  - automated manufacturing systems
KW  - completion time analysis
KW  - Tools
KW  - Robots
KW  - Task analysis
KW  - Switches
KW  - Optimal scheduling
KW  - Job shop scheduling
KW  - Time factors
DO  - 10.1109/ICRA.2018.8460980
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper analyzes the completion time of automated manufacturing systems, especially a dual-armed cluster tool, equipped with parallel processing modules (PMs). Cluster tools, which consist of multiple PMs, a transport robot, and loadlocks where wafer lots are loaded and unloaded, perform semiconductor manufacturing processes, such as lithography, etching, deposition, and testing. Wafer lots are transported by overhead hoist transports (OHTs) between tools or stockers where wafer lots are stored. To reduce the idle time of OHTs or cluster tools, it is essential to estimate the time when all wafers of a lot finish processing in a tool. Hence, we derive closed-form expressions for the completion time of wafer lots, especially in dual-armed cluster tools with parallel PMs to reflect real circumstances of fabs. We finally show that the formulas derived can be used even when there are small processing time variations with numerical experiments.
ER  - 

TY  - CONF
TI  - Reliably Arranging Objects in Uncertain Domains
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1603
EP  - 1610
AU  - A. S. Anders
AU  - L. P. Kaelbling
AU  - T. Lozano-Perez
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - control uncertainty
KW  - conformant planning approach
KW  - robot manipulation
KW  - multiple planar objects
KW  - specified arrangement
KW  - external sensing
KW  - belief-state planning problem
KW  - initial belief state
KW  - forward belief-state planning
KW  - deterministic belief-state transition model
KW  - off-line physics simulations
KW  - on-line physics-based manipulation approach
KW  - physical robot experiments
KW  - uncertain domains
KW  - Planning
KW  - Robot sensing systems
KW  - Task analysis
KW  - Reliability
KW  - Computational modeling
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8462892
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A crucial challenge in robotics is achieving reliable results in spite of sensing and control uncertainty. In this work, we explore the conformant planning approach to robot manipulation. In particular, we tackle the problem of pushing multiple planar objects simultaneously to achieve a specified arrangement without external sensing. Conformant planning is a belief-state planning problem. A belief state is the set of all possible states of the world, and the goal is to find a sequence of actions that will bring an initial belief state to a goal belief state. To do forward belief-state planning, we created a deterministic belief-state transition model from supervised learning based on off-line physics simulations. We compare our method with an on-line physics-based manipulation approach and show significantly reduced planning times and increased robustness in simulated experiments. Finally, we demonstrate the success of this approach in simulations and physical robot experiments.
ER  - 

TY  - CONF
TI  - RoboTSP – A Fast Solution to the Robotic Task Sequencing Problem
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1611
EP  - 1616
AU  - F. Suárez-Ruiz
AU  - T. S. Lembono
AU  - Q. Pham
PY  - 2018
KW  - industrial robots
KW  - travelling salesman problems
KW  - Robotic Task Sequencing Problem
KW  - industrial robotics applications
KW  - spray-painting
KW  - robot travel time
KW  - execution time
KW  - robot configurations
KW  - task space
KW  - configuration space
KW  - RTSP literature
KW  - Generalized Traveling Salesman Problem
KW  - Task analysis
KW  - Measurement
KW  - Collision avoidance
KW  - Service robots
KW  - Planning
KW  - Space exploration
DO  - 10.1109/ICRA.2018.8460581
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In many industrial robotics applications, such as spot-welding, spray-painting or drilling, the robot is required to visit successively multiple targets. The robot travel time among the targets is a significant component of the overall execution time. This travel time is in turn greatly affected by the order of visit of the targets, and by the robot configurations used to reach each target. Therefore, it is crucial to optimize these two elements, a problem known in the literature as the Robotic Task Sequencing Problem (RTSP). Our contribution in this paper is two-fold. First, we propose a fast, near-optimal, algorithm to solve RTSP. The key to our approach is to exploit the classical distinction between task space and configuration space, which, surprisingly, has been so far overlooked in the RTSP literature. Second, we provide an open-source implementation of the above algorithm, which has been carefully benchmarked to yield an efficient, ready-to-use, software solution. We discuss the relationship between RTSP and other Traveling Salesman Problem (TSP) variants, such as the Generalized Traveling Salesman Problem (GTSP), and show experimentally that our method finds motion sequences of the same quality but using several orders of magnitude less computation time than existing approaches.
ER  - 

TY  - CONF
TI  - An Automated Reactive Approach to Single Robot Exogeneous Planar Assembly
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1617
EP  - 1622
AU  - H. I. Bozma
AU  - F. Öztüirk
PY  - 2018
KW  - collision avoidance
KW  - motion control
KW  - robotic assembly
KW  - unactuated disk-shaped parts
KW  - automated reactive approach
KW  - single robot exogeneous planar assembly
KW  - assembly task
KW  - Conferences
KW  - Automation
KW  - Australia
DO  - 10.1109/ICRA.2018.8460665
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we are concerned with the automation of single robot exogeneous assembly in simple planar settings. Here, a set of of unactuated disk-shaped parts needs to be serviced by a single robot that resides outside the workspace and is capable of moving the parts one at a time through sliding or lifting slightly. The task is to have the parts end up in their respective goal positions without any collisions whilst moving. We present an automated reactive approach through the composition of one-part movements. The movement of each part is achieved by a controller obtained through the projection of a carefully constructed vector field on the respective configuration subspace. Such a scheme is known to accommodate positional variations naturally. Once the movement terminates, the robot chooses the next part to move in a cyclic manner. The contribution of this paper is to show for the first time that with certain restrictions on the allowed goal configurations, the assembly task is either successfully completed or terminated (rather than useless cycling of a part or from part to part) while the generated sequence of motions never causes collisions among the parts.
ER  - 

TY  - CONF
TI  - Robotic Cleaning Through Dirt Rearrangement Planning with Learned Transition Models
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1623
EP  - 1630
AU  - S. Elliott
AU  - M. Cakmak
PY  - 2018
KW  - cleaning
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - sampling methods
KW  - service robots
KW  - PR2 robots
KW  - Fetch robots
KW  - primitive dirt-oriented tool actions
KW  - heuristic search
KW  - cleaning tool
KW  - arbitrary amounts
KW  - manipulator
KW  - learned transition models
KW  - dirt rearrangement planning
KW  - robotic cleaning
KW  - Tools
KW  - Planning
KW  - Surface cleaning
KW  - Manipulators
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460915
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We address the problem of enabling a manipulator to move arbitrary amounts and configurations of dirt on a surface to a goal region using a cleaning tool. We represent this problem as heuristic search with a set of primitive dirt-oriented tool actions. We present dirt and action representations that allow efficient learning and prediction of future dirt states, given the current dirt state and applied action. We also present a method for sampling promising actions based on a clustering of dirt states and heuristics for planning. We demonstrate the effectiveness of our approach on challenging cleaning tasks through implementations on PR2 and Fetch robots.
ER  - 

TY  - CONF
TI  - Fast Planning for 3D Any-Pose-Reorienting Using Pivoting
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1631
EP  - 1638
AU  - Y. Hou
AU  - Z. Jia
AU  - M. T. Mason
PY  - 2018
KW  - dexterous manipulators
KW  - geometry
KW  - grippers
KW  - mesh generation
KW  - solid modelling
KW  - fast planning
KW  - two-finger pinch gripper
KW  - 3D mesh model
KW  - gripper motions
KW  - arbitrary object
KW  - grasping positions
KW  - gripper poses
KW  - motion primitives
KW  - compliant rolling
KW  - planning problem
KW  - object shapes
KW  - nontrivial geometry
KW  - gripper workspace
KW  - 3D Any-pose-reorienting
KW  - mesh models approximation
KW  - pivoting
KW  - Grippers
KW  - Planning
KW  - Gravity
KW  - Robots
KW  - Three-dimensional displays
KW  - Friction
DO  - 10.1109/ICRA.2018.8462834
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we consider reorienting 3D objects on a table using a two-finger pinch gripper. Given the 3D mesh model of the object, our algorithm solves for the gripper motions that are required to transit between arbitrary object poses, grasping positions and gripper poses. The two motion primitives we used, pivoting and compliant rolling, enable us to decompose the planning problem and solve it more efficiently. Our algorithm can work with approximated (simplified) mesh models while being robust to approximation errors, thereby allowing us to efficiently handle object shapes with originally thousands of facets. We show the effectiveness of the proposed method by testing on objects with non-trivial geometry in both simulations and experiments. Results show that our algorithm can solve a larger range of reorienting problems with less number of making and breaking contacts when compared to traditional pick-and-place based methods, especially when the gripper workspace is highly constrained.
ER  - 

TY  - CONF
TI  - An Intelligent Control Scheme to Facilitate Abrupt Stopping on Self-Adjustable Treadmills
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1639
EP  - 1644
AU  - H. J. Asl
AU  - S. Pyo
AU  - J. Yoon
PY  - 2018
KW  - acceleration control
KW  - closed loop systems
KW  - control system synthesis
KW  - feedback
KW  - gait analysis
KW  - intelligent control
KW  - observers
KW  - patient rehabilitation
KW  - position control
KW  - uncertain systems
KW  - velocity control
KW  - AF
KW  - oscillation-free response
KW  - supervisory control scheme
KW  - RISE controller
KW  - positive-output controller
KW  - stopping stage
KW  - position error
KW  - supervisory system
KW  - intelligent control scheme
KW  - self-adjustable treadmills
KW  - reference position
KW  - oscillatory response
KW  - closed-loop system
KW  - high-gain observer
KW  - user velocity
KW  - acceleration estimation
KW  - intentional velocity estimation
KW  - abrupt stopping
KW  - patient rehabilitation
KW  - Observers
KW  - Acceleration
KW  - Force
KW  - Convergence
KW  - Feedforward systems
KW  - Closed loop systems
KW  - Self-adjustable treadmill
KW  - observer
KW  - RISE controller
DO  - 10.1109/ICRA.2018.8462897
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The control problem in self-adjustable treadmills is to keep the position of the user at a reference position. The position error is the key obstacle in facilitating the abrupt stopping on self-adjustable treadmills. Another difficulty in this application is the oscillatory response of the closed-loop system. The conventional control methods utilize a high-gain observer to estimate the user velocity and exploit this information beside feedback signals to decrease the position error. Utilizing the high-gain observer, however, applies anomalous force (AF) to the user, leading to an unnatural feeling, and does not guarantee an oscillation-free response for the output. This paper aims to alleviate these problems by proposing a supervisory control scheme. First, a RISE controller is utilized for walking/running stage to compensate for slowly varying uncertainties in the system model without applying a large AF. Then, a positive-output controller is exploited for the stopping stage to guarantee the convergence of the position error without oscillation. Using the estimated intentional velocity and acceleration, a supervisory system is designed to switch between the controllers. Experimental results show the superiority of the proposed approach over the existing methods.
ER  - 

TY  - CONF
TI  - Modeling and Control of Brachiating Robots Traversing Flexible Cables
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1645
EP  - 1652
AU  - S. Farzan
AU  - A. Hu
AU  - E. Davies
AU  - J. Rogers
PY  - 2018
KW  - cables (mechanical)
KW  - legged locomotion
KW  - manipulator dynamics
KW  - motion control
KW  - optimal control
KW  - torque control
KW  - trajectory control
KW  - vibration control
KW  - brachiating robots
KW  - coupling soft junctions
KW  - multiple-shooting
KW  - parametric trajectory approaches
KW  - catenary cable
KW  - energy-efficient continuous brachiation
KW  - optimal torque profiles
KW  - control torque profiles
KW  - optimized trajectories
KW  - robot locomotion
KW  - cable vibration
KW  - energy-minimizing optimal control strategy
KW  - two-link robot
KW  - multibody system
KW  - flexible cable
KW  - two-link underactuated brachiating robot
KW  - locomotion control
KW  - dynamic modeling
KW  - Junctions
KW  - Mathematical model
KW  - Grippers
KW  - Legged locomotion
KW  - Trajectory
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8461036
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes the dynamic modeling and locomotion control of a two-link underactuated brachiating robot traversing a flexible cable. A multi-body system comprised of a two-link robot, a flexible cable, and coupling soft junctions is modeled dynamically. This model is used to formulate an energy-minimizing optimal control strategy that includes the effects of cable vibration induced by robot locomotion. Optimized trajectories and control torque profiles are obtained via multiple-shooting and parametric trajectory approaches. Simulation results show that these optimal torque profiles result in energy-efficient continuous brachiation over a flexible cable. Additional studies examine how the optimal torque profiles change depending on the robot's initial position along a catenary cable.
ER  - 

TY  - CONF
TI  - Performance Indicator for Benchmarking Force-Controlled Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1653
EP  - 1660
AU  - R. Behrens
AU  - A. Belov
AU  - M. Poggendorf
AU  - F. Penzlin
AU  - M. Hanses
AU  - E. Jantz
AU  - N. Elkmann
PY  - 2018
KW  - force control
KW  - force feedback
KW  - mobile robots
KW  - position control
KW  - robotic assembly
KW  - performance indicator
KW  - force control
KW  - impedance control
KW  - robot-based sensitive assembly
KW  - robotics
KW  - force feedback information
KW  - direct force control
KW  - force-controlled robot benchmarking
KW  - Force
KW  - Robot sensing systems
KW  - Service robots
KW  - Task analysis
KW  - Tools
KW  - Benchmark testing
DO  - 10.1109/ICRA.2018.8460858
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robot-based sensitive assembly is a recent and growing trend in robotics. Force-controlled robots are expected to interact with an unknown environment using solely force feedback information. In general, the exact contact is difficult to predict due to various impact factors, such as the dynamics of the interaction, work-piece stiffness and geometry, the robot's configuration, and the efficiency of the control algorithm. Currently, there is no general indicator for evaluating the performance of a force-controlled robot. This work presents a concept of such a performance indicator. In order to test the proposed concept for comparison, an experimental setup is presented that simulates a contour-following task under force control. This setup is used to test two robots with different force-controllers and control principles, namely direct force and impedance control. The results indicate good applicability of the proposed performance indicator to benchmark force-controlled robots, and this is extensively discussed.
ER  - 

TY  - CONF
TI  - A Failure-Tolerant Approach to Synchronous Formation Control of Mobile Robots Under Communication Delays
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1661
EP  - 1666
AU  - Z. Liu
AU  - H. Wang
AU  - L. Xu
AU  - Y. Liu
AU  - J. Lu
AU  - W. Chen
PY  - 2018
KW  - delays
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - switching systems (control)
KW  - topology
KW  - failure-tolerant approach
KW  - mobile robots
KW  - communication delays
KW  - robot malfunction
KW  - robot formation control
KW  - system malfunction
KW  - synchronous formation control problem
KW  - network connectivity
KW  - motion synchronism
KW  - robot replacements
KW  - synchronous formation control method
KW  - recursive switched topology control strategy
KW  - neighboring robots
KW  - Topology
KW  - Switches
KW  - Robot kinematics
KW  - Network topology
KW  - Synchronization
DO  - 10.1109/ICRA.2018.8460660
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robot malfunction is inevitable in practical applications of the robot formation control due to uncontrolled crashing, system malfunction or communication loss. In this paper, we study the synchronous formation control problem in the presence of robot malfunctions. Our main idea is to improve the network connectivity and motion synchronism of the robot formation through a series of topology switchings and robot replacements. Firstly, the synchronous formation control method is introduced which enables the robots to tracking their desired trajectories while keeping predefined formation shapes. Secondly, a recursive switched topology control strategy is proposed to restore the formation shape as well as to improve the network connectivity and motion synchronism in the presence of robot malfunctions. Thirdly, the convergence analysis of the proposed control system is presented and a sufficient condition is obtained under an average dwell time scheme. What's more, the proposed approach is fully distributed and the communication delays between neighboring robots also have been taken into consideration. Simulation results demonstrate the effectiveness of the proposed approach.
ER  - 

TY  - CONF
TI  - Perceived Stiffness Estimation for Robot Force Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1667
EP  - 1672
AU  - L. Santos
AU  - R. Cortesão
PY  - 2018
KW  - adaptive control
KW  - force control
KW  - manipulators
KW  - position control
KW  - environment stiffness
KW  - perceived stiffness estimation
KW  - positive force feedback loop
KW  - contact dynamics
KW  - force measurements
KW  - force signals
KW  - low pass filters
KW  - environment dynamics
KW  - force control performance
KW  - force control perspective
KW  - robot effective mass
KW  - force based stiffness estimation strategy
KW  - control gains
KW  - control optimization parameter
KW  - force control
KW  - robot dynamics
KW  - Robots
KW  - Force
KW  - Estimation
KW  - Dynamics
KW  - Force control
KW  - Effective mass
KW  - Adaptation models
DO  - 10.1109/ICRA.2018.8460925
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Typical robot force control architectures have a positive force feedback loop to decouple robot dynamics from contact dynamics. Due to the noisy profile of force measurements, it is common to filter force signals by low pass filters. This paper shows that, when force feedback is filtered, robot and environment dynamics are no longer decoupled, affecting force control performance. Additionally, the perceived stiffness from the force control perspective, is correlated with the robot effective mass. To cope with this issue, a force based stiffness estimation strategy that also includes the inertial properties (effective mass) in the estimation algorithm is proposed, allowing to adapt control gains based on the robot effective mass. In this way, the perceived stiffness can be seen as a control optimization parameter, rather than a well defined physical property. Simulation and experimental results with a 1-DoF robot and 7-DoF manipulator, respectively, validate the estimation strategy, showing better force control results with the perceived stiffness in the control loop, as compared to the real environment stiffness.
ER  - 

TY  - CONF
TI  - Grasp a Moving Target from the Air: System & Control of an Aerial Manipulator
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1681
EP  - 1687
AU  - G. Zhang
AU  - Y. He
AU  - B. Dai
AU  - F. Gu
AU  - L. Yang
AU  - J. Han
AU  - G. Liu
AU  - J. Qi
PY  - 2018
KW  - autonomous aerial vehicles
KW  - force control
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - rotors
KW  - visual servoing
KW  - CoM offset motion
KW  - center of mass
KW  - aerial grasping experiments
KW  - aerial vehicle
KW  - aerial manipulator control system
KW  - independent control structure
KW  - hex-rotor
KW  - fixed-base manipulator
KW  - Manipulator dynamics
KW  - Grasping
KW  - Control systems
KW  - Kinematics
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2018.8461103
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Grasping a moving target has been investigated extensively for fixed-base manipulator. However, such a task becomes much more challenging when the manipulator is free flying in the air with an UAV. Towards moving target grasping, this paper presents an aerial manipulator system composed of a hex-rotor and a 7-DoF (Degree of Freedom) manipulator. An independent control structure is used in the aerial manipulator control system, i.e., the hex-rotor and the manipulator are controlled separately. In the hex-rotor's controller, the system CoM (Center of Mass) offset motion is used to compensate disturbance of the robotic arm. In the manipulator's controller, the relative kinematics between the target and the aerial vehicle is taken into consideration to grasp the target. At last aerial grasping experiments are conducted to validate the feasibility of the proposed control scheme and the reliability of our aerial manipulator system.
ER  - 

TY  - CONF
TI  - Task Space Motion Planning Decomposition
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1688
EP  - 1694
AU  - N. Larkin
AU  - A. Short
AU  - Z. Pan
AU  - S. Van Duin
PY  - 2018
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - autonomous robotics
KW  - T-Space parameters
KW  - maze navigation
KW  - path planning
KW  - motion planning
KW  - Task Space Motion Planning Decomposition
KW  - TSMPD
KW  - manipulator
KW  - Planning
KW  - Task analysis
KW  - Manipulators
KW  - Manifolds
KW  - Kinematics
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8460903
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In autonomous robotics there are many situations that require solving a motion planning problem to complete a task. A Task Space (T-Space), composed of parameters that define the task being performed, can be a more effective planning space for these problems, however, planning within a T-Space is often computationally challenging. In this paper, we present a novel method to analyse the relationship between T-Space parameters and the pose of manipulator bodies to create a dependency matrix. We then use this information to decompose the motion planning problem into sequential lower complexity sub-problems. We call this approach Task Space Motion Planning Decomposition (TSMPD). This paper introduces TSMPD and quantifies the improvement to planning efficiency on a challenging maze navigation problem and weld path planning problem.
ER  - 

TY  - CONF
TI  - Planning Hybrid Driving-Stepping Locomotion on Multiple Levels of Abstraction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1695
EP  - 1702
AU  - T. Klamt
AU  - S. Behnke
PY  - 2018
KW  - legged locomotion
KW  - path planning
KW  - navigating
KW  - rescue environments
KW  - locomotion methods
KW  - navigation planning method
KW  - hybrid driving-stepping locomotion planning
KW  - Momaro robot
KW  - robot state dimensionality
KW  - Planning
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Semantics
KW  - Motion segmentation
DO  - 10.1109/ICRA.2018.8461054
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Navigating in search and rescue environments is challenging, since a variety of terrains has to be considered. Hybrid driving-stepping locomotion, as provided by our robot Momaro, is a promising approach. Similar to other locomotion methods, it incorporates many degrees of freedom - offering high flexibility but making planning computationally expensive for larger environments. We propose a navigation planning method, which unifies different levels of representation in a single planner. In the vicinity of the robot, it provides plans with a fine resolution and a high robot state dimensionality. With increasing distance from the robot, plans become coarser and the robot state dimensionality decreases. We compensate this loss of information by enriching coarser representations with additional semantics. Experiments show that the proposed planner provides plans for large, challenging scenarios in feasible time.
ER  - 

TY  - CONF
TI  - Design and Evaluation of Skating Motions for a Dexterous Quadruped
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1703
EP  - 1709
AU  - G. Bellegarda
AU  - K. van Teeffelen
AU  - K. Byl
PY  - 2018
KW  - control system synthesis
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - robot dynamics
KW  - wheels
KW  - Dexterous Quadruped
KW  - contact force distribution
KW  - wheel slip
KW  - three-wheeled skating maneuvers
KW  - omnidirectional motion primitives
KW  - dexterous limbs
KW  - quadruped robot
KW  - skating motions
KW  - locomotion
KW  - continuous ground contact
KW  - Wheels
KW  - Mobile robots
KW  - Planning
KW  - Force
KW  - Trajectory
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8460600
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes skating locomotion for a quadruped robot with dexterous limbs. The emphasis is on design of omnidirectional motion primitives and quantification of resulting speed and accuracy when traversing different types of smooth but potentially non-flat terrain. In particular, we study trade-offs between using four-wheeled versus three-wheeled skating maneuvers. In four-wheeled skating, motions have the benefit of symmetry, so that errors due to wheel slip should theoretically cancel out on average. Three-wheeled skating, by contrast, introduces significantly more asymmetry in configuration and contact force distribution over time; however, it has the advantage of guaranteeing continuous ground contact for all skates when terrain has bumps or other curvature. We present simulation results quantifying errors for each approach, for various terrains. Our results allow us to tune motions to reduce biases and variability in motion, which are primarily due to accelerations as locomotion begins.
ER  - 

TY  - CONF
TI  - Gradient-Informed Path Smoothing for Wheeled Mobile Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1710
EP  - 1717
AU  - E. Heiden
AU  - L. Palmieri
AU  - S. Koenig
AU  - K. O. Arras
AU  - G. S. Sukhatme
PY  - 2018
KW  - gradient methods
KW  - mobile robots
KW  - motion control
KW  - optimal control
KW  - optimisation
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - smoothing methods
KW  - trajectory control
KW  - wheels
KW  - wheeled mobile robots
KW  - crowded environments
KW  - optimal sampling-based motion planners
KW  - nonoptimal motion planners
KW  - post-smoothing step
KW  - gradient-informed post-smoothing algorithm
KW  - gradient-informed path smoothing
KW  - smooth trajectories planning
KW  - GRIPS
KW  - kinodynamic constraints
KW  - Trajectory
KW  - Smoothing methods
KW  - Shape
KW  - Mobile robots
KW  - Interpolation
KW  - Strain
DO  - 10.1109/ICRA.2018.8460818
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Planning smooth trajectories is important for the safe, efficient and comfortable operation of mobile robots, such as wheeled robots moving in crowded environments or cars moving at high speed. Asymptotically optimal sampling-based motion planners can be used to generate such trajectories. However, to achieve the necessary efficiency for the realtime operation of robots, one often uses their initial feasible trajectories or the trajectories of non-optimal motion planners instead, typically after a post-smoothing step. We propose a gradient-informed post-smoothing algorithm, called GRIPS, that deforms given trajectories by locally optimizing the placement of vertices while satisfying the system's kinodynamic constraints. We show experimentally that GRIPS typically produces trajectories of significantly smaller length and higher smoothness than several existing post-smoothing algorithms.
ER  - 

TY  - CONF
TI  - Indoor Coverage Path Planning: Survey, Implementation, Analysis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1718
EP  - 1725
AU  - R. Bormann
AU  - F. Jordan
AU  - J. Hampp
AU  - M. Hägele
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - service robots
KW  - trajectory control
KW  - indoor coverage path planning
KW  - robot trajectories
KW  - mobile cleaning robots
KW  - lawn mowing robots
KW  - harvesting machines
KW  - Path planning
KW  - Cleaning
KW  - Robot sensing systems
KW  - Planning
KW  - Traveling salesman problems
DO  - 10.1109/ICRA.2018.8460566
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Coverage Path Planning (CPP) describes the process of generating robot trajectories that fully cover an area or volume. Applications are, amongst many others, mobile cleaning robots, lawn mowing robots or harvesting machines in agriculture. Many approaches and facets of this problem have been discussed in literature but despite the availability of several surveys on the topic there is little work on quantitative assessment and comparison of different coverage path planning algorithms. This paper analyzes six popular off-line coverage path planning methods, applicable to previously recorded maps, in the setting of indoor coverage path planning on room-sized units. The implemented algorithms are thoroughly compared on a large dataset of over 550 rooms with and without furniture.
ER  - 

TY  - CONF
TI  - Robot Navigation in Complex Workspaces Using Harmonic Maps
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1726
EP  - 1731
AU  - P. Vlantis
AU  - C. Vrohidis
AU  - C. P. Bechlioulis
AU  - K. J. Kyriakopoulos
PY  - 2018
KW  - geometry
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - complex workspaces
KW  - harmonic maps
KW  - Artificial Potential Fields
KW  - autonomous robot navigation control schemes
KW  - local minima
KW  - APF based control scheme
KW  - goal configuration
KW  - multiply connected compact 2D workspaces
KW  - Harmonic analysis
KW  - Navigation
KW  - Robot kinematics
KW  - Convergence
KW  - Tuning
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460695
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Artificial Potential Fields (APFs) constitute an intuitive tool for designing autonomous robot navigation control schemes, though they generally suffer from the existence of local minima which may trap the robot away from its desired configuration, an issue usually addressed by appropriate offline “tuning” of the potential field's parameters. On the other side, most APF based approaches rely on a diffeomorphism to sphere worlds to handle realistic scenarios, which may be either costly to compute (e.g., conformal mappings) or requires some sort of preconditioning of the workspace (e.g., decomposition of complex geometries to simple elementary components). In this work, we first propose a constructive procedure to map multiply connected compact 2D workspaces to one or more punctured disks based on harmonic maps. Subsequently, we design an APF based control scheme along with an adaptive law for its parameters that requires no offline tuning to guarantee safe convergence to its goal configuration. Finally, an extensive simulation study is conducted to demonstrate the efficacy of the proposed control scheme.
ER  - 

TY  - CONF
TI  - Backprop-MPDM: Faster Risk-Aware Policy Evaluation Through Efficient Gradient Optimization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1740
EP  - 1746
AU  - D. Mehta
AU  - G. Ferrer
AU  - E. Olson
PY  - 2018
KW  - decision making
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - optimisation
KW  - stochastic processes
KW  - multipolicy decision-making
KW  - gradient optimization
KW  - risk-aware policy evaluation
KW  - backprop-MPDM policy
KW  - robot platform
KW  - easily-differentiable heuristic function
KW  - random sampling
KW  - stochastic gradient optimization algorithms
KW  - decision making process
KW  - risk-aware formulations
KW  - Robots
KW  - Computational modeling
KW  - Trajectory
KW  - Navigation
KW  - Decision making
KW  - Cost function
DO  - 10.1109/ICRA.2018.8462903
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In Multi-Policy Decision-Making (MPDM), many computationally-expensive forward simulations are performed in order to predict the performance of a set of candidate policies. In risk-aware formulations of MPDM, only the worst outcomes affect the decision making process, and efficiently finding these influential outcomes becomes the core challenge. Recently, stochastic gradient optimization algorithms, using a heuristic function, were shown to be significantly superior to random sampling. In this paper, we show that accurate gradients can be computed - even through a complex forward simulation - using approaches similar to those in deep networks. We show that our proposed approach finds influential outcomes more reliably, and is faster than earlier methods, allowing us to evaluate more policies while simultaneously eliminating the need to design an easily-differentiable heuristic function. We demonstrate significant performance improvements in simulation as well as on a real robot platform navigating a highly dynamic environment.
ER  - 

TY  - CONF
TI  - Spherical Foot Placement Estimator for Humanoid Balance Control and Recovery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1747
EP  - 1754
AU  - B. J. DeHart
AU  - R. Gorbet
AU  - D. Kulić
PY  - 2018
KW  - feedback
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - optimal control
KW  - robot dynamics
KW  - stepping
KW  - SFPE-based feedback
KW  - SFPE point
KW  - control reference
KW  - balance criteria
KW  - recovery step location prediction
KW  - momentum objectives
KW  - Spherical Foot Placement Estimator
KW  - bipedal gait
KW  - unknown disturbances
KW  - momentum-based leaning
KW  - smooth dynamics
KW  - Three-dimensional displays
KW  - Foot
KW  - Integrated circuit modeling
KW  - Mathematical model
KW  - Legged locomotion
KW  - Solid modeling
KW  - Iterative closest point algorithm
DO  - 10.1109/ICRA.2018.8460718
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the main challenges of bipedal gait is to avoid falling due to unknown disturbances. Compensating for these disturbances in bipeds is often achieved by leaning or stepping. In this work, the Spherical Foot Placement Estimator (SFPE) is introduced, which uses the biped's current kinematics and dynamics to predict if a step is needed, and if so where to step, to restore balance in 3D. An example of a controller using the SFPE is shown, which augments an existing optimal controller with both leaning and stepping: SFPE-based feedback is used to generate a desired momentum for momentum-based leaning while the SFPE point is used as a control reference for stepping. The new estimator outperforms existing balance criteria by providing both recovery step location prediction and momentum objectives with smooth dynamics.
ER  - 

TY  - CONF
TI  - Simultaneous Optimization of ZMP and Footsteps Based on the Analytical Solution of Divergent Component of Motion
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1763
EP  - 1770
AU  - T. Kamioka
AU  - H. Kaneko
AU  - T. Takenaka
AU  - T. Yoshiike
PY  - 2018
KW  - legged locomotion
KW  - linear systems
KW  - motion control
KW  - nonlinear control systems
KW  - path planning
KW  - pendulums
KW  - quadratic programming
KW  - DCM
KW  - ZMP
KW  - foot placements
KW  - bipedal research
KW  - quadratic programming problem
KW  - optimization
KW  - divergent component of motion
KW  - Real-time planning
KW  - linear inverted pendulum
KW  - zero moment point
KW  - push recovery experiment
KW  - disturbance compensation
KW  - Planning
KW  - Lips
KW  - Trajectory
KW  - Foot
KW  - Real-time systems
KW  - Optimization
KW  - Laplace equations
DO  - 10.1109/ICRA.2018.8460572
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Real-time planning of footsteps has been a big challenge for bipedal research. A large number of methods have been proposed over the last several years. In addition, divergent component of motion (DCM) of linear inverted pendulum (LIP) has been applied to solve this problem thus attracting a great deal of attention. In this paper, we derive an analytical solution of DCM for an arbitrary input function and propose a novel quadratic programming (QP) problem for the simultaneous optimization of zero moment point (ZMP) and foot placements based on the analytical solution. To validate the method, we conducted a push recovery experiment on real hardware. The result of the experiment shows that our new algorithm realizes a hierarchical strategy for disturbance compensation.
ER  - 

TY  - CONF
TI  - Bayesian Optimization Using Domain Knowledge on the ATRIAS Biped
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1771
EP  - 1778
AU  - A. Rai
AU  - R. Antonova
AU  - S. Song
AU  - W. Martin
AU  - H. Geyer
AU  - C. Atkeson
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - gait analysis
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - Bayesian optimization
KW  - 1-dimensional space
KW  - feature transformation
KW  - different walking controllers
KW  - ATRIAS bipedal robot
KW  - nonhumanoid robot morphologies
KW  - human-inspired neuromuscular controller
KW  - human walking
KW  - 16-dimensional locomotion controller
KW  - bipedal locomotion
KW  - black-box data-efficient optimization scheme
KW  - data-efficient learning techniques
KW  - legged locomotion
KW  - simulation transfer
KW  - expert-designed heuristics
KW  - robotics controllers
KW  - domain knowledge
KW  - Hardware
KW  - Legged locomotion
KW  - Optimization
KW  - Kernel
KW  - Transforms
KW  - Measurement
DO  - 10.1109/ICRA.2018.8461237
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotics controllers often consist of expert-designed heuristics, which can be hard to tune in higher dimensions. Simulation can aid in optimizing these controllers if parameters learned in simulation transfer to hardware. Unfortunately, this is often not the case in legged locomotion, necessitating learning directly on hardware. This motivates using data-efficient learning techniques like Bayesian Optimization (BO) to minimize collecting expensive data samples. BO is a black-box data-efficient optimization scheme, though its performance typically degrades in higher dimensions. We aim to overcome this problem by incorporating domain knowledge, with a focus on bipedal locomotion. In our previous work, we proposed a feature transformation that projected a 16-dimensional locomotion controller to a 1-dimensional space using knowledge of human walking. When optimizing a human-inspired neuromuscular controller in simulation, this feature transformation enhanced sample efficiency of BO over traditional BO with a Squared Exponential kernel. In this paper, we present a generalized feature transform applicable to non-humanoid robot morphologies and evaluate it on the ATRIAS bipedal robot, in both simulation and hardware. We present three different walking controllers and two are evaluated on the real robot. Our results show that this feature transform captures important aspects of walking and accelerates learning on hardware and simulation, as compared to traditional BO.
ER  - 

TY  - CONF
TI  - Balance Control Using Both ZMP and COM Height Variations: A Convex Boundedness Approach
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1779
EP  - 1784
AU  - S. Caron
AU  - B. Mallein
PY  - 2018
KW  - convex programming
KW  - humanoid robots
KW  - legged locomotion
KW  - mechanical stability
KW  - mechanical variables control
KW  - convex boundedness approach
KW  - biped robots
KW  - CoM height variations
KW  - nonconvex direct transcriptions
KW  - centroidal dynamics
KW  - boundedness condition
KW  - balance control
KW  - ZMP
KW  - sagittal plane
KW  - CoM trajectories
KW  - Trajectory
KW  - Mathematical model
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Robots
KW  - Radio frequency
KW  - Differential equations
DO  - 10.1109/ICRA.2018.8460942
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Developments for 3D control of the center of mass (CoM) of biped robots are currently located in two local minima: on the one hand, methods that allow CoM height variations but only work in the 2D sagittal plane; on the other hand, nonconvex direct transcriptions of centroidal dynamics that are delicate to handle. This paper presents an alternative that controls the CoM in 3D via an indirect transcription that is both low-dimensional and solvable fast enough for real-time control. The key to this development is the notion of boundedness condition, which quantifies the capturability of 3D CoM trajectories.
ER  - 

TY  - CONF
TI  - An MPC Walking Framework with External Contact Forces
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1785
EP  - 1790
AU  - S. Mason
AU  - N. Rotella
AU  - S. Schaal
AU  - L. Righetti
PY  - 2018
KW  - compensation
KW  - integer programming
KW  - legged locomotion
KW  - linear systems
KW  - predictive control
KW  - quadratic programming
KW  - hand contact
KW  - MPC walking framework
KW  - external contact forces
KW  - two-step optimization problem
KW  - Zero Moment Point
KW  - ZMP tracking error
KW  - friction cone
KW  - walking control scheme
KW  - linear model predictive control scheme
KW  - multiple contact locations
KW  - center of mass trajectory
KW  - mixed integer quadratic program
KW  - frequency 100.0 Hz to 300.0 Hz
KW  - Optimization
KW  - Force
KW  - Legged locomotion
KW  - Trajectory
KW  - Friction
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8461236
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we present an extension to a linear Model Predictive Control (MPC) scheme that plans external contact forces for the robot when given multiple contact locations and their corresponding friction cone. To this end, we set up a two-step optimization problem. In the first optimization, we compute the Center of Mass (CoM) trajectory, foot step locations, and introduce slack variables to account for violating the imposed constraints on the Zero Moment Point (ZMP). We then use the slack variables to trigger the second optimization, in which we calculate the optimal external force that compensates for the ZMP tracking error. This optimization considers multiple contacts positions within the environment by formulating the problem as a Mixed Integer Quadratic Program (MIQP) that can be solved at a speed between 100-300 Hz. Once contact is created, the MIQP reduces to a single Quadratic Program (QP) that can be solved in real-time (<; 1kHz). Simulations show that the presented walking control scheme can withstand disturbances 2-3× larger with the additional force provided by a hand contact.
ER  - 

TY  - CONF
TI  - Inclusion of Angular Momentum During Planning for Capture Point Based Walking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1791
EP  - 1798
AU  - T. Seyde
AU  - A. Shrivastava
AU  - J. Englsberger
AU  - S. Bertrand
AU  - J. Pratt
AU  - R. J. Griffin
PY  - 2018
KW  - angular momentum
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - trajectory control
KW  - smooth trajectories
KW  - continuous trajectories
KW  - leg swing
KW  - nonnegligible angular momentum rate
KW  - reference trajectory generator
KW  - bipedal walking
KW  - centroidal angular momentum
KW  - planning stage
KW  - closed-form trajectory solutions
KW  - centroidal moment pivot
KW  - instantaneous capture point
KW  - CMP
KW  - ICP
KW  - center of mass
KW  - Legged locomotion
KW  - Trajectory
KW  - Iterative closest point algorithm
KW  - Planning
KW  - Dynamics
KW  - Lips
DO  - 10.1109/ICRA.2018.8461140
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When walking at high speeds, the swing legs of robots produce a non-negligible angular momentum rate. To accommodate this, we provide a reference trajectory generator for bipedal walking that incorporates predicted centroidal angular momentum at the planning stage. This can be done efficiently as the Centroidal Moment Pivot (CMP), Instantaneous Capture Point (ICP) and the center of mass (CoM) all have closed-form trajectory solutions due to their linear dynamics. This is then used to produce smooth, continuous trajectories. We furthermore provide a lightweight model to estimate angular momentum as induced during leg swing of the gait cycle. Our proposed trajectory generator is tested thoroughly in simulation and has been shown to successfully operate on the real hardware.
ER  - 

TY  - CONF
TI  - Subject-Independent Data Pooling in Classification of Gait Intent Using Mechanomyography on a Transtibial Amputee
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1806
EP  - 1811
AU  - A. P. H. Needham
AU  - F. P. Paszkiewicz
AU  - M. F. M. Alias
AU  - S. Wilson
AU  - A. A. Dehghani-Sanij
AU  - B. C. Khoo
AU  - R. Vaidyanathan
PY  - 2018
KW  - artificial limbs
KW  - electromyography
KW  - gait analysis
KW  - learning (artificial intelligence)
KW  - medical signal processing
KW  - neurophysiology
KW  - signal classification
KW  - support vector machines
KW  - support vector machine classifier
KW  - movement delay classification
KW  - controller response
KW  - training pool
KW  - subject specific classifiers
KW  - prosthetic legs
KW  - subject-specific amputee data sets
KW  - supervised training
KW  - real-time monitoring
KW  - EMG
KW  - neuromuscular interfaces
KW  - patient activities
KW  - inertial measurement units
KW  - prosthetic measurement units
KW  - gait mode
KW  - active lower limb prosthetics
KW  - transtibial amputee
KW  - mechanomyography
KW  - gait intent
KW  - subject-independent data pooling
KW  - prosthetic control
KW  - subject-specific training
KW  - MMG gait classifier
KW  - user-specific data
KW  - pooled training data
KW  - Electromyography
KW  - Training
KW  - Legged locomotion
KW  - Muscles
KW  - Sensors
KW  - Prosthetics
KW  - Support vector machines
DO  - 10.1109/ICRA.2018.8461246
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Active lower limb prosthetics rely on the detection of gait mode to direct controller response. The majority of systems require feedback from the prosthetic and/or inertial measurement units (IMUs). Reliance on movement delays classification, reducing the range of patient activities and terrain traversed. Neuromuscular interfaces using electromyography (EMG) enable real-time monitoring by registering user intent, however EMG has known robustness issues out-of-clinic that have impeded its translation. Furthermore, supervised training of gait classifiers can require large subject-specific amputee data sets which are difficult to obtain. Mechanomyography (MMG) has shown less dependence on environmental conditions than EMG yet has seen limited use in this realm. In this investigation we introduce an MMG gait classifier targeting improved control of prosthetic (robotic) legs. We compare the accuracy of subject specific classifiers to those trained using subject-independent pooling. Additionally, we quantify the effect of introducing a small amount of data from individual test subjects to the training pool. Experiments were performed on 12 participants and 5 gait modes. A support vector machine (SVM) classifier achieved 65% accuracy with subject-specific data, 92% with pooled training data, and 94% with pooled plus limited user-specific data. The results show the promise of MMG gait classifiers with increased robustness and reduced subject-specific training in prosthetic control.
ER  - 

TY  - CONF
TI  - Embroidered Electrodes for Control of Affordable Myoelectric Prostheses
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1812
EP  - 1817
AU  - S. Pitou
AU  - F. Wu
AU  - A. Shafti
AU  - B. Michael
AU  - R. Stopforth
AU  - M. Howard
PY  - 2018
KW  - biomechanics
KW  - biomedical electrodes
KW  - electromyography
KW  - gesture recognition
KW  - prosthetics
KW  - myoelectric control
KW  - low-cost sensory systems
KW  - accurate gesture recognition
KW  - gesture recognition method
KW  - surface electromyography experiments
KW  - low-cost prostheses
KW  - hand gesture recognition
KW  - textile electrodes
KW  - electrode reuse
KW  - disposable gel electrodes
KW  - surface-electromyographic measurements
KW  - pre-programmed control strategies
KW  - low-cost prosthesis actuation
KW  - developing countries
KW  - low-cost manufacturing
KW  - affordable myoelectric prostheses
KW  - Electrodes
KW  - Electromyography
KW  - Textiles
KW  - Prosthetics
KW  - Muscles
KW  - Gesture recognition
KW  - Wrist
DO  - 10.1109/ICRA.2018.8461066
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The low-cost manufacturing and maintenance of prostheses is of vital importance to their successful deployment in developing countries. Low-cost prosthesis actuation is generally achieved by combining pre-programmed control strategies, with surface-electromyographic measurements taken from the residual limb. In a standard setting, these signals are measured with disposable gel electrodes. However, this limit on electrode reuse requires that prosthesis users have a stable supply of electrodes. Alternatively, the textile electrodes sewn from conductive thread are studied in the context of hand gesture recognition to consider their future use with low-cost prostheses. In this paper, it is demonstrated that textile electrodes can be applied for gesture recognition. To do so, surface electromyography (sEMG) experiments are run in South Africa on three amputees where they were asked to perform gestures with their phantom limb (i.e., the missing limb segment). A gesture recognition method is implemented, and the classification accuracy with data recorded from textile electrodes is compared to that from gel electrodes. Further analysis examining the relationship between classifier performance and physiological parameters are performed. Results show that textile electrodes can be used to perform accurate gesture recognition, and are comparable to disposable gel electrodes. This demonstrates that low-cost sensory systems are not barrier to myoelectric control in developing countries.
ER  - 

TY  - CONF
TI  - Continuous Wrist Joint Control Using Muscle Deformation Measured on Forearm Skin
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1818
EP  - 1824
AU  - A. Kato
AU  - M. Hirabayashi
AU  - Y. Matsurnoto
AU  - Y. Nakashima
AU  - Y. Kobayashi
AU  - M. G. Fujie
AU  - S. Sugano
PY  - 2018
KW  - artificial limbs
KW  - biomechanics
KW  - deformation
KW  - electromyography
KW  - medical control systems
KW  - medical signal processing
KW  - muscle
KW  - prosthetics
KW  - skin
KW  - viscoelasticity
KW  - wrist movement tasks
KW  - Voigt model
KW  - measured estimated angles
KW  - muscle viscoelastic model
KW  - stable wrist joint angle control
KW  - accurate wrist joint angle control
KW  - deformation signal
KW  - continuous prosthesis wrist joint control method
KW  - intended wrist joint angle
KW  - skin surface change
KW  - muscle bulge
KW  - measured deformation
KW  - transra-dial amputees
KW  - intended angle motion
KW  - upper-limb amputees
KW  - intended joint angles
KW  - forearm skin
KW  - muscle deformation measured
KW  - continuous wrist joint control
KW  - Wrist
KW  - Muscles
KW  - Strain
KW  - Skin
KW  - Prosthetic hand
KW  - Mathematical model
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460491
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Continuous, easy-to-implement, accurate inference of intended joint angles is important for effectively controlling powered prosthetic devices that can improve the lives and capabilities of upper-limb amputees. Estimation of intended joint angles is difficult because conventional biosignals are not directly related to the intended angle motion. In previous work, we began to address this issue by confirming that both transra-dial amputees and intact subjects, the measured deformation of the muscle bulge on the skin surface change according to the intended wrist joint angle. This paper presents a continuous prosthesis wrist joint control method using this deformation signal. We here verify the effectiveness of the distribution of the muscle bulge for accurate and stable wrist joint angle control in real time. The wrist joint angles were calculated in real time from a muscle viscoelastic model using the previously determined algorithm. We compared the error between measured and estimated angles with a conventional method, the Voigt model, and the KelvinVoigt model. Experimental results obtained for three intact people over three trials of wrist movement tasks gave the accuracy and stability of 7.96±6.16° when using the Voigt model; this is a similar performance compared to related work using a surface electromyogram. A method for continuously controlling the wrist joint angle for a prosthesis using the distribution of the muscle bulge was thus successfully established.
ER  - 

TY  - CONF
TI  - Empirical Quantification and Modeling of Muscle Deformation: Toward Ultrasound-Driven Assistive Device Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1825
EP  - 1832
AU  - L. A. Hallock
AU  - A. Kato
AU  - R. Bajcsy
PY  - 2018
KW  - biomechanics
KW  - biomedical ultrasonics
KW  - electromyography
KW  - medical image processing
KW  - medical robotics
KW  - medical signal processing
KW  - muscle
KW  - assistive device sensor locations
KW  - real-time ultrasound scanning
KW  - muscle cross-sectional area
KW  - force-associated deformation signals
KW  - motion capture
KW  - ultrasound scanner
KW  - high-DoF assistive devices
KW  - B-mode ultrasound
KW  - exoskeletons
KW  - biosignal-driven prostheses
KW  - surface electromyography
KW  - toward ultrasound-driven assistive device control
KW  - empirical quantification
KW  - muscle deformation models
KW  - Muscles
KW  - Strain
KW  - Ultrasonic imaging
KW  - Elbow
KW  - Assistive devices
KW  - Deformable models
KW  - Ultrasonic variables measurement
DO  - 10.1109/ICRA.2018.8462887
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Surface electromyography is currently the sensing modality of choice for control of biosignal-driven prostheses and exoskeletons; however, the sensor's noisy and aggregate nature inhibits collection of distinguishable signal streams to robustly manipulate multiple device degrees of freedom (DoF). We here explore 2D B-mode ultrasound as an alternative source of muscle activation data (namely, muscle deformation) that can be more precisely localized, allowing for the theoretical collection of multiple naturally-varying signals that could be used to control high-DoF assistive devices. We here present a proof-of-concept study showing a) the observability of muscle deformation via ultrasound, and b) novel descriptions of the spatially-varying nature of the signal. These analyses are accomplished through the study of nine volumetric scans of the biceps brachii under varied elbow angle and loading conditions, collected and spatially localized using an ultrasound scanner and motion capture. We here establish the feasibility of measuring several force-associated deformation signals (including muscle cross-sectional area and thickness) via real-time ultrasound scanning and quantify the spatial variation of these signals. Additionally, we propose future applications for both our signal characterizations and the generated muscle volume data set, including better design of assistive device sensor locations and validation of existing muscle deformation models.
ER  - 

TY  - CONF
TI  - Grasp-training Robot to Activate Neural Control Loop for Reflex and Experimental Verification
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1849
EP  - 1854
AU  - S. Okajima
AU  - F. S. Alnajjar
AU  - H. Yamasaki
AU  - M. Itkonen
AU  - Á. C. García
AU  - Y. Hasegawa
AU  - S. Shimoda
PY  - 2018
KW  - electromyography
KW  - handicapped aids
KW  - medical robotics
KW  - neurocontrollers
KW  - neurophysiology
KW  - patient rehabilitation
KW  - grasp rehabilitation
KW  - robot design
KW  - grasping movements
KW  - mechanical motions
KW  - reflex response
KW  - motion intention
KW  - rehabilitation robot
KW  - activate neural control loop
KW  - grasp-training robot
KW  - paralyzed hand
KW  - grasp reflex
KW  - elastic bar
KW  - Robots
KW  - Grasping
KW  - Shafts
KW  - Bars
KW  - Force
KW  - Electromyography
KW  - Rubber
DO  - 10.1109/ICRA.2018.8461114
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Using a rehabilitation robot to activate motion intention and reflex response simultaneously is an effective approach to aiding recovery from paralysis caused by neurological disorders. Mechanical motions supported by conventional robots are, however, not enough to activate reflex. In this paper, we propose a grasp-training robot that can stimulate the grasp reflex of a paralyzed hand by pushing the hand onto an elastic bar while supporting the grasping movements. In addition to this feature, we discuss the robot design in relation to its usability and wearability for ease of use in clinical practice. Experimental results obtained from healthy subjects show that the proposed robot can support grasping in a way similar to the traditional range-of-motion exercise used by therapists for grasp rehabilitation. Combining this appropriate grasping-motion support and the mechanism for pushing the hand onto an elastic bar succeeds in activating the grasp reflex of a completely paralyzed patient in a clinical test that involves monitoring electromyography signals from the paralyzed hand.
ER  - 

TY  - CONF
TI  - Multi-View 3D Entangled Forest for Semantic Segmentation and Mapping
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1855
EP  - 1862
AU  - M. Antonello
AU  - D. Wolf
AU  - J. Prankl
AU  - S. Ghidoni
AU  - E. Menegatti
AU  - M. Vincze
PY  - 2018
KW  - image fusion
KW  - image reconstruction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - multiview frame fusion technique
KW  - perceived 3D structure
KW  - semantic labelling task
KW  - human interaction
KW  - verbal references
KW  - location related services
KW  - multiview 3D entangled forest
KW  - semantic maps
KW  - offline reconstruction
KW  - single frames
KW  - online multiview semantic segmentation
KW  - batch approach
KW  - Semantics
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Forestry
KW  - Labeling
KW  - Context modeling
KW  - Standards
DO  - 10.1109/ICRA.2018.8460837
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Applications that provide location related services need to understand the environment in which humans live such that verbal references and human interaction are possible. We formulate this semantic labelling task as the problem of learning the semantic labels from the perceived 3D structure. In this contribution we propose a batch approach and a novel multi-view frame fusion technique to exploit multiple views for improving the semantic labelling results. The batch approach works offline and is the direct application of an existing single-view method to scene reconstructions with multiple views. The multi-view frame fusion works in an incremental fashion accumulating the single-view results, hence allowing the online multi-view semantic segmentation of single frames and the offline reconstruction of semantic maps. Our experiments show the superiority of the approaches based on our fusion scheme, which leads to a more accurate semantic labelling.
ER  - 

TY  - CONF
TI  - Mark Yourself: Road Marking Segmentation via Weakly-Supervised Annotations from Multimodal Data
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1863
EP  - 1870
AU  - T. Bruls
AU  - W. Maddern
AU  - A. A. Morye
AU  - P. Newman
PY  - 2018
KW  - feature extraction
KW  - image segmentation
KW  - object detection
KW  - object recognition
KW  - traffic engineering computing
KW  - unsupervised learning
KW  - video signal processing
KW  - visual databases
KW  - road marking segmentation
KW  - weakly-supervised annotations
KW  - multimodal data
KW  - weakly-supervised learning system
KW  - complex urban environments
KW  - monocular camera
KW  - expensive manual labelling
KW  - annotated images
KW  - deep semantic segmentation network
KW  - road markings
KW  - traffic situations
KW  - weather conditions
KW  - sensor modalities
KW  - lighting
KW  - qualitative performance
KW  - real-time road marking detection
KW  - labelling effort
KW  - Oxford RobotCar dataset
KW  - CamVid dataset
KW  - Roads
KW  - Laser radar
KW  - Cameras
KW  - Image segmentation
KW  - Real-time systems
KW  - Labeling
KW  - Semantics
DO  - 10.1109/ICRA.2018.8460952
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a weakly-supervised learning system for real-time road marking detection using images of complex urban environments obtained from a monocular camera. We avoid expensive manual labelling by exploiting additional sensor modalities to generate large quantities of annotated images in a weakly-supervised way, which are then used to train a deep semantic segmentation network. At run time, the road markings in the scene are detected in real time in a variety of traffic situations and under different lighting and weather conditions without relying on any preprocessing steps or predefined models. We achieve reliable qualitative performance on the Oxford RobotCar dataset, and demonstrate quantitatively on the CamVid dataset that exploiting these annotations significantly reduces the required labelling effort and improves performance.
ER  - 

TY  - CONF
TI  - Semantic Labeling of Indoor Environments from 3D RGB Maps
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1871
EP  - 1878
AU  - M. Brucker
AU  - M. Durner
AU  - R. Ambruş
AU  - Z. C. Márton
AU  - A. Wendt
AU  - P. Jensfelt
AU  - K. O. Arras
AU  - R. Triebel
PY  - 2018
KW  - data mining
KW  - feature extraction
KW  - geometry
KW  - image classification
KW  - image colour analysis
KW  - image reconstruction
KW  - image sensors
KW  - indoor navigation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - object recognition
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - semantic labels assignment
KW  - rooms reconstruction
KW  - deep-learning techniques
KW  - virtual RGB views
KW  - geometric analysis
KW  - object detection
KW  - scene classification
KW  - room types
KW  - 3D RGB maps
KW  - indoor environments
KW  - semantic labeling
KW  - Semantics
KW  - Labeling
KW  - Three-dimensional displays
KW  - Robots
KW  - Training
KW  - Task analysis
KW  - Solid modeling
DO  - 10.1109/ICRA.2018.8462922
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present an approach to automatically assign semantic labels to rooms reconstructed from 3D RGB maps of apartments. Evidence for the room types is generated using state-of-the-art deep-learning techniques for scene classification and object detection based on automatically generated virtual RGB views, as well as from a geometric analysis of the map's 3D structure. The evidence is merged in a conditional random field, using statistics mined from different datasets of indoor environments. We evaluate our approach qualitatively and quantitatively and compare it to related methods.
ER  - 


TY  - CONF
TI  - Practical Motion Segmentation for Urban Street View Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1879
EP  - 1886
AU  - C. Rubino
AU  - A. Del Bue
AU  - T. Chin
PY  - 2018
KW  - cameras
KW  - image motion analysis
KW  - image segmentation
KW  - image sequences
KW  - traffic engineering computing
KW  - video signal processing
KW  - generic motion segmentation algorithms
KW  - KITTI dataset
KW  - video sequence annotation
KW  - restricted camera movement
KW  - application-specific factors
KW  - urban environment
KW  - image-based motion segmentation
KW  - urban street view scenes
KW  - practical motion segmentation
KW  - realistic motion segmentation benchmark dataset
KW  - Motion segmentation
KW  - Trajectory
KW  - Computer vision
KW  - Cameras
KW  - Transmission line matrix methods
KW  - Semantics
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460993
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Though a long-studied problem, motion segmentation has yet to migrate into practical applications. We argue that a vital step towards that goal lies in addressing motion segmentation for the specific setting of interest. To this end, this paper presents a new approach for image-based motion segmentation in the case of vehicles navigating inside an urban environment. We exploit two application-specific factors - the restricted camera movement and the known type of moving objects - to deal with the two major limiting factors - missing data and strong perspective effects - that affect most previous “generic” motion segmentation algorithms. By constraining the geometry and exploiting known semantic classes in the scene, we achieve much higher accuracy than previous approaches. In addition to the novel algorithm, we contribute a more realistic motion segmentation benchmark dataset for moving platforms by annotating real video sequences from the KITTI dataset. Experiments on this dataset and other synthetic data confirm the effectiveness of the proposed approach.
ER  - 

TY  - CONF
TI  - SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1887
EP  - 1893
AU  - B. Wu
AU  - A. Wan
AU  - X. Yue
AU  - K. Keutzer
PY  - 2018
KW  - computer games
KW  - feedforward neural nets
KW  - image classification
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object detection
KW  - optical radar
KW  - pattern clustering
KW  - Grand Theft Auto
KW  - video game
KW  - autonomous driving
KW  - road-objects
KW  - semantic segmentation
KW  - 3D LiDAR point cloud
KW  - real-time road-object segmentation
KW  - recurrent CRF
KW  - realistic training data
KW  - LiDAR simulator
KW  - extra training data
KW  - 3D bounding boxes
KW  - point-wise segmentation labels
KW  - CNN model
KW  - instance-level labels
KW  - point-wise label map
KW  - transformed LiDAR point cloud
KW  - convolutional neural networks
KW  - SqueezeSeg
KW  - end-to-end pipeline
KW  - point-wise classification problem
KW  - LiDAR point clouds
KW  - time 8.2 ms to 9.2 ms
KW  - time 3.0 d
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Computational modeling
KW  - Pipelines
KW  - Autonomous vehicles
KW  - Semantics
KW  - Clustering algorithms
DO  - 10.1109/ICRA.2018.8462926
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We address semantic segmentation of road-objects from 3D LiDAR point clouds. In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists. We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer. Instance-level labels are then obtained by conventional clustering algorithms. Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI. To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto V (GTA-V), a popular video game, to synthesize large amounts of realistic training data. Our experiments show that SqueezeSeg achieves high accuracy with astonishingly fast and stable runtime (8.7±0.5 ms per frame), highly desirable for autonomous driving. Furthermore, additionally training on synthesized data boosts validation accuracy on real-world data. Our source code is open-source released1. The paper is accompanied by a video2 containing a high level introduction and demonstrations of this work.
ER  - 

TY  - CONF
TI  - Driven to Distraction: Self-Supervised Distractor Learning for Robust Monocular Visual Odometry in Urban Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1894
EP  - 1900
AU  - D. Barnes
AU  - W. Maddern
AU  - G. Pascoe
AU  - I. Posner
PY  - 2018
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - image classification
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion estimation
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - self-supervised distractor learning
KW  - robust monocular visual odometry
KW  - self-supervised approach
KW  - distractors
KW  - camera images
KW  - cluttered urban environments
KW  - per-pixel ephemerality mask
KW  - depth map
KW  - deep convolutional network
KW  - monocular visual odometry pipeline
KW  - sparse features
KW  - dense photometric matching
KW  - metric-scale VO
KW  - single camera
KW  - robust VO methods
KW  - odometry drift
KW  - egomotion estimation
KW  - moving vehicles
KW  - urban traffic
KW  - vehicle motion
KW  - ephemerality
KW  - offline multisession mapping approaches
KW  - Three-dimensional displays
KW  - Cameras
KW  - Robustness
KW  - Visual odometry
KW  - Motion estimation
KW  - Entropy
KW  - Training data
DO  - 10.1109/ICRA.2018.8460564
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a self-supervised approach to ignoring “distractors” in camera images for the purposes of robustly estimating vehicle motion in cluttered urban environments. We leverage offline multi-session mapping approaches to automatically generate a per-pixel ephemerality mask and depth map for each input image, which we use to train a deep convolutional network. At run-time we use the predicted ephemerality and depth as an input to a monocular visual odometry (VO) pipeline, using either sparse features or dense photometric matching. Our approach yields metric-scale VO using only a single camera and can recover the correct egomotion even when 90% of the image is obscured by dynamic, independently moving objects. We evaluate our robust VO methods on more than 400km of driving from the Oxford RobotCar Dataset and demonstrate reduced odometry drift and significantly improved egomotion estimation in the presence of large moving vehicles in urban traffic.
ER  - 

TY  - CONF
TI  - Semantic Mapping with Omnidirectional Vision
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1901
EP  - 1907
AU  - L. F. Posada
AU  - A. Velasquez-Lopez
AU  - F. Hoffmann
AU  - T. Bertram
PY  - 2018
KW  - cameras
KW  - distortion
KW  - image classification
KW  - image fusion
KW  - image segmentation
KW  - image sensors
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - omnidirectional vision
KW  - omnidirectional images
KW  - robust segmentation
KW  - occupancy grid maps
KW  - inverse sensor model
KW  - nonlinear distortions
KW  - omnidirectional camera mirror
KW  - place category classifier
KW  - range-based occupancy grid
KW  - dense semantic map
KW  - bird eye view
KW  - visual semantic mapping framework
KW  - robot local free space
KW  - Semantics
KW  - Sensors
KW  - Cameras
KW  - Robots
KW  - Buildings
KW  - Mirrors
KW  - Visualization
DO  - 10.1109/ICRA.2018.8461165
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a purely visual semantic mapping framework using omnidirectional images. The approach rests upon the robust segmentation of the robot's local free space, replacing conventional range sensors for the generation of occupancy grid maps. The perceptions are mapped into a bird's eye view allowing an inverse sensor model directly by removing the non-linear distortions of the omnidirectional camera mirror. The system relies on a place category classifier to label the navigation relevant categories: room, corridor, doorway, and open room. Each place class maintains a separated grid map that are fused with the range-based occupancy grid for building a dense semantic map.
ER  - 

TY  - CONF
TI  - Semantic Segmentation from Limited Training Data
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1908
EP  - 1915
AU  - A. Milan
AU  - T. Pham
AU  - K. Vijay
AU  - D. Morrison
AU  - A. W. Tow
AU  - L. Liu
AU  - J. Erskine
AU  - R. Grinover
AU  - A. Gurman
AU  - T. Hunn
AU  - N. Kelly-Boxall
AU  - D. Lee
AU  - M. McTaggart
AU  - G. Rallos
AU  - A. Razjigaev
AU  - T. Rowntree
AU  - T. Shen
AU  - R. Smith
AU  - S. Wade-McCue
AU  - Z. Zhuang
AU  - C. Lehnert
AU  - G. Lin
AU  - I. Reid
AU  - P. Corke
AU  - J. Leitner
PY  - 2018
KW  - convolution
KW  - image classification
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - object recognition
KW  - recurrent neural nets
KW  - robot vision
KW  - limited training data
KW  - robotic perception
KW  - cluttered scenes
KW  - shiny surfaces
KW  - transparent surfaces
KW  - robust perception pipeline
KW  - data acquisition
KW  - deep metric learning approach
KW  - semantic-agnostic boundary detection
KW  - pixel-wise voting
KW  - fully-supervised semantic segmentation approach
KW  - ARC 2017 dataset
KW  - Amazon Robotics Challenge 2017
KW  - dataset collection
KW  - deep convolutional neural networks
KW  - Task analysis
KW  - Image segmentation
KW  - Training
KW  - Semantics
KW  - Robots
KW  - Measurement
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8461082
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present our approach for robotic perception in cluttered scenes that led to winning the recent Amazon Robotics Challenge (ARC) 2017. Next to small objects with shiny and transparent surfaces, the biggest challenge of the 2017 competition was the introduction of unseen categories. In contrast to traditional approaches which require large collections of annotated data and many hours of training, the task here was to obtain a robust perception pipeline with only few minutes of data acquisition and training time. To that end, we present two strategies that we explored. One is a deep metric learning approach that works in three separate steps: semantic-agnostic boundary detection, patch classification and pixel-wise voting. The other is a fully-supervised semantic segmentation approach with efficient dataset collection. We conduct an extensive analysis of the two methods on our ARC 2017 dataset. Interestingly, only few examples of each class are sufficient to fine-tune even very deep convolutional neural networks for this specific task.
ER  - 

TY  - CONF
TI  - Planning Ergonomic Sequences of Actions in Human-Robot Interaction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1916
EP  - 1923
AU  - B. Busch
AU  - M. Toussaint
AU  - M. Lopes
PY  - 2018
KW  - ergonomics
KW  - human-robot interaction
KW  - multi-agent systems
KW  - multi-robot systems
KW  - path planning
KW  - optimization formulation
KW  - ergonomic situations
KW  - human-robot interaction
KW  - human-robot collaboration
KW  - motion planning problem
KW  - multiagent case
KW  - human robot
KW  - Ergonomics
KW  - Task analysis
KW  - Robot kinematics
KW  - Planning
KW  - Cost function
DO  - 10.1109/ICRA.2018.8462927
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we define the problem of human-robot collaboration as a combined task and motion planning problem which is extended to the multi-agent case (human and robot). Our proposed approach allows us to explicitly take into account ergonomic cost, synchrony and concurrency of behavior in an optimization formulation. We show simulated results as well as an experiment with a real robot combined with a user study. Results show that optimizing over a sequence of actions leads to more ergonomic situations.
ER  - 

TY  - CONF
TI  - Proposal of Collaboration Safety in a Coexistence Environment of Human and Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1924
EP  - 1930
AU  - M. Dohi
AU  - K. Okada
AU  - I. Maeda
AU  - S. Fujitani
AU  - T. Fujita
PY  - 2018
KW  - Big Data
KW  - factory automation
KW  - human-robot interaction
KW  - industrial robots
KW  - Internet of Things
KW  - manufacturing systems
KW  - production engineering computing
KW  - safety
KW  - solution-oriented industrial society
KW  - high technological capabilities
KW  - next-generation manufacturing systems
KW  - flexible productivity
KW  - human-robot collaboration
KW  - robot revolution
KW  - collaboration safety
KW  - safety level
KW  - IoT technology
KW  - optimization
KW  - big data
KW  - progressing digitalization
KW  - 4th industrial revolution
KW  - manufacturing sites
KW  - Collaboration
KW  - Service robots
KW  - Production
KW  - Hazards
KW  - Optimization
KW  - Robot Safety
KW  - Industrial Robots
KW  - Factory Automation
DO  - 10.1109/ICRA.2018.8460869
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Whereas various things are connected via networks thanks to IoT technology, and the era of the 4th industrial revolution which realizes optimization and efficiency by utilizing AI and big data is emerging, manufacturing systems are also significantly transforming globally. In addition to the robot revolution, along with progressing digitalization, manufacturing sites in Japan are changing, aiming at establishment of “Connected Industries” that is a solution-oriented industrial society, based on the high technological capabilities. In order to respond timely to diversifying demands of customers, it is necessary to build a next-generation manufacturing systems that realizes flexible and high productivity, such as human-robot collaboration, and it is becoming difficult to respond to the necessity by conventional safety concept. Therefore, in order to realize the 4th industrial revolution, the robot revolution, and “Connected Industries,” it is essential to establish a new safety concept corresponding to the next-generation manufacturing systems to ensure safety. This paper introduces the safety concept to be changed along with the evolution of manufacturing sites, and proposes a new safety concept, which realizes collaboration safety of humans and robots, and an outline of its safety level, for the first time in the world.
ER  - 

TY  - CONF
TI  - A Robust Method to Predict Temporal Aspects of Actions by Observation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1931
EP  - 1938
AU  - E. Hourdakis
AU  - P. Trahanias
PY  - 2018
KW  - human-robot interaction
KW  - manipulators
KW  - robust method
KW  - temporal properties
KW  - ground truth data
KW  - temporal aspec prediction
KW  - time-constrained tasks
KW  - wiping
KW  - table
KW  - vegetable chopping
KW  - floor cleaning
KW  - Task analysis
KW  - Frequency modulation
KW  - Motion segmentation
KW  - Predictive models
KW  - Process control
DO  - 10.1109/ICRA.2018.8461067
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The ability to predict the duration of an activity can enable a robot to plan its behaviors ahead, interact seamlessly with other humans, by coordinating its actions, and allocate effort and resources to tasks that are time-constrained or critical. Despite its usefulness, models that examine the temporal properties of an activity remain relatively unexplored. In the current paper we present, to the best of our knowledge, the first method that can estimate temporal properties of an activity by observation. We evaluate it on three use-cases (i) wiping a table, (ii) chopping vegetables and (iii) cleaning the floor, using ground truth data from real demonstrations, and show that it can make predictions with high accuracy and little training. In addition, we investigate different methods to approximate the progress of each task, and demonstrate how a model can generalize, by reusing part of it in different activities.
ER  - 

TY  - CONF
TI  - Augmented Reality for Feedback in a Shared Control Spraying Task
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1939
EP  - 1946
AU  - J. Elsdon
AU  - Y. Demiris
PY  - 2018
KW  - augmented reality
KW  - calibration
KW  - control engineering computing
KW  - feedback
KW  - industrial robots
KW  - mobile robots
KW  - spraying
KW  - handheld spraying robot
KW  - industrial robots
KW  - task awareness
KW  - Microsoft Hololens system
KW  - motion capture system
KW  - augmented reality spraying task
KW  - calibration routine
KW  - augmented reality interfaces
KW  - feedback
KW  - logical approach
KW  - target regions
KW  - shared control methods
KW  - shared control spraying task
KW  - time 4.0 s
KW  - Task analysis
KW  - Robots
KW  - Spraying
KW  - Augmented reality
KW  - Calibration
KW  - Paints
KW  - Headphones
DO  - 10.1109/ICRA.2018.8461179
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Using industrial robots to spray structures has been investigated extensively, however interesting challenges emerge when using handheld spraying robots. In previous work we have demonstrated the use of shared control of a handheld spraying robot to assist a user in a 3D spraying task. In this paper we demonstrate the use of Augmented Reality Interfaces to increase the user's progress and task awareness. We describe our solutions to challenging calibration issues between the Microsoft Hololens system and a motion capture system without the need for well defined markers or careful alignment on the part of the user. Error relative to the motion capture system was shown to be 10mm after only a 4 second calibration routine. Secondly we outline a logical approach for visualising liquid density for an augmented reality spraying task, this system allows the user to see target regions to complete, areas that are complete and areas that have been overdosed clearly. Finally we produced a user study to investigate the level of assistance that a handheld robot utilising shared control methods should provide during a spraying task. Using a handheld spraying robot with a moving spray head did not aid the user much over simply actuating spray nozzle for them. Compared to manual control the automatic modes significantly reduced the task load experienced by the user and significantly increased the quality of the result of the spraying task, reducing the error by 33-45%.
ER  - 

TY  - CONF
TI  - Interactive Robot Knowledge Patching Using Augmented Reality
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1947
EP  - 1954
AU  - H. Liu
AU  - Y. Zhang
AU  - W. Si
AU  - X. Xie
AU  - Y. Zhu
AU  - S. Zhu
PY  - 2018
KW  - augmented reality
KW  - data visualisation
KW  - decision making
KW  - human-robot interaction
KW  - knowledge representation
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - Augmented Reality
KW  - Temporal And-Or graph
KW  - robot program
KW  - interactive robot teaching
KW  - AR interface
KW  - knowledge representation
KW  - comprehensive visualizations
KW  - decision making process
KW  - Microsoft HoloLens
KW  - interactive robot knowledge patching
KW  - Task analysis
KW  - Decision making
KW  - Knowledge representation
KW  - Visualization
KW  - Robot sensing systems
KW  - Grammar
DO  - 10.1109/ICRA.2018.8462837
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a novel Augmented Reality (AR) approach, through Microsoft HoloLens, to address the challenging problems of diagnosing, teaching, and patching interpretable knowledge of a robot. A Temporal And-Or graph (T-AOG) of opening bottles is learned from human demonstration and programmed to the robot. This representation yields a hierarchical structure that captures the compositional nature of the given task, which is highly interpretable for the users. By visualizing the knowledge structure represented by a T-AOG and the decision making process by parsing the T-AOG, the user can intuitively understand what the robot knows, supervise the robot's action planner, and monitor visually latent robot states (e.g., the force exerted during interactions). Given a new task, through such comprehensive visualizations of robot's inner functioning, users can quickly identify the reasons of failures, interactively teach the robot with a new action, and patch it to the current knowledge structure. In this way, the robot is capable of solving similar but new tasks only through minor modifications provided by the users interactively. This process demonstrates the interpretability of our knowledge representation and the effectiveness of the AR interface.
ER  - 

TY  - CONF
TI  - Using Constrained Optimization for Real-Time Synchronization of Verbal and Nonverbal Robot Behavior
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1955
EP  - 1961
AU  - A. E. Vijayan
AU  - S. Alexanderson
AU  - J. Beskow
AU  - I. Leite
PY  - 2018
KW  - computer animation
KW  - humanoid robots
KW  - image motion analysis
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - robot vision
KW  - constrained optimization
KW  - real-time synchronization
KW  - motion re-targeting techniques
KW  - virtual character animation research
KW  - joint angular velocities
KW  - robot motion
KW  - re-targeted motion sequences
KW  - humanoid robot
KW  - joint motion trajectories
KW  - verbal behavior synchronization
KW  - nonverbal behavior synchronization
KW  - verbal robot behavior
KW  - nonverbal robot behavior
KW  - Optimization
KW  - Trajectory
KW  - Angular velocity
KW  - Synchronization
KW  - Dynamics
KW  - Robot motion
DO  - 10.1109/ICRA.2018.8462828
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Most of the motion re-targeting techniques are grounded on virtual character animation research, which means that they typically assume that the target embodiment has unconstrained joint angular velocities. However, because robots often do have such constraints, traditional re-targeting approaches can originate irregular delays in the robot motion. With the goal of ensuring synchronization between verbal and nonverbal behavior, this paper proposes an optimization framework for processing re-targeted motion sequences that addresses constraints such as joint angle and angular velocities. The proposed framework was evaluated on a humanoid robot using both objective and subjective metrics. While the analysis of the joint motion trajectories provides evidence that our framework successfully performs the desired modifications to ensure verbal and nonverbal behavior synchronization, results from a perceptual study showed that participants found the robot motion generated by our method more natural, elegant and lifelike than a control condition.
ER  - 

TY  - CONF
TI  - Learning Task-Based Instructional Policy for Excavator-Like Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1962
EP  - 1969
AU  - H. Maske
AU  - E. Kieson
AU  - G. Chowdhary
AU  - C. Abramson
PY  - 2018
KW  - excavators
KW  - learning by example
KW  - mobile robots
KW  - learning from demonstration
KW  - demonstration trajectories automatic segmentation
KW  - hydraulic actuated scaled excavator robot
KW  - complex truck loading task
KW  - nongeneric policy model
KW  - mapping continuous state action trajectories
KW  - expert demonstration
KW  - task-based instructional policy
KW  - Task analysis
KW  - Robots
KW  - Trajectory
KW  - Hidden Markov models
KW  - Load modeling
KW  - Actuators
KW  - Loading
DO  - 10.1109/ICRA.2018.8462923
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We explore beyond existing work in learning from demonstration by asking the question: “Can robots learn to guide?”, that is, can a robot autonomously learn an instructional policy from expert demonstration and use it to instruct humans in executing complex task? As a solution, we propose learning of instructional policy (πI) that maps the state to an instruction for a human. To learn πI, we define action primitives that addresses the challenge of mapping continuous state action trajectories to human parse-able instructions. Action primitives are demonstrated to be very effective in automatic segmentation of demonstration trajectories into fewer repetitive and reusable segments, and a highly scalable approach in comparison to the existing state-of-the art. Finally, we construct a non-generic policy model as a generative model for instructional policies to generate instruction for an entire task. With few modifications, the proposed model is demonstrated to perform autonomous execution of complex truck loading task on hydraulic actuated scaled excavator robot. Guidance approach is tested based on a controlled group study involving 75 participants, who learn to perform the same task.
ER  - 

TY  - CONF
TI  - Playdough to Roombots: Towards a Novel Tangible User Interface for Self-reconfigurable Modular Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1970
EP  - 1977
AU  - M. Mutlu
AU  - S. Hauser
AU  - A. Bernardino
AU  - A. Ijspeert
PY  - 2018
KW  - control engineering computing
KW  - furniture
KW  - mobile robots
KW  - robot dynamics
KW  - user interfaces
KW  - self-reconfigurable modular robots
KW  - shape-shift
KW  - self-reconfigurable furniture
KW  - intuitive user interface
KW  - tangible user interface
KW  - Roombots shape
KW  - 3D shape scanning
KW  - SRMR system
KW  - Shape
KW  - Three-dimensional displays
KW  - User interfaces
KW  - Solid modeling
KW  - Robots
KW  - Planning
KW  - Buildings
KW  - tangible user interface
KW  - self-reconfigurable modular robots
KW  - deformable material
KW  - shape formation
DO  - 10.1109/ICRA.2018.8461248
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the main strengths of self-reconfigurable modular robots (SRMR) is their ability to shape-shift and dynamically change their morphology. In the case of our SRMR system “Roombots”, these shapes can be quite arbitrary for a great variety of tasks while the major utility is envisioned to be self-reconfigurable furniture. As such, the ideas and inspirations from users quickly need to be translated into the final Roombots shape. This involves a multitude of separate processes and - most importantly - requires an intuitive user interface. Our current approach led to the development of a tangible user interface (TUI) which involves 3D-scanning of a shape formed by modeling clay and the necessary steps to prepare the digitized model to be formed by Roombots. The system is able to generate a solution in less than two minutes for our target use as demonstrated with various examples.
ER  - 

TY  - CONF
TI  - A Hierarchical Model for Action Recognition Based on Body Parts
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1978
EP  - 1985
AU  - Z. Shao
AU  - Y. Li
AU  - Y. Guo
AU  - J. Yang
AU  - Z. Wang
PY  - 2018
KW  - gesture recognition
KW  - image motion analysis
KW  - image representation
KW  - object detection
KW  - vectors
KW  - hierarchical model
KW  - body parts
KW  - human action recognition
KW  - human actions
KW  - human skeleton
KW  - discriminative body-parts selection
KW  - Fisher vectors
KW  - hierarchical representations
KW  - hierarchical RRV descriptors
KW  - Rotation and Relative Velocity descriptors
KW  - Skeleton
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Trajectory
KW  - Couplings
KW  - Biological system modeling
DO  - 10.1109/ICRA.2018.8460516
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - As increasing attention is paid on human action recognition from skeleton data, this paper focuses on such tasks by proposing a hierarchical model to discover the structure information of body-parts involved in human actions. Considering human actions as simultaneous motions of different body-parts of the human skeleton, we propose a hierarchical model to simultaneously apply discriminative body-parts selection at a same scale and group coupling of bundles of body-parts at different scales, while we decompose the human skeleton into a hierarchy of body-parts of varying scales. To represent such hierarchy of body-parts, we accordingly build a hierarchical RRV (Rotation and Relative Velocity) descriptors. The hierarchical representations encoded by Fisher vectors of the hierarchical RRV descriptors are properly formulated into the hierarchical model via the proposed hierarchical mixed norm, to apply sparse selection of body-parts and regularize the structure of such hierarchy of body-parts. The extensive evaluations on three challenging datasets demonstrate the effectiveness of our proposed approach, which achieves superior performance compared to state-of-the-art results on different sizes of datasets, showing it is more widely applicable than existing approaches.
ER  - 

TY  - CONF
TI  - 3D Human Pose Estimation in RGBD Images for Robotic Task Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1986
EP  - 1992
AU  - C. Zimmermann
AU  - T. Welschehold
AU  - C. Dornhege
AU  - W. Burgard
AU  - T. Brox
PY  - 2018
KW  - image colour analysis
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - service robots
KW  - monocular 3D pose estimation
KW  - service robot
KW  - color images
KW  - robust human keypoint detectors
KW  - robotic task learning
KW  - RGBD images
KW  - 3D human pose estimation
KW  - human teacher
KW  - PR2 robot
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Color
KW  - Pose estimation
KW  - Robot sensing systems
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8462833
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose an approach to estimate 3D human pose in real world units from a single RGBD image and show that it exceeds performance of monocular 3D pose estimation approaches from color as well as pose estimation exclusively from depth. Our approach builds on robust human keypoint detectors for color images and incorporates depth for lifting into 3D. We combine the system with our learning from demonstration framework to instruct a service robot without the need of markers. Experiments in real world settings demonstrate that our approach enables a PR2 robot to imitate manipulation actions observed from a human teacher.
ER  - 

TY  - CONF
TI  - Safe and Efficient Human-Robot Collaboration Part I: Estimation of Human Arm Motions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 1993
EP  - 1999
AU  - R. Weitschat
AU  - J. Ehrensperger
AU  - M. Maier
AU  - H. Aschemann
PY  - 2018
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - motion control
KW  - path planning
KW  - human arm motions
KW  - fenceless robot cells
KW  - safety requirements
KW  - robot motions
KW  - control-oriented dynamic model
KW  - human-robot collaboration
KW  - cycle times
KW  - admissible path velocity
KW  - Collision avoidance
KW  - Manipulators
KW  - Kinematics
KW  - Collaboration
KW  - Safety
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461190
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A significant barrier regarding a successful implementation of fenceless robot cells into manufacturing areas with humans is given by the inefficiency due to safety requirements. Robot motions have to be slowed down so that an unexpected collision with a human does not result in human injuries. This velocity reduction leads to longer cycle times and, hence, fenceless robot cells turn out as uneconomic. In this paper, a new approach for human-robot collaboration in assembly tasks is presented. For a better performance of the robot, methods are investigated on how the robot can exploit a maximum performance while maintaining the safety of collaborating humans. For this purpose, the kinematics and dynamics of a human arm are described by a control-oriented dynamic model to determine its capability and reachability. Successful experiments validate the dynamic model as well as a corresponding projection approach for calculating possible movements of the human arm that may lead to a collision with the robot. Finally, this information is used to calculate an admissible path velocity that minimizes the danger of human injuries.
ER  - 

TY  - CONF
TI  - Robust Real-Time 3D Person Detection for Indoor and Outdoor Applications
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2000
EP  - 2006
AU  - R. Hanten
AU  - P. Kuhlmann
AU  - S. Otte
AU  - A. Zell
PY  - 2018
KW  - graphics processing units
KW  - human computer interaction
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - stereo image processing
KW  - mobile robotics
KW  - 3D sensor types
KW  - indoor applications
KW  - outdoor applications
KW  - outdoor scenarios
KW  - indoor scenarios
KW  - smaller robotic systems
KW  - single CPU thread
KW  - multiple CPU cores
KW  - human interaction
KW  - robotic applications
KW  - robust person detection
KW  - robust real-time 3D person detection
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Feature extraction
KW  - Visualization
KW  - Pipelines
KW  - Real-time systems
DO  - 10.1109/ICRA.2018.8461257
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Fast and robust person detection is one of the most important tasks for robotic applications involving human interaction. Particularly in mobile robotics this task is still challenging. Though there are already reliable and real-time capable approaches, they are usually computationally expensive. They either require GPUs or multiple CPU cores in order to work properly. Furthermore, some of the approaches are designed for special environments and sensor types, which reduces general applicability. In this work, we present a robust, generic and lightweight solution for real-time 3D person detection. Since our approach requires only a single CPU thread, it can be run as a background process and is suitable for smaller robotic systems. We demonstrate applicability to indoor and outdoor scenarios using different 3D sensor types separately. Moreover, we are able to show that the proposed method outperforms other state-of-the-art approaches, including a DCNN.
ER  - 

TY  - CONF
TI  - Pedestrian Feature Generation in Fish-Eye Images via Adversary
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2007
EP  - 2012
AU  - Y. Qian
AU  - M. Yang
AU  - C. Wang
AU  - B. Wang
PY  - 2018
KW  - driver information systems
KW  - feature extraction
KW  - image classification
KW  - object detection
KW  - pedestrians
KW  - FSTN
KW  - pedestrian detection
KW  - pedestrian feature generation
KW  - advanced driver assistance systems
KW  - ADAS
KW  - training
KW  - fish eye spatial transformer network
KW  - fish eye images
KW  - feature maps
KW  - robust
KW  - deformation
KW  - ETH
KW  - KITTI pedestrian datasets
KW  - adversarial network
KW  - fish eye pedestrian detectors
KW  - Detectors
KW  - Training
KW  - Feature extraction
KW  - Mathematical model
KW  - Cameras
KW  - Proposals
KW  - Convolution
DO  - 10.1109/ICRA.2018.8460565
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Pedestrian detection in fish-eye images is always an important problem in advanced driver assistance systems (ADAS). In conventional methods, pedestrian detectors will be trained using fish-eye images. But it is hard to collect and label enough fish-eye images manually. Therefore, a new strategy for training fish-eye pedestrian detectors using images from normal pedestrian datasets is proposed in this work. Concretely, Fish-eye Spatial Transformer Network (FSTN) is designed to generate pedestrian features in fish-eye images. FSTN aims to simulate distorted pedestrian features on the feature maps. Then the entire network is trained via adversary. FSTN is trained to generate examples which are difficult for pedestrian detectors to classify. So that the detectors are more robust to the deformation. FSTN can be embedded into state-of-the-art detectors easily. And the entire pedestrian detector, where the FSTN embedded, can be trained end to end via adversary. Moreover, experiments on ETH and KITTI pedestrian datasets show the slight accuracy improvement of pedestrian detection in fish-eye images using adversarial network compared with conventional methods.
ER  - 

TY  - CONF
TI  - Eye on You: Fusing Gesture Data from Depth Camera and Inertial Sensors for Person Identification
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2021
EP  - 2026
AU  - W. Chang
AU  - C. Wu
AU  - R. Y. Tsai
AU  - K. C. Lin
AU  - Y. Tseng
PY  - 2018
KW  - biometrics (access control)
KW  - cameras
KW  - gesture recognition
KW  - image fusion
KW  - EOY
KW  - asynchronous timing
KW  - coordinate calibration
KW  - environmental constraints
KW  - IoT applications
KW  - person identification
KW  - gesture data
KW  - fusion algorithms
KW  - inertial measurement unit
KW  - wearable sensors
KW  - 3D depth camera
KW  - data fusion approach
KW  - Eye On You
KW  - remote PID
KW  - reliable PID
KW  - recognition rate
KW  - Skeleton
KW  - Cameras
KW  - Sensors
KW  - Correlation
KW  - Iris recognition
KW  - Feature extraction
KW  - Motion segmentation
DO  - 10.1109/ICRA.2018.8462924
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Person identification (PID) is a key issue in many IoT applications. It has long been studied and achieved by technologies such as RFID and face/fingerprint/iris recognition. These approaches, however, have their limitations due to environmental constraints (such as lighting and obstacles) or require close contact to specific devices. Therefore, their recognition rates highly depend on use scenarios. To enable reliable and remote PID, in this work, we present EOY (Eye On You)1, a data fusion approach that combines two kinds of sensors, a 3D depth camera and wearable sensors embedded with inertial measurement unit (IMU). Since these two kinds of data share common features, we are able to fuse them to conduct PID. Further, the result can be transferred to a mobile platform (such as robot) since we have less constraints on devices. To realize EOY, we develop fusion algorithms to address practical challenges, such as asynchronous timing and coordinate calibration. The experimental evaluation shows that EOY can achieve the recognition rate of 95% and is very robust even in crowded areas.
ER  - 

TY  - CONF
TI  - Human Motion Capture Using a Drone
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2027
EP  - 2033
AU  - X. Zhou
AU  - S. Liu
AU  - G. Pavlakos
AU  - V. Kumar
AU  - K. Daniilidis
PY  - 2018
KW  - calibration
KW  - cameras
KW  - image motion analysis
KW  - image reconstruction
KW  - image sensors
KW  - mobile robots
KW  - robot vision
KW  - motion capture systems
KW  - calibrated cameras
KW  - indoor environments
KW  - on-board RGB camera
KW  - autonomously flying drone
KW  - 3D human MoCap
KW  - drone-based system
KW  - human motion capture
KW  - consumer drone
KW  - motion reconstruction
KW  - reconstruction algorithm
KW  - Cameras
KW  - Drones
KW  - Two dimensional displays
KW  - Three-dimensional displays
KW  - Image reconstruction
KW  - Tracking
KW  - Joints
DO  - 10.1109/ICRA.2018.8462830
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Current motion capture (MoCap) systems generally require markers and multiple calibrated cameras, which can be used only in constrained environments. In this work we introduce a drone-based system for 3D human MoCap. The system only needs an autonomously flying drone with an on-board RGB camera and is usable in various indoor and outdoor environments. A reconstruction algorithm is developed to recover full-body motion from the video recorded by the drone. We argue that, besides the capability of tracking a moving subject, a flying drone also provides fast varying viewpoints, which is beneficial for motion reconstruction. We evaluate the accuracy of the proposed system using our new DroCap dataset and also demonstrate its applicability for MoCap in the wild using a consumer drone.
ER  - 

TY  - CONF
TI  - Navigating Occluded Intersections with Autonomous Vehicles Using Deep Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2034
EP  - 2039
AU  - D. Isele
AU  - R. Rahimi
AU  - A. Cosgun
AU  - K. Subramanian
AU  - K. Fujimura
PY  - 2018
KW  - learning systems
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - road vehicles
KW  - autonomous vehicles
KW  - unsignaled intersections
KW  - Deep RL
KW  - intersection handling problem
KW  - deep reinforcement learning system
KW  - occluded intersections
KW  - active sensing behaviors
KW  - Autonomous vehicles
KW  - Automobiles
KW  - Machine learning
KW  - Safety
KW  - Navigation
KW  - Learning (artificial intelligence)
DO  - 10.1109/ICRA.2018.8461233
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Providing an efficient strategy to navigate safely through unsignaled intersections is a difficult task that requires determining the intent of other drivers. We explore the effectiveness of Deep Reinforcement Learning to handle intersection problems. Using recent advances in Deep RL, we are able to learn policies that surpass the performance of a commonly-used heuristic approach in several metrics including task completion time and goal success rate and have limited ability to generalize. We then explore a system's ability to learn active sensing behaviors to enable navigating safely in the case of occlusions. Our analysis, provides insight into the intersection handling problem, the solutions learned by the network point out several shortcomings of current rule-based methods, and the failures of our current deep reinforcement learning system point to future research directions.
ER  - 

TY  - CONF
TI  - Autonomous Vehicle Navigation in Rural Environments Without Detailed Prior Maps
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2040
EP  - 2047
AU  - T. Ort
AU  - L. Paull
AU  - D. Rus
PY  - 2018
KW  - collision avoidance
KW  - least squares approximations
KW  - mobile robots
KW  - recursive filters
KW  - robot vision
KW  - sensors
KW  - prior maps
KW  - positive societal impact
KW  - autonomous vehicle navigating
KW  - recursive filtering approach
KW  - navigate road networks
KW  - least-squares residual approach
KW  - vehicle frame
KW  - sensor-based perception system
KW  - global navigation
KW  - sparse topological maps
KW  - mapless driving framework
KW  - autonomous navigation
KW  - autonomous driving technology
KW  - transmit detailed maps
KW  - urban areas
KW  - rural environments
KW  - autonomous vehicle navigation
KW  - Roads
KW  - Navigation
KW  - Autonomous vehicles
KW  - Trajectory
KW  - Robot sensing systems
KW  - Reliability
DO  - 10.1109/ICRA.2018.8460519
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - State-of-the-art autonomous driving systems rely heavily on detailed and highly accurate prior maps. However, outside of small urban areas, it is very challenging to build, store, and transmit detailed maps since the spatial scales are so large. Furthermore, maintaining detailed maps of large rural areas can be impracticable due to the rapid rate at which these environments can change. This is a significant limitation for the widespread applicability of autonomous driving technology, which has the potential for an incredibly positive societal impact. In this paper, we address the problem of autonomous navigation in rural environments through a novel mapless driving framework that combines sparse topological maps for global navigation with a sensor-based perception system for local navigation. First, a local navigation goal within the sensor view of the vehicle is chosen as a waypoint leading towards the global goal. Next, the local perception system generates a feasible trajectory in the vehicle frame to reach the waypoint while abiding by the rules of the road for the segment being traversed. These trajectories are updated to remain in the local frame using the vehicle's odometry and the associated uncertainty based on the least-squares residual and a recursive filtering approach, which allows the vehicle to navigate road networks reliably, and at high speed, without detailed prior maps. We demonstrate the performance of the system on a full-scale autonomous vehicle navigating in a challenging rural environment and benchmark the system on a large amount of collected data.
ER  - 

TY  - CONF
TI  - Design of an Autonomous Racecar: Perception, State Estimation and System Integration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2048
EP  - 2055
AU  - M. I. Valls
AU  - H. F. C. Hendrikx
AU  - V. J. F. Reijgwart
AU  - F. V. Meier
AU  - I. Sa
AU  - R. Dubé
AU  - A. Gawel
AU  - M. Bürki
AU  - R. Siegwart
PY  - 2018
KW  - mobile robots
KW  - road vehicles
KW  - state estimation
KW  - modular redundant sub-systems
KW  - lateral accelerations
KW  - longitudinal accelerations
KW  - flüela driverless
KW  - onboard sensing
KW  - Formula Student Driverless competition
KW  - system integration
KW  - autonomous racecar
KW  - Automobiles
KW  - State estimation
KW  - Robot sensing systems
KW  - Current measurement
KW  - Laser radar
KW  - Wheels
KW  - Global Positioning System
DO  - 10.1109/ICRA.2018.8462829
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces jlüela driverless: the first autonomous racecar to win a Formula Student Driverless competition. In this competition, among other challenges, an autonomous racecar is tasked to complete 10 laps of a previously unknown racetrack as fast as possible and using only onboard sensing and computing. The key components of flüela's design are its modular redundant sub-systems that allow robust performance despite challenging perceptual conditions or partial system failures. The paper presents the integration of key components of our autonomous racecar, i.e., system design, EKF-based state estimation, LiDAR-based perception, and particle filter-based SLAM. We perform an extensive experimental evaluation on real-world data, demonstrating the system's effectiveness by outperforming the next-best ranking team by almost half the time required to finish a lap. The autonomous racecar reaches lateral and longitudinal accelerations comparable to those achieved by experienced human drivers.
ER  - 

TY  - CONF
TI  - Dynamic Occupancy Grid Prediction for Urban Autonomous Driving: A Deep Learning Approach with Fully Automatic Labeling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2056
EP  - 2063
AU  - S. Hoermann
AU  - M. Bach
AU  - K. Dietmayer
PY  - 2018
KW  - Bayes methods
KW  - convolution
KW  - feedforward neural nets
KW  - filtering theory
KW  - intelligent transportation systems
KW  - mobile robots
KW  - Monte Carlo methods
KW  - road traffic
KW  - time series
KW  - traffic engineering computing
KW  - unsupervised learning
KW  - complex interactions
KW  - dynamic occupancy grid prediction
KW  - urban autonomous driving
KW  - deep learning approach
KW  - long-term situation prediction
KW  - intelligent vehicles
KW  - complex downtown scenarios
KW  - multiple road users
KW  - motor vehicles
KW  - Bayesian filtering technique
KW  - environment representation
KW  - machine learning
KW  - deep convolutional neural network
KW  - spatially distributed velocity estimates
KW  - raw data sequence
KW  - input time series
KW  - multiple sensors
KW  - convolutional neural networks
KW  - road user interaction
KW  - pixel-wise balancing
KW  - static cells
KW  - dynamic cells
KW  - unsupervised learning character
KW  - pedestrians
KW  - bikes
KW  - distributed velocity estimation
KW  - Monte-Carlo simulation
KW  - Vehicle dynamics
KW  - Machine learning
KW  - Sensor fusion
KW  - Roads
KW  - Time series analysis
KW  - Laser radar
DO  - 10.1109/ICRA.2018.8460874
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Long-term situation prediction plays a crucial role for intelligent vehicles. A major challenge still to overcome is the prediction of complex downtown scenarios with multiple road users, e.g., pedestrians, bikes, and motor vehicles, interacting with each other. This contribution tackles this challenge by combining a Bayesian filtering technique for environment representation, and machine learning as long-term predictor. More specifically, a dynamic occupancy grid map is utilized as input to a deep convolutional neural network. This yields the advantage of using spatially distributed velocity estimates from a single time step for prediction, rather than a raw data sequence, alleviating common problems dealing with input time series of multiple sensors. Furthermore, convolutional neural networks have the inherent characteristic of using context information, enabling the implicit modeling of road user interaction. Pixel-wise balancing is applied in the loss function counteracting the extreme imbalance between static and dynamic cells. One of the major advantages is the unsupervised learning character due to fully automatic label generation. The presented algorithm is trained and evaluated on multiple hours of recorded sensor data and compared to Monte-Carlo simulation. Experiments show the ability to model complex interactions.
ER  - 

TY  - CONF
TI  - Realtime Vehicle and Pedestrian Tracking for Didi Udacity Self-Driving Car Challenge
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2064
EP  - 2069
AU  - A. Buyval
AU  - A. Gabdullin
AU  - R. Mustafin
AU  - I. Shimchik
PY  - 2018
KW  - image fusion
KW  - object tracking
KW  - optical radar
KW  - pedestrians
KW  - road vehicles
KW  - traffic engineering computing
KW  - road scene evaluation subsystem
KW  - vehicle tracking
KW  - image processing
KW  - LIDAR processing
KW  - pedestrian tracking
KW  - DiDi-Udacity Self-Driving Challenge datasets
KW  - frequency 25.0 Hz
KW  - Radar tracking
KW  - Laser radar
KW  - Cameras
KW  - Three-dimensional displays
KW  - Sensor fusion
DO  - 10.1109/ICRA.2018.8460913
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The efficiency and execution time of a road scene evaluation subsystem directly influences a self-driving car's control effectiveness. This article presents a novel approach to fuse data from various sensors (camera, LIDAR, radar, IMU) for pedestrian and vehicle tracking. Our approach, thanks to modern methods of image processing and power of GPU for LIDAR processing, achieves 25Hz update frequency for tracking. The system has been tested on the DiDi-Udacity Self-Driving Challenge datasets.
ER  - 

TY  - CONF
TI  - End-to-End Race Driving with Deep Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2070
EP  - 2075
AU  - M. Jaritz
AU  - R. de Charette
AU  - M. Toromanoff
AU  - E. Perot
AU  - F. Nashashibi
PY  - 2018
KW  - automobiles
KW  - cameras
KW  - computer games
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - traffic engineering computing
KW  - deep reinforcement learning
KW  - mediated perception
KW  - object recognition
KW  - scene understanding
KW  - learning strategies
KW  - RGB image
KW  - forward facing camera
KW  - car control
KW  - road structures
KW  - end-to-end race driving
KW  - reinforcement learning algorithm
KW  - legal speed limits
KW  - asynchronous actor critic framework
KW  - rally game
KW  - temperature 3.0 C
KW  - Automobiles
KW  - Training
KW  - Brakes
KW  - Games
KW  - Roads
KW  - Physics
KW  - Computer architecture
DO  - 10.1109/ICRA.2018.8460934
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present research using the latest reinforcement learning algorithm for end-to-end driving without any mediated perception (object recognition, scene understanding). The newly proposed reward and learning strategies lead together to faster convergence and more robust driving using only RGB image from a forward facing camera. An Asynchronous Actor Critic (A3C) framework is used to learn the car control in a physically and graphically realistic rally game, with the agents evolving simultaneously on tracks with a variety of road structures (turns, hills), graphics (seasons, location) and physics (road adherence). A thorough evaluation is conducted and generalization is proven on unseen tracks and using legal speed limits. Open loop tests on real sequences of images show some domain adaption capability of our method.
ER  - 

TY  - CONF
TI  - Scalable Decision Making with Sensor Occlusions for Autonomous Driving
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2076
EP  - 2081
AU  - M. Bouton
AU  - A. Nakhaei
AU  - K. Fujimura
AU  - M. J. Kochenderfer
PY  - 2018
KW  - collision avoidance
KW  - decision making
KW  - Markov processes
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - road safety
KW  - road vehicles
KW  - road users
KW  - scalable decision making
KW  - sensor occlusions
KW  - POMDP solution techniques
KW  - optimal avoidance strategy
KW  - decomposition method
KW  - computational cost
KW  - partially observable Markov decision process
KW  - robust navigation
KW  - autonomous driving
KW  - Automobiles
KW  - Uncertainty
KW  - Roads
KW  - Acceleration
KW  - Autonomous vehicles
KW  - Approximation algorithms
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8460914
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous driving in urban areas requires avoiding other road users with only partial observability of the environment. Observations are only partial because obstacles can occlude the field of view of the sensors. The problem of robust and efficient navigation under uncertainty can be framed as a partially observable Markov decision process (POMDP). In order to bypass the computational cost of scaling the formulation to avoiding multiple road users, this paper demonstrates a decomposition method that leverages the optimal avoidance strategy for a single user. We evaluate the performance of two POMDP solution techniques augmented with the decomposition method for scenarios involving a pedestrian crosswalk and an intersection.
ER  - 

TY  - CONF
TI  - Situation Assessment for Planning Lane Changes: Combining Recurrent Models and Prediction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2082
EP  - 2088
AU  - O. Scheel
AU  - L. Schwarz
AU  - N. Navab
AU  - F. Tombari
PY  - 2018
KW  - automobiles
KW  - driver information systems
KW  - intelligent transportation systems
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - prediction theory
KW  - recurrent neural nets
KW  - road safety
KW  - road traffic
KW  - road traffic control
KW  - fully autonomous cars
KW  - complex scenes
KW  - dynamic scenes
KW  - car following scenarios
KW  - situation assessment algorithm
KW  - lane changing
KW  - recurrent models
KW  - driver-assistance systems
KW  - bidirectional recurrent neural network
KW  - intelligent driver model
KW  - lane changes planning
KW  - maneuvers planning
KW  - driving situations classification
KW  - deep learning architecture
KW  - long short-term memory units
KW  - Automobiles
KW  - Planning
KW  - Machine learning
KW  - Predictive models
KW  - Prediction algorithms
KW  - Autonomous automobiles
DO  - 10.1109/ICRA.2018.8462838
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the greatest challenges towards fully autonomous cars is the understanding of complex and dynamic scenes. Such understanding is needed for planning of maneuvers, especially those that are particularly frequent such as lane changes. While in recent years advanced driver-assistance systems have made driving safer and more comfortable, these have mostly focused on car following scenarios, and less on maneuvers involving lane changes. In this work we propose a situation assessment algorithm for classifying driving situations with respect to their suitability for lane changing. For this, we propose a deep learning architecture based on a Bidirectional Recurrent Neural Network, which uses Long Short-Term Memory units, and integrates a prediction component in the form of the Intelligent Driver Model. We prove the feasibility of our algorithm on the publicly available NGSIM datasets, where we outperform existing methods.
ER  - 

TY  - CONF
TI  - Design and Analysis of a Novel Underwater Glider - RoBuoy
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2089
EP  - 2094
AU  - T. Ranganathan
AU  - S. Aravazhi
AU  - S. Mishra
AU  - A. Thondiyath
PY  - 2018
KW  - autonomous underwater vehicles
KW  - design engineering
KW  - mathematical analysis
KW  - mechatronics
KW  - mobile robots
KW  - oceanographic equipment
KW  - variable buoyancy method
KW  - autonomous underwater vehicles
KW  - underwater robots
KW  - mechatronic system
KW  - underwater gliders RoBuoy
KW  - metallic bellows
KW  - integrated mathematical model
KW  - wings
KW  - open loop performance
KW  - power efficient
KW  - actuated metallic bellows
KW  - parts fouling
KW  - optimized dimensions
KW  - Actuators
KW  - Buoyancy
KW  - Bellows
KW  - Surges
KW  - Pistons
KW  - Unmanned underwater vehicles
KW  - Prototypes
DO  - 10.1109/ICRA.2018.8462921
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Underwater gliders are special class of autonomous underwater vehicles (AUVs) proven to be power efficient with better range and endurance compared to the conventional underwater robots. Most of the existing underwater gliders use `change of mass' based variable buoyancy (VB) method in which the overall system architecture and construction are complex. A novel underwater glider RoBuoy based on the `change of volume' concept of variable buoyancy method is presented here. RoBuoy uses actuated metallic bellows to change the volume which makes the system simple and modular in construction without any compromise in the performance. It uses minimal number of parts compared to the existing gliders which reduces the overall complexity of the system. Also, most of the conventional gliders use the external fluid for its working which may result in corrosion or fouling of parts and requires frequent maintenance. In the proposed glider, all the vital parts required for its working, apart from the sensing payloads are enclosed inside the hull, thereby increasing the durability. In this paper, a detailed design of RoBuoy is discussed with its possible modes of operation. An integrated mathematical model considering the individual dynamics of the actuator, hull/fuselage, and the wings has been developed and the open loop performance of the glider is studied at different input conditions. An experimental prototype has been designed and fabricated based on optimized dimensions, with the required mechatronic system. Experiments have been conducted and the results prove the feasibility of the concept.
ER  - 

TY  - CONF
TI  - Modeling Speed-, Load-, and Position-Dependent Friction Effects in Strain Wave Gears
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2095
EP  - 2102
AU  - A. Wahrburg
AU  - S. Klose
AU  - D. Clever
AU  - T. Groth
AU  - S. Moberg
AU  - J. Styrud
AU  - H. Ding
PY  - 2018
KW  - force control
KW  - friction
KW  - gears
KW  - industrial robots
KW  - position control
KW  - velocity control
KW  - strain wave gears
KW  - robotic joint
KW  - position-dependent friction effects
KW  - industrial robots
KW  - load-dependent friction effects
KW  - sensorless force control
KW  - speed-dependent friction effects
KW  - Friction
KW  - Load modeling
KW  - Torque
KW  - Gravity
KW  - Strain
KW  - Gears
KW  - Robots
DO  - 10.1109/ICRA.2018.8461043
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Strain wave gears are frequently used in small and medium size industrial robots. In order to describe and quantify friction effects in gearboxes of such type, a structurally simple, yet powerful model is proposed taking into account both speed-and load-dependent friction effects. Moreover, position-dependent disturbances in a robotic joint are considered. An identification procedure is presented that allows to separate the individual components of the model and identify them subsequently. The effectiveness of the model and identification procedure is validated using experimental data gathered from four different robotic joints of varying size. Furthermore, the benefits of improved friction modeling are shown by means of different applications, including smooth lead-through programming and sensorless force control.
ER  - 

TY  - CONF
TI  - Real-Time Identification of Robot Payload Using a Multirate Quaternion-Based Kalman Filter and Recursive Total Least-Squares
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2103
EP  - 2109
AU  - S. Farsoni
AU  - C. T. Landi
AU  - F. Ferraguti
AU  - C. Secchi
AU  - M. Bonfè
PY  - 2018
KW  - end effectors
KW  - industrial manipulators
KW  - Kalman filters
KW  - least squares approximations
KW  - recursive estimation
KW  - robot kinematics
KW  - least-squares process
KW  - multirate quaternion-based Kalman filter
KW  - recursive total least-squares
KW  - inertial parameters
KW  - rigid load
KW  - robot kinematics
KW  - inertial sensors
KW  - robot payload real-time identification
KW  - end-effector
KW  - industrial manipulator
KW  - Kalman filters
KW  - Quaternions
KW  - Robot kinematics
KW  - Service robots
KW  - Robot sensing systems
KW  - Estimation
DO  - 10.1109/ICRA.2018.8461167
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The paper describes an estimation and identification procedure that allows to reconstruct the inertial parameters of a rigid load attached to the end-effector of an industrial manipulator. In particular, the proposed method adopts a multirate quaternion-based Kalman filter, fusing measurements obtained from robot kinematics and inertial sensors at possibly different sampling frequencies, to estimate linear accelerations and angular velocities/accelerations of the load. Then, a recursive total least-squares (RTLS) process is executed to identify the load parameters. Both steps of the estimation and identification procedure are performed in real-time, without the need for offline post-processing of measured data.
ER  - 

TY  - CONF
TI  - Optimal Active Sensing with Process and Measurement Noise
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2118
EP  - 2125
AU  - M. Cognetti
AU  - P. Salaris
AU  - P. Robuffo Giordano
PY  - 2018
KW  - covariance matrices
KW  - eigenvalues and eigenfunctions
KW  - gradient methods
KW  - Kalman filters
KW  - mobile robots
KW  - noise measurement
KW  - nonlinear filters
KW  - observability
KW  - optimisation
KW  - path planning
KW  - Riccati equations
KW  - trajectory control
KW  - estimation algorithm
KW  - OG
KW  - nonnegligible process noise
KW  - largest eigenvalue
KW  - optimal active sensing
KW  - measurement noise
KW  - nonlinear differentially flat system
KW  - online gradient descent method
KW  - optimal trajectories
KW  - maximum estimation uncertainty
KW  - Kalman Filter
KW  - onboard sensors
KW  - observability gramian
KW  - inversely proportional
KW  - posteriori covariance matrix
KW  - continuous Riccati equation
KW  - unicycle robot
KW  - Robot sensing systems
KW  - Estimation
KW  - Trajectory
KW  - Eigenvalues and eigenfunctions
KW  - Observability
DO  - 10.1109/ICRA.2018.8460476
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The goal of this paper is to increase the estimation performance of an Extended Kalman Filter for a nonlinear differentially flat system by planning trajectories able to maximize the amount of information gathered by onboard sensors in presence of both process and measurement noises. In a previous work, we presented an online gradient descent method for planning optimal trajectories along which the smallest eigenvalue of the Observability Gramian (OG) is maximized. As the smallest eigenvalue of the OG is inversely proportional to the maximum estimation uncertainty, its maximization reduces the maximum estimation uncertainty of any estimation algorithm employed during motion. However, the OG does not consider the process noise that, instead, in several applications is far from being negligible. For this reason, this paper proposes a novel solution able to cope with non-negligible process noise: this is achieved by minimizing the largest eigenvalue of the a posteriori covariance matrix obtained by solving the Continuous Riccati Equation as a measure of the total available information. This minimization is expected to maximize the information gathered by the outputs while, at the same time, limiting as much as possible the negative effects of the process noise. We apply our method to a unicycle robot. The comparison between the novel method and the one of our previous work (which did not consider process noise) shows significant improvements in the obtained estimation accuracy.
ER  - 

TY  - CONF
TI  - Encoderless Gimbal Calibration of Dynamic Multi-Camera Clusters
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2126
EP  - 2133
AU  - C. L. Choi
AU  - J. Rebello
AU  - L. Koppel
AU  - P. Ganti
AU  - A. Das
AU  - S. L. Waslander
PY  - 2018
KW  - angular measurement
KW  - calibration
KW  - cameras
KW  - encoderless gimbal calibration
KW  - dynamic multiCamera Clusters
KW  - Dynamic Camera Clusters
KW  - multicamera systems
KW  - cameras
KW  - joint angle measurements
KW  - time-varying transformation
KW  - static camera
KW  - motor encoders
KW  - transformation chain
KW  - encoderless gimbal mechanism
KW  - online estimation
KW  - Cameras
KW  - Calibration
KW  - Robot vision systems
KW  - Estimation
KW  - Reluctance motors
KW  - Kinematics
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2018.8462920
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Dynamic Camera Clusters (DCCs) are multi-camera systems where one or more cameras are mounted on actuated mechanisms such as a gimbal. Existing methods for DCC calibration rely on joint angle measurements to resolve the time-varying transformation between the dynamic and static camera. This information is usually provided by motor encoders, however, joint angle measurements are not always readily available on off-the-shelf mechanisms. In this paper, we present an encoderless approach for DCC calibration which simultaneously estimates the kinematic parameters of the transformation chain as well as the unknown joint angles. We also demonstrate the integration of an encoderless gimbal mechanism with a state-of-the art VIO algorithm, and show the extensions required in order to perform simultaneous online estimation of the joint angles and vehicle localization state. The proposed calibration approach is validated both in simulation and on a physical DCC composed of a 2-DOF gimbal mounted on a UAV. Finally, we show the experimental results of the calibrated mechanism integrated into the OKVIS VIO package, and demonstrate successful online joint angle estimation while maintaining localization accuracy that is comparable to a standard static multi-camera configuration.
ER  - 

TY  - CONF
TI  - Stickman: Towards a Human Scale Acrobatic Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2134
EP  - 2140
AU  - M. T. Pope
AU  - S. Christensen
AU  - D. Christensen
AU  - A. Simeonov
AU  - G. Imahara
AU  - G. Niemeyer
PY  - 2018
KW  - humanoid robots
KW  - laser ranging
KW  - mobile robots
KW  - motion control
KW  - pendulums
KW  - gravity-driven pendulum launch
KW  - two degree of freedom robot
KW  - autonomous robot
KW  - mobile robot
KW  - acrobatic techniques
KW  - acrobatic capability
KW  - laser range-finder
KW  - somersaulting stunts
KW  - gymnastic arts
KW  - human scale acrobatic robot
KW  - stickman
KW  - Robot sensing systems
KW  - Angular velocity
KW  - Mathematical model
KW  - Aerodynamics
DO  - 10.1109/ICRA.2018.8462836
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Human performers have developed impressive acrobatic techniques over thousands of years of practicing the gymnastic arts. At the same time, robots have started to become more mobile and autonomous, and can begin to imitate these stunts in dramatic and informative ways. We present a simple two degree of freedom robot that uses a gravity-driven pendulum launch and produces a variety of somersaulting stunts. The robot uses an IMU and a laser range-finder to estimate its state mid-flight and actuates to change its motion both on and and off the pendulum. We discuss the dynamics of this behavior in a framework of acrobatic capability and present experimental results.
ER  - 

TY  - CONF
TI  - 3D Lidar-IMU Calibration Based on Upsampled Preintegrated Measurements for Motion Distortion Correction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2149
EP  - 2155
AU  - C. Le Gentil
AU  - T. Vidal-Calleja
AU  - S. Huang
PY  - 2018
KW  - calibration
KW  - cameras
KW  - image motion analysis
KW  - optical radar
KW  - optimisation
KW  - probability
KW  - sampling methods
KW  - stereo image processing
KW  - interpolated inertial measurements
KW  - lidar scan
KW  - lidar point-to-plane distances
KW  - upsampled preintegrated measurements
KW  - motion distortion correction
KW  - probabilistic framework
KW  - lidar-IMU sensing system
KW  - motion distortion
KW  - on-manifold optimisation
KW  - 3D lidar-IMU calibration
KW  - Laser radar
KW  - Calibration
KW  - Distortion
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Distortion measurement
KW  - Motion measurement
DO  - 10.1109/ICRA.2018.8460179
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a probabilistic framework to recover the extrinsic calibration parameters of a lidar-IMU sensing system. Unlike global-shutter cameras, lidars do not take single snapshots of the environment. Instead, lidars collect a succession of 3D-points generally grouped in scans. If these points are assumed to be expressed in a common frame, this becomes an issue when the sensor moves rapidly in the environment causing motion distortion. The fundamental idea of our proposed framework is to use preintegration over interpolated inertial measurements to characterise the motion distortion in each lidar scan. Moreover, by using a set of planes as a calibration target, the proposed method makes use of lidar point-to-plane distances to jointly calibrate and localise the system using on-manifold optimisation. The calibration does not rely on a predefined target as arbitrary planes are detected and modelled in the first lidar scan. Simulated and real data are used to show the effectiveness of the proposed method.
ER  - 

TY  - CONF
TI  - High-Precision Depth Estimation with the 3D LiDAR and Stereo Fusion
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2156
EP  - 2163
AU  - K. Park
AU  - S. Kim
AU  - K. Sohn
PY  - 2018
KW  - feedforward neural nets
KW  - optical radar
KW  - radar imaging
KW  - stereo image processing
KW  - LiDAR
KW  - compact convolution module
KW  - dense stereo depth information
KW  - sparse 3D LiDAR
KW  - deep convolutional neural network architecture
KW  - stereo fusion
KW  - high-precision depth estimation
KW  - off-the-shelf stereo algorithm
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Estimation
KW  - Computer architecture
KW  - Sensors
KW  - Reliability
KW  - Image color analysis
DO  - 10.1109/ICRA.2018.8461048
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a deep convolutional neural network (CNN) architecture for high-precision depth estimation by jointly utilizing sparse 3D LiDAR and dense stereo depth information. In this network, the complementary characteristics of sparse 3D LiDAR and dense stereo depth are simultaneously encoded in a boosting manner. Tailored to the LiDAR and stereo fusion problem, the proposed network differs from previous CNNs in the incorporation of a compact convolution module, which can be deployed with the constraints of mobile devices. As training data for the LiDAR and stereo fusion is rather limited, we introduce a simple yet effective approach for reproducing the raw KITTI dataset. The raw LiDAR scans are augmented by adapting an off-the-shelf stereo algorithm and a confidence measure. We evaluate the proposed network on the KITTI benchmark and data collected by our multi-sensor acquisition system. Experiments demonstrate that the proposed network generalizes across datasets and is significantly more accurate than various baseline approaches.
ER  - 

TY  - CONF
TI  - Sampled-Point Network for Classification of Deformed Building Element Point Clouds
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2164
EP  - 2169
AU  - J. Chen
AU  - Y. K. Cho
AU  - J. Ueda
PY  - 2018
KW  - disasters
KW  - feature extraction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - robot vision
KW  - object recognition
KW  - post-disaster urban areas
KW  - search-and-rescue robots
KW  - deformed building element point clouds
KW  - point network
KW  - synthetically-deformed object datasets
KW  - point sorting
KW  - point coordinates
KW  - classification network
KW  - deformed building elements
KW  - 3D class recognition
KW  - point cloud input
KW  - disaster relief operations
KW  - potentially-deformed objects
KW  - unstructured environments
KW  - point cloud data
KW  - 3D point cloud
KW  - physical site information
KW  - Three-dimensional displays
KW  - Strain
KW  - Object recognition
KW  - Deformable models
KW  - Machine learning
KW  - Feature extraction
KW  - Buildings
DO  - 10.1109/ICRA.2018.8461095
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Search-and-rescue (SAR) robots operating in post-disaster urban areas need to accurately identify physical site information to perform navigation, mapping and manipulation tasks. This can be achieved by acquiring a 3D point cloud of the environment and performing object recognition from the point cloud data. However, this task is complicated by the unstructured environments and potentially-deformed objects encountered during disaster relief operations. Current 3D object recognition methods rely on point cloud input acquired under suitable conditions and do not consider deformations such as outlier noise, bending and truncation. This work introduces a deep learning architecture for 3D class recognition from point clouds of deformed building elements. The classification network, consisting of stacked convolution and average pooling layers applied directly to point coordinates, was trained using point clouds sampled from a database of mesh models. The proposed method achieves robustness to input variability using point sorting, resampling, and rotation normalization techniques. Experimental results on synthetically-deformed object datasets show that the proposed method outperforms the conventional deep learning methods in terms of classification accuracy and computational efficiency.
ER  - 

TY  - CONF
TI  - Recognizing Objects in-the-Wild: Where do we Stand?
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2170
EP  - 2177
AU  - M. Reza Loghmani
AU  - B. Caputo
AU  - M. Vincze
PY  - 2018
KW  - cameras
KW  - image classification
KW  - image colour analysis
KW  - image representation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object recognition
KW  - robot vision
KW  - multiview object dataset
KW  - RGB-D camera
KW  - deep convolutional networks
KW  - Web images
KW  - robotic system
KW  - autonomous agents
KW  - good visual perceptual systems
KW  - robotic vision research communities
KW  - human-populated environments
KW  - robot vision
KW  - real-life robotic data
KW  - object classification
KW  - deep representations
KW  - object recognition algorithms
KW  - real-life application
KW  - mobile robot
KW  - Task analysis
KW  - Clutter
KW  - Visualization
KW  - Mobile robots
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/ICRA.2018.8460985
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The ability to recognize objects is an essential skill for a robotic system acting in human-populated environments. Despite decades of effort from the robotic and vision research communities, robots are still missing good visual perceptual systems, preventing the use of autonomous agents for realworld applications. The progress is slowed down by the lack of a testbed able to accurately represent the world perceived by the robot in-the-wild. In order to fill this gap, we introduce a large-scale, multi-view object dataset collected with an RGB-D camera mounted on a mobile robot. The dataset embeds the challenges faced by a robot in a real-life application and provides a useful tool for validating object recognition algorithms. Besides describing the characteristics of the dataset, the paper evaluates the performance of a collection of well-established deep convolutional networks on the new dataset and analyzes the transferability of deep representations from Web images to robotic data. Despite the promising results obtained with such representations, the experiments demonstrate that object classification with real-life robotic data is far from being solved. Finally, we provide a comparative study to analyze and highlight the open challenges in robot vision, explaining the discrepancies in the performance.
ER  - 

TY  - CONF
TI  - A Controlled-Delay Event Camera Framework for On-Line Robotics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2178
EP  - 2183
AU  - A. Glover
AU  - V. Vasco
AU  - C. Bartolozzi
PY  - 2018
KW  - cameras
KW  - humanoid robots
KW  - image sensors
KW  - mobile robots
KW  - robot vision
KW  - controlled-delay event camera framework
KW  - dynamic robotics
KW  - low latency response
KW  - high dynamic range
KW  - inherent compression
KW  - visual signal
KW  - real-time performance
KW  - off-line datasets
KW  - camera resolution
KW  - latency-free operation
KW  - event-driven framework
KW  - iCub robot
KW  - algorithm processing rate
KW  - actual event-rate
KW  - algorithm performance
KW  - Cameras
KW  - Robot vision systems
KW  - Delays
KW  - Corner detection
KW  - Visualization
DO  - 10.1109/ICRA.2018.8460541
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Event cameras offer many advantages for dynamic robotics due to their low latency response to motion, high dynamic range, and inherent compression of the visual signal. Many algorithms easily achieve real-time performance when testing on off-line datasets, however with an increase in camera resolution and applications on fast-moving robots, latency-free operation is not guaranteed. The event-rate is not constant, but is proportional to the amount of movement in the scene, or the velocity of the camera itself. Recently, algorithms have instead reported a maximum event-rate that can be achieved in real-time. In this paper we present the event-driven framework used on the iCub robot, which closes the loop between algorithm processing rate and the actual event-rate of the camera in order to smoothly control and limit the latency, while allowing the algorithm to degrade gracefully when large bursts of events occur. We show two algorithms that process events differently from each other and demonstrate the trade-off between latency and algorithm performance that the framework provides.
ER  - 

TY  - CONF
TI  - Gemsketch: Interactive Image-Guided Geometry Extraction from Point Clouds
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2184
EP  - 2191
AU  - M. Maghoumi
AU  - J. J. LaVioia
AU  - K. Desingh
AU  - O. Chadwicke Jenkins
PY  - 2018
KW  - feature extraction
KW  - interactive systems
KW  - solid modelling
KW  - multiple-view point clouds
KW  - cuboids
KW  - interactive system
KW  - interactive image-guided geometry extraction
KW  - gemsketch
KW  - Three-dimensional displays
KW  - Shape
KW  - Geometry
KW  - Solid modeling
KW  - Tools
KW  - Cameras
KW  - Data mining
DO  - 10.1109/ICRA.2018.8460532
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We introduce an interactive system for extracting the geometries of generalized cylinders and cuboids from single-or multiple-view point clouds. Our proposed method is intuitive and only requires the object's silhouettes to be traced by the user. Leveraging the user's perceptual understanding of what an object looks like, our proposed method is capable of extracting accurate models, even in the presence of occlusion, clutter or incomplete point cloud data, while preserving the original object's details and scale. We demonstrate the merits of our proposed method through a set of experiments on a public RGB-D dataset. We extracted 16 objects from the dataset using at most two views of each object. Our extracted models represent a high degree of visual similarity to the original objects. Further, we achieved a mean normalized Hausdorff distance of 5.66% when comparing our extracted models with the dataset's ground truths.
ER  - 

TY  - CONF
TI  - Where can i do this? Geometric Affordances from a Single Example with the Interaction Tensor
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2192
EP  - 2199
AU  - E. Ruiz
AU  - W. Mayol-Cuevas
PY  - 2018
KW  - computational geometry
KW  - feature extraction
KW  - image capture
KW  - image colour analysis
KW  - image representation
KW  - tensors
KW  - geometric affordance
KW  - interaction tensor
KW  - tensor field representation
KW  - bisector surface representation
KW  - surface points
KW  - directional vectors
KW  - cognitive robots
KW  - autonomous robots
KW  - RGB-D sensors
KW  - Tensile stress
KW  - Robots
KW  - Three-dimensional displays
KW  - Solid modeling
KW  - Task analysis
KW  - Shape
KW  - Tools
DO  - 10.1109/ICRA.2018.8462835
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces and evaluates a new tensor field representation to express the geometric affordance of one object relative to another, a key competence for Cognitive and Autonomous robots. We expand the bisector surface representation to one that is weight-driven and that retains the provenance of surface points with directional vectors. We also incorporate the notion of affordance keypoints which allow for faster decisions at a point of query and with a compact and straightforward descriptor. Using a single interaction example, we are able to generalize to previously-unseen scenarios; both synthetic and also real scenes captured with RGB-D sensors. Evaluations also include crowdsourcing comparisons that confirm the validity of our affordance proposals, which agree on average 84 % of the time with human judgments, that is 20-40 % better than the baseline methods.
ER  - 

TY  - CONF
TI  - A Low-Cost Navigation Strategy for Yield Estimation in Vineyards
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2200
EP  - 2205
AU  - G. Riggio
AU  - C. Fantuzzi
AU  - C. Secchi
PY  - 2018
KW  - agriculture
KW  - image colour analysis
KW  - image resolution
KW  - object detection
KW  - yield estimation
KW  - grape varieties
KW  - vineyard management
KW  - low-cost navigation strategy
KW  - navigation algorithm
KW  - grape pictures
KW  - low-cost autonomous system
KW  - RGB camera
KW  - RGB image processing
KW  - Navigation
KW  - Pipelines
KW  - Yield estimation
KW  - Cameras
KW  - Robot vision systems
KW  - Lasers
DO  - 10.1109/ICRA.2018.8462839
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Accurate yield estimation is very important for improving the vineyard management, the quality of the grapes and the health of the vines. The most common systems use RGB image processing for achieving a good estimation. In order to collect images, robots or farming vehicles can be equipped with a RGB camera. In this paper, we propose a low-cost autonomous system which can navigate through a vineyard while collecting grape pictures in order to provide a yield estimation. Our system uses only a laser scanner to detect the row and follows it until its end, then it navigates towards the next one, exploiting the knowledge of the vineyard. The navigation algorithm was tested both in simulation and in a real environment with good results. Furthermore, a yield estimation of two different grape varieties is presented.
ER  - 

TY  - CONF
TI  - Object Detection for Cattle Gait Tracking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2206
EP  - 2213
AU  - J. Gardenier
AU  - J. Underwood
AU  - C. Clark
PY  - 2018
KW  - convolution
KW  - dairy products
KW  - dairying
KW  - feature extraction
KW  - feedforward neural nets
KW  - gait analysis
KW  - image sampling
KW  - object detection
KW  - veterinary medicine
KW  - kinematic gait features
KW  - object detection
KW  - cattle gait tracking
KW  - health issue
KW  - locomotion score
KW  - widespread commercial adoption
KW  - sensor configuration
KW  - flight sensors
KW  - rotary milking dairy
KW  - lameness detection systems
KW  - cattle kinematics
KW  - CNN
KW  - cartesian space
KW  - Cows
KW  - Feature extraction
KW  - Kinematics
KW  - Laser radar
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Australia
DO  - 10.1109/ICRA.2018.8460523
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Lameness in cattle is a health issue where gait is modified to minimise pain. Cattle are currently visually assessed for locomotion score, which provides the degree of lameness for individual animals. This subjective method is costly in terms of labour, and its level of accuracy and ability to detect small changes in locomotion that is critical for early detection of lameness and associated intervention. Current automatic lameness detection systems found in literature have not yet met the ultimate goal of widespread commercial adoption. We present a sensor configuration to record cattle kinematics towards automatic lameness detection. This configuration features four Time of Flight sensors to view cattle from above and from one side as they exit an automatic rotary milking dairy. Two dimensional near infrared images sampled from 223 cows passing through the system were used to train a Faster R-CNN to detect hooves (F1-score = 0.90) and carpal/tarsal joints (Fl-score = 0.85). The depth images were used to project these detected key points into Cartesian space where they were tracked to obtain individual trajectories per limb. The results show that kinematic gait features can be successfully obtained as a first and important step towards objective, accurate, automatic lameness detection.
ER  - 

TY  - CONF
TI  - Routing Algorithms for Robot Assisted Precision Irrigation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2221
EP  - 2228
AU  - T. C. Thayer
AU  - S. Vougioukas
AU  - K. Goldberg
AU  - S. Carpin
PY  - 2018
KW  - computational complexity
KW  - graph theory
KW  - greedy algorithms
KW  - irrigation
KW  - mobile robots
KW  - orienteering problem
KW  - NP-hard
KW  - routing algorithms
KW  - robot assisted precision irrigation
KW  - temporal budget
KW  - possible motions
KW  - spatially distributed sites
KW  - battery charge
KW  - optimization problem
KW  - irrigation adjustments
KW  - robots navigate
KW  - commercial vineyard
KW  - Irrigation
KW  - Routing
KW  - Approximation algorithms
KW  - Robot sensing systems
KW  - Navigation
DO  - 10.1109/ICRA.2018.8461242
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When robots navigate through vineyards to perform irrigation adjustments, an optimization problem emerges whereby robots are tasked with performing adjustments having the highest cumulative outcome within a given temporal budget due to limited battery charge. To this end, the robot needs to reach a set of spatially distributed sites, and the specific structure of the vineyard imposes various constraints on possible motions. In this paper we first demonstrate that this type of orienteering problem remains NP-hard even for the restricted class of graphs associated with precision irrigation. Then, we devise and analyze two greedy heuristics informed by the problem we consider. Finally, these algorithms are evaluated on settings associated with a commercial vineyard and we show that our methods favorably compare to solutions proposed in the past.
ER  - 

TY  - CONF
TI  - Real-Time Semantic Segmentation of Crop and Weed for Precision Agriculture Robots Leveraging Background Knowledge in CNNs
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2229
EP  - 2235
AU  - A. Milioto
AU  - P. Lottes
AU  - C. Stachniss
PY  - 2018
KW  - agricultural machinery
KW  - agrochemicals
KW  - convolution
KW  - crops
KW  - feedforward neural nets
KW  - image colour analysis
KW  - image segmentation
KW  - industrial robots
KW  - robot vision
KW  - precision agriculture robots leveraging background knowledge
KW  - precision farming robots
KW  - CNN-based semantic segmentation
KW  - crop fields
KW  - sugar beet plants
KW  - RGB data
KW  - vegetation indexes
KW  - real-time semantic segmentation
KW  - trigger weeding actions
KW  - agricultural robot operator
KW  - Agriculture
KW  - Vegetation mapping
KW  - Semantics
KW  - Real-time systems
KW  - Soil
KW  - Indexes
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460962
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Precision farming robots, which target to reduce the amount of herbicides that need to be brought out in the fields, must have the ability to identify crops and weeds in real time to trigger weeding actions. In this paper, we address the problem of CNN-based semantic segmentation of crop fields separating sugar beet plants, weeds, and background solely based on RGB data. We propose a CNN that exploits existing vegetation indexes and provides a classification in real time. Furthermore, it can be effectively re-trained to so far unseen fields with a comparably small amount of training data. We implemented and thoroughly evaluated our system on a real agricultural robot operating in different fields in Germany and Switzerland. The results show that our system generalizes well, can operate at around 20 Hz, and is suitable for online operation in the fields.
ER  - 

TY  - CONF
TI  - Robustly Adjusting Indoor Drip Irrigation Emitters with the Toyota HSR Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2236
EP  - 2243
AU  - R. Berenstein
AU  - R. Fox
AU  - S. McKinley
AU  - S. Carpin
AU  - K. Goldberg
PY  - 2018
KW  - computer vision
KW  - grippers
KW  - irrigation
KW  - manipulators
KW  - mobile robots
KW  - computer vision
KW  - build-in hand camera
KW  - modular Emitter Localization Device
KW  - lightweight Emitter Localization Device
KW  - Toyota HSR mobile manipulator robot
KW  - commercial buildings
KW  - indoor plants
KW  - Toyota HSR robot
KW  - indoor drip irrigation emitters
KW  - emitter axis
KW  - gripper axis
KW  - Cameras
KW  - Irrigation
KW  - Robot vision systems
KW  - Manipulators
KW  - Grippers
DO  - 10.1109/ICRA.2018.8460969
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Indoor plants in homes and commercial buildings such as malls, offices, airports, and hotels, can benefit from precision irrigation to maintain healthy growth and reduce water consumption. As active valves are too costly, and ongoing precise manual adjustment of drip emitters is impractical, we explore how the Toyota HSR mobile manipulator robot can autonomously adjust low-cost passive emitters. To provide sufficient accuracy for gripper alignment, we designed a lightweight, modular Emitter Localization Device (ELD) with cameras and LEDs that can be non-invasively mounted on the arm. This paper presents details of the design, algorithms, and experiments with adjusting emitters using a two-phase procedure: (1) aligning the robot base using the build-in hand camera, and (2) aligning the gripper axis with the emitter axis using the ELD. We report success rates and sensitivity analysis to tune computer vision parameters and joint motor gains. Experiments suggest that emitters can be adjusted with 95 % success rate in approximately 20 seconds.
ER  - 

TY  - CONF
TI  - Preliminary Study of Twisted String Actuation Through a Conduit Toward Soft and Wearable Actuation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2260
EP  - 2265
AU  - B. Suthar
AU  - M. Usman
AU  - H. Seong
AU  - I. Gaponov
AU  - J. Ryu
PY  - 2018
KW  - actuators
KW  - cables (mechanical)
KW  - friction
KW  - lubrication
KW  - mobile robots
KW  - wearable robots
KW  - twisted string actuation
KW  - conduit
KW  - wearable actuation
KW  - TSAs
KW  - modern engineering
KW  - robotic applications
KW  - conventional cable sliding transmission
KW  - lubricated twisting
KW  - friction
KW  - mobile robots
KW  - Friction
KW  - Force
KW  - Mathematical model
KW  - Cable shielding
KW  - DC motors
KW  - Power cables
KW  - Robots
DO  - 10.1109/ICRA.2018.8460589
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Twisted string actuators (TSAs) are gaining popularity in modern engineering and robotic applications. However, in conventional actuators of this type, the twisted part of the string should not be in contact with any surfaces or objects because this may interfere with the propagation of twisting. This imposes significant constraint on potential applications of TSAs. In this paper, we investigated the feasibility of using TSAs inside conduit and demonstrated that the twists of the string can be fully propagated through the sheath and that consistent periodic behavior of the twisted string can be achieved. In addition, we investigated input-output position and force characteristics of TSAs for various deflection angles of the conduit, effect of lubrication on transmission efficiency, and compared it with conventional cable sliding transmission. We found that TSA has higher transmission efficiency than sliding due to decreased friction between the string and conduit, which is further improved by lubrication. We have managed to achieve 85 % of force transmission efficiency for the case of lubricated twisting, as opposed to the 71.74% for lubricated sliding.
ER  - 

TY  - CONF
TI  - Stiffness Decomposition and Design Optimization of Under-Actuated Tendon-Driven Robotic Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2266
EP  - 2272
AU  - M. Kim
AU  - J. Park
AU  - J. Kim
AU  - M. Kim
PY  - 2018
KW  - compliant mechanisms
KW  - design engineering
KW  - elasticity
KW  - manipulator dynamics
KW  - motion control
KW  - stiffness decomposition
KW  - design optimization
KW  - systematic design framework
KW  - under-actuated tendon-driven robotic systems
KW  - free motion
KW  - contact task
KW  - configuration space
KW  - UATD robotic systems
KW  - actuation
KW  - active tendons
KW  - un-actuated space
KW  - passive compliance
KW  - UATD robotic finger
KW  - contact wrench
KW  - Robots
KW  - Tendons
KW  - Pulleys
KW  - Routing
KW  - Springs
KW  - Grasping
KW  - Actuators
DO  - 10.1109/ICRA.2018.8462906
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a novel systematic design framework for general under-actuated tendon-driven (UATD) robotic systems to exhibit desired behaviors both during the free motion and the contact task. For this, we propose stiffness decomposition, which enables us to completely decompose the configuration space of the UATD robotic systems into the actuated space (with full actuation via active tendons) and the un-actuated space (with no actuation, only with passive compliance and contact wrench). The behavior in the actuated space is then fully-controllable, thus, the attainment of the desired behaviors, particularly those during the contact task, hinges upon that in the un-actuated space. For this, relying on the stiffness decomposition, we optimize the design parameters (e.g., tendon routing, pulley radius, passive compliance, etc.) to ensure the deformation in the un-actuated space as directional (e.g., for adaptive grasping) and minimized (e.g., pushing with posture maintained) for different contact wrench sets as possible, while also rendering the free motion to be as compliant and backdrivable as possible. The presented framework is then applied to design a UATD robotic finger and experimentally verified with the robot able to mimic the behavior of human index finger both during the free motion and pinch-pushing.
ER  - 

TY  - CONF
TI  - Design and Development of Effective Transmission Mechanisms on a Tendon Driven Hand Orthosis for Stroke Patients
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2281
EP  - 2287
AU  - S. Park
AU  - L. Weber
AU  - L. Bishop
AU  - J. Stein
AU  - M. Ciocarlie
PY  - 2018
KW  - biomechanics
KW  - fatigue
KW  - orthotics
KW  - patient rehabilitation
KW  - three-dimensional printing
KW  - 3D-printed artificial finger
KW  - moment arms
KW  - fatigue
KW  - spasticity
KW  - wearable tendon-driven hand orthosis
KW  - exoskeletons
KW  - transmission efficiency
KW  - low-profile design
KW  - effective transmission mechanisms
KW  - stroke patients
KW  - joint angle characteristics
KW  - finger joints
KW  - effective force transmission
KW  - Tendons
KW  - Force
KW  - Exoskeletons
KW  - Robots
KW  - Electron tubes
KW  - Task analysis
KW  - Thumb
DO  - 10.1109/ICRA.2018.8461069
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Tendon-driven hand orthoses have advantages over exoskeletons with respect to wearability and safety because of their low-profile design and ability to fit a range of patients without requiring custom joint alignment. However, no existing study on a wearable tendon-driven hand orthosis for stroke patients presents evidence that such devices can overcome spasticity given repeated use and fatigue, or discusses transmission efficiency. In this study, we propose two designs that provide effective force transmission by increasing moment arms around finger joints. We evaluate the designs with geometric models and experiment using a 3D-printed artificial finger to find force and joint angle characteristics of the suggested structures. We also perform clinical tests with stroke patients to demonstrate the feasibility of the designs. The testing supports the hypothesis that the proposed designs efficiently elicit extension of the digits in patients with spasticity as compared to existing baselines.
ER  - 

TY  - CONF
TI  - Discovering a Library of Rhythmic Gaits for Spherical Tensegrity Locomotion
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2290
EP  - 2295
AU  - C. Rennie
AU  - K. E. Bekris
PY  - 2018
KW  - Bayes methods
KW  - gait analysis
KW  - Gaussian processes
KW  - legged locomotion
KW  - Monte Carlo methods
KW  - motion control
KW  - pattern classification
KW  - regression analysis
KW  - significant control challenges
KW  - high-dimensionality
KW  - nonlinear nature
KW  - effective parameterization
KW  - rhythmic gaits
KW  - periodic control signals
KW  - rhythmic control signals
KW  - gait parameters
KW  - parameter space
KW  - Bayesian Optimization
KW  - parameter sample
KW  - gait discovery process
KW  - spherical tensegrity locomotion
KW  - tensegrity robots
KW  - rigid elements
KW  - soft elements
KW  - locomotion capabilities
KW  - central pattern generators
KW  - Gaussian Process regression model
KW  - Robots
KW  - Optimization
KW  - Aerospace electronics
KW  - Bayes methods
KW  - Shape
KW  - Angular velocity
KW  - Libraries
DO  - 10.1109/ICRA.2018.8460873
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Tensegrity robots, which combine both rigid and soft elements, provide exciting new locomotion capabilities but introduce significant control challenges given their high-dimensionality and non-linear nature. This work first defines an effective parameterization of a spherical tensegrity for generating rhythmic gaits based on Central Pattern Generators (cp G). This allows the definition of periodic and rhythmic control signals, while exposing only five gait parameters. Then, this work proposes a framework for optimizing such gaits by exploring the parameter space through Bayesian Optimization on an underlying Gaussian Process regression model. The objective is to provide gaits that allow the platform to move along different directions with high velocity. Additionally, kNN binary classifiers are trained to estimate whether a parameter sample will result in an effective gait. The classification biases the sampling toward subspaces likely to yield effective gaits. An asynchronous communication layer is defined between the optimization and classification processes. The proposed gait discovery process is shown to efficiently optimize the parameters of gaits defined given the novel CPG architecture and outperforms less holistic approaches and Monte Carlo sampling.
ER  - 

TY  - CONF
TI  - Line-Based Global Localization of a Spherical Camera in Manhattan Worlds
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2296
EP  - 2303
AU  - T. Goto
AU  - S. Pathak
AU  - Y. Ji
AU  - H. Fujii
AU  - A. Yamashita
AU  - H. Asama
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - gradient methods
KW  - Hough transforms
KW  - SLAM (robots)
KW  - 3D line map
KW  - complicated six degrees of freedom search
KW  - 2D line information
KW  - line-based global localization
KW  - spherical Hough representation
KW  - 6 DoF localization process
KW  - Manhattan world assumption
KW  - 3D-2D line correspondences
KW  - spherical-gradient filtering
KW  - spherical image
KW  - indoor environment
KW  - camera position
KW  - global environmental information
KW  - spherical camera
KW  - indoor localization
KW  - indoor spaces
KW  - Cameras
KW  - Three-dimensional displays
KW  - Image edge detection
KW  - Robustness
KW  - Robot vision systems
KW  - Solid modeling
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460920
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Localization is an important task for mobile service robots in indoor spaces. In this research, we propose a novel technique for indoor localization using a spherical camera. Spherical cameras can obtain a complete view of the surroundings allowing the use of global environmental information. We take advantage of this in order to estimate camera position and the orientation with respect to a known 3D line map of an indoor environment, using a single image. We robustly extract 2D line information from the spherical image via spherical-gradient filtering and match it to 3D line information in the line map. Our method requires no information about the 3D-2D line correspondences. In order to avoid a complicated six degrees of freedom (6 DoF) search for position and orientation, we use a Manhattan world assumption to decompose the line information in the image. The 6 DoF localization process is divided into two phases. First, we estimate the orientation by extracting the three principle directions from the image. Then, the position is estimated by robustly matching the distribution of lines between the image and the 3D model via a spherical Hough representation. This decoupled search can robustly localize a spherical camera using a single image, as we demonstrate experimentally.
ER  - 

TY  - CONF
TI  - Optimizing Placement and Number of RF Beacons to Achieve Better Indoor Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2304
EP  - 2311
AU  - R. Falque
AU  - M. Patel
AU  - J. Biehl
PY  - 2018
KW  - indoor radio
KW  - mobility management (mobile radio)
KW  - optimisation
KW  - RF beacons
KW  - RF signal propagation
KW  - indoor infrastructure
KW  - cost function
KW  - Radio Frequency beacons
KW  - indoor localization
KW  - Sensors
KW  - Optimization
KW  - Wireless sensor networks
KW  - Lattices
KW  - Genetic algorithms
KW  - Radio frequency
KW  - RF signals
KW  - Indoor localization
KW  - Beacon deployment
KW  - Bluetooth Low Energy (BLE)
KW  - k-Coverage
KW  - Wireless sensor networks (WSN)
DO  - 10.1109/ICRA.2018.8460202
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we propose a novel solution to optimize the deployment of Radio Frequency (RF) beacons for the purpose of indoor localization. We propose a system that optimizes both the number of beacons and their placement in a given environment. We propose a novel cost-function, called CovBsm, that allows to simultaneously optimize the 3-coverage while maximizing the beacon spreading. Using this cost function, we propose a framework that maximize both the number of beacons and their placement in a given environment. The proposed solution accounts for the indoor infrastructure and its influence on the RF signal propagation by embedding a realistic simulator into the optimization process.
ER  - 

TY  - CONF
TI  - Robust Target-Relative Localization with Ultra-Wideband Ranging and Communication
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2312
EP  - 2319
AU  - T. Nguyen
AU  - A. Hanif Zaini
AU  - C. Wang
AU  - K. Guo
AU  - L. Xie
PY  - 2018
KW  - aircraft communication
KW  - aircraft navigation
KW  - altimeters
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - Kalman filters
KW  - nonlinear filters
KW  - position control
KW  - sensors
KW  - target tracking
KW  - ultra wideband communication
KW  - quadcopter
KW  - autonomous flight
KW  - Extended Kalman Filter
KW  - UWB ranging measurements
KW  - onboard sensors
KW  - altimeters
KW  - optical flow
KW  - UWB based communication capability
KW  - robust target-relative localization
KW  - ultra-wideband ranging communication
KW  - Ultra-wideband ranging sensors
KW  - Distance measurement
KW  - Sensors
KW  - Antenna measurements
KW  - Robustness
KW  - Iron
KW  - Robots
KW  - Kalman filters
DO  - 10.1109/ICRA.2018.8460844
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a method to achieve relative positioning and tracking of a target by a quadcopter using Ultra-wideband (UWB) ranging sensors, which are strategically installed to help retrieve both relative position and bearing between the quadcopter and target. To achieve robust localization for autonomous flight even with uncertainty in the speed of the target, two main features are developed. First, an estimator based on Extended Kalman Filter (EKF) is developed to fuse UWB ranging measurements with data from onboard sensors including inertial measurement unit (IMU), altimeters and optical flow. Second, to properly handle the coupling of the target's orientation with the range measurements, UWB based communication capability is utilized to transfer the target's orientation to the quadcopter. Experiments results demonstrate the ability of the quadcopter to control its position relative to the target autonomously in both cases when the target is static and moving.
ER  - 

TY  - CONF
TI  - Visual Odometry Using a Homography Formulation with Decoupled Rotation and Translation Estimation Using Minimal Solutions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2320
EP  - 2327
AU  - B. Guan
AU  - P. Vasseur
AU  - C. Demonceaux
AU  - F. Fraundorfer
PY  - 2018
KW  - distance measurement
KW  - estimation theory
KW  - image matching
KW  - matrix algebra
KW  - motion estimation
KW  - pose estimation
KW  - robot vision
KW  - motion estimation
KW  - decoupled rotation
KW  - optimal inlier set
KW  - histogram voting
KW  - RANSAC step
KW  - KITTI data set
KW  - road driving scenarios
KW  - homography formulation
KW  - visual odometry
KW  - exhaustive search
KW  - motion hypothesis
KW  - translation estimation
KW  - dominant ground plane
KW  - Estimation
KW  - Visual odometry
KW  - Mathematical model
KW  - Cameras
KW  - Histograms
KW  - Gravity
KW  - Motion estimation
DO  - 10.1109/ICRA.2018.8460747
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present minimal solutions for two-view relative motion estimation based on a homography formulation. By assuming a known vertical direction (e.g. from an IMU) and assuming a dominant ground plane we demonstrate that rotation and translation estimation can be decoupled. This result allows us to reduce the number of point matches needed to compute a motion hypothesis. We then derive different algorithms based on this decoupling that allow an efficient estimation. We also demonstrate how these algorithms can be used efficiently to compute an optimal inlier set using exhaustive search or histogram voting instead of a traditional RANSAC step. Our methods are evaluated on synthetic data and on the KITTI data set, demonstrating that our methods are well suited for visual odometry in road driving scenarios.
ER  - 

TY  - CONF
TI  - Local Nearest Neighbor Integrity Risk Evaluation for Robot Navigation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2328
EP  - 2333
AU  - G. Duenas Arana
AU  - M. Joerger
AU  - M. Spenko
PY  - 2018
KW  - computational complexity
KW  - feature extraction
KW  - mobile robots
KW  - nearest neighbour methods
KW  - risk analysis
KW  - sensor fusion
KW  - association faults
KW  - nearest neighbor data association algorithm
KW  - upper bound
KW  - nearest neighbor integrity risk evaluation
KW  - robot localization
KW  - integrity risk prediction
KW  - robot navigation
KW  - data association algorithms
KW  - feature extraction
KW  - Feature extraction
KW  - Technological innovation
KW  - Covariance matrices
KW  - Robots
KW  - Upper bound
KW  - Safety
KW  - Noise measurement
DO  - 10.1109/ICRA.2018.8460762
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes the design of a new integrity risk prediction/monitoring methodology for robot localization that uses feature extraction and data association algorithms. The work specifically addresses incorrect association faults when employing a local nearest neighbor data association algorithm. This approach is more efficient and easier to implement than previous work. The methodology is tested in simulation, showing that the computed upper bound on integrity risk is a performance metric capable of providing warnings when the safety of the system cannot be guaranteed.
ER  - 

TY  - CONF
TI  - Aided Inertial Navigation with Geometric Features: Observability Analysis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2334
EP  - 2340
AU  - Y. Yang
AU  - G. Huang
PY  - 2018
KW  - cameras
KW  - inertial navigation
KW  - Monte Carlo methods
KW  - observability
KW  - optical radar
KW  - radar imaging
KW  - radionavigation
KW  - sonar imaging
KW  - stereo image processing
KW  - Monte Carlo simulations
KW  - VINS
KW  - plane features
KW  - bearing measurements
KW  - point features
KW  - bearing sensor
KW  - vision-aided INS
KW  - generic exteroceptive range
KW  - inertial navigation systems
KW  - observability analysis
KW  - Observability
KW  - Jacobian matrices
KW  - Sensors
KW  - Position measurement
KW  - Gravity
KW  - Rotation measurement
KW  - Current measurement
DO  - 10.1109/ICRA.2018.8460670
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we perform observability analysis for inertial navigation systems (INS) aided by generic exteroceptive range and/or bearing sensors with different geometric features including points, lines and planes. While the observability of vision-aided INS (VINS, which uses camera as a bearing sensor) with point features has been extensively studied in the literature, we analytically show that the same observability property remains if using generic range and/or bearing measurements, and if global measurements are also available, as expected, some unobservable directions dismiss. We study in-depth the effects of four degenerate motions on the system observability. In particular, building upon the observability analysis of the aided INS with point features, we perform observability analysis for the same system but with line and plane features, respectively, and show that there exist 5 (and 6) unobservable directions for a single line (and plane) feature. Moreover, we, for the first time, analytically derive the unobservable directions for the cases of multiple lines/planes. We validate our analysis through Monte Carlo simulations.
ER  - 

TY  - CONF
TI  - Omnidirectional CNN for Visual Place Recognition and Navigation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2341
EP  - 2348
AU  - T. Wang
AU  - H. Huang
AU  - J. Lin
AU  - C. Hu
AU  - K. Zeng
AU  - M. Sun
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - feedforward neural nets
KW  - image matching
KW  - image retrieval
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - pose estimation
KW  - robot vision
KW  - visual place recognition
KW  - place exemplars
KW  - recognition method
KW  - omnidirectional cameras
KW  - visual input
KW  - matched place exemplar
KW  - closest place exemplar
KW  - relative distance
KW  - retrieved closest place
KW  - omnidirectional view
KW  - powerful O-CNN
KW  - Omnidirectional CNN
KW  - virtual world datasets
KW  - real-world datasets
KW  - omnidirectional convolutional neural network
KW  - camera pose variation
KW  - Visualization
KW  - Navigation
KW  - Robots
KW  - Measurement
KW  - Cameras
KW  - Feature extraction
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8463173
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Visual place recognition is challenging, especially when only a few place exemplars are given. To mitigate the challenge, we consider place recognition method using omnidirectional cameras and propose a novel Omnidirectional Convolutional Neural Network (O-CNN) to handle severe camera pose variation. Given a visual input, the task of the O-CNN is not to retrieve the matched place exemplar, but to retrieve the closest place exemplar and estimate the relative distance between the input and the closest place. With the ability to estimate relative distance, a heuristic policy is proposed to navigate a robot to the retrieved closest place. Note that the network is designed to take advantage of the omnidirectional view by incorporating circular padding and rotation invariance. To train a powerful O-CNN, we build a virtual world for training on a large scale. We also propose a continuous lifted structured feature embedding loss to learn the concept of distance efficiently. Finally, our experimental results confirm that our method achieves state-of-the-art accuracy and speed with both the virtual world and real-world datasets.
ER  - 

TY  - CONF
TI  - Addressing Challenging Place Recognition Tasks Using Generative Adversarial Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2349
EP  - 2355
AU  - Y. Latif
AU  - R. Garg
AU  - M. Milford
AU  - I. Reid
PY  - 2018
KW  - feature extraction
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - visual perception
KW  - perception task
KW  - place recognition tasks
KW  - simultaneous localization and mapping
KW  - SLAM
KW  - coupled Generative Adversarial Networks
KW  - domain translation task
KW  - Task analysis
KW  - Gallium nitride
KW  - Lighting
KW  - Generators
KW  - Image recognition
KW  - Feature extraction
KW  - Visualization
DO  - 10.1109/ICRA.2018.8461081
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Place recognition is an essential component of Simultaneous Localization And Mapping (SLAM). Under severe appearance change, reliable place recognition is a difficult perception task since the same place is perceptually very different in the morning, at night, or over different seasons. This work addresses place recognition as a domain translation task. Using a pair of coupled Generative Adversarial Networks (GANs), we show that it is possible to generate the appearance of one domain (such as summer) from another (such as winter) without requiring image-to-image correspondences across the domains. Mapping between domains is learned from sets of images in each domain without knowing the instance-to-instance correspondence by enforcing a cyclic consistency constraint. In the process, meaningful feature spaces are learned for each domain, the distances in which can be used for the task of place recognition. Experiments show that learned features correspond to visual similarity and can be effectively used for place recognition across seasons.
ER  - 

TY  - CONF
TI  - Re-Deployment Algorithms for Multiple Service Robots to Optimize Task Response
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2356
EP  - 2363
AU  - A. Sadeghi
AU  - S. L. Smith
PY  - 2018
KW  - approximation theory
KW  - computational complexity
KW  - greedy algorithms
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - service robots
KW  - N task arrivals
KW  - service tasks
KW  - redeployment cost
KW  - one-stage greedy algorithm
KW  - constant-factor approximation algorithm
KW  - service cost
KW  - multiple service robots
KW  - autonomous robots
KW  - re-deployment algorithms
KW  - task response optimization
KW  - NP-hard
KW  - Robots
KW  - Task analysis
KW  - Time factors
KW  - Approximation algorithms
KW  - Probability distribution
KW  - Measurement
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2018.8460726
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper focuses on the problem of deploying a set of autonomous robots to efficiently service tasks that arrive sequentially in an environment over time. Each task is serviced when the robot visits the corresponding task location. Robots can then redeploy while waiting for the next task to arrive. The objective is to redeploy the robots taking into account the next N task arrivals. We seek to minimize a linear combination of the expected cost to service tasks and the redeployment cost between task arrivals. In the single robot case, we propose a one-stage greedy algorithm and prove its optimality. For multiple robots, the problem is NP-hard, and we propose two constant-factor approximation algorithm, one for the problem with a horizon of two task arrivals and the other for the infinite horizon when redeployment cost is weighted more heavily than service cost. Finally, we present extensive benchmarking results to characterize both solution quality and runtime.
ER  - 

TY  - CONF
TI  - Multi-Agent Time-Based Decision-Making for the Search and Action Problem
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2365
EP  - 2372
AU  - T. Miki
AU  - M. Popović
AU  - A. Gawel
AU  - G. Hitz
AU  - R. Siegwart
PY  - 2018
KW  - computational complexity
KW  - control engineering computing
KW  - decision making
KW  - multi-agent systems
KW  - multi-robot systems
KW  - probability
KW  - rescue robots
KW  - search-and-rescue
KW  - task allocation
KW  - probabilistic reasoning
KW  - Gazebo-based environmenT
KW  - multiagent time-based decision-making
KW  - Mohamed Bin Zayed International Robotics Challenge
KW  - near-optimal decisions
KW  - agent action
KW  - allocated budget
KW  - time constraints
KW  - decentralized multiagent decision-making framework
KW  - computational complexity
KW  - task selection
KW  - missions present several challenges
KW  - robotic applications
KW  - action problem
KW  - Task analysis
KW  - Search problems
KW  - Decision making
KW  - Planning
KW  - Time factors
KW  - Robots
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2018.8460996
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Many robotic applications, such as search-and-rescue, require multiple agents to search for and perform actions on targets. However, such missions present several challenges, including cooperative exploration, task selection and allocation, time limitations, and computational complexity. To address this, we propose a decentralized multi-agent decision-making framework for the search and action problem with time constraints. The main idea is to treat time as an allocated budget in a setting where each agent action incurs a time cost and yields a certain reward. Our approach leverages probabilistic reasoning to make near-optimal decisions leading to maximized reward. We evaluate our method in the search, pick, and place scenario of the Mohamed Bin Zayed International Robotics Challenge (MBZIRC), by using a probability density map and reward prediction function to assess actions. Extensive simulations show that our algorithm outperforms benchmark strategies, and we demonstrate system integration in a Gazebo-based environment, validating the framework's readiness for field application.
ER  - 

TY  - CONF
TI  - Multi-robot Dubins Coverage with Autonomous Surface Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2373
EP  - 2379
AU  - N. Karapetyan
AU  - J. Moulton
AU  - J. S. Lewis
AU  - A. Quattrini Li
AU  - J. M. O'Kane
AU  - I. Rekleitis
PY  - 2018
KW  - computational complexity
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - remotely operated vehicles
KW  - travelling salesman problems
KW  - multirobot Dubins coverage
KW  - aerial monitoring
KW  - single robot approaches
KW  - multirobot approaches
KW  - Dubins vehicle kinematics
KW  - environmental monitoring
KW  - multirobot team
KW  - Dubins vehicles
KW  - NP-complete problems
KW  - salesman problem-k-TSP-formulation
KW  - autonomous surface vehicles
KW  - large scale coverage operations
KW  - marine exploration
KW  - Robot sensing systems
KW  - Clustering algorithms
KW  - Task analysis
KW  - Lakes
KW  - Multi-robot systems
KW  - Kinematics
DO  - 10.1109/ICRA.2018.8460661
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In large scale coverage operations, such as marine exploration or aerial monitoring, single robot approaches are not ideal, as they may take too long to cover a large area. In such scenarios, multi-robot approaches are preferable. Furthermore, several real world vehicles are non-holonomic, but can be modeled using Dubins vehicle kinematics. This paper focuses on environmental monitoring of aquatic environments using Autonomous Surface Vehicles (ASVs). In particular, we propose a novel approach for solving the problem of complete coverage of a known environment by a multi-robot team consisting of Dubins vehicles. It is worth noting that both multi-robot coverage and Dubins vehicle coverage are NP-complete problems. As such, we present two heuristics methods based on a variant of the traveling salesman problem-k-TSP-formulation and clustering algorithms that efficiently solve the problem. The proposed methods are tested both in simulations to assess their scalability and with a team of ASVs operating on a 200 km2 lake to ensure their applicability in real world.
ER  - 

TY  - CONF
TI  - How Many Robots are Enough: A Multi-Objective Genetic Algorithm for the Single-Objective Time-Limited Complete Coverage Problem
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2380
EP  - 2387
AU  - X. Zhou
AU  - H. Wang
AU  - B. Ding
PY  - 2018
KW  - computational complexity
KW  - genetic algorithms
KW  - multi-robot systems
KW  - trees (mathematics)
KW  - multiobjective genetic algorithm
KW  - multirobot complete coverage problem
KW  - task-allocation
KW  - number-fixed problem
KW  - multiobjective GA
KW  - Mofint
KW  - single-objective time-limited complete coverage problem
KW  - Robots
KW  - Vegetation
KW  - Task analysis
KW  - Genetic algorithms
KW  - Resource management
KW  - Optimization
KW  - Approximation algorithms
DO  - 10.1109/ICRA.2018.8461028
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Complete coverage, which is the foundation of many robotic applications, aims to cover an area as quickly as possible. This study investigates the time-limited version of multi-robot complete coverage problem, that is, to find the least number of robots and allocate tasks properly to them such that they can finish a known mission within the time limit. This version of problem can be tackled straightforwardly based on optimizing the task-allocation to a fixed number of robots and enumerating the number. However, the number-fixed problem is NP-hard and the existing algorithm for the number-fixed problem allows intersecting tasks (possibly causing robots' interference) and endures high approximation factor. In this study, the time-limited complete coverage problem is tackled with a multi-objective approach, instead of enumerating robots' number and optimizing each number-fixed problem one by one. The multi-objective GA, Mofint, at first estimates the lower and upper bounds of the number of robots. It abstracts each task as a weighted node of a graph. Then, Mofint evolves individuals, each individual being a forest containing a certain number (within the bounds) of non-intersecting trees. Mofint can finally obtain higher precision than existing work with less time: the approximation factor for Mofint is 1.1 to 1.5 times the ideal allocation when robots' number is fixed, while for existing work is 1.5 to 2. Due to its higher precision, the least number of robots obtained in the experiments by Mofint is 0.6 times of existing work.
ER  - 

TY  - CONF
TI  - Joint Multi-Policy Behavior Estimation and Receding-Horizon Trajectory Planning for Automated Urban Driving
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2388
EP  - 2394
AU  - B. Zhou
AU  - W. Schwarting
AU  - D. Rus
AU  - J. Alonso-Mora
PY  - 2018
KW  - collision avoidance
KW  - Markov processes
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - road vehicles
KW  - multipolicy decision-making
KW  - traffic participants
KW  - planned trajectory
KW  - ego-vehicle
KW  - safe trajectories
KW  - multiple motion policies
KW  - receding-horizon planner
KW  - simulated multivehicle intersection scenarios
KW  - joint multipolicy behavior
KW  - automated urban driving
KW  - urban environments
KW  - autonomous vehicle
KW  - multiple motion hypothesis
KW  - joint behavior estimation
KW  - observable Markov decision processes
KW  - receding-horizon control
KW  - receding-horizon trajectory planning
KW  - Trajectory
KW  - Planning
KW  - Estimation
KW  - Space vehicles
KW  - Uncertainty
KW  - Roads
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8461138
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When driving in urban environments, an autonomous vehicle must account for the interaction with other traffic participants. It must reason about their future behavior, how its actions affect their future behavior, and potentially consider multiple motion hypothesis. In this paper we introduce a method for joint behavior estimation and trajectory planning that models interaction and multi-policy decision-making. The method leverages Partially Observable Markov Decision Processes to estimate the behavior of other traffic participants given the planned trajectory for the ego-vehicle, and Receding-Horizon Control for generating safe trajectories for the ego-vehicle. To achieve safe navigation we introduce chance constraints over multiple motion policies in the receding-horizon planner. These constraints account for uncertainty over the behavior of other traffic participants. The method is capable of running in real-time and we show its performance and good scalability in simulated multi-vehicle intersection scenarios.
ER  - 

TY  - CONF
TI  - Robust Environmental Mapping by Mobile Sensor Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2395
EP  - 2402
AU  - H. Park
AU  - J. Liu
AU  - M. Johnson-Roberson
AU  - R. Vasudevan
PY  - 2018
KW  - Bayes methods
KW  - computational geometry
KW  - environmental factors
KW  - fires
KW  - mobile radio
KW  - mobile robots
KW  - wireless sensor networks
KW  - environmental mapping
KW  - ground truth distribution
KW  - Voronoi diagram
KW  - ad-hoc communication
KW  - human safety
KW  - satisfactory convergence
KW  - autonomous agents
KW  - mapping tasks
KW  - terrain elevation
KW  - physical quantities
KW  - forest fires
KW  - hazardous chemical leakages
KW  - spatial map
KW  - mobile sensor networks
KW  - decentralized manner
KW  - disjoint regions
KW  - hardware failures
KW  - short-range sensors
KW  - mobile robots
KW  - environmental parameters
KW  - robust spatial mapping
KW  - Bayesian approach
KW  - Robot sensing systems
KW  - Robustness
KW  - Mutual information
KW  - Computational modeling
KW  - Mobile robots
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461034
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Constructing a spatial map of environmental parameters is a crucial step to preventing hazardous chemical leakages, forest fires, or while estimating a spatially distributed physical quantities such as terrain elevation. Although prior methods can do such mapping tasks efficiently via dispatching a group of autonomous agents, they are unable to ensure satisfactory convergence to the underlying ground truth distribution in a decentralized manner when any of the agents fail. Since the types of agents utilized to perform such mapping are typically inexpensive and prone to failure, this results in poor overall mapping performance in real-world applications, which can in certain cases endanger human safety. This paper presents a Bayesian approach for robust spatial mapping of environmental parameters by deploying a group of mobile robots capable of ad-hoc communication equipped with short-range sensors in the presence of hardware failures. Our approach first utilizes a variant of the Voronoi diagram to partition the region to be mapped into disjoint regions that are each associated with at least one robot. These robots are then deployed in a decentralized manner to maximize the likelihood that at least one robot detects every target in their associated region despite a non-zero probability of failure. A suite of simulation results is presented to demonstrate the effectiveness and robustness of the proposed method when compared to existing techniques.
ER  - 

TY  - CONF
TI  - Best Response Model Predictive Control for Agile Interactions Between Autonomous Ground Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2403
EP  - 2410
AU  - G. Williams
AU  - B. Goldfain
AU  - P. Drews
AU  - J. M. Rehg
AU  - E. A. Theodorou
PY  - 2018
KW  - game theory
KW  - information theory
KW  - mobile robots
KW  - nonlinear control systems
KW  - predictive control
KW  - remotely operated vehicles
KW  - stochastic systems
KW  - best response model predictive control
KW  - AutoRally platforms
KW  - nonlinear stochastic systems
KW  - information theoretic model predictive control algorithm
KW  - iterated best response
KW  - game theoretic notion
KW  - autonomous control
KW  - autonomous ground vehicles
KW  - Games
KW  - Stochastic processes
KW  - Predictive control
KW  - Nash equilibrium
KW  - Optimization
KW  - Vehicle dynamics
KW  - Prediction algorithms
DO  - 10.1109/ICRA.2018.8462831
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We introduce an algorithm for autonomous control of multiple fast ground vehicles operating in close proximity to each other. The algorithm is based on a combination of the game theoretic notion of iterated best response, and an information theoretic model predictive control algorithm designed for non-linear stochastic systems. We test the algorithm on two one-fifth scale AutoRally platforms traveling at speeds upwards of 8 meters per second, while maintaining a following distance of under two meters from bumper-to-bumper.
ER  - 

TY  - CONF
TI  - A Deep Incremental Boltzmann Machine for Modeling Context in Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2411
EP  - 2416
AU  - F. I. Doğan
AU  - H. Çelikkanat
AU  - S. Kalkan
PY  - 2018
KW  - Boltzmann machines
KW  - learning (artificial intelligence)
KW  - pattern classification
KW  - contextual model
KW  - context layer
KW  - scene classification benchmark
KW  - nonincremental models
KW  - deep incremental Boltzmann machine
KW  - robots
KW  - context modeling efforts
KW  - fixed structure
KW  - incremental deep model
KW  - Neurons
KW  - Context modeling
KW  - Hidden Markov models
KW  - Robots
KW  - Computational modeling
KW  - Adaptation models
KW  - Data models
DO  - 10.1109/ICRA.2018.8462925
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Context is an essential capability for robots that are to be as adaptive as possible in challenging environments. Although there are many context modeling efforts, they assume a fixed structure and number of contexts. In this paper, we propose an incremental deep model that extends Restricted Boltzmann Machines. Our model gets one scene at a time, and gradually extends the contextual model when necessary, either by adding a new context or a new context layer to form a hierarchy. We show on a scene classification benchmark that our method converges to a good estimate of the contexts of the scenes, and performs better or on-par on several tasks compared to other incremental models or non-incremental models.
ER  - 

TY  - CONF
TI  - Accelerating Model Learning with Inter-Robot Knowledge Transfer
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2417
EP  - 2424
AU  - N. Makondo
AU  - B. Rosman
AU  - O. Hasegawa
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - multi-robot systems
KW  - robot programming
KW  - training transfer models
KW  - online learning
KW  - inverse dynamics model
KW  - model learning
KW  - inter-robot knowledge transfer
KW  - multirobot setting
KW  - trajectory tracking tasks
KW  - robot inverse dynamics model
KW  - tabula rasa learning
KW  - robot learning
KW  - Interbotix PhantomX Pincher arm
KW  - Kuka youBot arm
KW  - Adaptation models
KW  - Manipulator dynamics
KW  - Data models
KW  - Acceleration
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461218
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Online learning of a robot's inverse dynamics model for trajectory tracking necessitates an interaction between the robot and its environment to collect training data. This is challenging for physical robots in the real world, especially for humanoids and manipulators due to their large and high dimensional state and action spaces, as a large amount of data must be collected over time. This can put the robot in danger when learning tabula rasa and can also be a time-intensive process especially in a multi-robot setting, where each robot is learning its model from scratch. We propose accelerating learning of the inverse dynamics model for trajectory tracking tasks in this multi-robot setting using knowledge transfer, where robots share and re-use data collected by preexisting robots, in order to speed up learning for new robots. We propose a scheme for collecting a sample of correspondences from the robots for training transfer models, and demonstrate, in simulations, the benefit of knowledge transfer in accelerating online learning of the inverse dynamics model between several robots, including between a low-cost Interbotix PhantomX Pincher arm, and a more expensive and relatively heavier Kuka youBot arm. We show that knowledge transfer can save up to 63% of training time of the youBot arm compared to learning from scratch, and about 58% for the lighter Pincher arm.
ER  - 

TY  - CONF
TI  - Online Learning of a Memory for Learning Rates
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2425
EP  - 2432
AU  - F. Meier
AU  - D. Kappler
AU  - S. Schaal
PY  - 2018
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - pattern classification
KW  - learning rates
KW  - learning process
KW  - memory model
KW  - optimal learning rate landscape
KW  - task specific optimization
KW  - meta-learner
KW  - internal memory
KW  - optimization tasks
KW  - meta-learning algorithm speeds
KW  - learning control tasks
KW  - online learning settings
KW  - gradient behaviors
KW  - gradient-based optimizer
KW  - MNIST classification
KW  - Task analysis
KW  - Optimization
KW  - Prediction algorithms
KW  - Robots
KW  - Transforms
KW  - Computational modeling
KW  - Predictive models
DO  - 10.1109/ICRA.2018.8460625
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The promise of learning to learn for robotics rests on the hope that by extracting some information about the learning process itself we can speed up subsequent similar learning tasks. Here, we introduce a computationally efficient online meta-learning algorithm that builds and optimizes a memory model of the optimal learning rate landscape from previously observed gradient behaviors. While performing task specific optimization, this memory of learning rates predicts how to scale currently observed gradients. After applying the gradient scaling our meta-learner updates its internal memory based on the observed effect its prediction had. Our meta-learner can be combined with any gradient-based optimizer, learns on the fly and can be transferred to new optimization tasks. In our evaluations we show that our meta-learning algorithm speeds up learning of MNIST classification and a variety of learning control tasks, either in batch or online learning settings.
ER  - 

TY  - CONF
TI  - Learning Coupled Forward-Inverse Models with Combined Prediction Errors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2433
EP  - 2439
AU  - D. Koert
AU  - G. Maeda
AU  - G. Neumann
AU  - J. Pcters
PY  - 2018
KW  - learning (artificial intelligence)
KW  - robots
KW  - multiple solutions
KW  - inverse space
KW  - forward models
KW  - paired forward-inverse models
KW  - multiple modules
KW  - local minima
KW  - training multiple models-that
KW  - monolithic complex network
KW  - efficient alternative
KW  - multiple simple models
KW  - complex models
KW  - unstructured environments
KW  - combined prediction errors
KW  - coupled forward-inverse models
KW  - Inverse problems
KW  - Computational modeling
KW  - Data models
KW  - Predictive models
KW  - Adaptation models
KW  - Robots
KW  - Context modeling
DO  - 10.1109/ICRA.2018.8460675
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Challenging tasks in unstructured environments require robots to learn complex models. Given a large amount of information, learning multiple simple models can offer an efficient alternative to a monolithic complex network. Training multiple models-that is, learning their parameters and their responsibilities-has been shown to be prohibitively hard as optimization is prone to local minima. To efficiently learn multiple models for different contexts, we thus develop a new algorithm based on expectation maximization (EM). In contrast to comparable concepts, this algorithm trains multiple modules of paired forward-inverse models by using the prediction errors of both forward and inverse models simultaneously. In particular, we show that our method yields a substantial improvement over only considering the errors of the forward models on tasks where the inverse space contains multiple solutions.
ER  - 

TY  - CONF
TI  - DEFO-NET: Learning Body Deformation Using Generative Adversarial Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2440
EP  - 2447
AU  - Z. Wang
AU  - S. Rosa
AU  - L. Xie
AU  - B. Yang
AU  - S. Wang
AU  - N. Trigoni
AU  - A. Markham
PY  - 2018
KW  - finite element analysis
KW  - image colour analysis
KW  - image reconstruction
KW  - mobile robots
KW  - robot vision
KW  - RGB-D image
KW  - finite element methods
KW  - mobile robots
KW  - single depth view
KW  - physical finite element model simulator
KW  - autonomous robots
KW  - Generative Adversarial networks
KW  - body deformation
KW  - DEFO-NET
KW  - Strain
KW  - Gallium nitride
KW  - Force
KW  - Deformable models
KW  - Robots
KW  - Training
KW  - Generators
DO  - 10.1109/ICRA.2018.8462832
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Modelling the physical properties of everyday objects is a fundamental prerequisite for autonomous robots. We present a novel generative adversarial network (DEFO-NET), able to predict body deformations under external forces from a single RGB-D image. The network is based on an invertible conditional Generative Adversarial Network (IcGAN) and is trained on a collection of different objects of interest generated by a physical finite element model simulator. Defo-netinherits the generalisation properties of GANs. This means that the network is able to reconstruct the whole 3-D appearance of the object given a single depth view of the object and to generalise to unseen object configurations. Contrary to traditional finite element methods, our approach is fast enough to be used in real-time applications. We apply the network to the problem of safe and fast navigation of mobile robots carrying payloads over different obstacles and floor materials. Experimental results in real scenarios show how a robot equipped with an RGB-D camera can use the network to predict terrain deformations under different payload configurations and use this to avoid unsafe areas.
ER  - 

TY  - CONF
TI  - Bodily Aware Soft Robots: Integration of Proprioceptive and Exteroceptive Sensors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2448
EP  - 2453
AU  - G. Soter
AU  - A. Conn
AU  - H. Hauser
AU  - J. Rossiter
PY  - 2018
KW  - cameras
KW  - convolution
KW  - dexterous manipulators
KW  - mobile robots
KW  - object tracking
KW  - path planning
KW  - recurrent neural nets
KW  - sensors
KW  - bodily aware soft robots
KW  - exteroceptive sensors
KW  - proprioceptive sensors
KW  - bend sensors
KW  - visual sensor
KW  - nonlinearity
KW  - octopus-inspired arm
KW  - camera record
KW  - arm capturing
KW  - internal sensory signals
KW  - stacked convolutional autoencoder
KW  - CAE
KW  - recurrent neural network
KW  - RNN
KW  - motion
KW  - Convolution
KW  - Soft robotics
KW  - Robot sensing systems
KW  - Visualization
KW  - Recurrent neural networks
DO  - 10.1109/ICRA.2018.8463169
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Being aware of our body has great importance in our everyday life. It helps us to complete difficult tasks, such as movement in a dark room or grasping a complex object. These skills are important for robots as well, however, robotic bodily awareness is still an open question, and the nonlinearity of soft robots adds even more complexity. In this paper, we address this problem and present a novel method to implement bodily awareness into a real soft robot by the integration of its exteroceptive and proprioceptive sensors. We use an octopus-inspired arm as an example where the proprioceptive representation is approximated by four bend sensors integrated into the soft body, while a camera records the movement of the arm capturing its exteroceptive representation. The internal sensory signals are mapped to the visual information using a combination of a stacked convolutional autoencoder (CAE) and a recurrent neural network (RNN). As a result, the soft robot can learn to estimate and, therefore, to imagine its motion even when its visual sensor is not available.
ER  - 

TY  - CONF
TI  - Deep Learning a Quadrotor Dynamic Model for Multi-Step Prediction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2454
EP  - 2459
AU  - N. Mohajerin
AU  - M. Mozifian
AU  - S. Waslander
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - predictive control
KW  - recurrent neural nets
KW  - robot dynamics
KW  - robot kinematics
KW  - trajectory control
KW  - quadrotor dynamic model
KW  - motion prediction
KW  - dynamic systems
KW  - long horizons
KW  - deep learning
KW  - deep recurrent neural networks
KW  - quadrotor motion model
KW  - initial system state
KW  - motor speeds
KW  - prediction horizon
KW  - recurrent neural network state initialization
KW  - quadrotor vehicle flights
KW  - indoor flight arena
KW  - hybrid network architecture
KW  - system identification methods
KW  - robust state predictions
KW  - time 2.0 s
KW  - frequency 100.0 Hz
KW  - Mathematical model
KW  - Predictive models
KW  - Vehicle dynamics
KW  - Aerodynamics
KW  - Recurrent neural networks
KW  - Training
DO  - 10.1109/ICRA.2018.8460840
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We develop a multi-step motion prediction modeling method for dynamic systems over long horizons using deep learning. Building on previous work, we propose a novel hybrid network architecture, by combining deep recurrent neural networks with a quadrotor motion model created using classic system identification methods. The proposed model takes only the initial system state and motor speeds over the prediction horizon as inputs and returns robust state predictions for up to two seconds of motion at 100 Hz. We employ recurrent neural network state initialization during training, to exploit real-world dataset collected from quadrotor vehicle flights in an indoor flight arena. Our experiments demonstrate that the proposed hybrid network model consistently outperforms both black box and rigid body dynamics predictions over single and multi-step prediction scenarios, with an order of magnitude improvements in velocity estimates in particular.
ER  - 

TY  - CONF
TI  - Safe Learning of Quadrotor Dynamics Using Barrier Certificates
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2460
EP  - 2465
AU  - L. Wang
AU  - E. A. Theodorou
AU  - M. Egerstedt
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - Gaussian processes
KW  - helicopters
KW  - learning systems
KW  - mobile robots
KW  - nonlinear control systems
KW  - probability
KW  - uncertain systems
KW  - complex dynamical systems
KW  - accurate nonlinear models
KW  - data-driven approach
KW  - Gaussian processes
KW  - learning process
KW  - barrier certificates
KW  - safe learning
KW  - learning controller
KW  - quadrotor dynamics
KW  - Safety
KW  - Control systems
KW  - Computational modeling
KW  - Gaussian processes
KW  - Adaptation models
KW  - Lyapunov methods
KW  - System dynamics
DO  - 10.1109/ICRA.2018.8460471
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To effectively control complex dynamical systems, accurate nonlinear models are typically needed. However, these models are not always known. In this paper, we present a data-driven approach based on Gaussian processes that learns models of quadrotors operating in partially unknown environments. What makes this challenging is that if the learning process is not carefully controlled, the system will go unstable, i.e., the quadcopter will crash. To this end, barrier certificates are employed for safe learning. The barrier certificates establish a non-conservative forward invariant safe region, in which high probability safety guarantees are provided based on the statistics of the Gaussian Process. A learning controller is designed to efficiently explore those uncertain states and expand the barrier certified safe region based on an adaptive sampling scheme. Simulation results are provided to demonstrate the effectiveness of the proposed approach.
ER  - 

TY  - CONF
TI  - Data-Efficient Decentralized Visual SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2466
EP  - 2473
AU  - T. Cieslewski
AU  - S. Choudhary
AU  - D. Scaramuzza
PY  - 2018
KW  - cameras
KW  - data mining
KW  - graph theory
KW  - image sensors
KW  - multi-robot systems
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - decentralized visual SLAM system
KW  - decentralized SLAM components
KW  - data-efficient decentralized visual SLAM
KW  - pose-graph optimization method
KW  - data association scales
KW  - robot count
KW  - data transfers
KW  - robots
KW  - map data
KW  - visual SLAM systems exchange
KW  - versatile cameras
KW  - lightweight cameras
KW  - cheap cameras
KW  - multirobot applications
KW  - mapping
KW  - Supplementary Material Data
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Optimization
KW  - Pose estimation
KW  - Trajectory
KW  - Bandwidth
DO  - 10.1109/ICRA.2018.8461155
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Decentralized visual simultaneous localization and mapping (SLAM) is a powerful tool for multi-robot applications in environments where absolute positioning is not available. Being visual, it relies on cheap, lightweight and versatile cameras, and, being decentralized, it does not rely on communication to a central entity. In this work, we integrate state-of-the-art decentralized SLAM components into a new, complete decentralized visual SLAM system. To allow for data association and optimization, existing decentralized visual SLAM systems exchange the full map data among all robots, incurring large data transfers at a complexity that scales quadratically with the robot count. In contrast, our method performs efficient data association in two stages: first, a compact full-image descriptor is deterministically sent to only one robot. Then, only if the first stage succeeded, the data required for relative pose estimation is sent, again to only one robot. Thus, data association scales linearly with the robot count and uses highly compact place representations. For optimization, a state-of-the-art decentralized pose-graph optimization method is used. It exchanges a minimum amount of data which is linear with trajectory overlap. We characterize the resulting system and identify bottlenecks in its components. The system is evaluated on publicly available datasets and we provide open access to the code. Supplementary Material Data and code are at: https://github.com/uzh-rpg/dslam_open.
ER  - 

TY  - CONF
TI  - A Linear Least Square Initialization Method for 3D Pose Graph Optimization Problem
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2474
EP  - 2479
AU  - S. M. Nasiri
AU  - H. Moradi
AU  - R. Hosseini
PY  - 2018
KW  - approximation theory
KW  - computer vision
KW  - graph theory
KW  - image reconstruction
KW  - iterative methods
KW  - least squares approximations
KW  - optimisation
KW  - pose estimation
KW  - SLAM (robots)
KW  - important optimization problem
KW  - machine vision applications
KW  - 3D SLAM
KW  - graph corresponds
KW  - PGO problem
KW  - relative noisy observation
KW  - PGO solvers
KW  - state-of-the-art initialization methods
KW  - low noise problems
KW  - measurement noise
KW  - iterative methods
KW  - high noise problems
KW  - PGO optimization problem
KW  - iterative least-squares method
KW  - linear least square initialization method
KW  - pose graph optimization
KW  - least-square problem
KW  - Robots
KW  - Integrated circuits
KW  - Cost function
KW  - Iterative methods
KW  - Three-dimensional displays
KW  - Estimation
KW  - Pose Graph Optimization
KW  - Least square
KW  - 3D SLAM
KW  - Initialization method
DO  - 10.1109/ICRA.2018.8460741
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Pose Graph Optimization (PGO) is an important optimization problem arising in robotics and machine vision applications like 3D reconstruction and 3D SLAM. Each node of pose graph corresponds to an orientation and a location. The PGO problem finds orientations and locations of the nodes from relative noisy observation between nodes. Recent investigations show that well-known iterative PGO solvers need good initialization to converge to good solutions. However, we observed that state-of-the-art initialization methods obtain good initialization only in low noise problems, and they fail in challenging problems having more measurement noise. Consequently, iterative methods may converge to bad solutions in high noise problems. In this paper, a new method for obtaining orientations in the PGO optimization problem is presented. Like other well-known methods the initial locations are obtained from the result of a least-squares problem. The proposed method iteratively approximates the problem around current estimation and converts it to a least-squares problem. Therefore, the method can be seen as an iterative least-squares method which is computationally efficient. Simulation results show that the proposed initialization method helps the most well-known iterative solver to obtain better optima and significantly outperform other solvers in some cases.
ER  - 

TY  - CONF
TI  - IMLS-SLAM: Scan-to-Model Matching Based on 3D Data
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2480
EP  - 2485
AU  - J. Deschaud
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - optical radar
KW  - remotely operated vehicles
KW  - road traffic control
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - robotics community
KW  - stereo cameras
KW  - depth sensors
KW  - Velodyne LiDAR
KW  - autonomous driving
KW  - low-drift SLAM algorithm
KW  - 3D LiDAR data
KW  - scan-to-model matching framework
KW  - specific sampling strategy
KW  - LiDAR scans
KW  - Velodyne HDL32
KW  - Velodyne HDL64
KW  - global drift
KW  - IMLS-SLAM
KW  - 3D data
KW  - simultaneous localization and mapping
KW  - localized LiDAR sweeps
KW  - IMLS surface representation
KW  - implicit moving least squares
KW  - size 4.0 km
KW  - size 16.0 m
KW  - time 10.0 year
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Simultaneous localization and mapping
KW  - Two dimensional displays
KW  - Iterative closest point algorithm
KW  - Observability
DO  - 10.1109/ICRA.2018.8460653
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The Simultaneous Localization And Mapping (SLAM) problem has been well studied in the robotics community, especially using mono, stereo cameras or depth sensors. 3D depth sensors, such as Velodyne LiDAR, have proved in the last 10 years to be very useful to perceive the environment in autonomous driving, but few methods exist that directly use these 3D data for odometry. We present a new low-drift SLAM algorithm based only on 3D LiDAR data. Our method relies on a scan-to-model matching framework. We first have a specific sampling strategy based on the LiDAR scans. We then define our model as the previous localized LiDAR sweeps and use the Implicit Moving Least Squares (IMLS) surface representation. We show experiments with the Velodyne HDL32 with only 0.40% drift over a 4 km acquisition without any loop closure (i.e., 16 m drift after 4 km). We tested our solution on the KITTI benchmark with a Velodyne HDL64 and ranked among the best methods (against mono, stereo and LiDAR methods) with a global drift of only 0.69%.
ER  - 

TY  - CONF
TI  - ApriISAM: Real-Time Smoothing and Mapping
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2486
EP  - 2493
AU  - X. Wang
AU  - R. Marcotte
AU  - G. Ferrer
AU  - E. Olson
PY  - 2018
KW  - error analysis
KW  - matrix decomposition
KW  - mobile robots
KW  - SLAM (robots)
KW  - sparse matrices
KW  - fixed computational budget
KW  - dynamic variable reordering algorithm
KW  - ApriISAM
KW  - real-time smoothing
KW  - online robots
KW  - incremental SLAM algorithms
KW  - batch algorithms
KW  - absolute error
KW  - incremental Cholesky factorizations
KW  - marginalization order
KW  - iSAM
KW  - re-linearize
KW  - Simultaneous localization and mapping
KW  - Heuristic algorithms
KW  - Smoothing methods
KW  - Sparse matrices
KW  - Clustering algorithms
KW  - Real-time systems
DO  - 10.1109/ICRA.2018.8461072
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For online robots, incremental SLAM algorithms offer huge potential computational savings over batch algorithms. The dominant incremental algorithms are iSAM and iSAM2 which offer radically different approaches to computing incremental updates, balancing issues like 1) the need to re-linearize, 2) changes in the desirable variable marginalization order, and 3) the underlying conceptual approach (i.e. the “matrix” story versus the “factor graph” story). In this paper, we propose a new incremental algorithm that computes solutions with lower absolute error and generally provides lower error solutions for a fixed computational budget than either iSAM or iSAM2. Key to AprilSAM's performance are a new dynamic variable reordering algorithm for fast incremental Cholesky factorizations, a method for reducing the work involved in backsubstitutions, and a new algorithm for deciding between incremental and batch updates.
ER  - 

TY  - CONF
TI  - Fast Nonlinear Approximation of Pose Graph Node Marginalization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2494
EP  - 2501
AU  - D. Ta
AU  - N. Banerjee
AU  - S. Eick
AU  - S. Lenser
AU  - M. E. Munich
PY  - 2018
KW  - approximation theory
KW  - graph theory
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - pose estimation
KW  - SLAM (robots)
KW  - pose graph node marginalization
KW  - longterm localization
KW  - longterm mapping
KW  - longterm navigation
KW  - pose graph structure
KW  - absolute-to relative-pose spaces
KW  - pose-composition approach scaled version
KW  - approximate subgraph
KW  - fast nonlinear approximation method
KW  - Topology
KW  - Jacobian matrices
KW  - Covariance matrices
KW  - Gaussian distribution
KW  - Simultaneous localization and mapping
KW  - Approximation methods
DO  - 10.1109/ICRA.2018.8460979
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a fast nonlinear approximation method for marginalizing out nodes on pose graphs for longterm simultaneous localization, mapping, and navigation. Our approximation preserves the pose graph structure to leverage the rich literature of pose graphs and optimization schemes. By re-parameterizing from absolute-to relative-pose spaces, our method does not suffer from the choice of linearization points as in previous works. We then join our approximation process with a scaled version of the recently-demoted pose-composition approach. Our approach eschews the expenses of many state-of-the-art convex optimization schemes through our efficient and simple O(N2) implementation for a given known topology of the approximate subgraph. We demonstrate its speed and near optimality in practice by comparing against state-of-the-art techniques on popular datasets.
ER  - 

TY  - CONF
TI  - A Benchmark Comparison of Monocular Visual-Inertial Odometry Algorithms for Flying Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2502
EP  - 2509
AU  - J. Delmerico
AU  - D. Scaramuzza
PY  - 2018
KW  - aerospace robotics
KW  - cameras
KW  - Global Positioning System
KW  - image capture
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - state estimation
KW  - monocular visual-inertial odometry algorithms
KW  - state estimation algorithms
KW  - computational constraints
KW  - inertial measurement units
KW  - VIO algorithms
KW  - single-board computer systems
KW  - flying robots
KW  - pose estimation
KW  - cameras
KW  - IMUs
KW  - motion capture
KW  - global positioning systems
KW  - MSCKF
KW  - OKVIS
KW  - ROVIO
KW  - VINS-Mono
KW  - SVO-MSF
KW  - SVO-GTSAM
KW  - hardware configurations
KW  - EuRoC datasets
KW  - six degree of freedom
KW  - 6 DoF
KW  - State estimation
KW  - Visualization
KW  - Optimization
KW  - Pipelines
KW  - Hardware
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8460664
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Flying robots require a combination of accuracy and low latency in their state estimation in order to achieve stable and robust flight. However, due to the power and payload constraints of aerial platforms, state estimation algorithms must provide these qualities under the computational constraints of embedded hardware. Cameras and inertial measurement units (IMUs) satisfy these power and payload constraints, so visual-inertial odometry (VIO) algorithms are popular choices for state estimation in these scenarios, in addition to their ability to operate without external localization from motion capture or global positioning systems. It is not clear from existing results in the literature, however, which VIO algorithms perform well under the accuracy, latency, and computational constraints of a flying robot with onboard state estimation. This paper evaluates an array of publicly-available VIO pipelines (MSCKF, OKVIS, ROVIO, VINS-Mono, SVO+MSF, and SVO+GTSAM) on different hardware configurations, including several single-board computer systems that are typically found on flying robots. The evaluation considers the pose estimation accuracy, per-frame processing time, and CPU and memory load while processing the EuRoC datasets, which contain six degree of freedom (6DoF) trajectories typical of flying robots. We present our complete results as a benchmark for the research community.
ER  - 

TY  - CONF
TI  - Direct Sparse Visual-Inertial Odometry Using Dynamic Marginalization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2510
EP  - 2517
AU  - L. Von Stumberg
AU  - V. Usenko
AU  - D. Cremers
PY  - 2018
KW  - cameras
KW  - distance measurement
KW  - geometry
KW  - image motion analysis
KW  - image sequences
KW  - optimisation
KW  - pose estimation
KW  - optimization
KW  - IMU information
KW  - intensity gradients
KW  - photometric error
KW  - key-point based systems
KW  - photometric IMU measurement errors
KW  - sparse scene geometry
KW  - camera poses
KW  - direct sparse visual-inertial odometry
KW  - VI-DSO
KW  - dynamic marginalization
KW  - visual-inertial system
KW  - IMU data
KW  - gravity direction
KW  - Cameras
KW  - Optimization
KW  - Visualization
KW  - Gravity
KW  - Measurement
KW  - Geometry
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8462905
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present VI-DSO, a novel approach for visual-inertial odometry, which jointly estimates camera poses and sparse scene geometry by minimizing photometric and IMU measurement errors in a combined energy functional. The visual part of the system performs a bundle-adjustment like optimization on a sparse set of points, but unlike key-point based systems it directly minimizes a photometric error. This makes it possible for the system to track not only corners, but any pixels with large enough intensity gradients. IMU information is accumulated between several frames using measurement preintegration and is inserted into the optimization as an additional constraint between keyframes. We explicitly include scale and gravity direction into our model and jointly optimize them together with other variables such as poses. As the scale is often not immediately observable using IMU data this allows us to initialize our visual-inertial system with an arbitrary scale instead of having to delay the initialization until everything is observable. We perform partial marginalization of old variables so that updates can be computed in a reasonable time. In order to keep the system consistent we propose a novel strategy which we call “dynamic marginalization”. This technique allows us to use partial marginalization even in cases where the initial scale estimate is far from the optimum. We evaluate our method on the challenging EuRoC dataset, showing that VI-DSO outperforms the state of the art.
ER  - 

TY  - CONF
TI  - A Monocular SLAM System Leveraging Structural Regularity in Manhattan World
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2518
EP  - 2525
AU  - H. Li
AU  - J. Yao
AU  - J. Bazin
AU  - X. Lu
AU  - Y. Xing
AU  - K. Liu
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - mobile robots
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - rotation optimization strategy
KW  - parallelism
KW  - global binding method
KW  - absolute rotation
KW  - relative rotation
KW  - translation optimization strategy leveraging coplanarity
KW  - coplanar features
KW  - relative translation
KW  - optimal absolute translation
KW  - 3D line optimization strategy
KW  - structural line segments
KW  - structural features
KW  - structural feature-based optimization module
KW  - 3D map
KW  - structural regularity
KW  - optimization strategies
KW  - monocular SLAM systems
KW  - Manhattan World
KW  - camera poses
KW  - Three-dimensional displays
KW  - Cameras
KW  - Optimization
KW  - Parallel processing
KW  - Simultaneous localization and mapping
KW  - Robustness
KW  - Estimation
DO  - 10.1109/ICRA.2018.8463165
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The structural features in Manhattan world encode useful geometric information of parallelism, orthogonality and/or coplanarity in the scene. By fully exploiting these structural features, we propose a novel monocular SLAM system which provides accurate estimation of camera poses and 3D map. The foremost contribution of the proposed system is a structural feature-based optimization module which contains three novel optimization strategies. First, a rotation optimization strategy using the parallelism and orthogonality of 3D lines is presented. We propose a global binding method to compute an accurate estimation of the absolute rotation of the camera. Then we propose an approach for calculating the relative rotation to further refine the absolute rotation. Second, a translation optimization strategy leveraging coplanarity is proposed. Coplanar features are effectively identified, and we leverage them by a unified model handling both points and lines to calculate the relative translation, and then the optimal absolute translation. Third, a 3D line optimization strategy utilizing parallelism, orthogonality and coplanarity simultaneously is proposed to obtain an accurate 3D map consisting of structural line segments with low computational complexity. Experiments in man-made environments have demonstrated that the proposed system outperforms existing state-of-the-art monocular SLAM systems in terms of accuracy and robustness.
ER  - 

TY  - CONF
TI  - Visual Saliency-Aware Receding Horizon Autonomous Exploration with Application to Aerial Robotics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2526
EP  - 2533
AU  - T. Dang
AU  - C. Papachristos
AU  - K. Alexis
PY  - 2018
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - robot vision
KW  - trees (mathematics)
KW  - visual saliency-aware receding horizon autonomous exploration
KW  - reobserving salient regions
KW  - environment exploration rate
KW  - robot endurance
KW  - random tree
KW  - two-step optimization paradigm
KW  - salient objects
KW  - path planner
KW  - visual attention
KW  - aerial robotics
KW  - Visualization
KW  - Robot sensing systems
KW  - Planning
KW  - Computational modeling
KW  - Path planning
DO  - 10.1109/ICRA.2018.8460992
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel strategy for autonomous visual saliency-aware receding horizon exploration of unknown environments using aerial robots. Through a model of visual attention, incrementally built maps are annotated regarding the visual importance and saliency of different objects and entities in the environment. Provided this information, a path planner that simultaneously optimizes for exploration of unknown space, and also directs the robot's attention to focus on the most salient objects, is developed. Following a two-step optimization paradigm, the algorithm first samples a random tree and identifies the branch maximizing for new volume to be explored. The first viewpoint of this path is then provided as a reference to the second planning step. Within that, a new tree is spanned, admissible branches arriving at the reference viewpoint while respecting a time budget dependent on the robot endurance and its environment exploration rate are found and evaluated in terms of reobserving salient regions at sufficient resolution. The best branch is then selected and executed by the robot, and the whole process is iteratively repeated. The proposed method is evaluated regarding its ability to provide increased attention toward salient objects, is verified to run onboard a small aerial robot, and is demonstrated in a set of challenging experimental studies.
ER  - 

TY  - CONF
TI  - Perception-aware Receding Horizon Navigation for MAVs
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2534
EP  - 2541
AU  - Z. Zhang
AU  - D. Scaramuzza
PY  - 2018
KW  - aircraft control
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - state estimation
KW  - perception-aware receding horizon navigation
KW  - microaerial vehicle
KW  - state estimation uncertainty
KW  - perception-aware receding horizon approach
KW  - monocular state estimation
KW  - candidate trajectories
KW  - perception quality
KW  - collision probability
KW  - receding horizon navigation framework
KW  - improved state estimation accuracy
KW  - goal-reaching task
KW  - purely-reactive navigation system
KW  - MAV
KW  - Trajectory
KW  - State estimation
KW  - Planning
KW  - Navigation
KW  - Cameras
KW  - Measurement
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461133
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To reach a given destination safely and accurately, a micro aerial vehicle needs to be able to avoid obstacles and minimize its state estimation uncertainty at the same time. To achieve this goal, we propose a perception-aware receding horizon approach. In our method, a single forward-looking camera is used for state estimation and mapping. Using the information from the monocular state estimation and mapping system, we generate a library of candidate trajectories and evaluate them in terms of perception quality, collision probability, and distance to the goal. The best trajectory to execute is then selected as the one that maximizes a reward function based on these three metrics. To the best of our knowledge, this is the first work that integrates active vision within a receding horizon navigation framework for a goal reaching task. We demonstrate by simulation and real-world experiments on an actual quadrotor that our active approach leads to improved state estimation accuracy in a goal-reaching task when compared to a purely-reactive navigation system, especially in difficult scenes (e.g., weak texture).
ER  - 

TY  - CONF
TI  - Viewpoint-Tolerant Place Recognition Combining 2D and 3D Information for UAV Navigation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2542
EP  - 2549
AU  - F. Maffra
AU  - Z. Chen
AU  - M. Chli
PY  - 2018
KW  - autonomous aerial vehicles
KW  - distance measurement
KW  - geometry
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - stereo image processing
KW  - 3D information
KW  - UAV navigation
KW  - Unmanned Aerial Vehicles
KW  - vision-based odometry
KW  - loop-closure detection
KW  - place recognition framework
KW  - local 3D geometry
KW  - viewpoint-tolerant place recognition
KW  - 2D Information
KW  - hand-held datasets
KW  - perceptual aliasing
KW  - binary features
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Visualization
KW  - Vocabulary
KW  - Image recognition
KW  - Navigation
DO  - 10.1109/ICRA.2018.8460786
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The booming interest in Unmanned Aerial Vehicles (UAV s) is fed by their potentially great impact, however progress is hindered by their limited perception capabilities. While vision-based odometry was shown to run successfully onboard UAV s, loop-closure detection to correct for drift or to recover from tracking failures, has so far, proven particularly challenging for UAVs. At the heart of this is the problem of viewpoint-tolerant place recognition; in stark difference to ground robots, UAVs can revisit a scene from very different viewpoints. As a result, existing approaches struggle greatly as the task at hand violates underlying assumptions in assessing scene similarity. In this paper, we propose a place recognition framework, which exploits both efficient binary features and noisy estimates of the local 3D geometry, which are anyway computed for visual-inertial odometry onboard the UAV. Attaching both an appearance and a geometry signature to each `location', the proposed approach demonstrates unprecedented recall for perfect precision as well as high quality loop-closing transformations on both flying and hand-held datasets exhibiting large viewpoint and appearance changes as well as perceptual aliasing.
ER  - 

TY  - CONF
TI  - Flexible Stereo: Constrained, Non-Rigid, Wide-Baseline Stereo Vision for Fixed-Wing Aerial Platforms
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2550
EP  - 2557
AU  - T. Hinzmann
AU  - T. Taubner
AU  - R. Siegwart
PY  - 2018
KW  - aerospace components
KW  - angular velocity measurement
KW  - autonomous aerial vehicles
KW  - cameras
KW  - collision avoidance
KW  - Kalman filters
KW  - nonlinear filters
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - landing maneuvers
KW  - wing model
KW  - probability density function
KW  - measured deviations
KW  - nominal relative baseline transformation
KW  - relative pose measurements
KW  - relative perspective N-point problem
KW  - inertial measurement units
KW  - highly accurate baseline transformations
KW  - flexible stereo
KW  - wide-baseline stereo vision
KW  - fixed-wing aerial platforms
KW  - computationally efficient method
KW  - visual-inertial sensor rigs
KW  - fixed-wing unmanned aerial vehicle
KW  - estimated relative poses
KW  - highly accurate depth maps
KW  - obstacle avoidance
KW  - low-altitude flights
KW  - extended Kalman filter
KW  - Cameras
KW  - Visualization
KW  - Mathematical model
KW  - Quaternions
KW  - Unmanned aerial vehicles
KW  - Real-time systems
KW  - Accelerometers
DO  - 10.1109/ICRA.2018.8461085
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes a computationally efficient method to estimate the time-varying relative pose between two visual-inertial sensor rigs mounted on the flexible wings of a fixed-wing unmanned aerial vehicle (UAV). The estimated relative poses are used to generate highly accurate depth maps in real-time and can be employed for obstacle avoidance in low-altitude flights or landing maneuvers. The approach is structured as follows: Initially, a wing model is identified by fitting a probability density function to measured deviations from the nominal relative baseline transformation. At runtime, the prior knowledge about the wing model is fused in an Extended Kalman filter (EKF) together with relative pose measurements obtained from solving a relative perspective N-point problem (PNP), and the linear accelerations and angular velocities measured by the two inertial measurement units (IMU) which are rigidly attached to the cameras. Results obtained from extensive synthetic experiments demonstrate that our proposed framework is able to estimate highly accurate baseline transformations and depth maps.
ER  - 

TY  - CONF
TI  - Visual-Inertial Navigation Algorithm Development Using Photorealistic Camera Simulation in the Loop
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2566
EP  - 2573
AU  - T. Sayre-McCord
AU  - W. Guerra
AU  - A. Antonini
AU  - J. Arneberg
AU  - A. Brown
AU  - G. Cavalheiro
AU  - Y. Fang
AU  - A. Gorodetsky
AU  - D. McCoy
AU  - S. Quilter
AU  - F. Riether
AU  - E. Tal
AU  - Y. Terzioglu
AU  - L. Carlone
AU  - S. Karaman
PY  - 2018
KW  - aerospace computing
KW  - autonomous aerial vehicles
KW  - computer vision
KW  - control engineering computing
KW  - image sensors
KW  - inertial navigation
KW  - rendering (computer graphics)
KW  - virtual reality
KW  - vision-based perception
KW  - virtual reality
KW  - visual-inertial navigation algorithm
KW  - high-rate cameras
KW  - image simulation system
KW  - photorealistic camera simulation
KW  - agile maneuvering
KW  - on-board inertial measurement unit
KW  - rapidly prototype computing
KW  - on-board camera images
KW  - NVIDIA Jetson Tegra X1 system-on-chip compute module
KW  - inertial sensors
KW  - microUAV platform
KW  - vision-in-the-loop control algorithms
KW  - agile microUnmanned Aerial Vehicles
KW  - Cameras
KW  - Sensors
KW  - Visualization
KW  - Real-time systems
KW  - Unmanned aerial vehicles
KW  - Navigation
KW  - Solid modeling
DO  - 10.1109/ICRA.2018.8460692
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The development of fast, agile micro Unmanned Aerial Vehicles (UAVs) has been limited by (i) on-board computing hardware restrictions, (ii) the lack of sophisticated vision-based perception and vision-in-the-loop control algorithms, and (iii) the absence of development environments where such systems and algorithms can be rapidly and easily designed, implemented, and validated. Here, we first present a new micro UAV platform that integrates high-rate cameras, inertial sensors, and an NVIDIA Jetson Tegra X1 system-on-chip compute module that boasts 256 GPU cores. The UAV mechanics and electronics were designed and built in house, and are described in detail. Second, we present a novel “virtual reality” development environment, in which photorealistically-rendered synthetic on-board camera images are generated in real time while the UAV is in flight. This development environment allows us to rapidly prototype computing and sensing hardware as well as perception and control algorithms, using real physics, real interoceptive sensor data (e.g., from the on-board inertial measurement unit), and synthetic exteroceptive sensor data (e.g., from synthetic cameras). Third, we demonstrate repeated agile maneuvering with closed-loop vision-based perception and control algorithms, which we have developed using this environment.
ER  - 

TY  - CONF
TI  - Development and Implementation of High Power Hexapole Magnetic Tweezer System for Micromanipulations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2670
EP  - 2675
AU  - X. Zhang
AU  - H. Kim
AU  - L. W. Rogowski
AU  - S. Sheckman
AU  - M. JunKim
PY  - 2018
KW  - coils
KW  - collision avoidance
KW  - electromagnetic actuators
KW  - magnetic devices
KW  - micromanipulators
KW  - microrobots
KW  - mobile robots
KW  - non-Newtonian fluids
KW  - radiation pressure
KW  - three-dimensional printing
KW  - electromagnetic coil
KW  - 3D printed magnetic yokes
KW  - double layer structure
KW  - power source
KW  - microscale robotic swimmer manipulations
KW  - high power hexapole magnetic tweezer system
KW  - tapering-tipped magnetic poles
KW  - Cartesian coordinate system
KW  - 3D micromanipulations
KW  - Newtonian fluid
KW  - nonNewtonian fluid
KW  - obstacle avoidance
KW  - Magnetic flux
KW  - Magnetic resonance imaging
KW  - Magnetic fields
KW  - Saturation magnetization
KW  - Magnetic hysteresis
KW  - Force
KW  - Power supplies
DO  - 10.1109/ICRA.2018.8463175
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the design, development and implementation of a novel, high power hexapole magnetic tweezer system for 3D micromanipulations. Six tapering-tipped magnetic poles are deployed in a tilted Cartesian coordinate system, with an electromagnetic coil on each for actuation, connected by two 3D printed magnetic yokes to form a double layer structure. The power source is integrated to the magnetic tweezer system through a control algorithm on the software level; image processing was used for experiment analysis. Because of the high magnetic field that the magnetic coils can generate, the working space in the system is relatively larger than other similar designs, which provides better performance on microscale robotic swimmer manipulations. Simulations and experiments performed in this paper demonstrate the agile and powerful manipulation of microswimmers with desired control input to follow complex trajectories, avoid obstacles and move against micro-flow in the samples. We prove that the developed hexapole magnetic tweezer has enough power and controllability to guide microswimmers in Newtonian and Non-Newtonian fluid environments. The system will be optimized continuously and implemented into cell penetration experiments. Finally, the application will be deployed into in vivo based environments.
ER  - 

TY  - CONF
TI  - Robotic Immobilization of Motile Sperm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2676
EP  - 2681
AU  - Z. Zhang
AU  - C. Dai
AU  - J. Huang
AU  - X. Wang
AU  - J. Liu
AU  - J. Zhang
AU  - S. Moskovtsev
AU  - C. Librach
AU  - K. Jarvi
AU  - Y. Sun
PY  - 2018
KW  - cell motility
KW  - cellular biophysics
KW  - manipulators
KW  - medical robotics
KW  - microorganisms
KW  - position control
KW  - servomechanisms
KW  - visual servoing
KW  - robotic sperm immobilization
KW  - visual servo control
KW  - sperm velocity
KW  - sperm orientation
KW  - sperm tail positions
KW  - robotic system
KW  - proximal sperms
KW  - sperm head
KW  - motile cells
KW  - motile sperm
KW  - robotic immobilization
KW  - Robots
KW  - Head
KW  - Visualization
KW  - Target tracking
KW  - Servosystems
KW  - Glass
DO  - 10.1109/ICRA.2018.8462912
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Manipulation of motile cells such as bacteria and sperm is required in both cell biology and clinical applications. For immobilizing a motile sperm, the sperm head and tail positions must be accurately tracked, interference of proximal sperms on the target sperm must be tackled, and the orientation of the sperm must be properly aligned with the manipulation tool in order not to damage the sperm head where DNA is contained. Manual operation of sperm immobilization has stringent skill requirements, and both manual operation and existing robotic sperm immobilization suffer from inconsistent success rates and incapability of manipulating sperms swimming in all directions. This paper presents a robotic system for fully automated tracking, orientation control, and immobilization of motile sperms. Algorithms were developed for robustly tracking the sperm head and estimating the sperm tail positions under interfering conditions. A new visual servo control strategy was developed to enable the robotic system to actively adjust sperm orientation for immobilizing a sperm swimming in any direction. Experimental results from robotic immobilization of 400 sperms confirmed that the robotic system achieved a consistent success rate of 94.5 %, independent of sperm velocity or swimming direction.
ER  - 

TY  - CONF
TI  - Automated Non-Invasive Measurement of Sperm Motility and Morphology Parameters
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2682
EP  - 2687
AU  - C. Sheng Dai
AU  - Z. Zhang
AU  - J. Huang
AU  - X. Wang
AU  - W. Meng
AU  - J. Zhang
AU  - S. Moskovtsev
AU  - C. Librach
AU  - K. Jarvi
AU  - Y. Sun
PY  - 2018
KW  - biological techniques
KW  - biomedical measurement
KW  - cell motility
KW  - filtering theory
KW  - image reconstruction
KW  - image segmentation
KW  - medical image processing
KW  - probability
KW  - target tracking
KW  - motile cells
KW  - automation techniques
KW  - noninvasive measurement
KW  - adapted joint probabilistic data association filter
KW  - multisperm tracking
KW  - inherent inhomogeneous image intensity
KW  - quadratic cost function method
KW  - DIC image reconstruction
KW  - sperm motility measurement
KW  - differential interference contrast imaging method
KW  - sperm morphology measurement
KW  - image intensity
KW  - sperm subcellular structures
KW  - single sperm motility
KW  - sperm morphology parameters
KW  - illumination effect
KW  - Morphology
KW  - Switches
KW  - Head
KW  - Target tracking
KW  - Microscopy
KW  - Robots
DO  - 10.1109/ICRA.2018.8461252
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Measuring the motility and morphology parameters of motile cells is important for revealing their functional characteristics. This paper presents automation techniques that, for the first time, enable automated, non-invasive measurement of motility and morphology parameters of individual sperms. Compared to the status quo of qualitative estimation of single sperm's motility and morphology based on embryologists' empirical experience, the automation techniques provide quantitative data in nearly real time. An adapted joint probabilistic data association filter (JPDAF) was used for multi-sperm tracking and tackled challenges of identifying sperms that intersect or have small spatial distances. Since the standard differential interference contrast (DIC) imaging method has side illumination effect which causes inherent inhomogeneous image intensity and poses difficulties for accurate sperm morphology measurement, we integrated total variation norm into the quadratic cost function method, which together effectively removed inhomogeneous image intensity and retained sperm's subcellular structures after DIC image reconstruction. In order to relocate the same sperm of interest identified under low magnification after switching to high magnification, coordinate transformation was conducted to handle the changes in the field of view caused by magnification switch. Experimental results demonstrated an accuracy of 95.6% in sperm motility measurement and errors <;10% in morphology measurement.
ER  - 

TY  - CONF
TI  - Construction of Hepatic Lobule-Like Vascular Network by Using Magnetic Fields
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2688
EP  - 2693
AU  - E. Kim
AU  - M. Takeuchi
AU  - W. Atou
AU  - Y. Iwamoto
AU  - T. Nomura
AU  - T. Kozuka
AU  - A. Hasegawa
AU  - A. Ichikawa
AU  - T. Fukuda
PY  - 2018
KW  - biomagnetism
KW  - biomedical materials
KW  - blood vessels
KW  - cellular biophysics
KW  - ferrites
KW  - gels
KW  - liver
KW  - molecular biophysics
KW  - proteins
KW  - tissue engineering
KW  - cell viability
KW  - multilayered structure
KW  - different magnetic poles
KW  - magnetic tweezer
KW  - magnetizer
KW  - alginate gel fibers
KW  - magnetic fibers
KW  - kinds veins
KW  - portal vein
KW  - central vein
KW  - 3D cellular structure
KW  - transporting required nutrients
KW  - magnetic fields
KW  - vascular network
KW  - hepatic lobule-like
KW  - temperature 22.0 degC
KW  - time 3.0 d
KW  - Steel
KW  - Optical fiber networks
KW  - Veins
KW  - Magnetic flux
KW  - Three-dimensional displays
KW  - Electromagnetics
KW  - Toroidal magnetic fields
DO  - 10.1109/ICRA.2018.8460628
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Fabrication of vascular network is an important research for transporting required nutrients and oxygen to the artificial tissues. In this paper, we propose a novel method to construct a hepatic lobule-like vascular network in a 3D cellular structure. The network is simply constructed by three types of veins, central vein, portal vein, and sinusoids. To realize these kinds veins, we utilize two different sizes of steel rods and magnetic fibers for delivering nutrients in 3D cellular structure. Alginate gel fibers embedding ferrite particles are prepared as the same length and are magnetized by magnetizer at 3T. A magnetic tweezer with seven poles is proposed to generate sufficient forces that can manipulate magnetized fibers. Here, two types of rods are magnetized to different magnetic poles in order to attract opposite the end of fibers. This manipulation process is performed in fibrinogen and thrombin solution with liver cells (RLC-18). After solidification of the solution, we deposit solutions with cells and fibers repeatedly, and therefore, a multi-layered structure can be constructed. In addition, we investigate cell a viability in fibrin gel according to the depth of the gel. The result is that the deeper the depth of the gel is, the lower the cell viability is. The cell viability is conducted in several condition. As a result, at the low temperature (here at 22 °C), the viability of cell is increased.
ER  - 

TY  - CONF
TI  - A Framework for Sensorless Tissue Motion Tracking in Robotic Endomicroscopy Scanning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2694
EP  - 2699
AU  - P. Triantafyllou
AU  - P. Wisanuvej
AU  - S. Giannarou
AU  - J. Liu
AU  - G. Yang
PY  - 2018
KW  - biological tissues
KW  - biomedical optical imaging
KW  - endoscopes
KW  - image resolution
KW  - image segmentation
KW  - laser applications in medicine
KW  - medical image processing
KW  - medical robotics
KW  - optical microscopy
KW  - probe-based confocal laser endomicroscopy
KW  - robotic endomicroscopy scanning
KW  - image-quality metric
KW  - sensorless tissue motion tracking
KW  - ex vivo porcine tissue validate
KW  - autonomous endomicroscopy scanning
KW  - pCLE robotic tool
KW  - novel sensorless framework
KW  - sensorless approaches
KW  - endomicroscopy probe
KW  - robotic manipulation
KW  - tissue deformation
KW  - probe-tissue contact force
KW  - Probes
KW  - Tools
KW  - Force
KW  - Robot sensing systems
KW  - Strain
DO  - 10.1109/ICRA.2018.8462907
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recent advances in probe-based Confocal Laser Endomicroscopy (pCLE) enable real-time, in situ and in vivo tissue assessment at the micro scale. The limited field-of-view offered by pCLE necessitates the use of mosaicking to allow for accurate tissue characterization from the incoming image stream. However, mosaicking requires a series of contiguous good-quality images, which is particularly challenging because probe-tissue distance must be maintained within a very narrow working range at all times and probe-tissue contact force must be kept to a minimum so that tissue deformation is avoided. Robotic manipulation of the endomicroscopy probe has provided partial solution to these challenges, but sensorless approaches have not been thoroughly investigated up to date. This paper proposes a novel sensorless framework that uses a single non-reference image-quality metric to learn an approximation of tissue motion and subsequently track it. Moreover, a pCLE robotic tool for autonomous endomicroscopy scanning is designed and used for testing and validation purposes. Experiments on lens paper and ex vivo porcine tissue validate the philosophy of the framework.
ER  - 

TY  - CONF
TI  - SAT-C: An Efficient Control Strategy for Assembly of Heterogeneous Stress-Engineered MEMS Microrobots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2700
EP  - 2707
AU  - V. Foroutan
AU  - F. Farzami
AU  - D. Erricolo
AU  - R. Majumdar
AU  - I. Paprotny
PY  - 2018
KW  - controllability
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - position control
KW  - control primitives
KW  - control pulses
KW  - microrobotic systems
KW  - control policy
KW  - planar assembly
KW  - efficient control strategy
KW  - heterogeneous stress-engineered MEMS microrobots
KW  - efficient control framework
KW  - controllable microrobots
KW  - theoretical control strategy
KW  - multiple-shapes microassembly
KW  - arbitrary initial configuration
KW  - power delivery waveform
KW  - nonholonomic unicycles
KW  - multiple macroscale robots
KW  - direct drive wheels
KW  - Robots
KW  - Hysteresis
KW  - Microassembly
KW  - Micromechanical devices
KW  - Voltage control
KW  - Bandwidth
KW  - Actuators
DO  - 10.1109/ICRA.2018.8460481
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a new efficient control framework for controlling groups of heterogeneous stress-engineered MEMS microrobots for accomplishing micro-assembly. The objective is to maximize the number of controllable microrobots in the system while keeping the number of external global signals as low as possible. This work proposes a theoretical control strategy that could complete multiple-shapes microassembly from arbitrary initial configuration where all the control primitives can be accompanied with a constant number (O(1)) of control pulses of the power delivery waveform. We focus on microrobotic systems that can be modeled as nonholonomic unicycles. We validate the control policy with hardware experiments for implementing planar assembly using multiple macroscale robots with direct drive wheels. These results lay the foundation for developing new methods to control of a large number of MEMS microrobots.
ER  - 

TY  - CONF
TI  - Robotic Intracellular Manipulation: 3D Navigation and Measurement Inside a Single Cell
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2716
EP  - 2721
AU  - X. Wang
AU  - M. Luo
AU  - C. Ho
AU  - Z. Zhang
AU  - Q. Zhao
AU  - C. Dai
AU  - Y. Sun
PY  - 2018
KW  - biomagnetism
KW  - biomechanics
KW  - bioMEMS
KW  - Brownian motion
KW  - cancer
KW  - cellular biophysics
KW  - force control
KW  - medical robotics
KW  - micromanipulators
KW  - optical microscopy
KW  - patient treatment
KW  - position control
KW  - predictive control
KW  - magnetic bead
KW  - cell nucleus minor axes
KW  - cell nucleus major axes
KW  - stiffness polarity
KW  - sub-micrometer object
KW  - tissue level
KW  - untethered technique
KW  - 3D navigation
KW  - robotic intracellular manipulation
KW  - force-displacement data
KW  - Brownian motion-imposed constraint
KW  - high-resolution confocal microscopy
KW  - slow visual feedback
KW  - generalized predictive controller
KW  - single human bladder cancer cell
KW  - piconewton force control
KW  - sub-micrometer position control
KW  - magnetic micromanipulation task
KW  - size 0.7 mum
KW  - frequency 1.0 Hz
KW  - distance 0.43 mum
KW  - Magnetic resonance imaging
KW  - Magnetic levitation
KW  - Force
KW  - Magnetic noise
KW  - Magnetic shielding
KW  - Magnetic devices
KW  - Magnetic separation
DO  - 10.1109/ICRA.2018.8463170
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Magnetic micromanipulation is an untethered technique and has enabled numerous applications in the scale of millimeters to micrometers from the tissue level to cell level. However, existing systems are not capable of maneuvering a sub-micrometer object for precise force control, preventing the realization of intracellular manipulation or `fantastic voyage' inside a single cell. The magnetic micromanipulation task achieved in this work is sub-micrometer position control and piconewton force control of a sub-micron (0.7 μm) magnetic bead inside a single human bladder cancer cell (RT4). The magnetic bead was 3D positioned in the cell using a generalized predictive controller that effectively tackled the control challenge caused by the slow visual feedback (1 Hz) from high-resolution confocal microscopy. The average positioning error was quantified to be 0.43 μm, which is slightly larger than Brownian motion-imposed constraint (0.31 μm). The system is capable of three-dimensionally applying a maximum force of 60 pN with a resolution of 4 pN. In experiments, a 0.7 μm magnetic bead was controlled to move from an initial position in a cell to target positions on the cell nucleus. Force-displacement data were obtained from multiple locations along the cell nucleus' major and minor axes. The results revealed, for the first time, significantly higher stiffness exists in the cell nucleus' major axis than the minor axis. This stiffness polarity was likely attributed to the aligned stress fibers of actin filament inside the cells.
ER  - 

TY  - CONF
TI  - ViTac: Feature Sharing Between Vision and Tactile Sensing for Cloth Texture Recognition
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2722
EP  - 2727
AU  - S. Luo
AU  - W. Yuan
AU  - E. Adelson
AU  - A. G. Cohn
AU  - R. Fuentes
PY  - 2018
KW  - covariance analysis
KW  - feature extraction
KW  - image recognition
KW  - image texture
KW  - neural nets
KW  - touch (physiological)
KW  - tactile data
KW  - cloth textures
KW  - good recognition performance
KW  - perception performance
KW  - tactile sensing
KW  - shared representation space
KW  - feature sharing
KW  - cloth texture recognition
KW  - multimodal sensing ability
KW  - tactile images
KW  - Deep Maximum Covariance Analysis
KW  - learned features
KW  - DMCA framework
KW  - unimodal data
KW  - joint latent space
KW  - Gelsight sensor
KW  - deep neural networks
KW  - sensing modalities
KW  - Visualization
KW  - Tactile sensors
KW  - Cameras
KW  - Task analysis
KW  - Surface topography
DO  - 10.1109/ICRA.2018.8460494
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Vision and touch are two of the important sensing modalities for humans and they offer complementary information for sensing the environment. Robots could also benefit from such multi-modal sensing ability. In this paper, addressing for the first time (to the best of our knowledge) texture recognition from tactile images and vision, we propose a new fusion method named Deep Maximum Covariance Analysis (DMCA) to learn a joint latent space for sharing features through vision and tactile sensing. The features of camera images and tactile data acquired from a GelSight sensor are learned by deep neural networks. But the learned features are of a high dimensionality and are redundant due to the differences between the two sensing modalities, which deteriorates the perception performance. To address this, the learned features are paired using maximum covariance analysis. Results of the algorithm on a newly collected dataset of paired visual and tactile data relating to cloth textures show that a good recognition performance of greater than 90% can be achieved by using the proposed DMCA framework. In addition, we find that the perception performance of either vision or tactile sensing can be improved by employing the shared representation space, compared to learning from unimodal data.
ER  - 

TY  - CONF
TI  - Calibration and Analysis of Tactile Sensors as Slip Detectors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2744
EP  - 2751
AU  - K. Van Wyk
AU  - J. Falco
PY  - 2018
KW  - calibration
KW  - force sensors
KW  - neural nets
KW  - slip
KW  - tactile sensors
KW  - long short-term memory neural networks
KW  - high-quality slip detection
KW  - tactile technologies
KW  - electro-mechanical resistance
KW  - sensing mechanics
KW  - tactile sensing
KW  - robust slip detectors
KW  - sensor behavior
KW  - sensory responses
KW  - spectral analysis
KW  - sensory data points
KW  - systematic data collection process
KW  - robust slip detection
KW  - tactile-based slip detection
KW  - secondary force modulation protocols
KW  - human hand
KW  - mechanical transients
KW  - tactile afferents
KW  - Force
KW  - Tactile sensors
KW  - Detectors
KW  - Robustness
KW  - Spectral analysis
KW  - tactile sensors
KW  - slip detection
KW  - neural networks
KW  - deep learning
DO  - 10.1109/ICRA.2018.8461117
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The existence of tactile afferents sensitive to slip-related mechanical transients in the human hand augments the robustness of grasping through secondary force modulation protocols. Despite this knowledge and the fact that tactile-based slip detection has been researched for decades, robust slip detection is still not an out-of-the-box capability for any commercially available tactile sensor. This research seeks to bridge this gap with a comprehensive study addressing several aspects of slip detection. In particular, key developments include a systematic data collection process yielding millions of sensory data points, a spectral analysis of sensory responses providing insight into sensor behavior, and the application of Long Short-Term Memory (LSTM) neural networks to produce robust slip detectors from three commercially available sensors capable of tactile sensing. The sensing mechanics behind these sensors are all fundamentally different and leverage principles in electro-mechanical resistance, optics, and hydro-acoustics. Critically, slip detection performance of the tactile technologies is quantified through a measurement methodology that unveils the effects of data window size, sampling rate, material type, slip speed, and sensor manufacturing variability. Results indicate that the investigated commercial tactile sensors are inherently capable of high-quality slip detection.
ER  - 

TY  - CONF
TI  - Voronoi Features for Tactile Sensing: Direct Inference of Pressure, Shear, and Contact Locations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2752
EP  - 2757
AU  - L. Cramphorn
AU  - J. Lloyd
AU  - N. F. Lepora
PY  - 2018
KW  - calibration
KW  - computational geometry
KW  - computerised instrumentation
KW  - inference mechanisms
KW  - optical sensors
KW  - pressure measurement
KW  - pressure sensors
KW  - tactile sensors
KW  - transducers
KW  - Voronoi tessellation
KW  - visualisation mode
KW  - optical tactile sensor
KW  - shear magnitude
KW  - tactile contact
KW  - object grasping
KW  - manipulation
KW  - perception
KW  - contact location inference
KW  - pressure location inference
KW  - shear location inference
KW  - transducing method
KW  - local shear measurement
KW  - TacTip
KW  - calibration
KW  - complex systems
KW  - robot hands
KW  - Pins
KW  - Tactile sensors
KW  - Optical sensors
KW  - Data visualization
KW  - Biomedical optical imaging
KW  - Strain
DO  - 10.1109/ICRA.2018.8460644
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - There are a wide range of features that tactile contact provides, each with different aspects of information that can be used for object grasping, manipulation, and perception. In this paper inference of some key tactile features, tip displacement, contact location, shear direction and magnitude, is demonstrated by introducing a novel method of transducing a third dimension to the sensor data via Voronoi tessellation. The inferred features are displayed throughout the work in a new visualisation mode derived from the Voronoi tessellation; these visualisations create easier interpretation of data from an optical tactile sensor that measures local shear from displacement of internal pins (the TacTip). The output values of tip displacement and shear magnitude are calibrated to appropriate mechanical units and validate the direction of shear inferred from the sensor. We show that these methods can infer the direction of shear to ~2.3° without the need for training a classifier or regressor. The approach demonstrated here will increase the versatility and generality of the sensors and thus allow sensor to be used in more unstructured and unknown environments, as well as improve the use of these tactile sensors in more complex systems such as robot hands.
ER  - 

TY  - CONF
TI  - Learning Manipulation Graphs from Demonstrations Using Multimodal Sensory Signals
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2758
EP  - 2765
AU  - Z. Su
AU  - O. Kroemer
AU  - G. E. Loeb
AU  - G. S. Sukhatme
AU  - S. Schaal
PY  - 2018
KW  - dexterous manipulators
KW  - graph theory
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - tactile sensors
KW  - erroneous contact states
KW  - manipulation demonstrations
KW  - motor primitive
KW  - manipulation task
KW  - insertion tasks
KW  - learned manipulation graphs
KW  - robust manipulation executions
KW  - sensory goals
KW  - multimodal sensory signals
KW  - complex contact manipulation tasks
KW  - contact state
KW  - contact state information
KW  - Barrett arm
KW  - BioTacs
KW  - contact changes
KW  - Robot sensing systems
KW  - Task analysis
KW  - Fasteners
KW  - Trajectory
KW  - Motion segmentation
KW  - Vibrations
DO  - 10.1109/ICRA.2018.8461121
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Complex contact manipulation tasks can be decomposed into sequences of motor primitives. Individual primitives often end with a distinct contact state, such as inserting a screwdriver tip into a screw head or loosening it through twisting. To achieve robust execution, the robot should be able to verify that the primitive's goal has been reached as well as disambiguate it from erroneous contact states. In this paper, we introduce and evaluate a framework to autonomously construct manipulation graphs from manipulation demonstrations. Our manipulation graphs include sequences of motor primitives for performing a manipulation task as well as corresponding contact state information. The sensory models for the contact states allow the robot to verify the goal of each motor primitive as well as detect erroneous contact changes. The proposed framework was experimentally evaluated on grasping, unscrewing, and insertion tasks on a Barrett arm and hand equipped with two BioTacs. The results of our experiments indicate that the learned manipulation graphs achieve more robust manipulation executions by confirming sensory goals as well as discovering and detecting novel failure modes.
ER  - 

TY  - CONF
TI  - ExoSense: Measuring Manipulation in a Wearable Manner
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2774
EP  - 2781
AU  - E. Battaglia
AU  - M. G. Catalano
AU  - G. Grioli
AU  - M. Bianchi
AU  - A. Bicchi
PY  - 2018
KW  - design engineering
KW  - dexterous manipulators
KW  - end effectors
KW  - force control
KW  - force measurement
KW  - force sensors
KW  - grippers
KW  - manipulator dynamics
KW  - medical robotics
KW  - position control
KW  - tactile sensors
KW  - torque
KW  - end-effector posture measurements
KW  - human internal grasp force variations
KW  - robotic hand
KW  - passive hand exoskeleton
KW  - wearable manner
KW  - design engineering
KW  - forces measurement
KW  - exosense
KW  - robotic manipulators control
KW  - fingertip wearable force
KW  - torque sensing system
KW  - position control
KW  - Kinematics
KW  - Exoskeletons
KW  - Robot sensing systems
KW  - Force
KW  - Calibration
DO  - 10.1109/ICRA.2018.8460498
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Grasp and manipulation is a complex task, deceivingly simple to accomplish for humans in everyday life, yet challenging to implement in a robotic hand. There is a trend in literature to use information obtained from studies on human grasp for the design and control of robotic manipulators. However, the effectiveness of such approach is dependent on the measurement tools that are available for use with human hands. While there are many sensing solutions that are designed for this purpose, obtaining a complete set of measurements of forces during grasp interaction is still challenging. In this work we aim to bridge this gap by introducing ExoSense, a passive hand exoskeleton. This device can provide position and orientation of the fingertips and, when integrated with the fingertip wearable force/torque sensing system ThimbleSense, a complete characterization of manipulation in terms of generalized forces and position of contacts on each fingertip in a completely wearable and unconstrained manner. After validating the device in terms of end-effector posture measurements and overall accuracy of grasp measurements, we report on a preliminary experiment aiming to show the potentialities of the system to study human internal grasp force variations and for neuroscientific investigation in general.
ER  - 

TY  - CONF
TI  - Robotizing Double-Bar Ankle-Foot Orthosis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2782
EP  - 2787
AU  - T. Noda
AU  - A. Takai
AU  - T. Teramae
AU  - E. Hirookai
AU  - K. Hase
AU  - J. Morimoto
PY  - 2018
KW  - actuators
KW  - cables (mechanical)
KW  - gait analysis
KW  - iterative learning control
KW  - medical robotics
KW  - muscle
KW  - orthotics
KW  - patient rehabilitation
KW  - pneumatic actuators
KW  - position control
KW  - pulleys
KW  - shafts
KW  - springs (mechanical)
KW  - double-bar ankle-foot orthosis
KW  - post-stroke gait rehabilitation
KW  - double-bar AFO
KW  - rehabilitation facilities
KW  - pneumatic actuator
KW  - Bowden cable force-transmission system
KW  - modular joint system
KW  - Modular Exoskeletal Joint
KW  - MEJ
KW  - hollow shaft
KW  - AFO's pivot
KW  - Bowden cables
KW  - contraction forces
KW  - actuation scheme
KW  - Nested-cylinder Pneumatic Artificial Muscle system
KW  - PAM
KW  - ideal actuation system
KW  - exoskeletal robots
KW  - NcPAM houses
KW  - cable-tensioning spring
KW  - cable tension
KW  - cable stopper
KW  - ankle-joint trajectory tracking performances
KW  - integrated system
KW  - iterative learning control
KW  - Robots
KW  - Force
KW  - Actuators
KW  - Mechanical cables
KW  - Exoskeletons
KW  - Torque
KW  - Springs
DO  - 10.1109/ICRA.2018.8462911
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces an approach that robotizes an ankle-foot orthosis (AFO). In particular, toward post-stroke gait rehabilitation, we robotize a double-bar AFO, which is widely used in rehabilitation facilities, by newly designing a modular joint, a pneumatic actuator, and a Bowden cable force-transmission system. Our modular joint system, called the Modular Exoskeletal Joint (MEJ), has a hollow shaft for simple attachment to an AFO's pivot. We designed MEJ to compactly house an encoder that is built in a bearing in a pulley. We adopted Bowden cables to transmit contraction forces from an actuator to the MEJ. As an actuation scheme, we developed the Nested-cylinder Pneumatic Artificial Muscle (NcPAM) system. Even though PAMs are mechanically compliant and lightweight, they can still generate a large force. Therefore, they can provide an ideal actuation system for exoskeletal robots. The nested-cylinder in NcPAM houses a cable-tensioning spring to properly maintain small cable tension for passive movements and a cable stopper to connect the PAM and the cable for properly transmitting the large force generated by PAM. We show the ankle-joint trajectory tracking performances of this integrated system using iterative learning control.
ER  - 

TY  - CONF
TI  - Design and Benchtop Validation of a Powered Knee-Ankle Prosthesis with High-Torque, Low-Impedance Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2788
EP  - 2795
AU  - T. Elery
AU  - S. Rezazadeh
AU  - C. Nesler
AU  - J. Doan
AU  - H. Zhu
AU  - R. D. Gregg
PY  - 2018
KW  - actuators
KW  - artificial limbs
KW  - gait analysis
KW  - motion control
KW  - open loop systems
KW  - torque control
KW  - powered knee-ankle prosthesis
KW  - low-impedance actuators
KW  - high torque density actuators
KW  - low-reduction transmissions
KW  - low-speed motor
KW  - low mechanical impedance
KW  - high backdrivability
KW  - robotic prosthetic legs
KW  - negligible unmodeled actuator dynamics
KW  - power regeneration
KW  - free-swinging knee tests
KW  - open-loop impedance control tests
KW  - intrinsic impedance
KW  - joint impedance
KW  - torque feedback
KW  - powered knee-and-ankle transfemoral prosthetic leg
KW  - actuation styles
KW  - free-swinging knee motion
KW  - size 3.0 nm
KW  - Actuators
KW  - Gears
KW  - Legged locomotion
KW  - Knee
KW  - Torque
KW  - Brushless DC motors
DO  - 10.1109/ICRA.2018.8461259
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes the design of a powered knee-and-ankle transfemoral prosthetic leg, which implements high torque density actuators with low-reduction transmissions. The low reduction of the transmission coupled with a high-torque and low-speed motor creates an actuator with low mechanical impedance and high backdrivability. This style of actuation presents several possible benefits over modern actuation styles implemented in emerging robotic prosthetic legs. Such benefits include free-swinging knee motion, compliance with the ground, negligible unmodeled actuator dynamics, and greater potential for power regeneration. Benchtop validation experiments were conducted to verify some of these benefits. Backdrive and free-swinging knee tests confirm that both joints can be backdriven by small torques (~3 Nm). Bandwidth tests reveal that the actuator is capable of achieving frequencies required for walking and running. Lastly, open-loop impedance control tests prove that the intrinsic impedance and unmodeled dynamics of the actuator are sufficiently small to control joint impedance without torque feedback.
ER  - 


TY  - CONF
TI  - Variable Transmission Series Elastic Actuator for Robotic Prosthesis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2796
EP  - 2803
AU  - X. Sun
AU  - F. Sugai
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - actuators
KW  - artificial limbs
KW  - biomechanics
KW  - elasticity
KW  - legged locomotion
KW  - medical robotics
KW  - motion control
KW  - prosthetics
KW  - robot dynamics
KW  - torque control
KW  - robotic prosthetic knee
KW  - passive mode test
KW  - passive prosthesis
KW  - rotary motion
KW  - linear motion
KW  - slider crank mechanism
KW  - knee angle
KW  - variable transmission mechanism
KW  - SuKnee
KW  - robotic prosthesis
KW  - variable transmission series elastic actuator
KW  - Knee
KW  - Prosthetics
KW  - Legged locomotion
KW  - Springs
KW  - Batteries
KW  - Force
DO  - 10.1109/ICRA.2018.8460796
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we introduce a novel robotic prosthetic knee as shown in Fig. 1 (named as SuKnee) with variable transmission mechanism that could vary transmission ratio while knee angle varies during ambulation activities. A slider crank mechanism is utilized to transform linear motion of series elastic actuator to rotary motion of knee joint. And it contributes to variable transmission ratio with knee angle, which help obtain desired speed variation and torque output in different activities in one mechanism. This feature could uniquely give the SuKnee both: the torque necessary to assist with standing up from a chair and the speed necessary to swing the leg forward during walking. The knee has an active mode, where it operates with batteries and is capable of providing external power, and a passive mode, behaving like a passive prosthesis. Preliminary tests have been performed by a transfemoral amputee and SuKnee could provide user with power to assist walking on level ground and standing up from a chair. And a passive mode test shows it could work like passive prosthesis after battery exhaustion.
ER  - 

TY  - CONF
TI  - Towards Restoring Locomotion for Paraplegics: Realizing Dynamically Stable Walking on Exoskeletons
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2804
EP  - 2811
AU  - T. Gurriet
AU  - S. Finet
AU  - G. Boeris
AU  - A. Duburcq
AU  - A. Hereid
AU  - O. Harib
AU  - M. Masselin
AU  - J. Grizzle
AU  - A. D. Ames
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - optimisation
KW  - robot dynamics
KW  - stable walking gaits
KW  - direct collocation optimization formulation
KW  - paraplegics
KW  - crutch-less dynamic walking
KW  - lower-body exoskeleton
KW  - French start-up company Wandercraft
KW  - partial hybrid zero dynamics framework
KW  - PHZD
KW  - legged locomotion
KW  - Exoskeletons
KW  - Legged locomotion
KW  - Foot
KW  - Companies
KW  - Optimization
KW  - Kinematics
DO  - 10.1109/ICRA.2018.8460647
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the first experimental results of crutch-less dynamic walking with paraplegics on a lower-body exoskeleton: ATALANTE, designed by the French start-up company Wandercraft. The methodology used to achieve these results is based on the partial hybrid zero dynamics (PHZD) framework for formally generating stable walking gaits. A direct collocation optimization formulation is used to provide fast and efficient generation of gaits tailored to each patient. These gaits are then implemented on the exoskeleton for three paraplegics. The end result is dynamically stable walking in an exoskeleton without the need for crutches. After a short period of tuning by the engineers and practice by the subjects, each subject was able to dynamically walk across a room of about 10 m up to a speed of 0.15 m/s (0.5 km/h) without the need for crutches or any other kind of assistance.
ER  - 

TY  - CONF
TI  - Autonomous Multi-Joint Soft Exosuit for Assistance with Walking Overground
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2812
EP  - 2819
AU  - S. Lee
AU  - N. Karavas
AU  - B. T. Quinlivan
AU  - D. LouiseRyan
AU  - D. Perry
AU  - A. Eckert-Erdheim
AU  - P. Murphy
AU  - T. Greenberg Goldy
AU  - N. Menard
AU  - M. Athanassiu
AU  - J. Kim
AU  - G. Lee
AU  - I. Galiana
AU  - C. J. Walsh
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - force control
KW  - gait analysis
KW  - medical robotics
KW  - motion control
KW  - autonomous multijoint soft exosuit
KW  - human locomotion
KW  - assistive torques
KW  - gait assistance
KW  - overground walking
KW  - soft exosuit assists
KW  - ankle plantarflexion
KW  - hip flexion
KW  - hip extension
KW  - mobile actuation system
KW  - high assistive forces
KW  - force profiles
KW  - walking cycle
KW  - control adaptation method
KW  - force consistency
KW  - peak force
KW  - target force
KW  - country-course walking
KW  - RMS error
KW  - human energy economy
KW  - Legged locomotion
KW  - Hip
KW  - Belts
KW  - Force
KW  - Actuators
KW  - Thigh
DO  - 10.1109/ICRA.2018.8460972
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft exosuits are a new approach for assisting with human locomotion, which applies assistive torques to the wearer through functional apparel. In this paper, we present a new version of autonomous multi-joint soft exosuit for gait assistance, particularly designed for overground walking. The soft exosuit assists with ankle plantarflexion, hip flexion, and hip extension, equally distributing the forces between ankle plantarflexion and hip flexion. A mobile actuation system was developed to generate high assistive forces, and Bowden cables are used to transmit the forces to the exosuit. A sensor harness connects two load cells and three IMU s per leg that are used to measure real-time data for a controller that commands desired force profiles as a function of the walking cycle. In addition, a control adaptation method was developed which adjusts control parameters while walking on irregular surfaces. In preliminary studies, the proposed method substantially improved the force consistency while walking over uneven terrain. Specifically, the number of steps where the peak force deviated from the target force decreased from 100 to 57 out of 250 steps, and RMS error on the peak force decreased from 90.0 N to 76.6 N with respect to 300 N target force. Also, a two-subject case study on country-course walking demonstrated the potential of this soft exosuit to improve human energy economy while walking overground.
ER  - 

TY  - CONF
TI  - A Lightweight and Efficient Portable Soft Exosuit for Paretic Ankle Assistance in Walking After Stroke
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2820
EP  - 2827
AU  - J. Bae
AU  - C. Siviy
AU  - M. Rouleau
AU  - N. Menard
AU  - K. O'Donnell
AU  - I. Geliana
AU  - M. Athanassiu
AU  - D. Ryan
AU  - C. Bibeau
AU  - L. Sloot
AU  - P. Kudzia
AU  - T. Ellis
AU  - L. Awad
AU  - C. J. Walsh
PY  - 2018
KW  - gait analysis
KW  - medical robotics
KW  - patient rehabilitation
KW  - hemiparetic gait
KW  - paretic ankle assistance
KW  - overground walking
KW  - heterogeneous gait patterns
KW  - mechanical assistance
KW  - clinical gait training
KW  - optimized soft exosuit
KW  - poststroke patients
KW  - soft exosuits
KW  - soft wearable robots
KW  - paretic ankle dorsiflexion
KW  - forward propulsion symmetry
KW  - impaired paretic ankle plantarflexion
KW  - paretic ankle function
KW  - walking deficits
KW  - Legged locomotion
KW  - Prototypes
KW  - Foot
KW  - Actuators
KW  - Force
KW  - Mechanical cables
DO  - 10.1109/ICRA.2018.8461046
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Hemiparetic gait after stroke is typically asymmetric and energetically inefficient. A major contributor to walking deficits is impaired paretic ankle function. Impaired paretic ankle plantarflexion (PF) reduces forward propulsion symmetry and impaired paretic ankle dorsiflexion (DF) diminishes ground clearance during swing. We have developed soft wearable robots (soft exosuits) to assist paretic PF and DF during walking after stroke. Through experimental studies with poststroke patients, we have demonstrated that exosuits can improve forward propulsion symmetry and ground clearance in walking, ultimately reducing the metabolic cost of walking. This paper presents an optimized soft exosuit aimed at use in clinical gait training for patients poststroke. The optimized exosuit is lightweight, easy to don and doff, and capable of efficiently delivering mechanical assistance to the paretic ankle. This paper focuses on the optimized controller that can deliver well-timed consistent ankle assistance to patients. A preliminary study was performed using this exosuit with three poststroke patients with heterogeneous gait patterns. Results showed that compared to a previously published controller, more consistent assistive force profiles could be delivered to individuals poststroke while consuming 50% less electrical power. Additionally, a preliminary biomechanical assessment was performed during overground walking.
ER  - 

TY  - CONF
TI  - Comparing Assistive Admittance Control Algorithms for a Trunk Supporting Exoskeleton
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2828
EP  - 2834
AU  - P. G. Van Lenthe
AU  - S. Verros
AU  - E. E. G. Hekman
AU  - R. Carloni
AU  - H. F. J. M. Koopman
PY  - 2018
KW  - diseases
KW  - feedforward
KW  - handicapped aids
KW  - human-robot interaction
KW  - medical robotics
KW  - muscle
KW  - assistive admittance control algorithms
KW  - trunk supporting exoskeleton
KW  - duchenne muscular dystrophy
KW  - health care
KW  - active exoskeletons
KW  - daily living
KW  - trunk supporting robot
KW  - constant parameters
KW  - variable parameters
KW  - control laws
KW  - feedforward
KW  - variable admittance controllers
KW  - standard admittance
KW  - feed-forward force
KW  - Fitts-like experiment
KW  - Force
KW  - Admittance
KW  - Robots
KW  - Trajectory
KW  - Force measurement
KW  - Exoskeletons
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461062
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Duchenne muscular dystrophy leaves patients with severe dependency on health care. In an effort to increase independence and quality of life, active exoskeletons are developed to support activities of daily living. This study is dedicated to the development and assessment of three different admittance control algorithms for a trunk supporting robot; a law with constant parameters, a law with added feed-forward force, and a law with variable parameters. A Fitts'-like experiment with 12 healthy subjects was performed to compare the control laws. The results show decreased movement times for the feedforward and variable admittance controllers with respect to the standard admittance.
ER  - 

TY  - CONF
TI  - Dynamic Actuator Selection and Robust State-Feedback Control of Networked Soft Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2857
EP  - 2864
AU  - N. Ebrahimi
AU  - S. Nugroho
AU  - A. F. Taha
AU  - N. Gatsis
AU  - W. Gao
AU  - A. Jafari
PY  - 2018
KW  - control system synthesis
KW  - electroactive polymer actuators
KW  - pneumatic actuators
KW  - robots
KW  - robust control
KW  - state feedback
KW  - Electromagnetic Soft Actuator
KW  - logistic constraints
KW  - dynamic actuator selection
KW  - networked soft actuators
KW  - soft robotic systems
KW  - dynamic environments
KW  - robust state-feedback control
KW  - control input bounds
KW  - minimal actuator selection problem
KW  - physical network
KW  - artificial muscle fiber
KW  - soft actuator matrix
KW  - networked ESAs
KW  - robust control
KW  - soft-body actuators
KW  - actuator selection algorithms
KW  - realtime control
KW  - lightweight power sources
KW  - external stimuli
KW  - Actuators
KW  - Muscles
KW  - Force
KW  - Coils
KW  - Robust control
KW  - Magnetic cores
KW  - Springs
DO  - 10.1109/ICRA.2018.8460679
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The design of robots that are light, soft, powerful is a grand challenge. Since they can easily adapt to dynamic environments, soft robotic systems have the potential of changing the status-quo of bulky robotics. A crucial component of soft robotics is a soft actuator that is activated by external stimuli to generate desired motions. Unfortunately, there is a lack of powerful soft actuators that operate through lightweight power sources. To that end, we recently designed a highly scalable, flexible, biocompatible Electromagnetic Soft Actuator (ESA). With ESAs, artificial muscles can be designed by integrating a network of ESAs. The main research gap addressed in this work is in the absence of system-theoretic understanding of the impact of the realtime control and actuator selection algorithms on the performance of networked soft-body actuators and ESAs. The objective of this paper is to establish a framework that guides the analysis and robust control of networked ESAs. A novel ESA is described, and a configuration of soft actuator matrix to resemble artificial muscle fiber is presented. A mathematical model which depicts the physical network is derived, considering the disturbances due to external forces and linearization errors as an integral part of this model. Then, a robust control and minimal actuator selection problem with logistic constraints and control input bounds is formulated, and tractable computational routines are proposed with numerical case studies.
ER  - 

TY  - CONF
TI  - Safety and Guaranteed Stability Through Embedded Energy-Aware Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2902
EP  - 2908
AU  - G. A. Folkertsma
AU  - S. S. Groothuis
AU  - S. Stramigioli
PY  - 2018
KW  - actuators
KW  - human-robot interaction
KW  - stability
KW  - embedded energy-aware actuators
KW  - robots
KW  - control algorithm
KW  - discrete-time computer
KW  - communication delays
KW  - model-free passivity
KW  - safety layer
KW  - complex robotic systems
KW  - physical human-robot interaction
KW  - safety mechanism
KW  - Actuators
KW  - Robots
KW  - Safety
KW  - Force
KW  - Springs
KW  - Shock absorbers
DO  - 10.1109/ICRA.2018.8463174
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Safety is essential for robots in unknown environments, especially when there is physical Human-Robot Interaction (pHRI). Control over energy, or passivity, is an effective safety mechanism. However, when the control algorithm is implemented in a discrete-time computer, computation and communication delays readily lead to loss of passivity and to instability. In this paper, a way to make the actuators aware of the energy that they inject into the system is presented. Passivity and stability are then always guaranteed, even in situations of total communication loss. These Embedded Energy-Aware Actuators are a model-free passivity and safety layer that make complex robotic systems dependable, well-behaved and safe. The proposed method is validated in simulation and experiments.
ER  - 

TY  - CONF
TI  - High-Level MLN-Based Approach for Spatial Context Disambiguation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2909
EP  - 2915
AU  - O. Adjali
AU  - A. Ramdane-Cherif
PY  - 2018
KW  - control engineering computing
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - mobile robots
KW  - probability
KW  - robot dynamics
KW  - sensor fusion
KW  - spatial context disambiguation
KW  - probabilistic MLN-based model
KW  - incomplete knowledge
KW  - High-level task planning
KW  - semantic spatial relations
KW  - robot dynamic
KW  - High-level MLN
KW  - MLN probabilistic reasoning
KW  - Robot sensing systems
KW  - Context modeling
KW  - Semantics
KW  - Probabilistic logic
KW  - Object recognition
DO  - 10.1109/ICRA.2018.8460923
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we propose a probabilistic MLN-based model for spatial context disambiguation. This model serves as a solution for the problem of incomplete knowledge in High-level task planning. By applying the state of the art MLN probabilistic reasoning such as MCSAT, we determine the concept class of the current spatial context of the robot and contribute by combining semantic spatial relations with observed data at different timesteps. The inherent uncertainty of robot dynamic environments makes the proposed approach suitable to deal with partial observability and sensing limitations of robots. Simulation experiments and evaluation results are presented to validate our model.
ER  - 

TY  - CONF
TI  - Pairwise Consistent Measurement Set Maximization for Robust Multi-Robot Map Merging
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2916
EP  - 2923
AU  - J. G. Mangelson
AU  - D. Dominic
AU  - R. M. Eustice
AU  - R. Vasudevan
PY  - 2018
KW  - expectation-maximisation algorithm
KW  - graph theory
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - PCM
KW  - robust multirobot map
KW  - robust selection
KW  - robust SLAM methods
KW  - multirobot case
KW  - simultaneous localization and mapping
KW  - pairwise consistency set maximization
KW  - pairwise consistent measurement set maximization
KW  - odometry backbone
KW  - Simultaneous localization and mapping
KW  - Robot kinematics
KW  - Phase change materials
KW  - Trajectory
KW  - Robustness
KW  - Merging
DO  - 10.1109/ICRA.2018.8460217
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper reports on a method for robust selection of inter-map loop closures in multi-robot simultaneous localization and mapping (SLAM). Existing robust SLAM methods assume a good initialization or an “odometry backbone” to classify inlier and outlier loop closures. In the multi-robot case, these assumptions do not always hold. This paper presents an algorithm called Pairwise Consistency Maximization (PCM) that estimates the largest pairwise internally consistent set of measurements. Finding the largest pairwise internally consistent set can be transformed into an instance of the maximum clique problem from graph theory, and by leveraging the associated literature it can be solved in realtime. This paper evaluates how well PCM approximates the combinatorial gold standard using simulated data. It also evaluates the performance of PCM on synthetic and real-world data sets in comparison with DCS, SCGP, and RANSAC, and shows that PCM significantly outperforms these methods.
ER  - 

TY  - CONF
TI  - Task-Specific Sensor Planning for Robotic Assembly Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2932
EP  - 2939
AU  - G. Rosman
AU  - C. Choi
AU  - M. Dogar
AU  - J. W. Fisher
AU  - D. Rus
PY  - 2018
KW  - feedback
KW  - multi-robot systems
KW  - open loop systems
KW  - path planning
KW  - robotic assembly
KW  - sensors
KW  - task-specific sensor planning
KW  - robotic assembly tasks
KW  - sensory feedback
KW  - task planning
KW  - open-loop simulation
KW  - task-specific uncertainty approximants
KW  - multirobot planner
KW  - multirobot tasks
KW  - Robot sensing systems
KW  - Task analysis
KW  - Uncertainty
KW  - Planning
KW  - Robotic assembly
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460194
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When performing multi-robot tasks, sensory feedback is crucial in reducing uncertainty for correct execution. Yet the utilization of sensors should be planned as an integral part of the task planning, taken into account several factors such as the tolerance of different inferred properties of the scene and interaction with different agents. In this paper we handle this complex problem in a principled, yet efficient way. We use surrogate predictors based on open-loop simulation to estimate and bound the probability of success for specific tasks. We reason about such task-specific uncertainty approximants and their effectiveness. We show how they can be incorporated into a multi-robot planner, and demonstrate results with a team of robots performing assembly tasks.
ER  - 

TY  - CONF
TI  - Map-Aware Particle Filter for Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2940
EP  - 2947
AU  - A. Rechy Rormero
AU  - P. V. K. Borges
AU  - A. Pfrunder
AU  - A. Elfes
PY  - 2018
KW  - distance measurement
KW  - Global Positioning System
KW  - optical radar
KW  - particle filtering (numerical methods)
KW  - SLAM (robots)
KW  - map-aware particle filter
KW  - 2D LiDAR localization
KW  - GPS localization
KW  - map information
KW  - localization sensors
KW  - particle filter framework
KW  - map-matching
KW  - prior occupancy grid
KW  - vehicle localization
KW  - Trajectory
KW  - Roads
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Sensors
KW  - Particle filters
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2018.8460707
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work presents a method to improve vehicle localization by using the information from a prior occupancy grid to bound the possible poses. The method, named Map-Aware Particle Filter, uses a nonlinear approach to map-matching that can be integrated into a particle filter framework for localization. Each particle is re-weighted based on the validity of its current position in the map. In addition, we buffer the trajectory followed by the vehicle and then append it to each particle's pose. We then quantify the overlap between the trajectory and the map's free space. This serves as a measure of each particle's validity given the trajectory and the shape of the map. We evaluated the method by performing experiments with different types of localization sensors: First, (i) we significantly reduced the drift inherent to dead reckoning. By only using wheel odometry and map information we achieved loop closure over a distance of approximately 3 km. We also (ii) increased the accuracy of GPS localization. Finally, (iii) we fused a fragile 2D LiDAR localization with the map information. The resulting system had a higher robustness and managed to close the loop in an outdated map where it had failed before.
ER  - 

TY  - CONF
TI  - Active Motion-Based Communication for Robots with Monocular Vision
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2948
EP  - 2955
AU  - H. Nishimura
AU  - M. Schwager
PY  - 2018
KW  - Bayes methods
KW  - decoding
KW  - estimation theory
KW  - image classification
KW  - Kalman filters
KW  - Monte Carlo methods
KW  - robot vision
KW  - online Bayesian estimation algorithm
KW  - monocular camera
KW  - receiver robot
KW  - sending robot
KW  - active motion-based communication
KW  - accurate trajectory classification
KW  - trajectory class distribution
KW  - active vision-based control policy
KW  - message decoding
KW  - trajectory identification
KW  - monocular vision model
KW  - receiving robot
KW  - Trajectory
KW  - Receivers
KW  - Cameras
KW  - Robot vision systems
KW  - Bayes methods
KW  - Estimation
DO  - 10.1109/ICRA.2018.8463152
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we consider motion as a means of sending messages between robots. We focus on a scenario in which a message is encoded in a sending robot's trajectory, and decoded by a receiver robot equipped with a monocular camera. The relative pose between the robots is unknown. We introduce an online Bayesian estimation algorithm based on the Multi-hypothesis Extended Kalman Filter for the receiving robot to simultaneously estimate its relative pose to the sender, and the trajectory class of the sender. The difficulty in this problem arises from the monocular vision model of the receiver and the unknown relative pose between robots, which brings inherent ambiguity into the trajectory identification, and hence the message decoding. An active vision-based control policy is derived and combined with the Bayesian estimation in order to deal with this difficulty. The policy is constructed online based on Monte Carlo Tree Search and aims at reducing the entropy over the trajectory class distribution. The algorithm has broad applications, e.g., to intent modeling and motion prediction for autonomous driving and autonomous drone operations. Simulation results demonstrate that the proposed estimation algorithm and the control policy result in an accurate trajectory classification.
ER  - 

TY  - CONF
TI  - A Novel Recurrent Neural Network for Improving Redundant Manipulator Motion Planning Completeness
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2956
EP  - 2961
AU  - Y. Li
AU  - S. Li
AU  - B. Hannaford
PY  - 2018
KW  - collision avoidance
KW  - neurocontrollers
KW  - recurrent neural nets
KW  - redundant manipulators
KW  - Recurrent Neural Networks
KW  - manipulator control optimization
KW  - obstacle avoidance
KW  - RNN control
KW  - redundant manipulator motion planning
KW  - Planning
KW  - Manipulators
KW  - Task analysis
KW  - Recurrent neural networks
KW  - Collision avoidance
KW  - Robustness
KW  - Aerospace electronics
KW  - Motion Planning
KW  - Kinematic Control
KW  - Recurrent Neural Networks
KW  - Redundant Manipulator
KW  - Robot
DO  - 10.1109/ICRA.2018.8461204
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recurrent Neural Networks (RNNs) demonstrated advantages on control precision, system robustness and computational efficiency, and have been widely applied to redundant manipulator control optimization. Existing RNN control schemes locally optimize trajectories and are efficient and reliable on obstacle avoidance. However, for motion planning, they suffer from local minimum and do not have planning completeness. This work explained the cause of the planning incompleteness and addressed the problem with a novel RNN control scheme. The paper presented the proposed method in detail and analyzed the global stability and the planning completeness in theory. The proposed method was compared with other three control schemes on the precision, the robustness and the planning completeness in software simulation and the results shows the proposed method has improved precision and robustness, and planning completeness.
ER  - 

TY  - CONF
TI  - Robust Collision Avoidance via Sliding Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2962
EP  - 2969
AU  - B. T. Lopez
AU  - J. Slotine
AU  - J. P. How
PY  - 2018
KW  - adaptive control
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - nonlinear control systems
KW  - parameter estimation
KW  - robust control
KW  - trajectory control
KW  - uncertain systems
KW  - variable structure systems
KW  - robust collision avoidance
KW  - planning algorithms
KW  - robots
KW  - unknown environments
KW  - cluttered environments
KW  - model uncertainty
KW  - external disturbances
KW  - nonlinear control theory
KW  - CASC
KW  - safe trajectory
KW  - parameter estimation
KW  - composite adaptive sliding controller
KW  - quadrotor navigation
KW  - Trajectory
KW  - Electron tubes
KW  - Uncertainty
KW  - Robustness
KW  - Optimization
KW  - Adaptation models
DO  - 10.1109/ICRA.2018.8460817
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recent advances in perception and planning algorithms have enabled robots to navigate autonomously through unknown, cluttered environments at high-speeds. A key component of these systems is the ability to identify, select, and execute a safe trajectory around obstacles. Many of these systems, however, lack performance guarantees because model uncertainty and external disturbances are ignored when a trajectory is selected for execution. This work leverages results from nonlinear control theory to establish a bound on tracking performance that can be used to select a provably safe trajectory. The Composite Adaptive Sliding Controller (CASC) provides robustness to disturbances and reduces model uncertainty through high-rate parameter estimation. CASC is demonstrated in simulation and hardware to significantly improve the performance of a quadrotor navigating through unknown environments with external disturbances and unknown model parameters.
ER  - 

TY  - CONF
TI  - Optimizing Simulations with Noise-Tolerant Structured Exploration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2970
EP  - 2977
AU  - K. Choromanski
AU  - A. Iscen
AU  - V. Sindhwani
AU  - J. Tan
AU  - E. Coumans
PY  - 2018
KW  - digital simulation
KW  - fast Fourier transforms
KW  - finite difference methods
KW  - gradient methods
KW  - Hadamard transforms
KW  - Jacobian matrices
KW  - legged locomotion
KW  - Newton method
KW  - optimisation
KW  - rendering (computer graphics)
KW  - Walsh functions
KW  - trajectory optimizers
KW  - noisy dynamics
KW  - quasiNewton optimizer
KW  - turning policies
KW  - noise-tolerant structured exploration
KW  - blackbox optimization
KW  - parameter perturbation directions
KW  - structured orthogonal matrices
KW  - structured finite differences
KW  - continuous control tasks
KW  - agile walking learning
KW  - Fast Walsh-Hadamard Fourier Transform
KW  - FWHT FFT
KW  - drop-in noise-tolerant replacement
KW  - quadruped locomotion
KW  - deep reinforcement learning
KW  - Mujoco simulator
KW  - 3D renderers
KW  - Perturbation methods
KW  - Optimization
KW  - Standards
KW  - Smoothing methods
KW  - Robots
KW  - Jacobian matrices
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460492
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a simple drop-in noise-tolerant replacement for the standard finite difference procedure used ubiquitously in blackbox optimization. In our approach, parameter perturbation directions are defined by a family of structured orthogonal matrices. We show that at the small cost of computing a Fast Walsh-Hadamard/Fourier Transform (FWHT/FFT), such structured finite differences consistently give higher quality approximation of gradients and Jacobians in comparison to vanilla approaches that use coordinate directions or random Gaussian perturbations. We find that trajectory optimizers like Iterative LQR and Differential Dynamic Programming require fewer iterations to solve several classic continuous control tasks when our methods are used to linearize noisy, blackbox dynamics instead of standard finite differences. By embedding structured exploration in a quasi-Newton optimizer (LBFGS), we are able to learn agile walking and turning policies for quadruped locomotion, that successfully transfer from simulation to actual hardware. We theoretically justify our methods via bounds on the quality of gradient reconstruction and provide a basis for applying them also to nonsmooth problems.
ER  - 

TY  - CONF
TI  - Using a Memory of Motion to Efficiently Warm-Start a Nonlinear Predictive Controller
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2986
EP  - 2993
AU  - N. Mansard
AU  - A. DelPrete
AU  - M. Geisert
AU  - S. Tonneau
AU  - O. Stasse
PY  - 2018
KW  - autonomous aerial vehicles
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - nonlinear control systems
KW  - optimal control
KW  - optimisation
KW  - path planning
KW  - predictive control
KW  - sampling methods
KW  - trajectory optimisation (aerospace)
KW  - direct optimal control
KW  - control policy
KW  - optimal state-control trajectories
KW  - nonlinear predictive controller
KW  - nonlinear optimization problem
KW  - model-based methodology
KW  - control cycle
KW  - kinodynamic probabilistic roadmap
KW  - nonlinear solver
KW  - unmanned aerial vehicle
KW  - UAV
KW  - complex dynamical systems
KW  - sampling-based planning
KW  - policy learning
KW  - Computational modeling
KW  - Approximation algorithms
KW  - Optimal control
KW  - Planning
KW  - Robots
KW  - Trajectory optimization
DO  - 10.1109/ICRA.2018.8463154
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Predictive control is an efficient model-based methodology to control complex dynamical systems. In general, it boils down to the resolution at each control cycle of a large nonlinear optimization problem. A critical issue is then to provide a good guess to initialize the nonlinear solver so as to speed up convergence. This is particularly important when disturbances or changes in the environment prevent the use of the trajectory computed at the previous control cycle as initial guess. In this paper, we introduce an original and very efficient solution to automatically build this initial guess. We propose to rely on off-line computation to build an approximation of the optimal trajectories, that can be used on-line to initialize the predictive controller. To that end, we combined the use of sampling-based planning, policy learning with generic representations (such as neural networks), and direct optimal control. We first propose an algorithm to simultaneously build a kinodynamic probabilistic roadmap (PRM) and approximate value function and control policy. This algorithm quickly converges toward an approximation of the optimal state-control trajectories (along with an optimal PRM). Then, we propose two methods to store the optimal trajectories and use them to initialize the predictive controller. We experimentally show that directly storing the state-control trajectories leads the predictive controller to quickly converges (2 to 5 iterations) toward the (global) optimal solution. The results are validated in simulation with an unmanned aerial vehicle (UAV) and other dynamical systems.
ER  - 

TY  - CONF
TI  - Goal Directed Dynamics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2994
EP  - 3000
AU  - E. Todorov
PY  - 2018
KW  - control engineering computing
KW  - end effectors
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - motion control
KW  - quadratic programming
KW  - robot dynamics
KW  - telerobotics
KW  - forward dynamics
KW  - greedy optimization
KW  - feature-based control
KW  - control policies
KW  - trajectory optimization
KW  - goal directed dynamics
KW  - general control framework
KW  - low-level optimizer
KW  - robot dynamics
KW  - dynamical system
KW  - high level command
KW  - cost function
KW  - end-effector poses
KW  - soft-constraint physics model
KW  - quadratic programming framework
KW  - teleoperation
KW  - MuJoCo simulator
KW  - Acceleration
KW  - Robots
KW  - Force
KW  - Cost function
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8462904
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We develop a general control framework where a low-level optimizer is built into the robot dynamics. This optimizer together with the robot constitute a goal directed dynamical system, controlled on a higher level. The high level command is a cost function. It can encode desired accelerations, end-effector poses, center of pressure, and other intuitive features that have been studied before. Unlike the currently popular quadratic programming framework, which comes with performance guarantees at the expense of modeling flexibility, the optimization problem we solve at each time step is non-convex and non-smooth. Nevertheless, by exploiting the unique properties of the soft-constraint physics model we have recently developed, we are able to design an efficient solver for goal directed dynamics. It is only two times slower than the forward dynamics solver, and is much faster than real time. The simulation results reveal that complex movements can be generated via greedy optimization of simple costs. This new computational infrastructure can facilitate teleoperation, feature-based control, deep learning of control policies, and trajectory optimization. It will become a standard feature in future releases of the MuJoCo simulator.
ER  - 

TY  - CONF
TI  - Regression-Based Linear Quadratic Regulator
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3001
EP  - 3006
AU  - H. Carlos
AU  - J. Hayer
AU  - R. Murrieta-Cid
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - linear quadratic control
KW  - mobile robots
KW  - optimisation
KW  - regression analysis
KW  - search problems
KW  - nonlinear dynamics
KW  - nonquadratic cost functions
KW  - free-derivative algorithm
KW  - local quadratic regressions
KW  - robot motion policy
KW  - locally-optimal control feedback policies
KW  - regression-based linear quadratic regulator
KW  - R-LQR
KW  - search space
KW  - optimization
KW  - Cost function
KW  - Approximation algorithms
KW  - Heuristic algorithms
KW  - Regulators
KW  - Optimal control
KW  - Robots
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2018.8460479
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present the Regression-based Linear Quadratic Regulator (R-LQR), a new approach for determining locally-optimal control feedback policies for robots with non-linear dynamics and non-quadratic cost functions. Our proposal uses a free-derivative algorithm based on local quadratic regressions to obtain the robot motion policy. In addition, our methodology allows to define a notion of scale that translates into the definition of neighborhoods of valid policy and into the exploration of larger areas of the search space to find the optimal policies. The results show that our formulation allows to reach policies with lower costs than existing algorithms and to avoid problems when the behavior of the cost function makes the optimization difficult.
ER  - 

TY  - CONF
TI  - Time-Optimal Path Tracking via Reachability Analysis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3007
EP  - 3012
AU  - H. Pham
AU  - Q. Pham
PY  - 2018
KW  - control system analysis
KW  - mobile robots
KW  - path planning
KW  - perturbation techniques
KW  - reachability analysis
KW  - time optimal control
KW  - torque control
KW  - trajectory control
KW  - geometric path
KW  - control strategy
KW  - tracking controller
KW  - path parameterization problems
KW  - reachability analysis
KW  - time-optimal path tracking problem
KW  - tracking error regulation
KW  - reference trajectory
KW  - tracking performance degradation
KW  - path controller parameterization
KW  - joint torques
KW  - torque bounds
KW  - perturbations
KW  - Trajectory
KW  - Torque
KW  - Robustness
KW  - Perturbation methods
KW  - Acceleration
KW  - Manipulator dynamics
DO  - 10.1109/ICRA.2018.8460576
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Given a geometric path, the Time-Optimal Path Tracking problem consists in finding the control strategy to traverse the path time-optimally while regulating tracking errors. A simple yet effective approach to this problem is to decompose the controller into two components: (i) a path controller, which modulates the parameterization of the desired path in an online manner, yielding a reference trajectory; and (ii) a tracking controller, which takes the reference trajectory and outputs joint torques for tracking. However, there is one major difficulty: the path controller might not find any feasible reference trajectory that can be tracked by the tracking controller because of torque bounds. In turn, this results in degraded tracking performances. Here, we propose a new path controller that is guaranteed to find feasible reference trajectories by accounting for possible future perturbations. The main technical tool underlying the proposed controller is Reachability Analysis, a new method for analyzing path parameterization problems. Simulations show that the proposed controller outperforms existing methods.
ER  - 

TY  - CONF
TI  - Acceleration of Gradient-Based Path Integral Method for Efficient Optimal and Inverse Optimal Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3013
EP  - 3020
AU  - M. Okada
AU  - T. Taniguchi
PY  - 2018
KW  - convergence of numerical methods
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - optimal control
KW  - optimisation
KW  - predictive control
KW  - gradient-based path integral method
KW  - inverse optimal control
KW  - accelerated path integral method
KW  - gradient descent
KW  - iterative path integral method
KW  - optimization methods
KW  - momentum-based acceleration
KW  - momentum-based methods
KW  - Nesterov Accelerated Gradient
KW  - simulated control systems
KW  - model predictive control
KW  - path integral networks
KW  - accelerated PI-Net
KW  - reinforcement learning
KW  - Iterative methods
KW  - Acceleration
KW  - Optimal control
KW  - Convergence
KW  - Mirrors
KW  - Trajectory
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2018.8463164
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper deals with a new accelerated path integral method, which iteratively searches optimal controls with a small number of iterations. This study is based on the recent observations that a path integral method for reinforcement learning can be interpreted as gradient descent. This observation also applies to an iterative path integral method for optimal control, which sets a convincing argument for utilizing various optimization methods for gradient descent, such as momentum-based acceleration, step-size adaptation and their combination. We introduce these types of methods to the path integral and demonstrate that momentum-based methods, like Nesterov Accelerated Gradient and Adam, can significantly improve the convergence rate to search for optimal controls in simulated control systems. We also demonstrate that the accelerated path integral could improve the performance on model predictive control for various vehicle navigation tasks. Finally, we represent this accelerated path integral method as a recurrent network, which is the accelerated version of the previously proposed path integral networks (PI-Net). We can train the accelerated PI-Net more efficiently for inverse optimal control with less RAM than the original PI-Net.
ER  - 

TY  - CONF
TI  - Charging Station Placement for Indoor Robotic Applications
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3029
EP  - 3036
AU  - T. Kundu
AU  - I. Saha
PY  - 2018
KW  - computability
KW  - mobile robots
KW  - path planning
KW  - indoor robotic application
KW  - battery
KW  - satisfiability modulo theory
KW  - charging station placement problem
KW  - autonomous mobile robot
KW  - Charging stations
KW  - Trajectory
KW  - Batteries
KW  - Planning
KW  - Mobile robots
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461006
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For an autonomous mobile robot, when the available power goes below a certain threshold, the robot needs to abort its current task and move towards a charging station to recharge its battery. The efficiency of an autonomous mobile robot depends significantly on the location of the charging stations. In this paper, we address the charging station placement problem for mobile robots in a controlled workspace. We propose two algorithms to place a number of charging stations so that a robot is always capable of reaching one of the charging stations from any obstacle-free location in the workspace without aborting its task too early. We reduce the charging-station placement problem to a series of Satisfiability Modulo Theory (SMT) problems and use the off-the-shelf SMT solver Z3 to implement our algorithm. The algorithm produces as output the locations of the charging stations in the workspace and the trajectories from any obstacle-free locations to one of the charging stations. Our experimental results show how our algorithm can efficiently find the locations of the charging stations and robot trajectories to reach the charging stations. We demonstrate through simulation how the generated trajectories can be effectively used by a robot to reach a charging stations autonomously without getting depleted with power.
ER  - 

TY  - CONF
TI  - Path Tracking of a Two-Wheel Steering Mobile Robot: An Accurate and Robust Multi-Model Off-Road Steering Strategy
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3037
EP  - 3044
AU  - M. Deremetz
AU  - R. Lenain
AU  - B. Thuilot
PY  - 2018
KW  - control nonlinearities
KW  - mobile robots
KW  - observers
KW  - robot kinematics
KW  - robust control
KW  - steering systems
KW  - wheels
KW  - robust multi-model off-road steering strategy
KW  - path tracking algorithms
KW  - backstepping control strategy
KW  - two-wheel steering mobile robot
KW  - control law
KW  - dynamic models
KW  - kinematic models
KW  - observer
KW  - Mobile robots
KW  - Kinematics
KW  - Mathematical model
KW  - Trajectory
KW  - Observers
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460598
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, the problem associated with accurate control of a two-wheel steering mobile robot following a path is addressed thanks to a backstepping control strategy. This approach involves an observer to estimate the grip conditions, based on previous work, and the proposed control algorithm for the front axle. Since the significant parameters of the grip conditions are available from the observer, namely the sideslip angles and the cornering stiffnesses, it is then suitable to include them into an algorithm to control mobile robots and obtain a more accurate path tracking. This is made possible by gathering into a single backstepping approach both kinematic and dynamic models. This new point of view permits to take account of both kinematic and dynamic behaviors and grip parameters in the control law. The proposed approach is experimentally evaluated at different speeds and compared with two other state-of-the-art path tracking algorithms and evaluated for several values of lateral deviations.
ER  - 

TY  - CONF
TI  - Annotating Traversable Gaps in Walkable Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3045
EP  - 3052
AU  - J. L. Vermeulen
AU  - A. Hillebrand
AU  - R. Geraerts
PY  - 2018
KW  - computational geometry
KW  - mesh generation
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - solid modelling
KW  - virtual reality
KW  - navigation mesh generation
KW  - walkable areas
KW  - 3D virtual environment
KW  - walkable environment
KW  - annotating traversable gaps
KW  - Navigation
KW  - Three-dimensional displays
KW  - Maintenance engineering
KW  - Image edge detection
KW  - Geometry
KW  - Surface morphology
KW  - Path planning
DO  - 10.1109/ICRA.2018.8461152
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous agents typically need a navigation mesh of a 3D virtual environment to allow efficient path planning. This mesh needs as input a continuous representation of the walkable areas. However, the walkable environment (WE), i.e. the parts of the 3D environment that an agent can walk on, may contain gaps. These may be due to the filtering steps performed to compute the WE, because of modelling errors in the 3D model, or simply be part of the geometry of the environment. We provide an algorithm that identifies and fills these gaps. We detect gaps, up to a given distance, between pairs of boundary edges of the walkable environment, and fill them with polygons. We employ a heuristic for choosing which pairs of edges should be connected. We compare our algorithm to Recast [10], a voxel-based method for navigation mesh generation. We find that our method gives more accurate results in many environments: it retains the exact representation of the walkable environment, semantically separates the gaps from the walkable areas, and requires no tweaking of parameters to obtain good results. However, our method is currently slower than Recast, and requires more memory.
ER  - 

TY  - CONF
TI  - Topological Nearest-Neighbor Filtering for Sampling-Based Planners
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3053
EP  - 3060
AU  - R. Sandström
AU  - A. Bregger
AU  - B. Smith
AU  - S. Thomas
AU  - N. M. Amato
PY  - 2018
KW  - filtering theory
KW  - mobile robots
KW  - nearest neighbour methods
KW  - path planning
KW  - sampling methods
KW  - trees (mathematics)
KW  - topological nearest-neighbor filtering
KW  - computational techniques
KW  - locality-sensitive hashing
KW  - workspace connectivity
KW  - nearest-neighbor time
KW  - nearest-neighbor algorithm
KW  - candidate neighbor configurations
KW  - topologically relevant set
KW  - sampling-based motion planning algorithms
KW  - Nearest-neighbor finding
KW  - sampling-based planners
DO  - 10.1109/ICRA.2018.8460896
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Nearest-neighbor finding is a major bottleneck for sampling-based motion planning algorithms. The cost of finding nearest neighbors grows with the size of the roadmap, leading to significant slowdowns for problems which require many configurations to find a solution. Prior work has investigated relieving this pressure with quicker computational techniques, such as kd-trees or locality-sensitive hashing. In this work, we investigate an alternative direction for expediting this process based on workspace connectivity. We present an algorithm called Topological Nearest-Neighbor Filtering, which employs a workspace decomposition to select a topologically relevant set of candidate neighbor configurations as a pre-processing step for a nearest-neighbor algorithm. We investigate the application of this filter to several varieties of RRT and demonstrate that the filter improves both nearest-neighbor time and overall planning performance.
ER  - 

TY  - CONF
TI  - Integration of Local Geometry and Metric Information in Sampling-Based Motion Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3061
EP  - 3068
AU  - V. Pacelli
AU  - O. Arslan
AU  - D. E. Koditschek
PY  - 2018
KW  - geometry
KW  - linear quadratic control
KW  - linear systems
KW  - linearisation techniques
KW  - matrix algebra
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - sampling methods
KW  - sampling-based motion planning algorithms
KW  - steering procedure
KW  - configuration space geometry
KW  - sample configurations
KW  - local system dynamics
KW  - convex subsets
KW  - free space
KW  - local behavior
KW  - LQR cost-to-go function
KW  - system linearization
KW  - linear-Gaussian system
KW  - second-order linear system
KW  - Gram matrix
KW  - Mahalanobis distance
KW  - kinematic unicycle
KW  - local geometry
KW  - metric information
KW  - Measurement
KW  - Heuristic algorithms
KW  - Trajectory
KW  - Geometry
KW  - Robots
KW  - System dynamics
KW  - Planning
DO  - 10.1109/ICRA.2018.8460739
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The efficiency of sampling-based motion planning algorithms is dependent on how well a steering procedure is capable of capturing both system dynamics and configuration space geometry to connect sample configurations. This paper considers how metrics describing local system dynamics may be combined with convex subsets of the free space to describe the local behavior of a steering function for sampling-based planners. Subsequently, a framework for using these subsets to extend the steering procedure to incorporate this information is introduced. To demonstrate our framework, three specific metrics are considered: the LQR cost-to-go function, a Gram matrix derived from system linearization, and the Mahalanobis distance of a linear-Gaussian system. Finally, numerical tests are conducted for a second-order linear system, a kinematic unicycle, and a linear-Gaussian system to demonstrate that our framework increases the connectivity of sampling-based planners and allows them to better explore the free space.
ER  - 

TY  - CONF
TI  - Realization of a Real-Time Optimal Control Strategy to Stabilize a Falling Humanoid Robot with Hand Contact
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3092
EP  - 3098
AU  - S. Wang
AU  - K. Hauser
PY  - 2018
KW  - collision avoidance
KW  - friction
KW  - humanoid robots
KW  - mobile robots
KW  - motion control
KW  - optimal control
KW  - robot dynamics
KW  - stability
KW  - falling humanoid robot
KW  - environmental obstacles
KW  - obstacle geometry
KW  - contact point
KW  - planar dynamic model
KW  - optimal control approach
KW  - three-link robot model
KW  - hand contact optimization
KW  - Darwin-Mini robot
KW  - realtime optimal control strategy
KW  - realtime falling robot stabilization system
KW  - Real-time systems
KW  - Legged locomotion
KW  - Computational modeling
KW  - Humanoid robots
KW  - Robot sensing systems
KW  - Kinetic energy
DO  - 10.1109/ICRA.2018.8460500
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a real-time falling robot stabilization system for a humanoid robot in which the robot can prevent falling using hand contact with walls and other surfaces in the environment. Instead of ignoring or avoiding interaction with environmental obstacles, our system uses obstacle geometry to determine a contact point that reduces impact and necessary friction. It uses a planar dynamic model that is appropriate for falling stabilization in the robot's sagittal plane and frontal plane. The hand contact is determined with an optimal control approach, and to make the algorithm run in realtime, a simplified three-link robot model and a pre-computed database of subproblems for the hand contact optimization are adopted. Moreover, if the robot is not leaning too far after stabilization, we employ a heuristic push-up strategy to recover the robot to a standing posture. System integration is performed on the Darwin-Mini robot and validation is conducted in several environments and falling scenarios.
ER  - 

TY  - CONF
TI  - Markerless Visual Servoing on Unknown Objects for Humanoid Robot Platforms
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3099
EP  - 3106
AU  - C. Fantacci
AU  - G. Vezzani
AU  - U. Pattacini
AU  - V. Tikhanoff
AU  - L. Natale
PY  - 2018
KW  - Bayes methods
KW  - end effectors
KW  - humanoid robots
KW  - least squares approximations
KW  - Monte Carlo methods
KW  - recursive filters
KW  - stereo image processing
KW  - visual perception
KW  - visual servoing
KW  - least squares minimization problem
KW  - stereo vision
KW  - image-based visual servo control
KW  - nonlinear constrained optimization problem
KW  - Sequential Monte Carlo filtering
KW  - recursive Bayesian filtering technique
KW  - markerless visual servoing
KW  - iCub humanoid robot platform
KW  - Visual servoing
KW  - Grasping
KW  - Solid modeling
KW  - Three-dimensional displays
KW  - Mathematical model
KW  - Humanoid robots
DO  - 10.1109/ICRA.2018.8462914
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To precisely reach for an object with a humanoid robot, it is of central importance to have good knowledge of both end-effector, object pose and shape. In this work we propose a framework for markerless visual servoing on unknown objects, which is divided in four main parts: I) a leastsquares minimization problem is formulated to find the volume of the object graspable by the robot's hand using its stereo vision; II) a recursive Bayesian filtering technique, based on Sequential Monte Carlo (SMC) filtering, estimates the 6D pose (position and orientation) of the robot's end-effector without the use of markers; III) a nonlinear constrained optimization problem is formulated to compute the desired graspable pose about the object; IV) an image-based visual servo control commands the robot's end-effector toward the desired pose. We demonstrate effectiveness and robustness of our approach with extensive experiments on the iCub humanoid robot platform, achieving real-time computation, smooth trajectories and subpixel precisions.
ER  - 

TY  - CONF
TI  - Generating Assistive Humanoid Motions for Co-Manipulation Tasks with a Multi-Robot Quadratic Program Controller
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3107
EP  - 3113
AU  - K. Otani
AU  - K. Bouyarmane
AU  - S. Ivaldi
PY  - 2018
KW  - humanoid robots
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - optimal control
KW  - quadratic programming
KW  - human-humanoid collaborative tasks
KW  - multirobot quadratic program controller
KW  - human dynamics reconstruction
KW  - optimal robot controls
KW  - interaction motions
KW  - interaction forces
KW  - humanoid controller
KW  - co-manipulation tasks
KW  - robot platform simulation
KW  - optimization problem
KW  - Task analysis
KW  - Dynamics
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Optimization
KW  - Humanoid robots
DO  - 10.1109/ICRA.2018.8463167
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Human-humanoid collaborative tasks require that the robot take into account the goals of the task, interaction forces with the human, and its own balance. We present a formulation for a real-time humanoid controller which allows the robot to keep itself balanced, while also assisting the human in achieving their shared objectives. We achieve this with a multi-robot quadratic program controller, which solves for human dynamics reconstruction and optimal robot controls in a single optimization problem. Our experiments on a simulated robot platform demonstrate the ability to generate interaction motions and forces that are similar to what a human collaborator would produce.
ER  - 

TY  - CONF
TI  - Affordance-Based Multi-Contact Whole-Body Pose Sequence Planning for Humanoid Robots in Unknown Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3114
EP  - 3121
AU  - P. Kaiser
AU  - C. Mandery
AU  - A. Boltres
AU  - T. Asfour
PY  - 2018
KW  - end effectors
KW  - humanoid robots
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - stability
KW  - end-effectors
KW  - multicontact contact pose sequence planning
KW  - humanoid robot ARMAR-4
KW  - loco-manipulation tasks
KW  - contacts
KW  - loco-manipulation affordances
KW  - vision-based detection
KW  - whole-body multicontact tasks
KW  - motion planning
KW  - multicontact pose sequences
KW  - goal-directed planning
KW  - end-effector contact opportunities
KW  - autonomous detection
KW  - whole-body loco-manipulation actions
KW  - autonomous planning
KW  - humanoid robotics
KW  - humanoid robots
KW  - whole-body pose sequence planning
KW  - affordance-based multicontact
KW  - Planning
KW  - Humanoid robots
KW  - Task analysis
KW  - Motion segmentation
KW  - Robot sensing systems
KW  - Complexity theory
DO  - 10.1109/ICRA.2018.8461087
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Despite impressive advances of humanoid robotics, the autonomous planning of whole-body loco-manipulation actions in unknown environments is still an open problem. In our previous work, we addressed two fundamental aspects related to this problem: 1) the autonomous detection of end-effector contact opportunities in unknown environments and 2) the goal-directed planning of multi-contact pose sequences, which can serve as the starting point for motion planning and control approaches of reduced complexity. Both problems suffer from the extensive amounts of possible solutions, particularly due to the complexity of humanoid robots and the multitude of available contact opportunities. In this paper, we propose a method for the planning of whole-body multi-contact tasks based on our previous work on vision-based detection of loco-manipulation affordances and whole-body multi-contact pose sequence planning. We demonstrate a combined approach for planning multi-contact pose sequences with a focus on the utilization of available end-effectors for stabilizing contacts with the environment during loco-manipulation tasks. The method is evaluated in simulation in multiple exemplary scenarios based on actual sensor data and the humanoid robot ARMAR-4.
ER  - 

TY  - CONF
TI  - Model-Based External Force/Moment Estimation for Humanoid Robots with no Torque Measurement
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3122
EP  - 3129
AU  - M. Benallegue
AU  - P. Gergondet
AU  - H. Audrerr
AU  - A. Mifsud
AU  - M. Morisawa
AU  - F. Lamiraux
AU  - A. Kheddar
AU  - F. Kanehiro
PY  - 2018
KW  - biomechanics
KW  - force measurement
KW  - force sensors
KW  - humanoid robots
KW  - humanoid robot
KW  - torque measurement
KW  - external forces
KW  - direct force measurements
KW  - regular force sensors
KW  - model-based estimator
KW  - floating-base kinematics
KW  - filtered measurement
KW  - contact force
KW  - additional estimation external force
KW  - model-based external force-moment estimation
KW  - Dynamics
KW  - Robot sensing systems
KW  - Kinematics
KW  - Force
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8460809
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The dynamics of a humanoid robot cannot be correctly described independently from the external forces acting on it. These forces have to be reconstructed to enable the robot to control them or to compensate for them. Force sensors are usually used to measure these forces, but because of their cost, they are often put only on the ankle/feet and possibly the wrists. This paper addresses the issue of the estimation of external forces and moments that apply at any part of a robot without direct force measurements and without torque measurements. The sensors used are the regular force sensors and the IMUs of the robot. The method relies on a model-based estimator able to make the fusion between these sensors and the whole body dynamics. The estimator reconstructs a single state vector containing the floating-base kinematics, a filtered measurement of contact force and an additional estimation external force that we evaluate in this paper. Validation is performed on HRP-2 in a multi-contact motion.
ER  - 

TY  - CONF
TI  - Nonintuitive Optima for Dynamic Locomotion: The Acrollbot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3130
EP  - 3136
AU  - G. Bellegarda
AU  - N. Talele
AU  - K. By
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - optimal control
KW  - robot dynamics
KW  - velocity control
KW  - wheels
KW  - nonintuitive optima
KW  - dynamic locomotion
KW  - acrollbot
KW  - locally-optimal locomotion
KW  - two-link planar robot
KW  - unactuated wheel
KW  - passive wheel
KW  - ground reaction forces
KW  - net accelerations
KW  - decelerations
KW  - bipedal robot locomotion
KW  - toy system
KW  - locomotion speed
KW  - actuation
KW  - forward velocity
KW  - optimization techniques
KW  - direct collocation optimization framework
KW  - nonintuitive dynamic robot models
KW  - physical robot parameterizations
KW  - locomotion efficiency
KW  - data-driven optimization
KW  - dynamically-stable locomotion
KW  - legged rolling locomotion solutions
KW  - Wheels
KW  - Optimization
KW  - Damping
KW  - Trajectory
KW  - Controllability
KW  - Mobile robots
DO  - 10.1109/ICRA.2018.8461221
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper explores locally-optimal, efficient locomotion of a two-link planar robot balancing on a single, unactuated wheel. Because this model is essentially an acrobot mounted on a passive wheel, we name this model the acrollbot. By actuating an internal degree of freedom, the model can indirectly produce ground reaction forces yielding net accelerations and decelerations, to achieve locomotion. As with bipedal robot locomotion, this toy system is particularly challenging to control due to the need to balance continuously while controlling forward locomotion speed. However, unlike typical legged or rolling locomotion solutions, it is not immediately obvious how best to exploit actuation, internal reconfigurations, and motions to produce and control forward velocity along the ground, providing a useful benchmarking system for exploring optimization techniques. We use a direct collocation optimization framework to study this toy system, both to achieve a range of feasible locomotion solutions for nonintuitive dynamic robot models, and to investigate optimization of physical robot parameterizations, in the sense of improving locomotion efficiency. The framework and example presented throughout are designed with an aim toward bridging the gap between non-intuitive, data-driven optimization and model-based methods for design and control of underactuated and dynamically-stable locomotion.
ER  - 

TY  - CONF
TI  - Simultaneous Planning and Estimation Based on Physics Reasoning in Robot Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3137
EP  - 3144
AU  - M. Murooka
AU  - S. Nozawa
AU  - M. Bando
AU  - I. Yanokura
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - manipulators
KW  - multi-robot systems
KW  - path planning
KW  - physics reasoning
KW  - robot manipulation
KW  - manipulation planning
KW  - human-robot cooperation
KW  - multi-robot cooperation
KW  - Planning
KW  - Cognition
KW  - Estimation
KW  - Force
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8463156
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For robots to autonomously achieve manipulation tasks in various scenes, advanced operational skills such as tool use, learning from demonstration, and multi-robot/human-robot cooperation are necessary. In this research, we devise a method for robots to realize such operational skills in a unified manner by evaluating physical consistency (referred to as “physics reasoning”) based on the formulation of the manipulation statics constraints. First, we propose manipulation planning and estimation methods in which the operational feasibility and properties' likelihood are derived by physics reasoning. In addition, we propose a framework to manipulate an object with unknown physical properties by executing planning and estimation both sequentially and in parallel. We demonstrate the effectiveness of the proposed methods by performing experiments in which real humanoid robots achieve various manipulation tasks with advanced operational skills.
ER  - 

TY  - CONF
TI  - Learning Modes of Within-Hand Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3145
EP  - 3151
AU  - B. Calli
AU  - K. Srinivasan
AU  - A. Morgan
AU  - A. M. Dollar
PY  - 2018
KW  - actuators
KW  - control engineering computing
KW  - feature extraction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - motion control
KW  - robot vision
KW  - tactile sensors
KW  - learning modes
KW  - prehensile fingertip-based within-hand manipulation
KW  - tactile sensors
KW  - actuator states
KW  - visual data
KW  - supervised learning techniques
KW  - classification performance
KW  - Extra Trees
KW  - Gradient Boosting
KW  - visual features
KW  - classification rate
KW  - actuator loads
KW  - within-hand manipulation movements
KW  - hand/object system
KW  - Actuators
KW  - Visualization
KW  - Task analysis
KW  - Robot sensing systems
KW  - Grippers
KW  - Feature extraction
DO  - 10.1109/ICRA.2018.8461187
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we investigate methods to detect four phenomena (modes) that occur during prehensile fingertip-based within-hand manipulation without the use of tactile sensors. By using actuator states and visual data, we aim to recognize different modes of operation such as interpreting if the hand is about to drop the object, if the object will begin to slide on the fingers, or if the system is at or near a singularity. For this purpose, we utilize supervised learning techniques, which allow us to detect the modes without the use of a mechanical model of the system. We analyze the individual roles of specific features available through both the actuator and visual data, and identify the ones that have the most significance for detecting the operation modes. Our results show classification performance of 96% (using either Extra Trees, Gradient Boosting, or SVM) when using combined actuator and visual features. Interestingly, we were able to achieve a 94% classification rate using only actuator information, and 93 % using only visual information. Overall, the classifiers identified actuator positions, actuator loads, and commanded velocities as the most important features for detecting a mode. These results have implications for enabling the control of within-hand manipulation movements utilizing a minimal amount of sensory information without a model of the hand/object system.
ER  - 

TY  - CONF
TI  - Cost Functions to Specify Full-Body Motion and Multi-Goal Manipulation Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3152
EP  - 3159
AU  - P. Ruppel
AU  - N. Hendrich
AU  - S. Starke
AU  - J. Zhang
PY  - 2018
KW  - control engineering computing
KW  - evolutionary computation
KW  - gradient methods
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - motion control
KW  - operating systems (computers)
KW  - particle swarm optimisation
KW  - public domain software
KW  - robot programming
KW  - trees (mathematics)
KW  - full-body motion generation
KW  - open-source software package
KW  - inverse kinematics
KW  - arbitrary kinematic trees
KW  - evolutionary optimization
KW  - particle swarm optimization
KW  - cost functions
KW  - multigoal manipulation tasks
KW  - serial kinematic chains
KW  - dual-arm manipulation
KW  - multifinger hands
KW  - memetic algorithm
KW  - full-body motion specification
KW  - ROS
KW  - MoveIt!
KW  - Kinematics
KW  - Task analysis
KW  - Cost function
KW  - Robot kinematics
KW  - End effectors
KW  - Quaternions
DO  - 10.1109/ICRA.2018.8460799
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - While the problem of inverse kinematics on serial kinematic chains is well researched, solving motion tasks quickly on more complex robots remains an open problem. Examples include dual-arm manipulation, grasping with multi-finger hands, and full-body motion generation for humanoids. In this paper, we introduce an open-source software package for ROS and MoveIt! that solves inverse kinematics and motion tasks on robots with arbitrary kinematic trees. The underlying memetic algorithm integrates evolutionary optimization, particle swarm optimization, and gradient methods. The optimization respects joint limits, effectively avoids local minima, and achieves fast convergence to accurate solutions. More importantly, the overall motion goal is specified using a set of weighted sub-goals, providing great flexibility and control of secondary objectives. Several application examples demonstrate how to combine the predefined sub-goals to achieve complex motion tasks.
ER  - 

TY  - CONF
TI  - Robot Composite Learning and the Nunchaku Flipping Challenge
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3160
EP  - 3165
AU  - L. Zhao
AU  - Y. Zhao
AU  - S. Patil
AU  - D. Davies
AU  - C. Wang
AU  - L. Lu
AU  - B. Ouyang
PY  - 2018
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot dynamics
KW  - heavily case-specific engineering
KW  - ubiquitous manner
KW  - human demonstration
KW  - LfD
KW  - dynamic skills
KW  - composite learning scheme
KW  - human definition
KW  - advanced motor skills
KW  - dynamic time-critical maneuver
KW  - complex contact control
KW  - partly soft partly rigid objects
KW  - nunchaku flipping challenge
KW  - physical success
KW  - robot composite learning
KW  - robot dynamics
KW  - hyper robot motor capabilities
KW  - robot learning
KW  - Petri nets
KW  - Robot learning
KW  - Mobile robots
KW  - Compounds
KW  - Dynamics
KW  - Real-time systems
DO  - 10.1109/ICRA.2018.8461141
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Advanced motor skills are essential for robots to physically coexist with humans. Much research on robot dynamics and control has achieved success on hyper robot motor capabilities, but mostly through heavily case-specific engineering. Meanwhile, in terms of robot acquiring skills in a ubiquitous manner, robot learning from human demonstration (LfD) has achieved great progress, but still has limitations handling dynamic skills and compound actions. We present a composite learning scheme which goes beyond LfD and integrates robot learning from human definition, demonstration, and evaluation. The method tackles advanced motor skills that require dynamic time-critical maneuver, complex contact control, and handling partly soft partly rigid objects. We also introduce the “nunchaku flipping challenge”, an extreme test that puts hard requirements to all these three aspects. Continued from our previous presentations, this paper introduces the latest update of the composite learning scheme and the physical success of the nunchaku flipping challenge.
ER  - 

TY  - CONF
TI  - Iterative Learning Scheme for Dexterous In-Hand Manipulation with Stochastic Uncertainty
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3166
EP  - 3171
AU  - M. Yashima
AU  - T. Yamawaki
PY  - 2018
KW  - dexterous manipulators
KW  - gradient methods
KW  - iterative learning control
KW  - stochastic processes
KW  - stochastic systems
KW  - uncertain systems
KW  - dexterous manipulation tasks
KW  - model-based approaches
KW  - stochastic uncertainty
KW  - iterative learning scheme
KW  - adaptive learning rate methods
KW  - dexterous in-hand manipulation
KW  - gradient descent-based iterative learning control
KW  - Uncertainty
KW  - Stochastic processes
KW  - Robots
KW  - Torque
KW  - Cost function
KW  - Noise measurement
KW  - Robustness
DO  - 10.1109/ICRA.2018.8462913
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In-hand manipulation has attracted attention because of its potential for performing dexterous manipulation tasks. Few successful examples using real robotic fingers have been reported because model-based approaches have been assumed. A gradient descent-based iterative learning control is one of the typical methods for improving the control performance without the need for a precise model. However, the learning performances deteriorate greatly owing to the stochastic uncertainties, and the learning rates have to be determined manually. We propose a novel iterative learning scheme with adaptive learning rate methods for dexterous in-hand manipulation. The proposed scheme not only eliminates the need for a precise model and manual tuning of a learning rate but also is robust to stochastic uncertainties and insensitive to hyperparameters. The validity of the proposed iterative learning scheme is demonstrated through several experiments.
ER  - 

TY  - CONF
TI  - Dexterous Manipulation by Two Fingers with Coupled Joints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3172
EP  - 3179
AU  - Y. Jia
AU  - Y. Xue
PY  - 2018
KW  - dexterous manipulators
KW  - humanoid robots
KW  - manipulator kinematics
KW  - mechanical contact
KW  - finger
KW  - links
KW  - coupled joints
KW  - Lagrangian mechanics
KW  - independent joint angles
KW  - contact kinematics
KW  - slip modes
KW  - angular accelerations
KW  - joint accelerations
KW  - joint torques
KW  - proportional-derivative law
KW  - dexterous manipulation
KW  - stick modes
KW  - Acceleration
KW  - Kinematics
KW  - Task analysis
KW  - Thumb
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460531
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper studies dexterous manipulation in the plane by a two-fingered hand in the plane. The dynamics of each finger, which consists of two links with coupled joints, are derived based on Lagrangian mechanics. As an object is being manipulated, its orientation and the two independent joint angles of the hand constitute the state of the entire system. Contact kinematics, accounting for both stick and slip modes, are combined with dynamics to establish a dependence of the object's linear and angular accelerations on joint accelerations. This allows control of joint torques, under a proportional-derivative (PD) law, to move the object to a target position in a desired orientation.
ER  - 

TY  - CONF
TI  - Extrinsic Dexterity Through Active Slip Control Using Deep Predictive Models
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3180
EP  - 3185
AU  - S. Stepputtis
AU  - Y. Yang
AU  - H. Ben Amor
PY  - 2018
KW  - dexterous manipulators
KW  - end effectors
KW  - grippers
KW  - learning (artificial intelligence)
KW  - slip
KW  - tactile sensors
KW  - extrinsic dexterity
KW  - active slip control
KW  - machine learning methodology
KW  - robot dexterity
KW  - recent insights
KW  - deep learning
KW  - tactile sensor information
KW  - manipulated object
KW  - robot end-effector
KW  - deep predictive models
KW  - Grippers
KW  - Training
KW  - Robot sensing systems
KW  - Predictive models
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8461055
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a machine learning methodology for actively controlling slip, in order to increase robot dexterity. Leveraging recent insights in deep learning, we propose a Deep Predictive Model that uses tactile sensor information to reason about slip and its future influence on the manipulated object. The obtained information is then used to precisely manipulate objects within a robot end-effector using external perturbations imposed by gravity or acceleration. We show in a set of experiments that this approach can be used to increase a robot's repertoire of motor skills.
ER  - 

TY  - CONF
TI  - A General Pipeline for 3D Detection of Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3194
EP  - 3200
AU  - X. Du
AU  - M. H. Ang
AU  - S. Karaman
AU  - D. Rus
PY  - 2018
KW  - automobiles
KW  - convolution
KW  - feature extraction
KW  - feedforward neural nets
KW  - mobile robots
KW  - robot vision
KW  - traffic engineering computing
KW  - 2D detection network
KW  - generalised car models
KW  - two-stage convolutional neural network
KW  - 3D detection algorithms
KW  - general pipeline
KW  - autonomous driving
KW  - flexible pipeline
KW  - 3D point cloud
KW  - model fitting algorithm
KW  - 3D box detection
KW  - 2D vehicle detection
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Automobiles
KW  - Pipelines
KW  - Solid modeling
KW  - Proposals
KW  - Laser radar
DO  - 10.1109/ICRA.2018.8461232
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous driving requires 3D perception of vehicles and other objects in the in environment. Much of the current methods support 2D vehicle detection. This paper proposes a flexible pipeline to adopt any 2D detection network and fuse it with a 3D point cloud to generate 3D information with minimum changes of the 2D detection networks. To identify the 3D box, an effective model fitting algorithm is developed based on generalised car models and score maps. A two-stage convolutional neural network (CNN) is proposed to refine the detected 3D box. This pipeline is tested on the KITTI dataset using two different 2D detection networks. The 3D detection results based on these two networks are similar, demonstrating the flexibility of the proposed pipeline. The results rank second among the 3D detection algorithms, indicating its competencies in 3D detection.
ER  - 

TY  - CONF
TI  - Meshed Up: Learnt Error Correction in 3D Reconstructions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3201
EP  - 3206
AU  - M. Tanner
AU  - S. Săftescu
AU  - A. Bewley
AU  - P. Newman
PY  - 2018
KW  - error correction
KW  - feature extraction
KW  - image reconstruction
KW  - inverse problems
KW  - learning (artificial intelligence)
KW  - stereo image processing
KW  - 3D reconstruction accuracy
KW  - sensors
KW  - laser reconstruction
KW  - deep network architecture
KW  - stereo image reconstruction
KW  - two dimensional inverse-depth image extraction
KW  - 2D inverse-depth image extraction
KW  - RMSE
KW  - depth reconstructions
KW  - depth estimate errors
KW  - machine learning technique
KW  - learnt error correction
KW  - Image reconstruction
KW  - Feature extraction
KW  - Cameras
KW  - Three-dimensional displays
KW  - Lasers
KW  - Image color analysis
KW  - Training
DO  - 10.1109/ICRA.2018.8460977
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Dense reconstructions often contain errors that prior work has so far minimised using high quality sensors and regularising the output. Nevertheless, errors still persist. This paper proposes a machine learning technique to identify errors in three dimensional (3D) meshes. Beyond simply identifying errors, our method quantifies both the magnitude and the direction of depth estimate errors when viewing the scene. This enables us to Improve the reconstruction accuracy. We train a suitably deep network architecture with two 3D meshes: a high-quality laser reconstruction, and a lower quality stereo image reconstruction. The network predicts the amount of error in the lower quality reconstruction with respect to the high-quality one, having only view the former through its input. We evaluate our approach by correcting two dimensional (2D) inverse-depth images extracted from the 3D model, and show that our method improves the quality of these depth reconstructions by up to a relative 10% RMSE.
ER  - 

TY  - CONF
TI  - Fast Disparity Estimation Using Dense Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3207
EP  - 3212
AU  - R. Atienza
PY  - 2018
KW  - convolution
KW  - feedforward neural nets
KW  - image colour analysis
KW  - stereo image processing
KW  - CNN-based methods
KW  - DenseMapNet
KW  - deep convolutional neural networks
KW  - repetitive regions
KW  - textureless regions
KW  - stereo vision
KW  - color stereo images
KW  - dense networks
KW  - disparity map
KW  - autoencoder method
KW  - Estimation
KW  - Two dimensional displays
KW  - Semantics
KW  - Image resolution
KW  - Three-dimensional displays
KW  - Cameras
KW  - Computer vision
DO  - 10.1109/ICRA.2018.8463172
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Disparity estimation is a difficult problem in stereo vision because the correspondence technique fails in images with textureless and repetitive regions. Recent body of work using deep convolutional neural networks (CNN) overcomes this problem with semantics. Most CNN implementations use an autoencoder method; stereo images are encoded, merged and finally decoded to predict the disparity map. In this paper, we present a CNN implementation inspired by dense networks to reduce the number of parameters. Furthermore, our approach takes into account semantic reasoning in disparity estimation. Our proposed network, called DenseMapNet, is compact, fast and can be trained end-to-end. DenseMapNet requires 290k parameters only and runs at 30Hz or faster on color stereo images in full resolution. Experimental results show that DenseMapNet accuracy is comparable with other significantly bigger CNN-based methods.
ER  - 

TY  - CONF
TI  - SceneCut: Joint Geometric and Object Segmentation for Indoor Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3213
EP  - 3220
AU  - T. T. Pham
AU  - T. Do
AU  - N. Sünderhauf
AU  - I. Reid
PY  - 2018
KW  - geometry
KW  - image colour analysis
KW  - image representation
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object detection
KW  - joint geometric
KW  - object segmentation
KW  - indoor scenes
KW  - unseen objects
KW  - nonobject surfaces
KW  - scene semantics
KW  - scene surfaces
KW  - unified energy function
KW  - hierarchical segmentation trees
KW  - RGB-D image
KW  - deep learning-based methods
KW  - SceneCut
KW  - convolutional oriented boundary network
KW  - Image segmentation
KW  - Semantics
KW  - Silicon
KW  - Object segmentation
KW  - Robots
KW  - Training
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8461108
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents SceneCut, a novel approach to jointly discover previously unseen objects and non-object surfaces using a single RGB-D image. SceneCut's joint reasoning over scene semantics and geometry allows a robot to detect and segment object instances in complex scenes where modern deep learning-based methods either fail to separate object instances, or fail to detect objects that were not seen during training. SceneCut automatically decomposes a scene into meaningful regions which either represent objects or scene surfaces. The decomposition is qualified by an unified energy function over objectness and geometric fitting. We show how this energy function can be optimized efficiently by utilizing hierarchical segmentation trees. Moreover, we leverage a pre-trained convolutional oriented boundary network to predict accurate boundaries from images, which are used to construct high-quality region hierarchies. We evaluate SceneCut on several different indoor environments, and the results show that SceneCut significantly outperforms all the existing methods.
ER  - 

TY  - CONF
TI  - Bayesian Viewpoint-Dependent Robust Classification Under Model and Localization Uncertainty
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3221
EP  - 3228
AU  - Y. Feldman
AU  - V. Indelman
PY  - 2018
KW  - Bayes methods
KW  - image classification
KW  - pattern classification
KW  - Bayesian viewpoint-dependent robust classification
KW  - localization uncertainty
KW  - robust visual classification
KW  - black-box Bayesian classifier
KW  - localization error
KW  - spatial correlation
KW  - Uncertainty
KW  - Measurement uncertainty
KW  - Robots
KW  - Correlation
KW  - Bayes methods
KW  - Robustness
KW  - Training data
DO  - 10.1109/ICRA.2018.8461127
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose an algorithm for robust visual classification of an object of interest observed from multiple views using a black-box Bayesian classifier which provides a measure of uncertainty, in the presence of significant ambiguity and classifier noise, and of localization error. The fusion of classifier outputs takes into account viewpoint dependency and spatial correlation among observations, as well as pose uncertainty when these observations are taken and a measure of confidence provided by the classifier itself. Our experiments confirm an improvement in robustness over state-of-the-art.
ER  - 

TY  - CONF
TI  - Signature of Topologically Persistent Points for 3D Point Cloud Description
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3229
EP  - 3234
AU  - W. J. Beksi
AU  - N. Papanikolopoulos
PY  - 2018
KW  - computer graphics
KW  - image resolution
KW  - solid modelling
KW  - object classification
KW  - object detection
KW  - 3D point cloud processing tasks
KW  - RGB-D dataset
KW  - spatial resolutions
KW  - topological invariant encoding
KW  - global descriptor
KW  - topologically persistent point signature
KW  - homology groups
KW  - competitive 3D point cloud descriptor
KW  - topological space
KW  - 3D point cloud data
KW  - STPP
KW  - time 3.0 d
KW  - Three-dimensional displays
KW  - Shape
KW  - Robot sensing systems
KW  - Generators
KW  - Histograms
KW  - Topology
KW  - Face
DO  - 10.1109/ICRA.2018.8460605
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present the Signature of Topologically Persistent Points (STPP), a global descriptor that encodes topological invariants of 3D point cloud data. These topological invariants include the zeroth and first homology groups and are computed using persistent homology, a method for finding the features of a topological space at different spatial resolutions. STPP is a competitive 3D point cloud descriptor when compared to the state of art and is resilient to noisy sensor data. We demonstrate experimentally on a publicly available RGB-D dataset that STPP can be used as a distinctive signature, thus allowing for 3D point cloud processing tasks such as object detection and classification.
ER  - 

TY  - CONF
TI  - Label Fusion: A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3235
EP  - 3242
AU  - P. Marion
AU  - P. R. Florence
AU  - L. Manuelli
AU  - R. Tedrake
PY  - 2018
KW  - image colour analysis
KW  - image fusion
KW  - image reconstruction
KW  - image representation
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural net architecture
KW  - object detection
KW  - object tracking
KW  - pose estimation
KW  - robot vision
KW  - video cameras
KW  - video signal processing
KW  - reconstruction techniques
KW  - ground truth label generation
KW  - labeled object instances
KW  - object pose
KW  - video scene collection
KW  - annotation pipeline
KW  - DNN architecture
KW  - RGBD image
KW  - object meshes
KW  - human assisted ICP-fitting
KW  - 3D dense reconstruction
KW  - RGBD camera
KW  - pixelwise labels
KW  - specific robotic manipulation task
KW  - training data
KW  - DNN pipelines
KW  - object segmentation
KW  - deep neural network architectures
KW  - cluttered scenes
KW  - real RGBD data
KW  - label fusion
KW  - Pipelines
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Image segmentation
KW  - Cameras
KW  - Image reconstruction
DO  - 10.1109/ICRA.2018.8460950
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Deep neural network (DNN) architectures have been shown to outperform traditional pipelines for object segmentation and pose estimation using RGBD data, but the performance of these DNN pipelines is directly tied to how representative the training data is of the true data. Hence a key requirement for employing these methods in practice is to have a large set of labeled data for your specific robotic manipulation task, a requirement that is not generally satisfied by existing datasets. In this paper we develop a pipeline to rapidly generate high quality RGBD data with pixelwise labels and object poses. We use an RGBD camera to collect video of a scene from multiple viewpoints and leverage existing reconstruction techniques to produce a 3D dense reconstruction. We label the 3D reconstruction using a human assisted ICP-fitting of object meshes. By reprojecting the results of labeling the 3D scene we can produce labels for each RGBD image of the scene. This pipeline enabled us to collect over 1,000,000 labeled object instances in just a few days. We use this dataset to answer questions related to how much training data is required, and of what quality the data must be, to achieve high performance from a DNN architecture. Our dataset and annotation pipeline are available at labelfusion.csail.mit.edu.
ER  - 

TY  - CONF
TI  - Dropout Sampling for Robust Object Detection in Open-Set Conditions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3243
EP  - 3249
AU  - D. Miller
AU  - L. Nicholson
AU  - F. Dayoub
AU  - N. Sünderhauf
PY  - 2018
KW  - approximation theory
KW  - Bayes methods
KW  - image classification
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - regression analysis
KW  - robot vision
KW  - sampling methods
KW  - dropout sampling network
KW  - dropout variational inference
KW  - approximation technique
KW  - Bayesian deep learning
KW  - mobile robot
KW  - versatile campus environment
KW  - robotic vision
KW  - regression tasks
KW  - image classification
KW  - open-set conditions
KW  - robust object detection
KW  - Object detection
KW  - Uncertainty
KW  - Training
KW  - Bayes methods
KW  - Entropy
KW  - Task analysis
KW  - Robots
DO  - 10.1109/ICRA.2018.8460700
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Dropout Variational Inference, or Dropout Sampling, has been recently proposed as an approximation technique for Bayesian Deep Learning and evaluated for image classification and regression tasks. This paper investigates the utility of Dropout Sampling for object detection for the first time. We demonstrate how label uncertainty can be extracted from a state-of-the-art object detection system via Dropout Sampling. We evaluate this approach on a large synthetic dataset of 30,000 images, and a real-world dataset captured by a mobile robot in a versatile campus environment. We show that this uncertainty can be utilized to increase object detection performance under the open-set conditions that are typically encountered in robotic vision. A Dropout Sampling network is shown to achieve a 12.3 % increase in recall (for the same precision score as a standard network) and a 15.1 % increase in precision (for the same recall score as the standard network).
ER  - 

TY  - CONF
TI  - Early Turn-Taking Prediction with Spiking Neural Networks for Human Robot Collaboration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3250
EP  - 3256
AU  - T. Zhou
AU  - J. P. Wachs
PY  - 2018
KW  - cognition
KW  - control engineering computing
KW  - groupware
KW  - human computer interaction
KW  - human-robot interaction
KW  - medical computing
KW  - medical robotics
KW  - neural nets
KW  - surgery
KW  - team working
KW  - user interfaces
KW  - early prediction capability
KW  - turn-taking actions
KW  - early turn-taking prediction
KW  - Spiking Neural networks
KW  - human robot collaboration
KW  - human teamwork
KW  - Cognitive Turn-taking Model
KW  - turn-taking prediction algorithms
KW  - CTTM
KW  - robotic scrub nurse
KW  - human turn-taking intentions
KW  - multimodal human communication cues
KW  - Neurons
KW  - Robot kinematics
KW  - Task analysis
KW  - Training
KW  - Teamwork
DO  - 10.1109/ICRA.2018.8461208
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Turn-taking is essential to the structure of human teamwork. Humans are typically aware of team members' intention to keep or relinquish their turn before a turn switch, where the responsibility of working on a shared task is shifted. Future co-robots are also expected to provide such competence. To that end, this paper proposes the Cognitive Turn-taking Model (CTTM), which leverages cognitive models (i.e., Spiking Neural Network) to achieve early turn-taking prediction. The CTTM framework can process multimodal human communication cues (both implicit and explicit) and predict human turn-taking intentions in an early stage. The proposed framework is tested on a simulated surgical procedure, where a robotic scrub nurse predicts the surgeon's turn-taking intention. It was found that the proposed CTTM framework outperforms the state-of-the-art turn-taking prediction algorithms by a large margin. It also outperforms humans when presented with partial observations of communication cues (i.e., less than 40 % of full actions). This early prediction capability enables robots to initiate turn-taking actions at an early stage, which facilitates collaboration and increases overall efficiency.
ER  - 

TY  - CONF
TI  - Learning Human Ergonomic Preferences for Handovers
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3257
EP  - 3264
AU  - A. Bestick
AU  - R. Pandya
AU  - R. Bajcsy
AU  - A. D. Dragan
PY  - 2018
KW  - ergonomics
KW  - human-robot interaction
KW  - manipulators
KW  - human ergonomic preferences
KW  - handovers
KW  - robots
KW  - ergonomic human grasping configurations
KW  - ergonomic cost function
KW  - online estimation problem
KW  - in-person user study
KW  - Ergonomics
KW  - Handover
KW  - Cost function
KW  - Training
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8461216
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Our goal is for people to be physically comfortable when taking objects from robots. This puts a burden on the robot to hand over the object in such a way that a person can easily reach it, without needing to strain or twist their arm - a way that is conducive to ergonomic human grasping configurations. To achieve this, the robot needs to understand what makes a configuration more or less ergonomic to the person, i.e. their ergonomic cost function. In this work, we formulate learning a person's ergonomic cost as an online estimation problem. The robot can implicitly make queries to the person by handing them objects in different configurations, and gets observations in response about the way they choose to take the object. We compare the performance of both passive and active approaches for solving this problem in simulation, as well as in an in-person user study.
ER  - 

TY  - CONF
TI  - Joining High-Level Symbolic Planning with Low-Level Motion Primitives in Adaptive HRI: Application to Dressing Assistance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3273
EP  - 3278
AU  - G. Canal
AU  - E. Pignat
AU  - G. Alenyà
AU  - S. Calinon
AU  - C. Torras
PY  - 2018
KW  - control engineering computing
KW  - footwear
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - planning (artificial intelligence)
KW  - robot programming
KW  - service robots
KW  - daily living assistance
KW  - robot motion encoding
KW  - programming
KW  - shoe-dressing scenario
KW  - robot verbosity
KW  - robot speed
KW  - safe living assistance
KW  - dressing assistance
KW  - adaptive HRI
KW  - low-level motion primitives
KW  - high-level symbolic planning
KW  - user preferences
KW  - human-robot interaction
KW  - Task analysis
KW  - Planning
KW  - Robot sensing systems
KW  - Footwear
KW  - Foot
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460606
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For a safe and successful daily living assistance, far from the highly controlled environment of a factory, robots should be able to adapt to ever-changing situations. Programming such a robot is a tedious process that requires expert knowledge. An alternative is to rely on a high-level planner, but the generic symbolic representations used are not well suited to particular robot executions. Contrarily, motion primitives encode robot motions in a way that can be easily adapted to different situations. This paper presents a combined framework that exploits the advantages of both approaches. The number of required symbolic states is reduced, as motion primitives provide “smart actions” that take the current state and cope online with variations. Symbolic actions can include interactions (e.g., ask and inform) that are difficult to demonstrate. We show that the proposed framework can adapt to the user preferences (in terms of robot speed and robot verbosity), can readjust the trajectories based on the user movements, and can handle unforeseen situations. Experiments are performed in a shoe-dressing scenario. This scenario is particularly interesting because it involves a sufficient number of actions, and the human-robot interaction requires the handling of user preferences and unexpected reactions.
ER  - 

TY  - CONF
TI  - A Passivity-Based Strategy for Coaching in Human-Robot Interaction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3279
EP  - 3284
AU  - C. Talignani Landi
AU  - F. Ferraguti
AU  - C. Fantuzzi
AU  - C. Secchi
PY  - 2018
KW  - control engineering computing
KW  - end effectors
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - robot programming
KW  - end-effector
KW  - initial trajectory
KW  - path tracking
KW  - admittance parameters
KW  - passivity-based strategy
KW  - coaching
KW  - human-robot interaction
KW  - robot programming
KW  - programming techniques
KW  - passivity-based framework
KW  - Dynamical Movement Primitives
KW  - admittance control
KW  - human operator grabs
KW  - Trajectory
KW  - Admittance
KW  - Service robots
KW  - Robot sensing systems
KW  - Hidden Markov models
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460836
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In order to make robot programming more easy and immediate, walk-through programming techniques can be exploited. However, a modification of a portion of the trajectory usually means to execute the path from the beginning. In this paper we propose a passivity-based framework to modify the trajectory online, manually driving the robot throughout the desired correction. The system follows the initial trajectory, encoded with Dynamical Movement Primitives, by setting high gains in the admittance control. When the human operator grabs the end-effector, the robot becomes compliant and the user can easily teach the desired correction, until he/she releases it at the end of the modification. Finally, the correction is optimally joined to the initial trajectory, restarting the path tracking. To avoid unsafe behaviors, the variation of the admittance parameters is performed exploiting energy tanks, in order to preserve the passivity of the interaction.
ER  - 

TY  - CONF
TI  - A Tensegrity-Inspired Compliant 3-DOF Compliant Joint
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3301
EP  - 3306
AU  - J. M. Friesen
AU  - J. L. Dean
AU  - T. Bewley
AU  - V. Sunspiral
PY  - 2018
KW  - actuators
KW  - design engineering
KW  - geometry
KW  - mechatronics
KW  - motion control
KW  - optimisation
KW  - position control
KW  - robot dynamics
KW  - velocity control
KW  - tensegrity-inspired compliant three degree-of-freedom robotic joint
KW  - continuously soft materials
KW  - embedded sensing
KW  - position information
KW  - velocity information
KW  - geometry selection
KW  - optimization
KW  - theoretical configuration space
KW  - mechatronic design solutions
KW  - hardware prototype
KW  - low order dynamic systems
KW  - soft robotic systems
KW  - robotic limb
KW  - omnidirectional compliance
KW  - Tensegrity-Inspired Compliant 3-DOF Compliant joint
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Geometry
KW  - Force
KW  - Topology
DO  - 10.1109/ICRA.2018.8460593
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Our Tensegrity-Inspired Compliant Three degree-of-freedom (DOF) robotic joint adds omnidirectional compliance to robotic limbs while reducing sprung mass through base mounted actuation. This enables a robotic limb which is safer to operate alongside humans and fragile equipment while still capable of generating quick movements and large forces if required. Unlike many other soft robotic systems which leverage continuously soft materials, our joint is simpler to model with low order dynamic systems and has a host of embedded sensing which provide ample information of its position and velocity. We first discuss geometry selection and optimization to maximize the theoretical configuration space of the joint. We then show several of our mechatronic design solutions, which are easily generalized to a multitude of cable-driven mechanisms, and demonstrate the performance of these mechanisms within the context of our hardware prototype. We then present results on the controllable stiffness of our physical prototype. Finally, we demonstrate the strength of our prototype which is capable of lifting a 7 kg mass at a distance of 0.95 meters from the joint.
ER  - 

TY  - CONF
TI  - Training Deep Neural Networks for Visual Servoing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3307
EP  - 3314
AU  - Q. Bateux
AU  - E. Marchand
AU  - J. Leitner
AU  - F. Chaumette
AU  - P. Corke
PY  - 2018
KW  - feedforward neural nets
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - position control
KW  - robot vision
KW  - servomechanisms
KW  - visual servoing
KW  - 6 DOF robot
KW  - deep neural network-based method
KW  - convolutional neural network
KW  - robust handling
KW  - scene-agnostic network
KW  - deep neural network training
KW  - real-time 6 DOF positioning
KW  - pose-based visual servoing control law
KW  - occlusions
KW  - lighting variations
KW  - Training
KW  - Robots
KW  - Feature extraction
KW  - Task analysis
KW  - Cameras
KW  - Voltage control
KW  - Robustness
DO  - 10.1109/ICRA.2018.8461068
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a deep neural network-based method to perform high-precision, robust and real-time 6 DOF positioning tasks by visual servoing. A convolutional neural network is fine-tuned to estimate the relative pose between the current and desired images and a pose-based visual servoing control law is considered to reach the desired pose. The paper describes how to efficiently and automatically create a dataset used to train the network. We show that this enables the robust handling of various perturbations (occlusions and lighting variations). We then propose the training of a scene-agnostic network by feeding in both the desired and current images into a deep network. The method is validated on a 6 DOF robot.
ER  - 

TY  - CONF
TI  - A Delay Compensation Approach for Pan-Tilt-Unit-based Stereoscopic 360 Degree Telepresence Systems Using Head Motion Prediction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3323
EP  - 3330
AU  - T. Aykut
AU  - C. Zou
AU  - J. Xu
AU  - D. Van Opdenbosch
AU  - E. Steinbach
PY  - 2018
KW  - helmet mounted displays
KW  - motion estimation
KW  - stereo image processing
KW  - telecontrol
KW  - video signal processing
KW  - virtual reality
KW  - Head-Mounted Displays
KW  - immersive experience
KW  - unbearable motion sickness
KW  - teleoperation session
KW  - delay compensation approach
KW  - head motion prediction
KW  - head motion estimation
KW  - quality of experience
KW  - communication delays
KW  - mean compensation rates
KW  - pan-tilt-unit-based stereoscopic 360 degree telepresence systems
KW  - teleoperation applications
KW  - quality-reducing effect
KW  - head movement predictors
KW  - head motion datasets
KW  - 3D 360° video
KW  - time 100.0 ms to 1000.0 ms
KW  - time 3.0 d
KW  - Delays
KW  - Head
KW  - Cameras
KW  - Stereo image processing
KW  - Three-dimensional displays
KW  - Visualization
KW  - Resists
DO  - 10.1109/ICRA.2018.8460750
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The acceptance of teleoperation applications like tele-driving, tele-surgery, tele-maintenance, etc., is challenged by the quality-reducing effect of end-to-end latency. Particularly, when users wear Head-Mounted Displays to enhance the immersive experience, the lag between head motion and display response leads to unbearable motion sickness, indisposition, and, in the worst case, abortion of the teleoperation session. In this paper, we propose a delay compensation approach with head motion prediction that can be applied to pan-tilt-unit-based stereoscopic telepresence systems. We provide the user with the impression of a 3D 360° video that represents the remote scene without noticing the present delay, even when rotating the head. To this end, we propose a novel prediction paradigm for head motion estimation to substantially mitigate the negative impact of the latency on the quality of experience. We re-implemented state-of-the-art head movement predictors and compare them to our proposed approach by means of qualitative measures. In our experiments, we used two real and independent head motion datasets for validation and tested communication delays between 100-1000ms. Our results show that mean compensation rates of more than 99% are able with our approach.
ER  - 

TY  - CONF
TI  - Improving 6D Pose Estimation of Objects in Clutter Via Physics-Aware Monte Carlo Tree Search
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3331
EP  - 3338
AU  - C. Mitash
AU  - A. Boularias
AU  - K. E. Bekris
PY  - 2018
KW  - clutter
KW  - image registration
KW  - Monte Carlo methods
KW  - object detection
KW  - optimisation
KW  - pose estimation
KW  - rendering (computer graphics)
KW  - tree searching
KW  - global point cloud registration techniques
KW  - global optimization process
KW  - cluttered scenes physically-consistent object poses
KW  - 6D pose estimation
KW  - object detection
KW  - physics-aware Monte Carlo tree search
KW  - Cartesian product
KW  - MCTS
KW  - rendering
KW  - upper confidence bound technique
KW  - UCB technique
KW  - Search problems
KW  - Three-dimensional displays
KW  - Solid modeling
KW  - Pose estimation
KW  - Computational modeling
KW  - Training
KW  - Image segmentation
DO  - 10.1109/ICRA.2018.8461163
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work proposes a process for efficiently searching over combinations of individual object 6D pose hypotheses in cluttered scenes, especially in cases involving occlusions and objects resting on each other. The initial set of candidate object poses is generated from state-of-the-art object detection and global point cloud registration techniques. The best scored pose per object by using these techniques may not be accurate due to overlaps and occlusions. Nevertheless, experimental indications provided in this work show that object poses with lower ranks may be closer to the real poses than ones with high ranks according to registration techniques. This motivates a global optimization process for improving these poses by taking into account scene-level physical interactions between objects. It also implies that the Cartesian product of candidate poses for interacting objects must be searched so as to identify the best scene-level hypothesis. To perform the search efficiently, the candidate poses for each object are clustered so as to reduce their number but still keep a sufficient diversity. Then, searching over the combinations of candidate object poses is performed through a Monte Carlo Tree Search (MCTS) process that uses the similarity between the observed depth image of the scene and a rendering of the scene given the hypothesized pose as a score that guides the search procedure. MCTS handles in a principled way the tradeoff between fine-tuning the most promising poses and exploring new ones, by using the Upper Confidence Bound (UCB) technique. Experimental results indicate that this process is able to quickly identify in cluttered scenes physically-consistent object poses that are significantly closer to ground truth compared to poses found by point cloud registration methods.
ER  - 

TY  - CONF
TI  - SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3339
EP  - 3346
AU  - A. Byravan
AU  - F. Leeb
AU  - F. Meier
AU  - D. Fox
PY  - 2018
KW  - cameras
KW  - closed loop systems
KW  - control engineering computing
KW  - gradient methods
KW  - image colour analysis
KW  - image segmentation
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - minimisation
KW  - neural nets
KW  - pose estimation
KW  - robot dynamics
KW  - robot vision
KW  - SE3-pose-Nets
KW  - deep visuomotor control
KW  - SE3-Nets
KW  - encoder-decoder structure
KW  - pose embedding
KW  - point-wise data associations
KW  - closed-loop control
KW  - scene dynamics
KW  - structred deep dynamics models
KW  - pose error minimization
KW  - gradient-based methods
KW  - Baxter robot
KW  - Three-dimensional displays
KW  - Predictive models
KW  - Transforms
KW  - Computational modeling
KW  - Data models
KW  - Aerospace electronics
KW  - Training
DO  - 10.1109/ICRA.2018.8461184
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we present an approach to deep visuomotor control using structured deep dynamics models. Our model, a variant of SE3-Nets, learns a low-dimensional pose embedding for visuomotor control via an encoder-decoder structure. Unlike prior work, our model is structured: given an input scene, our network explicitly learns to segment salient parts and predict their pose embedding and motion, modeled as a change in the pose due to the applied actions. We train our model using a pair of point clouds separated by an action and show that given supervision only through point-wise data associations between the frames our network is able to learn a meaningful segmentation of the scene along with consistent poses. We further show that our model can be used for closed-loop control directly in the learned low-dimensional pose space, where the actions are computed by minimizing pose error using gradient-based methods, similar to traditional model-based control. We present results on controlling a Baxter robot from raw depth data in simulation and RGBD data in the real world and compare against two baseline deep networks. We also test the robustness and generalization performance of our controller under changes in camera pose, lighting, occlusion, and motion. Our method is robust, runs in real-time, achieves good prediction of scene dynamics, and outperforms baselines on multiple control runs. Video results can be found at: https://rse-lab.cs.washington.edu/se3-structured-deep-ctrl/.
ER  - 

TY  - CONF
TI  - Fast Object Learning and Dual-arm Coordination for Cluttered Stowing, Picking, and Packing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3347
EP  - 3354
AU  - M. Schwarz
AU  - C. Lenz
AU  - G. M. García
AU  - S. Koo
AU  - A. S. Periyasamy
AU  - M. Schreiber
AU  - S. Behnke
PY  - 2018
KW  - grippers
KW  - humanoid robots
KW  - human-robot interaction
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - service robots
KW  - robotic picking
KW  - cluttered bins
KW  - 2017 Amazon Robotics Challenge
KW  - ARC
KW  - storage system
KW  - deep object perception pipeline
KW  - custom turntable capture system
KW  - transfer learning
KW  - robot arms
KW  - NimbRo Picking
KW  - stow-and-pick task
KW  - Task analysis
KW  - Training
KW  - Robot kinematics
KW  - Pipelines
KW  - Robot sensing systems
KW  - Semantics
DO  - 10.1109/ICRA.2018.8461195
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotic picking from cluttered bins is a demanding task, for which Amazon Robotics holds challenges. The 2017 Amazon Robotics Challenge (ARC) required stowing items into a storage system, picking specific items, and packing them into boxes. In this paper, we describe the entry of team NimbRo Picking. Our deep object perception pipeline can be quickly and efficiently adapted to new items using a custom turntable capture system and transfer learning. It produces high-quality item segments, on which grasp poses are found. A planning component coordinates manipulation actions between two robot arms, minimizing execution time. The system has been demonstrated successfully at ARC, where our team reached second places in both the picking task and the final stow-and-pick task. We also evaluate individual components.
ER  - 

TY  - CONF
TI  - Optical Sensing and Control Methods for Soft Pneumatically Actuated Robotic Manipulators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3355
EP  - 3362
AU  - J. L. Molnar
AU  - C. Cheng
AU  - L. O. Tiziani
AU  - B. Boots
AU  - F. L. Hammond
PY  - 2018
KW  - elastomers
KW  - manipulators
KW  - mean square error methods
KW  - optical sensors
KW  - pneumatic actuators
KW  - regression analysis
KW  - strain data
KW  - chamber pressures
KW  - gravitational tip loading conditions
KW  - soft continuum robot
KW  - pressure data
KW  - base orientation
KW  - combined optical sensor
KW  - control methods
KW  - soft pneumatically actuated robotic
KW  - soft pneumatic manipulator motion
KW  - optically-diffuse elastomer sensors
KW  - strain mode
KW  - optical sensors measure local strains
KW  - axial center
KW  - optical sensing method
KW  - soft pneumatically actuated robotic manipulators
KW  - regression analyses
KW  - end-effector
KW  - Robot sensing systems
KW  - Optical fiber sensors
KW  - Optical fibers
KW  - Pneumatic systems
DO  - 10.1109/ICRA.2018.8461110
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A low-cost optical sensing method for improved measurement and control of soft pneumatic manipulator motion is presented. The core of a soft continuum robot is embedded with several optically-diffuse elastomer sensors which attenuate light depending on their strain mode and degree. The optical sensors measure local strains at the robot's axial center, and these strain data are combined with measured actuator chamber pressures to determine the pose of the robot under various gravitational and tip loading conditions. Regression analyses using neural networks (NNs) demonstrate that when the soft continuum robot's base orientation is fixed, the position of its end-effector can be estimated with 3.42 times more accuracy (71 % smaller root mean squared error) when using both optical sensor and pressure data (~2.44mm) than when using only pressure data (~8.3mm). When the robot's base orientation was varied, the combined optical sensor and pressure data provide position estimates which are as much as 37.8 times more accurate (~2.76mm) than pressure data alone (~104mm).
ER  - 

TY  - CONF
TI  - Mono-Stixels: Monocular Depth Reconstruction of Dynamic Street Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3369
EP  - 3375
AU  - F. Brickwedde
AU  - S. Abraham
AU  - R. Mester
PY  - 2018
KW  - cameras
KW  - image motion analysis
KW  - image reconstruction
KW  - image representation
KW  - image segmentation
KW  - image sequences
KW  - stereo image processing
KW  - monocular depth reconstruction
KW  - dynamic street scenes
KW  - semantic information
KW  - pixel-wise semantic segmentation
KW  - camera motion
KW  - optical flow estimation
KW  - depth reconstruction
KW  - stereo depth measurements
KW  - monostixel model
KW  - Semantics
KW  - Cameras
KW  - Optical imaging
KW  - Vehicle dynamics
KW  - Estimation
KW  - Dynamics
KW  - Motion segmentation
DO  - 10.1109/ICRA.2018.8460490
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present mono-stixels, a compact environment representation specially designed for dynamic street scenes. Mono-stixels are a novel approach to estimate stixels from a monocular camera sequence instead of the traditionally used stereo depth measurements. Our approach jointly infers the depth, motion and semantic information of the dynamic scene as a 1D energy minimization problem based on optical flow estimates, pixel-wise semantic segmentation and camera motion. The optical flow of a stixel is described by a homography. By applying the mono-stixel model the degrees of freedom of a stixel-homography are reduced to only up to two degrees of freedom. Furthermore, we exploit a scene model and semantic information to handle moving objects. In our experiments we use the public available DeepFlow for optical flow estimation and FCN8s for the semantic information as inputs and show on the KITTI 2015 dataset that mono-stixels provide a compact and reliable depth reconstruction of both the static and moving parts of the scene. Thereby, mono-stixels overcome the limitation to static scenes of previous structure-from-motion approaches.
ER  - 

TY  - CONF
TI  - The DriveU Traffic Light Dataset: Introduction and Comparison with Existing Datasets
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3376
EP  - 3383
AU  - A. Fregin
AU  - J. Muller
AU  - U. Krebel
AU  - K. Dietmayer
PY  - 2018
KW  - computer vision
KW  - image recognition
KW  - traffic engineering computing
KW  - DriveU traffic light dataset
KW  - traffic light recognition
KW  - autonomous driving
KW  - computer vision
KW  - University of Ulm Traffic Light Dataset
KW  - Daimler AG
KW  - Cameras
KW  - Urban areas
KW  - Benchmark testing
KW  - Lenses
KW  - Training
KW  - Visualization
KW  - Detectors
DO  - 10.1109/ICRA.2018.8460737
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous driving is a topic in computer vision which has captured a great deal of attention in recent years. One key problem is the detection and state analysis of traffic lights. Even over time, very few datasets for research in this topic have been published and they vary widely in quantity and in quality. To address the complexity of traffic light recognition, we introduce the DriveU**driveU is a joint innovation center of the Daimler AG and the University of Ulm Traffic Light Dataset (DTLD), a large-scale dataset consisting of more than 230,000 annotations. All annotations are hand-labeled according to strict rules and show a high quality. Recordings were made in eleven different cities during different weather conditions. Our dataset exceeds previous traffic light datasets in size, variance, annotation quality and amount of additional sensor data. We prove the extent of our dataset by an extensive comparison with existing traffic light datasets. Miscellaneous dataset criteria are compared, illustrated and statistically analyzed. In the process, metrics to express the quality and variance of datasets are developed and verified. The dataset can be downloaded from http://traffic-light-data.de.
ER  - 

TY  - CONF
TI  - Modeling Driver Behavior from Demonstrations in Dynamic Environments Using Spatiotemporal Lattices
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3384
EP  - 3390
AU  - D. S. González
AU  - O. Erkent
AU  - V. Romero-Cano
AU  - J. Dibangoye
AU  - C. Laugier
PY  - 2018
KW  - collision avoidance
KW  - driver information systems
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - road vehicles
KW  - spatiotemporal lattices
KW  - path planners
KW  - intelligent vehicles
KW  - cost function
KW  - model parameters
KW  - demonstrated driving data
KW  - Inverse Reinforcement
KW  - IRL methods
KW  - forward control problem
KW  - traditional path-planning techniques
KW  - conformal spatiotemporal state lattice
KW  - dynamic obstacles
KW  - model assessment
KW  - IRL framework
KW  - highly dynamic environments
KW  - highway tactical driving task
KW  - instrumented vehicle
KW  - driver behavior modeling
KW  - Trajectory
KW  - Lattices
KW  - Task analysis
KW  - Spatiotemporal phenomena
KW  - Vehicle dynamics
KW  - Learning (artificial intelligence)
KW  - Cost function
DO  - 10.1109/ICRA.2018.8460208
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the most challenging tasks in the development of path planners for intelligent vehicles is the design of the cost function that models the desired behavior of the vehicle. While this task has been traditionally accomplished by hand-tuning the model parameters, recent approaches propose to learn the model automatically from demonstrated driving data using Inverse Reinforcement Learning (IRL). To determine if the model has correctly captured the demonstrated behavior, most IRL methods require obtaining a policy by solving the forward control problem repetitively. Calculating the full policy is a costly task in continuous or large domains and thus often approximated by finding a single trajectory using traditional path-planning techniques. In this work, we propose to find such a trajectory using a conformal spatiotemporal state lattice, which offers two main advantages. First, by conforming the lattice to the environment, the search is focused only on feasible motions for the robot, saving computational power. And second, by considering time as part of the state, the trajectory is optimized with respect to the motion of the dynamic obstacles in the scene. As a consequence, the resulting trajectory can be used for the model assessment. We show how the proposed IRL framework can successfully handle highly dynamic environments by modeling the highway tactical driving task from demonstrated driving data gathered with an instrumented vehicle.
ER  - 

TY  - CONF
TI  - Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3399
EP  - 3406
AU  - E. Schmerling
AU  - K. Leung
AU  - W. Vollprecht
AU  - M. Pavone
PY  - 2018
KW  - decision making
KW  - human-robot interaction
KW  - intelligent transportation systems
KW  - learning (artificial intelligence)
KW  - probability
KW  - highway on-ramp-off-ramps
KW  - human-robot interaction policies
KW  - multimodal probabilistic model-based planning
KW  - traffic weaving scenario
KW  - human-in-the-loop simulation
KW  - candidate future robot actions
KW  - interaction history
KW  - action distributions
KW  - direct learning
KW  - candidate robot action sequences
KW  - human responses
KW  - massively parallel sampling
KW  - real-time robot policy construction
KW  - human-human exemplars
KW  - future human actions
KW  - multimodal probability distributions
KW  - inherent multimodal uncertainty
KW  - experienced drivers
KW  - entering exiting cars
KW  - decision making
KW  - Robots
KW  - Vehicles
KW  - Predictive models
KW  - History
KW  - Cognition
KW  - Probabilistic logic
KW  - Weaving
DO  - 10.1109/ICRA.2018.8460766
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a method for constructing human-robot interaction policies in settings where multimodality, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traffic weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars must swap lanes in a short distance-a challenging negotiation even for experienced drivers due to the inherent multimodal uncertainty of who will pass whom. Our approach is to learn multimodal probability distributions over future human actions from a dataset of human-human exemplars and perform real-time robot policy construction in the resulting environment model through massively parallel sampling of human responses to candidate robot action sequences. Direct learning of these distributions is made possible by recent advances in the theory of conditional variational autoencoders (CVAEs), whereby we learn action distributions simultaneously conditioned on the present interaction history, as well as candidate future robot actions in order to take into account response dynamics. We demonstrate the efficacy of this approach with a human-in-the-loop simulation of a traffic weaving scenario.
ER  - 

TY  - CONF
TI  - AA-ICP: Iterative Closest Point with Anderson Acceleration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3407
EP  - 3412
AU  - A. L. Pavlov
AU  - G. W. Ovchinnikov
AU  - D. Y. Derbyshev
AU  - D. Tsetserukou
AU  - I. V. Oseledets
PY  - 2018
KW  - iterative methods
KW  - PCL
KW  - Point Cloud Library
KW  - fixed point problem
KW  - ICP implementations
KW  - standard Picard iteration
KW  - iterative procedure
KW  - registration
KW  - scan-matching
KW  - Anderson acceleration
KW  - iterative closest point
KW  - AA-ICP
KW  - Iterative closest point algorithm
KW  - Acceleration
KW  - History
KW  - Convergence
KW  - Three-dimensional displays
KW  - Robots
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2018.8461063
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Iterative Closest Point (ICP) is a widely used method for performing scan-matching and registration. Being simple and robust, this method is still computationally expensive and may be challenging to use in real-time applications with limited resources on mobile platforms. In this paper we propose a novel effective method for acceleration of ICP which does not require substantial modifications to the existing code. This method is based on an idea of Anderson acceleration which is an iterative procedure for finding a fixed point of contractive mapping. The latter is often faster than a standard Picard iteration, usually used in ICP implementations. We show that ICP, being a fixed point problem, can be significantly accelerated by this method enhanced by heuristics to improve overall robustness. We implement proposed approach into Point Cloud Library (PCL) and make it available online. Benchmarking on the real-world data fully supports our claims.
ER  - 

TY  - CONF
TI  - Robust and Fast 3D Scan Alignment Using Mutual Information
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3413
EP  - 3420
AU  - N. Mehta
AU  - J. R. McBride
AU  - G. Pandey
PY  - 2018
KW  - graphics processing units
KW  - image registration
KW  - solid modelling
KW  - stereo image processing
KW  - mutual information
KW  - point clouds
KW  - 3D voxel grid
KW  - parallel implementation
KW  - 3D scan alignment
KW  - 6 DOF rigid body transformation
KW  - 6-degree-of-freedom rigid body transformation
KW  - MI
KW  - Three-dimensional displays
KW  - Mutual information
KW  - Robustness
KW  - Histograms
KW  - Iterative closest point algorithm
KW  - Optimization
KW  - Feature extraction
DO  - 10.1109/ICRA.2018.8460716
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a mutual information (MI) based algorithm for the estimation of full 6-degree-of-freedom (DOF) rigid body transformation between two overlapping point clouds. We first divide the scene into a 3D voxel grid and define simple to compute features for each voxel in the scan. The two scans that need to be aligned are considered as a collection of these features and the MI between these voxelized features is maximized to obtain the correct alignment of scans. We have implemented our method with various simple point cloud features (such as number of points in voxel, variance of z-height in voxel) and compared the performance of the proposed method with existing point-to-point and point-to-distribution registration methods. We show that our approach has an efficient and fast parallel implementation on GPU, and evaluate the robustness and speed of the proposed algorithm on two real-world datasets which have variety of dynamic scenes from different environments.
ER  - 

TY  - CONF
TI  - Drive Video Analysis for the Detection of Traffic Near-Miss Incidents
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3421
EP  - 3428
AU  - H. Kataoka
AU  - T. Suzuki
AU  - S. Oikawa
AU  - Y. Matsui
AU  - Y. Satoh
PY  - 2018
KW  - automobiles
KW  - driver information systems
KW  - learning (artificial intelligence)
KW  - object detection
KW  - road safety
KW  - road traffic
KW  - video signal processing
KW  - traffic near-miss incidents
KW  - self-driving cars
KW  - advanced driver assistance system equipped vehicles
KW  - dangerous traffic
KW  - normal drivers
KW  - novel traffic database
KW  - mounting driving recorders
KW  - automated systems
KW  - database instances
KW  - large-scale traffic near-miss incident database
KW  - monocular driving recorder
KW  - NIDB traffic
KW  - primary database-related improvements
KW  - near-miss scenes
KW  - near-miss detection
KW  - drive video analysis
KW  - near-miss incident
KW  - motion representation
KW  - performance level
KW  - Databases
KW  - Vehicles
KW  - Autonomous automobiles
KW  - Semantics
KW  - Advanced driver assistance systems
KW  - Public transportation
KW  - Training
DO  - 10.1109/ICRA.2018.8460812
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Because of their recent introduction, self-driving cars and advanced driver assistance system (ADAS) equipped vehicles have had little opportunity to learn, the dangerous traffic (including near-miss incident) scenarios that provide normal drivers with strong motivation to drive safely. Accordingly, as a means of providing learning depth, this paper presents a novel traffic database that contains information on a large number of traffic near-miss incidents that were obtained by mounting driving recorders in more than 100 taxis over the course of a decade. The study makes the following two main contributions: (i) In order to assist automated systems in detecting near-miss incidents based on database instances, we created a large-scale traffic near-miss incident database (NIDB) that consists of video clip of dangerous events captured by monocular driving recorders. (ii) To illustrate the applicability of NIDB traffic near-miss incidents, we provide two primary database-related improvements: parameter fine-tuning using various near-miss scenes from NIDB, and foreground/background separation into motion representation. Then, using our new database in conjunction with a monocular driving recorder, we developed a near-miss recognition method that provides automated systems with a performance level that is comparable to a human-level understanding of near-miss incidents (64.5% vs. 68.4% at near-miss recognition, 61.3% vs. 78.7% at near-miss detection).
ER  - 

TY  - CONF
TI  - A Modular Dielectric Elastomer Actuator to Drive Miniature Autonomous Underwater Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3429
EP  - 3435
AU  - F. Berlinger
AU  - M. Duduta
AU  - H. Gloria
AU  - D. Clarke
AU  - R. Nagpal
AU  - R. Wood
PY  - 2018
KW  - autonomous underwater vehicles
KW  - biomimetics
KW  - control system synthesis
KW  - elastomers
KW  - electroactive polymer actuators
KW  - force control
KW  - mobile robots
KW  - motion control
KW  - remotely operated vehicles
KW  - velocity control
KW  - thrust force
KW  - actuation layers
KW  - fin-like dielectric elastomer actuator
KW  - DEA design
KW  - fish fins undulatory motions
KW  - tunable DEAs
KW  - soft actuators
KW  - autonomous planar swimming
KW  - actuator designs
KW  - swimming speed
KW  - vertical swimming
KW  - underwater operation
KW  - elastomers
KW  - autonomous mobility
KW  - AUV
KW  - miniature autonomous underwater vehicle
KW  - modular dielectric elastomer actuator
KW  - Aquatic robots
KW  - Power supplies
KW  - Propulsion
KW  - Dielectric elastomer actuators
DO  - 10.1109/ICRA.2018.8461217
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present the design of a fin-like dielectric elastomer actuator (DEA) that drives a miniature autonomous underwater vehicle (AUV). The fin-like actuator is modular and independent of the body of the AUV. All electronics required to run the actuator are inside the 100 mm long 3D-printed body, allowing for autonomous mobility of the AUV. The DEA is easy to manufacture, requires no pre-stretch of the elastomers, and is completely sealed for underwater operation. The output thrust force can be tuned by stacking multiple actuation layers and modifying the Young's modulus of the elastomers. The AUV is reconfigurable by a shift of its center of mass, such that both planar and vertical swimming can be demonstrated on a single vehicle. For the DEA we measured thrust force and swimming speed for various actuator designs ran at frequencies from 1 Hz to 5 Hz. For the AUV we demonstrated autonomous planar swimming and closed-loop vertical diving. The actuators capable of outputting the highest thrust forces can power the AUV to swim at speeds of up to 0.55 body lengths per second. The speed falls in the upper range of untethered swimming robots powered by soft actuators. Our tunable DEAs also demonstrate the potential to mimic the undulatory motions of fish fins.
ER  - 

TY  - CONF
TI  - Proprioceptive-Inertial Autonomous Locomotion for Articulated Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3436
EP  - 3441
AU  - F. Ruscelli
AU  - G. Sartoretti
AU  - J. Nan
AU  - Z. Feng
AU  - M. Travers
AU  - H. Choset
PY  - 2018
KW  - collision avoidance
KW  - feedback
KW  - force control
KW  - legged locomotion
KW  - motion control
KW  - parallel controller
KW  - bi-stable dynamical system
KW  - snake robot
KW  - unevenly-spaced obstacles
KW  - proprioceptive controller
KW  - legged locomotion
KW  - hexaprint robot
KW  - proprioceptive-inertial autonomous locomotion
KW  - articulated robots
KW  - proprioception
KW  - vestibular feedback
KW  - gait
KW  - force sensing
KW  - force feedback
KW  - Shape
KW  - Robot sensing systems
KW  - Snake robots
KW  - Legged locomotion
KW  - Force feedback
KW  - Robot motion
DO  - 10.1109/ICRA.2018.8460584
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Inspired by the ability of animals to rely on proprioception and vestibular feedback to adapt their gait, we propose a modular framework for autonomous locomotion that relies on force sensing and inertial information. A first controller exploits anti-compliance, a new application of positive force feedback, to quickly react against obstacles upon impact. We hypothesize that, in situations where a robot experiences occasional impacts with the environment, anti-compliance can help negotiate unknown obstacles, similar to biological systems where positive feedback enables fast responses to external stimuli. A novel parallel controller, based on a bi-stable dynamical system, continuously adjusts the robot's direction of locomotion, and reverts it in reaction to major swerves. We present experimental results, demonstrating how our framework allows a snake robot to autonomously locomote through a row of unevenly-spaced obstacles. Finally, we extend our proprioceptive controller to legged locomotion, showing how a hexaprint robot can adapt its motion to climb over obstacles.
ER  - 

TY  - CONF
TI  - Autonomous Bio-Inspired Small-Object Detection and Avoidance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3442
EP  - 3447
AU  - M. Ohradzansky
AU  - H. E. Alvarez
AU  - J. Keshavan
AU  - B. N. Ranganathan
AU  - J. S. Humbert
PY  - 2018
KW  - collision avoidance
KW  - Fourier analysis
KW  - helicopters
KW  - image sequences
KW  - mobile robots
KW  - navigation
KW  - object detection
KW  - robot vision
KW  - small-field motion-sensitive interneurons
KW  - insect visuomotor system
KW  - small-field object detection
KW  - artificial potential function-based low-order steering control law
KW  - small-field clutter
KW  - bio-inspired approach
KW  - autonomous robots
KW  - autonomous vehicles
KW  - bio-inspired navigation technique
KW  - Fourier residual analysis
KW  - instantaneous optic flow
KW  - Optical sensors
KW  - Optical imaging
KW  - Navigation
KW  - Biomedical optical imaging
KW  - Insects
KW  - Neurons
DO  - 10.1109/ICRA.2018.8461156
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Small-object detection and avoidance in unknown environments is a significant challenge to overcome for small autonomous vehicles that are generally highly agile and restricted in payload and computational processing power. Typical machine-vision and range measurement based solutions suffer either from restricted fields-of-view or significant computational complexity and are not easily portable to small platforms. In this paper, a novel bio-inspired navigation technique is introduced that is modeled using analogues of the small-field motion-sensitive interneurons of the insect visuomotor system. The proposed technique achieves small-field object detection based on Fourier residual analysis of instantaneous optic flow. The small field signal is used to extract relative range and bearing of the nearest obstacle, which is then combined with an artificial potential function-based low-order steering control law. The proposed sensing and control scheme is experimentally validated with a quadrotor vehicle that is able to effectively navigate an unknown environment laden with small-field clutter. This bio-inspired approach is computationally efficient and serves as a robust, reflexive solution to the problem of small-object detection and avoidance for autonomous robots.
ER  - 

TY  - CONF
TI  - PISRob: A Pneumatic Soft Robot for Locomoting Like an Inchworm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3448
EP  - 3453
AU  - R. Xie
AU  - M. Su
AU  - Y. Zhang
AU  - M. Li
AU  - H. Zhu
AU  - Y. Guan
PY  - 2018
KW  - actuators
KW  - bending
KW  - mobile robots
KW  - pneumatic actuators
KW  - pneumatic systems
KW  - inchworm-like locomotion
KW  - PISRob
KW  - pneumatic soft robot
KW  - pneumatic actuation
KW  - pneumatic system
KW  - soft climbing robots
KW  - soft parts
KW  - system development
KW  - Legged locomotion
KW  - Soft robotics
KW  - Pneumatic systems
KW  - Strain
KW  - Fabrication
KW  - Glass
DO  - 10.1109/ICRA.2018.8461189
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Climbing or crawling robots may be widely applied in agriculture, forestry, military, construction industry, disaster searching and rescuing, and so on. Soft robots possess better safety, flexibility, dexterity, portability, and adaption to complex environments than traditional robots. However, there are big challenges in system development, modeling and control of soft climbing robots. To address system development of a soft robot as a new type climbing robot, we present a pneumatic soft robot capable of inchworm-like locomotion, PISRob. The presented robot is composed of three soft parts in H-shaped configuration. Each part is able to perform 2D bending. While the middle part, as the main body, can bend in Ω -shape for actuation, the two end parts as legs can conduct simple bending motion for grasping or anchoring during locomotion. The system design and fabrication process of the soft robot is presented in details in this paper. A control system is developed for pneumatic actuation of the robot. Tests are carried out to get the relationship between the actuating air pressure and the step length in locomotion. Experiments of crawling on a floor and climbing on a pole are performed to verify the feasibility of development of the new soft robot and the effectiveness of the control method for the pneumatic system.
ER  - 

TY  - CONF
TI  - Continuous Growth in Plant-Inspired Robots Through 3D Additive Manufacturing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3454
EP  - 3460
AU  - E. Del Dottore
AU  - A. Sadeghi
AU  - A. Mondini
AU  - B. Mazzolai
PY  - 2018
KW  - agriculture
KW  - bending
KW  - bio-inspired materials
KW  - position control
KW  - rapid prototyping (industrial)
KW  - robots
KW  - three-dimensional printing
KW  - three-term control
KW  - plant-inspired robots
KW  - 3D additive manufacturing
KW  - plant growth
KW  - 3D printer-like mechanism
KW  - tubular body
KW  - material deposition process
KW  - turning behavior
KW  - filament height
KW  - position PID control algorithm
KW  - homogeneous structures
KW  - robust structures
KW  - continuous growth
KW  - plotting velocity
KW  - bending
KW  - Magnetic heads
KW  - Force
KW  - Robot sensing systems
KW  - Soil
KW  - Wires
KW  - Fingers
DO  - 10.1109/ICRA.2018.8460616
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a new material deposition strategy for developing a growing robot capable of building its own body. The growing robot is inspired by plant growth and is based on a 3D printer-like mechanism. The plotting of a filament near the tip allows the forward movement of the robot and results in building a tubular body. A material deposition process is introduced to perform a straight continuous growth as well as a turning behavior in order to permit the navigation of the robot in the environment. Bending is achieved by controlling the filament height in each position of the plotting, lowering or increasing plotting velocity with a position PID control algorithm. We demonstrate that the continuous deposition of the filament allows to obtain homogeneous and robust structures, with a significant improvement of the robot's performance compared to our previous version of the system (i.e., more than 100 N pulling force and 200 N shear force). The current version of the robot can sustain its weight, move efficiently by growing in the environment - both air and soil - and penetrate hard medium (up to 60kPa).
ER  - 

TY  - CONF
TI  - Investigation of Scaling Effect of Copper Microwire Based on in-Situ Nanorobotic Twisting Inside SEM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3461
EP  - 3466
AU  - H. Lu
AU  - F. Xue
AU  - W. Wan
AU  - Y. Shen
PY  - 2018
KW  - copper
KW  - deformation
KW  - fracture
KW  - manipulators
KW  - nanomechanics
KW  - nanostructured materials
KW  - plastic deformation
KW  - scanning electron microscopy
KW  - twinning
KW  - deformation intertwine
KW  - deformation twin
KW  - plastic deformation
KW  - assembly method
KW  - positioning method
KW  - scanning electron microscope
KW  - copper microwire in situ twisting test
KW  - micromaterial
KW  - scaling effects
KW  - nanomaterial
KW  - copper microwire sample fracture morphology
KW  - copper microwire specimen
KW  - degree-of-freedoms nanorobotic manipulator
KW  - nanorobotics manipulation system
KW  - copper microwire mechanical properties
KW  - scaling effect
KW  - microelectron mechanical systems
KW  - SEM
KW  - in-situ nanorobotic twisting
KW  - Cu
KW  - Copper
KW  - Scanning electron microscopy
KW  - Manipulators
KW  - Mechanical factors
KW  - Calibration
DO  - 10.1109/ICRA.2018.8460573
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Copper microwire is an essential metal widely used in micro-electron mechanical systems. Since micro/nano material usually demonstrates unique mechanical properties due to scaling effect, copper microwire mechanical properties need to be investigated for better adhibition. Herein, we propose a nanorobotics manipulation system for copper microwire insitu twisting test. Firstly, a system with six degree-of-freedoms (DOFs) nanorobotic manipulator integrated inside scanning electron microscope (SEM) is introduced. Secondly, a positioning and assembly method for copper microwire specimen are proposed to solve the mismatching problem. Finally, the copper microwire is twisted in-situ and its properties are investigated and analyzed. The copper microwire sample fracture morphology shows a severe plastic deformation and being along with the emergence of deformation twin and intertwine, which exhibit strong scaling effects. This system provides a new method for in-situ twisting test, which paves the way for mechanical characterization inside SEM and benefits the fundamental nanomaterial research immensely.
ER  - 

TY  - CONF
TI  - Optimisation of Trap Design for Vibratory Bowl Feeders
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3467
EP  - 3474
AU  - S. Mathiesen
AU  - L. CarØe SØrensen
AU  - D. Kraft
AU  - L. Ellekilde
PY  - 2018
KW  - assembling
KW  - Bayes methods
KW  - design engineering
KW  - optimisation
KW  - production engineering computing
KW  - prototypes
KW  - regression analysis
KW  - vibrations
KW  - trap design
KW  - vibratory bowl feeders
KW  - industrial part feeding
KW  - VBF design
KW  - optimal parameter
KW  - passive devices
KW  - dynamic simulation
KW  - modified Upper Confidence Bound
KW  - Bayesian optimisation
KW  - kernel density estimation
KW  - regression analysis
KW  - prototypes
KW  - assembling
KW  - Optimization
KW  - Bayes methods
KW  - Task analysis
KW  - Vibrations
KW  - Shape
KW  - Manuals
KW  - Robustness
DO  - 10.1109/ICRA.2018.8460767
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Vibratory bowl feeders (VBFs) are a widely used option for industrial part feeding, but their design is still largely manual. A subtask of VBF design is determining an optimal parameter set for the passive devices, called traps, which the VBF uses to ensure correct part orientation. This paper proposes a fast and robust strategy for optimising traps, which makes use of dynamic simulation to efficiently evaluate the performance of parameter sets. The optimisation strategy is based on Bayesian Optimisation and selects new parameter sets to evaluate, using a modified Upper Confidence Bound with regression by Kernel Density Estimation as function estimator. The optimisation is run for four different traps with an industrial part and the best parameter sets are tested for robustness in simulation. The traps are then combined to create two sequences performing orientation of the parts and the designs are prototyped and tested on a real VBF.
ER  - 

TY  - CONF
TI  - Teach-and-Replay of Mobile Robot with Particle Filter on Episode
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3475
EP  - 3481
AU  - R. Ueda
AU  - M. Kato
AU  - A. Saito
AU  - R. Okazaki
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - robust control
KW  - mobile robot
KW  - reinforcement learning method
KW  - task teaching
KW  - micromouse type robot
KW  - Teach-and-Replay
KW  - PFoE
KW  - particle filter on episode
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Education
KW  - Hidden Markov models
KW  - Mobile robots
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461235
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A novel method for replaying behavior of a mobile robot from its memory of past experiences is presented in this paper. The method is a version of a particle filter on episode (PFoE), which applies a particle filter on the memory so as to efficiently find some similar situations with the current one. Though the original PFoE was proposed as a reinforcement learning method, we once removed the reward system from the original one so as to apply it to task teaching. In the experiment, we gave several kinds of motion to a micromouse type robot with the proposed method through a gamepad. The robot replayed the behaviors robustly with sensor feedback after several number of repetitive teaching.
ER  - 

TY  - CONF
TI  - Vision-Based Robotic Grasping and Manipulation of USB Wires
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3482
EP  - 3487
AU  - X. Li
AU  - X. Su
AU  - Y. Gao
AU  - Y. Liu
PY  - 2018
KW  - closed loop systems
KW  - grippers
KW  - industrial manipulators
KW  - Lyapunov methods
KW  - peripheral interfaces
KW  - robot vision
KW  - stability
KW  - USB cables
KW  - vision-based controller
KW  - wire alignment
KW  - USB color code
KW  - vision-based robotic grasping
KW  - USB wires
KW  - two-level structure
KW  - dynamic stability
KW  - closed-loop system
KW  - Lyapunov methods
KW  - Wires
KW  - Universal Serial Bus
KW  - Robots
KW  - Grasping
KW  - Grippers
KW  - Strain
KW  - Image color analysis
DO  - 10.1109/ICRA.2018.8460694
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The fast expanding 3C (Computer, Communication, and Consumer electronics) manufacturing leads to a high demand on the fabrication of USB cables. While several commercial machines have been developed to automate the process of stripping and soldering of USB cables, the operation of manipulating USB wires according to the color code is heavily dependent on manual works because of the deformation property of wires, probably resulting in the falling-off or the escape of wires during manipulation. In this paper, a new vision-based controller is proposed for robotic grasping and manipulation of USB wires. A novel two-level structure is developed and embedded into the controller, where Level-I is referred to as the grasping and manipulation of wires, and Level-II is referred to as the wire alignment by following the USB color code. The proposed formulation allows the robot to automatically grasp, manipulate, and align the wires in a sequential, simultaneous, and smooth manner, and hence to deal with the deformation of wires. The dynamic stability of the closed-loop system is rigorously proved with Lyapunov methods, and experiments are performed to validate the proposed controller.
ER  - 

TY  - CONF
TI  - Visual Grasping for a Lightweight Aerial Manipulator Based on NSGA-II and Kinematic Compensation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3488
EP  - 3493
AU  - L. Fang
AU  - H. Chen
AU  - Y. Lou
AU  - Y. Li
AU  - Y. Liu
PY  - 2018
KW  - autonomous aerial vehicles
KW  - calibration
KW  - collision avoidance
KW  - compensation
KW  - genetic algorithms
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - visual grasping
KW  - lightweight aerial manipulator
KW  - complex kinematics/dynamics
KW  - motion constraints
KW  - X8 coaxial octocopter
KW  - 4-DoF manipulator
KW  - grasping control problem
KW  - NSGA-II method
KW  - trajectory planning
KW  - kinematic compensation-based visual trajectory tracking
KW  - trajectory generation
KW  - dynamic parameter calibration
KW  - Manipulator dynamics
KW  - Trajectory
KW  - Grasping
KW  - Kinematics
KW  - Acceleration
KW  - Visualization
DO  - 10.1109/ICRA.2018.8460520
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The grasping control of an aerial manipulator in practical environments is challenging due to its complex kinematics/dynamics and motion constraints. This paper introduces a lightweight aerial manipulator, which is combined with an X8 coaxial octocopter and a 4-DoF manipulator. To address the grasping control problem, we develop an efficient scheme containing trajectory generation, visual trajectory tracking, and kinematic compensation. The NSGA-II method is utilized to implement the multiobjective optimization for trajectory planning. Motion constraints and collision avoidance are also considered in the optimization. A kinematic compensation-based visual trajectory tracking is introduced to address the coupled nature between manipulator and VAV body. No dynamic parameter calibration is needed. Finally, several experiments are performed to verify the stability and feasibility of the proposed approach.
ER  - 

TY  - CONF
TI  - Track, Then Decide: Category-Agnostic Vision-Based Multi-Object Tracking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3494
EP  - 3501
AU  - A. Ošep
AU  - W. Mehner
AU  - P. Voigtlaender
AU  - B. Leibe
PY  - 2018
KW  - computer vision
KW  - image colour analysis
KW  - image recognition
KW  - image segmentation
KW  - object detection
KW  - object tracking
KW  - object category
KW  - tracking-by-detection methods
KW  - segmentation mask-based tracker
KW  - pixel-precise masks
KW  - category-agnostic vision-based multiobject tracking
KW  - generic object proposals
KW  - class-agnostic multiobject tracking
KW  - Proposals
KW  - Three-dimensional displays
KW  - Tracking
KW  - Laser radar
KW  - Semantics
KW  - Detectors
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2018.8460975
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The most common paradigm for vision-based multi-object tracking is tracking-by-detection, due to the availability of reliable detectors for several important object categories such as cars and pedestrians. However, future mobile systems will need a capability to cope with rich human-made environments, in which obtaining detectors for every possible object category would be infeasible. In this paper, we address the problem of class-agnostic multi-object tracking using generic object proposals. We present an efficient segmentation mask-based tracker which associates pixel-precise masks reported by the segmentation. Our approach can utilize semantic information whenever it is available for classifying objects at the track level, while retaining the capability to track generic unknown objects in the absence of such information. We demonstrate experimentally that our approach achieves performance comparable to state-of-the-art tracking-by-detection methods for popular object categories such as cars and pedestrians. Additionally, we show that the proposed method can discover and robustly track a large variety of other objects.
ER  - 

TY  - CONF
TI  - Vision-Based Global Localization Using Ceiling Space Density
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3502
EP  - 3507
AU  - A. Ribacki
AU  - V. A. M. Jorge
AU  - M. Mantelli
AU  - R. Maffei
AU  - E. Prestes
PY  - 2018
KW  - cameras
KW  - mobile robots
KW  - robot vision
KW  - service robots
KW  - home environments
KW  - free space density
KW  - available blueprint information
KW  - ceiling vision
KW  - robust localization information
KW  - robotic vacuum
KW  - superior localization results
KW  - vision-based global localization
KW  - ceiling space density
KW  - service robots
KW  - homes
KW  - self-localize
KW  - man-made constructions
KW  - documented blueprint
KW  - robot localization
KW  - smart home applications
KW  - movable objects
KW  - complicated task
KW  - horizontal range-finders
KW  - effective global localization approach
KW  - Cameras
KW  - Kernel
KW  - Three-dimensional displays
KW  - Robot vision systems
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8460515
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Service robots are becoming a reality across homes. Still, the range of applications supported by such robots remains tied to their ability to self-localize in the environment. Man-made constructions often have a documented blueprint which can be used as input information for robot localization and smart home applications. However, home environments commonly include movable objects and furniture, which can make localization a complicated task, especially for forward-facing horizontal range-finders. In this paper, we present a new and effective global localization approach for home environments which adapts the notion of free space density to a camera pointing to the ceiling. We exploit the available blueprint information, as well as evidence that ceiling vision can provide robust localization information, even in the presence of occlusions. We perform real-world experiments using a robotic vacuum cleaner equipped with an upward-facing camera in two different apartments across multiple trajectories and compare the proposed method with competing approaches. Our solution shows superior localization results using maps where neither furniture or movable objects are not modeled.
ER  - 

TY  - CONF
TI  - Beyond Pixels: Leveraging Geometry and Shape Cues for Online Multi-Object Tracking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3508
EP  - 3515
AU  - S. Sharma
AU  - J. A. Ansari
AU  - J. Krishna Murthy
AU  - K. Madhava Krishna
PY  - 2018
KW  - cameras
KW  - image motion analysis
KW  - object detection
KW  - object tracking
KW  - optimisation
KW  - pose estimation
KW  - data association method
KW  - tracking-by-detection framework
KW  - object detectors
KW  - object motions
KW  - online multiobject tracking
KW  - object shape
KW  - monocular camera
KW  - object pose
KW  - object motion
KW  - Three-dimensional displays
KW  - Shape
KW  - Target tracking
KW  - Roads
KW  - Trajectory
KW  - Cameras
DO  - 10.1109/ICRA.2018.8461018
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces geometry and object shape and pose costs for multi-object tracking in urban driving scenarios. Using images from a monocular camera alone, we devise pairwise costs for object tracks, based on several 3D cues such as object pose, shape, and motion. The proposed costs are agnostic to the data association method and can be incorporated into any optimization framework to output the pairwise data associations. These costs are easy to implement, can be computed in real-time, and complement each other to account for possible errors in a tracking-by-detection framework. We perform an extensive analysis of the designed costs and empirically demonstrate consistent improvement over the state-of-the-art under varying conditions that employ a range of object detectors, exhibit a variety in camera and object motions, and, more importantly, are not reliant on the choice of the association framework. We also show that, by using the simplest of associations frameworks (two-frame Hungarian assignment), we surpass the state-of-the-art in multi-object-tracking on road scenes. More qualitative and quantitative results can be found at https://junaidcs032.github.io/Geometry_ObjectShape_MOT/.
ER  - 

TY  - CONF
TI  - Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from Simulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3516
EP  - 3523
AU  - K. Fang
AU  - Y. Bai
AU  - S. Hinterstoisser
AU  - S. Savarese
AU  - M. Kalakrishnan
PY  - 2018
KW  - feature extraction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - robot vision
KW  - multitask domain adaptation
KW  - deep learning
KW  - successful grasping probability
KW  - transfer learning framework
KW  - domain-adversarial loss
KW  - candidate motor command
KW  - specified target object
KW  - instance segmentation mask
KW  - monocular RGB images
KW  - neural network
KW  - cluttered scenes
KW  - instance grasping
KW  - robotic manipulation
KW  - Grasping
KW  - Robots
KW  - Adaptation models
KW  - Data models
KW  - Feature extraction
KW  - Image segmentation
KW  - Neural networks
DO  - 10.1109/ICRA.2018.8461041
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.
ER  - 

TY  - CONF
TI  - Learning Robotic Assembly from CAD
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3524
EP  - 3531
AU  - G. Thomas
AU  - M. Chien
AU  - A. Tamar
AU  - J. A. Ojea
AU  - P. Abbeel
PY  - 2018
KW  - CAD
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - production engineering computing
KW  - robotic assembly
KW  - suboptimal control
KW  - autonomous robotic assembly
KW  - industrial assembly tasks
KW  - contact-rich manipulation skills
KW  - motion planning approaches
KW  - robot controllers
KW  - reinforcement learning
KW  - robot skills
KW  - contact-rich dynamics
KW  - control policy
KW  - robot executions
KW  - locally suboptimal solutions
KW  - RL performance
KW  - CAD design files
KW  - geometric motion plan
KW  - CAD data
KW  - assembly controller
KW  - manufacturing trends
KW  - Task analysis
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Tracking
KW  - Robotic assembly
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460696
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, motivated by recent manufacturing trends, we investigate autonomous robotic assembly. Industrial assembly tasks require contact-rich manipulation skills, which are challenging to acquire using classical control and motion planning approaches. Consequently, robot controllers for assembly domains are presently engineered to solve a particular task, and cannot easily handle variations in the product or environment. Reinforcement learning (RL) is a promising approach for autonomously acquiring robot skills that involve contact-rich dynamics. However, RL relies on random exploration for learning a control policy, which requires many robot executions, and often gets trapped in locally suboptimal solutions. Instead, we posit that prior knowledge, when available, can improve RL performance. We exploit the fact that in modern assembly domains, geometric information about the task is readily available via the CAD design files. We propose to leverage this prior knowledge by guiding RL along a geometric motion plan, calculated using the CAD data. We show that our approach effectively improves over traditional control approaches for tracking the motion plan, and can solve assembly tasks that require high precision, even without accurate state estimation. In addition, we propose a neural network architecture that can learn to track the motion plan, thereby generalizing the assembly controller to changes in the object positions.
ER  - 

TY  - CONF
TI  - Accurate and Adaptive in Situ Fabrication of an Undulated Wall Using an on-Board Visual Sensing System
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3532
EP  - 3539
AU  - M. Lussi
AU  - T. Sandy
AU  - K. Dörfler
AU  - N. Hack
AU  - F. Gramazio
AU  - M. Kohler
AU  - J. Buchli
PY  - 2018
KW  - buildings (structures)
KW  - CAD
KW  - geometry
KW  - mobile robots
KW  - reinforced concrete
KW  - robot vision
KW  - steel
KW  - structural engineering computing
KW  - walls
KW  - wires
KW  - in situ fabrication
KW  - visual sensing system
KW  - curved steel reinforced concrete wall
KW  - steel wire mesh
KW  - building construction
KW  - digital building process
KW  - CAD model
KW  - material deformations
KW  - geometry
KW  - mobile robot
KW  - vision-based sensing
KW  - load-bearing
KW  - building plan
KW  - Buildings
KW  - Robot sensing systems
KW  - Wires
KW  - Fabrication
KW  - Steel
DO  - 10.1109/ICRA.2018.8460480
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present a system for the in situ33In the context of building construction, “in situ” means that fabrication takes place at the structure's final location directly on the building site. fabrication of a full-scale, load-bearing, and doubly-curved steel reinforced concrete wall. Two complementary vision-based sensing systems provide the feedback necessary to build a 12 meter long steel wire mesh as part of a novel digital building process. The sensing systems provide estimates of the robot pose, referenced to the CAD model of the building site, as well as feedback on the accuracy of the built structure over the course of construction. This second piece of information is used to adapt the building plan to compensate for system inaccuracies and material deformations which occur during buildup. In this way, the structure was successfully built with 98% of the total geometry within 2 centimeters of the designed position. To the best of our knowledge, this is the largest structure which has been built by a mobile robot using solely vision-based sensing.
ER  - 

TY  - CONF
TI  - Robot Assisted Carpentry for Mass Customization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3540
EP  - 3547
AU  - J. I. Lipton
AU  - A. Schulz
AU  - A. Spielberg
AU  - L. Trueba
AU  - W. Matusik
AU  - D. Rus
PY  - 2018
KW  - design engineering
KW  - furniture
KW  - mass production
KW  - mobile robots
KW  - product customisation
KW  - production engineering computing
KW  - mass customization
KW  - laymen editable templates
KW  - CNC fabrication
KW  - template based system
KW  - robotic fabrication system
KW  - mobile robots
KW  - standard carpentry tools
KW  - end-to-end design
KW  - template design
KW  - laymen users
KW  - robotics system
KW  - design tools
KW  - robot assisted carpentered items
KW  - Fabrication
KW  - Robots
KW  - Solid modeling
KW  - Tools
KW  - Standards
KW  - Face
KW  - Connectors
DO  - 10.1109/ICRA.2018.8460736
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Despite the ubiquity of carpentered items, the customization of carpentered items remains labor intensive. The generation of laymen editable templates for carpentry is difficult. Current design tools rely heavily on CNC fabrication, limiting applicability. We develop a template based system for carpentry and a robotic fabrication system using mobile robots and standard carpentry tools. Our end-to-end design and fabrication tool democratizes design and fabrication of carpentered items. Our method combines expert knowledge for template design, allows laymen users to customize and verify specific designs, and uses robotics system to fabricate parts. We validate our system using multiple designs to make customizable, verifiable templates and fabrication plans and show an end-to-end example that was designed, manufactured, and assembled using our tools.
ER  - 

TY  - CONF
TI  - A General and Flexible Search Framework for Disassembly Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3548
EP  - 3555
AU  - T. Ebinger
AU  - S. Kaden
AU  - S. Thomas
AU  - R. Andre
AU  - N. M. Amato
AU  - U. Thomas
PY  - 2018
KW  - assembly planning
KW  - design for disassembly
KW  - iterative methods
KW  - search problems
KW  - iterative motion planning
KW  - collision information
KW  - subassembly identification
KW  - preemptive scheme
KW  - exhaustive scheme
KW  - search strategies
KW  - hierarchical approach
KW  - disassembly sequence planning
KW  - parallelism
KW  - part separation techniques
KW  - Planning
KW  - Trajectory
KW  - Measurement
KW  - Data structures
KW  - Search problems
KW  - Learning systems
KW  - Containers
DO  - 10.1109/ICRA.2018.8460483
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a new general framework for disassembly sequence planning. This framework is versatile allowing different types of search schemes (exhaustive vs. preemptive), various part separation techniques, and the ability to group parts, or not, into subassemblies to improve the solution efficiency and parallelism. This enables a truly hierarchical approach to disassembly sequence planning. We demonstrate two different search strategies using this framework that can either yield a single solution quickly or provide a spectrum of solutions from which an optimal may be selected. We also develop a method for subassembly identification based on collision information. Our results show improved performance over an iterative motion planning based method for finding a single solution and greater functionality through hierarchical planning and optimal solution search.
ER  - 

TY  - CONF
TI  - 1-Actuator 3-DoF Manipulation Using a Virtual Turntable Based on Differential Friction Surface
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3573
EP  - 3580
AU  - K. Yamaguchi
AU  - M. Higashimori
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - end effectors
KW  - friction
KW  - manipulator dynamics
KW  - motion control
KW  - plates (structures)
KW  - position control
KW  - flat plate
KW  - manipulator
KW  - active-passive hybrid joint mechanism
KW  - surface friction property
KW  - 3- DoF manipulation strategy
KW  - virtual turntable
KW  - 1-actuator 3-DoF manipulation
KW  - differential friction surface
KW  - nonprehensile manipulation
KW  - single actuator
KW  - manipulation strategy
KW  - Friction
KW  - Actuators
KW  - Orbits
KW  - Vibrations
KW  - End effectors
KW  - Frequency control
DO  - 10.1109/ICRA.2018.8460634
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes nonprehensile manipulation realized using the vibration of a plate. A novel manipulation strategy is proposed wherein the three degrees-of-freedom (DoF) of a part are controlled by only one actuator. First, a manipulator driven by a single actuator is introduced. The end effector of this manipulator is a flat plate. The manipulator employs an active-passive hybrid joint mechanism with nonparallel axes. Based on the sinusoidal displacement input to the actuator, the manipulator can generate the velocity of a part omnidirectionally on the plate. Next, simulation results are presented to show that the velocity map of the part varies depending upon the surface friction property of the plate. Further, the control of the rotational behavior of the part on the boundary of two areas with different friction properties by means of the input frequency is shown. Based on this control, a 3- DoF manipulation strategy using a virtual turntable is developed to realize the desired position and orientation of the part. Finally, the proposed method is demonstrated via experiments.
ER  - 

TY  - CONF
TI  - A Fish-Like Magnetically Propelled Microswimmer Fabricated by 3D Laser Lithography
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3581
EP  - 3586
AU  - P. Liao
AU  - J. Li
AU  - S. Zhang
AU  - D. Sun
PY  - 2018
KW  - bioMEMS
KW  - biomimetics
KW  - cell motility
KW  - hydrodynamics
KW  - laser materials processing
KW  - magnetic actuators
KW  - medical robotics
KW  - microfabrication
KW  - microorganisms
KW  - microrobots
KW  - nickel
KW  - permanent magnets
KW  - fish-like magnetically propelled microswimmer fabrication
KW  - glass substrate
KW  - detoxification tools
KW  - biosensing tools
KW  - fabricated microswimmers
KW  - permanent magnets
KW  - magnetic control system
KW  - external magnetic field
KW  - oscillating uniform magnetic field
KW  - magnetic actuation
KW  - caudal fin
KW  - 3D laser lithography
KW  - size 50.0 nm
KW  - Ni
KW  - Magnetic fields
KW  - Magnetic domains
KW  - Magnetic heads
KW  - Magnetic flux
KW  - Magnetic resonance imaging
KW  - Propulsion
DO  - 10.1109/ICRA.2018.8460522
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the development of a fish-like magnetically propelled microswimmer fabricated by 3D laser lithography. The microswimmer consists of a head and a caudal fin, just like a natural fish. There is a joint between the head and the fin so that the caudal fin can oscillate around the head to generate thrust, and the oscillation of the fin hardly transfers to the head, which benefits the stable motion of the microswimmer. The caudal fin of the microswimmer is deposited with a layer of 50 nm nickel (Ni) for magnetic actuation. Through applying an oscillating uniform magnetic field, the microswimmer can move along with the direction guided by the external magnetic field. A magnetic control system with permanent magnets is designed to provide such an oscillating uniform magnetic field, where the oscillating frequency and amplitude are controllable. A micro probe operation platform is used to detach the fabricated microswimmers from glass substrate in manufacturing. The proposed magnetically propelled microswimmer can be potentially used as powerful detoxification and biosensing tools for medical diagnosis and treatment in precision medicine.
ER  - 

TY  - CONF
TI  - Liftoff of a 190 mg Laser-Powered Aerial Vehicle: The Lightest Wireless Robot to Fly
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3587
EP  - 3594
AU  - J. James
AU  - V. Iyer
AU  - Y. Chukewad
AU  - S. Gollakota
AU  - S. B. Fuller
PY  - 2018
KW  - aerospace robotics
KW  - autonomous aerial vehicles
KW  - avionics
KW  - electronics packaging
KW  - feedback
KW  - microcontrollers
KW  - microrobots
KW  - mobile robots
KW  - power convertors
KW  - robot dynamics
KW  - wire tethers
KW  - high-voltage power electronics
KW  - severely constrained weight budgets
KW  - wireless liftoff
KW  - fast-turnaround laser based circuit fabrication technique
KW  - onboard electronics
KW  - high voltage bias
KW  - drive signals
KW  - insect scale aerial robots
KW  - aerial vehicle
KW  - power electronics package
KW  - wireless robot
KW  - laser-powered aerial vehicle
KW  - microcontroller
KW  - feedback control
KW  - mass 190.0 mg
KW  - mass 104.0 mg
KW  - wavelength 976.0 nm
KW  - Actuators
KW  - Insects
KW  - Microcontrollers
KW  - High-voltage techniques
KW  - Capacitors
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8460582
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To date, insect scale aerial robots have required wire tethers for providing power due to the challenges of integrating the required high-voltage power electronics within their severely constrained weight budgets. In this paper we present a significant milestone in the achievement of flight autonomy: the first wireless liftoff of a 190 mg aerial vehicle. Our robot is remotely powered using a 976 nm laser and integrates a complete power electronics package weighing a total of 104 mg, using commercially available components and fabricated using a fast-turnaround laser based circuit fabrication technique. The onboard electronics include a lightweight boost converter capable of producing high voltage bias and drive signals of over 200 V at up to 170 Hz and regulated by a microcontroller performing feedback control. We present our system design and analysis, detailed description of our fabrication method, and results from flight experiments.
ER  - 

TY  - CONF
TI  - Soft Miniaturized Linear Actuators Wirelessly Powered by Rotating Permanent Magnets
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3595
EP  - 3600
AU  - T. Qiu
AU  - S. Palagi
AU  - J. Sachs
AU  - P. Fischer
PY  - 2018
KW  - magnetic actuators
KW  - magnetic fields
KW  - microactuators
KW  - permanent magnets
KW  - torque control
KW  - soft miniaturized linear actuators
KW  - wirelessly powered microactuators
KW  - magnet assembly
KW  - magnetic field generator
KW  - externally applied magnetic torque
KW  - soft miniaturized actuator
KW  - magnetic torques
KW  - untethered miniaturized devices
KW  - wireless actuation
KW  - rotating permanent magnets
KW  - Actuators
KW  - Magnetic fields
KW  - Magnetic resonance imaging
KW  - Permanent magnets
KW  - Magnetic moments
KW  - Torque
KW  - Magnetic flux
DO  - 10.1109/ICRA.2018.8461145
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Wireless actuation by magnetic fields allows for the operation of untethered miniaturized devices, e.g. in biomedical applications. Nevertheless, generating large controlled forces over relatively large distances is challenging. Magnetic torques are easier to generate and control, but they are not always suitable for the tasks at hand. Moreover, strong magnetic fields are required to generate a sufficient torque, which are difficult to achieve with electromagnets. Here, we demonstrate a soft miniaturized actuator that transforms an externally applied magnetic torque into a controlled linear force. We report the design, fabrication and characterization of both the actuator and the magnetic field generator. We show that the magnet assembly, which is based on a set of rotating permanent magnets, can generate strong controlled oscillating fields over a relatively large workspace. The actuator, which is 3D-printed, can lift a load of more than 40 times its weight. Finally, we show that the actuator can be further miniaturized, paving the way towards strong, wirelessly powered microactuators.
ER  - 

TY  - CONF
TI  - Eight-Degrees-of-Freedom Remote Actuation of Small Magnetic Mechanisms
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3608
EP  - 3613
AU  - S. Salmanipour
AU  - E. Diller
PY  - 2018
KW  - magnetic fields
KW  - medical robotics
KW  - microfluidics
KW  - microrobots
KW  - motion control
KW  - microscale devices
KW  - microrobotic devices
KW  - independent motions
KW  - magnetic elements
KW  - independent actuation
KW  - homogeneous magnetic field input
KW  - magnetic field signals
KW  - field generation source
KW  - magnetic microrobots
KW  - complex mechanism motions
KW  - multiagent mechanism motions
KW  - stationary devices
KW  - mobile devices
KW  - microfactories
KW  - microfluidic tools
KW  - medical procedures
KW  - remote applications
KW  - millimeter-scale robotic devices
KW  - magnetic mechanisms
KW  - degrees-of-freedom remote actuation
KW  - size 500.0 mum
KW  - size 0.6 mm
KW  - Magnetic resonance imaging
KW  - Magnetic devices
KW  - Magnetic moments
KW  - Torque
KW  - Mathematical model
KW  - Force
KW  - Wireless communication
DO  - 10.1109/ICRA.2018.8461026
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Magnetically-driven micrometer to millimeter-scale robotic devices have recently shown great capabilities for remote applications in medical procedures, in microfluidic tools and in microfactories. Significant effort recently has been on the creation of mobile or stationary devices with multiple independently-controllable degrees of freedom (DOF) for multiagent or complex mechanism motions. In most applications of magnetic microrobots, however, the relatively large distance from the field generation source and the microscale devices results in controlling magnetic field signals which are applied homogeneously over all agents. While some progress has been made in this area allowing up to six independent DOF to be individually commanded, there has been no rigorous effort in determining the maximum achievable number of DOF for systems with homogeneous magnetic field input. In this work, we show that this maximum is eight and we introduce the theoretical basis for this conclusion, relying on the number of independent usable components in a magnetic field at a point. In order to verify the claim experimentally, we develop a simple demonstration mechanism with 8 DOF designed specifically to show independent actuation. Using this mechanism with 500 μm magnetic elements, we demonstrate eight independent motions of 0.6 mm with 8.6 % coupling using an eight coil system. These results will enable the creation of richer outputs in future microrobotic devices.
ER  - 

TY  - CONF
TI  - Feature-Based SLAM for Imaging Sonar with Under-Constrained Landmarks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3629
EP  - 3636
AU  - E. Westman
AU  - A. Hinduja
AU  - M. Kaess
PY  - 2018
KW  - feature extraction
KW  - image reconstruction
KW  - image sensors
KW  - reliability
KW  - SLAM (robots)
KW  - sonar imaging
KW  - sonar imaging
KW  - point landmark identification
KW  - feature-point extraction
KW  - general-purpose method
KW  - planar scene assumption
KW  - underwater feature-based SLAM
KW  - under-constrained landmarks
KW  - Feature extraction
KW  - Imaging
KW  - Sonar measurements
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Image reconstruction
DO  - 10.1109/ICRA.2018.8461004
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recent algorithms have demonstrated the feasibility of underwater feature-based SLAM using imaging sonar. But previous methods have either relied on manual feature extraction and correspondence or used prior knowledge of the scene, such as the planar scene assumption. Our proposed system provides a general-purpose method for feature-point extraction and correspondence in arbitrary scenes. Additionally, we develop a method of identifying point landmarks that are likely to be well-constrained and reliably reconstructed. Finally, we demonstrate that while under-constrained landmarks cannot be accurately reconstructed themselves, they can still be used to constrain and correct the sensor motion. These advances represent a large step towards general-purpose, feature-based SLAM with imaging sonar.
ER  - 

TY  - CONF
TI  - SLAMBench2: Multi-Objective Head-to-Head Benchmarking for Visual SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3637
EP  - 3644
AU  - B. Bodin
AU  - H. Wagstaff
AU  - S. Saecdi
AU  - L. Nardi
AU  - E. Vespa
AU  - J. Mawer
AU  - A. Nisbet
AU  - M. Lujan
AU  - S. Furber
AU  - A. J. Davison
AU  - P. H. J. Kelly
AU  - M. F. P. O'Boyle
PY  - 2018
KW  - augmented reality
KW  - autonomous aerial vehicles
KW  - mobile computing
KW  - mobile robots
KW  - navigation
KW  - robot vision
KW  - SLAM (robots)
KW  - visual SLAM
KW  - augmented reality systems
KW  - nonfunctional requirements
KW  - mobile phone-based AR application
KW  - tight energy budget
KW  - UAV navigation system
KW  - SLAMBench2
KW  - benchmarking framework
KW  - open source
KW  - close source
KW  - performance metrics
KW  - ORB-SLAM2
KW  - publicly-available software framework
KW  - SLAM applications
KW  - SLAM systems
KW  - SLAM algorithms
KW  - multiobjective head-to-head benchmarking
KW  - functional requirements
KW  - Simultaneous localization and mapping
KW  - Measurement
KW  - Trajectory
KW  - Benchmark testing
KW  - User interfaces
KW  - C++ languages
DO  - 10.1109/ICRA.2018.8460558
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - SLAM is becoming a key component of robotics and augmented reality (AR) systems. While a large number of SLAM algorithms have been presented, there has been little effort to unify the interface of such algorithms, or to perform a holistic comparison of their capabilities. This is a problem since different SLAM applications can have different functional and non-functional requirements. For example, a mobile phone-based AR application has a tight energy budget, while a UAV navigation system usually requires high accuracy. SLAMBench2 is a benchmarking framework to evaluate existing and future SLAM systems, both open and close source, over an extensible list of datasets, while using a comparable and clearly specified list of performance metrics. A wide variety of existing SLAM algorithms and datasets is supported, e.g. ElasticFusion, InfiniTAM, ORB-SLAM2, OKVIS, and integrating new ones is straightforward and clearly specified by the framework. SLAMBench2 is a publicly-available software framework which represents a starting point for quantitative, comparable and val-idatable experimental research to investigate trade-offs across SLAM systems.
ER  - 

TY  - CONF
TI  - Don't Look Back: Robustifying Place Categorization for Viewpoint- and Condition-Invariant Place Recognition
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3645
EP  - 3652
AU  - S. Garg
AU  - N. Suenderhauf
AU  - M. Milford
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - image matching
KW  - image representation
KW  - image sequences
KW  - mobile robots
KW  - neural nets
KW  - object recognition
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - semantics-aware higher-order layers
KW  - deep neural networks
KW  - pure appearance-based techniques
KW  - place categorization
KW  - place-centric characteristics
KW  - condition-invariant place recognition
KW  - rear view mirror
KW  - semantic visual understanding
KW  - visual places
KW  - Semantics
KW  - Visualization
KW  - Robustness
KW  - Databases
KW  - Image recognition
KW  - Cameras
KW  - Neural networks
DO  - 10.1109/ICRA.2018.8461051
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When a human drives a car along a road for the first time, they later recognize where they are on the return journey typically without needing to look in their rear view mirror or turn around to look back, despite significant viewpoint and appearance change. Such navigation capabilities are typically attributed to our semantic visual understanding of the environment [1] beyond geometry to recognizing the types of places we are passing through such as “passing a shop on the left” or “moving through a forested area”. Humans are in effect using place categorization [2] to perform specific place recognition even when the viewpoint is 180 degrees reversed. Recent advances in deep neural networks have enabled high performance semantic understanding of visual places and scenes, opening up the possibility of emulating what humans do. In this work, we develop a novel methodology for using the semantics-aware higher-order layers of deep neural networks for recognizing specific places from within a reference database. To further improve the robustness to appearance change, we develop a descriptor normalization scheme that builds on the success of normalization schemes for pure appearance-based techniques such as SeqSLAM [3]. Using two different datasets - one road-based, one pedestrian-based, we evaluate the performance of the system in performing place recognition on reverse traversals of a route with a limited field of view camera and no turn-back-and-Iook behaviours, and compare to existing state-of-the-art techniques and vanilla off-the-shelf features. The results demonstrate significant improvements over the existing state of the art, especially for extreme perceptual challenges that involve both great viewpoint change and environmental appearance change. We also provide experimental analyses of the contributions of the various system components: the use of spatio-temporal sequences, place categorization and place-centric characteristics as opposed to object-centric semantics.
ER  - 

TY  - CONF
TI  - Delight: An Efficient Descriptor for Global Localisation Using LiDAR Intensities
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3653
EP  - 3660
AU  - K. P. Cop
AU  - P. V. K. Borges
AU  - R. Dubé
PY  - 2018
KW  - mobile robots
KW  - navigation
KW  - optical information processing
KW  - optical radar
KW  - path planning
KW  - robot vision
KW  - intensity information
KW  - DELIGHT
KW  - distributed histograms
KW  - chi-squared tests
KW  - two-stage solution
KW  - geometry-based verification
KW  - range information
KW  - GPS-denied areas
KW  - robot position
KW  - kidnapped robot problems
KW  - mobile robotics
KW  - place recognition
KW  - global localisation
KW  - intensity-based prior estimation
KW  - LiDAR intensities
KW  - Laser radar
KW  - Histograms
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8460940
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Place recognition is a key element of mobile robotics. It can assist with the “wake-up” and “kidnapped robot” problems, where the robot position needs to be estimated without prior information. Among the different sensors that can be used for the task (e.g., camera, GPS, LiDAR), LiDAR has the advantage of operating in the dark and in GPS-denied areas. We propose a new method that uses solely the LiDAR data and that can be performed without robot motion. In contrast to other methods, our system leverages intensity information (as opposed to only range information) which is encoded into a novel descriptor of LiDAR intensities as a group of histograms, named DELIGHT. The descriptor encodes the distributed histograms of intensity of the surroundings which are compared using chi-squared tests. Our pipeline is a two-stage solution consisting of an intensity-based prior estimation and a geometry-based verification. For a map of 220k square meters, the method achieves localisation in around 3s with a success rate of 97%, illustrating the applicability of the method in real environments.
ER  - 

TY  - CONF
TI  - Online Probabilistic Change Detection in Feature-Based Maps
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3661
EP  - 3668
AU  - F. Nobre
AU  - C. Heckman
AU  - P. Ozog
AU  - R. W. Wolcott
AU  - J. M. Walls
PY  - 2018
KW  - compressed sensing
KW  - feature extraction
KW  - image representation
KW  - object detection
KW  - probability
KW  - sensor fusion
KW  - terrain mapping
KW  - online data association decisions
KW  - online probabilistic change detection
KW  - sparse feature-based maps
KW  - compact representation
KW  - static map features
KW  - feature repeatability
KW  - probabilistically principled approach
KW  - sparse mapping model
KW  - Feature extraction
KW  - Simultaneous localization and mapping
KW  - Robustness
KW  - Heuristic algorithms
KW  - Probabilistic logic
KW  - Visualization
DO  - 10.1109/ICRA.2018.8461111
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Sparse feature-based maps provide a compact representation of the environment that admit efficient algorithms, for example simultaneous localization and mapping. These representations typically assume a static world and therefore contain static map features. However, since the world contains dynamic elements, determining when map features no longer correspond to the environment is essential for long-term utility. This work develops a feature-based model of the environment which evolves over time through feature persistence. Moreover, we augment the state-of-the-art sparse mapping model with a correlative structure that captures spatio-temporal properties, e.g. that nearby features frequently have similar persistence. We show that such relationships, typically addressed through an ad hoc formalism focusing only on feature repeatability, are crucial to evaluate through a probabilistically principled approach. The joint posterior over feature persistence can be computed efficiently and used to improve online data association decisions for localization. The proposed algorithms are validated in numerical simulation and using publicly available data sets.
ER  - 

TY  - CONF
TI  - The Dynamic Bearing Observability Matrix Nonlinear Observability and Estimation for Multi-Agent Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3669
EP  - 3676
AU  - F. Schiano
AU  - R. Tron
PY  - 2018
KW  - geometry
KW  - group theory
KW  - Kalman filters
KW  - Lie groups
KW  - matrix algebra
KW  - multi-agent systems
KW  - multi-robot systems
KW  - nonlinear filters
KW  - multiagent formations
KW  - dynamic agents
KW  - algebraic properties
KW  - first-order derivatives
KW  - nonlinear observability theory
KW  - higher order derivatives
KW  - localization problem
KW  - dynamic bearing observability matrix nonlinear observability
KW  - multiagent systems
KW  - rigidity matrix
KW  - Observability
KW  - Robot sensing systems
KW  - Geometry
KW  - Manifolds
KW  - Cameras
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460792
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the problem of localization in multiagent formations with bearing only measurements, and analyze the fundamental observability properties for dynamic agents. The current well-established approach is based on the socalled rigidity matrix, and its algebraic properties (e.g., its rank and nullspace). This method is typically motivated using first-order derivatives, and shows, among other facts, that the global scale of the formation is not observable. This work shows that current results represent an incomplete view of the problem. In particular, we show that 1) current methods are a particular instantiation of nonlinear observability theory, 2) we can introduce the concept of the dynamic bearing observability matrix from higher order derivatives to study the observability of dynamic formations, and 3) the global scale is, in fact, generally observable when the agents move according to known inputs. We use tools from Riemannian geometry and Lie group theory to tackle, in a general and principled way, the general formulation of the localization problem with states that include both rotations and translations. Finally, we verify our theoretical results by deriving and applying, in both simulations and real experiments on UAVs, a centralized Extended Kalman Filter on Lie groups that is able to estimate the global scale of a moving formation.
ER  - 

TY  - CONF
TI  - CDDT: Fast Approximate 2D Ray Casting for Accelerated Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3677
EP  - 3684
AU  - C. H. Walsh
AU  - S. Karaman
PY  - 2018
KW  - data structures
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - ray tracing
KW  - table lookup
KW  - constant time ray casting performance
KW  - particle filter algorithm
KW  - resource-constrained mobile robots
KW  - localization approach
KW  - approximate 2D ray casting
KW  - mobile robot
KW  - compressed directional distance transform
KW  - two dimensional occupancy grid maps
KW  - autonomous robots
KW  - three dimensional lookup table
KW  - frequency 40.0 Hz
KW  - Casting
KW  - Table lookup
KW  - Robot sensing systems
KW  - Transforms
KW  - Approximation algorithms
KW  - Memory management
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8460743
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Localization is an essential component for autonomous robots. A well-established localization approach combines ray casting with a particle filter, leading to a computationally expensive algorithm that is difficult to run on resource-constrained mobile robots. We present a novel data structure called the Compressed Directional Distance Transform for accelerating ray casting in two dimensional occupancy grid maps. Our approach allows online map updates, and near constant time ray casting performance for a fixed size map, in contrast with other methods exhibit poor worst case performance. Our experimental results show that the proposed algorithm approximates the performance characteristics of reading from a three dimensional lookup table of ray cast solutions while requiring two orders of magnitude less memory and precomputation. This results in a particle filter algorithm which can maintain 2500 particles with 61 ray casts per particle at 40Hz, using a single CPU thread onboard a mobile robot.
ER  - 

TY  - CONF
TI  - Towards Globally Consistent Visual-Inertial Collaborative SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3685
EP  - 3692
AU  - M. Karrer
AU  - M. Chli
PY  - 2018
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - globally consistent tracking
KW  - autonomous robot navigation
KW  - monocular-inertial odometry
KW  - vision-based perception
KW  - metric scale estimation
KW  - benchmarking datasets
KW  - UAVs
KW  - monocular-inertial sensor suite
KW  - unmanned aerial vehicles
KW  - visual-inertial collaborative SLAM
KW  - drift correction
KW  - Simultaneous localization and mapping
KW  - Collaboration
KW  - Unmanned aerial vehicles
KW  - Optimization
KW  - Measurement
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8461213
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Motivated by the need for globally consistent tracking and mapping before autonomous robot navigation becomes realistically feasible, this paper presents a novel backend to monocular-inertial odometry. As some of the most challenging platforms for vision-based perception, we evaluate the performance of our system using Unmanned Aerial Vehicles (UAV s). Our experimental validation demonstrates that the proposed approach achieves drift correction and metric scale estimation from a single UAV on benchmarking datasets. Furthermore, the generality of our approach is demonstrated to achieve globally consistent maps built in a collaborative manner from two UAVs, each equipped with a monocular-inertial sensor suite, showing the possible gains opened by collaboration amongst robots to perform SLAM. Video - https://youtu.be/wbX36HBu2Eg.
ER  - 

TY  - CONF
TI  - Modelling Resource Contention in Multi-Robot Task Allocation Problems with Uncertain Timing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3693
EP  - 3700
AU  - A. W. Palmer
AU  - A. J. Hill
AU  - S. J. Scheding
PY  - 2018
KW  - approximation theory
KW  - Monte Carlo methods
KW  - multi-robot systems
KW  - normal distribution
KW  - optimisation
KW  - probability
KW  - independent normally distributed random events
KW  - conditional probability distributions
KW  - multirobot task allocation problems
KW  - deterministic method
KW  - optimisation method
KW  - travel times
KW  - task durations
KW  - approximation methods
KW  - resource contention modelling
KW  - Robots
KW  - Task analysis
KW  - Uncertainty
KW  - Probability distribution
KW  - Random variables
KW  - Resource management
DO  - 10.1109/ICRA.2018.8460981
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes an analytical framework for modelling resource contention in multi-robot systems, where the travel times and task durations are uncertain. It uses several approximation methods to quickly and accurately calculate the probability distributions describing the times at which the tasks start and finish. Specific contributions include exact and fast approximation methods for calculating the probability of a set of independent normally distributed random events occurring in a given order, a method for calculating the most likely and n-th most likely orders of occurrence for a set of independent normally distributed random events that have equal standard deviations, and a method for approximating the conditional probability distributions of the events given a specific order of the events. The complete framework is shown to be faster than a Monte Carlo approach for the same accuracy in two multi-robot task allocation problems. In addition, the importance of incorporating uncertainty is demonstrated through a comparison with a deterministic method. This is a general framework that is agnostic to the optimisation method and objective function used, and is applicable to a wide range of problems.
ER  - 

TY  - CONF
TI  - Constrained-Action POMDPs for Multi-Agent Intelligent Knowledge Distribution
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3701
EP  - 3708
AU  - M. Fowler
AU  - P. Tokekar
AU  - T. Charles Clancy
AU  - R. K. Williams
PY  - 2018
KW  - decision theory
KW  - intelligent control
KW  - Markov processes
KW  - Monte Carlo methods
KW  - multi-agent systems
KW  - multi-robot systems
KW  - optimal control
KW  - optimisation
KW  - multiagent intelligent knowledge distribution
KW  - infinite-horizon policy
KW  - minimal constraint guarantees
KW  - constraint analysis
KW  - information content
KW  - Markov chain Monte Carlo analysis
KW  - probabilistic constraint satisfaction
KW  - partially observable Markov decision processes
KW  - action-based constraints
KW  - multiagent coordination
KW  - multiagent systems
KW  - communication requirements
KW  - constrained-action POMDPs
KW  - Markov processes
KW  - Collaboration
KW  - Monte Carlo methods
KW  - Bandwidth
KW  - Proposals
KW  - Entropy
KW  - Power capacitors
DO  - 10.1109/ICRA.2018.8461118
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper addresses a fundamental question of multi-agent knowledge distribution: what information should be sent to whom and when, with the limited resources available to each agent? Intelligent Knowledge Distribution is a framework that answers these questions. Communication requirements for multi-agent systems can be rather high when an accurate picture of the environment and the state of other agents must be maintained. To reduce the impact of multi-agent coordination on systems, including communications, this paper introduces the concept of action-based constraints on partially observable Markov decision processes, rewards based upon the value of information driven by Kullback-Leibler Divergence, and probabilistic constraint satisfaction through discrete optimization and Markov chain Monte Carlo analysis. Intelligent Knowledge Distribution is driven by determining the information content an agent believes another agent will obtain by receiving certain information, along with the importance or relevance of that information to the system objective. To perform constraint analysis on an infinite-horizon policy, policies are represented as a Finite State Controller allowing Markov chain Monte Carlo analysis to determine a probabilistic level of guarantee that the constraints will be satisfied. The analysis of performance for an example mission presented in this paper shows the constrained controllers, during the highest constraint seen in simulations, can be constructed to meet minimal constraint guarantees (80%) while impacting the optimal value less than 50%, where the unconstrained optimal controller only satisfied the constraint 10% of the time.
ER  - 

TY  - CONF
TI  - Incorporating Potential Contingency Tasks in Multi-Robot Mission Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3709
EP  - 3715
AU  - S. Shriyam
AU  - S. K. Gupta
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - probability
KW  - potential contingency task
KW  - multirobot mission planning
KW  - expected mission completion time
KW  - probability
KW  - Task analysis
KW  - Robot kinematics
KW  - Uncertainty
KW  - Schedules
KW  - Marine vehicles
KW  - Resource management
DO  - 10.1109/ICRA.2018.8460659
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In most complex missions, unexpected situations arise that may interfere with the planned execution of mission tasks. These situations result in the generation of contingency tasks that need to be executed before the originally planned tasks are completed. Potential contingency tasks may not always affect mission tasks due to the inherent uncertainty in the environment. Deferring action on a potential contingency task may incur a penalty in terms of wasted time due to idle robots if the contingency task becomes a bottleneck in the future. On the other hand, immediate action on a potential contingency task may incur a penalty in terms of wasted time if the contingency task did not actually impact the mission. When a contingency task is reported, the planner generates an updated plan that minimizes expected mission completion time by taking into account the probability of the contingency task impacting mission tasks, its effect on the mission, and its spatial location. We have characterized the performance of the algorithm through simulation experiments. We show that the proactive approach to contingency task management outperforms a conservative approach.
ER  - 

TY  - CONF
TI  - Distributed Simultaneous Action and Target Assignment for Multi-Robot Multi-Target Tracking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3724
EP  - 3729
AU  - Y. Sung
AU  - A. K. Budhiraja
AU  - R. K. Williams
AU  - P. Tokekar
PY  - 2018
KW  - computational complexity
KW  - distributed control
KW  - multi-robot systems
KW  - target tracking
KW  - O(hlog1/ε) communication rounds
KW  - distributed simultaneous action
KW  - multirobot multitarget tracking
KW  - multirobot assignment problems
KW  - Robot sensing systems
KW  - Target tracking
KW  - Approximation algorithms
KW  - Partitioning algorithms
DO  - 10.1109/ICRA.2018.8460974
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We study two multi-robot assignment problems for multi-target tracking. We consider distributed approaches in order to deal with limited sensing and communication ranges. We seek to simultaneously assign trajectories and targets to the robots. Our focus is on local algorithms that achieve performance close to the optimal algorithms with limited communication. We show how to use a local algorithm that guarantees a bounded approximate solution within O(hlog1/ε) communication rounds. We compare with a greedy approach that achieves a 2-approximation in as many rounds as the number of robots. Simulation results show that the local algorithm is an effective solution to the assignment problem.
ER  - 

TY  - CONF
TI  - How to Make Fat Autonomous Robots See all Others Fast?
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3730
EP  - 3735
AU  - G. Sharma
AU  - C. Busch
AU  - S. Mukhopadhyay
PY  - 2018
KW  - collision avoidance
KW  - computational complexity
KW  - deterministic algorithms
KW  - distributed algorithms
KW  - mobile robots
KW  - multi-robot systems
KW  - scheduling
KW  - fat autonomous robots
KW  - coordination problems
KW  - autonomous mobile robots
KW  - distributed robotics community
KW  - convex hull
KW  - nontransparent fat robots
KW  - deterministic distributed algorithm
KW  - semisynchronous scheduler
KW  - Robot kinematics
KW  - Fats
KW  - Cogeneration
KW  - Collision avoidance
KW  - Runtime
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460899
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The coordination problems arising in a team of autonomous mobile robots have received a lot of attention in the distributed robotics community. Along those lines, we study in this paper the problem of coordinating autonomous mobile robots to reposition on a convex hull so that each robot sees all others. In particular, we consider non-transparent fat robots operating in the 2-dimensional plane. They are abstracted as unit discs and they make local decisions with vision being the only mean of coordination among them. We develop a (deterministic) distributed algorithm that solves the problem for a team of N ≥ 3 fat robots in O(N) time avoiding collisions under the semi-synchronous scheduler. The main idea is to enforce the robots to reach a configuration in which (i) the robots' centers form a convex hull; (ii) all robots are on the convex hull's boundary; and (iii) each robot can see all other robots. The result is achieved assuming some reasonable conditions on the input configuration and showing that starting from any input configuration that satisfies our conditions, robots reach such a configuration in linear time and terminate.
ER  - 


TY  - CONF
TI  - A Synchronization Scheme for Position Control of Multiple Rope-Climbing Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3736
EP  - 3741
AU  - G. Sun
AU  - X. Li
AU  - P. Li
AU  - Y. Meng
AU  - Y. Zhou
AU  - E. Xu
AU  - Y. Liu
PY  - 2018
KW  - actuators
KW  - asymptotic stability
KW  - manipulators
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - robot dynamics
KW  - singularly perturbed systems
KW  - single rope-climbing robot
KW  - multiple rope-climbing robots
KW  - position control
KW  - Robot kinematics
KW  - Synchronization
KW  - Task analysis
KW  - Actuators
KW  - Mathematical model
KW  - Position control
KW  - multiple Rope-Climbing Robots
KW  - climbing robots
KW  - motion control
DO  - 10.1109/ICRA.2018.8460484
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The ability of rope-climbing robots in aloft operation is limited by its self-supporting and locomotion ability. In many applications, a given task is also too complex to be achieved by a single rope-climbing robot acting alone. The solution of multiple rope-climbing robots can overcome the limitations. However, existing control methods for rope-climbing robots are limited to single robot, and the open issue of coordination between multiple rope-climbing robots has not been systematically addressed. This paper presents a new synchronization scheme for position control of multiple rope-climbing robots, such that each robot moves to the corresponding desired position while synchronizing the heights between each other. Maintaining the same height is very important to guarantee the stability of the task-oriented manipulator installed among multiple robots, when it is performing the manipulation task. The development of the proposed controller is based on the singular perturbation approach, by treating the fast actuator dynamics as a perturbation of the slow robot dynamics, such that the lowest control complexity is achieved. The exponential stability of the overall system that consists of the fast and slow subsystems is proved by using Tikhonov' s theorem. Experimental results are presented to illustrate the performance of the proposed controller.
ER  - 

TY  - CONF
TI  - Robotic Pick-and-Place of Novel Objects in Clutter with Multi-Affordance Grasping and Cross-Domain Image Matching
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3750
EP  - 3757
AU  - A. Zeng
AU  - S. Song
AU  - K. Yu
AU  - E. Donlon
AU  - F. R. Hogan
AU  - M. Bauza
AU  - D. Ma
AU  - O. Taylor
AU  - M. Liu
AU  - E. Romo
AU  - N. Fazeli
AU  - F. Alet
AU  - N. C. Dafle
AU  - R. Holladay
AU  - I. Morena
AU  - P. Qu Nair
AU  - D. Green
AU  - I. Taylor
AU  - W. Liu
AU  - T. Funkhouser
AU  - A. Rodriguez
PY  - 2018
KW  - grippers
KW  - image classification
KW  - image matching
KW  - object recognition
KW  - robot vision
KW  - robotic pick-and-place
KW  - image classification framework
KW  - 2017 Amazon Robotics Challenge
KW  - MIT-Princeton Team system
KW  - category-agnostic affordance prediction algorithm
KW  - cross-domain image matching
KW  - Grasping
KW  - Robots
KW  - Clutter
KW  - Grippers
KW  - Robustness
KW  - Proposals
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461044
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a robotic pick-and-place system that is capable of grasping and recognizing both known and novel objects in cluttered environments. The key new feature of the system is that it handles a wide range of object categories without needing any task-specific training data for novel objects. To achieve this, it first uses a category-agnostic affordance prediction algorithm to select and execute among four different grasping primitive behaviors. It then recognizes picked objects with a cross-domain image classification framework that matches observed images to product images. Since product images are readily available for a wide range of objects (e.g., from the web), the system works out-of-the-box for novel objects without requiring any additional training data. Exhaustive experimental results demonstrate that our multi-affordance grasping achieves high success rates for a wide variety of objects in clutter, and our recognition algorithm achieves high accuracy for both known and novel grasped objects. The approach was part of the MIT-Princeton Team system that took 1st place in the stowing task at the 2017 Amazon Robotics Challenge. All code, datasets, and pre-trained models are available online at http://arc.cs.princeton.edu.
ER  - 

TY  - CONF
TI  - Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-to-End Learning from Demonstration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3758
EP  - 3765
AU  - R. Rahmatizadeh
AU  - P. Abolghasemi
AU  - L. Bölöni
AU  - S. Levine
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - recurrent neural nets
KW  - robot vision
KW  - nonprehensile manipulation
KW  - recurrent neural network
KW  - raw images
KW  - VAE-GAN-based reconstruction
KW  - autoregressive multimodal action prediction
KW  - complex manipulation tasks
KW  - towel
KW  - weight
KW  - reconstruction-based regularization
KW  - vision-based multitask manipulation
KW  - end-to-end learning
KW  - multitask learning
KW  - low-cost robotic arm
KW  - robot arm trajectories
KW  - complex picking and placing tasks
KW  - Task analysis
KW  - Robots
KW  - Feature extraction
KW  - Neural networks
KW  - Image reconstruction
KW  - Training
KW  - Visualization
DO  - 10.1109/ICRA.2018.8461076
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a technique for multi-task learning from demonstration that trains the controller of a low-cost robotic arm to accomplish several complex picking and placing tasks, as well as non-prehensile manipulation. The controller is a recurrent neural network using raw images as input and generating robot arm trajectories, with the parameters shared across the tasks. The controller also combines VAE-GAN-based reconstruction with autoregressive multimodal action prediction. Our results demonstrate that it is possible to learn complex manipulation tasks, such as picking up a towel, wiping an object, and depositing the towel to its previous position, entirely from raw images with direct behavior cloning. We show that weight sharing and reconstruction-based regularization substantially improve generalization and robustness, and training on multiple tasks simultaneously increases the success rate on all tasks.
ER  - 

TY  - CONF
TI  - Learning 6-DOF Grasping Interaction via Deep Geometry-Aware 3D Representations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3766
EP  - 3773
AU  - X. Yan
AU  - J. Hsu
AU  - M. Khansari
AU  - Y. Bai
AU  - A. Pathak
AU  - A. Gupta
AU  - J. Davidson
AU  - H. Lee
PY  - 2018
KW  - convolution
KW  - dexterous manipulators
KW  - geometry
KW  - grippers
KW  - image reconstruction
KW  - image representation
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - recurrent neural nets
KW  - virtual reality
KW  - outcome prediction model
KW  - 3D shape modeling
KW  - DGGN
KW  - analysis-by-synthesis optimization
KW  - 6-DOF grasping net
KW  - virtual reality
KW  - sensory annotations
KW  - data augmentation strategy
KW  - CNN
KW  - 3D occupancy grid
KW  - mental geometry-aware representation
KW  - deep geometry-aware grasping network
KW  - 3D geometry prediction
KW  - grasping interaction learning
KW  - parallel jaw gripper
KW  - RGBD input
KW  - internal geometry-aware representation
KW  - Grasping
KW  - Three-dimensional displays
KW  - Shape
KW  - Geometry
KW  - Solid modeling
KW  - Two dimensional displays
KW  - Robots
DO  - 10.1109/ICRA.2018.8460609
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper focuses on the problem of learning 6- DOF grasping with a parallel jaw gripper in simulation. Our key idea is constraining and regularizing grasping interaction learning through 3D geometry prediction. We introduce a deep geometry-aware grasping network (DGGN) that decomposes the learning into two steps. First, we learn to build mental geometry-aware representation by reconstructing the scene (i.e., 3D occupancy grid) from RGBD input via generative 3D shape modeling. Second, we learn to predict grasping outcome with its internal geometry-aware representation. The learned outcome prediction model is used to sequentially propose grasping solutions via analysis-by-synthesis optimization. Our contributions are fourfold: (1) To best of our knowledge, we are presenting for the first time a method to learn a 6-DOF grasping net from RGBD input; (2) We build a grasping dataset from demonstrations in virtual reality with rich sensory and interaction annotations. This dataset includes 101 everyday objects spread across 7 categories, additionally, we propose a data augmentation strategy for effective learning; (3) We demonstrate that the learned geometry-aware representation leads to about 10% relative performance improvement over the baseline CNN on grasping objects from our dataset. (4) We further demonstrate that the model generalizes to novel viewpoints and object instances.
ER  - 

TY  - CONF
TI  - Interactively Picking Real-World Objects with Unconstrained Spoken Language Instructions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3774
EP  - 3781
AU  - J. Hatori
AU  - Y. Kikuchi
AU  - S. Kobayashi
AU  - K. Takahashi
AU  - Y. Tsuboi
AU  - Y. Unno
AU  - W. Ko
AU  - J. Tan
PY  - 2018
KW  - industrial robots
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - natural language interfaces
KW  - natural language processing
KW  - object detection
KW  - robot vision
KW  - natural language processing technologies
KW  - unconstrained spoken instructions
KW  - instruction ambiguity
KW  - physical industrial robot arm
KW  - natural instructions
KW  - object picking task
KW  - real-world objects
KW  - unconstrained spoken language instructions
KW  - spoken natural language
KW  - human instructions
KW  - comprehensive system
KW  - Task analysis
KW  - Object recognition
KW  - Natural languages
KW  - Object detection
KW  - Feature extraction
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460699
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Comprehension of spoken natural language is an essential skill for robots to communicate with humans effectively. However, handling unconstrained spoken instructions is challenging due to (1) complex structures and the wide variety of expressions used in spoken language, and (2) inherent ambiguity of human instructions. In this paper, we propose the first comprehensive system for controlling robots with unconstrained spoken language, which is able to effectively resolve ambiguity in spoken instructions. Specifically, we integrate deep learning-based object detection together with natural language processing technologies to handle unconstrained spoken instructions, and propose a method for robots to resolve instruction ambiguity through dialogue. Through our experiments on both a simulated environment as well as a physical industrial robot arm, we demonstrate the ability of our system to understand natural instructions from human operators effectively, and show how higher success rates of the object picking task can be achieved through an interactive clarification process.
ER  - 

TY  - CONF
TI  - Translating Videos to Commands for Robotic Manipulation with Deep Recurrent Neural Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3782
EP  - 3788
AU  - A. Nguyen
AU  - D. Kanoulas
AU  - L. Muratore
AU  - D. G. Caldwell
AU  - N. G. Tsagarakis
PY  - 2018
KW  - control engineering computing
KW  - convolution
KW  - feature extraction
KW  - feedforward neural nets
KW  - humanoid robots
KW  - mobile robots
KW  - recurrent neural nets
KW  - video signal processing
KW  - feature extraction
KW  - video translation
KW  - CNN
KW  - RNN
KW  - full-size humanoid robot WALK-MAN
KW  - manipulation tasks
KW  - translation module
KW  - visual features
KW  - encoder-decoder architecture
KW  - RNN layers
KW  - deep Convolutional Neural Networks
KW  - input video frames
KW  - deep features
KW  - command
KW  - Deep Recurrent Neural Networks
KW  - robotic manipulation
KW  - Videos
KW  - Robots
KW  - Feature extraction
KW  - Task analysis
KW  - Visualization
KW  - Recurrent neural networks
KW  - Logic gates
DO  - 10.1109/ICRA.2018.8460857
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a new method to translate videos to commands for robotic manipulation using Deep Recurrent Neural Networks (RNN). Our framework first extracts deep features from the input video frames with a deep Convolutional Neural Networks (CNN). Two RNN layers with an encoder-decoder architecture are then used to encode the visual features and sequentially generate the output words as the command. We demonstrate that the translation accuracy can be improved by allowing a smooth transaction between two RNN layers and using the state-of-the-art feature extractor. The experimental results on our new challenging dataset show that our approach outperforms recent methods by a fair margin. Furthermore, we combine the proposed translation module with the vision and planning system to let a robot perform various manipulation tasks. Finally, we demonstrate the effectiveness of our framework on a full-size humanoid robot WALK-MAN.
ER  - 

TY  - CONF
TI  - Distributed Learning for the Decentralized Control of Articulated Mobile Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3789
EP  - 3794
AU  - G. Sartoretti
AU  - Y. Shi
AU  - W. Paivine
AU  - M. Travers
AU  - H. Choset
PY  - 2018
KW  - decentralised control
KW  - distributed control
KW  - learning systems
KW  - mobile robots
KW  - multi-agent systems
KW  - highly cluttered evaluation environments
KW  - decentralized control architectures
KW  - central pattern generators
KW  - spatially distributed portions
KW  - articulated bodies
KW  - system-level objectives
KW  - reinforcement learning
KW  - independent agents
KW  - parallel environments
KW  - meta-level agent
KW  - homogeneous decentralized control
KW  - articulated locomotion
KW  - distributed learning
KW  - asynchronous advantage actor-critic algorithm
KW  - A3C
KW  - decentralized control policies
KW  - independently controlled portion
KW  - autonomous decentralized compliant control framework
KW  - compliant control baseline
KW  - articulated mobile robots
KW  - Shape
KW  - Decentralized control
KW  - Aerospace electronics
KW  - Robot kinematics
KW  - Admittance
KW  - Hardware
DO  - 10.1109/ICRA.2018.8460802
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Decentralized control architectures, such as those conventionally defined by central pattern generators, independently coordinate spatially distributed portions of articulated bodies to achieve system-level objectives. State of the art distributed algorithms for reinforcement learning employ a different but conceptually related idea; independent agents simultaneously coordinating their own behaviors in parallel environments while asynchronously updating the policy of a system-or, rather, meta-level agent. This work, to the best of the authors' knowledge, is the first to explicitly explore the potential relationship between the underlying concepts in homogeneous decentralized control for articulated locomotion and distributed learning. We present an approach that leverages the structure of the asynchronous advantage actor-critic (A3C) algorithm to provide a natural framework for learning decentralized control policies on a single platform. Our primary contribution shows an individual agent in the A3C algorithm can be defined by an independently controlled portion of the robot's body, thus enabling distributed learning on a single platform for efficient hardware implementation. To this end, we show how the system is trained offline using hardware experiments implementing an autonomous decentralized compliant control framework. Our experimental results show that the trained agent outperforms the compliant control baseline by more than 40% in terms of steady progression through a series of randomized, highly cluttered evaluation environments.
ER  - 

TY  - CONF
TI  - Neural Task Programming: Learning to Generalize Across Hierarchical Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3795
EP  - 3802
AU  - D. Xu
AU  - S. Nair
AU  - Y. Zhu
AU  - J. Gao
AU  - A. Garg
AU  - L. Fei-Fei
AU  - S. Savarese
PY  - 2018
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - neural task programming
KW  - unseen tasks
KW  - sequential tasks
KW  - robot manipulation tasks
KW  - bottom-level programs
KW  - hierarchical neural program
KW  - finer sub-task specifications
KW  - task specification
KW  - neural program induction
KW  - few-shot learning
KW  - NTP
KW  - novel robot learning framework
KW  - hierarchical tasks
KW  - Task analysis
KW  - Programming
KW  - Robots
KW  - Sorting
KW  - Semantics
KW  - Topology
KW  - Data models
DO  - 10.1109/ICRA.2018.8460689
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we propose a novel robot learning framework called Neural Task Programming (NTP), which bridges the idea of few-shot learning from demonstration and neural program induction. NTP takes as input a task specification (e.g., video demonstration of a task) and recursively decomposes it into finer sub-task specifications. These specifications are fed to a hierarchical neural program, where bottom-level programs are callable subroutines that interact with the environment. We validate our method in three robot manipulation tasks. NTP achieves strong generalization across sequential tasks that exhibit hierarchal and compositional structures. The experimental results show that NTP learns to generalize well towards unseen tasks with increasing lengths, variable topologies, and changing objectives.stanfordvl.github.io/ntp/.
ER  - 

TY  - CONF
TI  - Sim-to-Real Transfer of Robotic Control with Dynamics Randomization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3803
EP  - 3810
AU  - X. B. Peng
AU  - M. Andrychowicz
AU  - W. Zaremba
AU  - P. Abbeel
PY  - 2018
KW  - calibration
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - robot dynamics
KW  - sim-to-real transfer
KW  - robotic control
KW  - dynamics randomization
KW  - training agents
KW  - training process
KW  - robotic arm
KW  - calibration error
KW  - Robots
KW  - Training
KW  - Adaptation models
KW  - Task analysis
KW  - Trajectory
KW  - Data models
KW  - Robustness
DO  - 10.1109/ICRA.2018.8460528
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Simulations are attractive environments for training agents as they provide an abundant source of data and alleviate certain safety concerns during the training process. But the behaviours developed by agents in simulation are often specific to the characteristics of the simulator. Due to modeling error, strategies that are successful in simulation may not transfer to their real world counterparts. In this paper, we demonstrate a simple method to bridge this “reality gap”. By randomizing the dynamics of the simulator during training, we are able to develop policies that are capable of adapting to very different dynamics, including ones that differ significantly from the dynamics on which the policies were trained. This adaptivity enables the policies to generalize to the dynamics of the real world without any training on the physical system. Our approach is demonstrated on an object pushing task using a robotic arm. Despite being trained exclusively in simulation, our policies are able to maintain a similar level of performance when deployed on a real robot, reliably moving an object to a desired location from random initial configurations. We explore the impact of various design decisions and show that the resulting policies are robust to significant calibration error.
ER  - 

TY  - CONF
TI  - Topomap: Topological Mapping and Navigation Based on Visual SLAM Maps
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3818
EP  - 3825
AU  - F. Blochliger
AU  - M. Fehr
AU  - M. Dymczyk
AU  - T. Schneider
AU  - R. Siegwart
PY  - 2018
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - three-dimensional topological map
KW  - noisy sparse point cloud
KW  - convex free-space clusters
KW  - global planning
KW  - mobile robotic platform
KW  - Topomap
KW  - visual SLAM
KW  - visual robot navigation
KW  - navigation task
KW  - sparse feature-based map
KW  - path planning algorithms
KW  - visual simultaneous localization and mapping system
KW  - Navigation
KW  - Visualization
KW  - Simultaneous localization and mapping
KW  - Path planning
KW  - Three-dimensional displays
KW  - Planning
DO  - 10.1109/ICRA.2018.8460641
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Visual robot navigation within large-scale, semistructured environments deals with various challenges such as computation intensive path planning algorithms or insufficient knowledge about traversable spaces. Moreover, many state-of-the-art navigation approaches only operate locally instead of gaining a more conceptual understanding of the planning objective. This limits the complexity of tasks a robot can accomplish and makes it harder to deal with uncertainties that are present in the context of real-time robotics applications. In this work, we present Topomap, a framework which simplifies the navigation task by providing a map to the robot which is tailored for path planning use. This novel approach transforms a sparse feature-based map from a visual Simultaneous Localization And Mapping (SLAM) system into a three-dimensional topological map. This is done in two steps. First, we extract occupancy information directly from the noisy sparse point cloud. Then, we create a set of convex free-space clusters, which are the vertices of the topological map. We show that this representation improves the efficiency of global planning, and we provide a complete derivation of our algorithm. Planning experiments on real world datasets demonstrate that we achieve similar performance as RRT* with significantly lower computation times and storage requirements. Finally, we test our algorithm on a mobile robotic platform to prove its advantages.
ER  - 

TY  - CONF
TI  - PIRVS: An Advanced Visual-Inertial SLAM System with Flexible Sensor Fusion and Hardware Co-Design
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3826
EP  - 3832
AU  - Z. Zhang
AU  - S. Liu
AU  - G. Tsai
AU  - H. Hu
AU  - C. Chu
AU  - F. Zheng
PY  - 2018
KW  - cameras
KW  - image fusion
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - synchronisation
KW  - embedded simultaneous localization and mapping algorithm
KW  - multi-core processor
KW  - public visual-inertial datasets
KW  - PerceptIn Robotics Vision System
KW  - Hardware Co-Design
KW  - advanced visual-inertial SLAM System
KW  - state-of-the-art visual-inertial algorithms
KW  - additional sensor modalities
KW  - inertial measurements
KW  - visual measurements
KW  - flexible sensor fusion approach
KW  - PIRVS software features
KW  - precise hardware synchronization
KW  - global-shutter stereo camera
KW  - PIRVS hardware
KW  - visual-inertial computing hardware
KW  - Simultaneous localization and mapping
KW  - Hardware
KW  - Cameras
KW  - Feature extraction
KW  - Synchronization
KW  - Visualization
DO  - 10.1109/ICRA.2018.8460672
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present the PerceptIn Robotics Vision System (PIRVS), a visual-inertial computing hardware with embedded simultaneous localization and mapping (SLAM) algorithm. The PIRVS hardware is equipped with a multi-core processor, a global-shutter stereo camera, and an IMU with precise hardware synchronization. The PIRVS software features a flexible sensor fusion approach to not only tightly integrate visual measurements with inertial measurements and also to loosely couple with additional sensor modalities. It runs in real-time on both PC and the PIRVS hardware. We perform a thorough evaluation of the proposed system using multiple public visual-inertial datasets. Experimental results demonstrate that our system reaches comparable accuracy of state-of-the-art visual-inertial algorithms on PC, while being more efficient on the PIRVS hardware.
ER  - 

TY  - CONF
TI  - ProSLAM: Graph SLAM from a Programmer's Perspective
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3833
EP  - 3840
AU  - D. Schlegel
AU  - M. Colosi
AU  - G. Grisetti
PY  - 2018
KW  - C++ language
KW  - data structures
KW  - graph theory
KW  - public domain software
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - Graph SLAM
KW  - data structures
KW  - C++ programming language
KW  - standard libraries
KW  - lightweight open-source stereo visual SLAM system
KW  - programmer
KW  - ProSLAM
KW  - algorithmic aspects
KW  - mathematical aspects
KW  - highly modular system
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Three-dimensional displays
KW  - Cameras
KW  - Data structures
KW  - Benchmark testing
DO  - 10.1109/ICRA.2018.8461180
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present ProSLAM, a lightweight open-source stereo visual SLAM system designed with simplicity in mind. This work stems from the experience gathered by the authors while teaching SLAM and aims at providing a highly modular system that can be easily implemented and understood. Rather than focusing on the well known mathematical aspects of stereo visual SLAM, we highlight the data structures and the algorithmic aspects required to realize such a system. We implemented ProSLAM using the C++ programming language in combination with a minimal set of standard libraries. The results of a thorough validation performed on several standard benchmark datasets show that ProSLAM achieves precision comparable to state-of-the-art approaches, while requiring substantially less computation.
ER  - 

TY  - CONF
TI  - Talk Resource-Efficiently to Me: Optimal Communication Planning for Distributed Loop Closure Detection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3841
EP  - 3848
AU  - M. Giamou
AU  - K. Khosoussi
AU  - J. P. How
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - SLAM (robots)
KW  - cooperative simultaneous localization and mapping
KW  - inter-robot loop closures
KW  - general resource-efficiency communication planning
KW  - sensory data sharing
KW  - distributed loop closure detection
KW  - optimal communication planning
KW  - CSLAM
KW  - Robot sensing systems
KW  - Distributed databases
KW  - Planning
KW  - Trajectory
KW  - Visualization
KW  - Metadata
DO  - 10.1109/ICRA.2018.8460783
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Due to the distributed nature of cooperative simultaneous localization and mapping (CSLAM), detecting inter-robot loop closures necessitates sharing sensory data with other robots. A naïve approach to data sharing can easily lead to a waste of mission-critical resources. This paper investigates the logistical aspects of CSLAM. Particularly, we present a general resource-efficient communication planning framework that takes into account both the total amount of exchanged data and the induced division of labor between the participating robots. Compared to other state-of-the-art approaches, our framework is able to verify the same set of potential inter-robot loop closures while exchanging considerably less data and influencing the induced workloads. We develop a fast algorithm for finding globally optimal communication policies, and present theoretical analysis to characterize the necessary and sufficient conditions under which simpler strategies are optimal. The proposed framework is extensively evaluated with data from the KITTI odometry benchmark datasets.
ER  - 

TY  - CONF
TI  - StaticFusion: Background Reconstruction for Dense RGB-D SLAM in Dynamic Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3849
EP  - 3856
AU  - R. Scona
AU  - M. Jaimez
AU  - Y. R. Petillot
AU  - M. Fallon
AU  - D. Cremers
PY  - 2018
KW  - cameras
KW  - image colour analysis
KW  - image filtering
KW  - image motion analysis
KW  - image reconstruction
KW  - image segmentation
KW  - image sensors
KW  - image sequences
KW  - motion estimation
KW  - object detection
KW  - object tracking
KW  - pose estimation
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - frame-to-model alignment
KW  - 3D model estimation
KW  - outlier filtering techniques
KW  - moving object detection
KW  - camera pose tracking
KW  - probabilistic static-dynamic segmentation
KW  - background structure reconstruction
KW  - dynamic scenes
KW  - static environments
KW  - dynamic sequences
KW  - static sequences
KW  - camera motion estimation
KW  - weighted dense RGB-D fusion
KW  - current RGB-D image pair
KW  - implicit robust penalisers
KW  - background structure
KW  - robust dense RGB-D SLAM
KW  - visual SLAM
KW  - dynamic environments
KW  - Cameras
KW  - Robustness
KW  - Image segmentation
KW  - Motion segmentation
KW  - Dynamics
KW  - Three-dimensional displays
KW  - Image reconstruction
DO  - 10.1109/ICRA.2018.8460681
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Dynamic environments are challenging for visual SLAM as moving objects can impair camera pose tracking and cause corruptions to be integrated into the map. In this paper, we propose a method for robust dense RGB-D SLAM in dynamic environments which detects moving objects and simultaneously reconstructs the background structure. While most methods employ implicit robust penalisers or outlier filtering techniques in order to handle moving objects, our approach is to simultaneously estimate the camera motion as well as a probabilistic static/dynamic segmentation of the current RGB-D image pair. This segmentation is then used for weighted dense RGB-D fusion to estimate a 3D model of only the static parts of the environment. By leveraging the 3D model for frame-to-model alignment, as well as static/dynamic segmentation, camera motion estimation has reduced overall drift - as well as being more robust to the presence of dynamics in the scene. Demonstrations are presented which compare the proposed method to related state-of-the-art approaches using both static and dynamic sequences. The proposed method achieves similar performance in static environments and improved accuracy and robustness in dynamic scenes.
ER  - 

TY  - CONF
TI  - Vision Based Collaborative Path Planning for Micro Aerial Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3889
EP  - 3895
AU  - S. Vemprala
AU  - S. Saripalli
PY  - 2018
KW  - cameras
KW  - collision avoidance
KW  - covariance matrices
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - robot vision
KW  - trees (mathematics)
KW  - microaerial vehicles
KW  - collaborative path-planning framework
KW  - localization uncertainty
KW  - two-step planning framework
KW  - visual-fidelity aerial vehicle simulator
KW  - Planning
KW  - Uncertainty
KW  - Cameras
KW  - Three-dimensional displays
KW  - Collaboration
KW  - Optimization
KW  - Path planning
DO  - 10.1109/ICRA.2018.8462910
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a collaborative path-planning framework for a group of micro aerial vehicles that are capable of localizing through vision. Each of the micro aerial vehicles is assumed to be equipped with a forward facing monocular camera. The vehicles initially use their captured images to build 3D maps through common features; and subsequently track these features to localize through 3D-2D correspondences. The planning algorithm, while connecting start locations to provided goal locations, also aims to reduce the localization uncertainty of the vehicles in the group. To achieve this, we develop a two-step planning framework: the first step attempts to build an improved map of the environment by solving the next-best-view problem for multiple cameras. We express this as a black-box optimization problem and solve it using the Covariance Matrix Adaption evolution strategy (CMA-ES). Once an improved map is available, the second stage of the planning framework performs belief space planning for the vehicles individually using the rapidly exploring random belief tree (RRBT) algorithm. Through the RRBT approach, the planner generates paths that ensure feature visibility while attempting to optimize path cost and reduce localization uncertainty. We validate our approach using experiments conducted in a high visual-fidelity aerial vehicle simulator, Microsoft AirSim.
ER  - 

TY  - CONF
TI  - Semi-Dense Visual-Inertial Odometry and Mapping for Quadrotors with SWAP Constraints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3904
EP  - 3909
AU  - W. Liu
AU  - G. Loianno
AU  - K. Mohta
AU  - K. Daniilidis
AU  - V. Kumar
PY  - 2018
KW  - helicopters
KW  - inertial navigation
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - state estimation
KW  - stereo image processing
KW  - semidense visual-inertial odometry
KW  - quadrotors
KW  - SWAP constraints
KW  - autonomous navigation capabilities
KW  - dense 3D maps
KW  - indoor environments
KW  - visual inertial state estimation
KW  - microaerial vehicles
KW  - size, weight, and power constraints
KW  - stereo camera
KW  - Cameras
KW  - Three-dimensional displays
KW  - Visual odometry
KW  - Optimization
KW  - Navigation
KW  - Robot vision systems
DO  - 10.1109/ICRA.2018.8463163
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Micro Aerial Vehicles have the potential to assist humans in real life tasks involving applications such as smart homes, search and rescue, and architecture construction. To enhance autonomous navigation capabilities these vehicles need to be able to create dense 3D maps of the environment, while concurrently estimating their own motion. In this paper, we are particularly interested in small vehicles that can navigate cluttered indoor environments. We address the problem of visual inertial state estimation, control and 3D mapping on platforms with Size, Weight, And Power (SWAP) constraints. The proposed approach is validated through experimental results on a 250 g, 22 cm diameter quadrotor equipped only with a stereo camera and an IMU with a computationally-limited CPU showing the ability to autonomously navigate, while concurrently creating a 3D map of the environment.
ER  - 

TY  - CONF
TI  - Approximation Algorithms for Tours of Orientation-Varying View Cones
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3910
EP  - 3915
AU  - N. Stefas
AU  - P. A. Plonski
AU  - V. Isler
PY  - 2018
KW  - approximation theory
KW  - computational complexity
KW  - travelling salesman problems
KW  - apex angle
KW  - 3D traveling salesman problem
KW  - shorter tours
KW  - tilted Cone-TSPN problem
KW  - planar surface
KW  - apex points
KW  - inverted cone views
KW  - shortest tour
KW  - orientation-varying view cones
KW  - approximation algorithms
KW  - Approximation algorithms
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Traveling salesman problems
KW  - Lakes
KW  - Animals
KW  - Cameras
DO  - 10.1109/ICRA.2018.8462908
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper considers the problem of finding the shortest tour to cover a given set of inverted cone views with apex angle α and height H when their apex points lie on a planar surface. This is a novel variant of the 3D Traveling Salesman Problem with intersecting Neighborhoods (TSPN) called Cone-TSPN. When the cones are allowed to tilt by an angle c we have the tilted Cone-TSPN problem, to which we present an algorithm that returns a solution with an approximation ratio of O (1+tan α/1-tan ϵ tan α (1 + log max(H)/min(H)). We demonstrate through simulations that our algorithm can be implemented in a practical way and by exploiting the structure of the cones we can achieve shorter tours. Finally, we present results from covering a reflective surface (lake area) that shows the importance of selecting different view angles under strong sunlight specularities.
ER  - 

TY  - CONF
TI  - Geometric Calibration of an OCT Imaging System
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3993
EP  - 3999
AU  - M. Ourak
AU  - B. Tamadazte
AU  - G. J. Laurent
AU  - N. Andreff
PY  - 2018
KW  - biological organs
KW  - biomedical optical imaging
KW  - calibration
KW  - medical image processing
KW  - optical tomography
KW  - optical coherence tomography
KW  - OCT geometric calibration method
KW  - OCT imaging system
KW  - spectral domain OCT system
KW  - 3D images
KW  - calibration model
KW  - spectral distortions
KW  - optical path
KW  - OCT images formation
KW  - optical biopsies
KW  - OCT medical imaging system
KW  - Optical distortion
KW  - Distortion
KW  - Optical imaging
KW  - Mirrors
KW  - Adaptive optics
KW  - Two dimensional displays
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8463171
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper deals with an OCT (optical coherence tomography) geometric calibration method. OCT medical imaging system has received a growing interest during the last two decades. In medical purposes, OCT images are generally called optical biopsies which allows in-vivo investigation almost similar to a histopathological study. The physician can rely on the OCT images to establish a rapid and direct diagnosis. But the OCT images formation suffered numerous distortions due in particular to the optical path, from the source to the viewed sample passing through the two reflecting mirrors and a scan objective. The obtained optical biopsies include several spectral and geometric distortions. The proposed calibration model aims to compensate the geometrical ones. More precisely, two models were developed allowing the correction of both 2D images (B-Scan slices) and 3D images (volume). These models were experimentally validated (in both artificial and biological samples) using a spectral domain OCT system. It has demonstrated a significant enhancement of the OCT images accuracy.
ER  - 

TY  - CONF
TI  - Marker-Based Registration for Large Deformations - Application to Open Liver Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4007
EP  - 4012
AU  - Y. Adagolodjo
AU  - N. Golse
AU  - E. Vibert
AU  - M. De Mathelin
AU  - S. Cotin
AU  - H. Courtecuisse
PY  - 2018
KW  - augmented reality
KW  - computerised tomography
KW  - image registration
KW  - liver
KW  - medical image processing
KW  - surgery
KW  - tumours
KW  - augmented reality system
KW  - marker-based method
KW  - liver resection surgery
KW  - realtime tracking algorithm
KW  - nonrigid initial registration method
KW  - preoperative model
KW  - open surgery
KW  - open liver surgery
KW  - marker-based registration
KW  - Surgery
KW  - Strain
KW  - Liver
KW  - Cameras
KW  - Deformable models
KW  - Biological system modeling
DO  - 10.1109/ICRA.2018.8462909
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces an Augmented Reality (AR) system for open liver surgery. Although open surgery remains the gold-standard for the treatment of complex tumors and central lesions, technological issues actually prevent using AR with sufficient accuracy for clinical use. We propose a markers-based method allowing for the tracking and the deformation of a preoperative model in real-time during the surgery. Markers are manually placed on the surface of the organ after opening the abdominal cavity, and tracked in real-time by a set of infrared cameras. Our framework is composed of both a nonrigid initial registration method, providing an estimation of the location of the markers in the preoperative model, and a realtime tracking algorithm to deform the model during the surgery (even for large deformation or partial occlusion of the organ). The method is validated on both synthetic and ex-vivo samples; in addition, we demonstrate its applicability in the operating room during a liver resection surgery on a human patient. Preliminary studies provided promising results to improve the location of tumors, and to help surgeons into planning the ideal resection intraoperatively.
ER  - 

TY  - CONF
TI  - Real-Time Image-Guided Cooperative Robotic Assist Device for Deep Anterior Lamellar Keratoplasty
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4013
EP  - 4018
AU  - M. Draelos
AU  - B. Keller
AU  - G. Tang
AU  - A. Kuo
AU  - K. Hauser
AU  - J. Izatt
PY  - 2018
KW  - biomechanics
KW  - biomedical equipment
KW  - biomedical optical imaging
KW  - eye
KW  - manipulators
KW  - medical robotics
KW  - optical tomography
KW  - surgery
KW  - robot arm
KW  - graft rejection risk
KW  - chronic immunosuppression comorbidities
KW  - corneal transplantation
KW  - promising technique
KW  - deep anterior lamellar keratoplasty
KW  - time image-guided cooperative robotic
KW  - perforation-free needle depth
KW  - DALK needle insertions
KW  - real-time OCT segmentation
KW  - posterior corneal boundary virtual fixture
KW  - optical coherence tomography imaging
KW  - robot-assisted solution
KW  - inadequate needle depth
KW  - Needles
KW  - Surgery
KW  - Robot sensing systems
KW  - Visualization
KW  - Tools
KW  - Cornea
KW  - Cooperative control
KW  - medical robotics
DO  - 10.1109/ICRA.2018.8463153
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Deep anterior lamellar keratoplasty (DALK) is a promising technique for corneal transplantation that avoids the chronic immunosuppression comorbidities and graft rejection risk associated with penetrating keratoplasty (PKP), the standard procedure. In DALK, surgeons must insert a needle 90% through the 500 μm cornea without penetrating its underlying membrane. This pushes surgeons to their manipulation and visualization limits such that 59% of DALK attempts fail due to corneal perforation or inadequate needle depth. We propose a robot-assisted solution to jointly solve the manipulation and visualization challenges using a cooperatively-controlled, precise robot arm and live optical coherence tomography (OCT) imaging, respectively. Our system features an interface handle, with which the surgeon and robot cooperatively hold the tool, and a posterior corneal boundary virtual fixture driven by real-time OCT segmentation. A study in which three operators performed DALK needle insertions manually and cooperatively in ex vivo human corneas demonstrated an 84% improvement in perforation-free needle depth without an increased perforation rate.
ER  - 

TY  - CONF
TI  - Hall Effect Sensing Workspace Estimation with Non-Permanent Magnetic Needle for Eye Anesthesia Training System via Robotic Experiments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4019
EP  - 4024
AU  - K. Borvorntanajanya
AU  - J. Suthakorn
PY  - 2018
KW  - eye
KW  - Hall effect devices
KW  - Kalman filters
KW  - manipulators
KW  - medical robotics
KW  - needles
KW  - position control
KW  - sensor arrays
KW  - sensors
KW  - surgery
KW  - Hall effect sensing workspace
KW  - nonpermanent magnetic needle
KW  - eye anesthesia training system
KW  - robotic experiments
KW  - eye surgery
KW  - needle tip tracking system
KW  - ophthalmic anesthesia training
KW  - anesthesia needle
KW  - magnetized needle tip
KW  - Hall-effect sensor array
KW  - orbital structure model
KW  - Hall-effect sensors
KW  - ophthalmic anesthesia pathway
KW  - needle tip position
KW  - commercial robotic manipulator
KW  - developed system
KW  - Needles
KW  - Robot sensing systems
KW  - Magnetic flux
KW  - Anesthesia
KW  - Orbits
DO  - 10.1109/ICRA.2018.8461015
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Ophthalmic anesthesia is an important preparation for eye surgery. The conventional practice is performed blind in a cadaver under the supervision of an experienced surgeon. This paper introduces a needle tip tracking system for ophthalmic anesthesia training without major modification of an anesthesia needle. The study presents a prototyped system to track a magnetized needle tip using Hall-effect sensor array. The orbital structure model was embedded with Hall-effect sensors after considering the sensing workspace and ophthalmic anesthesia pathway. The extended Kalman filter was used to calculate needle tip position. A commercial robotic manipulator was used to model the characteristics of sensor and accuracy of the developed system. A prototype can detect needle tip position with a root-mean-square deviation around 1.80 mm. As a result, the system is capable of providing needle tip positions for training purposes.
ER  - 

TY  - CONF
TI  - Precision Needle Tip Localization Using Optical Coherence Tomography Images for Subretinal Injection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4033
EP  - 4040
AU  - M. Zhou
AU  - K. Huang
AU  - A. Eslami
AU  - H. Roodaki
AU  - D. Zapp
AU  - M. Maier
AU  - C. P. Lohmann
AU  - A. Knoll
AU  - M. A. Nasseri
PY  - 2018
KW  - biological tissues
KW  - biomedical equipment
KW  - biomedical optical imaging
KW  - eye
KW  - medical image processing
KW  - medical robotics
KW  - needles
KW  - optical tomography
KW  - surgery
KW  - robot-assisted subretinal injection
KW  - needle tip localization
KW  - microsurgery
KW  - microscope-integrated intraoperative optical coherence tomography
KW  - insertion depth
KW  - subretinal visual feedback
KW  - optical coherence tomography images
KW  - Needles
KW  - Retina
KW  - Surgery
KW  - Microscopy
KW  - Robots
KW  - Probes
DO  - 10.1109/ICRA.2018.8460745
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Subretinal injection is a delicate and complex microsurgery, which requires surgeons to inject the therapeutic substance in a pre-operatively defined and intra-operatively updated subretinal target area. Due to the lack of subretinal visual feedback, it is hard to sense the insertion depth during the procedure, thus affecting the results of surgical outcome and hindering the widespread use of this treatment. This paper presents a novel approach to estimate the 3D position of the needle under the retina using the information from microscope-integrated Intraoperative Optical Coherence Tomography (iOCT). We evaluated our approach on both tissue phantom and ex-vivo porcine eyes. Evaluation results show that the average error in distance measurement is 4.7 μm (maximum of 16.5 μm). We furthermore, verified the feasibility of the proposed method to track the insertion depth of needle in robot-assisted subretinal injection.
ER  - 

TY  - CONF
TI  - Proprioceptive Inference for Dual-Arm Grasping of Bulky Objects Using RoboSimian
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4049
EP  - 4056
AU  - M. Burkhardt
AU  - S. Karumanchi
AU  - K. Edelberg
AU  - J. W. Burdick
AU  - P. Backes
PY  - 2018
KW  - Bayes methods
KW  - dexterous manipulators
KW  - humanoid robots
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - position control
KW  - robot kinematics
KW  - sensors
KW  - torque measurement
KW  - nasa jet propulsion laboratorys
KW  - robosimian
KW  - JPL
KW  - supporting manipulator
KW  - cumbersome objects
KW  - data-driven Bayesian models
KW  - inferred object properties
KW  - dual-arm lifting
KW  - bulky object
KW  - dual-arm grasping
KW  - proprioceptive inference
KW  - Manipulators
KW  - Probabilistic logic
KW  - Rotation measurement
KW  - Grasping
KW  - Shape
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460776
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work demonstrates dual-arm lifting of bulky objects based on inferred object properties (center of mass (COM) location, weight, and shape) using proprioception (i.e. force torque measurements). Data-driven Bayesian models describe these quantities, which enables subsequent behaviors to depend on confidence of the learned models. Experiments were conducted using the NASA Jet Propulsion Laboratory's (JPL) RoboSimian to lift a variety of cumbersome objects ranging in mass from 7kg to 25kg. The position of a supporting second manipulator was determined using a particle set and heuristics that were derived from inferred object properties. The supporting manipulator decreased the initial manipulator's load and distributed the wrench load more equitably across each manipulator, for each bulky object. Knowledge of the objects came from pure proprioception (i.e. without reliance on vision or other exteroceptive sensors) throughout the experiments.
ER  - 

TY  - CONF
TI  - Compact and High Performance Torque-Controlled Actuators and its Implementation to Disaster Response Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4057
EP  - 4063
AU  - Y. Kanemoto
AU  - T. Yoshiike
AU  - M. Muromachi
AU  - M. Osada
PY  - 2018
KW  - actuators
KW  - disasters
KW  - electromagnetic interference
KW  - gears
KW  - legged locomotion
KW  - rescue robots
KW  - strain gauges
KW  - torque control
KW  - high performance torque-controlled actuators
KW  - disaster response robot
KW  - scattered debris
KW  - axial compactness
KW  - torque sensors
KW  - torque control
KW  - analog digital converter board
KW  - differential control
KW  - joint torque
KW  - torque ripple
KW  - torque-controlled legged robot
KW  - disaster environments
KW  - harmonic drive gear
KW  - electromagnetic interference
KW  - strain gauges
KW  - Torque
KW  - Actuators
KW  - Robot sensing systems
KW  - Torque measurement
KW  - Strain measurement
DO  - 10.1109/ICRA.2018.8460789
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Applying robots in narrow and cluttered disaster environments such as oil refineries requires a slim body and a wide range of motion. It is also necessary to have abilities to absorb unexpected contact with the environment and to walk on scattered debris. In this paper we propose new compact and high performance torque-controlled actuators for legged robots to satisfy the above mentioned requirements. For axial compactness, torque sensors are designed as ring-shaped thin cylinders surrounding motors or gears with strain gauges for sensing. To achieve broad bandwidth of torque control, we introduced an analog differentiator circuit into an analog digital converter (ADC) board in order to suppress noise in the differential control of joint torque. We also propose methods to reduce torque ripple caused by the deformation of the harmonic drive gear and electromagnetic interference (EMI) from a motor and a motor driver. Finally, experiments of a collision with objects and movement on scattered debris were executed with a fully torque-controlled legged robot built with the proposed actuators.
ER  - 

TY  - CONF
TI  - High Dynamic Range Sensing by a Multistage Six-Axis Force Sensor with Stopper Mechanism
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4065
EP  - 4070
AU  - D. Okumura
AU  - S. Sakaino
AU  - T. Tsuji
PY  - 2018
KW  - force measurement
KW  - force sensors
KW  - seals (stoppers)
KW  - torque measurement
KW  - high dynamic range six-axis force-torque sensor
KW  - HDR six-axis force-torque sensor
KW  - force measurement
KW  - stopper mechanism
KW  - multistage six-axis force sensor
KW  - high dynamic range sensing
KW  - HDR measurement
KW  - overload protection mechanism
KW  - low-rigidity flexure element
KW  - high-rigidity flexure element
KW  - Robot sensing systems
KW  - Force sensors
KW  - Force
KW  - Strain
KW  - Force measurement
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8460571
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes the design of a high dynamic range (HDR) six-axis force/torque sensor. The sensor is composed of a high-rigidity flexure element detecting large force and a low-rigidity flexure element detecting small force. The overload on the low-rigidity flexure element is prevented by an overload protection mechanism. An HDR measurement is achieved by combining the outputs of the two flexure elements. A loading test for the designed sensor is performed, and the results indicate that the six-axis sensor measures force with a dynamic range from 0.01N to 1000 N.
ER  - 

TY  - CONF
TI  - Principal Components of Touch
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4071
EP  - 4078
AU  - K. Aquilina
AU  - D. A. W. Barton
AU  - N. F. Lepora
PY  - 2018
KW  - biology computing
KW  - data visualisation
KW  - principal component analysis
KW  - sensor arrays
KW  - tactile sensors
KW  - touch (physiological)
KW  - vibrissal arrays
KW  - PCA
KW  - touch
KW  - complex robotic manipulation
KW  - tactile sensor arrays
KW  - principal component analysis
KW  - visualisation approach
KW  - k-NN
KW  - Euclidean distance
KW  - Principal component analysis
KW  - Tactile sensors
KW  - Data visualization
KW  - Sensor arrays
KW  - Pins
DO  - 10.1109/ICRA.2018.8461045
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Our human sense of touch enables us to manipulate our surroundings; therefore, complex robotic manipulation will require artificial tactile sensing. Typically tactile sensor arrays are used in robotics, implying that a straightforward way of interpreting multidimensional data is required. In this paper we present a simple visualisation approach based on applying principal component analysis (PCA) to systematically collected sets of tactile data. We apply the visualisation approach to 4 different types of tactile sensor, encompassing fingertips and vibrissal arrays. The results show that PCA can reveal structure and regularities in the tactile data, which also permits the use of simple classifiers such as k-NN to achieve good inference. Additionally, the Euclidean distance in principal component space gives a measure of sensitivity, which can aid visualisation and also be used to find regions in the tactile input space where the sensor is able to perceive with higher accuracy. We expect that these observations will generalise, and thus offer the potential for novel control methods based on touch.
ER  - 

TY  - CONF
TI  - Design and Force-Tracking Impedance Control of a 2-DOF Wall-Cleaning Manipulator Using Disturbance Observer and Sliding Mode Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4079
EP  - 4084
AU  - T. Kim
AU  - S. Yoo
AU  - H. S. Kim
AU  - J. Kim
PY  - 2018
KW  - control system synthesis
KW  - force control
KW  - manipulator dynamics
KW  - motion control
KW  - observers
KW  - position control
KW  - variable structure systems
KW  - disturbance observer
KW  - sliding mode control
KW  - SMC
KW  - position-based force
KW  - FTIC
KW  - constant contact force
KW  - force tracking capability
KW  - force-tracking impedance control
KW  - 2-degree-of-freedom
KW  - 2-DOF wall-cleaning manipulator
KW  - Force
KW  - Manipulator dynamics
KW  - Brushes
KW  - Impedance
KW  - Dynamics
KW  - Shape
DO  - 10.1109/ICRA.2018.8460897
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents design and force-tracking impedance control of 2-degree-of-freedom (DOF) wall-cleaning manipulator equipped with disturbance observer (DOB) and sliding mode control (SMC). In order to keep in contact with various shapes of walls, the proposed manipulator is designed to ensure 2-DOF motions of translation and tilting by using ball screws. The position-based force tracking impedance control (FTIC) is first adopted for the proposed manipulator not only to interact with walls in a desired dynamic behavior but also to maintain a constant contact force. Also, to improve the force tracking capability of proposed manipulator against different walls and brushes for manipulator, the FTIC is combined with the disturbance observer (DOB) and the sliding mode control (SMC). Extensive experiments prove that although different brushes used for manipulator rotate against varying shapes of walls, the proposed manipulator can keep a constant contact force within a bound of ± 4.5 N by virtue of the proposed FTIC equipped with the DOB and the SMC.
ER  - 

TY  - CONF
TI  - Artistic Pen Drawing on an Arbitrary Surface Using an Impedance-Controlled Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4085
EP  - 4090
AU  - D. Song
AU  - T. Lee
AU  - Y. J. Kim
PY  - 2018
KW  - art
KW  - computational geometry
KW  - curve fitting
KW  - manipulators
KW  - position control
KW  - splines (mathematics)
KW  - vectors
KW  - surface-reconstruction
KW  - position control
KW  - vector-graphics engine
KW  - Bézier spline curves
KW  - artistic pen drawing
KW  - impedance control
KW  - seven-degree-of-freedom manipulator
KW  - pen strokes
KW  - pen art
KW  - semiautonomous robotic pen-drawing system
KW  - impedance-controlled robot
KW  - arbitrary surface
KW  - Surface impedance
KW  - Robot sensing systems
KW  - Service robots
KW  - Surface reconstruction
KW  - Rendering (computer graphics)
KW  - Art
DO  - 10.1109/ICRA.2018.8461084
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a semi-autonomous robotic pen-drawing system that is capable of creating pen art on an arbitrary surface with varying thickness of pen strokes but without reconstructing the surface explicitly. Our robotic system relies on an industrial, seven-degree-of-freedom (7DoF) manipulator that can be both position- and impedance-controlled. We use a vector-graphics engine to take an artist's pen drawing as input and generate Bézier spline curves with varying offsets. In order to estimate geometric details of the target, unknown surface, during drawing, we rely on incremental and adaptive sampling on the surface using a combination of position and impedance control. Then, our control algorithm physically replicates this drawing on any arbitrary, continuous surface by impedance-controlling the manipulator. We demonstrate that our system can create visually-pleasing and complicated artistic pen drawings on general surfaces without explicit surface-reconstruction nor visual feedback.
ER  - 

TY  - CONF
TI  - Detection and Control of Contact Force Transients in Robotic Manipulation Without a Force Sensor
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4091
EP  - 4096
AU  - M. Karlsson
AU  - A. Robertsson
AU  - R. Johansson
PY  - 2018
KW  - force sensors
KW  - industrial robots
KW  - manipulators
KW  - recurrent neural nets
KW  - torque
KW  - recurrent neural network
KW  - RNN
KW  - industrial robot
KW  - force transient detection
KW  - robot joint torques
KW  - force sensor
KW  - robotic manipulation
KW  - contact force transients
KW  - Robot sensing systems
KW  - Transient analysis
KW  - Training
KW  - Switches
KW  - Task analysis
KW  - Data models
DO  - 10.1109/ICRA.2018.8461104
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this research, it is shown that robot joint torques can be used to recognize contact force transients induced during robotic manipulation, thus detecting when a task is completed. The approach does not assume any external sensor, which is a benefit compared to the state of the art. The joint torque data are used as input to a recurrent neural network (RNN), and the output of the RNN indicates whether the task is completed. A real-time application for force transient detection is developed, and verified experimentally on an industrial robot.
ER  - 

TY  - CONF
TI  - Unsupervised Learning of Hierarchical Models for Hand-Object Interactions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4097
EP  - 4102
AU  - X. Xie
AU  - H. Liu
AU  - M. Edmonds
AU  - F. Gaol
AU  - S. Qi
AU  - Y. Zhu
AU  - B. Rothrock
AU  - S. Zhu
PY  - 2018
KW  - image segmentation
KW  - pose estimation
KW  - support vector machines
KW  - tactile sensors
KW  - unsupervised learning
KW  - force vectors
KW  - unsupervised manner
KW  - event labeling sequences
KW  - manipulation event segmentation
KW  - hierarchical models
KW  - hand-object interactions
KW  - contact forces
KW  - unsupervised learning approach
KW  - manipulation event parsing
KW  - low-cost easy-to-replicate tactile glove
KW  - temporal grammar model
KW  - Force
KW  - Grammar
KW  - Robot sensing systems
KW  - Task analysis
KW  - Motion segmentation
KW  - Unsupervised learning
DO  - 10.1109/ICRA.2018.8461214
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Contact forces of the hand are visually unobservable, but play a crucial role in understanding hand-object interactions. In this paper, we propose an unsupervised learning approach for manipulation event segmentation and manipulation event parsing. The proposed framework incorporates hand pose kinematics and contact forces using a low-cost easy-to-replicate tactile glove. We use a temporal grammar model to capture the hierarchical structure of events, integrating extracted force vectors from the raw sensory input of poses and forces. The temporal grammar is represented as a temporal And-Or graph (T-AOG), which can be induced in an unsupervised manner. We obtain the event labeling sequences by measuring the similarity between segments using the Dynamic Time Alignment Kernel (DTAK). Experimental results show that our method achieves high accuracy in manipulation event segmentation, recognition and parsing by utilizing both pose and force data.
ER  - 

TY  - CONF
TI  - Decoupled Motion Control of Wearable Robot for Rejecting Human Induced Disturbances
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4103
EP  - 4110
AU  - F. Y. Wu
AU  - H. H. Asada
PY  - 2018
KW  - artificial limbs
KW  - dexterous manipulators
KW  - medical robotics
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - wearable robots
KW  - human arm
KW  - human induced disturbances
KW  - data-driven latent space impedance control method
KW  - latent space impedance controller
KW  - wearable robotic fingers
KW  - decoupled motion control
KW  - wearable extra limbs
KW  - human movement
KW  - self-standing robots
KW  - single-handed object manipulation
KW  - 5G mobile communication
KW  - Conferences
KW  - Automation
KW  - Australia
DO  - 10.1109/ICRA.2018.8461109
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When a human performs a task with the assistance of wearable extra limbs, the human movement for performing the task may inadvertently disturb the position and orientation of the robot base, making it difficult for the robot to properly carry out its objective. Therefore, unlike self-standing robots, a wearable robot must not only assist the user without interfering or prohibiting the natural human movement, but also have the capability to detect and reject disturbances caused by the wearer's motion. This paper examines such a situation, where the human attempts to twist open a bottle while a pair of robotic fingers mounted on the same arm holds the bottle in place. As the human arm rotates to twist the cap, the robot and consequently the bottle would rotate in that same direction, which makes separation of the cap from the bottle almost impossible. To compensate for the human induced disturbances, a data-driven latent space impedance control method is developed such that the robot can secure the bottle and at the same time allow natural human movement to be carried out during manipulation. Simulation and experiments have demonstrated the efficacy of the latent space impedance controller to enable single-handed object manipulation with the assistance of wearable robotic fingers.
ER  - 

TY  - CONF
TI  - Estimation of Object Orientation Using Conductive Ink and Fabric Based Multilayered Tactile Sensor
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4135
EP  - 4141
AU  - G. Ponraj
AU  - H. Ren
PY  - 2018
KW  - accelerometers
KW  - dexterous manipulators
KW  - force sensors
KW  - grippers
KW  - manipulator kinematics
KW  - tactile sensors
KW  - fabric based multilayered tactile sensor
KW  - hard materials
KW  - soft materials
KW  - robotic hand gripper
KW  - kinesthetic sensation
KW  - grasped object orientation
KW  - tactile sensing
KW  - rigid inertial measurement units
KW  - object orientation estimation
KW  - conductive silver ink
KW  - conductive fabric
KW  - fabric based sensors
KW  - hard surfaces
KW  - soft surfaces
KW  - manipulator kinematics
KW  - object manipulation tasks
KW  - Ink
KW  - Fabrics
KW  - Tactile sensors
KW  - Piezoresistance
KW  - Silver
KW  - Fabric Tactile sensor
KW  - Multilayered sensor
KW  - Tilt sensing
KW  - Conductive silver ink
DO  - 10.1109/ICRA.2018.8461031
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robots, either made from hard or soft materials, are being used increasingly for unknown object manipulation tasks in unstructured environments. To hold an object firmly and do the required task, the orientation of the object with respect to the robotic hand gripper is one of the necessary key information. Humans can sense the orientation of an object based on vision, kinesthetic sensation, or touch sensation. Similarly, robots shall also be able to estimate grasped object orientation just based on tactile sensing without knowing manipulator kinesthetic or kinematics. Existing sensors are mostly based on vision or rigid inertial measurement units (such as accelerometers, gyroscopes, magnetometers), which require additional setup and are typically not compliant with the arbitrary surfaces of the unknown obj ects. This paper discusses a new approach for object orientation estimation from a multilayered tactile sensor based on conductive silver ink and conductive fabric. Fabric based sensors are flexible and can confer to both hard and soft surfaces. Experimental results show that the tactile sensor developed is able to estimate the tilt angle without any information about manipulator kinematics.
ER  - 

TY  - CONF
TI  - Magnified Force Sensory Substitution for Telemanipulation via Force-Controlled Skin Deformation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4142
EP  - 4148
AU  - Y. Kamikawa
AU  - N. Enayati
AU  - A. M. Okamura
PY  - 2018
KW  - force control
KW  - force feedback
KW  - force sensors
KW  - haptic interfaces
KW  - medical robotics
KW  - skin
KW  - surgery
KW  - tactile sensors
KW  - telerobotics
KW  - magnified force sensory substitution
KW  - teleoperation systems
KW  - kinesthetic force feedback systems
KW  - force-controlled tactile skin deformation
KW  - tangential force
KW  - normal force
KW  - sensory substitution device
KW  - skin deformation force feedback
KW  - maximum stable kinesthetic force feedback
KW  - da Vinci Research Kit teleoperation system
KW  - force magnification
KW  - interaction force
KW  - magnified force feedback
KW  - force feedback maximized performance
KW  - force-controlled skin deformation feedback
KW  - magnified kinesthetic force feedback
KW  - Force
KW  - Force feedback
KW  - Manipulators
KW  - Robot sensing systems
KW  - Skin
KW  - Strain
KW  - Force sensors
KW  - Haptics and Haptic Interfaces
KW  - Surgical Robotics
KW  - Laparoscopy
KW  - Force Control
KW  - Telerobotics and Teleoperation
DO  - 10.1109/ICRA.2018.8460810
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Teleoperation systems could benefit from force sensory substitution when kinesthetic force feedback systems are too bulky or expensive, and when they cause instability by magnifying force feedback. We aim to magnify force feedback using sensory substitution via force-controlled tactile skin deformation, using a device with the ability to provide tangential and normal force directly to the fingerpads. The sensory substitution device is able to provide skin deformation force feedback over ten times the maximum stable kinesthetic force feedback on a da Vinci Research Kit teleoperation system. We evaluated the effect of this force magnification in two experimental tasks where the goal was to minimize interaction force with the environment. In a peg transfer task, magnified force feedback using sensory substitution improved participants' performance for force magnifications up to ten times, but decreased performance for higher force magnifications. In a tube connection task, sensory substitution that doubled the force feedback maximized performance; there was no improvement at the larger magnifications. These experiments demonstrate that magnified force feedback using sensory substitution via force-controlled skin deformation feedback can decrease applied forces similarly to magnified kinesthetic force feedback during teleoperation.
ER  - 

TY  - CONF
TI  - Obstacle-Aided Navigation of a Soft Growing Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4165
EP  - 4172
AU  - J. D. Greer
AU  - L. H. Blumenschein
AU  - A. M. Okamura
AU  - E. W. Hawkes
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - path planning
KW  - obstacle-aided navigation
KW  - soft growing robot
KW  - obstacle avoidance
KW  - robot path planning
KW  - soft robots
KW  - intentional obstacle collisions
KW  - soft robot navigation
KW  - robot-obstacle interaction
KW  - tip-extending soft robot
KW  - obstacle interaction model
KW  - account obstacle collisions
KW  - Collision avoidance
KW  - Computational modeling
KW  - Kinematics
KW  - Pneumatic systems
KW  - Soft robotics
KW  - Navigation
DO  - 10.1109/ICRA.2018.8460777
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For many types of robots, avoiding obstacles is necessary to prevent damage to the robot and environment. As a result, obstacle avoidance has historically been an important problem in robot path planning and control. Soft robots represent a paradigm shift with respect to obstacle avoidance because their low mass and compliant bodies can make collisions with obstacles inherently safe. Here we consider the benefits of intentional obstacle collisions for soft robot navigation. We develop and experimentally verify a model of robot-obstacle interaction for a tip-extending soft robot. Building on the obstacle interaction model, we develop an algorithm to determine the path of a growing robot that takes into account obstacle collisions. We find that obstacle collisions can be beneficial for open-loop navigation of growing robots because the obstacles passively steer the robot, both reducing the uncertainty of the location of the robot and directing the robot to targets that do not lie on a straight path from the starting point. Our work shows that for a robot with predictable and safe interactions with obstacles, target locations in a cluttered, mapped environment can be reached reliably by simply setting the initial trajectory. This has implications for the control and design of robots with minimal active steering.
ER  - 

TY  - CONF
TI  - Color-Based Sensing of Bending Deformation on Soft Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4181
EP  - 4187
AU  - R. B. N. Scharff
AU  - R. M. Doornbusch
AU  - X. L. Klootwijk
AU  - A. A. Doshi
AU  - E. L. Doubrovski
AU  - J. Wu
AU  - J. M. P. Geraedts
AU  - C. C. L. Wang
PY  - 2018
KW  - image colour analysis
KW  - pneumatic actuators
KW  - robots
KW  - signal generators
KW  - three-dimensional printing
KW  - signal generator
KW  - color sensors
KW  - soft pneumatic actuators
KW  - soft actuators
KW  - multicolor 3D printing
KW  - soft robots
KW  - bending deformation
KW  - color-based sensing
KW  - Color
KW  - Strain
KW  - Actuators
KW  - Robot sensing systems
KW  - Signal generators
KW  - Soft robotics
DO  - 10.1109/ICRA.2018.8460521
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces a novel approach for sensing the bending deformation on soft robots by leveraging multicolor 3D printing. The measurement of deformation enables to complete the feedback loop of deformation control on soft actuators. The working principle of our approach is based on using compact color sensors to detect deformation that is visualized by the change of color ratios. Two novel designs are presented to generate color signals on 3D printed objects, which we call an external signal generator and an internal signal generator. Signal processing and calibration methods are developed to transform the raw RGB-data into a meaningful deformation metric. Our experimental tests taken on soft pneumatic actuators verify that color signals can be stably generated and captured to indicate the bending deformation. The results also demonstrate the usability of this sensing approach in deformation control.
ER  - 

TY  - CONF
TI  - Modelling and Control of a Novel Soft Crawling Robot Based on a Dielectric Elastomer Actuator
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4188
EP  - 4193
AU  - J. Cao
AU  - W. Liang
AU  - Q. Ren
AU  - U. Gupta
AU  - F. Chen
AU  - J. Zhu
PY  - 2018
KW  - elastomers
KW  - electric actuators
KW  - electroactive polymer actuators
KW  - feedback
KW  - feedforward
KW  - mobile robots
KW  - motion control
KW  - viscoelasticity
KW  - dielectric elastomer actuator
KW  - soft crawling robot
KW  - inchworms
KW  - viscoelasticity
KW  - feedforward plus feedback control scheme
KW  - motion control
KW  - Force
KW  - Actuators
KW  - Soft robotics
KW  - Friction
KW  - Steady-state
KW  - Electrodes
DO  - 10.1109/ICRA.2018.8460784
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft robots have recently evoked extensive attention due to their abilities to work effectively in unstructured environments. As an actuation technology of soft robots, dielectric elastomers exhibit many intriguing attributes such as large strain and high energy density. This work presents a novel dielectric elastomer based soft crawling robot inspired by inchworms. To fill the need of control of the soft robot, a model describing the interaction between the dielectric elastomer actuator and the environment is proposed, which takes inertia, viscoelasticity and friction into consideration. The model can well describe the robot's dynamic performances and the modelling approach used here can be extended to other dielectric elastomer actuators with complicated geometries for control purposes. The obtained model allows us to design a feedforward plus feedback control scheme for the robot to achieve desired motion. Simulation shows fast response and good tracking performances which are further confirmed by the experiments.
ER  - 

TY  - CONF
TI  - Geometry-based Direct Simulation for Multi-Material Soft Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4194
EP  - 4199
AU  - G. Fang
AU  - C. Matte
AU  - T. Kwok
AU  - C. C. L. Wang
PY  - 2018
KW  - calibration
KW  - deformation
KW  - design engineering
KW  - elasticity
KW  - geometry
KW  - manipulators
KW  - motion control
KW  - optimisation
KW  - pneumatic actuators
KW  - shapes (structures)
KW  - three-dimensional printing
KW  - material properties
KW  - deformation simulation
KW  - deformed shape
KW  - geometry-based direct simulation
KW  - multimaterial soft robots
KW  - soft materials
KW  - motion simulation
KW  - robots fabrication
KW  - numerical optimization
KW  - pneumatic actuators
KW  - cable-driven
KW  - calibration
KW  - design engineering
KW  - manipulators
KW  - 3D-printing
KW  - elasticity
KW  - Shape
KW  - Soft robotics
KW  - Strain
KW  - Computational modeling
KW  - Optimization
KW  - Numerical models
KW  - Deformable models
DO  - 10.1109/ICRA.2018.8461088
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robots fabricated by soft materials can provide higher flexibility and thus better safety while interacting with natural objects with low stiffness such as food and human beings. However, as many more degrees of freedom are introduced, the motion simulation of a soft robot becomes cumbersome, especially when large deformations are presented. Moreover, when the actuation is defined by geometry variation, it is not easy to obtain the exact loads and material properties to be used in the conventional methods of deformation simulation. In this paper, we present a direct approach to take the geometric actuation as input and compute the deformed shape of soft robots by numerical optimization using a geometry-based algorithm. By a simple calibration, the properties of multiple materials can be modeled geometrically in the framework. Numerical and experimental tests have been conducted to demonstrate the performance of our approach on both cable-driven and pneumatic actuators in soft robotics.
ER  - 

TY  - CONF
TI  - Incorporate Oblique Muscle Contractions to Strengthen Soft Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4200
EP  - 4205
AU  - X. Wang
AU  - H. Faraji
AU  - Y. Mengüç
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - muscle
KW  - robot kinematics
KW  - shear strength
KW  - wearable robots
KW  - soft robotics
KW  - shear forces
KW  - muscle arrangements
KW  - incompressible property
KW  - biological hydrostatic skeletons
KW  - longitudinal muscles
KW  - transverse muscles
KW  - oblique arrangement
KW  - shape-independent load-carrying capability
KW  - actuation mechanisms
KW  - oblique muscle contractions
KW  - flexibility
KW  - Muscles
KW  - Skeleton
KW  - Strain
KW  - Shape
KW  - Soft robotics
KW  - Force
KW  - Frequency modulation
DO  - 10.1109/ICRA.2018.8461139
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For the state-of-the-art of soft robotics, the current actuation mechanisms cannot produce shear forces, neither are the current stiffening mechanisms adaptive to various deformations. Consequently, the soft robots gain strength at the price of losing flexibility. To fill this gap, we proposed a new mechanism based on the muscle arrangements and incompressible property identified in biological hydrostatic skeletons. Beside longitudinal and transverse muscles, the proposed mechanism includes the oblique arrangement which is proved to play an indispensable role of producing shear forces. The effectiveness of the new mechanism is demonstrated through a benchmark problem - carrying a distributed load at the initial horizontal configuration, thus indicating an improved direction to realise shape-independent load-carrying capability of soft robotics. Furthermore, the proposed mechanism may explain how elephants coordinate the two contradicting properties, strength and flexibility, during their trunk manipulations.
ER  - 

TY  - CONF
TI  - Efficient FEM-Based Simulation of Soft Robots Modeled as Kinematic Chains
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4206
EP  - 4213
AU  - M. Pozzi
AU  - E. Miguel
AU  - R. Deimel
AU  - M. Malvezzi
AU  - B. Bickel
AU  - O. Brock
AU  - D. Prattichizzo
PY  - 2018
KW  - dexterous manipulators
KW  - finite element analysis
KW  - pneumatic actuators
KW  - soft manipulation
KW  - soft hands
KW  - environmental constraints
KW  - object surfaces
KW  - simulation technologies
KW  - triple-layered simulation framework
KW  - dynamic properties
KW  - lumped parameter model
KW  - fast simulate soft fingers
KW  - soft pneumatic fingers
KW  - soft robots modeled
KW  - kinematic chains
KW  - robotic manipulation
KW  - grasping
KW  - force closure
KW  - single posture
KW  - contact-rich
KW  - FEM-based simulation
KW  - FEM simulation data
KW  - Computational modeling
KW  - Actuators
KW  - Deformable models
KW  - Finite element analysis
KW  - Data models
KW  - Object oriented modeling
KW  - Robots
DO  - 10.1109/ICRA.2018.8461106
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the context of robotic manipulation and grasping, the shift from a view that is static (force closure of a single posture) and contact-deprived (only contact for force closure is allowed, everything else is obstacle) towards a view that is dynamic and contact-rich (soft manipulation) has led to an increased interest in soft hands. These hands can easily exploit environmental constraints and object surfaces without risk, and safely interact with humans, but present also some challenges. Designing them is difficult, as well as predicting, modelling, and “programming” their interactions with the objects and the environment. This paper tackles the problem of simulating them in a fast and effective way, leveraging on novel and existing simulation technologies. We present a triple-layered simulation framework where dynamic properties such as stiffness are determined from slow but accurate FEM simulation data once, and then condensed into a lumped parameter model that can be used to fast simulate soft fingers and soft hands. We apply our approach to the simulation of soft pneumatic fingers.
ER  - 

TY  - CONF
TI  - Evaluating the Quality of Non-Prehensile Balancing Grasps
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4215
EP  - 4220
AU  - R. Krug
AU  - Y. Bekiroglu
AU  - D. Kragic
AU  - M. A. Roa
PY  - 2018
KW  - dexterous manipulators
KW  - grippers
KW  - manipulator dynamics
KW  - mobile robots
KW  - nonprehensile balancing grasps
KW  - wrench-based quality metric
KW  - force-closure grasps
KW  - autonomous robotic applications
KW  - manipulation
KW  - prediction capability
KW  - dexterity
KW  - Task analysis
KW  - Measurement
KW  - Force
KW  - Robots
KW  - Grasping
KW  - Friction
KW  - Predictive models
DO  - 10.1109/ICRA.2018.8461078
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Assessing grasp quality and, subsequently, predicting grasp success is useful for avoiding failures in many autonomous robotic applications. In addition, interest in nonprehensile grasping and manipulation has been growing as it offers the potential for a large increase in dexterity. However, while force-closure grasping has been the subject of intense study for many years, few existing works have considered quality metrics for non-prehensile grasps. Furthermore, no studies exist to validate them in practice. In this work we use a real-world data set of non-prehensile balancing grasps and use it to experimentally validate a wrench-based quality metric by means of its grasp success prediction capability. The overall accuracy of up to 84 % is encouraging and in line with existing results for force-closure grasps.
ER  - 

TY  - CONF
TI  - Transferring Grasping Skills to Novel Instances by Latent Space Non-Rigid Registration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4229
EP  - 4236
AU  - D. Rodriguez
AU  - C. Cogswell
AU  - S. Koo
AU  - S. Behnke
PY  - 2018
KW  - image registration
KW  - inference mechanisms
KW  - intelligent robots
KW  - shape recognition
KW  - latent space nonrigid transformation
KW  - coherent point drift approach
KW  - class-level knowledge
KW  - grasping motions
KW  - shape parameters
KW  - low-dimensional latent space
KW  - subspace methods
KW  - nonrigid registration method
KW  - grasping skills
KW  - Shape
KW  - Grasping
KW  - Strain
KW  - Aerospace electronics
KW  - Three-dimensional displays
KW  - Robots
KW  - Coherence
DO  - 10.1109/ICRA.2018.8461169
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robots acting in open environments need to be able to handle novel objects. Based on the observation that objects within a category are often similar in their shapes and usage, we propose an approach for transferring grasping skills from known instances to novel instances of an object category. Correspondences between the instances are established by means of a non-rigid registration method that combines the Coherent Point Drift approach with subspace methods. The known object instances are modeled using a canonical shape and a transformation which deforms it to match the instance shape. The principle axes of variation of these deformations define a low-dimensional latent space. New instances can be generated through interpolation and extrapolation in this shape space. For inferring the shape parameters of an unknown instance, an energy function expressed in terms of the latent variables is minimized. Due to the class-level knowledge of the object, our method is able to complete novel shapes from partial views. Control poses for generating grasping motions are transferred efficiently to novel instances by the estimated non-rigid transformation.
ER  - 

TY  - CONF
TI  - Grasping Objects Big and Small: Human Heuristics Relating Grasp-Type and Object Size
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4237
EP  - 4242
AU  - A. Kothari
AU  - J. Morrow
AU  - V. Thrasher
AU  - K. Engle
AU  - R. Balasubramanian
AU  - C. Grimm
PY  - 2018
KW  - biomechanics
KW  - dexterous manipulators
KW  - motion control
KW  - human heuristics
KW  - grasp-type
KW  - object size
KW  - online data collection method
KW  - human intuition
KW  - survey questions
KW  - adopted taxonomy
KW  - wrist orientation
KW  - common grasps
KW  - object height
KW  - robot hand size
KW  - confidence-interval based polytope
KW  - object shape space
KW  - potential pre-grasps
KW  - grasping objects
KW  - fundamental object shapes
KW  - Shape
KW  - Taxonomy
KW  - Robots
KW  - Grasping
KW  - Planning
KW  - Videos
KW  - Data collection
DO  - 10.1109/ICRA.2018.8460860
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents an online data collection method that captures human intuition about what grasp types are preferred for different fundamental object shapes and sizes. Survey questions are based on an adopted taxonomy that combines grasp pre-shape, approach, wrist orientation, object shape, orientation and size which covers a large swathe of common grasps. For example, the survey identifies at what object height or width dimension (normalized by robot hand size) the human prefers to use a two finger precision grasp versus a three-finger power grasp. This information is represented as a confidence-interval based polytope in the object shape space. The result is a database that can be used to quickly find potential pre-grasps that are likely to work, given an estimate of the object shape and size.
ER  - 

TY  - CONF
TI  - Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4243
EP  - 4250
AU  - K. Bousmalis
AU  - A. Irpan
AU  - P. Wohlhart
AU  - Y. Bai
AU  - M. Kelcey
AU  - M. Kalakrishnan
AU  - L. Downs
AU  - J. Ibarz
AU  - P. Pastor
AU  - K. Konolige
AU  - S. Levine
AU  - V. Vanhoucke
PY  - 2018
KW  - image colour analysis
KW  - manipulators
KW  - neurocontrollers
KW  - robot vision
KW  - deep robotic grasping
KW  - off-the-shelf simulators
KW  - ground-truth annotations
KW  - randomized simulated environments
KW  - domain adaptation methods
KW  - grasping system
KW  - raw monocular RGB images
KW  - pixel-level domain adaptation
KW  - real-world grasping performance
KW  - annotated visual grasping datasets
KW  - GraspGAN
KW  - generative adversial network
KW  - Grasping
KW  - Robots
KW  - Training
KW  - Feature extraction
KW  - Adaptation models
KW  - Cameras
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460875
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Instrumenting and collecting annotated visual grasping datasets to train modern machine learning algorithms can be extremely time-consuming and expensive. An appealing alternative is to use off-the-shelf simulators to render synthetic data for which ground-truth annotations are generated automatically. Unfortunately, models trained purely on simulated data often fail to generalize to the real world. We study how randomized simulated environments and domain adaptation methods can be extended to train a grasping system to grasp novel objects from raw monocular RGB images. We extensively evaluate our approaches with a total of more than 25,000 physical test grasps, studying a range of simulation conditions and domain adaptation methods, including a novel extension of pixel-level domain adaptation that we term the GraspGAN. We show that, by using synthetic data and domain adaptation, we are able to reduce the number of real-world samples needed to achieve a given level of performance by up to 50 times, using only randomly generated simulated objects. We also show that by using only unlabeled real-world data and our GraspGAN methodology, we obtain real-world grasping performance without any real-world labels that is similar to that achieved with 939,777 labeled real-world samples.
ER  - 

TY  - CONF
TI  - Coordination of Intrinsic and Extrinsic Degrees of Freedom in Soft Robotic Grasping
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4251
EP  - 4256
AU  - C. Erdogan
AU  - A. Schröder
AU  - O. Brock
PY  - 2018
KW  - adaptive control
KW  - grippers
KW  - manipulators
KW  - motion control
KW  - hand capabilities
KW  - soft RBO Hand 2
KW  - predefined motion
KW  - finger movements
KW  - compliant robot
KW  - soft robotic grasping
KW  - human grasping
KW  - movement patterns
KW  - adaptive intrinsic/extrinsic motion
KW  - Robot kinematics
KW  - Grasping
KW  - Wrist
KW  - Manipulators
KW  - Protocols
KW  - Kinematics
DO  - 10.1109/ICRA.2018.8461075
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We demonstrate that moving the wrist while the fingers perform a grasp increases performance. The coordination shapes the interactions between the fingers, the object and its environment to extend the hand capabilities (e.g. higher payload and precision). We evaluated our hypothesis with a human grasping study where the volunteers grasped objects by moving the soft RBO Hand 2 while its fingers closed in a predefined motion. We limited their ability to coordinate their motion with the finger movements using a compliant robot attached to the hand, and observed that their grasp success decreases with increased constraints. We also successfully transferred one of the observed movement patterns to the robot, indicating that adaptive intrinsic/extrinsic motion increases robotic grasp performance as well.
ER  - 

TY  - CONF
TI  - Reinforcement Learning for 4-Finger-Gripper Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4257
EP  - 4262
AU  - M. Ojer De Andres
AU  - M. Mahdi Ghazaei Ardakani
AU  - A. Robertsson
PY  - 2018
KW  - grippers
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - motion control
KW  - path planning
KW  - high-level discrete actions
KW  - Q-learning
KW  - rhythmic Dynamic Movement Primitives
KW  - 4-finger-gripper manipulator
KW  - hierarchical planning
KW  - Reinforcement Learning
KW  - 4-finger-gripper manipulation
KW  - hierarchical-planning approach
KW  - Robots
KW  - Trajectory
KW  - Task analysis
KW  - Planning
KW  - Heuristic algorithms
KW  - Learning (artificial intelligence)
KW  - Approximation algorithms
DO  - 10.1109/ICRA.2018.8461153
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the framework of robotics, Reinforcement Learning (RL) deals with the learning of a task by the robot itself. This paper presents a hierarchical-planning approach in which the robot learns the optimal behavior for different levels in a decoupled way. For high-level discrete actions, Q-learning was chosen, whereas for the low level we utilize Policy Improvement with Path Integrals (PI2) algorithm to learn the parameters of policies, represented by rhythmic Dynamic Movement Primitives (DMPs). The paper studies the case of a 4-finger-gripper manipulator, which performs the task of continuously spinning a ball around a desired axis. The results demonstrate the efficacy of the hierarchical planning and the increased performance of the task when PI2 is used in conjunction with rhythmic DMPs in a real environment.
ER  - 

TY  - CONF
TI  - Popcorn-Driven Robotic Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4271
EP  - 4276
AU  - S. Ceron
AU  - A. Kurumunda
AU  - E. Garg
AU  - M. Kim
AU  - T. Yeku
AU  - K. Pctersen
PY  - 2018
KW  - actuators
KW  - compressive strength
KW  - friction
KW  - granular flow
KW  - granular materials
KW  - grippers
KW  - ignition
KW  - mixtures
KW  - robot dynamics
KW  - inter-granular friction
KW  - granular fluids
KW  - jamming actuators
KW  - popcorn-driven actuation
KW  - robotics
KW  - popcorn-driven robotic actuators
KW  - popcorn kernels
KW  - expansion ratio
KW  - transition temperature
KW  - compression strength
KW  - hot oil
KW  - hot air
KW  - direct contact
KW  - heated Nichrome wire
KW  - popping force
KW  - biodegradability
KW  - Kernel
KW  - Heating systems
KW  - Robots
KW  - Jamming
KW  - Actuators
KW  - Force
KW  - Wires
DO  - 10.1109/ICRA.2018.8461147
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Popcorn kernels are a natural, edible, and inexpensive material that has the potential to rapidly expand with high force upon application of heat. Although this transition is irreversible, it carries potential for several robotic applications. Here, we examine relevant characteristics of three types of kernels including expansion ratio, transition temperature, popping force, compression strength, and biodegradability. We test the viability of popping by hot oil, hot air, microwaves, and direct contact with heated Nichrome wire. As kernels can change from regular to (larger) irregular shapes, we examine the change in inter-granular friction and propose their use as granular fluids in jamming actuators, without the need for a vacuum pump. Furthermore, as a proof-of-concept, we also demonstrate the use of popcorn-driven actuation in soft, compliant, and rigid-link grippers. Serving as a first introduction of popcorn into robotics, we hope this paper will inspire novel mechanisms for multi-functional designs.
ER  - 

TY  - CONF
TI  - A Hybrid Dynamic-Regenerative Damping Scheme for Energy Regeneration in Variable Impedance Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4277
EP  - 4282
AU  - F. wu
AU  - M. Howard
PY  - 2018
KW  - actuators
KW  - damping
KW  - electromagnetic devices
KW  - energy conservation
KW  - regenerative braking
KW  - vibration control
KW  - VIA
KW  - variable damping module design
KW  - numerical simulations
KW  - energy consumption
KW  - energy efficiency
KW  - variable impedance actuators
KW  - dynamic-regenerative damping scheme
KW  - dynamic braking
KW  - regenerative braking effect
KW  - energy regeneration
KW  - dissipated energy
KW  - Damping
KW  - Resistance
KW  - Actuators
KW  - DC motors
KW  - Task analysis
KW  - Robots
DO  - 10.1109/ICRA.2018.8460207
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Increasing research efforts have been made to improve the energy efficiency of variable impedance actuators (VIAs) through reduction of energy consumption. However, the harvesting of dissipated energy in such systems remains under-explored. This study proposes a novel variable damping module design enabling energy regeneration in VIAs by exploiting the regenerative braking effect of DC motors. The proposed damping module uses four switches to combine regenerative and dynamic braking, in a hybrid approach that enables energy regeneration without reduction in the range of damping achievable. Numerical simulations and a physical experiment are presented in which the proposed module shows an optimal trade-off between task-performance and energy efficiency.
ER  - 

TY  - CONF
TI  - Screw-Powered Propulsion in Granular Media: An Experimental and Computational Study
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4283
EP  - 4288
AU  - A. Thoesen
AU  - S. Ramirez
AU  - H. Marvi
PY  - 2018
KW  - aerospace propulsion
KW  - blades
KW  - design engineering
KW  - discrete element method
KW  - fasteners
KW  - glass
KW  - granular materials
KW  - planetary rovers
KW  - propellers
KW  - shafts
KW  - space vehicles
KW  - tracked vehicles
KW  - transportation
KW  - vehicle dynamics
KW  - thrust force
KW  - granular media
KW  - screw-powered propulsion
KW  - industrial processes
KW  - pontoon shaft
KW  - arctic media
KW  - tracked vehicles
KW  - screw design
KW  - soda-lime glass beads
KW  - screw-propelled vehicles
KW  - transportation
KW  - dewatering
KW  - blades damage
KW  - blade sinkage
KW  - lunar rover design
KW  - aqueous media
KW  - angular velocity
KW  - double-helix Archimedes screw generating propulsive force
KW  - miniaturized exploration vehicle
KW  - discrete element modeling software
KW  - size 5.0 cm
KW  - size 8.0 cm
KW  - size 10.0 cm
KW  - size 1.8 mm to 2.2 mm
KW  - size 4 cm
KW  - Fasteners
KW  - Friction
KW  - Force
KW  - Glass
KW  - Media
KW  - Young's modulus
KW  - Propulsion
DO  - 10.1109/ICRA.2018.8460916
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Screw-Propelled Vehicles (SPV's) have been widely used for terrestrial applications such as transportation over mud, snow, and amphibious environments. Similar vehicles have also been applied to industrial processes such as dewatering. Typical designs rely on a large pontoon shaft and relatively small blades to prevent unwanted sinkage or blade damage. These types of vehicles were considered during the design of the first lunar rover, given their success in aqueous and arctic media and simplicity compared to tracked vehicles. Studies have looked at the mobility of SPV's on the surface of granular media but there are not any computational and experimental studies on propulsive buried screws. Understanding the role of screw design and its angular velocity on thrust force is key to the advancement and control of SPV's. This study presents experimental and computational results of a submerged, double-helix Archimedes screw generating propulsive force against a bed of soda-lime glass beads. Thus, this research forms the basis for design of a future miniaturized exploration vehicle for space applications. In our study, we used two different screw designs (5 cm radius, 10 cm length, 63 and 44 degrees helix angle corresponding to 4 cm and 8 cm pitch, respectively) submerged in 2mm glass beads (90% roundness with sizes 1.8 mm to 2.2 mm), For both screws, a similar trend is observed between rotational speed and thrust force. We used EDEM, a Discrete Element Modeling (DEM) software for computational studies of the screw interactions with granular media. There is 5-20% discrepancy between our computational and experimental results. We will discuss possible sources of error and the potential for using DEM as a design tool for SPV's.
ER  - 

TY  - CONF
TI  - Axially and Radially Expandable Modular Helical Soft Actuator for Robotic Implantables
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4297
EP  - 4304
AU  - E. R. Perez-Guagnelli
AU  - S. Nejus
AU  - J. Yu
AU  - S. Miyashita
AU  - Y. Liu
AU  - D. D. Damian
PY  - 2018
KW  - biological tissues
KW  - biomedical materials
KW  - cellular biophysics
KW  - elastomers
KW  - medical robotics
KW  - pneumatic actuators
KW  - prosthetics
KW  - surgery
KW  - radially expandable modular helical soft actuator
KW  - axially expandable modular helical soft actuator
KW  - elastomeric strands
KW  - elongation
KW  - tissue regeneration
KW  - long-gap esophageal atresia condition
KW  - soft pneumatic actuator
KW  - soft robots
KW  - modular soft basic constituents
KW  - human body
KW  - biomedical engineering
KW  - robotic implantables
KW  - soft medical robots
KW  - pressure 19.0 kPa
KW  - Actuators
KW  - Implants
KW  - Soft robotics
KW  - Esophagus
KW  - Surgery
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8461239
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft robotics has advanced the field of biomedical engineering by creating safer technologies for interfacing with the human body. One of the challenges in this field is the realization of modular soft basic constituents and accessible assembly methods to increase the versatility of soft robots. We present a soft pneumatic actuator composed of two elastomeric strands that provide interdependent axial and radial expansion due to the modularity of the components and their helical arrangement. The actuator reaches 35% of elongation with respect to its initial height and both chambers achieve forces of 1N at about 19kPa. We describe the design, fabrication, modeling and benchtop testing of the soft actuator towards realizing 3D functional structures with potential medical applications. An example of application for soft medical robots is tissue regenerative for the long-gap esophageal atresia condition.
ER  - 

TY  - CONF
TI  - Displacement Amplifier Mechanism for Piezoelectric Actuators Design Using SIMP Topology Optimization Approach
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4305
EP  - 4311
AU  - T. Schlinquer
AU  - A. Mohand-Ousaid
AU  - M. Rakotondrabe
PY  - 2018
KW  - finite element analysis
KW  - optimisation
KW  - piezoelectric actuators
KW  - Rhombus mechanism
KW  - SIMP topology optimization method
KW  - displacement range
KW  - inherent crystalline properties piezoelectric actuators
KW  - SIMP topology optimization approach
KW  - piezoelectric actuators design
KW  - displacement amplifier mechanism
KW  - Optimization
KW  - Topology
KW  - Force
KW  - Piezoelectric actuators
KW  - Sensitivity
KW  - Mathematical model
KW  - piezoelectric actuators
KW  - optimal design
KW  - compliant structure
KW  - SIMP topology optimization
DO  - 10.1109/ICRA.2018.8460183
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Due to their inherent crystalline properties piezoelectric actuators have a limited deformation. This intrinsic drawback deprives to exploit the potential of these actuators such as, high bandwidth and high resolution in applications that require large displacement range. To overcome this limitation, classical as well as systematic approaches were proposed to design amplification mechanisms. The classical approach leads to empirical mechanisms which are not trivial and needs much experience and intuition. In contrast, systematic approach uses topology optimization method which permits to automatically derive optimal designs that can satisfy specified performances and imposed constraints simultaneously, this with a reasonable time and cost. This paper proposes the design of a mechanism devoted to amplify the displacement of a piezoelectric actuators (PEA). Based on the SIMP topology optimization method, the approach permits to derive a design with a displacement amplification ratio of 4.5, which is higher than with the existing method of Rhombus mechanism. Both finite element (FE) simulation and experimental results confirm and demonstrate the efficiency of the approach.
ER  - 

TY  - CONF
TI  - Clothoid-Based Global Path Planning for Autonomous Vehicles in Urban Scenarios
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4312
EP  - 4318
AU  - J. A. R. Silva
AU  - V. Grassi
PY  - 2018
KW  - curve fitting
KW  - mobile robots
KW  - path planning
KW  - road traffic
KW  - road vehicles
KW  - roads
KW  - autonomous vehicles
KW  - urban scenario
KW  - intelligent vehicles
KW  - kinematic constraints
KW  - continuous-curvature paths
KW  - low curvature derivatives
KW  - clothoid-based global path planning
KW  - road network representation
KW  - Roads
KW  - Path planning
KW  - Geometry
KW  - Autonomous vehicles
KW  - Wheels
KW  - Kinematics
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8461201
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Intelligent vehicles require an efficient way to compute a feasible path that connects its current localization to a destination point. To achieve that, the knowledge about the road network, including its geometry, is important since connections between roads can be used in the path planning. This work consists on computing a feasible global path for autonomous vehicles with kinematic constraints. Piecewise linear continuous-curvature paths composed of clothoids, circular arcs, and straight lines are used for this purpose. Low curvature derivatives provide comfort to passengers. This approach provides a compact road network representation as only the parameters of the curves are stored. A real urban scenario with straight and curved roads, multiple lanes, intersections, and roundabouts is modeled and the proposed approach is validated. As a result of the proposed approaches, door-to-door global continuous-curvature paths are generated considering the shortest traveled distance.
ER  - 

TY  - CONF
TI  - Surface-Based Exploration for Autonomous 3D Modeling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4319
EP  - 4326
AU  - S. Song
AU  - S. Jo
PY  - 2018
KW  - mobile robots
KW  - path planning
KW  - solid modelling
KW  - surface reconstruction
KW  - 3D models
KW  - exploration algorithm
KW  - autonomous 3D modeling
KW  - path planning problem
KW  - exploration path
KW  - low-confidence surfaces
KW  - reconstructed surfaces
KW  - volumetric model
KW  - volumetric map
KW  - mobile robot
KW  - Surface reconstruction
KW  - Computational modeling
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Inspection
KW  - Mobile robots
KW  - Solid modeling
DO  - 10.1109/ICRA.2018.8460862
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this study, we addressed a path planning problem of a mobile robot to construct highly accurate 3D models of an unknown environment. Most studies have focused on exploration approaches, which find the most informative viewpoint or trajectories by analyzing a volumetric map. However, the completion of a volumetric map does not necessarily describe the completion of a 3D model. A highly complicated structure sometimes cannot be represented as a volumetric model. We propose a novel exploration algorithm that considers not only a volumetric map but also reconstructed surfaces. Unlike previous approaches, we evaluate the model completeness according to the quality of the reconstructed surfaces and extract low-confidence surfaces. The surface information is used to guide the computation of the exploration path. Experimental results showed that the proposed algorithm performed better than other state-of-the-art exploration methods and especially improved the completeness and confidence of the 3D models.
ER  - 

TY  - CONF
TI  - Departure and Conflict Management in Multi-Robot Path Coordination
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4327
EP  - 4333
AU  - P. Lertkultanon
AU  - J. Yang
AU  - H. Pham
AU  - Q. Pham
PY  - 2018
KW  - aircraft control
KW  - airports
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - automatic aircraft taxiing coordination
KW  - driver-less cars coordination
KW  - no-backward-movement constraint
KW  - complex conflict situations
KW  - Charles de Gaulle airport
KW  - multirobot path coordination
KW  - Robot kinematics
KW  - Planning
KW  - Aircraft
KW  - Collision avoidance
KW  - Airports
KW  - Automobiles
DO  - 10.1109/ICRA.2018.8460587
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper addresses the problem of multi-robot path coordination, considering specific features that arise in applications such as automatic aircraft taxiing or driver-less cars coordination. The first feature is departure events: when robots arrive at their destinations (e.g. the runway for takeoff), they can be removed from the coordination diagram. The second feature is the “no-backward-movement” constraint: the robots can only move forward on their assigned paths. These features can interact to give rise to complex conflict situations, which existing planners are unable to solve in practical time. We propose a set of algorithms to efficiently account for these features and validate these algorithms on a realistic model of Charles de Gaulle airport.
ER  - 

TY  - CONF
TI  - A Single-Planner Approach to Multi-Modal Humanoid Mobility
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4334
EP  - 4341
AU  - A. Dornbush
AU  - K. Vijayakumar
AU  - S. Bardapurkar
AU  - F. Islam
AU  - M. Ito
AU  - M. Likhachev
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - path planning
KW  - planning (artificial intelligence)
KW  - search problems
KW  - planning efforts
KW  - planning process
KW  - single-planner approach
KW  - multimodal humanoid mobility
KW  - configuration space
KW  - humanoid robot
KW  - single search process
KW  - search spaces
KW  - adaptive dimensionality
KW  - Planning
KW  - Task analysis
KW  - Aerospace electronics
KW  - Legged locomotion
KW  - Superluminescent diodes
KW  - Humanoid robots
DO  - 10.1109/ICRA.2018.8461134
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we present an approach to planning for humanoid mobility. Humanoid mobility is a challenging problem, as the configuration space for a humanoid robot is intractably large, especially if the robot is capable of performing many types of locomotion. For example, a humanoid robot may be able to perform such tasks as bipedal walking, crawling, and climbing. Our approach is to plan for all these tasks within a single search process. This allows the search to reason about all the capabilities of the robot at any point, and to derive the complete solution such that the plan is guaranteed to be feasible. A key observation is that we often can roughly decompose a mobility task into a sequence of smaller tasks, and focus planning efforts to reason over much smaller search spaces. To this end, we leverage the results of a recently developed framework for planning with adaptive dimensionality, and incorporate the capabilities of available controllers directly into the planning process. The resulting planner can also be run in an interleaved fashion alongside execution so that time spent idle is much reduced.
ER  - 

TY  - CONF
TI  - Information Based Mobile Sensor Planning for Source Term Estimation of a Non-Continuous Atmospheric Release
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4342
EP  - 4347
AU  - M. Hutchinson
AU  - C. Liu
AU  - W. Chen
PY  - 2018
KW  - air pollution
KW  - atmospheric chemistry
KW  - atmospheric techniques
KW  - Bayes methods
KW  - chemical sensors
KW  - disperse systems
KW  - hazardous materials
KW  - inverse problems
KW  - mobile sensor planning
KW  - Bayes' theorem
KW  - static sensors
KW  - single mobile sensor
KW  - chemical sensor
KW  - dispersion parameters
KW  - Gaussian puff dispersion model
KW  - meteorological information
KW  - inverse problem
KW  - hazardous material
KW  - noncontinuous atmospheric release
KW  - source term estimation
KW  - Robot sensing systems
KW  - Dispersion
KW  - Atmospheric modeling
KW  - Unmanned aerial vehicles
KW  - Position measurement
KW  - Wind speed
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8460686
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Ahstract- This paper presents a method to estimate the original location and the mass of an instantaneous release of hazardous material into the atmosphere. It is formulated as an inverse problem, where concentration observations from a mobile sensor are fused with meteorological information and a Gaussian puff dispersion model to characterise the source. Bayes' theorem is used to estimate the parameters of the release taking into account the uncertainty that exists in the dispersion parameters and meteorological variables. An information based reward is used to guide an unmanned aerial vehicle equipped with a chemical sensor to the expected most informative measurement locations. Simulation results compare the performance between a single mobile sensor with various amounts of static sensors.
ER  - 

TY  - CONF
TI  - Collision-Free Motion Planning for Human-Robot Collaborative Safety Under Cartesian Constraint
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4348
EP  - 4354
AU  - J. Chen
AU  - K. Song
PY  - 2018
KW  - collision avoidance
KW  - control system synthesis
KW  - end effectors
KW  - human-robot interaction
KW  - image segmentation
KW  - Kalman filters
KW  - nearest neighbour methods
KW  - robot vision
KW  - human-robot collaborative safety
KW  - Cartesian constraint
KW  - real-time motion planning
KW  - control design
KW  - robotic arm
KW  - multiple KinectV2 depth cameras
KW  - robot workspace
KW  - collision avoidance
KW  - robot end effector
KW  - collision-free motion planning method
KW  - 6-DOF robot arm
KW  - Kalman filter
KW  - K-nearest neighbor searching algorithm
KW  - K-nearest neighbor searching algorithm
KW  - Robots
KW  - Collision avoidance
KW  - Force
KW  - Planning
KW  - Three-dimensional displays
KW  - Collaboration
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460185
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a real-time motion planning and control design of a robotic arm for human-robot collaborative safety. A novel collision-free motion planning method is proposed not only to keep robot body from colliding with objects but also preserve the execution of robot's original task under the Cartesian constraint of the environment. Multiple KinectV2 depth cameras are utilized to model and track dynamic obstacles (e.g. Humans and objects) inside the robot workspace. Depth images are applied to generate point cloud of segmented objects in the environment. A K-nearest neighbor (KNN) searching algorithm is used to cluster and find the closest point from the obstacle to the robot. Then a Kalman filter is applied to estimate the obstacle position and velocity. For the collision avoidance in collaborative operation, attractive and repulsive potential is generated for robot end effector based on the task specification and obstacle observation. Practical experiments show that the 6-DOF robot arm can effectively avoid an obstacle in a constrained environment and complete the original task.
ER  - 

TY  - CONF
TI  - Sampling-Based Motion Planning with μ-Calculus Specifications Without Steering
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4355
EP  - 4360
AU  - L. Larocque
AU  - J. Liu
PY  - 2018
KW  - boundary-value problems
KW  - feedback
KW  - formal verification
KW  - linear quadratic control
KW  - motion control
KW  - path planning
KW  - probability
KW  - sampling methods
KW  - temporal logic
KW  - sampling-based motion planning
KW  - temporal logic specifications
KW  - linear dynamics
KW  - two-point boundary value problem
KW  - asymptotically optimal planning algorithm SST
KW  - local deterministic μ-calculus model
KW  - motion planning algorithm
KW  - deterministic μ-calculus specifications
KW  - multiple Kripke structures
KW  - abstracted Kripke structure
KW  - state-space
KW  - linear-quadratic regulator feedback control policy
KW  - complex liveness specification
KW  - steering function
KW  - kinodynamic planning algorithm SST
KW  - LQR feedback control policy
KW  - Calculus
KW  - Planning
KW  - Model checking
KW  - Trajectory
KW  - Reactive power
KW  - Lattices
DO  - 10.1109/ICRA.2018.8460769
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - While using temporal logic specifications with motion planning has been heavily researched, the reliance on having an available steering function is impractical and often suited only to basic problems with linear dynamics. This is because a steering function is a solution to an optimal two-point boundary value problem (OBVP); to our knowledge, it is nearly impossible to find an analytic solution to such problems in many cases. Addressing this issue, we have developed a means of combining the asymptotically optimal and probabilistically complete kinodynamic planning algorithm SST* with a local deterministic μ-calculus model checking procedure to create a motion planning algorithm with deterministic μ-calculus specifications that does not rely on a steering function. The procedure involves combining only the most pertinent information from multiple Kripke structures in order to create one abstracted Kripke structure storing the best paths to all possible proposition regions of the state-space. A linear-quadratic regulator (LQR) feedback control policy is then used to track these best paths, effectively connecting the trajectories found from multiple Kripke structures. Simulations demonstrate that it is possible to satisfy a complex liveness specification for infinitely often reaching specified regions of state-space using only forward propagation.
ER  - 

TY  - CONF
TI  - Generating Vibration Free Rest-to-Rest Trajectories for Configuration Dependent Dynamic Systems via 3-Segmented Input Shaping
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4361
EP  - 4366
AU  - D. K. Thomsen
AU  - R. S. Knudsen
AU  - D. Brandt
AU  - O. Balling
AU  - X. Zhang
PY  - 2018
KW  - bang-bang control
KW  - path planning
KW  - position control
KW  - configuration dependent dynamics
KW  - vibration-free RTR trajectory generation
KW  - bang-coast-bang trajectory
KW  - system dynamics
KW  - piece wise shaping
KW  - trajectory segmentation strategy
KW  - 3-Segmented Input Shaping
KW  - configuration dependent dynamic systems
KW  - free rest-to-rest trajectories
KW  - Trajectory
KW  - Vibrations
KW  - Acceleration
KW  - Motion segmentation
KW  - System dynamics
KW  - Numerical simulation
DO  - 10.1109/ICRA.2018.8460865
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a new method to generate vibration free rest-to-rest (RTR) trajectories for configuration dependent dynamic systems, such as robots, cranes or machine tools. The new method named 3-Segmented Input Shaping is based on a combination of the widely known Input Shaping method and a new trajectory segmentation strategy for piece wise shaping of the trajectory. The new segmentation strategy facilitates the capability of accounting for variations in system dynamics during motion by shaping acceleration and deceleration profiles with individual frequencies. In this paper the new segmentation strategy is used in combination with the bang-coast-bang (BCB) trajectory. The generated trajectories are described in closed form, hence requires no optimization and thereby provides strong computational performance. The new method is verified by numerical simulations and detailed analysis and shows great potential in vibration-free RTR trajectory generation for systems with configuration dependent dynamics.
ER  - 

TY  - CONF
TI  - A Model-Based Hierarchical Controller for Legged Systems Subject to External Disturbances
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4375
EP  - 4382
AU  - G. Xin
AU  - H. Lin
AU  - J. Smith
AU  - O. Cebe
AU  - M. Mistry
PY  - 2018
KW  - control system synthesis
KW  - force control
KW  - legged locomotion
KW  - motion control
KW  - position control
KW  - robot dynamics
KW  - robot kinematics
KW  - robust control
KW  - model-based hierarchical controller
KW  - model-based controller
KW  - projected inverse dynamics controller
KW  - control law
KW  - constrained space controller
KW  - unknown external disturbances
KW  - impedance controller
KW  - legged systems
KW  - unconstrained component
KW  - contact forces
KW  - force sensors
KW  - torque sensors
KW  - ANYmal quadruped platform
KW  - contact locations
KW  - legged robots
KW  - Task analysis
KW  - Force
KW  - Legged locomotion
KW  - Aerospace electronics
KW  - Dynamics
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2018.8461172
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Legged robots have many potential applications in real-world scenarios where the tasks are too dangerous for humans, and compliance is needed to protect the system against external disturbances and impacts. In this paper, we propose a model-based controller for hierarchical tasks of legged systems subject to external disturbance. The control framework is based on projected inverse dynamics controller, such that the control law is decomposed into two orthogonal subspaces, i.e., the constrained and the unconstrained subspaces. The unconstrained component controls multiple desired tasks with impedance responses. The constrained space controller maintains the contact subject to unknown external disturbances, without the use of any force/torque sensing at the contact points. By explicitly modelling the external force, our controller is robust to external disturbances and errors arising from incorrect dynamic model information. The main contributions of this paper include (1) incorporating an impedance controller to control external disturbances and allow impedance shaping to adjust the behaviour of the motion under external disturbances, (2) optimising contact forces within the constrained subspace that also takes into account the external disturbances without using force/torque sensors at the contact locations. The techniques are evaluated on the ANYmal quadruped platform under a variety of scenarios.
ER  - 

TY  - CONF
TI  - Fore-Aft Leg Specialization Controller for a Dynamic Quadruped
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4383
EP  - 4390
AU  - J. M. Brown
AU  - C. P. Carbiener
AU  - J. Nicholson
AU  - N. Hemenway
AU  - J. L. Pusey
AU  - J. E. Clark
PY  - 2018
KW  - legged locomotion
KW  - robot dynamics
KW  - trajectory control
KW  - fore-aft leg specialization controller
KW  - running animals
KW  - robotic counterparts
KW  - functional dynamic decomposition
KW  - Dynamic Quadruped
KW  - trajectory-based controller
KW  - Legged locomotion
KW  - Trajectory
KW  - Force
KW  - Springs
KW  - Vehicle dynamics
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8460763
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Many running animals, unlike their robotic counterparts, have distinct morphologies and functional roles for their front and rear legs. In this paper we present a new control approach for a 5kg autonomous dynamic quadruped that explicitly encodes separate roles for each contralateral pair of legs. This controller utilizes a functional dynamic decomposition similar to Raibert's three part control law, but focuses on fore-aft leg specialization to regulate the robot's performance. The velocity of this controller, which exceeds 5 body lengths per sec, is compared with an improved trajectory-based controller and shown to be significantly more robust to changes in environment.
ER  - 

TY  - CONF
TI  - Contact Model Fusion for Event-Based Locomotion in Unstructured Terrains
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4399
EP  - 4406
AU  - G. Bledt
AU  - P. M. Wensing
AU  - S. Ingersoll
AU  - S. Kim
PY  - 2018
KW  - discrete time systems
KW  - finite state machines
KW  - force control
KW  - Kalman filters
KW  - legged locomotion
KW  - motion control
KW  - observers
KW  - robot dynamics
KW  - robot kinematics
KW  - robust control
KW  - contact detection
KW  - contact state estimation
KW  - MIT Cheetah 3 robot
KW  - dynamic modeling
KW  - kinematic
KW  - Event-Based Finite State Machine
KW  - Kalman Filtering
KW  - contact priors
KW  - proprioceptive force control estimates
KW  - generalized-momentum disturbance observer
KW  - discrete-time extension
KW  - contact initiation
KW  - terrain geometry
KW  - contact models
KW  - contact transitions
KW  - unstructured environments
KW  - legged robots
KW  - unstructured terrains
KW  - event-based locomotion
KW  - contact model fusion
KW  - time 4.0 ms to 5.0 ms
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Force
KW  - Disturbance observers
KW  - Robustness
DO  - 10.1109/ICRA.2018.8460904
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - As legged robots are sent into unstructured environments, the ability to robustly manage contact transitions will be a critical skill. This paper introduces an approach to probabilistically fuse contact models, managing uncertainty in terrain geometry, dynamic modeling, and kinematics to improve the robustness of contact initiation at touchdown. A discrete-time extension of the generalized-momentum disturbance observer is presented to increase the accuracy of proprioceptive force control estimates. This information is fused with other contact priors under a framework of Kalman Filtering to increase robustness of the method. This approach results in accurate contact detection with 99.3 % accuracy and a small 4-5ms delay. Using this new detector, an Event-Based Finite State Machine is implemented to deal with unexpected early and late contacts. This allows the robot to traverse cluttered environments by modifying the control actions for each individual leg based on the estimated contact state rather than adhering to a rigid time schedule regardless of actual contact state. Experiments with the MIT Cheetah 3 robot show the success of both the detection algorithm, as well as the Event-Based FSM while making unexpected contacts during trotting.
ER  - 

TY  - CONF
TI  - Single-Image Footstep Prediction for Versatile Legged Locomotion
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4407
EP  - 4413
AU  - W. Zhang
AU  - K. Hauser
PY  - 2018
KW  - convolution
KW  - feedforward neural nets
KW  - image colour analysis
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - path planning
KW  - prediction theory
KW  - robot kinematics
KW  - sensors
KW  - versatile legged locomotion
KW  - robots
KW  - longterm routes
KW  - horizontal terrain
KW  - vertical terrain
KW  - onboard sensors
KW  - vantage points
KW  - strongly foreshortened images
KW  - terrain features
KW  - viewing angle
KW  - convolutional neural network method
KW  - arbitrary tilt angles
KW  - route planner
KW  - plausible plans
KW  - rock climbing gyms
KW  - walking robots
KW  - climbing robots
KW  - single image footstep prediction
KW  - distance angle
KW  - valid handhold prediction
KW  - foothold locations prediction
KW  - single RGB+D images
KW  - learning techniques
KW  - flat ground
KW  - stairs
KW  - walls
KW  - Cameras
KW  - Legged locomotion
KW  - Planning
KW  - Robot kinematics
KW  - Three-dimensional displays
KW  - Rocks
DO  - 10.1109/ICRA.2018.8460999
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Walking and climbing robots need to plan longterm routes on both horizontal and vertical terrain, but onboard sensors take images from vantage points that provide strongly foreshortened images that cause the appearance of terrain features to vary greatly by distance and viewing angle. This paper presents a convolutional neural network (CNN) method for predicting valid handhold and foothold locations from single RGB+D images taken at arbitrary tilt angles. Experiments show that the method predicts holds more accurately than comparable learning techniques, and that a route planner based on these predictions generates plausible plans for flat ground, stairs, and walls in rock climbing gyms.
ER  - 

TY  - CONF
TI  - Legged Robot State-Estimation Through Combined Forward Kinematic and Preintegrated Contact Factors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4422
EP  - 4429
AU  - R. Hartley
AU  - J. Mangelson
AU  - L. Gan
AU  - M. Ghaffari Jadidi
AU  - J. M. Walls
AU  - R. M. Eustice
AU  - J. W. Grizzle
PY  - 2018
KW  - graph theory
KW  - legged locomotion
KW  - object tracking
KW  - optimisation
KW  - robot kinematics
KW  - robot vision
KW  - state estimation
KW  - robotic perception systems
KW  - robot state-estimation
KW  - Agility Robotics
KW  - Cassie-series robot
KW  - forward kinematic factor
KW  - factor graph framework
KW  - preintegrated contact factor
KW  - kinematic factors
KW  - legged robots
KW  - state-estimation technique
KW  - visual tracking
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Kinematics
KW  - Optimization
KW  - Foot
KW  - Cameras
DO  - 10.1109/ICRA.2018.8460748
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - State-of-the-art robotic perception systems have achieved sufficiently good performance using Inertial Measurement Units (IMUs), cameras, and nonlinear optimization techniques, that they are now being deployed as technologies. However, many of these methods rely significantly on vision and often fail when visual tracking is lost due to lighting or scarcity of features. This paper presents a state-estimation technique for legged robots that takes into account the robot's kinematic model as well as its contact with the environment. We introduce forward kinematic factors and preintegrated contact factors into a factor graph framework that can be incrementally solved in real-time. The forward kinematic factor relates the robot's base pose to a contact frame through noisy encoder measurements. The preintegrated contact factor provides odometry measurements of this contact frame while accounting for possible foot slippage. Together, the two developed factors constrain the graph optimization problem allowing the robot's trajectory to be estimated. The paper evaluates the method using simulated and real sensory IMU and kinematic data from experiments with a Cassie-series robot designed by Agility Robotics. These preliminary experiments show that using the proposed method in addition to IMU decreases drift and improves localization accuracy, suggesting that its use can enable successful recovery from a loss of visual tracking.
ER  - 

TY  - CONF
TI  - Learning to Parse Natural Language to Grounded Reward Functions with Weak Supervision
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4430
EP  - 4436
AU  - E. C. Williams
AU  - N. Gopalan
AU  - M. Rhee
AU  - S. Tellex
PY  - 2018
KW  - grammars
KW  - lambda calculus
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - robots
KW  - trees (mathematics)
KW  - parse weights
KW  - validation-driven perceptron weight updates
KW  - goal-condition learning approach
KW  - grounded reward functions
KW  - language representations
KW  - weighted linear Combinatory Categorial Grammar semantic parser
KW  - CCG lexicon
KW  - parse trees
KW  - robot behaviors
KW  - Cleanup World domain
KW  - natural language parsing
KW  - goal-state reward functions
KW  - lambda calculus
KW  - Natural languages
KW  - Semantics
KW  - Task analysis
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Navigation
DO  - 10.1109/ICRA.2018.8460937
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In order to intuitively and efficiently collaborate with humans, robots must learn to complete tasks specified using natural language. We represent natural language instructions as goal-state reward functions specified using lambda calculus. Using reward functions as language representations allows robots to plan efficiently in stochastic environments. To map sentences to such reward functions, we learn a weighted linear Combinatory Categorial Grammar (CCG) semantic parser. The parser, including both parameters and the CCG lexicon, is learned from a validation procedure that does not require execution of a planner, annotating reward functions, or labeling parse trees, unlike prior approaches. To learn a CCG lexicon and parse weights, we use coarse lexical generation and validation-driven perceptron weight updates using the approach of Artzi and Zettlemoyer [4]. We present results on the Cleanup World domain [18] to demonstrate the potential of our approach. We report an F1 score of 0.82 on a collected corpus of 23 tasks containing combinations of nested referential expressions, comparators and object properties with 2037 corresponding sentences. Our goal-condition learning approach enables an improvement of orders of magnitude in computation time over a baseline that performs planning during learning, while achieving comparable results. Further, we conduct an experiment with just 6 labeled demonstrations to show the ease of teaching a robot behaviors using our method. We show that parsing models learned from small data sets can generalize to commands not seen during training.
ER  - 

TY  - CONF
TI  - Deep Haptic Model Predictive Control for Robot-Assisted Dressing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4437
EP  - 4444
AU  - Z. Erickson
AU  - H. M. Clever
AU  - G. Turk
AU  - C. K. Liu
AU  - C. C. Kemp
PY  - 2018
KW  - assisted living
KW  - clothing
KW  - control engineering computing
KW  - end effectors
KW  - handicapped aids
KW  - haptic interfaces
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - optimal control
KW  - predictive control
KW  - service robots
KW  - physical human-robot interaction
KW  - people with disabilities
KW  - controller objective function
KW  - deep predictive model
KW  - prediction horizon
KW  - PR2 robot
KW  - physics-based simulation
KW  - dressing assistance
KW  - garment
KW  - deep recurrent model
KW  - nonrigid garments
KW  - physical implications
KW  - robot-assisted dressing
KW  - deep haptic model predictive control
KW  - Robot sensing systems
KW  - Haptic interfaces
KW  - End effectors
KW  - Clothing
KW  - Predictive models
DO  - 10.1109/ICRA.2018.8460656
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robot-assisted dressing offers an opportunity to benefit the lives of many people with disabilities, such as some older adults. However, robots currently lack common sense about the physical implications of their actions on people. The physical implications of dressing are complicated by non-rigid garments, which can result in a robot indirectly applying high forces to a person's body. We present a deep recurrent model that, when given a proposed action by the robot, predicts the forces a garment will apply to a person's body. We also show that a robot can provide better dressing assistance by using this model with model predictive control. The predictions made by our model only use haptic and kinematic observations from the robot's end effector, which are readily attainable. Collecting training data from real world physical human-robot interaction can be time consuming, costly, and put people at risk. Instead, we train our predictive model using data collected in an entirely self-supervised fashion from a physics-based simulation. We evaluated our approach with a PR2 robot that attempted to pull a hospital gown onto the arms of 10 human participants. With a 0.2s prediction horizon, our controller succeeded at high rates and lowered applied force while navigating the garment around a persons fist and elbow without getting caught. Shorter prediction horizons resulted in significantly reduced performance with the sleeve catching on the participants' fists and elbows, demonstrating the value of our model's predictions. These behaviors of mitigating catches emerged from our deep predictive model and the controller objective function, which primarily penalizes high forces.
ER  - 

TY  - CONF
TI  - EmoRL: Continuous Acoustic Emotion Classification Using Deep Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4445
EP  - 4450
AU  - E. Lakomkin
AU  - M. A. Zamani
AU  - C. Weber
AU  - S. Magg
AU  - S. Wermter
PY  - 2018
KW  - acoustic signal processing
KW  - emotion recognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - EmoRL model
KW  - audio signal
KW  - continuous acoustic emotion classification
KW  - deep reinforcement learning
KW  - acoustically expressed emotions
KW  - deep neural network-based models
KW  - affective state evaluation
KW  - real-time communication scenario
KW  - human-robot interaction
KW  - Acoustics
KW  - Robots
KW  - Adaptation models
KW  - Logic gates
KW  - Feature extraction
KW  - Predictive models
KW  - Recurrent neural networks
DO  - 10.1109/ICRA.2018.8461058
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Acoustically expressed emotions can make communication with a robot more efficient. Detecting emotions like anger could provide a clue for the robot indicating unsafe/undesired situations. Recently, several deep neural network-based models have been proposed which establish new state-of-the-art results in affective state evaluation. These models typically start processing at the end of each utterance, which not only requires a mechanism to detect the end of an utterance but also makes it difficult to use them in a real-time communication scenario, e.g. human-robot interaction. We propose the EmoRL model that triggers an emotion classification as soon as it gains enough confidence while listening to a person speaking. As a result, we minimize the need for segmenting the audio signal for classification and achieve lower latency as the audio signal is processed incrementally. The method is competitive with the accuracy of a strong baseline model, while allowing much earlier prediction.
ER  - 

TY  - CONF
TI  - Temporal Spatial Inverse Semantics for Robots Communicating with Humans
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4451
EP  - 4458
AU  - Z. Gong
AU  - Y. Zhang
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - natural language processing
KW  - Amazon MTurk
KW  - TeSIS
KW  - natural language sentences
KW  - extended sentence structure
KW  - spatial context information
KW  - human listeners
KW  - temporal spatial inverse semantics
KW  - temporal context
KW  - Semantics
KW  - Grounding
KW  - Pallets
KW  - Natural languages
KW  - Tires
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460754
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Effective communication between humans often embeds both temporal and spatial context. While spatial context captures the geographic settings of objects in the environment, temporal context describes their changes over time. In this paper, we propose temporal spatial inverse semantics (TeSIS) to extend the inverse semantics approach to also consider the temporal context for robots communicating with humans. Inverse semantics generates natural language requests while taking into account how well the human listeners would interpret those requests given the current spatial context. Compared to inverse semantics, our approach incorporates also temporal context by referring to spatial context information in the past. To achieve this, we extend the sentence structure in inverse semantics to generate sentences that can refer to not only the current but also previous states of the environment. A new metric based on the extended sentence structure is developed by breaking a single sentence into multiple independent sentences that refer to environment states at different times. Using this approach, we are able to generate sentences such as “Please pick up the cup beside the oven that was on the dining table”. To evaluate our approach, we randomly generate scenarios in an experimental domain. Each scenario includes the description of the current and several immediate previous states. Natural language sentences are then generated for these scenarios using both inverse semantics that uses only the spatial context and our approach. Amazon MTurk is used to compare the sentences generated and results show that TeSIS achieves better accuracy, sometimes by a significant margin, than the baseline.
ER  - 

TY  - CONF
TI  - Brain-Computer Interface Meets ROS: A Robotic Approach to Mentally Drive Telepresence Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4459
EP  - 4464
AU  - G. Beraldo
AU  - M. Antonello
AU  - A. Cimolato
AU  - E. Menegatti
AU  - L. Tonin
PY  - 2018
KW  - brain
KW  - brain-computer interfaces
KW  - collision avoidance
KW  - control engineering computing
KW  - geriatrics
KW  - handicapped aids
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - medical signal processing
KW  - mobile robots
KW  - operating systems (computers)
KW  - patient rehabilitation
KW  - position control
KW  - robot programming
KW  - telerobotics
KW  - video streaming
KW  - noninvasive Brain-Computer Interface
KW  - Robot Operating System
KW  - telepresence robot
KW  - mobile device
KW  - human brain signals
KW  - severe physical disabilities
KW  - elderly people
KW  - BCI user
KW  - robot position control
KW  - obstacle avoidance
KW  - video streaming
KW  - Navigation
KW  - Robot sensing systems
KW  - Task analysis
KW  - Telepresence
KW  - Brain-computer interfaces
DO  - 10.1109/ICRA.2018.8460578
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper shows and evaluates a novel approach to integrate a non-invasive Brain-Computer Interface (BCI) with the Robot Operating System (ROS) to mentally drive a telepresence robot. Controlling a mobile device by using human brain signals might improve the quality of life of people suffering from severe physical disabilities or elderly people who cannot move anymore. Thus, the BCI user can actively interact with relatives and friends located in different rooms thanks to a video streaming connection to the robot. To facilitate the control of the robot via BCI, we explore new ROS-based algorithms for navigation and obstacle avoidance in order to make the system safer and more reliable. In this regard, the robot exploits two maps of the environment, one for localization and one for navigation, and both are used as additional visual feedback for the BCI user to control the robot position. Experimental results show a decrease of the number of commands needed to complete the navigation task, suggesting a reduction user's cognitive workload. The novelty of this work is to provide a first evidence of an integration between BCI and ROS that can simplify and foster the development of software for BCI driven robotics devices.
ER  - 

TY  - CONF
TI  - FaNeuRobot: A Framework for Robot and Prosthetics Control Using the NeuCube Spiking Neural Network Architecture and Finite Automata Theory
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4465
EP  - 4472
AU  - K. Kumarasinghe
AU  - M. Owen
AU  - D. Taylor
AU  - N. Kasabov
AU  - C. Kit
PY  - 2018
KW  - brain
KW  - brain-computer interfaces
KW  - electroencephalography
KW  - finite automata
KW  - handicapped aids
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - medical signal processing
KW  - muscle
KW  - neural nets
KW  - neurophysiology
KW  - brain-machine interface
KW  - central nervous system
KW  - biomedical signal
KW  - finite automata theory
KW  - NeuCube evolving spiking neural network architecture
KW  - robust prosthetic control
KW  - anthropomorphic mechanical design
KW  - noninvasive BMI
KW  - muscle atrophy
KW  - motor control framework
KW  - anthropomorphic design
KW  - prosthetic limbs
KW  - limb amputation
KW  - prosthetics control
KW  - Prosthetics
KW  - Muscles
KW  - Electroencephalography
KW  - DC motors
KW  - Grasping
KW  - Bones
KW  - Thumb
DO  - 10.1109/ICRA.2018.8460197
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Limb amputation is a global problem. Prosthetic limbs can enhance the quality of life of amputees. To this end, anthropomorphic design and intuitive manipulation are two essential requirements. This paper presents a motor control framework for prosthetic control through Brain-Machine Interface (BMI) using Finite Automata Theory, and NeuCube Evolving Spiking Neural Network (SNN) architecture. Voluntary control of prosthetics requires decoding motor commands from the Central Nervous System of the amputee. Selection of the most suitable biomedical signal depends on many parameters such as level of amputation and muscle atrophy. Non-invasive BMI's have the possibility of supporting a wider range of amputees as it extracts the motor commands from the brain. In this paper, we present a proof of concept study on whether a cognitive computational model that is inspired by the motor control of the human body through muscle synergies combined with an anthropomorphic mechanical design, can result in accurate and robust prosthetic control through a noninvasive BMI. In future, learning of a complex Finite Automata that reflects complex upper limb motor behaviours will be investigated.
ER  - 

TY  - CONF
TI  - Human in the Loop of Robot Learning: EEG-Based Reward Signal for Target Identification and Reaching Task
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4473
EP  - 4480
AU  - L. Schiatti
AU  - J. Tessadori
AU  - N. Deshpande
AU  - G. Barresi
AU  - L. C. King
AU  - L. S. Mattos
PY  - 2018
KW  - brain
KW  - control engineering computing
KW  - electroencephalography
KW  - human-robot interaction
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - target reaching task
KW  - assistive technologies
KW  - shared control
KW  - intelligent robotic device
KW  - electrophysiological measures
KW  - error detection
KW  - Error-related Potentials
KW  - semiautonomous system
KW  - online robot learning task
KW  - detected ErrP
KW  - robot learning loop
KW  - optimal policy learning
KW  - shared autonomy
KW  - reinforcement learning framework
KW  - Electroencephalography
KW  - Training
KW  - Graphical user interfaces
KW  - Microsoft Windows
KW  - Testing
KW  - Robot learning
DO  - 10.1109/ICRA.2018.8460551
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Shared control and shared autonomy play an important role in assistive technologies, allowing the offloading of the cognitive burden required for control from the user to the intelligent robotic device. In this context, electrophysiological measures of error detection, directly measured from a person's brain activity as Error-related Potentials (ErrPs), can be exploited to provide passive adaptation of an external semi-autonomous system to the human. This concept was implemented in an online robot learning task, where user's evaluation of the robot's actions, in terms of detected ErrP, was exploited to update a reward function in a Reinforcement Learning (RL) framework. Results from both simulated and experimental studies show that the introduction of human evaluation in the robot learning loop allows for: (1) the acceleration of optimal policy learning in a target reaching task, (2) the introduction of a further degree of control in robot learning, namely identification of one among multiple targets, according to the user's will. Overall, presented results support the potential of human-robot co-adaptive and co-operative strategies to develop human-centered assistive technologies.
ER  - 

TY  - CONF
TI  - Incremental Adversarial Domain Adaptation for Continually Changing Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4489
EP  - 4495
AU  - M. Wulfmeier
AU  - A. Bewley
AU  - I. Posner
PY  - 2018
KW  - feature extraction
KW  - image segmentation
KW  - unsupervised learning
KW  - machine learning models
KW  - robotics applications
KW  - alignment step
KW  - feature distribution
KW  - GAN training
KW  - continuous appearance shifts
KW  - continually changing environments
KW  - incremental adversarial domain adaptation
KW  - generative adversarial network
KW  - traversable-path segmentation task
KW  - unsupervised domain adaptation
KW  - Training
KW  - Task analysis
KW  - Adaptation models
KW  - Robots
KW  - Gallium nitride
KW  - Mathematical model
KW  - Lighting
DO  - 10.1109/ICRA.2018.8460982
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Continuous appearance shifts such as changes in weather and lighting conditions can impact the performance of deployed machine learning models. While unsupervised domain adaptation aims to address this challenge, current approaches do not utilise the continuity of the occurring shifts. In particular, many robotics applications exhibit these conditions and thus facilitate the potential to incrementally adapt a learnt model over minor shifts which integrate to massive differences over time. Our work presents an adversarial approach for lifelong, incremental domain adaptation which benefits from unsupervised alignment to a series of intermediate domains which successively diverge from the labelled source domain. We empirically demonstrate that our incremental approach improves handling of large appearance changes, e.g. day to night, on a traversable-path segmentation task compared with a direct, single alignment step approach. Furthermore, by approximating the feature distribution for the source domain with a generative adversarial network, the deployment module can be rendered fully independent of retaining potentially large amounts of the related source training data for only a minor reduction in performance.
ER  - 

TY  - CONF
TI  - DeepVP: Deep Learning for Vanishing Point Detection on 1 Million Street View Images
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4496
EP  - 4503
AU  - C. Chang
AU  - J. Zhao
AU  - L. Itti
PY  - 2018
KW  - cameras
KW  - convolution
KW  - edge detection
KW  - feedforward neural nets
KW  - image classification
KW  - learning (artificial intelligence)
KW  - object detection
KW  - algorithmic vanishing point detector
KW  - DeepVP
KW  - Google street view image dataset
KW  - camera parameters
KW  - deep learning
KW  - deep vanishing point system
KW  - CNN classification problem
KW  - inferred ground-truth vanishing points
KW  - convolutional neural network
KW  - vanishing point detection
KW  - Roads
KW  - Cameras
KW  - Google
KW  - Machine learning
KW  - Videos
KW  - Image segmentation
KW  - Computer architecture
DO  - 10.1109/ICRA.2018.8460499
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a novel approach to detect vanishing points in images using a convolutional neural network (CNN) trained on a newly collected Google street-view image dataset. By utilizing the camera parameters and road direction data from Google street view, we collected a total of 1,053,425 images with inferred ground-truth vanishing points, along 23 worldwide routes totaling 125,165 kilometers. We then formulate vanishing point detection as a CNN classification problem using an output layer with 225 discrete possible vanishing point locations. Experimental results show that our deep vanishing point system outperforms the state-of-the-art algorithmic vanishing point detector. We achieved 99% accuracy in recovering the horizon line and 92% in locating the vanishing point within a ±5-degree range.
ER  - 

TY  - CONF
TI  - Deep Lidar CNN to Understand the Dynamics of Moving Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4504
EP  - 4509
AU  - V. Vaquero
AU  - A. Sanfeliu
AU  - F. Moreno-Noguer
PY  - 2018
KW  - image colour analysis
KW  - image sensors
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - neural net architecture
KW  - optical radar
KW  - semantic networks
KW  - pretext tasks
KW  - test time
KW  - including distilled image information
KW  - standard image-based optical flow
KW  - novel lidar-flow feature
KW  - semantic information
KW  - image data
KW  - consecutive lidar scans
KW  - testing time
KW  - CNN architecture
KW  - external observed vehicles
KW  - observer vehicle
KW  - proprio-motion
KW  - autonomous cars
KW  - Deep Learning solutions
KW  - RGB images
KW  - semantically rich information
KW  - Autonomous Driving
KW  - perception technologies
KW  - Deep lidar CNN
KW  - Laser radar
KW  - Task analysis
KW  - Vehicle dynamics
KW  - Three-dimensional displays
KW  - Dynamics
KW  - Machine learning
KW  - Semantics
DO  - 10.1109/ICRA.2018.8460554
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Perception technologies in Autonomous Driving are experiencing their golden age due to the advances in Deep Learning. Yet, most of these systems rely on the semantically rich information of RGB images. Deep Learning solutions applied to the data of other sensors typically mounted on autonomous cars (e.g. lidars or radars) are not explored much. In this paper we propose a novel solution to understand the dynamics of moving vehicles of the scene from only lidar information. The main challenge of this problem stems from the fact that we need to disambiguate the proprio-motion of the “observer” vehicle from that of the external “observed” vehicles. For this purpose, we devise a CNN architecture which at testing time is fed with pairs of consecutive lidar scans. However, in order to properly learn the parameters of this network, during training we introduce a series of so-called pretext tasks which also leverage on image data. These tasks include semantic information about vehicleness and a novel lidar-flow feature which combines standard image-based optical flow with lidar scans. We obtain very promising results and show that including distilled image information only during training, allows improving the inference results of the network at test time, even when image data is no longer used.
ER  - 

TY  - CONF
TI  - Optimization Beyond the Convolution: Generalizing Spatial Relations with End-to-End Metric Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4510
EP  - 4516
AU  - P. Jund
AU  - A. Eitel
AU  - N. Abdo
AU  - W. Burgard
PY  - 2018
KW  - convolution
KW  - distance learning
KW  - feedforward neural nets
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - pose estimation
KW  - solid modelling
KW  - robots
KW  - arbitrary spatial relations
KW  - sizes
KW  - shapes
KW  - distance metric learning
KW  - 3D point clouds
KW  - metric space
KW  - object poses
KW  - arbitrary target relation
KW  - domestic environments
KW  - convolution
KW  - gradient based optimization
KW  - neural network
KW  - geometric models
KW  - continuous spectrum
KW  - end to end metric learning
KW  - Measurement
KW  - Three-dimensional displays
KW  - Robots
KW  - Optimization
KW  - Transforms
KW  - Shape
KW  - Convolution
DO  - 10.1109/ICRA.2018.8460220
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To operate intelligently in domestic environments, robots require the ability to understand arbitrary spatial relations between objects and to generalize them to objects of varying sizes and shapes. In this work, we present a novel end-to-end approach to generalize spatial relations based on distance metric learning. We train a neural network to transform 3D point clouds of objects to a metric space that captures the similarity of the depicted spatial relations, using only geometric models of the objects. Our approach employs gradient-based optimization to compute object poses in order to imitate an arbitrary target relation by reducing the distance to it under the learned metric. Our results based on simulated and real-world experiments show that the proposed method enables robots to generalize spatial relations to unknown objects over a continuous spectrum.
ER  - 

TY  - CONF
TI  - Constructing Category-Specific Models for Monocular Object-SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4517
EP  - 4524
AU  - P. Parkhiya
AU  - R. Khawad
AU  - J. K. Murthy
AU  - B. Bhowmick
AU  - K. M. Krishna
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - mobile robots
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - category-specific models
KW  - real-time object-oriented SLAM
KW  - monocular camera
KW  - object-level models
KW  - category-level models
KW  - object deformations
KW  - discriminative object features
KW  - category models
KW  - object landmark observations
KW  - generic monocular SLAM framework
KW  - 2D object features
KW  - sparse feature-based monocular SLAM
KW  - object instance retrieval
KW  - instance-independent monocular object-SLAM system
KW  - feature-based SLAM methods
KW  - time 2.0 d
KW  - time 3.0 d
KW  - Solid modeling
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Object oriented modeling
KW  - Pipelines
KW  - Two dimensional displays
KW  - Shape
DO  - 10.1109/ICRA.2018.8460816
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a new paradigm for real-time object-oriented SLAM with a monocular camera. Contrary to previous approaches, that rely on object-level models, we construct category-level models from CAD collections which are now widely available. To alleviate the need for huge amounts of labeled data, we develop a rendering pipeline that enables synthesis of large datasets from a limited amount of manually labeled data. Using data thus synthesized, we learn category-level models for object deformations in 3D, as well as discriminative object features in 2D. These category models are instance-independent and aid in the design of object landmark observations that can be incorporated into a generic monocular SLAM framework. Where typical object-SLAM approaches usually solve only for object and camera poses, we also estimate object shape on-the-fty, allowing for a wide range of objects from the category to be present in the scene. Moreover, since our 2D object features are learned discriminatively, the proposed object-SLAM system succeeds in several scenarios where sparse feature-based monocular SLAM fails due to insufficient features or parallax. Also, the proposed category-models help in object instance retrieval, useful for Augmented Reality (AR) applications. We evaluate the proposed framework on multiple challenging real-world scenes and show - to the best of our knowledge - first results of an instance-independent monocular object-SLAM system and the benefits it enjoys over feature-based SLAM methods.
ER  - 

TY  - CONF
TI  - DPDB-Net: Exploiting Dense Connections for Convolutional Encoders
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4525
EP  - 4531
AU  - G. L. Oliveira
AU  - W. Burgard
AU  - T. Brox
PY  - 2018
KW  - convolutional codes
KW  - decoding
KW  - image classification
KW  - image coding
KW  - image segmentation
KW  - neural net architecture
KW  - dense connections
KW  - Cam Vid dataset
KW  - Freiburg Forest dataset
KW  - convolutional encoders
KW  - multiple segmentation tasks
KW  - feature map explosion
KW  - residual network architecture
KW  - dense block
KW  - DPDB-Net
KW  - Dual-Path Dense-Block Network
KW  - encoder-decoder architectures
KW  - feature re-usage
KW  - dense networks
KW  - multiple classification tasks
KW  - feature exploration
KW  - densely connected networks
KW  - Decoding
KW  - Computer architecture
KW  - Semantics
KW  - Task analysis
KW  - Explosions
KW  - Image segmentation
KW  - Forestry
DO  - 10.1109/ICRA.2018.8461089
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Densely connected networks for classification enable feature exploration and result in state-of-the-art performance on multiple classification tasks. The alternative to dense networks is the residual network which enables feature re-usage. In this work, we combine these orthogonal concepts for encoder-decoder architectures, which we call Dual-Path Dense-Block Network (DPDB-Net). We introduce a dense block which incorporates feature re-usage and new feature exploration in the encoder. Moreover, we discuss that feature re-usage by the residual network architecture leads to a feature map explosion in the decoder and, thus, is not advantageous in this part of the network. We evaluated our proposed architecture in multiple segmentation tasks and report state-of-the-art performance on the Freiburg Forest dataset and competitive results on the Cam Vid dataset.
ER  - 

TY  - CONF
TI  - The Hands-Free Push-Cart: Autonomous Following in Front by Predicting User Trajectory Around Obstacles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4548
EP  - 4554
AU  - P. Nikdel
AU  - R. Shrestha
AU  - R. Vaughan
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - object detection
KW  - trajectory control
KW  - autonomous mobile robot
KW  - walking user
KW  - autonomous push-carts
KW  - multimodal person detection
KW  - human-motion model
KW  - obstacle mapper
KW  - human tracker
KW  - human motion model
KW  - robot motion planner
KW  - robot motion controller
KW  - industrial entertainment applications
KW  - domestic entertainment applications
KW  - hands-free push-cart
KW  - predicting user trajectory
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Cameras
KW  - Tracking
KW  - Trajectory
KW  - Predictive models
DO  - 10.1109/ICRA.2018.8461181
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper demonstrates an autonomous mobile robot that follows a walking user while staying ahead of them. Despite several useful applications for autonomous push-carts, this problem has received much less attention than the easier problem of following from behind. In contrast to previous work, we use multi-modal person detection and a human-motion model that considers obstacles to predict the future path of the user. We implement the system with a modular architecture of obstacle mapper, human tracker, human motion model, robot motion planner and robot motion controller. We report on the performance of the robot in real-world experiments. We believe that approaches to this largely overlooked problem could be useful in real industrial, domestic and entertainment applications in the near future.
ER  - 

TY  - CONF
TI  - Socially Constrained Tracking in Crowded Environments Using Shoulder Pose Estimates
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4555
EP  - 4562
AU  - A. Virgona
AU  - A. Alempijevic
AU  - T. Vidal-Calleja
PY  - 2018
KW  - object detection
KW  - object tracking
KW  - pose estimation
KW  - robot vision
KW  - inner city train station
KW  - robotic technologies
KW  - 2D pose
KW  - motion capture system
KW  - person tracking framework
KW  - human environments
KW  - shoulder pose estimates
KW  - crowded environments
KW  - pose errors
KW  - lab environment
KW  - Target tracking
KW  - Sensors
KW  - Cameras
KW  - Robustness
KW  - Task analysis
KW  - Head
DO  - 10.1109/ICRA.2018.8461030
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Detecting and tracking people is a key requirement in the development of robotic technologies intended to operate in human environments. In crowded environments such as train stations this task is particularly challenging due the high numbers of targets and frequent occlusions. In this paper we present a framework for detecting and tracking humans in such crowded environments in terms of 2D pose ( x, y, θ). The main contributions are a method for extracting pose from the most visible parts of the body in a crowd, the head and shoulders, and a tracker which leverages social constraints regarding peoples orientation, movement and proximity to one another, to improve robustness in this challenging environment. The framework is evaluated on two datasets: one captured in a lab environment with ground truth obtained using a motion capture system, and the other captured in a busy inner city train station. Pose errors are reported against the ground truth and the tracking results are then compared with a state-of-the-art person tracking framework.
ER  - 

TY  - CONF
TI  - Anticipating Many Futures: Online Human Motion Prediction and Generation for Human-Robot Interaction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4563
EP  - 4570
AU  - J. Bütepage
AU  - H. Kjellström
AU  - D. Kragic
PY  - 2018
KW  - human-robot interaction
KW  - image coding
KW  - image colour analysis
KW  - image motion analysis
KW  - image representation
KW  - probability
KW  - robot vision
KW  - motion patterns
KW  - kinematic cues
KW  - natural human motion
KW  - human-robot interaction
KW  - online human motion prediction
KW  - target prediction
KW  - RGB depth images
KW  - skeletal data
KW  - conditional variational autoencoder
KW  - time 300.0 ms to 500.0 ms
KW  - Trajectory
KW  - Task analysis
KW  - Robot kinematics
KW  - Predictive models
KW  - Computational modeling
KW  - Training data
DO  - 10.1109/ICRA.2018.8460651
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Fluent and safe interactions of humans and robots require both partners to anticipate the others' actions. The bottleneck of most methods is the lack of an accurate model of natural human motion. In this work, we present a conditional variational autoencoder that is trained to predict a window of future human motion given a window of past frames. Using skeletal data obtained from RGB depth images, we show how this unsupervised approach can be used for online motion prediction for up to 1660 ms. Additionally, we demonstrate online target prediction within the first 300-500 ms after motion onset without the use of target specific training data. The advantage of our probabilistic approach is the possibility to draw samples of possible future motion patterns. Finally, we investigate how movements and kinematic cues are represented on the learned low dimensional manifold.
ER  - 

TY  - CONF
TI  - Joint Long-Term Prediction of Human Motion Using a Planning-Based Social Force Approach
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4571
EP  - 4577
AU  - A. Rudenko
AU  - L. Palmieri
AU  - K. O. Arras
PY  - 2018
KW  - collision avoidance
KW  - Markov processes
KW  - mobile robots
KW  - motion control
KW  - multi-agent systems
KW  - multi-robot systems
KW  - random processes
KW  - stochastic processes
KW  - motion trajectories
KW  - planning-based approach
KW  - dynamic objects
KW  - planning-based social force approach
KW  - joint long-term prediction
KW  - individual agent velocities
KW  - social forces
KW  - weighted random walk algorithm
KW  - stochastic motion policies
KW  - long-term predictions
KW  - multiple agents
KW  - joint motion
KW  - local interactions
KW  - long-term human motion prediction
KW  - dynamic environments
KW  - intelligent vehicles
KW  - mobile robots
KW  - Trajectory
KW  - Prediction algorithms
KW  - Force
KW  - Predictive models
KW  - Planning
KW  - Stochastic processes
KW  - Robots
DO  - 10.1109/ICRA.2018.8460527
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The ability to perceive and predict future positions of dynamic objects is essential for mobile robots and intelligent vehicles in dynamic environments. In this paper, we present a novel planning-based approach for long-term human motion prediction that accounts for local interactions and can accurately predict joint motion of multiple agents. Long-term predictions are handled using an MDP formulation that computes a set of stochastic motion policies. To obtain distributions over future motion trajectories, we sample the policies with a weighted random walk algorithm in which each person is locally influenced by social forces from other nearby agents. Unlike related work, the algorithm is environment-aware, can account for individual agent velocities, requires no training phase and makes joint predictions for multiple agents. Experiments in simulation and with real data show that our method makes more accurate predictions than two state-of-the-art methods in terms of probabilistic and geometrical performance measures.
ER  - 

TY  - CONF
TI  - Negotiating with a Robot: Analysis of Regulatory Focus Behavior
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4578
EP  - 4594
AU  - A. Cruz-Maya
AU  - A. Tapus
PY  - 2018
KW  - control engineering computing
KW  - geriatrics
KW  - man-machine systems
KW  - psychology
KW  - robots
KW  - user interfaces
KW  - persuasive communication skills
KW  - social psychology theory
KW  - promotion behavior
KW  - prevention behavior
KW  - neutral behavior
KW  - companion robots
KW  - caregivers
KW  - elderly people
KW  - decisions taking
KW  - regulatory focus behavior
KW  - prevention focus
KW  - body gestures
KW  - negotiation scenario
KW  - Robots
KW  - Senior citizens
KW  - Psychology
KW  - Games
KW  - Speech recognition
KW  - Tracking
KW  - Human-robot interaction
DO  - 10.1109/ICRA.2018.8460611
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Companion robots are more and more taking the role of caregivers for elderly people. Elderly people sometimes take the advice given by their family members or caregivers as a criticism. In this context, persuasive communication skills could be helpful. A social psychology theory called Regulatory Focus states that people have one of two inclinations when taking decisions: Promotion or Prevention Focus. Also, based on these inclinations, people can be influenced by the way the message is sent, including the speed of the speech and the amplitude of body gestures. In this paper, we analyze the influence of Regulatory Focus on a negotiation scenario, using 3 conditions: (1) a robot with a promotion behavior, (2) a robot with a prevention behavior, and (3) a robot with a neutral behavior. Our results support the results found in the psychology literature related to Regulatory Focus, suggesting that Promotion participants were more influenced by the robot showing a Promotion based behavior. Moreover, Prevention participants were more relaxed on the condition with the robot showing a Prevention based behavior, and accepted the biggest concession between the initial and final offer.
ER  - 

TY  - CONF
TI  - Multi3: Multi-Sensory Perception System for Multi-Modal Child Interaction with Multiple Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4585
EP  - 4592
AU  - A. Tsiami
AU  - P. Koutras
AU  - N. Efthymiou
AU  - P. P. Filntisis
AU  - G. Potamianos
AU  - P. Maragos
PY  - 2018
KW  - computer games
KW  - control engineering computing
KW  - educational robots
KW  - gesture recognition
KW  - human-robot interaction
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - speech recognition
KW  - robotic platforms
KW  - child-robot interaction scenarios
KW  - Multi3
KW  - robotic sensory
KW  - perception capabilities
KW  - speech recognition modules
KW  - gesture recognition modules
KW  - modular multirobot architecture
KW  - action recognition modules
KW  - indoors interaction scenarios
KW  - child-robot interaction scene
KW  - multiple Kinect-based system
KW  - multiple robots
KW  - Multimodal child interaction
KW  - Multisensory perception system
KW  - Speech recognition
KW  - Trajectory
KW  - Robot sensing systems
KW  - Microphone arrays
DO  - 10.1109/ICRA.2018.8461210
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Child-robot interaction is an interdisciplinary research area that has been attracting growing interest, primarily focusing on edutainment applications. A crucial factor to the successful deployment and wide adoption of such applications remains the robust perception of the child's multi-modal actions, when interacting with the robot in a natural and untethered fashion. Since robotic sensory and perception capabilities are platform-dependent and most often rather limited, we propose a multiple Kinect-based system to perceive the child-robot interaction scene that is robot-independent and suitable for indoors interaction scenarios. The audio-visual input from the Kinect sensors is fed into speech, gesture, and action recognition modules, appropriately developed in this paper to address the challenging nature of child-robot interaction. For this purpose, data from multiple children are collected and used for module training or adaptation. Further, information from the multiple sensors is fused to enhance module performance. The perception system is integrated in a modular multi-robot architecture demonstrating its flexibility and scalability with different robotic platforms. The whole system, called Multi3, is evaluated, both objectively at the module level and subjectively in its entirety, under appropriate child-robot interaction scenarios containing several carefully designed games between children and robots.
ER  - 

TY  - CONF
TI  - Multi-Robot Coordination in Dynamic Environments Shared with Humans
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4593
EP  - 4600
AU  - Z. Talebpour
AU  - A. Martinoli
PY  - 2018
KW  - human-robot interaction
KW  - mobile robots
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - market-based framework
KW  - coordination mechanism
KW  - social costs
KW  - bid evaluations
KW  - realistic environment
KW  - human-aware navigation
KW  - human-agnostic planning
KW  - social constraints
KW  - multirobot coordination
KW  - dynamic environments
KW  - social human-populated environments
KW  - multirobot task allocation problem
KW  - static humans
KW  - moving humans
KW  - high-fidelity simulator
KW  - localization noise
KW  - static people
KW  - blocked passages
KW  - human-aware planning
KW  - human-agnostic navigation
KW  - robot experiments
KW  - MRTA metrics
KW  - Robot kinematics
KW  - Task analysis
KW  - Navigation
KW  - Planning
KW  - Resource management
KW  - Measurement
DO  - 10.1109/ICRA.2018.8460978
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work addresses multi-robot coordination in social human-populated environments using a market-based framework for solving the Multi-Robot Task Allocation (MRTA) problem. Humans are considered in the proposed coordination mechanism by means of accounting for social costs in bid evaluations and requesting collaboration in socially blocking situations. Initially, the effect of a realistic environment with varying number of static/moving humans on the behavior and performance of our method is studied through an extensive suite of experiments in a high-fidelity simulator. Results show that the total traveled distance and time are increased when humans are present in the environments. Localization noise is also increased particularly in the case of static people. In the second series of experiments, a number of problematic cases resulting in longer modified paths, blocked passages, and long waits have been investigated. A comparative study targeting human-agnostic navigation and planning, human-aware navigation and human-agnostic planning, and human-aware navigation and planning has been conducted. Both simulated and real robot experiments confirm the effectiveness of accounting for humans at both team and individual levels. This leads to respecting social constraints as well as achieving a better performance based on MRTA metrics.
ER  - 

TY  - CONF
TI  - Social Attention: Modeling Attention in Human Crowds
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4601
EP  - 4607
AU  - A. Vemula
AU  - K. Muelling
AU  - J. Oh
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - publicly available crowd datasets
KW  - trained attention model
KW  - Social Attention
KW  - human crowds
KW  - robots
KW  - human predictable trajectories
KW  - human trajectory prediction
KW  - Trajectory
KW  - Navigation
KW  - Predictive models
KW  - Robots
KW  - Collision avoidance
KW  - Dynamics
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460504
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robots that navigate through human crowds need to be able to plan safe, efficient, and human predictable trajectories. This is a particularly challenging problem as it requires the robot to predict future human trajectories within a crowd where everyone implicitly cooperates with each other to avoid collisions. Previous approaches to human trajectory prediction have modeled the interactions between humans as a function of proximity. However, that is not necessarily true as some people in our immediate vicinity moving in the same direction might not be as important as other people that are further away, but that might collide with us in the future. In this work, we propose Social Attention, a novel trajectory prediction model that captures the relative importance of each person when navigating in the crowd, irrespective of their proximity. We demonstrate the performance of our method against a state-of-the-art approach on two publicly available crowd datasets and analyze the trained attention model to gain a better understanding of which surrounding agents humans attend to, when navigating in a crowd.
ER  - 

TY  - CONF
TI  - Fully Convolutional Neural Networks for Road Detection with Multiple Cues Integration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4608
EP  - 4613
AU  - X. Han
AU  - J. Lu
AU  - C. Zhao
AU  - H. Li
PY  - 2018
KW  - convergence
KW  - convolution
KW  - feature extraction
KW  - feedforward neural nets
KW  - gradient methods
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optical radar
KW  - position control
KW  - convolutional neural networks
KW  - multiple cues integration
KW  - autonomous driving
KW  - deep learning
KW  - road detection algorithms
KW  - pre-trained Resnet-lOl
KW  - RGB images
KW  - CNN
KW  - feature maps extraction
KW  - Lidar scanner
KW  - position map
KW  - image gradient
KW  - convergence
KW  - KITTI benchmark
KW  - Roads
KW  - Feature extraction
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Fuses
KW  - Network architecture
DO  - 10.1109/ICRA.2018.8460663
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Road detection from images is a key task in autonomous driving. The recent advent of deep learning (and in particular, CNN or convolutional neural networks) has greatly improved the performance of road detection algorithms. In this paper, we show how to fuse multiple different cues under the same convolutional network framework. Specifically, we adopt a pre-trained Resnet-lOl to extract feature maps from RGB images; we then connect it with three extra deconvolution layers. These deconvolution layers is trained conditioning on appropriate image cues, and in our case they are a height image (i.e. elevation map obtained by e.g. Lidar scanner), image gradient, and position map. We also design two skip layers to speed up the convergence. Experiments on KITTI benchmark show competitive performance of our new networks.
ER  - 

TY  - CONF
TI  - A Visual-Inertial Approach to Human Gait Estimation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4614
EP  - 4621
AU  - A. Ahmed
AU  - S. Roumeliotis
PY  - 2018
KW  - cameras
KW  - gait analysis
KW  - image motion analysis
KW  - inertial navigation
KW  - pose estimation
KW  - head-mounted IMU-camera
KW  - batch least-squares algorithm
KW  - human motion models
KW  - inertial data
KW  - visual data
KW  - human gait estimation
KW  - minimal sensors-based system
KW  - VICON motion capture system
KW  - gait models
KW  - inertial measurement units
KW  - Foot
KW  - Trajectory
KW  - Computational modeling
KW  - Sensors
KW  - Legged locomotion
KW  - Visualization
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460871
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper addresses the problem of gait estimation using visual and inertial data, as well as human motion models. Specifically, a batch least-squares (BLS) algorithm is presented that fuses data from a minimal set of sensors [two inertial measurement units (IMUs), one on each foot, and a head-mounted IMU-camera pair] along with motion constraints corresponding to the different walking states, to estimate the person's head and feet poses. Subsequently, gait models are employed to solve for the lower-body's posture and generate its animation. Experimental results against the VICON motion capture system demonstrate the accuracy of the proposed minimal sensors-based system for determining a person's motion.
ER  - 

TY  - CONF
TI  - A Deep Learning Based Behavioral Approach to Indoor Autonomous Navigation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4646
EP  - 4653
AU  - G. Sepulveda
AU  - J. C. Niebles
AU  - A. Soto
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigational behaviors
KW  - deep learning architectures
KW  - semantic abstraction
KW  - navigation tasks
KW  - navigational missions
KW  - behavioral approach
KW  - indoor autonomous navigation
KW  - semantically rich graph representation
KW  - indoor robotic navigation
KW  - semantic locations
KW  - Navigation
KW  - Semantics
KW  - Visualization
KW  - Simultaneous localization and mapping
KW  - Robustness
KW  - Measurement
DO  - 10.1109/ICRA.2018.8460646
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a semantically rich graph representation for indoor robotic navigation. Our graph representation encodes: semantic locations such as offices or corridors as nodes, and navigational behaviors such as enter office or cross a corridor as edges. In particular, our navigational behaviors operate directly from visual inputs to produce motor controls and are implemented with deep learning architectures. This enables the robot to avoid explicit computation of its precise location or the geometry of the environment, and enables navigation at a higher level of semantic abstraction. We evaluate the effectiveness of our representation by simulating navigation tasks in a large number of virtual environments. Our results show that using a simple sets of perceptual and navigational behaviors, the proposed approach can successfully guide the way of the robot as it completes navigational missions such as going to a specific office. Furthermore, our implementation shows to be effective to control the selection and switching of behaviors.
ER  - 

TY  - CONF
TI  - Footstep Planning in Rough Terrain for Bipedal Robots Using Curved Contact Patches
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4662
EP  - 4669
AU  - D. Kanoulas
AU  - A. Stumpf
AU  - V. S. Raghavan
AU  - C. Zhou
AU  - A. Toumpa
AU  - O. Von Stryk
AU  - D. G. Caldwell
AU  - N. G. Tsagarakis
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - off-road vehicles
KW  - path planning
KW  - robot vision
KW  - rough terrain
KW  - rough terrain stepping
KW  - WALK-MAN humanoid robot
KW  - flat foothold contact analysis
KW  - rough local terrain surfaces
KW  - curved patch modeling system
KW  - 6DoF footstep sequences
KW  - black box walking controller
KW  - proper environment modeling
KW  - visual perception
KW  - foothold placements
KW  - exteroceptive perception
KW  - curved contact patches
KW  - bipedal robots
KW  - footstep planning
KW  - Planning
KW  - Three-dimensional displays
KW  - Rough surfaces
KW  - Surface roughness
KW  - Robot sensing systems
KW  - Navigation
DO  - 10.1109/ICRA.2018.8460561
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Bipedal robots have gained a lot of locomotion capabilities the past few years, especially in the control level. Navigation over complex and unstructured environments using exteroceptive perception, is still an active research topic. In this paper, we present a footstep planning system to produce foothold placements, using visual perception and proper environment modeling, given a black box walking controller. In particular, we extend a state-of-the-art search-based planning approach (ARA*) that produces 6DoF footstep sequences in 3D space for flat uneven terrain, to also handle rough curved surfaces, e.g. rocks. This is achieved by integrating both a curved patch modeling system for rough local terrain surfaces and a flat foothold contact analysis based on visual range input data, into the existing planning framework. The system is experimentally validated using real-world point clouds, while rough terrain stepping demonstrations are presented on the WALK-MAN humanoid robot, in simulation.
ER  - 

TY  - CONF
TI  - Robust and Precise Vehicle Localization Based on Multi-Sensor Fusion in Diverse City Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4670
EP  - 4677
AU  - G. Wan
AU  - X. Yang
AU  - R. Cai
AU  - H. Li
AU  - Y. Zhou
AU  - H. Wang
AU  - S. Song
PY  - 2018
KW  - Global Positioning System
KW  - Kalman filters
KW  - optical radar
KW  - road vehicles
KW  - satellite navigation
KW  - sensor fusion
KW  - LiDAR
KW  - localization system
KW  - GNSS RTK module
KW  - urban downtown
KW  - complementary sensors
KW  - precise localization system
KW  - robust localization system
KW  - precise vehicle localization
KW  - localization measurements
KW  - error-state Kalman filter
KW  - ambiguity resolution success rate
KW  - multisensor fusion framework
KW  - size 60.0 km
KW  - size 5.0 cm to 10.0 cm
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Estimation
KW  - Sensors
KW  - Global navigation satellite system
KW  - Autonomous vehicles
KW  - Robustness
DO  - 10.1109/ICRA.2018.8461224
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a robust and precise localization system that achieves centimeter-level localization accuracy in disparate city scenes. Our system adaptively uses information from complementary sensors such as GNSS, LiDAR, and IMU to achieve high localization accuracy and resilience in challenging scenes, such as urban downtown, highways, and tunnels. Rather than relying only on LiDAR intensity or 3D geometry, we make innovative use of LiDAR intensity and altitude cues to significantly improve localization system accuracy and robustness. Our GNSS RTK module utilizes the help of the multi-sensor fusion framework and achieves a better ambiguity resolution success rate. An error-state Kalman filter is applied to fuse the localization measurements from different sources with novel uncertainty estimation. We validate, in detail, the effectiveness of our approaches, achieving 5-10cm RMS accuracy and outperforming previous state-of-the-art systems. Importantly, our system, while deployed in a large autonomous driving fleet, made our vehicles fully autonomous in crowded city streets despite road construction that occurred from time to time. A dataset including more than 60 km real traffic driving in various urban roads is used to comprehensively test our system.
ER  - 

TY  - CONF
TI  - Safe Distributed Lane Change Maneuvers for Multiple Autonomous Vehicles Using Buffered Input Cells
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4678
EP  - 4684
AU  - M. Wang
AU  - Z. Wang
AU  - S. Paudel
AU  - M. Schwager
PY  - 2018
KW  - collision avoidance
KW  - computational geometry
KW  - decision making
KW  - feedback
KW  - mobile robots
KW  - position control
KW  - road safety
KW  - road vehicles
KW  - safe distributed lane change maneuvers
KW  - multiple autonomous vehicles
KW  - reciprocal collision avoidance method
KW  - autonomous cars
KW  - linear dynamics
KW  - buffered input cell
KW  - Voronoi cell
KW  - Voronoi diagrams
KW  - vehicles control input
KW  - control stack
KW  - freeway driving scenario
KW  - decision-making layer
KW  - trajectory planning layer
KW  - feedback controller
KW  - BIC method
KW  - human-driven car
KW  - Collision avoidance
KW  - Robots
KW  - Vehicle dynamics
KW  - Aerospace electronics
KW  - Traffic control
KW  - Autonomous vehicles
KW  - Planning
DO  - 10.1109/ICRA.2018.8460898
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces the Buffered Input Cell as a reciprocal collision avoidance method for multiple vehicles with high-order linear dynamics, extending recently proposed methods based on the Buffered Voronoi Cell [1] and generalized Voronoi diagrams [2]. We prove that if each vehicle's control input remains in its Buffered Input Cell at each time step, collisions will be avoided indefinitely. The method is fast, reactive, and only requires that each vehicle measures the relative position of neighboring vehicles. We incorporate this collision avoidance method as one layer of a complete lane change control stack for autonomous cars in a freeway driving scenario. The lane change control stack comprises a decision-making layer, a trajectory planning layer, a trajectory following feedback controller, and the Buffered Input Cell for collision avoidance. We show in simulations that collisions are avoided with multiple vehicles simultaneously changing lanes on a freeway. We also show in simulations that autonomous cars using the BIC method effectively avoid collisions with an aggressive human-driven car.
ER  - 

TY  - CONF
TI  - Deep Predictive Models for Collision Risk Assessment in Autonomous Driving
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4685
EP  - 4692
AU  - M. Strickland
AU  - G. Fainekos
AU  - H. B. Amor
PY  - 2018
KW  - Bayes methods
KW  - collision avoidance
KW  - decision making
KW  - driver information systems
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - recurrent neural nets
KW  - risk management
KW  - video streaming
KW  - Deep Predictive Models
KW  - collision risk assessment
KW  - autonomous driving
KW  - predictive approach
KW  - assisted driving
KW  - deep predictive model
KW  - video streams
KW  - RGB images
KW  - temporal information
KW  - multi-modal information
KW  - proprioceptive state
KW  - Bayesian convolutional LSTM
KW  - decision making
KW  - Predictive models
KW  - Accidents
KW  - Stochastic processes
KW  - Uncertainty
KW  - Bayes methods
KW  - Cameras
KW  - Tensile stress
DO  - 10.1109/ICRA.2018.8461160
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we investigate a predictive approach for collision risk assessment in autonomous and assisted driving. A deep predictive model is trained to anticipate imminent accidents from traditional video streams. In particular, the model learns to identify cues in RGB images that are predictive of hazardous upcoming situations. In contrast to previous work, our approach incorporates (a) temporal information during decision making, (b) multi-modal information about the environment, as well as the proprioceptive state and steering actions of the controlled vehicle, and (c) information about the uncertainty inherent to the task. To this end, we discuss Deep Predictive Models and present an implementation using a Bayesian Convolutional LSTM. Experiments in a simple simulation environment show that the approach can learn to predict impending accidents with reasonable accuracy, especially when multiple cameras are used as input sources.
ER  - 

TY  - CONF
TI  - End-to-End Driving Via Conditional Imitation Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4693
EP  - 4700
AU  - F. Codevilla
AU  - M. Müller
AU  - A. López
AU  - V. Koltun
AU  - A. Dosovitskiy
PY  - 2018
KW  - collision avoidance
KW  - learning systems
KW  - mobile robots
KW  - road traffic control
KW  - driving policy functions
KW  - conditional imitation learning
KW  - sensorimotor coordination
KW  - vision-based driving
KW  - robotic truck
KW  - driving policies
KW  - deep networks
KW  - high-level navigational commands
KW  - urban driving
KW  - high-level command input
KW  - condition imitation
KW  - Robot sensing systems
KW  - Task analysis
KW  - Vehicles
KW  - Cameras
KW  - Roads
KW  - Navigation
DO  - 10.1109/ICRA.2018.8460487
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Deep networks trained on demonstrations of human driving have learned to follow roads and avoid obstacles. However, driving policies trained via imitation learning cannot be controlled at test time. A vehicle trained end-to-end to imitate an expert cannot be guided to take a specific turn at an upcoming intersection. This limits the utility of such systems. We propose to condition imitation learning on high-level command input. At test time, the learned driving policy functions as a chauffeur that handles sensorimotor coordination but continues to respond to navigational commands. We evaluate different architectures for conditional imitation learning in vision-based driving. We conduct experiments in realistic three-dimensional simulations of urban driving and on a 1/5 scale robotic truck that is trained to drive in a residential area. Both systems drive based on visual input yet remain responsive to high-level navigational commands.
ER  - 

TY  - CONF
TI  - VisualBackProp: Efficient Visualization of CNNs for Autonomous Driving
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4701
EP  - 4708
AU  - M. Bojarski
AU  - A. Choromanska
AU  - K. Choromanski
AU  - B. Firner
AU  - L. J. Ackel
AU  - U. Muller
AU  - P. Yeres
AU  - K. Zieba
PY  - 2018
KW  - data visualisation
KW  - feedforward neural nets
KW  - learning (artificial intelligence)
KW  - object detection
KW  - traffic engineering computing
KW  - video signal processing
KW  - convolutional neural network
KW  - irrelevant information
KW  - prediction decision
KW  - CNN-based systems
KW  - steering self-driving cars
KW  - visualization method
KW  - valuable debugging tool
KW  - theoretical arguments
KW  - input pixels
KW  - individual pixels
KW  - visualization tool
KW  - NVIDIA neural-network-based end-to-end learning system
KW  - autonomous driving
KW  - VisualBackProp
KW  - public road video data
KW  - layer-wise relevance propagation approach
KW  - similar visualization results
KW  - PilotNet steering decision
KW  - relevant object capture
KW  - Neurons
KW  - Visualization
KW  - Deconvolution
KW  - Tools
KW  - Biological neural networks
KW  - Roads
KW  - Data visualization
DO  - 10.1109/ICRA.2018.8461053
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes a new method, that we call VisualBackProp, for visualizing which sets of pixels of the input image contribute most to the predictions made by the convolutional neural network (CNN). The method heavily hinges on exploring the intuition that the feature maps contain less and less irrelevant information to the prediction decision when moving deeper into the network. The technique we propose is dedicated for CNN-based systems for steering self-driving cars and is therefore required to run in real-time. This makes the proposed visualization method a valuable debugging tool which can be easily used during both training and inference. We justify our approach with theoretical arguments and confirm that the proposed method identifies sets of input pixels, rather than individual pixels, that collaboratively contribute to the prediction. We utilize the proposed visualization tool in the NVIDIA neural-network-based end-to-end learning system for autonomous driving, known as PilotNet. We demonstrate that VisualBackProp determines which elements in the road image most influence PilotNet's steering decision and indeed captures relevant objects on the road. The empirical evaluation furthermore shows the plausibility of the proposed approach on public road video data as well as in other applications and reveals that it compares favorably to the layer-wise relevance propagation approach, i.e. it obtains similar visualization results and achieves order of magnitude speed-ups.
ER  - 

TY  - CONF
TI  - Predicting Ego-Vehicle Paths from Environmental Observations with a Deep Neural Network
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4709
EP  - 4716
AU  - U. Baumann
AU  - C. Guiser
AU  - M. Herman
AU  - J. M. Zollner
PY  - 2018
KW  - driver information systems
KW  - feature extraction
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - road vehicles
KW  - static vehicle environment
KW  - grid-based prediction
KW  - varying assistance tasks
KW  - baseline approaches
KW  - environmental observations
KW  - deep neural network
KW  - advanced driver assistance systems
KW  - predictive model
KW  - road topologies
KW  - environmental properties
KW  - path extraction
KW  - ego-vehicle path prediction
KW  - ego-vehicle motion
KW  - Predictive models
KW  - Vehicles
KW  - Sensors
KW  - Roads
KW  - Trajectory
KW  - Data models
KW  - Motion measurement
DO  - 10.1109/ICRA.2018.8460704
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Advanced driver assistance systems allow for increasing user comfort and safety by sensing the environment and anticipating upcoming hazards. Often, this requires to accurately predict how situations will change. Recent approaches make simplifying assumptions on the predictive model of the Ego-Vehicle motion or assume prior knowledge, such as road topologies, to be available. However, in many urban areas this assumption is not satisfied. Furthermore, temporary changes (e.g. construction areas, vehicles parked on the street) are not considered by such models. Since many cars observe the environment with several different sensors, predictive models can benefit from them by considering environmental properties. In this work, we present an approach for an Ego-Vehicle path prediction from such sensor measurements of the static vehicle environment. Besides proposing a learned model for predicting the driver's multi-modal future path as a grid-based prediction, we derive an approach for extracting paths from it. In driver assistance systems both can be used to solve varying assistance tasks. The proposed approach is evaluated on real driving data and outperforms several baseline approaches.
ER  - 

TY  - CONF
TI  - Learning Steering Bounds for Parallel Autonomous Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4717
EP  - 4724
AU  - A. Amini
AU  - L. Paull
AU  - T. Balch
AU  - S. Karaman
AU  - D. Rus
PY  - 2018
KW  - Bayes methods
KW  - cameras
KW  - control engineering computing
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - mixture models
KW  - mobile robots
KW  - neural nets
KW  - path planning
KW  - road vehicles
KW  - robot vision
KW  - steering systems
KW  - parallel autonomous systems
KW  - deep learning
KW  - autonomous driving task
KW  - camera data input
KW  - autonomous navigation
KW  - vehicle control
KW  - continuous control probability distribution
KW  - deep neural network based algorithm
KW  - steering angles
KW  - parallel autonomy setting
KW  - driving conditions
KW  - variational Bayesian methods
KW  - steering bounds learning
KW  - end-to-end learning
KW  - steering control options
KW  - Gaussian mixture models
KW  - Autonomous vehicles
KW  - Navigation
KW  - Neural networks
KW  - Probability distribution
KW  - Decision making
KW  - Machine learning
KW  - Bayes methods
DO  - 10.1109/ICRA.2018.8461253
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Deep learning has been successfully applied to “end-to-end” learning of the autonomous driving task, where a deep neural network learns to predict steering control commands from camera data input. However, the learned representations do not support higher-level decision making required for autonomous navigation, nor the uncertainty estimates required for parallel autonomy, where vehicle control is shared between human and robot. This paper tackles the problem of learning a representation to predict a continuous control probability distribution, and thus steering control options and bounds for those options, which can be used for autonomous navigation. Each mode of the distribution encodes a possible macro-action that the system could execute at that instant, and the covariances of the modes place bounds on safe steering control values. Our approach has the added advantage of being trained on unlabeled data collected from inexpensive cameras. The deep neural network based algorithm generates a probability distribution over the space of steering angles, from which we leverage Variational Bayesian methods to extract a mixture model and compute the different possible actions in the environment. A bound, which the autonomous vehicle must respect in our parallel autonomy setting, is then computed for each of these actions. We evaluate our approach on a challenging dataset containing a wide variety of driving conditions, and show that our algorithm is capable of parameterizing Gaussian Mixture Models for possible actions, and extract steering bounds with a mean error of only 2 degrees. Additionally, we demonstrate our system working on a full scale autonomous vehicle and evaluate its ability to successful handle various different parallel autonomy situations.
ER  - 

TY  - CONF
TI  - End to End Learning of Spiking Neural Network Based on R-STDP for a Lane Keeping Vehicle
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4725
EP  - 4732
AU  - Z. Bing
AU  - C. Meschede
AU  - K. Huang
AU  - G. Chen
AU  - F. Rohrbein
AU  - M. Akl
AU  - A. Knoll
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - road vehicles
KW  - robot vision
KW  - SLAM (robots)
KW  - spiking neural network
KW  - lane keeping vehicle
KW  - mobile applications
KW  - mobile robot applications
KW  - reward-modulated spike-timing-dependent-plasticity
KW  - reinforcement learning
KW  - Pioneer robot
KW  - lane information
KW  - robot tasks control
KW  - end to end learning approach
KW  - R-STDP
KW  - SNNs training
KW  - neuromorphic vision sensor
KW  - lateral localization accuracy
KW  - Voltage control
KW  - Task analysis
KW  - Robot sensing systems
KW  - Training
KW  - Synapses
KW  - Neurons
DO  - 10.1109/ICRA.2018.8460482
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Learning-based methods have demonstrated clear advantages in controlling robot tasks, such as the information fusion abilities, strong robustness, and high accuracy. Meanwhile, the on-board systems of robots have limited computation and energy resources, which are contradictory with state-of-the-art learning approaches. They are either too lightweight to solve complex problems or too heavyweight to be used for mobile applications. On the other hand, training spiking neural networks (SNNs) with biological plausibility has great potentials of performing fast computation and energy efficiency. However, the lack of effective learning rules for SNNs impedes their wide usage in mobile robot applications. This paper addresses the problem by introducing an end to end learning approach of spiking neural networks for a lane keeping vehicle. We consider the reward-modulated spike-timing-dependent-plasticity (R-STDP) as a promising solution in training SNNs, since it combines the advantages of both reinforcement learning and the well-known STDP. We test our approach in three scenarios that a Pioneer robot is controlled to keep lanes based on an SNN. Specifically, the lane information is encoded by the event data from a neuromorphic vision sensor. The SNN is constructed using R-STDP synapses in an all-to-all fashion. We demonstrate the advantages of our approach in terms of the lateral localization accuracy by comparing with other state-of-the-art learning algorithms based on SNNs.
ER  - 

TY  - CONF
TI  - A Dual-Modal Vision-Based Tactile Sensor for Robotic Hand Grasping
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4740
EP  - 4745
AU  - B. Fang
AU  - F. Sun
AU  - C. Yang
AU  - H. Xue
AU  - W. Chen
AU  - C. Zhang
AU  - D. Guo
AU  - H. Liu
PY  - 2018
KW  - backpropagation
KW  - CCD image sensors
KW  - elastomers
KW  - force measurement
KW  - image texture
KW  - neural nets
KW  - robots
KW  - shape recognition
KW  - tactile sensors
KW  - robotic hand grasping
KW  - force vector distribution
KW  - transparent elastomer
KW  - transparent acrylic board
KW  - CCD camera
KW  - reflective membrane
KW  - markers array
KW  - object contact surface
KW  - backpropagation neural network
KW  - local binary pattern algorith
KW  - force magnitude
KW  - force direction
KW  - surface texture sensing
KW  - dual-modal vision-based tactile sensor
KW  - texture recognition rate
KW  - texture information
KW  - Force
KW  - Tactile sensors
KW  - Neurons
KW  - Cameras
KW  - Light emitting diodes
DO  - 10.1109/ICRA.2018.8461007
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Humans' fingertips can perceive not only the magnitude and the direction of force but also the texture of object. When we grasp an object, the surface texture sensing of the fingertip helps us recognize the object and the force feeling that is parallel to the skin helps us grasp stably. Focusing on these points, we have developed a dual-modal vision-based tactile sensor that can measure the texture of object and a distribution of force vectors. The tactile sensor consists of a transparent elastomer, a camera, a piece of transparent acrylic board, LEDs and supporting structures. A reflective membrane and markers array are on the surface of the elastomer. An applied force on the elastic body results in movements of the markers, which are acquired by the CCD camera. In addition, the shape and texture of the object's contact surface can be reflected by the membrane deformations. The distribution of force vectors is determined by the BP neural network. The local binary pattern algorithm using captured images calculates the texture information. This paper reports experimental evaluation results concerning accuracy of determination of magnitude, direction of force, and texture recognition rate.
ER  - 

TY  - CONF
TI  - Adapting the Goals/Questions/Metrics (GQM) Method for Applications in Robot Design
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4746
EP  - 4751
AU  - C. McGinn
AU  - E. Bourke
AU  - T. O'Kelly
AU  - M. F. Cullinan
PY  - 2018
KW  - grippers
KW  - service robots
KW  - Goals/Questions/Metrics method
KW  - robot design
KW  - advanced robots
KW  - resource-intensive activity
KW  - research teams
KW  - complex robot systems
KW  - design metrics
KW  - design tool
KW  - design-orientated GQM method
KW  - bespoke robotic gripper
KW  - service robot
KW  - GQM principles
KW  - robotics applications
KW  - Measurement
KW  - Prototypes
KW  - Grippers
KW  - Service robots
KW  - Robot sensing systems
KW  - Planning
DO  - 10.1109/ICRA.2018.8460630
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Developing advanced robots can be a resource-intensive activity that creates many challenges for research teams. There is a need to formulate new techniques for systematically designing complex robot systems, especially in cases where high adaptability is needed and design metrics cannot be explicitly specified in advance. This research explores how the Goals/Questions/Metrics (GQM) method, a well-established technique for process measurement, can be modified for use as a design tool in robotics. To illustrate how a design-orientated GQM method may be used in practice, a sample use-case is given detailing how the approach was applied to the task of developing a bespoke robotic gripper for a service robot. The study provides an early indication that the adoption of GQM principles by designers can have significant benefits in robotics applications. However, further investigation is needed to better understand the magnitude and scope of any improvements.
ER  - 

TY  - CONF
TI  - The Exchange of Knowledge Using Cloud Robotics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4768
EP  - 4775
AU  - A. K. Bozcuoğlu
AU  - G. Kazhoyan
AU  - Y. Furuta
AU  - S. Stelter
AU  - M. Beetz
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - cloud computing
KW  - ontologies (artificial intelligence)
KW  - robots
KW  - ontologies
KW  - OPENEASE cloud engine
KW  - web-based user interface
KW  - Fetch robot
KW  - PR2 robots
KW  - execution logs
KW  - knowledge exchange
KW  - encyclopedic knowledge
KW  - cloud application
KW  - crowd-sourcing
KW  - cloud robotics
KW  - Robots
KW  - Ontologies
KW  - Semantics
KW  - Task analysis
KW  - Containers
KW  - Cloud computing
KW  - Cognition
DO  - 10.1109/ICRA.2018.8460187
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To enable robots to perform human-level tasks flexibly in varying conditions, we need a mechanism that allows them to exchange knowledge between themselves for crowd-sourcing the knowledge gap problem. One approach to achieve this is to equip a cloud application with a range of encyclopedic knowledge (i.e. ontologies) and execution logs of different robots performing the same tasks in different environments. In this paper, we show how knowledge exchange between robots can be done using OPENEASE as the cloud application. We equipped OPENEASE with ontologies about the kitchen domain, execution logs of three robots operating in two different kitchens, and semantic descriptions of both environments. By addressing two different use cases, we show that two PR2 robots and one Fetch robot can successfully adapt each other's plan parameters and sub symbolic data to the experiments that they are conducting.
ER  - 

TY  - CONF
TI  - Dry Stacking for Automated Construction with Irregular Objects
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4782
EP  - 4789
AU  - V. Thangavelu
AU  - Y. Liu
AU  - M. Saboia
AU  - N. Napp
PY  - 2018
KW  - assembly planning
KW  - brick
KW  - building management systems
KW  - buildings (structures)
KW  - construction industry
KW  - disasters
KW  - heuristic programming
KW  - mechanical stability
KW  - robotic assembly
KW  - statistical analysis
KW  - structural engineering
KW  - automated construction
KW  - irregular objects
KW  - dry stacked structures
KW  - disaster areas
KW  - remote environments
KW  - assembly planning process
KW  - bricks
KW  - heuristics programming
KW  - Shape
KW  - Stacking
KW  - Planning
KW  - Stability analysis
KW  - Two dimensional displays
KW  - Building materials
DO  - 10.1109/ICRA.2018.8460562
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We describe a method for automatically building structures from stacked, irregularly shaped objects. This is a simplified model for the problem of building dry stacked structures (i.e. no mortar) from found stones. Although automating such construction methods would be ideally suited for disaster areas or remote environments, currently such structures need to be built by skilled masons. No practical methods for automating the assembly planning process are known. The problem is challenging since each assembly action can be drawn from a continuous space poses for an object and several local geometric and physical considerations strongly affect the overall stability. We show that structures that are built following a stacking order for perfect bricks can accommodate a limited amount of irregularity, however, their performance degrades quickly when objects deviate from their ideal shape. We present a strategy for stacking irregular shapes that first considers geometric and physical constraints to find a small set of feasible actions and then further refines this set by using heuristics gathered from instructional literature for masons. The proposed method of choosing assembly actions allows construction with objects that contain a significant amount of variation.
ER  - 


TY  - CONF
TI  - High-Speed Well-Focused Image-Capturing System for Moving Micro-Objects Based on Histograms of the Luminance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4790
EP  - 4795
AU  - T. Aoyama
AU  - M. Hanabishi
AU  - T. Takaki
AU  - I. Ishii
AU  - Y. Hasegawa
PY  - 2018
KW  - brightness
KW  - lenses
KW  - optical microscopes
KW  - high-speed well-focused image-capturing microscope system
KW  - luminance histogram-based algorithm
KW  - high-speed microobject system
KW  - vibration machine
KW  - microchannel
KW  - vision-based analysis systems
KW  - objective lens
KW  - size 10 mum to 100 mum
KW  - size 1 mum to 4 mum
KW  - Vibrations
KW  - Microscopy
KW  - Lenses
KW  - Histograms
KW  - Microchannels
KW  - Lighting
KW  - Machine vision
DO  - 10.1109/ICRA.2018.8461238
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In recent years, vision-based analysis systems of micro-objects in a microchannel have been actively developed. However, it is difficult to focus on high-speed micro-objects in a microchannel because the general height of a microchannel is approximately 10-100 μm, whereas the depth of focus of the objective lens is approximately 1-4 μm. Therefore, we propose a high-speed well-focused image-capturing microscope, which is a system with an objective lens attached to a vibration machine that moves the focus position rapidly by oscillating it up and down to capture well-focused images using a histogram-based algorithm. The proposed microscope system is verified experimentally to capture well-focused images of moving micro- objects.
ER  - 

TY  - CONF
TI  - Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4796
EP  - 4803
AU  - F. Ma
AU  - S. Karaman
PY  - 2018
KW  - image colour analysis
KW  - image reconstruction
KW  - image resolution
KW  - image sampling
KW  - image segmentation
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - mean square error methods
KW  - optical radar
KW  - random processes
KW  - regression analysis
KW  - SLAM (robots)
KW  - sparse matrices
KW  - prediction root-mean-square error
KW  - sparse maps
KW  - dense maps
KW  - sparse-to-dense
KW  - dense depth prediction
KW  - sparse set
KW  - depth measurements
KW  - single RGB image
KW  - depth estimation
KW  - monocular images
KW  - low-resolution depth sensor
KW  - single deep regression network
KW  - RGB-D raw data
KW  - sparse depth samples
KW  - visual simultaneous localization and mapping algorithms
KW  - plug-in module
KW  - NYU-depth-v2 indoor dataset
KW  - LiDARs
KW  - Training
KW  - Laser radar
KW  - Image reconstruction
KW  - Estimation
KW  - Prediction algorithms
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8460184
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the problem of dense depth prediction from a sparse set of depth measurements and a single RGB image. Since depth estimation from monocular images alone is inherently ambiguous and unreliable, to attain a higher level of robustness and accuracy, we introduce additional sparse depth samples, which are either acquired with a low-resolution depth sensor or computed via visual Simultaneous Localization and Mapping (SLAM) algorithms. We propose the use of a single deep regression network to learn directly from the RGB-D raw data, and explore the impact of number of depth samples on prediction accuracy. Our experiments show that, compared to using only RGB images, the addition of 100 spatially random depth samples reduces the prediction root-mean-square error by 50% on the NYU-Depth-v2 indoor dataset. It also boosts the percentage of reliable prediction from 59% to 92% on the KITTI dataset. We demonstrate two applications of the proposed algorithm: a plug-in module in SLAM to convert sparse maps to dense maps, and super-resolution for LiDARs. Software2 and video demonstration3 are publicly available.
ER  - 

TY  - CONF
TI  - Real-Time Object Tracking in Sparse Point Clouds Based on 3D Interpolation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4804
EP  - 4811
AU  - Y. Lee
AU  - S. Seo
PY  - 2018
KW  - estimation theory
KW  - image matching
KW  - interpolation
KW  - object detection
KW  - object tracking
KW  - statistical distributions
KW  - stereo image processing
KW  - target object clouds
KW  - sparse point clouds
KW  - point-to-distribution matching technique
KW  - tracking algorithm
KW  - 3D point clouds
KW  - direct point-to-point matching method
KW  - real-time object tracking
KW  - Estimation of Vertical Distributions
KW  - object-tracking strategy
KW  - EVD
KW  - interpolation method
KW  - 3D interpolation
KW  - Three-dimensional displays
KW  - Target tracking
KW  - Real-time systems
KW  - Solid modeling
KW  - Interpolation
KW  - Vehicle dynamics
KW  - Laser radar
DO  - 10.1109/ICRA.2018.8460639
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - While object tracking for 3D point clouds has been widely researched in recent years, most trackers employ a direct point-to-point matching method under the assumption that target object clouds are dense, although the method is not suitable for sparse point clouds. In this paper, we introduce a novel object-tracking strategy that enables even sparse point clouds to be tracked properly. The strategy involves estimating distributions, called as Estimation of Vertical Distributions (EVD), by the proposed interpolation method to augment data and by a point-to-distribution matching technique. The EVD step generates vertical distributions of unoccupied areas on a target object using the distributions of the occupied areas and then seeks the optimal solution through a coarse-to-fine grid search to guarantee real-time performance. In order to verify the proposed tracking algorithm, we have tested our tracker on real world data collected by our own platform, and the results have demonstrated that the tracker outperforms other trackers.
ER  - 

TY  - CONF
TI  - Robust Generalized Point Cloud Registration Using Hybrid Mixture Model
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4812
EP  - 4818
AU  - Z. Min
AU  - J. Wang
AU  - M. Q. -. Meng
PY  - 2018
KW  - computerised tomography
KW  - expectation-maximisation algorithm
KW  - Gaussian processes
KW  - image registration
KW  - medical image processing
KW  - mixture models
KW  - optimisation
KW  - probability
KW  - Gaussian mixture model
KW  - probabilistic approach
KW  - expectation-maximization algorithm
KW  - CT images
KW  - FMM
KW  - GMM
KW  - EM algorithm
KW  - optimization problem
KW  - Von-Mises-Fisher mixture model
KW  - robust point cloud registration method
KW  - hybrid mixture model
KW  - Three-dimensional displays
KW  - Mixture models
KW  - Iterative closest point algorithm
KW  - Robustness
KW  - Probabilistic logic
KW  - Gaussian mixture model
KW  - Point cloud registration
KW  - Von-Mises-Fisher distribution
KW  - Gaussian mixture model
DO  - 10.1109/ICRA.2018.8460825
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces a robust point cloud registration method which utilizes not only positional but also the orientation information at each point. The proposed method takes a probabilistic approach which forms the problem as a hybrid mixture model, in which a Von-Mises-Fisher mixture model (FMM) is adopted to model the orientation part and a gaussian mixture model (GMM) is used to represent the position part. When two point clouds are optimally registered, the correspondence is the maximum of the posterior probability of the overall mixture model. Expectation-Maximization (EM) algorithm has been adopted to solve the optimization problem in an iterative manner to find the optimal rotation and translation between two point clouds. Extensive experiments under different noise levels and different outlier ratios have been carried out on a dataset of the femur CT images. Comparison results show that the proposed method outperforms the state-of-the-art methods under most of the experimental conditions, which indicates the validity of our method.
ER  - 

TY  - CONF
TI  - Multi-Stage Suture Detection for Robot Assisted Anastomosis Based on Deep Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4826
EP  - 4833
AU  - Y. Hu
AU  - Y. Gu
AU  - J. Yang
AU  - G. Yang
PY  - 2018
KW  - blood vessels
KW  - convolution
KW  - image recognition
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - medical robotics
KW  - recurrent neural nets
KW  - surgery
KW  - thread centerline reconstruction
KW  - multistage suture detection
KW  - robot assisted anastomosis
KW  - deep learning
KW  - robust suture detection
KW  - suture augmentation
KW  - robotic-assisted surgery
KW  - fully convolutional neural networks
KW  - trainee suturing skill evaluation
KW  - curvilinear structure detector
KW  - Yarn
KW  - Instruction sets
KW  - Surgery
KW  - Splines (mathematics)
KW  - Image reconstruction
KW  - Robots
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461131
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The technique of robust suture detection is vital in many applications including trainee suturing skill evaluation, suture augmentation in robotic-assisted surgery and suture recognition for automatic suturing. Due to the complicated environment of surgery, the detection of a suture is challenged by high deformation and frequent occlusion. In this paper, we propose a deep multi-stage framework for suture detection. The fully convolutional neural networks are firstly used to predict a gradient map which not only serves as a segmentation mask, but also provides useful structure information for the following thread centerline reconstruction. An overlapping map is also predicted to improve the quality of the gradient map in self-intersection area. Based on the gradient map, multiple segments of the thread are extracted and linked to form the whole thread using a curvilinear structure detector. Experiments on two types of threads demonstrate that the proposed method is able to detect the thread with human level performance when the thread is no occlusion or under finite self-intersection.
ER  - 

TY  - CONF
TI  - Active Clothing Material Perception Using Tactile Sensing and Deep Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4842
EP  - 4849
AU  - W. Yuan
AU  - Y. Mo
AU  - S. Wang
AU  - E. H. Adelson
PY  - 2018
KW  - clothing
KW  - control engineering computing
KW  - convolution
KW  - feedforward neural nets
KW  - image sensors
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - tactile sensors
KW  - active clothing material perception
KW  - tactile sensing
KW  - deep learning
KW  - intelligent robot
KW  - robot system
KW  - object properties
KW  - common object category
KW  - external Kinect sensor
KW  - GelSight tactile sensor
KW  - tactile data
KW  - physical properties
KW  - durability
KW  - semantic properties
KW  - clothing properties
KW  - active tactile perception system
KW  - vision-touch system
KW  - robots
KW  - varied clothing related housework
KW  - convolutional neural networks
KW  - Clothing
KW  - Tactile sensors
KW  - Shape
KW  - Grippers
DO  - 10.1109/ICRA.2018.8461164
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Humans represent and discriminate the objects in the same category using their properties, and an intelligent robot should be able to do the same. In this paper, we build a robot system that can autonomously perceive the object properties through touch. We work on the common object category of clothing. The robot moves under the guidance of an external Kinect sensor, and squeezes the clothes with a GelSight tactile sensor, then it recognizes the 11 properties of the clothing according to the tactile data. Those properties include the physical properties, like thickness, fuzziness, softness and durability, and semantic properties, like wearing season and preferred washing methods. We collect a dataset of 153 varied pieces of clothes, and conduct 6616 robot exploring iterations on them. To extract the useful information from the high-dimensional sensory output, we applied Convolutional Neural Networks (CNN) on the tactile data for recognizing the clothing properties, and on the Kinect depth images for selecting exploration locations. Experiments show that using the trained neural networks, the robot can autonomously explore the unknown clothes and learn their properties. This work proposes a new framework for active tactile perception system with vision-touch system, and has potential to enable robots to help humans with varied clothing related housework.
ER  - 

TY  - CONF
TI  - Optimal Path Planning in Time-Varying Flows with Forecasting Uncertainties
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4857
EP  - 4864
AU  - D. Kularatne
AU  - H. Hajieghrary
AU  - M. Ani Hsieh
PY  - 2018
KW  - graph theory
KW  - marine control
KW  - Markov processes
KW  - optimisation
KW  - path planning
KW  - Markov decision process
KW  - uncertain flow model
KW  - ocean environment
KW  - time-varying flows
KW  - minimum energy paths
KW  - uncertain flow field
KW  - transition probability model
KW  - minimum expected cost path
KW  - graph search based method
KW  - minimum expected cost policy
KW  - marine environments
KW  - Path planning
KW  - Computational modeling
KW  - Oceans
KW  - Predictive models
KW  - Forecast uncertainty
KW  - Drag
DO  - 10.1109/ICRA.2018.8460221
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Uncertainties in flow models have to be explicitly considered for effective path planning in marine environments. In this paper, we present two methods to compute minimum expected cost policies and paths over an uncertain flow model. The first method based on a Markov Decision Process computes a minimum expected cost policy while the second graph search based method, computes a minimum expected cost path. A transition probability model is developed to compute the probability of transition from one state to another under a given action. In addition, a method to compute the expected cost of a path when it is executed in an uncertain flow field is also presented. The two methods are used to compute minimum energy paths in an ocean environment and the results are analyzed in simulations.
ER  - 

TY  - CONF
TI  - Topological Hotspot Identification for Informative Path Planning with a Marine Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4865
EP  - 4872
AU  - S. McCammon
AU  - G. A. Hollinger
PY  - 2018
KW  - computational geometry
KW  - graph theory
KW  - greedy algorithms
KW  - image segmentation
KW  - marine control
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - topological graph
KW  - greedy-coverage algorithm
KW  - informative path planning problem
KW  - topological hotspot identification
KW  - marine robot
KW  - topological map
KW  - biological hotspots
KW  - aquatic environment
KW  - Fast Marching-based Voronoi segmentation
KW  - scheduling problem
KW  - Path planning
KW  - Monitoring
KW  - Oceans
KW  - Robot sensing systems
KW  - Task analysis
KW  - Frequency modulation
DO  - 10.1109/ICRA.2018.8460652
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we present a novel method for constructing a topological map of biological hotspots in an aquatic environment using a Fast Marching-based Voronoi segmentation. Using this topological map, we develop a closed form solution to the scheduling problem for any single path through the graph. Searching over the space of all paths allows us to compute a maximally informative path that traverses a subset of the hotspots, given some budget. Using a greedy-coverage algorithm we can then compute an informative path. We evaluate our method in a set of simulated trials, both with randomly generated environments and a real-world environment. In these trials, we show that our method produces a topological graph which more accurately captures features in the environment than standard thresholding techniques. Additionally, We show that our method can improve the performance of a greedy-coverage algorithm in the informative path planning problem by guiding it to different informative areas to help it escape from local maxima.
ER  - 

TY  - CONF
TI  - Heterogeneous Multi-Robot System for Exploration and Strategic Water Sampling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4873
EP  - 4880
AU  - S. Manjanna
AU  - A. Q. Li
AU  - R. N. Smith
AU  - I. Rekleitis
AU  - G. Dudek
PY  - 2018
KW  - ecology
KW  - hydrological equipment
KW  - hydrological techniques
KW  - microorganisms
KW  - multi-robot systems
KW  - remotely operated vehicles
KW  - reservoirs
KW  - water quality
KW  - data-driven behavior
KW  - real geophysical data
KW  - MODIS measurements
KW  - water-sampling apparatus
KW  - water quality sensor
KW  - plankton-rich water samples
KW  - chlorophyll density
KW  - autonomous surface vehicles plan
KW  - water-sampling behavior
KW  - efficient measurement
KW  - fresh-water systems
KW  - measuring contamination levels
KW  - drinking water
KW  - physical sampling
KW  - strategic water sampling
KW  - heterogeneous multirobot system
KW  - water reservoir
KW  - explorer robot
KW  - water sampling apparatus
KW  - ASV
KW  - Pollution measurement
KW  - Geophysical measurements
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Time measurement
KW  - Water pollution
DO  - 10.1109/ICRA.2018.8460759
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Physical sampling of water for off-site analysis is necessary for many applications like monitoring the quality of drinking water in reservoirs, understanding marine ecosystems, and measuring contamination levels in fresh-water systems. In this paper, the focus is on algorithms for efficient measurement and sampling using a multi-robot, data-driven, water-sampling behavior, where autonomous surface vehicles plan and execute water sampling using the chlorophyll density as a cue for plankton-rich water samples. We use two Autonomous Surface Vehicles (ASVs), one equipped with a water quality sensor and the other equipped with a water-sampling apparatus. The ASV with the sensor acts as an explorer, measuring and building a spatial map of chlorophyll density in the given region of interest. The ASV equipped with the water sampling apparatus makes decisions in real time on where to sample the water based on the suggestions made by the explorer robot. We evaluate the system in the context of measuring chlorophyll distributions. We do this both in simulation based on real geophysical data from MODIS measurements, and on real robots in a water reservoir. We demonstrate the effectiveness of the proposed approach in several ways including in terms of mean error in the interpolated data as a function of distance traveled.
ER  - 

TY  - CONF
TI  - Extended Kalman Filter-Based 3D Active-Alignment Control for LED Communication
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4881
EP  - 4888
AU  - P. Bhanu Solanki
AU  - X. Tan
PY  - 2018
KW  - Kalman filters
KW  - light emitting diodes
KW  - mobile robots
KW  - optical communication
KW  - extended Kalman filter
KW  - proportional-integral controller
KW  - receiver-transmitter line
KW  - active alignment control system
KW  - transmitting device
KW  - active alignment system
KW  - mobile robots
KW  - Line-Of-Sight
KW  - underwater communication
KW  - optical communication
KW  - LED communication
KW  - active-alignment control
KW  - Receivers
KW  - Transmitters
KW  - Light emitting diodes
KW  - Robots
KW  - Three-dimensional displays
KW  - Estimation
KW  - Optical fiber communication
DO  - 10.1109/ICRA.2018.8460949
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - LED-based optical communication is emerging as a low-cost, high-data-rate alternative to the traditional acoustics mode of underwater communication. However, it is challenging to establish and maintain Line-Of-Sight (LOS) between the receiver and the transmitter, especially when such systems are used by mobile robots. Hence, there is a need for an active alignment system that enables the receiver to constantly align itself towards the direction of the transmitting device. In this paper, we propose and implement an active alignment control system capable of tracking a transmitting source moving in the three-dimensional (3D) space. An extended Kalman filter is used to estimate the components of the angle between the receiver orientation and the receiver-transmitter line. Using the estimate, a proportional-integral (PI) controller is implemented to adjust the receiver orientation. The algorithm uses one measurement of the light intensity from a single photo-diode, where successive measurements are obtained via a circular scanning technique. The amplitude of the scanning is adapted to the alignment performance, to achieve a sound trade-off between estimation accuracy, signal strength, and energy consumption. Simulation and experimental results are presented to illustrate the effectiveness of the proposed approach.
ER  - 

TY  - CONF
TI  - Robust Model-Aided Inertial Localization for Autonomous Underwater Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4889
EP  - 4896
AU  - S. Arnold
AU  - L. Medagoda
PY  - 2018
KW  - autonomous underwater vehicles
KW  - C++ language
KW  - drag
KW  - inertial navigation
KW  - Kalman filters
KW  - marine navigation
KW  - nonlinear filters
KW  - vehicle model parameter error
KW  - ADCP-aiding
KW  - DVL bottom-lock loss
KW  - IMU biases
KW  - navigation filter
KW  - DVL dropouts
KW  - robust model-aided inertial localization
KW  - autonomous underwater vehicles
KW  - Unscented Kalman Filter
KW  - inertial model-aiding
KW  - Acoustic Doppler Current Profiler measurement incorporation
KW  - Earth rotation
KW  - tactical grade IMU
KW  - heading convergence
KW  - data denial
KW  - drag
KW  - thrust model
KW  - MTK
KW  - ROCK
KW  - FlatFish AUV
KW  - Navigation
KW  - Mathematical model
KW  - Accelerometers
KW  - Damping
KW  - Uncertainty
KW  - Acoustics
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8460839
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a manifold based Unscented Kalman Filter that applies a novel strategy for inertial, model-aiding and Acoustic Doppler Current Profiler (ADCP) measurement incorporation. The filter is capable of observing and utilizing the Earth rotation for heading estimation with a tactical grade IMU, and utilizes information from the vehicle model during DVL drop outs. The drag and thrust model-aiding accounts for the correlated nature of vehicle model parameter error by applying them as states in the filter. ADCP-aiding provides further information for the model-aiding in the case of DVL bottom-lock loss. Additionally this work was implemented using the MTK and ROCK framework in C++, and is capable of running in real-time on computing available on the FlatFish AUV. The IMU biases are estimated in a fully coupled approach in the navigation filter. Heading convergence is shown on a real-world data set. Further experiments show that the filter is capable of consistent positioning, and data denial validates the method for DVL dropouts due to very low or high altitude scenarios.
ER  - 

TY  - CONF
TI  - Preliminary Evaluation of Cooperative Navigation of Underwater Vehicles without a DVL Utilizing a Dynamic Process Model
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4897
EP  - 4904
AU  - Z. J. Harris
AU  - L. L. Whitcomb
PY  - 2018
KW  - attitude control
KW  - autonomous underwater vehicles
KW  - Global Positioning System
KW  - marine control
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - sensors
KW  - velocity measurement
KW  - preliminary evaluation
KW  - dynamic process model
KW  - fully dynamic vehicle process model
KW  - acoustic modem
KW  - surface vehicle
KW  - at-sea experimental trials
KW  - JHU Iver3 autonomous underwater vehicle
KW  - underwater vehicle navigation
KW  - DVL acoustic bottom-lock range
KW  - kinematic process model
KW  - dynamical process model
KW  - submerged vehicle
KW  - underwater communication
KW  - velocity measurements
KW  - attitude sensor
KW  - Acoustics
KW  - Underwater vehicles
KW  - Kinematics
KW  - Global Positioning System
KW  - Sensors
DO  - 10.1109/ICRA.2018.8460970
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper reports a preliminary study for use of a fully dynamic vehicle process model in combined underwater communication and navigation (cooperative navigation) of underwater vehicles equipped with an acoustic modem, attitude, and depth sensors, but lacking a Doppler velocity log (DVL), and a surface vehicle equipped with an acoustic modem and GPS. We report both simulation and at-sea experimental trials with the JHU Iver3 autonomous underwater vehicle (AUV). The case of underwater vehicle navigation without a DVL is of interest in several use-cases including (a) small and low-cost underwater vehicles for which DVLs may be impractical or infeasible due to their size and cost and (b) for missions in which the vehicle's altitude above the sea floor (or depth beneath overhead ice) exceeds the DVL acoustic bottom-lock range. To the best of our knowledge, all previous studies on cooperative navigation have reported use of a kinematic process model, which works well in the presence of frequent, high-accuracy velocity measurements, as is the case when the vehicle is equipped with a DVL. This preliminary study suggests that the dynamical process model may offer a significant advantage over the purely kinematic model in the absence of frequent, high-accuracy velocity measurements, as is the case when the submerged vehicle is not equipped with a DVL.
ER  - 

TY  - CONF
TI  - Self-Calibration of Mobile Manipulator Kinematic and Sensor Extrinsic Parameters Through Contact-Based Interaction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4913
EP  - 4920
AU  - O. Limoyo
AU  - T. Ablett
AU  - F. Marić
AU  - L. Volpatti
AU  - J. Kelly
PY  - 2018
KW  - calibration
KW  - computer graphics
KW  - end effectors
KW  - image registration
KW  - image sensors
KW  - manipulator kinematics
KW  - mobile robots
KW  - robot vision
KW  - mobile manipulator platform
KW  - mobile manipulator kinematic parameters
KW  - calibration rigs
KW  - centimetre-level post-calibration accuracy
KW  - end effector
KW  - registration algorithm
KW  - sensor extrinsic parameters
KW  - contact-based interaction
KW  - mobile manipulator self-calibration
KW  - point cloud registration
KW  - fixed vision sensor
KW  - mobile base
KW  - sensor calibration
KW  - manipulator kinematic model parameters
KW  - nonrigid registration process
KW  - on-board sensing
KW  - external measurement devices
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Manipulators
KW  - Calibration
KW  - Cameras
KW  - Kinematics
KW  - Transforms
DO  - 10.1109/ICRA.2018.8460658
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a novel approach for mobile manipulator self-calibration using contact information. Our method, based on point cloud registration, is applied to estimate the extrinsic transform between a fixed vision sensor mounted on a mobile base and an end effector. Beyond sensor calibration, we demonstrate that the method can be extended to include manipulator kinematic model parameters, which involves a nonrigid registration process. Our procedure uses on-board sensing exclusively and does not rely on any external measurement devices, fiducial markers, or calibration rigs. Further, it is fully automatic in the general case. We experimentally validate the proposed method on a custom mobile manipulator platform, and demonstrate centimetre-level post-calibration accuracy in positioning of the end effector using visual guidance only. We also discuss the stability properties of the registration algorithm, in order to determine the conditions under which calibration is possible.
ER  - 

TY  - CONF
TI  - Geometry Based Self Kinematic Calibration Method for Industrial Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4921
EP  - 4926
AU  - T. Messay-Kebede
AU  - G. Sutton
AU  - O. Djaneye-Boundjou
PY  - 2018
KW  - calibration
KW  - coordinate measuring machines
KW  - geometry
KW  - industrial robots
KW  - particle swarm optimisation
KW  - robot kinematics
KW  - industrial setting
KW  - kinematic calibration methodology
KW  - external metrology device
KW  - kinematic calibration model
KW  - optimal parameters/characteristics
KW  - Particle Swarm Optimization technique
KW  - Coordinate Measurement Machine
KW  - PSO
KW  - CMM
KW  - Yaskawa Motoman MHS-Hi robot
KW  - Yaskawa Motoman MHS-Hi robot
KW  - industrial robots
KW  - geometry based self kinematic calibration method
KW  - anthropomorphic robots
KW  - Robot kinematics
KW  - Calibration
KW  - Probes
KW  - Metrology
KW  - Bars
KW  - Data acquisition
DO  - 10.1109/ICRA.2018.8460764
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Accuracy of robots is an important facet in an industrial setting. In this paper, we present a novel kinematic calibration methodology. Traditional calibration techniques require an external metrology device. Unlike those, the presented product here is highly practical in that it does not require a metrology device. The kinematic calibration model is formulated by making use of the robot itself as a metrology device to measure the geometry of a known artifact. The optimal parameters/characteristics of the model are identified using a Particle Swarm Optimization (PSO) technique. Our experimental results show that this new approach provides results comparable to those generated using spatial information provided by a Coordinate Measurement Machine (CMM). Using this new approach (GageCAL), the Yaskawa Motoman “MHS-Hi” robot is calibrated. Our experimental testing also indicates that this methodology can be extended to a wide variety of anthropomorphic robots.
ER  - 

TY  - CONF
TI  - Inertial Parameters Identification of a Humanoid Robot Hanged to a Fix Force Sensor
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4927
EP  - 4932
AU  - V. Bonnet
AU  - A. Crosnier
AU  - G. Venture
AU  - M. Gautier
AU  - P. Fraisse
PY  - 2018
KW  - CAD
KW  - force sensors
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - parameter estimation
KW  - path planning
KW  - robot dynamics
KW  - fix force sensor
KW  - model-based controller
KW  - motion planning
KW  - dynamic identification
KW  - dynamic motions
KW  - safe fix base tree structure robot
KW  - optimal exciting motions
KW  - HOAP3 humanoid robot
KW  - 6-axis force sensor
KW  - computer aided design data
KW  - inertial parameter identification
KW  - Humanoid robots
KW  - Force sensors
KW  - Dynamics
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Optimization
DO  - 10.1109/ICRA.2018.8461112
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Knowledge of the mass and inertial parameters of a humanoid robot is crucial for the development of model-based controller and motion planning in dynamics situation. Parameters are usually provided from Computer Aided Design (CAD) data and thus inaccurate specially if the robot is modified over time. In this paper, a practical method consisting of hanging a humanoid robot to a fix force sensor to perform its dynamic identification is proposed. This allows, contrary to the literature, to generate very exciting and dynamic motions to identify most of the elements of the inertia tensors in a reduced amount of time. This procedure transforms an instable floating base legged humanoid robot to a safe fix base tree structure robot which makes easier to generate optimal exciting motions. Because of a better excitation the overall trajectory lasts for less than a minute. The method was experimentally validated with a HOAP3 humanoid robot and using a 6-axis force sensor. A reduction of 3 times in average of the RMS difference between measured external reaction forces and moments and their estimates from CAD data was obtained with a single minute of optimal exciting motions.
ER  - 

TY  - CONF
TI  - Online System Identification and Calibration of Dynamic Models for Autonomous Ground Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4933
EP  - 4939
AU  - S. Aghli
AU  - C. Heckman
PY  - 2018
KW  - calibration
KW  - mobile robots
KW  - vehicles
KW  - wheels
KW  - high-fidelity dynamical model
KW  - constant time algorithm
KW  - autonomous ground vehicles
KW  - dynamic models
KW  - online system identification
KW  - scale four wheel drive vehicle
KW  - estimated parameter
KW  - model parameters
KW  - informative motion segments
KW  - robotic platform
KW  - Calibration
KW  - Vehicle dynamics
KW  - Motion segmentation
KW  - Dynamics
KW  - Wheels
KW  - Friction
DO  - 10.1109/ICRA.2018.8460691
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper is concerned with system identification and the calibration of parameters of dynamic models used in different robotic platforms. A constant time algorithm has been developed in order to automatically calibrate the parameters of a high-fidelity dynamical model for a robotic platform. The presented method is capable of choosing informative motion segments in order to calibrate model parameters in constant time while also calculating a confidence level on each estimated parameter. Simulations and experiments with a ⅛ th scale four wheel drive vehicle are performed to calibrate two of the parameters of test vehicle which demonstrate the accuracy and efficiency of the approach.
ER  - 

TY  - CONF
TI  - On Geometric Models and Their Accuracy for Extrinsic Sensor Calibration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4948
EP  - 4954
AU  - K. Huang
AU  - C. Stachniss
PY  - 2018
KW  - calibration
KW  - geometry
KW  - numerical analysis
KW  - sensors
KW  - extrinsic sensor calibration methods
KW  - robotics
KW  - numerical simulation
KW  - abstract geometric model
KW  - Calibration
KW  - Cameras
KW  - Estimation
KW  - Task analysis
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8461029
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Extrinsic sensor calibration is an important task in robotics. There are various ways to perform the calibration task, but it often remains unclear which methods are better than the others. In this paper, we provide a systematic study about the calibration accuracy of three types of calibration methods, each represented by an abstract geometric model based on the sensor configuration and the calibration setup. We discuss the advantages and disadvantages of each model and perform a rigorous study on their noise sensitivity from a geometric perspective. As a result, we can reveal and quantify the relative calibration accuracies of the three models, thus answering the question of “which model is better and why?”. Beside our analytical analysis, we also provide numerical simulation experiments that validate our findings.
ER  - 

TY  - CONF
TI  - Dynamic Modeling and Identification of an Heterogeneously Actuated Underwater Manipulator Arm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4955
EP  - 4960
AU  - F. Leborne
AU  - V. Creuze
AU  - A. Chemori
AU  - L. Brignone
PY  - 2018
KW  - actuators
KW  - autonomous underwater vehicles
KW  - gears
KW  - manipulators
KW  - mobile robots
KW  - position control
KW  - telerobotics
KW  - arms parameters
KW  - linear actuators
KW  - identification procedure
KW  - manipulator arms
KW  - dynamic modeling
KW  - heterogeneously actuated underwater manipulator arm
KW  - electrically driven underwater robot manipulator
KW  - Ifremer's HROV Ariane underwater vehicle
KW  - hybrid remotely operated vehicle
KW  - Manipulator dynamics
KW  - Actuators
KW  - Vehicle dynamics
KW  - Gears
KW  - Friction
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8460963
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper deals with the dynamic modeling and identification of an electrically driven underwater robot manipulator. The proposed study includes the dynamic modeling of the actuators of the arm as well as the identification of the parameters of the model. The proposed method deals with the specific case of heterogeneously actuated arms, namely arms with actuators behaving differently for each joint, being considered at the kinematic level. Indeed, we show how to estimate the arms parameters when some of their revolute joints are directly actuated by geared motors, while the others are actuated by linear actuators. A minimum set of identifiable parameters is determined, and adequate excitation trajectories are generated and used in the identification procedure. Realtime experimental validation on the manipulator arms of Ifremer's HROV (Hybrid Remotely Operated Vehicle) Ariane underwater vehicle demonstrates that the proposed method improves the estimation of the dynamic model.
ER  - 

TY  - CONF
TI  - A General Framework for Flexible Multi-Cue Photometric Point Cloud Registration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4969
EP  - 4976
AU  - B. Della Corte
AU  - I. Bogoslavskyi
AU  - C. Stachniss
AU  - G. Grisetti
PY  - 2018
KW  - image registration
KW  - image sensors
KW  - mobile robots
KW  - sensor fusion
KW  - flexible framework
KW  - general framework
KW  - explicit data association
KW  - flexible multicue photometric point cloud registration
KW  - mobile robots
KW  - mapping systems
KW  - recorded sensor data
KW  - photometric registration
KW  - multiple modalities
KW  - image data streams
KW  - pixel-wise difference
KW  - multichannel images
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Cameras
KW  - Iterative closest point algorithm
KW  - Minimization
KW  - Integrated circuit modeling
KW  - Laser radar
DO  - 10.1109/ICRA.2018.8461049
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The ability to build maps is a key functionality for the majority of mobile robots. A central ingredient to most mapping systems is the registration or alignment of the recorded sensor data. In this paper, we present a general methodology for photometric registration that can deal with multiple different cues. We provide examples for registering RGBD as well as 3D LIDAR data. In contrast to popular point cloud registration approaches such as ICP our method does not rely on explicit data association and exploits multiple modalities such as raw range and image data streams. Color, depth, and normal information are handled in an uniform manner and the registration is obtained by minimizing the pixel-wise difference between two multi-channel images. We developed a flexible and general framework and implemented our approach inside that framework. We also released our implementation as open source C++ code. The experiments show that our approach allows for an accurate registration of the sensor data without requiring an explicit data association or model-specific adaptations to datasets or sensors. Our approach exploits the different cues in a natural and consistent way and the registration can be done at framerate for a typical range or imaging sensor.
ER  - 

TY  - CONF
TI  - Just-in-Time Reconstruction: Inpainting Sparse Maps Using Single View Depth Predictors as Priors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4977
EP  - 4984
AU  - C. S. Weerasekera
AU  - T. Dharmasiri
AU  - R. Garg
AU  - T. Drummond
AU  - I. Reid
PY  - 2018
KW  - convolution
KW  - feature extraction
KW  - image colour analysis
KW  - image fusion
KW  - image reconstruction
KW  - image sensors
KW  - iterative methods
KW  - neural nets
KW  - pose estimation
KW  - recurrent neural nets
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - CRF model
KW  - RGB image
KW  - confidence-based fusion
KW  - realtime inpainting
KW  - convolutional neural networks
KW  - CNN
KW  - ORB-SLAM
KW  - Kinect
KW  - conditional depth error distributions
KW  - pixel-wise confidence weights
KW  - input depth map
KW  - fused depth map
KW  - virtual depth sensor
KW  - single-view depth prediction network
KW  - sparse sensor
KW  - monocular visual SLAM system
KW  - fully dense depth map
KW  - realtime image-guided inpainting
KW  - just-in-time reconstruction
KW  - single view depth predictors
KW  - scale-invariant depth error
KW  - outlier input depth
KW  - LIDAR depth maps
KW  - arbitrary scale
KW  - sparse map
KW  - Image reconstruction
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Three-dimensional displays
KW  - Real-time systems
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8460549
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present “just-in-time reconstruction” as realtime image-guided inpainting of a map with arbitrary scale and sparsity to generate a fully dense depth map for the image. In particular, our goal is to inpaint a sparse map - obtained from either a monocular visual SLAM system or a sparse sensor - using a single-view depth prediction network as a virtual depth sensor. We adopt a fairly standard approach to data fusion, to produce a fused depth map by performing inference over a novel fully-connected Conditional Random Field (CRF) which is parameterized by the input depth maps and their pixel-wise confidence weights. Crucially, we obtain the confidence weights that parameterize the CRF model in a data-dependent manner via Convolutional Neural Networks (CNNs) which are trained to model the conditional depth error distributions given each source of input depth map and the associated RGB image. Our CRF model penalises absolute depth error in its nodes and pairwise scale-invariant depth error in its edges, and the confidence-based fusion minimizes the impact of outlier input depth values on the fused result. We demonstrate the flexibility of our method by real-time inpainting of ORB-SLAM, Kinect, and LIDAR depth maps acquired both indoors and outdoors at arbitrary scale and varied amount of irregular sparsity.
ER  - 

TY  - CONF
TI  - Fast Global Labelling for Depth-Map Improvement Via Architectural Priors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4985
EP  - 4992
AU  - P. Amayo
AU  - P. Piniés
AU  - L. M. Paz
AU  - P. Newman
PY  - 2018
KW  - cameras
KW  - image reconstruction
KW  - spatial variables measurement
KW  - cameras
KW  - planar extraction
KW  - urban environment
KW  - vision-only method
KW  - depth map estimation techniques
KW  - fast global labelling
KW  - Labeling
KW  - Estimation
KW  - Minimization
KW  - Image reconstruction
KW  - Cameras
KW  - Pipelines
KW  - Surface texture
DO  - 10.1109/ICRA.2018.8460192
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Depth map estimation techniques from cameras often struggle to accurately estimate the depth of large textureless regions. In this work we present a vision-only method that accurately extracts planar priors from a viewed scene without making any assumptions of the underlying scene layout. Through a fast global labelling, these planar priors can be associated to the individual pixels leading to more complete depth-maps specifically over large, plain and planar regions that tend to dominate the urban environment. When these depth-maps are deployed to the creation of a vision only dense reconstruction over large scales, we demonstrate reconstructions that yield significantly better results in terms of coverage while still maintaining high accuracy.
ER  - 

TY  - CONF
TI  - A Method to Segment Maps from Different Modalities Using Free Space Layout MAORIS: Map of Ripples Segmentation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4993
EP  - 4999
AU  - M. Mielle
AU  - M. Magnusson
AU  - A. J. Lilienthal
PY  - 2018
KW  - computational geometry
KW  - convolution
KW  - image segmentation
KW  - robot vision
KW  - hand-drawn sketch maps
KW  - segmentation evaluation metric
KW  - ground-truth segmentations
KW  - Voronoi-based segmentation method
KW  - DuDe segmentation method
KW  - ground truth segmentations
KW  - segment maps
KW  - free space layout MAORIS
KW  - navigation maps
KW  - semantic representations
KW  - convolution
KW  - circular kernel
KW  - ripple-like patterns
KW  - Matthews correlation coefficient
KW  - map of ripples segmentation
KW  - Image segmentation
KW  - Merging
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Measurement
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2018.8461128
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - How to divide floor plans or navigation maps into semantic representations, such as rooms and corridors, is an important research question in fields such as human-robot interaction, place categorization, or semantic mapping. While most works focus on segmenting robot built maps, those are not the only types of map a robot, or its user, can use. We present a method for segmenting maps from different modalities, focusing on robot built maps and hand-drawn sketch maps, and show better results than state of the art for both types. Our method segments the map by doing a convolution between the distance image of the map and a circular kernel, and grouping pixels of the same value. Segmentation is done by detecting ripple-like patterns where pixel values vary quickly, and merging neighboring regions with similar values. We identify a flaw in the segmentation evaluation metric used in recent works and propose a metric based on Matthews correlation coefficient (MCC). We compare our results to ground-truth segmentations of maps from a publicly available dataset, on which we obtain a better MCC than the state of the art with 0.98 compared to 0.65 for a recent Voronoi-based segmentation method and 0.70 for the DuDe segmentation method. We also provide a dataset of sketches of an indoor environment, with two possible sets of ground truth segmentations, on which our method obtains an MCC of 0.56 against 0.28 for the Voronoi-based segmentation method and 0.30 for DuDe.
ER  - 

TY  - CONF
TI  - Efficient Continuous-Time SLAM for 3D Lidar-Based Online Mapping
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5000
EP  - 5007
AU  - D. Droeschel
AU  - S. Behnke
PY  - 2018
KW  - continuous time systems
KW  - entropy
KW  - graph theory
KW  - image registration
KW  - image resolution
KW  - laser ranging
KW  - optical radar
KW  - SLAM (robots)
KW  - solid modelling
KW  - stereo image processing
KW  - laser-range scanners
KW  - high data rate
KW  - 3D laser scanner
KW  - surfel-based registration
KW  - recursive state estimation
KW  - multiresolution maps
KW  - continuous-time SLAM
KW  - 3D lidar-based online mapping
KW  - online simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Measurement by laser beam
KW  - Optimization
KW  - Trajectory
KW  - Laser modes
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8461000
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Modern 3D laser-range scanners have a high data rate, making online simultaneous localization and mapping (SLAM) computationally challenging. Recursive state estimation techniques are efficient but commit to a state estimate immediately after a new scan is made, which may lead to misalignments of measurements. We present a 3D SLAM approach that allows for refining alignments during online mapping. Our method is based on efficient local mapping and a hierarchical optimization back-end. Measurements of a 3D laser scanner are aggregated in local multiresolution maps by means of surfel-based registration. The local maps are used in a multi-level graph for allocentric mapping and localization. In order to incorporate corrections when refining the alignment, the individual 3D scans in the local map are modeled as a sub-graph and graph optimization is performed to account for drift and misalignments in the local maps. Furthermore, in each sub-graph, a continuous-time representation of the sensor trajectory allows to correct measurements between scan poses. We evaluate our approach in multiple experiments by showing qualitative results. Furthermore, we quantify the map quality by an entropy-based measure.
ER  - 

TY  - CONF
TI  - Efficient Mobile Robot Exploration with Gaussian Markov Random Fields in 3D Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5015
EP  - 5021
AU  - C. Wang
AU  - T. Li
AU  - M. Q. -. Meng
AU  - C. De Silva
PY  - 2018
KW  - computer graphics
KW  - Gaussian processes
KW  - indoor environment
KW  - Markov processes
KW  - mobile robots
KW  - sampling methods
KW  - efficient computation algorithm
KW  - GMRF model hyperparameters
KW  - information gain
KW  - efficient mobile robot exploration
KW  - autonomous exploration
KW  - unknown indoor environments
KW  - mutual information
KW  - MI
KW  - informative sensing location
KW  - sampling method
KW  - random sensing patches
KW  - sensing patch
KW  - informative locations
KW  - training sample patches
KW  - established GMRF model
KW  - Gaussian Markov random fields
KW  - Gaussian process model
KW  - Robot sensing systems
KW  - Computational modeling
KW  - Mathematical model
KW  - Training
KW  - Mutual information
DO  - 10.1109/ICRA.2018.8460788
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we study the problem of autonomous exploration in unknown indoor environments using mobile robot. We use mutual information (MI) to evaluate the information the robot would get at a certain location. In order to get the most informative sensing location, we first propose a sampling method that can get random sensing patches in free space. Each sensing patch is extended to informative locations to collect information with true values. Then we use Gaussian Markov Random Fields (GMRF) to model the distribution of MI in environment. Compared with the traditional methods that employ Gaussian Process (GP) model, GMRF is more efficient. MI of every sensing location can be estimated using the training sample patches and the established GMRF model. We utilize an efficient computation algorithm to estimate the GMRF model hyperparameters so as to speed up the computation. Besides the information gain of the candidates regions, the path cost is also considered in this work. We propose a utility function that can balance the path cost and the information gain the robot would collect. We tested our algorithm in both simulated and real experiment. The experiment results demonstrate that our proposed method can explore the environment efficiently with relatively shorter path length.
ER  - 

TY  - CONF
TI  - A Scalable Multi-Robot Task Allocation Algorithm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5022
EP  - 5027
AU  - C. Sarkar
AU  - H. S. Paul
AU  - A. Pal
PY  - 2018
KW  - computational complexity
KW  - industrial robots
KW  - mobile robots
KW  - multi-robot systems
KW  - nearest neighbour methods
KW  - pattern clustering
KW  - vehicle routing
KW  - warehouse automation
KW  - CVRP instance
KW  - nCAR
KW  - scalable multirobot task allocation algorithm
KW  - modern warehouses
KW  - docking station
KW  - route planning
KW  - capacity-constrained vehicle routing problem
KW  - nearest-neighbor based clustering and routing
KW  - Task analysis
KW  - Heuristic algorithms
KW  - Clustering algorithms
KW  - Resource management
KW  - Routing
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460886
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In modern warehouses, robots are being deployed to perform complex tasks such as fetching a set of objects from various locations in a warehouse to a docking station. This requires a careful task allocation along with route planning such that the total distance traveled (cost) is minimized. The number of tasks that can be performed by a robot on a single route depends on the maximum capacity of the robot and the combined weight of the objects it picks on the route. This task allocation problem is an instance of the Capacity-constrained Vehicle Routing Problem (CVRP), which is known to be NP-hard. Although, there exist a number of heuristics that provide near-optimal solutions to a CVRP instance, they do not scale well with the task size (number of nodes). In this paper, we present a heuristic, called nearest-neighbor based Clustering And Routing (nCAR), which has better execution time compared to the state-of-the-art heuristics. Also, our heuristic reduces cost of the solutions when there are a large number of nodes. We compare the performance of nCAR with the Google OR-Tools and found a speedup of 6 in runtime when task size is 2000. Though OR-Tools provides a low-cost solution for small number of tasks, it's execution time and number of routes is 1.5 times that of nCAR.
ER  - 

TY  - CONF
TI  - Distributed Intermittent Communication Control of Mobile Robot Networks Under Time-Critical Dynamic Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5028
EP  - 5033
AU  - Y. Kantaros
AU  - M. M. Zavlanos
PY  - 2018
KW  - control engineering computing
KW  - distributed control
KW  - mobile robots
KW  - multi-robot systems
KW  - protocols
KW  - scheduling
KW  - time-critical dynamic tasks
KW  - offline schedules
KW  - mobile robot networks
KW  - distributed intermittent communication control
KW  - task accomplishment
KW  - task planning
KW  - communication events
KW  - distributed control framework
KW  - communication constraints
KW  - intermittent communication protocols
KW  - connected networks
KW  - reliable networks
KW  - robot communication capabilities
KW  - Task analysis
KW  - Robot sensing systems
KW  - Time factors
KW  - Schedules
KW  - Communication networks
DO  - 10.1109/ICRA.2018.8460570
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we develop a distributed intermittent communication framework for teams of mobile robots that are responsible for accomplishing time-critical dynamic tasks and sharing the collected information with all other robots and possibly also with a user. Specifically, we consider situations where the robot communication capabilities are not sufficient to maintain reliable and connected networks while the robots move to accomplish their tasks. In this case, intermittent communication protocols are necessary that allow the robots to temporarily disconnect from the network in order to accomplish their tasks free of communication constraints. We assume that the robots can only communicate with each other when they meet at common locations in space. Our proposed distributed control framework determines offline schedules of communication events and integrates them online with task planning. The resulting paths ensure task accomplishment and exchange of information among robots infinitely often at locations that minimize a user-specified metric. Simulation results corroborate the proposed distributed control framework.
ER  - 

TY  - CONF
TI  - Landmark-based Exploration with Swarm of Resource Constrained Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5034
EP  - 5041
AU  - R. Ramaithititima
AU  - S. Bhattacharya
PY  - 2018
KW  - distance measurement
KW  - Global Positioning System
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - robot vision
KW  - sensor fusion
KW  - landmark-based exploration
KW  - resource constrained robots
KW  - autonomous exploration
KW  - topological representation
KW  - topological information
KW  - exploitation strategy
KW  - robot swarm
KW  - GPS-denied environment
KW  - sensing capabilities
KW  - range sensor
KW  - dense landmarks
KW  - bearing angles
KW  - metric information
KW  - local navigation
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Navigation
KW  - Dispersion
KW  - Measurement
DO  - 10.1109/ICRA.2018.8460884
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we consider the problem of autonomous exploration of an unknown, GPS-denied environment using a swarm of robots with very limited resources and limited sensing capabilities. To that end we use a landmark complex, a simplicial complex utilizing an observation of landmarks, as a topological representation of the environment. Each robot is equipped with an omni-directional, limited-range sensor that can identify landmarks in the robot's neighborhood. The robots use the bearing angles to the landmarks for local navigation. Given a collection of identifiable landmarks, a landmark complex can then be cumulatively constructed to encapsulate the topological information of the environment. Under the assumption of sufficiently dense landmarks, we propose an exploration and exploitation strategy that guides the swarm of robots to explore an environment using only bearing measurements without any metric information. Lastly, we demonstrate the coordinate-free and localization-free navigation in the environment using the constructed landmark complex.
ER  - 

TY  - CONF
TI  - Coverage Control for Wire-Traversing Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5042
EP  - 5047
AU  - G. Notomista
AU  - M. Egerstedt
PY  - 2018
KW  - gradient methods
KW  - minimisation
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - continuous constrained coverage control problem
KW  - mobile robots
KW  - COW map
KW  - Continuous Onto Wires map
KW  - constrained locational cost minimization
KW  - final projection step
KW  - Lloyd descent algorithm
KW  - planar environment
KW  - continuous motion
KW  - one-dimensional manifolds
KW  - two-dimensional motion
KW  - wire-traversing robots
KW  - Wires
KW  - Minimization
KW  - Robot sensing systems
KW  - Optimization
KW  - Motion control
KW  - Power transmission lines
DO  - 10.1109/ICRA.2018.8461123
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we consider the coverage control problem for a team of wire-traversing robots. The two-dimensional motion of robots moving in a planar environment has to be projected to one-dimensional manifolds representing the wires. Starting from Lloyd's descent algorithm for coverage control, a solution that generates continuous motion of the robots on the wires is proposed. This is realized by means of a Continuous Onto Wires (COW) map: the robots' workspace is mapped onto the wires on which the motion of the robots is constrained to be. A final projection step is introduced to ensure that the configuration of the robots on the wires is a local minimizer of the constrained locational cost. An algorithm for the continuous constrained coverage control problem is proposed and it is tested both in simulation and on a team of mobile robots.
ER  - 

TY  - CONF
TI  - Control of Multiple Passive-Follower Type Robots Based on Feasible Braking Control Region Analysis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5056
EP  - 5061
AU  - Y. Hirata
AU  - K. Kimura
AU  - S. Matsuzaki
AU  - N. Ogawa
AU  - T. Kubota
PY  - 2018
KW  - brakes
KW  - braking
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - wheels
KW  - braking control region analysis
KW  - passive mobile robot
KW  - wheel
KW  - formation control
KW  - control law
KW  - passive robot
KW  - fundamental control method
KW  - active leader
KW  - multiple mobile robots
KW  - external pulling force
KW  - servo brakes
KW  - multiple passive-follower type robots
KW  - Mobile robots
KW  - Force
KW  - Wheels
KW  - Robot kinematics
KW  - Brakes
KW  - Torque
DO  - 10.1109/ICRA.2018.8460637
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Ahstract- In this study, we propose a development and formation control of a passive mobile robot equipped only with servo brakes and no motors. The developed passive mobile robot can move forward by utilizing an external pulling force, and steers itself by controlling the servo brakes attached to each wheel. Systems composed of multiple mobile robots are very effective at exploring vast areas. However the coordination and simultaneous control of several robots utilizing simple information is a difficult task. Therefore we propose a leader follower architecture composed of multiple passive follower robots tethered to one active leader. In this paper, we first introduce the developed passive mobile robot. Then, we analyze the fundamental control method of this passive mobile robot from the perspective of the feasible braking control region, which considers the slip of the passive robot and the limitation of the external pulling force from the active leader. Lastly, a control law for the servo brakes attached to each wheel is proposed, followed by a feasibility study to determine whether the passive followers can stay in formation by controlling the servo brakes with the proposed control law.
ER  - 

TY  - CONF
TI  - Voronoi-Based Coverage Control of Pan/Tilt/Zoom Camera Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5062
EP  - 5069
AU  - O. Arslan
AU  - H. Min
AU  - D. E. Koditschek
PY  - 2018
KW  - cameras
KW  - computational geometry
KW  - event distribution
KW  - activity distribution
KW  - reactive coverage control algorithm
KW  - greedy gradient algorithms
KW  - pan camera network
KW  - tilt camera network
KW  - zoom camera network
KW  - continuous-and discrete-time first-order PTZ camera dynamics
KW  - coverage algorithms
KW  - locally optimal coverage configuration
KW  - first-order PTZ camera dynamics
KW  - camera network allocation problem
KW  - sensing quality measures
KW  - conic Voronoi diagrams
KW  - visual sensing quality
KW  - total coverage quality
KW  - camera orientations
KW  - PTZ camera networks
KW  - automated active network reconfiguration
KW  - flexible visual monitoring
KW  - Cameras
KW  - Sensors
KW  - Heuristic algorithms
KW  - Visualization
KW  - Resource management
KW  - Image resolution
KW  - Optimization
DO  - 10.1109/ICRA.2018.8460701
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A challenge of pan/tilt/zoom (PTZ) camera networks for efficient and flexible visual monitoring is automated active network reconfiguration in response to environmental stimuli. In this paper, given an event/activity distribution over a convex environment, we propose a new provably correct reactive coverage control algorithm for PTZ camera networks that continuously (re) configures camera orientations and zoom levels (i.e., angles of view) in order to locally maximize their total coverage quality. Our construction is based on careful modeling of visual sensing quality that is consistent with the physical nature of cameras, and we introduce a new notion of conic Voronoi diagrams, based on our sensing quality measures, to solve the camera network allocation problem: that is, to determine where each camera should focus in its field of view given all the other cameras' configurations. Accordingly, we design simple greedy gradient algorithms for both continuous-and discrete-time first-order PTZ camera dynamics that asymptotically converge a locally optimal coverage configuration. Finally, we provide numerical and experimental evidence demonstrating the effectiveness of the proposed coverage algorithms.
ER  - 

TY  - CONF
TI  - Shaping in Practice: Training Wheels to Learn Fast Hopping Directly in Hardware
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5076
EP  - 5081
AU  - S. Heim
AU  - F. Ruppert
AU  - A. A. Sarvestani
AU  - A. Spröwitz
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - robust control
KW  - temporary modifications
KW  - physical hardware
KW  - robot leg
KW  - reward landscape
KW  - fast hopping
KW  - robot controllers
KW  - engineering effort
KW  - potentially unstable parameters
KW  - training wheels
KW  - video synopsis
KW  - boom learning
KW  - robustness
KW  - Legged locomotion
KW  - Training
KW  - Wheels
KW  - Hardware
KW  - Hip
DO  - 10.1109/ICRA.2018.8460984
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Learning instead of designing robot controllers can greatly reduce engineering effort required, while also emphasizing robustness. Despite considerable progress in simulation, applying learning directly in hardware is still challenging, in part due to the necessity to explore potentially unstable parameters. We explore the concept of shaping the reward landscape with training wheels; temporary modifications of the physical hardware that facilitate learning. We demonstrate the concept with a robot leg mounted on a boom learning to hop fast. This proof of concept embodies typical challenges such as instability and contact, while being simple enough to empirically map out and visualize the reward landscape. Based on our results we propose three criteria for designing effective training wheels for learning in robotics. A video synopsis can be found at https://youtu.be/6iH5E3LrYh8.
ER  - 

TY  - CONF
TI  - Speeding Up Incremental Learning Using Data Efficient Guided Exploration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5082
EP  - 5089
AU  - M. Hazara
AU  - V. Kyrki
PY  - 2018
KW  - Bayes methods
KW  - generalisation (artificial intelligence)
KW  - learning (artificial intelligence)
KW  - regression analysis
KW  - search problems
KW  - global parametric model
KW  - model-free policy search agent
KW  - model selection
KW  - Bayes method
KW  - online incremental learning
KW  - data uncertainty
KW  - reinforcement learning
KW  - probabilistic models
KW  - motor primitives
KW  - data efficient guided exploration
KW  - Task analysis
KW  - Uncertainty
KW  - Covariance matrices
KW  - Adaptation models
KW  - Computational modeling
KW  - Parametric statistics
KW  - Predictive models
DO  - 10.1109/ICRA.2018.8461241
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To cope with varying conditions, motor primitives (MPs) must support generalization over task parameters to avoid learning separate primitives for each situation. In this regard, deterministic and probabilistic models have been proposed for generalizing MPs to new task parameters, thus providing limited generalization. Although generalization of MPs using probabilistic models has been studied, it is not clear how such generalizable models can be learned efficiently. Reinforcement learning can be more efficient when the exploration process is tuned with data uncertainty, thus reducing unnecessary exploration in a data-efficient way. We propose an empirical Bayes method to predict uncertainty and utilize it for guiding the exploration process of an incremental learning framework. The online incremental learning framework uses a single human demonstration for constructing a database of MPs. The main ingredients of the proposed framework are a global parametric model (GPDMP) for generalizing MPs for new situations, a model-free policy search agent for optimizing the failed predicted MPs, model selection for controlling the complexity of GPDMp, and empirical Bayes for extracting the uncertainty of MPs prediction. Experiments with a ball-in-a-cup task demonstrate that the global GPDMP model generalizes significantly better than linear models and Locally Weighted Regression especially in terms of extrapolation capability. Furthermore, the model selection has successfully identified the required complexity of GPDMP even with few training samples while satisfying the Occam Razor's prinicple. Above all, the uncertainty predicted by the proposed empirical Bayes approach successfully guided the exploration process of the model-free policy search. The experiments indicated statistically significant improvement of learning speed over covariance matrix adaptation (CMA) with a significance of p=0.002.
ER  - 

TY  - CONF
TI  - Eager and Memory-Based Non-Parametric Stochastic Search Methods for Learning Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5090
EP  - 5096
AU  - V. Barbaros
AU  - H. van Hoof
AU  - A. Abdolmaleki
AU  - D. Megerl
PY  - 2018
KW  - learning systems
KW  - nonparametric statistics
KW  - optimisation
KW  - robots
KW  - search problems
KW  - stochastic processes
KW  - learning control
KW  - direct policy search
KW  - complex problems
KW  - nonparametric methods
KW  - robot skill learning
KW  - memory-based learner
KW  - hybrid controller
KW  - memory-based non-parametric stochastic search methods
KW  - computing schedules
KW  - robot controller parameter optimisation
KW  - Stochastic processes
KW  - Robots
KW  - Search methods
KW  - Task analysis
KW  - Entropy
KW  - Computational modeling
KW  - Kernel
DO  - 10.1109/ICRA.2018.8460633
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Direct policy search has shown to be a successful method to optimize robot controller parameters. However, defining a good parametric form for the controller can be challenging for complex problems. Non-parametric methods provide a flexible alternative and are thus a promising tool in robot skill learning. In this paper, we investigate two nonparametric methods based on similar principles but utilizing differing computing schedules: an eager learner and a memory-based learner. We compare the methods experimentally on two different control problems. Furthermore, we define and evaluate a new `hybrid' controller that combines the strong points of both of these methods.
ER  - 

TY  - CONF
TI  - Data-driven Construction of Symbolic Process Models for Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5105
EP  - 5112
AU  - E. Derner
AU  - J. Kubalík
AU  - R. Babuška
PY  - 2018
KW  - genetic algorithms
KW  - Internet
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pendulums
KW  - time-varying systems
KW  - time varying dynamics
KW  - controlling systems
KW  - data driven construction
KW  - online
KW  - single node genetic programming
KW  - SNGP
KW  - pendulum swing up problem
KW  - training data
KW  - accurate models
KW  - real-time experiments
KW  - simulated mobile robot
KW  - realtime robot control
KW  - analytic equations
KW  - parsimonious models
KW  - symbolic regression
KW  - acceptable policy
KW  - RL
KW  - reinforcement learning
KW  - symbolic process models
KW  - Mathematical model
KW  - Data models
KW  - Learning (artificial intelligence)
KW  - Computational modeling
KW  - Mobile robots
KW  - Genetic programming
KW  - Model learning for control
KW  - AI-based methods
KW  - symbolic regression
KW  - reinforcement learning
KW  - optimal control
DO  - 10.1109/ICRA.2018.8461182
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Reinforcement learning (RL) is a suitable approach for controlling systems with unknown or time-varying dynamics. RL in principle does not require a model of the system, but before it learns an acceptable policy, it needs many unsuccessful trials, which real robots usually cannot withstand. It is well known that RL can be sped up and made safer by using models learned online. In this paper, we propose to use symbolic regression to construct compact, parsimonious models described by analytic equations, which are suitable for realtime robot control. Single node genetic programming (SNGP) is employed as a tool to automatically search for equations fitting the available data. We demonstrate the approach on two benchmark examples: a simulated mobile robot and the pendulum swing-up problem; the latter both in simulations and real-time experiments. The results show that through this approach we can find accurate models even for small batches of training data. Based on the symbolic model found, RL can control the system well.
ER  - 

TY  - CONF
TI  - PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-Based Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5113
EP  - 5120
AU  - A. Faust
AU  - K. Oslund
AU  - O. Ramirez
AU  - A. Francis
AU  - L. Tapia
AU  - M. Fiser
AU  - J. Davidson
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - neural nets
KW  - path planning
KW  - probability
KW  - robot dynamics
KW  - robot vision
KW  - sampling methods
KW  - sampling based planner
KW  - hierarchical method
KW  - sampling based path planning
KW  - large scale topology
KW  - probabilistic roadmaps
KW  - feature based deep neural net policies
KW  - continuous state
KW  - action spaces
KW  - simulation
KW  - office environments
KW  - aerial cargo delivery
KW  - urban environments
KW  - load displacement constraints
KW  - trajectories
KW  - noisy sensor conditions
KW  - flights
KW  - training
KW  - PRM RL
KW  - long range robotic navigation tasks
KW  - point to point navigation policies
KW  - end to end differential drive indoor navigation
KW  - nontrivial robot dynamics
KW  - robot configurations
KW  - task constraints
KW  - capture robot dynamics
KW  - RL agent
KW  - reinforcement learning
KW  - Task analysis
KW  - Robot sensing systems
KW  - Indoor navigation
KW  - Aerospace electronics
KW  - Learning (artificial intelligence)
DO  - 10.1109/ICRA.2018.8461096
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present PRM-RL, a hierarchical method for long-range navigation task completion that combines sampling-based path planning with reinforcement learning (RL). The RL agents learn short-range, point-to-point navigation policies that capture robot dynamics and task constraints without knowledge of the large-scale topology. Next, the sampling-based planners provide roadmaps which connect robot configurations that can be successfully navigated by the RL agent. The same RL agents are used to control the robot under the direction of the planning, enabling long-range navigation. We use the Probabilistic Roadmaps (PRMs) for the sampling-based planner. The RL agents are constructed using feature-based and deep neural net policies in continuous state and action spaces. We evaluate PRM-RL, both in simulation and on-robot, on two navigation tasks with non-trivial robot dynamics: end-to-end differential drive indoor navigation in office environments, and aerial cargo delivery in urban environments with load displacement constraints. Our results show improvement in task completion over both RL agents on their own and traditional sampling-based planners. In the indoor navigation task, PRM-RL successfully completes up to 215 m long trajectories under noisy sensor conditions, and the aerial cargo delivery completes flights over 1000 m without violating the task constraints in an environment 63 million times larger than used in training.
ER  - 

TY  - CONF
TI  - Using Parameterized Black-Box Priors to Scale Up Model-Based Policy Search for Robotics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5121
EP  - 5128
AU  - K. Chatzilygeroudis
AU  - J. Mouret
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - optimisation
KW  - search problems
KW  - parameterized black-box priors
KW  - robotics
KW  - data-efficient algorithms
KW  - reinforcement learning
KW  - dynamical model
KW  - black-box optimization algorithm
KW  - model-based policy search approaches
KW  - model learning procedure
KW  - high-dimensional systems
KW  - physical hexapod robot
KW  - Black-DROPS algorithm
KW  - Robots
KW  - Data models
KW  - Mathematical model
KW  - Computational modeling
KW  - Heuristic algorithms
KW  - Analytical models
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461083
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The most data-efficient algorithms for reinforcement learning in robotics are model-based policy search algorithms, which alternate between learning a dynamical model of the robot and optimizing a policy to maximize the expected return given the model and its uncertainties. Among the few proposed approaches, the recently introduced Black-DROPS algorithm exploits a black-box optimization algorithm to achieve both high data-efficiency and good computation times when several cores are used; nevertheless, like all model-based policy search approaches, Black-DROPS does not scale to high dimensional state/action spaces. In this paper, we introduce a new model learning procedure in Black-DROPS that leverages parameterized black-box priors to (1) scale up to high-dimensional systems, and (2) be robust to large inaccuracies of the prior information. We demonstrate the effectiveness of our approach with the “pendubot” swing-up task in simulation and with a physical hexapod robot (48D state space, 18D action space) that has to walk forward as fast as possible. The results show that our new algorithm is more data-efficient than previous model-based policy search algorithms (with and without priors) and that it can allow a physical 6-legged robot to learn new gaits in only 16 to 30 seconds of interaction time.
ER  - 

TY  - CONF
TI  - Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5129
EP  - 5136
AU  - G. Kahn
AU  - A. Villaflor
AU  - B. Ding
AU  - P. Abbeel
AU  - S. Levine
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - double Q-learning
KW  - self-supervised deep reinforcement learning
KW  - self-supervised training
KW  - model-based methods
KW  - value-based model-free methods
KW  - learning-based methods
KW  - planning method
KW  - internal map
KW  - robot navigation
KW  - generalized computation graph
KW  - Computational modeling
KW  - Navigation
KW  - Learning (artificial intelligence)
KW  - Robots
KW  - Task analysis
KW  - Prediction algorithms
KW  - Planning
DO  - 10.1109/ICRA.2018.8460655
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and N-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.
ER  - 

TY  - CONF
TI  - Direct Line Guidance Odometry
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5137
EP  - 5143
AU  - S. Li
AU  - B. Ren
AU  - Y. Liu
AU  - M. Cheng
AU  - D. Frost
AU  - V. A. Prisacariu
PY  - 2018
KW  - distance measurement
KW  - feature extraction
KW  - robot vision
KW  - SLAM (robots)
KW  - direct line guidance odometry
KW  - pixel intensities
KW  - line-based features
KW  - point-based direct monocular visual odometry method
KW  - visual odometry algorithms
KW  - feature extraction
KW  - keypoint selection
KW  - Feature extraction
KW  - IP networks
KW  - Cameras
KW  - Optimization
KW  - Visual odometry
KW  - Simultaneous localization and mapping
KW  - Computational efficiency
DO  - 10.1109/ICRA.2018.8461003
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Modern visual odometry algorithms utilize sparse point-based features for tracking due to their low computational cost. Current state-of-the-art methods are split between indirect methods that process features extracted from the image, and indirect methods that deal directly on pixel intensities. In recent years, line-based features have been used in SLAM and have shown an increase in performance albeit with an increase in computational cost. In this paper, we propose an extension to a point-based direct monocular visual odometry method. Here we that uses lines to guide keypoint selection rather than acting as features. Points on a line are treated as stronger keypoints than those in other parts of the image, steering point-selection away from less distinctive points and thereby increasing efficiency. By combining intensity and geometry information from a set of points on a line, accuracy may also be increased.
ER  - 

TY  - CONF
TI  - Direct Visual SLAM Using Sparse Depth for Camera-LiDAR System
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5144
EP  - 5151
AU  - Y. Shin
AU  - Y. S. Park
AU  - A. Kim
PY  - 2018
KW  - cameras
KW  - image matching
KW  - motion estimation
KW  - motion measurement
KW  - optical radar
KW  - optical sensors
KW  - optical tracking
KW  - optical windows
KW  - portable instruments
KW  - SLAM (robots)
KW  - sparse depth information
KW  - motion estimation
KW  - pose-graph SLAM
KW  - KITTI odometry benchmark datasets
KW  - direct visual SLAM
KW  - monocular camera
KW  - light detection and ranging
KW  - portable camera-LiDAR mapping system
KW  - direct visual simultaneous localization and mapping
KW  - sliding window-based tracking method
KW  - depth-integrated frame matching
KW  - feature-based visual LiDAR mapping
KW  - sensors
KW  - Cameras
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Visualization
KW  - Simultaneous localization and mapping
KW  - Optimization
DO  - 10.1109/ICRA.2018.8461102
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes a framework for direct visual simultaneous localization and mapping (SLAM) combining a monocular camera with sparse depth information from Light Detection and Ranging (LiDAR). To ensure realtime performance while maintaining high accuracy in motion estimation, we present (i) a sliding window-based tracking method, (ii) strict pose marginalization for accurate pose-graph SLAM and (iii) depth-integrated frame matching for large-scale mapping. Unlike conventional feature-based visual and LiDAR mapping, the proposed approach is direct, eliminating the visual feature in the objective function. We evaluated results using our portable camera-LiDAR system as well as KITTI odometry benchmark datasets. The experimental results prove that the characteristics of two complementary sensors are very effective in improving real-time performance and accuracy. Via validation, we achieved low drift error of 0.98 % in the KITTI benchmark including various environments such as a highway and residential areas.
ER  - 

TY  - CONF
TI  - Bayesian Scale Estimation for Monocular SLAM Based on Generic Object Detection for Correcting Scale Drift
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5152
EP  - 5158
AU  - E. Sucar
AU  - J. Hayet
PY  - 2018
KW  - Bayes methods
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - monocular SLAM system
KW  - Bayesian framework
KW  - deep-learning based generic object detector
KW  - detection region
KW  - scale drift
KW  - monocular systems
KW  - Bayesian scale estimation
KW  - generic object detection
KW  - local scale correction
KW  - object class detection
KW  - KITTI dataset
KW  - quantitative evaluations
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Bayes methods
KW  - Object detection
KW  - Image reconstruction
DO  - 10.1109/ICRA.2018.8461178
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a novel real-time algorithm for estimating the local scale correction of a monocular SLAM system, to obtain a correctly scaled version of the 3D map and of the camera trajectory. Within a Bayesian framework, it integrates observations from a deep-learning based generic object detector and landmarks from the map whose projection lie inside a detection region, to produce scale correction estimates from single frames. For each observation, a prior distribution on the height of the detected object class is used to define the observation's likelihood. Due to the scale drift inherent to monocular SLAM systems, we also incorporate a rough model on the dynamics of scale drift. Quantitative evaluations are presented on the KITTI dataset, and compared with different approaches. The results show a superior performance of our proposal in terms of relative translational error when compared to other monocular systems based on object detection.
ER  - 

TY  - CONF
TI  - Efficient Active SLAM Based on Submap Joining, Graph Topology and Convex Optimization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5159
EP  - 5166
AU  - Y. Chen
AU  - S. Huang
AU  - R. Fitch
AU  - J. Yu
PY  - 2018
KW  - computational complexity
KW  - convex programming
KW  - least squares approximations
KW  - minimisation
KW  - mobile robots
KW  - path planning
KW  - predictive control
KW  - quadratic programming
KW  - robot vision
KW  - SLAM (robots)
KW  - graph topology
KW  - active SLAM problem
KW  - robot trajectory
KW  - area coverage task
KW  - model predictive control framework
KW  - uncertainty minimization MPC problem
KW  - graphical structure
KW  - 2D feature-based SLAM
KW  - variable substitutions
KW  - convex optimization method
KW  - MPC framework
KW  - sequential quadratic programming method
KW  - linear SLAM
KW  - submap joining approach
KW  - planning
KW  - simultaneous localization and mapping
KW  - nonconvex constrained least-squares problem
KW  - Optimized production technology
KW  - Simultaneous localization and mapping
KW  - Uncertainty
KW  - Task analysis
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8460864
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The active SLAM problem considered in this paper aims to plan a robot trajectory for simultaneous localization and mapping (SLAM) as well as for an area coverage task with robot pose uncertainty. Based on a model predictive control (MPC) framework, these two problems are solved respectively by different methods. For the uncertainty minimization MPC problem, based on the graphical structure of the 2D feature-based SLAM, a non-convex constrained least-squares problem is presented to approximate the original problem. Then, using variable substitutions, it is further transformed into a convex problem, and then solved by a convex optimization method. For the coverage task considering robot pose uncertainty, it is formulated and solved by the MPC framework and the sequential quadratic programming (SQP) method. In the whole process, considering the computation complexity, we use linear SLAM, which is a submap joining approach, to reduce the time for planning and estimation. Finally, various simulations are presented to validate the effectiveness of the proposed approach.
ER  - 

TY  - CONF
TI  - 2D SLAM Correction Prediction in Large Scale Urban Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5167
EP  - 5174
AU  - Z. Alsayed
AU  - G. Bresson
AU  - A. Verroust-Blondet
AU  - F. Nashashibi
PY  - 2018
KW  - image representation
KW  - mobile robots
KW  - multilayer perceptrons
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - autonomous mobile robots
KW  - large scale urban environments
KW  - simultaneous location and mapping
KW  - hybrid correction module
KW  - likelihood distributions
KW  - 2D likelihood SLAM approaches
KW  - successive estimated poses
KW  - Ensemble Multilayer Perceptron model
KW  - SLAM estimations
KW  - systematic errors
KW  - sensor measurement errors
KW  - SLAM map representation
KW  - observation model
KW  - motion model
KW  - probabilistic formulation
KW  - Simultaneous localization and mapping
KW  - Two dimensional displays
KW  - Estimation
KW  - Neural networks
KW  - Predictive models
KW  - Kalman filters
DO  - 10.1109/ICRA.2018.8460773
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Simultaneous Localization And Mapping (SLAM) is one of the major bricks needed to build truly autonomous mobile robots. The probabilistic formulation of SLAM is based on two models: the motion model and the observation model. In practice, these models, together with the SLAM map representation, do not model perfectly the robot's real dynamics, the sensor measurement errors and the environment. Consequently, systematic errors affect SLAM estimations. In this paper, we propose two approaches to predict corrections to be applied to SLAM estimations. Both are based on the Ensemble Multilayer Perceptron model. The first approach uses successive estimated poses to predict the errors, with no assumptions on the underlying SLAM process or sensor used. The second method is specific to 2D likelihood SLAM approaches, thus, the likelihood distributions are used to predict the corrections, making this second approach independent of the sensor used. We also build a hybrid correction module based on successive estimated poses and the likelihood distributions. The validity of both approaches is evaluated through two experiments using different evaluation metrics and sensor configurations.
ER  - 

TY  - CONF
TI  - Omnidirectional Multisensory Perception Fusion for Long-Term Place Recognition
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5175
EP  - 5181
AU  - S. Siva
AU  - H. Zhang
PY  - 2018
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - sensor fusion
KW  - SLAM (robots)
KW  - omnidirectional multisensory perception fusion
KW  - long-term place recognition
KW  - long-term autonomy
KW  - omnidirectional sensors
KW  - omnidirectional observation
KW  - multidirectional place recognition
KW  - omnidirectional multisensory data
KW  - appearance variations
KW  - Simultaneous Localization and Mapping
KW  - Feature extraction
KW  - Sensor phenomena and characterization
KW  - Simultaneous localization and mapping
KW  - Optimization
DO  - 10.1109/ICRA.2018.8461042
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation.
ER  - 

TY  - CONF
TI  - Online Initialization and Automatic Camera-IMU Extrinsic Calibration for Monocular Visual-Inertial SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5182
EP  - 5189
AU  - W. Huang
AU  - H. Liu
PY  - 2018
KW  - accelerometers
KW  - calibration
KW  - cameras
KW  - gyroscopes
KW  - inertial navigation
KW  - iterative methods
KW  - mobile robots
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - extrinsic orientation
KW  - extrinsic translation
KW  - accelerometer bias
KW  - camera-IMU extrinsic parameters
KW  - initial values
KW  - visual scale
KW  - initialization stage
KW  - mechanical configuration
KW  - sensor suite changes
KW  - online initialization method
KW  - translation calibration
KW  - initialization procedure
KW  - gyroscope bias
KW  - monocular visual-inertial SLAM techniques
KW  - gyroscope
KW  - gravitational magnitude
KW  - Gyroscopes
KW  - Cameras
KW  - Quaternions
KW  - Accelerometers
KW  - Calibration
KW  - Simultaneous localization and mapping
KW  - Gravity
DO  - 10.1109/ICRA.2018.8460206
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Most of the existing monocular visual-inertial SLAM techniques assume that the camera-IMU extrinsic parameters are known, therefore these methods merely estimate the initial values of velocity, visual scale, gravity, biases of gyroscope and accelerometer in the initialization stage. However, it's usually a professional work to carefully calibrate the extrinsic parameters, and it is required to repeat this work once the mechanical configuration of the sensor suite changes slightly. To tackle this problem, we propose an online initialization method to automatically estimate the initial values and the extrinsic parameters without knowing the mechanical configuration. The biases of gyroscope and accelerometer are considered in our method, and a convergence criteria for both orientation and translation calibration is introduced to identify the convergence and to terminate the initialization procedure. In the three processes of our method, an iterative strategy is firstly introduced to iteratively estimate the gyroscope bias and the extrinsic orientation. Secondly, the scale factor, gravity, and extrinsic translation are approximately estimated without considering the accelerometer bias. Finally, these values are further optimized by a refinement algorithm in which the accelerometer bias and the gravitational magnitude are taken into account. Extensive experimental results show that our method achieves competitive accuracy compared with the state-of-the-art with less calculation.
ER  - 

TY  - CONF
TI  - Sonar Visual Inertial SLAM of Underwater Structures
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5190
EP  - 5196
AU  - S. Rahman
AU  - A. Q. Li
AU  - I. Rekleitis
PY  - 2018
KW  - oceanographic techniques
KW  - SLAM (robots)
KW  - sonar
KW  - underwater sound
KW  - underwater vehicles
KW  - underwater structures
KW  - acoustic range data
KW  - sonar visual inertial SLAM
KW  - visual-inertial state estimation package
KW  - resource management
KW  - marine archaeology
KW  - underwater acoustic sensor
KW  - underwater cave
KW  - underwater wrecks
KW  - underwater domain
KW  - Sonar
KW  - Cameras
KW  - Visualization
KW  - Sonar navigation
KW  - Simultaneous localization and mapping
KW  - Underwater structures
DO  - 10.1109/ICRA.2018.8460545
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents an extension to a state of the art Visual-Inertial state estimation package (OKVIS) in order to accommodate data from an underwater acoustic sensor. Mapping underwater structures is important in several fields, such as marine archaeology, search and rescue, resource management, hydrogeology, and speleology. Collecting the data, however, is a challenging, dangerous, and exhausting task. The underwater domain presents unique challenges in the quality of the visual data available; as such, augmenting the exteroceptive sensing with acoustic range data results in improved reconstructions of the underwater structures. Experimental results from underwater wrecks, an underwater cave, and a submerged bus demonstrate the performance of our approach.
ER  - 

TY  - CONF
TI  - Differential Flatness Transformations for Aggressive Quadrotor Flight
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5204
EP  - 5210
AU  - B. Morrell
AU  - M. Rigter
AU  - G. Merewether
AU  - R. Reid
AU  - R. Thakker
AU  - T. Tzanetos
AU  - V. Rajur
AU  - G. Chamitoff
PY  - 2018
KW  - helicopters
KW  - mobile robots
KW  - stability
KW  - trajectory control
KW  - flight envelope
KW  - hierarchical control
KW  - quadrotor flight
KW  - differential flatness transformation
KW  - trajectory control
KW  - stability issues
KW  - Trajectory
KW  - Attitude control
KW  - Standards
KW  - Acceleration
KW  - Aerospace electronics
KW  - Australia
KW  - Robustness
DO  - 10.1109/ICRA.2018.8460838
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Aggressive maneuvering amongst obstacles could enable advanced capabilities for quadrotors in applications such as search and rescue, surveillance, inspection, and situations where rapid flight is required in cluttered environments. Previous works have treated quadrotors as differentially flat systems, and this property has been exploited widely to design simple algorithms that generate dynamically feasible trajectories and to enable hierarchical control. The differentially flat property allows the full state of the quadrotor to be extracted from the reduced dimensional space of x, y, z, yaw and their derivatives. This differential flatness transformation has a number of singularities, however, as well as stability issues when controlling near these singularities. Many methods have been described in the literature to address these; however, they all have limitations when exploring the full flight envelope of a quadrotor, including roll or pitch angles past 90°, and during inverted flight. In this paper, we review these existing methods and then introduce our method, which combines multiple methods to provide a highly-robust differential flatness transformation that addresses most of these issues. Our approach is demonstrated enabling highly-aggressive quadrotor flight in both simulations and real-world experiments.
ER  - 

TY  - CONF
TI  - Autonomous Control of the Interacting-BoomCopter UAV for Remote Sensor Mounting
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5219
EP  - 5224
AU  - D. R. McArthur
AU  - A. B. Chowdhury
AU  - D. J. Cappelleri
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - finite state machines
KW  - mobile robots
KW  - propellers
KW  - robot vision
KW  - target tracking
KW  - Interacting-BoomCopter UAV
KW  - remote sensor mounting
KW  - sensor package
KW  - vertical surface
KW  - unmanned aerial vehicle
KW  - on-board webcam
KW  - reversible propeller
KW  - aerial manipulation task
KW  - vehicle design
KW  - image processing algorithms
KW  - target tracking
KW  - extended finite state machine
KW  - high-level autonomous control
KW  - autonomous control strategy
KW  - I-BC platform
KW  - autonomous sensor
KW  - Task analysis
KW  - Propellers
KW  - Webcams
KW  - Unmanned aerial vehicles
KW  - Inspection
KW  - Force
KW  - Control systems
DO  - 10.1109/ICRA.2018.8461119
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel approach for autonomously mounting a sensor package on a vertical surface with an unmanned aerial vehicle (UAV). The Interacting-BoomCopter (I-BC) UAV uses an on-board webcam and computer along with a horizontally-mounted reversible propeller on its front boom to autonomously perform the aerial manipulation task. An overview of the vehicle design is presented along with the image processing algorithms used for target tracking, and the implementation of an extended finite state machine (EFSM) for carrying out the high-level autonomous control. The effectiveness of the autonomous control strategy and I-BC platform are examined through the performance of several autonomous sensor mounting flight tests.
ER  - 

TY  - CONF
TI  - Model Predictive Control of a Multi-Rotor with a Suspended Load for Avoiding Obstacles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5233
EP  - 5238
AU  - C. Y. Son
AU  - H. Seo
AU  - T. Kim
AU  - H. Jin Kim
PY  - 2018
KW  - aerospace robotics
KW  - collision avoidance
KW  - helicopters
KW  - mobile robots
KW  - predictive control
KW  - robot dynamics
KW  - vehicle dynamics
KW  - path planning
KW  - trajectory generation algorithms
KW  - MPC
KW  - sequential linear quadratic
KW  - SLQ
KW  - obstacle-avoidance algorithm
KW  - Model Predictive Control
KW  - dynamic environments
KW  - planning algorithms
KW  - multirotor
KW  - suspended load
KW  - Heuristic algorithms
KW  - Trajectory
KW  - Cost function
KW  - Mathematical model
KW  - Vehicle dynamics
KW  - Load modeling
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460749
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper investigates a multi-rotor with a suspended load in perspectives of 1) real-time path planning, 2) obstacle avoidance, and 3) transportation of a suspended object. A suspended load cannot be controlled with conventional controllers designed for nominal multi-rotors due to the dynamic coupling between the multi-rotor and load. Although several control and planning algorithms have been proposed based on elaborately derived dynamic equations, most existing studies separate control and path planning problems by following predefined trajectories after trajectory generation. Moreover, many state-of-the-art trajectory generation algorithms cannot work real-time for a system with high degrees of freedom, which makes it not suitable to operate the system in dynamic environments where obstacles appear abruptly or move unexpectedly. With this in mind, we apply Model Predictive Control (MPC) with Sequential Linear Quadratic (SLQ) solver to compute feasible and optimal trajectory real-time and to operate a multi-rotor with a suspended load in dynamic environments. We design an obstacle-avoidance algorithm suitable for the current platform flying in cluttered environments. Flight experiments shows that the proposed algorithm successfully controls the multi-rotor and allows to avoid obstacles simultaneously.
ER  - 

TY  - CONF
TI  - Asymmetric Collaborative Bar Stabilization Tethered to Two Heterogeneous Aerial Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5247
EP  - 5253
AU  - P. O. Pereira
AU  - P. Roque
AU  - D. V. Dimarogonas
PY  - 2018
KW  - autonomous aerial vehicles
KW  - force
KW  - stability
KW  - three-term control
KW  - asymmetric collaborative bar stabilization tethered
KW  - unmanned aerial vehicles
KW  - rigid links
KW  - tensile forces
KW  - control objective
KW  - PID control law
KW  - decoupled motions
KW  - cascaded motions
KW  - system asymmetries
KW  - cable lengths
KW  - UAV
KW  - systems physical parameters
KW  - Bars
KW  - Force
KW  - Unmanned aerial vehicles
KW  - Dynamics
KW  - Mathematical model
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460529
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider a system composed of a bar tethered to two unmanned aerial vehicles (UAVs), where the cables behave as rigid links under tensile forces, and with the control objective of stabilizing the bar's pose around a desired pose. Each UAV is equipped with a PID control law, and we verify that the bar's motion is decomposable into three decoupled motions, namely a longitudinal, a lateral and a vertical. We then provide relations between the UAV s' gains, which, if satisfied, allows us to decompose each of those motions into two cascaded motions; the latter relations between the UAV s' gains are found so as to counteract the system asymmetries, such as the different cable lengths and the different UAV s' weights. Finally, we provide conditions, based on the system's physical parameters, that describe good and bad types of asymmetries. We present experiments that demonstrate the stabilization of the bar's pose.
ER  - 

TY  - CONF
TI  - Innovative Bio-Impedance Sensor Towards Puncture Detection in Eye Surgery for Retinal Vein Occlusion Treatment
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5343
EP  - 5348
AU  - L. Schoevaerdts
AU  - L. Esteveny
AU  - G. Borghesan
AU  - M. Ourak
AU  - A. Gijbels
AU  - J. Smits
AU  - D. Reynaerts
AU  - E. Vander Poorten
PY  - 2018
KW  - biosensors
KW  - blood vessels
KW  - diseases
KW  - electric impedance
KW  - electric impedance measurement
KW  - eye
KW  - medical image processing
KW  - patient diagnosis
KW  - surgery
KW  - vision defects
KW  - thrombolytic agent flushing
KW  - patient eye lens
KW  - double puncture event detection
KW  - retinal vein occlusion treatment
KW  - innovative bio-impedance sensor
KW  - eye surgery
KW  - clotted retinal vessels
KW  - size 50 micron to 400 micron
KW  - Surgery
KW  - Needles
KW  - Probes
KW  - Retina
KW  - Impedance
KW  - Biosensors
DO  - 10.1109/ICRA.2018.8460205
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - At the moment, surgeons struggle curing a widespread eye disease known as retinal vein occlusion where clots obstruct the retinal vessels. Latter vascular disorder involves black spots in people's eyesight and lead eventually to blindness. A recent promising treatment consists in flushing a thrombolytic agent inside the clotted retinal vessels. The surgery implies puncturing vessels ranging from 50 to 400 microns diameter on the backside of the eye, namely the retina. Latest research succeeded in tackling several challenges around this operation: the surgeon's hand tremor and the high precision required amongst other requirements. Despite several breakthroughs, the surgeon only relies on a microscope to perform the surgery through the patient eye's lens, giving poor depth perception to properly puncture the retinal vessels. This way, the surgeon is most likely to pierce through the vessel and inject the thrombolytic drug under the retina, which would endanger the person's eyesight. In this paper, we investigate the use of a novel bio-impedance sensor developed for eye surgery. Together with this new sensor, a detection algorithm has been developed to detect the puncture and double puncture events to give a feedback to the operator of the system. As far as we are aware of, such technology doesn't exist yet in eye surgery to tackle the depth perception question. This paper aims at demonstrating the benefits of this technology.
ER  - 

TY  - CONF
TI  - Distal End Force Sensing with Optical Fiber Bragg Gratings for Tendon-Sheath Mechanisms in Flexible Endoscopic Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5349
EP  - 5255
AU  - W. Lai
AU  - L. Cao
AU  - Z. Xu
AU  - P. T. Phan
AU  - P. Shum
AU  - S. J. Phee
PY  - 2018
KW  - Bragg gratings
KW  - end effectors
KW  - endoscopes
KW  - feedback
KW  - fibre optic sensors
KW  - force sensors
KW  - friction
KW  - haptic interfaces
KW  - medical robotics
KW  - surgery
KW  - distal end haptic sensing
KW  - compression force
KW  - tension force
KW  - surgical end-effectors
KW  - mechanics analysis
KW  - verification tests
KW  - tendon-sheath driven grasper
KW  - TSMs-driven systems
KW  - distal end force sensing
KW  - optical fiber Bragg gratings
KW  - tendon-sheath mechanisms
KW  - haptic feedback
KW  - endoscopic surgical robots
KW  - transmission systems
KW  - nonlinear friction profiles
KW  - nitinol tube
KW  - FBG fiber
KW  - robotic fingers-hands
KW  - wearable devices
KW  - rehabilitation devices
KW  - Force
KW  - Robot sensing systems
KW  - Tendons
KW  - Fiber gratings
KW  - Haptic Sensing
KW  - Fiber Bragg Gratings
KW  - Flexible Surgical Endoscopic Robot
KW  - Tendon-Sheath Mechanisms
DO  - 10.1109/ICRA.2018.8461090
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Accurate haptic feedback is a critical challenge for surgical robots, especially for flexible endoscopic surgical robots whose transmission systems are Tendon-Sheath Mechanisms (TSMs) with highly nonlinear friction profiles and force hysteresis. For distal end haptic sensing of TSMs, this paper, for the first time, proposes to measure the compression force on the sheath at the distal end so that the tension force on the tendon, which equals the compression force on the sheath, can be obtained. A new force sensor, i.e., a nitinol tube attached with an optical Fiber Bragg Grating (FBG) fiber, is proposed to measure the compression force on the sheath. This sensor, with similar diameter and configuration (hollow) as the sheath, can be compactly integrated with TSMs and surgical end-effectors. In this paper, mechanics analysis and verification tests are presented to reveal the relationship between the tension force on the tendon and the compression force on the sheath. The proposed force sensor was calibrated in tests with a sensitivity of 24.28 pm/N and integrated with a tendon-sheath driven grasper to demonstrate the effectiveness of the proposed approach and sensor. The proposed approach and sensor can also be applied for a variety of TSMs-driven systems, such as robotic fingers/hands, wearable devices, and rehabilitation devices.
ER  - 

TY  - CONF
TI  - Trajectory-Optimized Sensing for Active Search of Tissue Abnormalities in Robotic Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5356
EP  - 5363
AU  - H. Salman
AU  - E. Ayvali
AU  - R. A. Srivatsan
AU  - Y. Ma
AU  - N. Zevallos
AU  - R. Yasin
AU  - L. Wang
AU  - N. Simaan
AU  - H. Choset
PY  - 2018
KW  - end effectors
KW  - Gaussian processes
KW  - knowledge acquisition
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - mobile robots
KW  - position control
KW  - robot kinematics
KW  - surgery
KW  - trajectory optimisation (aerospace)
KW  - tumours
KW  - uncertain systems
KW  - tumors
KW  - Gaussian processes
KW  - stiffness distribution
KW  - palpation path
KW  - acquisition function
KW  - active learning algorithm
KW  - incorporate uncertainties
KW  - robot position
KW  - sensor measurements
KW  - robot-kinematics
KW  - trajectory-optimized sensing
KW  - tissue abnormalities
KW  - da Vinci research kit
KW  - insertable robotic effector platform
KW  - robotic surgery
KW  - 6-DoF industrial arm
KW  - dVRK
KW  - IREP
KW  - Trajectory
KW  - Robot sensing systems
KW  - Optimization
KW  - Uncertainty
KW  - Bayes methods
KW  - Tumors
DO  - 10.1109/ICRA.2018.8460936
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we develop an approach for guiding robots to automatically localize and find the shapes of tumors and other stiff inclusions present in the anatomy. Our approach uses Gaussian processes to model the stiffness distribution and active learning to direct the palpation path of the robot. The palpation paths are chosen such that they maximize an acquisition function provided by an active learning algorithm. Our approach provides the flexibility to avoid obstacles in the robot's path, incorporate uncertainties in robot position and sensor measurements, include prior information about location of stiff inclusions while respecting the robot-kinematics. To the best of our knowledge this is the first work in literature that considers all the above conditions while localizing tumors. The proposed framework is evaluated via simulation and experimentation on three different robot platforms: 6-DoF industrial arm, da Vinci Research Kit (dVRK), and the Insertable Robotic Effector Platform (IREP). Results show that our approach can accurately estimate the locations and boundaries of the stiff inclusions while reducing exploration time.
ER  - 

TY  - CONF
TI  - Active Constraints Using Vector Field Inequalities for Surgical Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5364
EP  - 5371
AU  - M. M. Marinho
AU  - B. V. Adorno
AU  - K. Harada
AU  - M. Mitsuishi
PY  - 2018
KW  - brain
KW  - collision avoidance
KW  - manipulators
KW  - medical robotics
KW  - neurophysiology
KW  - surgery
KW  - vectors
KW  - deep brain neurosurgery
KW  - tremor-free procedures
KW  - robotic assistance
KW  - surgical robots
KW  - manipulator-boundary collisions
KW  - vector field inequality
KW  - active constraints
KW  - surgical tool tips
KW  - endonasal surgery
KW  - Quaternions
KW  - Surgery
KW  - Tools
KW  - Task analysis
KW  - Kinematics
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8461105
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotic assistance allows surgeons to perform dexterous and tremor-free procedures, but is still underrepresented in deep brain neurosurgery and endonasal surgery where the workspace is constrained. In these conditions, the vision of surgeons is restricted to areas near the surgical tool tips, which increases the risk of unexpected collisions between the shafts of the instruments and their surroundings, in particular in areas outside the surgical field-of-view. Active constraints can be used to prevent the tools from entering restricted zones and thus avoid collisions. In this paper, a vector field inequality is proposed that guarantees that tools do not enter restricted zones. Moreover, in contrast with early techniques, the proposed method limits the tool approach velocity in the direction of the forbidden zone boundary, guaranteeing a smooth behavior and that tangential velocities will not be disturbed. The proposed method is evaluated in simulations featuring two eight degrees-of-freedom manipulators that were custom-designed for deep neurosurgery. The results show that both manipulator-manipulator and manipulator-boundary collisions can be avoided using the vector field inequalities.
ER  - 

TY  - CONF
TI  - A Method for Online Optimization of Lower Limb Assistive Devices with High Dimensional Parameter Spaces
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5380
EP  - 5385
AU  - N. Thatte
AU  - H. Duan
AU  - H. Geyer
PY  - 2018
KW  - gait analysis
KW  - handicapped aids
KW  - medical robotics
KW  - advanced prosthesis controls
KW  - control parameters
KW  - optimization method
KW  - offline portion
KW  - intact subject gait data
KW  - neuromuscular control policy
KW  - ankle prosthesis
KW  - high-dimensional parameter spaces
KW  - parameter selection process
KW  - offline optimization procedure
KW  - dueling bandits problem
KW  - assistive lower-limb devices
KW  - control policies
KW  - lower limb assistive devices
KW  - online optimization
KW  - Knee
KW  - Prosthetics
KW  - Optimization
KW  - Torque
KW  - Neuromuscular
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460953
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a method for optimizing control policies for assistive lower-limb devices. The method frames parameter selection as a dueling bandits problem in which a user indicates his or her qualitative preferences between pairs of parameter sets chosen from a library. We generate the library through an offline optimization procedure that seeks to reproduce the varied gaits of healthy human subjects. By separating the parameter selection process into online and offline portions, the method can handle high-dimensional parameter spaces and produces policies that can generalize to different gait scenarios such as speed variation. We evaluate the method on five subjects walking on a powered knee and ankle prosthesis governed by a neuromuscular control policy that has 43 parameters. We find the five subjects preferred four different parameter sets from the library and that the resulting optima resemble intact subject gait data. This result suggests the offline portion of the optimization method indeed produces control parameters that can adapt to different gaits. Moreover, we find that for three out of the four parameter sets we tested, the procedure also generates parameters that improve the ability of the prosthesis to adapt to increasing gait speed by increasing ankle net work production. The results encourage further research and exploration in clinical settings toward advanced prosthesis controls that employ online learning.
ER  - 

TY  - CONF
TI  - Endo-VMFuseNet: A Deep Visual-Magnetic Sensor Fusion Approach for Endoscopic Capsule Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5386
EP  - 5392
AU  - M. Turan
AU  - Y. Almalioglu
AU  - H. B. Gilbert
AU  - A. E. Sari
AU  - U. Soylu
AU  - M. Sitti
PY  - 2018
KW  - endoscopes
KW  - learning (artificial intelligence)
KW  - magnetic sensors
KW  - medical robotics
KW  - sensor fusion
KW  - sensor fusion techniques
KW  - endo-VMFuseNet
KW  - asymmetric sensor data
KW  - asynchronous sensor data
KW  - deep learning
KW  - active medical robots
KW  - passive capsule endoscopes
KW  - medical device companies
KW  - endoscopic capsule robots
KW  - deep visual-magnetic sensor fusion approach
KW  - Robot sensing systems
KW  - Magnetic separation
KW  - Magnetic levitation
KW  - Sensor fusion
KW  - Magnetic cores
KW  - Magnetic resonance imaging
DO  - 10.1109/ICRA.2018.8461129
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the last decade, researchers and medical device companies have made major advances towards transforming passive capsule endoscopes into active medical robots. One of the major challenges is to endow capsule robots with accurate perception of the environment inside the human body, which will provide necessary information and enable improved medical procedures. We extend the success of deep learning approaches from various research fields to the problem of sensor fusion for endoscopic capsule robots in the case of asynchronous and asymmetric sensor data without any need of calibration between sensors. The results performed on real pig stomach datasets show that our method achieves high precision for both translational and rotational movements and contains various advantages over traditional sensor fusion techniques.
ER  - 

TY  - CONF
TI  - EndoSensorFusion: Particle Filtering-Based Multi-Sensory Data Fusion with Switching State-Space Model for Endoscopic Capsule Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5393
EP  - 5400
AU  - M. Turan
AU  - Y. Almalioglu
AU  - H. Gilbert
AU  - H. Araujo
AU  - T. Cemgil
AU  - M. Sitti
PY  - 2018
KW  - distance measurement
KW  - endoscopes
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - recurrent neural nets
KW  - robot vision
KW  - sensor fusion
KW  - multisensor fusion
KW  - endoscopy robots
KW  - endoscopic capsule robot trajectories
KW  - recurrent neural network
KW  - nonlinear kinematic model
KW  - sensor reliability
KW  - online estimation
KW  - particle filter
KW  - gastrointestinal tract
KW  - therapeutic technology
KW  - switching state-space model
KW  - particle filtering-based multisensory data fusion
KW  - Robot sensing systems
KW  - Switches
KW  - Kalman filters
KW  - Proposals
KW  - Endoscopes
KW  - Magnetic resonance imaging
DO  - 10.1109/ICRA.2018.8460472
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A reliable, real time, multi-sensor fusion functionality is crucial for localization of actively controlled capsule endoscopy robots, which are an emerging, minimally invasive diagnostic and therapeutic technology for the gastrointestinal (GI) tract. In this study, we propose a novel multi-sensor fusion approach based on a particle filter that incorporates an online estimation of sensor reliability and a non-linear kinematic model learned by a recurrent neural network. Our method sequentially estimates the true robot pose from noisy pose observations delivered by multiple sensors. We experimentally test the method using 5 degree-of-freedom (5-DoF) absolute pose measurement by a magnetic localization system and a 6-DoF relative pose measurement by visual odometry. In addition, the proposed method is capable of detecting and handling sensor failures by ignoring corrupted data, providing the robustness expected of a medical device. Detailed analyses and evaluations are presented using ex vivo experiments on a porcine stomach model, proving that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories.
ER  - 

TY  - CONF
TI  - Force Control of Series Elastic Actuators-Driven Parallel Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5401
EP  - 5406
AU  - H. Lee
AU  - S. Kwak
AU  - S. Oh
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - force control
KW  - motion control
KW  - robot kinematics
KW  - torque control
KW  - Spatial Force control algorithm
KW  - Series Elastic Actuators-driven parallel Robot
KW  - Virtual Ground Robot
KW  - RFSEAs
KW  - Reaction Force-sensing Series Elastic Actuator
KW  - torque generation
KW  - force generation
KW  - Kinematics
KW  - VGR motions
KW  - Legged locomotion
KW  - Force control
KW  - Parallel robots
KW  - Force
KW  - Aerospace electronics
KW  - Actuators
DO  - 10.1109/ICRA.2018.8460768
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes a novel parallel robot - Virtual Ground Robot (VGR) - that is driven by three Series Elastic Actuators (SEAs) to interact with a human. The proposed Virtual Ground Robot provides a virtual ground on which a human can stand on and interact in three directions: the pitch, the roll and the height directions. The most significant features of the proposed VGR are that 1) it is driven by RFSEAs (Reaction Force-sensing Series Elastic Actuator), and thus it can provide precise forces and torques, 2) the size of the VGR is small enough for a human to stand on with ease, and 3) it can generate torque/force large to support a weight of a human. Taking advantage of RFSEAs utilized in the proposed VGR, Spatial Force control algorithm is proposed in this paper. In order to design this controller, the motions of VGR are defined in the task space, the joint space and the RFSEA level. Based on the Kinematics, force control of VGR in the task level, which is named Spatial Force Control is designed and verified using experiments.
ER  - 

TY  - CONF
TI  - Analyzing and Improving Cartesian Stiffness Control Stability of Series Elastic Tendon-Driven Robotic Hands
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5415
EP  - 5420
AU  - P. Rao
AU  - A. D. Deshpande
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - dexterous manipulators
KW  - elasticity
KW  - force control
KW  - manipulator kinematics
KW  - position control
KW  - stability
KW  - stability criteria
KW  - series elastic tendon-driven robotic hands
KW  - dexterous manipulation
KW  - robotic hand design
KW  - fingertip force directions
KW  - Cartesian stiffness control
KW  - position dependent fingertip forces
KW  - stability conditions
KW  - Cartesian stiffness controllers
KW  - passive joint coupling
KW  - generalized passivity based stability boundary
KW  - Cartesian stiffness controlled series elastic tendon-driven robotic fingers
KW  - stability criteria
KW  - Stability criteria
KW  - Robots
KW  - Tendons
KW  - Force
KW  - Loading
KW  - Actuators
DO  - 10.1109/ICRA.2018.8460956
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robust and dexterous manipulation is identified as one of the critical challenges in the field of robotic hand design and control. A key requirement of dexterous manipulation is the ability to modulate fingertip force directions and magnitudes. Cartesian stiffness control is a strategy to generate position dependent fingertip forces. However the stability conditions for the Cartesian stiffness controllers vary nonlinearly because of dependency on the manipulator's configuration and loading forces. The challenge is enhanced in case of tendon-driven robotic hands due to passive joint coupling. In this work, we derive a generalized passivity based stability boundary for Cartesian stiffness. We then present a methodology to analyze the stability boundaries of Cartesian stiffness controlled series elastic tendon-driven robotic fingers. We also present a solution to improve stability by optimizing the arrangement of optimized passive compliance in parallel to the actuators based on the stability criteria. Our analysis not only allows for informed design of new robotic hands but also applies to improving performance of existing robotic hands.
ER  - 

TY  - CONF
TI  - A Projected Inverse Dynamics Approach for Multi-Arm Cartesian Impedance Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5421
EP  - 5428
AU  - H. Lin
AU  - J. Smith
AU  - K. K. Babarahmati
AU  - N. Dehio
AU  - M. Mistry
PY  - 2018
KW  - force control
KW  - friction
KW  - manipulator dynamics
KW  - motion control
KW  - unknown object dynamics
KW  - projected inverse dynamics approach
KW  - multiarm Cartesian impedance control
KW  - model-based control framework
KW  - multiarm manipulation
KW  - control law
KW  - constrained subspaces
KW  - unconstrained subspaces
KW  - unconstrained components
KW  - motion task
KW  - Cartesian impedance behaviour
KW  - constrained component enforces contact
KW  - friction constraints
KW  - contact forces
KW  - constrained subspace
KW  - contact points
KW  - dual-arm platform
KW  - Dynamics
KW  - Impedance
KW  - Force
KW  - Aerospace electronics
KW  - Robots
KW  - Task analysis
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2018.8461202
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a model-based control framework for multi-arm manipulation of a rigid object subject to external disturbances. The control framework, based on projected inverse dynamics, decomposes the control law into constrained and unconstrained subspaces. Unconstrained components accomplish the motion task with a desired 6-DOF Cartesian impedance behaviour against external disturbances. Meanwhile, the constrained component enforces contact and friction constraints by optimising for contact forces within the constrained subspace. External disturbances are explicitly compensated for without using force/torque sensors at the contact points. The approach is evaluated on a dual-arm platform manipulating a rigid object while coping with unknown object dynamics and human interaction.
ER  - 

TY  - CONF
TI  - Whole-Body Sensory Concept for Compliant Mobile Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5429
EP  - 5435
AU  - M. Kollmitz
AU  - D. Büscher
AU  - T. Schubert
AU  - W. Burgard
PY  - 2018
KW  - compliance control
KW  - filtering theory
KW  - force sensors
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - neurocontrollers
KW  - path planning
KW  - torque control
KW  - compliant mobile robots
KW  - mobile robot navigation
KW  - direct physical contact
KW  - intuitive communication
KW  - physical interaction
KW  - disturbance forces
KW  - mobile platform
KW  - neural network approach
KW  - distance sensors
KW  - mobile robot applications
KW  - whole-body sensory
KW  - model-free filtering approach
KW  - 6-DoF force-torque sensor
KW  - robot-human interaction
KW  - Robot sensing systems
KW  - Force
KW  - Mobile robots
KW  - Collision avoidance
KW  - Oscillators
DO  - 10.1109/ICRA.2018.8460510
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Most of the conventional approaches to mobile robot navigation avoid any kind of contact with the environment or with humans. As nowadays distance sensors typically have a limited - and often only two-dimensional - field of view, collisions with the environment or contacts with humans cannot be fully avoided in practical mobile robot applications. On the other hand, direct physical contact can be used for intuitive communication between a robot and humans. In this paper, we present a whole-body sensory concept based on a 6-DoF force-torque sensor to perceive physical interaction between the robot and humans. To distinguish between external contact and disturbance forces that result from the motion of the mobile platform or oscillations, we present a novel model-free filtering approach based on a neural network. In extensive experiments carried out with our robot Canny we demonstrate the effectiveness and advantages of the neural network approach, which clearly outperforms a classical model-based one.
ER  - 

TY  - CONF
TI  - Robust, Compliant Assembly via Optimal Belief Space Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5436
EP  - 5443
AU  - F. Wirnshofer
AU  - P. S. Schmitt
AU  - W. Feiten
AU  - G. v. Wichert
AU  - W. Burgard
PY  - 2018
KW  - assembling
KW  - CAD
KW  - friction
KW  - geometry
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - planning (artificial intelligence)
KW  - probability
KW  - robot dynamics
KW  - uncertain systems
KW  - compliant assembly
KW  - optimal belief space planning
KW  - automated manufacturing
KW  - robots
KW  - nonlinear contact-dynamics
KW  - model parameters
KW  - belief space planning problem
KW  - compliant system
KW  - asymptotically optimal belief space planner
KW  - kinodynamic motion planner
KW  - asymptotic optimality
KW  - multiple assembly tasks
KW  - CAD models
KW  - state spaces
KW  - object poses
KW  - geometry
KW  - friction
KW  - uncertainty
KW  - impedance-control
KW  - nondeterministic domains
KW  - probabilistic completeness
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Uncertainty
KW  - Task analysis
KW  - Aerospace electronics
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460995
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In automated manufacturing, robots must reliably assemble parts of various geometries and low tolerances. Ideally, they plan the required motions autonomously. This poses a substantial challenge due to high-dimensional state spaces and non-linear contact-dynamics. Furthermore, object poses and model parameters, such as friction, are not exactly known and a source of uncertainty. The method proposed in this paper models the task of parts assembly as a belief space planning problem over an underlying impedance-controlled, compliant system. To solve this planning problem we introduce an asymptotically optimal belief space planner by extending an optimal, randomized, kinodynamic motion planner to nondeterministic domains. Under an expansiveness assumption we establish probabilistic completeness and asymptotic optimality. We validate our approach in thorough, simulated and realworld experiments of multiple assembly tasks. The experiments demonstrate our planner's ability to reliably assemble objects, solely based on CAD models as input.
ER  - 

TY  - CONF
TI  - Cooperative Manipulation and Identification of a 2-DOF Articulated Object by a Dual-Arm Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5445
EP  - 5451
AU  - D. Almeida
AU  - Y. Karayiannidis
PY  - 2018
KW  - manipulators
KW  - dual-arm robot
KW  - dual-arm manipulation
KW  - motion directions
KW  - motion constraints
KW  - coordinated task space frameworks
KW  - redundancy exploitation
KW  - robot arms
KW  - two degrees-of-freedom articulated object
KW  - Task analysis
KW  - Robot kinematics
KW  - Manipulators
KW  - Uncertainty
KW  - Kinematics
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460511
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we address the dual-arm manipulation of a two degrees-of-freedom articulated object that consists of two rigid links. This can include a linkage constrained along two motion directions, or two objects in contact, where the contact imposes motion constraints. We formulate the problem as a cooperative task, which allows the employment of coordinated task space frameworks, thus enabling redundancy exploitation by adjusting how the task is shared by the robot arms. In addition, we propose a method that can estimate the joint location and the direction of the degrees-of-freedom, based on the contact forces and the motion constraints imposed by the object. Experimental results demonstrate the performance of the system in its ability to estimate the two degrees of freedom independently or simultaneously.
ER  - 

TY  - CONF
TI  - A Soft Pneumatic Fabric-Polymer Actuator for Wearable Biomedical Devices: Proof of Concept for Lymphedema Treatment
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5452
EP  - 5458
AU  - E. Suarez
AU  - J. J. Huaroto
AU  - A. A. Reymundo
AU  - D. Holland
AU  - C. Walsh
AU  - E. Vela
PY  - 2018
KW  - bending
KW  - control system synthesis
KW  - elasticity
KW  - force control
KW  - medical robotics
KW  - motion control
KW  - patient monitoring
KW  - pneumatic actuators
KW  - polymers
KW  - manual lymphatic drainage
KW  - human arm
KW  - lateral force
KW  - polymer element
KW  - hyperelastic polymer
KW  - mechanical elements
KW  - robotic device
KW  - soft pneumatic fabric-polymer bending actuator
KW  - rigid actuators
KW  - soft actuators
KW  - wearable biomedical devices
KW  - soft pneumatic fabric-polymer actuator
KW  - lymphedema treatment
KW  - actuator motion
KW  - hyperelastic beam
KW  - polymer beam
KW  - fabric element
KW  - Iron
KW  - Actuators
KW  - Skin
KW  - Fabrics
KW  - Force
KW  - Shape
KW  - Strain
DO  - 10.1109/ICRA.2018.8460790
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft actuators are ideal candidates for wearable biomedical devices, their inherent compliance, robustness, lightweight and the possibility to be washable take advantage over rigid actuators. Thus, a soft pneumatic fabric-polymer bending actuator as a base component for a robotic device for lymphedema treatment is reported in this work. The actuator is composed of two mechanical elements, one made of fabric and the other one made of a hyperelastic polymer which is stuck on the fabric element. The fabric element is designed and fabricated with a curved shape longer than the polymer element, that is a hyperelastic beam. To assemble both elements, the fabric element was folded before sticking in order to match the length of the polymer beam. Once the air is pumped into the fabric, it bends towards its original curved shape. Once the air is removed, the hyperelastic beam allows the actuator to recover its initial position. This actuator is capable of exerting compression and lateral force on a human arm mimicking manual lymphatic drainage. A mathematical model is presented which is in good agreement with the experimental data, it could serve to predict the actuator motion. An end-tip free bending displacement of about 2.2 cm and a bending force of about 0.35 N were achieved at 12.5 kPa. A proof-of-concept system for lymphedema treatment is presented as well.
ER  - 

TY  - CONF
TI  - Force Control of Textile-Based Soft Wearable Robots for Mechanotherapy
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5459
EP  - 5465
AU  - C. J. Payne
AU  - E. G. Hevia
AU  - N. Phipps
AU  - A. Atalay
AU  - O. Atalay
AU  - B. R. Seo
AU  - D. J. Mooney
AU  - C. J. Walsh
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - closed loop systems
KW  - force control
KW  - medical robotics
KW  - patient treatment
KW  - force tracking variability
KW  - force-controlled actuation patterns
KW  - soft robotic system
KW  - open-loop pressure-based control
KW  - soft robotic force control device
KW  - sinusoidal force profiles
KW  - closed-loop force control methodology
KW  - manual mechanotherapy practices
KW  - massage-magnitude forces
KW  - closed-loop force control system
KW  - fully soft sensors
KW  - muscular tissue
KW  - tissue regeneration
KW  - judicious force application
KW  - soft tissues
KW  - mechanotherapeutic applications
KW  - soft robotic wearable devices
KW  - biomedical applications
KW  - soft robotic devices
KW  - textile-based soft wearable robots
KW  - Sensors
KW  - Soft robotics
KW  - Force
KW  - Muscles
KW  - Biological tissues
KW  - Actuators
DO  - 10.1109/ICRA.2018.8461059
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft robotic devices have been utilized in a number of biomedical applications involving human interaction. An emerging opportunity for soft robotic wearable devices is in mechanotherapeutic applications for the recovery and regeneration of soft tissues. Previous studies have implied that judicious force application during mechanotherapy plays an important role in the functional outcome of tissue regeneration. In this paper, we propose soft robotic devices with closed-loop force control to precisely manipulate muscular tissue. The developed devices incorporate fully soft sensors and actuators using textile-based materials and fabrication methods. The closed-loop force control system is demonstrated in bench studies to regulate massage-magnitude forces at frequencies akin to those expected in manual mechanotherapy practices. Testing of the device on human limbs demonstrates the precision and accuracy of the closed-loop force control methodology across different body shapes and types. When commanded to regulate sinusoidal force profiles (with amplitudes of 30N, 45N and 60N), the soft robotic force control device could regulate peak compressive loads to within 0.7N of the desired force. Conversely, open-loop pressure-based control resulted in up to +/-6.6N force tracking variability between participants. A soft robotic system with independently actuatable modules was also fabricated to demonstrate force-controlled actuation patterns to mimic manual massage techniques.
ER  - 

TY  - CONF
TI  - HapWRAP: Soft Growing Wearable Haptic Device
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5466
EP  - 5472
AU  - N. Agharese
AU  - T. Cloyd
AU  - L. H. Blumenschein
AU  - M. Raitor
AU  - E. W. Hawkes
AU  - H. Culbertson
AU  - A. M. Okamura
PY  - 2018
KW  - force feedback
KW  - haptic interfaces
KW  - pneumatic actuators
KW  - polymers
KW  - HapWRAP
KW  - soft growing wearable haptic device
KW  - soft robotics
KW  - lightweight wearable haptic devices
KW  - flexible low density polyethylene
KW  - directional force feedback
KW  - haptic feedback device
KW  - mechanoreceptors
KW  - air flow control
KW  - distributed touch feedback
KW  - pneumatic actuators
KW  - Actuators
KW  - Haptic interfaces
KW  - Soft robotics
KW  - Skin
KW  - Electron tubes
KW  - Pneumatic systems
DO  - 10.1109/ICRA.2018.8460891
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft robotics and pneumatic actuation present opportunities for lightweight wearable haptic devices that provide distributed touch feedback to the skin. Ideally, such devices would be easily donned and doffed, since permanent coverage of a large area of the skin is undesirable. Here we present the design and evaluation of a concept device called HapWRAP: a growing haptic device constructed from flexible low density polyethylene. Controlled air flow through tubes and pouches allows HapWRAP to grow out of a compact housing unit and provide a combination of directional and force feedback to a user. When activated, HapWRAP grows up and around the forearm; its loops form a temporary sleeve. After growth, pneumatic actuators inflate and deflate to stimulate mechanoreceptors in the skin at distinguishable locations. This paper describes the design and manufacturing of HapWRAP, reports its performance metrics, and tests its suitability as a haptic feedback device. Participants were able to interpret force and direction cues from HapWRAP with 92.5% accuracy. These findings suggest that HapWRAP can be successfully used for applications where both force and direction cues are necessary.
ER  - 

TY  - CONF
TI  - Autonomous and Portable Soft Exosuit for Hip Extension Assistance with Online Walking and Running Detection Algorithm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5473
EP  - 5480
AU  - J. Kim
AU  - R. Heimgartner
AU  - G. Lee
AU  - N. Karavas
AU  - D. Perry
AU  - D. L. Ryan
AU  - A. Eckert-Erdheim
AU  - P. Murphy
AU  - D. K. Choe
AU  - I. Galiana
AU  - C. J. Walsh
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - gait analysis
KW  - medical robotics
KW  - patient rehabilitation
KW  - portable hip-only
KW  - augmenting human walking
KW  - different fixed assistance profiles
KW  - online classification algorithm
KW  - mass potential energy fluctuations
KW  - abdomen-mounted IMU
KW  - maximum hip extension
KW  - autonomous wearable robot
KW  - assistance profile individualization
KW  - hip extension assistance
KW  - online walking
KW  - autonomous hip-only
KW  - Legged locomotion
KW  - Hip
KW  - Thigh
KW  - Exoskeletons
KW  - Acceleration
KW  - Force
DO  - 10.1109/ICRA.2018.8460474
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present an autonomous and portable hip-only soft exosuit, for augmenting human walking and running that assists hip extension by delivering peak forces of 300N to the user. Different fixed assistance profiles for walking and running were applied based on an online classification algorithm. The approach is based on the biomechanical understanding that the center of mass potential energy fluctuations during walking and running are out of phase. Specifically, we monitor the vertical acceleration with an abdomen-mounted IMU at the moment of maximum hip extension. Validation is demonstrated with six subjects on the treadmill and with eight subjects outdoors. Our results demonstrated a 99.99% accuracy on average over the fourteen participants for various speeds (0.5 - 4m/s), slopes (-10 -20%), treadmill and overground terrain, loaded (13.6 kg) and unloaded, Exo On and Exo Off conditions, and different shoe types. Results from an evaluation outdoors overground on the energetics of eight subjects demonstrated a significant reduction for running when comparing Exo On to No Exo (3.9%) and for walking and running when comparing Exo On to Exo Off (12.2% and 8.2% respectively). This study represents the first demonstration of an autonomous wearable robot reducing the energy cost of running. Significant variation in response across subjects was observed, highlighting further improvements may be possible via assistance profile individualization with human-in-the-Ioop optimization.
ER  - 

TY  - CONF
TI  - Design and Analysis of a Wearable Robotic Forearm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5489
EP  - 5496
AU  - V. Vatsal
AU  - G. Hoffman
PY  - 2018
KW  - ergonomics
KW  - groupware
KW  - human computer interaction
KW  - human-robot interaction
KW  - manipulator kinematics
KW  - medical robotics
KW  - service robots
KW  - user interfaces
KW  - collaborative tool
KW  - human-human collaboration
KW  - human ergonomic wear limits
KW  - robot autonomy
KW  - lightweight wearable robotic augmentation device
KW  - human-wearable collaboration
KW  - wearable robotic forearm
KW  - close-range human-robot collaboration
KW  - lightweight supernumerary third arm
KW  - shared workspace activities
KW  - functional prototype
KW  - iterative design process
KW  - reachable workspace
KW  - natural human reach
KW  - human-robot interaction
KW  - Solid modeling
KW  - Collaboration
KW  - Manipulators
KW  - Elbow
KW  - Load modeling
KW  - Prototypes
DO  - 10.1109/ICRA.2018.8461212
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the design of a wearable robotic forearm for close-range human-robot collaboration. The robot's function is to serve as a lightweight supernumerary third arm for shared workspace activities. We present a functional prototype resulting from an iterative design process including several user studies. An analysis of the robot's kinematics shows an increase in reachable workspace by 246 % compared to the natural human reach. The robot's degrees of freedom and range of motion support a variety of usage scenarios with the robot as a collaborative tool, including self-handovers, fetching objects while the human's hands are occupied, assisting human-human collaboration, and stabilizing an object. We analyze the bio-mechanical loads for these scenarios and find that the design is able to operate within human ergonomic wear limits. We then report on a pilot human-robot interaction study that indicates robot autonomy is more task-time efficient and preferred by users when compared to direct voice-control. These results suggest that the design presented here is a promising configuration for a lightweight wearable robotic augmentation device, and can serve as a basis for further research into human-wearable collaboration.
ER  - 

TY  - CONF
TI  - Real-Time Learning of Efficient Lift Generation on a Dynamically Scaled Flapping Wing Using Policy Search
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5519
EP  - 5525
AU  - Y. E. Bayiz
AU  - L. Chen
AU  - S. Hsu
AU  - P. Liu
AU  - A. N. Aguiles
AU  - B. Cheng
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - learning (artificial intelligence)
KW  - search problems
KW  - efficient lift generation
KW  - policy search algorithm
KW  - real-time robotic learning problem
KW  - dynamically scaled flapping robotic wing
KW  - degrees-of-freedom
KW  - mineral oil
KW  - Reynolds number
KW  - optimal wing pitching amplitude
KW  - stroke-pitch phase difference
KW  - aerodynamic efficiency
KW  - quasisteady aerodynamic mechanism
KW  - wing rotation
KW  - stroke reversal
KW  - unsteady lift generation mechanisms
KW  - stroke amplitude range
KW  - Trajectory
KW  - Heuristic algorithms
KW  - Servomotors
KW  - Real-time systems
KW  - Aerodynamics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8460781
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we present a successful application of a policy search algorithm to a real-time robotic learning problem, where the goal is to maximize the efficiency of lift generation on a dynamically scaled flapping robotic wing. The robotic wing has two degrees-of-freedom, i.e., stroke and pitch, and operates in a tank filled with mineral oil. For all experiments, the Reynolds number is maintained constant at 1000, where learning is performed for different prescribed stroke amplitudes to find the optimal wing pitching amplitude and the stroke-pitch phase difference that maximize the power loading (PL) of lift generation, a measure of aerodynamic efficiency. For the investigated stroke amplitude range (30°-90°), the efficiency is observed to increase with the stroke amplitude and the lift is mainly generated through the delayed stall, a quasi-steady aerodynamic mechanism. Furthermore, the wing rotation becomes more asymmetric with respect to stroke reversal as the stroke amplitude decreases, indicating an increased use of unsteady lift generation mechanisms at lower stroke amplitudes.
ER  - 

TY  - CONF
TI  - Exploration and Inspection with Vine-Inspired Continuum Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5526
EP  - 5533
AU  - M. Wooten
AU  - C. Frazelle
AU  - I. D. Walker
AU  - A. Kapadia
AU  - J. H. Lee
PY  - 2018
KW  - inspection
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - shape control
KW  - motion generation
KW  - robot tendril hardware
KW  - International Space Station
KW  - NASA Johnson Space Center
KW  - continuum robot backbones
KW  - theoretical plant growth-inspired approach
KW  - inspection operations
KW  - long thin continuum robot exploration
KW  - vine-inspired movement strategies
KW  - robot access
KW  - thin-stemmed plants
KW  - vine-inspired continuum robots
KW  - Tendons
KW  - Strain
KW  - Adaptation models
KW  - Hardware
KW  - Robot kinematics
KW  - Inspection
DO  - 10.1109/ICRA.2018.8461132
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we show how structures and strategies employed by thin-stemmed plants can be adapted to improve robot access to unstructured and congested environments. Specifically, we show how the use of vine-inspired movement strategies can enhance long thin continuum robot exploration and inspection operations. We introduce a new theoretical plant growth-inspired approach for modeling and motion generation of continuum robot backbones. The approach is demonstrated in numerous experiments including inspection within a high fidelity, full-scale mock-up of the International Space Station at NASA Johnson Space Center, using novel robot tendril hardware.
ER  - 

TY  - CONF
TI  - The Role of Massive Morphing Wings for Maneuvering a Bio-Inspired Bat-Like Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5534
EP  - 5539
AU  - J. Colorado
AU  - C. Rossi
AU  - A. Barrientos
AU  - A. Parra
AU  - C. Devia
AU  - D. Patino
PY  - 2018
KW  - aerospace components
KW  - biomimetics
KW  - mobile robots
KW  - position control
KW  - robot dynamics
KW  - rolling torques
KW  - pitch torque generation
KW  - massive morphing wings
KW  - bio-inspired bat-like robot
KW  - inertial effects
KW  - wing shape
KW  - robotic platform
KW  - massive morphing-wings
KW  - wingbeats
KW  - Robots
KW  - Aerodynamics
KW  - Trajectory
KW  - Heuristic algorithms
KW  - Elbow
DO  - 10.1109/ICRA.2018.8460829
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present an approach for analyzing the inertial effects of changing the wing shape for steering a bat-like robot. Using BaTboT, a robotic platform with massive morphing-wings, we have estimated the generation of pitching and rolling torques, which are directly related to forward and turning maneuvers. Results let us conclude that faster retraction of the wings during the upstroke, and slower extension during the downstroke increase both pitching and rolling torques in about 50% compared to those wingbeats with equal periods for retraction/extension. Also, we determined that the pitch torque generation is proportional to 0.6m1/f, whereas the rolling torque is promotional to 0.1m1/f, being m the mass of the robot and f the flapping frequency of the wings.
ER  - 

TY  - CONF
TI  - Stability and Predictability in Dynamically Complex Physical Interactions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5540
EP  - 5545
AU  - S. Bazzi
AU  - J. Ebert
AU  - N. Hogan
AU  - D. Sternad
PY  - 2018
KW  - human-robot interaction
KW  - pendulums
KW  - perturbation techniques
KW  - robust control
KW  - trajectory control
KW  - human control strategy
KW  - suspended pendulum
KW  - cart-pendulum system
KW  - assistive perturbations
KW  - resistive perturbations
KW  - trajectory stability
KW  - cart trajectories
KW  - robust control strategies
KW  - dynamically complex physical interactions
KW  - stability properties
KW  - human-object interaction
KW  - simplified 2D model
KW  - virtual implementation
KW  - Perturbation methods
KW  - Task analysis
KW  - Trajectory
KW  - Robots
KW  - Mathematical model
KW  - Stability analysis
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2018.8460774
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This study examines human control of physical interaction with objects that exhibit complex (nonlinear, chaotic, underactuated) dynamics. We hypothesized that humans exploited stability properties of the human-object interaction. Using a simplified 2D model for carrying a “cup of coffee”, we developed a virtual implementation to identify human control strategies. Transporting a cup of coffee was modeled as a cart with a suspended pendulum, where humans moved the cart on a horizontal line via a robotic manipulandum. The specific task was to transport the cart-pendulum system to a target, as fast as possible, while accommodating assistive and resistive perturbations. To assess trajectory stability, we applied contraction analysis. We showed that when the perturbation was assistive, humans absorbed the perturbation by controlling cart trajectories into a contraction region prior to the perturbation. When the perturbation was resistive, subjects passed through a contraction region following the perturbation. Entering a contraction region stabilizes performance and makes the dynamics more predictable. This human control strategy could inspire more robust control strategies for physical interaction in robots.
ER  - 

TY  - CONF
TI  - First Autonomous Multi-Room Exploration with an Insect-Inspired Flapping Wing Vehicle
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5546
EP  - 5552
AU  - K. Y. W. Scheper
AU  - M. Karásek
AU  - C. De Wagter
AU  - B. D. W. Remes
AU  - G. C. H. E. De Croon
PY  - 2018
KW  - autonomous aerial vehicles
KW  - image colour analysis
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - stereo image processing
KW  - multiroom exploration task
KW  - DelFly Explorer
KW  - autonomous indoor exploration mission
KW  - room exploration
KW  - stereo-vision based droplet algorithm
KW  - heading-based door passage algorithm
KW  - flapping wing vehicles
KW  - autonomous exploration tasks
KW  - autonomous multiroom exploration
KW  - wing vehicle
KW  - MAVs
KW  - autonomous indoor navigation
KW  - rotary wings
KW  - flapping wing MAV
KW  - stereo vision system
KW  - microair vehicles
KW  - monocular color based Snake-gate algorithm
KW  - Task analysis
KW  - Robot sensing systems
KW  - Navigation
KW  - Collision avoidance
KW  - Cameras
KW  - Image color analysis
DO  - 10.1109/ICRA.2018.8460702
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the emerging tasks for Micro Air Vehicles (MAVs) is autonomous indoor navigation. While commonly employed platforms for such tasks are micro-quadrotors, insect-inspired flapping wing MAVs can offer many advantages, such as being inherently safe due to their low inertia, reciprocating wings bouncing of objects or potentially lower noise levels compared to rotary wings. Here, we present the first flapping wing MAV to perform an autonomous multi-room exploration task. Equipped with an on-board autopilot and a 4 g stereo vision system, the DelFly Explorer succeeded in combining the two most common tasks of an autonomous indoor exploration mission: room exploration and door passage. During the room exploration, the vehicle uses stereo-vision based droplet algorithm to avoid and navigate along the walls and obstacles. Simultaneously, it is running a newly developed monocular color based Snake-gate algorithm to locate doors. A successful detection triggers the heading-based door passage algorithm. In the real-world test, the vehicle could successfully navigate, multiple times in a row, between two rooms separated by a corridor, demonstrating the potential of flapping wing vehicles for autonomous exploration tasks.
ER  - 

TY  - CONF
TI  - Evaluating Robust Trajectory Control of a Miniature Rolling and Spinning Robot in Outdoor Conditions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5553
EP  - 5560
AU  - A. R. Chowdhury
AU  - G. S. Soh
AU  - S. H. Foong
AU  - K. L. Wood
PY  - 2018
KW  - adaptive control
KW  - control system synthesis
KW  - feedback
KW  - legged locomotion
KW  - motion control
KW  - nonlinear control systems
KW  - robust control
KW  - trajectory control
KW  - variable structure systems
KW  - robust trajectory control
KW  - spinning robot mechanism
KW  - robot stability
KW  - trajectory following accuracy
KW  - wheel velocity response
KW  - ASMC controller
KW  - trajectory following control
KW  - miniature spherical rolling robot
KW  - nonlinear adaptive sliding mode
KW  - locomotory rolling patterns
KW  - roll angle stability
KW  - ISMC controller
KW  - integral sliding controller
KW  - Trajectory
KW  - Wheels
KW  - Spinning
KW  - Mobile robots
KW  - Mathematical model
KW  - Robustness
KW  - Spherical Robot
KW  - Rolling gait
KW  - Central Pattern Generator (CPG)
KW  - Trajectory following
KW  - Adaptive sliding mode (ASMC) Control
DO  - 10.1109/ICRA.2018.8460594
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents trajectory following control experiments of a miniature spherical rolling and spinning robot mechanism on three different types of outdoor surfaces. The research is inspired from the efficient locomotory rolling patterns of various insects in unstructured environment. A nonlinear adaptive sliding mode (ASMC) feedback method maintains the robot stability and robustness in the presence of parameter uncertainties and external disturbances. The proposed trajectory following control policy is developed, implemented and tested for the miniature spherical robot on three different types of irregular surfaces in outdoors. Trajectory following accuracy, roll angle stability and wheel velocity response are three parameters measured to evaluate robot performance. ASMC controller is compared with an integral sliding (ISMC) controller. Experimental results show that proposed control policy is able to manage an accurate trajectory following amidst robust control of a rolling and spinning robot on three types of irregular surface in practical outdoor conditions.
ER  - 

TY  - CONF
TI  - Bio-Inspired Tensegrity Flexural Joints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5561
EP  - 5566
AU  - E. Jung
AU  - V. Ly
AU  - N. Cessna
AU  - M. L. Ngo
AU  - D. Castro
AU  - V. SunSpiral
AU  - M. Teodorescu
PY  - 2018
KW  - biomechanics
KW  - manipulator kinematics
KW  - motion control
KW  - tensegrity flexural manipulator
KW  - OpenSim simulation environment
KW  - tension analysis
KW  - human leg behavior
KW  - tensegrity manipulator
KW  - revolute joint
KW  - robotics literature model
KW  - bio-inspired tensegrity flexural joints
KW  - Knee
KW  - Legged locomotion
KW  - Joints
KW  - Biological system modeling
KW  - Hip
KW  - Muscles
DO  - 10.1109/ICRA.2018.8461027
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Most robotics literature model the human's knee and hip as a revolute joint with limited range of rotation. Although somehow close to reality, this approach neglects a critical aspect of these joints, which is their internal flexibility. This paper presents a prototype tensegrity flexural manipulator whose kinematic behavior is inspired by human leg's gait. This prototype, which considers a hybrid (flexible-rigid) structure of the knee and hip would be able to better approximate real behavior and hopefully lead to a better design of artificial (prosthetic) knees and hips. The behavior of the proposed tensegrity manipulator was firstly predicted using OpenSim simulation environment. The paper reports the comparisons between the simulations, physical prototypes and human leg behavior for a variety of ranges of motions and tension analysis.
ER  - 

TY  - CONF
TI  - Grasp Quality Evaluation with Whole Arm Kinematic Noise Propagation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5575
EP  - 5581
AU  - S. Liu
AU  - S. Carpin
PY  - 2018
KW  - grippers
KW  - manipulator kinematics
KW  - path planning
KW  - probability
KW  - robust control
KW  - arm configurations
KW  - force closure region
KW  - kinematic robot structure
KW  - arm kinematic noise propagation
KW  - grasp quality evaluation
KW  - local robustness
KW  - arm configuration
KW  - grasp quality metric
KW  - redundant robot
KW  - Measurement
KW  - Force
KW  - Kinematics
KW  - Manipulators
KW  - Ellipsoids
KW  - Random variables
DO  - 10.1109/ICRA.2018.8460715
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a new approach to evaluate grasps that accounts for both the kinematic structure of the robot and the noise at its joints. Our starting observation is that with a redundant robot the same grasp can be implemented with different arm configurations, and these may display significant differences in terms of robustness to disturbances. Consequently, the grasp quality metric is seen as a random variable depending on the arm configuration. Starting from a first order approximation for the error, we introduce the high probability force closure region as a tool to evaluate the local robustness of an arm configuration, and we then introduce a new metric Qarm to rank different configurations according to the robustness to noise. By combining this method in an offline/online framework, we demonstrate through large scale simulations that this approach successfully captures aspects that were neglected in former literature regarding grasp evaluation, and can successfully be integrated into future grasp planners.
ER  - 

TY  - CONF
TI  - Realtime Planning for High-DOF Deformable Bodies Using Two-Stage Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5582
EP  - 5589
AU  - Z. Pan
AU  - D. Manocha
PY  - 2018
KW  - collision avoidance
KW  - finite element analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - neurocontrollers
KW  - path planning
KW  - position control
KW  - realtime planning
KW  - high-DOF deformable bodies
KW  - arbitrarily-shaped volumetric deformable bodies
KW  - complex environments
KW  - high-dimensional configuration spaces
KW  - dynamics constraints
KW  - two-stage learning method
KW  - multitask controller
KW  - dynamic movement primitives
KW  - neural-network controller
KW  - DMP task
KW  - finite element method
KW  - contact invariant optimization
KW  - gradient-based method
KW  - two-stage learning algorithm
KW  - trained DMP controller
KW  - different navigation tasks
KW  - learned motion planner
KW  - walking deformable robots
KW  - obstacle avoidance
KW  - Deep Q-Learning
KW  - Planning
KW  - Deformable models
KW  - Robots
KW  - Finite element analysis
KW  - Strain
KW  - Computational modeling
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460602
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a method for planning the motion of arbitrarily-shaped volumetric deformable bodies or robots through complex environments. Such robots have very high-dimensional configuration spaces and we compute trajectories that satisfy the dynamics constraints using a two-stage learning method. First, we train a multitask controller parameterized using dynamic movement primitives (DMP), which encodes various locomotion or movement skills. Next, we train a neural-network controller to select the DMP task to navigate the robot through environments while avoiding obstacles. By combining the finite element method (FEM), model reduction, and contact invariant optimization (CIO), the DMP controller's parameters can be optimized efficiently using a gradient-based method, while the neural-network's parameters are optimized using Deep Q-Learning (DQL). This two-stage learning algorithm also allows us to reuse the trained DMP controller for different navigation tasks, such as moving through different environmental types and to different goal positions. Our results show that the learned motion planner can navigate swimming and walking deformable robots with thousands of DOFs at realtime.
ER  - 

TY  - CONF
TI  - Grasping Flat Objects by Exploiting Non-Convexity of the Object and Support Surface
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5606
EP  - 5611
AU  - I. Sarantopoulos
AU  - Y. Koveos
AU  - Z. Doulgeri
PY  - 2018
KW  - concave programming
KW  - dexterous manipulators
KW  - geometry
KW  - grippers
KW  - nonconvexity
KW  - support surface
KW  - grasp strategy
KW  - environmental contact
KW  - nonconvex geometry
KW  - object-surface combination
KW  - domestic flat objects grasping
KW  - Grasping
KW  - Robots
KW  - Three-dimensional displays
KW  - Color
KW  - Geometry
KW  - Grippers
KW  - Visualization
DO  - 10.1109/ICRA.2018.8461192
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a grasp strategy which exploits environmental contact for grasping domestic flat objects placed or hinged on support surfaces. The proposed grasp strategy considers the non-convex geometry of the object-surface combination, as this appears in objects like plates on tables or handles on cupboards. Following the fact that state-of-the-art grasp planners fail to produce candidate grasps for flat objects due to the environmental constraint of the support surface, this work utilizes compliant interaction of the hand with the support surface, inspired by human grasp strategies.
ER  - 

TY  - CONF
TI  - Caging Loops in Shape Embedding Space: Theory and Computation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5612
EP  - 5619
AU  - J. Liu
AU  - S. Xin
AU  - Z. Gao
AU  - K. Xu
AU  - C. Tu
AU  - B. Chen
PY  - 2018
KW  - geometry
KW  - grippers
KW  - object detection
KW  - robot vision
KW  - topology
KW  - shape embedding space
KW  - robot gripper
KW  - surface geometry
KW  - caging grasps
KW  - Caging Loops
KW  - target object
KW  - Grasping
KW  - Grippers
KW  - Robots
KW  - Shape
KW  - Geometry
KW  - Topology
KW  - Robustness
DO  - 10.1109/ICRA.2018.8461206
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose to synthesize feasible caging grasps for a target object through computing Caging Loops, a closed curve defined in the shape embedding space of the object. Different from the traditional methods, our approach decouples caging loops from the surface geometry of target objects through working in the embedding space. This enables us to synthesize caging loops encompassing multiple topological holes, instead of always tied with one specific handle which could be too small to be graspable by the robot gripper. Our method extracts caging loops through a topological analysis of the distance field defined for the target surface in the embedding space, based on a rigorous theoretical study on the relation between caging loops and the field topology. Due to the decoupling, our method can tolerate incomplete and noisy surface geometry of an unknown target object captured on-the-fly. We implemented our method with a robotic gripper and demonstrate through extensive experiments that our method can synthesize reliable grasps for objects with complex surface geometry and topology and in various scales.
ER  - 

TY  - CONF
TI  - Dex-Net 3.0: Computing Robust Vacuum Suction Grasp Targets in Point Clouds Using a New Analytic Model and Deep Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5620
EP  - 5627
AU  - J. Mahler
AU  - M. Matl
AU  - X. Liu
AU  - A. Li
AU  - D. Gealy
AU  - K. Goldberg
PY  - 2018
KW  - convolution
KW  - dexterous manipulators
KW  - end effectors
KW  - feedforward neural nets
KW  - grippers
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - deep learning
KW  - vacuum-based end effectors
KW  - multifinger grippers
KW  - suction cup
KW  - external wrenches
KW  - pneumatic suction gripper
KW  - point clouds
KW  - grasp quality convolutional neural network
KW  - robust vacuum suction grasp targets
KW  - gravity wrench
KW  - parallel-jaw grippers
KW  - object pose
KW  - material properties
KW  - GQ-CNN
KW  - ABB YuMi
KW  - adversarial
KW  - Three-dimensional displays
KW  - Robustness
KW  - Robots
KW  - Analytical models
KW  - Seals
KW  - Computational modeling
KW  - Planning
DO  - 10.1109/ICRA.2018.8460887
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Vacuum-based end effectors are widely used in industry and are often preferred over parallel-jaw and multifinger grippers due to their ability to lift objects with a single point of contact. Suction grasp planners often target planar surfaces on point clouds near the estimated centroid of an object. In this paper, we propose a compliant suction contact model that computes the quality of the seal between the suction cup and local target surface and a measure of the ability of the suction grasp to resist an external gravity wrench. To characterize grasps, we estimate robustness to perturbations in end-effector and object pose, material properties, and external wrenches. We analyze grasps across 1,500 3D object models to generate Dex-Net 3.0, a dataset of 2.8 million point clouds, suction grasps, and grasp robustness labels. We use Dex-Net 3.0 to train a Grasp Quality Convolutional Neural Network (GQ-CNN) to classify robust suction targets in point clouds containing a single object. We evaluate the resulting system in 350 physical trials on an ABB YuMi fitted with a pneumatic suction gripper. When evaluated on novel objects that we categorize as Basic (prismatic or cylindrical), Typical (more complex geometry), and Adversarial (with few available suction-grasp points) Dex-Net 3.0 achieves success rates of 98%, 82%, and 58% respectively, improving to 81% in the latter case when the training set includes only adversarial objects. Code, datasets, and supplemental material can be found at http://berkeleyautomation.github.io/dex-net.
ER  - 

TY  - CONF
TI  - Deep Imitation Learning for Complex Manipulation Tasks from Virtual Reality Teleoperation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5628
EP  - 5635
AU  - T. Zhang
AU  - Z. McCarthy
AU  - O. Jow
AU  - D. Lee
AU  - X. Chen
AU  - K. Goldberg
AU  - P. Abbeel
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - learning by example
KW  - manipulators
KW  - neural nets
KW  - robot programming
KW  - robot vision
KW  - telerobotics
KW  - virtual reality
KW  - virtual reality teleoperation
KW  - robot skill acquisition
KW  - raw pixels
KW  - consumer-grade Virtual Reality headsets
KW  - hand tracking hardware
KW  - deep neural network policies
KW  - manipulation tasks
KW  - deep imitation learning
KW  - PR2 robot
KW  - RGB-D images
KW  - Robots
KW  - Task analysis
KW  - Neural networks
KW  - Three-dimensional displays
KW  - Head
KW  - Visualization
KW  - Grippers
DO  - 10.1109/ICRA.2018.8461249
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Imitation learning is a powerful paradigm for robot skill acquisition. However, obtaining demonstrations suitable for learning a policy that maps from raw pixels to actions can be challenging. In this paper we describe how consumer-grade Virtual Reality headsets and hand tracking hardware can be used to naturally teleoperate robots to perform complex tasks. We also describe how imitation learning can learn deep neural network policies (mapping from pixels to actions) that can acquire the demonstrated skills. Our experiments showcase the effectiveness of our approach for learning visuomotor skills.
ER  - 

TY  - CONF
TI  - Accelerated Testing and Evaluation of Autonomous Vehicles via Imitation Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5636
EP  - 5642
AU  - G. E. Mullins
AU  - A. G. Dress
AU  - P. G. Stankiewicz
AU  - J. D. Appler
AU  - S. K. Gupta
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - life testing
KW  - mobile robots
KW  - neurocontrollers
KW  - regression analysis
KW  - autonomous vehicle
KW  - imitation learning
KW  - surrogate agents
KW  - test scenario generation
KW  - performance modes
KW  - deep neural networks
KW  - imitator surrogates
KW  - mission performance
KW  - simulation-based testing
KW  - on-line imitation
KW  - complex mission
KW  - target vehicle
KW  - behavioral modes
KW  - dataset aggregation
KW  - collision avoidance
KW  - Testing
KW  - Training
KW  - Autonomous vehicles
KW  - Trajectory
KW  - Adaptation models
KW  - History
DO  - 10.1109/ICRA.2018.8460965
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we investigate the use of surrogate agents to accelerate test scenario generation for autonomous vehicles. Our goal is to train the surrogate to replicate the true performance modes of the system. We create these surrogates by utilizing imitation learning with deep neural networks. By using imitator surrogates in place of the true agent, we are capable of predicting mission performance more quickly, gaining greater throughput for simulation-based testing. We demonstrate that using on-line imitation learning with Dataset Aggregation (DAgger) can not only correctly encode a policy that executes a complex mission, but can also encode multiple different behavioral modes. To improve performance for the target vehicle and mission, we manipulate the training set during each iteration to remove samples which do not contribute to the final policy. We call this approach Quantile-DAgger (Q-DAgger) and demonstrate its ability to replicate the behaviors of an autonomous vehicle in a collision avoidance scenario.
ER  - 

TY  - CONF
TI  - Feature-Based Transfer Learning for Robotic Push Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5643
EP  - 5650
AU  - J. Stüber
AU  - M. Kopicki
AU  - C. Zito
PY  - 2018
KW  - CAD
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - contact models
KW  - motion models
KW  - point cloud object model
KW  - CAD model
KW  - contact-based predictors
KW  - robotic push manipulation
KW  - feature-based transfer learning
KW  - Robots
KW  - Three-dimensional displays
KW  - Predictive models
KW  - Solid modeling
KW  - Kernel
KW  - Probability density function
KW  - Training
DO  - 10.1109/ICRA.2018.8460989
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a data-efficient approach to learning transferable forward models for robotic push manipulation. Our approach extends our previous work on contact-based predictors by leveraging information on the pushed object's local surface features. We test the hypothesis that, by conditioning predictions on local surface features, we can achieve generalisation across objects of different shapes. In doing so, we do not require a CAD model of the object but rather rely on a point cloud object model (PCOM). Our approach involves learning motion models that are specific to contact models. Contact models encode the contacts seen during training time and allow generating similar contacts at prediction time. Predicting on familiar ground reduces the motion models' sample complexity while using local contact information for prediction increases their transferability. In extensive experiments in simulation, our approach is capable of transfer learning for various test objects, outperforming a baseline predictor. We support those results with a proof of concept on a real robot.
ER  - 

TY  - CONF
TI  - Inducing Probabilistic Context-Free Grammars for the Sequencing of Movement Primitives
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5651
EP  - 5658
AU  - R. Lioutikov
AU  - G. Maeda
AU  - F. Veiga
AU  - K. Kersting
AU  - J. Peters
PY  - 2018
KW  - Bayes methods
KW  - context-free grammars
KW  - formal languages
KW  - grammars
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - Monte Carlo methods
KW  - motion control
KW  - probability
KW  - robot dynamics
KW  - robots
KW  - rule-based nature
KW  - formal grammars
KW  - complex robot policies
KW  - composing primitives
KW  - modern robotics
KW  - inducing probabilistic context-free grammars
KW  - simple movement primitives
KW  - complex sequences
KW  - degree-of-freedom lightweight robotic arm
KW  - Markov Chain Monte Carlo optimization
KW  - grammar space
KW  - robot movement primitives
KW  - physical nature
KW  - yet unsolved challenge
KW  - complicated challenge
KW  - way robot policies
KW  - hierarchical concept
KW  - recursively structured tasks
KW  - hierarchically tasks
KW  - Grammar
KW  - Robots
KW  - Task analysis
KW  - Probabilistic logic
KW  - Sequential analysis
KW  - Markov processes
KW  - Optimization
DO  - 10.1109/ICRA.2018.8460190
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Movement Primitives are a well studied and widely applied concept in modern robotics. Composing primitives out of an existing library, however, has shown to be a challenging problem. We propose the use of probabilistic context-free grammars to sequence a series of primitives to generate complex robot policies from a given library of primitives. The rule-based nature of formal grammars allows an intuitive encoding of hierarchically and recursively structured tasks. This hierarchical concept strongly connects with the way robot policies can be learned, organized, and re-used. However, the induction of context-free grammars has proven to be a complicated and yet unsolved challenge. In this work, we exploit the physical nature of robot movement primitives to restrict and efficiently search the grammar space. The grammar is learned applying a Markov Chain Monte Carlo optimization over the posteriors of the grammars given the observations. The proposal distribution is defined as a mixture over the probabilities of the operators connecting the search space. Restrictions to these operators guarantee continuous sequences while reducing the grammar space. We validate our method on a redundant 7 degree-of-freedom lightweight robotic arm on tasks that require the generation of complex sequences consisting of simple movement primitives.
ER  - 

TY  - CONF
TI  - Synthetically Trained Neural Networks for Learning Human-Readable Plans from Real-World Demonstrations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5659
EP  - 5666
AU  - J. Tremblay
AU  - T. To
AU  - A. Molchanov
AU  - S. Tyree
AU  - J. Kautz
AU  - S. Birchfield
PY  - 2018
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - robots
KW  - convolutional pose machines
KW  - human-readable plans learning
KW  - domain randomization
KW  - Baxter robot
KW  - image space
KW  - synthetic images
KW  - perception network
KW  - program execution
KW  - program generation
KW  - human-readable program
KW  - synthetically trained neural networks
KW  - world space
KW  - Task analysis
KW  - Training
KW  - Neural networks
KW  - Robot sensing systems
KW  - Robustness
KW  - Stacking
DO  - 10.1109/ICRA.2018.8460642
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a system to infer and execute a human-readable program from a real-world demonstration. The system consists of a series of neural networks to perform perception, program generation, and program execution. Leveraging convolutional pose machines, the perception network reliably detects the bounding cuboids of objects in real images even when severely occluded, after training only on synthetic images using domain randomization. To increase the applicability of the perception network to new scenarios, the network is formulated to predict in image space rather than in world space. Additional networks detect relationships between objects, generate plans, and determine actions to reproduce a real-world demonstration. The networks are trained entirely in simulation, and the system is tested in the real world on the pick-and-place problem of stacking colored cubes using a Baxter robot.
ER  - 

TY  - CONF
TI  - Generalized Task-Parameterized Skill Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5667
EP  - 5474
AU  - Y. Huang
AU  - J. Silvério
AU  - L. Rozo
AU  - D. G. Caldwell
PY  - 2018
KW  - Gaussian processes
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mixture models
KW  - motion control
KW  - robot programming
KW  - generalized task-parameterized skill learning
KW  - human skills
KW  - task-parameterized Gaussian mixture model
KW  - TP-GMM
KW  - human-robot collaboration
KW  - dual-arm manipulation
KW  - learning framework
KW  - task parameters
KW  - robot joint limits
KW  - task-parameterized learning
KW  - learned skills
KW  - real robotic systems
KW  - task constraints
KW  - learning perspective
KW  - Programming by demonstration
KW  - Task analysis
KW  - Trajectory
KW  - Robot kinematics
KW  - Optimization
KW  - Feature extraction
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8461079
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Programming by demonstration has recently gained much attention due to its user-friendly and natural way to transfer human skills to robots. In order to facilitate the learning of multiple demonstrations and meanwhile generalize to new situations, a task-parameterized Gaussian mixture model (TP-GMM) has been recently developed. This model has achieved reliable performance in areas such as human-robot collaboration and dual-arm manipulation. However, the crucial task frames and associated parameters in this learning framework are often set by the human teacher, which renders three problems that have not been addressed yet: (i) task frames are treated equally, without considering their individual importance, (ii) task parameters are defined without taking into account additional task constraints, such as robot joint limits and motion smoothness, and (iii) a fixed number of task frames are pre-defined regardless of whether some of them may be redundant or even irrelevant for the task at hand. In this paper, we generalize the task-parameterized learning by addressing the aforementioned problems. Moreover, we provide a novel learning perspective which allows the robot to refine and adapt previously learned skills in a low dimensional space. Several examples are studied in both simulated and real robotic systems, showing the applicability of our approach.
ER  - 

TY  - CONF
TI  - Teaching Human Teachers to Teach Robot Learners
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5675
EP  - 5681
AU  - A. Sena
AU  - Y. Zhao
AU  - M. J. Howard
PY  - 2018
KW  - automatic programming
KW  - computer aided instruction
KW  - control engineering computing
KW  - data visualisation
KW  - feedback
KW  - human-robot interaction
KW  - robot programming
KW  - robots
KW  - teaching
KW  - robot learners generalisable skills
KW  - demonstration data sets
KW  - ambiguous demonstrations
KW  - teaching phase
KW  - interactive teaching process
KW  - robust teaching process
KW  - human teachers
KW  - heuristic rules
KW  - robot learners teaching
KW  - undemonstrated states
KW  - visual feedback
KW  - programming by demonstration
KW  - PbD
KW  - feedback visualisation
KW  - Task analysis
KW  - Education
KW  - Trajectory
KW  - Robot sensing systems
KW  - Visualization
KW  - Service robots
DO  - 10.1109/ICRA.2018.8461194
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Using Programming by Demonstration to teach robot learners generalisable skills relies on having effective human teachers. This paper aims to address two problems commonly observed in demonstration data sets that arise due to poor teaching strategies; undemonstrated states and ambiguous demonstrations. Overcoming these issues through the use of visual feedback and simple heuristic rules is investigated as a potential way of guiding novice users to more effectively teach robot learners to generalise a task. The proposed method intends to offer the user a more transparent understanding of the robot learner's model state during the teaching phase, to create a more interactive and robust teaching process. Results from a single-factor, three-phase repeated measures study with n=30 participants, comparing the proposed feedback and heuristic rules set against an unguided condition, show a statistically significant (F(2,58)=7.952,p=0.001) improvement of user teaching efficiency of approximately 180% when using the proposed feedback visualisation.
ER  - 

TY  - CONF
TI  - Sensor-Based Reactive Symbolic Planning in Partially Known Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5683
EP  - 5690
AU  - V. Vasilopoulos
AU  - W. Vega-Brown
AU  - O. Arslan
AU  - N. Roy
AU  - D. E. Koditschek
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - sensors
KW  - differential drive robot
KW  - LIDAR sensor
KW  - passive objects
KW  - deliberative planner
KW  - symbolic commands
KW  - obstacle avoidance
KW  - reactive planner
KW  - sensor-based reactive symbolic planning
KW  - nonconvex environments
KW  - convex obstacles
KW  - high-level commands
KW  - Robot sensing systems
KW  - Planning
KW  - Task analysis
KW  - Grippers
KW  - Laser radar
KW  - Collision avoidance
DO  - 10.1109/ICRA.2018.8460861
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper considers the problem of completing assemblies of passive objects in nonconvex environments, cluttered with convex obstacles of unknown position, shape and size that satisfy a specific separation assumption. A differential drive robot equipped with a gripper and a LIDAR sensor, capable of perceiving its environment only locally, is used to position the passive objects in a desired configuration. The method combines the virtues of a deliberative planner generating high-level, symbolic commands, with the formal guarantees of convergence and obstacle avoidance of a reactive planner that requires little onboard computation and is used online. The validity of the proposed method is verified both with formal proofs and numerical simulations.
ER  - 

TY  - CONF
TI  - Near-optimal Irrevocable Sample Selection for Periodic Data Streams with Applications to Marine Robotics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5691
EP  - 5698
AU  - G. Flaspohler
AU  - N. Roy
AU  - Y. Girdhar
PY  - 2018
KW  - autonomous underwater vehicles
KW  - environmental science computing
KW  - mobile robots
KW  - optimisation
KW  - sampling methods
KW  - set theory
KW  - spatiotemporal phenomena
KW  - optimal irrevocable sample selection
KW  - periodic data streams
KW  - marine robotics
KW  - spatiotemporal phenomena
KW  - classical secretary problem
KW  - random order
KW  - environmental monitoring domains
KW  - spatiotemporal structure
KW  - representative samples
KW  - periodic structure
KW  - monotone submodular utility function
KW  - Martha's Vineyard Coastal Observatory
KW  - phytoplankton sample locations
KW  - information-theoretic sense
KW  - periodic secretary algorithm
KW  - theoretical performance guarantees
KW  - sample selection algorithm
KW  - environmental dataset
KW  - optimal sample set
KW  - Entropy
KW  - Mutual information
KW  - Robot sensing systems
KW  - Prediction algorithms
KW  - Real-time systems
KW  - Periodic structures
DO  - 10.1109/ICRA.2018.8460709
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the task of monitoring spatiotemporal phenomena in real-time by deploying limited sampling resources at locations of interest irrevocably and without knowledge of future observations. This task can be modeled as an instance of the classical secretary problem. Although this problem has been studied extensively in theoretical domains, existing algorithms require that data arrive in random order to provide performance guarantees. These algorithms will perform arbitrarily poorly on data streams such as those encountered in robotics and environmental monitoring domains, which tend to have spatiotemporal structure. We focus on the problem of selecting representative samples from phenomena with periodic structure and introduce a novel sample selection algorithm that recovers a near-optimal sample set according to any monotone submodular utility function. We evaluate our algorithm on a seven-year environmental dataset collected at the Martha's Vineyard Coastal Observatory and show that it selects phytoplankton sample locations that are nearly optimal in an information-theoretic sense for predicting phytoplankton concentrations in locations that were not directly sampled. The proposed periodic secretary algorithm can be used with theoretical performance guarantees in many real-time sensing and robotics applications for streaming, irrevocable sample selection from periodic data streams.
ER  - 

TY  - CONF
TI  - Autonomous Feature Tracing and Adaptive Sampling in Real-World Underwater Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5699
EP  - 5704
AU  - A. Quraishi
AU  - A. Bahr
AU  - F. Schill
AU  - A. Martinoli
PY  - 2018
KW  - autonomous underwater vehicles
KW  - lakes
KW  - mobile robots
KW  - temperature sensors
KW  - real-world operation
KW  - adaptive sampling missions
KW  - AUV
KW  - Autonomous feature tracing
KW  - real-world Underwater environments
KW  - underwater environmental sensing
KW  - compact high resolution
KW  - temperature sensing module
KW  - microstructure
KW  - turbulence measurements
KW  - sensing requirements
KW  - horizontal variation capture
KW  - water bodies
KW  - Temperature measurement
KW  - Lakes
KW  - Microorganisms
KW  - Robot sensing systems
KW  - Trajectory
KW  - Temperature sensors
DO  - 10.1109/ICRA.2018.8460627
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Applications of robots for gathering data in underwater environments has been limited due to the challenges posed by the medium. We have developed a miniature, agile, easy to carry and deploy Autonomous Underwater Vehicle (AUV) equipped with a suite of sensors for underwater environmental sensing. We have also developed a compact high resolution fast temperature sensing module for the AUV for microstructure and turbulence measurements in water bodies. In this paper, we describe a number of algorithms and subsystems of the AUV that enable autonomous real-world operation, and present the data gathered in an experimental campaign in collaboration with limnologists. We demonstrate adaptive sampling missions where the AUV could autonomously locate a zone of interest and adapt its trajectory to stay in it. Further, it could execute specific behaviors to accommodate special sensing requirements necessary to enhance the quality of the data collected. In these missions, the AUV could autonomously trace a feature and capture horizontal variation in various quantities, including turbidity and temperature fluctuations, allowing limnologists to study lake phenomena in an additional dimension.
ER  - 

TY  - CONF
TI  - Navigating Congested Environments with Risk Level Sets
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5712
EP  - 5719
AU  - A. Pierson
AU  - W. Schwarting
AU  - S. Karaman
AU  - D. Rus
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - multi-agent systems
KW  - road vehicles
KW  - risk level set
KW  - congested environment navigation
KW  - cluttered environment
KW  - congestion cost
KW  - occupancy risk
KW  - cost function
KW  - planning space
KW  - agent planning
KW  - autonomous vehicle driving
KW  - risk threshold
KW  - conservative behavior
KW  - aggressive behavior
KW  - Planning
KW  - Level set
KW  - Navigation
KW  - Vehicle dynamics
KW  - Autonomous vehicles
KW  - Collision avoidance
KW  - Cost function
DO  - 10.1109/ICRA.2018.8460697
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we address the problem of navigating in a cluttered environment by introducing a congestion cost that maps the density and motion of objects to an occupancy risk. We propose that an agent can choose a “risk level set” from this cost function and construct a planning space from this set. In choosing different levels of risk, the agent adjusts its interactions with the other agents. From the assumption that agents are self-preserving, we show that any agent planning within their risk level set will avoid collisions with other agents. We then present an application of planning with risk level sets in the framework of an autonomous vehicle driving along a highway. Using the risk level sets, the agent can determine safe zones when planning a sequence of lane changes. Through simulations in Matlab, we demonstrate how the choice of risk threshold manifests as aggressive or conservative behavior.
ER  - 

TY  - CONF
TI  - Algorithms for Routing of Unmanned Aerial Vehicles with Mobile Recharging Stations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5720
EP  - 5725
AU  - K. Yu
AU  - A. K. Budhiraja
AU  - P. Tokekar
PY  - 2018
KW  - autonomous aerial vehicles
KW  - battery powered vehicles
KW  - computational complexity
KW  - travelling salesman problems
KW  - vehicle routing
KW  - Unmanned Aerial Vehicles
KW  - mobile recharging stations
KW  - energy-limited Unmanned Aerial Vehicle
KW  - stationary recharging stations
KW  - Unmanned Ground Vehicles
KW  - UGV
KW  - Traveling Salesperson Problem
KW  - stationary charging stations
KW  - UAV mission
KW  - Routing
KW  - NP-Hard
KW  - Generalized TSP
KW  - Batteries
KW  - Unmanned aerial vehicles
KW  - Charging stations
KW  - Land vehicles
KW  - Optimization
KW  - Monitoring
KW  - Planning
DO  - 10.1109/ICRA.2018.8460819
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We study the problem of finding a tour for an energy-limited Unmanned Aerial Vehicle (UAV) to visit a set of sites in the least amount of time. We envision scenarios where the UAV can be recharged along the way either by landing on stationary recharging stations or on Unmanned Ground Vehicles (UGVs) acting as mobile recharging stations. This leads to a new variant of the Traveling Salesperson Problem (TSP). We present an algorithm that finds not only the order in which to visit the sites but also when and where to land on the charging stations to recharge. Our algorithm plans tours for the UGVs as well as determines best locations to place stationary charging stations. While the problems we study are NP-Hard, we present a practical solution using Generalized TSP that finds the optimal solution. If the UGVs are slower, the algorithm also finds the minimum number of UGVs required to support the UAV mission such that the UAV is not required to wait for the UGV. Our simulation results show that the running time is acceptable for reasonably sized instances.
ER  - 

TY  - CONF
TI  - Topological Multi-Robot Belief Space Planning in Unknown Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5726
EP  - 5732
AU  - A. Kitanov
AU  - V. Indelman
PY  - 2018
KW  - Bayes methods
KW  - graph theory
KW  - multi-robot systems
KW  - path planning
KW  - topology
KW  - graph pruning
KW  - topological properties
KW  - factor graphs
KW  - topological space
KW  - embedded state space
KW  - high-dimensional state spaces
KW  - announced path approach
KW  - topological multirobot belief space planning
KW  - BSP approaches
KW  - factor graph representation
KW  - posterior beliefs
KW  - Planning
KW  - Robot kinematics
KW  - Simultaneous localization and mapping
KW  - Linear programming
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2018.8460772
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we introduce a novel concept, topological belief space planning (BSP), that uses topological properties of the underlying factor graph representation of future posterior beliefs to direct the search for an optimal solution. This concept deviates from state-of-the-art BSP approaches and is motivated by recent results which indicated, in the context of graph pruning, that topological properties of factor graphs dominantly determine the estimation accuracy. Topological space is also often less dimensional than the embedded state space. In particular, we show how this novel concept can be used in multi-robot belief space planning in high-dimensional state spaces to overcome drawbacks of state-of-the-art approaches: computational intractability of an exhaustive objective evaluation for all candidate path combinations from different robots and dependence on the initial guess in the announced path approach, which can lead to a local minimum of the objective function. We demonstrate our approach in a synthetic simulation.
ER  - 

TY  - CONF
TI  - Efficient Stabilization of Zero-Slope Walking for Bipedal Robots Following Their Passive Fixed-Point Trajectories
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5733
EP  - 5738
AU  - A. Smyrli
AU  - G. A. Bertos
AU  - E. Papadopoulos
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - stability
KW  - trajectory control
KW  - biped walking
KW  - stabilization
KW  - control law
KW  - ankle torques
KW  - hip
KW  - counterweight joint
KW  - energy input
KW  - numerical simulations
KW  - semicircular feet
KW  - compliant legs
KW  - passive fixed-point trajectories
KW  - bipedal robots
KW  - zero-slope walking
KW  - passive gaits
KW  - stable gaits
KW  - nonlinear PD terms
KW  - virtual-gravity components
KW  - Legged locomotion
KW  - Foot
KW  - Gravity
KW  - Hip
KW  - Damping
KW  - Torso
KW  - Stability analysis
DO  - 10.1109/ICRA.2018.8460845
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents an efficient method of stabilizing the gait of an underactuated biped with compliant legs and semicircular feet. First, the model is defined, incorporating elements that are often present in experimental biped robots. The biped's passive behavior is studied through numerical simulations that provide insight into the gravity's contribution as an energy input to the system. Based on this study, it is shown that an augmented biped -with the addition of a counterweight joint at the hip- is able to perform stable gaits with minimal input. This design is implemented easily as it does not require ankle torques; instead, both motors are mounted at the biped's hip. The control law used for the stabilization is the combination of virtual-gravity components with non-linear PD terms. The stable gaits performed by the augmented biped on level floor strongly resemble the passive gaits of the original biped walking on a slope, resulting in an efficient, natural-like motion of low transport cost.
ER  - 

TY  - CONF
TI  - Straight-Leg Walking Through Underconstrained Whole-Body Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5747
EP  - 5754
AU  - R. J. Griffin
AU  - G. Wiedebach
AU  - S. Bertrand
AU  - A. Leonessa
AU  - J. Pratt
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - quadratic programming
KW  - reachability analysis
KW  - robot kinematics
KW  - straight-leg walking
KW  - whole-body control
KW  - natural gait
KW  - bipedal robots
KW  - straightened legs
KW  - complex height planning
KW  - whole-body controller
KW  - straightest possible leg configuration
KW  - run-time
KW  - controller solutions
KW  - leg joint angle objectives
KW  - null-space
KW  - quadratic program motion objectives
KW  - toe-off motion
KW  - kinematic reachability
KW  - Legged locomotion
KW  - Iterative closest point algorithm
KW  - Trajectory
KW  - Planning
KW  - Acceleration
KW  - Foot
DO  - 10.1109/ICRA.2018.8460751
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present an approach for achieving a natural, efficient gait on bipedal robots using straightened legs and toe-off. Our algorithm avoids complex height planning by allowing a whole-body controller to determine the straightest possible leg configuration at run-time. The controller solutions are biased towards a straight leg configuration by projecting leg joint angle objectives into the null-space of the other quadratic program motion objectives. To allow the legs to remain straight throughout the gait, toe-off was utilized to increase the kinematic reachability of the legs. The toe-off motion is achieved through underconstraining the foot position, allowing it to emerge naturally. We applied this approach of under-specifying the motion objectives to the Atlas humanoid, allowing it to walk over a variety of terrain. We present both experimental and simulation results and discuss performance limitations and potential improvements.
ER  - 

TY  - CONF
TI  - Agile and Adaptive Hopping Height Control for a Pneumatic Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5755
EP  - 5760
AU  - M. F. Hale
AU  - J. L. Du Bois
AU  - P. Iravani
PY  - 2018
KW  - legged locomotion
KW  - pneumatic actuators
KW  - hop height every step
KW  - discontinuous terrain
KW  - safe footholds
KW  - bipedal running
KW  - quadrupedal running
KW  - constrained vertical hopping
KW  - pneumatic robot
KW  - vertical height
KW  - hopping robot
KW  - pneumatically actuated hopper
KW  - Legged locomotion
KW  - Valves
KW  - Computational modeling
KW  - Actuators
KW  - Atmospheric modeling
KW  - Force
DO  - 10.1109/ICRA.2018.8460557
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a controller for the vertical height of a hopping robot. The ability to accurately change the hop height every step will contribute toward the traversal of discontinuous terrain with limited safe footholds, with application to bipedal or quadrupedal running. A key feature of the approach presented is the use of information from previous hops/steps to inform the control of the current step. As well as avoiding modelling errors, this allows the robot to make on-line adjustments in response to changes in system parameters or the environment. The algorithm is simple enough to be easily implemented on a low power hardware, not requiring computationally demanding optimisation or numerical simulation. The effectiveness of this approach has been demonstrated for constrained vertical hopping in simulation and on a pneumatically actuated hopper.
ER  - 

TY  - CONF
TI  - Robust Rough-Terrain Locomotion with a Quadrupedal Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5761
EP  - 5768
AU  - P. Fankhauser
AU  - M. Bjelonic
AU  - C. Dario Bellicoso
AU  - T. Miki
AU  - M. Hutter
PY  - 2018
KW  - collision avoidance
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - path planning
KW  - pose estimation
KW  - robot dynamics
KW  - robot kinematics
KW  - terrain mapping
KW  - robust rough-terrain locomotion
KW  - natural settings
KW  - industrial settings
KW  - motion planner
KW  - perceptive rough-terrain locomotion
KW  - safe footholds
KW  - collision-free swing-leg motions
KW  - acquired terrain map
KW  - optimization approach
KW  - significant obstacles
KW  - quadrupedal robot ANYmal
KW  - locomotion planner
KW  - dynamic environments
KW  - urban settings
KW  - pose optimization approach
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Planning
KW  - Collision avoidance
KW  - Surface treatment
DO  - 10.1109/ICRA.2018.8460731
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robots working in natural, urban, and industrial settings need to be able to navigate challenging environments. In this paper, we present a motion planner for the perceptive rough-terrain locomotion with quadrupedal robots. The planner finds safe footholds along with collision-free swing-leg motions by leveraging an acquired terrain map. To this end, we present a novel pose optimization approach that enables the robot to climb over significant obstacles. We experimentally validate our approach with the quadrupedal robot ANYmal by autonomously traversing obstacles such steps, inclines, and stairs. The locomotion planner re-plans the motion at every step to cope with disturbances and dynamic environments. The robot has no prior knowledge of the scene, and all mapping, state estimation, control, and planning is performed in real-time onboard the robot.
ER  - 

TY  - CONF
TI  - Central Pattern Generator With Inertial Feedback for Stable Locomotion and Climbing in Unstructured Terrain
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5769
EP  - 5775
AU  - G. Sartoretti
AU  - S. Shaw
AU  - K. Lam
AU  - N. Fan
AU  - M. Travers
AU  - H. Choset
PY  - 2018
KW  - feedback
KW  - legged locomotion
KW  - motion control
KW  - neurophysiology
KW  - sensory feedback
KW  - inertial feedback
KW  - open-loop control strategy
KW  - complexity
KW  - terrain steepness
KW  - challenging terrains
KW  - steep terrains
KW  - hexapod robot
KW  - steep terrain
KW  - legged locomotion
KW  - body posture
KW  - CPG framework
KW  - level terrain
KW  - open-loop gait generation
KW  - CPG models
KW  - locomotive performance
KW  - gait adaptation
KW  - swimming legged robots
KW  - crawling legged robots
KW  - articulated robots
KW  - gaits
KW  - central pattern generator models
KW  - unstructured terrain
KW  - stable locomotion
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Limit-cycles
KW  - Robot kinematics
KW  - Adaptation models
KW  - Oscillators
DO  - 10.1109/ICRA.2018.8461013
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Inspired by the locomotor nervous system of vertebrates, central pattern generator (CPG) models can be used to design gaits for articulated robots, such as crawling, swimming or legged robots. Incorporating sensory feedback for gait adaptation in these models can improve the locomotive performance of such robots in challenging terrain. However, many CPG models to date have been developed exclusively for open-loop gait generation for traversing level terrain. In this paper, we present a novel approach for incorporating inertial feedback into the CPG framework for the control of body posture during legged locomotion on steep, unstructured terrain. That is, we adapt the limit cycle of each leg of the robot with time to simultaneously produce locomotion and body posture control. We experimentally validate our approach on a hexapod robot, locomoting in a variety of steep, challenging terrains (grass, rocky slide, stairs). We show how our approach can be used to level the robot's body, allowing it to locomote at a relatively constant speed, even as terrain steepness and complexity prevents the use of an open-loop control strategy.
ER  - 

TY  - CONF
TI  - On Time Optimization of Centroidal Momentum Dynamics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5776
EP  - 5782
AU  - B. Ponton
AU  - A. Herzog
AU  - A. Del Prete
AU  - S. Schaal
AU  - L. Righetti
PY  - 2018
KW  - angular momentum
KW  - concave programming
KW  - convex programming
KW  - humanoid robots
KW  - minimisation
KW  - mobile robots
KW  - path planning
KW  - position control
KW  - robot dynamics
KW  - time optimal control
KW  - fixed timing
KW  - motion plans
KW  - timing optimization
KW  - nonconvex problem
KW  - time-optimized dynamically consistent trajectories
KW  - centroidal dynamics
KW  - time variables
KW  - nonconvexity
KW  - contact forces
KW  - momentum trajectories
KW  - convex relaxation
KW  - trajectory optimization techniques
KW  - multicontact scenarios
KW  - dynamically consistent motions
KW  - centroidal momentum dynamics
KW  - Optimization
KW  - Dynamics
KW  - Robots
KW  - Kinematics
KW  - Torque
KW  - Mathematical model
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460537
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recently, the centroidal momentum dynamics has received substantial attention to plan dynamically consistent motions for robots with arms and legs in multi-contact scenarios. However, it is also non convex which renders any optimization approach difficult and timing is usually kept fixed in most trajectory optimization techniques to not introduce additional non convexities to the problem. But this can limit the versatility of the algorithms. In our previous work, we proposed a convex relaxation of the problem that allowed to efficiently compute momentum trajectories and contact forces. However, our approach could not minimize a desired angular momentum objective which seriously limited its applicability. Noticing that the non-convexity introduced by the time variables is of similar nature as the centroidal dynamics one, we propose two convex relaxations to the problem based on trust regions and soft constraints. The resulting approaches can compute time-optimized dynamically consistent trajectories sufficiently fast to make the approach realtime capable. The performance of the algorithm is demonstrated in several multi-contact scenarios for a humanoid robot. In particular, we show that the proposed convex relaxation of the original problem finds solutions that are consistent with the original non-convex problem and illustrate how timing optimization allows to find motion plans that would be difficult to plan with fixed timing ††Implementation details and demos can be found in the source code available at https://git-amd.tuebingen.mpg.de/bponton/timeoptimization.
ER  - 

TY  - CONF
TI  - Toward Intuitive Teleoperation in Surgery: Human-Centric Evaluation of Teleoperation Algorithms for Robotic Needle Steering
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5799
EP  - 5806
AU  - Z. Wang
AU  - I. Reed
AU  - A. M. Fey
PY  - 2018
KW  - biomechanics
KW  - cognition
KW  - force feedback
KW  - haptic interfaces
KW  - medical robotics
KW  - needles
KW  - robot kinematics
KW  - steering systems
KW  - surgery
KW  - telerobotics
KW  - robotically steered needles
KW  - joint space control
KW  - Cartesian space control
KW  - hub-centered steering
KW  - user experience
KW  - user cognitive workload
KW  - muscle fatigue
KW  - human-centric metrics
KW  - human-centric evaluation
KW  - teleoperation algorithms
KW  - teleoperated systems
KW  - physiological metrics
KW  - cognitive metrics
KW  - teleoperation performance
KW  - intuitive teleoperation
KW  - robotic needle steering
KW  - kinematic metrics
KW  - teleoperation mappings
KW  - teleoperation strategies
KW  - steering control mapping
KW  - Needles
KW  - Aerospace electronics
KW  - Task analysis
KW  - Kinematics
KW  - Haptic interfaces
KW  - Measurement
KW  - Sensors
DO  - 10.1109/ICRA.2018.8460729
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The effectiveness of control algorithms for teleoperated systems is typically evaluated through experimental performance measures, post-experimental user surveys, and theoretical analysis. However, none of these methods provide an objective assessment of teleoperation algorithms with respect to the real-time changes of human users during teleoperated tasks in terms of physiological, kinematic, or cognitive metrics. In this study, we recruited subjects to control robotically steered needles in a randomized experiment, using four different teleoperation mappings (joint space control, steering control, and Cartesian space control with and without force feedback). We investigated how the choice of these algorithms affect both performance and user response. Our novel steering control mapping, which mimics hub-centered steering, is significantly correlated with decreased cognitive stress and improved teleoperation performance when compared to joint space control. Overall, user experience and teleoperation performance were significantly improved with Cartesian space control, resulting in faster needle insertion, higher targeting accuracy, lower cognitive load, and smoother movements. Furthermore, while additional haptic feedback in Cartesian space provided an improved performance, it may increase user cognitive workload and muscle fatigue. These results highlight the importance of considering human-centric metrics when designing novel teleoperation strategies for complex systems.
ER  - 

TY  - CONF
TI  - Human-guided Optical Manipulation of Multiple Microscopic Objects
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5807
EP  - 5812
AU  - Q. M. Ta
AU  - S. Lyu
AU  - C. C. Cheah
PY  - 2018
KW  - collision avoidance
KW  - decision making
KW  - manipulators
KW  - micromanipulators
KW  - multi-robot systems
KW  - radiation pressure
KW  - human-guided optical manipulation
KW  - multiple microscopic objects
KW  - control systems
KW  - multiple microobjects
KW  - robotic control technique
KW  - automated optical manipulation system
KW  - precise manipulation
KW  - productive manipulation
KW  - Robots
KW  - Microscopy
KW  - Optical microscopy
KW  - Potential energy
KW  - Biomedical optical imaging
KW  - Collision avoidance
DO  - 10.1109/ICRA.2018.8461258
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Existing control systems for optical manipulation of multiple micro-objects do not allow users to interact with the systems during manipulation to deal with unexpected events, while ensuring stability of the overall control systems. In this paper, we propose a robotic control technique for human-guided optical manipulation of multiple micro-objects using robotic tweezers. Humans, when necessary, are able to interact or intervene with an automated optical manipulation system in a stable manner, and thus guiding a group of micro-objects to be manipulated towards a desired region while ensuring collision avoidance during manipulation. Both the ability of humans, in term of decision making, when needed, and the advantages of an automated optical manipulation system which provides precise and productive manipulation of micro-objects, are consolidated into one single technique. A theoretical foundation is developed and investigated to achieve the control objective. Experimental results are presented to illustrate the effectiveness of the proposed control technique.
ER  - 


TY  - CONF
TI  - Enhanced Tele-interaction in Unknown Environments Using Semi-Autonomous Motion and Impedance Regulation Principles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5813
EP  - 5820
AU  - L. Muratore
AU  - A. Laurenzi
AU  - E. M. Hoffman
AU  - L. Baccelliere
AU  - N. Kashiri
AU  - D. G. Caldwell
AU  - N. G. Tsagarakis
PY  - 2018
KW  - collision avoidance
KW  - human-robot interaction
KW  - mobile robots
KW  - telerobotics
KW  - human intervention
KW  - tele-interaction
KW  - shared-autonomy Tele-Interaction control approach
KW  - impendance colliding
KW  - impedance setting
KW  - physical interactions
KW  - slave robot
KW  - human pilot
KW  - shared-autonomy control principles
KW  - autonomous impedance regulation
KW  - autonomous manner
KW  - physical constraints
KW  - robot platform
KW  - interaction forces
KW  - physical obstacles
KW  - remote robot
KW  - impedance modulators
KW  - autonomous motion
KW  - motion commands
KW  - remote workspace
KW  - human operator
KW  - remote environment
KW  - hazardous environments
KW  - robotics teleoperation
KW  - impedance regulation principles
KW  - Robots
KW  - Impedance
KW  - Task analysis
KW  - Collision avoidance
KW  - Payloads
KW  - Trajectory
KW  - Correlation
DO  - 10.1109/ICRA.2018.8460559
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotics teleoperation has been extensively studied and considered in the past in several task scenarios where direct human intervention is not possible due to the hazardous environments. In such applications, both communication degradation and reduced perception of the remote environment are practical issues that can challenge the human operator while controlling the robot and attempting to physically interact within the remote workspace. To address this challenge, we introduce a novel shared-autonomy Tele-Interaction control approach that blends the motion commands from the pilot (master side) with locally (slave side) executed autonomous motion and impedance modulators. This enables a remote robot to handle and autonomously avoid physical obstacles during manoeuvring, reduce interaction forces during contacts, and finally accommodate different payload conditions while at the same time operating with a “default” low impedance setting. We implemented and experimentally validated the proposed method both on simulation and on a real robot platform called CENTAURO. A series of tasks, such as maneuvering through the physical constraints of the remote environment in an autonomous manner, pushing and lifting heavy objects with autonomous impedance regulation and colliding with the rigid geometry of the remote environment were executed. The obtained results demonstrate the effectiveness of the shared-autonomy control principles that eventually aim to reduce the level of attention and stress of human pilot while manoeuvring the slave robot, and at the same time to enhance the robustness of the robot during physical interactions even if accidentally occurred.
ER  - 

TY  - CONF
TI  - Intuitive Hand Teleoperation by Novice Operators Using a Continuous Teleoperation Subspace
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5821
EP  - 5827
AU  - C. Meeker
AU  - T. Rasmussen
AU  - M. Ciocarlie
PY  - 2018
KW  - dexterous manipulators
KW  - motion control
KW  - telerobotics
KW  - intuitive control method
KW  - pose spaces
KW  - low-dimensional teleoperation subspace
KW  - continuous teleoperation subspace
KW  - nonanthropomorphic robot
KW  - teleoperation subspaces
KW  - teleoperation subspace mapping
KW  - intuitive hand teleoperation
KW  - novice operators
KW  - human-in-the-loop manipulation
KW  - autonomous grasping
KW  - input device
KW  - teleoperation methods
KW  - Aerospace electronics
KW  - Grasping
KW  - Kinematics
KW  - Task analysis
KW  - Teleoperators
KW  - Shape
DO  - 10.1109/ICRA.2018.8460506
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Human-in-the-loop manipulation is useful in when autonomous grasping is not able to deal sufficiently well with corner cases or cannot operate fast enough. Using the teleoperator's hand as an input device can provide an intuitive control method but requires mapping between pose spaces which may not be similar. We propose a low-dimensional and continuous teleoperation subspace which can be used as an intermediary for mapping between different hand pose spaces. We present an algorithm to project between pose space and teleoperation subspace. We use a non-anthropomorphic robot to experimentally prove that it is possible for teleoperation subspaces to effectively and intuitively enable teleoperation. In experiments, novice users completed pick and place tasks significantly faster using teleoperation subspace mapping than they did using state of the art teleoperation methods.
ER  - 

TY  - CONF
TI  - Avoiding Human-Robot Collisions Using Haptic Communication
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5828
EP  - 5834
AU  - Y. Che
AU  - C. T. Sun
AU  - A. M. Okamura
PY  - 2018
KW  - collision avoidance
KW  - haptic interfaces
KW  - human-robot interaction
KW  - mobile robots
KW  - service robots
KW  - telerobotics
KW  - collision scenario
KW  - haptic communication channel
KW  - human movement
KW  - human-robot collisions
KW  - autonomous navigation
KW  - populated environments
KW  - mobile robots
KW  - human-robot communication
KW  - navigation tasks
KW  - human users
KW  - wearable haptic interface
KW  - distinct haptic cues
KW  - vibration amplitudes
KW  - single human-single robot orthogonal encounter scenario
KW  - Collision avoidance
KW  - Haptic interfaces
KW  - Robot kinematics
KW  - Navigation
KW  - Legged locomotion
KW  - Predictive models
DO  - 10.1109/ICRA.2018.8460946
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Fully autonomous navigation in populated environments is still a challenging problem for mobile robots. This paper explores the idea of using active human-robot communication to facilitate navigation tasks. We propose to convey a robot's intent to human users via a wearable haptic interface. The interface can display distinct haptic cues by modulating vibration amplitudes and patterns. We applied the concept to a single human/single robot orthogonal encounter scenario, where one of the two parties has to yield the right of way to avoid collision. Under certain conditions, the robot's intent (to yield to the human or not) is revealed to the human via the haptic interface prior to the interaction. We conducted an experiment with 10 users, in which the robot was teleoperated as a substitute for autonomy. Results show that, when given priority, users become more risk-accepting and use different strategies to navigate the collision scenario than when the robot takes priority or there is no haptic communication channel. In addition, we propose a social-force based model to predict human movement during navigation. The effect of communication can be explained as a shift in the user's safety buffer and expectation of the robot's future velocity.
ER  - 

TY  - CONF
TI  - High Speed Whole Body Dynamic Motion Experiment with Real Time Master-Slave Humanoid Robot System
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5835
EP  - 5841
AU  - Y. Ishiguro
AU  - K. Kojima
AU  - F. Sugai
AU  - S. Nozawa
AU  - Y. Kakiuchi
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - humanoid robots
KW  - motion control
KW  - robot dynamics
KW  - smoothing methods
KW  - stability
KW  - telerobotics
KW  - master-slave operations
KW  - foot landing delay prediction
KW  - trajectory smoothing method
KW  - master-slave tennis swing experiment
KW  - high kick motion experiment
KW  - life-sized humanoid robot JAXON
KW  - high speed whole body dynamic motion experiment
KW  - online real time whole body master-slave control
KW  - dynamic whole body master-slave experiment
KW  - flexible master-slave operation
KW  - real time master-slave humanoid robot system
KW  - Foot
KW  - Master-slave
KW  - Humanoid robots
KW  - Interpolation
KW  - Dynamics
KW  - Real-time systems
DO  - 10.1109/ICRA.2018.8461207
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we propose novel methods suitable for online real time whole body master-slave control with real life-sized humanoid robot. We conducted some dynamic whole body master-slave experiment with life-sized humanoid robot, and we achieved speedier and flexible master-slave operation compared to conventional study. Conventionally, master-slave operations with humanoid robots were available with only the upper body of the humanoid robot, and the COM movement was limited to be static. In our previous study, we introduced LIP model based restrictions to ensure the balance stability. In this study, we extend the safety restrictions by introducing foot landing delay prediction and trajectory smoothing method suitable for real robot. We conducted master-slave tennis swing experiment and high kick motion experiment with life-sized humanoid robot “JAXON”, and we evaluated the effectiveness of our proposed methods and system.
ER  - 

TY  - CONF
TI  - Deep Trail-Following Robotic Guide Dog in Pedestrian Environments for People who are Blind and Visually Impaired - Learning from Virtual and Real Worlds
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5849
EP  - 5855
AU  - T. Chuang
AU  - N. Lin
AU  - J. Chen
AU  - C. Hung
AU  - Y. Huang
AU  - C. Teng
AU  - H. Huang
AU  - L. Yu
AU  - L. Giarré
AU  - H. Wang
PY  - 2018
KW  - biomimetics
KW  - control engineering computing
KW  - convolution
KW  - feedforward neural nets
KW  - handicapped aids
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robotic guide dog
KW  - interclass trail variations
KW  - deep convolutional neural network
KW  - virtual worlds
KW  - man-made trails
KW  - pedestrian environments
KW  - contact feedback
KW  - tactile trails
KW  - autonomous trail-following
KW  - virtual real-world environments
KW  - visually impaired
KW  - Dogs
KW  - Cameras
KW  - Robot vision systems
KW  - Navigation
KW  - Mobile robots
DO  - 10.1109/ICRA.2018.8460994
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Navigation in pedestrian environments is critical to enabling independent mobility for the blind and visually impaired (BVI) in their daily lives. White canes have been commonly used to obtain contact feedback for following walls, curbs, or man-made trails, whereas guide dogs can assist in avoiding physical contact with obstacles or other pedestrians. However, the infrastructures of tactile trails or guide dogs are expensive to maintain. Inspired by the autonomous lane following of self-driving cars, we wished to combine the capabilities of existing navigation solutions for BVI users. We proposed an autonomous, trail-following robotic guide dog that would be robust to variances of background textures, illuminations, and interclass trail variations. A deep convolutional neural network (CNN) is trained from both the virtual and realworld environments. Our work included major contributions: 1) conducting experiments to verify that the performance of our models trained in virtual worlds was comparable to that of models trained in the real world; 2) conducting user studies with 10 blind users to verify that the proposed robotic guide dog could effectively assist them in reliably following man-made trails.
ER  - 

TY  - CONF
TI  - MergeNet: A Deep Net Architecture for Small Obstacle Discovery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5856
EP  - 5862
AU  - K. Gupta
AU  - S. A. Javed
AU  - V. Gandhi
AU  - K. M. Krishna
PY  - 2018
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - neural net architecture
KW  - object tracking
KW  - traffic engineering computing
KW  - lost and found dataset
KW  - complementary features
KW  - RGBD input
KW  - high level features
KW  - low level features
KW  - weight-sharing
KW  - multistage training procedure
KW  - annotation process
KW  - autonomous driving
KW  - on-road scenes
KW  - novel network architecture
KW  - small obstacle discovery
KW  - deep net architecture
KW  - MergeNet
KW  - Roads
KW  - Image segmentation
KW  - Strips
KW  - Semantics
KW  - Training
KW  - Autonomous vehicles
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461065
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present here, a novel network architecture called MergeNet for discovering small obstacles for on-road scenes in the context of autonomous driving. The basis of the architecture rests on the central consideration of training with less amount of data since the physical setup and the annotation process for small obstacles is hard to scale. For making effective use of the limited data, we propose a multi-stage training procedure involving weight-sharing, separate learning of low and high level features from the RGBD input and a refining stage which learns to fuse the obtained complementary features. The model is trained and evaluated on the Lost and Found dataset and is able to achieve state-of-art results with just 135 images in comparison to the 1000 images used by the previous benchmark. Additionally, we also compare our results with recent methods trained on 6000 images and show that our method achieves comparable performance with only 1000 training samples.
ER  - 

TY  - CONF
TI  - Deep Encoder-Decoder Networks for Mapping Raw Images to Dynamic Movement Primitives
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5863
EP  - 5868
AU  - R. Pahič
AU  - A. Gams
AU  - A. Ude
AU  - J. Morimoto
PY  - 2018
KW  - backpropagation
KW  - handwriting recognition
KW  - handwritten character recognition
KW  - neural nets
KW  - dynamic movement primitives
KW  - cost functions
KW  - raw image mapping
KW  - backpropagation
KW  - MNIST database
KW  - deep encoder-decoder network
KW  - associated movement trajectories
KW  - perception-action couplings
KW  - encoder-decoder networks
KW  - calculated movements
KW  - handwriting movements
KW  - Trajectory
KW  - Differential equations
KW  - Neural networks
KW  - Cost function
KW  - Training
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8460954
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a new approach for learning perception-action couplings. We show that by collecting a suitable set of raw images and the associated movement trajectories, a deep encoder-decoder network can be trained that takes raw images as input and outputs the corresponding dynamic movement primitives. We propose suitable cost functions for training the network and describe how to calculate their gradients to enable effective training by back-propagation. We tested the proposed approach both on a synthetic dataset and on a widely used MNIST database to generate handwriting movements from raw images of digits. The calculated movements were also applied for digit writing with a real robot.
ER  - 

TY  - CONF
TI  - What is (Missing or Wrong) in the Scene? A Hybrid Deep Boltzmann Machine for Contextualized Scene Modeling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5869
EP  - 5874
AU  - I. Bozcan
AU  - Y. Oymak
AU  - İ. Z. Alemdar
AU  - S. Kalkan
PY  - 2018
KW  - Boltzmann machines
KW  - image classification
KW  - learning (artificial intelligence)
KW  - restricted Boltzmann machines
KW  - hybrid deep Boltzmann machine
KW  - scene classification dataset
KW  - baseline models
KW  - different objects
KW  - visible nodes
KW  - BM
KW  - hybrid Boltzmann Machine
KW  - contextualized scene modeling
KW  - scene reasoning tasks
KW  - Training
KW  - Task analysis
KW  - Robots
KW  - Computational modeling
KW  - Context modeling
KW  - Estimation
KW  - Cognition
DO  - 10.1109/ICRA.2018.8460828
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Scene models allow robots to reason about what is in the scene, what else should be in it, and what should not be in it. In this paper, we propose a hybrid Boltzmann Machine (BM) for scene modeling where relations between objects are integrated. To be able to do that, we extend BM to include tri-way edges between visible (object) nodes and make the network to share the relations across different objects. We evaluate our method against several baseline models (Deep Boltzmann Machines, and Restricted Boltzmann Machines) on a scene classification dataset, and show that it performs better in several scene reasoning tasks.
ER  - 

TY  - CONF
TI  - Scene Recognition and Object Detection in a Unified Convolutional Neural Network on a Mobile Manipulator
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5875
EP  - 5881
AU  - H. Sun
AU  - Z. Meng
AU  - P. Y. Tao
AU  - M. H. Ang
PY  - 2018
KW  - control engineering computing
KW  - convolution
KW  - feature extraction
KW  - feedforward neural nets
KW  - image classification
KW  - image colour analysis
KW  - manipulators
KW  - mobile robots
KW  - object detection
KW  - object recognition
KW  - operating systems (computers)
KW  - robot programming
KW  - robot vision
KW  - scene classification
KW  - unified architecture
KW  - global scene features
KW  - regional object features
KW  - object recognition
KW  - continuous robot beliefs
KW  - robotics applications
KW  - Robot Operating System
KW  - mobile manipulator
KW  - object detection
KW  - object locations
KW  - network predictions
KW  - SUN RGBD dataset
KW  - 3D space
KW  - unified convolutional neural network
KW  - Proposals
KW  - Robots
KW  - Object detection
KW  - Object recognition
KW  - Three-dimensional displays
KW  - Semantics
KW  - Feature extraction
DO  - 10.1109/ICRA.2018.8460535
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Environment understanding, object detection and recognition are crucial skills for robots operating in the real world. In this paper, we propose a Convolutional Neural Network with multi-task objectives: object detection and scene classification in one unified architecture. The proposed network reasons globally about an image to understand the scene, hypothesize object locations, and encodes global scene features with regional object features to improve object recognition. We evaluate our network on the standard SUN RGBD dataset. Experiments show that our approach outperforms state-of-the-arts. Network predictions are further transformed into continuous robot beliefs to ensure temporal coherence and extended to 3D space for robotics applications. We embed the whole framework in Robot Operating System, and evaluate its performance on a real robot for semantic mapping and grasp detection.
ER  - 

TY  - CONF
TI  - AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5882
EP  - 5889
AU  - T. Do
AU  - A. Nguyen
AU  - I. Reid
PY  - 2018
KW  - image classification
KW  - learning (artificial intelligence)
KW  - object detection
KW  - multiple object detection
KW  - AffordanceNet
KW  - object localization
KW  - object classification
KW  - affordance label
KW  - robust resizing strategy
KW  - deconvolutional layer sequence
KW  - real-time robotic applications
KW  - testing environments
KW  - end-to-end architecture
KW  - multitask loss function
KW  - affordance mask
KW  - RGB images
KW  - object affordance detection
KW  - end-to-end deep learning approach
KW  - Feature extraction
KW  - Robots
KW  - Computer architecture
KW  - Object detection
KW  - Training
KW  - Image segmentation
KW  - Machine learning
DO  - 10.1109/ICRA.2018.8460902
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose AffordanceNet, a new deep learning approach to simultaneously detect multiple objects and their affordances from RGB images. Our AffordanceNet has two branches: an object detection branch to localize and classify the object, and an affordance detection branch to assign each pixel in the object to its most probable affordance label. The proposed framework employs three key components for effectively handling the multiclass problem in the affordance mask: a sequence of deconvolutional layers, a robust resizing strategy, and a multi-task loss function. The experimental results on the public datasets show that our AffordanceNet outperforms recent state-of-the-art methods by a fair margin, while its end-to-end architecture allows the inference at the speed of 150ms per image. This makes our AffordanceNet well suitable for real-time robotic applications. Furthermore, we demonstrate the effectiveness of AffordanceNet in different testing environments and in real robotic applications. The source code is available at https://github.com/nqanh/affordance-net.
ER  - 

TY  - CONF
TI  - ContextualNet: Exploiting Contextual Information Using LSTMs to Improve Image-Based Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5890
EP  - 5896
AU  - M. Patel
AU  - B. Emery
AU  - Y. Chen
PY  - 2018
KW  - convolution
KW  - feedforward neural nets
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - SLAM (robots)
KW  - CNN-LSTM model
KW  - pose estimation
KW  - single monocular image
KW  - Convolutional Neural Networks
KW  - image-based localization
KW  - ContextualNet
KW  - image content
KW  - indoor office space
KW  - Feature extraction
KW  - Cameras
KW  - Context modeling
KW  - Computer vision
KW  - Logic gates
KW  - Neural networks
DO  - 10.1109/ICRA.2018.8461124
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Convolutional Neural Networks (CNN) have successfully been utilized for localization using a single monocular image [1]. Most of the work to date has either focused on reducing the dimensionality of data for better learning of parameters during training or on developing different variations of CNN models to improve pose estimation. Many of the best performing works solely consider the content in a single image, while the context from historical images is ignored. In this paper, we propose a combined CNN-LSTM which is capable of incorporating contextual information from historical images to better estimate the current pose. Experimental results achieved using a dataset collected in an indoor office space improved the overall system results to 0.8 m & 2.5° at the third quartile of the cumulative distribution as compared with 1.5 m & 3.0° achieved by PoseNet [1]. Furthermore, we demonstrate how the temporal information exploited by the CNN-LSTM model assists in localizing the robot in situations where image content does not have sufficient features.
ER  - 

TY  - CONF
TI  - Learning Human-Aware Path Planning with Fully Convolutional Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5897
EP  - 5902
AU  - N. Pérez-Higueras
AU  - F. Caballero
AU  - L. Merino
PY  - 2018
KW  - convolution
KW  - feedforward neural nets
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - random processes
KW  - trees (mathematics)
KW  - robot social navigation
KW  - Fully Convolutional Neural Networks
KW  - mobile robots
KW  - human-aware path planning learning
KW  - optimal Rapidly-exploring Random Tree planner
KW  - robot navigation
KW  - classification problem
KW  - Robots
KW  - Navigation
KW  - Task analysis
KW  - Trajectory
KW  - Cost function
KW  - Feature extraction
DO  - 10.1109/ICRA.2018.8460851
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work presents an approach to learn path planning for robot social navigation by demonstration. We make use of Fully Convolutional Neural Networks (FCNs) to learn from expert's path demonstrations a map that marks a feasible path to the goal as a classification problem. The use of FCNs allows us to overcome the problem of manually designing/identifying the cost-map and relevant features for the task of robot navigation. The method makes use of optimal Rapidly-exploring Random Tree planner (RRT*) to overcome eventual errors in the path prediction; the FCNs prediction is used as cost-map and also to partially bias the sampling of the configuration space, leading the planner to behave similarly to the learned expert behavior. The approach is evaluated in experiments with real trajectories and compared with Inverse Reinforcement Learning algorithms that use RRT* as underlying planner.
ER  - 

TY  - CONF
TI  - Pedestrian Prediction by Planning Using Deep Neural Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5903
EP  - 5908
AU  - E. Rehder
AU  - F. Wirth
AU  - M. Lauer
AU  - C. Stiller
PY  - 2018
KW  - collision avoidance
KW  - convolution
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - pedestrians
KW  - traffic engineering computing
KW  - monolithic neural network
KW  - inverse reinforcement learning
KW  - pedestrian prediction
KW  - deep neural networks
KW  - collision avoidance
KW  - autonomous vehicles
KW  - goal-directed planning
KW  - mixture density function
KW  - motion prediction
KW  - convolutional network
KW  - traffic participant prediction
KW  - trajectories
KW  - Planning
KW  - Network topology
KW  - Topology
KW  - Convolution
KW  - Learning (artificial intelligence)
KW  - Trajectory
KW  - Prediction algorithms
DO  - 10.1109/ICRA.2018.8460203
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Accurate traffic participant prediction is the prerequisite for collision avoidance of autonomous vehicles. In this work, we propose to predict pedestrians using goal-directed planning. For this, we infer a mixture density function for possible destinations. We use these destinations as the goal states of a planning stage that performs motion prediction based on common behavior patterns. The patterns are learned by a fully convolutional network operating on maps of the environment. We show that this entire system can be modeled as one monolithic neural network and trained via inverse reinforcement learning. Experimental validation on real world data shows the system's ability to predict both, destinations and trajectories accurately.
ER  - 

TY  - CONF
TI  - Anticipation in Human-Robot Cooperation: A Recurrent Neural Network Approach for Multiple Action Sequences Prediction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5909
EP  - 5914
AU  - P. Schydlo
AU  - M. Rakovic
AU  - L. Jamone
AU  - J. Santos-Victor
PY  - 2018
KW  - feature selection
KW  - human-robot interaction
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pose estimation
KW  - recurrent neural nets
KW  - stochastic processes
KW  - human robot cooperation scenario
KW  - prediction model
KW  - action prediction dataset
KW  - human motion data
KW  - human-robot cooperation
KW  - recurrent neural network approach
KW  - multiple action sequences prediction
KW  - assistive applications
KW  - nonverbal cues
KW  - neural networks
KW  - human action prediction problem
KW  - continuous spaces
KW  - discrete spaces
KW  - encoder-decoder recurrent neural network topology
KW  - discrete action prediction problem
KW  - action sequences
KW  - feature selection
KW  - stochastic reward
KW  - Predictive models
KW  - Decoding
KW  - Hidden Markov models
KW  - Recurrent neural networks
KW  - Robot kinematics
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460924
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Close human-robot cooperation is a key enabler for new developments in advanced manufacturing and assistive applications. Close cooperation require robots that can predict human actions and intent, understanding human non-verbal cues. Recent approaches based on neural networks have led to encouraging results in the human action prediction problem both in continuous and discrete spaces. Our approach extends the research in this direction. Our contributions are three-fold. First, we validate the use of gaze and body pose cues as a means of predicting human action through a feature selection method. Next, we address two shortcomings of existing literature: predicting multiple and variable-length action sequences. This is achieved by applying an encoder-decoder recurrent neural network topology in the discrete action prediction problem. In addition, we theoretically demonstrate the importance of predicting multiple action sequences as a means of estimating the stochastic reward in a human robot cooperation scenario. Finally, we show the ability to effectively train the prediction model on an action prediction dataset, involving human motion data, and explore the influence of the model's parameters on its performance.
ER  - 

TY  - CONF
TI  - Text2Action: Generative Adversarial Synthesis from Language to Action
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5915
EP  - 5920
AU  - H. Ahn
AU  - T. Ha
AU  - Y. Choi
AU  - H. Yoo
AU  - S. Oh
PY  - 2018
KW  - recurrent neural nets
KW  - robots
KW  - text analysis
KW  - video signal processing
KW  - sequence to sequence model
KW  - Baxter robot
KW  - virtual agent
KW  - generative adversarial synthesis
KW  - Text2action
KW  - MSR-Video-to-Text
KW  - action decoder RNN
KW  - text encoder recurrent neural network
KW  - generative network
KW  - SEQ2SEQ
KW  - sequence model
KW  - generative adversarial network
KW  - human behavior
KW  - sentence
KW  - human action sequence
KW  - generative model
KW  - Decoding
KW  - Gallium nitride
KW  - Hidden Markov models
KW  - Generative adversarial networks
KW  - Robots
KW  - Recurrent neural networks
KW  - Generators
DO  - 10.1109/ICRA.2018.8460608
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we propose a generative model which learns the relationship between language and human action in order to generate a human action sequence given a sentence describing human behavior. The proposed generative model is a generative adversarial network (GAN), which is based on the sequence to sequence (SEQ2SEQ) model. Using the proposed generative network, we can synthesize various actions for a robot or a virtual agent using a text encoder recurrent neural network (RNN) and an action decoder RNN. The proposed generative network is trained from 29,770 pairs of actions and sentence annotations extracted from MSR-Video-to-Text (MSR-VTT), a large-scale video dataset. We demonstrate that the network can generate human-like actions which can be transferred to a Baxter robot, such that the robot performs an action based on a provided sentence. Results show that the proposed generative network correctly models the relationship between language and action and can generate a diverse set of actions from the same sentence.
ER  - 

TY  - CONF
TI  - A Data-driven Model for Interaction-Aware Pedestrian Motion Prediction in Object Cluttered Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5921
EP  - 5928
AU  - M. Pfeiffer
AU  - G. Paolo
AU  - H. Sommer
AU  - J. Nieto
AU  - R. Siegwart
AU  - C. Cadena
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion estimation
KW  - navigation
KW  - neural nets
KW  - pedestrians
KW  - human motion behavior
KW  - prediction accuracy
KW  - data-driven model
KW  - interaction-aware pedestrian motion prediction
KW  - object cluttered environments
KW  - interaction-aware motion prediction approach
KW  - human navigation behavior
KW  - Long-Short Term Memory neural networks
KW  - static obstacles
KW  - trajectory forecasting
KW  - polar angle space
KW  - Predictive models
KW  - Robots
KW  - Trajectory
KW  - Adaptation models
KW  - Navigation
KW  - Planning
KW  - Neural networks
DO  - 10.1109/ICRA.2018.8461157
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper reports on a data-driven, interaction-aware motion prediction approach for pedestrians in environments cluttered with static obstacles. When navigating in such workspaces shared with humans, robots need accurate motion predictions of the surrounding pedestrians. Human navigation behavior is mostly influenced by their surrounding pedestrians and by the static obstacles in their vicinity. In this paper we introduce a new model based on Long-Short Term Memory (LSTM) neural networks, which is able to learn human motion behavior from demonstrated data. To the best of our knowledge, this is the first approach using LSTMs, that incorporates both static obstacles and surrounding pedestrians for trajectory forecasting. As part of the model, we introduce a new way of encoding surrounding pedestrians based on a 1d-grid in polar angle space. We evaluate the benefit of interaction-aware motion prediction and the added value of incorporating static obstacles on both simulation and real-world datasets by comparing with state-of-the-art approaches. The results show, that our new approach outperforms the other approaches while being very computationally efficient and that taking into account static obstacles for motion predictions significantly improves the prediction accuracy, especially in cluttered environments.
ER  - 

TY  - CONF
TI  - Spatiotemporal Learning of Dynamic Gestures from 3D Point Cloud Data
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5929
EP  - 5934
AU  - J. Owoyemi
AU  - K. Hashimoto
PY  - 2018
KW  - feature extraction
KW  - feedforward neural nets
KW  - gesture recognition
KW  - image classification
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - motion recognition
KW  - spatiotemporal features
KW  - dense occupancy grids
KW  - 3D point cloud data
KW  - end-to-end spatiotemporal gesture learning approach
KW  - dynamic gestures
KW  - spatiotemporal learning
KW  - point cloud data augmentation
KW  - 3D convolutional neural network
KW  - gestures sample data
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Feature extraction
KW  - Solid modeling
KW  - Training data
KW  - Spatiotemporal phenomena
KW  - Hidden Markov models
DO  - 10.1109/ICRA.2018.8460910
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we demonstrate an end-to-end spatiotemporal gesture learning approach for 3D point cloud data using a new gestures dataset of point clouds acquired from a 3D sensor. Nine classes of gestures were learned from gestures sample data. We mapped point cloud data into dense occupancy grids, then time steps of the occupancy grids are used as inputs into a 3D convolutional neural network which learns the spatiotemporal features in the data without explicit modeling of gesture dynamics. We also introduced a 3D region of interest jittering approach for point cloud data augmentation. This resulted in an increased classification accuracy of up to 10% when the augmented data is added to the original training data. The developed model is able to classify gestures from the dataset with 84.44% accuracy. We propose that point cloud data will be a more viable data type for scene understanding and motion recognition, as 3D sensors become ubiquitous in years to come.
ER  - 

TY  - CONF
TI  - Functional Object-Oriented Network: Construction & Expansion
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5935
EP  - 5941
AU  - D. Paulius
AU  - A. B. Jelodar
AU  - Y. Sun
PY  - 2018
KW  - knowledge representation
KW  - object-oriented methods
KW  - manipulation sequences
KW  - knowledge retrieval algorithm
KW  - object categories
KW  - functional units
KW  - object similarity
KW  - video sources
KW  - knowledge spanning
KW  - object-motion affordances
KW  - structured knowledge representation
KW  - functional object-oriented network
KW  - Task analysis
KW  - Robots
KW  - Merging
KW  - Sun
KW  - Knowledge representation
KW  - Mirrors
KW  - Neurons
DO  - 10.1109/ICRA.2018.8460200
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We build upon the functional object-oriented network (FOON), a structured knowledge representation which is constructed from observations of human activities and manipulations. A FOON can be used for representing object-motion affordances. Knowledge retrieval through graph search allows us to obtain novel manipulation sequences using knowledge spanning across many video sources, hence the novelty in our approach. However, we are limited to the sources collected. To further improve the performance of knowledge retrieval as a follow up to our previous work, we discuss generalizing knowledge to be applied to objects which are similar to what we have in FOON without manually annotating new sources of knowledge. We discuss two means of generalization: 1) expanding our network through the use of object similarity to create new functional units from those we already have, and 2) compressing the functional units by object categories rather than specific objects. We discuss experiments which compare the performance of our knowledge retrieval algorithm with both expansion and compression by categories.
ER  - 

TY  - CONF
TI  - 3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5942
EP  - 5948
AU  - L. Sun
AU  - Z. Yan
AU  - S. M. Mellado
AU  - M. Hanheide
AU  - T. Duckett
PY  - 2018
KW  - cameras
KW  - codecs
KW  - image annotation
KW  - image coding
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - pedestrians
KW  - pose estimation
KW  - robot vision
KW  - service robots
KW  - SLAM (robots)
KW  - long-term temporal information
KW  - sequence-to-sequence LSTM encoder-decoder
KW  - on-the-fly prediction
KW  - global coordinate system
KW  - T-Pose-LSTM model
KW  - human trajectory prediction
KW  - long-term mobile robot deployments
KW  - 3DOF pedestrian trajectory prediction learned
KW  - Long-Term autonomous mobile robot deployment data
KW  - autonomous mobile service robots
KW  - monocular camera images
KW  - range-finder sensors
KW  - 3DOF pedestrian trajectory prediction approach
KW  - temporal 3DOF-pose long-short-term memory
KW  - robust human detection
KW  - Trajectory
KW  - Cameras
KW  - Robot kinematics
KW  - Robot vision systems
KW  - Two dimensional displays
KW  - Mobile robots
DO  - 10.1109/ICRA.2018.8461228
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.
ER  - 

TY  - CONF
TI  - Conditional Compatibility Branch and Bound for Feature Cloud Matching
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5965
EP  - 5970
AU  - X. Shen
AU  - M. H. Ang
AU  - D. Rus
PY  - 2018
KW  - computational complexity
KW  - image matching
KW  - SLAM (robots)
KW  - statistical distributions
KW  - tree searching
KW  - chi-square test
KW  - gating threshold
KW  - joint compatibility branch and bound
KW  - conditional compatibility branch and bound
KW  - feature cloud matching
KW  - incremental posterior joint compatibility
KW  - IPJC
KW  - FastJCBB
KW  - global optimal data association
KW  - Joint Compatibility test
KW  - JC test based search algorithm
KW  - CC test
KW  - conditional probability distribution
KW  - feature pairing
KW  - Conditional Compatibility test
KW  - Probabilistic logic
KW  - Robots
KW  - Measurement errors
KW  - Computational complexity
KW  - Probability distribution
KW  - Integrated circuits
KW  - Feature Cloud Matching
KW  - Scan Matching
KW  - Data Association
KW  - Conditional Compatibility Test
DO  - 10.1109/ICRA.2018.8460711
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we consider the problem of data association in feature cloud matching. While Joint Compatibility (JC) test is a widely adopted technique for searching the global optimal data association, it becomes less restrictive as more features are well matched. The early well-matched features contribute little to total matching cost while the gating threshold increases in the chi-square test, which allows the acceptance of bad feature pairings in the last step. In this paper, we propose the Conditional Compatibility (CC) test, which is not only more restrictive than JC test, but also probabilistically sound. The proposed test of a new feature pairing is based on the conditional probability distribution of feature locations given the early pairings. CC test can be added into any JC test based search algorithm, such as Joint Compatibility Branch and Bound (JCBB), Incremental Posterior Joint Compatibility (IPJC) and FastJCBB, without increasing much computational complexity. The more restrictive criterion of accepting a feature pairing, not only helps to reject bad associations, but also bounds the search space, which substantially improves the search efficiency. The real matching experiments justify that our algorithm produces better feature cloud matching results in a more efficient manner.
ER  - 

TY  - CONF
TI  - Assigning Visual Words to Places for Loop Closure Detection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5979
EP  - 5985
AU  - K. A. Tsintotas
AU  - L. Bampis
AU  - A. Gasteratos
PY  - 2018
KW  - image matching
KW  - image recognition
KW  - image representation
KW  - image segmentation
KW  - mobile robots
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - simultaneous localization and mapping
KW  - image stream
KW  - image match
KW  - dynamic segmentation
KW  - nearest neighbor voting scheme
KW  - image descriptors
KW  - query time
KW  - on-line clustering algorithm
KW  - visual vocabulary construction
KW  - robotic applications
KW  - LCD
KW  - place recognition
KW  - loop closure detection
KW  - visual words
KW  - Visualization
KW  - Liquid crystal displays
KW  - Robots
KW  - Databases
KW  - Pipelines
KW  - Feature extraction
KW  - Vocabulary
DO  - 10.1109/ICRA.2018.8461146
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Place recognition of pre-visited areas, widely known as Loop Closure Detection (LCD), constitutes one of the most important components in robotic applications, where the robot needs to estimate its pose while navigating through the field (e.g., simultaneous localization and mapping). In this paper, we present a novel approach for LCD based on the assignment of Visual Words (VWs) to particular places of the traversed path. The system operates in real time and does not require any pre-training procedure, such as visual vocabulary construction or descriptor-space dimensionality reduction. A place is defined through a dynamic segmentation of the incoming image stream and is assigned with VWs through the usage of an on-line clustering algorithm. At query time, image descriptors are converted into VWs on the map accumulating votes to the corresponding places. By means of a probability function, the mechanism is capable of identifying a loop closing candidate place. A nearest neighbor voting scheme on the descriptors' space allows the system to select the most appropriate image match at the chosen place. Geometrical and temporal consistency checks are applied on the proposed loop closing pair increasing the system's performance. Evaluation took place on several publicly available and challenging datasets offering high precision and recall scores as compared to other state-of-the-art approaches.
ER  - 

TY  - CONF
TI  - Dijkstra Model for Stereo-Vision Based Road Detection: A Non-Parametric Method
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5986
EP  - 5993
AU  - Y. Zhang
AU  - J. Yang
AU  - J. Ponce
AU  - H. Kong
PY  - 2018
KW  - computer vision
KW  - graph theory
KW  - image segmentation
KW  - object detection
KW  - roads
KW  - stereo image processing
KW  - traffic engineering computing
KW  - road detection
KW  - nonparametric method
KW  - improved v-disparity map
KW  - vanishing point
KW  - road region
KW  - horizon information
KW  - source node
KW  - weighted graph
KW  - left stereo-image
KW  - adjacency relationships
KW  - adjacent pixels
KW  - disparity information
KW  - road borders
KW  - Dijkstra algorithm
KW  - Dijkstra model
KW  - stereo vision
KW  - gray-scale information
KW  - image pairs
KW  - road scenes
KW  - weighted-sampling RANSAC-like method
KW  - KITTI dataset
KW  - Roads
KW  - Robustness
KW  - Three-dimensional displays
KW  - Stereo vision
KW  - Splines (mathematics)
KW  - Cameras
KW  - Image edge detection
DO  - 10.1109/ICRA.2018.8461071
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes a new method for detecting a road from a stereo pair of images. First, the horizon is accurately estimated by a robust, weighted-sampling RANSAC-like method in the improved v-disparity map. The vanishing point of the road region is located using both the horizon information and road flatness constraints. Then it is used as the source node of a weighted graph formed by the pixels of the left stereo-image and their adjacency relationships. The weight of each edge measures the inconsistency of adjacent pixels, and is computed using both the gray-scale and disparity information. Detecting road borders is thus reduced to finding two shortest paths from the source node to the bottom row of the image by the Dijkstra algorithm. The proposed method has been tested on 2621 image pairs of different road scenes from the KITTI dataset. Our experiments demonstrate that this training free approach detects horizon, vanishing point, and road region accurately and robustly, and compares favorably with the state of the art on the KITTI benchmark.
ER  - 

TY  - CONF
TI  - Asynchronous Multi-Sensor Fusion for 3D Mapping and Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5994
EP  - 5999
AU  - P. Geneva
AU  - K. Eckenhoff
AU  - G. Huang
PY  - 2018
KW  - graph theory
KW  - intelligent transportation systems
KW  - optimisation
KW  - pose estimation
KW  - sensor fusion
KW  - stereo image processing
KW  - 3D localization
KW  - factor graph-based optimization
KW  - autonomous driving
KW  - 3D pose measurement
KW  - asynchronous multisensor fusion
KW  - asynchronous-measurement alignment
KW  - graph nodes
KW  - out-of-sequence measurement alignment
KW  - multiple navigation sensors
KW  - modular sensor-fusion system
KW  - autonomous vehicles
KW  - 3D mapping
KW  - asynchronous sensors
KW  - multiple heterogeneous sensors
KW  - Sensors
KW  - Three-dimensional displays
KW  - Optimization
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Frequency measurement
KW  - Laser radar
DO  - 10.1109/ICRA.2018.8460204
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we address the problem of optimally fusing multiple heterogeneous and asynchronous sensors for use in 3D mapping and localization of autonomous vehicles. To this end, based on the factor graph-based optimization framework, we design a modular sensor-fusion system that allows for efficient and accurate incorporation of multiple navigation sensors operating at different sampling rates. In particular, we develop a general method of out-of-sequence (asynchronous) measurement alignment to incorporate heterogeneous sensors into a factor graph for mapping and localization in 3D, without requiring the addition of new graph nodes, thus allowing the graph to have an overall reduced complexity. The proposed sensor-fusion system is validated on a real-world experimental dataset, in which the asynchronous-measurement alignment is shown to have an improved performance when compared to a naive approach without alignment.
ER  - 

TY  - CONF
TI  - Localization Under Topological Uncertainty for Lane Identification of Autonomous Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6000
EP  - 6005
AU  - S. B. Nashed
AU  - D. M. Ilstrup
AU  - J. Biswas
PY  - 2018
KW  - hidden Markov models
KW  - mobile robots
KW  - position control
KW  - remotely operated vehicles
KW  - road traffic control
KW  - topology
KW  - VSM-HMM
KW  - topological uncertainty
KW  - lane membership
KW  - topological localization process
KW  - topological structure estimation
KW  - AV lane estimation
KW  - lane identification
KW  - autonomous vehicles
KW  - topological location
KW  - decision-making
KW  - public roads
KW  - variable structure multiple hidden Markov model
KW  - metric location
KW  - Earth mover distance
KW  - Hidden Markov models
KW  - Computational modeling
KW  - Topology
KW  - Roads
KW  - Uncertainty
KW  - Measurement
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2018.8461185
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous vehicles (AVs) require accurate metric and topological location estimates for safe, effective navigation and decision-making. Although many high-definition (HD) roadmaps exist, they are not always accurate since public roads are dynamic, shaped unpredictably by both human activity and nature. Thus, AVs must be able to handle situations in which the topology specified by the map does not agree with reality. We present the Variable Structure Multiple Hidden Markov Model (VSM-HMM) as a framework for localizing in the presence of topological uncertainty, and demonstrate its effectiveness on an AV where lane membership is modeled as a topological localization process. VSM-HMMs use a dynamic set of HMMs to simultaneously reason about location within a set of most likely current topologies and therefore may also be applied to topological structure estimation as well as AV lane estimation. In addition, we present an extension to the Earth Mover's Distance which allows uncertainty to be taken into account when computing the distance between belief distributions on simplices of arbitrary relative sizes.
ER  - 

TY  - CONF
TI  - Stabilizing Traffic with Autonomous Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6012
EP  - 6018
AU  - C. Wu
AU  - A. M. Bayen
AU  - A. Mehta
PY  - 2018
KW  - frequency-domain analysis
KW  - intelligent transportation systems
KW  - linear systems
KW  - mobile robots
KW  - nonlinear programming
KW  - optimal control
KW  - road safety
KW  - road traffic control
KW  - road vehicles
KW  - stability
KW  - autonomously controlled vehicles
KW  - autonomous vehicles
KW  - human-driven vehicles
KW  - traffic stabilization
KW  - safer roads
KW  - energy savings
KW  - single-lane system stabilization
KW  - linear string stability
KW  - optimality conditions
KW  - frequency-domain analysis
KW  - nonlinear optimization problem
KW  - safety constraint
KW  - optimal linear controller
KW  - traffic conditions
KW  - human driver behavior
KW  - Autonomous vehicles
KW  - Vehicle dynamics
KW  - Stability criteria
KW  - Optimization
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8460567
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous vehicles promise safer roads, energy savings, and more efficient use of existing infrastructure, among many other benefits. Although the effect of autonomous vehicles has been studied in the limits (near-zero or full penetration), the transition range requires new formulations, mathematical modeling, and control analysis. In this article, we study the ability of small numbers of autonomous vehicles to stabilize a single-lane system of human-driven vehicles. We formalize the problem in terms of linear string stability, derive optimality conditions from frequency-domain analysis, and pose the resulting nonlinear optimization problem. In particular, we introduce two conditions which simultaneously stabilize traffic while imposing a safety constraint on the autonomous vehicle and limiting degradation of performance. With this optimal linear controller in a system with typical human driver behavior, we can numerically determine that only a 6% uniform penetration of autonomously controlled vehicles (i.e. one per string of up to 16 human-driven vehicles) is necessary to stabilize traffic across all traffic conditions.
ER  - 

TY  - CONF
TI  - Data-Driven Model Predictive Control of Autonomous Mobility-on-Demand Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6019
EP  - 6025
AU  - R. Iglesias
AU  - F. Rossi
AU  - K. Wang
AU  - D. Hallac
AU  - J. Leskovec
AU  - M. Pavone
PY  - 2018
KW  - demand forecasting
KW  - intelligent transportation systems
KW  - predictive control
KW  - recurrent neural nets
KW  - road traffic control
KW  - end-to-end performance
KW  - customer demand
KW  - data-driven Model Predictive Control
KW  - LSTM neural network
KW  - travel demand
KW  - Autonomous Mobility-on-Demand systems control
KW  - DiDi Chuxing
KW  - MPC algorithm
KW  - transportation system
KW  - optimal rebalancing strategy
KW  - AMoD system
KW  - Prediction algorithms
KW  - Predictive control
KW  - Transportation
KW  - Pricing
KW  - Control systems
KW  - Steady-state
KW  - Real-time systems
DO  - 10.1109/ICRA.2018.8460966
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The goal of this paper is to present an end-to-end, data-driven framework to control Autonomous Mobility-on-Demand systems (AMoD, i.e. fleets of self-driving vehicles). We first model the AMoD system using a time-expanded network, and present a formulation that computes the optimal rebalancing strategy (i.e., preemptive repositioning) and the minimum feasible fleet size for a given travel demand. Then, we adapt this formulation to devise a Model Predictive Control (MPC) algorithm that leverages short-term demand forecasts based on historical data to compute rebalancing strategies. Using simulations based on real customer data from DiDi Chuxing, we test the end-to-end performance of this controller with a state-of-the-art LSTM neural network to predict customer demand: we show that this approach scales very well for large systems (indeed, the computational complexity of the MPC algorithm does not depend on the number of customers and of vehicles in the system) and outperforms state-of-the-art rebalancing strategies by reducing the mean customer wait time by up to to 89.6 %.
ER  - 

TY  - CONF
TI  - VALUE: Large Scale Voting-Based Automatic Labelling for Urban Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6033
EP  - 6038
AU  - G. Dabisias
AU  - E. Ruffaldi
AU  - H. Grimmett
AU  - P. Ondruska
PY  - 2018
KW  - distributed processing
KW  - image reconstruction
KW  - stereo image processing
KW  - traffic engineering computing
KW  - VALUE
KW  - automatic localisation
KW  - static 3D objects
KW  - New York City
KW  - urban environments
KW  - voting-based automatic labelling
KW  - distributed voting schema
KW  - traffic lights
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Urban areas
KW  - Cameras
KW  - Robustness
KW  - Noise measurement
KW  - Semantics
DO  - 10.1109/ICRA.2018.8460196
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a simple and robust method for the automatic localisation of static 3D objects in large-scale urban environments. By exploiting the potential to merge a large volume of noisy but accurately localised 2D image data, we achieve superior performance in terms of both robustness and accuracy of the recovered 3D information. The method is based on a simple distributed voting schema which can be fully distributed and parallelised to scale to large-scale scenarios. To evaluate the method we collected city-scale data sets from New York City and San Francisco consisting of almost 400k images spanning the area of 40 km2 and used it to accurately recover the 3D positions of traffic lights. We demonstrate a robust performance and also show that the solution improves in quality over time as the amount of data increases.
ER  - 

TY  - CONF
TI  - Automated Process for Incorporating Drivable Path into Real-Time Semantic Segmentation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6039
EP  - 6044
AU  - W. Zhou
AU  - S. Worrall
AU  - A. Zyner
AU  - E. Nebot
PY  - 2018
KW  - cameras
KW  - image segmentation
KW  - mobile robots
KW  - object detection
KW  - path planning
KW  - road traffic
KW  - road vehicles
KW  - robot vision
KW  - path prediction model
KW  - camera sensors
KW  - autonomous vehicle systems
KW  - vision systems
KW  - real-time semantic segmentation
KW  - intelligent vehicles
KW  - odometry
KW  - monocular camera
KW  - car-width drivable lane
KW  - path proposal category
KW  - intelligent vehicle system
KW  - drivable path information
KW  - human operation
KW  - clear lane markings
KW  - urban roads
KW  - Semantics
KW  - Cameras
KW  - Roads
KW  - Image segmentation
KW  - Sensors
KW  - Proposals
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460486
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Vision systems are widely used in autonomous vehicle systems due to the rich information that camera sensors provide of the surrounding environment. This paper presents an automatic algorithm to obtain the drivable path of a vehicle operating in urban roads with or without clear lane markings. The developed system projects trajectories obtained during human operation of the vehicle and utilizes these to generate automatic labels for training a semantic based path prediction model. The system segments an urban scenario into 13 categories including vehicles, pedestrian, undrivable road, other categories relevant to urban roads, and a new class for a path proposal. The drivable path information is essential particularly in unstructured scenarios, and is critical for an intelligent vehicle system to make sound driving decisions. The path proposal category is a car-width drivable lane estimated to be safe to drive for the vehicle under consideration. The data collection, model training and inference process requires only images from a monocular camera and odometry from a low-cost IMU combined with a wheel encoder. The algorithm has been successfully demonstrated on the Sydney University campus, which is a challenging environment without clear road markings. The algorithm was demonstrated to run in real-time, proving its applicability for intelligent vehicles.
ER  - 

TY  - CONF
TI  - Precise Ego-Motion Estimation with Millimeter-Wave Radar Under Diverse and Challenging Conditions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6045
EP  - 6052
AU  - S. H. Cen
AU  - P. Newman
PY  - 2018
KW  - CW radar
KW  - distance measurement
KW  - feature extraction
KW  - FM radar
KW  - Global Positioning System
KW  - image matching
KW  - millimetre wave radar
KW  - motion estimation
KW  - precise ego-motion estimation
KW  - millimeter-wave radar
KW  - cameras
KW  - lidars
KW  - proprioceptive sensors
KW  - radars
KW  - long-range objects
KW  - mobile autonomous systems
KW  - frequency-modulated continuous-wave scanning radar
KW  - GPS/INS
KW  - radar odometry
KW  - Sensors
KW  - Feature extraction
KW  - Radar imaging
KW  - Azimuth
KW  - Motion estimation
KW  - Robustness
DO  - 10.1109/ICRA.2018.8460687
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In contrast to cameras, lidars, GPS, and proprioceptive sensors, radars are affordable and efficient systems that operate well under variable weather and lighting conditions, require no external infrastructure, and detect long-range objects. In this paper, we present a reliable and accurate radar-only motion estimation algorithm for mobile autonomous systems. Using a frequency-modulated continuous-wave (FMCW) scanning radar, we first extract landmarks with an algorithm that accounts for unwanted effects in radar returns. To estimate relative motion, we then perform scan matching by greedily adding point correspondences based on unary descriptors and pairwise compatibility scores. Our radar odometry results are robust under a variety of conditions, including those under which visual odometry and GPS/INS fail.
ER  - 

TY  - CONF
TI  - SeDAR - Semantic Detection and Ranging: Humans can Localise without LiDAR, can Robots?
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6053
EP  - 6060
AU  - O. Mendez
AU  - S. Hadfield
AU  - N. Pugeault
AU  - R. Bowden
PY  - 2018
KW  - feature extraction
KW  - image colour analysis
KW  - image matching
KW  - image representation
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - vision-based approaches
KW  - high level semantic cues
KW  - floorplan
KW  - global localisation approach
KW  - range measurements
KW  - robotic scan-matching algorithms
KW  - SeDAR
KW  - semantic detection and ranging
KW  - pose estimation
KW  - 2D geometry
KW  - 2D representation
KW  - discriminative landmarks
KW  - RGB images
KW  - Semantics
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Robustness
DO  - 10.1109/ICRA.2018.8461074
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - How does a person work out their location using a floorplan? It is probably safe to say that we do not explicitly measure depths to every visible surface and try to match them against different pose estimates in the floorplan. And yet, this is exactly how most robotic scan-matching algorithms operate. Similarly, we do not extrude the 2D geometry present in the floorplan into 3D and try to align it to the real-world. And yet, this is how most vision-based approaches localise. Humans do the exact opposite. Instead of depth, we use high level semantic cues. Instead of extruding the floorplan up into the third dimension, we collapse the 3D world into a 2D representation. Evidence of this is that many of the floorplans we use in everyday life are not accurate, opting instead for high levels of discriminative landmarks. In this work, we use this insight to present a global localisation approach that relies solely on the semantic labels present in the floorplan and extracted from RGB images. While our approach is able to use range measurements if available, we demonstrate that they are unnecessary as we can achieve results comparable to state-of-the-art without them.
ER  - 

TY  - CONF
TI  - Design of a Novel 3-DoF Leg with Series and Parallel Compliant Actuation for Energy Efficient Articulated Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6068
EP  - 6075
AU  - W. Roozing
AU  - Z. Ren
AU  - N. G. Tsagarakis
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - elasticity
KW  - legged locomotion
KW  - motion control
KW  - similar mass
KW  - mass distribution
KW  - biarticulated actuation configuration
KW  - mechanical design
KW  - actuation configuration principles
KW  - 3-DoF leg
KW  - parallel compliant actuation
KW  - series-elastic main actuators
KW  - leg design
KW  - energy efficient articulated robots
KW  - Legged locomotion
KW  - Actuators
KW  - Knee
KW  - Pulleys
KW  - Torque
KW  - Energy storage
DO  - 10.1109/ICRA.2018.8460493
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work presents the development of a 3-DoF leg with series and parallel compliant actuation. Series-elastic main actuators are combined with parallel high efficiency energy storage branches, to substantially improve energy efficiency. The leg design is semi-anthropomorphic, with similar mass and mass distribution to the human limb, and includes a biarticulated actuation configuration. The parallel branches are driven by secondary motors and their design parameters are optimised. The mechanical design of the prototype leg is presented, introducing details of the actuation configuration principles employed. Preliminary experimental data are presented, in which a baseline series-elastic-only configuration is compared with configurations with mono- and biarticulated parallel branches, respectively. The results effectively demonstrate the concept's potential, showing improvements of 53% and 60% in electrical power consumption while the leg is executing loaded cyclic motion profiles.
ER  - 

TY  - CONF
TI  - Design of a Serial-Parallel Hybrid Leg for a Humanoid Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6076
EP  - 6081
AU  - K. G. Gim
AU  - J. Kim
AU  - K. Yamane
PY  - 2018
KW  - end effectors
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - manipulator kinematics
KW  - medical robotics
KW  - motion control
KW  - position control
KW  - trajectory tracking
KW  - gait trajectory
KW  - bar-linkage mechanism
KW  - serial mechanism
KW  - twin 3 DOF serial chains
KW  - parallel mechanisms
KW  - serial mechanisms
KW  - 6 DOF leg mechanism
KW  - humanoid robot
KW  - serial-parallel Hybrid Leg
KW  - inverse kinematics
KW  - forward kinematics
KW  - conventional serial leg
KW  - commercial robot
KW  - kinematic specification
KW  - hardware prototype
KW  - knee pitch rotation
KW  - Legged locomotion
KW  - Kinematics
KW  - Couplings
KW  - Prototypes
KW  - Hip
KW  - Hardware
DO  - 10.1109/ICRA.2018.8460733
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a 6 DOF leg mechanism for a humanoid robot. The proposed Hybrid Leg is designed to combine serial and parallel mechanisms and consists of a pair of twin 3 DOF serial chains in parallel. A 5-bar-linkage mechanism is implemented to the serial mechanism to generate 2 DOF motion regarding hip and knee pitch rotation. The hardware prototype is designed by matching the kinematic specification of a commercial robot's leg to compare the proposed mechanism with a conventional serial leg. We derive the analytical expressions of its forward and inverse kinematics. End-effector workspaces are shown with plots and inverse dynamics analysis of Hybrid Leg and serial leg with a given walking gait trajectory is presented. Hardware experiment is conducted with a prototype to verify the simulated workspace and trajectory tracking performance.
ER  - 

TY  - CONF
TI  - Self-Engaging Spined Gripper with Dynamic Penetration and Release for Steep Jumps
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6082
EP  - 6089
AU  - J. S. Lee
AU  - M. Plecnik
AU  - J. Yang
AU  - R. S. Fearing
PY  - 2018
KW  - actuators
KW  - adhesion
KW  - aerospace robotics
KW  - bone
KW  - gait analysis
KW  - grippers
KW  - impact (mechanical)
KW  - legged locomotion
KW  - robot kinematics
KW  - substrates
KW  - dynamic penetration
KW  - steep jumps
KW  - high impact forces
KW  - low duty cycles
KW  - monopedal jumping robots
KW  - slipping foot
KW  - dynamic jumping robot
KW  - surface approach speed
KW  - cycle time
KW  - penetrable substrate
KW  - gripper mechanism
KW  - robot Salto
KW  - angled spines
KW  - penetrable inclines
KW  - holding angles
KW  - leg crouch-extension
KW  - actuators
KW  - static adhesion
KW  - ceiling
KW  - self engaging spined gripper
KW  - kinematics
KW  - Grippers
KW  - Pins
KW  - Robot kinematics
KW  - Legged locomotion
KW  - Couplings
KW  - Substrates
DO  - 10.1109/ICRA.2018.8460933
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Due to high impact forces and low duty cycles, monopedal jumping robots are particularly susceptible to failure from a slipping foot. Spines provide a solution to reduce slip, but there has been little research on how to effectively engage them into a surface with a dynamic jumping robot. Previous robots utilizing spines operate in different regimes of surface approach speed and cycle time. For a penetrable substrate, spines must be directed into the surface at suitable holding angles, then extracted before the foot leaves the ground. We accomplished this by designing a gripper mechanism for the robot Salto that pushes in angled spines along their length and is kinematically constrained to engage/disengage with leg crouch/extension. The resulting mechanism introduces no new actuators, enables jumping on penetrable inclines up to 60°, and enables static adhesion to hold 7.5 times the robot's weight from a ceiling.
ER  - 

TY  - CONF
TI  - Design, Modeling, and Analysis of Inductive Resonant Coupling Wireless Power Transfer for Micro Aerial Vehicles (MAVs)
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6104
EP  - 6109
AU  - G. M. Plaizier
AU  - E. Andersen
AU  - B. Truong
AU  - X. He
AU  - S. Roundy
AU  - K. K. Leang
PY  - 2018
KW  - battery powered vehicles
KW  - coils
KW  - inductive power transmission
KW  - WPT system
KW  - transmit coil
KW  - WPT circuit design
KW  - power-transfer model
KW  - two-coil system
KW  - WPT circuitry
KW  - wirelessly powered MAV
KW  - inductive resonant coupling
KW  - microaerial vehicle
KW  - power transfer system
KW  - Batteries
KW  - Magnetic resonance
KW  - Integrated circuit modeling
KW  - Geometry
KW  - Analytical models
KW  - Couplings
KW  - Wireless power transfer
DO  - 10.1109/ICRA.2018.8461162
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the design, modeling, analysis, and experimental validation of an inductive resonant wireless power transfer (WPT) system to power a micro aerial vehicle (MAV). Using WPT, in general, enables longer flight times, virtually eliminates the need for batteries, and minimizes down time for recharging or replacing batteries. The proposed WPT system consists of a transmit coil, which can either be fixed to ground or placed on a mobile platform, and a receive coil carried by the MAV. The details of the WPT circuit design are presented. A power-transfer model is developed for the two-coil system, where the model is used to select suitable coil geometries to maximize the power received by the MAV for hovering. Analysis, simulation, and experimental results are presented to demonstrate the effectiveness of the WPT circuitry. Finally, a wirelessly powered MAV that hovers above the transmit coil is demonstrated in a laboratory setting.
ER  - 

TY  - CONF
TI  - Simplified Quasi-Steady Aeromechanic Model for Flapping-Wing Robots with Passively Rotating Hinges
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6110
EP  - 6115
AU  - Z. Li
AU  - S. Suntharasantic
AU  - P. Chirarattananon
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - approximation theory
KW  - bending strength
KW  - drag
KW  - hinges
KW  - Navier-Stokes equations
KW  - robot kinematics
KW  - torque
KW  - model predictions
KW  - flapping-wing robots
KW  - flexural passive wing hinges
KW  - aerodynamic forces
KW  - balanced torque
KW  - quasisteady aeromechanic model
KW  - rotating hinge
KW  - mechanical complexity
KW  - drag
KW  - stroke-averaged forces
KW  - Aerodynamics
KW  - Torque
KW  - Robots
KW  - Fasteners
KW  - Predictive models
KW  - Drag
KW  - Force
DO  - 10.1109/ICRA.2018.8461020
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - At millimeter and centimeter scales, flapping-wing robots often employ flexural passive wing hinges to eliminate extra actuation and mechanical complexity. In this paper, we propose a modified quasi-steady model for predicting aerodynamic forces from a flapping wing with a passively rotating hinge. The model is based on a simplifying assumption of balanced torque (aerodynamic torque equals to the restoring torque from the hinge). The resulting lift and drag can then be accurately predicted by the modified quasi-steady model without direct knowledge of the angle of attack of the wing. Approximate expression of stroke-averaged forces are also derived. We performed flapping experiments on a centimeter-scale device and the measured lifts show good agreement with the model predictions.
ER  - 

TY  - CONF
TI  - Surface Edge Explorer (see): Planning Next Best Views Directly from 3D Observations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6116
EP  - 6123
AU  - R. Border
AU  - J. D. Gammell
AU  - P. Newman
PY  - 2018
KW  - computational geometry
KW  - feature extraction
KW  - image reconstruction
KW  - mesh generation
KW  - solid modelling
KW  - Surface Edge Explorer
KW  - Best View planning
KW  - NBV planning approaches
KW  - voxel grids
KW  - triangulated meshes
KW  - surface geometry
KW  - high-resolution models
KW  - Surface representations
KW  - multiple survey stages
KW  - scene-model-free NBV planning approach
KW  - density representation
KW  - current measurements
KW  - observed surface boundaries
KW  - surface coverage
KW  - evaluated state-of-the-art volumetric approaches
KW  - Next Best views
KW  - time 3.0 d
KW  - Planning
KW  - Computational modeling
KW  - Density measurement
KW  - Geometry
KW  - Surface treatment
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8461098
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Surveying 3D scenes is a common task in robotics. Systems can do so autonomously by iteratively obtaining measurements. This process of planning observations to improve the model of a scene is called Next Best View (NBV) planning. NBV planning approaches often use either volumetric (e.g., voxel grids) or surface (e.g., triangulated meshes) representations. Volumetric approaches generalise well between scenes as they do not depend on surface geometry but do not scale to high-resolution models of large scenes. Surface representations can obtain high-resolution models at any scale but often require tuning of unintuitive parameters or multiple survey stages. This paper presents a scene-model-free NBV planning approach with a density representation. The Surface Edge Explorer (SEE) uses the density of current measurements to detect and explore observed surface boundaries. This approach is shown experimentally to provide better surface coverage in lower computation time than the evaluated state-of-the-art volumetric approaches while moving equivalent distances.
ER  - 

TY  - CONF
TI  - Active Image-Based Modeling with a Toy Drone
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6124
EP  - 6131
AU  - R. Huang
AU  - D. Zou
AU  - R. Vaughan
AU  - P. Tan
PY  - 2018
KW  - autonomous aerial vehicles
KW  - data acquisition
KW  - image reconstruction
KW  - image sensors
KW  - solid modelling
KW  - stereo image processing
KW  - iterative linear method
KW  - multiview stereo problem
KW  - online model reconstruction
KW  - toy unmanned aerial vehicle
KW  - data acquisition
KW  - toy drone
KW  - image-based modeling techniques
KW  - photo-realistic 3D models
KW  - multi-view stereo algorithm
KW  - active image-based modeling
KW  - Three-dimensional displays
KW  - Image reconstruction
KW  - Solid modeling
KW  - Unmanned aerial vehicles
KW  - Planning
KW  - Pipelines
KW  - Cameras
DO  - 10.1109/ICRA.2018.8460673
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Image-based modeling techniques [1]-[3] can now generate photo-realistic 3D models from images. But it is up to users to provide high quality images with good coverage and view overlap, which makes the data capturing process tedious and time consuming. We seek to automate data capturing for image-based modeling. The core of our system is an iterative linear method to solve the multi-view stereo (MVS) problem quickly and plan the Next-Best-View (NBV) effectively. Our fast MVS algorithm enables online model reconstruction and quality assessment to determine the NBVs on the fly. We test our system with a toy unmanned aerial vehicle (UAV) in simulated, indoor and outdoor experiments. Results show that our system improves the efficiency of data acquisition and ensures the completeness of the final model.
ER  - 

TY  - CONF
TI  - Fusing Object Context to Detect Functional Area for Cognitive Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6132
EP  - 6139
AU  - H. Cheng
AU  - J. Cai
AU  - Q. Liu
AU  - Z. Zhang
AU  - K. Yang
AU  - C. C. Loy
AU  - L. Lin
PY  - 2018
KW  - feature extraction
KW  - image classification
KW  - image fusion
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object context
KW  - deep learning
KW  - object detection dataset
KW  - current object detection framework
KW  - functional area detection
KW  - functionality-related feature
KW  - object-related
KW  - potential image regions
KW  - deep-model-based classifier
KW  - functional area image dataset
KW  - area detection problem
KW  - image recognition
KW  - cognitive robot
KW  - Feature extraction
KW  - Object detection
KW  - Robots
KW  - Task analysis
KW  - Machine learning
KW  - Proposals
KW  - Image recognition
DO  - 10.1109/ICRA.2018.8460590
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A cognitive robot usually needs to perform multiple tasks in practice and needs to locate the desired area for each task. Since deep learning has achieved substantial progress in image recognition, to solve this area detection problem, it is straightforward to label a functional area (affordance) image dataset and apply a well-trained deep-model-based classifier on all the potential image regions. However, annotating the functional area is time consuming and the requirement of large amount of training data limits the application scope. We observe that the functional area are usually related to the surrounding object context. In this work, we propose to use the existing object detection dataset and employ the object context as effective prior to improve the performance without additional annotated data. In particular, we formulate a two-stream network that fuses the object-related and functionality-related feature for functional area detection. The whole system is formulated in an end-to-end manner and easy to implement with current object detection framework. Experiments demonstrate that the proposed network outperforms current method by almost 20% in terms of precision and recall.
ER  - 

TY  - CONF
TI  - When Regression Meets Manifold Learning for Object Recognition and Pose Estimation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6140
EP  - 6146
AU  - M. Bui
AU  - S. Zakharov
AU  - S. Albarqouni
AU  - S. Ilic
AU  - N. Navab
PY  - 2018
KW  - convolution
KW  - feedforward neural nets
KW  - image matching
KW  - nearest neighbour methods
KW  - object recognition
KW  - pose estimation
KW  - regression analysis
KW  - manifold learning
KW  - pose regression
KW  - NN descriptor matching
KW  - manifold descriptor learning
KW  - multitask learning framework
KW  - nearest neighbor search
KW  - convolutional neural networks
KW  - pose estimation
KW  - object recognition
KW  - Pose estimation
KW  - Manifolds
KW  - Task analysis
KW  - Training
KW  - Robustness
KW  - Object recognition
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8460654
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we propose a method for object recognition and pose estimation from depth images using convolutional neural networks. Previous methods addressing this problem rely on manifold learning to learn low dimensional viewpoint descriptors and employ them in a nearest neighbor search on an estimated descriptor space. In comparison we create an efficient multi-task learning framework combining manifold descriptor learning and pose regression. By combining the strengths of manifold learning using triplet loss and pose regression, we could either estimate the pose directly reducing the complexity compared to NN search, or use the learned descriptor for the NN descriptor matching. By in depth experimental evaluation of the novel loss function we observed that the view descriptors learned by the network are much more discriminative resulting in almost 30% increase regarding relative pose accuracy compared to related works. On the other hand, regarding directly regressed poses we obtained important improvement compared to simple pose regression. By leveraging the advantages of both manifold learning and regression tasks, we are able to improve the current state-of-the-art for object recognition and pose retrieval.
ER  - 

TY  - CONF
TI  - Ultra-Fast Multi-Scale Shape Estimation of Light Transport Matrix for Complex Light Reflection Objects
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6147
EP  - 6152
AU  - N. Chiba
AU  - K. Hashimoto
PY  - 2018
KW  - cameras
KW  - image reconstruction
KW  - image resolution
KW  - light reflection
KW  - optical projectors
KW  - shape measurement
KW  - sparse matrices
KW  - multiple light paths
KW  - complex light reflection objects
KW  - Light Transport Matrix estimation
KW  - LT Matrix estimation
KW  - high resolution measurement
KW  - sparse matrix representation
KW  - ultra-fast multiscale shape estimation
KW  - target objects
KW  - specular reflection
KW  - light path
KW  - memory efficiency
KW  - 256 × 256 resolution projector
KW  - camera system
KW  - 3D measurement methods
KW  - Cameras
KW  - Three-dimensional displays
KW  - Estimation
KW  - Sparse matrices
KW  - Shape
KW  - Shape measurement
KW  - Sensors
DO  - 10.1109/ICRA.2018.8460892
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - 3D measurement of target objects characterized by specular reflection or subsurface scatterings cannot be measured by traditional 3D measurement methods because these targets have multiple light paths that make it difficult to determine the unique surface. We define these objects as complex light reflection objects. In this case, 3D measurement methods based on Light Transport (LT) Matrix estimation may be a solution to measure these complex light reflection objects, because LT Matrix captures every light path, and we can identify all 3D points on the target shape by using LT Matrix. However, these methods either provide low resolution results, or they are too slow for use in robot vision in practice. In this paper, we suppress the computational cost of LT Matrix estimation by dividing LT Matrix estimation into multi-scale. The proposed method reduces the number of candidate combinations between camera pixels and projector pixels greatly by using the information given by low resolution observations. The proposed algorithm allows high resolution measurement of the LT Matrix very efficiently. Furthermore, careful implementation of our method by using a sparse matrix representation achieves memory efficiency. We evaluated our method by measuring 3D points for a 256 × 256 resolution projector and camera system, which is an LT matrix 4096 times larger than that developed in our previous study [1] and 100 times faster than our naïve implementation of [2].
ER  - 

TY  - CONF
TI  - A Deep Learning-Based Stalk Grasping Pipeline
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6161
EP  - 6167
AU  - T. Parhar
AU  - H. Baweja
AU  - M. Jenkins
AU  - G. Kantor
PY  - 2018
KW  - crops
KW  - image segmentation
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - stalk segmentation
KW  - grasp point generation pipeline
KW  - high stalk density
KW  - lighting variation
KW  - custom-built ground robot
KW  - end-to-end system
KW  - average grasping accuracy
KW  - Generative Adversarial Network
KW  - in-situ sorghum stalk detection
KW  - online pipeline
KW  - deep learning-based high throughput
KW  - labor-intensive phenotyping processes
KW  - robotic solutions
KW  - plant attributes
KW  - precise measurements
KW  - fast measurements
KW  - deep learning-based stalk grasping pipeline
KW  - pixel-wise stalk detection
KW  - grasp point detection
KW  - stalk detection F1 score
KW  - Robots
KW  - Pipelines
KW  - Image segmentation
KW  - Generators
KW  - Three-dimensional displays
KW  - Gallium nitride
KW  - Cameras
DO  - 10.1109/ICRA.2018.8460597
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The need for fast and precise measurements of plant attributes makes robotic solutions an ideal replacement for labor-intensive phenotyping processes. In this work we present a deep learning-based high throughput, online pipeline for in-situ sorghum stalk detection and grasping. We use a variation of Generative Adversarial Network (GAN) for stalk segmentation trained on a relatively small number of images followed by a grasp point generation pipeline. The presented pipeline is robust to field challenges such as occlusions, high stalk density and lighting variation, and was deployed on a custom-built ground robot. We tested our end-to-end system in a field of Sorghum bicolor in South Carolina, USA, achieving an average grasping accuracy of 74.13% and a stalk detection F1 score of 0.90. Grasp point detection for plant manipulation takes an average of 0.98 seconds, and pixel-wise stalk detection takes 0.2 seconds per image.
ER  - 

TY  - CONF
TI  - Configuration of Perception Systems via Planning Over Factor Graphs
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6168
EP  - 6174
AU  - V. Dietrich
AU  - B. Kast
AU  - P. Schmitt
AU  - S. Albrecht
AU  - M. Fiegert
AU  - W. Feiten
AU  - M. Beetz
PY  - 2018
KW  - assembling
KW  - graph theory
KW  - planning (artificial intelligence)
KW  - production engineering computing
KW  - sensor fusion
KW  - sensors
KW  - perception systems
KW  - factor graph
KW  - automated systems
KW  - data processing algorithms
KW  - sensor noise
KW  - calibration errors
KW  - planning problem
KW  - probabilistic graphical models
KW  - configuration space
KW  - perceptions systems
KW  - perception steps
KW  - sensor data fusion
KW  - industrial assembly
KW  - Task analysis
KW  - Planning
KW  - Robot sensing systems
KW  - Uncertainty
KW  - Semantics
KW  - Cameras
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2018.8460955
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Sensor guided, automated systems require the composition of various sensors and data processing algorithms to obtain relevant information for performing their task. Many applications have additional requirements such as a certain accuracy, which has to be achieved despite sensor noise and calibration errors. In this paper we model the configuration of perception systems as a planning problem over probabilistic graphical models. We work on a subset of the full configuration space of perceptions systems, specifically the used sensors, data processing algorithms and view poses. Based on a semantic description of the goal, available sensors and data processing algorithms, our system plans perception steps and sensor data fusion autonomously. The planner operates by constructing a factor graph until the accuracy requirements of tasks are fulfilled or unobtainable with the available action set. We validate our approach in an industrial assembly scenario.
ER  - 

TY  - CONF
TI  - Intelligent Shipwreck Search Using Autonomous Underwater Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6175
EP  - 6182
AU  - J. Rutledge
AU  - W. Yuan
AU  - J. Wu
AU  - S. Freed
AU  - A. Lewis
AU  - Z. Wood
AU  - T. Gambin
AU  - C. Clark
PY  - 2018
KW  - archaeology
KW  - autonomous underwater vehicles
KW  - control engineering computing
KW  - image processing
KW  - intelligent control
KW  - marine control
KW  - mobile robots
KW  - path planning
KW  - sonar
KW  - archaeological survey
KW  - intelligent shipwreck search
KW  - autonomous underwater vehicles
KW  - autonomous robot system
KW  - multistep pipeline
KW  - high altitude scan
KW  - low-resolution side scan sonar data
KW  - image processing software
KW  - AUV path planner
KW  - archaeological sites
KW  - underwater archaeological sites
KW  - ranking algorithm
KW  - Sonar
KW  - Proposals
KW  - Clustering algorithms
KW  - Pipelines
KW  - Feature extraction
KW  - Software
DO  - 10.1109/ICRA.2018.8460548
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents an autonomous robot system that is designed to autonomously search for and geo-localize potential underwater archaeological sites. The system, based on Autonomous Underwater Vehicles, invokes a multi-step pipeline. First, the AUV constructs a high altitude scan over a large area to collect low-resolution side scan sonar data. Second, image processing software is employed to automatically detect and identify potential sites of interest. Third, a ranking algorithm assigns importance scores to each site. Fourth, an AUV path planner is used to plan a time-limited path that visits sites with a high importance at a low altitude to acquire high-resolution sonar data. Last, the AUV is deployed to follow this path. This system was implemented and evaluated during an archaeological survey located along the coast of Malta. These experiments demonstrated that the system is able to identify valuable archaeological sites accurately and efficiently in a large previously unsurveyed area. Also, the planned missions led to the discovery of a historical plane wreck whose location was previously unknown.
ER  - 

TY  - CONF
TI  - A Robust Model Predictive Control Approach for Autonomous Underwater Vehicles Operating in a Constrained Workspace
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6183
EP  - 6188
AU  - S. Heshmati-alamdari
AU  - G. C. Karras
AU  - P. Marantos
AU  - K. J. Kyriakopoulos
PY  - 2018
KW  - autonomous underwater vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - nonlinear control systems
KW  - predictive control
KW  - robust control
KW  - robust Model Predictive Control approach
KW  - constrained workspace
KW  - underwater robotic vehicles
KW  - static obstacles
KW  - workspace boundary
KW  - thruster saturation
KW  - vehicle velocity
KW  - control design
KW  - ocean currents
KW  - control inputs
KW  - way-point tracking mission
KW  - control strategy
KW  - constrained test tank
KW  - Nonlinear Model Predictive Control scheme
KW  - way points
KW  - underwater robotic vehicle
KW  - Oceans
KW  - Robots
KW  - Underwater vehicles
KW  - Mathematical model
KW  - Vehicle dynamics
KW  - Energy consumption
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460918
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel Nonlinear Model Predictive Control (NMPC) scheme for underwater robotic vehicles operating in a constrained workspace including static obstacles. The purpose of the controller is to guide the vehicle towards specific way points. Various limitations such as: obstacles, workspace boundary, thruster saturation and predefined desired upper bound of the vehicle velocity are captured as state and input constraints and are guaranteed during the control design. The proposed scheme incorporates the full dynamics of the vehicle in which the ocean currents are also involved. Hence, the control inputs calculated by the proposed scheme are formulated in a way that the vehicle will exploit the ocean currents, when these are in favor of the way-point tracking mission which results in reduced energy consumption by the thrusters. The performance of the proposed control strategy is experimentally verified using a 4 Degrees of Freedom (DoF) underwater robotic vehicle inside a constrained test tank with obstacles.
ER  - 

TY  - CONF
TI  - Design, Modeling, and Nonlinear Model Predictive Tracking Control of a Novel Autonomous Surface Vehicle
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6189
EP  - 6196
AU  - W. Wang
AU  - L. A. Mateos
AU  - S. Park
AU  - P. Leoni
AU  - B. Gheneti
AU  - F. Duarte
AU  - C. Ratti
AU  - D. Rus
PY  - 2018
KW  - autonomous underwater vehicles
KW  - boats
KW  - Global Positioning System
KW  - hydrodynamics
KW  - indoor environment
KW  - matrix algebra
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - predictive control
KW  - tracking
KW  - trajectory control
KW  - nonlinear model predictive tracking control
KW  - autonomous surface vehicle
KW  - autonomous robotic boat
KW  - indoor environments
KW  - outdoor environments
KW  - cross type four-thruster configuration
KW  - robot prototype
KW  - nonlinear dynamic model
KW  - NMPC algorithm
KW  - surface swarm robotics testbeds
KW  - trajectory tracking
KW  - holonomic motions
KW  - fiberglass
KW  - centripetal matrix
KW  - Coriolis
KW  - hydrodynamic
KW  - damping
KW  - GPS modules
KW  - inertial measurement unit
KW  - IMU
KW  - swimming pool
KW  - natural river
KW  - code generation strategy
KW  - Boats
KW  - Vehicle dynamics
KW  - Symmetric matrices
KW  - Global Positioning System
KW  - Heuristic algorithms
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8460632
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present the design, modeling, and real-time nonlinear model predictive control (NMPC) of an autonomous robotic boat. The robot is easy to manufacture, highly maneuverable, and capable of accurate trajectory tracking in both indoor and outdoor environments. In particular, a cross type four-thruster configuration is proposed for the robotic boat to produce efficient holonomic motions. The robot prototype is rapidly 3D-printed and then sealed by adhering several layers of fiberglass. To achieve accurate tracking control, we formulate an NMPC strategy for the four-control-input boat with control input constraints, where the nonlinear dynamic model includes a Coriolis and centripetal matrix, the hydrodynamic added mass, and damping. By integrating “GPS” modules and an inertial measurement unit (IMU) into the robot, we demonstrate accurate trajectory tracking of the robotic boat along preplanned paths in both a swimming pool and a natural river. Furthermore, the code generation strategy employed in our paper yields a two order of magnitude improvement in the run time of the NMPC algorithm compared to similar systems. The robot is designed to form the basis for surface swarm robotics testbeds, on which collective algorithms for surface transportation and self-assembly of dynamic floating infrastructures can be assessed.
ER  - 

TY  - CONF
TI  - Reinforcement Learning of Depth Stabilization with a Micro Diving Agent
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6197
EP  - 6203
AU  - G. Brinkmann
AU  - W. M. Bessa
AU  - D. Duecker
AU  - E. Kreuzer
AU  - E. Solowjow
PY  - 2018
KW  - embedded systems
KW  - learning (artificial intelligence)
KW  - microrobots
KW  - multi-agent systems
KW  - robot programming
KW  - underwater vehicles
KW  - model-based value-function RL algorithm
KW  - micro underwater agents
KW  - underwater robotics
KW  - underwater depth stabilization
KW  - light embedded systems
KW  - control tasks
KW  - microdiving agent
KW  - reinforcement learning
KW  - Computational modeling
KW  - Learning (artificial intelligence)
KW  - Task analysis
KW  - Robot kinematics
KW  - Heuristic algorithms
KW  - Force
DO  - 10.1109/ICRA.2018.8461137
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Reinforcement learning (RL) allows robots to solve control tasks through interaction with their environment. In this paper we study a model-based value-function RL approach, which is suitable for computationally limited robots and light embedded systems. We develop a diving agent, which uses the RL algorithm for underwater depth stabilization. Simulations and experiments with the micro diving agent demonstrate its ability to learn the depth stabilization task.
ER  - 

TY  - CONF
TI  - Real-Time Underwater 3D Reconstruction Using Global Context and Active Labeling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6204
EP  - 6211
AU  - R. DeBortoli
AU  - A. Nicolai
AU  - F. Li
AU  - G. A. Hollinger
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - feedforward neural nets
KW  - image classification
KW  - image reconstruction
KW  - image resolution
KW  - image sensors
KW  - sonar imaging
KW  - underwater vehicles
KW  - underwater environments
KW  - sonar images
KW  - low-resolution imagery
KW  - standard cameras
KW  - automatic feature extractors
KW  - sonar imagery
KW  - environment reconstructions
KW  - high data capture rates
KW  - standard imaging sonars
KW  - high-quality frames
KW  - feature annotation
KW  - real-time reconstruction capability
KW  - underwater vehicle
KW  - time underwater 3D reconstruction
KW  - real-time 3D reconstruction
KW  - convolutional neural network
KW  - Image reconstruction
KW  - Feature extraction
KW  - Real-time systems
KW  - Three-dimensional displays
KW  - Imaging
KW  - Sonar measurements
DO  - 10.1109/ICRA.2018.8461148
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work we develop a novel framework that enables the real-time 3D reconstruction of underwater environments using features from 2D sonar images. Due to noisy and low-resolution imagery as compared with standard cameras, automatic feature extractors for sonar images are not reliable in many scenarios. Thus, a human often needs to hand-select features in sonar imagery for environment reconstructions. Given the high data capture rates of standard imaging sonars (on the order of 20Hz), hand-annotating the features in every frame cannot be done in real-time. To address this we use a Convolutional Neural Network (CNN) that analyzes incoming imagery in real-time and proposes only a small subset of high-quality frames to the user for feature annotation. We demonstrate that our approach provides real-time reconstruction capability without loss in classification performance on datasets captured onboard our underwater vehicle while operating in a variety of environments.
ER  - 

TY  - CONF
TI  - Dynamic Reconfiguration of Mission Parameters in Underwater Human-Robot Collaboration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6212
EP  - 6219
AU  - M. J. Islam
AU  - M. Ho
AU  - J. Sattar
PY  - 2018
KW  - feedforward neural nets
KW  - finite state machines
KW  - gesture recognition
KW  - human-robot interaction
KW  - mobile robots
KW  - hand gestures
KW  - hand gesture recognition
KW  - gesture-to-instruction mapping
KW  - finite-state machine
KW  - convolutional neural network
KW  - human-robot collaborative tasks
KW  - autonomous underwater robots
KW  - parameter reconfiguration method
KW  - real-time programming
KW  - underwater human-robot collaboration
KW  - mission parameters
KW  - dynamic reconfiguration
KW  - Robustness
KW  - Task analysis
KW  - Visualization
KW  - Robot sensing systems
KW  - Unmanned underwater vehicles
KW  - Gesture recognition
DO  - 10.1109/ICRA.2018.8461197
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a real-time programming and parameter reconfiguration method for autonomous underwater robots in human-robot collaborative tasks. Using a set of intuitive and meaningful hand gestures, we develop a syntactically simple framework that is computationally more efficient than a complex, grammar-based approach. In the proposed framework, a convolutional neural network is trained to provide accurate hand gesture recognition; subsequently, a finite-state machine- based deterministic model performs efficient gesture-to-instruction mapping and further improves robustness of the interaction scheme. The key aspect of this framework is that it can be easily adopted by divers for communicating simple instructions to underwater robots without using artificial tags such as fiducial markers or requiring memorization of a potentially complex set of language rules. Extensive experiments are performed both on field-trial data and through simulation, which demonstrate the robustness, efficiency, and portability of this framework in a number of different scenarios. Finally, a user interaction study is presented that illustrates the gain in the ease of use of our proposed interaction framework compared to the existing methods for the underwater domain.
ER  - 

TY  - CONF
TI  - Gaussian Process Adaptive Sampling Using the Cross-Entropy Method for Environmental Sensing and Monitoring
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6220
EP  - 6227
AU  - Y. T. Tan
AU  - A. Kunapareddy
AU  - M. Kobilarov
PY  - 2018
KW  - bathymetry
KW  - entropy
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - sampling methods
KW  - single ROI
KW  - deepest region
KW  - coastal bathymetry mapping mission validate
KW  - efficient sampling strategy
KW  - latest sensory measurements
KW  - sampling density
KW  - CE trajectory optimization
KW  - higher spatial variability
KW  - exhibit extreme sensory measurements
KW  - exploring learning
KW  - initial stage
KW  - path planning
KW  - GP-UCB
KW  - GP upper confidence
KW  - receding-horizon Cross-Entropy trajectory optimization
KW  - environmental sensing
KW  - cross-entropy method
KW  - Gaussian process adaptive sampling
KW  - Robot sensing systems
KW  - Adaptation models
KW  - Optimization
KW  - Predictive models
KW  - Trajectory
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8460821
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we focus on adaptive sampling on a Gaussian Processes (GP) using the receding-horizon Cross-Entropy (CE) trajectory optimization. Specifically, we employ the GP upper confidence bound (GP-UCB) as the optimization criteria to adaptively plan sampling paths that balance the exploitation-exploration trade-off. Path planning at the initial stage focuses on exploring and learning a model of the environment, and later, on exploiting the learned model to focus sampling around regions that exhibit extreme sensory measurements and much higher spatial variability, denoted as the Region of Interest (ROI). The integration of the CE trajectory optimization allows the sampling density to be dynamically adjusted based on the latest sensory measurements, thus providing an efficient sampling strategy for sensing and localizing the ROI. We demonstrate the effectiveness of the proposed method in exploring simulated scalar fields with single or multiple ROIs. Field experiments with an Unmanned Surface Vehicle (USV) in a coastal bathymetry mapping mission validate the approach's capability in quickly exploring and mapping the given area, and then focusing and increasing the sampling density around the deepest region, as a surrogate for e.g. the extremal concentration of a pollutant in the environment.
ER  - 

TY  - CONF
TI  - OptLayer - Practical Constrained Optimization for Deep Reinforcement Learning in the Real World
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6236
EP  - 6243
AU  - T. Pham
AU  - G. De Magistris
AU  - R. Tachibana
PY  - 2018
KW  - control engineering computing
KW  - decision making
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - optimisation
KW  - decision-making problems
KW  - reinforcement learning architecture
KW  - OptLayer
KW  - neural network
KW  - closest actions
KW  - safe actions
KW  - robot reaching tasks
KW  - practical constrained optimization
KW  - deep reinforcement learning techniques
KW  - Robot kinematics
KW  - Neural networks
KW  - Task analysis
KW  - Optimization
KW  - Learning (artificial intelligence)
KW  - Training
DO  - 10.1109/ICRA.2018.8460547
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - While deep reinforcement learning techniques have recently produced considerable achievements on many decision-making problems, their use in robotics has largely been limited to simulated worlds or restricted motions, since unconstrained trial-and-error interactions in the real world can have undesirable consequences for the robot or its environment. To overcome such limitations, we propose a novel reinforcement learning architecture, OptLayer, that takes as inputs possibly unsafe actions predicted by a neural network and outputs the closest actions that satisfy chosen constraints. While learning control policies often requires carefully crafted rewards and penalties while exploring the range of possible actions, OptLayer ensures that only safe actions are actually executed and unsafe predictions are penalized during training. We demonstrate the effectiveness of our approach on robot reaching tasks, both simulated and in the real world.
ER  - 

TY  - CONF
TI  - Composable Deep Reinforcement Learning for Robotic Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6244
EP  - 6251
AU  - T. Haarnoja
AU  - V. Pong
AU  - A. Zhou
AU  - M. Dalal
AU  - P. Abbeel
AU  - S. Levine
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - composable deep reinforcement
KW  - model-free deep reinforcement learning
KW  - simulated robotic manipulation
KW  - model-free methods
KW  - real-world robotic tasks
KW  - maximum entropy policies
KW  - soft Q-learning
KW  - real-world robotic manipulation
KW  - Entropy
KW  - Robots
KW  - Learning (artificial intelligence)
KW  - Neural networks
KW  - Machine learning
KW  - Task analysis
KW  - Training
DO  - 10.1109/ICRA.2018.8460756
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Model-free deep reinforcement learning has been shown to exhibit good performance in domains ranging from video games to simulated robotic manipulation and locomotion. However, model-free methods are known to perform poorly when the interaction time with the environment is limited, as is the case for most real-world robotic tasks. In this paper, we study how maximum entropy policies trained using soft Q-learning can be applied to real-world robotic manipulation. The application of this method to real-world manipulation is facilitated by two important features of soft Q-learning. First, soft Q-learning can learn multimodal exploration strategies by learning policies represented by expressive energy-based models. Second, we show that policies learned with soft Q-learning can be composed to create new policies, and that the optimality of the resulting policy can be bounded in terms of the divergence between the composed policies. This compositionality provides an especially valuable tool for real-world manipulation, where constructing new policies by composing existing skills can provide a large gain in efficiency over training from scratch. Our experimental evaluation demonstrates that soft Q-learning is substantially more sample efficient than prior model-free deep reinforcement learning methods, and that compositionality can be performed for both simulated and real-world tasks.
ER  - 

TY  - CONF
TI  - Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6252
EP  - 6259
AU  - P. Long
AU  - T. Fan
AU  - X. Liao
AU  - W. Liu
AU  - H. Zhang
AU  - J. Pan
PY  - 2018
KW  - collision avoidance
KW  - decentralised control
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - multiscenario multistage training framework
KW  - optimal policy
KW  - policy gradient
KW  - reinforcement learning algorithm
KW  - learned sensor-level collision avoidance policy
KW  - final learned policy
KW  - collision-free paths
KW  - large-scale robot system
KW  - deep reinforcement learning
KW  - safe collision avoidance policy
KW  - efficient collision avoidance policy
KW  - optimally decentralized multirobot collision avoidance
KW  - agent-level feature extraction
KW  - decentralized methods
KW  - maps raw sensor measurements
KW  - multirobot systems
KW  - decentralized sensor-level collision avoidance policy
KW  - local collision-free action
KW  - distributed multirobot collision avoidance systems
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Navigation
KW  - Robustness
KW  - Training
DO  - 10.1109/ICRA.2018.8461113
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Developing a safe and efficient collision avoidance policy for multiple robots is challenging in the decentralized scenarios where each robot generates its paths without observing other robots' states and intents. While other distributed multi-robot collision avoidance systems exist, they often require extracting agent-level features to plan a local collision-free action, which can be computationally prohibitive and not robust. More importantly, in practice the performance of these methods are much lower than their centralized counterparts. We present a decentralized sensor-level collision avoidance policy for multi-robot systems, which directly maps raw sensor measurements to an agent's steering commands in terms of movement velocity. As a first step toward reducing the performance gap between decentralized and centralized methods, we present a multi-scenario multi-stage training framework to learn an optimal policy. The policy is trained over a large number of robots on rich, complex environments simultaneously using a policy gradient based reinforcement learning algorithm. We validate the learned sensor-level collision avoidance policy in a variety of simulated scenarios with thorough performance evaluations and show that the final learned policy is able to find time efficient, collision-free paths for a large-scale robot system. We also demonstrate that the learned policy can be well generalized to new scenarios that do not appear in the entire training period, including navigating a heterogeneous group of robots and a large-scale scenario with 100 robots. Videos are available at https://sites.google.com/view/drlmaca.
ER  - 

TY  - CONF
TI  - Tensegrity Robot Locomotion Under Limited Sensory Inputs via Deep Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6260
EP  - 6267
AU  - J. Luo
AU  - R. Edmunds
AU  - F. Rice
AU  - A. M. Agogino
PY  - 2018
KW  - learning systems
KW  - mobile robots
KW  - motion control
KW  - neurocontrollers
KW  - nonlinear dynamical systems
KW  - search problems
KW  - state-space methods
KW  - nonlinear dynamics
KW  - high-dimensional state space
KW  - robotic systems
KW  - space exploration
KW  - tensegrity robot locomotion
KW  - deep reinforcement learning algorithms
KW  - policy learning process
KW  - locomotion control policies
KW  - neural network policies
KW  - mirror descent guided policy search
KW  - end-to-end locomotion policies
KW  - tensegrity robotics
KW  - Robot sensing systems
KW  - Neural networks
KW  - Aerospace electronics
KW  - Hardware
KW  - NASA
KW  - Training
DO  - 10.1109/ICRA.2018.8463144
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Tensegrity robots are composed of rigid rods connected by elastic cables, and their unique light-weight yet compliant structure makes them an appealing choice for space exploration. However, locomotion control for these robotic systems remains difficult due to their nonlinear dynamics and high-dimensional state space. We demonstrate that in the domain of tensegrity robotics, it is possible to efficiently learn end-to-end locomotion policies using mirror descent guided policy search (MDGPS) even with limited sensory inputs. We compare learned neural network policies with other locomotion control policies in various testing environments; and results show that neural network policies consistently outperform others. We also shed light to the policy learning process by analyzing different choices of observation inputs to the robot. Moreover these findings motivate exploration of deep reinforcement learning algorithms in the domain of tensegrity robotics. We show preliminary results with one such locomotion example on discontinuous rough terrains.
ER  - 

TY  - CONF
TI  - Applying Asynchronous Deep Classification Networks and Gaming Reinforcement Learning-Based Motion Planners to Mobile Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6268
EP  - 6275
AU  - G. Ryou
AU  - Y. Sim
AU  - S. H. Yeon
AU  - S. Seok
PY  - 2018
KW  - control engineering computing
KW  - game theory
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - path planning
KW  - pattern classification
KW  - gaming reinforcement learning-based motion planner
KW  - mobile robotic platform
KW  - deep classifier
KW  - asynchronous deep classification network
KW  - visual recognition
KW  - motion planning
KW  - deep learning-based algorithms
KW  - TT2-bot
KW  - embedded neural networks
KW  - Mobile robots
KW  - Learning (artificial intelligence)
KW  - Machine learning
KW  - Neural networks
KW  - Sensors
KW  - Training
DO  - 10.1109/ICRA.2018.8460798
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we propose a new methodology to embed deep learning-based algorithms in both visual recognition and motion planning for general mobile robotic platforms. A framework for an asynchronous deep classification network is introduced to integrate heavy deep classification networks into a mobile robot with no loss of system bandwidth. Moreover, a gaming reinforcement learning-based motion planner, a novel and convenient embodiment of reinforcement learning, is introduced for simple implementation and high applicability. The proposed approaches are implemented and evaluated on a developed robot, TT2-bot. The evaluation was based on a mission devised for a qualitative evaluation of the general purposes and performances of a mobile robotic platform. The robot was required to recognize targets with a deep classifier and plan the path effectively using a deep motion planner. As a result, the robot verified that the proposed approaches successfully integrate deep learning technologies on the stand-alone mobile robot. The embedded neural networks for recognition and path planning were critical components for the robot.
ER  - 

TY  - CONF
TI  - Learning with Training Wheels: Speeding up Training with a Simple Controller for Deep Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6276
EP  - 6283
AU  - L. Xie
AU  - S. Wang
AU  - S. Rosa
AU  - A. Markham
AU  - N. Trigoni
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - three-term control
KW  - DRL network
KW  - standard Deep Deterministic Policy Gradient network
KW  - training wheels
KW  - deep reinforcement learning
KW  - robotic applications
KW  - robot applications
KW  - Assisted Reinforcement Learning
KW  - PID controller
KW  - local planning
KW  - navigation problems
KW  - simple control law
KW  - Training
KW  - Navigation
KW  - Acceleration
KW  - Robot kinematics
KW  - Machine learning
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461203
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Deep Reinforcement Learning (DRL) has been applied successfully to many robotic applications. However, the large number of trials needed for training is a key issue. Most of existing techniques developed to improve training efficiency (e.g. imitation) target on general tasks rather than being tailored for robot applications, which have their specific context to benefit from. We propose a novel framework, Assisted Reinforcement Learning, where a classical controller (e.g. a PID controller) is used as an alternative, switchable policy to speed up training of DRL for local planning and navigation problems. The core idea is that the simple control law allows the robot to rapidly learn sensible primitives, like driving in a straight line, instead of random exploration. As the actor network becomes more advanced, it can then take over to perform more complex actions, like obstacle avoidance. Eventually, the simple controller can be discarded entirely. We show that not only does this technique train faster, it also is less sensitive to the structure of the DRL network and consistently outperforms a standard Deep Deterministic Policy Gradient network. We demonstrate the results in both simulation and real-world experiments.
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning for Vision-Based Robotic Grasping: A Simulated Comparative Evaluation of Off-Policy Methods
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6284
EP  - 6291
AU  - D. Quillen
AU  - E. Jang
AU  - O. Nachum
AU  - C. Finn
AU  - J. Ibarz
AU  - S. Levine
PY  - 2018
KW  - learning (artificial intelligence)
KW  - Monte Carlo methods
KW  - neural nets
KW  - robot vision
KW  - deep neural network models
KW  - off-policy correction
KW  - vision-based robotic grasping
KW  - off-policy methods
KW  - deep reinforcement learning algorithms
KW  - off-policy learning
KW  - Monte Carlo methods
KW  - Grasping
KW  - Robots
KW  - Task analysis
KW  - Benchmark testing
KW  - Monte Carlo methods
KW  - Machine learning
KW  - Training
DO  - 10.1109/ICRA.2018.8461039
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we explore deep reinforcement learning algorithms for vision-based robotic grasping. Model-free deep reinforcement learning (RL) has been successfully applied to a range of challenging environments, but the proliferation of algorithms makes it difficult to discern which particular approach would be best suited for a rich, diverse task like grasping. To answer this question, we propose a simulated benchmark for robotic grasping that emphasizes off-policy learning and generalization to unseen objects. Off-policy learning enables utilization of grasping data over a wide variety of objects, and diversity is important to enable the method to generalize to new objects that were not seen during training. We evaluate the benchmark tasks against a variety of Q-function estimation methods, a method previously proposed for robotic grasping with deep neural network models, and a novel approach based on a combination of Monte Carlo return estimation and an off-policy correction. Our results indicate that several simple methods provide a surprisingly strong competitor to popular algorithms such as double Q-learning, and our analysis of stability sheds light on the relative tradeoffs between the algorithms1.
ER  - 

TY  - CONF
TI  - Overcoming Exploration in Reinforcement Learning with Demonstrations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6292
EP  - 6299
AU  - A. Nair
AU  - B. McGrew
AU  - M. Andrychowicz
AU  - W. Zaremba
AU  - P. Abbeel
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - reinforcement learning
KW  - reward function
KW  - task horizon
KW  - RL methods
KW  - exploration problem
KW  - multistep robotics tasks
KW  - robot arm
KW  - deep deterministic policy gradients
KW  - hindsight experience replay
KW  - simulated robotics tasks
KW  - Task analysis
KW  - Robots
KW  - Learning (artificial intelligence)
KW  - Stacking
KW  - Training
KW  - Mathematical model
KW  - Games
DO  - 10.1109/ICRA.2018.8463162
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Exploration in environments with sparse rewards has been a persistent problem in reinforcement learning (RL). Many tasks are natural to specify with a sparse reward, and manually shaping a reward function can result in suboptimal performance. However, finding a non-zero reward is exponentially more difficult with increasing task horizon or action dimensionality. This puts many real-world tasks out of practical reach of RL methods. In this work, we use demonstrations to overcome the exploration problem and successfully learn to perform long-horizon, multi-step robotics tasks with continuous control such as stacking blocks with a robot arm. Our method, which builds on top of Deep Deterministic Policy Gradients and Hindsight Experience Replay, provides an order of magnitude of speedup over RL on simulated robotics tasks. It is simple to implement and makes only the additional assumption that we can collect a small set of demonstrations. Furthermore, our method is able to solve tasks not solvable by either RL or behavior cloning alone, and often ends up outperforming the demonstrator policy.
ER  - 

TY  - CONF
TI  - Fast Image-Based Geometric Change Detection Given a 3D Model
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6308
EP  - 6315
AU  - E. Palazzolo
AU  - C. Stachniss
PY  - 2018
KW  - image reconstruction
KW  - image sequences
KW  - object detection
KW  - solid modelling
KW  - stereo image processing
KW  - fast image-based geometric change detection
KW  - multiple images
KW  - self-recorded image sequences
KW  - robotic applications
KW  - 3D model
KW  - 3D location
KW  - Three-dimensional displays
KW  - Solid modeling
KW  - Computational modeling
KW  - Cameras
KW  - Robots
KW  - Two dimensional displays
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8461019
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - 3D models of the environment are used in numerous robotic applications and should reflect the current state of the world. In this paper, we address the problem of quickly finding structural changes between the current state of the world and a given 3D model using a small number of images. Our approach finds inconsistencies between pairs of images by re-projecting an image onto another one by passing through the given 3D model. This process leads to ambiguities, which we resolve by combining multiple images such that the 3D location of the change can be estimated. A focus of our approach is that it can be executed fast enough to allow the operation on a mobile system. We implemented our approach in C++ and released it as open source software. We tested it on existing datasets as well as on self-recorded image sequences and 3D models, which we publicly share. Our experiments show that our method quickly finds changes in the geometry of a scene.
ER  - 

TY  - CONF
TI  - Multimodal 2D Image to 3D Model Registration via a Mutual Alignment of Sparse and Dense Visual Features
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6316
EP  - 6322
AU  - N. Crombez
AU  - R. Seulin
AU  - O. Morel
AU  - D. Fofi
AU  - C. Demonceaux
PY  - 2018
KW  - geometry
KW  - image registration
KW  - solid modelling
KW  - multimodal 2D image
KW  - 3D model registration
KW  - dense visual features
KW  - 2D/3D registration methods
KW  - geometric features
KW  - feature type
KW  - hybrid registration framework
KW  - visual sensors
KW  - 3D model
KW  - Mutual Alignment
KW  - geometric visual features
KW  - sparse visual features
KW  - 2D/3D alignment
KW  - Three-dimensional displays
KW  - Cameras
KW  - Solid modeling
KW  - Visualization
KW  - Feature extraction
KW  - Two dimensional displays
KW  - Sensors
DO  - 10.1109/ICRA.2018.8461092
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Many fields of application could benefit from an accurate registration of measurements of different modalities over a known 3D model. However, aligning a 2D image to a 3D model is a challenging task and is even more complex when the two have a different modality. Most of the 2D/3D registration methods are based on either geometric or dense visual features. Both have their own advantages and their own drawbacks. We propose, in this paper, to mutually exploit the advantages of one feature type to reduce the drawbacks of the other one. For this, an hybrid registration framework has been designed to mutually align geometrical and dense visual features in order to obtain an accurate final 2D/3D alignment. We evaluate and compare the proposed registration method on real data acquired by a robot equipped with several visual sensors. The results highlights the robustness of the method and its ability to produce wide convergence domain and a high registration accuracy.
ER  - 

TY  - CONF
TI  - An Efficient Volumetric Mesh Representation for Real-Time Scene Reconstruction Using Spatial Hashing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6323
EP  - 6330
AU  - W. Dong
AU  - J. Shi
AU  - W. Tang
AU  - X. Wang
AU  - H. Zha
PY  - 2018
KW  - computational geometry
KW  - data structures
KW  - image reconstruction
KW  - image representation
KW  - mesh generation
KW  - sensor fusion
KW  - solid modelling
KW  - real-time scene reconstruction
KW  - spatial hashing
KW  - flexible data structures
KW  - 3D data fusion
KW  - mesh refinement
KW  - mesh quality
KW  - mesh memory consumption
KW  - volumetric mesh representation
KW  - Hamming distance
KW  - 3D reconstruction
KW  - Three-dimensional displays
KW  - Real-time systems
KW  - Data integration
KW  - Mesh generation
KW  - Rendering (computer graphics)
KW  - Data structures
KW  - Sensors
DO  - 10.1109/ICRA.2018.8463157
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Mesh plays an indispensable role in dense realtime reconstruction essential in robotics. Efforts have been made to maintain flexible data structures for 3D data fusion, yet an efficient incremental framework specifically designed for online mesh storage and manipulation is missing. We propose a novel framework to compactly generate, update, and refine mesh for scene reconstruction upon a volumetric representation. Maintaining a spatial-hashed field of cubes, we distribute vertices with continuous value on discrete edges that support O(1) vertex accessing and forbid memory redundancy. By introducing Hamming distance in mesh refinement, we further improve the mesh quality regarding the triangle type consistency with a low cost. Lock-based and lock-free operations were applied to avoid thread conflicts in GPU parallel computation. Experiments demonstrate that the mesh memory consumption is significantly reduced while the running speed is kept in the online reconstruction process.
ER  - 

TY  - CONF
TI  - Mapping with Dynamic-Object Probabilities Calculated from Single 3D Range Scans
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6331
EP  - 6336
AU  - P. Ruchti
AU  - W. Burgard
PY  - 2018
KW  - control engineering computing
KW  - laser ranging
KW  - mobile robots
KW  - navigation
KW  - neural nets
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - KITTI dataset
KW  - mapping process
KW  - mapping module
KW  - dynamic object
KW  - pointwise probability
KW  - neural network
KW  - laser range data
KW  - 3D grid map
KW  - navigation functions
KW  - robot perceptions
KW  - dynamic environments
KW  - safe navigation
KW  - robust navigation
KW  - autonomous robotic systems
KW  - single 3D range scans
KW  - dynamic-object probabilities
KW  - time 3.0 d
KW  - Three-dimensional displays
KW  - Cameras
KW  - Neural networks
KW  - Measurement by laser beam
KW  - Lasers
KW  - Laser beams
KW  - Image segmentation
DO  - 10.1109/ICRA.2018.8463149
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Various autonomous robotic systems require maps for robust and safe navigation. Particularly when robots are employed in dynamic environments, accurate knowledge about which components of the robot perceptions belong to dynamic and static aspects in the environment can greatly improve navigation functions. In this paper we propose a novel method for building 3D grid maps using laser range data in dynamic environments. Our approach uses a neural network to estimate the pointwise probability of a point belonging to a dynamic object. The output from our network is fed to the mapping module for building a 3D grid map containing only static parts of the environment. We present experimental results obtained by training our neural network using the KITTI dataset and evaluating it in a mapping process using our own dataset. In extensive experiments, we show that maps generated using the proposed probability about dynamic objects increases the accuracy of the resulting maps.
ER  - 

TY  - CONF
TI  - A Survey of Voxel Interpolation Methods and an Evaluation of Their Impact on Volumetric Map-Based Visual Odometry
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3637
EP  - 3643
AU  - D. R. Canelhas
AU  - T. Stoyanov
AU  - A. J. Lilienthal
PY  - 2018
KW  - cameras
KW  - computational geometry
KW  - distance measurement
KW  - image reconstruction
KW  - interpolation
KW  - medical image processing
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - camera trajectories
KW  - trilinear interpolation method
KW  - depth-camera pose tracking
KW  - performance degradation
KW  - truncated signed distance field
KW  - voxel-based map representations
KW  - geometric interpolation methods
KW  - intermediate options
KW  - nearest neighbors
KW  - voxel volumes
KW  - volumetric map-based visual odometry
KW  - voxel interpolation methods
KW  - Interpolation
KW  - Memory management
KW  - Three-dimensional displays
KW  - Pose estimation
KW  - Extrapolation
KW  - Two dimensional displays
KW  - Image resolution
DO  - 10.1109/ICRA.2018.8461227
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Voxel volumes are simple to implement and lend themselves to many of the tools and algorithms available for 2D images. However, the additional dimension of voxels may be costly to manage in memory when mapping large spaces at high resolutions. While lowering the resolution and using interpolation is common work-around, in the literature we often find that authors either use trilinear interpolation or nearest neighbors and rarely any of the intermediate options. This paper presents a survey of geometric interpolation methods for voxel-based map representations. In particular we study the truncated signed distance field (TSDF) and the impact of using fewer than 8 samples to perform interpolation within a depth-camera pose tracking and mapping scenario. We find that lowering the number of samples fetched to perform the interpolation results in performance similar to the commonly used trilinear interpolation method, but leads to higher frame-rates. We also report that lower bit-depth generally leads to performance degradation, though not as much as may be expected, with voxels containing as few as 3 bits sometimes resulting in adequate estimation of camera trajectories.
ER  - 

TY  - CONF
TI  - Complex Urban LiDAR Data Set
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6344
EP  - 6351
AU  - J. Jeong
AU  - Y. Cho
AU  - Y. Shin
AU  - H. Roh
AU  - A. Kim
PY  - 2018
KW  - graph theory
KW  - mobile robots
KW  - optical radar
KW  - pose estimation
KW  - radar computing
KW  - SLAM (robots)
KW  - complex urban environments
KW  - light detection and ranging data set
KW  - fiber optic gyro
KW  - inertial measurement unit
KW  - Global Positioning System
KW  - vehicle pose estimation
KW  - graph simultaneous location and mapping algorithm
KW  - graph SLAM algorithm
KW  - Robot Operating System environment
KW  - raw sensor data
KW  - 2D LiDAR
KW  - 16-ray 3D LiDARs
KW  - LiDAR sensors
KW  - three-dimensional LiDAR
KW  - building complexes
KW  - high-rise buildings
KW  - complex urban LiDAR data set
KW  - frequency 100.0 Hz
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Global Positioning System
KW  - Two dimensional displays
KW  - Sensor systems
KW  - Urban areas
DO  - 10.1109/ICRA.2018.8460834
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a Light Detection and Ranging (LiDAR) data set that targets complex urban environments. Urban environments with high-rise buildings and congested traffic pose a significant challenge for many robotics applications. The presented data set is unique in the sense it is able to capture the genuine features of an urban environment (e.g. metropolitan areas, large building complexes and underground parking lots). Data of two-dimensional (2D) and three-dimensional (3D) LiDAR, which are typical types of LiDAR sensors, are provided in the data set. The two 16-ray 3D LiDARs are tilted on both sides for maximal coverage. One 2D LiDAR faces backward while the other faces forwards to collect data of roads and buildings, respectively. Raw sensor data from Fiber Optic Gyro (FOG), Inertial Measurement Unit (IMU), and the Global Positioning System (GPS) are presented in a file format for vehicle pose estimation. The pose information of the vehicle estimated at 100 Hz is also presented after applying the graph simultaneous localization and mapping (SLAM) algorithm. For the convenience of development, the file player and data viewer in Robot Operating System (ROS) environment were also released via the web page. The full data sets are available at: http://irap.kaist.ac.kr/dataset. In this website, 3D preview of each data set is provided using WebGL.
ER  - 

TY  - CONF
TI  - Live Structural Modeling Using RGB-D SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6352
EP  - 6358
AU  - N. Olivier
AU  - H. Uchiyama
AU  - M. Mishima
AU  - D. Thomas
AU  - R. Taniguchi
AU  - R. Roberto
AU  - J. P. Lima
AU  - V. Teichrieb
PY  - 2018
KW  - image colour analysis
KW  - image fusion
KW  - image texture
KW  - robot vision
KW  - SLAM (robots)
KW  - solid modelling
KW  - live structural modeling
KW  - dense point cloud
KW  - shape map
KW  - single point cloud
KW  - metric primitive modeling
KW  - RGB-D SLAM
KW  - primitive shape localization
KW  - shape fusion
KW  - Shape
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Computational modeling
KW  - History
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460973
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a method for localizing primitive shapes in a dense point cloud computed by the RGB-D SLAM system. To stably generate a shape map containing only primitive shapes, the primitive shape is incrementally modeled by fusing the shapes estimated at previous frames in the SLAM, so that an accurate shape can be finally generated. Specifically, the history of the fusing process is used to avoid the influence of error accumulation in the SLAM. The point cloud of the shape is then updated by fusing the points in all the previous frames into a single point cloud. In the experimental results, we show that metric primitive modeling in texture-less and unprepared environments can be achieved online.
ER  - 

TY  - CONF
TI  - Adaptive Sampling and Online Learning in Multi-Robot Sensor Coverage with Mixture of Gaussian Processes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6359
EP  - 6364
AU  - W. Luo
AU  - K. Sycara
PY  - 2018
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - multi-robot systems
KW  - optimisation
KW  - online learning
KW  - multirobot sensor coverage
KW  - online environmental sampling
KW  - multirobot coverage control
KW  - environmental phenomenon
KW  - robot team
KW  - Gaussian Process
KW  - locally learned Gaussian Processes
KW  - collective model learning
KW  - simultaneous adaptive sampling
KW  - density function
KW  - sensing performance optimization
KW  - Robot sensing systems
KW  - Adaptation models
KW  - Density functional theory
KW  - Temperature distribution
KW  - Data models
DO  - 10.1109/ICRA.2018.8460473
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the problem of online environmental sampling and modeling for multi-robot sensor coverage, where a team of robots spread out over the workspace in order to optimize the overall sensing performance. In contrast to most existing works on multi-robot coverage control that assume prior knowledge of the distribution of environmental phenomenon, also known as density function, we relax this assumption and enable the robot team to efficiently learn the model of the unknown density function Online using adaptive sampling and non-parametric inference such as Gaussian Process (GP). To capture significantly different components of the environmental phenomenon, we propose a new approach with mixture of locally learned Gaussian Processes for collective model learning and an information-theoretic criterion for simultaneous adaptive sampling in multi-robot coverage. Our approach demonstrates a better generalization of the environment modeling and thus the improved performance of coverage without assuming the density function is known a priori. We demonstrate the effectiveness of our algorithm via simulations of information gathering from indoor static sensors.
ER  - 

TY  - CONF
TI  - Coordinated Dense Aerial Traffic with Self-Driving Drones
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6365
EP  - 6372
AU  - B. Balázs
AU  - G. Vásárhelyi
PY  - 2018
KW  - air traffic control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - decentralised control
KW  - multi-robot systems
KW  - coordinated dense aerial traffic
KW  - general air traffic control solution
KW  - decentralized air traffic control solution
KW  - package-delivery scenarios
KW  - intelligent collective collision avoidance
KW  - motion planning
KW  - jam-free optimal traffic flow
KW  - force-based distributed multirobot control model
KW  - behaviour-driven velocity alignment
KW  - self-organized queueing
KW  - conflict-avoiding self-driving
KW  - Drones
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Oscillators
KW  - Acceleration
KW  - Task analysis
KW  - Roads
DO  - 10.1109/ICRA.2018.8461073
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present a general, decentralized air traffic control solution using autonomous drones. We challenge some of the most difficult dense traffic situations, namely, crosswalk and package-delivery scenarios, where intelligent collective collision avoidance and motion planning is essential for a jam-free optimal traffic flow. We build up a force-based distributed multi-robot control model using a tunable selection of interaction terms: anisotropic repulsion, behaviour-driven velocity alignment, self-organized queueing and conflict-avoiding self-driving. We optimize the model with evolution in a realistic simulation framework and demonstrate its applicability with 30 autonomous drones in a coordinated outdoor flight within a densely packed virtual arena.
ER  - 

TY  - CONF
TI  - Near-Optimal Adversarial Policy Switching for Decentralized Asynchronous Multi-Agent Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6373
EP  - 6380
AU  - T. N. Hoang
AU  - Y. Xiao
AU  - K. Sivakumar
AU  - C. Amato
AU  - J. P. Howl
PY  - 2018
KW  - decision making
KW  - multi-agent systems
KW  - multi-robot systems
KW  - planning (artificial intelligence)
KW  - multirobot
KW  - small-scale synchronous decision-making scenarios
KW  - asynchronous agents
KW  - multiple strategic adversaries
KW  - adversary strategies
KW  - optimized stratagems
KW  - unified policy
KW  - near-optimality
KW  - optimal adversarial policy switching
KW  - decentralized asynchronous multiagent systems
KW  - communication capabilities
KW  - Switches
KW  - Planning
KW  - Task analysis
KW  - Robot kinematics
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2018.8460485
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A key challenge in multi-robot and multi-agent systems is generating solutions that are robust to other self-interested or even adversarial parties who actively try to prevent the agents from achieving their goals. The practicality of existing works addressing this challenge is limited to only small-scale synchronous decision-making scenarios or a single agent planning its best response against a single adversary with fixed, procedurally characterized strategies. In contrast this paper considers a more realistic class of problems where a team of asynchronous agents with limited observation and communication capabilities need to compete against multiple strategic adversaries with changing strategies. This problem necessitates agents that can coordinate to detect changes in adversary strategies and plan the best response accordingly. Our approach first optimizes a set of stratagems that represent these best responses. These optimized stratagems are then integrated into a unified policy that can detect and respond when the adversaries change their strategies. The near-optimality of the proposed framework is established theoretically as well as demonstrated empirically in simulation and hardware.
ER  - 

TY  - CONF
TI  - Data Ferrying with Swarming UAS in Tactical Defence Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6381
EP  - 6388
AU  - R. Hunjet
AU  - B. Fraser
AU  - T. Stevens
AU  - L. Hodges
AU  - K. Mayen
AU  - J. C. Barca
AU  - M. Cochrane
AU  - R. Cannizzaro
AU  - J. L. Palmer
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - harsh communication environments
KW  - UAS
KW  - human-swarm interaction
KW  - data dissemination capabilities
KW  - indoor flight facilities
KW  - physical swarm robotic platforms
KW  - radio-frequency communications
KW  - swarm members
KW  - tactical defence networks
KW  - Emulation
KW  - Convergence
KW  - Australia
KW  - Radio frequency
KW  - Data models
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8463151
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we categorise swarming into four classes, depending on the manner in which swarm members communicate. We identify two of these classes as ready candidates for the provision of communications within tactical defence networks in which radio-frequency communications are highly contested or denied. We demonstrate the feasibility of a swarm-robotics approach to data ferrying from both of these classes using simulation, emulation, and physical swarm robotic platforms within indoor flight facilities. The results show strong alignment between data dissemination capabilities of the simulated and physical systems; we envisage these techniques providing communications between not only troops, but also other swarm robotic platforms, thereby enabling swarm robotics applications and human-swarm interaction within harsh communications environments.
ER  - 

TY  - CONF
TI  - Distance-Based Multi-Robot Coordination on Pocket Drones
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6389
EP  - 6394
AU  - B. Broecker
AU  - K. Tuyls
AU  - J. Butterworth
PY  - 2018
KW  - learning (artificial intelligence)
KW  - particle filtering (numerical methods)
KW  - recurrent neural nets
KW  - remotely operated vehicles
KW  - Deep Q-Learning Network
KW  - recurrent network
KW  - UWB-distance information
KW  - neural networks
KW  - distance-based multirobot coordination
KW  - pocket drones
KW  - MicroAerial Vehicles
KW  - recurrent neural network
KW  - Drones
KW  - Robot kinematics
KW  - Recurrent neural networks
KW  - Hardware
KW  - Robot sensing systems
KW  - Distance measurement
DO  - 10.1109/ICRA.2018.8461176
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a fully realised system illustrating decentralised coordination on Micro Aerial Vehicles (MAV) or pocket drones, based on distance information. This entails the development of an ultra light hardware solution to determine the distances between the drones and also the development of a model to learn good control policies. The model we present is a combination of a recurrent neural network and a Deep Q-Learning Network (DQN). The recurrent network provides bearing information to the DQN. The DQN itself is responsible for choosing movement actions to avoid collisions and to reach a desired position. Overall we are able provide a complete system which is capable of letting multiple drones navigate in a confined space only based on UWB-distance information and velocity input. We tackle the problem of neural networks and real world sensor noise, by combining the network with a particle filter and show that the combination outperforms the traditional particle filter in terms of converge speed and robustness. A video is available at: https://youtu.be/yj6QqhOzpok.
ER  - 

TY  - CONF
TI  - Human-in-the-Loop Mixed-Initiative Control Under Temporal Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6395
EP  - 6400
AU  - M. Guo
AU  - S. Andersson
AU  - D. V. Dimarogonas
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - planning (artificial intelligence)
KW  - temporal logic
KW  - plan adaptation scheme
KW  - short-term tasks
KW  - iterative inverse reinforcement learning algorithm
KW  - human preference
KW  - plan synthesis
KW  - human-in-the-loop simulations
KW  - mixed-initiative control
KW  - motion control
KW  - task planning problem
KW  - mobile robots
KW  - high-level tasks
KW  - Linear Temporal Logic
KW  - hard constraints
KW  - soft constraints
KW  - robot autonomy
KW  - additive terms
KW  - contingent task assignments
KW  - online coordination scheme
KW  - mixed-initiative continuous controller
KW  - temporal tasks
KW  - human initiatives
KW  - Task analysis
KW  - Safety
KW  - Robot kinematics
KW  - Automata
KW  - Planning
KW  - Navigation
DO  - 10.1109/ICRA.2018.8460793
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper considers the motion control and task planning problem of mobile robots under complex high-level tasks and human initiatives. The assigned task is specified as Linear Temporal Logic (LTL) formulas that consist of hard and soft constraints. The human initiative influences the robot autonomy in two explicit ways: with additive terms in the continuous controller and with contingent task assignments. We propose an online coordination scheme that encapsulates (i) a mixed-initiative continuous controller that ensures all-time safety despite of possible human errors, (ii) a plan adaptation scheme that accommodates new features discovered in the workspace and short-term tasks assigned by the operator during run time, and (iii) an iterative inverse reinforcement learning (IRL) algorithm that allows the robot to asymptotically learn the human preference on the parameters during the plan synthesis. The results are demonstrated by both realistic human-in-the-loop simulations and experiments.
ER  - 

TY  - CONF
TI  - Cooperative Adaptive Control for Cloud-Based Robotics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6401
EP  - 6408
AU  - P. M. Wensing
AU  - J. Slotine
PY  - 2018
KW  - adaptive control
KW  - cloud computing
KW  - control engineering computing
KW  - control system synthesis
KW  - decentralised control
KW  - Lyapunov methods
KW  - manipulators
KW  - multi-robot systems
KW  - adaptive control
KW  - robot manipulators
KW  - synchronous centralized update laws
KW  - parameter convergence
KW  - time-varying network topologies
KW  - nonidealized networked conditions
KW  - planar manipulator
KW  - cloud-based robotics
KW  - inertial parameters
KW  - collective sufficient richness notion
KW  - decentralized update laws
KW  - Adaptive control
KW  - Manipulators
KW  - Convergence
KW  - Robot sensing systems
KW  - Cloud computing
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460856
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper studies collaboration through the cloud in the context of cooperative adaptive control for robot manipulators. We first consider the case of multiple robots manipulating a common object through synchronous centralized update laws to identify unknown inertial parameters. Through this development, we introduce a notion of Collective Sufficient Richness, wherein parameter convergence can be enabled through teamwork in the group. The introduction of this property and the analysis of stable adaptive controllers that benefit from it constitute the main new contributions of this work. Building on this original example, we then consider decentralized update laws, time-varying network topologies, and the influence of communication delays on this process. Perhaps surprisingly, these nonidealized networked conditions inherit the same benefits of convergence being determined through collective effects for the group. Simple simulations of a planar manipulator identifying an unknown load are provided to illustrate the central idea and benefits of Collective Sufficient Richness.
ER  - 

TY  - CONF
TI  - Optimized Environment Exploration for Autonomous Underwater Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6409
EP  - 6416
AU  - E. Vidal
AU  - J. D. Hernández
AU  - K. Istenic
AU  - M. Carreras
PY  - 2018
KW  - autonomous underwater vehicles
KW  - image reconstruction
KW  - mobile robots
KW  - path planning
KW  - quadtrees
KW  - tree data structures
KW  - viewpoint generation process
KW  - consistent maps
KW  - noisy sonar data
KW  - optimized environment exploration
KW  - autonomous underwater
KW  - autonomous robotic environment exploration
KW  - underwater domain
KW  - noisy acoustic sensors
KW  - high localization error
KW  - control disturbances
KW  - robotic exploration algorithm
KW  - underwater vehicles
KW  - view planning
KW  - path planning algorithms
KW  - exploration approach
KW  - quadtree data structure
KW  - relevant queries
KW  - natural environments
KW  - underwater maps
KW  - map representation
KW  - optical coverage
KW  - time 3.0 d
KW  - Cameras
KW  - Sonar
KW  - Planning
KW  - Robot sensing systems
KW  - Inspection
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8460919
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Achieving full autonomous robotic environment exploration in the underwater domain is very challenging, mainly due to noisy acoustic sensors, high localization error, control disturbances of the water and lack of accurate underwater maps. In this work we present a robotic exploration algorithm for underwater vehicles that does not rely on prior information about the environment. Our method has been greatly influenced by many robotic exploration, view planning and path planning algorithms. The proposed method constitutes a significant improvement over our previous work [1]: Firstly, we refine our exploration approach to improve robustness; Secondly, we propose an alternative map representation based on the quadtree data structure that allows different relevant queries to be performed efficiently, reducing the computational cost of the viewpoint generation process; Thirdly, we present an algorithm that is capable of generating consistent maps even when noisy sonar data is used. The aforementioned contributions have increased the reliability of the algorithm, allowing new real experiments performed in artificial structures but also in more challenging natural environments, from which we provide a 3D reconstruction to show that with this algorithm full optical coverage is obtained.
ER  - 

TY  - CONF
TI  - Pilot Surveys for Adaptive Informative Sampling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6417
EP  - 6424
AU  - S. Kemna
AU  - O. Kroemer
AU  - G. S. Sukhatme
PY  - 2018
KW  - aerospace control
KW  - environmental factors
KW  - Gaussian processes
KW  - mobile robots
KW  - path planning
KW  - regression analysis
KW  - sampling methods
KW  - sampling trajectory
KW  - Gaussian Process regression
KW  - pilot surveys
KW  - adaptive informative sampling
KW  - GP hyperparameter estimation
KW  - path planning decisions
KW  - environmental field modeling
KW  - informative samples
KW  - adaptive sampling techniques
KW  - GP regression
KW  - Adaptation models
KW  - Data models
KW  - Kernel
KW  - Robots
KW  - Gaussian processes
KW  - Estimation
KW  - Optimization
DO  - 10.1109/ICRA.2018.8460488
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Adaptive sampling has been shown to be an effective method for modeling environmental fields, such as algae concentrations in the ocean. In adaptive sampling, a robot adapts its sampling trajectory based on data that it is collecting. This data is often aggregated into models, using techniques such as Gaussian Process (G P) regression. The (hyper-)parameters for these models need to be manually set or, ideally, estimated from data. For GP regression, hyperparameters are typically estimated using prior data. This paper addresses the case where initial hyperparameters need to be estimated, but no prior data is available. Without prior data or accurately pre-defined hyperparameters, adaptive sampling techniques may fail, because there is no good model to base path planning decisions on. One method of gathering data is to perform a pilot survey. This survey needs to select informative samples for initiating the model, but without having a model to determine where best to sample. In this work, we evaluate four pilot surveys, which use a softmax function on the distance between waypoints and previously sampled data for waypoint selection. Simulation results show that pilot surveys that maximize waypoint spread over randomization lead to more stable estimation of GP hyperparameters, and create accurate models more quickly.
ER  - 

TY  - CONF
TI  - Gaze-Assisted Adaptive Motion Scaling Optimization Using Graded and Preference Based Bayesian Approaches
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6425
EP  - 6430
AU  - G. Gras
AU  - C. A. Seneci
AU  - P. Giataganas
AU  - G. Yang
PY  - 2018
KW  - adaptive control
KW  - Bayes methods
KW  - human-robot interaction
KW  - medical robotics
KW  - optimisation
KW  - surgery
KW  - telerobotics
KW  - gaze-assisted adaptive motion scaling optimization
KW  - Bayesian approaches
KW  - master-slave surgical systems
KW  - slave robot
KW  - gaze-assisted intention recognition scheme
KW  - Bayesian approach
KW  - human-robot interface
KW  - Bayesian optimization methods
KW  - Robots
KW  - Bayes methods
KW  - Instruments
KW  - Linear programming
KW  - Optimization methods
KW  - Master-slave
DO  - 10.1109/ICRA.2018.8460588
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A key component to the success of master-slave surgical systems is the quality of the master interface used to relay the surgeon's instructions to the slave robot. In previous work the authors developed a gaze-assisted intention recognition scheme, allowing the system to dynamically adapt the motion scaling based on where the user is trying to reach. This allowed users to perform tasks significantly more quickly and with less need for clutching. However, the system possessed a number of core parameters that were manually optimized, potentially providing a non-optimal solution depending on the user. This paper presents a Bayesian approach to the problem of optimizing a human-robot interface in a user-specific manner. Two Bayesian optimization methods are studied: one in which users are asked to grade robot behavior for a given set of parameters, and one where only preference relative to other parameter sets is expressed. The performance of these optimizations is evaluated in a blind comparison user study, demonstrating that the optimized parameters are preferred to the manually optimized ones in over 90 % of cases after only 12 test samples. These parameters are further shown to perform at least as well as the manually optimized ones in all cases, and showing statistically significant improvement in the case of the graded optimization.
ER  - 

TY  - CONF
TI  - Learning to Race Through Coordinate Descent Bayesian Optimisation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6431
EP  - 6438
AU  - R. Oliveira
AU  - F. H. M. Rocha
AU  - L. Ott
AU  - V. Guizilini
AU  - F. Ramos
AU  - V. Grassi
PY  - 2018
KW  - automobiles
KW  - Bayes methods
KW  - Hilbert spaces
KW  - mobile robots
KW  - optimisation
KW  - robot dynamics
KW  - vehicle dynamics
KW  - dynamical model
KW  - robot
KW  - car racing simulation
KW  - descent Bayesian optimisation
KW  - race track
KW  - kernel Hilbert space
KW  - Bayesian optimisation
KW  - Optimization
KW  - Robot kinematics
KW  - Bayes methods
KW  - Search problems
KW  - Kernel
KW  - Linear programming
DO  - 10.1109/ICRA.2018.8460735
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the automation of many kinds of processes, the observable outcome can often be described as the combined effect of an entire sequence of actions, or controls, applied throughout the process execution. In these cases, strategies to optimise control policies for individual stages of the process are not applicable, and instead the whole policy needs to be optimised at once. On the other hand, the cost to evaluate the policy's performance might also be high, being desirable that a solution can be found with as few interactions as possible with the real system. We consider the problem of optimising control policies to allow a robot to complete a given race track within a minimum amount of time. We assume that the robot has no prior information about the track or its own dynamical model, just an initial valid driving example. Localisation is only applied to monitor the robot and to provide an indication of its position along the track's centre axis. With that in mind, we propose a method for finding a policy that minimises the time per lap while keeping the vehicle on the track using a Bayesian optimisation (BO) approach over a reproducing kernel Hilbert space. We apply an algorithm to search more efficiently over high-dimensional policy-parameter spaces with BO, by iterating over each dimension individually, in a sequential coordinate descent-like scheme. Experiments demonstrate the performance of the algorithm against other methods in a simulated car racing environment.
ER  - 

TY  - CONF
TI  - Towards Emergence of Tool Use in Robots: Automatic Tool Recognition and Use Without Prior Tool Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6439
EP  - 6446
AU  - K. P. Tee
AU  - J. Li
AU  - L. T. Pang Chen
AU  - K. W. Wan
AU  - G. Ganesh
PY  - 2018
KW  - cognition
KW  - object recognition
KW  - robot vision
KW  - automatic tool recognition
KW  - human dexterity
KW  - skill transfer
KW  - robots cognition
KW  - robots capabilities
KW  - tools embodiment
KW  - object recognition
KW  - Tools
KW  - Task analysis
KW  - Kinematics
KW  - Automobiles
KW  - Robot sensing systems
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460987
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Humans are adept at tool use. We can intuitively and immediately improvise and use unknown objects in our environment as tools, to assist us in performing tasks. In this study, we provide similar cognition and capabilities to robots. Neuroscientific studies on tool use have suggested that human dexterity with tools is enabled by the embodiment of the tools, which in effect, allows humans to immediately transfer prior skills acquired without tools, onto tasks requiring tool use. Here, utilizing the theoretical results from our investigations on embodiment and tool use in humans over the last years, we propose a concept and algorithm to enable similar skill transfer by robots. Our algorithm enables a robot that has had no prior learning with tools, to automatically recognize an object (seen for the first time) in its environment as a potential tool for an otherwise unattainable task, and use the tool to perform the task thereafter.
ER  - 

TY  - CONF
TI  - Put-in-Box Task Generated from Multiple Discrete Tasks by aHumanoid Robot Using Deep Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6447
EP  - 6452
AU  - K. Kase
AU  - K. Suzuki
AU  - P. Yang
AU  - H. Mori
AU  - T. Ogata
PY  - 2018
KW  - feature extraction
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - recurrent neural nets
KW  - multiple discrete tasks
KW  - deep learning
KW  - deep neural networks
KW  - robot manipulation model
KW  - DNNs
KW  - long sequential dynamic tasks
KW  - multiple short sequential tasks
KW  - multiple timescale recurrent neural network
KW  - MTRNN
KW  - initial motion steps
KW  - final motion steps
KW  - initial image input
KW  - subtask
KW  - put-in-box task
KW  - Task analysis
KW  - Robots
KW  - Feature extraction
KW  - Switches
KW  - Neurons
KW  - Training
KW  - Convolution
DO  - 10.1109/ICRA.2018.8460623
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For robots to have a wide range of applications, they must be able to execute numerous tasks. However, recent studies into robot manipulation using deep neural networks (DNN) have primarily focused on single tasks. Therefore, we investigate a robot manipulation model that uses DNNs and can execute long sequential dynamic tasks by performing multiple short sequential tasks at appropriate times. To generate compound tasks, we propose a model comprising two DNNs: a convolutional autoencoder that extracts image features and a multiple timescale recurrent neural network (MTRNN) to generate motion. The internal state of the MTRNN is constrained to have similar values at the initial and final motion steps; thus, motions can be differentiated based on the initial image input. As an example compound task, we demonstrate that the robot can generate a “Put-In-Box” task that is divided into three subtasks: open the box, grasp the object and put it into the box, and close the box. The subtasks were trained as discrete tasks, and the connections between each subtask were not trained. With the proposed model, the robot could perform the Put-In-Box task by switching among subtasks and could skip or repeat subtasks depending on the situation.
ER  - 

TY  - CONF
TI  - CASSL: Curriculum Accelerated Self-Supervised Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6453
EP  - 6460
AU  - A. Murali
AU  - L. Pinto
AU  - D. Gandhi
AU  - A. Gupta
PY  - 2018
KW  - grippers
KW  - learning (artificial intelligence)
KW  - sensitivity analysis
KW  - adaptive-underactuated multifingered gripper
KW  - curriculum accelerated self-supervised learning
KW  - variance-based global sensitivity analysis
KW  - control parameters
KW  - control dimensions
KW  - training data
KW  - CASSL orders
KW  - higher-dimensional action
KW  - map visual information
KW  - clever sampling strategy
KW  - data collection efforts
KW  - higher-dimensional control
KW  - low-dimensional action
KW  - self-supervised learning approaches
KW  - complete end-to-end learning
KW  - staged curriculum learning
KW  - CASSL framework
KW  - Aerospace electronics
KW  - Grasping
KW  - Training
KW  - Task analysis
KW  - Robots
KW  - Sensitivity analysis
DO  - 10.1109/ICRA.2018.8463147
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recent self-supervised learning approaches focus on using a few thousand data points to learn policies for high-level, low-dimensional action spaces. However, scaling this framework for higher-dimensional control requires either scaling up the data collection efforts or using a clever sampling strategy for training. We present a novel approach - Curriculum Accelerated Self-Supervised Learning (CASSL) - to train policies that map visual information to high-level, higher-dimensional action spaces. CASSL orders the sampling of training data based on control dimensions: the learning and sampling are focused on few control parameters before other parameters. The right curriculum for learning is suggested by variance-based global sensitivity analysis of the control space. We apply our CASSL framework to learning how to grasp using an adaptive, underactuated multi-fingered gripper, a challenging system to control. Our experimental results indicate that CASSL provides significant improvement and generalization compared to baseline methods such as staged curriculum learning (8% increase) and complete end-to-end learning with random exploration (14% improvement) tested on a set of novel objects.
ER  - 

TY  - CONF
TI  - Learning to Control Redundant Musculoskeletal Systems with Neural Networks and SQP: Exploiting Muscle Properties
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6461
EP  - 6468
AU  - D. Driess
AU  - H. Zimmermann
AU  - S. Wolfen
AU  - D. Suissa
AU  - D. Haeufle
AU  - D. Hennes
AU  - M. Toussaint
AU  - S. Schmitt
PY  - 2018
KW  - biomechanics
KW  - biomimetics
KW  - bone
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - muscle
KW  - neural nets
KW  - nonlinear control systems
KW  - physiological models
KW  - quadratic programming
KW  - machine learning approaches
KW  - muscle stimulations
KW  - high actuator redundancy
KW  - learned forward model
KW  - neural network
KW  - biomimetic muscle-driven robot show
KW  - nonlinearity
KW  - biomechanical musculoskeletal systems
KW  - quadratic programming
KW  - SQP
KW  - Muscles
KW  - Joints
KW  - Robots
KW  - Biological system modeling
KW  - Torque
KW  - Biomechanics
DO  - 10.1109/ICRA.2018.8463160
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Modeling biomechanical musculoskeletal systems reveals that the mapping from muscle stimulations to movement dynamics is highly nonlinear and complex, which makes it difficult to control those systems with classical techniques. In this work, we not only investigate whether machine learning approaches are capable of learning a controller for such systems. We are especially interested in the question if the structure of the musculoskeletal apparatus exhibits properties that are favorable for the learning task. In particular, we consider learning a control policy from target positions to muscle stimulations. To account for the high actuator redundancy of biomechanical systems, our approach uses a learned forward model represented by a neural network and sequential quadratic programming to obtain the control policy, which also enables us to alternate the co-contraction level and hence allows to change the stiffness of the system and to include optimality criteria like small muscle stimulations. Experiments on both a simulated musculoskeletal model of a human arm and a real biomimetic muscle-driven robot show that our approach is able to learn an accurate controller despite high redundancy and nonlinearity, while retaining sample efficiency.
ER  - 

TY  - CONF
TI  - Q-CP: Learning Action Values for Cooperative Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6469
EP  - 6475
AU  - F. Riccio
AU  - R. Capobianco
AU  - D. Nardi
PY  - 2018
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mobile robots
KW  - Monte Carlo methods
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - state-space methods
KW  - stochastic games
KW  - tree searching
KW  - uncertain systems
KW  - multirobot systems
KW  - manifold applications
KW  - unstructured scenarios
KW  - state dimensionality
KW  - model-based reinforcement learning algorithm
KW  - Q-learning
KW  - curse-of-dimensionality
KW  - cooperation scenario
KW  - mobile robots
KW  - robot behaviors
KW  - uncertainties
KW  - state space exploration
KW  - action values learning
KW  - stochastic cooperative games
KW  - cooperative navigation problem
KW  - cooperative planning
KW  - Monte-Carlo tree search iterations
KW  - general-sum games
KW  - KUKA YouBots
KW  - robot hand-overs
KW  - coordination task
KW  - Robot kinematics
KW  - Games
KW  - Monte Carlo methods
KW  - Task analysis
KW  - Planning
KW  - Stochastic processes
DO  - 10.1109/ICRA.2018.8460180
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Research on multi-robot systems has demonstrated promising results in manifold applications and domains. Still, efficiently learning an effective robot behaviors is very difficult, due to unstructured scenarios, high uncertainties, and large state dimensionality (e.g, hyper-redundant and groups of robot). To alleviate this problem, we present Q-CP a cooperative model-based reinforcement learning algorithm, which exploits action values to both (1) guide the exploration of the state space and (2) generate effective policies. Specifically, we exploit Q-learning to attack the curse-of-dimensionality in the iterations of a Monte-Carlo Tree Search. We implement and evaluate Q-CP on different stochastic cooperative (general-sum) games: (1) a simple cooperative navigation problem among 3 robots, (2) a cooperation scenario between a pair of KUKA YouBots performing hand-overs, and (3) a coordination task between two mobile robots entering a door. The obtained results show the effectiveness of Q- CP in the chosen applications, where action values drive the exploration and reduce the computational demand of the planning process while achieving good performance.
ER  - 

TY  - CONF
TI  - Long-Term Visual Localization Using Semantically Segmented Images
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6484
EP  - 6490
AU  - E. Stenborg
AU  - C. Toft
AU  - L. Hammarstrand
PY  - 2018
KW  - feature extraction
KW  - image segmentation
KW  - particle filtering (numerical methods)
KW  - transforms
KW  - particle filter based semantic localization solution
KW  - SIFT-features
KW  - vehicle localization
KW  - semantically labeled 3D point maps
KW  - autonomous vehicles
KW  - long-term visual navigation
KW  - robust cross-seasonal localization
KW  - semantically segmented images
KW  - long-term visual localization
KW  - image segmenter
KW  - hand-crafted feature descriptors
KW  - Semantics
KW  - Cameras
KW  - Roads
KW  - Image segmentation
KW  - Visualization
KW  - Robustness
KW  - Feature extraction
DO  - 10.1109/ICRA.2018.8463150
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robust cross-seasonal localization is one of the major challenges in long-term visual navigation of autonomous vehicles. In this paper, we exploit recent advances in semantic segmentation of images, i.e., where each pixel is assigned a label related to the type of object it represents, to attack the problem of long-term visual localization. We show that semantically labeled 3D point maps of the environment, together with semantically segmented images, can be efficiently used for vehicle localization without the need for detailed feature descriptors (SIFT, SURF, etc.), Thus, instead of depending on hand-crafted feature descriptors, we rely on the training of an image segmenter. The resulting map takes up much less storage space compared to a traditional descriptor based map. A particle filter based semantic localization solution is compared to one based on SIFT-features, and even with large seasonal variations over the year we perform on par with the larger and more descriptive SIFT-features, and are able to localize with an error below 1 m most of the time.
ER  - 

TY  - CONF
TI  - Robust Localization of Mobile Robots Considering Reliability of LiDAR Measurements
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6491
EP  - 6496
AU  - J. Kim
AU  - W. Chung
PY  - 2018
KW  - mobile robots
KW  - optical radar
KW  - optical sensors
KW  - pose estimation
KW  - reliability
KW  - robot vision
KW  - mobile robot
KW  - LiDAR measurements
KW  - localization errors
KW  - LiDAR sensor-based localization
KW  - optical sensors
KW  - robust localization
KW  - range measurements
KW  - reliability
KW  - Light Detection and Ranging sensor
KW  - pose estimation
KW  - Reliability
KW  - Laser radar
KW  - Robot sensing systems
KW  - Optical sensors
KW  - Glass
KW  - Adaptive optics
KW  - Optical variables measurement
DO  - 10.1109/ICRA.2018.8460648
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this study, we propose a novel Light Detection and Ranging (LiDAR) sensor-based localization method for localization of a mobile robot. In localization using the LiDAR sensor, localization errors occur when real range measurements differ from reference distances computed from a map. This study focuses on three factors that cause differences between real range measurements and reference distances. The first factor corresponds to optical characteristics of the LiDAR sensor for objects such as glass walls and mirrors. The second factor corresponds to occlusions by dynamic obstacles. The third factor corresponds to static changes in the environment. In practical applications, three factors often simultaneously occur. Although there have been many previous works, robust localization to overcome these three difficulties is still a challenging problem. This study proposes a novel robust localization scheme that exploits only reliable range measurements. A LiDAR sensor-based localization scheme can be successfully executed by utilizing only a few reliable range measurements. Therefore, the computation of reliability plays a significant role. The computation of reliability is divided into two steps. The first step considers characteristics of optical sensors. The second step mainly deals with the effects of obstacles. The observation likelihood model exploits computed reliability for pose estimation. The proposed scheme was successfully verified through various experiments under challenging situations.
ER  - 

TY  - CONF
TI  - Sparse Gaussian Processes on Matrix Lie Groups: A Unified Framework for Optimizing Continuous-Time Trajectories
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6497
EP  - 6504
AU  - J. Dong
AU  - M. Mukadam
AU  - B. Boots
AU  - F. Dellaert
PY  - 2018
KW  - continuous time systems
KW  - Gaussian processes
KW  - Lie groups
KW  - matrix algebra
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - path planning
KW  - regression analysis
KW  - state estimation
KW  - trajectory control
KW  - nonparametric representation
KW  - trajectory distributions
KW  - sparse GP regression
KW  - robot state
KW  - locally linear GPs
KW  - state estimation
KW  - motion planning tasks
KW  - sparse Gaussian processes
KW  - continuous-time trajectories
KW  - trajectory optimization
KW  - matrix Lie groups
KW  - robot motion reasoning
KW  - Trajectory
KW  - Simultaneous localization and mapping
KW  - Estimation
KW  - Planning
KW  - Sparse matrices
KW  - Gaussian processes
DO  - 10.1109/ICRA.2018.8461077
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Continuous-time trajectories are useful for reasoning about robot motion in a wide range of tasks. Sparse Gaussian processes (GPs) can be used as a non-parametric representation for trajectory distributions that enables fast trajectory optimization by sparse GP regression. However, most previous approaches that utilize sparse GPs for trajectory optimization are limited by the fact that the robot state is represented in vector space. In this paper, we first extend previous works to consider the state on general matrix Lie groups by applying a constant-velocity prior and defining locally linear GPs. Next, we discuss how sparse GPs on Lie groups provide a unified continuous-time framework for trajectory optimization for solving a number of robotics problems including state estimation and motion planning. Finally, we demonstrate and evaluate our approach on several different estimation and motion planning tasks with both synthetic and real-world experiments.
ER  - 

TY  - CONF
TI  - Complexity Analysis and Efficient Measurement Selection Primitives for High-Rate Graph SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6505
EP  - 6512
AU  - K. M. Frey
AU  - T. J. Steiner
AU  - J. P. How
PY  - 2018
KW  - computational complexity
KW  - graph theory
KW  - iterative methods
KW  - Newton method
KW  - optimisation
KW  - SLAM (robots)
KW  - complexity analysis
KW  - globally-efficient structure
KW  - favorable global structures
KW  - Gauss-Newton iteration
KW  - factorization step
KW  - primary computational bottleneck
KW  - graph structure
KW  - existing analytic gap
KW  - quantitative metric called elimination complexity
KW  - significant computation reductions
KW  - measurement decimation
KW  - simple heuristics
KW  - aggressive pruning
KW  - significant computational savings
KW  - structurally-naïve techniques
KW  - global level
KW  - edge count
KW  - SLAM graph
KW  - graph-based SLAM
KW  - high-rate graph
KW  - efficient measurement selection primitives
KW  - Simultaneous localization and mapping
KW  - Complexity theory
KW  - Optimization
KW  - Sparse matrices
KW  - Extraterrestrial measurements
KW  - Linear algebra
DO  - 10.1109/ICRA.2018.8460708
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Sparsity has been widely recognized as crucial for efficient optimization in graph-based SLAM. Because the sparsity and structure of the SLAM graph reflect the set of incorporated measurements, many methods for sparsification have been proposed in hopes of reducing computation. These methods often focus narrowly on reducing edge count without regard for structure at a global level. Such structurally-naïve techniques can fail to produce significant computational savings, even after aggressive pruning. In contrast, simple heuristics such as measurement decimation and keyframing are known empirically to produce significant computation reductions. To demonstrate why, we propose a quantitative metric called elimination complexity (EC) that bridges the existing analytic gap between graph structure and computation. EC quantifies the complexity of the primary computational bottleneck: the factorization step of a Gauss-Newton iteration. Using this metric, we show rigorously that decimation and keyframing impose favorable global structures and therefore achieve computation reductions on the order of r2/9 and r3, respectively, where r is the pruning rate. We additionally present numerical results showing EC provides a good approximation of computation in both batch and incremental (iSAM2) optimization and demonstrate that pruning methods promoting globally-efficient structure outperform those that do not.
ER  - 

TY  - CONF
TI  - Dense Planar-Inertial SLAM with Structural Constraints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6521
EP  - 6528
AU  - M. Hsiao
AU  - E. Westman
AU  - M. Kaess
PY  - 2018
KW  - distance measurement
KW  - image reconstruction
KW  - least squares approximations
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - dense visual odometry estimation
KW  - planar measurements
KW  - SLAM framework
KW  - IMU biases
KW  - planar landmarks
KW  - incremental smoothing
KW  - Bayes Tree
KW  - IMU data
KW  - visual information
KW  - modeling planes
KW  - IMU states
KW  - reconstruction results
KW  - SLAM algorithms
KW  - structural constraints
KW  - DPI-SLAM system
KW  - planar-inertial SLAM system
KW  - novel dense planar-inertial SLAM
KW  - dense 3D models
KW  - indoor environments
KW  - hand-held RGB-D sensor
KW  - inertial measurement unit
KW  - preinte-grated IMU measurements
KW  - factor graph
KW  - incremental mapping
KW  - probabilistic global optimization
KW  - Simultaneous localization and mapping
KW  - Optimization
KW  - Three-dimensional displays
KW  - Real-time systems
KW  - Estimation
KW  - Visualization
DO  - 10.1109/ICRA.2018.8461094
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we develop a novel dense planar-inertial SLAM (DPI-SLAM) system to reconstruct dense 3D models of large indoor environments using a hand-held RGB-D sensor and an inertial measurement unit (IMU). The preinte-grated IMU measurements are loosely-coupled with the dense visual odometry (VO) estimation and tightly-coupled with the planar measurements in a full SLAM framework. The poses, velocities, and IMU biases are optimized together with the planar landmarks in a global factor graph using incremental smoothing and mapping with the Bayes Tree (iSAM2). With odometry estimation using both RGB-D and IMU data, our system can keep track of the poses of the sensors even without sufficient planes or visual information (e.g. textureless walls) temporarily. Modeling planes and IMU states in the fully probabilistic global optimization reduces the drift that distorts the reconstruction results of other SLAM algorithms. Moreover, structural constraints between nearby planes (e.g. right angles) are added into the DPI-SLAM system, which further recovers the drift and distortion. We test our DPI-SLAM on large indoor datasets and demonstrate its state-of-the-art performance as the first planar-inertial SLAM system.
ER  - 

TY  - CONF
TI  - Radiation Source Localization in GPS-Denied Environments Using Aerial Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6537
EP  - 6544
AU  - F. Mascarich
AU  - T. Wilson
AU  - C. Papachristos
AU  - K. Alexis
PY  - 2018
KW  - gamma-ray detection
KW  - Global Positioning System
KW  - mobile robots
KW  - photomultipliers
KW  - radioactive sources
KW  - radioactivity measurement
KW  - solid scintillation detectors
KW  - radiation measurements
KW  - radioactive source localization
KW  - radiation mapping
KW  - thallium-doped cesium iodide scintillator
KW  - indoor GPS-denied environments
KW  - Cesium-137 radiation source
KW  - GPS-denied localization
KW  - visual-inertial localization
KW  - autonomous nuclear radiation source localization
KW  - aerial robot
KW  - Scintillators
KW  - Calibration
KW  - Robot sensing systems
KW  - Detectors
KW  - Unmanned aerial vehicles
KW  - Radiation detectors
DO  - 10.1109/ICRA.2018.8460760
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper details the system and methods developed to enable autonomous nuclear radiation source localization and mapping using aerial robots in GPS-denied environments. A Thallium-doped Cesium Iodide (CsI(Tl)) scintillator and a Silicon Photomultiplier are combined with custom-built electronics for counting and spectroscopy, and the provided radiation measurements are pose-annotated using visual-inertial localization enabling autonomous operation in GPS-denied environments. Provided this capability, a strategy for radioactive source localization, as well as active source search path planning was developed. The proposed method is motivated and accounts for the limited endurance of the vehicle, which entails a very small amount of dwell points, and the fact that GPS-denied localization implies varying uncertainty of the robot's position estimate. The complete system is evaluated in multiple experimental studies using a small aerial robot and a Cesium-137 radiation source. As shown, accurate radioactive source localization is achieved, enabling efficient radiation mapping of indoor GPS-denied environments.
ER  - 

TY  - CONF
TI  - LineDrone Technology: Landing an Unmanned Aerial Vehicle on a Power Line
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6545
EP  - 6552
AU  - F. Mirallès
AU  - P. Hamelin
AU  - G. Lambert
AU  - S. Lavoie
AU  - N. Pouliot
AU  - M. Montfrond
AU  - S. Montambault
PY  - 2018
KW  - aircraft landing guidance
KW  - autonomous aerial vehicles
KW  - cameras
KW  - electrical maintenance
KW  - helicopters
KW  - inspection
KW  - optical radar
KW  - power overhead lines
KW  - remotely operated vehicles
KW  - robot vision
KW  - sensor fusion
KW  - LineDrone Technology
KW  - unmanned aerial vehicle landing
KW  - semiautomatic landing
KW  - vehicle onboard vision system
KW  - monocular camera
KW  - lidar
KW  - nondestructive testing
KW  - multirotor unmanned aerial vehicle capable
KW  - power transmission lines
KW  - landing assistance
KW  - Cameras
KW  - Payloads
KW  - Unmanned aerial vehicles
KW  - Inspection
KW  - Laser radar
KW  - Task analysis
KW  - Machine vision
DO  - 10.1109/ICRA.2018.8461250
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the design of a multirotor unmanned aerial vehicle (UAV) capable of landing semiautomatically on a power line while carrying a payload. The vehicle then rolls along the line to perform an inspection. Special attention is given to the vehicle's onboard vision system, which consists of a monocular camera and LiDAR used together to compute the pose of the vehicle relative to the power line. Landing assistance is provided to the pilot by a position-based visual controller that aligns and keeps the vehicle centered along the power line. The pilot remains in control of vertical and longitudinal movement during descent. The proposed approach was tested on a full-scale test line and shows promise for future applications of high value to the electric industry such as non-destructive testing of power transmission lines.
ER  - 

TY  - CONF
TI  - Direction Controlled Descent of Samara Autorotating Wings (SAW) with N-Wings * Research supported by the SUTD-MIT International Design Centre (IDC) and by the Temasek Laboratories Defence Innovation Research Programme (DIRP) IGDSP15020141.
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6553
EP  - 6559
AU  - S. K. Hla Win
AU  - T. H. Goh
AU  - J. E. Low
AU  - D. S. Bin Shaiful
AU  - L. T. Soe Win
AU  - G. S. Soh
AU  - S. Foong
PY  - 2018
KW  - aerospace components
KW  - gyroscopes
KW  - mechanical stability
KW  - numerical analysis
KW  - position control
KW  - wind tunnels
KW  - direction controlled descent
KW  - spinning wing
KW  - direction controllability
KW  - control schemes
KW  - conical spiral autorotation trajectory
KW  - gyroscopic stability
KW  - maple trees
KW  - translational motion
KW  - numerical simulations
KW  - multiwing SAW prototype
KW  - wind-tunnel
KW  - samara autorotating wings
KW  - ball joint
KW  - Surface acoustic waves
KW  - Blades
KW  - Prototypes
KW  - Rotors
KW  - Mathematical model
KW  - Solid modeling
KW  - Stability analysis
DO  - 10.1109/ICRA.2018.8463145
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The seeds of Maple trees (Samara) use autorotation as a unique mechanism to disperse their seeds. By exploiting gyroscopic stability of a spinning wing, the Samara is able to cover large horizontal distance despite having no form of propulsion. We applied and adapted this natural ability in our novel concept, the Samara Autorotating Wings (SAW), and extended its stability and direction controllability by generalizing the mechanism to incorporate designs with more than 1 wing. By conceiving cyclic control, the translational motion of autorotation is regulated. A nonlinear model of SAW with n wings is derived and control schemes developed to control the translational position during autorotation. Numerical simulations were performed to investigate the performance of the multi-wing SAW prototypes to track a conical spiral autorotation trajectory. Direct experiments were conducted in a vertical wind-tunnel through a special ball joint that allows z-axis translation and all three rotational degrees of freedom. Finally, free-fall drop tests are used to verify the directional controllability and performance of SAW.
ER  - 

TY  - CONF
TI  - Pseudo-bearing Measurements for Improved Localization of Radio Sources with Multirotor UAVs
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6560
EP  - 6565
AU  - L. Dressel
AU  - M. J. Kochenderfer
PY  - 2018
KW  - autonomous aerial vehicles
KW  - directive antennas
KW  - helicopters
KW  - mobile radio
KW  - mobile robots
KW  - omnidirectional antennas
KW  - radionavigation
KW  - pseudobearing measurements
KW  - radio frequency sources
KW  - RF source
KW  - directional antenna
KW  - omnidirectional antenna
KW  - antenna theory
KW  - ground tests
KW  - multirotor UAVs
KW  - radio sources localization
KW  - bearing-like measurements
KW  - unmanned aerial vehicles
KW  - Antenna measurements
KW  - Directional antennas
KW  - Gain
KW  - Radio frequency
KW  - Extraterrestrial measurements
KW  - Rotation measurement
DO  - 10.1109/ICRA.2018.8460734
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Localizing radio frequency (RF) sources is an important application for unmanned aerial vehicles (UAVs), Localization is often carried out by estimating bearing to an RF source, which can be achieved by rotating a directional antenna in place. Multirotor UAVs are well-suited for this sensing modality because they can efficiently rotate in place. However, a full rotation from a single location is needed to account for scale factors affecting the directional antenna's measurements. Although easy to perform, these rotations tend to be slow and delay localization. In this paper, we equip a multirotor UAV with a directional antenna and an omnidirectional antenna. The omnidirectional antenna serves to normalize measurements made by the directional antenna, yielding “pseudo-bearing” measurements. These bearing-like measurements are less informative than bearing measurements but do not require a full rotation, leading to more measurements and faster localization. We validate the normalization with antenna theory and ground tests. Claims of improved localization are validated with simulations and flight tests on a multirotor UAV. Our setup significantly reduces localization time compared to a multirotor UAV equipped with only a directional antenna.
ER  - 

TY  - CONF
TI  - Onboard State Dependent LQR for Agile Quadrotors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6566
EP  - 6572
AU  - P. Foehn
AU  - D. Scaramuzza
PY  - 2018
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - helicopters
KW  - linear quadratic control
KW  - mobile robots
KW  - state estimation
KW  - time-varying systems
KW  - trajectory control
KW  - onboard state dependent LQR
KW  - agile quadrotors
KW  - quadrotor control
KW  - multiple cascaded subproblems
KW  - rotational dynamics
KW  - translational dynamics
KW  - cascaded attitude controller
KW  - attitude dynamics
KW  - robustness
KW  - LQR controller
KW  - rotational states
KW  - translational states
KW  - time-varying system dynamics
KW  - control parameters
KW  - linearization
KW  - Vehicle dynamics
KW  - Acceleration
KW  - Trajectory
KW  - Quaternions
KW  - Attitude control
KW  - Visualization
KW  - Regulators
DO  - 10.1109/ICRA.2018.8460885
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - State-of-the-art approaches in quadrotor control split the problem into multiple cascaded subproblems, exploiting the different time scales of the rotational and translational dynamics. They calculate a desired acceleration as input for a cascaded attitude controller but omit the attitude dynamics. These approaches use limits on the desired acceleration to maintain feasibility and robustness through the control cascade. We propose an implementation of an LQR controller, which: (I) is linearized depending on the quadrotor's state; (II) unifies the control of rotational and translational states; (III) handles time-varying system dynamics and control parameters. Our implementation is efficient enough to compute the full linearization and solution of the LQR at a minimum of 10 Hz on the vehicle using a common ARM processor. We show four successful experiments: (I) controlling at hover state with large disturbances; (II) tracking along a trajectory; (III) tracking along an infeasible trajectory; (IV) tracking along a trajectory with disturbances. All the experiments were done using only onboard visual inertial state estimation and LQR computation. To the best of our knowledge, this is the first implementation and evaluation of a state-dependent LQR capable of onboard computation while providing this amount of versatility and performance.
ER  - 

TY  - CONF
TI  - Autonomous Fixed-Wing Aerobatics: From Theory to Flight
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6573
EP  - 6580
AU  - E. Bulka
AU  - M. Nahon
PY  - 2018
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - Matlab
KW  - microcontrollers
KW  - mobile robots
KW  - position control
KW  - autonomous fixed-wing aerobatics
KW  - unmanned aerial vehicles
KW  - conventional fixed-wing aircraft
KW  - hardware-in-the-loop simulator
KW  - Pixhawk microcontroller
KW  - Xplane physics engine
KW  - HIL simulator
KW  - flight platform
KW  - agile fixed-wing UAV
KW  - rotorcraft
KW  - orientation time histories
KW  - position time histories
KW  - Matlab-Simulink high-fidelity simulation
KW  - Aircraft
KW  - Aerodynamics
KW  - Atmospheric modeling
KW  - Control systems
KW  - Mathematical model
KW  - Aerospace control
KW  - Propellers
DO  - 10.1109/ICRA.2018.8460610
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Unmanned aerial vehicles (UAVs) are increasingly being proposed for a wide range of applications. A promising new class of these vehicles, known as agile fixed-wing UAV s, is intended to bridge the gap between conventional fixed-wing aircraft, which can cover long distances efficiently, and rotorcraft, which are typically very maneuverable. This paper addresses the implementation of a controller for agile UAVs, beginning with a hardware-in-the-loop (HIL) simulator, followed by testing on a real platform, both implemented on the Pixhawk microcontroller. We replace the Xplane physics engine used in the standard Pixhawk HIL with our own in-house Matlab/Simulink high-fidelity simulation of an agile UA V. The HIL simulator is found to provide substantial advantages in the transition from pure simulation to experimental testing. Once the controller is integrated into the flight platform, flight tests are conducted, and the results of those tests are compared to those from the HIL simulation and those obtained from the pure simulation environment, for maneuvers including hover, aggressive turnaround, knife-edge, and rolling Harrier. The desired position and orientation time histories were successfully tracked with the proposed implementation, demonstrating the impressive autonomous maneuverability that can be achieved by this type of aircraft.
ER  - 

TY  - CONF
TI  - Adaptive Attitude Control for a Tail-Sitter UAV with Single Thrust-Vectored Propeller
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6581
EP  - 6586
AU  - W. Wang
AU  - J. Zhu
AU  - M. Kuang
AU  - X. Zhu
PY  - 2018
KW  - adaptive control
KW  - aerodynamics
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - least squares approximations
KW  - Lyapunov methods
KW  - propellers
KW  - stability
KW  - unified controller
KW  - attitude dynamics model
KW  - flight regimes
KW  - Lyapunov stability theory
KW  - control challenges
KW  - rotary wing UAVs
KW  - fixed wing
KW  - tail-sitter unmanned aerial vehicles
KW  - tail-sitter UAV
KW  - adaptive attitude control
KW  - control scheme
KW  - adaptive controller
KW  - quaternion attitude description
KW  - full-regime aerodynamics model
KW  - thrust vectoring model
KW  - single thrust-vectored propeller
KW  - cumbersome controller switchings
KW  - transition flights
KW  - Propellers
KW  - Aerodynamics
KW  - Atmospheric modeling
KW  - Attitude control
KW  - Aircraft
KW  - Mathematical model
KW  - Quaternions
DO  - 10.1109/ICRA.2018.8463158
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Tail-sitter unmanned aerial vehicles (UAVs) have gained extensive popularity in recent years due to their inherent advantages of both fixed wing and rotary wing UAVs. However, these advantages are accompanied with control challenges because of two different flight regimes and drastically changing dynamics during transition flights. This paper focuses on the design of a unified controller free from cumbersome controller switchings and applicable in all attitude range for a tail-sitter with single thrust-vectored propeller. To achieve this, both thrust vectoring model and full-regime aerodynamics model are built first, after which a complete attitude dynamics model of the tail-sitter is established utilizing the quaternion attitude description to avoid the singularity problem. An adaptive controller is then derived based on a simplified model using the Lyapunov stability theory with unknown system parameters identified online by forgetting factor recursive least square (FF-RLS) method. Flight experiments are conducted to demonstrate the feasibility and effectiveness of the proposed control scheme.
ER  - 

TY  - CONF
TI  - Online Aerodynamic Model Identification on Small Fixed-Wing UAVs with Uncertain Flight Data
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6587
EP  - 6592
AU  - P. Vaiopoulos
AU  - G. Zogopoulos-Papaliakos
AU  - K. J. Kyriakopoulos
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - least squares approximations
KW  - Monte Carlo methods
KW  - real-time systems
KW  - sensors
KW  - wind tunnels
KW  - small fixed-wing unmanned aerial vehicles
KW  - total least squares estimation
KW  - ordinary least squares method
KW  - low-cost sensor system
KW  - insufficient system excitation
KW  - variable forgetting factor
KW  - Monte Carlo approach
KW  - compound aerodynamic variables
KW  - uncertainty estimation
KW  - real-time schemes
KW  - wind-tunnel experiments
KW  - real-time estimation
KW  - uncertain flight data
KW  - online aerodynamic model identification
KW  - Aerodynamics
KW  - Atmospheric modeling
KW  - Estimation
KW  - Uncertainty
KW  - Real-time systems
KW  - Aircraft
KW  - Adaptation models
DO  - 10.1109/ICRA.2018.8460585
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper focuses on real-time estimation of the aerodynamic model parameters of small-scale fixed wing Unmanned Aerial Vehicles (UAVs) without the aid of wind-tunnel experiments, using exclusively flight data. The key tool of the following analysis centers around the principles of Total Least Squares estimation. Contrary to Ordinary Least Squares, this method accounts for errors in both explanatory data and variables to-be-explained. This is a highly desirable property for UAVs equipped with low-cost sensor systems. The proposed implementation combines both batch and real-time schemes, while deals efficiently with the problem of Insufficient System Excitation. Online adaptation to model changes is performed by applying a Variable Forgetting Factor to the estimation data. Finally, a Monte Carlo approach is developed for uncertainty estimation regarding compound aerodynamic variables.
ER  - 

TY  - CONF
TI  - Towards X-Ray Medical Imaging with Robots in the Open: Safety Without Compromising Performances
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6604
EP  - 6610
AU  - L. Joseph
AU  - V. Padois
AU  - G. Morel
PY  - 2018
KW  - collision avoidance
KW  - control engineering computing
KW  - end effectors
KW  - linear quadratic control
KW  - manipulator dynamics
KW  - medical image processing
KW  - medical robotics
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - control solution
KW  - robotic manipulator
KW  - generic safe controller
KW  - Linear Quadratic Problem formulation
KW  - unified energetic formulation
KW  - kinetic energy
KW  - redundant Kuka LWR4+ robot
KW  - X-ray medical imaging
KW  - end-effector
KW  - Robots
KW  - Task analysis
KW  - Torque
KW  - Safety
KW  - Collision avoidance
KW  - X-ray imaging
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2018.8460794
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, a control solution featuring an energetic constraint is developed to improve the safety of a robotic manipulator sharing its workspace with humans. This general control structure, exploits a generic safe controller that ensures the respect of multiple constraints thanks to a Linear Quadratic Problem formulation. With a unified energetic formulation, the controller allows to explicitly limit both the kinetic energy when moving and the wrench applied to the environment in case of contact with an unexpected obstacle. This control approach is experimented on a redundant Kuka LWR4+ robot which end-effector shall precisely point toward a given location while following a trajectory.
ER  - 

TY  - CONF
TI  - Safety-Enhanced Human-Robot Interaction Control of Redundant Robot for Teleoperated Minimally Invasive Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6611
EP  - 6616
AU  - H. Su
AU  - J. Sandoval
AU  - M. Makhdoomi
AU  - G. Ferrigno
AU  - E. De Momi
PY  - 2018
KW  - adaptive control
KW  - fuzzy control
KW  - human-robot interaction
KW  - manipulators
KW  - medical robotics
KW  - surgery
KW  - telerobotics
KW  - robot manipulator
KW  - human-robot interaction
KW  - teleoperated minimally invasive surgery
KW  - surgical task execution
KW  - virtual surgical tasks
KW  - compliant null space motion
KW  - tele-operated MIS tasks
KW  - implemented impedance control
KW  - safety-enhanced compliant behavior
KW  - teleoperation control
KW  - redundant robot
KW  - safety-enhanced human-robot interaction control
KW  - Task analysis
KW  - Null space
KW  - Manipulators
KW  - Human-robot interaction
KW  - Torque
KW  - Surgery
DO  - 10.1109/ICRA.2018.8463148
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, a teleoperation control of a 7-DoF robot manipulator for Minimally Invasive Surgery (MIS), which guarantees a safety-enhanced compliant behavior in the null space, is described. The redundancy of the manipulator is exploited to provide a flexible workspace for nurses or other staff (assisting physicians, patient support). The issue with safety and accurate surgical task execution may arise in the presence of human-robot interaction. Based on the implemented impedance control of tele-operated MIS tasks, a safety enhanced constraint is applied on the compliant null space motion. At the same time, the control approach integrates an adaptive fuzzy compensator to guarantee the accuracy of the surgical tasks during the uncertain human-robot interaction. The performance of the proposed algorithm is verified with virtual surgical tasks. The results showed that the compliant null space motion is constrained in a safe area, and also that the accuracy of tool tip is improved, providing a flexible and safe collaborative behavior in the null space for human-robot interaction during surgical tasks.
ER  - 

TY  - CONF
TI  - Three-Dimensional Surgical Needle Localization and Tracking Using Stereo Endoscopic Image Streams
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6617
EP  - 6624
AU  - O. Özgüner
AU  - R. Hao
AU  - R. C. Jackson
AU  - T. Shkurti
AU  - W. Newman
AU  - M. C. Cavusoglu
PY  - 2018
KW  - Bayes methods
KW  - biomedical optical imaging
KW  - endoscopes
KW  - medical image processing
KW  - medical robotics
KW  - rendering (computer graphics)
KW  - robot kinematics
KW  - 3D surgical needle localization
KW  - stereoendoscopic image streams
KW  - robot kinematics
KW  - computer vision techniques
KW  - da Vinci® Surgical Robotic System
KW  - stereo endoscopic camera images
KW  - three-dimensional tracking
KW  - da Vinci ® robot endoscope
KW  - Needles
KW  - Robots
KW  - Task analysis
KW  - Surgery
KW  - Image segmentation
KW  - Bayes methods
KW  - Atmospheric measurements
DO  - 10.1109/ICRA.2018.8460867
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents algorithms for three-dimensional tracking of surgical needles using the stereo endoscopic camera images obtained from the da Vinci® Surgical Robotic System. The proposed method employs Bayesian state estimation, computer vision techniques, and robot kinematics. A virtual needle rendering procedure is implemented to create simulated images of the surgical needle under the da Vinci ® robot endoscope, which makes it possible to measure the similarity between the rendered needle image and the real needle. A particle filter algorithm using the mentioned techniques is then used for tracking the surgical needle. The performance of the tracking is experimentally evaluated using an actual da Vinci® surgical robotic system and quantitatively validated in a ROS/Gazebo simulation thereof.
ER  - 

TY  - CONF
TI  - Robotic Assistance-as-Needed for Enhanced Visuomotor Learning in Surgical Robotics Training: An Experimental Study
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6631
EP  - 6636
AU  - N. Enayati
AU  - A. M. Okamura
AU  - A. Mariani
AU  - E. Pellegrini
AU  - M. M. Coad
AU  - G. Ferrigno
AU  - E. De Momi
PY  - 2018
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - surgery
KW  - telerobotics
KW  - visuomotor learning
KW  - complex visuomotor training
KW  - da Vinci Research Kit surgical console
KW  - surgical teleoperated robots
KW  - surgical practice
KW  - hands-on training
KW  - surgical robotics training
KW  - Task analysis
KW  - Training
KW  - Robot kinematics
KW  - Wires
KW  - Tools
KW  - Surgery
DO  - 10.1109/ICRA.2018.8463168
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Hands-on training is an indispensable part of surgical practice. As the tools used in the operating room become more intricate, the demand for efficient training methods increases. This work proposes a robotic assistance-as-needed method for training with surgical teleoperated robots. The method adapts the intensity of the assistance according to the trainee's current and past performance while gradually increasing the level of control of the trainee as the training progresses. The work includes an experiment comprising 160 acquisition sessions from 16 novice subjects performing a bimanual teleoperated exercise with a da Vinci Research Kit surgical console. Results capture the subtleties in the task's learning curve with and without robotic assistance and hint at the potential of robotic assistance for complex visuomotor training. Although robotic assistance for motor learning has received mixed results that range from beneficial to detrimental effects, this study shows such assistance may increase the rate of learning of certain skills in complex motor tasks.
ER  - 

TY  - CONF
TI  - Semi-Autonomous Laparoscopic Robotic Electro-Surgery with a Novel 3D Endoscope
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6637
EP  - 6644
AU  - H. N. D. Le
AU  - J. D. Opfermann
AU  - M. Kam
AU  - S. Raghunathan
AU  - H. Saeidi
AU  - S. Leonard
AU  - J. U. Kang
AU  - A. Krieger
PY  - 2018
KW  - biomedical optical imaging
KW  - endoscopes
KW  - kidney
KW  - medical image processing
KW  - medical robotics
KW  - surgery
KW  - 3D endoscope
KW  - robotic surgical system
KW  - cutting depth
KW  - freedom electro-surgical tool
KW  - robotic system
KW  - imaging system
KW  - laparoscopic camera
KW  - open loop control scheme
KW  - porcine cadaver kidney
KW  - robotic laparoscopic surgery system
KW  - semiautonomous laparoscopic robotic electro-surgery
KW  - Robots
KW  - Imaging
KW  - Surgery
KW  - Three-dimensional displays
KW  - Laparoscopes
KW  - Kidney
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461060
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper reports a robotic laparoscopic surgery system performing electro-surgery on porcine cadaver kidney, and evaluates its accuracy in an open loop control scheme to conduct targeting and cutting tasks guided by a novel 3D endoscope. We describe the design and integration of the novel laparoscopic imaging system that is capable of reconstructing the surgical field using structured light. A targeting task is first performed to determine the average positioning error of the system as guided by the laparoscopic camera. The imaging system is then used to reconstruct the surface of a porcine cadaver kidney, and generate a cutting trajectory with consistent depth. The paper concludes by using the robotic system in open loop control to cut this trajectory using a multi degree of freedom electro-surgical tool. It is demonstrated that for a cutting depth of 3 mm, the robotic surgical system follows the trajectory with an average depth of 2.44 mm and standard deviation of 0.34 mm. The average positional accuracy of the system was 2.74±0.99 mm.
ER  - 

TY  - CONF
TI  - An Ultrasonic Bone Cutting Tool for the da Vinci Research Kit
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6645
EP  - 6650
AU  - A. Gordon
AU  - T. Looi
AU  - J. Drake
AU  - C. R. Forrest
PY  - 2018
KW  - biomedical transducers
KW  - biomedical ultrasonics
KW  - bone
KW  - finite element analysis
KW  - genetic algorithms
KW  - medical robotics
KW  - surgery
KW  - ultrasonic transducers
KW  - finite element software
KW  - cutting phantom
KW  - research kit system
KW  - ultrasonic system
KW  - multiobjective genetic algorithm
KW  - ultrasonic transducer
KW  - minimally invasive ultrasonic bone cutting tool
KW  - da Vinci research kit
KW  - Acoustics
KW  - Impedance
KW  - Finite element analysis
KW  - Transducers
KW  - Bones
KW  - Surgery
KW  - Cutting tools
DO  - 10.1109/ICRA.2018.8460797
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a minimally invasive ultrasonic bone cutting tool designed for the da Vinci® research kit (dVRK). An ultrasonic transducer is modelled using finite element software, and correlated with testing results using an impedance analyzer. A multi-objective genetic algorithm is then used to design and analyze the remaining components of the ultrasonic system, in order to maximize system performance. The system is fabricated and mounted to the da Vinci® research kit system and tested on a cutting phantom.
ER  - 

TY  - CONF
TI  - Fast and Reliable Autonomous Surgical Debridement with Cable-Driven Robots Using a Two-Phase Calibration Procedure
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6651
EP  - 6658
AU  - D. Seita
AU  - S. Krishnan
AU  - R. Fox
AU  - S. McKinley
AU  - J. Canny
AU  - K. Goldberg
PY  - 2018
KW  - biological tissues
KW  - calibration
KW  - cameras
KW  - diseases
KW  - edge detection
KW  - end effectors
KW  - endoscopes
KW  - medical robotics
KW  - neural nets
KW  - position control
KW  - robot vision
KW  - surgery
KW  - telerobotics
KW  - fragment phantoms
KW  - cable-driven robots
KW  - diseased tissue fragments
KW  - da Vinci Research Kit
KW  - cable-driven systems
KW  - two-phase coarse-to-fine calibration method
KW  - red calibration marker
KW  - end effector
KW  - open-loop trajectories
KW  - camera pixels
KW  - internal robot end-effector configurations
KW  - robotic surgical assistants
KW  - deep neural network
KW  - end-effector position
KW  - random forest
KW  - two-phase calibration procedure
KW  - surgical debridement
KW  - fine transformation bias
KW  - residual compensation bias
KW  - coarse transformation bias
KW  - time 7.3 s to 15.8 s
KW  - size 4.55 mm
KW  - size 2.14 mm
KW  - size 1.08 mm
KW  - Calibration
KW  - Cameras
KW  - Grippers
KW  - Robot kinematics
KW  - Robot vision systems
KW  - Tools
DO  - 10.1109/ICRA.2018.8460583
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Automating precision subtasks such as debridement (removing dead or diseased tissue fragments) with Robotic Surgical Assistants (RSAs) such as the da Vinci Research Kit (dVRK) is challenging due to inherent nOnlinearities in cable-driven systems. We propose and evaluate a novel two-phase coarse-to-fine calibration method. In Phase I (coarse), we place a red calibration marker on the end effector and let it randomly move through a set of open-loop trajectories to obtain a large sample set of camera pixels and internal robot end-effector configurations. This coarse data is then used to train a Deep Neural Network (DNN) to learn the coarse transformation bias. In Phase II (fine), the bias from Phase I is applied to move the end -effector toward a small set of specific target points on a printed sheet. For each target, a human operator manually adjusts the end -effector position by direct contact (not through teleoperation) and the residual compensation bias is recorded. This fine data is then used to train a Random Forest (RF) to learn the fine transformation bias. Subsequent experiments suggest that without calibration, position errors average 4.55mm. Phase I can reduce average error to 2.14mm and the combination of Phase I and Phase II can reduces average error to 1.08mm. We apply these results to debridement of raisins and pumpkin seeds as fragment phantoms. Using an endoscopic stereo camera with standard edge detection, experiments with 120 trials achieved average success rates of 94.5 %, exceeding prior results with much larger fragments (89.4%) and achieving a speedup of 2.1x, decreasing time per fragment from 15.8 seconds to 7.3 seconds. Source code, data, and videos are available at https://sites.google.com/view/calib-icra/.
ER  - 


TY  - CONF
TI  - Distributed Real Time Control of Multiple UAVs in Adversarial Environment: Algorithm and Flight Testing Results
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6659
EP  - 6664
AU  - M. Abdelkader
AU  - Y. Lu
AU  - H. Jaleel
AU  - J. S. Shamma
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - game theory
KW  - helicopters
KW  - mobile robots
KW  - multi-robot systems
KW  - optimal control
KW  - path planning
KW  - trajectory control
KW  - multiple quadrotors
KW  - flag game
KW  - distributed trajectory planning algorithm
KW  - WiFi based communication infrastructure
KW  - autopilot modules
KW  - low power computing modules
KW  - suboptimal control action
KW  - adversarial game
KW  - Gazebo robot simulator
KW  - multiple UAVs
KW  - quadrotor platform
KW  - flight testing
KW  - robot operating system
KW  - ROS
KW  - Games
KW  - Software algorithms
KW  - Software
KW  - Hardware
KW  - Real-time systems
KW  - Testing
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460866
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a complete design and implementation of a system that consists of multiple quadrotors playing capture the flag game. Our main contributions in this work include a custom built quadrotor platform, an efficient implementation of a distributed trajectory planning algorithm, and a WiFi based communication infrastructure. In our design, we equip the quadrotors with autopilot modules for low level control. Moreover, we install low power computing modules for implementing the distributed trajectory planning algorithm online. Furthermore, we develop a communication infrastructure to enable coordination among the quadrotors, which is required for computing a suboptimal control action in real time. The interactions among all the hardware and software components are managed at a higher level by Robot Operating System (ROS). To test the performance of the system, we select a motivating setup of capture the flag game, which is an adversarial game played between two teams of agents called attack and defense. The system is initially simulated in the Gazebo robot simulator with software in the loop. Finally, the complete system is tested and the flight testing results are presented.
ER  - 

TY  - CONF
TI  - Collaborative 6DoF Relative Pose Estimation for Two UAVs with Overlapping Fields of View
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6688
EP  - 6693
AU  - M. Karrer
AU  - M. Agarwal
AU  - M. Kamel
AU  - R. Siegwart
AU  - M. Chli
PY  - 2018
KW  - aerospace computing
KW  - autonomous aerial vehicles
KW  - groupware
KW  - image fusion
KW  - Kalman filters
KW  - multi-robot systems
KW  - nonlinear filters
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - monocular-inertial odometry
KW  - Extended Kalman Filter
KW  - collaborative scene estimation
KW  - monocular camera
KW  - variable-baseline stereo rig
KW  - inertial sensor
KW  - Unmanned Aerial Vehicles
KW  - collaborative robot operation
KW  - collaborative 6DoF relative pose estimation
KW  - UAV
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Collaboration
KW  - Estimation
KW  - Unmanned aerial vehicles
DO  - 10.1109/ICRA.2018.8461143
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Driven by the promise of leveraging the benefits of collaborative robot operation, this paper presents an approach to estimate the relative transformation between two small Unmanned Aerial Vehicles (UAVs), each equipped with a single camera and an inertial sensor, comprising the first step of any meaningful collaboration. Formation flying and collaborative object manipulation are some of the few tasks that the proposed work has direct applications on, while forming a variable-baseline stereo rig using two UAVs carrying a monocular camera each promises unprecedented effectiveness in collaborative scene estimation. Assuming an overlap in the UAVs' fields of view, in the proposed framework, each UAV runs monocular-inertial odometry onboard, while an Extended Kalman Filter fuses the UAVs' estimates and common image measurements to estimate the metrically scaled relative transformation between them, in realtime. Decoupling the direction of the baseline between the cameras of the two UAVs from its magnitude, this work enables consistent and robust estimation of the uncertainty of the relative pose estimation. Our evaluation on both on simulated data and benchmarking datasets consisting of real aerial data, reveals the power of the proposed methodology in a variety of scenarios. Video - https://youtu.be/AmkkaXa2601.
ER  - 

TY  - CONF
TI  - BFM: a Scalable and Resource-Aware Method for Adaptive Mission Planning of UAVs
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6702
EP  - 6707
AU  - C. Hireche
AU  - C. Dezan
AU  - J. Diguet
AU  - L. Mejias
PY  - 2018
KW  - autonomous aerial vehicles
KW  - belief networks
KW  - decision making
KW  - embedded systems
KW  - Markov processes
KW  - planning
KW  - quality of service
KW  - target tracking
KW  - diagnosis modules
KW  - Bayesian Networks
KW  - mission specifications
KW  - Markov Decision Processes
KW  - BFM model
KW  - application configurations
KW  - embedded system level
KW  - UAV level
KW  - target tracking mission
KW  - applications specifications
KW  - MDP model
KW  - embedded applications
KW  - resource-aware method
KW  - adaptive mission planning
KW  - external hazards
KW  - FMEA tables
KW  - scalable model
KW  - modular method
KW  - decision making process
KW  - UAV
KW  - internal hazards
KW  - Quality of service
KW  - Target tracking
KW  - Monitoring
KW  - Computational modeling
KW  - Sensor systems and applications
KW  - Context modeling
DO  - 10.1109/ICRA.2018.8460944
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - UAVs must continuously adapt their mission to face unexpected internal or external hazards. This paper proposes a new BFM model (Bayesian Networks built from FMEA tables for MDP). This scalable model offers a modular and comprehensive method to incorporate different types of diagnosis modules based on BN (Bayesian Networks) and FMEA table (Failure Mode and Effects Analysis) to mission specifications expressed as a MDP (Markov Decision Processes). The BFM model implements the complete decision making process that covers both the application configurations at the embedded system level and the mission planning at the UAV level. These decisions are based on the QoS (Quality of Service) of applications, the resource use and the system and sensors health. We demonstrate on a case study for a target tracking mission that the BFM model can interface hazards and applications specifications and can improve the success and quality of the mission. To the best of our knowledge, this is the first proposal of a systematic method that integrates diagnosis modules to MDP model in order to take care of the implementation of embedded applications during a mission.
ER  - 

TY  - CONF
TI  - Simultaneous Optimization of Assignments and Goal Formations for Multiple Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6708
EP  - 6715
AU  - S. Agarwal
AU  - S. Akella
PY  - 2018
KW  - approximation theory
KW  - computational complexity
KW  - graph theory
KW  - multi-robot systems
KW  - optimisation
KW  - path planning
KW  - O(n3) time complexity
KW  - optimal assignments
KW  - multiple robots
KW  - fixed goal formations
KW  - standard assignment problem
KW  - transformed problem
KW  - formation parameters
KW  - linear sum assignment problem
KW  - variable goal formation problem
KW  - location parameters
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Trajectory
KW  - Shape
KW  - Cost function
DO  - 10.1109/ICRA.2018.8460542
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents algorithms to simultaneously compute the optimal assignments and formation parameters for a team of robots from a given initial formation to a variable goal formation (where the shape of the goal formation is given, and its scale and location parameters must be optimized). We assume the n robots are identical spheres. We use the sum of squared travel distances as the objective function to be minimized, which also ensures that the trajectories are collision free. We show that this assignment with variable goal formation problem can be transformed to a linear sum assignment problem (LSAP) with pseudo costs that we establish are independent of the formation parameters. The transformed problem can then be solved using the Hungarian algorithm in O(n3) time. Thus the assignment problem with variable goal formations using this new approach has the same O(n3) time complexity as the standard assignment problem with fixed goal formations. Results from simulations on 200 and 600 robots are presented to show the algorithm is sufficiently fast for practical applications.
ER  - 

TY  - CONF
TI  - Machine Learning for Placement-Insensitive Inertial Motion Capture
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6716
EP  - 6721
AU  - X. Xiao
AU  - S. Zarar
PY  - 2018
KW  - calibration
KW  - image motion analysis
KW  - image sensors
KW  - multilayer perceptrons
KW  - sensor positions
KW  - body segments
KW  - standard deviation
KW  - calibration values
KW  - rotation matrices
KW  - inertial motion-capture systems
KW  - latency errors
KW  - motion data
KW  - sensor-displacement patterns
KW  - multilayer perceptrons
KW  - rotational transformations
KW  - kinematic algorithms
KW  - sensor movement
KW  - performance degradation
KW  - Euler angles
KW  - placement-insensitive inertial motion capture
KW  - machine learning
KW  - joint angles
KW  - sensor data
KW  - time 3.0 hour
KW  - Tracking
KW  - Robot sensing systems
KW  - Motion segmentation
KW  - Machine learning
KW  - Calibration
KW  - Kinematics
KW  - Neural networks
DO  - 10.1109/ICRA.2018.8463176
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Although existing inertial motion-capture systems work reasonably well (≤10° error in Euler angles), their accuracy suffers when sensor positions change relative to the associated body segments (±60° mean error and 120° standard deviation). We attribute this performance degradation to undermined calibration values, sensor movement latency and displacement offsets. The latter specifically leads to incongruent rotation matrices in kinematic algorithms that rely on rotational transformations. To overcome these limitations, we propose to employ machine-learning techniques. In particular, we use multi-layer perceptrons to learn sensor-displacement patterns based on 3 hours of motion data collected from 12 test subjects in the lab over 215 trials. Furthermore, to compensate for calibration and latency errors, we directly process sensor data with deep neural networks and estimate the joint angles. Based on these approaches, we demonstrate up to 69% reduction in tracking errors.
ER  - 

TY  - CONF
TI  - Optimizing Stiffness of a Novel Parallel-Actuated Robotic Shoulder Exoskeleton for a Desired Task or Workspace
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6745
EP  - 6751
AU  - J. Hunt
AU  - P. Artemiadis
AU  - H. Lee
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - feedback
KW  - medical robotics
KW  - optimisation
KW  - patient rehabilitation
KW  - robot dynamics
KW  - robot kinematics
KW  - wrist robots
KW  - analytical stiffness model
KW  - bounded nonlinear multiobjective optimization
KW  - parallel architecture
KW  - wearable hip
KW  - ankle
KW  - parallel-actuated robotic shoulder exoskeleton
KW  - sagittal plane
KW  - Shoulder
KW  - Actuators
KW  - Exoskeletons
KW  - Kinematics
KW  - End effectors
DO  - 10.1109/ICRA.2018.8463159
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The purpose of this work is to optimize the stiffness of a novel parallel-actuated robotic exoskeleton designed to offer a large workspace. This is done in an effort to help provide a solution to the issue wearable parallel actuated robots face regarding a tradeoff between stiffness and workspace. Presented in the form of a shoulder exoskeleton, the device demonstrates a new parallel architecture that can be used for wearable hip, ankle and wrist robots as well. The stiffness of the architecture is dependent on the placement of its actuated substructures. Therefore, it is desirable to place these substructures effectively so as to maximize dynamic performance for any application. In this work, an analytical stiffness model of the device is created and validated experimentally. The model is then used, along with a method of bounded nonlinear multi-objective optimization to configure the parallel actuators so as to maximize stiffness for the entire workspace. Furthermore, it is shown how to use the same technique to optimize the device for a particular task, such as lifting in the sagittal plane.
ER  - 

TY  - CONF
TI  - Adaptive Oscillator-Based Control for Active Lower-Limb Exoskeleton and its Metabolic Impact
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6752
EP  - 6758
AU  - K. Seo
AU  - K. Kim
AU  - Y. J. Park
AU  - J. Cho
AU  - J. Lee
AU  - B. Choi
AU  - B. Lim
AU  - Y. Lee
AU  - Y. Shim
PY  - 2018
KW  - adaptive control
KW  - artificial limbs
KW  - gait analysis
KW  - handicapped aids
KW  - medical robotics
KW  - muscle
KW  - patient rehabilitation
KW  - active lower-limb exoskeleton
KW  - metabolic impact
KW  - hip abduction/adduction
KW  - hip extension/flexion
KW  - knee extension/flexion joints
KW  - walking environment
KW  - adaptive oscillator-based control
KW  - electric actuators
KW  - Foot
KW  - Legged locomotion
KW  - Exoskeletons
KW  - Hip
KW  - Torque
KW  - Knee
KW  - Oscillators
DO  - 10.1109/ICRA.2018.8460841
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We developed a robotic lower-limb exoskeleton for those who have weakened muscle due to aging and experience difficulty in walking or getting up without help. The exoskeleton covering both limbs from the feet to the waist has 6 electric actuators in the hip abduction/adduction, hip extension/flexion and knee extension/flexion joints. For users with volitional motion, delivering assistance power according to their intention is a challenging task. We propose an adaptive oscillator-based controller to assist users walk in the lower-limb exoskeleton. To adapt to changes in walking speed and environment, motion command from the controller is modulated by estimate walking speed and walking environment recognized as one of the following categories: level ground, stairs up/down and slope up/down. Experimental results demonstrate the feasibility of the proposed environment recognition method and the impact of assistance on the metabolic cost of walking on level and inclined treadmills.
ER  - 

TY  - CONF
TI  - Human-Exoskeleton System Dynamics Identification Using Affordable Sensors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6759
EP  - 6765
AU  - R. Mallat
AU  - V. Bonnet
AU  - W. Huo
AU  - P. Karasinski
AU  - Y. Amirat
AU  - M. Khalil
AU  - S. Mohammed
PY  - 2018
KW  - gait analysis
KW  - Kalman filters
KW  - kinematics
KW  - medical robotics
KW  - Wii Balance Board
KW  - joint kinematics
KW  - body segment inertial parameters
KW  - human locomotor apparatus
KW  - augmented regressor matrix
KW  - ground reaction force
KW  - dynamic identification pipeline
KW  - QR visual markers
KW  - extended Kalman filter
KW  - human-exoskeleton system dynamics identification
KW  - lower limb exoskeleton
KW  - Exoskeletons
KW  - Kinematics
KW  - Solid modeling
KW  - Dynamics
KW  - Three-dimensional displays
KW  - Calibration
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8463178
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a practical method to identify body segments inertial parameters of a human-exoskeleton system using affordable and easy-to-use sensors. First, the joints and the base kinematics are estimated based on the use of an extended Kalman filter and QR visual markers. Then, joints kinematics are used in a dynamic identification pipeline together with the ground reaction force and moments collected with an affordable Wii Balance Board. The identification process is done using an augmented regressor matrix to identify at once each segment mass, center of mass 3D position and inertia tensor elements of both human locomotor apparatus and exoskeleton. The proposed method is able to accurately estimate external force and moments, with less than 6 % of normalized RMS difference in average, and is experimentally validated with a subject wearing a full lower limb exoskeleton.
ER  - 

TY  - CONF
TI  - A Locomotion Recognition System Using Depth Images
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6766
EP  - 6772
AU  - T. Yan
AU  - Y. Sun
AU  - T. Liu
AU  - C. Cheung
AU  - M. Q. Meng
PY  - 2018
KW  - artificial limbs
KW  - feature extraction
KW  - finite state machines
KW  - gait analysis
KW  - handicapped aids
KW  - intelligent robots
KW  - motion control
KW  - orthotics
KW  - robot vision
KW  - wearable robots
KW  - lower-limb assistive device
KW  - depth images
KW  - prostheses
KW  - daily living activities
KW  - intelligent controller
KW  - innovative locomotion recognition system
KW  - feature extraction subsystem
KW  - finite-state-machine based recognition subsystem
KW  - limb movements
KW  - locomotion modes
KW  - transition states
KW  - locomotion tasks
KW  - Powered lower-limb orthoses
KW  - wearable robot
KW  - Cameras
KW  - Task analysis
KW  - Image edge detection
KW  - Feature extraction
KW  - Legged locomotion
DO  - 10.1109/ICRA.2018.8460514
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Powered lower-limb orthoses and prostheses are attracting an increasing amount of attention in assisting daily living activities. To safely and naturally collaborate with human users, the key technology relies on an intelligent controller to accurately decode users' movement intention. In this work, we proposed an innovative locomotion recognition system based on depth images. Composed of a feature extraction subsystem and a finite-state-machine based recognition subsystem, the proposed approach is capable of capturing both the limb movements and the terrains right in front of the user. This makes it possible to anticipate the detection of locomotion modes, especially at transition states, thus enabling the associated wearable robot to deliver a smooth and seamless assistance. Validation experiments were implemented with nine subjects to trace a track that comprised of standing, walking, stair ascending, and stair descending, for three rounds each. The results showed that in steady state, the proposed system could recognize all four locomotion tasks with approximate 100% of accuracy. Out of 216 mode transitions, 82.4% of the intended locomotion tasks can be detected before the transition happened. Thanks to its high accuracy and promising prediction performance, the proposed locomotion recognition system is expected to significantly improve the safety as well as the effectiveness of a lower-limb assistive device.
ER  - 

TY  - CONF
TI  - The Effect of Bending Compliance on Adhesion Pressure of Hybrid Electrostatic/Gecko-Like Adhesives
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6773
EP  - 6778
AU  - B. Temple
AU  - A. Simaite
AU  - M. Spenko
PY  - 2018
KW  - adhesion
KW  - adhesives
KW  - bending
KW  - bending strength
KW  - elasticity
KW  - shear strength
KW  - substrates
KW  - surface roughness
KW  - dry switchable adhesives
KW  - compliant structures
KW  - high stored strain energy
KW  - shear adhesion pressures
KW  - contact area
KW  - bending compliance
KW  - hybrid electrostatic-gecko-like adhesives
KW  - shear stiffness
KW  - surface roughness
KW  - mechanical strength
KW  - substrates
KW  - Electrodes
KW  - Adhesives
KW  - Substrates
KW  - Force
KW  - Rough surfaces
KW  - Surface roughness
DO  - 10.1109/ICRA.2018.8460725
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the constraints in the design of dry switchable adhesives is the compliance trade-off: compliant structures conform better to surfaces but are limited in strength due to high stored strain energy. In this work we study the effects of bending compliance on the shear adhesion pressures of hybrid electrostatic/gecko-like adhesives of various areas. We reaffirm that normal electrostatic preload increases contact area and show that it is more effective on compliant adhesives. We also show that the gain in contact area can compensate for low shear stiffness and adhesives with high bending compliance outperform stiffer adhesives on substrates with large scale roughness.
ER  - 

TY  - CONF
TI  - Design of Frictional 2D-Anisotropy Surface for Wriggle Locomotion of Printable Soft-Bodied Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6779
EP  - 6785
AU  - T. D. Ta
AU  - T. Umedachi
AU  - Y. Kawahara
PY  - 2018
KW  - friction
KW  - mobile robots
KW  - continuum robots
KW  - soft-bodied robots
KW  - snake robot
KW  - serpentine locomotion
KW  - wriggle soft-bodied robot
KW  - high friction material
KW  - low friction material
KW  - snake-like soft-bodied robots
KW  - frictional 2D-anisotropy surface
KW  - printable soft-bodied robots
KW  - anisotropic structure
KW  - Friction
KW  - Tendons
KW  - Anisotropic magnetoresistance
KW  - DC motors
KW  - Mobile robots
KW  - Surface morphology
DO  - 10.1109/ICRA.2018.8463177
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft-bodied and continuum robots have shown great adaptability to the environment thanks to its flexibility of the body. They have great potential in environment exploring or rescuing mission. One of those robots is snake-like soft-bodied robots. A snake robot is often made by attaching passive wheels along a long body to achieve frictional anisotropy. This anisotropic structure helps to propel the body with serpentine locomotion and prevents it from sliding laterally. However, with a snake-like soft-bodied robot, attaching wheels is not only clumsy but also adding weight to the robot. In this paper, being inspired by the scales on the skin of a snake, we propose a designing scheme to achieve an all-printed wriggle soft-bodied robot by patterning high and low friction material to the ventral side of the robot. Compared to a totally flat ventral, we are able to speed-up the serpentine locomotion 2.8 times. Besides, by changing the configuration of high/low friction material, our wriggle soft-bodied robot can easily move forward or backward just by switching the controlling signal. The fabrication time is just less than 1 hour and the robot can achieve the speed of 26 mm/s.
ER  - 

TY  - CONF
TI  - Inchworm Locomotion Mechanism Inspired Self-Deformable Capsule-Like Robot: Design, Modeling, and Experimental Validation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6800
EP  - 6805
AU  - Y. Luo
AU  - N. Zhao
AU  - K. J. Kim
AU  - J. Yi
AU  - Y. Shen
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - biomimetics
KW  - deformation
KW  - robot dynamics
KW  - robot kinematics
KW  - crawling locomotion behavior
KW  - inchworm-like crawling movement
KW  - deformable properties
KW  - bio-inspired design
KW  - robot kinematics
KW  - experimental validation
KW  - actuated deformation capability
KW  - soft actuation mechanisms
KW  - inchworm locomotion mechanism
KW  - self-deformable capsule-like robot
KW  - rigid elements-based morphing structure
KW  - robot deformation
KW  - Robots
KW  - Force
KW  - Strain
KW  - Friction
KW  - Kinetic theory
KW  - Biological system modeling
DO  - 10.1109/ICRA.2018.8460666
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Inspired by the inchworm locomotion mechanism, this paper presents our recently developed self-deformable capsule-like robot. The robot has the actuated deformation capability that relies on a novel rigid elements-based morphing structure (REMS) and its soft actuation mechanisms. When the robot deforms, it generates the crawling locomotion behavior and thus friction waves between the robot and contact surface to facilitate the inchworm-like crawling movement. The paper starts reviewing the deformable properties of natural biological entities like capsules, presents state of the art of the current capsule-like robots, and details the bio-inspired design of the self-deformable capsule-like robot by describing the model of robot kinematics and its locomotion mechanism. Both simulation and experimental results validate the excellent performance of this capsule-like robot. The developed self-deformable capsule-like robot has the advantage of crawling on varied surfaces and it also has the capabilities to crawl in a variety of narrow pipes based on the deformation elicited locomotion nature of the robot.
ER  - 

TY  - CONF
TI  - Realtime On-Board Attitude Estimation of High-Frequency Flapping Wing MAVs Under Large Instantaneous Oscillation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6806
EP  - 6811
AU  - Z. Tu
AU  - F. Fei
AU  - Y. Yang
AU  - J. Zhang
AU  - X. Deng
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - sensor fusion
KW  - realtime on-board attitude estimation
KW  - high-frequency flapping wing MAVs
KW  - instantaneous oscillation
KW  - fixed wings
KW  - rotary wings
KW  - high-frequency wing flapping
KW  - aerial vehicles
KW  - Flapping Wing Micro Aerial Vehicles
KW  - FWMAVs
KW  - instantaneous oscillations
KW  - Magnetometers
KW  - Robot sensing systems
KW  - Aerodynamics
KW  - Estimation
KW  - Accelerometers
KW  - Magnetic flux
KW  - Magnetomechanical effects
DO  - 10.1109/ICRA.2018.8461025
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Unlike conventional aerial vehicles of fixed or rotary wings, realtime on-board attitude estimation of insect or hummingbird scale Flapping Wing Micro Aerial Vehicles (FWMAVs) is very challenging due to the severe instantaneous oscillations (approximately ten times of gravity on our platform) induced by high-frequency wing flapping. In this work, we present a novel sensor fusion algorithm for realtime on-board attitude estimation of FWMAVs. The algorithm is proposed with adaptive model-based compensation for both sensing drift and aerodynamic forces induced by flapping wings. We validated our approach on a 12.5 grams hummingbird robot. The experimental results demonstrated the accuracy, convergence, and robustness of the proposed algorithm.
ER  - 

TY  - CONF
TI  - FireAnt: A Modular Robot with Full-Body Continuous Docks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6812
EP  - 6817
AU  - P. Swissler
AU  - M. Rubenstein
PY  - 2018
KW  - mobile robots
KW  - robotic assembly
KW  - self-assembly
KW  - modular 2D robot
KW  - full-body continuous docks
KW  - docking mechanism
KW  - mechanical complexity
KW  - robotic self-assembling structures
KW  - inert fireant robots
KW  - Robot sensing systems
KW  - Plastics
KW  - Copper
KW  - Strips
KW  - Wires
DO  - 10.1109/ICRA.2018.8463146
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Nature offers many examples of organisms coming together to form self-assembling structures. The attachment methods these organisms employ allow them to grab onto others' bodies, often without need for specific alignment or orientation, an ability absent from most existing robotic self-assembling structures, which require complicated sensing and specific alignment. This paper presents FireAnt, a modular 2D robot that demonstrates full-body continuous docks, an attachment mechanism able to attach anywhere onto other robots at any orientation, eliminating the need for alignment mechanisms and complex sensors. Such docks allow FireAnt to climb over copies of itself, something critical to self-assembling structures. This paper first discusses the design of FireAnt before presenting test results that show the strength and reliability of the continuous docks and demonstrate FireAnt's ability to traverse an environment consisting of inert FireAnt robots. The work presented in this paper provides a docking mechanism that can minimize the mechanical complexity of modular robots and will allow the creation of swarms of rigid and adaptable self-assembling structures.
ER  - 

TY  - CONF
TI  - Perception-Informed Autonomous Environment Augmentation with Modular Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6818
EP  - 6824
AU  - T. Tosun
AU  - J. Daudelin
AU  - G. Jing
AU  - H. Kress-Gazit
AU  - M. Campbell
AU  - M. Yim
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - planning (artificial intelligence)
KW  - high-level planner
KW  - disconnected regions
KW  - hardware experiments
KW  - planning tools
KW  - robot locomotion capabilities
KW  - specially-designed building blocks
KW  - environment characterization algorithm
KW  - modular robot systems
KW  - building structures
KW  - high-level tasks
KW  - perception-informed autonomous environment augmentation
KW  - Task analysis
KW  - Hardware
KW  - Mobile robots
KW  - Bridges
KW  - Buildings
KW  - Planning
DO  - 10.1109/ICRA.2018.8463155
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a system enabling a modular robot to autonomously build structures in order to accomplish high-level tasks. Building structures allows the robot to surmount large obstacles, expanding the set of tasks it can perform. This addresses a common weakness of modular robot systems, which often struggle to traverse large obstacles. This paper presents the hardware, perception, and planning tools that comprise our system. An environment characterization algorithm identifies features in the environment that can be augmented to create a path between two disconnected regions of the environment. Specially-designed building blocks enable the robot to create structures that can augment the environment to make obstacles traversable. A high-level planner reasons about the task, robot locomotion capabilities, and environment to decide if and where to augment the environment in order to perform the desired task. We validate our system in hardware experiments.
ER  - 

TY  - CONF
TI  - Design and Online Calibration of a Highly Compact Microgripper
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6825
EP  - 6830
AU  - Z. Yu
AU  - Q. Shi
AU  - H. Wang
AU  - T. Sun
AU  - Q. Huang
AU  - T. Fukuda
PY  - 2018
KW  - calibration
KW  - grippers
KW  - image sensors
KW  - microassembling
KW  - micromanipulators
KW  - microsensors
KW  - position measurement
KW  - compact microgripper
KW  - microobject manipulation
KW  - flexure hinge
KW  - low impedance grasping mechanism
KW  - kinematics analysis
KW  - fine element analysis
KW  - FEA
KW  - fibrous microring assembling
KW  - visual-based calibration method
KW  - position sensors
KW  - laser sensor
KW  - embedded sensors
KW  - dexterous manipulation
KW  - Grippers
KW  - Force
KW  - Fasteners
KW  - Calibration
KW  - Robot sensing systems
KW  - Strain measurement
KW  - Prototypes
DO  - 10.1109/ICRA.2018.8460683
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Microgrippers play a significant role in manipulation of micro-objects. To achieve dexterous and precise manipulation, a microgripper is required to be compactly designed and embedded with sensing feedback. Meanwhile, to convert the sensor position into displacement of the microgripper, the embedded sensors should be calibrated by additional equipment like laser sensor. However, a microgripper always needs to be calibrated during manipulation (online calibration), which is still a big challenge with current technology. In this paper, we proposed a highly compact microgripper integrated with position sensors, and a visual-based calibration method to handle such challenge. Moreover, to enhance grasping accuracy, flexure hinges are employed to achieve a low impedance grasping mechanism and to avoid the backlash in traditional bearing. Furthermore, kinematics analysis and Fine Element Analysis (FEA) are implemented to improve the design efficiency. Finally, fibrous micro-rings are successfully assembled, and the results reveal that the calibrated microgripper can be well employed to operate micro-objects.
ER  - 

TY  - CONF
TI  - Grasping of Unknown Objects Using Deep Convolutional Neural Networks Based on Depth Images
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6831
EP  - 6838
AU  - P. Schmidt
AU  - N. Vahrenkamp
AU  - M. Wächter
AU  - T. Asfour
PY  - 2018
KW  - dexterous manipulators
KW  - end effectors
KW  - feedforward neural nets
KW  - grippers
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - rendering (computer graphics)
KW  - robot vision
KW  - Deep Convolutional Neural Networks
KW  - training input
KW  - high-quality grasps
KW  - analytical grasp planners
KW  - rendered depth images
KW  - training objects
KW  - deep learning techniques
KW  - robotic grasping
KW  - approach directions
KW  - grasping setup
KW  - big data grasping database
KW  - qualitative grasping experiments
KW  - humanoid robot ARMAR-III
KW  - unknown objects
KW  - data-driven
KW  - deep learning approach
KW  - Grasping
KW  - Robots
KW  - Training
KW  - Data models
KW  - Databases
KW  - Feature extraction
KW  - Machine learning
DO  - 10.1109/ICRA.2018.8463204
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a data-driven, bottom-up, deep learning approach to robotic grasping of unknown objects using Deep Convolutional Neural Networks (DCNNs). The approach uses depth images of the scene as its sole input for synthesis of a single-grasp solution during execution, adequately portraying the robot's visual perception during exploration of a scene. The training input consists of precomputed high-quality grasps, generated by analytical grasp planners, accompanied with rendered depth images of the training objects. In contrast to previous work on applying deep learning techniques to robotic grasping, our approach is able to handle full end-effector poses and therefore approach directions other than the view direction of the camera. Furthermore, the approach is not limited to a certain grasping setup (e. g. parallel jaw gripper) by design. We evaluate the method regarding its force-closure performance in simulation using the KIT and YCB object model datasets as well as a big data grasping database. We demonstrate the performance of our approach in qualitative grasping experiments on the humanoid robot ARMAR-III.
ER  - 

TY  - CONF
TI  - Grasp Planning for Load Sharing in Collaborative Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6847
EP  - 6854
AU  - U. Tariq
AU  - R. Muthusamy
AU  - V. Kyrki
PY  - 2018
KW  - dexterous manipulators
KW  - force control
KW  - grippers
KW  - human-robot interaction
KW  - industrial manipulators
KW  - lifting
KW  - manipulators
KW  - collaborative manipulation
KW  - manipulation task
KW  - grasp location
KW  - human robot collaborative lifting task
KW  - grasp planning
KW  - grasp analysis approach
KW  - load sharing
KW  - partial observability
KW  - two-agent decentralized set-up
KW  - Task analysis
KW  - Robot kinematics
KW  - Planning
KW  - Collaboration
KW  - Force
KW  - Quadratic programming
DO  - 10.1109/ICRA.2018.8460579
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In near future, robots are envisioned to work alongside humans in unstructured professional and domestic environments. In such setups, collaborative manipulation is a fundamental skill that allows manipulation of heavy loads by load sharing between agents. Grasp planning plays a pivotal role for load sharing but it has not received attention in the literature. This work proposes a grasp analysis approach for collaborative manipulation that allows load sharing by minimizing exerted grasp wrenches in a task specific way. The manipulation task is defined as expected external wrenches acting on the target object. The analysis approach is demonstrated in a two-agent decentralized set-up with unknown objects. After the first agent has grasped the target, the second agent observes the first agent's grasp location and plans its own grasp according to optimal load sharing. The method was verified in a human robot collaborative lifting task. Experiments with multiple objects show that the proposed method results in optimal load sharing despite limited information and partial observability.
ER  - 

TY  - CONF
TI  - Human-Inspired Object Manipulation Control with the Anatomically Correct Testbed Hand
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6861
EP  - 6866
AU  - T. D. Niehues
AU  - A. D. Deshpande
PY  - 2018
KW  - biocontrol
KW  - biomechanics
KW  - dexterous manipulators
KW  - force control
KW  - manipulator dynamics
KW  - mechanical stability
KW  - muscle
KW  - position control
KW  - human neuromuscular system
KW  - grasp stability
KW  - human-inspired object manipulation control
KW  - anatomically correct testbed hand
KW  - dexterous manipulation
KW  - robotic hand
KW  - object-level impedance control strategies
KW  - grasp forces
KW  - robotic system
KW  - object stiffness control gains
KW  - object-space stiffness control algorithm
KW  - object size
KW  - object shape
KW  - grasp stability bounds
KW  - object-space stiffness
KW  - low-level stiffness
KW  - ACT hand
KW  - Robots
KW  - Force
KW  - Tendons
KW  - Task analysis
KW  - Muscles
KW  - Frequency modulation
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8463166
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Dexterous manipulation with robotic hands can be achieved using object-level impedance control strategies, which allow intuitive regulation of object position, external environmental interactions, and grasp forces. However, for grasp stability, object stiffness gains are limited by the inherent compliance of the robotic system, object size/shape, and applied grasp forces, which can lead to restricted manipulation capabilities. In this work, we first use analytical modeling techniques to explore the theoretical passivity bounds on object stiffness control gains to ensure grasp stability. Then, an object-space stiffness control algorithm is developed for the Anatomically Correct Testbed (ACT) hand, a robotic hand designed to replicate the complex tendon and joint structure of the human hand, and grasp stability bounds are experimentally tested for various task scenarios. Finally, inspired by the hierarchical structure of the human neuromuscular system, we develop a novel control strategy that implements low-level stiffness in muscle-space, while also emulating a separately defined object-space stiffness in quasi-static conditions. Experimental results demonstrate that this control strategy increases achievable object stiffness without sacrificing grasp stability, leading to significantly increased manipulation capabilities.
ER  - 

TY  - CONF
TI  - Improving Superquadric Modeling and Grasping with Prior on Object Shapes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6875
EP  - 6882
AU  - G. Vezzani
AU  - U. Pattacini
AU  - G. Pasquale
AU  - L. Natale
PY  - 2018
KW  - grippers
KW  - humanoid robots
KW  - pattern classification
KW  - superquadric modeling
KW  - grasping
KW  - object shape
KW  - object modeling
KW  - humanoid robots
KW  - superquadric functions
KW  - object classifier
KW  - robot hands
KW  - robotic system
KW  - iCub humanoid robot
KW  - Grasping
KW  - Shape
KW  - Computational modeling
KW  - Robots
KW  - Three-dimensional displays
KW  - Pipelines
KW  - Optimization
DO  - 10.1109/ICRA.2018.8463161
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes an object modeling and grasping pipeline for humanoid robots. This work improves our previous approach based on superquadric functions. In particular, we speed up and refine the modeling process by using prior information on the object shape provided by an object classifier. We use our previous method for the computation of grasping pose to obtain pose candidates for both the robot hands and, then, we automatically choose the best candidate for grasping the object according to a given quality index. The performance of our pipeline has been assessed on a real robotic system, the iCub humanoid robot. The robot can grasp 18 objects of the YCB and iCub World datasets considerably different in terms of shape and dimensions with a high success rate.
ER  - 

TY  - CONF
TI  - Active Reward Learning from Critiques
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6907
EP  - 6914
AU  - Y. Cui
AU  - S. Niekum
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - query processing
KW  - robot programming
KW  - critiques
KW  - active reward Learning
KW  - programming robots
KW  - active Bayesian inverse reinforcement learning
KW  - trajectory queries
KW  - labeling process
KW  - active learning
KW  - Trajectory
KW  - Robots
KW  - Learning (artificial intelligence)
KW  - Bayes methods
KW  - Entropy
KW  - Task analysis
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8460854
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Learning from demonstration algorithms, such as Inverse Reinforcement Learning, aim to provide a natural mechanism for programming robots, but can often require a prohibitive number of demonstrations to capture important subtleties of a task. Rather than requesting additional demonstrations blindly, active learning methods leverage uncertainty to query the user for action labels at states with high expected information gain. However, this approach can still require a large number of labels to adequately reduce uncertainty and may also be unintuitive, as users are not accustomed to determining optimal actions in a single out-of-context state. To address these shortcomings, we propose a novel trajectory-based active Bayesian inverse reinforcement learning algorithm that (1) queries the user for critiques of automatically generated trajectories, rather than asking for demonstrations or action labels, (2) utilizes trajectory segmentation to expedite the critique / labeling process, and (3) predicts the user's critiques to generate the most highly informative trajectory queries. We evaluated our algorithm in simulated domains, finding it to compare favorably to prior work and a randomized baseline.
ER  - 

TY  - CONF
TI  - Uncertainty-Aware Learning from Demonstration Using Mixture Density Networks with Sampling-Free Variance Modeling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6915
EP  - 6922
AU  - S. Choi
AU  - K. Lee
AU  - S. Lim
AU  - S. Oh
PY  - 2018
KW  - estimation theory
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - measurement uncertainty
KW  - mobile robots
KW  - Monte Carlo methods
KW  - sampling methods
KW  - uncertainty handling
KW  - uncertainty estimation method utilizing
KW  - Monte Carlo sampling
KW  - robotics applications
KW  - autonomous driving
KW  - epistemic uncertainties
KW  - aleatoric uncertainties
KW  - uncertainty acquisition
KW  - demonstration method
KW  - sampling-free variance modeling
KW  - mixture density network
KW  - uncertainty-aware learning
KW  - Uncertainty
KW  - Predictive models
KW  - Noise measurement
KW  - Data models
KW  - Training
KW  - Estimation
KW  - Measurement uncertainty
DO  - 10.1109/ICRA.2018.8462978
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we propose an uncertainty-aware learning from demonstration method by presenting a novel uncertainty estimation method utilizing a mixture density network appropriate for modeling complex and noisy human behaviors. The proposed uncertainty acquisition can be done with a single forward path without Monte Carlo sampling and is suitable for real-time robotics applications. Then, we show that it can be decomposed into explained variance and unexplained variance where the connections between aleatoric and epistemic uncertainties are addressed. The properties of the proposed uncertainty measure are analyzed through three different synthetic examples, absence of data, heavy measurement noise, and composition of functions scenarios. We show that each case can be distinguished using the proposed uncertainty measure and presented an uncertainty-aware learning from demonstration method for autonomous driving using this property. The proposed uncertainty-aware learning from demonstration method outperforms other compared methods in terms of safety using a complex real-world driving dataset.
ER  - 

TY  - CONF
TI  - Human-Driven Feature Selection for a Robotic Agent Learning Classification Tasks from Demonstration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6923
EP  - 6930
AU  - K. Bullard
AU  - S. Chernova
AU  - A. L. Thomaz
PY  - 2018
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - pattern classification
KW  - robots
KW  - LfD scenarios
KW  - human feature selection
KW  - robot learner
KW  - informative features
KW  - multiclass classification task
KW  - computational feature selection
KW  - human selected features
KW  - informative task features
KW  - general-purpose robot
KW  - learning computation
KW  - robotic agent learning classification tasks
KW  - human-driven feature selection
KW  - Task analysis
KW  - Feature extraction
KW  - Robots
KW  - Training
KW  - Training data
KW  - Object recognition
KW  - Support vector machines
DO  - 10.1109/ICRA.2018.8461012
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The state features available to a robot define the variables on which the learning computation depends. However, little prior work considers feature selection in the context of deploying a general-purpose robot able to learn new tasks. In this work, we explore human-driven feature selection in which a robotic agent can identify useful features with the aid of a human user, by extracting information from users about which features are most informative for discriminating between classes of objects needed for a given task (e.g. sorting groceries). The research questions examine (a) whether a domain expert is able to identify a subset of informative task features, (b) whether human selected features will enable the agent to classify unseen examples as accurately as using computational feature selection, and (c) if the interaction strategy used to elicit the information from the user impacts the quality of resulting feature selection. Toward that end, we conducted a user study with 30 participants on campus, given a multi-class classification task and one of five different approaches for conveying information about informative features to a robot learner. Our findings show that when features are semantically interpretable, human feature selection is effective in LfD scenarios because it is able to outperform computational methods when there is limited training data, yet still remains on-par with computational methods as the training sample size increases.
ER  - 

TY  - CONF
TI  - Object-Centric Approach to Prediction and Labeling of Manipulation Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6931
EP  - 6938
AU  - E. H. Chen
AU  - D. Burschka
PY  - 2018
KW  - cameras
KW  - graph theory
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - object-centric approach
KW  - manipulation tasks
KW  - human manipulation actions
KW  - object trajectories
KW  - context specific human vocabulary
KW  - directed action graph representation
KW  - pre-computed Location Areas
KW  - offline teaching phase
KW  - graph generation
KW  - online action recognition phase
KW  - high-level reasoning
KW  - sensor observation
KW  - visual sensory input
KW  - depth camera
KW  - LA
KW  - sector-maps
KW  - SM
KW  - Service robots
KW  - Hidden Markov models
KW  - Vocabulary
KW  - Feature extraction
KW  - Knowledge based systems
KW  - Task analysis
KW  - Action Recognition
KW  - Motion analysis
KW  - Graph method
KW  - Location Area
KW  - Sector-Map
KW  - Knowledge representation
DO  - 10.1109/ICRA.2018.8462973
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose an object-centric framework to label and predict human manipulation actions from observations of the object trajectories in 3D space. The goal is to lift the low-level sensor observation to a context specific human vocabulary. The low-level visual sensory input from a depth camera is processed into high-level descriptive action labels using a directed action graph representation. It is built based on the concepts of pre-computed Location Areas (LA), regions within a scene where an action typically occur, and Sector-Maps (SM), reference trajectories between the LAs. The framework consists of two stages, an offline teaching phase for graph generation, and an online action recognition phase that maps the current observations to the generated graph. This graph representation allows the framework to predict the most probable action from the observed motion in real-time and to adapt its structure whenever a new LA appears. Furthermore, the descriptive action labels enable not only a better exchange of information between a human and a robot but they allow also the robots to perform high-level reasoning. We present experimental results on real human manipulation actions using a system designed with this framework to show the performance of prediction and labeling that can be achieved.
ER  - 

TY  - CONF
TI  - Deep Auxiliary Learning for Visual Localization and Odometry
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6939
EP  - 6946
AU  - A. Valada
AU  - N. Radwan
AU  - W. Burgard
PY  - 2018
KW  - distance measurement
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pose estimation
KW  - video signal processing
KW  - state-of-the-art SIFT-based approaches
KW  - deep learning technique
KW  - multitask learning
KW  - Geometric Consistency Loss
KW  - visual odometry estimation
KW  - global localization
KW  - parameter sharing
KW  - multitask model
KW  - consecutive monocular images
KW  - VLocNet
KW  - convolutional neural networks
KW  - action execution
KW  - robot
KW  - visual localization
KW  - Task analysis
KW  - Visual odometry
KW  - Estimation
KW  - Visualization
KW  - Training
KW  - Robustness
DO  - 10.1109/ICRA.2018.8462979
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Localization is an indispensable component of a robot's autonomy stack that enables it to determine where it is in the environment, essentially making it a precursor for any action execution or planning. Although convolutional neural networks have shown promising results for visual localization, they are still grossly outperformed by state-of-the-art local feature-based techniques. In this work, we propose VLocNet, a new convolutional neural network architecture for 6-DoF global pose regression and odometry estimation from consecutive monocular images. Our multitask model incorporates hard parameter sharing, thus being compact and enabling real-time inference, in addition to being end-to-end trainable. We propose a novel loss function that utilizes auxiliary learning to leverage relative pose information during training, thereby constraining the search space to obtain consistent pose estimates. We evaluate our proposed VLocNet on indoor as well as outdoor datasets and show that even our single task model exceeds the performance of state-of-the-art deep architectures for global localization, while achieving competitive performance for visual odometry estimation. Furthermore, we present extensive experimental evaluations utilizing our proposed Geometric Consistency Loss that show the effectiveness of multitask learning and demonstrate that our model is the first deep learning technique to be on par with, and in some cases outperforms state-of-the-art SIFT-based approaches.
ER  - 

TY  - CONF
TI  - An Experimental Investigation of Extra Measurements for Solving the Direct Kinematics of Cable-Driven Parallel Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6947
EP  - 6952
AU  - J. -. Merlet
PY  - 2018
KW  - manipulator kinematics
KW  - position control
KW  - CDPR
KW  - extra measurements
KW  - extra sensors
KW  - cable orientations
KW  - direct kinematics
KW  - cable-driven parallel robots
KW  - cable length measurements
KW  - model-based approach
KW  - cable tension sensors
KW  - Measurement uncertainty
KW  - Mathematical model
KW  - Robot sensing systems
KW  - Kinematics
KW  - Instruments
DO  - 10.1109/ICRA.2018.8460901
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Solving the direct kinematics (DK) of cable-driven parallel robots (CDPR) based only on the cable length measurements is a demanding problem that is still not well mastered, especially for robots having sagging cables. A model-based approach may be used to solve this problem but the model parameters and measurements are uncertain, thereby leading to positioning inaccuracy. A possible way to improve the accuracy and speed up the solving is to add extra measurements. For that purpose a preliminary step is to determine what type of measurements are possible and then to estimate how accurate they are. For that purpose we have used a CDPR with 4 cables that has been instrumented with various types of extra measurements: cable tensions and orientations, platform orientation. Ground truth has been established and we have compared the data provided by the extra sensors with their real values. This work shows that cable tensions sensors and platform orientation sensors are not good candidates to be used for the DK while cable orientations may be obtained with a good accuracy both in static poses or during a quasi-static motion.
ER  - 

TY  - CONF
TI  - Kinematic Optimization of a Novel Partially Decoupled Three Degree of Freedom Hybrid Wrist Mechanism
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6953
EP  - 6960
AU  - N. M. Bajaj
AU  - A. M. Dollar
PY  - 2018
KW  - actuators
KW  - couplings
KW  - manipulator kinematics
KW  - motion control
KW  - optimisation
KW  - kinematic design
KW  - geometric optimization
KW  - prismatic-revolute-universal linkage
KW  - prismatic-spherical-spherical linkage
KW  - spherical motion
KW  - pitch-yaw-roll wrist
KW  - arbitrary direction
KW  - forward kinematics
KW  - inverse kinematics
KW  - parallel 2-DOF mechanism
KW  - design parameters
KW  - global transmission index
KW  - torque transmissibility
KW  - decoupled nature
KW  - yaw mechanism
KW  - kinematic optimization
KW  - partially decoupled three degree of freedom hybrid wrist mechanism
KW  - wrist configuration
KW  - Kinematics
KW  - Wrist
KW  - Couplings
KW  - Actuators
KW  - Optimization
KW  - Computer architecture
KW  - End effectors
DO  - 10.1109/ICRA.2018.8460568
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper discusses the kinematic design and geometric optimization of a novel hybrid three degree-of-freedom (DOF) wrist mechanism. The architecture consists of a one prismatic-revolute-universal linkage and one prismatic-spherical-spherical linkage in parallel with a revolute-universal linkage. This architecture is capable of spherical motion identical to that of a pitch-yaw-roll wrist. Moreover, this mechanism is considered to be partially decoupled, as not all actuators contribute to motion in an arbitrary direction. The forward and inverse kinematics of the parallel 2-DOF mechanism are presented. The 2-DOF mechanism is geometrically optimized over its design parameters to maximize a global transmission index, which measures the motion and torque transmissibility of particular wrist configuration over its workspace. The decoupled nature of the mechanism allows the pitch and yaw mechanism to be optimized separately, greatly reducing the parameter search space and allowing a much larger number of mechanism configurations to be simulated. We leverage this increase in simulated configurations to examine the effect of size constraints on the resulting mechanisms as well.
ER  - 

TY  - CONF
TI  - Reconfiguration Analysis and Motion Planning of a Novel Reconfigurable Mobile Manipulator Torso
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6961
EP  - 6966
AU  - W. Ding
AU  - T. Detert
AU  - J. De La Cruz
AU  - B. Corves
PY  - 2018
KW  - bars
KW  - flexible manipulators
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - reconfiguration analysis
KW  - mutual mode transition rules
KW  - kinematics model
KW  - motion planning
KW  - reconfiguration rules
KW  - ReConBot
KW  - flexible torso
KW  - straight bar-shape base
KW  - metamorphic kinematic chains
KW  - configuration states
KW  - reconfigurable mobile manipulator torso
KW  - 2RER reconfigurable parallel mechanism
KW  - transition handling
KW  - singularity position
KW  - Kinematics
KW  - Torso
KW  - Mathematical model
KW  - Robot kinematics
KW  - Planning
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8460214
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A novel 2-RER reconfigurable parallel mechanism (ReConBot) considered as the flexible torso of the mobile manipulator is proposed. This paper deals with the analysis of reconfiguration, kinematics, and motion planning. The ReConBot is composed of straight bar-shape base and moving platforms and two metamorphic kinematic chains (MKC) consisted of a revolute (R) joint, a planar (E) joint, and an R joint in sequence. Firstly, mobility and reconfiguration analysis discuss the conditions and mutual mode transition rules of 12 possible configuration states. And then, the kinematics model covers all states with Cartesian coordinate and axis/angle representations. What's more, the motion planning following the rules of the mode transition is explained and illustrated together with a case study. Furthermore, the method of handling the transition at singularity position is discussed. Finally, the robotic system and its experiments verify the correctness of the theoretical analysis and the validation of reconfiguration rules.
ER  - 

TY  - CONF
TI  - Efficient Event-Driven Forward Kinematics of Open Kinematic Chains with O(Log n) Complexity
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6975
EP  - 6982
AU  - R. Wakatabe
AU  - K. Morita
AU  - G. Cheng
AU  - Y. Kuniyoshi
PY  - 2018
KW  - computational complexity
KW  - manipulator kinematics
KW  - matrix algebra
KW  - open kinematic chains
KW  - event-driven forward kinematics algorithms
KW  - computational resources
KW  - root joint
KW  - conventional forward kinematics
KW  - computation time
KW  - event-driven FK algorithms
KW  - sensory data
KW  - homogeneous transformation matrix
KW  - time-variance
KW  - algebraic structures
KW  - Kinematics
KW  - Robot sensing systems
KW  - Heuristic algorithms
KW  - Robot kinematics
KW  - Complexity theory
KW  - Real-time systems
DO  - 10.1109/ICRA.2018.8461211
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents novel event-driven forward kinematics algorithms for open kinematic chains with O(log n) complexity. This event-driven algorithm can efficiently update forward kinematics only when new sensory data comes. This will also contribute to localization of computational resources at sensitive joints to the position of the endpoint (e.g. a fingertip), like a root joint. We constructed 3 event-driven FK algorithms. We proved that the algorithms have the complexity of O(logn) for updating 1 joint angle, and O(logn) for obtaining a homogeneous transformation matrix between links. We compared the 3 algorithms with a conventional forward kinematics algorithm in the viewpoint of complexity, computation time, time-variance and algebraic structures. The results showed that the computation time is well adequate for real-time computation. Computation time is less than 2 us per 1 query, for 40,000 kinematic chains.
ER  - 

TY  - CONF
TI  - Reactive Magnetic-Field-Inspired Navigation for Non-Holonomic Mobile Robots in Unknown Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6983
EP  - 6988
AU  - A. Ataka
AU  - H. Lam
AU  - K. Althoefer
PY  - 2018
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - TurtleBot mobile robot platform
KW  - local sensory information
KW  - arbitrary-shaped convex environment
KW  - magnetic fields
KW  - nonholonomic mobile robot taking inspiration
KW  - reactive robot navigation method
KW  - unknown environments
KW  - nonholonomic mobile robots
KW  - reactive magnetic-field-inspired navigation
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Navigation
KW  - Mobile robots
KW  - Force
KW  - Wires
DO  - 10.1109/ICRA.2018.8463203
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a reactive robot navigation method for a non-holonomic mobile robot taking inspiration from the phenomena observed in magnetic fields. The algorithm is shown to be able to guide mobile robots in arbitrary-shaped convex environment without being trapped in local minima by exploiting the local sensory information without priori knowledge about the environment. A preliminary validation study involving simulation of and experiments with a TurtleBot mobile robot platform show the advantage of the proposed method over existing ones.
ER  - 

TY  - CONF
TI  - Aerial Grasping Based on Shape Adaptive Transformation by HALO: Horizontal Plane Transformable Aerial Robot with Closed-Loop Multilinks Structure
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6990
EP  - 6996
AU  - T. Anzai
AU  - M. Zhao
AU  - S. Nozawa
AU  - F. Shi
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - closed loop systems
KW  - mobile robots
KW  - optimisation
KW  - position control
KW  - propellers
KW  - closed-loop aerial transformation
KW  - aerial grasping
KW  - shape adaptive transformation
KW  - aerial manipulation
KW  - HALO
KW  - horizontal plane transformable aerial robot
KW  - closed-loop multilinks structure
KW  - flight control
KW  - serial-link structure
KW  - propeller
KW  - optimization planning method
KW  - Unmanned aerial vehicles
KW  - Propellers
KW  - Shape
KW  - Grasping
KW  - Servomotors
KW  - Force
KW  - End effectors
DO  - 10.1109/ICRA.2018.8460928
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present the achievement of aerial grasping by shape adaptive transformation to the object shape, using a novel transformable aerial robot called HALO: Horizontal Plane Transformable Aerial Robot with Closed-loop Multilinks Structure. Aerial manipulation is an active research area and using multiple aerial robots is an effective solution for the large size object. However the cooperation is considered that there are some difficulties such as the synchronized flight control and collision with each other. Then, we focus on the transformable aerial robot with two-dimensional multilinks proposed in our previous works, which can transform to the suitable form for the target object and grasp it. However the transformable aerial robot with the serial-link structure could not achieve stable flight in terms of horizontal position and yaw control due to the low rigidity and large inertia in the case of more than 4 links. Thus, first we construct a novel type of multilinks with closed-loop structure to avoid the deformation and a new link module with a tilted propeller for fully-actuated control. Second, we describe transformation method with closed-loop multilinks. Third, we present the optimization planning method for the multilinks form to be adaptive to the two-dimensional shape of the target object. Finally, we present experimental results to demonstrate the feasibility of closed-loop aerial transformation and aerial grasping for the large size object.
ER  - 

TY  - CONF
TI  - Towards a Flying Assistant Paradigm: the OTHex
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6997
EP  - 7002
AU  - N. Staub
AU  - D. Bicego
AU  - Q. Sablé
AU  - V. Arellano
AU  - S. Mishra
AU  - A. Franchi
PY  - 2018
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - estimation theory
KW  - geometry
KW  - manipulators
KW  - mobile robots
KW  - robust control
KW  - trajectory control
KW  - maintenance tasks
KW  - task-driven custom design
KW  - experimental validations
KW  - control framework
KW  - low-level geometric controller
KW  - external wrench estimator
KW  - admittance filter
KW  - trajectory generator
KW  - external force disturbances
KW  - Flying Assistant paradigm
KW  - OTHex platform
KW  - aerial manipulation
KW  - LAAS-CNRS
KW  - multidirectional thrust platform
KW  - human operators
KW  - long bars
KW  - assembly tasks
KW  - ground manipulators
KW  - Propellers
KW  - Bars
KW  - Trajectory
KW  - Robots
KW  - Task analysis
KW  - Admittance
KW  - Force
DO  - 10.1109/ICRA.2018.8460877
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the OTHex platform for aerial manipulation developed at LAAS-CNRS. The OTHex is probably the first multi-directional thrust platform designed to act as Flying Assistant which can aid human operators and/or Ground Manipulators to move long bars for assembly and maintenance tasks. The work emphasis is on task-driven custom design and experimental validations. The proposed control framework is built around a low-level geometric controller, and includes an external wrench estimator, an admittance filter, and a trajectory generator. This tool gives the system the necessary compliance to resist external force disturbances arising from contact with the surrounding environment or to parameter uncertainties in the load. A set of experiments validates the real-world applicability and robustness of the overall system.
ER  - 

TY  - CONF
TI  - Emulating a Fully Actuated Aerial Vehicle Using Two Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7011
EP  - 7016
AU  - J. Paulos
AU  - B. Caraher
AU  - M. Yim
PY  - 2018
KW  - actuators
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - blades
KW  - helicopters
KW  - position control
KW  - rotors
KW  - vehicle dynamics
KW  - flat body attitude
KW  - fully actuated aerial vehicle
KW  - actuators
KW  - microair vehicles
KW  - quadrotors
KW  - downward thrust
KW  - spatial trajectories
KW  - coaxial helicopter
KW  - thrust vector
KW  - translation dynamics
KW  - cyclic flapping response
KW  - Rotors
KW  - Blades
KW  - Aircraft
KW  - Force
KW  - Fasteners
KW  - Actuators
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8462975
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Micro air vehicles exemplified by quadrotors generate downward thrust in their body fixed frame and may only maneuver spatially by changing their orientation. As a result of this underactuation they are fundamentally incapable of simultaneously regulating orientation and position. Furthermore, their feasible maneuvers are limited to spatial trajectories with continuously differentiable acceleration. We present a coaxial helicopter which emulates full actuation over forces and torques (six degrees of freedom) using only two actuators. The orientation of the thrust vector from each rotor is governed by the drive motor by exciting a cyclic flapping response in special articulated blades. The useful separation of orientation and translation dynamics is demonstrated in flight experiments by tracking spatial trajectories while maintaining flat body attitude as well as tracking desired orientations near hover while station keeping.
ER  - 

TY  - CONF
TI  - LASDRA: Large-Size Aerial Skeleton System with Distributed Rotor Actuation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7017
EP  - 7023
AU  - H. Yang
AU  - S. Park
AU  - J. Lee
AU  - J. Ahn
AU  - D. Son
AU  - D. Lee
PY  - 2018
KW  - decentralised control
KW  - hydraulic actuators
KW  - machine control
KW  - rotors
KW  - valves
KW  - robotic system
KW  - LASDRA
KW  - valve turning
KW  - trajectory tracking
KW  - strong/sturdy base actuator/structure
KW  - actuators
KW  - hydraulic actuation
KW  - large-size aerial skeleton system
KW  - large-size dexterously-articulated robot
KW  - internal actuation
KW  - external actuation
KW  - distributed rotors
KW  - distributed rotor actuation
KW  - Rotors
KW  - Robots
KW  - Force
KW  - Loading
KW  - Torque
KW  - Hydraulic systems
KW  - Actuators
DO  - 10.1109/ICRA.2018.8460713
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Electrical motor and hydraulic actuation widely-used in robotics are “internal actuation” with their actuators sitting at the joint between two links. This internal actuation is fundamentally limiting to construct a large-size dexterously-articulated robot, since any external force (and its own link weight) is to be accumulated to the base multiplied by the moment arm length, requiring extremely strong/sturdy base actuator/structure as the system size increases. In this paper, we propose a novel robotic system, LASDRA (large-size aerial skeleton with distributed rotor actuation), which, by utilizing distributed rotors as “external actuation”, can overcome this limitation of internal actuation and enables us to realize large-size dexterously-articulated robots. We present its design and modeling, joint locking strategy to increase its loading capability, and also a novel decentralized control scheme to allow for compliant operation with scalability against the number of links. Trajectory tracking and valve turning experiments are also performed to validate the theory.
ER  - 

TY  - CONF
TI  - A Flying Gripper Based on Cuboid Modular Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7024
EP  - 7030
AU  - B. Gabrich
AU  - D. Saldaña
AU  - V. Kumar
AU  - M. Yim
PY  - 2018
KW  - autonomous aerial vehicles
KW  - grippers
KW  - helicopters
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - degree of freedom
KW  - four-bar linkage
KW  - aperture angle
KW  - cuboid frame
KW  - docking mechanism
KW  - vertical edges
KW  - grasp object
KW  - cuboid modular robots
KW  - flying Gripper
KW  - hovering performance
KW  - DOF
KW  - Grippers
KW  - Apertures
KW  - Robots
KW  - Rotors
KW  - Grasping
KW  - Propellers
KW  - Shape
DO  - 10.1109/ICRA.2018.8460682
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a novel flying modular platform capable of grasping and transporting objects. It is composed of four cooperative identical modules where each is based on a quadrotor within a cuboid frame with a docking mechanism. Pairs of modules are able to fly independently and physically connect by matching their vertical edges forming a hinge. Four one degree of freedom (DOF) connections results in a one DOF four-bar linkage that can be used to grasp external objects. In this paper, we propose a decentralized method that allows the Flying Gripper to control its position, attitude and aperture angle. In our experiments, we tested the hovering performance for different aperture angles and with a grasped object. The performance for a closing and opening motion was also verified.
ER  - 

TY  - CONF
TI  - ACT: An Autonomous Drone Cinematography System for Action Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7039
EP  - 7046
AU  - C. Huang
AU  - F. Gao
AU  - J. Pan
AU  - Z. Yang
AU  - W. Qiu
AU  - P. Chen
AU  - X. Yang
AU  - S. Shen
AU  - K. Cheng
PY  - 2018
KW  - cinematography
KW  - motion estimation
KW  - remotely operated vehicles
KW  - video cameras
KW  - action scenes
KW  - aerial filming
KW  - autonomous cinematography system
KW  - autonomous drone cinematography system
KW  - state-of-the-art drone camera system
KW  - real-time dynamical camera planning strategy
KW  - drone platform
KW  - human action
KW  - external motion capture systems
KW  - drone cinematography systems
KW  - aesthetic objectives
KW  - Cameras
KW  - Drones
KW  - Three-dimensional displays
KW  - Skeleton
KW  - Planning
KW  - Robot vision systems
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460703
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Drones are enabling new forms of cinematography. Aerial filming via drones in action scenes is difficult because it requires users to understand the dynamic scenarios and operate the drone and camera simultaneously. Existing systems allow the user to manually specify the shots and guide the drone to capture footage, while none of them employ aesthetic objectives to automate aerial filming in action scenes. Meanwhile, these drone cinematography systems depend on the external motion capture systems to perceive the human action, which is limited to the indoor environment. In this paper, we propose an Autonomous CinemaTography system “ACT” on the drone platform to address the above the challenges. To our knowledge, this is the first drone camera system which can autonomously capture cinematic shots of action scenes based on limb movements in both indoor and outdoor environments. Our system includes the following novelties. First, we propose an efficient method to extract 3D skeleton points via a stereo camera. Second, we design a real-time dynamical camera planning strategy that fulfills the aesthetic objectives for filming and respects the physical limits of a drone. At the system level, we integrate cameras and GPUs into the limited space of a drone and demonstrate the feasibility of running the entire cinematography system onboard in real-time. Experimental results in both simulation and real-world scenarios demonstrate that our cinematography system “ACT” can capture more expressive video footage of human action than that of a state-of-the-art drone camera system.
ER  - 

TY  - CONF
TI  - Approximate Branch and Bound for Fast, Risk-Bound Stochastic Path Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7047
EP  - 7054
AU  - D. Strawser
AU  - B. Williams
PY  - 2018
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - path planning
KW  - stochastic processes
KW  - tree searching
KW  - risk-bound stochastic path planning
KW  - often intractable problem
KW  - autonomous agents
KW  - complex stochastic processes
KW  - fast path planning
KW  - chance constraint
KW  - stochastic path planning problem
KW  - nonconvex problem
KW  - scales computational effort
KW  - MILP approach
KW  - parallelized sampling-based approach
KW  - Computational modeling
KW  - Stochastic processes
KW  - Trajectory
KW  - Uncertainty
KW  - Planning
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2018.8461070
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Path planning under uncertainty is a difficult and often intractable problem. Autonomous agents must model and reason about complex stochastic processes to quickly derive high quality plans. Most approaches separate the model of uncertainty from the planning; a model is selected and then a controller derived. This work proposes an approach for fast path planning under uncertainty that scales the model of uncertainty such that good policies receive the most effort. To do this, we use an innovative form of the problem's chance constraint to formulate a convex, stochastic path planning problem from the non-convex problem. Next, a bound on the path's expected cost is developed that allows a trade-off between speed of computation and accuracy. The bound is trivially parallelized on a GPU. Finally, a modified branch and bound algorithm is introduced that scales computational effort for more promising solutions. The method is benchmarked against existing approaches including those using Boole's inequality, a MILP approach, and a parallelized sampling-based approach. It outperforms other approaches based on speed and the ability to meet the chance constraint while not being overly conservative.
ER  - 

TY  - CONF
TI  - Rapidly-Exploring Random Vines (RRV) for Motion Planning in Configuration Spaces with Narrow Passages
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7055
EP  - 7062
AU  - A. Tahirovic
AU  - M. Ferizbegovic
PY  - 2018
KW  - collision avoidance
KW  - eigenvalues and eigenfunctions
KW  - mobile robots
KW  - random processes
KW  - sampling methods
KW  - trees (mathematics)
KW  - configuration space
KW  - tree expansion
KW  - eigenvectors
KW  - classical RRT algorithm
KW  - rapidly-exploring random vines algorithm
KW  - motion planning problem
KW  - narrow passage
KW  - Space exploration
KW  - Planning
KW  - Terminology
KW  - Principal component analysis
KW  - Probabilistic logic
KW  - Robots
KW  - Collision avoidance
DO  - 10.1109/ICRA.2018.8460186
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Classical RRT algorithm is blind to efficiently explore configuration space for expanding the tree through a narrow passage when solving a motion planning (MP) problem. Although there have been several attempts to deal with narrow passages which are based on a wide spectrum of assumptions and configuration setups, we solve this problem in rather general way. We use dominant eigenvectors of the configuration sets formed by properly sampling the space around the nearest node, to efficiently expand the tree around the obstacles and through narrow passages. Unlike classical RRT, our algorithm is aware of having the tree nodes in front of a narrow passage and in a narrow passage, which enables a proper tree expansion in a vine-like manner. A thorough comparison with RRT, RRT-connect, and DDRRT algorithm is provided by solving three different difficult MP problems. The results suggest a significant superiority the proposed Rapidly-exploring Random Vines (RRV) algorithm might have in configuration spaces with narrow passages.
ER  - 

TY  - CONF
TI  - Generalizing Informed Sampling for Asymptotically-Optimal Sampling-Based Kinodynamic Planning via Markov Chain Monte Carlo
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7063
EP  - 7070
AU  - D. Yi
AU  - R. Thakker
AU  - C. Gulino
AU  - O. Salzman
AU  - S. Srinivasa
PY  - 2018
KW  - approximation theory
KW  - convergence of numerical methods
KW  - estimation theory
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - Monte Carlo methods
KW  - optimisation
KW  - path planning
KW  - random processes
KW  - sampling methods
KW  - state-space methods
KW  - trees (mathematics)
KW  - asymptotically-optimal motion planners
KW  - subsequent samples
KW  - motion-planning problem
KW  - Euclidean space
KW  - nonEuclidean state spaces
KW  - dimensional state space
KW  - planning algorithm
KW  - sub-level-set
KW  - Monte Carlo sampling methods
KW  - high-quality solutions
KW  - high-dimensional problems
KW  - Markov chain Monte Carlo
KW  - informed set
KW  - generalizing informed sampling
KW  - asymptotically-optimal sampling-based kinodynamic planning
KW  - hierarchical rejection sampling
KW  - Trajectory
KW  - Planning
KW  - Monte Carlo methods
KW  - Markov processes
KW  - Cost function
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2018.8460188
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Asymptotically-optimal motion planners such as RRT* have been shown to incrementally approximate the shortest path between start and goal states. Once an initial solution is found, their performance can be dramatically improved by restricting subsequent samples to regions of the state space that can potentially improve the current solution. When the motion-planning problem lies in a Euclidean space, this region Xinf, called the informed set, can be sampled directly. However, when planning with differential constraints in non-Euclidean state spaces, no analytic solutions exists to sampling Xinf directly. State-of-the-art approaches to sampling Xinf in such domains such as Hierarchical Rejection Sampling (HRS) may still be slow in high -dimensional state space. This may cause the planning algorithm to spend most of its time trying to produces samples in Xinf rather than explore it. In this paper, we suggest an alternative approach to produce samples in the informed set Xinf for a wide range of settings. Our main insight is to recast this problem as one of sampling uniformly within the sub-level-set of an implicit non-convex function. This recasting enables us to apply Monte Carlo sampling methods, used very effectively in the Machine Learning and Optimization communities, to solve our problem. We show for a wide range of scenarios that using our sampler can accelerate the convergence rate to high-quality solutions in high-dimensional problems.
ER  - 

TY  - CONF
TI  - Dancing PRM*: Simultaneous Planning of Sampling and Optimization with Configuration Free Space Approximation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7071
EP  - 7078
AU  - D. Kim
AU  - Y. Kwon
AU  - S. Yoon
PY  - 2018
KW  - approximation theory
KW  - optimisation
KW  - path planning
KW  - grid-based approaches
KW  - optimization-based planner
KW  - resolution-complete factors
KW  - spatial information
KW  - empirical information
KW  - learned information
KW  - optimization-based local planner
KW  - asymptotic optimal planners
KW  - simultaneous planning
KW  - configuration free space approximation
KW  - optimal motion planning
KW  - sampling-based planner
KW  - Dancing PRM
KW  - Planning
KW  - Approximation algorithms
KW  - Trajectory
KW  - Optimization
KW  - Robots
KW  - Probabilistic logic
KW  - Linear programming
DO  - 10.1109/ICRA.2018.8463181
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A recent trend in optimal motion planning has broadened the research area toward the hybridization of sampling, optimization and grid-based approaches. We can expect that synergy from such integrations leads to overall performance improvement, but seamless integration and generalization is still an open problem. In this paper, we suggest a hybrid motion planning algorithm utilizing a sampling-based and optimization-based planner while simultaneously approximating a configuration free space. Unlike conventional optimization-based approaches, the proposed algorithm does not depend on a priori information or resolution-complete factors, e.g., a distance field. Ours instead learns spatial information on the fly by exploiting empirical information during the execution, and decentralizes the information over the constructed graph for efficient access. With the help of the learned information, our optimization-based local planner exploits the local area to identify the connectivity of configuration free space without depending on the precomputed domain knowledge. To show the novelty of proposed algorithm, we evaluate it against other asymptotic optimal planners in both synthetic and complex benchmarks with varying degrees of freedom. We also discuss the performance improvement, properties and limitations we have observed.
ER  - 

TY  - CONF
TI  - Randomized Kinodynamic Planning for Constrained Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7079
EP  - 7086
AU  - R. Bordalba
AU  - L. Ros
AU  - J. M. Porta
PY  - 2018
KW  - collision avoidance
KW  - large-scale systems
KW  - manipulators
KW  - mobile robots
KW  - random processes
KW  - robot dynamics
KW  - robot kinematics
KW  - state-space methods
KW  - trajectory control
KW  - trees (mathematics)
KW  - kinodynamic RRT planner
KW  - atlas
KW  - state-space manifold
KW  - randomized kinodynamic planner
KW  - holonomic constraints
KW  - constrained systems
KW  - high-dimensional dynamical systems
KW  - parallel manipulators
KW  - complex systems
KW  - trajectories
KW  - robots
KW  - Mathematical model
KW  - Robot kinematics
KW  - Planning
KW  - Trajectory
KW  - Manifolds
KW  - Standards
DO  - 10.1109/ICRA.2018.8460753
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Kinodynamic RRT planners are considered to be general tools for effectively finding feasible trajectories for high-dimensional dynamical systems. However, they struggle when holonomic constraints are present in the system, such as those arising in parallel manipulators, in robots that cooperate to fulfill a given task, or in situations involving contacts with the environment. In such cases, the state space becomes an implicitly-defined manifold, which makes the diffusion heuristic inefficient and leads to inaccurate dynamical simulations. To address these issues, this paper presents an extension of the kinodynamic RRT planner that constructs an atlas of the state-space manifold incrementally, and uses this atlas both to generate random states and to dynamically steer the system towards such states. To the best of our knowledge, this is the first randomized kinodynamic planner that explicitly takes holonomic constraints into account. We validate the approach in significantly-complex systems.
ER  - 

TY  - CONF
TI  - Learning Sampling Distributions for Robot Motion Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7087
EP  - 7094
AU  - B. Ichter
AU  - J. Harrison
AU  - M. Pavone
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - sampling methods
KW  - robot motion planning
KW  - sampling-based motion planning
KW  - collision-avoidance
KW  - variational autoencoder
KW  - bias sampling
KW  - Planning
KW  - Robots
KW  - Probabilistic logic
KW  - Manifolds
KW  - Collision avoidance
KW  - Feature extraction
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8460730
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A defining feature of sampling-based motion planning is the reliance on an implicit representation of the state space, which is enabled by a set of probing samples. Traditionally, these samples are drawn either probabilistically or deterministically to uniformly cover the state space. Yet, the motion of many robotic systems is often restricted to “small” regions of the state space, due to e.g. differential constraints or collision-avoidance constraints. To accelerate the planning process, it is thus desirable to devise non-uniform sampling strategies that favor sampling in those regions where an optimal solution might lie. This paper proposes a methodology for nonuniform sampling, whereby a sampling distribution is learned from demonstrations, and then used to bias sampling. The sampling distribution is computed through a conditional variational autoencoder, allowing sample generation from the latent space conditioned on the specific planning problem. This methodology is general, can be used in combination with any sampling-based planner, and can effectively exploit the underlying structure of a planning problem while maintaining the theoretical guarantees of sampling-based approaches. Specifically, on several planning problems, the proposed methodology is shown to effectively learn representations for the relevant regions of the state space, resulting in an order of magnitude improvement in terms of success rate and convergence to the optimal cost.
ER  - 

TY  - CONF
TI  - Deep Object-Centric Representations for Generalizable Robot Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7111
EP  - 7118
AU  - C. Devin
AU  - P. Abbeel
AU  - T. Darrell
AU  - S. Levine
PY  - 2018
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - visual perception
KW  - robotic manipulation
KW  - generalizable robot learning
KW  - object-centric representations
KW  - reinforcement learning
KW  - object-level attentional mechanism
KW  - perception system
KW  - semantic feature space
KW  - Task analysis
KW  - Visualization
KW  - Semantics
KW  - Trajectory
KW  - Computer vision
KW  - Standards
DO  - 10.1109/ICRA.2018.8461196
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotic manipulation in complex open-world scenarios requires both reliable physical manipulation skills and effective and generalizable perception. In this paper, we propose using an object-centric prior and a semantic feature space for the perception system of a learned policy. We devise an object-level attentional mechanism that can be used to determine relevant objects from a few trajectories or demonstrations, and then immediately incorporate those objects into a learned policy. A task-independent attention locates possible objects in the scene, and a task-specific attention identifies which objects are predictive of the trajectories. The scope of the task-specific attention is easily adjusted by showing demonstrations with distractor objects or with diverse relevant objects. Our results indicate that this approach exhibits good generalization across object instances using very few samples, and can be used to learn a variety of manipulation tasks using reinforcement learning.
ER  - 

TY  - CONF
TI  - Real-time 3D Glint Detection in Remote Eye Tracking Based on Bayesian Inference
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7119
EP  - 7126
AU  - D. Geisler
AU  - D. Fox
AU  - E. Kasneci
PY  - 2018
KW  - Bayes methods
KW  - gaze tracking
KW  - human-robot interaction
KW  - object detection
KW  - stereo image processing
KW  - remote eye tracking
KW  - Bayesian inference
KW  - human gaze
KW  - cognitive states
KW  - gaze-based interaction
KW  - human-robot collaboration
KW  - gaze estimation
KW  - 3D glint detection
KW  - Cameras
KW  - Gaze tracking
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Probabilistic logic
KW  - Solid modeling
KW  - Calibration
DO  - 10.1109/ICRA.2018.8460800
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - As human gaze provides information on our cognitive states, actions, and intentions, gaze-based interaction has the potential to enable a fluent and natural human-robot collaboration. In this work, we focus on reliable gaze estimation in remote eye tracking based on calibration-free methods. Although these methods work well in controlled settings, they fail when illumination conditions change or other objects induce noise. We propose a novel, adaptive method based on a probabilistic model, which reliably detects glints from stereo images and evaluate our method using a data set that contains different challenges with regarding to light and reflections.
ER  - 

TY  - CONF
TI  - Generative One-Shot Learning (GOL): A Semi-Parametric Approach to One-Shot Learning in Autonomous Vision
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7127
EP  - 7134
AU  - S. M. Grigorescu
PY  - 2018
KW  - computer vision
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object recognition
KW  - Pareto optimisation
KW  - GOL
KW  - input single one-shot objects
KW  - environment perception
KW  - autonomous vision
KW  - semiparametric approach
KW  - deep neural networks
KW  - visual perception
KW  - driving environment
KW  - training perceptions systems
KW  - generative framework
KW  - highly autonomous driving systems
KW  - generative one-shot learning
KW  - HAD systems
KW  - Pareto optimal solutions
KW  - object detection algorithms
KW  - Pareto optimization
KW  - Training
KW  - Autonomous vehicles
KW  - Generators
KW  - Linear programming
KW  - Probability density function
DO  - 10.1109/ICRA.2018.8461174
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Highly Autonomous Driving (HAD) systems rely on deep neural networks for the visual perception of the driving environment. Such networks are train on large manually annotated databases. In this work, a semi-parametric approach to one-shot learning is proposed, with the aim of bypassing the manual annotation step required for training perceptions systems used in autonomous driving. The proposed generative framework, coined Generative One-Shot Learning (GOL), takes as input single one-shot objects, or generic patterns, and a small set of so-called regularization samples used to drive the generative process. New synthetic data is generated as Pareto optimal solutions from one-shot objects using a set of generalization functions built into a generalization generator. GOL has been evaluated on environment perception challenges encountered in autonomous vision.
ER  - 

TY  - CONF
TI  - Adaptive Deep Learning Through Visual Domain Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7135
EP  - 7142
AU  - G. Angeletti
AU  - B. Caputo
AU  - T. Tommasi
PY  - 2018
KW  - generalisation (artificial intelligence)
KW  - humanoid robots
KW  - human-robot interaction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - robot vision
KW  - domain shift
KW  - end-to-end deep domain adaptation architecture
KW  - target domain
KW  - training time
KW  - human-robot interactions
KW  - adaptive deep
KW  - visual domain localization
KW  - commercial robot
KW  - illumination conditions
KW  - domain adaptation methods
KW  - robotics applications
KW  - computer vision
KW  - generalization issue
KW  - iCub World database
KW  - Visualization
KW  - Training
KW  - Adaptive systems
KW  - Adaptation models
KW  - Machine learning
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460650
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A commercial robot, trained by its manufacturer to recognize a predefined number and type of objects, might be used in many settings, that will in general differ in their illumination conditions, background, type and degree of clutter, and so on. Recent computer vision works tackle this generalization issue through domain adaptation methods, assuming as source the visual domain where the system is trained and as target the domain of deployment. All approaches assume to have access to images from all classes of the target during training, an unrealistic condition in robotics applications. We address this issue proposing an algorithm that takes into account the specific needs of robot vision. Our intuition is that the nature of the domain shift experienced mostly in robotics is local. We exploit this through the learning of maps that spatially ground the domain and quantify the degree of shift, embedded into an end-to-end deep domain adaptation architecture. By explicitly localizing the roots of the domain shift we significantly reduce the number of parameters of the architecture to tune, we gain the flexibility necessary to deal with subset of categories in the target domain at training time, and we provide a clear feedback on the rationale behind any classification decision, which can be exploited in human-robot interactions. Experiments on two different settings of the iCub World database confirm the suitability of our method for robot vision.
ER  - 

TY  - CONF
TI  - Towards Understanding Object-Directed Actions: A Generative Model for Grounding Syntactic Categories of Speech Through Visual Perception
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7143
EP  - 7150
AU  - A. Aly
AU  - T. Taniguchi
PY  - 2018
KW  - Bayes methods
KW  - cognition
KW  - hidden Markov models
KW  - human-robot interaction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - object detection
KW  - robot vision
KW  - object-directed actions
KW  - human arm joints
KW  - manipulating objects
KW  - segmented objects
KW  - successful human-robot collaboration
KW  - high-level cognitive functions
KW  - human language
KW  - human actions
KW  - Hidden Markov models
KW  - Grounding
KW  - Tagging
KW  - Three-dimensional displays
KW  - Robots
KW  - Computational modeling
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2018.8461231
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Creating successful human-robot collaboration requires robots to have high-level cognitive functions that could allow them to understand human language and actions in space. To meet this target, an elusive challenge that we address in this paper is to understand object-directed actions through grounding language based on visual cues representing the dynamics of human actions on objects, object characteristics (color and geometry), and spatial relationships between objects in a tabletop scene. The proposed probabilistic framework investigates unsupervised Part-of-Speech (POS) tagging to determine syntactic categories of words so as to infer grammatical structure of language. The dynamics of object-directed actions are characterized through the locations of the human arm joints - modeled on a Hidden Markov Model (HMM) - while manipulating objects, in addition to those of objects represented in 3D point clouds. These corresponding point clouds to segmented objects encode geometric features and spatial semantics of referents and landmarks in the environment. The proposed Bayesian learning model is successfully evaluated through interaction experiments between a human user and Toyota HSR robot in space.
ER  - 

TY  - CONF
TI  - GeneSIS-Rt: Generating Synthetic Images for Training Secondary Real-World Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7151
EP  - 7158
AU  - G. J. Stein
AU  - N. Roy
PY  - 2018
KW  - collision avoidance
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - synthetic images
KW  - synthetic data
KW  - domain-specific learning tasks
KW  - leverage recent progress
KW  - image-to-image translation
KW  - simulated images
KW  - realistic training data
KW  - real-world images
KW  - GeneSIS-Rtameliorates
KW  - GeneSIS-Rtto
KW  - high-accuracy predictions
KW  - raw simulated data
KW  - GeneSIS-RT images
KW  - mission-critical tasks
KW  - secondary real-world task training
KW  - cluttered environment
KW  - reactive obstacle avoidance
KW  - semantic segmentation
KW  - Training
KW  - Task analysis
KW  - Semantics
KW  - Image segmentation
KW  - Collision avoidance
KW  - Gallium nitride
KW  - Training data
DO  - 10.1109/ICRA.2018.8462971
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a novel approach for generating high-quality, synthetic data for domain-specific learning tasks, for which training data may not be readily available. We leverage recent progress in image-to-image translation to bridge the gap between simulated and real images, allowing us to generate realistic training data for real-world tasks using only unlabeled real-world images and a simulation. GeneSIS-Rtameliorates the burden of having to collect labeled real-world images and is a promising candidate for generating high-quality, domain-specific, synthetic data. To show the effectiveness of using GeneSIS-Rtto create training data, we study two tasks: semantic segmentation and reactive obstacle avoidance. We demonstrate that learning algorithms trained using data generated by GeneSIS-RT make high-accuracy predictions and outperform systems trained on raw simulated data alone, and as well or better than those trained on real data. Finally, we use our data to train a quadcopter to fly 60 meters at speeds up to 3.4 m/s through a cluttered environment, demonstrating that our GeneSIS-RT images can be used to learn to perform mission-critical tasks.
ER  - 

TY  - CONF
TI  - Enhancing Underwater Imagery Using Generative Adversarial Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7159
EP  - 7165
AU  - C. Fabbri
AU  - M. J. Islam
AU  - J. Sattar
PY  - 2018
KW  - autonomous underwater vehicles
KW  - decision making
KW  - image colour analysis
KW  - image denoising
KW  - image fusion
KW  - image restoration
KW  - neural nets
KW  - robot vision
KW  - Generative Adversarial Networks
KW  - autonomous underwater vehicles
KW  - AUVs
KW  - intelligent decision making
KW  - color distortion
KW  - noisy images
KW  - distorted images
KW  - underwater image restoration
KW  - underwater imagery
KW  - visual data quality
KW  - visual underwater scene quality
KW  - Nonlinear distortion
KW  - Gallium nitride
KW  - Generators
KW  - Image color analysis
KW  - Visualization
KW  - Sensors
DO  - 10.1109/ICRA.2018.8460552
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous underwater vehicles (AUVs) rely on a variety of sensors - acoustic, inertial and visual - for intelligent decision making. Due to its non-intrusive, passive nature and high information content, vision is an attractive sensing modality, particularly at shallower depths. However, factors such as light refraction and absorption, suspended particles in the water, and color distortion affect the quality of visual data, resulting in noisy and distorted images. AUVs that rely on visual sensing thus face difficult challenges and consequently exhibit poor performance on vision-driven tasks. This paper proposes a method to improve the quality of visual underwater scenes using Generative Adversarial Networks (GANs), with the goal of improving input to vision-driven behaviors further down the autonomy pipeline. Furthermore, we show how recently proposed methods are able to generate a dataset for the purpose of such underwater image restoration. For any visually-guided underwater robots, this improvement can result in increased safety and reliability through robust visual perception. To that effect, we present quantitative and qualitative data which demonstrates that images corrected through the proposed approach generate more visually appealing images, and also provide increased accuracy for a diver tracking algorithm.
ER  - 

TY  - CONF
TI  - Faster R-CNN with Classifier Fusion for Small Fruit Detection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7166
EP  - 7172
AU  - X. Mai
AU  - H. Zhang
AU  - M. Q. -. Meng
PY  - 2018
KW  - convolution
KW  - crops
KW  - feedforward neural nets
KW  - image classification
KW  - image fusion
KW  - object detection
KW  - probability
KW  - recurrent neural nets
KW  - robot vision
KW  - multiple classifiers
KW  - classifier correlation
KW  - small fruit detection
KW  - Faster R-CNN network
KW  - multiple classifier fusion
KW  - objectness classification
KW  - probabilities
KW  - agricultural robots
KW  - Proposals
KW  - Correlation
KW  - Feature extraction
KW  - Image segmentation
KW  - Machine learning
KW  - Robots
KW  - Adaptation models
DO  - 10.1109/ICRA.2018.8461130
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The-state-of-the-art of fruit detection with Faster R-CNN shows lack of detection advantage on small fruits. One of reasons is only single level features is used for localization of proposal candidates. In this paper, we propose to incorporate a multiple classifier fusion strategy into a Faster R-CNN network for small fruit detection. We utilize features from three different levels to learn three classifiers for objectness classification in the stage of proposal localization. Probabilities from classifiers are combined by a simple convolutional layer to generate final objectness classification for proposal candidates. In order to keep diversity of multiple classifiers, a novel loss term of classifier correlation is introduced into original loss function. Experimental results show that our model is feasible for detecting small fruits.
ER  - 

TY  - CONF
TI  - Robot Button Pressing in Human Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7173
EP  - 7180
AU  - F. Wang
AU  - G. Chen
AU  - K. Hauser
PY  - 2018
KW  - calibration
KW  - mobile robots
KW  - service robots
KW  - robot button pressing
KW  - human environments
KW  - service robots
KW  - mobile robot
KW  - SwitchIt
KW  - hand-held tablet
KW  - buttons categorization
KW  - Force
KW  - Robot sensing systems
KW  - Switches
KW  - Reliability
KW  - Pressing
KW  - Service robots
DO  - 10.1109/ICRA.2018.8463180
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In order to conduct many desirable functions, service robots will need to actuate buttons and switches that are designed for humans. This paper presents the design of a robot named SwitchIt that is small, relatively inexpensive, easily mounted on a mobile robot, and actuates buttons reliably. Its operating characteristics were developed after conducting a systematic study of buttons and switches in human environments. From this study, we develop a categorization of buttons based on a set of physical properties relevant for robots to operate them. After a human calibrates and annotates buttons in the robot's environment using a hand-held tablet, the system automatically recognizes, pushes, and detects the state of a variety of buttons. Empirical tests demonstrate that the system succeeds in operating 95.7% of 234 total buttons/switches in an office building and a household environment.
ER  - 

TY  - CONF
TI  - Enhancing Overall Object Placement by Understanding Uncertain Spatial and Qualitative Distance Information in User Commands
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7181
EP  - 7188
AU  - M. M. S. N. Edirisinghe
AU  - M. A. V. J. Muthugala
AU  - H. P. C. Sirithunge
AU  - A. G. Buddhika
AU  - P. Jayasekara
PY  - 2018
KW  - human-robot interaction
KW  - speech-based user interfaces
KW  - uncertain spatial terms
KW  - uncertain qualitative terms
KW  - placement location
KW  - object placement
KW  - qualitative distance information
KW  - voice commands
KW  - peer companions
KW  - daily assistive tasks
KW  - assistive robot companions
KW  - voice instructions
KW  - Task analysis
KW  - Navigation
KW  - Visualization
KW  - Robot kinematics
KW  - Service robots
KW  - Manipulators
KW  - human-robot interactions
KW  - human friendly robotics
KW  - service robotics
KW  - object manipulation
KW  - spatial infor-mation
DO  - 10.1109/ICRA.2018.8460624
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Humans prefer to use voice commands to guide their peer companions in daily assistive tasks. In human perspective, they expect same behavior from assistive robot companions as well. The paper presents an approach towards using such voice instructions based on uncertain and qualitative information to describe object placements. Consider a case in which a set of objects has to be arranged on a table in a particular spatial area. In such a situation, humans will prefer to use a single command regarding overall arrangement rather than repeating the same command for each and every object placement. In such scenarios, people will be comfortable with commands which are simple and with non-technical words. Most of such commands include uncertain spatial terms such as “Left”, “Middle”, “Right” and uncertain qualitative terms such as “Together”, “Little separately”, “Separately” to describe the arrangement. For example “Keep all objects together in the middle of the table” and “Keep objects separately on the right side of the table” can be considered. But in some situations, these commands will not give a direct idea about the placement location of the objects. For instance, “Keep the middle of the table free” can be cited. Therefore, the robot must be able to understand precisely such information in commands before executing them. The experiments are conducted in a simulated domestic environment. Results of the experiment are presented and discussed.
ER  - 

TY  - CONF
TI  - Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7189
EP  - 7195
AU  - B. Lee
AU  - J. Choi
AU  - C. Baek
AU  - B. Zhang
PY  - 2018
KW  - Bayes methods
KW  - collision avoidance
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - predictive control
KW  - robot vision
KW  - robust control
KW  - service robots
KW  - trajectory control
KW  - variational techniques
KW  - RoboCup@Home 2017 Social Standard Platform League
KW  - robust functions
KW  - home service robots
KW  - service-oriented robots
KW  - human assistance
KW  - commercial service robot
KW  - RGB-D camera
KW  - deep learning methods
KW  - variational Bayesian techniques
KW  - deep learning modules
KW  - dynamic home environment
KW  - deep Bayesian trajectory prediction method
KW  - collision avoidance
KW  - robust human following
KW  - smooth person following capability
KW  - human cooperation
KW  - robustness
KW  - target detection
KW  - robot following ability
KW  - Robot kinematics
KW  - Trajectory
KW  - Collision avoidance
KW  - Robustness
KW  - Robot sensing systems
KW  - Bayes methods
DO  - 10.1109/ICRA.2018.8462969
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.
ER  - 

TY  - CONF
TI  - Ruling the Control Authority of a Service Robot Based on Information Precision
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7204
EP  - 7210
AU  - V. Magnago
AU  - M. Andreetto
AU  - S. Divan
AU  - D. Fontanelli
AU  - L. Palopoli
PY  - 2018
KW  - geriatrics
KW  - handicapped aids
KW  - mobile robots
KW  - path planning
KW  - position control
KW  - service robots
KW  - SLAM (robots)
KW  - active sensing system
KW  - control law
KW  - senior user guidance
KW  - path following problem
KW  - landmarks
KW  - actuator control
KW  - accurate localisation
KW  - exact localisation
KW  - robotic walking assistant
KW  - information precision
KW  - service robot
KW  - control authority
KW  - design strategy
KW  - massive data collection
KW  - SLAM approaches
KW  - Robot sensing systems
KW  - Estimation error
KW  - Uncertainty
KW  - Probabilistic logic
KW  - Service robots
KW  - Automobiles
DO  - 10.1109/ICRA.2018.8460714
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the problem of guiding a senior user along a path using a robotic walking assistant. This is a particular type of path following problem, for which most of the solutions available in the literature require an exact localisation of the robot in the environment. An accurate localisation is obtained either with a heavy infrastructure (e.g., an active sensing system deployed in the environment or deploying landmarks in known positions) or using SLAM approaches with a massive data collection. Our key observation is that the intervention of the system (and a good level of accuracy) is only required in proximity of difficult decision points, while we can rely on the user in an environment where the only possibility is just to maintain a course (e.g., a corridor). The direct implication is that we can instrument the environment with a heavy infrastructure only in certain areas. This design strategy has to be complemented by an adequate control law that shifts the authority (i.e., the control of the actuators) between the robot and the user according to the accuracy of the information available to the robot. Such a control law is exactly the contribution of this paper.
ER  - 

TY  - CONF
TI  - A Nonparametric Motion Flow Model for Human Robot Cooperation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7211
EP  - 7218
AU  - S. Choi
AU  - K. Lee
AU  - H. A. Park
AU  - S. Oh
PY  - 2018
KW  - Gaussian processes
KW  - human-robot interaction
KW  - image motion analysis
KW  - image representation
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - nonparametric motion flow model
KW  - human robot cooperation method
KW  - partial trajectory information
KW  - target trajectories
KW  - learned motion description
KW  - underlying reward function
KW  - interacting trajectories
KW  - variance functions
KW  - temporal properties
KW  - spatial properties
KW  - motion flow similarity measure
KW  - motion trajectory
KW  - Trajectory
KW  - Motion measurement
KW  - Kernel
KW  - Computational modeling
KW  - Robot sensing systems
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8463201
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a novel nonparametric motion flow model that effectively describes a motion trajectory of a human and its application to human robot cooperation. To this end, motion flow similarity measure which considers both spatial and temporal properties of a trajectory is proposed by utilizing the mean and variance functions of a Gaussian process. We also present a human robot cooperation method using the proposed motion flow model. Given a set of interacting trajectories of two workers, the underlying reward function of cooperating behaviors is optimized by using the learned motion description as an input to the reward function where a stochastic trajectory optimization method is used to control a robot. The presented human robot cooperation method is compared with the state-of-the-art algorithm, which utilizes a mixture of interaction primitives (MIP), in terms of the RMS error between generated and target trajectories. While the proposed method shows comparable performance with the MIP when the full observation of human demonstrations is given, it shows superior performance when partial trajectory information is given.
ER  - 

TY  - CONF
TI  - Learning by Demonstration and Adaptation of Finishing Operations Using Virtual Mechanism Approach
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7219
EP  - 7225
AU  - B. Nemec
AU  - K. Yasuda
AU  - N. Mullennix
AU  - N. Likar
AU  - A. Ude
PY  - 2018
KW  - force sensors
KW  - grinding
KW  - grinding machines
KW  - industrial robots
KW  - iterative learning control
KW  - polishing
KW  - polishing machines
KW  - robot dynamics
KW  - robot kinematics
KW  - surface finishing
KW  - finishing operations
KW  - virtual mechanism approach
KW  - passive digitizer
KW  - optimal robot execution
KW  - serial kinematic chain
KW  - augmented system
KW  - polishing tools
KW  - grinding tool
KW  - iterative learning controller
KW  - Robot kinematics
KW  - Task analysis
KW  - Tools
KW  - Service robots
KW  - Trajectory
KW  - Quaternions
DO  - 10.1109/ICRA.2018.8460603
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a new approach for efficient programming of grinding and polishing operation. In the proposed system, the initial policy is performed by a skilled operator and recorded with a passive digitizer. The demonstrated policy comprises both position and force data. The optimal robot execution of the task is provided by applying a virtual mechanism approach, which models the polishing/grinding tool as a serial kinematic chain. By joining the robot and the virtual mechanism in an augmented system, additional degrees of freedom are obtained and redundancy resolution can be applied to optimize the demonstrated motion. Another benefit of the proposed approach is that the same policy can be transferred to different combination of robots and grinding/polishing tools without any modification of the captured motion. The proposed approach requires known contact point between the treated object and the polishing/grinding tool. We propose a novel approach for accurate estimation of this point using data obtained from the force-torque sensor. Finally, the demonstrated path is refined to compensate for inaccurate calibration and different dynamics of a robot and the human demonstrator using iterative learning controller. The proposed method was verified in a real industrial environment.
ER  - 

TY  - CONF
TI  - Hybrid Probabilistic Trajectory Optimization Using Null-Space Exploration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7226
EP  - 7232
AU  - Y. Huang
AU  - J. Silvério
AU  - L. Rozo
AU  - D. G. Caldwell
PY  - 2018
KW  - humanoid robots
KW  - learning systems
KW  - manipulator kinematics
KW  - probability
KW  - trajectory control
KW  - joint space
KW  - motion constraints
KW  - probabilistic formulation
KW  - dynamic movement primitives
KW  - probabilistic treatment
KW  - trajectory constraints
KW  - hybrid space learning
KW  - motion smoothness
KW  - robot null-space
KW  - hybrid probabilistic trajectory optimization
KW  - null-space exploration
KW  - Cartesian space
KW  - learning from demonstration
KW  - Jacobian-based inverse kinematics
KW  - Probabilistic logic
KW  - Task analysis
KW  - Robot kinematics
KW  - Acceleration
KW  - Trajectory optimization
DO  - 10.1109/ICRA.2018.8460550
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the context of learning from demonstration, human examples are usually imitated in either Cartesian or joint space. However, this treatment might result in undesired movement trajectories in either space. This is particularly important for motion skills such as striking, which typically imposes motion constraints in both spaces. In order to address this issue, we consider a probabilistic formulation of dynamic movement primitives, and apply it to adapt trajectories in Cartesian and joint spaces simultaneously. The probabilistic treatment allows the robot to capture the variability of multiple demonstrations and facilitates the mixture of trajectory constraints from both spaces. In addition to this proposed hybrid space learning, the robot often needs to consider additional constraints such as motion smoothness and joint limits. On the basis of Jacobian-based inverse kinematics, we propose to exploit robot null-space so as to unify trajectory constraints from Cartesian and joint spaces while satisfying additional constraints. Evaluations of hand-shaking and striking tasks carried out with a humanoid robot demonstrate the applicability of our approach.
ER  - 

TY  - CONF
TI  - Feature-constrained Active Visual SLAM for Mobile Robot Navigation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7233
EP  - 7238
AU  - X. Deng
AU  - Z. Zhang
AU  - A. Sintov
AU  - J. Huang
AU  - T. Bretl
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - sensory constraints
KW  - iterative motion planning framework
KW  - collision avoidance
KW  - online mapping
KW  - associated map points
KW  - distance-optimal path planner
KW  - data-driven approach
KW  - continuous identification
KW  - feature-based Visual Simultaneous Localization
KW  - vision-based navigation
KW  - failure avoidance
KW  - mobile robot navigation
KW  - feature-constrained active Visual SLAM
KW  - Cameras
KW  - Navigation
KW  - Collision avoidance
KW  - Simultaneous localization and mapping
KW  - Planning
DO  - 10.1109/ICRA.2018.8460721
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper focuses on tracking failure avoidance during vision-based navigation to a desired goal in unknown environments. While using feature-based Visual Simultaneous Localization and Mapping (VSLAM), continuous identification and association of map points are required during motion. Thus, we discuss a motion planning framework that takes into account sensory constraints for a reliable navigation. We use information available in the SLAM and propose a data-driven approach to predict the number of map points associated in a given pose. Then, a distance-optimal path planner utilizes the model to constrain paths such that the number of associated map points in each pose is above a threshold. We also include an online mapping of the environment for collision avoidance. Overall, we propose an iterative motion planning framework that enables real-time replanning after the acquisition of more information. Experiments in two environments demonstrate the performance of the proposed framework.
ER  - 

TY  - CONF
TI  - Level-Headed: Evaluating Gimbal-Stabilised Visual Teach and Repeat for Improved Localisation Performance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7239
EP  - 7246
AU  - M. Warren
AU  - A. P. Schoellig
AU  - T. D. Barfoot
PY  - 2018
KW  - feature extraction
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - rough terrain
KW  - unstructured terrain
KW  - border patrol
KW  - agricultural work
KW  - sensor-based navigation
KW  - erratic motion
KW  - feature-poor environments test feature tracking
KW  - repeat matching
KW  - salient point features
KW  - Grizzly Robotic Utility Vehicle
KW  - actively gimbaled camera
KW  - image motion
KW  - search-and-rescue
KW  - field-deployable ground robot
KW  - vision-based route-following
KW  - feature extraction
KW  - Transforms
KW  - Cameras
KW  - Visualization
KW  - Robot sensing systems
KW  - Robustness
KW  - Navigation
DO  - 10.1109/ICRA.2018.8460961
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Operating in rough, unstructured terrain is an essential requirement for any truly field-deployable ground robot. Search-and-rescue, border patrol and agricultural work all require operation in environments with little established infrastructure for easy navigation. This presents challenges for sensor-based navigation such as vision, where erratic motion and feature-poor environments test feature tracking and hinder the performance of repeat matching of point features. For vision-based route-following methods such as Visual Teach and Repeat (VT&R), maintaining similar visual perspective of salient point features is critical for reliable odometry and accurate localisation over long periods. In this paper, we investigate a potential solution to these challenges by integrating a gimbaled camera with VT&R on a Grizzly Robotic Utility Vehicle (RUV) for testing at high speeds and in visually challenging environments. We examine the benefits and drawbacks of using an actively gimbaled camera to attenuate image motion and control viewpoint. We compare the use of a gimbaled camera to our traditional fixed stereo configuration and demonstrate cases of improved performance in Visual Odometry (VO), localisation and path following in several sets of outdoor experiments.
ER  - 

TY  - CONF
TI  - Low-Drift Visual Odometry in Structured Environments by Decoupling Rotational and Translational Motion
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7247
EP  - 7253
AU  - P. Kim
AU  - B. Coltin
AU  - H. J. Kim
PY  - 2018
KW  - distance measurement
KW  - mobile robots
KW  - motion control
KW  - motion estimation
KW  - position control
KW  - robot vision
KW  - motion estimation process
KW  - positioning inaccuracy
KW  - structured environments
KW  - rotational motion
KW  - drift-free rotation
KW  - SO(3)-manifold constrained mean shift algorithm
KW  - multiple orthogonal planes
KW  - rotation estimate
KW  - structural regularities
KW  - drift-free rotational motion
KW  - low-drift visual odometry algorithm
KW  - translational motion
KW  - Cameras
KW  - Tracking
KW  - Three-dimensional displays
KW  - Estimation
KW  - Visual odometry
KW  - Feature extraction
KW  - Image segmentation
DO  - 10.1109/ICRA.2018.8463207
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a low-drift visual odometry algorithm that separately estimates rotational and translational motion from lines, planes, and points found in RGB-D images. Previous methods estimate drift-free rotational motion from structural regularities to reduce drift in the rotation estimate, which is the primary source of positioning inaccuracy in visual odometry. However, multiple orthogonal planes are required to be visible throughout the entire motion estimation process; otherwise, these VO approaches fail. We propose a new approach to estimate drift-free rotational motion jointly from both lines and planes by exploiting environmental regularities. We track the spatial regularities with an efficient SO(3)-manifold constrained mean shift algorithm. Once the drift-free rotation is found, we recover the translational motion from all tracked points with and without depth by minimizing the de-rotated reprojection error. We compare the proposed algorithm to other state-of-the-art visual odometry methods on a variety of RGB-D datasets (including especially challenging pure rotations) and demonstrate improved accuracy and lower drift error.
ER  - 

TY  - CONF
TI  - Visual Homing via Guided Locality Preserving Matching
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7254
EP  - 7261
AU  - J. Ma
AU  - J. Zhao
AU  - J. Jiang
AU  - H. Zhou
AU  - Y. Zhou
AU  - Z. Wang
AU  - X. Guo
PY  - 2018
KW  - computational complexity
KW  - feature extraction
KW  - image matching
KW  - motion estimation
KW  - guided locality preserving matching
KW  - GLPM
KW  - panoramic images
KW  - linear space complexities
KW  - visual homing problem
KW  - sparse feature matches
KW  - homing directions
KW  - feature matching
KW  - mismatch removal
KW  - dense motion flow estimation
KW  - Tikhonov regularization
KW  - Visualization
KW  - Feature extraction
KW  - Electronic mail
KW  - Cost function
KW  - Measurement
KW  - Closed-form solutions
KW  - Intelligent robots
DO  - 10.1109/ICRA.2018.8460935
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This study proposes a simple yet surprisingly effective feature matching approach, termed as guided locality preserving matching (GLPM), for visual homing of panoramic images. The key idea of our approach is merely to preserve the neighborhood structures of potential true matches between two panoramic images. We formulate it into a mathematical model, and derive a simple closed-form solution with linearithmic time and linear space complexities. This enables our method to accomplish the mismatch removal from hundreds of putative correspondences in only a few milliseconds. To handle extremely large proportions of outliers, we further design a guided matching strategy based on the proposed method, using the matching result on a small putative set with a high inlier ratio to guide the matching on a large putative set. This strategy can also significantly boost true matches without sacrifice in accuracy. To apply our GLPM to the visual homing problem, we develop a method for dense motion flow estimation from sparse feature matches based on Tikhonov regularization. Moreover, the focus-of-contraction/focus-of-expansion is derived to determine homing directions. The effectiveness of our method is demonstrated on a panoramic database in both feature matching and visual homing.
ER  - 

TY  - CONF
TI  - LOGOS: Local Geometric Support for High-Outlier Spatial Verification
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7262
EP  - 7269
AU  - S. Lowry
AU  - H. Andreasson
PY  - 2018
KW  - feature extraction
KW  - pose estimation
KW  - outlier removal
KW  - LOGOS
KW  - local geometric support
KW  - high-outlier spatial verification
KW  - visual localization
KW  - orientation information
KW  - inlier points
KW  - secondary localization verification
KW  - benchmark localization datasets
KW  - local neighbourhoods
KW  - pose estimation
KW  - Visualization
KW  - Feature extraction
KW  - Robustness
KW  - Urban areas
KW  - Transforms
KW  - Pose estimation
KW  - Robots
DO  - 10.1109/ICRA.2018.8460988
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents LOGOS, a method of spatial verification for visual localization that is robust in the presence of a high proportion of outliers. LOGOS uses scale and orientation information from local neighbourhoods of features to determine which points are likely to be inliers. The inlier points can be used for secondary localization verification and pose estimation. LOGOS is demonstrated on a number of benchmark localization datasets and outperforms RANSAC as a method of outlier removal and localization verification in scenarios that require robustness to many outliers.
ER  - 

TY  - CONF
TI  - Selection and Compression of Local Binary Features for Remote Visual SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7270
EP  - 7277
AU  - D. Van Opdenbosch
AU  - M. Oelsch
AU  - A. Garcea
AU  - T. Aykut
AU  - E. Steinbach
PY  - 2018
KW  - feature extraction
KW  - feature selection
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - SLAM (robots)
KW  - feature selection stage
KW  - remote visual SLAM
KW  - autonomous robotics
KW  - collaborative SLAM approaches
KW  - multiple robots
KW  - feature coding scheme
KW  - simultaneous localization and mapping
KW  - visual sensors
KW  - embedded devices
KW  - local binary features extraction
KW  - centralized powerful processing node
KW  - Visualization
KW  - Encoding
KW  - Simultaneous localization and mapping
KW  - Feature extraction
KW  - Task analysis
KW  - Image coding
DO  - 10.1109/ICRA.2018.8463202
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the field of autonomous robotics, Simultaneous Localization and Mapping (SLAM) is still a challenging problem. With cheap visual sensors attracting more and more attention, various solutions to the SLAM problem using visual cues have been proposed. However, current visual SLAM systems are still computationally demanding, especially on embedded devices. In addition, collaborative SLAM approaches emerge using visual information acquired from multiple robots simultaneously to build a joint map. In order to address both challenges, we present an approach for remote visual SLAM where local binary features are extracted at the robot, compressed and sent over a network to a centralized powerful processing node running the visual SLAM algorithm. To this end, we propose a new feature coding scheme including a feature selection stage which ensures that only relevant information is transmitted. We demonstrate the effectiveness of our approach on well-known datasets. With the proposed approach, it is possible to build an accurate map while limiting the data rate to 75 kbits/frame.
ER  - 

TY  - CONF
TI  - UnDeepVO: Monocular Visual Odometry Through Unsupervised Deep Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7286
EP  - 7291
AU  - R. Li
AU  - S. Wang
AU  - Z. Long
AU  - D. Gu
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pose estimation
KW  - stereo image processing
KW  - unsupervised learning
KW  - monocular visual odometry system
KW  - monocular camera
KW  - deep neural networks
KW  - unsupervised deep learning scheme
KW  - UnDeepVo
KW  - Training
KW  - Cameras
KW  - Machine learning
KW  - Three-dimensional displays
KW  - Estimation
KW  - Image sequences
KW  - Visual odometry
DO  - 10.1109/ICRA.2018.8461251
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a novel monocular visual odometry (VO) system called UnDeepVO in this paper. UnDeepVO is able to estimate the 6-DoF pose of a monocular camera and the depth of its view by using deep neural networks. There are two salient features of the proposed UnDeepVo:one is the unsupervised deep learning scheme, and the other is the absolute scale recovery. Specifically, we train UnDeepVoby using stereo image pairs to recover the scale but test it by using consecutive monocular images. Thus, UnDeepVO is a monocular system. The loss function defined for training the networks is based on spatial and temporal dense information. A system overview is shown in Fig. 1. The experiments on KITTI dataset show our UnDeepVO achieves good performance in terms of pose accuracy.
ER  - 

TY  - CONF
TI  - Counterexamples for Robotic Planning Explained in Structured Language
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7292
EP  - 7297
AU  - L. Feng
AU  - M. Ghasemi
AU  - K. Chang
AU  - U. Topcu
PY  - 2018
KW  - control engineering computing
KW  - formal verification
KW  - integer programming
KW  - linear programming
KW  - Markov processes
KW  - natural languages
KW  - path planning
KW  - robots
KW  - complex automaton
KW  - mixed-integer linear programming
KW  - Markov decision processes
KW  - model checking
KW  - warehouse robots planning
KW  - robotic mission plan
KW  - MDP model
KW  - robotic behavior
KW  - structured natural language sentences
KW  - Robots
KW  - Natural languages
KW  - Planning
KW  - Computational modeling
KW  - Charging stations
KW  - Model checking
KW  - Markov processes
DO  - 10.1109/ICRA.2018.8460945
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Automated techniques such as model checking have been used to verify models of robotic mission plans based on Markov decision processes (MDPs) and generate counterexamples that may help diagnose requirement violations. However, such artifacts may be too complex for humans to understand, because existing representations of counterexamples typically include a large number of paths or a complex automaton. To help improve the interpretability of counterexamples, we define a notion of explainable counterexample, which includes a set of structured natural language sentences to describe the robotic behavior that lead to a requirement violation in an MDP model of robotic mission plan. We propose an approach based on mixed-integer linear programming for generating explainable counterexamples that are minimal, sound and complete. We demonstrate the usefulness of the proposed approach via a case study of warehouse robots planning.
ER  - 

TY  - CONF
TI  - Multi-Vehicle Motion Planning for Social Optimal Mobility-on-Demand
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7298
EP  - 7305
AU  - J. Karlsson
AU  - C. Vasile
AU  - J. Tumova
AU  - S. Karaman
AU  - D. Rus
PY  - 2018
KW  - automobiles
KW  - collision avoidance
KW  - mobile robots
KW  - optimal control
KW  - optimisation
KW  - road traffic
KW  - scheduling
KW  - potential collision situations
KW  - road geometries
KW  - joint motion plans
KW  - multivehicle motion planning
KW  - road network
KW  - Vienna Convention
KW  - desired deadlines
KW  - integrated route
KW  - road traffic
KW  - motion planning problem
KW  - social optimal mobility-on-demand
KW  - self-driving cars
KW  - bubble spaces
KW  - queue scheduling
KW  - Roads
KW  - Planning
KW  - Delays
KW  - Task analysis
KW  - Sensors
KW  - Trajectory
KW  - Automobiles
DO  - 10.1109/ICRA.2018.8462968
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we consider a fleet of self-driving cars operating in a road network governed by rules of the road, such as the Vienna Convention on Road Traffic, providing rides to customers to serve their demands with desired deadlines. We focus on the associated motion planning problem that trades-off the demands' delays and level of violation of the rules of the road to achieve social optimum among the vehicles. Due to operating in the same environment, the interaction between the cars must be taken into account, and can induce further delays. We propose an integrated route and motion planning approach that achieves scalability with respect to the number of cars by resolving potential collision situations locally within so-called bubble spaces enclosing the conflict. The algorithms leverage the road geometries, and perform joint planning only for lead vehicles in the conflict and use queue scheduling for the remaining cars. Furthermore, a framework for storing previously resolved conflict situations is proposed, which can be use for quick querying of joint motion plans. We show the mobility-on-demand setup and effectiveness of the proposed approach in simulated case studies involving up to 10 self-driving vehicles.
ER  - 

TY  - CONF
TI  - Verifying Controllers Against Adversarial Examples with Bayesian Optimization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7306
EP  - 7313
AU  - S. Ghosh
AU  - F. Berkenkamp
AU  - G. Ranade
AU  - S. Qadeer
AU  - A. Kapoor
PY  - 2018
KW  - Bayes methods
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - robots
KW  - safety
KW  - complex safety specifications
KW  - complex controllers
KW  - Bayesian optimization
KW  - adversarial examples
KW  - coherent optimization framework
KW  - Gaussian Process prior
KW  - individual functions
KW  - reinforcement learning
KW  - reward functions
KW  - smooth functions
KW  - complex boolean combinations
KW  - adversarial counter examples
KW  - safety constraints
KW  - Bayesian Optimization
KW  - active-testing framework
KW  - safety-critical applications
KW  - Safety
KW  - Uncertainty
KW  - Robots
KW  - Testing
KW  - Trajectory
KW  - Optimization
KW  - Bayes methods
DO  - 10.1109/ICRA.2018.8460635
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recent successes in reinforcement learning have lead to the development of complex controllers for realworld robots. As these robots are deployed in safety-critical applications and interact with humans, it becomes critical to ensure safety in order to avoid causing harm. A first step in this direction is to test the controllers in simulation. To be able to do this, we need to capture what we mean by safety and then efficiently search the space of all behaviors to see if they are safe. In this paper, we present an active-testing framework based on Bayesian Optimization. We specify safety constraints using logic and exploit structure in the problem in order to test the system for adversarial counter examples that violate the safety specifications. These specifications are defined as complex boolean combinations of smooth functions on the trajectories and, unlike reward functions in reinforcement learning, are expressive and impose hard constraints on the system. In our framework, we exploit regularity assumptions on individual functions in form of a Gaussian Process (GP) prior. We combine these into a coherent optimization framework using problem structure. The resulting algorithm is able to provably verify complex safety specifications or alternatively find counter examples. Experimental results show that the proposed method is able to find adversarial examples quickly.
ER  - 

TY  - CONF
TI  - On the Relationship Between Bisimulation and Combinatorial Filter Reduction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7314
EP  - 7321
AU  - H. Rahmani
AU  - J. M. O'Kane
PY  - 2018
KW  - bisimulation equivalence
KW  - computational complexity
KW  - filtering theory
KW  - minimisation
KW  - polynomials
KW  - equivalence relation
KW  - filter minimization problem
KW  - polynomial time
KW  - bisimulation relations
KW  - bisimilarity relation -the union
KW  - equivalent behavior-is NP-hard
KW  - combinatorial filter reduction
KW  - bisimulation quotient operation
KW  - input filter
KW  - Minimization
KW  - Robots
KW  - Task analysis
KW  - Color
KW  - Computational modeling
KW  - Cognition
KW  - Partitioning algorithms
DO  - 10.1109/ICRA.2018.8460507
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Combinatorial filters are discrete structures for modeling and reasoning about robotic systems. Such filters are of interest not only because of the potential for reduction of the computational power needed to execute the filter, but also for the insight they can sometimes provide into the information requirements of certain robotic tasks. It is known that the filter minimization problem -that is, for a given filter, to find a combinatorial filter with the minimal number of states among all filters with equivalent behavior-is NP-hard. Intuition might suggest that the well-known notion of bisimulation might be of direct use for this minimization problem. Indeed, the bisimilarity relation -the union of all bisimulation relations over the state space of the original filter-is an equivalence relation, and one might attempt to reduce a filter by merging states that are equivalent under this relation. This paper studies this relationship between bisimulation and combinatorial filter reduction. Specifically, we show that every filter minimization problem can be solved by computing a quotient of the input filter with some relation, but that for some filters, the bisimilarity relation is not the correct relation for this purpose. We also characterize the result of the bisimulation quotient operation as the solution to a different, stricter filter minimization problem, and identify several classes of filters for which a variant of bisimulation, called compatibility, can be used to minimize filters in polynomial time.
ER  - 

TY  - CONF
TI  - Learning-Based Model Predictive Control Under Signal Temporal Logic Specifications
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7322
EP  - 7329
AU  - K. Cho
AU  - S. Oh
PY  - 2018
KW  - control system synthesis
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - predictive control
KW  - regression analysis
KW  - temporal logic
KW  - learning-based model predictive control method
KW  - differential constraints
KW  - dynamical systems
KW  - control strategy synthesis method
KW  - signal temporal logic specifications
KW  - specific rules
KW  - model predictive control procedure
KW  - learned margin
KW  - signal temporal logic formula
KW  - designed controller
KW  - traditional control scheme
KW  - Predictive control
KW  - Robustness
KW  - Collision avoidance
KW  - Task analysis
KW  - Gaussian processes
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460811
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a control strategy synthesis method for dynamical systems with differential constraints while satisfying a set of given rules in consideration of their importances. A special attention is given to situations where all rules cannot be met in order to fulfill a given task. Such dilemmas compel us to make a decision on the degree of satisfaction of each rule including which rule should be maintained or not. In this work, we propose a learning-based model predictive control method in order to solve this problem, where a key insight is to combine a learning method and traditional control scheme so that the designed controller behaves close to human experts. A rule is represented as a signal temporal logic (STL) formula. A robustness slackness, a margin to the satisfaction of the rule, is learned from expert's demonstrations using Gaussian process regression. The learned margin is used in a model predictive control procedure, which helps to decide how much to obey each rule, even ignoring specific rules. In track driving simulation, we show that the proposed method generates human-like behavior and efficiently handles dilemmas as human teachers do.
ER  - 

TY  - CONF
TI  - Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7330
EP  - 7337
AU  - P. Schillinger
AU  - M. Bürger
AU  - D. V. Dimarogonas
PY  - 2018
KW  - control engineering computing
KW  - formal specification
KW  - mobile robots
KW  - multi-robot systems
KW  - operating systems (computers)
KW  - path planning
KW  - temporal logic
KW  - probabilistic options
KW  - temporal logic-based multirobot cooperation
KW  - temporal dependencies
KW  - task specification
KW  - robot team
KW  - temporal logic specifications
KW  - goal specification
KW  - ROS implementation
KW  - Robot kinematics
KW  - Task analysis
KW  - Uncertainty
KW  - Planning
KW  - Resource management
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2018.8462967
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.
ER  - 

TY  - CONF
TI  - Path Clustering with Homology Area
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7346
EP  - 7353
AU  - J. F. Carvalho
AU  - M. Vejdemo-Johansson
AU  - D. Kragic
AU  - F. T. Pokorny
PY  - 2018
KW  - computational complexity
KW  - mesh generation
KW  - pattern clustering
KW  - topology
KW  - triangulated mesh
KW  - topology
KW  - path clustering
KW  - pairwise distance calculations
KW  - triangle inequality
KW  - minimum homology area
KW  - Clustering methods
KW  - Topology
KW  - Clustering algorithms
KW  - Toy manufacturing industry
KW  - Robots
KW  - Programming
KW  - Support vector machines
DO  - 10.1109/ICRA.2018.8460939
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Path clustering has found many applications in recent years. Common approaches to this problem use aggregates of the distances between points to provide a measure of dissimilarity between paths which do not satisfy the triangle inequality. Furthermore, they do not take into account the topology of the space where the paths are embedded. To tackle this, we extend previous work in path clustering with relative homology, by employing minimum homology area as a measure of distance between homologous paths in a triangulated mesh. Further, we show that the resulting distance satisfies the triangle inequality, and how we can exploit the properties of homology to reduce the amount of pairwise distance calculations necessary to cluster a set of paths. We further compare the output of our algorithm with that of DTW on a toy dataset of paths, as well as on a dataset of real-world paths.
ER  - 

TY  - CONF
TI  - GraspMan - A Novel Robotic Platform with Grasping, Manipulation, and Multimodal Locomotion Capability
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7354
EP  - 7359
AU  - N. Govindan
AU  - S. S. V. Kovvali
AU  - K. Chandrasekaran
AU  - A. Thondiyath
PY  - 2018
KW  - actuators
KW  - belts
KW  - drives
KW  - grippers
KW  - legged locomotion
KW  - manipulator kinematics
KW  - motion control
KW  - springs (mechanical)
KW  - finger
KW  - synchronous belt drive
KW  - underactuated graspers
KW  - serial kinematic chain
KW  - scalable kinematic structure
KW  - kinematic analysis
KW  - prototype robot
KW  - multimodal locomotion
KW  - robotic platform
KW  - active gripping surface
KW  - underactuated fingers
KW  - multipurpose grasper
KW  - manipulation
KW  - grasping
KW  - GraspMan
KW  - Grasping
KW  - Belts
KW  - Actuators
KW  - Task analysis
KW  - Grippers
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8462970
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present the design of a novel, hybrid multipurpose robotic platform equipped with a pair of graspers to synergize grasping, manipulation, and locomotion. The multipurpose grasper consists of two underactuated fingers with an active gripping surface, which passively conforms to an object while grasping. Each finger has a spring loaded synchronous belt drive which functions as the active gripping surface. The grasper is capable of handling a range of objects with irregular geometry and size. Two such underactuated graspers are connected through a serial kinematic chain and this provides the platform both manipulation and locomotion capability. Graspers act as “legs” or “wheels” of the robot during locomotion and can easily adapt to terrain variations. Fewer number of actuators, simple and scalable kinematic structure, and computationally efficient control are some of the main features of the design. Design details and kinematic analysis are presented. Experiments were conducted on a prototype robot to demonstrate multiple modes of operation.
ER  - 

TY  - CONF
TI  - Design and Evaluation of a Novel Cable-Driven Gripper with Perception Capabilities for Strawberry Picking Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7384
EP  - 7391
AU  - Y. Xiong
AU  - P. J. From
AU  - V. Isler
PY  - 2018
KW  - agriculture
KW  - closed loop systems
KW  - grippers
KW  - infrared detectors
KW  - manipulators
KW  - position control
KW  - robot vision
KW  - robust control
KW  - gripper design
KW  - cable-driven gripper
KW  - autonomous harvesting
KW  - IR sensors
KW  - manipulator arm
KW  - vision algorithm
KW  - robustness
KW  - positional error tolerance
KW  - high-level closed-loop control
KW  - strawberry picking robots
KW  - Grippers
KW  - Servomotors
KW  - Containers
KW  - Sensors
KW  - Robots
KW  - Mechanical cables
KW  - Pulleys
DO  - 10.1109/ICRA.2018.8460705
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel cable-driven gripper with perception capabilities for autonomous harvesting of strawberries. Experiments show that the gripper allows for more accurate and faster picking of strawberries compared to existing systems. The gripper consists of four functional parts for sensing, picking, transmission, and storing. It has six fingers that open to form a closed space to swallow a target strawberry and push other surrounding berries away from the target. Equipped with three IR sensors, the gripper controls a manipulator arm to correct for positional error, and can thus pick strawberries that are not exactly localized by the vision algorithm, improving the robustness. Experiments show that the gripper is gentle on the berries as it merely cuts the stem and there is no physical interaction with the berries during the cutting process. We show that the gripper has close-to-perfect successful picking rate when addressing isolated strawberries. By including internal perception, we get high positional error tolerance, and avoid using slow, high-level closed-loop control. Moreover, the gripper can store several berries, which reduces the overall travel distance for the manipulator, and decreases the time needed to pick a single strawberry substantially. The experiments show that the gripper design decreased picking execution time noticeably compared to results found in literature.
ER  - 

TY  - CONF
TI  - Underactuated Hand Design Using Mechanically Realizable Manifolds
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7392
EP  - 7398
AU  - T. Chen
AU  - M. Haas-Heger
AU  - M. Ciocarlie
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - grippers
KW  - manipulator kinematics
KW  - stability
KW  - hand synergies
KW  - kinematic hand model
KW  - physical underactuation mechanism
KW  - hand posture
KW  - single-actuator hand
KW  - underactuated hand design
KW  - mechanically realizable manifolds
KW  - joint coordination patterns
KW  - planning algorithms
KW  - robotic grasping
KW  - mechanically realizable manifold
KW  - Tendons
KW  - Force
KW  - Optimization
KW  - Springs
KW  - Manifolds
KW  - Kinematics
KW  - Grasping
DO  - 10.1109/ICRA.2018.8462972
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Hand synergies, or joint coordination patterns, have become an effective tool for achieving versatile robotic grasping with simple hands or planning algorithms. Here we propose a method to determine the hand synergies such that they can be physically implemented in an underactuated fashion. Given a kinematic hand model and a set of desired grasps, our algorithm optimizes a Mechanically Realizable Manifold designed to be achievable by a physical underactuation mechanism, enabling the resulting hand to achieve the desired grasps with few actuators. Furthermore, in contrast to existing methods for determining synergies which are only concerned with hand posture, our method explicitly optimizes the stability of the target grasps. We implement this method in the design of a three-finger single-actuator hand as an example, and evaluate its effectiveness numerically and experimentally.
ER  - 

TY  - CONF
TI  - Robotic Handling of Liquids with Spilling Avoidance: A Constraint-Based Control Approach
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7414
EP  - 7420
AU  - R. Maderna
AU  - A. Casalino
AU  - A. M. Zanchettin
AU  - P. Rocco
PY  - 2018
KW  - industrial manipulators
KW  - materials handling
KW  - motion control
KW  - path planning
KW  - sloshing
KW  - handling liquids
KW  - service robotic applications
KW  - motion planning
KW  - liquid transfer
KW  - sloshing control
KW  - anti spilling constraint
KW  - spilling avoidance constraint
KW  - constraint-based control
KW  - sloshing suppression
KW  - industrial ABB robot
KW  - robotic manipulators
KW  - Liquids
KW  - Robots
KW  - Trajectory
KW  - Containers
KW  - Task analysis
KW  - Acceleration
KW  - Optimization
DO  - 10.1109/ICRA.2018.8460927
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Handling liquids with spilling avoidance is a topic of interest for a broad range of fields, both in industry and in service robotic applications. In this paper we present a new control architecture for motion planning of industrial robots, able to tackle the problem of liquid transfer with sloshing control. We do not focus on a complete sloshing suppression, but we show how to enforce an anti spilling constraint. This less conservative approach allows to impose higher accelerations, reducing motion time. A constraint-based approach, amenable to an Online implementation, has been developed. The proposed controller generates trajectories in real time, in order to follow a reference path, while being compliant to the spilling avoidance constraint. The approach has been validated on a 6 degree of freedom industrial ABB robot.
ER  - 

TY  - CONF
TI  - A Robust Robot Design for Item Picking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7421
EP  - 7426
AU  - A. Causo
AU  - Z. Chong
AU  - R. Luxman
AU  - Y. Y. Kok
AU  - Z. Yi
AU  - W. Pang
AU  - R. Meixuan
AU  - Y. S. Teoh
AU  - W. Jing
AU  - H. S. Tju
AU  - I. -. Chen
PY  - 2018
KW  - calibration
KW  - cameras
KW  - grippers
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - path planning
KW  - robot vision
KW  - service robots
KW  - feature-based comparison
KW  - gripper system
KW  - grasping strategy
KW  - robust performance
KW  - target items
KW  - robot system
KW  - dual 6 degrees of freedom industrial arms
KW  - error recovery strategies
KW  - fixed calibrated frame
KW  - multiple stereo cameras
KW  - vision system
KW  - custom-designed top-open extendable shelf
KW  - calibrated table
KW  - fixed bases
KW  - module designs
KW  - component selection
KW  - motion planning
KW  - system requirements
KW  - Amazon Robotics Challenge
KW  - reliable system
KW  - stable system
KW  - item picking
KW  - robust robot design
KW  - Cameras
KW  - Manipulators
KW  - Task analysis
KW  - Planning
KW  - Service robots
KW  - Robot vision systems
DO  - 10.1109/ICRA.2018.8461057
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In order to build a stable and reliable system for the Amazon Robotics Challenge we went through a detailed study of the performance and system requirements based on the rules and our past experience of the challenge. The challenge was to build a robot that integrates grasping, vision, motion planning, among others, to be able to pick items from a shelf to specific order boxes. This paper presents the development process including component selection, module designs, and deployment. The resulting robot system has dual 6 degrees of freedom industrial arms mounted on fixed bases, which in turn are mounted on a calibrated table. The robot works with a custom-designed top-open extendable shelf. The vision system uses multiple stereo cameras mounted on a fixed calibrated frame. Feature-based comparison and machine-learning based matching are used to identify and determine item pose. The gripper system uses suction cup and the grasping strategy is pick from the top. Error recovery strategies were also implemented to ensure robust performance. During the competition, the robot was able to pick all target items with the shortest amount of time.
ER  - 

TY  - CONF
TI  - Physics-Based Selection of Informative Actions for Interactive Perception
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7427
EP  - 7432
AU  - C. Eppner
AU  - R. Martín-Martín
AU  - O. Brock
PY  - 2018
KW  - mobile robots
KW  - robot dynamics
KW  - robot kinematics
KW  - visual perception
KW  - physics-based selection
KW  - informative action
KW  - forceful interactions
KW  - task-relevant information
KW  - informative interactions
KW  - articulated mechanisms
KW  - action selection task
KW  - interactive perception methods
KW  - information gain
KW  - robust manipulation
KW  - Kinematics
KW  - Task analysis
KW  - Dynamics
KW  - Robot sensing systems
KW  - Shape
KW  - Force
DO  - 10.1109/ICRA.2018.8460596
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Interactive perception exploits the correlation between forceful interactions and changes in the observed signals to extract task-relevant information from the sensor stream. Finding the most informative interactions to perceive complex objects, like articulated mechanisms, is challenging because the outcome of the interaction is difficult to predict. We propose a method to select the most informative action while deriving a model of articulated mechanisms that includes kinematic, geometric, and dynamic properties. Our method addresses the complexity of the action selection task based on two insights. First, we show that for a class of interactive perception methods, information gain can be approximated by the amount of motion induced in the mechanism. Second, we resort to physics simulations grounded in the real-world through interactive perception to predict possible action outcomes. Our method enables the robot to autonomously select actions for interactive perception that reveal most information, given the current knowledge of the world. This leads to improved perception and more accurate world models, finally enabling robust manipulation.
ER  - 

TY  - CONF
TI  - Pick and Place Without Geometric Object Models
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7433
EP  - 7440
AU  - M. Gualtieri
AU  - A. t. Pas
AU  - R. Platt
PY  - 2018
KW  - geometry
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - geometric object models
KW  - robotic pick
KW  - deep reinforcement learning problem
KW  - deep RL
KW  - robotic manipulation frame
KW  - low level states
KW  - pick-place
KW  - regrasping problems
KW  - exact geometry
KW  - sensor perception
KW  - Shape
KW  - History
KW  - Task analysis
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Geometry
DO  - 10.1109/ICRA.2018.8460553
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a novel formulation of robotic pick and place as a deep reinforcement learning (RL) problem. Whereas most deep RL approaches to robotic manipulation frame the problem in terms of low level states and actions, we propose a more abstract formulation. In this formulation, actions are target reach poses for the hand and states are a history of such reaches. We show this approach can solve a challenging class of pick-place and regrasping problems where the exact geometry of the objects to be handled is unknown. The only information our method requires is: 1) the sensor perception available to the robot at test time; 2) prior knowledge of the general class of objects for which the system was trained. We evaluate our method using objects belonging to two different categories, mugs and bottles, both in simulation and on real hardware. Results show a major improvement relative to a shape primitives baseline.
ER  - 

TY  - CONF
TI  - Automatic Material Properties Estimation for the Physics-Based Robotic Garment Folding
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7449
EP  - 7454
AU  - V. Petrík
AU  - J. Cmíral
AU  - V. Smutný
AU  - P. Krsek
AU  - V. Hlaváč
PY  - 2018
KW  - clothing
KW  - fabrics
KW  - industrial robots
KW  - iterative methods
KW  - laser ranging
KW  - optimisation
KW  - automatic material properties estimation
KW  - physics-based robotic garment folding
KW  - fabric material property
KW  - iterative strategy
KW  - optimisation task
KW  - laser range finder
KW  - Fabrics
KW  - Estimation
KW  - Robots
KW  - Grippers
KW  - Material properties
KW  - Clothing
KW  - Measurement by laser beam
DO  - 10.1109/ICRA.2018.8461016
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The estimation of the fabric material property during the folding is presented. The available techniques for the accurate garment folding rely on known material properties. Currently, the properties are estimated by an operator in advance of folding. We propose an iterative strategy, which updates the property while the garment is folded. The estimation is formulated as an optimisation task. It is based on measurements from a laser range finder. The proposed algorithm improves the estimation iteratively and prevents the garment from slipping at the same time. We demonstrate the estimation procedure for 10 fabric strips of different materials.
ER  - 

TY  - CONF
TI  - Slipping Control Algorithms for Object Manipulation with Sensorized Parallel Grippers
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7455
EP  - 7461
AU  - M. Costanzo
AU  - G. De Maria
AU  - C. Natale
PY  - 2018
KW  - deformation
KW  - dexterous manipulators
KW  - force measurement
KW  - force sensors
KW  - grippers
KW  - mechanical contact
KW  - tactile sensors
KW  - torque measurement
KW  - object manipulation
KW  - sensorized parallel grippers
KW  - parallel jaw grippers
KW  - in-hand manipulation tasks
KW  - controlled sliding motion
KW  - grasped object
KW  - rotational sliding maneuver
KW  - grip force
KW  - translational sliding
KW  - rotational slippage
KW  - linear slippage
KW  - fragile objects
KW  - deformable objects
KW  - controlled rotational sliding
KW  - in-hand manipulation actions
KW  - sensorized gripper
KW  - six-axis force/tactile sensor
KW  - contact force
KW  - torque measurements
KW  - slipping control algorithms
KW  - in-hand manipulation action
KW  - Force
KW  - Robot sensing systems
KW  - Grippers
KW  - Friction
KW  - Task analysis
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460883
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Parallel jaw grippers have a limited dexterity, however they can still be used for in-hand manipulation tasks, such as pivoting or other controlled sliding motions of the grasped object. A rotational sliding maneuver is challenging since the grasped object can easily slip if the grip force is not properly adjusted to allow rotational sliding while avoiding translational sliding at the same time. This paper has a twofold aim. First, it intends to refine control algorithms to avoid both rotational and linear slippage, already presented by the authors, by proposing a novel sliding motion model that leads to a grip force as small as possible to avoid slippage, so as to enlarge the set of fragile and deformable objects that can be safely grasped with this approach. Second, the paper exploits the motion model to set up a new algorithm for controlled rotational sliding, thus enabling challenging in-hand manipulation actions. All control algorithms are sensor-based, exploiting a sensorized gripper equipped with a six-axis force/tactile sensor, which provides contact force and torque measurements as well as orientation of the object with respect to the gripper. A set of experiments are executed on a Kuka iiwa showing how the proposed control algorithms are effective to both avoid slippage and allow a controlled sliding motion.
ER  - 

TY  - CONF
TI  - Semantic Robot Programming for Goal-Directed Manipulation in Cluttered Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7462
EP  - 7469
AU  - Z. Zeng
AU  - Z. Zhou
AU  - Z. Sui
AU  - O. C. Jenkins
PY  - 2018
KW  - graph theory
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - path planning
KW  - pose estimation
KW  - robot programming
KW  - robot vision
KW  - object geometries
KW  - Semantic Robot Programming
KW  - task planning
KW  - motion planning
KW  - Discriminatively-Informed Generative Estimation of Scenes and Transforms
KW  - DIGEST method
KW  - RGBD images
KW  - goal-directed manipulation
KW  - cluttered scene dataset
KW  - Michigan Progress Fetch robot
KW  - object poses
KW  - robot manipulator
KW  - SRP
KW  - semantic mapping
KW  - Task analysis
KW  - Semantics
KW  - Robot programming
KW  - Estimation
KW  - Planning
KW  - Detectors
DO  - 10.1109/ICRA.2018.8460538
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present the Semantic Robot Programming (SRP) paradigm as a convergence of robot programming by demonstration and semantic mapping. In SRP, a user can directly program a robot manipulator by demonstrating a snapshot of their intended goal scene in workspace. The robot then parses this goal as a scene graph comprised of object poses and inter-object relations, assuming known object geometries. Task and motion planning is then used to realize the user's goal from an arbitrary initial scene configuration. Even when faced with different initial scene configurations, SRP enables the robot to seamlessly adapt to reach the user's demonstrated goal. For scene perception, we propose the Discriminatively-Informed Generative Estimation of Scenes and Transforms (DIGEST) method to infer the initial and goal states of the world from RGBD images. The efficacy of SRP with DIGEST perception is demonstrated for the task of tray-setting with a Michigan Progress Fetch robot. Scene perception and task execution are evaluated with a public household occlusion dataset and our cluttered scene dataset.
ER  - 

TY  - CONF
TI  - Off-Road Lidar Simulation with Data-Driven Terrain Primitives
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7470
EP  - 7477
AU  - A. Tallavajhula
AU  - Ç. Meriçli
AU  - A. Kelly
PY  - 2018
KW  - geophysics computing
KW  - mobile robots
KW  - optical radar
KW  - remote sensing by laser beam
KW  - vegetation
KW  - perception algorithms
KW  - geometric terrain representation
KW  - Lidar rays
KW  - off-road Lidar simulation
KW  - vegetation
KW  - trees
KW  - shrubs
KW  - data logs
KW  - off-road environments
KW  - state estimation algorithms
KW  - high-fidelity sensor-realistic simulation
KW  - scale off-road robot applications
KW  - data-driven terrain primitives
KW  - Lidar observations
KW  - natural terrain
KW  - Laser radar
KW  - Software
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Training
DO  - 10.1109/ICRA.2018.8461198
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Developing software for large scale off-road robot applications is challenging and tedious due to cost, logistics, and rigor of field testing. High-fidelity sensor-realistic simulation can speed up the development process for perception and state estimation algorithms. We focus on Lidar simulation for robots operating in off-road environments. Lidars are integral sensors for robots, and Lidar simulation for off-road environments is particularly challenging due to the way Lidar rays interact with natural terrain such as vegetation. A hybrid geometric terrain representation has been shown to model Lidar observations well [1]. However, previous work has only been able to simulate a single, fixed scene, and the entire scene had to be precisely surveyed. In this work, we add semantic information to the hybrid geometric model. This allows us to extract terrain primitives, such as trees and shrubs, from data logs. Our approach uses these primitives to compose arbitrary scenes for Lidar simulation. We evaluate our simulator on a real-world environment of interest, and show that primitives derived using our approach generalize to new scenes.
ER  - 

TY  - CONF
TI  - Historical Data is Useful for Navigation Planning: Data Driven Route Generation for Autonomous Ship
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7478
EP  - 7483
AU  - W. C. Tan
AU  - C. Weng
AU  - Y. Zhou
AU  - K. H. Chua
AU  - I. -. Chen
PY  - 2018
KW  - autonomous underwater vehicles
KW  - collision avoidance
KW  - marine control
KW  - marine navigation
KW  - mobile robots
KW  - ships
KW  - Navigation Feature
KW  - historical data
KW  - navigation planning
KW  - data driven route generation
KW  - autonomous ship
KW  - automated generation
KW  - autonomous surface vessel
KW  - robotic surface vessel
KW  - Historical Automatic Identification System data
KW  - AIS locations
KW  - nearest neighbour based path retrieval
KW  - Ship Feature
KW  - AIS records
KW  - Marine vehicles
KW  - Navigation
KW  - Artificial intelligence
KW  - Noise measurement
KW  - Planning
KW  - Path planning
KW  - Databases
DO  - 10.1109/ICRA.2018.8460880
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work presents a method for automated generation of navigation plan for autonomous or robotic surface vessel. Historical Automatic Identification System (AIS) data is of significant value to this problem. The method joins AIS locations of a same vessel at different time and locations in a region into a route. Next, it automatically computes navigation plans using nearest neighbour based path retrieval relying on two representations, Ship Feature and Navigation Feature. Before starting service, existing AIS records in the form of ship properties and corresponding route are preprocessed and stored in the form of Ship and Navigation Feature. During online retrieval, given input constraints in vector form, nearest neighbour of this query vector in the same space is found and corresponding path of the neighbour is returned as recommended path. Analysis was done in four and two dimensional spaces for Ship and Navigation Feature respectively. Application of the method is demonstrated in two regions of Australian, covering Bass Strait and Great Australian Bight.
ER  - 

TY  - CONF
TI  - A Preliminary Study of Ice-Relative Underwater Vehicle Navigation Beneath Moving Sea Ice
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7484
EP  - 7491
AU  - L. D. L. Barker
AU  - L. L. Whitcomb
PY  - 2018
KW  - autonomous underwater vehicles
KW  - Kalman filters
KW  - marine navigation
KW  - mobile robots
KW  - navigation
KW  - nonlinear filters
KW  - oceanographic techniques
KW  - position control
KW  - ships
KW  - under-ice navigation methods
KW  - extended Kalman filter
KW  - sufficient satellite beacon separation
KW  - vehicle position
KW  - ice velocities
KW  - vehicle trajectory
KW  - ice survey
KW  - navigation sensors
KW  - ship
KW  - precision vehicle
KW  - satellite navigation beacons
KW  - precision navigation capabilities
KW  - under-ice robotic vehicles
KW  - moving stationary sea ice
KW  - underwater robotic vehicle navigation
KW  - vehicle navigation beneath moving sea ice
KW  - ice-relative
KW  - size 7.6 km
KW  - size 1.2 km
KW  - Satellite navigation systems
KW  - Marine vehicles
KW  - Sea ice
KW  - Sonar navigation
KW  - Acoustics
DO  - 10.1109/ICRA.2018.8461166
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper addresses the problem of underwater robotic vehicle navigation relative to moving or stationary sea ice. A brief review of previously-reported under-ice navigation methods is given, as well as a brief motivation for the use of under-ice robotic vehicles with precision navigation capabilities. We then describe our proposed approach, which employs two or more satellite navigation beacons atop the sea ice along with other precision vehicle and ship mounted navigation sensors to estimate vehicle, ice, and ship states by means of an Extended Kalman Filter. Navigation results for a simulated 7.6 km under ice survey are presented for varying satellite beacon separation. Preliminary analysis suggests that for the simulated sensors, vehicle trajectory, and ice velocities, the proposed method can accurately estimate vehicle position up to 1.2 km from the deployment ship given sufficient satellite beacon separation. Decreased beacon separation results in divergence of the vehicle's position estimate at large standoff distances from the ship. We conclude with suggestions for future improvements.
ER  - 

TY  - CONF
TI  - A Soft Robot for Random Exploration of Terrestrial Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7492
EP  - 7497
AU  - S. Mintchev
AU  - D. Zappetti
AU  - J. Willemin
AU  - D. Floreano
PY  - 2018
KW  - control engineering computing
KW  - industrial robots
KW  - mass production
KW  - microrobots
KW  - motion control
KW  - multi-robot systems
KW  - soft robot
KW  - random exploration
KW  - terrestrial environments
KW  - unknown terrains
KW  - adequate locomotion strategy
KW  - fast exploration
KW  - obstacles negotiation
KW  - mass manufacturing
KW  - minimalistic design
KW  - roll
KW  - soft cage
KW  - swarm operations
KW  - randomly moving miniature robots
KW  - Robots
KW  - Propellers
KW  - Aerodynamics
KW  - Shock absorbers
KW  - Batteries
DO  - 10.1109/ICRA.2018.8460667
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A swarm of randomly moving miniature robots is an effective solution for the exploration of unknown terrains. However, the deployment of a swarm of miniature robots poses two challenges: finding an adequate locomotion strategy for fast exploration and obstacles negotiation; and implementing simple design and control solutions suited for mass manufacturing. Here, we tackle these challenges by developing a new soft robot with a minimalistic design and a simple control strategy that can randomly propel itself above obstacles and roll on the ground upon landing. The robot is equipped with two propellers that are periodically activated to jump, a soft cage that protects the robot from impacts and allows to passively roll on the ground, and a passive self-righting mechanism for repetitive jumps. The minimalistic control and design reduce the complexity of the mechanics and electronics and are instrumental to the production of a large number of robots. In the paper, the key design aspects of the robot are discussed, the locomotion of a single prototype is experimentally characterized, and improvements of the system for future swarm operations are discussed.
ER  - 

TY  - CONF
TI  - Micro Underwater Vehicle Hydrobatics: A Submerged Furuta Pendulum
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7498
EP  - 7503
AU  - D. A. Duecker
AU  - A. Hackbarth
AU  - T. Johannink
AU  - E. Kreuzer
AU  - E. Solowjow
PY  - 2018
KW  - attitude control
KW  - autonomous underwater vehicles
KW  - control system synthesis
KW  - marine control
KW  - microrobots
KW  - mobile robots
KW  - pendulums
KW  - robust control
KW  - stability
KW  - vehicle dynamics
KW  - submerged Furuta pendulum
KW  - HippoCampus microunderwater vehicle
KW  - fluid volumes
KW  - tightly constrained settings
KW  - agile vehicle dynamics
KW  - robust attitude control scheme
KW  - aerial drones
KW  - underwater domain
KW  - control method
KW  - microunderwater vehicle hydrobatics
KW  - submerged Furuta pendulum stabilization
KW  - Vehicle dynamics
KW  - Hippocampus
KW  - Attitude control
KW  - Hydrodynamics
KW  - Force
KW  - Monitoring
KW  - Drones
DO  - 10.1109/ICRA.2018.8461091
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present the new HippoCampus micro underwater vehicle, first introduced in [1]. It is designed for monitoring confined fluid volumes. These tightly constrained settings demand agile vehicle dynamics. Moreover, we adapt a robust attitude control scheme for aerial drones to the underwater domain. We demonstrate the performance of the controller with a challenging maneuver. A submerged Furuta pendulum is stabilized by HippoCampus after a swing-up. The experimental results reveal the robustness of the control method, as the system quickly recovers from strong physical disturbances, which are applied to the system.
ER  - 

TY  - CONF
TI  - Satellite-Based Tele-Operation of an Underwater Vehicle-Manipulator System. Preliminary Experimental Results
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7504
EP  - 7509
AU  - P. Di Lillo
AU  - D. Di Vito
AU  - E. Simetti
AU  - G. Casalino
AU  - G. Antonelli
PY  - 2018
KW  - artificial satellites
KW  - end effectors
KW  - manipulator kinematics
KW  - mobile robots
KW  - remotely operated vehicles
KW  - satellite communication
KW  - satellite links
KW  - telerobotics
KW  - underwater vehicles
KW  - UVMS
KW  - Underwater Vehicle-Manipulator System
KW  - satellite link
KW  - task-priority-based inverse kinematics algorithm
KW  - satellite-based tele-operation
KW  - European project
KW  - underwater intervention
KW  - remote control room
KW  - satellite communication link
KW  - DexROV
KW  - cognitive engine
KW  - communication latency
KW  - end effector
KW  - size 2017.0 inch
KW  - Task analysis
KW  - Trajectory
KW  - Kinematics
KW  - Satellite communication
KW  - Exoskeletons
KW  - Engines
KW  - Robustness
DO  - 10.1109/ICRA.2018.8462976
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Within the European project DexROV the topic of underwater intervention is addressed. In particular, a remote control room is connected through a satellite communication link to surface vessel, which is in turn connected to an UVMS (Underwater Vehicle-Manipulator System) with an umbilical cable. The operator may interact with the system using a joystick or exoskeleton. Since a direct teleoperation is not feasible, a cognitive engine is in charge of handling communication latency or interruptions caused by the satellite link, and the UVMS should have sufficient autonomy in dealing with low level constraints or secondary objectives. To this purpose, a task-priority-based inverse kinematics algorithm has been developed in order to allow the operator to control only the end effector, while the algorithm is in charge of handling both operative and joint-space constraints. This paper describes some preliminary experimental results achieved during the DexROV campaign of July 2017 in Marseilles (France), where most of the components have been successfully integrated and the inverse kinematics nicely run.
ER  - 

TY  - CONF
TI  - Robust Dense Mapping for Large-Scale Dynamic Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7510
EP  - 7517
AU  - I. A. Barsan
AU  - P. Liu
AU  - M. Pollefeys
AU  - A. Geiger
PY  - 2018
KW  - cameras
KW  - image motion analysis
KW  - image reconstruction
KW  - image segmentation
KW  - mobile robots
KW  - motion control
KW  - object detection
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - robust dense mapping
KW  - large-scale dynamic environments
KW  - stereo-based dense mapping algorithm
KW  - large-scale dynamic urban environments
KW  - static background
KW  - high-level mobile robotic tasks
KW  - crowded environments
KW  - instance-aware semantic segmentation
KW  - sparse scene flow
KW  - visual odometry
KW  - depth maps
KW  - stereo input
KW  - map pruning technique
KW  - reconstruction accuracy
KW  - stationary objects
KW  - moving objects detection
KW  - path planning
KW  - camera poses estimation
KW  - frequency 2.5 Hz
KW  - Three-dimensional displays
KW  - Cameras
KW  - Semantics
KW  - Vehicle dynamics
KW  - Dynamics
KW  - Real-time systems
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2018.8462974
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a stereo-based dense mapping algorithm for large-scale dynamic urban environments. In contrast to other existing methods, we simultaneously reconstruct the static background, the moving objects, and the potentially moving but currently stationary objects separately, which is desirable for high-level mobile robotic tasks such as path planning in crowded environments. We use both instance-aware semantic segmentation and sparse scene flow to classify objects as either background, moving, or potentially moving, thereby ensuring that the system is able to model objects with the potential to transition from static to dynamic, such as parked cars. Given camera poses estimated from visual odometry, both the background and the (potentially) moving objects are reconstructed separately by fusing the depth maps computed from the stereo input. In addition to visual odometry, sparse scene flow is also used to estimate the 3D motions of the detected moving objects, in order to reconstruct them accurately. A map pruning technique is further developed to improve reconstruction accuracy and reduce memory consumption, leading to increased scalability. We evaluate our system thoroughly on the well-known KITTI dataset. Our system is capable of running on a PC at approximately 2.5Hz, with the primary bottleneck being the instance-aware semantic segmentation, which is a limitation we hope to address in future work. The source code is available from the project Websitea.
ER  - 

TY  - CONF
TI  - Self-triggered Adaptive Planning and Scheduling of UAV Operations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7518
EP  - 7524
AU  - E. Yel
AU  - T. X. Lin
AU  - N. Bezzo
PY  - 2018
KW  - adaptive control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - energy consumption
KW  - helicopters
KW  - mobile robots
KW  - noise
KW  - reachability analysis
KW  - risk analysis
KW  - scheduling
KW  - trajectory optimisation (aerospace)
KW  - obstacles avoidance
KW  - energy consumption
KW  - trajectory curvature
KW  - self-triggered adaptive planning
KW  - unmanned aerial vehicles
KW  - scheduling
KW  - quadrotor UAV motion planning
KW  - obstacles detection
KW  - time consumption
KW  - constant periodic sensor measurements
KW  - online speed adaptation policy
KW  - risk-based analysis
KW  - noise
KW  - reachability analysis
KW  - Trajectory
KW  - Robot sensing systems
KW  - Safety
KW  - Unmanned aerial vehicles
KW  - Reachability analysis
KW  - Schedules
DO  - 10.1109/ICRA.2018.8463205
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Modern unmanned aerial vehicles (UAVs) rely on constant periodic sensor measurements to detect and avoid obstacles. However, constant checking and replanning are time and energy consuming and are often not necessary especially in situations in which the UAV can safely fly in uncluttered environments without entering unsafe states. Thus, in this paper, we propose a self-triggered framework that leverages reachability analysis to schedule the next time to check sensor measurements and perform replanning while guaranteeing safety under noise and disturbance effects. Further, we relax sensor checking and motion replanning operations by leveraging a risk-based analysis that determines the likelihood to reach undesired states over a certain time horizon. We also propose an online speed adaptation policy based on the planned trajectory curvature to minimize drift from the desired path due to the system dynamics. Finally, we validate the proposed approach with simulations and experiments for a quadrotor UAV motion planning case study in a cluttered environment.
ER  - 

TY  - CONF
TI  - Cross-Domain Transfer in Reinforcement Learning Using Target Apprentice
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7525
EP  - 7532
AU  - G. Joshi
AU  - G. Chowdhary
PY  - 2018
KW  - generalisation (artificial intelligence)
KW  - learning (artificial intelligence)
KW  - target apprentice learning
KW  - cross-domain transfer
KW  - reinforcement learning
KW  - cross-domain tasks
KW  - target task learning
KW  - target domain
KW  - policy augmentation
KW  - Task analysis
KW  - Adaptation models
KW  - Automobiles
KW  - Manifolds
KW  - Bicycles
KW  - Learning (artificial intelligence)
KW  - Complexity theory
DO  - 10.1109/ICRA.2018.8462977
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a new approach to transfer in Reinforcement Learning (RL) for cross-domain tasks. Unlike, available transfer approaches, where target task learning is accelerated through initialized learning from source, we propose to adapt and reuse the optimal source policy directly in the related domains. We show the optimal policy from a related source task can be near optimal in target domain provided an adaptive policy accounts for the model error between target and the projected source. A significant advantage of the proposed policy augmentation is in generalizing the policies across related domains without having to re-Iearn the new tasks. We demonstrate that, this architecture leads to better sample efficiency in the transfer, reducing sample complexity of target task learning to target apprentice learning.
ER  - 

TY  - CONF
TI  - Intent-Aware Multi-Agent Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7533
EP  - 7540
AU  - S. Qi
AU  - S. Zhu
PY  - 2018
KW  - aerospace robotics
KW  - control engineering computing
KW  - decision theory
KW  - function approximation
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - multi-agent systems
KW  - planning (artificial intelligence)
KW  - robot dynamics
KW  - low-level planning algorithms
KW  - intent-aware multiagent reinforcement learning
KW  - learning algorithm
KW  - planning process
KW  - partially observable Markov decision process
KW  - linear function approximation
KW  - intent-aware multiagent planning
KW  - aerial robots
KW  - human interaction
KW  - dynamic process
KW  - POMDP
KW  - Planning
KW  - Prediction algorithms
KW  - Automata
KW  - Vehicles
KW  - History
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8463211
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes an intent-aware multi-agent planning framework as well as a learning algorithm. Under this framework, an agent plans in the goal space to maximize the expected utility. The planning process takes the belief of other agents' intents into consideration. Instead of formulating the learning problem as a partially observable Markov decision process (POMDP), we propose a simple but effective linear function approximation of the utility function. It is based on the observation that for humans, other people's intents will pose an influence on our utility for a goal. The proposed framework has several major advantages: i) it is computationally feasible and guaranteed to converge. ii) It can easily integrate existing intent prediction and low-level planning algorithms. iii) It does not suffer from sparse feedbacks in the action space. We experiment our algorithm in a real-world problem that is non-episodic, and the number of agents and goals can vary over time. Our algorithm is trained in a scene in which aerial robots and humans interact, and tested in a novel scene with a different environment. Experimental results show that our algorithm achieves the best performance and human-like behaviors emerge during the dynamic process.
ER  - 

TY  - CONF
TI  - Improving Model-Based Balance Controllers Using Reinforcement Learning and Adaptive Sampling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7541
EP  - 7547
AU  - V. C. V. Kumar
AU  - S. Ha
AU  - K. Yamane
PY  - 2018
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - optimal control
KW  - sampling methods
KW  - control signals
KW  - adaptive sampling
KW  - model-based balance controllers
KW  - humanoid model
KW  - in-place balancing
KW  - training disturbances
KW  - standard reinforcement learning formulations
KW  - deep reinforcement learning techniques
KW  - control policy
KW  - RoA
KW  - model-based optimal controller
KW  - learning framework
KW  - full-body actions
KW  - nonplanar pushes
KW  - full-body dynamics
KW  - optimal control theory
KW  - Perturbation methods
KW  - Hip
KW  - Adaptation models
KW  - Robots
KW  - Training
KW  - Lips
KW  - Learning (artificial intelligence)
DO  - 10.1109/ICRA.2018.8463209
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Balance control to recover from a wide range of disturbances is an important skill for humanoid robots. Traditionally, researchers have often designed a balance controller by applying optimal control theory on a simplified model that abstracts the full-body dynamics. However, the resulting controller may not be able to recover from unexpected scenarios such as non-planar pushes, or fail to exploit full-body actions such as balancing with arm movements. This paper presents a learning framework for enhancing the performance of a model-based optimal controller by expanding the region of attraction (RoA). We train a control policy that generates additional control signals on top of the model-based controller using deep reinforcement learning techniques. Instead of relying on standard reinforcement learning formulations, we explicitly model the region of attraction and continuously adjust it during the training. By drawing the training disturbances at the boundary of the RoA, we can effectively expand the RoA while avoiding local minima. We test our learning framework for in-place balancing as well as balancing with stepping on a humanoid model in simulation.
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning Supervised Autonomous Exploration in Office Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7548
EP  - 7555
AU  - D. Zhu
AU  - T. Li
AU  - D. Ho
AU  - C. Wang
AU  - M. Q. -. Meng
PY  - 2018
KW  - decision making
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - supervised autonomous exploration
KW  - office environments
KW  - exploration region selection
KW  - autonomous robot exploration task
KW  - greedy methods
KW  - long-term planning
KW  - deep reinforcement learning
KW  - exploration knowledge
KW  - office blueprints
KW  - DRL model
KW  - next-best-view selection approach
KW  - structural integrity measurement
KW  - office maps
KW  - decision making process
KW  - Planning
KW  - Optimization
KW  - Prediction algorithms
KW  - Task analysis
KW  - Predictive models
KW  - Computer architecture
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8463213
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Exploration region selection is an essential decision making process in autonomous robot exploration task. While a majority of greedy methods are proposed to deal with this problem, few efforts are made to investigate the importance of predicting long-term planning. In this paper, we present an algorithm that utilizes deep reinforcement learning (DRL) to learn exploration knowledge over office blueprints, which enables the agent to predict a long-term visiting order for unexplored subregions. On the basis of this algorithm, we propose an exploration architecture that integrates a DRL model, a next-best-view (NBV) selection approach and a structural integrity measurement to further improve the exploration performance. At the end of this paper, we evaluate the proposed architecture against other methods on several new office maps, showing that the agent can efficiently explore uncertain regions with a shorter path and smarter behaviors.
ER  - 

TY  - CONF
TI  - Bayesian Optimization with Automatic Prior Selection for Data-Efficient Direct Policy Search
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7571
EP  - 7578
AU  - R. Pautrat
AU  - K. Chatzilygeroudis
AU  - J. Mouret
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - manipulators
KW  - maximum likelihood estimation
KW  - motion control
KW  - optimisation
KW  - search problems
KW  - Most Likely Expected Improvement
KW  - 5DOF planar arm
KW  - 6-legged robot
KW  - transfer learning task
KW  - acquisition function
KW  - data-efficient direct policy search
KW  - automatic prior selection
KW  - Bayesian optimization
KW  - Optimization
KW  - Bayes methods
KW  - Legged locomotion
KW  - Task analysis
KW  - Predictive models
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8463197
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the most interesting features of Bayesian optimization for direct policy search is that it can leverage priors (e.g., from simulation or from previous tasks) to accelerate learning on a robot. In this paper, we are interested in situations for which several priors exist but we do not know in advance which one fits best the current situation. We tackle this problem by introducing a novel acquisition function, called Most Likely Expected Improvement (MLEI), that combines the likelihood of the priors and the expected improvement. We evaluate this new acquisition function on a transfer learning task for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has to learn to walk on flat ground and on stairs, with priors corresponding to different stairs and different kinds of damages. Our results show that MLEI effectively identifies and exploits the priors, even when there is no obvious match between the current situations and the priors.
ER  - 

TY  - CONF
TI  - Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7559
EP  - 7566
AU  - A. Nagabandi
AU  - G. Kahn
AU  - R. S. Fearing
AU  - S. Levine
PY  - 2018
KW  - computational complexity
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - predictive control
KW  - model-free learning
KW  - model-free fine-tuning
KW  - model-free deep reinforcement learning algorithms
KW  - model-based algorithms
KW  - model predictive control
KW  - model-based reinforcement learning algorithm
KW  - complex locomotion tasks
KW  - deep neural network dynamics models
KW  - model-free learner
KW  - model-based approaches
KW  - model-free methods
KW  - sample complexity
KW  - model-based deep reinforcement learning
KW  - robotic skills
KW  - MPC
KW  - plausible gaits
KW  - stable gaits
KW  - Task analysis
KW  - Predictive models
KW  - Neural networks
KW  - Data models
KW  - Heuristic algorithms
KW  - Machine learning
KW  - Complexity theory
DO  - 10.1109/ICRA.2018.8463189
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5× on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf.
ER  - 

TY  - CONF
TI  - Adapting Parameterized Motions Using Iterative Learning and Online Collision Detection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7587
EP  - 7594
AU  - J. S. Laursen
AU  - L. C. Sorensen
AU  - U. P. Schultz
AU  - L. Ellekilde
AU  - D. Kraft
PY  - 2018
KW  - Bayes methods
KW  - collision avoidance
KW  - Gaussian processes
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - robotic assembly
KW  - servomotors
KW  - signal classification
KW  - iterative learning
KW  - online collision detection
KW  - robust robot system
KW  - uncertainty-tolerant motions
KW  - Gaussian Process learning
KW  - Bayesian Optimization
KW  - robot motor currents
KW  - assembly process
KW  - medium-sized productions
KW  - parameterized motions
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Robustness
KW  - Robotic assembly
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8463208
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Achieving both the flexibility and robustness required to advance the use of robotics in small and medium-sized productions is an essential but difficult task. A fundamental problem is making the robot run blindly without additional sensors while still being robust to uncertainties and variations in the assembly processes. In this paper, we address the use of parameterized motions suitable for blind execution and robust to uncertainties in the assembly process. Collisions and incorrect assemblies are detected based on robot motor currents while motion parameters are updated based on Bayesian Optimization utilizing Gaussian Process learning. This allows for motion parameters to be optimized using real world trials which incorporate all uncertainties inherent in the assembly process without requiring advanced robot and sensor setups. The result is a simple and straightforward system which helps the user automatically find robust and uncertainty-tolerant motions. We present experiments for an assembly case showing both detection and learning in the real world and how these combine to a robust robot system.
ER  - 

TY  - CONF
TI  - Trajectory Replanning for Quadrotors Using Kinodynamic Search and Elastic Optimization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7595
EP  - 7602
AU  - W. Ding
AU  - W. Gao
AU  - K. Wang
AU  - S. Shen
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - elasticity
KW  - helicopters
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - pipes
KW  - predictive control
KW  - quadratic programming
KW  - robot dynamics
KW  - robot kinematics
KW  - robot vision
KW  - search problems
KW  - splines (mathematics)
KW  - trajectory control
KW  - quadratically constrained quadratic programming problem
KW  - receding horizon replanner design
KW  - trajectory replanning
KW  - grid structure
KW  - dynamically feasible time-parameterized trajectory
KW  - B-spline based kinodynamic search algorithm
KW  - greedy search
KW  - B-spline parameterization
KW  - position-only shortest path search
KW  - monocular vision-based quadrotor
KW  - replanning system
KW  - local control property
KW  - expanded elastic tube
KW  - optimal control point placement
KW  - EO approach
KW  - RBK search
KW  - post-optimization process
KW  - elastic optimization approach
KW  - Splines (mathematics)
KW  - Trajectory
KW  - Optimization
KW  - Real-time systems
KW  - Process control
KW  - Planning
KW  - Complexity theory
DO  - 10.1109/ICRA.2018.8463188
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We focus on a replanning scenario for quadrotors where considering time efficiency, non-static initial state and dynamical feasibility is of great significance. We propose a real-time B-spline based kinodynamic (RBK) search algorithm, which transforms a position-only shortest path search (such as A * and Dijkstra) into an efficient kinodynamic search, by exploring the properties of B-spline parameterization. The RBK search is greedy and produces a dynamically feasible time-parameterized trajectory efficiently, which facilitates non-static initial state of the quadrotor. To cope with the limitation of the greedy search and the discretization induced by a grid structure, we adopt an elastic optimization (EO) approach as a post-optimization process, to refine the control point placement provided by the RBK search. The EO approach finds the optimal control point placement inside an expanded elastic tube which represents the free space, by solving a Quadratically Constrained Quadratic Programming (QCQP) problem. We design a receding horizon replanner based on the local control property of B-spline. A systematic comparison of our method against two state-of-the-art methods is provided. We integrate our replanning system with a monocular vision-based quadrotor and validate our performance onboard.
ER  - 

TY  - CONF
TI  - On Bisection Continuous Collision Checking Method: Spherical Joints and Minimum Distance to Obstacles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7613
EP  - 7619
AU  - S. Tarbouriech
AU  - W. Suleiman
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - bisection Continuous Collision checking method
KW  - spherical joints
KW  - Continuous Collision Detection method
KW  - tight motion bounds
KW  - sampling-based motion planning technique
KW  - Baxter research robot
KW  - minimum distance extension
KW  - obstacle minimum distance
KW  - robotic systems
KW  - Collision avoidance
KW  - Charge coupled devices
KW  - Planning
KW  - Computational modeling
KW  - Manipulators
KW  - Motion segmentation
DO  - 10.1109/ICRA.2018.8463199
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we adapt the Continuous Collision Detection (CCD) method proposed in [1] to efficiently handle the case of spherical and two revolute joints, this kind of joints is very common in modern robotic systems. The new formulations provide more tight motion bounds, thus increase the success rate of checking collision-free paths. We also propose an extension to get the minimum distance to obstacles along a path, this information is primordial as it allows sampling-based motion planning techniques to sort collision-free paths according to their minimum clearance. We have integrated our implementation into a sampling-based motion planning technique and validated it through simulation and on the real Baxter research robot. The experiments revealed that the method not only does not miss any collision between the robot and the obstacles, but also the minimum distance extension provides the path with the maximum clearance at no additional computational cost.
ER  - 

TY  - CONF
TI  - MPC-based Collision Avoidance Strategy for Existing Marine Vessel Guidance Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7618
EP  - 7623
AU  - I. B. Hagen
AU  - D. K. M. Kufoalor
AU  - E. F. Brekke
AU  - T. A. Johansen
PY  - 2018
KW  - collision avoidance
KW  - marine control
KW  - predictive control
KW  - MPC-based collision avoidance strategy
KW  - marine vessel guidance systems
KW  - COLREGS
KW  - MPC COLAV algorithm
KW  - simulation-based model predictive control
KW  - Collision avoidance
KW  - Computational modeling
KW  - Trajectory
KW  - Cost function
KW  - Mathematical model
KW  - Vehicle dynamics
KW  - Propulsion
DO  - 10.1109/ICRA.2018.8463182
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a viable approach for incorporating collision avoidance strategies into existing guidance and control systems on marine vessels. We propose a method that facilitates the use of simulation-based Model Predictive Control (MPC) for collision avoidance (COLAV) on marine vessels. Any COLAV strategy to be applied in real traffic must adhere to the international regulations for preventing collisions at sea (COLREGS). The proposed MPC COLAV method does not rely on an accurate model of the guidance system to achieve vessel behaviors that are compliant with the COLREGS. Rather, it depends on transitional costs in the MPC objective for collision avoidance maneuvers that are being executed by the marine vessel. Hence, it is straightforward to implement the MPC COLAV on different vessels without specific knowledge of the vessel's guidance strategy. Moreover, it offers the possibility to switch between different (possibly application specific) guidance strategies on the same vessel while running the same MPC COLAV algorithm. We present results from full scale experiments that show the viability of our method in different collision avoidance scenarios.
ER  - 

TY  - CONF
TI  - Avoidance of High-Speed Obstacles Based on Velocity Obstacles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7624
EP  - 7630
AU  - Z. Liu
AU  - Z. Jiang
AU  - T. Xu
AU  - H. Cheng
AU  - Z. Xie
AU  - L. Lin
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - velocity control
KW  - time horizon
KW  - obstacle avoidance algorithm
KW  - collision avoidance
KW  - two-period velocity obstacle algorithm
KW  - high-speed obstacles avoidance
KW  - mobile robots
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Prediction algorithms
KW  - Heuristic algorithms
KW  - Robot sensing systems
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8463200
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For obstacles moving with high speeds, existing motion planning methods can rarely guarantee collision avoidance. This paper proposes a viable two-period velocity obstacle algorithm where one period predicts potential collisions within a limited time horizon, and the second period foresees collisions beyond that horizon. The second period is activated only when the obstacle's moving speed is larger than the maximum speed of the robot. The applicability of the new algorithm and the related computation issues are discussed. Both computer simulations and laboratory experiments illustrated the effectiveness of the proposed obstacle avoidance algorithm.
ER  - 


TY  - CONF
TI  - NanoMap: Fast, Uncertainty-Aware Proximity Queries with Lazy Search Over Local 3D Data
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7631
EP  - 7638
AU  - P. R. Florence
AU  - J. Carter
AU  - J. Ware
AU  - R. Tedrake
PY  - 2018
KW  - cartography
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - sensors
KW  - NanoMap
KW  - uncertainty-aware proximity queries
KW  - lazy search
KW  - local 3D data
KW  - local 3D information
KW  - robustly plan motions
KW  - local map structure
KW  - mapping approaches
KW  - global map fusion
KW  - motion planner
KW  - pose-uncertainty-aware local 3D geometric information
KW  - noisy relative pose transforms
KW  - depth sensor measurements
KW  - minimum-uncertainty view
KW  - motion planning
KW  - fast 3D obstacle avoidance
KW  - mapping techniques
KW  - Uncertainty
KW  - Robot sensing systems
KW  - Planning
KW  - Three-dimensional displays
KW  - Collision avoidance
KW  - History
KW  - Current measurement
DO  - 10.1109/ICRA.2018.8463195
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We would like robots to be able to safely navigate at high speed, efficiently use local 3D information, and robustly plan motions that consider pose uncertainty of measurements in a local map structure. This is hard to do with previously existing mapping approaches, like occupancy grids, that are focused on incrementally fusing 3D data into a common world frame. In particular, both their fragile sensitivity to state estimation errors and computational cost can be limiting. We develop an alternative framework, NanoMap, which alleviates the need for global map fusion and enables a motion planner to efficiently query pose-uncertainty-aware local 3D geometric information. The key idea of NanoMap is to store a history of noisy relative pose transforms and search over a corresponding set of depth sensor measurements for the minimum-uncertainty view of a queried point in space. This approach affords a variety of capabilities not offered by traditional mapping techniques: (a) the pose uncertainty associated with 3D data can be incorporated in motion planning, (b) poses can be updated (i.e., from loop closures) with minimal computational effort, and (c) 3D data can be fused lazily for the purpose of planning. We provide an open-source implementation of NanoMap, and analyze its capabilities and computational efficiency in simulation experiments. Finally, we demonstrate in hardware its effectiveness for fast 3D obstacle avoidance onboard a quadrotor flying up to 10 m/s.
ER  - 


TY  - CONF
TI  - A Sensorless Collision Detection Approach Based on Virtual Contact Points
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7639
EP  - 7645
AU  - Z. Qiu
AU  - R. Ozawa
PY  - 2018
KW  - collision avoidance
KW  - force control
KW  - manipulators
KW  - virtual contact points
KW  - force-sensorless collision detection approach
KW  - virtual contacts
KW  - virtual instantaneous powers
KW  - 2D collision detection tasks
KW  - 3D collision detection tasks
KW  - DOF spatial manipulator validate
KW  - contact link
KW  - Collision avoidance
KW  - Task analysis
KW  - Manipulators
KW  - Force
KW  - Two dimensional displays
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8460219
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a force-sensorless collision detection approach based on virtual contacts. A series of indices based on virtual instantaneous powers are introduced associating to several virtual contacts defined on corresponding links of a manipulator. A possible contact link can be determined by comparing the introduced indices without any force or tactile sensors. Simulation results of 2D collision detection tasks by using a three DOF (Degree of Freedom) planar manipulator and 3D collision detection tasks by using a six DOF spatial manipulator validate the effectiveness of the proposed collision detection approach.
ER  - 


TY  - CONF
TI  - Probabilistic Graph Security for Networked Multi-Robot Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7646
EP  - 7653
AU  - R. Wehbe
AU  - R. K. Williams
PY  - 2018
KW  - binary decision diagrams
KW  - Boolean functions
KW  - graph theory
KW  - mobile robots
KW  - multi-robot systems
KW  - probability
KW  - networked multirobot systems
KW  - robot interactions
KW  - existing control-theoretic notion
KW  - network attacks
KW  - left invertibility
KW  - dynamical system
KW  - probabilistic robot communication
KW  - adversarial influence
KW  - probabilistic graph security problem
KW  - system reliability
KW  - efficient graphical representation
KW  - binary decision diagrams
KW  - networked MRS
KW  - mobile multirobot teams
KW  - mobile MRS
KW  - reduced order BDD
KW  - Robot sensing systems
KW  - Probabilistic logic
KW  - Observers
KW  - Security
KW  - Boolean functions
DO  - 10.1109/ICRA.2018.8460752
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we develop a method for determining the probability of a multi-robot system (MRS) being secure when robot interactions are modeled as a probabilistic graph. To define the security of an MRS, we apply an existing control-theoretic notion of network attacks based on the left invertibility of a dynamical system. We then extend previous work by assuming probabilistic robot communication and sensing, modeling the effects of noise, failure, or adversarial influence on interactions in the network. The probabilistic graph security problem can then be seen as a variant of problems solved in the field of system reliability. This interpretation motivates the application of an efficient graphical representation of boolean functions known as binary decision diagrams (BDDs). Specifically, we use the canonical properties of a special type of BDD, the Reduced Order BDD, to generate a tree that can be efficiently traversed to compute the probability that a networked MRS is left invertible, and thus, secure. We then show how our adopted approach can be applied to systems that have interactions that change over time, e.g., for mobile multi-robot teams. Finally, we demonstrate the validity of our method by simulating a mobile MRS performing a rendezvous objective, while tracking its probability of security over time.
ER  - 


TY  - CONF
TI  - Controlling the Interaction of a Multi-Robot System with External Entities
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7654
EP  - 7659
AU  - L. Sabattini
AU  - C. Secchi
AU  - C. Fantuzzi
PY  - 2018
KW  - force control
KW  - multi-robot systems
KW  - external entities
KW  - dynamic interaction model
KW  - multirobot system
KW  - interaction control
KW  - local deformations
KW  - coupling actions
KW  - passivity property
KW  - safety guarantees
KW  - Robots
KW  - Couplings
KW  - Multi-robot systems
KW  - Dynamics
KW  - Force
KW  - Damping
KW  - Collision avoidance
DO  - 10.1109/ICRA.2018.8463198
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we consider a multi-robot system that shares the environment with external entities, and we propose a methodology for controlling the interaction with them. In particular, we consider the problem of achieving a desired dynamic interaction model, in such a way that the multi-robot system exchanges desired forces with external entities. This is obtained by introducing local deformations of the coupling actions among the robots. The proposed method ensures preservation of the passivity property, which provides safety guarantees in the interaction with the (possibly poorly known) external entities.
ER  - 


TY  - CONF
TI  - Network Topology Inference in Swarm Robotics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7660
EP  - 7666
AU  - B. L. Mendívez Vásquez
AU  - J. c. Barca
PY  - 2018
KW  - graph theory
KW  - inference mechanisms
KW  - multi-robot systems
KW  - network theory (graphs)
KW  - swarm intelligence
KW  - network topology inference
KW  - swarm robotics
KW  - topological graph
KW  - swarm intelligence
KW  - Trajectory
KW  - Robots
KW  - Network topology
KW  - Acceleration
KW  - Australia
KW  - Mathematical model
KW  - Atmospheric measurements
DO  - 10.1109/ICRA.2018.8463190
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Swarm robotics refers to the implementation of swarm intelligence features like autonomy and self-organization to a collective of robots. This study focuses on the construction of a topological graph that represents both the magnitude and orientation of swarm interactions. Such structure is used for identifying global parameters like leadership and to derive a relationship between the distribution of interaction magnitudes and swarm parameters. Interaction magnitudes were derived from the trajectory distance between nearest neighbors and it was found that the distribution is able to differentiate between only a small subset of controllers, communication ranges and swarm sizes. Leader detection was based on the analysis of position vectors orientation in local neighborhoods. The method was successful at a 100% rate for 10 and 30 robots, while for 60 a minimum rate of 67% was obtained. Additionally, processing times never exceeded a simulation duration for swarms up to 30 robots, with the potential to parallelize for larger sizes.
ER  - 


TY  - CONF
TI  - Using Hardware Specialization and Hierarchy to Simplify Robotic Swarms
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7667
EP  - 7673
AU  - G. Espinosa
AU  - M. Rubenstein
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - work distribution
KW  - hardware specialization
KW  - classical distributed robotics problem
KW  - robotic swarms
KW  - simulated environment
KW  - shape formation
KW  - Shape
KW  - Task analysis
KW  - Hardware
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Collision avoidance
DO  - 10.1109/ICRA.2018.8463206
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Specialization has always been a tool for work distribution and simplification in nature and in distributed robotics. We present a novel approach to use hardware specialization hierarchically to enhance the capabilities of a swarm without increasing complexity, allowing a numerous group of robots to benefit from the extended features of a few to complete a task that was impossible for them before. We tested the concept under a simulated environment with a classical distributed robotics problem, shape formation, and validated the simulated results against a real experiment.
ER  - 


TY  - CONF
TI  - From Swarms to Stars: Task Coverage in Robot Swarms with Connectivity Constraints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7674
EP  - 7681
AU  - J. Panerati
AU  - L. Gianoli
AU  - C. Pinciroli
AU  - A. Shabah
AU  - G. Nicolescu
AU  - G. Beltrame
PY  - 2018
KW  - distributed control
KW  - mobile robots
KW  - multi-robot systems
KW  - navigation
KW  - optimisation
KW  - scheduling
KW  - Task coverage
KW  - Robot swarms
KW  - connectivity constraints
KW  - swarm robotics
KW  - complex tasks
KW  - control algorithms
KW  - globally coordinated behaviours
KW  - spatial coverage
KW  - global connectivity
KW  - distributed Robot Navigation Controller
KW  - RNC
KW  - global Task Scheduling Controller
KW  - minimal computational load
KW  - connectivity assessment
KW  - real-life robot experiments
KW  - coverage optimality
KW  - Task analysis
KW  - Robot kinematics
KW  - Navigation
KW  - Eigenvalues and eigenfunctions
KW  - Computational modeling
KW  - Multi-robot systems
DO  - 10.1109/ICRA.2018.8463193
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Swarm robotics carries the potential of solving complex tasks using simple devices. To do so, however, one must define distributed control algorithms capable of producing globally coordinated behaviours. We propose a methodology to address the problem of the spatial coverage of multiple tasks with a swarm of robots that must not lose global connectivity. Our methodology comprises two layers: (i) a distributed Robot Navigation Controller (RNC) is responsible for simultaneously guaranteeing connectivity and pursuit of multiple tasks; and (ii) a global Task Scheduling Controller approximates the optimal strategy for the RNC with minimal computational load. Our contributions include: (i) a qualitative analysis of the literature on connectivity assessment, (ii) our proposed methodology, (iii) simulations in a multi-physics environment, (iv) real-life robot experiments, and (v) the experimental validation of connectivity, coverage optimality, and fault-tolerance.
ER  - 


TY  - CONF
TI  - Using Information Invariants to Compare Swarm Algorithms and General Multi-Robot Algorithms
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7682
EP  - 7687
AU  - G. Arpino
AU  - K. Morris
AU  - S. Nagavalli
AU  - K. Sycara
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - swarm intelligence
KW  - multirobot algorithms
KW  - proximal neighbors
KW  - emergent collective behaviors
KW  - all-to-all communication
KW  - deliberative collaboration
KW  - supervisory operator
KW  - mission constraints
KW  - application domains - navigation
KW  - dynamic area coverage
KW  - online algorithm selection decisions
KW  - offline system design decisions
KW  - robotic swarms
KW  - information invariants
KW  - Heuristic algorithms
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Multi-robot systems
KW  - Navigation
DO  - 10.1109/ICRA.2018.8463210
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotic swarms are decentralized multi-robot systems whose members use local information from proximal neighbors to execute simple reactive control laws that result in emergent collective behaviors. In contrast, members of a general multi-robot system may have access to global information, all-to-all communication or sophisticated deliberative collaboration. Some algorithms in the literature are applicable to robotic swarms. Others require the extra complexity of general multi-robot systems. Given an application domain, a system designer or supervisory operator must choose an appropriate system or algorithm respectively that will enable them to achieve their goals while satisfying mission constraints (e.g, bandwidth, energy, time limits). In this paper, we compare representative swarm and general multi-robot algorithms in two application domains - navigation and dynamic area coverage - with respect to several metrics (e.g, completion time, distance travelled). Our objective is to characterize each class of algorithms to inform offline system design decisions by engineers or online algorithm selection decisions by supervisory operators. Our contributions are (a) an empirical performance comparison of representative swarm and general multi-robot algorithms in two application domains, (b) a comparative analysis of the algorithms based on the theory of information invariants, which provides a theoretical characterization supported by our emnirical results.
ER  - 


TY  - CONF
TI  - Learning Robust Policies for Object Manipulation with Robot Swarms
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7688
EP  - 7695
AU  - G. H. W. Gebhardt
AU  - K. Daun
AU  - M. Schnaubelt
AU  - G. Neumann
PY  - 2018
KW  - Hilbert spaces
KW  - learning systems
KW  - mobile robots
KW  - multi-robot systems
KW  - robotic assembly
KW  - robust control
KW  - search problems
KW  - swarm size
KW  - robust policies learning
KW  - Hilbert space embeddings
KW  - policy search methods
KW  - low-level object movement policy
KW  - high-level assembly plan
KW  - assembly process
KW  - policy search method
KW  - autonomous object assembly
KW  - swarm robotics
KW  - robot swarms
KW  - object manipulation
KW  - Robot sensing systems
KW  - Task analysis
KW  - Light sources
KW  - Robustness
KW  - Kernel
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8463215
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Swarm robotics investigates how a large population of robots with simple actuation and limited sensors can collectively solve complex tasks. One particular interesting application with robot swarms is autonomous object assembly. Such tasks have been solved successfully with robot swarms that are controlled by a human operator using a light source. In this paper, we present a method to solve such assembly tasks autonomously based on policy search methods. We split the assembly process in two subtasks: generating a high-level assembly plan and learning a low-level object movement policy. The assembly policy plans the trajectories for each object and the object movement policy controls the trajectory execution. Learning the object movement policy is challenging as it depends on the complex state of the swarm which consists of an individual state for each agent. To approach this problem, we introduce a representation of the swarm which is based on Hilbert space embeddings of distributions. This representation is invariant to the number of agents in the swarm as well as to the allocation of an agent to its position in the swarm. These invariances make the learned policy robust to changes in the swarm and also reduce the search space for the policy search method significantly. We show that the resulting system is able to solve assembly tasks with varying object shapes in multiple simulation scenarios and evaluate the robustness of our representation to changes in the swarm size. Furthermore, we demonstrate that the policies learned in simulation are robust enough to be transferred to real robots.
ER  - 


TY  - CONF
TI  - Modeling and Identification of a Single Link Flexible Arm with a Passive Gravity Compensation Mechanism
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7704
EP  - 7710
AU  - J. C. Cambera
AU  - J. A. Chocoteco
AU  - V. Feliu-Batlle
PY  - 2018
KW  - compensation
KW  - flexible manipulators
KW  - linear systems
KW  - springs (mechanical)
KW  - spring based mechanism
KW  - flexible link arm
KW  - single link flexible arm
KW  - linear springs
KW  - flexible link robotics
KW  - passive gravity compensation
KW  - spring-based compensation
KW  - lumped-mass methodology
KW  - vibrational frequency
KW  - Gravity
KW  - Springs
KW  - Torque
KW  - DC motors
KW  - Wires
KW  - Robots
KW  - Payloads
DO  - 10.1109/ICRA.2018.8461097
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present an experimental study concerning the gravity compensation of flexible link arms based on linear springs. In the field of flexible link robotics, the gravity compensation based on counterweights has been successfully applied in the past, but little effort has been made to examine the potential benefits and difficulties of using spring-based compensation mechanisms. This paper focuses on the modeling and identification of a single link flexible arm compensated with a spring based mechanism. As modeling approach, we followed the lumped-mass methodology to develop a model capable of reproducing the first vibrational frequency of the flexible link arm. Keeping in mind the forces that interact with the flexible link, a combination of sensors is suggested in order to measure and estimate the most important variables of the system. Subsequently, a very simple and reliable identification method based on the time and frequency response of the system is proposed. Finally, the results of the modeling and identification are validated on our experimental platform.
ER  - 


TY  - CONF
TI  - A Nonlinear Control Strategy for Extensible Continuum Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7727
EP  - 7734
AU  - C. G. Frazelle
AU  - A. D. Kapadia
AU  - I. D. Walker
PY  - 2018
KW  - closed loop systems
KW  - control system synthesis
KW  - manipulators
KW  - nonlinear control systems
KW  - PD control
KW  - variable structure systems
KW  - extensible continuum robots
KW  - closed-loop control
KW  - adaptation-based control law
KW  - rigid-link control device
KW  - extensible continuum manipulator
KW  - nonlinear control strategy
KW  - set-point tracking
KW  - Manipulator dynamics
KW  - Mathematical model
KW  - Convergence
KW  - Kinematics
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2018.8463187
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we describe a novel nonlinear control strategy for the closed-loop control of extensible continuum robots. Previous attempts at controlling continuum robots have proved difficult due to the complexity of their system dynamics. Taking advantage of a previously developed dynamic model for a three-section, planar, continuum manipulator, we develop an adaptation-based control law. We present simulation results of a set-point tracking between a rigid-link control device and an extensible continuum manipulator. Experimental results of the controller implemented on a six degree-of-freedom continuum robot are also presented.
ER  - 


TY  - CONF
TI  - Continuously Controllable Series Clutches for Efficient Robot Actuation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7735
EP  - 7741
AU  - J. Malzahn
AU  - V. D. Amara
AU  - N. Tsagarakis
PY  - 2018
KW  - actuators
KW  - clutches
KW  - energy conservation
KW  - friction
KW  - gears
KW  - mobile robots
KW  - muscle
KW  - torque
KW  - controllable series clutches
KW  - efficient robot actuation
KW  - energy efficiency potential
KW  - continuously controllable clutches
KW  - robot joints
KW  - biological muscles
KW  - purely gravity driven robot link motion phases
KW  - gear friction
KW  - motor effort
KW  - energetic benefits
KW  - direct drives
KW  - unforced motion phases
KW  - high torque density
KW  - conventional geared robotic drive technology
KW  - mature geared robotic drive technology
KW  - forced motion phases
KW  - general functional principle
KW  - particular clutch implementation
KW  - harmonic link motions
KW  - friction torque
KW  - Friction
KW  - Torque
KW  - Robots
KW  - Actuators
KW  - Tendons
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8463192
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper investigates the energy efficiency potential of continuously controllable clutches between the motors and links of robot joints. Inspired by biological muscles, the clutch enables free, purely gravity driven robot link motion phases gradually disengaged from gear friction, not requiring motor effort. The concept combines the energetic benefits of direct drives during unforced motion phases with the high torque density of conventional and mature geared robotic drive technology during forced motion phases. The paper specifies the general functional principle of the clutch for energy saving independent of any particular clutch implementation. The feasible energy saving of up to 60 % is investigated for harmonic link motions with varying frequencies and with respect to different ratios of link weight to friction torque. The outcomes of the theoretical investigations are supported by first experimental results.
ER  - 


TY  - CONF
TI  - Stiffness Modulator: A Novel Actuator for Human Augmentation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7742
EP  - 7748
AU  - H. F. Lau
AU  - A. Sutrisno
AU  - T. H. Chong
AU  - D. J. Braun
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - elastic constants
KW  - medical robotics
KW  - muscle
KW  - portable instruments
KW  - sit-to-stand-task
KW  - cocontracted antagonistic muscles
KW  - metabolic energy cost
KW  - self-contained stiffness modulator
KW  - muscle activity
KW  - compliant actuators
KW  - stiffness modulation
KW  - human augmentation
KW  - human knee joint
KW  - stiffness augmentation
KW  - portable stiffness modulator
KW  - Modulation
KW  - Springs
KW  - Actuators
KW  - Force
KW  - Muscles
DO  - 10.1109/ICRA.2018.8463186
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Stiffness modulators are devices that promote a novel means of actuation; they provide stiffness modulation without deliberately doing mechanical work. These type of compliant actuators may be used for human augmentation to complement co-contracted antagonistic muscles and as such reduce muscle activity and metabolic energy cost. Despite the theoretical appeal of this concept, its implementation remains elusive in practical applications. This is particularly true for human augmentation which requires a portable stiffness modulator. In this paper, we present a compact, lightweight, and self-contained stiffness modulator. Using this device, we demonstrate stiffness augmentation of the human knee joint in a sit to stand task. The experimental results indicate that the proposed device is able to assist a human by reducing muscle activity while drawing minimal battery power.
ER  - 


TY  - CONF
TI  - Cartman: The Low-Cost Cartesian Manipulator that Won the Amazon Robotics Challenge
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7757
EP  - 7764
AU  - D. Morrison
AU  - A. W. Tow
AU  - M. McTaggart
AU  - R. Smith
AU  - N. Kelly-Boxall
AU  - S. Wade-McCue
AU  - J. Erskine
AU  - R. Grinover
AU  - A. Gurman
AU  - T. Hunn
AU  - D. Lee
AU  - A. Milan
AU  - T. Pham
AU  - G. Rallos
AU  - A. Razjigaev
AU  - T. Rowntree
AU  - K. Vijay
AU  - Z. Zhuang
AU  - C. Lehnert
AU  - I. Reid
AU  - P. Corke
AU  - J. Leitner
PY  - 2018
KW  - industrial manipulators
KW  - robot vision
KW  - warehouse automation
KW  - autonomous warehousing
KW  - robotic vision
KW  - manipulation
KW  - Cartesian robot system Cartman
KW  - experience-centred design methodology
KW  - low-cost cartesian manipulator
KW  - Amazon Robotics Challenge
KW  - pick-and-place robot
KW  - Task analysis
KW  - Manipulators
KW  - Tools
KW  - Grippers
KW  - Planning
KW  - Robustness
DO  - 10.1109/ICRA.2018.8463191
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The Amazon Robotics Challenge enlisted sixteen teams to each design a pick-and-place robot for autonomous warehousing, addressing development in robotic vision and manipulation. This paper presents the design of our custom-built, cost-effective, Cartesian robot system Cartman, which won first place in the competition finals by stowing 14 (out of 16) and picking all 9 items in 27 minutes, scoring a total of 272 points. We highlight our experience-centred design methodology and key aspects of our system that contributed to our competitiveness. We believe these aspects are crucial to building robust and effective robotic systems.
ER  - 


TY  - CONF
TI  - Slip Detection with Combined Tactile and Visual Information
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7772
EP  - 7777
AU  - J. Li
AU  - S. Dong
AU  - E. Adelson
PY  - 2018
KW  - feature extraction
KW  - force control
KW  - grippers
KW  - image capture
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - pattern classification
KW  - robot vision
KW  - tactile sensors
KW  - robot arm
KW  - grasping positions
KW  - slip detection
KW  - visual information
KW  - robotic manipulation
KW  - deep neural network
KW  - GelSight tactile sensor
KW  - grasping forces
KW  - DNN training
KW  - grasp stability
KW  - tactile information
KW  - gripper
KW  - camera-based tactile sensor
KW  - image sequences
KW  - image capture
KW  - Grippers
KW  - Grasping
KW  - Cameras
KW  - Tactile sensors
KW  - Force
DO  - 10.1109/ICRA.2018.8460495
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Slip detection plays a vital role in robotic manipulation and it has long been a challenging problem in the robotic community. In this paper, we propose a new method based on deep neural network (DNN) to detect slip. The training data is acquired by a GelSight tactile sensor and a camera mounted on a gripper when we use a robot arm to grasp and lift 94 daily objects with different grasping forces and grasping positions. The DNN is trained to classify whether a slip occurred or not. To evaluate the performance of the DNN, we test 10 unseen objects in 152 grasps. A detection accuracy as high as 88.03 % is achieved. It is anticipated that the accuracy can be further improved with a larger dataset. This method is beneficial for robots to make stable grasps, which can be widely applied to automatic force control, grasping strategy selection and fine manipulation.
ER  - 


TY  - CONF
TI  - Realtime State Estimation with Tactile and Visual Sensing. Application to Planar Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7778
EP  - 7785
AU  - K. Yu
AU  - A. Rodriguez
PY  - 2018
KW  - end effectors
KW  - feedback
KW  - object detection
KW  - pose estimation
KW  - position control
KW  - robot vision
KW  - SLAM (robots)
KW  - state estimation
KW  - touch (physiological)
KW  - tactile input
KW  - visual input
KW  - incremental smoothing
KW  - visual sensing
KW  - contact sensing
KW  - end-effector
KW  - realtime state estimation
KW  - robust object state estimation
KW  - visual sensor
KW  - visual feedback
KW  - object shapes
KW  - object manipulation
KW  - incremental smoothing and mapping
KW  - iSAM
KW  - planar manipulation
KW  - object poses estimation
KW  - Robot sensing systems
KW  - Visualization
KW  - Cost function
KW  - State estimation
KW  - Cameras
DO  - 10.1109/ICRA.2018.8463183
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Accurate and robust object state estimation enables successful object manipulation. Visual sensing is widely used to estimate object poses. However, in a cluttered scene or in a tight workspace, the robot's end-effector often occludes the object from the visual sensor. The robot then loses visual feedback and must fall back on open-loop execution. In this paper, we integrate both tactile and visual input using a framework for solving the SLAM problem, incremental smoothing and mapping (iSAM), to provide a fast and flexible solution. Visual sensing provides global pose information but is noisy in general, whereas contact sensing is local, but its measurements are more accurate relative to the end-effector. By combining them, we aim to exploit their advantages and overcome their limitations. We explore the technique in the context of a pusher-slider system. We adapt iSAM's measurement cost and motion cost to the pushing scenario, and use an instrumented setup to evaluate the estimation quality with different object shapes, on different surface materials, and under different contact modes.
ER  - 


TY  - CONF
TI  - Touch-Based Grasp Primitives for Soft Hands: Applications to Human-to-Robot Handover Tasks and Beyond
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7794
EP  - 7801
AU  - M. Bianchi
AU  - G. Averta
AU  - E. Battaglia
AU  - C. Rosales
AU  - M. Bonilla
AU  - A. Tondo
AU  - M. Poggiani
AU  - G. Santaera
AU  - S. Ciotti
AU  - M. G. Catalano
AU  - A. Bicchi
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - end effectors
KW  - grippers
KW  - human-robot interaction
KW  - mobile robots
KW  - tactile sensors
KW  - grasp response
KW  - hand adaptability
KW  - human inspiration
KW  - autonomous grasp sensory-motor primitives
KW  - simple touch-based approach
KW  - human-robot interaction
KW  - soft end effectors
KW  - soft robotic hands
KW  - adaptable hands
KW  - human-to-robot handover tasks
KW  - touch-based grasp primitives
KW  - soft robotic manipulation
KW  - human maneuvering
KW  - human wrist
KW  - hand closure commands
KW  - arm motions
KW  - grasping
KW  - contact
KW  - robotic arm
KW  - under-actuated soft anthropomorphic robotic hand
KW  - Pisa/IIT SoftHand
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Acceleration
KW  - Wrist
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8463212
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recently, the avenue of adaptable, soft robotic hands has opened simplified opportunities to grasp different items; however, the potential of soft end effectors (SEEs) is still largely unexplored, especially in human-robot interaction. In this paper, we propose, for the first time, a simple touch-based approach to endow a SEE with autonomous grasp sensory-motor primitives, in response to an item passed to the robot by a human (human-to-robot handover). We capitalize on human inspiration and minimalistic sensing, while hand adaptability is exploited to generalize grasp response to different objects. We consider the Pisa/IIT SoftHand (SH), an under-actuated soft anthropomorphic robotic hand, which is mounted on a robotic arm and equipped with Inertial Measurement Units (IMUs) on the fingertips. These sensors detect the accelerations arisen from contact with external items. In response to a contact, the hand pose and closure are planned for grasping, by executing arm motions with hand closure commands. We generate these motions from human wrist poses acquired from a human maneuvering the SH to grasp an object from a table. We obtained 86% of successful grasps, considering many objects passed to the SH in different manners. We also tested our techniques in preliminary experiments, where the robot moved to autonomously grasp objects from a surface. Results are positive and open interesting perspectives for soft robotic manipulation.
ER  - 


TY  - CONF
TI  - Model-Based Probabilistic Pursuit via Inverse Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7804
EP  - 7811
AU  - F. Shkurti
AU  - N. Kakodkar
AU  - G. Dudek
PY  - 2018
KW  - decision theory
KW  - graph theory
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - probability
KW  - search problems
KW  - control problem
KW  - single follower robot
KW  - visual contact
KW  - moving target
KW  - plausible predictions
KW  - predictive models
KW  - discrete hypotheses
KW  - combinatorial search
KW  - physical space
KW  - model target behavior
KW  - learned navigation reward function
KW  - semantic terrain features
KW  - search methods
KW  - predictive pursuit algorithm
KW  - multiple satellite maps
KW  - simulation scenarios
KW  - inverse reinforcement learning
KW  - long term behavior
KW  - short term behavior
KW  - planning pursuit paths
KW  - locations
KW  - graph representation
KW  - latent destination
KW  - position
KW  - POMDP solvers
KW  - domain specific knowledge
KW  - model based probabilistic pursuit
KW  - Navigation
KW  - Planning
KW  - Trajectory
KW  - Visualization
KW  - Entropy
KW  - Predictive models
KW  - Learning (artificial intelligence)
DO  - 10.1109/ICRA.2018.8463196
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We address the integrated prediction, planning, and control problem that enables a single follower robot (the photographer) to quickly re-establish visual contact with a moving target (the subject) that has escaped the follower's field of view. We deal with this scenario, which reactive controllers are typically ill-equipped to handle, by making plausible predictions about the long- and short-term behavior of the target, and planning pursuit paths that will maximize the chance of seeing the target again. At the core of our pursuit method is the use of predictive models of target behavior, which help narrow down the set of possible future locations of the target to a few discrete hypotheses, as well as the use of combinatorial search in physical space to check those hypotheses efficiently. We model target behavior in terms of a learned navigation reward function, using Inverse Reinforcement Learning, based on semantic terrain features of satellite maps. Our pursuit algorithm continuously predicts the latent destination of the target and its position in the future, and relies on efficient graph representation and search methods in order to navigate to locations at which the target is most likely to be seen at an anticipated time. We perform extensive evaluation of our predictive pursuit algorithm over multiple satellite maps, thousands of simulation scenarios, against state-of-the art MDP and POMDP solvers. We show that our method significantly outperforms them by exploiting domain-specific knowledge, while being able to run in real-time.
ER  - 


TY  - CONF
TI  - U sing a UAV for Destructive Surveys of Mosquito Population
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7812
EP  - 7819
AU  - A. Nguyen
AU  - D. Krupke
AU  - M. Burbage
AU  - S. Bhatnagar
AU  - S. P. Fekete
AU  - A. T. Becker
PY  - 2018
KW  - autonomous aerial vehicles
KW  - diseases
KW  - graph theory
KW  - integer programming
KW  - path planning
KW  - travelling salesman problems
KW  - destructive surveys
KW  - mosquito population
KW  - electrified screen
KW  - UAV path
KW  - mosquito elimination
KW  - trajectory planning
KW  - traveling salesman problem
KW  - milling with turn cost
KW  - lawn mower problem
KW  - grid graph
KW  - optimized energy consumption
KW  - Integer Programming
KW  - mosquito-borne diseases
KW  - mosquito-killing UAV
KW  - Unmanned aerial vehicles
KW  - Sociology
KW  - Statistics
KW  - Global Positioning System
KW  - Robots
KW  - Monitoring
KW  - Wind tunnels
DO  - 10.1109/ICRA.2018.8463184
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces techniques for mosquito population surveys in the field using electrified screens (bug zappers) mounted to a UAV. Instrumentation on the UAV logs the UAV path and the GPS location, altitude, and time of each mosquito elimination. Hardware experiments with a UAV equipped with an electrified screen provide real-time measurements of (former) mosquito locations and mosquito-free volumes. Planning a trajectory for the UAV that maximizes the number of mosquito kills is related to the Traveling Salesman Problem, the Lawn Mower Problem and, most closely, Milling with Turn Cost. We reduce this problem to considering variants of covering a grid graph with minimum turn cost, corresponding to optimized energy consumption. We describe an exact method based on Integer Programming that is able to compute provably optimal instances with over 1,500 pixels. These solutions are then implemented on the UAV.
ER  - 


TY  - CONF
TI  - Optical Fiber-Based Sensor for Assessing Electric Current in Unmanned Aerial Vehicles with ROS Interface
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7820
EP  - 7825
AU  - F. S. Delgado
AU  - M. A. Jucà
AU  - A. L. M. Marcato
AU  - A. B. Dos Santos
PY  - 2018
KW  - autonomous aerial vehicles
KW  - diffraction gratings
KW  - electric current measurement
KW  - fibre optic sensors
KW  - permanent magnets
KW  - Robot Operating System package
KW  - hysteresis
KW  - optical fiber-based sensor
KW  - sensing technology
KW  - unmanned aerial vehicles electric motors
KW  - ROS interface
KW  - sensing system
KW  - electric current measurements
KW  - linear electric current sensitivity
KW  - flexible sensing scheme
KW  - permanent Neodymium magnet
KW  - Long-Period Fiber Grating sensor
KW  - current 0.22 A
KW  - current 0.08 A
KW  - Robot sensing systems
KW  - Current
KW  - Optical fiber sensors
KW  - Optical fibers
KW  - Current measurement
KW  - Fiber gratings
DO  - 10.1109/ICRA.2018.8461144
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we propose and experimentally validate a novel optical fiber-based sensor for monitoring and assessing electric current in unmanned aerial vehicles electric motors. The proposed sensing technology combines a Long-Period Fiber Grating sensor and a permanent Neodymium magnet, providing a small and flexible sensing scheme deployed inside the arm of the drone. The experimental results show that good accuracy and linear electric current sensitivity of 0.21 A and 2.08 A/nm, respectively, were achieved with electric current measurements at a 100 Hz sampling rate. The values of hysteresis and repeatability achieved were 0.08 A and 0.22 A, respectively. Finally, a Robot Operating System package for interfacing with the sensing system was developed and tested, which greatly simplifies the deployment of the sensor in robotics applications.
ER  - 


TY  - CONF
TI  - A Lightweight, Compliant, Contact-Resistance-Based Airflow Sensor for Quadcopter Ground Effect Sensing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7826
EP  - 7831
AU  - S. D. Gollob
AU  - Y. Manian
AU  - R. St. Pierre
AU  - A. S. Chen
AU  - S. Bergbreiter
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft testing
KW  - autonomous aerial vehicles
KW  - design engineering
KW  - elastomers
KW  - flow measurement
KW  - flow sensors
KW  - helicopters
KW  - turbulence
KW  - wind tunnels
KW  - winds speeds
KW  - Crazyflie 2.0 quadcopter
KW  - turbulent flow
KW  - thrust level
KW  - aircraft testing
KW  - autonomous aerial vehicles
KW  - design engineering
KW  - quadcopter ground effect sensing
KW  - compliant contact-resistance-based airflow sensor
KW  - lightweight contact-resistance-based airflow sensor
KW  - wind tunnel characterization
KW  - sensor deflection
KW  - air flow speeds
KW  - flexible conductive pillar
KW  - elastomeric contact-resistance-based airflow sensor
KW  - nonobstructive solutions
KW  - power 42.0 muW
KW  - Wind speed
KW  - Robot sensing systems
KW  - Wind tunnels
KW  - Fabrication
KW  - Market research
KW  - Hair
DO  - 10.1109/ICRA.2018.8461229
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Sensors to measure quadcopter ground effect are often relatively large, heavy, and require significant power, which restricts their applicability when it comes to small quadcopters and other aircraft that require lightweight and non-obstructive solutions. This paper presents the design of an elastomeric contact-resistance-based airflow sensor to measure ground effect with a mass of approximately 0.04 g and a power draw of 42 μW when in operation. It uses a rigid flap attached to the top of a flexible conductive pillar (CNT/PDMS), which deflects with varying winds speeds. A simple model is presented to describe expected trends between air flow speeds and sensor deflection and is compared with a wind tunnel characterization of the sensor for varying airflows. The sensor is characterized in a wind tunnel to identify a minimum airflow necessary for sensor functionality. Finally, sensors are attached to a Crazyflie 2.0 (Bitcraze) quadcopter and tested for performance in detecting ground effect, where there is a clear trend between sensor output and the intensity of the turbulent flow, related to proximity to ground and thrust level.
ER  - 


TY  - CONF
TI  - Experiments in Fast, Autonomous, GPS-Denied Quadrotor Flight
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7832
EP  - 7839
AU  - K. Mohta
AU  - K. Sun
AU  - S. Liu
AU  - M. Watterson
AU  - B. Pfrommer
AU  - J. Svacha
AU  - Y. Mulgaonkar
AU  - C. J. Taylor
AU  - V. Kumar
PY  - 2018
KW  - aircraft control
KW  - aircraft navigation
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - helicopters
KW  - mobile robots
KW  - mixed indoor environments
KW  - outdoor environments
KW  - specific component technologies
KW  - high speed navigation capability
KW  - high speed autonomous flights
KW  - obstacle rich environments
KW  - GPS-denied quadrotor flight
KW  - unknown environments
KW  - robotics
KW  - fast computation
KW  - tight integration
KW  - subsystems
KW  - latency
KW  - perception-action loop
KW  - aerial robots
KW  - payload capacity
KW  - navigation system
KW  - quadrotor system
KW  - Cameras
KW  - Navigation
KW  - Robot vision systems
KW  - Laser radar
KW  - Payloads
DO  - 10.1109/ICRA.2018.8463214
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - High speed navigation through unknown environments is a challenging problem in robotics. It requires fast computation and tight integration of all the subsystems on the robot such that the latency in the perception-action loop is as small as possible. Aerial robots add a limitation of payload capacity, which restricts the amount of computation that can be carried onboard. This requires efficient algorithms for each component in the navigation system. In this paper, we describe our quadrotor system which is able to smoothly navigate through mixed indoor and outdoor environments and is able to fly at speeds of more than 18 m/s. We provide an overview of our system and details about the specific component technologies that enable the high speed navigation capability of our platform. We demonstrate the robustness of our system through high speed autonomous flights and navigation through a variety of obstacle rich environments.
ER  - 


TY  - CONF
TI  - A Self-contained Teleoperated Quadrotor: On-Board State-Estimation and Indoor Obstacle Avoidance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7840
EP  - 7847
AU  - M. Odelga
AU  - P. Stegagno
AU  - N. Kochanek
AU  - H. H. Bülthoff
PY  - 2018
KW  - autonomous aerial vehicles
KW  - cameras
KW  - collision avoidance
KW  - distance measurement
KW  - feedback
KW  - Global Positioning System
KW  - helicopters
KW  - image sequences
KW  - Kalman filters
KW  - mobile robots
KW  - path planning
KW  - probability
KW  - sensors
KW  - state estimation
KW  - telerobotics
KW  - tracking
KW  - on-board state-estimation
KW  - indoor obstacle avoidance
KW  - unmanned aerial vehicles
KW  - GPS signal
KW  - teleoperated quadrotor UAV platform
KW  - onboard miniature computer
KW  - linear velocity
KW  - Kalman filter integration
KW  - inertial flow
KW  - optical flow
KW  - depth measurements
KW  - robo-centric obstacle model
KW  - collision-free navigation
KW  - distance measurements
KW  - cramped spaces
KW  - sensors
KW  - tracking
KW  - RGB-D camera
KW  - visual feedback
KW  - probabilistic
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Estimation
KW  - Cameras
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8463185
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Indoor operation of unmanned aerial vehicles (UAV s) poses many challenges due to the lack of GPS signal and cramped spaces. The presence of obstacles in an unfamiliar environment requires reliable state estimation and active algorithms to prevent collisions. In this paper, we present a teleoperated quadrotor UAV platform equipped with an onboard miniature computer and a minimal set of sensors for this task. The platform is capable of highly accurate state-estimation, tracking of desired velocity commanded by the user and ensuring collision-free navigation. The robot estimates its linear velocity through a Kalman filter integration of inertial and optical flow (OF) readings with corresponding distance measurements. An RGB-D camera serves the purpose of providing visual feedback to the operator and depth measurements to build a probabilistic, robo-centric obstacle model, allowing the robot to avoid collisions. The platform is thoroughly validated in experiments in an obstacle rich environment.
ER  - 


TY  - CONF
TI  - Safe Teleoperation of Dynamic UAVs Through Control Barrier Functions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7848
EP  - 7855
AU  - B. Xu
AU  - K. Sreenath
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - helicopters
KW  - human-robot interaction
KW  - Lyapunov methods
KW  - quadratic programming
KW  - assistive training solution
KW  - safe human teleoperated flight
KW  - control approach
KW  - motion capture environment
KW  - safe teleoperation
KW  - control barrier functions
KW  - human operators
KW  - highly dynamic systems
KW  - constrained environment
KW  - quadrotor systems
KW  - potential obstacles
KW  - presented supervisory controller
KW  - safety constraints
KW  - dynamic UAV
KW  - exponential control barrier function
KW  - Safety
KW  - Trajectory
KW  - Collision avoidance
KW  - Vehicle dynamics
KW  - Dynamics
KW  - Robots
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8463194
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a method for assisting human operators to teleoperate highly dynamic systems such as quadrotors inside a constrained environment with safety guarantees. Our method enables human operators to focus on manually operating and flying quadrotor systems without the need to focus on avoiding potential obstacles. This is achieved with the presented supervisory controller overriding human input to enforce safety constraints when necessary. This method can be used as an assistive training solution for novice pilots to begin flying quadrotors without crashing them. Our supervisory controller uses an Exponential control barrier function based quadratic program to achieve safe human teleoperated flight. We demonstrate and validate our control approach through several experiments with multiple users with varying skill levels for three different scenarios of a quadrotor flying in a motion capture environment with virtual and physical constraints.
ER  - 


