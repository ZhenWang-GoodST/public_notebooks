TY  - CONF
TI  - Distributed Real Time Control of Multiple UAVs in Adversarial Environment: Algorithm and Flight Testing Results
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6659
EP  - 6664
AU  - M. Abdelkader
AU  - Y. Lu
AU  - H. Jaleel
AU  - J. S. Shamma
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - game theory
KW  - helicopters
KW  - mobile robots
KW  - multi-robot systems
KW  - optimal control
KW  - path planning
KW  - trajectory control
KW  - multiple quadrotors
KW  - flag game
KW  - distributed trajectory planning algorithm
KW  - WiFi based communication infrastructure
KW  - autopilot modules
KW  - low power computing modules
KW  - suboptimal control action
KW  - adversarial game
KW  - Gazebo robot simulator
KW  - multiple UAVs
KW  - quadrotor platform
KW  - flight testing
KW  - robot operating system
KW  - ROS
KW  - Games
KW  - Software algorithms
KW  - Software
KW  - Hardware
KW  - Real-time systems
KW  - Testing
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460866
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a complete design and implementation of a system that consists of multiple quadrotors playing capture the flag game. Our main contributions in this work include a custom built quadrotor platform, an efficient implementation of a distributed trajectory planning algorithm, and a WiFi based communication infrastructure. In our design, we equip the quadrotors with autopilot modules for low level control. Moreover, we install low power computing modules for implementing the distributed trajectory planning algorithm online. Furthermore, we develop a communication infrastructure to enable coordination among the quadrotors, which is required for computing a suboptimal control action in real time. The interactions among all the hardware and software components are managed at a higher level by Robot Operating System (ROS). To test the performance of the system, we select a motivating setup of capture the flag game, which is an adversarial game played between two teams of agents called attack and defense. The system is initially simulated in the Gazebo robot simulator with software in the loop. Finally, the complete system is tested and the flight testing results are presented.
ER  - 

TY  - CONF
TI  - Collaborative 6DoF Relative Pose Estimation for Two UAVs with Overlapping Fields of View
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6688
EP  - 6693
AU  - M. Karrer
AU  - M. Agarwal
AU  - M. Kamel
AU  - R. Siegwart
AU  - M. Chli
PY  - 2018
KW  - aerospace computing
KW  - autonomous aerial vehicles
KW  - groupware
KW  - image fusion
KW  - Kalman filters
KW  - multi-robot systems
KW  - nonlinear filters
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - monocular-inertial odometry
KW  - Extended Kalman Filter
KW  - collaborative scene estimation
KW  - monocular camera
KW  - variable-baseline stereo rig
KW  - inertial sensor
KW  - Unmanned Aerial Vehicles
KW  - collaborative robot operation
KW  - collaborative 6DoF relative pose estimation
KW  - UAV
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Collaboration
KW  - Estimation
KW  - Unmanned aerial vehicles
DO  - 10.1109/ICRA.2018.8461143
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Driven by the promise of leveraging the benefits of collaborative robot operation, this paper presents an approach to estimate the relative transformation between two small Unmanned Aerial Vehicles (UAVs), each equipped with a single camera and an inertial sensor, comprising the first step of any meaningful collaboration. Formation flying and collaborative object manipulation are some of the few tasks that the proposed work has direct applications on, while forming a variable-baseline stereo rig using two UAVs carrying a monocular camera each promises unprecedented effectiveness in collaborative scene estimation. Assuming an overlap in the UAVs' fields of view, in the proposed framework, each UAV runs monocular-inertial odometry onboard, while an Extended Kalman Filter fuses the UAVs' estimates and common image measurements to estimate the metrically scaled relative transformation between them, in realtime. Decoupling the direction of the baseline between the cameras of the two UAVs from its magnitude, this work enables consistent and robust estimation of the uncertainty of the relative pose estimation. Our evaluation on both on simulated data and benchmarking datasets consisting of real aerial data, reveals the power of the proposed methodology in a variety of scenarios. Video - https://youtu.be/AmkkaXa2601.
ER  - 

TY  - CONF
TI  - BFM: a Scalable and Resource-Aware Method for Adaptive Mission Planning of UAVs
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6702
EP  - 6707
AU  - C. Hireche
AU  - C. Dezan
AU  - J. Diguet
AU  - L. Mejias
PY  - 2018
KW  - autonomous aerial vehicles
KW  - belief networks
KW  - decision making
KW  - embedded systems
KW  - Markov processes
KW  - planning
KW  - quality of service
KW  - target tracking
KW  - diagnosis modules
KW  - Bayesian Networks
KW  - mission specifications
KW  - Markov Decision Processes
KW  - BFM model
KW  - application configurations
KW  - embedded system level
KW  - UAV level
KW  - target tracking mission
KW  - applications specifications
KW  - MDP model
KW  - embedded applications
KW  - resource-aware method
KW  - adaptive mission planning
KW  - external hazards
KW  - FMEA tables
KW  - scalable model
KW  - modular method
KW  - decision making process
KW  - UAV
KW  - internal hazards
KW  - Quality of service
KW  - Target tracking
KW  - Monitoring
KW  - Computational modeling
KW  - Sensor systems and applications
KW  - Context modeling
DO  - 10.1109/ICRA.2018.8460944
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - UAVs must continuously adapt their mission to face unexpected internal or external hazards. This paper proposes a new BFM model (Bayesian Networks built from FMEA tables for MDP). This scalable model offers a modular and comprehensive method to incorporate different types of diagnosis modules based on BN (Bayesian Networks) and FMEA table (Failure Mode and Effects Analysis) to mission specifications expressed as a MDP (Markov Decision Processes). The BFM model implements the complete decision making process that covers both the application configurations at the embedded system level and the mission planning at the UAV level. These decisions are based on the QoS (Quality of Service) of applications, the resource use and the system and sensors health. We demonstrate on a case study for a target tracking mission that the BFM model can interface hazards and applications specifications and can improve the success and quality of the mission. To the best of our knowledge, this is the first proposal of a systematic method that integrates diagnosis modules to MDP model in order to take care of the implementation of embedded applications during a mission.
ER  - 

TY  - CONF
TI  - Simultaneous Optimization of Assignments and Goal Formations for Multiple Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6708
EP  - 6715
AU  - S. Agarwal
AU  - S. Akella
PY  - 2018
KW  - approximation theory
KW  - computational complexity
KW  - graph theory
KW  - multi-robot systems
KW  - optimisation
KW  - path planning
KW  - O(n3) time complexity
KW  - optimal assignments
KW  - multiple robots
KW  - fixed goal formations
KW  - standard assignment problem
KW  - transformed problem
KW  - formation parameters
KW  - linear sum assignment problem
KW  - variable goal formation problem
KW  - location parameters
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Trajectory
KW  - Shape
KW  - Cost function
DO  - 10.1109/ICRA.2018.8460542
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents algorithms to simultaneously compute the optimal assignments and formation parameters for a team of robots from a given initial formation to a variable goal formation (where the shape of the goal formation is given, and its scale and location parameters must be optimized). We assume the n robots are identical spheres. We use the sum of squared travel distances as the objective function to be minimized, which also ensures that the trajectories are collision free. We show that this assignment with variable goal formation problem can be transformed to a linear sum assignment problem (LSAP) with pseudo costs that we establish are independent of the formation parameters. The transformed problem can then be solved using the Hungarian algorithm in O(n3) time. Thus the assignment problem with variable goal formations using this new approach has the same O(n3) time complexity as the standard assignment problem with fixed goal formations. Results from simulations on 200 and 600 robots are presented to show the algorithm is sufficiently fast for practical applications.
ER  - 

TY  - CONF
TI  - Machine Learning for Placement-Insensitive Inertial Motion Capture
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6716
EP  - 6721
AU  - X. Xiao
AU  - S. Zarar
PY  - 2018
KW  - calibration
KW  - image motion analysis
KW  - image sensors
KW  - multilayer perceptrons
KW  - sensor positions
KW  - body segments
KW  - standard deviation
KW  - calibration values
KW  - rotation matrices
KW  - inertial motion-capture systems
KW  - latency errors
KW  - motion data
KW  - sensor-displacement patterns
KW  - multilayer perceptrons
KW  - rotational transformations
KW  - kinematic algorithms
KW  - sensor movement
KW  - performance degradation
KW  - Euler angles
KW  - placement-insensitive inertial motion capture
KW  - machine learning
KW  - joint angles
KW  - sensor data
KW  - time 3.0 hour
KW  - Tracking
KW  - Robot sensing systems
KW  - Motion segmentation
KW  - Machine learning
KW  - Calibration
KW  - Kinematics
KW  - Neural networks
DO  - 10.1109/ICRA.2018.8463176
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Although existing inertial motion-capture systems work reasonably well (≤10° error in Euler angles), their accuracy suffers when sensor positions change relative to the associated body segments (±60° mean error and 120° standard deviation). We attribute this performance degradation to undermined calibration values, sensor movement latency and displacement offsets. The latter specifically leads to incongruent rotation matrices in kinematic algorithms that rely on rotational transformations. To overcome these limitations, we propose to employ machine-learning techniques. In particular, we use multi-layer perceptrons to learn sensor-displacement patterns based on 3 hours of motion data collected from 12 test subjects in the lab over 215 trials. Furthermore, to compensate for calibration and latency errors, we directly process sensor data with deep neural networks and estimate the joint angles. Based on these approaches, we demonstrate up to 69% reduction in tracking errors.
ER  - 

TY  - CONF
TI  - Optimizing Stiffness of a Novel Parallel-Actuated Robotic Shoulder Exoskeleton for a Desired Task or Workspace
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6745
EP  - 6751
AU  - J. Hunt
AU  - P. Artemiadis
AU  - H. Lee
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - feedback
KW  - medical robotics
KW  - optimisation
KW  - patient rehabilitation
KW  - robot dynamics
KW  - robot kinematics
KW  - wrist robots
KW  - analytical stiffness model
KW  - bounded nonlinear multiobjective optimization
KW  - parallel architecture
KW  - wearable hip
KW  - ankle
KW  - parallel-actuated robotic shoulder exoskeleton
KW  - sagittal plane
KW  - Shoulder
KW  - Actuators
KW  - Exoskeletons
KW  - Kinematics
KW  - End effectors
DO  - 10.1109/ICRA.2018.8463159
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The purpose of this work is to optimize the stiffness of a novel parallel-actuated robotic exoskeleton designed to offer a large workspace. This is done in an effort to help provide a solution to the issue wearable parallel actuated robots face regarding a tradeoff between stiffness and workspace. Presented in the form of a shoulder exoskeleton, the device demonstrates a new parallel architecture that can be used for wearable hip, ankle and wrist robots as well. The stiffness of the architecture is dependent on the placement of its actuated substructures. Therefore, it is desirable to place these substructures effectively so as to maximize dynamic performance for any application. In this work, an analytical stiffness model of the device is created and validated experimentally. The model is then used, along with a method of bounded nonlinear multi-objective optimization to configure the parallel actuators so as to maximize stiffness for the entire workspace. Furthermore, it is shown how to use the same technique to optimize the device for a particular task, such as lifting in the sagittal plane.
ER  - 

TY  - CONF
TI  - Adaptive Oscillator-Based Control for Active Lower-Limb Exoskeleton and its Metabolic Impact
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6752
EP  - 6758
AU  - K. Seo
AU  - K. Kim
AU  - Y. J. Park
AU  - J. Cho
AU  - J. Lee
AU  - B. Choi
AU  - B. Lim
AU  - Y. Lee
AU  - Y. Shim
PY  - 2018
KW  - adaptive control
KW  - artificial limbs
KW  - gait analysis
KW  - handicapped aids
KW  - medical robotics
KW  - muscle
KW  - patient rehabilitation
KW  - active lower-limb exoskeleton
KW  - metabolic impact
KW  - hip abduction/adduction
KW  - hip extension/flexion
KW  - knee extension/flexion joints
KW  - walking environment
KW  - adaptive oscillator-based control
KW  - electric actuators
KW  - Foot
KW  - Legged locomotion
KW  - Exoskeletons
KW  - Hip
KW  - Torque
KW  - Knee
KW  - Oscillators
DO  - 10.1109/ICRA.2018.8460841
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We developed a robotic lower-limb exoskeleton for those who have weakened muscle due to aging and experience difficulty in walking or getting up without help. The exoskeleton covering both limbs from the feet to the waist has 6 electric actuators in the hip abduction/adduction, hip extension/flexion and knee extension/flexion joints. For users with volitional motion, delivering assistance power according to their intention is a challenging task. We propose an adaptive oscillator-based controller to assist users walk in the lower-limb exoskeleton. To adapt to changes in walking speed and environment, motion command from the controller is modulated by estimate walking speed and walking environment recognized as one of the following categories: level ground, stairs up/down and slope up/down. Experimental results demonstrate the feasibility of the proposed environment recognition method and the impact of assistance on the metabolic cost of walking on level and inclined treadmills.
ER  - 

TY  - CONF
TI  - Human-Exoskeleton System Dynamics Identification Using Affordable Sensors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6759
EP  - 6765
AU  - R. Mallat
AU  - V. Bonnet
AU  - W. Huo
AU  - P. Karasinski
AU  - Y. Amirat
AU  - M. Khalil
AU  - S. Mohammed
PY  - 2018
KW  - gait analysis
KW  - Kalman filters
KW  - kinematics
KW  - medical robotics
KW  - Wii Balance Board
KW  - joint kinematics
KW  - body segment inertial parameters
KW  - human locomotor apparatus
KW  - augmented regressor matrix
KW  - ground reaction force
KW  - dynamic identification pipeline
KW  - QR visual markers
KW  - extended Kalman filter
KW  - human-exoskeleton system dynamics identification
KW  - lower limb exoskeleton
KW  - Exoskeletons
KW  - Kinematics
KW  - Solid modeling
KW  - Dynamics
KW  - Three-dimensional displays
KW  - Calibration
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8463178
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a practical method to identify body segments inertial parameters of a human-exoskeleton system using affordable and easy-to-use sensors. First, the joints and the base kinematics are estimated based on the use of an extended Kalman filter and QR visual markers. Then, joints kinematics are used in a dynamic identification pipeline together with the ground reaction force and moments collected with an affordable Wii Balance Board. The identification process is done using an augmented regressor matrix to identify at once each segment mass, center of mass 3D position and inertia tensor elements of both human locomotor apparatus and exoskeleton. The proposed method is able to accurately estimate external force and moments, with less than 6 % of normalized RMS difference in average, and is experimentally validated with a subject wearing a full lower limb exoskeleton.
ER  - 

TY  - CONF
TI  - A Locomotion Recognition System Using Depth Images
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6766
EP  - 6772
AU  - T. Yan
AU  - Y. Sun
AU  - T. Liu
AU  - C. Cheung
AU  - M. Q. Meng
PY  - 2018
KW  - artificial limbs
KW  - feature extraction
KW  - finite state machines
KW  - gait analysis
KW  - handicapped aids
KW  - intelligent robots
KW  - motion control
KW  - orthotics
KW  - robot vision
KW  - wearable robots
KW  - lower-limb assistive device
KW  - depth images
KW  - prostheses
KW  - daily living activities
KW  - intelligent controller
KW  - innovative locomotion recognition system
KW  - feature extraction subsystem
KW  - finite-state-machine based recognition subsystem
KW  - limb movements
KW  - locomotion modes
KW  - transition states
KW  - locomotion tasks
KW  - Powered lower-limb orthoses
KW  - wearable robot
KW  - Cameras
KW  - Task analysis
KW  - Image edge detection
KW  - Feature extraction
KW  - Legged locomotion
DO  - 10.1109/ICRA.2018.8460514
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Powered lower-limb orthoses and prostheses are attracting an increasing amount of attention in assisting daily living activities. To safely and naturally collaborate with human users, the key technology relies on an intelligent controller to accurately decode users' movement intention. In this work, we proposed an innovative locomotion recognition system based on depth images. Composed of a feature extraction subsystem and a finite-state-machine based recognition subsystem, the proposed approach is capable of capturing both the limb movements and the terrains right in front of the user. This makes it possible to anticipate the detection of locomotion modes, especially at transition states, thus enabling the associated wearable robot to deliver a smooth and seamless assistance. Validation experiments were implemented with nine subjects to trace a track that comprised of standing, walking, stair ascending, and stair descending, for three rounds each. The results showed that in steady state, the proposed system could recognize all four locomotion tasks with approximate 100% of accuracy. Out of 216 mode transitions, 82.4% of the intended locomotion tasks can be detected before the transition happened. Thanks to its high accuracy and promising prediction performance, the proposed locomotion recognition system is expected to significantly improve the safety as well as the effectiveness of a lower-limb assistive device.
ER  - 

TY  - CONF
TI  - The Effect of Bending Compliance on Adhesion Pressure of Hybrid Electrostatic/Gecko-Like Adhesives
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6773
EP  - 6778
AU  - B. Temple
AU  - A. Simaite
AU  - M. Spenko
PY  - 2018
KW  - adhesion
KW  - adhesives
KW  - bending
KW  - bending strength
KW  - elasticity
KW  - shear strength
KW  - substrates
KW  - surface roughness
KW  - dry switchable adhesives
KW  - compliant structures
KW  - high stored strain energy
KW  - shear adhesion pressures
KW  - contact area
KW  - bending compliance
KW  - hybrid electrostatic-gecko-like adhesives
KW  - shear stiffness
KW  - surface roughness
KW  - mechanical strength
KW  - substrates
KW  - Electrodes
KW  - Adhesives
KW  - Substrates
KW  - Force
KW  - Rough surfaces
KW  - Surface roughness
DO  - 10.1109/ICRA.2018.8460725
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the constraints in the design of dry switchable adhesives is the compliance trade-off: compliant structures conform better to surfaces but are limited in strength due to high stored strain energy. In this work we study the effects of bending compliance on the shear adhesion pressures of hybrid electrostatic/gecko-like adhesives of various areas. We reaffirm that normal electrostatic preload increases contact area and show that it is more effective on compliant adhesives. We also show that the gain in contact area can compensate for low shear stiffness and adhesives with high bending compliance outperform stiffer adhesives on substrates with large scale roughness.
ER  - 

TY  - CONF
TI  - Design of Frictional 2D-Anisotropy Surface for Wriggle Locomotion of Printable Soft-Bodied Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6779
EP  - 6785
AU  - T. D. Ta
AU  - T. Umedachi
AU  - Y. Kawahara
PY  - 2018
KW  - friction
KW  - mobile robots
KW  - continuum robots
KW  - soft-bodied robots
KW  - snake robot
KW  - serpentine locomotion
KW  - wriggle soft-bodied robot
KW  - high friction material
KW  - low friction material
KW  - snake-like soft-bodied robots
KW  - frictional 2D-anisotropy surface
KW  - printable soft-bodied robots
KW  - anisotropic structure
KW  - Friction
KW  - Tendons
KW  - Anisotropic magnetoresistance
KW  - DC motors
KW  - Mobile robots
KW  - Surface morphology
DO  - 10.1109/ICRA.2018.8463177
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft-bodied and continuum robots have shown great adaptability to the environment thanks to its flexibility of the body. They have great potential in environment exploring or rescuing mission. One of those robots is snake-like soft-bodied robots. A snake robot is often made by attaching passive wheels along a long body to achieve frictional anisotropy. This anisotropic structure helps to propel the body with serpentine locomotion and prevents it from sliding laterally. However, with a snake-like soft-bodied robot, attaching wheels is not only clumsy but also adding weight to the robot. In this paper, being inspired by the scales on the skin of a snake, we propose a designing scheme to achieve an all-printed wriggle soft-bodied robot by patterning high and low friction material to the ventral side of the robot. Compared to a totally flat ventral, we are able to speed-up the serpentine locomotion 2.8 times. Besides, by changing the configuration of high/low friction material, our wriggle soft-bodied robot can easily move forward or backward just by switching the controlling signal. The fabrication time is just less than 1 hour and the robot can achieve the speed of 26 mm/s.
ER  - 

TY  - CONF
TI  - Inchworm Locomotion Mechanism Inspired Self-Deformable Capsule-Like Robot: Design, Modeling, and Experimental Validation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6800
EP  - 6805
AU  - Y. Luo
AU  - N. Zhao
AU  - K. J. Kim
AU  - J. Yi
AU  - Y. Shen
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - biomimetics
KW  - deformation
KW  - robot dynamics
KW  - robot kinematics
KW  - crawling locomotion behavior
KW  - inchworm-like crawling movement
KW  - deformable properties
KW  - bio-inspired design
KW  - robot kinematics
KW  - experimental validation
KW  - actuated deformation capability
KW  - soft actuation mechanisms
KW  - inchworm locomotion mechanism
KW  - self-deformable capsule-like robot
KW  - rigid elements-based morphing structure
KW  - robot deformation
KW  - Robots
KW  - Force
KW  - Strain
KW  - Friction
KW  - Kinetic theory
KW  - Biological system modeling
DO  - 10.1109/ICRA.2018.8460666
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Inspired by the inchworm locomotion mechanism, this paper presents our recently developed self-deformable capsule-like robot. The robot has the actuated deformation capability that relies on a novel rigid elements-based morphing structure (REMS) and its soft actuation mechanisms. When the robot deforms, it generates the crawling locomotion behavior and thus friction waves between the robot and contact surface to facilitate the inchworm-like crawling movement. The paper starts reviewing the deformable properties of natural biological entities like capsules, presents state of the art of the current capsule-like robots, and details the bio-inspired design of the self-deformable capsule-like robot by describing the model of robot kinematics and its locomotion mechanism. Both simulation and experimental results validate the excellent performance of this capsule-like robot. The developed self-deformable capsule-like robot has the advantage of crawling on varied surfaces and it also has the capabilities to crawl in a variety of narrow pipes based on the deformation elicited locomotion nature of the robot.
ER  - 

TY  - CONF
TI  - Realtime On-Board Attitude Estimation of High-Frequency Flapping Wing MAVs Under Large Instantaneous Oscillation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6806
EP  - 6811
AU  - Z. Tu
AU  - F. Fei
AU  - Y. Yang
AU  - J. Zhang
AU  - X. Deng
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - sensor fusion
KW  - realtime on-board attitude estimation
KW  - high-frequency flapping wing MAVs
KW  - instantaneous oscillation
KW  - fixed wings
KW  - rotary wings
KW  - high-frequency wing flapping
KW  - aerial vehicles
KW  - Flapping Wing Micro Aerial Vehicles
KW  - FWMAVs
KW  - instantaneous oscillations
KW  - Magnetometers
KW  - Robot sensing systems
KW  - Aerodynamics
KW  - Estimation
KW  - Accelerometers
KW  - Magnetic flux
KW  - Magnetomechanical effects
DO  - 10.1109/ICRA.2018.8461025
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Unlike conventional aerial vehicles of fixed or rotary wings, realtime on-board attitude estimation of insect or hummingbird scale Flapping Wing Micro Aerial Vehicles (FWMAVs) is very challenging due to the severe instantaneous oscillations (approximately ten times of gravity on our platform) induced by high-frequency wing flapping. In this work, we present a novel sensor fusion algorithm for realtime on-board attitude estimation of FWMAVs. The algorithm is proposed with adaptive model-based compensation for both sensing drift and aerodynamic forces induced by flapping wings. We validated our approach on a 12.5 grams hummingbird robot. The experimental results demonstrated the accuracy, convergence, and robustness of the proposed algorithm.
ER  - 

TY  - CONF
TI  - FireAnt: A Modular Robot with Full-Body Continuous Docks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6812
EP  - 6817
AU  - P. Swissler
AU  - M. Rubenstein
PY  - 2018
KW  - mobile robots
KW  - robotic assembly
KW  - self-assembly
KW  - modular 2D robot
KW  - full-body continuous docks
KW  - docking mechanism
KW  - mechanical complexity
KW  - robotic self-assembling structures
KW  - inert fireant robots
KW  - Robot sensing systems
KW  - Plastics
KW  - Copper
KW  - Strips
KW  - Wires
DO  - 10.1109/ICRA.2018.8463146
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Nature offers many examples of organisms coming together to form self-assembling structures. The attachment methods these organisms employ allow them to grab onto others' bodies, often without need for specific alignment or orientation, an ability absent from most existing robotic self-assembling structures, which require complicated sensing and specific alignment. This paper presents FireAnt, a modular 2D robot that demonstrates full-body continuous docks, an attachment mechanism able to attach anywhere onto other robots at any orientation, eliminating the need for alignment mechanisms and complex sensors. Such docks allow FireAnt to climb over copies of itself, something critical to self-assembling structures. This paper first discusses the design of FireAnt before presenting test results that show the strength and reliability of the continuous docks and demonstrate FireAnt's ability to traverse an environment consisting of inert FireAnt robots. The work presented in this paper provides a docking mechanism that can minimize the mechanical complexity of modular robots and will allow the creation of swarms of rigid and adaptable self-assembling structures.
ER  - 

TY  - CONF
TI  - Perception-Informed Autonomous Environment Augmentation with Modular Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6818
EP  - 6824
AU  - T. Tosun
AU  - J. Daudelin
AU  - G. Jing
AU  - H. Kress-Gazit
AU  - M. Campbell
AU  - M. Yim
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - planning (artificial intelligence)
KW  - high-level planner
KW  - disconnected regions
KW  - hardware experiments
KW  - planning tools
KW  - robot locomotion capabilities
KW  - specially-designed building blocks
KW  - environment characterization algorithm
KW  - modular robot systems
KW  - building structures
KW  - high-level tasks
KW  - perception-informed autonomous environment augmentation
KW  - Task analysis
KW  - Hardware
KW  - Mobile robots
KW  - Bridges
KW  - Buildings
KW  - Planning
DO  - 10.1109/ICRA.2018.8463155
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a system enabling a modular robot to autonomously build structures in order to accomplish high-level tasks. Building structures allows the robot to surmount large obstacles, expanding the set of tasks it can perform. This addresses a common weakness of modular robot systems, which often struggle to traverse large obstacles. This paper presents the hardware, perception, and planning tools that comprise our system. An environment characterization algorithm identifies features in the environment that can be augmented to create a path between two disconnected regions of the environment. Specially-designed building blocks enable the robot to create structures that can augment the environment to make obstacles traversable. A high-level planner reasons about the task, robot locomotion capabilities, and environment to decide if and where to augment the environment in order to perform the desired task. We validate our system in hardware experiments.
ER  - 

TY  - CONF
TI  - Design and Online Calibration of a Highly Compact Microgripper
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6825
EP  - 6830
AU  - Z. Yu
AU  - Q. Shi
AU  - H. Wang
AU  - T. Sun
AU  - Q. Huang
AU  - T. Fukuda
PY  - 2018
KW  - calibration
KW  - grippers
KW  - image sensors
KW  - microassembling
KW  - micromanipulators
KW  - microsensors
KW  - position measurement
KW  - compact microgripper
KW  - microobject manipulation
KW  - flexure hinge
KW  - low impedance grasping mechanism
KW  - kinematics analysis
KW  - fine element analysis
KW  - FEA
KW  - fibrous microring assembling
KW  - visual-based calibration method
KW  - position sensors
KW  - laser sensor
KW  - embedded sensors
KW  - dexterous manipulation
KW  - Grippers
KW  - Force
KW  - Fasteners
KW  - Calibration
KW  - Robot sensing systems
KW  - Strain measurement
KW  - Prototypes
DO  - 10.1109/ICRA.2018.8460683
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Microgrippers play a significant role in manipulation of micro-objects. To achieve dexterous and precise manipulation, a microgripper is required to be compactly designed and embedded with sensing feedback. Meanwhile, to convert the sensor position into displacement of the microgripper, the embedded sensors should be calibrated by additional equipment like laser sensor. However, a microgripper always needs to be calibrated during manipulation (online calibration), which is still a big challenge with current technology. In this paper, we proposed a highly compact microgripper integrated with position sensors, and a visual-based calibration method to handle such challenge. Moreover, to enhance grasping accuracy, flexure hinges are employed to achieve a low impedance grasping mechanism and to avoid the backlash in traditional bearing. Furthermore, kinematics analysis and Fine Element Analysis (FEA) are implemented to improve the design efficiency. Finally, fibrous micro-rings are successfully assembled, and the results reveal that the calibrated microgripper can be well employed to operate micro-objects.
ER  - 

TY  - CONF
TI  - Grasping of Unknown Objects Using Deep Convolutional Neural Networks Based on Depth Images
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6831
EP  - 6838
AU  - P. Schmidt
AU  - N. Vahrenkamp
AU  - M. Wächter
AU  - T. Asfour
PY  - 2018
KW  - dexterous manipulators
KW  - end effectors
KW  - feedforward neural nets
KW  - grippers
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - rendering (computer graphics)
KW  - robot vision
KW  - Deep Convolutional Neural Networks
KW  - training input
KW  - high-quality grasps
KW  - analytical grasp planners
KW  - rendered depth images
KW  - training objects
KW  - deep learning techniques
KW  - robotic grasping
KW  - approach directions
KW  - grasping setup
KW  - big data grasping database
KW  - qualitative grasping experiments
KW  - humanoid robot ARMAR-III
KW  - unknown objects
KW  - data-driven
KW  - deep learning approach
KW  - Grasping
KW  - Robots
KW  - Training
KW  - Data models
KW  - Databases
KW  - Feature extraction
KW  - Machine learning
DO  - 10.1109/ICRA.2018.8463204
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a data-driven, bottom-up, deep learning approach to robotic grasping of unknown objects using Deep Convolutional Neural Networks (DCNNs). The approach uses depth images of the scene as its sole input for synthesis of a single-grasp solution during execution, adequately portraying the robot's visual perception during exploration of a scene. The training input consists of precomputed high-quality grasps, generated by analytical grasp planners, accompanied with rendered depth images of the training objects. In contrast to previous work on applying deep learning techniques to robotic grasping, our approach is able to handle full end-effector poses and therefore approach directions other than the view direction of the camera. Furthermore, the approach is not limited to a certain grasping setup (e. g. parallel jaw gripper) by design. We evaluate the method regarding its force-closure performance in simulation using the KIT and YCB object model datasets as well as a big data grasping database. We demonstrate the performance of our approach in qualitative grasping experiments on the humanoid robot ARMAR-III.
ER  - 

TY  - CONF
TI  - Grasp Planning for Load Sharing in Collaborative Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6847
EP  - 6854
AU  - U. Tariq
AU  - R. Muthusamy
AU  - V. Kyrki
PY  - 2018
KW  - dexterous manipulators
KW  - force control
KW  - grippers
KW  - human-robot interaction
KW  - industrial manipulators
KW  - lifting
KW  - manipulators
KW  - collaborative manipulation
KW  - manipulation task
KW  - grasp location
KW  - human robot collaborative lifting task
KW  - grasp planning
KW  - grasp analysis approach
KW  - load sharing
KW  - partial observability
KW  - two-agent decentralized set-up
KW  - Task analysis
KW  - Robot kinematics
KW  - Planning
KW  - Collaboration
KW  - Force
KW  - Quadratic programming
DO  - 10.1109/ICRA.2018.8460579
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In near future, robots are envisioned to work alongside humans in unstructured professional and domestic environments. In such setups, collaborative manipulation is a fundamental skill that allows manipulation of heavy loads by load sharing between agents. Grasp planning plays a pivotal role for load sharing but it has not received attention in the literature. This work proposes a grasp analysis approach for collaborative manipulation that allows load sharing by minimizing exerted grasp wrenches in a task specific way. The manipulation task is defined as expected external wrenches acting on the target object. The analysis approach is demonstrated in a two-agent decentralized set-up with unknown objects. After the first agent has grasped the target, the second agent observes the first agent's grasp location and plans its own grasp according to optimal load sharing. The method was verified in a human robot collaborative lifting task. Experiments with multiple objects show that the proposed method results in optimal load sharing despite limited information and partial observability.
ER  - 

TY  - CONF
TI  - Human-Inspired Object Manipulation Control with the Anatomically Correct Testbed Hand
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6861
EP  - 6866
AU  - T. D. Niehues
AU  - A. D. Deshpande
PY  - 2018
KW  - biocontrol
KW  - biomechanics
KW  - dexterous manipulators
KW  - force control
KW  - manipulator dynamics
KW  - mechanical stability
KW  - muscle
KW  - position control
KW  - human neuromuscular system
KW  - grasp stability
KW  - human-inspired object manipulation control
KW  - anatomically correct testbed hand
KW  - dexterous manipulation
KW  - robotic hand
KW  - object-level impedance control strategies
KW  - grasp forces
KW  - robotic system
KW  - object stiffness control gains
KW  - object-space stiffness control algorithm
KW  - object size
KW  - object shape
KW  - grasp stability bounds
KW  - object-space stiffness
KW  - low-level stiffness
KW  - ACT hand
KW  - Robots
KW  - Force
KW  - Tendons
KW  - Task analysis
KW  - Muscles
KW  - Frequency modulation
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8463166
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Dexterous manipulation with robotic hands can be achieved using object-level impedance control strategies, which allow intuitive regulation of object position, external environmental interactions, and grasp forces. However, for grasp stability, object stiffness gains are limited by the inherent compliance of the robotic system, object size/shape, and applied grasp forces, which can lead to restricted manipulation capabilities. In this work, we first use analytical modeling techniques to explore the theoretical passivity bounds on object stiffness control gains to ensure grasp stability. Then, an object-space stiffness control algorithm is developed for the Anatomically Correct Testbed (ACT) hand, a robotic hand designed to replicate the complex tendon and joint structure of the human hand, and grasp stability bounds are experimentally tested for various task scenarios. Finally, inspired by the hierarchical structure of the human neuromuscular system, we develop a novel control strategy that implements low-level stiffness in muscle-space, while also emulating a separately defined object-space stiffness in quasi-static conditions. Experimental results demonstrate that this control strategy increases achievable object stiffness without sacrificing grasp stability, leading to significantly increased manipulation capabilities.
ER  - 

TY  - CONF
TI  - Improving Superquadric Modeling and Grasping with Prior on Object Shapes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6875
EP  - 6882
AU  - G. Vezzani
AU  - U. Pattacini
AU  - G. Pasquale
AU  - L. Natale
PY  - 2018
KW  - grippers
KW  - humanoid robots
KW  - pattern classification
KW  - superquadric modeling
KW  - grasping
KW  - object shape
KW  - object modeling
KW  - humanoid robots
KW  - superquadric functions
KW  - object classifier
KW  - robot hands
KW  - robotic system
KW  - iCub humanoid robot
KW  - Grasping
KW  - Shape
KW  - Computational modeling
KW  - Robots
KW  - Three-dimensional displays
KW  - Pipelines
KW  - Optimization
DO  - 10.1109/ICRA.2018.8463161
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes an object modeling and grasping pipeline for humanoid robots. This work improves our previous approach based on superquadric functions. In particular, we speed up and refine the modeling process by using prior information on the object shape provided by an object classifier. We use our previous method for the computation of grasping pose to obtain pose candidates for both the robot hands and, then, we automatically choose the best candidate for grasping the object according to a given quality index. The performance of our pipeline has been assessed on a real robotic system, the iCub humanoid robot. The robot can grasp 18 objects of the YCB and iCub World datasets considerably different in terms of shape and dimensions with a high success rate.
ER  - 

TY  - CONF
TI  - Active Reward Learning from Critiques
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6907
EP  - 6914
AU  - Y. Cui
AU  - S. Niekum
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - query processing
KW  - robot programming
KW  - critiques
KW  - active reward Learning
KW  - programming robots
KW  - active Bayesian inverse reinforcement learning
KW  - trajectory queries
KW  - labeling process
KW  - active learning
KW  - Trajectory
KW  - Robots
KW  - Learning (artificial intelligence)
KW  - Bayes methods
KW  - Entropy
KW  - Task analysis
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8460854
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Learning from demonstration algorithms, such as Inverse Reinforcement Learning, aim to provide a natural mechanism for programming robots, but can often require a prohibitive number of demonstrations to capture important subtleties of a task. Rather than requesting additional demonstrations blindly, active learning methods leverage uncertainty to query the user for action labels at states with high expected information gain. However, this approach can still require a large number of labels to adequately reduce uncertainty and may also be unintuitive, as users are not accustomed to determining optimal actions in a single out-of-context state. To address these shortcomings, we propose a novel trajectory-based active Bayesian inverse reinforcement learning algorithm that (1) queries the user for critiques of automatically generated trajectories, rather than asking for demonstrations or action labels, (2) utilizes trajectory segmentation to expedite the critique / labeling process, and (3) predicts the user's critiques to generate the most highly informative trajectory queries. We evaluated our algorithm in simulated domains, finding it to compare favorably to prior work and a randomized baseline.
ER  - 

TY  - CONF
TI  - Uncertainty-Aware Learning from Demonstration Using Mixture Density Networks with Sampling-Free Variance Modeling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6915
EP  - 6922
AU  - S. Choi
AU  - K. Lee
AU  - S. Lim
AU  - S. Oh
PY  - 2018
KW  - estimation theory
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - measurement uncertainty
KW  - mobile robots
KW  - Monte Carlo methods
KW  - sampling methods
KW  - uncertainty handling
KW  - uncertainty estimation method utilizing
KW  - Monte Carlo sampling
KW  - robotics applications
KW  - autonomous driving
KW  - epistemic uncertainties
KW  - aleatoric uncertainties
KW  - uncertainty acquisition
KW  - demonstration method
KW  - sampling-free variance modeling
KW  - mixture density network
KW  - uncertainty-aware learning
KW  - Uncertainty
KW  - Predictive models
KW  - Noise measurement
KW  - Data models
KW  - Training
KW  - Estimation
KW  - Measurement uncertainty
DO  - 10.1109/ICRA.2018.8462978
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we propose an uncertainty-aware learning from demonstration method by presenting a novel uncertainty estimation method utilizing a mixture density network appropriate for modeling complex and noisy human behaviors. The proposed uncertainty acquisition can be done with a single forward path without Monte Carlo sampling and is suitable for real-time robotics applications. Then, we show that it can be decomposed into explained variance and unexplained variance where the connections between aleatoric and epistemic uncertainties are addressed. The properties of the proposed uncertainty measure are analyzed through three different synthetic examples, absence of data, heavy measurement noise, and composition of functions scenarios. We show that each case can be distinguished using the proposed uncertainty measure and presented an uncertainty-aware learning from demonstration method for autonomous driving using this property. The proposed uncertainty-aware learning from demonstration method outperforms other compared methods in terms of safety using a complex real-world driving dataset.
ER  - 

TY  - CONF
TI  - Human-Driven Feature Selection for a Robotic Agent Learning Classification Tasks from Demonstration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6923
EP  - 6930
AU  - K. Bullard
AU  - S. Chernova
AU  - A. L. Thomaz
PY  - 2018
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - pattern classification
KW  - robots
KW  - LfD scenarios
KW  - human feature selection
KW  - robot learner
KW  - informative features
KW  - multiclass classification task
KW  - computational feature selection
KW  - human selected features
KW  - informative task features
KW  - general-purpose robot
KW  - learning computation
KW  - robotic agent learning classification tasks
KW  - human-driven feature selection
KW  - Task analysis
KW  - Feature extraction
KW  - Robots
KW  - Training
KW  - Training data
KW  - Object recognition
KW  - Support vector machines
DO  - 10.1109/ICRA.2018.8461012
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The state features available to a robot define the variables on which the learning computation depends. However, little prior work considers feature selection in the context of deploying a general-purpose robot able to learn new tasks. In this work, we explore human-driven feature selection in which a robotic agent can identify useful features with the aid of a human user, by extracting information from users about which features are most informative for discriminating between classes of objects needed for a given task (e.g. sorting groceries). The research questions examine (a) whether a domain expert is able to identify a subset of informative task features, (b) whether human selected features will enable the agent to classify unseen examples as accurately as using computational feature selection, and (c) if the interaction strategy used to elicit the information from the user impacts the quality of resulting feature selection. Toward that end, we conducted a user study with 30 participants on campus, given a multi-class classification task and one of five different approaches for conveying information about informative features to a robot learner. Our findings show that when features are semantically interpretable, human feature selection is effective in LfD scenarios because it is able to outperform computational methods when there is limited training data, yet still remains on-par with computational methods as the training sample size increases.
ER  - 

TY  - CONF
TI  - Object-Centric Approach to Prediction and Labeling of Manipulation Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6931
EP  - 6938
AU  - E. H. Chen
AU  - D. Burschka
PY  - 2018
KW  - cameras
KW  - graph theory
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - object-centric approach
KW  - manipulation tasks
KW  - human manipulation actions
KW  - object trajectories
KW  - context specific human vocabulary
KW  - directed action graph representation
KW  - pre-computed Location Areas
KW  - offline teaching phase
KW  - graph generation
KW  - online action recognition phase
KW  - high-level reasoning
KW  - sensor observation
KW  - visual sensory input
KW  - depth camera
KW  - LA
KW  - sector-maps
KW  - SM
KW  - Service robots
KW  - Hidden Markov models
KW  - Vocabulary
KW  - Feature extraction
KW  - Knowledge based systems
KW  - Task analysis
KW  - Action Recognition
KW  - Motion analysis
KW  - Graph method
KW  - Location Area
KW  - Sector-Map
KW  - Knowledge representation
DO  - 10.1109/ICRA.2018.8462973
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose an object-centric framework to label and predict human manipulation actions from observations of the object trajectories in 3D space. The goal is to lift the low-level sensor observation to a context specific human vocabulary. The low-level visual sensory input from a depth camera is processed into high-level descriptive action labels using a directed action graph representation. It is built based on the concepts of pre-computed Location Areas (LA), regions within a scene where an action typically occur, and Sector-Maps (SM), reference trajectories between the LAs. The framework consists of two stages, an offline teaching phase for graph generation, and an online action recognition phase that maps the current observations to the generated graph. This graph representation allows the framework to predict the most probable action from the observed motion in real-time and to adapt its structure whenever a new LA appears. Furthermore, the descriptive action labels enable not only a better exchange of information between a human and a robot but they allow also the robots to perform high-level reasoning. We present experimental results on real human manipulation actions using a system designed with this framework to show the performance of prediction and labeling that can be achieved.
ER  - 

TY  - CONF
TI  - Deep Auxiliary Learning for Visual Localization and Odometry
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6939
EP  - 6946
AU  - A. Valada
AU  - N. Radwan
AU  - W. Burgard
PY  - 2018
KW  - distance measurement
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pose estimation
KW  - video signal processing
KW  - state-of-the-art SIFT-based approaches
KW  - deep learning technique
KW  - multitask learning
KW  - Geometric Consistency Loss
KW  - visual odometry estimation
KW  - global localization
KW  - parameter sharing
KW  - multitask model
KW  - consecutive monocular images
KW  - VLocNet
KW  - convolutional neural networks
KW  - action execution
KW  - robot
KW  - visual localization
KW  - Task analysis
KW  - Visual odometry
KW  - Estimation
KW  - Visualization
KW  - Training
KW  - Robustness
DO  - 10.1109/ICRA.2018.8462979
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Localization is an indispensable component of a robot's autonomy stack that enables it to determine where it is in the environment, essentially making it a precursor for any action execution or planning. Although convolutional neural networks have shown promising results for visual localization, they are still grossly outperformed by state-of-the-art local feature-based techniques. In this work, we propose VLocNet, a new convolutional neural network architecture for 6-DoF global pose regression and odometry estimation from consecutive monocular images. Our multitask model incorporates hard parameter sharing, thus being compact and enabling real-time inference, in addition to being end-to-end trainable. We propose a novel loss function that utilizes auxiliary learning to leverage relative pose information during training, thereby constraining the search space to obtain consistent pose estimates. We evaluate our proposed VLocNet on indoor as well as outdoor datasets and show that even our single task model exceeds the performance of state-of-the-art deep architectures for global localization, while achieving competitive performance for visual odometry estimation. Furthermore, we present extensive experimental evaluations utilizing our proposed Geometric Consistency Loss that show the effectiveness of multitask learning and demonstrate that our model is the first deep learning technique to be on par with, and in some cases outperforms state-of-the-art SIFT-based approaches.
ER  - 

TY  - CONF
TI  - An Experimental Investigation of Extra Measurements for Solving the Direct Kinematics of Cable-Driven Parallel Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6947
EP  - 6952
AU  - J. -. Merlet
PY  - 2018
KW  - manipulator kinematics
KW  - position control
KW  - CDPR
KW  - extra measurements
KW  - extra sensors
KW  - cable orientations
KW  - direct kinematics
KW  - cable-driven parallel robots
KW  - cable length measurements
KW  - model-based approach
KW  - cable tension sensors
KW  - Measurement uncertainty
KW  - Mathematical model
KW  - Robot sensing systems
KW  - Kinematics
KW  - Instruments
DO  - 10.1109/ICRA.2018.8460901
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Solving the direct kinematics (DK) of cable-driven parallel robots (CDPR) based only on the cable length measurements is a demanding problem that is still not well mastered, especially for robots having sagging cables. A model-based approach may be used to solve this problem but the model parameters and measurements are uncertain, thereby leading to positioning inaccuracy. A possible way to improve the accuracy and speed up the solving is to add extra measurements. For that purpose a preliminary step is to determine what type of measurements are possible and then to estimate how accurate they are. For that purpose we have used a CDPR with 4 cables that has been instrumented with various types of extra measurements: cable tensions and orientations, platform orientation. Ground truth has been established and we have compared the data provided by the extra sensors with their real values. This work shows that cable tensions sensors and platform orientation sensors are not good candidates to be used for the DK while cable orientations may be obtained with a good accuracy both in static poses or during a quasi-static motion.
ER  - 

TY  - CONF
TI  - Kinematic Optimization of a Novel Partially Decoupled Three Degree of Freedom Hybrid Wrist Mechanism
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6953
EP  - 6960
AU  - N. M. Bajaj
AU  - A. M. Dollar
PY  - 2018
KW  - actuators
KW  - couplings
KW  - manipulator kinematics
KW  - motion control
KW  - optimisation
KW  - kinematic design
KW  - geometric optimization
KW  - prismatic-revolute-universal linkage
KW  - prismatic-spherical-spherical linkage
KW  - spherical motion
KW  - pitch-yaw-roll wrist
KW  - arbitrary direction
KW  - forward kinematics
KW  - inverse kinematics
KW  - parallel 2-DOF mechanism
KW  - design parameters
KW  - global transmission index
KW  - torque transmissibility
KW  - decoupled nature
KW  - yaw mechanism
KW  - kinematic optimization
KW  - partially decoupled three degree of freedom hybrid wrist mechanism
KW  - wrist configuration
KW  - Kinematics
KW  - Wrist
KW  - Couplings
KW  - Actuators
KW  - Optimization
KW  - Computer architecture
KW  - End effectors
DO  - 10.1109/ICRA.2018.8460568
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper discusses the kinematic design and geometric optimization of a novel hybrid three degree-of-freedom (DOF) wrist mechanism. The architecture consists of a one prismatic-revolute-universal linkage and one prismatic-spherical-spherical linkage in parallel with a revolute-universal linkage. This architecture is capable of spherical motion identical to that of a pitch-yaw-roll wrist. Moreover, this mechanism is considered to be partially decoupled, as not all actuators contribute to motion in an arbitrary direction. The forward and inverse kinematics of the parallel 2-DOF mechanism are presented. The 2-DOF mechanism is geometrically optimized over its design parameters to maximize a global transmission index, which measures the motion and torque transmissibility of particular wrist configuration over its workspace. The decoupled nature of the mechanism allows the pitch and yaw mechanism to be optimized separately, greatly reducing the parameter search space and allowing a much larger number of mechanism configurations to be simulated. We leverage this increase in simulated configurations to examine the effect of size constraints on the resulting mechanisms as well.
ER  - 

TY  - CONF
TI  - Reconfiguration Analysis and Motion Planning of a Novel Reconfigurable Mobile Manipulator Torso
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6961
EP  - 6966
AU  - W. Ding
AU  - T. Detert
AU  - J. De La Cruz
AU  - B. Corves
PY  - 2018
KW  - bars
KW  - flexible manipulators
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - reconfiguration analysis
KW  - mutual mode transition rules
KW  - kinematics model
KW  - motion planning
KW  - reconfiguration rules
KW  - ReConBot
KW  - flexible torso
KW  - straight bar-shape base
KW  - metamorphic kinematic chains
KW  - configuration states
KW  - reconfigurable mobile manipulator torso
KW  - 2RER reconfigurable parallel mechanism
KW  - transition handling
KW  - singularity position
KW  - Kinematics
KW  - Torso
KW  - Mathematical model
KW  - Robot kinematics
KW  - Planning
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8460214
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A novel 2-RER reconfigurable parallel mechanism (ReConBot) considered as the flexible torso of the mobile manipulator is proposed. This paper deals with the analysis of reconfiguration, kinematics, and motion planning. The ReConBot is composed of straight bar-shape base and moving platforms and two metamorphic kinematic chains (MKC) consisted of a revolute (R) joint, a planar (E) joint, and an R joint in sequence. Firstly, mobility and reconfiguration analysis discuss the conditions and mutual mode transition rules of 12 possible configuration states. And then, the kinematics model covers all states with Cartesian coordinate and axis/angle representations. What's more, the motion planning following the rules of the mode transition is explained and illustrated together with a case study. Furthermore, the method of handling the transition at singularity position is discussed. Finally, the robotic system and its experiments verify the correctness of the theoretical analysis and the validation of reconfiguration rules.
ER  - 

TY  - CONF
TI  - Efficient Event-Driven Forward Kinematics of Open Kinematic Chains with O(Log n) Complexity
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6975
EP  - 6982
AU  - R. Wakatabe
AU  - K. Morita
AU  - G. Cheng
AU  - Y. Kuniyoshi
PY  - 2018
KW  - computational complexity
KW  - manipulator kinematics
KW  - matrix algebra
KW  - open kinematic chains
KW  - event-driven forward kinematics algorithms
KW  - computational resources
KW  - root joint
KW  - conventional forward kinematics
KW  - computation time
KW  - event-driven FK algorithms
KW  - sensory data
KW  - homogeneous transformation matrix
KW  - time-variance
KW  - algebraic structures
KW  - Kinematics
KW  - Robot sensing systems
KW  - Heuristic algorithms
KW  - Robot kinematics
KW  - Complexity theory
KW  - Real-time systems
DO  - 10.1109/ICRA.2018.8461211
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents novel event-driven forward kinematics algorithms for open kinematic chains with O(log n) complexity. This event-driven algorithm can efficiently update forward kinematics only when new sensory data comes. This will also contribute to localization of computational resources at sensitive joints to the position of the endpoint (e.g. a fingertip), like a root joint. We constructed 3 event-driven FK algorithms. We proved that the algorithms have the complexity of O(logn) for updating 1 joint angle, and O(logn) for obtaining a homogeneous transformation matrix between links. We compared the 3 algorithms with a conventional forward kinematics algorithm in the viewpoint of complexity, computation time, time-variance and algebraic structures. The results showed that the computation time is well adequate for real-time computation. Computation time is less than 2 us per 1 query, for 40,000 kinematic chains.
ER  - 

TY  - CONF
TI  - Reactive Magnetic-Field-Inspired Navigation for Non-Holonomic Mobile Robots in Unknown Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6983
EP  - 6988
AU  - A. Ataka
AU  - H. Lam
AU  - K. Althoefer
PY  - 2018
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - TurtleBot mobile robot platform
KW  - local sensory information
KW  - arbitrary-shaped convex environment
KW  - magnetic fields
KW  - nonholonomic mobile robot taking inspiration
KW  - reactive robot navigation method
KW  - unknown environments
KW  - nonholonomic mobile robots
KW  - reactive magnetic-field-inspired navigation
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Navigation
KW  - Mobile robots
KW  - Force
KW  - Wires
DO  - 10.1109/ICRA.2018.8463203
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a reactive robot navigation method for a non-holonomic mobile robot taking inspiration from the phenomena observed in magnetic fields. The algorithm is shown to be able to guide mobile robots in arbitrary-shaped convex environment without being trapped in local minima by exploiting the local sensory information without priori knowledge about the environment. A preliminary validation study involving simulation of and experiments with a TurtleBot mobile robot platform show the advantage of the proposed method over existing ones.
ER  - 

TY  - CONF
TI  - Aerial Grasping Based on Shape Adaptive Transformation by HALO: Horizontal Plane Transformable Aerial Robot with Closed-Loop Multilinks Structure
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6990
EP  - 6996
AU  - T. Anzai
AU  - M. Zhao
AU  - S. Nozawa
AU  - F. Shi
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - aerospace control
KW  - autonomous aerial vehicles
KW  - closed loop systems
KW  - mobile robots
KW  - optimisation
KW  - position control
KW  - propellers
KW  - closed-loop aerial transformation
KW  - aerial grasping
KW  - shape adaptive transformation
KW  - aerial manipulation
KW  - HALO
KW  - horizontal plane transformable aerial robot
KW  - closed-loop multilinks structure
KW  - flight control
KW  - serial-link structure
KW  - propeller
KW  - optimization planning method
KW  - Unmanned aerial vehicles
KW  - Propellers
KW  - Shape
KW  - Grasping
KW  - Servomotors
KW  - Force
KW  - End effectors
DO  - 10.1109/ICRA.2018.8460928
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present the achievement of aerial grasping by shape adaptive transformation to the object shape, using a novel transformable aerial robot called HALO: Horizontal Plane Transformable Aerial Robot with Closed-loop Multilinks Structure. Aerial manipulation is an active research area and using multiple aerial robots is an effective solution for the large size object. However the cooperation is considered that there are some difficulties such as the synchronized flight control and collision with each other. Then, we focus on the transformable aerial robot with two-dimensional multilinks proposed in our previous works, which can transform to the suitable form for the target object and grasp it. However the transformable aerial robot with the serial-link structure could not achieve stable flight in terms of horizontal position and yaw control due to the low rigidity and large inertia in the case of more than 4 links. Thus, first we construct a novel type of multilinks with closed-loop structure to avoid the deformation and a new link module with a tilted propeller for fully-actuated control. Second, we describe transformation method with closed-loop multilinks. Third, we present the optimization planning method for the multilinks form to be adaptive to the two-dimensional shape of the target object. Finally, we present experimental results to demonstrate the feasibility of closed-loop aerial transformation and aerial grasping for the large size object.
ER  - 

TY  - CONF
TI  - Towards a Flying Assistant Paradigm: the OTHex
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 6997
EP  - 7002
AU  - N. Staub
AU  - D. Bicego
AU  - Q. Sablé
AU  - V. Arellano
AU  - S. Mishra
AU  - A. Franchi
PY  - 2018
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - estimation theory
KW  - geometry
KW  - manipulators
KW  - mobile robots
KW  - robust control
KW  - trajectory control
KW  - maintenance tasks
KW  - task-driven custom design
KW  - experimental validations
KW  - control framework
KW  - low-level geometric controller
KW  - external wrench estimator
KW  - admittance filter
KW  - trajectory generator
KW  - external force disturbances
KW  - Flying Assistant paradigm
KW  - OTHex platform
KW  - aerial manipulation
KW  - LAAS-CNRS
KW  - multidirectional thrust platform
KW  - human operators
KW  - long bars
KW  - assembly tasks
KW  - ground manipulators
KW  - Propellers
KW  - Bars
KW  - Trajectory
KW  - Robots
KW  - Task analysis
KW  - Admittance
KW  - Force
DO  - 10.1109/ICRA.2018.8460877
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the OTHex platform for aerial manipulation developed at LAAS-CNRS. The OTHex is probably the first multi-directional thrust platform designed to act as Flying Assistant which can aid human operators and/or Ground Manipulators to move long bars for assembly and maintenance tasks. The work emphasis is on task-driven custom design and experimental validations. The proposed control framework is built around a low-level geometric controller, and includes an external wrench estimator, an admittance filter, and a trajectory generator. This tool gives the system the necessary compliance to resist external force disturbances arising from contact with the surrounding environment or to parameter uncertainties in the load. A set of experiments validates the real-world applicability and robustness of the overall system.
ER  - 

TY  - CONF
TI  - Emulating a Fully Actuated Aerial Vehicle Using Two Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7011
EP  - 7016
AU  - J. Paulos
AU  - B. Caraher
AU  - M. Yim
PY  - 2018
KW  - actuators
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - blades
KW  - helicopters
KW  - position control
KW  - rotors
KW  - vehicle dynamics
KW  - flat body attitude
KW  - fully actuated aerial vehicle
KW  - actuators
KW  - microair vehicles
KW  - quadrotors
KW  - downward thrust
KW  - spatial trajectories
KW  - coaxial helicopter
KW  - thrust vector
KW  - translation dynamics
KW  - cyclic flapping response
KW  - Rotors
KW  - Blades
KW  - Aircraft
KW  - Force
KW  - Fasteners
KW  - Actuators
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8462975
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Micro air vehicles exemplified by quadrotors generate downward thrust in their body fixed frame and may only maneuver spatially by changing their orientation. As a result of this underactuation they are fundamentally incapable of simultaneously regulating orientation and position. Furthermore, their feasible maneuvers are limited to spatial trajectories with continuously differentiable acceleration. We present a coaxial helicopter which emulates full actuation over forces and torques (six degrees of freedom) using only two actuators. The orientation of the thrust vector from each rotor is governed by the drive motor by exciting a cyclic flapping response in special articulated blades. The useful separation of orientation and translation dynamics is demonstrated in flight experiments by tracking spatial trajectories while maintaining flat body attitude as well as tracking desired orientations near hover while station keeping.
ER  - 

TY  - CONF
TI  - LASDRA: Large-Size Aerial Skeleton System with Distributed Rotor Actuation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7017
EP  - 7023
AU  - H. Yang
AU  - S. Park
AU  - J. Lee
AU  - J. Ahn
AU  - D. Son
AU  - D. Lee
PY  - 2018
KW  - decentralised control
KW  - hydraulic actuators
KW  - machine control
KW  - rotors
KW  - valves
KW  - robotic system
KW  - LASDRA
KW  - valve turning
KW  - trajectory tracking
KW  - strong/sturdy base actuator/structure
KW  - actuators
KW  - hydraulic actuation
KW  - large-size aerial skeleton system
KW  - large-size dexterously-articulated robot
KW  - internal actuation
KW  - external actuation
KW  - distributed rotors
KW  - distributed rotor actuation
KW  - Rotors
KW  - Robots
KW  - Force
KW  - Loading
KW  - Torque
KW  - Hydraulic systems
KW  - Actuators
DO  - 10.1109/ICRA.2018.8460713
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Electrical motor and hydraulic actuation widely-used in robotics are “internal actuation” with their actuators sitting at the joint between two links. This internal actuation is fundamentally limiting to construct a large-size dexterously-articulated robot, since any external force (and its own link weight) is to be accumulated to the base multiplied by the moment arm length, requiring extremely strong/sturdy base actuator/structure as the system size increases. In this paper, we propose a novel robotic system, LASDRA (large-size aerial skeleton with distributed rotor actuation), which, by utilizing distributed rotors as “external actuation”, can overcome this limitation of internal actuation and enables us to realize large-size dexterously-articulated robots. We present its design and modeling, joint locking strategy to increase its loading capability, and also a novel decentralized control scheme to allow for compliant operation with scalability against the number of links. Trajectory tracking and valve turning experiments are also performed to validate the theory.
ER  - 

TY  - CONF
TI  - A Flying Gripper Based on Cuboid Modular Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7024
EP  - 7030
AU  - B. Gabrich
AU  - D. Saldaña
AU  - V. Kumar
AU  - M. Yim
PY  - 2018
KW  - autonomous aerial vehicles
KW  - grippers
KW  - helicopters
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - degree of freedom
KW  - four-bar linkage
KW  - aperture angle
KW  - cuboid frame
KW  - docking mechanism
KW  - vertical edges
KW  - grasp object
KW  - cuboid modular robots
KW  - flying Gripper
KW  - hovering performance
KW  - DOF
KW  - Grippers
KW  - Apertures
KW  - Robots
KW  - Rotors
KW  - Grasping
KW  - Propellers
KW  - Shape
DO  - 10.1109/ICRA.2018.8460682
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a novel flying modular platform capable of grasping and transporting objects. It is composed of four cooperative identical modules where each is based on a quadrotor within a cuboid frame with a docking mechanism. Pairs of modules are able to fly independently and physically connect by matching their vertical edges forming a hinge. Four one degree of freedom (DOF) connections results in a one DOF four-bar linkage that can be used to grasp external objects. In this paper, we propose a decentralized method that allows the Flying Gripper to control its position, attitude and aperture angle. In our experiments, we tested the hovering performance for different aperture angles and with a grasped object. The performance for a closing and opening motion was also verified.
ER  - 

TY  - CONF
TI  - ACT: An Autonomous Drone Cinematography System for Action Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7039
EP  - 7046
AU  - C. Huang
AU  - F. Gao
AU  - J. Pan
AU  - Z. Yang
AU  - W. Qiu
AU  - P. Chen
AU  - X. Yang
AU  - S. Shen
AU  - K. Cheng
PY  - 2018
KW  - cinematography
KW  - motion estimation
KW  - remotely operated vehicles
KW  - video cameras
KW  - action scenes
KW  - aerial filming
KW  - autonomous cinematography system
KW  - autonomous drone cinematography system
KW  - state-of-the-art drone camera system
KW  - real-time dynamical camera planning strategy
KW  - drone platform
KW  - human action
KW  - external motion capture systems
KW  - drone cinematography systems
KW  - aesthetic objectives
KW  - Cameras
KW  - Drones
KW  - Three-dimensional displays
KW  - Skeleton
KW  - Planning
KW  - Robot vision systems
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460703
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Drones are enabling new forms of cinematography. Aerial filming via drones in action scenes is difficult because it requires users to understand the dynamic scenarios and operate the drone and camera simultaneously. Existing systems allow the user to manually specify the shots and guide the drone to capture footage, while none of them employ aesthetic objectives to automate aerial filming in action scenes. Meanwhile, these drone cinematography systems depend on the external motion capture systems to perceive the human action, which is limited to the indoor environment. In this paper, we propose an Autonomous CinemaTography system “ACT” on the drone platform to address the above the challenges. To our knowledge, this is the first drone camera system which can autonomously capture cinematic shots of action scenes based on limb movements in both indoor and outdoor environments. Our system includes the following novelties. First, we propose an efficient method to extract 3D skeleton points via a stereo camera. Second, we design a real-time dynamical camera planning strategy that fulfills the aesthetic objectives for filming and respects the physical limits of a drone. At the system level, we integrate cameras and GPUs into the limited space of a drone and demonstrate the feasibility of running the entire cinematography system onboard in real-time. Experimental results in both simulation and real-world scenarios demonstrate that our cinematography system “ACT” can capture more expressive video footage of human action than that of a state-of-the-art drone camera system.
ER  - 

TY  - CONF
TI  - Approximate Branch and Bound for Fast, Risk-Bound Stochastic Path Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7047
EP  - 7054
AU  - D. Strawser
AU  - B. Williams
PY  - 2018
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - path planning
KW  - stochastic processes
KW  - tree searching
KW  - risk-bound stochastic path planning
KW  - often intractable problem
KW  - autonomous agents
KW  - complex stochastic processes
KW  - fast path planning
KW  - chance constraint
KW  - stochastic path planning problem
KW  - nonconvex problem
KW  - scales computational effort
KW  - MILP approach
KW  - parallelized sampling-based approach
KW  - Computational modeling
KW  - Stochastic processes
KW  - Trajectory
KW  - Uncertainty
KW  - Planning
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2018.8461070
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Path planning under uncertainty is a difficult and often intractable problem. Autonomous agents must model and reason about complex stochastic processes to quickly derive high quality plans. Most approaches separate the model of uncertainty from the planning; a model is selected and then a controller derived. This work proposes an approach for fast path planning under uncertainty that scales the model of uncertainty such that good policies receive the most effort. To do this, we use an innovative form of the problem's chance constraint to formulate a convex, stochastic path planning problem from the non-convex problem. Next, a bound on the path's expected cost is developed that allows a trade-off between speed of computation and accuracy. The bound is trivially parallelized on a GPU. Finally, a modified branch and bound algorithm is introduced that scales computational effort for more promising solutions. The method is benchmarked against existing approaches including those using Boole's inequality, a MILP approach, and a parallelized sampling-based approach. It outperforms other approaches based on speed and the ability to meet the chance constraint while not being overly conservative.
ER  - 

TY  - CONF
TI  - Rapidly-Exploring Random Vines (RRV) for Motion Planning in Configuration Spaces with Narrow Passages
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7055
EP  - 7062
AU  - A. Tahirovic
AU  - M. Ferizbegovic
PY  - 2018
KW  - collision avoidance
KW  - eigenvalues and eigenfunctions
KW  - mobile robots
KW  - random processes
KW  - sampling methods
KW  - trees (mathematics)
KW  - configuration space
KW  - tree expansion
KW  - eigenvectors
KW  - classical RRT algorithm
KW  - rapidly-exploring random vines algorithm
KW  - motion planning problem
KW  - narrow passage
KW  - Space exploration
KW  - Planning
KW  - Terminology
KW  - Principal component analysis
KW  - Probabilistic logic
KW  - Robots
KW  - Collision avoidance
DO  - 10.1109/ICRA.2018.8460186
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Classical RRT algorithm is blind to efficiently explore configuration space for expanding the tree through a narrow passage when solving a motion planning (MP) problem. Although there have been several attempts to deal with narrow passages which are based on a wide spectrum of assumptions and configuration setups, we solve this problem in rather general way. We use dominant eigenvectors of the configuration sets formed by properly sampling the space around the nearest node, to efficiently expand the tree around the obstacles and through narrow passages. Unlike classical RRT, our algorithm is aware of having the tree nodes in front of a narrow passage and in a narrow passage, which enables a proper tree expansion in a vine-like manner. A thorough comparison with RRT, RRT-connect, and DDRRT algorithm is provided by solving three different difficult MP problems. The results suggest a significant superiority the proposed Rapidly-exploring Random Vines (RRV) algorithm might have in configuration spaces with narrow passages.
ER  - 

TY  - CONF
TI  - Generalizing Informed Sampling for Asymptotically-Optimal Sampling-Based Kinodynamic Planning via Markov Chain Monte Carlo
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7063
EP  - 7070
AU  - D. Yi
AU  - R. Thakker
AU  - C. Gulino
AU  - O. Salzman
AU  - S. Srinivasa
PY  - 2018
KW  - approximation theory
KW  - convergence of numerical methods
KW  - estimation theory
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - Monte Carlo methods
KW  - optimisation
KW  - path planning
KW  - random processes
KW  - sampling methods
KW  - state-space methods
KW  - trees (mathematics)
KW  - asymptotically-optimal motion planners
KW  - subsequent samples
KW  - motion-planning problem
KW  - Euclidean space
KW  - nonEuclidean state spaces
KW  - dimensional state space
KW  - planning algorithm
KW  - sub-level-set
KW  - Monte Carlo sampling methods
KW  - high-quality solutions
KW  - high-dimensional problems
KW  - Markov chain Monte Carlo
KW  - informed set
KW  - generalizing informed sampling
KW  - asymptotically-optimal sampling-based kinodynamic planning
KW  - hierarchical rejection sampling
KW  - Trajectory
KW  - Planning
KW  - Monte Carlo methods
KW  - Markov processes
KW  - Cost function
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2018.8460188
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Asymptotically-optimal motion planners such as RRT* have been shown to incrementally approximate the shortest path between start and goal states. Once an initial solution is found, their performance can be dramatically improved by restricting subsequent samples to regions of the state space that can potentially improve the current solution. When the motion-planning problem lies in a Euclidean space, this region Xinf, called the informed set, can be sampled directly. However, when planning with differential constraints in non-Euclidean state spaces, no analytic solutions exists to sampling Xinf directly. State-of-the-art approaches to sampling Xinf in such domains such as Hierarchical Rejection Sampling (HRS) may still be slow in high -dimensional state space. This may cause the planning algorithm to spend most of its time trying to produces samples in Xinf rather than explore it. In this paper, we suggest an alternative approach to produce samples in the informed set Xinf for a wide range of settings. Our main insight is to recast this problem as one of sampling uniformly within the sub-level-set of an implicit non-convex function. This recasting enables us to apply Monte Carlo sampling methods, used very effectively in the Machine Learning and Optimization communities, to solve our problem. We show for a wide range of scenarios that using our sampler can accelerate the convergence rate to high-quality solutions in high-dimensional problems.
ER  - 

TY  - CONF
TI  - Dancing PRM*: Simultaneous Planning of Sampling and Optimization with Configuration Free Space Approximation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7071
EP  - 7078
AU  - D. Kim
AU  - Y. Kwon
AU  - S. Yoon
PY  - 2018
KW  - approximation theory
KW  - optimisation
KW  - path planning
KW  - grid-based approaches
KW  - optimization-based planner
KW  - resolution-complete factors
KW  - spatial information
KW  - empirical information
KW  - learned information
KW  - optimization-based local planner
KW  - asymptotic optimal planners
KW  - simultaneous planning
KW  - configuration free space approximation
KW  - optimal motion planning
KW  - sampling-based planner
KW  - Dancing PRM
KW  - Planning
KW  - Approximation algorithms
KW  - Trajectory
KW  - Optimization
KW  - Robots
KW  - Probabilistic logic
KW  - Linear programming
DO  - 10.1109/ICRA.2018.8463181
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A recent trend in optimal motion planning has broadened the research area toward the hybridization of sampling, optimization and grid-based approaches. We can expect that synergy from such integrations leads to overall performance improvement, but seamless integration and generalization is still an open problem. In this paper, we suggest a hybrid motion planning algorithm utilizing a sampling-based and optimization-based planner while simultaneously approximating a configuration free space. Unlike conventional optimization-based approaches, the proposed algorithm does not depend on a priori information or resolution-complete factors, e.g., a distance field. Ours instead learns spatial information on the fly by exploiting empirical information during the execution, and decentralizes the information over the constructed graph for efficient access. With the help of the learned information, our optimization-based local planner exploits the local area to identify the connectivity of configuration free space without depending on the precomputed domain knowledge. To show the novelty of proposed algorithm, we evaluate it against other asymptotic optimal planners in both synthetic and complex benchmarks with varying degrees of freedom. We also discuss the performance improvement, properties and limitations we have observed.
ER  - 

TY  - CONF
TI  - Randomized Kinodynamic Planning for Constrained Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7079
EP  - 7086
AU  - R. Bordalba
AU  - L. Ros
AU  - J. M. Porta
PY  - 2018
KW  - collision avoidance
KW  - large-scale systems
KW  - manipulators
KW  - mobile robots
KW  - random processes
KW  - robot dynamics
KW  - robot kinematics
KW  - state-space methods
KW  - trajectory control
KW  - trees (mathematics)
KW  - kinodynamic RRT planner
KW  - atlas
KW  - state-space manifold
KW  - randomized kinodynamic planner
KW  - holonomic constraints
KW  - constrained systems
KW  - high-dimensional dynamical systems
KW  - parallel manipulators
KW  - complex systems
KW  - trajectories
KW  - robots
KW  - Mathematical model
KW  - Robot kinematics
KW  - Planning
KW  - Trajectory
KW  - Manifolds
KW  - Standards
DO  - 10.1109/ICRA.2018.8460753
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Kinodynamic RRT planners are considered to be general tools for effectively finding feasible trajectories for high-dimensional dynamical systems. However, they struggle when holonomic constraints are present in the system, such as those arising in parallel manipulators, in robots that cooperate to fulfill a given task, or in situations involving contacts with the environment. In such cases, the state space becomes an implicitly-defined manifold, which makes the diffusion heuristic inefficient and leads to inaccurate dynamical simulations. To address these issues, this paper presents an extension of the kinodynamic RRT planner that constructs an atlas of the state-space manifold incrementally, and uses this atlas both to generate random states and to dynamically steer the system towards such states. To the best of our knowledge, this is the first randomized kinodynamic planner that explicitly takes holonomic constraints into account. We validate the approach in significantly-complex systems.
ER  - 

TY  - CONF
TI  - Learning Sampling Distributions for Robot Motion Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7087
EP  - 7094
AU  - B. Ichter
AU  - J. Harrison
AU  - M. Pavone
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - sampling methods
KW  - robot motion planning
KW  - sampling-based motion planning
KW  - collision-avoidance
KW  - variational autoencoder
KW  - bias sampling
KW  - Planning
KW  - Robots
KW  - Probabilistic logic
KW  - Manifolds
KW  - Collision avoidance
KW  - Feature extraction
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8460730
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A defining feature of sampling-based motion planning is the reliance on an implicit representation of the state space, which is enabled by a set of probing samples. Traditionally, these samples are drawn either probabilistically or deterministically to uniformly cover the state space. Yet, the motion of many robotic systems is often restricted to “small” regions of the state space, due to e.g. differential constraints or collision-avoidance constraints. To accelerate the planning process, it is thus desirable to devise non-uniform sampling strategies that favor sampling in those regions where an optimal solution might lie. This paper proposes a methodology for nonuniform sampling, whereby a sampling distribution is learned from demonstrations, and then used to bias sampling. The sampling distribution is computed through a conditional variational autoencoder, allowing sample generation from the latent space conditioned on the specific planning problem. This methodology is general, can be used in combination with any sampling-based planner, and can effectively exploit the underlying structure of a planning problem while maintaining the theoretical guarantees of sampling-based approaches. Specifically, on several planning problems, the proposed methodology is shown to effectively learn representations for the relevant regions of the state space, resulting in an order of magnitude improvement in terms of success rate and convergence to the optimal cost.
ER  - 

TY  - CONF
TI  - Deep Object-Centric Representations for Generalizable Robot Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7111
EP  - 7118
AU  - C. Devin
AU  - P. Abbeel
AU  - T. Darrell
AU  - S. Levine
PY  - 2018
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - visual perception
KW  - robotic manipulation
KW  - generalizable robot learning
KW  - object-centric representations
KW  - reinforcement learning
KW  - object-level attentional mechanism
KW  - perception system
KW  - semantic feature space
KW  - Task analysis
KW  - Visualization
KW  - Semantics
KW  - Trajectory
KW  - Computer vision
KW  - Standards
DO  - 10.1109/ICRA.2018.8461196
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotic manipulation in complex open-world scenarios requires both reliable physical manipulation skills and effective and generalizable perception. In this paper, we propose using an object-centric prior and a semantic feature space for the perception system of a learned policy. We devise an object-level attentional mechanism that can be used to determine relevant objects from a few trajectories or demonstrations, and then immediately incorporate those objects into a learned policy. A task-independent attention locates possible objects in the scene, and a task-specific attention identifies which objects are predictive of the trajectories. The scope of the task-specific attention is easily adjusted by showing demonstrations with distractor objects or with diverse relevant objects. Our results indicate that this approach exhibits good generalization across object instances using very few samples, and can be used to learn a variety of manipulation tasks using reinforcement learning.
ER  - 

TY  - CONF
TI  - Real-time 3D Glint Detection in Remote Eye Tracking Based on Bayesian Inference
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7119
EP  - 7126
AU  - D. Geisler
AU  - D. Fox
AU  - E. Kasneci
PY  - 2018
KW  - Bayes methods
KW  - gaze tracking
KW  - human-robot interaction
KW  - object detection
KW  - stereo image processing
KW  - remote eye tracking
KW  - Bayesian inference
KW  - human gaze
KW  - cognitive states
KW  - gaze-based interaction
KW  - human-robot collaboration
KW  - gaze estimation
KW  - 3D glint detection
KW  - Cameras
KW  - Gaze tracking
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Probabilistic logic
KW  - Solid modeling
KW  - Calibration
DO  - 10.1109/ICRA.2018.8460800
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - As human gaze provides information on our cognitive states, actions, and intentions, gaze-based interaction has the potential to enable a fluent and natural human-robot collaboration. In this work, we focus on reliable gaze estimation in remote eye tracking based on calibration-free methods. Although these methods work well in controlled settings, they fail when illumination conditions change or other objects induce noise. We propose a novel, adaptive method based on a probabilistic model, which reliably detects glints from stereo images and evaluate our method using a data set that contains different challenges with regarding to light and reflections.
ER  - 

TY  - CONF
TI  - Generative One-Shot Learning (GOL): A Semi-Parametric Approach to One-Shot Learning in Autonomous Vision
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7127
EP  - 7134
AU  - S. M. Grigorescu
PY  - 2018
KW  - computer vision
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object recognition
KW  - Pareto optimisation
KW  - GOL
KW  - input single one-shot objects
KW  - environment perception
KW  - autonomous vision
KW  - semiparametric approach
KW  - deep neural networks
KW  - visual perception
KW  - driving environment
KW  - training perceptions systems
KW  - generative framework
KW  - highly autonomous driving systems
KW  - generative one-shot learning
KW  - HAD systems
KW  - Pareto optimal solutions
KW  - object detection algorithms
KW  - Pareto optimization
KW  - Training
KW  - Autonomous vehicles
KW  - Generators
KW  - Linear programming
KW  - Probability density function
DO  - 10.1109/ICRA.2018.8461174
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Highly Autonomous Driving (HAD) systems rely on deep neural networks for the visual perception of the driving environment. Such networks are train on large manually annotated databases. In this work, a semi-parametric approach to one-shot learning is proposed, with the aim of bypassing the manual annotation step required for training perceptions systems used in autonomous driving. The proposed generative framework, coined Generative One-Shot Learning (GOL), takes as input single one-shot objects, or generic patterns, and a small set of so-called regularization samples used to drive the generative process. New synthetic data is generated as Pareto optimal solutions from one-shot objects using a set of generalization functions built into a generalization generator. GOL has been evaluated on environment perception challenges encountered in autonomous vision.
ER  - 

TY  - CONF
TI  - Adaptive Deep Learning Through Visual Domain Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7135
EP  - 7142
AU  - G. Angeletti
AU  - B. Caputo
AU  - T. Tommasi
PY  - 2018
KW  - generalisation (artificial intelligence)
KW  - humanoid robots
KW  - human-robot interaction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - robot vision
KW  - domain shift
KW  - end-to-end deep domain adaptation architecture
KW  - target domain
KW  - training time
KW  - human-robot interactions
KW  - adaptive deep
KW  - visual domain localization
KW  - commercial robot
KW  - illumination conditions
KW  - domain adaptation methods
KW  - robotics applications
KW  - computer vision
KW  - generalization issue
KW  - iCub World database
KW  - Visualization
KW  - Training
KW  - Adaptive systems
KW  - Adaptation models
KW  - Machine learning
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460650
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A commercial robot, trained by its manufacturer to recognize a predefined number and type of objects, might be used in many settings, that will in general differ in their illumination conditions, background, type and degree of clutter, and so on. Recent computer vision works tackle this generalization issue through domain adaptation methods, assuming as source the visual domain where the system is trained and as target the domain of deployment. All approaches assume to have access to images from all classes of the target during training, an unrealistic condition in robotics applications. We address this issue proposing an algorithm that takes into account the specific needs of robot vision. Our intuition is that the nature of the domain shift experienced mostly in robotics is local. We exploit this through the learning of maps that spatially ground the domain and quantify the degree of shift, embedded into an end-to-end deep domain adaptation architecture. By explicitly localizing the roots of the domain shift we significantly reduce the number of parameters of the architecture to tune, we gain the flexibility necessary to deal with subset of categories in the target domain at training time, and we provide a clear feedback on the rationale behind any classification decision, which can be exploited in human-robot interactions. Experiments on two different settings of the iCub World database confirm the suitability of our method for robot vision.
ER  - 

TY  - CONF
TI  - Towards Understanding Object-Directed Actions: A Generative Model for Grounding Syntactic Categories of Speech Through Visual Perception
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7143
EP  - 7150
AU  - A. Aly
AU  - T. Taniguchi
PY  - 2018
KW  - Bayes methods
KW  - cognition
KW  - hidden Markov models
KW  - human-robot interaction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - object detection
KW  - robot vision
KW  - object-directed actions
KW  - human arm joints
KW  - manipulating objects
KW  - segmented objects
KW  - successful human-robot collaboration
KW  - high-level cognitive functions
KW  - human language
KW  - human actions
KW  - Hidden Markov models
KW  - Grounding
KW  - Tagging
KW  - Three-dimensional displays
KW  - Robots
KW  - Computational modeling
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2018.8461231
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Creating successful human-robot collaboration requires robots to have high-level cognitive functions that could allow them to understand human language and actions in space. To meet this target, an elusive challenge that we address in this paper is to understand object-directed actions through grounding language based on visual cues representing the dynamics of human actions on objects, object characteristics (color and geometry), and spatial relationships between objects in a tabletop scene. The proposed probabilistic framework investigates unsupervised Part-of-Speech (POS) tagging to determine syntactic categories of words so as to infer grammatical structure of language. The dynamics of object-directed actions are characterized through the locations of the human arm joints - modeled on a Hidden Markov Model (HMM) - while manipulating objects, in addition to those of objects represented in 3D point clouds. These corresponding point clouds to segmented objects encode geometric features and spatial semantics of referents and landmarks in the environment. The proposed Bayesian learning model is successfully evaluated through interaction experiments between a human user and Toyota HSR robot in space.
ER  - 

TY  - CONF
TI  - GeneSIS-Rt: Generating Synthetic Images for Training Secondary Real-World Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7151
EP  - 7158
AU  - G. J. Stein
AU  - N. Roy
PY  - 2018
KW  - collision avoidance
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - synthetic images
KW  - synthetic data
KW  - domain-specific learning tasks
KW  - leverage recent progress
KW  - image-to-image translation
KW  - simulated images
KW  - realistic training data
KW  - real-world images
KW  - GeneSIS-Rtameliorates
KW  - GeneSIS-Rtto
KW  - high-accuracy predictions
KW  - raw simulated data
KW  - GeneSIS-RT images
KW  - mission-critical tasks
KW  - secondary real-world task training
KW  - cluttered environment
KW  - reactive obstacle avoidance
KW  - semantic segmentation
KW  - Training
KW  - Task analysis
KW  - Semantics
KW  - Image segmentation
KW  - Collision avoidance
KW  - Gallium nitride
KW  - Training data
DO  - 10.1109/ICRA.2018.8462971
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a novel approach for generating high-quality, synthetic data for domain-specific learning tasks, for which training data may not be readily available. We leverage recent progress in image-to-image translation to bridge the gap between simulated and real images, allowing us to generate realistic training data for real-world tasks using only unlabeled real-world images and a simulation. GeneSIS-Rtameliorates the burden of having to collect labeled real-world images and is a promising candidate for generating high-quality, domain-specific, synthetic data. To show the effectiveness of using GeneSIS-Rtto create training data, we study two tasks: semantic segmentation and reactive obstacle avoidance. We demonstrate that learning algorithms trained using data generated by GeneSIS-RT make high-accuracy predictions and outperform systems trained on raw simulated data alone, and as well or better than those trained on real data. Finally, we use our data to train a quadcopter to fly 60 meters at speeds up to 3.4 m/s through a cluttered environment, demonstrating that our GeneSIS-RT images can be used to learn to perform mission-critical tasks.
ER  - 

TY  - CONF
TI  - Enhancing Underwater Imagery Using Generative Adversarial Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7159
EP  - 7165
AU  - C. Fabbri
AU  - M. J. Islam
AU  - J. Sattar
PY  - 2018
KW  - autonomous underwater vehicles
KW  - decision making
KW  - image colour analysis
KW  - image denoising
KW  - image fusion
KW  - image restoration
KW  - neural nets
KW  - robot vision
KW  - Generative Adversarial Networks
KW  - autonomous underwater vehicles
KW  - AUVs
KW  - intelligent decision making
KW  - color distortion
KW  - noisy images
KW  - distorted images
KW  - underwater image restoration
KW  - underwater imagery
KW  - visual data quality
KW  - visual underwater scene quality
KW  - Nonlinear distortion
KW  - Gallium nitride
KW  - Generators
KW  - Image color analysis
KW  - Visualization
KW  - Sensors
DO  - 10.1109/ICRA.2018.8460552
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous underwater vehicles (AUVs) rely on a variety of sensors - acoustic, inertial and visual - for intelligent decision making. Due to its non-intrusive, passive nature and high information content, vision is an attractive sensing modality, particularly at shallower depths. However, factors such as light refraction and absorption, suspended particles in the water, and color distortion affect the quality of visual data, resulting in noisy and distorted images. AUVs that rely on visual sensing thus face difficult challenges and consequently exhibit poor performance on vision-driven tasks. This paper proposes a method to improve the quality of visual underwater scenes using Generative Adversarial Networks (GANs), with the goal of improving input to vision-driven behaviors further down the autonomy pipeline. Furthermore, we show how recently proposed methods are able to generate a dataset for the purpose of such underwater image restoration. For any visually-guided underwater robots, this improvement can result in increased safety and reliability through robust visual perception. To that effect, we present quantitative and qualitative data which demonstrates that images corrected through the proposed approach generate more visually appealing images, and also provide increased accuracy for a diver tracking algorithm.
ER  - 

TY  - CONF
TI  - Faster R-CNN with Classifier Fusion for Small Fruit Detection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7166
EP  - 7172
AU  - X. Mai
AU  - H. Zhang
AU  - M. Q. -. Meng
PY  - 2018
KW  - convolution
KW  - crops
KW  - feedforward neural nets
KW  - image classification
KW  - image fusion
KW  - object detection
KW  - probability
KW  - recurrent neural nets
KW  - robot vision
KW  - multiple classifiers
KW  - classifier correlation
KW  - small fruit detection
KW  - Faster R-CNN network
KW  - multiple classifier fusion
KW  - objectness classification
KW  - probabilities
KW  - agricultural robots
KW  - Proposals
KW  - Correlation
KW  - Feature extraction
KW  - Image segmentation
KW  - Machine learning
KW  - Robots
KW  - Adaptation models
DO  - 10.1109/ICRA.2018.8461130
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The-state-of-the-art of fruit detection with Faster R-CNN shows lack of detection advantage on small fruits. One of reasons is only single level features is used for localization of proposal candidates. In this paper, we propose to incorporate a multiple classifier fusion strategy into a Faster R-CNN network for small fruit detection. We utilize features from three different levels to learn three classifiers for objectness classification in the stage of proposal localization. Probabilities from classifiers are combined by a simple convolutional layer to generate final objectness classification for proposal candidates. In order to keep diversity of multiple classifiers, a novel loss term of classifier correlation is introduced into original loss function. Experimental results show that our model is feasible for detecting small fruits.
ER  - 

TY  - CONF
TI  - Robot Button Pressing in Human Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7173
EP  - 7180
AU  - F. Wang
AU  - G. Chen
AU  - K. Hauser
PY  - 2018
KW  - calibration
KW  - mobile robots
KW  - service robots
KW  - robot button pressing
KW  - human environments
KW  - service robots
KW  - mobile robot
KW  - SwitchIt
KW  - hand-held tablet
KW  - buttons categorization
KW  - Force
KW  - Robot sensing systems
KW  - Switches
KW  - Reliability
KW  - Pressing
KW  - Service robots
DO  - 10.1109/ICRA.2018.8463180
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In order to conduct many desirable functions, service robots will need to actuate buttons and switches that are designed for humans. This paper presents the design of a robot named SwitchIt that is small, relatively inexpensive, easily mounted on a mobile robot, and actuates buttons reliably. Its operating characteristics were developed after conducting a systematic study of buttons and switches in human environments. From this study, we develop a categorization of buttons based on a set of physical properties relevant for robots to operate them. After a human calibrates and annotates buttons in the robot's environment using a hand-held tablet, the system automatically recognizes, pushes, and detects the state of a variety of buttons. Empirical tests demonstrate that the system succeeds in operating 95.7% of 234 total buttons/switches in an office building and a household environment.
ER  - 

TY  - CONF
TI  - Enhancing Overall Object Placement by Understanding Uncertain Spatial and Qualitative Distance Information in User Commands
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7181
EP  - 7188
AU  - M. M. S. N. Edirisinghe
AU  - M. A. V. J. Muthugala
AU  - H. P. C. Sirithunge
AU  - A. G. Buddhika
AU  - P. Jayasekara
PY  - 2018
KW  - human-robot interaction
KW  - speech-based user interfaces
KW  - uncertain spatial terms
KW  - uncertain qualitative terms
KW  - placement location
KW  - object placement
KW  - qualitative distance information
KW  - voice commands
KW  - peer companions
KW  - daily assistive tasks
KW  - assistive robot companions
KW  - voice instructions
KW  - Task analysis
KW  - Navigation
KW  - Visualization
KW  - Robot kinematics
KW  - Service robots
KW  - Manipulators
KW  - human-robot interactions
KW  - human friendly robotics
KW  - service robotics
KW  - object manipulation
KW  - spatial infor-mation
DO  - 10.1109/ICRA.2018.8460624
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Humans prefer to use voice commands to guide their peer companions in daily assistive tasks. In human perspective, they expect same behavior from assistive robot companions as well. The paper presents an approach towards using such voice instructions based on uncertain and qualitative information to describe object placements. Consider a case in which a set of objects has to be arranged on a table in a particular spatial area. In such a situation, humans will prefer to use a single command regarding overall arrangement rather than repeating the same command for each and every object placement. In such scenarios, people will be comfortable with commands which are simple and with non-technical words. Most of such commands include uncertain spatial terms such as “Left”, “Middle”, “Right” and uncertain qualitative terms such as “Together”, “Little separately”, “Separately” to describe the arrangement. For example “Keep all objects together in the middle of the table” and “Keep objects separately on the right side of the table” can be considered. But in some situations, these commands will not give a direct idea about the placement location of the objects. For instance, “Keep the middle of the table free” can be cited. Therefore, the robot must be able to understand precisely such information in commands before executing them. The experiments are conducted in a simulated domestic environment. Results of the experiment are presented and discussed.
ER  - 

TY  - CONF
TI  - Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7189
EP  - 7195
AU  - B. Lee
AU  - J. Choi
AU  - C. Baek
AU  - B. Zhang
PY  - 2018
KW  - Bayes methods
KW  - collision avoidance
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - predictive control
KW  - robot vision
KW  - robust control
KW  - service robots
KW  - trajectory control
KW  - variational techniques
KW  - RoboCup@Home 2017 Social Standard Platform League
KW  - robust functions
KW  - home service robots
KW  - service-oriented robots
KW  - human assistance
KW  - commercial service robot
KW  - RGB-D camera
KW  - deep learning methods
KW  - variational Bayesian techniques
KW  - deep learning modules
KW  - dynamic home environment
KW  - deep Bayesian trajectory prediction method
KW  - collision avoidance
KW  - robust human following
KW  - smooth person following capability
KW  - human cooperation
KW  - robustness
KW  - target detection
KW  - robot following ability
KW  - Robot kinematics
KW  - Trajectory
KW  - Collision avoidance
KW  - Robustness
KW  - Robot sensing systems
KW  - Bayes methods
DO  - 10.1109/ICRA.2018.8462969
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.
ER  - 

TY  - CONF
TI  - Ruling the Control Authority of a Service Robot Based on Information Precision
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7204
EP  - 7210
AU  - V. Magnago
AU  - M. Andreetto
AU  - S. Divan
AU  - D. Fontanelli
AU  - L. Palopoli
PY  - 2018
KW  - geriatrics
KW  - handicapped aids
KW  - mobile robots
KW  - path planning
KW  - position control
KW  - service robots
KW  - SLAM (robots)
KW  - active sensing system
KW  - control law
KW  - senior user guidance
KW  - path following problem
KW  - landmarks
KW  - actuator control
KW  - accurate localisation
KW  - exact localisation
KW  - robotic walking assistant
KW  - information precision
KW  - service robot
KW  - control authority
KW  - design strategy
KW  - massive data collection
KW  - SLAM approaches
KW  - Robot sensing systems
KW  - Estimation error
KW  - Uncertainty
KW  - Probabilistic logic
KW  - Service robots
KW  - Automobiles
DO  - 10.1109/ICRA.2018.8460714
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the problem of guiding a senior user along a path using a robotic walking assistant. This is a particular type of path following problem, for which most of the solutions available in the literature require an exact localisation of the robot in the environment. An accurate localisation is obtained either with a heavy infrastructure (e.g., an active sensing system deployed in the environment or deploying landmarks in known positions) or using SLAM approaches with a massive data collection. Our key observation is that the intervention of the system (and a good level of accuracy) is only required in proximity of difficult decision points, while we can rely on the user in an environment where the only possibility is just to maintain a course (e.g., a corridor). The direct implication is that we can instrument the environment with a heavy infrastructure only in certain areas. This design strategy has to be complemented by an adequate control law that shifts the authority (i.e., the control of the actuators) between the robot and the user according to the accuracy of the information available to the robot. Such a control law is exactly the contribution of this paper.
ER  - 

TY  - CONF
TI  - A Nonparametric Motion Flow Model for Human Robot Cooperation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7211
EP  - 7218
AU  - S. Choi
AU  - K. Lee
AU  - H. A. Park
AU  - S. Oh
PY  - 2018
KW  - Gaussian processes
KW  - human-robot interaction
KW  - image motion analysis
KW  - image representation
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - nonparametric motion flow model
KW  - human robot cooperation method
KW  - partial trajectory information
KW  - target trajectories
KW  - learned motion description
KW  - underlying reward function
KW  - interacting trajectories
KW  - variance functions
KW  - temporal properties
KW  - spatial properties
KW  - motion flow similarity measure
KW  - motion trajectory
KW  - Trajectory
KW  - Motion measurement
KW  - Kernel
KW  - Computational modeling
KW  - Robot sensing systems
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8463201
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a novel nonparametric motion flow model that effectively describes a motion trajectory of a human and its application to human robot cooperation. To this end, motion flow similarity measure which considers both spatial and temporal properties of a trajectory is proposed by utilizing the mean and variance functions of a Gaussian process. We also present a human robot cooperation method using the proposed motion flow model. Given a set of interacting trajectories of two workers, the underlying reward function of cooperating behaviors is optimized by using the learned motion description as an input to the reward function where a stochastic trajectory optimization method is used to control a robot. The presented human robot cooperation method is compared with the state-of-the-art algorithm, which utilizes a mixture of interaction primitives (MIP), in terms of the RMS error between generated and target trajectories. While the proposed method shows comparable performance with the MIP when the full observation of human demonstrations is given, it shows superior performance when partial trajectory information is given.
ER  - 

TY  - CONF
TI  - Learning by Demonstration and Adaptation of Finishing Operations Using Virtual Mechanism Approach
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7219
EP  - 7225
AU  - B. Nemec
AU  - K. Yasuda
AU  - N. Mullennix
AU  - N. Likar
AU  - A. Ude
PY  - 2018
KW  - force sensors
KW  - grinding
KW  - grinding machines
KW  - industrial robots
KW  - iterative learning control
KW  - polishing
KW  - polishing machines
KW  - robot dynamics
KW  - robot kinematics
KW  - surface finishing
KW  - finishing operations
KW  - virtual mechanism approach
KW  - passive digitizer
KW  - optimal robot execution
KW  - serial kinematic chain
KW  - augmented system
KW  - polishing tools
KW  - grinding tool
KW  - iterative learning controller
KW  - Robot kinematics
KW  - Task analysis
KW  - Tools
KW  - Service robots
KW  - Trajectory
KW  - Quaternions
DO  - 10.1109/ICRA.2018.8460603
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a new approach for efficient programming of grinding and polishing operation. In the proposed system, the initial policy is performed by a skilled operator and recorded with a passive digitizer. The demonstrated policy comprises both position and force data. The optimal robot execution of the task is provided by applying a virtual mechanism approach, which models the polishing/grinding tool as a serial kinematic chain. By joining the robot and the virtual mechanism in an augmented system, additional degrees of freedom are obtained and redundancy resolution can be applied to optimize the demonstrated motion. Another benefit of the proposed approach is that the same policy can be transferred to different combination of robots and grinding/polishing tools without any modification of the captured motion. The proposed approach requires known contact point between the treated object and the polishing/grinding tool. We propose a novel approach for accurate estimation of this point using data obtained from the force-torque sensor. Finally, the demonstrated path is refined to compensate for inaccurate calibration and different dynamics of a robot and the human demonstrator using iterative learning controller. The proposed method was verified in a real industrial environment.
ER  - 

TY  - CONF
TI  - Hybrid Probabilistic Trajectory Optimization Using Null-Space Exploration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7226
EP  - 7232
AU  - Y. Huang
AU  - J. Silvério
AU  - L. Rozo
AU  - D. G. Caldwell
PY  - 2018
KW  - humanoid robots
KW  - learning systems
KW  - manipulator kinematics
KW  - probability
KW  - trajectory control
KW  - joint space
KW  - motion constraints
KW  - probabilistic formulation
KW  - dynamic movement primitives
KW  - probabilistic treatment
KW  - trajectory constraints
KW  - hybrid space learning
KW  - motion smoothness
KW  - robot null-space
KW  - hybrid probabilistic trajectory optimization
KW  - null-space exploration
KW  - Cartesian space
KW  - learning from demonstration
KW  - Jacobian-based inverse kinematics
KW  - Probabilistic logic
KW  - Task analysis
KW  - Robot kinematics
KW  - Acceleration
KW  - Trajectory optimization
DO  - 10.1109/ICRA.2018.8460550
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the context of learning from demonstration, human examples are usually imitated in either Cartesian or joint space. However, this treatment might result in undesired movement trajectories in either space. This is particularly important for motion skills such as striking, which typically imposes motion constraints in both spaces. In order to address this issue, we consider a probabilistic formulation of dynamic movement primitives, and apply it to adapt trajectories in Cartesian and joint spaces simultaneously. The probabilistic treatment allows the robot to capture the variability of multiple demonstrations and facilitates the mixture of trajectory constraints from both spaces. In addition to this proposed hybrid space learning, the robot often needs to consider additional constraints such as motion smoothness and joint limits. On the basis of Jacobian-based inverse kinematics, we propose to exploit robot null-space so as to unify trajectory constraints from Cartesian and joint spaces while satisfying additional constraints. Evaluations of hand-shaking and striking tasks carried out with a humanoid robot demonstrate the applicability of our approach.
ER  - 

TY  - CONF
TI  - Feature-constrained Active Visual SLAM for Mobile Robot Navigation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7233
EP  - 7238
AU  - X. Deng
AU  - Z. Zhang
AU  - A. Sintov
AU  - J. Huang
AU  - T. Bretl
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - sensory constraints
KW  - iterative motion planning framework
KW  - collision avoidance
KW  - online mapping
KW  - associated map points
KW  - distance-optimal path planner
KW  - data-driven approach
KW  - continuous identification
KW  - feature-based Visual Simultaneous Localization
KW  - vision-based navigation
KW  - failure avoidance
KW  - mobile robot navigation
KW  - feature-constrained active Visual SLAM
KW  - Cameras
KW  - Navigation
KW  - Collision avoidance
KW  - Simultaneous localization and mapping
KW  - Planning
DO  - 10.1109/ICRA.2018.8460721
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper focuses on tracking failure avoidance during vision-based navigation to a desired goal in unknown environments. While using feature-based Visual Simultaneous Localization and Mapping (VSLAM), continuous identification and association of map points are required during motion. Thus, we discuss a motion planning framework that takes into account sensory constraints for a reliable navigation. We use information available in the SLAM and propose a data-driven approach to predict the number of map points associated in a given pose. Then, a distance-optimal path planner utilizes the model to constrain paths such that the number of associated map points in each pose is above a threshold. We also include an online mapping of the environment for collision avoidance. Overall, we propose an iterative motion planning framework that enables real-time replanning after the acquisition of more information. Experiments in two environments demonstrate the performance of the proposed framework.
ER  - 

TY  - CONF
TI  - Level-Headed: Evaluating Gimbal-Stabilised Visual Teach and Repeat for Improved Localisation Performance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7239
EP  - 7246
AU  - M. Warren
AU  - A. P. Schoellig
AU  - T. D. Barfoot
PY  - 2018
KW  - feature extraction
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - rough terrain
KW  - unstructured terrain
KW  - border patrol
KW  - agricultural work
KW  - sensor-based navigation
KW  - erratic motion
KW  - feature-poor environments test feature tracking
KW  - repeat matching
KW  - salient point features
KW  - Grizzly Robotic Utility Vehicle
KW  - actively gimbaled camera
KW  - image motion
KW  - search-and-rescue
KW  - field-deployable ground robot
KW  - vision-based route-following
KW  - feature extraction
KW  - Transforms
KW  - Cameras
KW  - Visualization
KW  - Robot sensing systems
KW  - Robustness
KW  - Navigation
DO  - 10.1109/ICRA.2018.8460961
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Operating in rough, unstructured terrain is an essential requirement for any truly field-deployable ground robot. Search-and-rescue, border patrol and agricultural work all require operation in environments with little established infrastructure for easy navigation. This presents challenges for sensor-based navigation such as vision, where erratic motion and feature-poor environments test feature tracking and hinder the performance of repeat matching of point features. For vision-based route-following methods such as Visual Teach and Repeat (VT&R), maintaining similar visual perspective of salient point features is critical for reliable odometry and accurate localisation over long periods. In this paper, we investigate a potential solution to these challenges by integrating a gimbaled camera with VT&R on a Grizzly Robotic Utility Vehicle (RUV) for testing at high speeds and in visually challenging environments. We examine the benefits and drawbacks of using an actively gimbaled camera to attenuate image motion and control viewpoint. We compare the use of a gimbaled camera to our traditional fixed stereo configuration and demonstrate cases of improved performance in Visual Odometry (VO), localisation and path following in several sets of outdoor experiments.
ER  - 

TY  - CONF
TI  - Low-Drift Visual Odometry in Structured Environments by Decoupling Rotational and Translational Motion
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7247
EP  - 7253
AU  - P. Kim
AU  - B. Coltin
AU  - H. J. Kim
PY  - 2018
KW  - distance measurement
KW  - mobile robots
KW  - motion control
KW  - motion estimation
KW  - position control
KW  - robot vision
KW  - motion estimation process
KW  - positioning inaccuracy
KW  - structured environments
KW  - rotational motion
KW  - drift-free rotation
KW  - SO(3)-manifold constrained mean shift algorithm
KW  - multiple orthogonal planes
KW  - rotation estimate
KW  - structural regularities
KW  - drift-free rotational motion
KW  - low-drift visual odometry algorithm
KW  - translational motion
KW  - Cameras
KW  - Tracking
KW  - Three-dimensional displays
KW  - Estimation
KW  - Visual odometry
KW  - Feature extraction
KW  - Image segmentation
DO  - 10.1109/ICRA.2018.8463207
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a low-drift visual odometry algorithm that separately estimates rotational and translational motion from lines, planes, and points found in RGB-D images. Previous methods estimate drift-free rotational motion from structural regularities to reduce drift in the rotation estimate, which is the primary source of positioning inaccuracy in visual odometry. However, multiple orthogonal planes are required to be visible throughout the entire motion estimation process; otherwise, these VO approaches fail. We propose a new approach to estimate drift-free rotational motion jointly from both lines and planes by exploiting environmental regularities. We track the spatial regularities with an efficient SO(3)-manifold constrained mean shift algorithm. Once the drift-free rotation is found, we recover the translational motion from all tracked points with and without depth by minimizing the de-rotated reprojection error. We compare the proposed algorithm to other state-of-the-art visual odometry methods on a variety of RGB-D datasets (including especially challenging pure rotations) and demonstrate improved accuracy and lower drift error.
ER  - 

TY  - CONF
TI  - Visual Homing via Guided Locality Preserving Matching
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7254
EP  - 7261
AU  - J. Ma
AU  - J. Zhao
AU  - J. Jiang
AU  - H. Zhou
AU  - Y. Zhou
AU  - Z. Wang
AU  - X. Guo
PY  - 2018
KW  - computational complexity
KW  - feature extraction
KW  - image matching
KW  - motion estimation
KW  - guided locality preserving matching
KW  - GLPM
KW  - panoramic images
KW  - linear space complexities
KW  - visual homing problem
KW  - sparse feature matches
KW  - homing directions
KW  - feature matching
KW  - mismatch removal
KW  - dense motion flow estimation
KW  - Tikhonov regularization
KW  - Visualization
KW  - Feature extraction
KW  - Electronic mail
KW  - Cost function
KW  - Measurement
KW  - Closed-form solutions
KW  - Intelligent robots
DO  - 10.1109/ICRA.2018.8460935
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This study proposes a simple yet surprisingly effective feature matching approach, termed as guided locality preserving matching (GLPM), for visual homing of panoramic images. The key idea of our approach is merely to preserve the neighborhood structures of potential true matches between two panoramic images. We formulate it into a mathematical model, and derive a simple closed-form solution with linearithmic time and linear space complexities. This enables our method to accomplish the mismatch removal from hundreds of putative correspondences in only a few milliseconds. To handle extremely large proportions of outliers, we further design a guided matching strategy based on the proposed method, using the matching result on a small putative set with a high inlier ratio to guide the matching on a large putative set. This strategy can also significantly boost true matches without sacrifice in accuracy. To apply our GLPM to the visual homing problem, we develop a method for dense motion flow estimation from sparse feature matches based on Tikhonov regularization. Moreover, the focus-of-contraction/focus-of-expansion is derived to determine homing directions. The effectiveness of our method is demonstrated on a panoramic database in both feature matching and visual homing.
ER  - 

TY  - CONF
TI  - LOGOS: Local Geometric Support for High-Outlier Spatial Verification
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7262
EP  - 7269
AU  - S. Lowry
AU  - H. Andreasson
PY  - 2018
KW  - feature extraction
KW  - pose estimation
KW  - outlier removal
KW  - LOGOS
KW  - local geometric support
KW  - high-outlier spatial verification
KW  - visual localization
KW  - orientation information
KW  - inlier points
KW  - secondary localization verification
KW  - benchmark localization datasets
KW  - local neighbourhoods
KW  - pose estimation
KW  - Visualization
KW  - Feature extraction
KW  - Robustness
KW  - Urban areas
KW  - Transforms
KW  - Pose estimation
KW  - Robots
DO  - 10.1109/ICRA.2018.8460988
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents LOGOS, a method of spatial verification for visual localization that is robust in the presence of a high proportion of outliers. LOGOS uses scale and orientation information from local neighbourhoods of features to determine which points are likely to be inliers. The inlier points can be used for secondary localization verification and pose estimation. LOGOS is demonstrated on a number of benchmark localization datasets and outperforms RANSAC as a method of outlier removal and localization verification in scenarios that require robustness to many outliers.
ER  - 

TY  - CONF
TI  - Selection and Compression of Local Binary Features for Remote Visual SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7270
EP  - 7277
AU  - D. Van Opdenbosch
AU  - M. Oelsch
AU  - A. Garcea
AU  - T. Aykut
AU  - E. Steinbach
PY  - 2018
KW  - feature extraction
KW  - feature selection
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - SLAM (robots)
KW  - feature selection stage
KW  - remote visual SLAM
KW  - autonomous robotics
KW  - collaborative SLAM approaches
KW  - multiple robots
KW  - feature coding scheme
KW  - simultaneous localization and mapping
KW  - visual sensors
KW  - embedded devices
KW  - local binary features extraction
KW  - centralized powerful processing node
KW  - Visualization
KW  - Encoding
KW  - Simultaneous localization and mapping
KW  - Feature extraction
KW  - Task analysis
KW  - Image coding
DO  - 10.1109/ICRA.2018.8463202
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the field of autonomous robotics, Simultaneous Localization and Mapping (SLAM) is still a challenging problem. With cheap visual sensors attracting more and more attention, various solutions to the SLAM problem using visual cues have been proposed. However, current visual SLAM systems are still computationally demanding, especially on embedded devices. In addition, collaborative SLAM approaches emerge using visual information acquired from multiple robots simultaneously to build a joint map. In order to address both challenges, we present an approach for remote visual SLAM where local binary features are extracted at the robot, compressed and sent over a network to a centralized powerful processing node running the visual SLAM algorithm. To this end, we propose a new feature coding scheme including a feature selection stage which ensures that only relevant information is transmitted. We demonstrate the effectiveness of our approach on well-known datasets. With the proposed approach, it is possible to build an accurate map while limiting the data rate to 75 kbits/frame.
ER  - 

TY  - CONF
TI  - UnDeepVO: Monocular Visual Odometry Through Unsupervised Deep Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7286
EP  - 7291
AU  - R. Li
AU  - S. Wang
AU  - Z. Long
AU  - D. Gu
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pose estimation
KW  - stereo image processing
KW  - unsupervised learning
KW  - monocular visual odometry system
KW  - monocular camera
KW  - deep neural networks
KW  - unsupervised deep learning scheme
KW  - UnDeepVo
KW  - Training
KW  - Cameras
KW  - Machine learning
KW  - Three-dimensional displays
KW  - Estimation
KW  - Image sequences
KW  - Visual odometry
DO  - 10.1109/ICRA.2018.8461251
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a novel monocular visual odometry (VO) system called UnDeepVO in this paper. UnDeepVO is able to estimate the 6-DoF pose of a monocular camera and the depth of its view by using deep neural networks. There are two salient features of the proposed UnDeepVo:one is the unsupervised deep learning scheme, and the other is the absolute scale recovery. Specifically, we train UnDeepVoby using stereo image pairs to recover the scale but test it by using consecutive monocular images. Thus, UnDeepVO is a monocular system. The loss function defined for training the networks is based on spatial and temporal dense information. A system overview is shown in Fig. 1. The experiments on KITTI dataset show our UnDeepVO achieves good performance in terms of pose accuracy.
ER  - 

TY  - CONF
TI  - Counterexamples for Robotic Planning Explained in Structured Language
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7292
EP  - 7297
AU  - L. Feng
AU  - M. Ghasemi
AU  - K. Chang
AU  - U. Topcu
PY  - 2018
KW  - control engineering computing
KW  - formal verification
KW  - integer programming
KW  - linear programming
KW  - Markov processes
KW  - natural languages
KW  - path planning
KW  - robots
KW  - complex automaton
KW  - mixed-integer linear programming
KW  - Markov decision processes
KW  - model checking
KW  - warehouse robots planning
KW  - robotic mission plan
KW  - MDP model
KW  - robotic behavior
KW  - structured natural language sentences
KW  - Robots
KW  - Natural languages
KW  - Planning
KW  - Computational modeling
KW  - Charging stations
KW  - Model checking
KW  - Markov processes
DO  - 10.1109/ICRA.2018.8460945
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Automated techniques such as model checking have been used to verify models of robotic mission plans based on Markov decision processes (MDPs) and generate counterexamples that may help diagnose requirement violations. However, such artifacts may be too complex for humans to understand, because existing representations of counterexamples typically include a large number of paths or a complex automaton. To help improve the interpretability of counterexamples, we define a notion of explainable counterexample, which includes a set of structured natural language sentences to describe the robotic behavior that lead to a requirement violation in an MDP model of robotic mission plan. We propose an approach based on mixed-integer linear programming for generating explainable counterexamples that are minimal, sound and complete. We demonstrate the usefulness of the proposed approach via a case study of warehouse robots planning.
ER  - 

TY  - CONF
TI  - Multi-Vehicle Motion Planning for Social Optimal Mobility-on-Demand
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7298
EP  - 7305
AU  - J. Karlsson
AU  - C. Vasile
AU  - J. Tumova
AU  - S. Karaman
AU  - D. Rus
PY  - 2018
KW  - automobiles
KW  - collision avoidance
KW  - mobile robots
KW  - optimal control
KW  - optimisation
KW  - road traffic
KW  - scheduling
KW  - potential collision situations
KW  - road geometries
KW  - joint motion plans
KW  - multivehicle motion planning
KW  - road network
KW  - Vienna Convention
KW  - desired deadlines
KW  - integrated route
KW  - road traffic
KW  - motion planning problem
KW  - social optimal mobility-on-demand
KW  - self-driving cars
KW  - bubble spaces
KW  - queue scheduling
KW  - Roads
KW  - Planning
KW  - Delays
KW  - Task analysis
KW  - Sensors
KW  - Trajectory
KW  - Automobiles
DO  - 10.1109/ICRA.2018.8462968
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we consider a fleet of self-driving cars operating in a road network governed by rules of the road, such as the Vienna Convention on Road Traffic, providing rides to customers to serve their demands with desired deadlines. We focus on the associated motion planning problem that trades-off the demands' delays and level of violation of the rules of the road to achieve social optimum among the vehicles. Due to operating in the same environment, the interaction between the cars must be taken into account, and can induce further delays. We propose an integrated route and motion planning approach that achieves scalability with respect to the number of cars by resolving potential collision situations locally within so-called bubble spaces enclosing the conflict. The algorithms leverage the road geometries, and perform joint planning only for lead vehicles in the conflict and use queue scheduling for the remaining cars. Furthermore, a framework for storing previously resolved conflict situations is proposed, which can be use for quick querying of joint motion plans. We show the mobility-on-demand setup and effectiveness of the proposed approach in simulated case studies involving up to 10 self-driving vehicles.
ER  - 

TY  - CONF
TI  - Verifying Controllers Against Adversarial Examples with Bayesian Optimization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7306
EP  - 7313
AU  - S. Ghosh
AU  - F. Berkenkamp
AU  - G. Ranade
AU  - S. Qadeer
AU  - A. Kapoor
PY  - 2018
KW  - Bayes methods
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - robots
KW  - safety
KW  - complex safety specifications
KW  - complex controllers
KW  - Bayesian optimization
KW  - adversarial examples
KW  - coherent optimization framework
KW  - Gaussian Process prior
KW  - individual functions
KW  - reinforcement learning
KW  - reward functions
KW  - smooth functions
KW  - complex boolean combinations
KW  - adversarial counter examples
KW  - safety constraints
KW  - Bayesian Optimization
KW  - active-testing framework
KW  - safety-critical applications
KW  - Safety
KW  - Uncertainty
KW  - Robots
KW  - Testing
KW  - Trajectory
KW  - Optimization
KW  - Bayes methods
DO  - 10.1109/ICRA.2018.8460635
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recent successes in reinforcement learning have lead to the development of complex controllers for realworld robots. As these robots are deployed in safety-critical applications and interact with humans, it becomes critical to ensure safety in order to avoid causing harm. A first step in this direction is to test the controllers in simulation. To be able to do this, we need to capture what we mean by safety and then efficiently search the space of all behaviors to see if they are safe. In this paper, we present an active-testing framework based on Bayesian Optimization. We specify safety constraints using logic and exploit structure in the problem in order to test the system for adversarial counter examples that violate the safety specifications. These specifications are defined as complex boolean combinations of smooth functions on the trajectories and, unlike reward functions in reinforcement learning, are expressive and impose hard constraints on the system. In our framework, we exploit regularity assumptions on individual functions in form of a Gaussian Process (GP) prior. We combine these into a coherent optimization framework using problem structure. The resulting algorithm is able to provably verify complex safety specifications or alternatively find counter examples. Experimental results show that the proposed method is able to find adversarial examples quickly.
ER  - 

TY  - CONF
TI  - On the Relationship Between Bisimulation and Combinatorial Filter Reduction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7314
EP  - 7321
AU  - H. Rahmani
AU  - J. M. O'Kane
PY  - 2018
KW  - bisimulation equivalence
KW  - computational complexity
KW  - filtering theory
KW  - minimisation
KW  - polynomials
KW  - equivalence relation
KW  - filter minimization problem
KW  - polynomial time
KW  - bisimulation relations
KW  - bisimilarity relation -the union
KW  - equivalent behavior-is NP-hard
KW  - combinatorial filter reduction
KW  - bisimulation quotient operation
KW  - input filter
KW  - Minimization
KW  - Robots
KW  - Task analysis
KW  - Color
KW  - Computational modeling
KW  - Cognition
KW  - Partitioning algorithms
DO  - 10.1109/ICRA.2018.8460507
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Combinatorial filters are discrete structures for modeling and reasoning about robotic systems. Such filters are of interest not only because of the potential for reduction of the computational power needed to execute the filter, but also for the insight they can sometimes provide into the information requirements of certain robotic tasks. It is known that the filter minimization problem -that is, for a given filter, to find a combinatorial filter with the minimal number of states among all filters with equivalent behavior-is NP-hard. Intuition might suggest that the well-known notion of bisimulation might be of direct use for this minimization problem. Indeed, the bisimilarity relation -the union of all bisimulation relations over the state space of the original filter-is an equivalence relation, and one might attempt to reduce a filter by merging states that are equivalent under this relation. This paper studies this relationship between bisimulation and combinatorial filter reduction. Specifically, we show that every filter minimization problem can be solved by computing a quotient of the input filter with some relation, but that for some filters, the bisimilarity relation is not the correct relation for this purpose. We also characterize the result of the bisimulation quotient operation as the solution to a different, stricter filter minimization problem, and identify several classes of filters for which a variant of bisimulation, called compatibility, can be used to minimize filters in polynomial time.
ER  - 

TY  - CONF
TI  - Learning-Based Model Predictive Control Under Signal Temporal Logic Specifications
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7322
EP  - 7329
AU  - K. Cho
AU  - S. Oh
PY  - 2018
KW  - control system synthesis
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - predictive control
KW  - regression analysis
KW  - temporal logic
KW  - learning-based model predictive control method
KW  - differential constraints
KW  - dynamical systems
KW  - control strategy synthesis method
KW  - signal temporal logic specifications
KW  - specific rules
KW  - model predictive control procedure
KW  - learned margin
KW  - signal temporal logic formula
KW  - designed controller
KW  - traditional control scheme
KW  - Predictive control
KW  - Robustness
KW  - Collision avoidance
KW  - Task analysis
KW  - Gaussian processes
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460811
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a control strategy synthesis method for dynamical systems with differential constraints while satisfying a set of given rules in consideration of their importances. A special attention is given to situations where all rules cannot be met in order to fulfill a given task. Such dilemmas compel us to make a decision on the degree of satisfaction of each rule including which rule should be maintained or not. In this work, we propose a learning-based model predictive control method in order to solve this problem, where a key insight is to combine a learning method and traditional control scheme so that the designed controller behaves close to human experts. A rule is represented as a signal temporal logic (STL) formula. A robustness slackness, a margin to the satisfaction of the rule, is learned from expert's demonstrations using Gaussian process regression. The learned margin is used in a model predictive control procedure, which helps to decide how much to obey each rule, even ignoring specific rules. In track driving simulation, we show that the proposed method generates human-like behavior and efficiently handles dilemmas as human teachers do.
ER  - 

TY  - CONF
TI  - Auctioning over Probabilistic Options for Temporal Logic-Based Multi-Robot Cooperation Under Uncertainty
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7330
EP  - 7337
AU  - P. Schillinger
AU  - M. Bürger
AU  - D. V. Dimarogonas
PY  - 2018
KW  - control engineering computing
KW  - formal specification
KW  - mobile robots
KW  - multi-robot systems
KW  - operating systems (computers)
KW  - path planning
KW  - temporal logic
KW  - probabilistic options
KW  - temporal logic-based multirobot cooperation
KW  - temporal dependencies
KW  - task specification
KW  - robot team
KW  - temporal logic specifications
KW  - goal specification
KW  - ROS implementation
KW  - Robot kinematics
KW  - Task analysis
KW  - Uncertainty
KW  - Planning
KW  - Resource management
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2018.8462967
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Coordinating a team of robots to fulfill a common task is still a demanding problem. This is even more the case when considering uncertainty in the environment, as well as temporal dependencies within the task specification. A multi-robot cooperation from a single goal specification requires mechanisms for decomposing the goal as well as an efficient planning for the team. However, planning action sequences offline is insufficient in real world applications. Rather, due to uncertainties, the robots also need to closely coordinate during execution and adjust their policies when additional observations are made. The framework presented in this paper enables the robot team to cooperatively fulfill tasks given as temporal logic specifications while explicitly considering uncertainty and incorporating observations during execution. We present the effectiveness of our ROS implementation of this approach in a case study scenario.
ER  - 

TY  - CONF
TI  - Path Clustering with Homology Area
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7346
EP  - 7353
AU  - J. F. Carvalho
AU  - M. Vejdemo-Johansson
AU  - D. Kragic
AU  - F. T. Pokorny
PY  - 2018
KW  - computational complexity
KW  - mesh generation
KW  - pattern clustering
KW  - topology
KW  - triangulated mesh
KW  - topology
KW  - path clustering
KW  - pairwise distance calculations
KW  - triangle inequality
KW  - minimum homology area
KW  - Clustering methods
KW  - Topology
KW  - Clustering algorithms
KW  - Toy manufacturing industry
KW  - Robots
KW  - Programming
KW  - Support vector machines
DO  - 10.1109/ICRA.2018.8460939
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Path clustering has found many applications in recent years. Common approaches to this problem use aggregates of the distances between points to provide a measure of dissimilarity between paths which do not satisfy the triangle inequality. Furthermore, they do not take into account the topology of the space where the paths are embedded. To tackle this, we extend previous work in path clustering with relative homology, by employing minimum homology area as a measure of distance between homologous paths in a triangulated mesh. Further, we show that the resulting distance satisfies the triangle inequality, and how we can exploit the properties of homology to reduce the amount of pairwise distance calculations necessary to cluster a set of paths. We further compare the output of our algorithm with that of DTW on a toy dataset of paths, as well as on a dataset of real-world paths.
ER  - 

TY  - CONF
TI  - GraspMan - A Novel Robotic Platform with Grasping, Manipulation, and Multimodal Locomotion Capability
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7354
EP  - 7359
AU  - N. Govindan
AU  - S. S. V. Kovvali
AU  - K. Chandrasekaran
AU  - A. Thondiyath
PY  - 2018
KW  - actuators
KW  - belts
KW  - drives
KW  - grippers
KW  - legged locomotion
KW  - manipulator kinematics
KW  - motion control
KW  - springs (mechanical)
KW  - finger
KW  - synchronous belt drive
KW  - underactuated graspers
KW  - serial kinematic chain
KW  - scalable kinematic structure
KW  - kinematic analysis
KW  - prototype robot
KW  - multimodal locomotion
KW  - robotic platform
KW  - active gripping surface
KW  - underactuated fingers
KW  - multipurpose grasper
KW  - manipulation
KW  - grasping
KW  - GraspMan
KW  - Grasping
KW  - Belts
KW  - Actuators
KW  - Task analysis
KW  - Grippers
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8462970
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present the design of a novel, hybrid multipurpose robotic platform equipped with a pair of graspers to synergize grasping, manipulation, and locomotion. The multipurpose grasper consists of two underactuated fingers with an active gripping surface, which passively conforms to an object while grasping. Each finger has a spring loaded synchronous belt drive which functions as the active gripping surface. The grasper is capable of handling a range of objects with irregular geometry and size. Two such underactuated graspers are connected through a serial kinematic chain and this provides the platform both manipulation and locomotion capability. Graspers act as “legs” or “wheels” of the robot during locomotion and can easily adapt to terrain variations. Fewer number of actuators, simple and scalable kinematic structure, and computationally efficient control are some of the main features of the design. Design details and kinematic analysis are presented. Experiments were conducted on a prototype robot to demonstrate multiple modes of operation.
ER  - 

TY  - CONF
TI  - Design and Evaluation of a Novel Cable-Driven Gripper with Perception Capabilities for Strawberry Picking Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7384
EP  - 7391
AU  - Y. Xiong
AU  - P. J. From
AU  - V. Isler
PY  - 2018
KW  - agriculture
KW  - closed loop systems
KW  - grippers
KW  - infrared detectors
KW  - manipulators
KW  - position control
KW  - robot vision
KW  - robust control
KW  - gripper design
KW  - cable-driven gripper
KW  - autonomous harvesting
KW  - IR sensors
KW  - manipulator arm
KW  - vision algorithm
KW  - robustness
KW  - positional error tolerance
KW  - high-level closed-loop control
KW  - strawberry picking robots
KW  - Grippers
KW  - Servomotors
KW  - Containers
KW  - Sensors
KW  - Robots
KW  - Mechanical cables
KW  - Pulleys
DO  - 10.1109/ICRA.2018.8460705
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel cable-driven gripper with perception capabilities for autonomous harvesting of strawberries. Experiments show that the gripper allows for more accurate and faster picking of strawberries compared to existing systems. The gripper consists of four functional parts for sensing, picking, transmission, and storing. It has six fingers that open to form a closed space to swallow a target strawberry and push other surrounding berries away from the target. Equipped with three IR sensors, the gripper controls a manipulator arm to correct for positional error, and can thus pick strawberries that are not exactly localized by the vision algorithm, improving the robustness. Experiments show that the gripper is gentle on the berries as it merely cuts the stem and there is no physical interaction with the berries during the cutting process. We show that the gripper has close-to-perfect successful picking rate when addressing isolated strawberries. By including internal perception, we get high positional error tolerance, and avoid using slow, high-level closed-loop control. Moreover, the gripper can store several berries, which reduces the overall travel distance for the manipulator, and decreases the time needed to pick a single strawberry substantially. The experiments show that the gripper design decreased picking execution time noticeably compared to results found in literature.
ER  - 

TY  - CONF
TI  - Underactuated Hand Design Using Mechanically Realizable Manifolds
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7392
EP  - 7398
AU  - T. Chen
AU  - M. Haas-Heger
AU  - M. Ciocarlie
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - grippers
KW  - manipulator kinematics
KW  - stability
KW  - hand synergies
KW  - kinematic hand model
KW  - physical underactuation mechanism
KW  - hand posture
KW  - single-actuator hand
KW  - underactuated hand design
KW  - mechanically realizable manifolds
KW  - joint coordination patterns
KW  - planning algorithms
KW  - robotic grasping
KW  - mechanically realizable manifold
KW  - Tendons
KW  - Force
KW  - Optimization
KW  - Springs
KW  - Manifolds
KW  - Kinematics
KW  - Grasping
DO  - 10.1109/ICRA.2018.8462972
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Hand synergies, or joint coordination patterns, have become an effective tool for achieving versatile robotic grasping with simple hands or planning algorithms. Here we propose a method to determine the hand synergies such that they can be physically implemented in an underactuated fashion. Given a kinematic hand model and a set of desired grasps, our algorithm optimizes a Mechanically Realizable Manifold designed to be achievable by a physical underactuation mechanism, enabling the resulting hand to achieve the desired grasps with few actuators. Furthermore, in contrast to existing methods for determining synergies which are only concerned with hand posture, our method explicitly optimizes the stability of the target grasps. We implement this method in the design of a three-finger single-actuator hand as an example, and evaluate its effectiveness numerically and experimentally.
ER  - 

TY  - CONF
TI  - Robotic Handling of Liquids with Spilling Avoidance: A Constraint-Based Control Approach
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7414
EP  - 7420
AU  - R. Maderna
AU  - A. Casalino
AU  - A. M. Zanchettin
AU  - P. Rocco
PY  - 2018
KW  - industrial manipulators
KW  - materials handling
KW  - motion control
KW  - path planning
KW  - sloshing
KW  - handling liquids
KW  - service robotic applications
KW  - motion planning
KW  - liquid transfer
KW  - sloshing control
KW  - anti spilling constraint
KW  - spilling avoidance constraint
KW  - constraint-based control
KW  - sloshing suppression
KW  - industrial ABB robot
KW  - robotic manipulators
KW  - Liquids
KW  - Robots
KW  - Trajectory
KW  - Containers
KW  - Task analysis
KW  - Acceleration
KW  - Optimization
DO  - 10.1109/ICRA.2018.8460927
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Handling liquids with spilling avoidance is a topic of interest for a broad range of fields, both in industry and in service robotic applications. In this paper we present a new control architecture for motion planning of industrial robots, able to tackle the problem of liquid transfer with sloshing control. We do not focus on a complete sloshing suppression, but we show how to enforce an anti spilling constraint. This less conservative approach allows to impose higher accelerations, reducing motion time. A constraint-based approach, amenable to an Online implementation, has been developed. The proposed controller generates trajectories in real time, in order to follow a reference path, while being compliant to the spilling avoidance constraint. The approach has been validated on a 6 degree of freedom industrial ABB robot.
ER  - 

TY  - CONF
TI  - A Robust Robot Design for Item Picking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7421
EP  - 7426
AU  - A. Causo
AU  - Z. Chong
AU  - R. Luxman
AU  - Y. Y. Kok
AU  - Z. Yi
AU  - W. Pang
AU  - R. Meixuan
AU  - Y. S. Teoh
AU  - W. Jing
AU  - H. S. Tju
AU  - I. -. Chen
PY  - 2018
KW  - calibration
KW  - cameras
KW  - grippers
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - path planning
KW  - robot vision
KW  - service robots
KW  - feature-based comparison
KW  - gripper system
KW  - grasping strategy
KW  - robust performance
KW  - target items
KW  - robot system
KW  - dual 6 degrees of freedom industrial arms
KW  - error recovery strategies
KW  - fixed calibrated frame
KW  - multiple stereo cameras
KW  - vision system
KW  - custom-designed top-open extendable shelf
KW  - calibrated table
KW  - fixed bases
KW  - module designs
KW  - component selection
KW  - motion planning
KW  - system requirements
KW  - Amazon Robotics Challenge
KW  - reliable system
KW  - stable system
KW  - item picking
KW  - robust robot design
KW  - Cameras
KW  - Manipulators
KW  - Task analysis
KW  - Planning
KW  - Service robots
KW  - Robot vision systems
DO  - 10.1109/ICRA.2018.8461057
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In order to build a stable and reliable system for the Amazon Robotics Challenge we went through a detailed study of the performance and system requirements based on the rules and our past experience of the challenge. The challenge was to build a robot that integrates grasping, vision, motion planning, among others, to be able to pick items from a shelf to specific order boxes. This paper presents the development process including component selection, module designs, and deployment. The resulting robot system has dual 6 degrees of freedom industrial arms mounted on fixed bases, which in turn are mounted on a calibrated table. The robot works with a custom-designed top-open extendable shelf. The vision system uses multiple stereo cameras mounted on a fixed calibrated frame. Feature-based comparison and machine-learning based matching are used to identify and determine item pose. The gripper system uses suction cup and the grasping strategy is pick from the top. Error recovery strategies were also implemented to ensure robust performance. During the competition, the robot was able to pick all target items with the shortest amount of time.
ER  - 

TY  - CONF
TI  - Physics-Based Selection of Informative Actions for Interactive Perception
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7427
EP  - 7432
AU  - C. Eppner
AU  - R. Martín-Martín
AU  - O. Brock
PY  - 2018
KW  - mobile robots
KW  - robot dynamics
KW  - robot kinematics
KW  - visual perception
KW  - physics-based selection
KW  - informative action
KW  - forceful interactions
KW  - task-relevant information
KW  - informative interactions
KW  - articulated mechanisms
KW  - action selection task
KW  - interactive perception methods
KW  - information gain
KW  - robust manipulation
KW  - Kinematics
KW  - Task analysis
KW  - Dynamics
KW  - Robot sensing systems
KW  - Shape
KW  - Force
DO  - 10.1109/ICRA.2018.8460596
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Interactive perception exploits the correlation between forceful interactions and changes in the observed signals to extract task-relevant information from the sensor stream. Finding the most informative interactions to perceive complex objects, like articulated mechanisms, is challenging because the outcome of the interaction is difficult to predict. We propose a method to select the most informative action while deriving a model of articulated mechanisms that includes kinematic, geometric, and dynamic properties. Our method addresses the complexity of the action selection task based on two insights. First, we show that for a class of interactive perception methods, information gain can be approximated by the amount of motion induced in the mechanism. Second, we resort to physics simulations grounded in the real-world through interactive perception to predict possible action outcomes. Our method enables the robot to autonomously select actions for interactive perception that reveal most information, given the current knowledge of the world. This leads to improved perception and more accurate world models, finally enabling robust manipulation.
ER  - 

TY  - CONF
TI  - Pick and Place Without Geometric Object Models
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7433
EP  - 7440
AU  - M. Gualtieri
AU  - A. t. Pas
AU  - R. Platt
PY  - 2018
KW  - geometry
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - geometric object models
KW  - robotic pick
KW  - deep reinforcement learning problem
KW  - deep RL
KW  - robotic manipulation frame
KW  - low level states
KW  - pick-place
KW  - regrasping problems
KW  - exact geometry
KW  - sensor perception
KW  - Shape
KW  - History
KW  - Task analysis
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Geometry
DO  - 10.1109/ICRA.2018.8460553
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a novel formulation of robotic pick and place as a deep reinforcement learning (RL) problem. Whereas most deep RL approaches to robotic manipulation frame the problem in terms of low level states and actions, we propose a more abstract formulation. In this formulation, actions are target reach poses for the hand and states are a history of such reaches. We show this approach can solve a challenging class of pick-place and regrasping problems where the exact geometry of the objects to be handled is unknown. The only information our method requires is: 1) the sensor perception available to the robot at test time; 2) prior knowledge of the general class of objects for which the system was trained. We evaluate our method using objects belonging to two different categories, mugs and bottles, both in simulation and on real hardware. Results show a major improvement relative to a shape primitives baseline.
ER  - 

TY  - CONF
TI  - Automatic Material Properties Estimation for the Physics-Based Robotic Garment Folding
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7449
EP  - 7454
AU  - V. Petrík
AU  - J. Cmíral
AU  - V. Smutný
AU  - P. Krsek
AU  - V. Hlaváč
PY  - 2018
KW  - clothing
KW  - fabrics
KW  - industrial robots
KW  - iterative methods
KW  - laser ranging
KW  - optimisation
KW  - automatic material properties estimation
KW  - physics-based robotic garment folding
KW  - fabric material property
KW  - iterative strategy
KW  - optimisation task
KW  - laser range finder
KW  - Fabrics
KW  - Estimation
KW  - Robots
KW  - Grippers
KW  - Material properties
KW  - Clothing
KW  - Measurement by laser beam
DO  - 10.1109/ICRA.2018.8461016
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The estimation of the fabric material property during the folding is presented. The available techniques for the accurate garment folding rely on known material properties. Currently, the properties are estimated by an operator in advance of folding. We propose an iterative strategy, which updates the property while the garment is folded. The estimation is formulated as an optimisation task. It is based on measurements from a laser range finder. The proposed algorithm improves the estimation iteratively and prevents the garment from slipping at the same time. We demonstrate the estimation procedure for 10 fabric strips of different materials.
ER  - 

TY  - CONF
TI  - Slipping Control Algorithms for Object Manipulation with Sensorized Parallel Grippers
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7455
EP  - 7461
AU  - M. Costanzo
AU  - G. De Maria
AU  - C. Natale
PY  - 2018
KW  - deformation
KW  - dexterous manipulators
KW  - force measurement
KW  - force sensors
KW  - grippers
KW  - mechanical contact
KW  - tactile sensors
KW  - torque measurement
KW  - object manipulation
KW  - sensorized parallel grippers
KW  - parallel jaw grippers
KW  - in-hand manipulation tasks
KW  - controlled sliding motion
KW  - grasped object
KW  - rotational sliding maneuver
KW  - grip force
KW  - translational sliding
KW  - rotational slippage
KW  - linear slippage
KW  - fragile objects
KW  - deformable objects
KW  - controlled rotational sliding
KW  - in-hand manipulation actions
KW  - sensorized gripper
KW  - six-axis force/tactile sensor
KW  - contact force
KW  - torque measurements
KW  - slipping control algorithms
KW  - in-hand manipulation action
KW  - Force
KW  - Robot sensing systems
KW  - Grippers
KW  - Friction
KW  - Task analysis
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460883
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Parallel jaw grippers have a limited dexterity, however they can still be used for in-hand manipulation tasks, such as pivoting or other controlled sliding motions of the grasped object. A rotational sliding maneuver is challenging since the grasped object can easily slip if the grip force is not properly adjusted to allow rotational sliding while avoiding translational sliding at the same time. This paper has a twofold aim. First, it intends to refine control algorithms to avoid both rotational and linear slippage, already presented by the authors, by proposing a novel sliding motion model that leads to a grip force as small as possible to avoid slippage, so as to enlarge the set of fragile and deformable objects that can be safely grasped with this approach. Second, the paper exploits the motion model to set up a new algorithm for controlled rotational sliding, thus enabling challenging in-hand manipulation actions. All control algorithms are sensor-based, exploiting a sensorized gripper equipped with a six-axis force/tactile sensor, which provides contact force and torque measurements as well as orientation of the object with respect to the gripper. A set of experiments are executed on a Kuka iiwa showing how the proposed control algorithms are effective to both avoid slippage and allow a controlled sliding motion.
ER  - 

TY  - CONF
TI  - Semantic Robot Programming for Goal-Directed Manipulation in Cluttered Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7462
EP  - 7469
AU  - Z. Zeng
AU  - Z. Zhou
AU  - Z. Sui
AU  - O. C. Jenkins
PY  - 2018
KW  - graph theory
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - path planning
KW  - pose estimation
KW  - robot programming
KW  - robot vision
KW  - object geometries
KW  - Semantic Robot Programming
KW  - task planning
KW  - motion planning
KW  - Discriminatively-Informed Generative Estimation of Scenes and Transforms
KW  - DIGEST method
KW  - RGBD images
KW  - goal-directed manipulation
KW  - cluttered scene dataset
KW  - Michigan Progress Fetch robot
KW  - object poses
KW  - robot manipulator
KW  - SRP
KW  - semantic mapping
KW  - Task analysis
KW  - Semantics
KW  - Robot programming
KW  - Estimation
KW  - Planning
KW  - Detectors
DO  - 10.1109/ICRA.2018.8460538
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present the Semantic Robot Programming (SRP) paradigm as a convergence of robot programming by demonstration and semantic mapping. In SRP, a user can directly program a robot manipulator by demonstrating a snapshot of their intended goal scene in workspace. The robot then parses this goal as a scene graph comprised of object poses and inter-object relations, assuming known object geometries. Task and motion planning is then used to realize the user's goal from an arbitrary initial scene configuration. Even when faced with different initial scene configurations, SRP enables the robot to seamlessly adapt to reach the user's demonstrated goal. For scene perception, we propose the Discriminatively-Informed Generative Estimation of Scenes and Transforms (DIGEST) method to infer the initial and goal states of the world from RGBD images. The efficacy of SRP with DIGEST perception is demonstrated for the task of tray-setting with a Michigan Progress Fetch robot. Scene perception and task execution are evaluated with a public household occlusion dataset and our cluttered scene dataset.
ER  - 

TY  - CONF
TI  - Off-Road Lidar Simulation with Data-Driven Terrain Primitives
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7470
EP  - 7477
AU  - A. Tallavajhula
AU  - Ç. Meriçli
AU  - A. Kelly
PY  - 2018
KW  - geophysics computing
KW  - mobile robots
KW  - optical radar
KW  - remote sensing by laser beam
KW  - vegetation
KW  - perception algorithms
KW  - geometric terrain representation
KW  - Lidar rays
KW  - off-road Lidar simulation
KW  - vegetation
KW  - trees
KW  - shrubs
KW  - data logs
KW  - off-road environments
KW  - state estimation algorithms
KW  - high-fidelity sensor-realistic simulation
KW  - scale off-road robot applications
KW  - data-driven terrain primitives
KW  - Lidar observations
KW  - natural terrain
KW  - Laser radar
KW  - Software
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Training
DO  - 10.1109/ICRA.2018.8461198
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Developing software for large scale off-road robot applications is challenging and tedious due to cost, logistics, and rigor of field testing. High-fidelity sensor-realistic simulation can speed up the development process for perception and state estimation algorithms. We focus on Lidar simulation for robots operating in off-road environments. Lidars are integral sensors for robots, and Lidar simulation for off-road environments is particularly challenging due to the way Lidar rays interact with natural terrain such as vegetation. A hybrid geometric terrain representation has been shown to model Lidar observations well [1]. However, previous work has only been able to simulate a single, fixed scene, and the entire scene had to be precisely surveyed. In this work, we add semantic information to the hybrid geometric model. This allows us to extract terrain primitives, such as trees and shrubs, from data logs. Our approach uses these primitives to compose arbitrary scenes for Lidar simulation. We evaluate our simulator on a real-world environment of interest, and show that primitives derived using our approach generalize to new scenes.
ER  - 

TY  - CONF
TI  - Historical Data is Useful for Navigation Planning: Data Driven Route Generation for Autonomous Ship
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7478
EP  - 7483
AU  - W. C. Tan
AU  - C. Weng
AU  - Y. Zhou
AU  - K. H. Chua
AU  - I. -. Chen
PY  - 2018
KW  - autonomous underwater vehicles
KW  - collision avoidance
KW  - marine control
KW  - marine navigation
KW  - mobile robots
KW  - ships
KW  - Navigation Feature
KW  - historical data
KW  - navigation planning
KW  - data driven route generation
KW  - autonomous ship
KW  - automated generation
KW  - autonomous surface vessel
KW  - robotic surface vessel
KW  - Historical Automatic Identification System data
KW  - AIS locations
KW  - nearest neighbour based path retrieval
KW  - Ship Feature
KW  - AIS records
KW  - Marine vehicles
KW  - Navigation
KW  - Artificial intelligence
KW  - Noise measurement
KW  - Planning
KW  - Path planning
KW  - Databases
DO  - 10.1109/ICRA.2018.8460880
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work presents a method for automated generation of navigation plan for autonomous or robotic surface vessel. Historical Automatic Identification System (AIS) data is of significant value to this problem. The method joins AIS locations of a same vessel at different time and locations in a region into a route. Next, it automatically computes navigation plans using nearest neighbour based path retrieval relying on two representations, Ship Feature and Navigation Feature. Before starting service, existing AIS records in the form of ship properties and corresponding route are preprocessed and stored in the form of Ship and Navigation Feature. During online retrieval, given input constraints in vector form, nearest neighbour of this query vector in the same space is found and corresponding path of the neighbour is returned as recommended path. Analysis was done in four and two dimensional spaces for Ship and Navigation Feature respectively. Application of the method is demonstrated in two regions of Australian, covering Bass Strait and Great Australian Bight.
ER  - 

TY  - CONF
TI  - A Preliminary Study of Ice-Relative Underwater Vehicle Navigation Beneath Moving Sea Ice
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7484
EP  - 7491
AU  - L. D. L. Barker
AU  - L. L. Whitcomb
PY  - 2018
KW  - autonomous underwater vehicles
KW  - Kalman filters
KW  - marine navigation
KW  - mobile robots
KW  - navigation
KW  - nonlinear filters
KW  - oceanographic techniques
KW  - position control
KW  - ships
KW  - under-ice navigation methods
KW  - extended Kalman filter
KW  - sufficient satellite beacon separation
KW  - vehicle position
KW  - ice velocities
KW  - vehicle trajectory
KW  - ice survey
KW  - navigation sensors
KW  - ship
KW  - precision vehicle
KW  - satellite navigation beacons
KW  - precision navigation capabilities
KW  - under-ice robotic vehicles
KW  - moving stationary sea ice
KW  - underwater robotic vehicle navigation
KW  - vehicle navigation beneath moving sea ice
KW  - ice-relative
KW  - size 7.6 km
KW  - size 1.2 km
KW  - Satellite navigation systems
KW  - Marine vehicles
KW  - Sea ice
KW  - Sonar navigation
KW  - Acoustics
DO  - 10.1109/ICRA.2018.8461166
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper addresses the problem of underwater robotic vehicle navigation relative to moving or stationary sea ice. A brief review of previously-reported under-ice navigation methods is given, as well as a brief motivation for the use of under-ice robotic vehicles with precision navigation capabilities. We then describe our proposed approach, which employs two or more satellite navigation beacons atop the sea ice along with other precision vehicle and ship mounted navigation sensors to estimate vehicle, ice, and ship states by means of an Extended Kalman Filter. Navigation results for a simulated 7.6 km under ice survey are presented for varying satellite beacon separation. Preliminary analysis suggests that for the simulated sensors, vehicle trajectory, and ice velocities, the proposed method can accurately estimate vehicle position up to 1.2 km from the deployment ship given sufficient satellite beacon separation. Decreased beacon separation results in divergence of the vehicle's position estimate at large standoff distances from the ship. We conclude with suggestions for future improvements.
ER  - 

TY  - CONF
TI  - A Soft Robot for Random Exploration of Terrestrial Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7492
EP  - 7497
AU  - S. Mintchev
AU  - D. Zappetti
AU  - J. Willemin
AU  - D. Floreano
PY  - 2018
KW  - control engineering computing
KW  - industrial robots
KW  - mass production
KW  - microrobots
KW  - motion control
KW  - multi-robot systems
KW  - soft robot
KW  - random exploration
KW  - terrestrial environments
KW  - unknown terrains
KW  - adequate locomotion strategy
KW  - fast exploration
KW  - obstacles negotiation
KW  - mass manufacturing
KW  - minimalistic design
KW  - roll
KW  - soft cage
KW  - swarm operations
KW  - randomly moving miniature robots
KW  - Robots
KW  - Propellers
KW  - Aerodynamics
KW  - Shock absorbers
KW  - Batteries
DO  - 10.1109/ICRA.2018.8460667
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A swarm of randomly moving miniature robots is an effective solution for the exploration of unknown terrains. However, the deployment of a swarm of miniature robots poses two challenges: finding an adequate locomotion strategy for fast exploration and obstacles negotiation; and implementing simple design and control solutions suited for mass manufacturing. Here, we tackle these challenges by developing a new soft robot with a minimalistic design and a simple control strategy that can randomly propel itself above obstacles and roll on the ground upon landing. The robot is equipped with two propellers that are periodically activated to jump, a soft cage that protects the robot from impacts and allows to passively roll on the ground, and a passive self-righting mechanism for repetitive jumps. The minimalistic control and design reduce the complexity of the mechanics and electronics and are instrumental to the production of a large number of robots. In the paper, the key design aspects of the robot are discussed, the locomotion of a single prototype is experimentally characterized, and improvements of the system for future swarm operations are discussed.
ER  - 

TY  - CONF
TI  - Micro Underwater Vehicle Hydrobatics: A Submerged Furuta Pendulum
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7498
EP  - 7503
AU  - D. A. Duecker
AU  - A. Hackbarth
AU  - T. Johannink
AU  - E. Kreuzer
AU  - E. Solowjow
PY  - 2018
KW  - attitude control
KW  - autonomous underwater vehicles
KW  - control system synthesis
KW  - marine control
KW  - microrobots
KW  - mobile robots
KW  - pendulums
KW  - robust control
KW  - stability
KW  - vehicle dynamics
KW  - submerged Furuta pendulum
KW  - HippoCampus microunderwater vehicle
KW  - fluid volumes
KW  - tightly constrained settings
KW  - agile vehicle dynamics
KW  - robust attitude control scheme
KW  - aerial drones
KW  - underwater domain
KW  - control method
KW  - microunderwater vehicle hydrobatics
KW  - submerged Furuta pendulum stabilization
KW  - Vehicle dynamics
KW  - Hippocampus
KW  - Attitude control
KW  - Hydrodynamics
KW  - Force
KW  - Monitoring
KW  - Drones
DO  - 10.1109/ICRA.2018.8461091
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present the new HippoCampus micro underwater vehicle, first introduced in [1]. It is designed for monitoring confined fluid volumes. These tightly constrained settings demand agile vehicle dynamics. Moreover, we adapt a robust attitude control scheme for aerial drones to the underwater domain. We demonstrate the performance of the controller with a challenging maneuver. A submerged Furuta pendulum is stabilized by HippoCampus after a swing-up. The experimental results reveal the robustness of the control method, as the system quickly recovers from strong physical disturbances, which are applied to the system.
ER  - 

TY  - CONF
TI  - Satellite-Based Tele-Operation of an Underwater Vehicle-Manipulator System. Preliminary Experimental Results
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7504
EP  - 7509
AU  - P. Di Lillo
AU  - D. Di Vito
AU  - E. Simetti
AU  - G. Casalino
AU  - G. Antonelli
PY  - 2018
KW  - artificial satellites
KW  - end effectors
KW  - manipulator kinematics
KW  - mobile robots
KW  - remotely operated vehicles
KW  - satellite communication
KW  - satellite links
KW  - telerobotics
KW  - underwater vehicles
KW  - UVMS
KW  - Underwater Vehicle-Manipulator System
KW  - satellite link
KW  - task-priority-based inverse kinematics algorithm
KW  - satellite-based tele-operation
KW  - European project
KW  - underwater intervention
KW  - remote control room
KW  - satellite communication link
KW  - DexROV
KW  - cognitive engine
KW  - communication latency
KW  - end effector
KW  - size 2017.0 inch
KW  - Task analysis
KW  - Trajectory
KW  - Kinematics
KW  - Satellite communication
KW  - Exoskeletons
KW  - Engines
KW  - Robustness
DO  - 10.1109/ICRA.2018.8462976
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Within the European project DexROV the topic of underwater intervention is addressed. In particular, a remote control room is connected through a satellite communication link to surface vessel, which is in turn connected to an UVMS (Underwater Vehicle-Manipulator System) with an umbilical cable. The operator may interact with the system using a joystick or exoskeleton. Since a direct teleoperation is not feasible, a cognitive engine is in charge of handling communication latency or interruptions caused by the satellite link, and the UVMS should have sufficient autonomy in dealing with low level constraints or secondary objectives. To this purpose, a task-priority-based inverse kinematics algorithm has been developed in order to allow the operator to control only the end effector, while the algorithm is in charge of handling both operative and joint-space constraints. This paper describes some preliminary experimental results achieved during the DexROV campaign of July 2017 in Marseilles (France), where most of the components have been successfully integrated and the inverse kinematics nicely run.
ER  - 

TY  - CONF
TI  - Robust Dense Mapping for Large-Scale Dynamic Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7510
EP  - 7517
AU  - I. A. Barsan
AU  - P. Liu
AU  - M. Pollefeys
AU  - A. Geiger
PY  - 2018
KW  - cameras
KW  - image motion analysis
KW  - image reconstruction
KW  - image segmentation
KW  - mobile robots
KW  - motion control
KW  - object detection
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - robust dense mapping
KW  - large-scale dynamic environments
KW  - stereo-based dense mapping algorithm
KW  - large-scale dynamic urban environments
KW  - static background
KW  - high-level mobile robotic tasks
KW  - crowded environments
KW  - instance-aware semantic segmentation
KW  - sparse scene flow
KW  - visual odometry
KW  - depth maps
KW  - stereo input
KW  - map pruning technique
KW  - reconstruction accuracy
KW  - stationary objects
KW  - moving objects detection
KW  - path planning
KW  - camera poses estimation
KW  - frequency 2.5 Hz
KW  - Three-dimensional displays
KW  - Cameras
KW  - Semantics
KW  - Vehicle dynamics
KW  - Dynamics
KW  - Real-time systems
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2018.8462974
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a stereo-based dense mapping algorithm for large-scale dynamic urban environments. In contrast to other existing methods, we simultaneously reconstruct the static background, the moving objects, and the potentially moving but currently stationary objects separately, which is desirable for high-level mobile robotic tasks such as path planning in crowded environments. We use both instance-aware semantic segmentation and sparse scene flow to classify objects as either background, moving, or potentially moving, thereby ensuring that the system is able to model objects with the potential to transition from static to dynamic, such as parked cars. Given camera poses estimated from visual odometry, both the background and the (potentially) moving objects are reconstructed separately by fusing the depth maps computed from the stereo input. In addition to visual odometry, sparse scene flow is also used to estimate the 3D motions of the detected moving objects, in order to reconstruct them accurately. A map pruning technique is further developed to improve reconstruction accuracy and reduce memory consumption, leading to increased scalability. We evaluate our system thoroughly on the well-known KITTI dataset. Our system is capable of running on a PC at approximately 2.5Hz, with the primary bottleneck being the instance-aware semantic segmentation, which is a limitation we hope to address in future work. The source code is available from the project Websitea.
ER  - 

TY  - CONF
TI  - Self-triggered Adaptive Planning and Scheduling of UAV Operations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7518
EP  - 7524
AU  - E. Yel
AU  - T. X. Lin
AU  - N. Bezzo
PY  - 2018
KW  - adaptive control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - energy consumption
KW  - helicopters
KW  - mobile robots
KW  - noise
KW  - reachability analysis
KW  - risk analysis
KW  - scheduling
KW  - trajectory optimisation (aerospace)
KW  - obstacles avoidance
KW  - energy consumption
KW  - trajectory curvature
KW  - self-triggered adaptive planning
KW  - unmanned aerial vehicles
KW  - scheduling
KW  - quadrotor UAV motion planning
KW  - obstacles detection
KW  - time consumption
KW  - constant periodic sensor measurements
KW  - online speed adaptation policy
KW  - risk-based analysis
KW  - noise
KW  - reachability analysis
KW  - Trajectory
KW  - Robot sensing systems
KW  - Safety
KW  - Unmanned aerial vehicles
KW  - Reachability analysis
KW  - Schedules
DO  - 10.1109/ICRA.2018.8463205
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Modern unmanned aerial vehicles (UAVs) rely on constant periodic sensor measurements to detect and avoid obstacles. However, constant checking and replanning are time and energy consuming and are often not necessary especially in situations in which the UAV can safely fly in uncluttered environments without entering unsafe states. Thus, in this paper, we propose a self-triggered framework that leverages reachability analysis to schedule the next time to check sensor measurements and perform replanning while guaranteeing safety under noise and disturbance effects. Further, we relax sensor checking and motion replanning operations by leveraging a risk-based analysis that determines the likelihood to reach undesired states over a certain time horizon. We also propose an online speed adaptation policy based on the planned trajectory curvature to minimize drift from the desired path due to the system dynamics. Finally, we validate the proposed approach with simulations and experiments for a quadrotor UAV motion planning case study in a cluttered environment.
ER  - 

TY  - CONF
TI  - Cross-Domain Transfer in Reinforcement Learning Using Target Apprentice
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7525
EP  - 7532
AU  - G. Joshi
AU  - G. Chowdhary
PY  - 2018
KW  - generalisation (artificial intelligence)
KW  - learning (artificial intelligence)
KW  - target apprentice learning
KW  - cross-domain transfer
KW  - reinforcement learning
KW  - cross-domain tasks
KW  - target task learning
KW  - target domain
KW  - policy augmentation
KW  - Task analysis
KW  - Adaptation models
KW  - Automobiles
KW  - Manifolds
KW  - Bicycles
KW  - Learning (artificial intelligence)
KW  - Complexity theory
DO  - 10.1109/ICRA.2018.8462977
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a new approach to transfer in Reinforcement Learning (RL) for cross-domain tasks. Unlike, available transfer approaches, where target task learning is accelerated through initialized learning from source, we propose to adapt and reuse the optimal source policy directly in the related domains. We show the optimal policy from a related source task can be near optimal in target domain provided an adaptive policy accounts for the model error between target and the projected source. A significant advantage of the proposed policy augmentation is in generalizing the policies across related domains without having to re-Iearn the new tasks. We demonstrate that, this architecture leads to better sample efficiency in the transfer, reducing sample complexity of target task learning to target apprentice learning.
ER  - 

TY  - CONF
TI  - Intent-Aware Multi-Agent Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7533
EP  - 7540
AU  - S. Qi
AU  - S. Zhu
PY  - 2018
KW  - aerospace robotics
KW  - control engineering computing
KW  - decision theory
KW  - function approximation
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - multi-agent systems
KW  - planning (artificial intelligence)
KW  - robot dynamics
KW  - low-level planning algorithms
KW  - intent-aware multiagent reinforcement learning
KW  - learning algorithm
KW  - planning process
KW  - partially observable Markov decision process
KW  - linear function approximation
KW  - intent-aware multiagent planning
KW  - aerial robots
KW  - human interaction
KW  - dynamic process
KW  - POMDP
KW  - Planning
KW  - Prediction algorithms
KW  - Automata
KW  - Vehicles
KW  - History
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8463211
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes an intent-aware multi-agent planning framework as well as a learning algorithm. Under this framework, an agent plans in the goal space to maximize the expected utility. The planning process takes the belief of other agents' intents into consideration. Instead of formulating the learning problem as a partially observable Markov decision process (POMDP), we propose a simple but effective linear function approximation of the utility function. It is based on the observation that for humans, other people's intents will pose an influence on our utility for a goal. The proposed framework has several major advantages: i) it is computationally feasible and guaranteed to converge. ii) It can easily integrate existing intent prediction and low-level planning algorithms. iii) It does not suffer from sparse feedbacks in the action space. We experiment our algorithm in a real-world problem that is non-episodic, and the number of agents and goals can vary over time. Our algorithm is trained in a scene in which aerial robots and humans interact, and tested in a novel scene with a different environment. Experimental results show that our algorithm achieves the best performance and human-like behaviors emerge during the dynamic process.
ER  - 

TY  - CONF
TI  - Improving Model-Based Balance Controllers Using Reinforcement Learning and Adaptive Sampling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7541
EP  - 7547
AU  - V. C. V. Kumar
AU  - S. Ha
AU  - K. Yamane
PY  - 2018
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - optimal control
KW  - sampling methods
KW  - control signals
KW  - adaptive sampling
KW  - model-based balance controllers
KW  - humanoid model
KW  - in-place balancing
KW  - training disturbances
KW  - standard reinforcement learning formulations
KW  - deep reinforcement learning techniques
KW  - control policy
KW  - RoA
KW  - model-based optimal controller
KW  - learning framework
KW  - full-body actions
KW  - nonplanar pushes
KW  - full-body dynamics
KW  - optimal control theory
KW  - Perturbation methods
KW  - Hip
KW  - Adaptation models
KW  - Robots
KW  - Training
KW  - Lips
KW  - Learning (artificial intelligence)
DO  - 10.1109/ICRA.2018.8463209
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Balance control to recover from a wide range of disturbances is an important skill for humanoid robots. Traditionally, researchers have often designed a balance controller by applying optimal control theory on a simplified model that abstracts the full-body dynamics. However, the resulting controller may not be able to recover from unexpected scenarios such as non-planar pushes, or fail to exploit full-body actions such as balancing with arm movements. This paper presents a learning framework for enhancing the performance of a model-based optimal controller by expanding the region of attraction (RoA). We train a control policy that generates additional control signals on top of the model-based controller using deep reinforcement learning techniques. Instead of relying on standard reinforcement learning formulations, we explicitly model the region of attraction and continuously adjust it during the training. By drawing the training disturbances at the boundary of the RoA, we can effectively expand the RoA while avoiding local minima. We test our learning framework for in-place balancing as well as balancing with stepping on a humanoid model in simulation.
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning Supervised Autonomous Exploration in Office Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7548
EP  - 7555
AU  - D. Zhu
AU  - T. Li
AU  - D. Ho
AU  - C. Wang
AU  - M. Q. -. Meng
PY  - 2018
KW  - decision making
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - supervised autonomous exploration
KW  - office environments
KW  - exploration region selection
KW  - autonomous robot exploration task
KW  - greedy methods
KW  - long-term planning
KW  - deep reinforcement learning
KW  - exploration knowledge
KW  - office blueprints
KW  - DRL model
KW  - next-best-view selection approach
KW  - structural integrity measurement
KW  - office maps
KW  - decision making process
KW  - Planning
KW  - Optimization
KW  - Prediction algorithms
KW  - Task analysis
KW  - Predictive models
KW  - Computer architecture
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8463213
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Exploration region selection is an essential decision making process in autonomous robot exploration task. While a majority of greedy methods are proposed to deal with this problem, few efforts are made to investigate the importance of predicting long-term planning. In this paper, we present an algorithm that utilizes deep reinforcement learning (DRL) to learn exploration knowledge over office blueprints, which enables the agent to predict a long-term visiting order for unexplored subregions. On the basis of this algorithm, we propose an exploration architecture that integrates a DRL model, a next-best-view (NBV) selection approach and a structural integrity measurement to further improve the exploration performance. At the end of this paper, we evaluate the proposed architecture against other methods on several new office maps, showing that the agent can efficiently explore uncertain regions with a shorter path and smarter behaviors.
ER  - 

TY  - CONF
TI  - Bayesian Optimization with Automatic Prior Selection for Data-Efficient Direct Policy Search
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7571
EP  - 7578
AU  - R. Pautrat
AU  - K. Chatzilygeroudis
AU  - J. Mouret
PY  - 2018
KW  - Bayes methods
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - manipulators
KW  - maximum likelihood estimation
KW  - motion control
KW  - optimisation
KW  - search problems
KW  - Most Likely Expected Improvement
KW  - 5DOF planar arm
KW  - 6-legged robot
KW  - transfer learning task
KW  - acquisition function
KW  - data-efficient direct policy search
KW  - automatic prior selection
KW  - Bayesian optimization
KW  - Optimization
KW  - Bayes methods
KW  - Legged locomotion
KW  - Task analysis
KW  - Predictive models
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8463197
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the most interesting features of Bayesian optimization for direct policy search is that it can leverage priors (e.g., from simulation or from previous tasks) to accelerate learning on a robot. In this paper, we are interested in situations for which several priors exist but we do not know in advance which one fits best the current situation. We tackle this problem by introducing a novel acquisition function, called Most Likely Expected Improvement (MLEI), that combines the likelihood of the priors and the expected improvement. We evaluate this new acquisition function on a transfer learning task for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has to learn to walk on flat ground and on stairs, with priors corresponding to different stairs and different kinds of damages. Our results show that MLEI effectively identifies and exploits the priors, even when there is no obvious match between the current situations and the priors.
ER  - 

TY  - CONF
TI  - Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7559
EP  - 7566
AU  - A. Nagabandi
AU  - G. Kahn
AU  - R. S. Fearing
AU  - S. Levine
PY  - 2018
KW  - computational complexity
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - predictive control
KW  - model-free learning
KW  - model-free fine-tuning
KW  - model-free deep reinforcement learning algorithms
KW  - model-based algorithms
KW  - model predictive control
KW  - model-based reinforcement learning algorithm
KW  - complex locomotion tasks
KW  - deep neural network dynamics models
KW  - model-free learner
KW  - model-based approaches
KW  - model-free methods
KW  - sample complexity
KW  - model-based deep reinforcement learning
KW  - robotic skills
KW  - MPC
KW  - plausible gaits
KW  - stable gaits
KW  - Task analysis
KW  - Predictive models
KW  - Neural networks
KW  - Data models
KW  - Heuristic algorithms
KW  - Machine learning
KW  - Complexity theory
DO  - 10.1109/ICRA.2018.8463189
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5× on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf.
ER  - 

TY  - CONF
TI  - Adapting Parameterized Motions Using Iterative Learning and Online Collision Detection
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7587
EP  - 7594
AU  - J. S. Laursen
AU  - L. C. Sorensen
AU  - U. P. Schultz
AU  - L. Ellekilde
AU  - D. Kraft
PY  - 2018
KW  - Bayes methods
KW  - collision avoidance
KW  - Gaussian processes
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - robotic assembly
KW  - servomotors
KW  - signal classification
KW  - iterative learning
KW  - online collision detection
KW  - robust robot system
KW  - uncertainty-tolerant motions
KW  - Gaussian Process learning
KW  - Bayesian Optimization
KW  - robot motor currents
KW  - assembly process
KW  - medium-sized productions
KW  - parameterized motions
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Robustness
KW  - Robotic assembly
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8463208
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Achieving both the flexibility and robustness required to advance the use of robotics in small and medium-sized productions is an essential but difficult task. A fundamental problem is making the robot run blindly without additional sensors while still being robust to uncertainties and variations in the assembly processes. In this paper, we address the use of parameterized motions suitable for blind execution and robust to uncertainties in the assembly process. Collisions and incorrect assemblies are detected based on robot motor currents while motion parameters are updated based on Bayesian Optimization utilizing Gaussian Process learning. This allows for motion parameters to be optimized using real world trials which incorporate all uncertainties inherent in the assembly process without requiring advanced robot and sensor setups. The result is a simple and straightforward system which helps the user automatically find robust and uncertainty-tolerant motions. We present experiments for an assembly case showing both detection and learning in the real world and how these combine to a robust robot system.
ER  - 

TY  - CONF
TI  - Trajectory Replanning for Quadrotors Using Kinodynamic Search and Elastic Optimization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7595
EP  - 7602
AU  - W. Ding
AU  - W. Gao
AU  - K. Wang
AU  - S. Shen
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - elasticity
KW  - helicopters
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - pipes
KW  - predictive control
KW  - quadratic programming
KW  - robot dynamics
KW  - robot kinematics
KW  - robot vision
KW  - search problems
KW  - splines (mathematics)
KW  - trajectory control
KW  - quadratically constrained quadratic programming problem
KW  - receding horizon replanner design
KW  - trajectory replanning
KW  - grid structure
KW  - dynamically feasible time-parameterized trajectory
KW  - B-spline based kinodynamic search algorithm
KW  - greedy search
KW  - B-spline parameterization
KW  - position-only shortest path search
KW  - monocular vision-based quadrotor
KW  - replanning system
KW  - local control property
KW  - expanded elastic tube
KW  - optimal control point placement
KW  - EO approach
KW  - RBK search
KW  - post-optimization process
KW  - elastic optimization approach
KW  - Splines (mathematics)
KW  - Trajectory
KW  - Optimization
KW  - Real-time systems
KW  - Process control
KW  - Planning
KW  - Complexity theory
DO  - 10.1109/ICRA.2018.8463188
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We focus on a replanning scenario for quadrotors where considering time efficiency, non-static initial state and dynamical feasibility is of great significance. We propose a real-time B-spline based kinodynamic (RBK) search algorithm, which transforms a position-only shortest path search (such as A * and Dijkstra) into an efficient kinodynamic search, by exploring the properties of B-spline parameterization. The RBK search is greedy and produces a dynamically feasible time-parameterized trajectory efficiently, which facilitates non-static initial state of the quadrotor. To cope with the limitation of the greedy search and the discretization induced by a grid structure, we adopt an elastic optimization (EO) approach as a post-optimization process, to refine the control point placement provided by the RBK search. The EO approach finds the optimal control point placement inside an expanded elastic tube which represents the free space, by solving a Quadratically Constrained Quadratic Programming (QCQP) problem. We design a receding horizon replanner based on the local control property of B-spline. A systematic comparison of our method against two state-of-the-art methods is provided. We integrate our replanning system with a monocular vision-based quadrotor and validate our performance onboard.
ER  - 

TY  - CONF
TI  - On Bisection Continuous Collision Checking Method: Spherical Joints and Minimum Distance to Obstacles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7613
EP  - 7619
AU  - S. Tarbouriech
AU  - W. Suleiman
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - bisection Continuous Collision checking method
KW  - spherical joints
KW  - Continuous Collision Detection method
KW  - tight motion bounds
KW  - sampling-based motion planning technique
KW  - Baxter research robot
KW  - minimum distance extension
KW  - obstacle minimum distance
KW  - robotic systems
KW  - Collision avoidance
KW  - Charge coupled devices
KW  - Planning
KW  - Computational modeling
KW  - Manipulators
KW  - Motion segmentation
DO  - 10.1109/ICRA.2018.8463199
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we adapt the Continuous Collision Detection (CCD) method proposed in [1] to efficiently handle the case of spherical and two revolute joints, this kind of joints is very common in modern robotic systems. The new formulations provide more tight motion bounds, thus increase the success rate of checking collision-free paths. We also propose an extension to get the minimum distance to obstacles along a path, this information is primordial as it allows sampling-based motion planning techniques to sort collision-free paths according to their minimum clearance. We have integrated our implementation into a sampling-based motion planning technique and validated it through simulation and on the real Baxter research robot. The experiments revealed that the method not only does not miss any collision between the robot and the obstacles, but also the minimum distance extension provides the path with the maximum clearance at no additional computational cost.
ER  - 

TY  - CONF
TI  - MPC-based Collision Avoidance Strategy for Existing Marine Vessel Guidance Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7618
EP  - 7623
AU  - I. B. Hagen
AU  - D. K. M. Kufoalor
AU  - E. F. Brekke
AU  - T. A. Johansen
PY  - 2018
KW  - collision avoidance
KW  - marine control
KW  - predictive control
KW  - MPC-based collision avoidance strategy
KW  - marine vessel guidance systems
KW  - COLREGS
KW  - MPC COLAV algorithm
KW  - simulation-based model predictive control
KW  - Collision avoidance
KW  - Computational modeling
KW  - Trajectory
KW  - Cost function
KW  - Mathematical model
KW  - Vehicle dynamics
KW  - Propulsion
DO  - 10.1109/ICRA.2018.8463182
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a viable approach for incorporating collision avoidance strategies into existing guidance and control systems on marine vessels. We propose a method that facilitates the use of simulation-based Model Predictive Control (MPC) for collision avoidance (COLAV) on marine vessels. Any COLAV strategy to be applied in real traffic must adhere to the international regulations for preventing collisions at sea (COLREGS). The proposed MPC COLAV method does not rely on an accurate model of the guidance system to achieve vessel behaviors that are compliant with the COLREGS. Rather, it depends on transitional costs in the MPC objective for collision avoidance maneuvers that are being executed by the marine vessel. Hence, it is straightforward to implement the MPC COLAV on different vessels without specific knowledge of the vessel's guidance strategy. Moreover, it offers the possibility to switch between different (possibly application specific) guidance strategies on the same vessel while running the same MPC COLAV algorithm. We present results from full scale experiments that show the viability of our method in different collision avoidance scenarios.
ER  - 

TY  - CONF
TI  - Avoidance of High-Speed Obstacles Based on Velocity Obstacles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7624
EP  - 7630
AU  - Z. Liu
AU  - Z. Jiang
AU  - T. Xu
AU  - H. Cheng
AU  - Z. Xie
AU  - L. Lin
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - velocity control
KW  - time horizon
KW  - obstacle avoidance algorithm
KW  - collision avoidance
KW  - two-period velocity obstacle algorithm
KW  - high-speed obstacles avoidance
KW  - mobile robots
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Prediction algorithms
KW  - Heuristic algorithms
KW  - Robot sensing systems
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8463200
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For obstacles moving with high speeds, existing motion planning methods can rarely guarantee collision avoidance. This paper proposes a viable two-period velocity obstacle algorithm where one period predicts potential collisions within a limited time horizon, and the second period foresees collisions beyond that horizon. The second period is activated only when the obstacle's moving speed is larger than the maximum speed of the robot. The applicability of the new algorithm and the related computation issues are discussed. Both computer simulations and laboratory experiments illustrated the effectiveness of the proposed obstacle avoidance algorithm.
ER  - 


