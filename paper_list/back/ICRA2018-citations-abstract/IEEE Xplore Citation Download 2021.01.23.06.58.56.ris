TY  - CONF
TI  - High-Speed Well-Focused Image-Capturing System for Moving Micro-Objects Based on Histograms of the Luminance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4790
EP  - 4795
AU  - T. Aoyama
AU  - M. Hanabishi
AU  - T. Takaki
AU  - I. Ishii
AU  - Y. Hasegawa
PY  - 2018
KW  - brightness
KW  - lenses
KW  - optical microscopes
KW  - high-speed well-focused image-capturing microscope system
KW  - luminance histogram-based algorithm
KW  - high-speed microobject system
KW  - vibration machine
KW  - microchannel
KW  - vision-based analysis systems
KW  - objective lens
KW  - size 10 mum to 100 mum
KW  - size 1 mum to 4 mum
KW  - Vibrations
KW  - Microscopy
KW  - Lenses
KW  - Histograms
KW  - Microchannels
KW  - Lighting
KW  - Machine vision
DO  - 10.1109/ICRA.2018.8461238
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In recent years, vision-based analysis systems of micro-objects in a microchannel have been actively developed. However, it is difficult to focus on high-speed micro-objects in a microchannel because the general height of a microchannel is approximately 10-100 μm, whereas the depth of focus of the objective lens is approximately 1-4 μm. Therefore, we propose a high-speed well-focused image-capturing microscope, which is a system with an objective lens attached to a vibration machine that moves the focus position rapidly by oscillating it up and down to capture well-focused images using a histogram-based algorithm. The proposed microscope system is verified experimentally to capture well-focused images of moving micro- objects.
ER  - 

TY  - CONF
TI  - Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4796
EP  - 4803
AU  - F. Ma
AU  - S. Karaman
PY  - 2018
KW  - image colour analysis
KW  - image reconstruction
KW  - image resolution
KW  - image sampling
KW  - image segmentation
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - mean square error methods
KW  - optical radar
KW  - random processes
KW  - regression analysis
KW  - SLAM (robots)
KW  - sparse matrices
KW  - prediction root-mean-square error
KW  - sparse maps
KW  - dense maps
KW  - sparse-to-dense
KW  - dense depth prediction
KW  - sparse set
KW  - depth measurements
KW  - single RGB image
KW  - depth estimation
KW  - monocular images
KW  - low-resolution depth sensor
KW  - single deep regression network
KW  - RGB-D raw data
KW  - sparse depth samples
KW  - visual simultaneous localization and mapping algorithms
KW  - plug-in module
KW  - NYU-depth-v2 indoor dataset
KW  - LiDARs
KW  - Training
KW  - Laser radar
KW  - Image reconstruction
KW  - Estimation
KW  - Prediction algorithms
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8460184
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the problem of dense depth prediction from a sparse set of depth measurements and a single RGB image. Since depth estimation from monocular images alone is inherently ambiguous and unreliable, to attain a higher level of robustness and accuracy, we introduce additional sparse depth samples, which are either acquired with a low-resolution depth sensor or computed via visual Simultaneous Localization and Mapping (SLAM) algorithms. We propose the use of a single deep regression network to learn directly from the RGB-D raw data, and explore the impact of number of depth samples on prediction accuracy. Our experiments show that, compared to using only RGB images, the addition of 100 spatially random depth samples reduces the prediction root-mean-square error by 50% on the NYU-Depth-v2 indoor dataset. It also boosts the percentage of reliable prediction from 59% to 92% on the KITTI dataset. We demonstrate two applications of the proposed algorithm: a plug-in module in SLAM to convert sparse maps to dense maps, and super-resolution for LiDARs. Software2 and video demonstration3 are publicly available.
ER  - 

TY  - CONF
TI  - Real-Time Object Tracking in Sparse Point Clouds Based on 3D Interpolation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4804
EP  - 4811
AU  - Y. Lee
AU  - S. Seo
PY  - 2018
KW  - estimation theory
KW  - image matching
KW  - interpolation
KW  - object detection
KW  - object tracking
KW  - statistical distributions
KW  - stereo image processing
KW  - target object clouds
KW  - sparse point clouds
KW  - point-to-distribution matching technique
KW  - tracking algorithm
KW  - 3D point clouds
KW  - direct point-to-point matching method
KW  - real-time object tracking
KW  - Estimation of Vertical Distributions
KW  - object-tracking strategy
KW  - EVD
KW  - interpolation method
KW  - 3D interpolation
KW  - Three-dimensional displays
KW  - Target tracking
KW  - Real-time systems
KW  - Solid modeling
KW  - Interpolation
KW  - Vehicle dynamics
KW  - Laser radar
DO  - 10.1109/ICRA.2018.8460639
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - While object tracking for 3D point clouds has been widely researched in recent years, most trackers employ a direct point-to-point matching method under the assumption that target object clouds are dense, although the method is not suitable for sparse point clouds. In this paper, we introduce a novel object-tracking strategy that enables even sparse point clouds to be tracked properly. The strategy involves estimating distributions, called as Estimation of Vertical Distributions (EVD), by the proposed interpolation method to augment data and by a point-to-distribution matching technique. The EVD step generates vertical distributions of unoccupied areas on a target object using the distributions of the occupied areas and then seeks the optimal solution through a coarse-to-fine grid search to guarantee real-time performance. In order to verify the proposed tracking algorithm, we have tested our tracker on real world data collected by our own platform, and the results have demonstrated that the tracker outperforms other trackers.
ER  - 

TY  - CONF
TI  - Robust Generalized Point Cloud Registration Using Hybrid Mixture Model
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4812
EP  - 4818
AU  - Z. Min
AU  - J. Wang
AU  - M. Q. -. Meng
PY  - 2018
KW  - computerised tomography
KW  - expectation-maximisation algorithm
KW  - Gaussian processes
KW  - image registration
KW  - medical image processing
KW  - mixture models
KW  - optimisation
KW  - probability
KW  - Gaussian mixture model
KW  - probabilistic approach
KW  - expectation-maximization algorithm
KW  - CT images
KW  - FMM
KW  - GMM
KW  - EM algorithm
KW  - optimization problem
KW  - Von-Mises-Fisher mixture model
KW  - robust point cloud registration method
KW  - hybrid mixture model
KW  - Three-dimensional displays
KW  - Mixture models
KW  - Iterative closest point algorithm
KW  - Robustness
KW  - Probabilistic logic
KW  - Gaussian mixture model
KW  - Point cloud registration
KW  - Von-Mises-Fisher distribution
KW  - Gaussian mixture model
DO  - 10.1109/ICRA.2018.8460825
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces a robust point cloud registration method which utilizes not only positional but also the orientation information at each point. The proposed method takes a probabilistic approach which forms the problem as a hybrid mixture model, in which a Von-Mises-Fisher mixture model (FMM) is adopted to model the orientation part and a gaussian mixture model (GMM) is used to represent the position part. When two point clouds are optimally registered, the correspondence is the maximum of the posterior probability of the overall mixture model. Expectation-Maximization (EM) algorithm has been adopted to solve the optimization problem in an iterative manner to find the optimal rotation and translation between two point clouds. Extensive experiments under different noise levels and different outlier ratios have been carried out on a dataset of the femur CT images. Comparison results show that the proposed method outperforms the state-of-the-art methods under most of the experimental conditions, which indicates the validity of our method.
ER  - 

TY  - CONF
TI  - Multi-Stage Suture Detection for Robot Assisted Anastomosis Based on Deep Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4826
EP  - 4833
AU  - Y. Hu
AU  - Y. Gu
AU  - J. Yang
AU  - G. Yang
PY  - 2018
KW  - blood vessels
KW  - convolution
KW  - image recognition
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - medical robotics
KW  - recurrent neural nets
KW  - surgery
KW  - thread centerline reconstruction
KW  - multistage suture detection
KW  - robot assisted anastomosis
KW  - deep learning
KW  - robust suture detection
KW  - suture augmentation
KW  - robotic-assisted surgery
KW  - fully convolutional neural networks
KW  - trainee suturing skill evaluation
KW  - curvilinear structure detector
KW  - Yarn
KW  - Instruction sets
KW  - Surgery
KW  - Splines (mathematics)
KW  - Image reconstruction
KW  - Robots
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461131
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The technique of robust suture detection is vital in many applications including trainee suturing skill evaluation, suture augmentation in robotic-assisted surgery and suture recognition for automatic suturing. Due to the complicated environment of surgery, the detection of a suture is challenged by high deformation and frequent occlusion. In this paper, we propose a deep multi-stage framework for suture detection. The fully convolutional neural networks are firstly used to predict a gradient map which not only serves as a segmentation mask, but also provides useful structure information for the following thread centerline reconstruction. An overlapping map is also predicted to improve the quality of the gradient map in self-intersection area. Based on the gradient map, multiple segments of the thread are extracted and linked to form the whole thread using a curvilinear structure detector. Experiments on two types of threads demonstrate that the proposed method is able to detect the thread with human level performance when the thread is no occlusion or under finite self-intersection.
ER  - 

TY  - CONF
TI  - Active Clothing Material Perception Using Tactile Sensing and Deep Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4842
EP  - 4849
AU  - W. Yuan
AU  - Y. Mo
AU  - S. Wang
AU  - E. H. Adelson
PY  - 2018
KW  - clothing
KW  - control engineering computing
KW  - convolution
KW  - feedforward neural nets
KW  - image sensors
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - tactile sensors
KW  - active clothing material perception
KW  - tactile sensing
KW  - deep learning
KW  - intelligent robot
KW  - robot system
KW  - object properties
KW  - common object category
KW  - external Kinect sensor
KW  - GelSight tactile sensor
KW  - tactile data
KW  - physical properties
KW  - durability
KW  - semantic properties
KW  - clothing properties
KW  - active tactile perception system
KW  - vision-touch system
KW  - robots
KW  - varied clothing related housework
KW  - convolutional neural networks
KW  - Clothing
KW  - Tactile sensors
KW  - Shape
KW  - Grippers
DO  - 10.1109/ICRA.2018.8461164
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Humans represent and discriminate the objects in the same category using their properties, and an intelligent robot should be able to do the same. In this paper, we build a robot system that can autonomously perceive the object properties through touch. We work on the common object category of clothing. The robot moves under the guidance of an external Kinect sensor, and squeezes the clothes with a GelSight tactile sensor, then it recognizes the 11 properties of the clothing according to the tactile data. Those properties include the physical properties, like thickness, fuzziness, softness and durability, and semantic properties, like wearing season and preferred washing methods. We collect a dataset of 153 varied pieces of clothes, and conduct 6616 robot exploring iterations on them. To extract the useful information from the high-dimensional sensory output, we applied Convolutional Neural Networks (CNN) on the tactile data for recognizing the clothing properties, and on the Kinect depth images for selecting exploration locations. Experiments show that using the trained neural networks, the robot can autonomously explore the unknown clothes and learn their properties. This work proposes a new framework for active tactile perception system with vision-touch system, and has potential to enable robots to help humans with varied clothing related housework.
ER  - 

TY  - CONF
TI  - Optimal Path Planning in Time-Varying Flows with Forecasting Uncertainties
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4857
EP  - 4864
AU  - D. Kularatne
AU  - H. Hajieghrary
AU  - M. Ani Hsieh
PY  - 2018
KW  - graph theory
KW  - marine control
KW  - Markov processes
KW  - optimisation
KW  - path planning
KW  - Markov decision process
KW  - uncertain flow model
KW  - ocean environment
KW  - time-varying flows
KW  - minimum energy paths
KW  - uncertain flow field
KW  - transition probability model
KW  - minimum expected cost path
KW  - graph search based method
KW  - minimum expected cost policy
KW  - marine environments
KW  - Path planning
KW  - Computational modeling
KW  - Oceans
KW  - Predictive models
KW  - Forecast uncertainty
KW  - Drag
DO  - 10.1109/ICRA.2018.8460221
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Uncertainties in flow models have to be explicitly considered for effective path planning in marine environments. In this paper, we present two methods to compute minimum expected cost policies and paths over an uncertain flow model. The first method based on a Markov Decision Process computes a minimum expected cost policy while the second graph search based method, computes a minimum expected cost path. A transition probability model is developed to compute the probability of transition from one state to another under a given action. In addition, a method to compute the expected cost of a path when it is executed in an uncertain flow field is also presented. The two methods are used to compute minimum energy paths in an ocean environment and the results are analyzed in simulations.
ER  - 

TY  - CONF
TI  - Topological Hotspot Identification for Informative Path Planning with a Marine Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4865
EP  - 4872
AU  - S. McCammon
AU  - G. A. Hollinger
PY  - 2018
KW  - computational geometry
KW  - graph theory
KW  - greedy algorithms
KW  - image segmentation
KW  - marine control
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - topological graph
KW  - greedy-coverage algorithm
KW  - informative path planning problem
KW  - topological hotspot identification
KW  - marine robot
KW  - topological map
KW  - biological hotspots
KW  - aquatic environment
KW  - Fast Marching-based Voronoi segmentation
KW  - scheduling problem
KW  - Path planning
KW  - Monitoring
KW  - Oceans
KW  - Robot sensing systems
KW  - Task analysis
KW  - Frequency modulation
DO  - 10.1109/ICRA.2018.8460652
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we present a novel method for constructing a topological map of biological hotspots in an aquatic environment using a Fast Marching-based Voronoi segmentation. Using this topological map, we develop a closed form solution to the scheduling problem for any single path through the graph. Searching over the space of all paths allows us to compute a maximally informative path that traverses a subset of the hotspots, given some budget. Using a greedy-coverage algorithm we can then compute an informative path. We evaluate our method in a set of simulated trials, both with randomly generated environments and a real-world environment. In these trials, we show that our method produces a topological graph which more accurately captures features in the environment than standard thresholding techniques. Additionally, We show that our method can improve the performance of a greedy-coverage algorithm in the informative path planning problem by guiding it to different informative areas to help it escape from local maxima.
ER  - 

TY  - CONF
TI  - Heterogeneous Multi-Robot System for Exploration and Strategic Water Sampling
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4873
EP  - 4880
AU  - S. Manjanna
AU  - A. Q. Li
AU  - R. N. Smith
AU  - I. Rekleitis
AU  - G. Dudek
PY  - 2018
KW  - ecology
KW  - hydrological equipment
KW  - hydrological techniques
KW  - microorganisms
KW  - multi-robot systems
KW  - remotely operated vehicles
KW  - reservoirs
KW  - water quality
KW  - data-driven behavior
KW  - real geophysical data
KW  - MODIS measurements
KW  - water-sampling apparatus
KW  - water quality sensor
KW  - plankton-rich water samples
KW  - chlorophyll density
KW  - autonomous surface vehicles plan
KW  - water-sampling behavior
KW  - efficient measurement
KW  - fresh-water systems
KW  - measuring contamination levels
KW  - drinking water
KW  - physical sampling
KW  - strategic water sampling
KW  - heterogeneous multirobot system
KW  - water reservoir
KW  - explorer robot
KW  - water sampling apparatus
KW  - ASV
KW  - Pollution measurement
KW  - Geophysical measurements
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Time measurement
KW  - Water pollution
DO  - 10.1109/ICRA.2018.8460759
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Physical sampling of water for off-site analysis is necessary for many applications like monitoring the quality of drinking water in reservoirs, understanding marine ecosystems, and measuring contamination levels in fresh-water systems. In this paper, the focus is on algorithms for efficient measurement and sampling using a multi-robot, data-driven, water-sampling behavior, where autonomous surface vehicles plan and execute water sampling using the chlorophyll density as a cue for plankton-rich water samples. We use two Autonomous Surface Vehicles (ASVs), one equipped with a water quality sensor and the other equipped with a water-sampling apparatus. The ASV with the sensor acts as an explorer, measuring and building a spatial map of chlorophyll density in the given region of interest. The ASV equipped with the water sampling apparatus makes decisions in real time on where to sample the water based on the suggestions made by the explorer robot. We evaluate the system in the context of measuring chlorophyll distributions. We do this both in simulation based on real geophysical data from MODIS measurements, and on real robots in a water reservoir. We demonstrate the effectiveness of the proposed approach in several ways including in terms of mean error in the interpolated data as a function of distance traveled.
ER  - 

TY  - CONF
TI  - Extended Kalman Filter-Based 3D Active-Alignment Control for LED Communication
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4881
EP  - 4888
AU  - P. Bhanu Solanki
AU  - X. Tan
PY  - 2018
KW  - Kalman filters
KW  - light emitting diodes
KW  - mobile robots
KW  - optical communication
KW  - extended Kalman filter
KW  - proportional-integral controller
KW  - receiver-transmitter line
KW  - active alignment control system
KW  - transmitting device
KW  - active alignment system
KW  - mobile robots
KW  - Line-Of-Sight
KW  - underwater communication
KW  - optical communication
KW  - LED communication
KW  - active-alignment control
KW  - Receivers
KW  - Transmitters
KW  - Light emitting diodes
KW  - Robots
KW  - Three-dimensional displays
KW  - Estimation
KW  - Optical fiber communication
DO  - 10.1109/ICRA.2018.8460949
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - LED-based optical communication is emerging as a low-cost, high-data-rate alternative to the traditional acoustics mode of underwater communication. However, it is challenging to establish and maintain Line-Of-Sight (LOS) between the receiver and the transmitter, especially when such systems are used by mobile robots. Hence, there is a need for an active alignment system that enables the receiver to constantly align itself towards the direction of the transmitting device. In this paper, we propose and implement an active alignment control system capable of tracking a transmitting source moving in the three-dimensional (3D) space. An extended Kalman filter is used to estimate the components of the angle between the receiver orientation and the receiver-transmitter line. Using the estimate, a proportional-integral (PI) controller is implemented to adjust the receiver orientation. The algorithm uses one measurement of the light intensity from a single photo-diode, where successive measurements are obtained via a circular scanning technique. The amplitude of the scanning is adapted to the alignment performance, to achieve a sound trade-off between estimation accuracy, signal strength, and energy consumption. Simulation and experimental results are presented to illustrate the effectiveness of the proposed approach.
ER  - 

TY  - CONF
TI  - Robust Model-Aided Inertial Localization for Autonomous Underwater Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4889
EP  - 4896
AU  - S. Arnold
AU  - L. Medagoda
PY  - 2018
KW  - autonomous underwater vehicles
KW  - C++ language
KW  - drag
KW  - inertial navigation
KW  - Kalman filters
KW  - marine navigation
KW  - nonlinear filters
KW  - vehicle model parameter error
KW  - ADCP-aiding
KW  - DVL bottom-lock loss
KW  - IMU biases
KW  - navigation filter
KW  - DVL dropouts
KW  - robust model-aided inertial localization
KW  - autonomous underwater vehicles
KW  - Unscented Kalman Filter
KW  - inertial model-aiding
KW  - Acoustic Doppler Current Profiler measurement incorporation
KW  - Earth rotation
KW  - tactical grade IMU
KW  - heading convergence
KW  - data denial
KW  - drag
KW  - thrust model
KW  - MTK
KW  - ROCK
KW  - FlatFish AUV
KW  - Navigation
KW  - Mathematical model
KW  - Accelerometers
KW  - Damping
KW  - Uncertainty
KW  - Acoustics
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8460839
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a manifold based Unscented Kalman Filter that applies a novel strategy for inertial, model-aiding and Acoustic Doppler Current Profiler (ADCP) measurement incorporation. The filter is capable of observing and utilizing the Earth rotation for heading estimation with a tactical grade IMU, and utilizes information from the vehicle model during DVL drop outs. The drag and thrust model-aiding accounts for the correlated nature of vehicle model parameter error by applying them as states in the filter. ADCP-aiding provides further information for the model-aiding in the case of DVL bottom-lock loss. Additionally this work was implemented using the MTK and ROCK framework in C++, and is capable of running in real-time on computing available on the FlatFish AUV. The IMU biases are estimated in a fully coupled approach in the navigation filter. Heading convergence is shown on a real-world data set. Further experiments show that the filter is capable of consistent positioning, and data denial validates the method for DVL dropouts due to very low or high altitude scenarios.
ER  - 

TY  - CONF
TI  - Preliminary Evaluation of Cooperative Navigation of Underwater Vehicles without a DVL Utilizing a Dynamic Process Model
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4897
EP  - 4904
AU  - Z. J. Harris
AU  - L. L. Whitcomb
PY  - 2018
KW  - attitude control
KW  - autonomous underwater vehicles
KW  - Global Positioning System
KW  - marine control
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - sensors
KW  - velocity measurement
KW  - preliminary evaluation
KW  - dynamic process model
KW  - fully dynamic vehicle process model
KW  - acoustic modem
KW  - surface vehicle
KW  - at-sea experimental trials
KW  - JHU Iver3 autonomous underwater vehicle
KW  - underwater vehicle navigation
KW  - DVL acoustic bottom-lock range
KW  - kinematic process model
KW  - dynamical process model
KW  - submerged vehicle
KW  - underwater communication
KW  - velocity measurements
KW  - attitude sensor
KW  - Acoustics
KW  - Underwater vehicles
KW  - Kinematics
KW  - Global Positioning System
KW  - Sensors
DO  - 10.1109/ICRA.2018.8460970
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper reports a preliminary study for use of a fully dynamic vehicle process model in combined underwater communication and navigation (cooperative navigation) of underwater vehicles equipped with an acoustic modem, attitude, and depth sensors, but lacking a Doppler velocity log (DVL), and a surface vehicle equipped with an acoustic modem and GPS. We report both simulation and at-sea experimental trials with the JHU Iver3 autonomous underwater vehicle (AUV). The case of underwater vehicle navigation without a DVL is of interest in several use-cases including (a) small and low-cost underwater vehicles for which DVLs may be impractical or infeasible due to their size and cost and (b) for missions in which the vehicle's altitude above the sea floor (or depth beneath overhead ice) exceeds the DVL acoustic bottom-lock range. To the best of our knowledge, all previous studies on cooperative navigation have reported use of a kinematic process model, which works well in the presence of frequent, high-accuracy velocity measurements, as is the case when the vehicle is equipped with a DVL. This preliminary study suggests that the dynamical process model may offer a significant advantage over the purely kinematic model in the absence of frequent, high-accuracy velocity measurements, as is the case when the submerged vehicle is not equipped with a DVL.
ER  - 

TY  - CONF
TI  - Self-Calibration of Mobile Manipulator Kinematic and Sensor Extrinsic Parameters Through Contact-Based Interaction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4913
EP  - 4920
AU  - O. Limoyo
AU  - T. Ablett
AU  - F. Marić
AU  - L. Volpatti
AU  - J. Kelly
PY  - 2018
KW  - calibration
KW  - computer graphics
KW  - end effectors
KW  - image registration
KW  - image sensors
KW  - manipulator kinematics
KW  - mobile robots
KW  - robot vision
KW  - mobile manipulator platform
KW  - mobile manipulator kinematic parameters
KW  - calibration rigs
KW  - centimetre-level post-calibration accuracy
KW  - end effector
KW  - registration algorithm
KW  - sensor extrinsic parameters
KW  - contact-based interaction
KW  - mobile manipulator self-calibration
KW  - point cloud registration
KW  - fixed vision sensor
KW  - mobile base
KW  - sensor calibration
KW  - manipulator kinematic model parameters
KW  - nonrigid registration process
KW  - on-board sensing
KW  - external measurement devices
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Manipulators
KW  - Calibration
KW  - Cameras
KW  - Kinematics
KW  - Transforms
DO  - 10.1109/ICRA.2018.8460658
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a novel approach for mobile manipulator self-calibration using contact information. Our method, based on point cloud registration, is applied to estimate the extrinsic transform between a fixed vision sensor mounted on a mobile base and an end effector. Beyond sensor calibration, we demonstrate that the method can be extended to include manipulator kinematic model parameters, which involves a nonrigid registration process. Our procedure uses on-board sensing exclusively and does not rely on any external measurement devices, fiducial markers, or calibration rigs. Further, it is fully automatic in the general case. We experimentally validate the proposed method on a custom mobile manipulator platform, and demonstrate centimetre-level post-calibration accuracy in positioning of the end effector using visual guidance only. We also discuss the stability properties of the registration algorithm, in order to determine the conditions under which calibration is possible.
ER  - 

TY  - CONF
TI  - Geometry Based Self Kinematic Calibration Method for Industrial Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4921
EP  - 4926
AU  - T. Messay-Kebede
AU  - G. Sutton
AU  - O. Djaneye-Boundjou
PY  - 2018
KW  - calibration
KW  - coordinate measuring machines
KW  - geometry
KW  - industrial robots
KW  - particle swarm optimisation
KW  - robot kinematics
KW  - industrial setting
KW  - kinematic calibration methodology
KW  - external metrology device
KW  - kinematic calibration model
KW  - optimal parameters/characteristics
KW  - Particle Swarm Optimization technique
KW  - Coordinate Measurement Machine
KW  - PSO
KW  - CMM
KW  - Yaskawa Motoman MHS-Hi robot
KW  - Yaskawa Motoman MHS-Hi robot
KW  - industrial robots
KW  - geometry based self kinematic calibration method
KW  - anthropomorphic robots
KW  - Robot kinematics
KW  - Calibration
KW  - Probes
KW  - Metrology
KW  - Bars
KW  - Data acquisition
DO  - 10.1109/ICRA.2018.8460764
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Accuracy of robots is an important facet in an industrial setting. In this paper, we present a novel kinematic calibration methodology. Traditional calibration techniques require an external metrology device. Unlike those, the presented product here is highly practical in that it does not require a metrology device. The kinematic calibration model is formulated by making use of the robot itself as a metrology device to measure the geometry of a known artifact. The optimal parameters/characteristics of the model are identified using a Particle Swarm Optimization (PSO) technique. Our experimental results show that this new approach provides results comparable to those generated using spatial information provided by a Coordinate Measurement Machine (CMM). Using this new approach (GageCAL), the Yaskawa Motoman “MHS-Hi” robot is calibrated. Our experimental testing also indicates that this methodology can be extended to a wide variety of anthropomorphic robots.
ER  - 

TY  - CONF
TI  - Inertial Parameters Identification of a Humanoid Robot Hanged to a Fix Force Sensor
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4927
EP  - 4932
AU  - V. Bonnet
AU  - A. Crosnier
AU  - G. Venture
AU  - M. Gautier
AU  - P. Fraisse
PY  - 2018
KW  - CAD
KW  - force sensors
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - parameter estimation
KW  - path planning
KW  - robot dynamics
KW  - fix force sensor
KW  - model-based controller
KW  - motion planning
KW  - dynamic identification
KW  - dynamic motions
KW  - safe fix base tree structure robot
KW  - optimal exciting motions
KW  - HOAP3 humanoid robot
KW  - 6-axis force sensor
KW  - computer aided design data
KW  - inertial parameter identification
KW  - Humanoid robots
KW  - Force sensors
KW  - Dynamics
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Optimization
DO  - 10.1109/ICRA.2018.8461112
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Knowledge of the mass and inertial parameters of a humanoid robot is crucial for the development of model-based controller and motion planning in dynamics situation. Parameters are usually provided from Computer Aided Design (CAD) data and thus inaccurate specially if the robot is modified over time. In this paper, a practical method consisting of hanging a humanoid robot to a fix force sensor to perform its dynamic identification is proposed. This allows, contrary to the literature, to generate very exciting and dynamic motions to identify most of the elements of the inertia tensors in a reduced amount of time. This procedure transforms an instable floating base legged humanoid robot to a safe fix base tree structure robot which makes easier to generate optimal exciting motions. Because of a better excitation the overall trajectory lasts for less than a minute. The method was experimentally validated with a HOAP3 humanoid robot and using a 6-axis force sensor. A reduction of 3 times in average of the RMS difference between measured external reaction forces and moments and their estimates from CAD data was obtained with a single minute of optimal exciting motions.
ER  - 

TY  - CONF
TI  - Online System Identification and Calibration of Dynamic Models for Autonomous Ground Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4933
EP  - 4939
AU  - S. Aghli
AU  - C. Heckman
PY  - 2018
KW  - calibration
KW  - mobile robots
KW  - vehicles
KW  - wheels
KW  - high-fidelity dynamical model
KW  - constant time algorithm
KW  - autonomous ground vehicles
KW  - dynamic models
KW  - online system identification
KW  - scale four wheel drive vehicle
KW  - estimated parameter
KW  - model parameters
KW  - informative motion segments
KW  - robotic platform
KW  - Calibration
KW  - Vehicle dynamics
KW  - Motion segmentation
KW  - Dynamics
KW  - Wheels
KW  - Friction
DO  - 10.1109/ICRA.2018.8460691
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper is concerned with system identification and the calibration of parameters of dynamic models used in different robotic platforms. A constant time algorithm has been developed in order to automatically calibrate the parameters of a high-fidelity dynamical model for a robotic platform. The presented method is capable of choosing informative motion segments in order to calibrate model parameters in constant time while also calculating a confidence level on each estimated parameter. Simulations and experiments with a ⅛ th scale four wheel drive vehicle are performed to calibrate two of the parameters of test vehicle which demonstrate the accuracy and efficiency of the approach.
ER  - 

TY  - CONF
TI  - On Geometric Models and Their Accuracy for Extrinsic Sensor Calibration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4948
EP  - 4954
AU  - K. Huang
AU  - C. Stachniss
PY  - 2018
KW  - calibration
KW  - geometry
KW  - numerical analysis
KW  - sensors
KW  - extrinsic sensor calibration methods
KW  - robotics
KW  - numerical simulation
KW  - abstract geometric model
KW  - Calibration
KW  - Cameras
KW  - Estimation
KW  - Task analysis
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8461029
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Extrinsic sensor calibration is an important task in robotics. There are various ways to perform the calibration task, but it often remains unclear which methods are better than the others. In this paper, we provide a systematic study about the calibration accuracy of three types of calibration methods, each represented by an abstract geometric model based on the sensor configuration and the calibration setup. We discuss the advantages and disadvantages of each model and perform a rigorous study on their noise sensitivity from a geometric perspective. As a result, we can reveal and quantify the relative calibration accuracies of the three models, thus answering the question of “which model is better and why?”. Beside our analytical analysis, we also provide numerical simulation experiments that validate our findings.
ER  - 

TY  - CONF
TI  - Dynamic Modeling and Identification of an Heterogeneously Actuated Underwater Manipulator Arm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4955
EP  - 4960
AU  - F. Leborne
AU  - V. Creuze
AU  - A. Chemori
AU  - L. Brignone
PY  - 2018
KW  - actuators
KW  - autonomous underwater vehicles
KW  - gears
KW  - manipulators
KW  - mobile robots
KW  - position control
KW  - telerobotics
KW  - arms parameters
KW  - linear actuators
KW  - identification procedure
KW  - manipulator arms
KW  - dynamic modeling
KW  - heterogeneously actuated underwater manipulator arm
KW  - electrically driven underwater robot manipulator
KW  - Ifremer's HROV Ariane underwater vehicle
KW  - hybrid remotely operated vehicle
KW  - Manipulator dynamics
KW  - Actuators
KW  - Vehicle dynamics
KW  - Gears
KW  - Friction
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8460963
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper deals with the dynamic modeling and identification of an electrically driven underwater robot manipulator. The proposed study includes the dynamic modeling of the actuators of the arm as well as the identification of the parameters of the model. The proposed method deals with the specific case of heterogeneously actuated arms, namely arms with actuators behaving differently for each joint, being considered at the kinematic level. Indeed, we show how to estimate the arms parameters when some of their revolute joints are directly actuated by geared motors, while the others are actuated by linear actuators. A minimum set of identifiable parameters is determined, and adequate excitation trajectories are generated and used in the identification procedure. Realtime experimental validation on the manipulator arms of Ifremer's HROV (Hybrid Remotely Operated Vehicle) Ariane underwater vehicle demonstrates that the proposed method improves the estimation of the dynamic model.
ER  - 

TY  - CONF
TI  - A General Framework for Flexible Multi-Cue Photometric Point Cloud Registration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4969
EP  - 4976
AU  - B. Della Corte
AU  - I. Bogoslavskyi
AU  - C. Stachniss
AU  - G. Grisetti
PY  - 2018
KW  - image registration
KW  - image sensors
KW  - mobile robots
KW  - sensor fusion
KW  - flexible framework
KW  - general framework
KW  - explicit data association
KW  - flexible multicue photometric point cloud registration
KW  - mobile robots
KW  - mapping systems
KW  - recorded sensor data
KW  - photometric registration
KW  - multiple modalities
KW  - image data streams
KW  - pixel-wise difference
KW  - multichannel images
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Cameras
KW  - Iterative closest point algorithm
KW  - Minimization
KW  - Integrated circuit modeling
KW  - Laser radar
DO  - 10.1109/ICRA.2018.8461049
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The ability to build maps is a key functionality for the majority of mobile robots. A central ingredient to most mapping systems is the registration or alignment of the recorded sensor data. In this paper, we present a general methodology for photometric registration that can deal with multiple different cues. We provide examples for registering RGBD as well as 3D LIDAR data. In contrast to popular point cloud registration approaches such as ICP our method does not rely on explicit data association and exploits multiple modalities such as raw range and image data streams. Color, depth, and normal information are handled in an uniform manner and the registration is obtained by minimizing the pixel-wise difference between two multi-channel images. We developed a flexible and general framework and implemented our approach inside that framework. We also released our implementation as open source C++ code. The experiments show that our approach allows for an accurate registration of the sensor data without requiring an explicit data association or model-specific adaptations to datasets or sensors. Our approach exploits the different cues in a natural and consistent way and the registration can be done at framerate for a typical range or imaging sensor.
ER  - 

TY  - CONF
TI  - Just-in-Time Reconstruction: Inpainting Sparse Maps Using Single View Depth Predictors as Priors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4977
EP  - 4984
AU  - C. S. Weerasekera
AU  - T. Dharmasiri
AU  - R. Garg
AU  - T. Drummond
AU  - I. Reid
PY  - 2018
KW  - convolution
KW  - feature extraction
KW  - image colour analysis
KW  - image fusion
KW  - image reconstruction
KW  - image sensors
KW  - iterative methods
KW  - neural nets
KW  - pose estimation
KW  - recurrent neural nets
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - CRF model
KW  - RGB image
KW  - confidence-based fusion
KW  - realtime inpainting
KW  - convolutional neural networks
KW  - CNN
KW  - ORB-SLAM
KW  - Kinect
KW  - conditional depth error distributions
KW  - pixel-wise confidence weights
KW  - input depth map
KW  - fused depth map
KW  - virtual depth sensor
KW  - single-view depth prediction network
KW  - sparse sensor
KW  - monocular visual SLAM system
KW  - fully dense depth map
KW  - realtime image-guided inpainting
KW  - just-in-time reconstruction
KW  - single view depth predictors
KW  - scale-invariant depth error
KW  - outlier input depth
KW  - LIDAR depth maps
KW  - arbitrary scale
KW  - sparse map
KW  - Image reconstruction
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Three-dimensional displays
KW  - Real-time systems
KW  - Uncertainty
DO  - 10.1109/ICRA.2018.8460549
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present “just-in-time reconstruction” as realtime image-guided inpainting of a map with arbitrary scale and sparsity to generate a fully dense depth map for the image. In particular, our goal is to inpaint a sparse map - obtained from either a monocular visual SLAM system or a sparse sensor - using a single-view depth prediction network as a virtual depth sensor. We adopt a fairly standard approach to data fusion, to produce a fused depth map by performing inference over a novel fully-connected Conditional Random Field (CRF) which is parameterized by the input depth maps and their pixel-wise confidence weights. Crucially, we obtain the confidence weights that parameterize the CRF model in a data-dependent manner via Convolutional Neural Networks (CNNs) which are trained to model the conditional depth error distributions given each source of input depth map and the associated RGB image. Our CRF model penalises absolute depth error in its nodes and pairwise scale-invariant depth error in its edges, and the confidence-based fusion minimizes the impact of outlier input depth values on the fused result. We demonstrate the flexibility of our method by real-time inpainting of ORB-SLAM, Kinect, and LIDAR depth maps acquired both indoors and outdoors at arbitrary scale and varied amount of irregular sparsity.
ER  - 

TY  - CONF
TI  - Fast Global Labelling for Depth-Map Improvement Via Architectural Priors
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4985
EP  - 4992
AU  - P. Amayo
AU  - P. Piniés
AU  - L. M. Paz
AU  - P. Newman
PY  - 2018
KW  - cameras
KW  - image reconstruction
KW  - spatial variables measurement
KW  - cameras
KW  - planar extraction
KW  - urban environment
KW  - vision-only method
KW  - depth map estimation techniques
KW  - fast global labelling
KW  - Labeling
KW  - Estimation
KW  - Minimization
KW  - Image reconstruction
KW  - Cameras
KW  - Pipelines
KW  - Surface texture
DO  - 10.1109/ICRA.2018.8460192
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Depth map estimation techniques from cameras often struggle to accurately estimate the depth of large textureless regions. In this work we present a vision-only method that accurately extracts planar priors from a viewed scene without making any assumptions of the underlying scene layout. Through a fast global labelling, these planar priors can be associated to the individual pixels leading to more complete depth-maps specifically over large, plain and planar regions that tend to dominate the urban environment. When these depth-maps are deployed to the creation of a vision only dense reconstruction over large scales, we demonstrate reconstructions that yield significantly better results in terms of coverage while still maintaining high accuracy.
ER  - 

TY  - CONF
TI  - A Method to Segment Maps from Different Modalities Using Free Space Layout MAORIS: Map of Ripples Segmentation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 4993
EP  - 4999
AU  - M. Mielle
AU  - M. Magnusson
AU  - A. J. Lilienthal
PY  - 2018
KW  - computational geometry
KW  - convolution
KW  - image segmentation
KW  - robot vision
KW  - hand-drawn sketch maps
KW  - segmentation evaluation metric
KW  - ground-truth segmentations
KW  - Voronoi-based segmentation method
KW  - DuDe segmentation method
KW  - ground truth segmentations
KW  - segment maps
KW  - free space layout MAORIS
KW  - navigation maps
KW  - semantic representations
KW  - convolution
KW  - circular kernel
KW  - ripple-like patterns
KW  - Matthews correlation coefficient
KW  - map of ripples segmentation
KW  - Image segmentation
KW  - Merging
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Measurement
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2018.8461128
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - How to divide floor plans or navigation maps into semantic representations, such as rooms and corridors, is an important research question in fields such as human-robot interaction, place categorization, or semantic mapping. While most works focus on segmenting robot built maps, those are not the only types of map a robot, or its user, can use. We present a method for segmenting maps from different modalities, focusing on robot built maps and hand-drawn sketch maps, and show better results than state of the art for both types. Our method segments the map by doing a convolution between the distance image of the map and a circular kernel, and grouping pixels of the same value. Segmentation is done by detecting ripple-like patterns where pixel values vary quickly, and merging neighboring regions with similar values. We identify a flaw in the segmentation evaluation metric used in recent works and propose a metric based on Matthews correlation coefficient (MCC). We compare our results to ground-truth segmentations of maps from a publicly available dataset, on which we obtain a better MCC than the state of the art with 0.98 compared to 0.65 for a recent Voronoi-based segmentation method and 0.70 for the DuDe segmentation method. We also provide a dataset of sketches of an indoor environment, with two possible sets of ground truth segmentations, on which our method obtains an MCC of 0.56 against 0.28 for the Voronoi-based segmentation method and 0.30 for DuDe.
ER  - 

TY  - CONF
TI  - Efficient Continuous-Time SLAM for 3D Lidar-Based Online Mapping
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5000
EP  - 5007
AU  - D. Droeschel
AU  - S. Behnke
PY  - 2018
KW  - continuous time systems
KW  - entropy
KW  - graph theory
KW  - image registration
KW  - image resolution
KW  - laser ranging
KW  - optical radar
KW  - SLAM (robots)
KW  - solid modelling
KW  - stereo image processing
KW  - laser-range scanners
KW  - high data rate
KW  - 3D laser scanner
KW  - surfel-based registration
KW  - recursive state estimation
KW  - multiresolution maps
KW  - continuous-time SLAM
KW  - 3D lidar-based online mapping
KW  - online simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Measurement by laser beam
KW  - Optimization
KW  - Trajectory
KW  - Laser modes
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8461000
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Modern 3D laser-range scanners have a high data rate, making online simultaneous localization and mapping (SLAM) computationally challenging. Recursive state estimation techniques are efficient but commit to a state estimate immediately after a new scan is made, which may lead to misalignments of measurements. We present a 3D SLAM approach that allows for refining alignments during online mapping. Our method is based on efficient local mapping and a hierarchical optimization back-end. Measurements of a 3D laser scanner are aggregated in local multiresolution maps by means of surfel-based registration. The local maps are used in a multi-level graph for allocentric mapping and localization. In order to incorporate corrections when refining the alignment, the individual 3D scans in the local map are modeled as a sub-graph and graph optimization is performed to account for drift and misalignments in the local maps. Furthermore, in each sub-graph, a continuous-time representation of the sensor trajectory allows to correct measurements between scan poses. We evaluate our approach in multiple experiments by showing qualitative results. Furthermore, we quantify the map quality by an entropy-based measure.
ER  - 

TY  - CONF
TI  - Efficient Mobile Robot Exploration with Gaussian Markov Random Fields in 3D Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5015
EP  - 5021
AU  - C. Wang
AU  - T. Li
AU  - M. Q. -. Meng
AU  - C. De Silva
PY  - 2018
KW  - computer graphics
KW  - Gaussian processes
KW  - indoor environment
KW  - Markov processes
KW  - mobile robots
KW  - sampling methods
KW  - efficient computation algorithm
KW  - GMRF model hyperparameters
KW  - information gain
KW  - efficient mobile robot exploration
KW  - autonomous exploration
KW  - unknown indoor environments
KW  - mutual information
KW  - MI
KW  - informative sensing location
KW  - sampling method
KW  - random sensing patches
KW  - sensing patch
KW  - informative locations
KW  - training sample patches
KW  - established GMRF model
KW  - Gaussian Markov random fields
KW  - Gaussian process model
KW  - Robot sensing systems
KW  - Computational modeling
KW  - Mathematical model
KW  - Training
KW  - Mutual information
DO  - 10.1109/ICRA.2018.8460788
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we study the problem of autonomous exploration in unknown indoor environments using mobile robot. We use mutual information (MI) to evaluate the information the robot would get at a certain location. In order to get the most informative sensing location, we first propose a sampling method that can get random sensing patches in free space. Each sensing patch is extended to informative locations to collect information with true values. Then we use Gaussian Markov Random Fields (GMRF) to model the distribution of MI in environment. Compared with the traditional methods that employ Gaussian Process (GP) model, GMRF is more efficient. MI of every sensing location can be estimated using the training sample patches and the established GMRF model. We utilize an efficient computation algorithm to estimate the GMRF model hyperparameters so as to speed up the computation. Besides the information gain of the candidates regions, the path cost is also considered in this work. We propose a utility function that can balance the path cost and the information gain the robot would collect. We tested our algorithm in both simulated and real experiment. The experiment results demonstrate that our proposed method can explore the environment efficiently with relatively shorter path length.
ER  - 

TY  - CONF
TI  - A Scalable Multi-Robot Task Allocation Algorithm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5022
EP  - 5027
AU  - C. Sarkar
AU  - H. S. Paul
AU  - A. Pal
PY  - 2018
KW  - computational complexity
KW  - industrial robots
KW  - mobile robots
KW  - multi-robot systems
KW  - nearest neighbour methods
KW  - pattern clustering
KW  - vehicle routing
KW  - warehouse automation
KW  - CVRP instance
KW  - nCAR
KW  - scalable multirobot task allocation algorithm
KW  - modern warehouses
KW  - docking station
KW  - route planning
KW  - capacity-constrained vehicle routing problem
KW  - nearest-neighbor based clustering and routing
KW  - Task analysis
KW  - Heuristic algorithms
KW  - Clustering algorithms
KW  - Resource management
KW  - Routing
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460886
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In modern warehouses, robots are being deployed to perform complex tasks such as fetching a set of objects from various locations in a warehouse to a docking station. This requires a careful task allocation along with route planning such that the total distance traveled (cost) is minimized. The number of tasks that can be performed by a robot on a single route depends on the maximum capacity of the robot and the combined weight of the objects it picks on the route. This task allocation problem is an instance of the Capacity-constrained Vehicle Routing Problem (CVRP), which is known to be NP-hard. Although, there exist a number of heuristics that provide near-optimal solutions to a CVRP instance, they do not scale well with the task size (number of nodes). In this paper, we present a heuristic, called nearest-neighbor based Clustering And Routing (nCAR), which has better execution time compared to the state-of-the-art heuristics. Also, our heuristic reduces cost of the solutions when there are a large number of nodes. We compare the performance of nCAR with the Google OR-Tools and found a speedup of 6 in runtime when task size is 2000. Though OR-Tools provides a low-cost solution for small number of tasks, it's execution time and number of routes is 1.5 times that of nCAR.
ER  - 

TY  - CONF
TI  - Distributed Intermittent Communication Control of Mobile Robot Networks Under Time-Critical Dynamic Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5028
EP  - 5033
AU  - Y. Kantaros
AU  - M. M. Zavlanos
PY  - 2018
KW  - control engineering computing
KW  - distributed control
KW  - mobile robots
KW  - multi-robot systems
KW  - protocols
KW  - scheduling
KW  - time-critical dynamic tasks
KW  - offline schedules
KW  - mobile robot networks
KW  - distributed intermittent communication control
KW  - task accomplishment
KW  - task planning
KW  - communication events
KW  - distributed control framework
KW  - communication constraints
KW  - intermittent communication protocols
KW  - connected networks
KW  - reliable networks
KW  - robot communication capabilities
KW  - Task analysis
KW  - Robot sensing systems
KW  - Time factors
KW  - Schedules
KW  - Communication networks
DO  - 10.1109/ICRA.2018.8460570
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we develop a distributed intermittent communication framework for teams of mobile robots that are responsible for accomplishing time-critical dynamic tasks and sharing the collected information with all other robots and possibly also with a user. Specifically, we consider situations where the robot communication capabilities are not sufficient to maintain reliable and connected networks while the robots move to accomplish their tasks. In this case, intermittent communication protocols are necessary that allow the robots to temporarily disconnect from the network in order to accomplish their tasks free of communication constraints. We assume that the robots can only communicate with each other when they meet at common locations in space. Our proposed distributed control framework determines offline schedules of communication events and integrates them online with task planning. The resulting paths ensure task accomplishment and exchange of information among robots infinitely often at locations that minimize a user-specified metric. Simulation results corroborate the proposed distributed control framework.
ER  - 

TY  - CONF
TI  - Landmark-based Exploration with Swarm of Resource Constrained Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5034
EP  - 5041
AU  - R. Ramaithititima
AU  - S. Bhattacharya
PY  - 2018
KW  - distance measurement
KW  - Global Positioning System
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - robot vision
KW  - sensor fusion
KW  - landmark-based exploration
KW  - resource constrained robots
KW  - autonomous exploration
KW  - topological representation
KW  - topological information
KW  - exploitation strategy
KW  - robot swarm
KW  - GPS-denied environment
KW  - sensing capabilities
KW  - range sensor
KW  - dense landmarks
KW  - bearing angles
KW  - metric information
KW  - local navigation
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Navigation
KW  - Dispersion
KW  - Measurement
DO  - 10.1109/ICRA.2018.8460884
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we consider the problem of autonomous exploration of an unknown, GPS-denied environment using a swarm of robots with very limited resources and limited sensing capabilities. To that end we use a landmark complex, a simplicial complex utilizing an observation of landmarks, as a topological representation of the environment. Each robot is equipped with an omni-directional, limited-range sensor that can identify landmarks in the robot's neighborhood. The robots use the bearing angles to the landmarks for local navigation. Given a collection of identifiable landmarks, a landmark complex can then be cumulatively constructed to encapsulate the topological information of the environment. Under the assumption of sufficiently dense landmarks, we propose an exploration and exploitation strategy that guides the swarm of robots to explore an environment using only bearing measurements without any metric information. Lastly, we demonstrate the coordinate-free and localization-free navigation in the environment using the constructed landmark complex.
ER  - 

TY  - CONF
TI  - Coverage Control for Wire-Traversing Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5042
EP  - 5047
AU  - G. Notomista
AU  - M. Egerstedt
PY  - 2018
KW  - gradient methods
KW  - minimisation
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - continuous constrained coverage control problem
KW  - mobile robots
KW  - COW map
KW  - Continuous Onto Wires map
KW  - constrained locational cost minimization
KW  - final projection step
KW  - Lloyd descent algorithm
KW  - planar environment
KW  - continuous motion
KW  - one-dimensional manifolds
KW  - two-dimensional motion
KW  - wire-traversing robots
KW  - Wires
KW  - Minimization
KW  - Robot sensing systems
KW  - Optimization
KW  - Motion control
KW  - Power transmission lines
DO  - 10.1109/ICRA.2018.8461123
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we consider the coverage control problem for a team of wire-traversing robots. The two-dimensional motion of robots moving in a planar environment has to be projected to one-dimensional manifolds representing the wires. Starting from Lloyd's descent algorithm for coverage control, a solution that generates continuous motion of the robots on the wires is proposed. This is realized by means of a Continuous Onto Wires (COW) map: the robots' workspace is mapped onto the wires on which the motion of the robots is constrained to be. A final projection step is introduced to ensure that the configuration of the robots on the wires is a local minimizer of the constrained locational cost. An algorithm for the continuous constrained coverage control problem is proposed and it is tested both in simulation and on a team of mobile robots.
ER  - 

TY  - CONF
TI  - Control of Multiple Passive-Follower Type Robots Based on Feasible Braking Control Region Analysis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5056
EP  - 5061
AU  - Y. Hirata
AU  - K. Kimura
AU  - S. Matsuzaki
AU  - N. Ogawa
AU  - T. Kubota
PY  - 2018
KW  - brakes
KW  - braking
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - wheels
KW  - braking control region analysis
KW  - passive mobile robot
KW  - wheel
KW  - formation control
KW  - control law
KW  - passive robot
KW  - fundamental control method
KW  - active leader
KW  - multiple mobile robots
KW  - external pulling force
KW  - servo brakes
KW  - multiple passive-follower type robots
KW  - Mobile robots
KW  - Force
KW  - Wheels
KW  - Robot kinematics
KW  - Brakes
KW  - Torque
DO  - 10.1109/ICRA.2018.8460637
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Ahstract- In this study, we propose a development and formation control of a passive mobile robot equipped only with servo brakes and no motors. The developed passive mobile robot can move forward by utilizing an external pulling force, and steers itself by controlling the servo brakes attached to each wheel. Systems composed of multiple mobile robots are very effective at exploring vast areas. However the coordination and simultaneous control of several robots utilizing simple information is a difficult task. Therefore we propose a leader follower architecture composed of multiple passive follower robots tethered to one active leader. In this paper, we first introduce the developed passive mobile robot. Then, we analyze the fundamental control method of this passive mobile robot from the perspective of the feasible braking control region, which considers the slip of the passive robot and the limitation of the external pulling force from the active leader. Lastly, a control law for the servo brakes attached to each wheel is proposed, followed by a feasibility study to determine whether the passive followers can stay in formation by controlling the servo brakes with the proposed control law.
ER  - 

TY  - CONF
TI  - Voronoi-Based Coverage Control of Pan/Tilt/Zoom Camera Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5062
EP  - 5069
AU  - O. Arslan
AU  - H. Min
AU  - D. E. Koditschek
PY  - 2018
KW  - cameras
KW  - computational geometry
KW  - event distribution
KW  - activity distribution
KW  - reactive coverage control algorithm
KW  - greedy gradient algorithms
KW  - pan camera network
KW  - tilt camera network
KW  - zoom camera network
KW  - continuous-and discrete-time first-order PTZ camera dynamics
KW  - coverage algorithms
KW  - locally optimal coverage configuration
KW  - first-order PTZ camera dynamics
KW  - camera network allocation problem
KW  - sensing quality measures
KW  - conic Voronoi diagrams
KW  - visual sensing quality
KW  - total coverage quality
KW  - camera orientations
KW  - PTZ camera networks
KW  - automated active network reconfiguration
KW  - flexible visual monitoring
KW  - Cameras
KW  - Sensors
KW  - Heuristic algorithms
KW  - Visualization
KW  - Resource management
KW  - Image resolution
KW  - Optimization
DO  - 10.1109/ICRA.2018.8460701
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A challenge of pan/tilt/zoom (PTZ) camera networks for efficient and flexible visual monitoring is automated active network reconfiguration in response to environmental stimuli. In this paper, given an event/activity distribution over a convex environment, we propose a new provably correct reactive coverage control algorithm for PTZ camera networks that continuously (re) configures camera orientations and zoom levels (i.e., angles of view) in order to locally maximize their total coverage quality. Our construction is based on careful modeling of visual sensing quality that is consistent with the physical nature of cameras, and we introduce a new notion of conic Voronoi diagrams, based on our sensing quality measures, to solve the camera network allocation problem: that is, to determine where each camera should focus in its field of view given all the other cameras' configurations. Accordingly, we design simple greedy gradient algorithms for both continuous-and discrete-time first-order PTZ camera dynamics that asymptotically converge a locally optimal coverage configuration. Finally, we provide numerical and experimental evidence demonstrating the effectiveness of the proposed coverage algorithms.
ER  - 

TY  - CONF
TI  - Shaping in Practice: Training Wheels to Learn Fast Hopping Directly in Hardware
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5076
EP  - 5081
AU  - S. Heim
AU  - F. Ruppert
AU  - A. A. Sarvestani
AU  - A. Spröwitz
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - robust control
KW  - temporary modifications
KW  - physical hardware
KW  - robot leg
KW  - reward landscape
KW  - fast hopping
KW  - robot controllers
KW  - engineering effort
KW  - potentially unstable parameters
KW  - training wheels
KW  - video synopsis
KW  - boom learning
KW  - robustness
KW  - Legged locomotion
KW  - Training
KW  - Wheels
KW  - Hardware
KW  - Hip
DO  - 10.1109/ICRA.2018.8460984
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Learning instead of designing robot controllers can greatly reduce engineering effort required, while also emphasizing robustness. Despite considerable progress in simulation, applying learning directly in hardware is still challenging, in part due to the necessity to explore potentially unstable parameters. We explore the concept of shaping the reward landscape with training wheels; temporary modifications of the physical hardware that facilitate learning. We demonstrate the concept with a robot leg mounted on a boom learning to hop fast. This proof of concept embodies typical challenges such as instability and contact, while being simple enough to empirically map out and visualize the reward landscape. Based on our results we propose three criteria for designing effective training wheels for learning in robotics. A video synopsis can be found at https://youtu.be/6iH5E3LrYh8.
ER  - 

TY  - CONF
TI  - Speeding Up Incremental Learning Using Data Efficient Guided Exploration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5082
EP  - 5089
AU  - M. Hazara
AU  - V. Kyrki
PY  - 2018
KW  - Bayes methods
KW  - generalisation (artificial intelligence)
KW  - learning (artificial intelligence)
KW  - regression analysis
KW  - search problems
KW  - global parametric model
KW  - model-free policy search agent
KW  - model selection
KW  - Bayes method
KW  - online incremental learning
KW  - data uncertainty
KW  - reinforcement learning
KW  - probabilistic models
KW  - motor primitives
KW  - data efficient guided exploration
KW  - Task analysis
KW  - Uncertainty
KW  - Covariance matrices
KW  - Adaptation models
KW  - Computational modeling
KW  - Parametric statistics
KW  - Predictive models
DO  - 10.1109/ICRA.2018.8461241
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To cope with varying conditions, motor primitives (MPs) must support generalization over task parameters to avoid learning separate primitives for each situation. In this regard, deterministic and probabilistic models have been proposed for generalizing MPs to new task parameters, thus providing limited generalization. Although generalization of MPs using probabilistic models has been studied, it is not clear how such generalizable models can be learned efficiently. Reinforcement learning can be more efficient when the exploration process is tuned with data uncertainty, thus reducing unnecessary exploration in a data-efficient way. We propose an empirical Bayes method to predict uncertainty and utilize it for guiding the exploration process of an incremental learning framework. The online incremental learning framework uses a single human demonstration for constructing a database of MPs. The main ingredients of the proposed framework are a global parametric model (GPDMP) for generalizing MPs for new situations, a model-free policy search agent for optimizing the failed predicted MPs, model selection for controlling the complexity of GPDMp, and empirical Bayes for extracting the uncertainty of MPs prediction. Experiments with a ball-in-a-cup task demonstrate that the global GPDMP model generalizes significantly better than linear models and Locally Weighted Regression especially in terms of extrapolation capability. Furthermore, the model selection has successfully identified the required complexity of GPDMP even with few training samples while satisfying the Occam Razor's prinicple. Above all, the uncertainty predicted by the proposed empirical Bayes approach successfully guided the exploration process of the model-free policy search. The experiments indicated statistically significant improvement of learning speed over covariance matrix adaptation (CMA) with a significance of p=0.002.
ER  - 

TY  - CONF
TI  - Eager and Memory-Based Non-Parametric Stochastic Search Methods for Learning Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5090
EP  - 5096
AU  - V. Barbaros
AU  - H. van Hoof
AU  - A. Abdolmaleki
AU  - D. Megerl
PY  - 2018
KW  - learning systems
KW  - nonparametric statistics
KW  - optimisation
KW  - robots
KW  - search problems
KW  - stochastic processes
KW  - learning control
KW  - direct policy search
KW  - complex problems
KW  - nonparametric methods
KW  - robot skill learning
KW  - memory-based learner
KW  - hybrid controller
KW  - memory-based non-parametric stochastic search methods
KW  - computing schedules
KW  - robot controller parameter optimisation
KW  - Stochastic processes
KW  - Robots
KW  - Search methods
KW  - Task analysis
KW  - Entropy
KW  - Computational modeling
KW  - Kernel
DO  - 10.1109/ICRA.2018.8460633
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Direct policy search has shown to be a successful method to optimize robot controller parameters. However, defining a good parametric form for the controller can be challenging for complex problems. Non-parametric methods provide a flexible alternative and are thus a promising tool in robot skill learning. In this paper, we investigate two nonparametric methods based on similar principles but utilizing differing computing schedules: an eager learner and a memory-based learner. We compare the methods experimentally on two different control problems. Furthermore, we define and evaluate a new `hybrid' controller that combines the strong points of both of these methods.
ER  - 

TY  - CONF
TI  - Data-driven Construction of Symbolic Process Models for Reinforcement Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5105
EP  - 5112
AU  - E. Derner
AU  - J. Kubalík
AU  - R. Babuška
PY  - 2018
KW  - genetic algorithms
KW  - Internet
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pendulums
KW  - time-varying systems
KW  - time varying dynamics
KW  - controlling systems
KW  - data driven construction
KW  - online
KW  - single node genetic programming
KW  - SNGP
KW  - pendulum swing up problem
KW  - training data
KW  - accurate models
KW  - real-time experiments
KW  - simulated mobile robot
KW  - realtime robot control
KW  - analytic equations
KW  - parsimonious models
KW  - symbolic regression
KW  - acceptable policy
KW  - RL
KW  - reinforcement learning
KW  - symbolic process models
KW  - Mathematical model
KW  - Data models
KW  - Learning (artificial intelligence)
KW  - Computational modeling
KW  - Mobile robots
KW  - Genetic programming
KW  - Model learning for control
KW  - AI-based methods
KW  - symbolic regression
KW  - reinforcement learning
KW  - optimal control
DO  - 10.1109/ICRA.2018.8461182
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Reinforcement learning (RL) is a suitable approach for controlling systems with unknown or time-varying dynamics. RL in principle does not require a model of the system, but before it learns an acceptable policy, it needs many unsuccessful trials, which real robots usually cannot withstand. It is well known that RL can be sped up and made safer by using models learned online. In this paper, we propose to use symbolic regression to construct compact, parsimonious models described by analytic equations, which are suitable for realtime robot control. Single node genetic programming (SNGP) is employed as a tool to automatically search for equations fitting the available data. We demonstrate the approach on two benchmark examples: a simulated mobile robot and the pendulum swing-up problem; the latter both in simulations and real-time experiments. The results show that through this approach we can find accurate models even for small batches of training data. Based on the symbolic model found, RL can control the system well.
ER  - 

TY  - CONF
TI  - PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-Based Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5113
EP  - 5120
AU  - A. Faust
AU  - K. Oslund
AU  - O. Ramirez
AU  - A. Francis
AU  - L. Tapia
AU  - M. Fiser
AU  - J. Davidson
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - neural nets
KW  - path planning
KW  - probability
KW  - robot dynamics
KW  - robot vision
KW  - sampling methods
KW  - sampling based planner
KW  - hierarchical method
KW  - sampling based path planning
KW  - large scale topology
KW  - probabilistic roadmaps
KW  - feature based deep neural net policies
KW  - continuous state
KW  - action spaces
KW  - simulation
KW  - office environments
KW  - aerial cargo delivery
KW  - urban environments
KW  - load displacement constraints
KW  - trajectories
KW  - noisy sensor conditions
KW  - flights
KW  - training
KW  - PRM RL
KW  - long range robotic navigation tasks
KW  - point to point navigation policies
KW  - end to end differential drive indoor navigation
KW  - nontrivial robot dynamics
KW  - robot configurations
KW  - task constraints
KW  - capture robot dynamics
KW  - RL agent
KW  - reinforcement learning
KW  - Task analysis
KW  - Robot sensing systems
KW  - Indoor navigation
KW  - Aerospace electronics
KW  - Learning (artificial intelligence)
DO  - 10.1109/ICRA.2018.8461096
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present PRM-RL, a hierarchical method for long-range navigation task completion that combines sampling-based path planning with reinforcement learning (RL). The RL agents learn short-range, point-to-point navigation policies that capture robot dynamics and task constraints without knowledge of the large-scale topology. Next, the sampling-based planners provide roadmaps which connect robot configurations that can be successfully navigated by the RL agent. The same RL agents are used to control the robot under the direction of the planning, enabling long-range navigation. We use the Probabilistic Roadmaps (PRMs) for the sampling-based planner. The RL agents are constructed using feature-based and deep neural net policies in continuous state and action spaces. We evaluate PRM-RL, both in simulation and on-robot, on two navigation tasks with non-trivial robot dynamics: end-to-end differential drive indoor navigation in office environments, and aerial cargo delivery in urban environments with load displacement constraints. Our results show improvement in task completion over both RL agents on their own and traditional sampling-based planners. In the indoor navigation task, PRM-RL successfully completes up to 215 m long trajectories under noisy sensor conditions, and the aerial cargo delivery completes flights over 1000 m without violating the task constraints in an environment 63 million times larger than used in training.
ER  - 

TY  - CONF
TI  - Using Parameterized Black-Box Priors to Scale Up Model-Based Policy Search for Robotics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5121
EP  - 5128
AU  - K. Chatzilygeroudis
AU  - J. Mouret
PY  - 2018
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - optimisation
KW  - search problems
KW  - parameterized black-box priors
KW  - robotics
KW  - data-efficient algorithms
KW  - reinforcement learning
KW  - dynamical model
KW  - black-box optimization algorithm
KW  - model-based policy search approaches
KW  - model learning procedure
KW  - high-dimensional systems
KW  - physical hexapod robot
KW  - Black-DROPS algorithm
KW  - Robots
KW  - Data models
KW  - Mathematical model
KW  - Computational modeling
KW  - Heuristic algorithms
KW  - Analytical models
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461083
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The most data-efficient algorithms for reinforcement learning in robotics are model-based policy search algorithms, which alternate between learning a dynamical model of the robot and optimizing a policy to maximize the expected return given the model and its uncertainties. Among the few proposed approaches, the recently introduced Black-DROPS algorithm exploits a black-box optimization algorithm to achieve both high data-efficiency and good computation times when several cores are used; nevertheless, like all model-based policy search approaches, Black-DROPS does not scale to high dimensional state/action spaces. In this paper, we introduce a new model learning procedure in Black-DROPS that leverages parameterized black-box priors to (1) scale up to high-dimensional systems, and (2) be robust to large inaccuracies of the prior information. We demonstrate the effectiveness of our approach with the “pendubot” swing-up task in simulation and with a physical hexapod robot (48D state space, 18D action space) that has to walk forward as fast as possible. The results show that our new algorithm is more data-efficient than previous model-based policy search algorithms (with and without priors) and that it can allow a physical 6-legged robot to learn new gaits in only 16 to 30 seconds of interaction time.
ER  - 

TY  - CONF
TI  - Self-Supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5129
EP  - 5136
AU  - G. Kahn
AU  - A. Villaflor
AU  - B. Ding
AU  - P. Abbeel
AU  - S. Levine
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - double Q-learning
KW  - self-supervised deep reinforcement learning
KW  - self-supervised training
KW  - model-based methods
KW  - value-based model-free methods
KW  - learning-based methods
KW  - planning method
KW  - internal map
KW  - robot navigation
KW  - generalized computation graph
KW  - Computational modeling
KW  - Navigation
KW  - Learning (artificial intelligence)
KW  - Robots
KW  - Task analysis
KW  - Prediction algorithms
KW  - Planning
DO  - 10.1109/ICRA.2018.8460655
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Enabling robots to autonomously navigate complex environments is essential for real-world deployment. Prior methods approach this problem by having the robot maintain an internal map of the world, and then use a localization and planning method to navigate through the internal map. However, these approaches often include a variety of assumptions, are computationally intensive, and do not learn from failures. In contrast, learning-based methods improve as the robot acts in the environment, but are difficult to deploy in the real-world due to their high sample complexity. To address the need to learn complex policies with few samples, we propose a generalized computation graph that subsumes value-based model-free methods and model-based methods, with specific instantiations interpolating between model-free and model-based. We then instantiate this graph to form a navigation model that learns from raw images and is sample efficient. Our simulated car experiments explore the design decisions of our navigation model, and show our approach outperforms single-step and N-step double Q-learning. We also evaluate our approach on a real-world RC car and show it can learn to navigate through a complex indoor environment with a few hours of fully autonomous, self-supervised training. Videos of the experiments and code can be found at github.com/gkahn13/gcg.
ER  - 

TY  - CONF
TI  - Direct Line Guidance Odometry
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5137
EP  - 5143
AU  - S. Li
AU  - B. Ren
AU  - Y. Liu
AU  - M. Cheng
AU  - D. Frost
AU  - V. A. Prisacariu
PY  - 2018
KW  - distance measurement
KW  - feature extraction
KW  - robot vision
KW  - SLAM (robots)
KW  - direct line guidance odometry
KW  - pixel intensities
KW  - line-based features
KW  - point-based direct monocular visual odometry method
KW  - visual odometry algorithms
KW  - feature extraction
KW  - keypoint selection
KW  - Feature extraction
KW  - IP networks
KW  - Cameras
KW  - Optimization
KW  - Visual odometry
KW  - Simultaneous localization and mapping
KW  - Computational efficiency
DO  - 10.1109/ICRA.2018.8461003
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Modern visual odometry algorithms utilize sparse point-based features for tracking due to their low computational cost. Current state-of-the-art methods are split between indirect methods that process features extracted from the image, and indirect methods that deal directly on pixel intensities. In recent years, line-based features have been used in SLAM and have shown an increase in performance albeit with an increase in computational cost. In this paper, we propose an extension to a point-based direct monocular visual odometry method. Here we that uses lines to guide keypoint selection rather than acting as features. Points on a line are treated as stronger keypoints than those in other parts of the image, steering point-selection away from less distinctive points and thereby increasing efficiency. By combining intensity and geometry information from a set of points on a line, accuracy may also be increased.
ER  - 

TY  - CONF
TI  - Direct Visual SLAM Using Sparse Depth for Camera-LiDAR System
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5144
EP  - 5151
AU  - Y. Shin
AU  - Y. S. Park
AU  - A. Kim
PY  - 2018
KW  - cameras
KW  - image matching
KW  - motion estimation
KW  - motion measurement
KW  - optical radar
KW  - optical sensors
KW  - optical tracking
KW  - optical windows
KW  - portable instruments
KW  - SLAM (robots)
KW  - sparse depth information
KW  - motion estimation
KW  - pose-graph SLAM
KW  - KITTI odometry benchmark datasets
KW  - direct visual SLAM
KW  - monocular camera
KW  - light detection and ranging
KW  - portable camera-LiDAR mapping system
KW  - direct visual simultaneous localization and mapping
KW  - sliding window-based tracking method
KW  - depth-integrated frame matching
KW  - feature-based visual LiDAR mapping
KW  - sensors
KW  - Cameras
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Visualization
KW  - Simultaneous localization and mapping
KW  - Optimization
DO  - 10.1109/ICRA.2018.8461102
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes a framework for direct visual simultaneous localization and mapping (SLAM) combining a monocular camera with sparse depth information from Light Detection and Ranging (LiDAR). To ensure realtime performance while maintaining high accuracy in motion estimation, we present (i) a sliding window-based tracking method, (ii) strict pose marginalization for accurate pose-graph SLAM and (iii) depth-integrated frame matching for large-scale mapping. Unlike conventional feature-based visual and LiDAR mapping, the proposed approach is direct, eliminating the visual feature in the objective function. We evaluated results using our portable camera-LiDAR system as well as KITTI odometry benchmark datasets. The experimental results prove that the characteristics of two complementary sensors are very effective in improving real-time performance and accuracy. Via validation, we achieved low drift error of 0.98 % in the KITTI benchmark including various environments such as a highway and residential areas.
ER  - 

TY  - CONF
TI  - Bayesian Scale Estimation for Monocular SLAM Based on Generic Object Detection for Correcting Scale Drift
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5152
EP  - 5158
AU  - E. Sucar
AU  - J. Hayet
PY  - 2018
KW  - Bayes methods
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - monocular SLAM system
KW  - Bayesian framework
KW  - deep-learning based generic object detector
KW  - detection region
KW  - scale drift
KW  - monocular systems
KW  - Bayesian scale estimation
KW  - generic object detection
KW  - local scale correction
KW  - object class detection
KW  - KITTI dataset
KW  - quantitative evaluations
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Bayes methods
KW  - Object detection
KW  - Image reconstruction
DO  - 10.1109/ICRA.2018.8461178
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a novel real-time algorithm for estimating the local scale correction of a monocular SLAM system, to obtain a correctly scaled version of the 3D map and of the camera trajectory. Within a Bayesian framework, it integrates observations from a deep-learning based generic object detector and landmarks from the map whose projection lie inside a detection region, to produce scale correction estimates from single frames. For each observation, a prior distribution on the height of the detected object class is used to define the observation's likelihood. Due to the scale drift inherent to monocular SLAM systems, we also incorporate a rough model on the dynamics of scale drift. Quantitative evaluations are presented on the KITTI dataset, and compared with different approaches. The results show a superior performance of our proposal in terms of relative translational error when compared to other monocular systems based on object detection.
ER  - 

TY  - CONF
TI  - Efficient Active SLAM Based on Submap Joining, Graph Topology and Convex Optimization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5159
EP  - 5166
AU  - Y. Chen
AU  - S. Huang
AU  - R. Fitch
AU  - J. Yu
PY  - 2018
KW  - computational complexity
KW  - convex programming
KW  - least squares approximations
KW  - minimisation
KW  - mobile robots
KW  - path planning
KW  - predictive control
KW  - quadratic programming
KW  - robot vision
KW  - SLAM (robots)
KW  - graph topology
KW  - active SLAM problem
KW  - robot trajectory
KW  - area coverage task
KW  - model predictive control framework
KW  - uncertainty minimization MPC problem
KW  - graphical structure
KW  - 2D feature-based SLAM
KW  - variable substitutions
KW  - convex optimization method
KW  - MPC framework
KW  - sequential quadratic programming method
KW  - linear SLAM
KW  - submap joining approach
KW  - planning
KW  - simultaneous localization and mapping
KW  - nonconvex constrained least-squares problem
KW  - Optimized production technology
KW  - Simultaneous localization and mapping
KW  - Uncertainty
KW  - Task analysis
KW  - Robot kinematics
DO  - 10.1109/ICRA.2018.8460864
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The active SLAM problem considered in this paper aims to plan a robot trajectory for simultaneous localization and mapping (SLAM) as well as for an area coverage task with robot pose uncertainty. Based on a model predictive control (MPC) framework, these two problems are solved respectively by different methods. For the uncertainty minimization MPC problem, based on the graphical structure of the 2D feature-based SLAM, a non-convex constrained least-squares problem is presented to approximate the original problem. Then, using variable substitutions, it is further transformed into a convex problem, and then solved by a convex optimization method. For the coverage task considering robot pose uncertainty, it is formulated and solved by the MPC framework and the sequential quadratic programming (SQP) method. In the whole process, considering the computation complexity, we use linear SLAM, which is a submap joining approach, to reduce the time for planning and estimation. Finally, various simulations are presented to validate the effectiveness of the proposed approach.
ER  - 

TY  - CONF
TI  - 2D SLAM Correction Prediction in Large Scale Urban Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5167
EP  - 5174
AU  - Z. Alsayed
AU  - G. Bresson
AU  - A. Verroust-Blondet
AU  - F. Nashashibi
PY  - 2018
KW  - image representation
KW  - mobile robots
KW  - multilayer perceptrons
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - autonomous mobile robots
KW  - large scale urban environments
KW  - simultaneous location and mapping
KW  - hybrid correction module
KW  - likelihood distributions
KW  - 2D likelihood SLAM approaches
KW  - successive estimated poses
KW  - Ensemble Multilayer Perceptron model
KW  - SLAM estimations
KW  - systematic errors
KW  - sensor measurement errors
KW  - SLAM map representation
KW  - observation model
KW  - motion model
KW  - probabilistic formulation
KW  - Simultaneous localization and mapping
KW  - Two dimensional displays
KW  - Estimation
KW  - Neural networks
KW  - Predictive models
KW  - Kalman filters
DO  - 10.1109/ICRA.2018.8460773
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Simultaneous Localization And Mapping (SLAM) is one of the major bricks needed to build truly autonomous mobile robots. The probabilistic formulation of SLAM is based on two models: the motion model and the observation model. In practice, these models, together with the SLAM map representation, do not model perfectly the robot's real dynamics, the sensor measurement errors and the environment. Consequently, systematic errors affect SLAM estimations. In this paper, we propose two approaches to predict corrections to be applied to SLAM estimations. Both are based on the Ensemble Multilayer Perceptron model. The first approach uses successive estimated poses to predict the errors, with no assumptions on the underlying SLAM process or sensor used. The second method is specific to 2D likelihood SLAM approaches, thus, the likelihood distributions are used to predict the corrections, making this second approach independent of the sensor used. We also build a hybrid correction module based on successive estimated poses and the likelihood distributions. The validity of both approaches is evaluated through two experiments using different evaluation metrics and sensor configurations.
ER  - 

TY  - CONF
TI  - Omnidirectional Multisensory Perception Fusion for Long-Term Place Recognition
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5175
EP  - 5181
AU  - S. Siva
AU  - H. Zhang
PY  - 2018
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - sensor fusion
KW  - SLAM (robots)
KW  - omnidirectional multisensory perception fusion
KW  - long-term place recognition
KW  - long-term autonomy
KW  - omnidirectional sensors
KW  - omnidirectional observation
KW  - multidirectional place recognition
KW  - omnidirectional multisensory data
KW  - appearance variations
KW  - Simultaneous Localization and Mapping
KW  - Feature extraction
KW  - Sensor phenomena and characterization
KW  - Simultaneous localization and mapping
KW  - Optimization
DO  - 10.1109/ICRA.2018.8461042
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation.
ER  - 

TY  - CONF
TI  - Online Initialization and Automatic Camera-IMU Extrinsic Calibration for Monocular Visual-Inertial SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5182
EP  - 5189
AU  - W. Huang
AU  - H. Liu
PY  - 2018
KW  - accelerometers
KW  - calibration
KW  - cameras
KW  - gyroscopes
KW  - inertial navigation
KW  - iterative methods
KW  - mobile robots
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - extrinsic orientation
KW  - extrinsic translation
KW  - accelerometer bias
KW  - camera-IMU extrinsic parameters
KW  - initial values
KW  - visual scale
KW  - initialization stage
KW  - mechanical configuration
KW  - sensor suite changes
KW  - online initialization method
KW  - translation calibration
KW  - initialization procedure
KW  - gyroscope bias
KW  - monocular visual-inertial SLAM techniques
KW  - gyroscope
KW  - gravitational magnitude
KW  - Gyroscopes
KW  - Cameras
KW  - Quaternions
KW  - Accelerometers
KW  - Calibration
KW  - Simultaneous localization and mapping
KW  - Gravity
DO  - 10.1109/ICRA.2018.8460206
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Most of the existing monocular visual-inertial SLAM techniques assume that the camera-IMU extrinsic parameters are known, therefore these methods merely estimate the initial values of velocity, visual scale, gravity, biases of gyroscope and accelerometer in the initialization stage. However, it's usually a professional work to carefully calibrate the extrinsic parameters, and it is required to repeat this work once the mechanical configuration of the sensor suite changes slightly. To tackle this problem, we propose an online initialization method to automatically estimate the initial values and the extrinsic parameters without knowing the mechanical configuration. The biases of gyroscope and accelerometer are considered in our method, and a convergence criteria for both orientation and translation calibration is introduced to identify the convergence and to terminate the initialization procedure. In the three processes of our method, an iterative strategy is firstly introduced to iteratively estimate the gyroscope bias and the extrinsic orientation. Secondly, the scale factor, gravity, and extrinsic translation are approximately estimated without considering the accelerometer bias. Finally, these values are further optimized by a refinement algorithm in which the accelerometer bias and the gravitational magnitude are taken into account. Extensive experimental results show that our method achieves competitive accuracy compared with the state-of-the-art with less calculation.
ER  - 

TY  - CONF
TI  - Sonar Visual Inertial SLAM of Underwater Structures
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5190
EP  - 5196
AU  - S. Rahman
AU  - A. Q. Li
AU  - I. Rekleitis
PY  - 2018
KW  - oceanographic techniques
KW  - SLAM (robots)
KW  - sonar
KW  - underwater sound
KW  - underwater vehicles
KW  - underwater structures
KW  - acoustic range data
KW  - sonar visual inertial SLAM
KW  - visual-inertial state estimation package
KW  - resource management
KW  - marine archaeology
KW  - underwater acoustic sensor
KW  - underwater cave
KW  - underwater wrecks
KW  - underwater domain
KW  - Sonar
KW  - Cameras
KW  - Visualization
KW  - Sonar navigation
KW  - Simultaneous localization and mapping
KW  - Underwater structures
DO  - 10.1109/ICRA.2018.8460545
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents an extension to a state of the art Visual-Inertial state estimation package (OKVIS) in order to accommodate data from an underwater acoustic sensor. Mapping underwater structures is important in several fields, such as marine archaeology, search and rescue, resource management, hydrogeology, and speleology. Collecting the data, however, is a challenging, dangerous, and exhausting task. The underwater domain presents unique challenges in the quality of the visual data available; as such, augmenting the exteroceptive sensing with acoustic range data results in improved reconstructions of the underwater structures. Experimental results from underwater wrecks, an underwater cave, and a submerged bus demonstrate the performance of our approach.
ER  - 

TY  - CONF
TI  - Differential Flatness Transformations for Aggressive Quadrotor Flight
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5204
EP  - 5210
AU  - B. Morrell
AU  - M. Rigter
AU  - G. Merewether
AU  - R. Reid
AU  - R. Thakker
AU  - T. Tzanetos
AU  - V. Rajur
AU  - G. Chamitoff
PY  - 2018
KW  - helicopters
KW  - mobile robots
KW  - stability
KW  - trajectory control
KW  - flight envelope
KW  - hierarchical control
KW  - quadrotor flight
KW  - differential flatness transformation
KW  - trajectory control
KW  - stability issues
KW  - Trajectory
KW  - Attitude control
KW  - Standards
KW  - Acceleration
KW  - Aerospace electronics
KW  - Australia
KW  - Robustness
DO  - 10.1109/ICRA.2018.8460838
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Aggressive maneuvering amongst obstacles could enable advanced capabilities for quadrotors in applications such as search and rescue, surveillance, inspection, and situations where rapid flight is required in cluttered environments. Previous works have treated quadrotors as differentially flat systems, and this property has been exploited widely to design simple algorithms that generate dynamically feasible trajectories and to enable hierarchical control. The differentially flat property allows the full state of the quadrotor to be extracted from the reduced dimensional space of x, y, z, yaw and their derivatives. This differential flatness transformation has a number of singularities, however, as well as stability issues when controlling near these singularities. Many methods have been described in the literature to address these; however, they all have limitations when exploring the full flight envelope of a quadrotor, including roll or pitch angles past 90°, and during inverted flight. In this paper, we review these existing methods and then introduce our method, which combines multiple methods to provide a highly-robust differential flatness transformation that addresses most of these issues. Our approach is demonstrated enabling highly-aggressive quadrotor flight in both simulations and real-world experiments.
ER  - 

TY  - CONF
TI  - Autonomous Control of the Interacting-BoomCopter UAV for Remote Sensor Mounting
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5219
EP  - 5224
AU  - D. R. McArthur
AU  - A. B. Chowdhury
AU  - D. J. Cappelleri
PY  - 2018
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - finite state machines
KW  - mobile robots
KW  - propellers
KW  - robot vision
KW  - target tracking
KW  - Interacting-BoomCopter UAV
KW  - remote sensor mounting
KW  - sensor package
KW  - vertical surface
KW  - unmanned aerial vehicle
KW  - on-board webcam
KW  - reversible propeller
KW  - aerial manipulation task
KW  - vehicle design
KW  - image processing algorithms
KW  - target tracking
KW  - extended finite state machine
KW  - high-level autonomous control
KW  - autonomous control strategy
KW  - I-BC platform
KW  - autonomous sensor
KW  - Task analysis
KW  - Propellers
KW  - Webcams
KW  - Unmanned aerial vehicles
KW  - Inspection
KW  - Force
KW  - Control systems
DO  - 10.1109/ICRA.2018.8461119
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a novel approach for autonomously mounting a sensor package on a vertical surface with an unmanned aerial vehicle (UAV). The Interacting-BoomCopter (I-BC) UAV uses an on-board webcam and computer along with a horizontally-mounted reversible propeller on its front boom to autonomously perform the aerial manipulation task. An overview of the vehicle design is presented along with the image processing algorithms used for target tracking, and the implementation of an extended finite state machine (EFSM) for carrying out the high-level autonomous control. The effectiveness of the autonomous control strategy and I-BC platform are examined through the performance of several autonomous sensor mounting flight tests.
ER  - 

TY  - CONF
TI  - Model Predictive Control of a Multi-Rotor with a Suspended Load for Avoiding Obstacles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5233
EP  - 5238
AU  - C. Y. Son
AU  - H. Seo
AU  - T. Kim
AU  - H. Jin Kim
PY  - 2018
KW  - aerospace robotics
KW  - collision avoidance
KW  - helicopters
KW  - mobile robots
KW  - predictive control
KW  - robot dynamics
KW  - vehicle dynamics
KW  - path planning
KW  - trajectory generation algorithms
KW  - MPC
KW  - sequential linear quadratic
KW  - SLQ
KW  - obstacle-avoidance algorithm
KW  - Model Predictive Control
KW  - dynamic environments
KW  - planning algorithms
KW  - multirotor
KW  - suspended load
KW  - Heuristic algorithms
KW  - Trajectory
KW  - Cost function
KW  - Mathematical model
KW  - Vehicle dynamics
KW  - Load modeling
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460749
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper investigates a multi-rotor with a suspended load in perspectives of 1) real-time path planning, 2) obstacle avoidance, and 3) transportation of a suspended object. A suspended load cannot be controlled with conventional controllers designed for nominal multi-rotors due to the dynamic coupling between the multi-rotor and load. Although several control and planning algorithms have been proposed based on elaborately derived dynamic equations, most existing studies separate control and path planning problems by following predefined trajectories after trajectory generation. Moreover, many state-of-the-art trajectory generation algorithms cannot work real-time for a system with high degrees of freedom, which makes it not suitable to operate the system in dynamic environments where obstacles appear abruptly or move unexpectedly. With this in mind, we apply Model Predictive Control (MPC) with Sequential Linear Quadratic (SLQ) solver to compute feasible and optimal trajectory real-time and to operate a multi-rotor with a suspended load in dynamic environments. We design an obstacle-avoidance algorithm suitable for the current platform flying in cluttered environments. Flight experiments shows that the proposed algorithm successfully controls the multi-rotor and allows to avoid obstacles simultaneously.
ER  - 

TY  - CONF
TI  - Asymmetric Collaborative Bar Stabilization Tethered to Two Heterogeneous Aerial Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5247
EP  - 5253
AU  - P. O. Pereira
AU  - P. Roque
AU  - D. V. Dimarogonas
PY  - 2018
KW  - autonomous aerial vehicles
KW  - force
KW  - stability
KW  - three-term control
KW  - asymmetric collaborative bar stabilization tethered
KW  - unmanned aerial vehicles
KW  - rigid links
KW  - tensile forces
KW  - control objective
KW  - PID control law
KW  - decoupled motions
KW  - cascaded motions
KW  - system asymmetries
KW  - cable lengths
KW  - UAV
KW  - systems physical parameters
KW  - Bars
KW  - Force
KW  - Unmanned aerial vehicles
KW  - Dynamics
KW  - Mathematical model
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460529
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider a system composed of a bar tethered to two unmanned aerial vehicles (UAVs), where the cables behave as rigid links under tensile forces, and with the control objective of stabilizing the bar's pose around a desired pose. Each UAV is equipped with a PID control law, and we verify that the bar's motion is decomposable into three decoupled motions, namely a longitudinal, a lateral and a vertical. We then provide relations between the UAV s' gains, which, if satisfied, allows us to decompose each of those motions into two cascaded motions; the latter relations between the UAV s' gains are found so as to counteract the system asymmetries, such as the different cable lengths and the different UAV s' weights. Finally, we provide conditions, based on the system's physical parameters, that describe good and bad types of asymmetries. We present experiments that demonstrate the stabilization of the bar's pose.
ER  - 

TY  - CONF
TI  - Innovative Bio-Impedance Sensor Towards Puncture Detection in Eye Surgery for Retinal Vein Occlusion Treatment
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5343
EP  - 5348
AU  - L. Schoevaerdts
AU  - L. Esteveny
AU  - G. Borghesan
AU  - M. Ourak
AU  - A. Gijbels
AU  - J. Smits
AU  - D. Reynaerts
AU  - E. Vander Poorten
PY  - 2018
KW  - biosensors
KW  - blood vessels
KW  - diseases
KW  - electric impedance
KW  - electric impedance measurement
KW  - eye
KW  - medical image processing
KW  - patient diagnosis
KW  - surgery
KW  - vision defects
KW  - thrombolytic agent flushing
KW  - patient eye lens
KW  - double puncture event detection
KW  - retinal vein occlusion treatment
KW  - innovative bio-impedance sensor
KW  - eye surgery
KW  - clotted retinal vessels
KW  - size 50 micron to 400 micron
KW  - Surgery
KW  - Needles
KW  - Probes
KW  - Retina
KW  - Impedance
KW  - Biosensors
DO  - 10.1109/ICRA.2018.8460205
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - At the moment, surgeons struggle curing a widespread eye disease known as retinal vein occlusion where clots obstruct the retinal vessels. Latter vascular disorder involves black spots in people's eyesight and lead eventually to blindness. A recent promising treatment consists in flushing a thrombolytic agent inside the clotted retinal vessels. The surgery implies puncturing vessels ranging from 50 to 400 microns diameter on the backside of the eye, namely the retina. Latest research succeeded in tackling several challenges around this operation: the surgeon's hand tremor and the high precision required amongst other requirements. Despite several breakthroughs, the surgeon only relies on a microscope to perform the surgery through the patient eye's lens, giving poor depth perception to properly puncture the retinal vessels. This way, the surgeon is most likely to pierce through the vessel and inject the thrombolytic drug under the retina, which would endanger the person's eyesight. In this paper, we investigate the use of a novel bio-impedance sensor developed for eye surgery. Together with this new sensor, a detection algorithm has been developed to detect the puncture and double puncture events to give a feedback to the operator of the system. As far as we are aware of, such technology doesn't exist yet in eye surgery to tackle the depth perception question. This paper aims at demonstrating the benefits of this technology.
ER  - 

TY  - CONF
TI  - Distal End Force Sensing with Optical Fiber Bragg Gratings for Tendon-Sheath Mechanisms in Flexible Endoscopic Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5349
EP  - 5255
AU  - W. Lai
AU  - L. Cao
AU  - Z. Xu
AU  - P. T. Phan
AU  - P. Shum
AU  - S. J. Phee
PY  - 2018
KW  - Bragg gratings
KW  - end effectors
KW  - endoscopes
KW  - feedback
KW  - fibre optic sensors
KW  - force sensors
KW  - friction
KW  - haptic interfaces
KW  - medical robotics
KW  - surgery
KW  - distal end haptic sensing
KW  - compression force
KW  - tension force
KW  - surgical end-effectors
KW  - mechanics analysis
KW  - verification tests
KW  - tendon-sheath driven grasper
KW  - TSMs-driven systems
KW  - distal end force sensing
KW  - optical fiber Bragg gratings
KW  - tendon-sheath mechanisms
KW  - haptic feedback
KW  - endoscopic surgical robots
KW  - transmission systems
KW  - nonlinear friction profiles
KW  - nitinol tube
KW  - FBG fiber
KW  - robotic fingers-hands
KW  - wearable devices
KW  - rehabilitation devices
KW  - Force
KW  - Robot sensing systems
KW  - Tendons
KW  - Fiber gratings
KW  - Haptic Sensing
KW  - Fiber Bragg Gratings
KW  - Flexible Surgical Endoscopic Robot
KW  - Tendon-Sheath Mechanisms
DO  - 10.1109/ICRA.2018.8461090
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Accurate haptic feedback is a critical challenge for surgical robots, especially for flexible endoscopic surgical robots whose transmission systems are Tendon-Sheath Mechanisms (TSMs) with highly nonlinear friction profiles and force hysteresis. For distal end haptic sensing of TSMs, this paper, for the first time, proposes to measure the compression force on the sheath at the distal end so that the tension force on the tendon, which equals the compression force on the sheath, can be obtained. A new force sensor, i.e., a nitinol tube attached with an optical Fiber Bragg Grating (FBG) fiber, is proposed to measure the compression force on the sheath. This sensor, with similar diameter and configuration (hollow) as the sheath, can be compactly integrated with TSMs and surgical end-effectors. In this paper, mechanics analysis and verification tests are presented to reveal the relationship between the tension force on the tendon and the compression force on the sheath. The proposed force sensor was calibrated in tests with a sensitivity of 24.28 pm/N and integrated with a tendon-sheath driven grasper to demonstrate the effectiveness of the proposed approach and sensor. The proposed approach and sensor can also be applied for a variety of TSMs-driven systems, such as robotic fingers/hands, wearable devices, and rehabilitation devices.
ER  - 

TY  - CONF
TI  - Trajectory-Optimized Sensing for Active Search of Tissue Abnormalities in Robotic Surgery
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5356
EP  - 5363
AU  - H. Salman
AU  - E. Ayvali
AU  - R. A. Srivatsan
AU  - Y. Ma
AU  - N. Zevallos
AU  - R. Yasin
AU  - L. Wang
AU  - N. Simaan
AU  - H. Choset
PY  - 2018
KW  - end effectors
KW  - Gaussian processes
KW  - knowledge acquisition
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - mobile robots
KW  - position control
KW  - robot kinematics
KW  - surgery
KW  - trajectory optimisation (aerospace)
KW  - tumours
KW  - uncertain systems
KW  - tumors
KW  - Gaussian processes
KW  - stiffness distribution
KW  - palpation path
KW  - acquisition function
KW  - active learning algorithm
KW  - incorporate uncertainties
KW  - robot position
KW  - sensor measurements
KW  - robot-kinematics
KW  - trajectory-optimized sensing
KW  - tissue abnormalities
KW  - da Vinci research kit
KW  - insertable robotic effector platform
KW  - robotic surgery
KW  - 6-DoF industrial arm
KW  - dVRK
KW  - IREP
KW  - Trajectory
KW  - Robot sensing systems
KW  - Optimization
KW  - Uncertainty
KW  - Bayes methods
KW  - Tumors
DO  - 10.1109/ICRA.2018.8460936
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we develop an approach for guiding robots to automatically localize and find the shapes of tumors and other stiff inclusions present in the anatomy. Our approach uses Gaussian processes to model the stiffness distribution and active learning to direct the palpation path of the robot. The palpation paths are chosen such that they maximize an acquisition function provided by an active learning algorithm. Our approach provides the flexibility to avoid obstacles in the robot's path, incorporate uncertainties in robot position and sensor measurements, include prior information about location of stiff inclusions while respecting the robot-kinematics. To the best of our knowledge this is the first work in literature that considers all the above conditions while localizing tumors. The proposed framework is evaluated via simulation and experimentation on three different robot platforms: 6-DoF industrial arm, da Vinci Research Kit (dVRK), and the Insertable Robotic Effector Platform (IREP). Results show that our approach can accurately estimate the locations and boundaries of the stiff inclusions while reducing exploration time.
ER  - 

TY  - CONF
TI  - Active Constraints Using Vector Field Inequalities for Surgical Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5364
EP  - 5371
AU  - M. M. Marinho
AU  - B. V. Adorno
AU  - K. Harada
AU  - M. Mitsuishi
PY  - 2018
KW  - brain
KW  - collision avoidance
KW  - manipulators
KW  - medical robotics
KW  - neurophysiology
KW  - surgery
KW  - vectors
KW  - deep brain neurosurgery
KW  - tremor-free procedures
KW  - robotic assistance
KW  - surgical robots
KW  - manipulator-boundary collisions
KW  - vector field inequality
KW  - active constraints
KW  - surgical tool tips
KW  - endonasal surgery
KW  - Quaternions
KW  - Surgery
KW  - Tools
KW  - Task analysis
KW  - Kinematics
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8461105
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotic assistance allows surgeons to perform dexterous and tremor-free procedures, but is still underrepresented in deep brain neurosurgery and endonasal surgery where the workspace is constrained. In these conditions, the vision of surgeons is restricted to areas near the surgical tool tips, which increases the risk of unexpected collisions between the shafts of the instruments and their surroundings, in particular in areas outside the surgical field-of-view. Active constraints can be used to prevent the tools from entering restricted zones and thus avoid collisions. In this paper, a vector field inequality is proposed that guarantees that tools do not enter restricted zones. Moreover, in contrast with early techniques, the proposed method limits the tool approach velocity in the direction of the forbidden zone boundary, guaranteeing a smooth behavior and that tangential velocities will not be disturbed. The proposed method is evaluated in simulations featuring two eight degrees-of-freedom manipulators that were custom-designed for deep neurosurgery. The results show that both manipulator-manipulator and manipulator-boundary collisions can be avoided using the vector field inequalities.
ER  - 

TY  - CONF
TI  - A Method for Online Optimization of Lower Limb Assistive Devices with High Dimensional Parameter Spaces
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5380
EP  - 5385
AU  - N. Thatte
AU  - H. Duan
AU  - H. Geyer
PY  - 2018
KW  - gait analysis
KW  - handicapped aids
KW  - medical robotics
KW  - advanced prosthesis controls
KW  - control parameters
KW  - optimization method
KW  - offline portion
KW  - intact subject gait data
KW  - neuromuscular control policy
KW  - ankle prosthesis
KW  - high-dimensional parameter spaces
KW  - parameter selection process
KW  - offline optimization procedure
KW  - dueling bandits problem
KW  - assistive lower-limb devices
KW  - control policies
KW  - lower limb assistive devices
KW  - online optimization
KW  - Knee
KW  - Prosthetics
KW  - Optimization
KW  - Torque
KW  - Neuromuscular
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460953
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a method for optimizing control policies for assistive lower-limb devices. The method frames parameter selection as a dueling bandits problem in which a user indicates his or her qualitative preferences between pairs of parameter sets chosen from a library. We generate the library through an offline optimization procedure that seeks to reproduce the varied gaits of healthy human subjects. By separating the parameter selection process into online and offline portions, the method can handle high-dimensional parameter spaces and produces policies that can generalize to different gait scenarios such as speed variation. We evaluate the method on five subjects walking on a powered knee and ankle prosthesis governed by a neuromuscular control policy that has 43 parameters. We find the five subjects preferred four different parameter sets from the library and that the resulting optima resemble intact subject gait data. This result suggests the offline portion of the optimization method indeed produces control parameters that can adapt to different gaits. Moreover, we find that for three out of the four parameter sets we tested, the procedure also generates parameters that improve the ability of the prosthesis to adapt to increasing gait speed by increasing ankle net work production. The results encourage further research and exploration in clinical settings toward advanced prosthesis controls that employ online learning.
ER  - 

TY  - CONF
TI  - Endo-VMFuseNet: A Deep Visual-Magnetic Sensor Fusion Approach for Endoscopic Capsule Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5386
EP  - 5392
AU  - M. Turan
AU  - Y. Almalioglu
AU  - H. B. Gilbert
AU  - A. E. Sari
AU  - U. Soylu
AU  - M. Sitti
PY  - 2018
KW  - endoscopes
KW  - learning (artificial intelligence)
KW  - magnetic sensors
KW  - medical robotics
KW  - sensor fusion
KW  - sensor fusion techniques
KW  - endo-VMFuseNet
KW  - asymmetric sensor data
KW  - asynchronous sensor data
KW  - deep learning
KW  - active medical robots
KW  - passive capsule endoscopes
KW  - medical device companies
KW  - endoscopic capsule robots
KW  - deep visual-magnetic sensor fusion approach
KW  - Robot sensing systems
KW  - Magnetic separation
KW  - Magnetic levitation
KW  - Sensor fusion
KW  - Magnetic cores
KW  - Magnetic resonance imaging
DO  - 10.1109/ICRA.2018.8461129
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In the last decade, researchers and medical device companies have made major advances towards transforming passive capsule endoscopes into active medical robots. One of the major challenges is to endow capsule robots with accurate perception of the environment inside the human body, which will provide necessary information and enable improved medical procedures. We extend the success of deep learning approaches from various research fields to the problem of sensor fusion for endoscopic capsule robots in the case of asynchronous and asymmetric sensor data without any need of calibration between sensors. The results performed on real pig stomach datasets show that our method achieves high precision for both translational and rotational movements and contains various advantages over traditional sensor fusion techniques.
ER  - 

TY  - CONF
TI  - EndoSensorFusion: Particle Filtering-Based Multi-Sensory Data Fusion with Switching State-Space Model for Endoscopic Capsule Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5393
EP  - 5400
AU  - M. Turan
AU  - Y. Almalioglu
AU  - H. Gilbert
AU  - H. Araujo
AU  - T. Cemgil
AU  - M. Sitti
PY  - 2018
KW  - distance measurement
KW  - endoscopes
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - recurrent neural nets
KW  - robot vision
KW  - sensor fusion
KW  - multisensor fusion
KW  - endoscopy robots
KW  - endoscopic capsule robot trajectories
KW  - recurrent neural network
KW  - nonlinear kinematic model
KW  - sensor reliability
KW  - online estimation
KW  - particle filter
KW  - gastrointestinal tract
KW  - therapeutic technology
KW  - switching state-space model
KW  - particle filtering-based multisensory data fusion
KW  - Robot sensing systems
KW  - Switches
KW  - Kalman filters
KW  - Proposals
KW  - Endoscopes
KW  - Magnetic resonance imaging
DO  - 10.1109/ICRA.2018.8460472
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A reliable, real time, multi-sensor fusion functionality is crucial for localization of actively controlled capsule endoscopy robots, which are an emerging, minimally invasive diagnostic and therapeutic technology for the gastrointestinal (GI) tract. In this study, we propose a novel multi-sensor fusion approach based on a particle filter that incorporates an online estimation of sensor reliability and a non-linear kinematic model learned by a recurrent neural network. Our method sequentially estimates the true robot pose from noisy pose observations delivered by multiple sensors. We experimentally test the method using 5 degree-of-freedom (5-DoF) absolute pose measurement by a magnetic localization system and a 6-DoF relative pose measurement by visual odometry. In addition, the proposed method is capable of detecting and handling sensor failures by ignoring corrupted data, providing the robustness expected of a medical device. Detailed analyses and evaluations are presented using ex vivo experiments on a porcine stomach model, proving that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories.
ER  - 

TY  - CONF
TI  - Force Control of Series Elastic Actuators-Driven Parallel Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5401
EP  - 5406
AU  - H. Lee
AU  - S. Kwak
AU  - S. Oh
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - force control
KW  - motion control
KW  - robot kinematics
KW  - torque control
KW  - Spatial Force control algorithm
KW  - Series Elastic Actuators-driven parallel Robot
KW  - Virtual Ground Robot
KW  - RFSEAs
KW  - Reaction Force-sensing Series Elastic Actuator
KW  - torque generation
KW  - force generation
KW  - Kinematics
KW  - VGR motions
KW  - Legged locomotion
KW  - Force control
KW  - Parallel robots
KW  - Force
KW  - Aerospace electronics
KW  - Actuators
DO  - 10.1109/ICRA.2018.8460768
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes a novel parallel robot - Virtual Ground Robot (VGR) - that is driven by three Series Elastic Actuators (SEAs) to interact with a human. The proposed Virtual Ground Robot provides a virtual ground on which a human can stand on and interact in three directions: the pitch, the roll and the height directions. The most significant features of the proposed VGR are that 1) it is driven by RFSEAs (Reaction Force-sensing Series Elastic Actuator), and thus it can provide precise forces and torques, 2) the size of the VGR is small enough for a human to stand on with ease, and 3) it can generate torque/force large to support a weight of a human. Taking advantage of RFSEAs utilized in the proposed VGR, Spatial Force control algorithm is proposed in this paper. In order to design this controller, the motions of VGR are defined in the task space, the joint space and the RFSEA level. Based on the Kinematics, force control of VGR in the task level, which is named Spatial Force Control is designed and verified using experiments.
ER  - 

TY  - CONF
TI  - Analyzing and Improving Cartesian Stiffness Control Stability of Series Elastic Tendon-Driven Robotic Hands
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5415
EP  - 5420
AU  - P. Rao
AU  - A. D. Deshpande
PY  - 2018
KW  - actuators
KW  - control system synthesis
KW  - dexterous manipulators
KW  - elasticity
KW  - force control
KW  - manipulator kinematics
KW  - position control
KW  - stability
KW  - stability criteria
KW  - series elastic tendon-driven robotic hands
KW  - dexterous manipulation
KW  - robotic hand design
KW  - fingertip force directions
KW  - Cartesian stiffness control
KW  - position dependent fingertip forces
KW  - stability conditions
KW  - Cartesian stiffness controllers
KW  - passive joint coupling
KW  - generalized passivity based stability boundary
KW  - Cartesian stiffness controlled series elastic tendon-driven robotic fingers
KW  - stability criteria
KW  - Stability criteria
KW  - Robots
KW  - Tendons
KW  - Force
KW  - Loading
KW  - Actuators
DO  - 10.1109/ICRA.2018.8460956
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robust and dexterous manipulation is identified as one of the critical challenges in the field of robotic hand design and control. A key requirement of dexterous manipulation is the ability to modulate fingertip force directions and magnitudes. Cartesian stiffness control is a strategy to generate position dependent fingertip forces. However the stability conditions for the Cartesian stiffness controllers vary nonlinearly because of dependency on the manipulator's configuration and loading forces. The challenge is enhanced in case of tendon-driven robotic hands due to passive joint coupling. In this work, we derive a generalized passivity based stability boundary for Cartesian stiffness. We then present a methodology to analyze the stability boundaries of Cartesian stiffness controlled series elastic tendon-driven robotic fingers. We also present a solution to improve stability by optimizing the arrangement of optimized passive compliance in parallel to the actuators based on the stability criteria. Our analysis not only allows for informed design of new robotic hands but also applies to improving performance of existing robotic hands.
ER  - 

TY  - CONF
TI  - A Projected Inverse Dynamics Approach for Multi-Arm Cartesian Impedance Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5421
EP  - 5428
AU  - H. Lin
AU  - J. Smith
AU  - K. K. Babarahmati
AU  - N. Dehio
AU  - M. Mistry
PY  - 2018
KW  - force control
KW  - friction
KW  - manipulator dynamics
KW  - motion control
KW  - unknown object dynamics
KW  - projected inverse dynamics approach
KW  - multiarm Cartesian impedance control
KW  - model-based control framework
KW  - multiarm manipulation
KW  - control law
KW  - constrained subspaces
KW  - unconstrained subspaces
KW  - unconstrained components
KW  - motion task
KW  - Cartesian impedance behaviour
KW  - constrained component enforces contact
KW  - friction constraints
KW  - contact forces
KW  - constrained subspace
KW  - contact points
KW  - dual-arm platform
KW  - Dynamics
KW  - Impedance
KW  - Force
KW  - Aerospace electronics
KW  - Robots
KW  - Task analysis
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2018.8461202
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a model-based control framework for multi-arm manipulation of a rigid object subject to external disturbances. The control framework, based on projected inverse dynamics, decomposes the control law into constrained and unconstrained subspaces. Unconstrained components accomplish the motion task with a desired 6-DOF Cartesian impedance behaviour against external disturbances. Meanwhile, the constrained component enforces contact and friction constraints by optimising for contact forces within the constrained subspace. External disturbances are explicitly compensated for without using force/torque sensors at the contact points. The approach is evaluated on a dual-arm platform manipulating a rigid object while coping with unknown object dynamics and human interaction.
ER  - 

TY  - CONF
TI  - Whole-Body Sensory Concept for Compliant Mobile Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5429
EP  - 5435
AU  - M. Kollmitz
AU  - D. Büscher
AU  - T. Schubert
AU  - W. Burgard
PY  - 2018
KW  - compliance control
KW  - filtering theory
KW  - force sensors
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - neurocontrollers
KW  - path planning
KW  - torque control
KW  - compliant mobile robots
KW  - mobile robot navigation
KW  - direct physical contact
KW  - intuitive communication
KW  - physical interaction
KW  - disturbance forces
KW  - mobile platform
KW  - neural network approach
KW  - distance sensors
KW  - mobile robot applications
KW  - whole-body sensory
KW  - model-free filtering approach
KW  - 6-DoF force-torque sensor
KW  - robot-human interaction
KW  - Robot sensing systems
KW  - Force
KW  - Mobile robots
KW  - Collision avoidance
KW  - Oscillators
DO  - 10.1109/ICRA.2018.8460510
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Most of the conventional approaches to mobile robot navigation avoid any kind of contact with the environment or with humans. As nowadays distance sensors typically have a limited - and often only two-dimensional - field of view, collisions with the environment or contacts with humans cannot be fully avoided in practical mobile robot applications. On the other hand, direct physical contact can be used for intuitive communication between a robot and humans. In this paper, we present a whole-body sensory concept based on a 6-DoF force-torque sensor to perceive physical interaction between the robot and humans. To distinguish between external contact and disturbance forces that result from the motion of the mobile platform or oscillations, we present a novel model-free filtering approach based on a neural network. In extensive experiments carried out with our robot Canny we demonstrate the effectiveness and advantages of the neural network approach, which clearly outperforms a classical model-based one.
ER  - 

TY  - CONF
TI  - Robust, Compliant Assembly via Optimal Belief Space Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5436
EP  - 5443
AU  - F. Wirnshofer
AU  - P. S. Schmitt
AU  - W. Feiten
AU  - G. v. Wichert
AU  - W. Burgard
PY  - 2018
KW  - assembling
KW  - CAD
KW  - friction
KW  - geometry
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - planning (artificial intelligence)
KW  - probability
KW  - robot dynamics
KW  - uncertain systems
KW  - compliant assembly
KW  - optimal belief space planning
KW  - automated manufacturing
KW  - robots
KW  - nonlinear contact-dynamics
KW  - model parameters
KW  - belief space planning problem
KW  - compliant system
KW  - asymptotically optimal belief space planner
KW  - kinodynamic motion planner
KW  - asymptotic optimality
KW  - multiple assembly tasks
KW  - CAD models
KW  - state spaces
KW  - object poses
KW  - geometry
KW  - friction
KW  - uncertainty
KW  - impedance-control
KW  - nondeterministic domains
KW  - probabilistic completeness
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Uncertainty
KW  - Task analysis
KW  - Aerospace electronics
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460995
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In automated manufacturing, robots must reliably assemble parts of various geometries and low tolerances. Ideally, they plan the required motions autonomously. This poses a substantial challenge due to high-dimensional state spaces and non-linear contact-dynamics. Furthermore, object poses and model parameters, such as friction, are not exactly known and a source of uncertainty. The method proposed in this paper models the task of parts assembly as a belief space planning problem over an underlying impedance-controlled, compliant system. To solve this planning problem we introduce an asymptotically optimal belief space planner by extending an optimal, randomized, kinodynamic motion planner to nondeterministic domains. Under an expansiveness assumption we establish probabilistic completeness and asymptotic optimality. We validate our approach in thorough, simulated and realworld experiments of multiple assembly tasks. The experiments demonstrate our planner's ability to reliably assemble objects, solely based on CAD models as input.
ER  - 

TY  - CONF
TI  - Cooperative Manipulation and Identification of a 2-DOF Articulated Object by a Dual-Arm Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5445
EP  - 5451
AU  - D. Almeida
AU  - Y. Karayiannidis
PY  - 2018
KW  - manipulators
KW  - dual-arm robot
KW  - dual-arm manipulation
KW  - motion directions
KW  - motion constraints
KW  - coordinated task space frameworks
KW  - redundancy exploitation
KW  - robot arms
KW  - two degrees-of-freedom articulated object
KW  - Task analysis
KW  - Robot kinematics
KW  - Manipulators
KW  - Uncertainty
KW  - Kinematics
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460511
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we address the dual-arm manipulation of a two degrees-of-freedom articulated object that consists of two rigid links. This can include a linkage constrained along two motion directions, or two objects in contact, where the contact imposes motion constraints. We formulate the problem as a cooperative task, which allows the employment of coordinated task space frameworks, thus enabling redundancy exploitation by adjusting how the task is shared by the robot arms. In addition, we propose a method that can estimate the joint location and the direction of the degrees-of-freedom, based on the contact forces and the motion constraints imposed by the object. Experimental results demonstrate the performance of the system in its ability to estimate the two degrees of freedom independently or simultaneously.
ER  - 

TY  - CONF
TI  - A Soft Pneumatic Fabric-Polymer Actuator for Wearable Biomedical Devices: Proof of Concept for Lymphedema Treatment
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5452
EP  - 5458
AU  - E. Suarez
AU  - J. J. Huaroto
AU  - A. A. Reymundo
AU  - D. Holland
AU  - C. Walsh
AU  - E. Vela
PY  - 2018
KW  - bending
KW  - control system synthesis
KW  - elasticity
KW  - force control
KW  - medical robotics
KW  - motion control
KW  - patient monitoring
KW  - pneumatic actuators
KW  - polymers
KW  - manual lymphatic drainage
KW  - human arm
KW  - lateral force
KW  - polymer element
KW  - hyperelastic polymer
KW  - mechanical elements
KW  - robotic device
KW  - soft pneumatic fabric-polymer bending actuator
KW  - rigid actuators
KW  - soft actuators
KW  - wearable biomedical devices
KW  - soft pneumatic fabric-polymer actuator
KW  - lymphedema treatment
KW  - actuator motion
KW  - hyperelastic beam
KW  - polymer beam
KW  - fabric element
KW  - Iron
KW  - Actuators
KW  - Skin
KW  - Fabrics
KW  - Force
KW  - Shape
KW  - Strain
DO  - 10.1109/ICRA.2018.8460790
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft actuators are ideal candidates for wearable biomedical devices, their inherent compliance, robustness, lightweight and the possibility to be washable take advantage over rigid actuators. Thus, a soft pneumatic fabric-polymer bending actuator as a base component for a robotic device for lymphedema treatment is reported in this work. The actuator is composed of two mechanical elements, one made of fabric and the other one made of a hyperelastic polymer which is stuck on the fabric element. The fabric element is designed and fabricated with a curved shape longer than the polymer element, that is a hyperelastic beam. To assemble both elements, the fabric element was folded before sticking in order to match the length of the polymer beam. Once the air is pumped into the fabric, it bends towards its original curved shape. Once the air is removed, the hyperelastic beam allows the actuator to recover its initial position. This actuator is capable of exerting compression and lateral force on a human arm mimicking manual lymphatic drainage. A mathematical model is presented which is in good agreement with the experimental data, it could serve to predict the actuator motion. An end-tip free bending displacement of about 2.2 cm and a bending force of about 0.35 N were achieved at 12.5 kPa. A proof-of-concept system for lymphedema treatment is presented as well.
ER  - 

TY  - CONF
TI  - Force Control of Textile-Based Soft Wearable Robots for Mechanotherapy
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5459
EP  - 5465
AU  - C. J. Payne
AU  - E. G. Hevia
AU  - N. Phipps
AU  - A. Atalay
AU  - O. Atalay
AU  - B. R. Seo
AU  - D. J. Mooney
AU  - C. J. Walsh
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - closed loop systems
KW  - force control
KW  - medical robotics
KW  - patient treatment
KW  - force tracking variability
KW  - force-controlled actuation patterns
KW  - soft robotic system
KW  - open-loop pressure-based control
KW  - soft robotic force control device
KW  - sinusoidal force profiles
KW  - closed-loop force control methodology
KW  - manual mechanotherapy practices
KW  - massage-magnitude forces
KW  - closed-loop force control system
KW  - fully soft sensors
KW  - muscular tissue
KW  - tissue regeneration
KW  - judicious force application
KW  - soft tissues
KW  - mechanotherapeutic applications
KW  - soft robotic wearable devices
KW  - biomedical applications
KW  - soft robotic devices
KW  - textile-based soft wearable robots
KW  - Sensors
KW  - Soft robotics
KW  - Force
KW  - Muscles
KW  - Biological tissues
KW  - Actuators
DO  - 10.1109/ICRA.2018.8461059
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft robotic devices have been utilized in a number of biomedical applications involving human interaction. An emerging opportunity for soft robotic wearable devices is in mechanotherapeutic applications for the recovery and regeneration of soft tissues. Previous studies have implied that judicious force application during mechanotherapy plays an important role in the functional outcome of tissue regeneration. In this paper, we propose soft robotic devices with closed-loop force control to precisely manipulate muscular tissue. The developed devices incorporate fully soft sensors and actuators using textile-based materials and fabrication methods. The closed-loop force control system is demonstrated in bench studies to regulate massage-magnitude forces at frequencies akin to those expected in manual mechanotherapy practices. Testing of the device on human limbs demonstrates the precision and accuracy of the closed-loop force control methodology across different body shapes and types. When commanded to regulate sinusoidal force profiles (with amplitudes of 30N, 45N and 60N), the soft robotic force control device could regulate peak compressive loads to within 0.7N of the desired force. Conversely, open-loop pressure-based control resulted in up to +/-6.6N force tracking variability between participants. A soft robotic system with independently actuatable modules was also fabricated to demonstrate force-controlled actuation patterns to mimic manual massage techniques.
ER  - 

TY  - CONF
TI  - HapWRAP: Soft Growing Wearable Haptic Device
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5466
EP  - 5472
AU  - N. Agharese
AU  - T. Cloyd
AU  - L. H. Blumenschein
AU  - M. Raitor
AU  - E. W. Hawkes
AU  - H. Culbertson
AU  - A. M. Okamura
PY  - 2018
KW  - force feedback
KW  - haptic interfaces
KW  - pneumatic actuators
KW  - polymers
KW  - HapWRAP
KW  - soft growing wearable haptic device
KW  - soft robotics
KW  - lightweight wearable haptic devices
KW  - flexible low density polyethylene
KW  - directional force feedback
KW  - haptic feedback device
KW  - mechanoreceptors
KW  - air flow control
KW  - distributed touch feedback
KW  - pneumatic actuators
KW  - Actuators
KW  - Haptic interfaces
KW  - Soft robotics
KW  - Skin
KW  - Electron tubes
KW  - Pneumatic systems
DO  - 10.1109/ICRA.2018.8460891
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft robotics and pneumatic actuation present opportunities for lightweight wearable haptic devices that provide distributed touch feedback to the skin. Ideally, such devices would be easily donned and doffed, since permanent coverage of a large area of the skin is undesirable. Here we present the design and evaluation of a concept device called HapWRAP: a growing haptic device constructed from flexible low density polyethylene. Controlled air flow through tubes and pouches allows HapWRAP to grow out of a compact housing unit and provide a combination of directional and force feedback to a user. When activated, HapWRAP grows up and around the forearm; its loops form a temporary sleeve. After growth, pneumatic actuators inflate and deflate to stimulate mechanoreceptors in the skin at distinguishable locations. This paper describes the design and manufacturing of HapWRAP, reports its performance metrics, and tests its suitability as a haptic feedback device. Participants were able to interpret force and direction cues from HapWRAP with 92.5% accuracy. These findings suggest that HapWRAP can be successfully used for applications where both force and direction cues are necessary.
ER  - 

TY  - CONF
TI  - Autonomous and Portable Soft Exosuit for Hip Extension Assistance with Online Walking and Running Detection Algorithm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5473
EP  - 5480
AU  - J. Kim
AU  - R. Heimgartner
AU  - G. Lee
AU  - N. Karavas
AU  - D. Perry
AU  - D. L. Ryan
AU  - A. Eckert-Erdheim
AU  - P. Murphy
AU  - D. K. Choe
AU  - I. Galiana
AU  - C. J. Walsh
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - gait analysis
KW  - medical robotics
KW  - patient rehabilitation
KW  - portable hip-only
KW  - augmenting human walking
KW  - different fixed assistance profiles
KW  - online classification algorithm
KW  - mass potential energy fluctuations
KW  - abdomen-mounted IMU
KW  - maximum hip extension
KW  - autonomous wearable robot
KW  - assistance profile individualization
KW  - hip extension assistance
KW  - online walking
KW  - autonomous hip-only
KW  - Legged locomotion
KW  - Hip
KW  - Thigh
KW  - Exoskeletons
KW  - Acceleration
KW  - Force
DO  - 10.1109/ICRA.2018.8460474
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present an autonomous and portable hip-only soft exosuit, for augmenting human walking and running that assists hip extension by delivering peak forces of 300N to the user. Different fixed assistance profiles for walking and running were applied based on an online classification algorithm. The approach is based on the biomechanical understanding that the center of mass potential energy fluctuations during walking and running are out of phase. Specifically, we monitor the vertical acceleration with an abdomen-mounted IMU at the moment of maximum hip extension. Validation is demonstrated with six subjects on the treadmill and with eight subjects outdoors. Our results demonstrated a 99.99% accuracy on average over the fourteen participants for various speeds (0.5 - 4m/s), slopes (-10 -20%), treadmill and overground terrain, loaded (13.6 kg) and unloaded, Exo On and Exo Off conditions, and different shoe types. Results from an evaluation outdoors overground on the energetics of eight subjects demonstrated a significant reduction for running when comparing Exo On to No Exo (3.9%) and for walking and running when comparing Exo On to Exo Off (12.2% and 8.2% respectively). This study represents the first demonstration of an autonomous wearable robot reducing the energy cost of running. Significant variation in response across subjects was observed, highlighting further improvements may be possible via assistance profile individualization with human-in-the-Ioop optimization.
ER  - 

TY  - CONF
TI  - Design and Analysis of a Wearable Robotic Forearm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5489
EP  - 5496
AU  - V. Vatsal
AU  - G. Hoffman
PY  - 2018
KW  - ergonomics
KW  - groupware
KW  - human computer interaction
KW  - human-robot interaction
KW  - manipulator kinematics
KW  - medical robotics
KW  - service robots
KW  - user interfaces
KW  - collaborative tool
KW  - human-human collaboration
KW  - human ergonomic wear limits
KW  - robot autonomy
KW  - lightweight wearable robotic augmentation device
KW  - human-wearable collaboration
KW  - wearable robotic forearm
KW  - close-range human-robot collaboration
KW  - lightweight supernumerary third arm
KW  - shared workspace activities
KW  - functional prototype
KW  - iterative design process
KW  - reachable workspace
KW  - natural human reach
KW  - human-robot interaction
KW  - Solid modeling
KW  - Collaboration
KW  - Manipulators
KW  - Elbow
KW  - Load modeling
KW  - Prototypes
DO  - 10.1109/ICRA.2018.8461212
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the design of a wearable robotic forearm for close-range human-robot collaboration. The robot's function is to serve as a lightweight supernumerary third arm for shared workspace activities. We present a functional prototype resulting from an iterative design process including several user studies. An analysis of the robot's kinematics shows an increase in reachable workspace by 246 % compared to the natural human reach. The robot's degrees of freedom and range of motion support a variety of usage scenarios with the robot as a collaborative tool, including self-handovers, fetching objects while the human's hands are occupied, assisting human-human collaboration, and stabilizing an object. We analyze the bio-mechanical loads for these scenarios and find that the design is able to operate within human ergonomic wear limits. We then report on a pilot human-robot interaction study that indicates robot autonomy is more task-time efficient and preferred by users when compared to direct voice-control. These results suggest that the design presented here is a promising configuration for a lightweight wearable robotic augmentation device, and can serve as a basis for further research into human-wearable collaboration.
ER  - 

TY  - CONF
TI  - Real-Time Learning of Efficient Lift Generation on a Dynamically Scaled Flapping Wing Using Policy Search
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5519
EP  - 5525
AU  - Y. E. Bayiz
AU  - L. Chen
AU  - S. Hsu
AU  - P. Liu
AU  - A. N. Aguiles
AU  - B. Cheng
PY  - 2018
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - learning (artificial intelligence)
KW  - search problems
KW  - efficient lift generation
KW  - policy search algorithm
KW  - real-time robotic learning problem
KW  - dynamically scaled flapping robotic wing
KW  - degrees-of-freedom
KW  - mineral oil
KW  - Reynolds number
KW  - optimal wing pitching amplitude
KW  - stroke-pitch phase difference
KW  - aerodynamic efficiency
KW  - quasisteady aerodynamic mechanism
KW  - wing rotation
KW  - stroke reversal
KW  - unsteady lift generation mechanisms
KW  - stroke amplitude range
KW  - Trajectory
KW  - Heuristic algorithms
KW  - Servomotors
KW  - Real-time systems
KW  - Aerodynamics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8460781
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we present a successful application of a policy search algorithm to a real-time robotic learning problem, where the goal is to maximize the efficiency of lift generation on a dynamically scaled flapping robotic wing. The robotic wing has two degrees-of-freedom, i.e., stroke and pitch, and operates in a tank filled with mineral oil. For all experiments, the Reynolds number is maintained constant at 1000, where learning is performed for different prescribed stroke amplitudes to find the optimal wing pitching amplitude and the stroke-pitch phase difference that maximize the power loading (PL) of lift generation, a measure of aerodynamic efficiency. For the investigated stroke amplitude range (30°-90°), the efficiency is observed to increase with the stroke amplitude and the lift is mainly generated through the delayed stall, a quasi-steady aerodynamic mechanism. Furthermore, the wing rotation becomes more asymmetric with respect to stroke reversal as the stroke amplitude decreases, indicating an increased use of unsteady lift generation mechanisms at lower stroke amplitudes.
ER  - 

TY  - CONF
TI  - Exploration and Inspection with Vine-Inspired Continuum Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5526
EP  - 5533
AU  - M. Wooten
AU  - C. Frazelle
AU  - I. D. Walker
AU  - A. Kapadia
AU  - J. H. Lee
PY  - 2018
KW  - inspection
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - shape control
KW  - motion generation
KW  - robot tendril hardware
KW  - International Space Station
KW  - NASA Johnson Space Center
KW  - continuum robot backbones
KW  - theoretical plant growth-inspired approach
KW  - inspection operations
KW  - long thin continuum robot exploration
KW  - vine-inspired movement strategies
KW  - robot access
KW  - thin-stemmed plants
KW  - vine-inspired continuum robots
KW  - Tendons
KW  - Strain
KW  - Adaptation models
KW  - Hardware
KW  - Robot kinematics
KW  - Inspection
DO  - 10.1109/ICRA.2018.8461132
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we show how structures and strategies employed by thin-stemmed plants can be adapted to improve robot access to unstructured and congested environments. Specifically, we show how the use of vine-inspired movement strategies can enhance long thin continuum robot exploration and inspection operations. We introduce a new theoretical plant growth-inspired approach for modeling and motion generation of continuum robot backbones. The approach is demonstrated in numerous experiments including inspection within a high fidelity, full-scale mock-up of the International Space Station at NASA Johnson Space Center, using novel robot tendril hardware.
ER  - 

TY  - CONF
TI  - The Role of Massive Morphing Wings for Maneuvering a Bio-Inspired Bat-Like Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5534
EP  - 5539
AU  - J. Colorado
AU  - C. Rossi
AU  - A. Barrientos
AU  - A. Parra
AU  - C. Devia
AU  - D. Patino
PY  - 2018
KW  - aerospace components
KW  - biomimetics
KW  - mobile robots
KW  - position control
KW  - robot dynamics
KW  - rolling torques
KW  - pitch torque generation
KW  - massive morphing wings
KW  - bio-inspired bat-like robot
KW  - inertial effects
KW  - wing shape
KW  - robotic platform
KW  - massive morphing-wings
KW  - wingbeats
KW  - Robots
KW  - Aerodynamics
KW  - Trajectory
KW  - Heuristic algorithms
KW  - Elbow
DO  - 10.1109/ICRA.2018.8460829
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present an approach for analyzing the inertial effects of changing the wing shape for steering a bat-like robot. Using BaTboT, a robotic platform with massive morphing-wings, we have estimated the generation of pitching and rolling torques, which are directly related to forward and turning maneuvers. Results let us conclude that faster retraction of the wings during the upstroke, and slower extension during the downstroke increase both pitching and rolling torques in about 50% compared to those wingbeats with equal periods for retraction/extension. Also, we determined that the pitch torque generation is proportional to 0.6m1/f, whereas the rolling torque is promotional to 0.1m1/f, being m the mass of the robot and f the flapping frequency of the wings.
ER  - 

TY  - CONF
TI  - Stability and Predictability in Dynamically Complex Physical Interactions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5540
EP  - 5545
AU  - S. Bazzi
AU  - J. Ebert
AU  - N. Hogan
AU  - D. Sternad
PY  - 2018
KW  - human-robot interaction
KW  - pendulums
KW  - perturbation techniques
KW  - robust control
KW  - trajectory control
KW  - human control strategy
KW  - suspended pendulum
KW  - cart-pendulum system
KW  - assistive perturbations
KW  - resistive perturbations
KW  - trajectory stability
KW  - cart trajectories
KW  - robust control strategies
KW  - dynamically complex physical interactions
KW  - stability properties
KW  - human-object interaction
KW  - simplified 2D model
KW  - virtual implementation
KW  - Perturbation methods
KW  - Task analysis
KW  - Trajectory
KW  - Robots
KW  - Mathematical model
KW  - Stability analysis
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2018.8460774
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This study examines human control of physical interaction with objects that exhibit complex (nonlinear, chaotic, underactuated) dynamics. We hypothesized that humans exploited stability properties of the human-object interaction. Using a simplified 2D model for carrying a “cup of coffee”, we developed a virtual implementation to identify human control strategies. Transporting a cup of coffee was modeled as a cart with a suspended pendulum, where humans moved the cart on a horizontal line via a robotic manipulandum. The specific task was to transport the cart-pendulum system to a target, as fast as possible, while accommodating assistive and resistive perturbations. To assess trajectory stability, we applied contraction analysis. We showed that when the perturbation was assistive, humans absorbed the perturbation by controlling cart trajectories into a contraction region prior to the perturbation. When the perturbation was resistive, subjects passed through a contraction region following the perturbation. Entering a contraction region stabilizes performance and makes the dynamics more predictable. This human control strategy could inspire more robust control strategies for physical interaction in robots.
ER  - 

TY  - CONF
TI  - First Autonomous Multi-Room Exploration with an Insect-Inspired Flapping Wing Vehicle
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5546
EP  - 5552
AU  - K. Y. W. Scheper
AU  - M. Karásek
AU  - C. De Wagter
AU  - B. D. W. Remes
AU  - G. C. H. E. De Croon
PY  - 2018
KW  - autonomous aerial vehicles
KW  - image colour analysis
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - stereo image processing
KW  - multiroom exploration task
KW  - DelFly Explorer
KW  - autonomous indoor exploration mission
KW  - room exploration
KW  - stereo-vision based droplet algorithm
KW  - heading-based door passage algorithm
KW  - flapping wing vehicles
KW  - autonomous exploration tasks
KW  - autonomous multiroom exploration
KW  - wing vehicle
KW  - MAVs
KW  - autonomous indoor navigation
KW  - rotary wings
KW  - flapping wing MAV
KW  - stereo vision system
KW  - microair vehicles
KW  - monocular color based Snake-gate algorithm
KW  - Task analysis
KW  - Robot sensing systems
KW  - Navigation
KW  - Collision avoidance
KW  - Cameras
KW  - Image color analysis
DO  - 10.1109/ICRA.2018.8460702
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the emerging tasks for Micro Air Vehicles (MAVs) is autonomous indoor navigation. While commonly employed platforms for such tasks are micro-quadrotors, insect-inspired flapping wing MAVs can offer many advantages, such as being inherently safe due to their low inertia, reciprocating wings bouncing of objects or potentially lower noise levels compared to rotary wings. Here, we present the first flapping wing MAV to perform an autonomous multi-room exploration task. Equipped with an on-board autopilot and a 4 g stereo vision system, the DelFly Explorer succeeded in combining the two most common tasks of an autonomous indoor exploration mission: room exploration and door passage. During the room exploration, the vehicle uses stereo-vision based droplet algorithm to avoid and navigate along the walls and obstacles. Simultaneously, it is running a newly developed monocular color based Snake-gate algorithm to locate doors. A successful detection triggers the heading-based door passage algorithm. In the real-world test, the vehicle could successfully navigate, multiple times in a row, between two rooms separated by a corridor, demonstrating the potential of flapping wing vehicles for autonomous exploration tasks.
ER  - 

TY  - CONF
TI  - Evaluating Robust Trajectory Control of a Miniature Rolling and Spinning Robot in Outdoor Conditions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5553
EP  - 5560
AU  - A. R. Chowdhury
AU  - G. S. Soh
AU  - S. H. Foong
AU  - K. L. Wood
PY  - 2018
KW  - adaptive control
KW  - control system synthesis
KW  - feedback
KW  - legged locomotion
KW  - motion control
KW  - nonlinear control systems
KW  - robust control
KW  - trajectory control
KW  - variable structure systems
KW  - robust trajectory control
KW  - spinning robot mechanism
KW  - robot stability
KW  - trajectory following accuracy
KW  - wheel velocity response
KW  - ASMC controller
KW  - trajectory following control
KW  - miniature spherical rolling robot
KW  - nonlinear adaptive sliding mode
KW  - locomotory rolling patterns
KW  - roll angle stability
KW  - ISMC controller
KW  - integral sliding controller
KW  - Trajectory
KW  - Wheels
KW  - Spinning
KW  - Mobile robots
KW  - Mathematical model
KW  - Robustness
KW  - Spherical Robot
KW  - Rolling gait
KW  - Central Pattern Generator (CPG)
KW  - Trajectory following
KW  - Adaptive sliding mode (ASMC) Control
DO  - 10.1109/ICRA.2018.8460594
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents trajectory following control experiments of a miniature spherical rolling and spinning robot mechanism on three different types of outdoor surfaces. The research is inspired from the efficient locomotory rolling patterns of various insects in unstructured environment. A nonlinear adaptive sliding mode (ASMC) feedback method maintains the robot stability and robustness in the presence of parameter uncertainties and external disturbances. The proposed trajectory following control policy is developed, implemented and tested for the miniature spherical robot on three different types of irregular surfaces in outdoors. Trajectory following accuracy, roll angle stability and wheel velocity response are three parameters measured to evaluate robot performance. ASMC controller is compared with an integral sliding (ISMC) controller. Experimental results show that proposed control policy is able to manage an accurate trajectory following amidst robust control of a rolling and spinning robot on three types of irregular surface in practical outdoor conditions.
ER  - 

TY  - CONF
TI  - Bio-Inspired Tensegrity Flexural Joints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5561
EP  - 5566
AU  - E. Jung
AU  - V. Ly
AU  - N. Cessna
AU  - M. L. Ngo
AU  - D. Castro
AU  - V. SunSpiral
AU  - M. Teodorescu
PY  - 2018
KW  - biomechanics
KW  - manipulator kinematics
KW  - motion control
KW  - tensegrity flexural manipulator
KW  - OpenSim simulation environment
KW  - tension analysis
KW  - human leg behavior
KW  - tensegrity manipulator
KW  - revolute joint
KW  - robotics literature model
KW  - bio-inspired tensegrity flexural joints
KW  - Knee
KW  - Legged locomotion
KW  - Joints
KW  - Biological system modeling
KW  - Hip
KW  - Muscles
DO  - 10.1109/ICRA.2018.8461027
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Most robotics literature model the human's knee and hip as a revolute joint with limited range of rotation. Although somehow close to reality, this approach neglects a critical aspect of these joints, which is their internal flexibility. This paper presents a prototype tensegrity flexural manipulator whose kinematic behavior is inspired by human leg's gait. This prototype, which considers a hybrid (flexible-rigid) structure of the knee and hip would be able to better approximate real behavior and hopefully lead to a better design of artificial (prosthetic) knees and hips. The behavior of the proposed tensegrity manipulator was firstly predicted using OpenSim simulation environment. The paper reports the comparisons between the simulations, physical prototypes and human leg behavior for a variety of ranges of motions and tension analysis.
ER  - 

TY  - CONF
TI  - Grasp Quality Evaluation with Whole Arm Kinematic Noise Propagation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5575
EP  - 5581
AU  - S. Liu
AU  - S. Carpin
PY  - 2018
KW  - grippers
KW  - manipulator kinematics
KW  - path planning
KW  - probability
KW  - robust control
KW  - arm configurations
KW  - force closure region
KW  - kinematic robot structure
KW  - arm kinematic noise propagation
KW  - grasp quality evaluation
KW  - local robustness
KW  - arm configuration
KW  - grasp quality metric
KW  - redundant robot
KW  - Measurement
KW  - Force
KW  - Kinematics
KW  - Manipulators
KW  - Ellipsoids
KW  - Random variables
DO  - 10.1109/ICRA.2018.8460715
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a new approach to evaluate grasps that accounts for both the kinematic structure of the robot and the noise at its joints. Our starting observation is that with a redundant robot the same grasp can be implemented with different arm configurations, and these may display significant differences in terms of robustness to disturbances. Consequently, the grasp quality metric is seen as a random variable depending on the arm configuration. Starting from a first order approximation for the error, we introduce the high probability force closure region as a tool to evaluate the local robustness of an arm configuration, and we then introduce a new metric Qarm to rank different configurations according to the robustness to noise. By combining this method in an offline/online framework, we demonstrate through large scale simulations that this approach successfully captures aspects that were neglected in former literature regarding grasp evaluation, and can successfully be integrated into future grasp planners.
ER  - 

TY  - CONF
TI  - Realtime Planning for High-DOF Deformable Bodies Using Two-Stage Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5582
EP  - 5589
AU  - Z. Pan
AU  - D. Manocha
PY  - 2018
KW  - collision avoidance
KW  - finite element analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - neurocontrollers
KW  - path planning
KW  - position control
KW  - realtime planning
KW  - high-DOF deformable bodies
KW  - arbitrarily-shaped volumetric deformable bodies
KW  - complex environments
KW  - high-dimensional configuration spaces
KW  - dynamics constraints
KW  - two-stage learning method
KW  - multitask controller
KW  - dynamic movement primitives
KW  - neural-network controller
KW  - DMP task
KW  - finite element method
KW  - contact invariant optimization
KW  - gradient-based method
KW  - two-stage learning algorithm
KW  - trained DMP controller
KW  - different navigation tasks
KW  - learned motion planner
KW  - walking deformable robots
KW  - obstacle avoidance
KW  - Deep Q-Learning
KW  - Planning
KW  - Deformable models
KW  - Robots
KW  - Finite element analysis
KW  - Strain
KW  - Computational modeling
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460602
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a method for planning the motion of arbitrarily-shaped volumetric deformable bodies or robots through complex environments. Such robots have very high-dimensional configuration spaces and we compute trajectories that satisfy the dynamics constraints using a two-stage learning method. First, we train a multitask controller parameterized using dynamic movement primitives (DMP), which encodes various locomotion or movement skills. Next, we train a neural-network controller to select the DMP task to navigate the robot through environments while avoiding obstacles. By combining the finite element method (FEM), model reduction, and contact invariant optimization (CIO), the DMP controller's parameters can be optimized efficiently using a gradient-based method, while the neural-network's parameters are optimized using Deep Q-Learning (DQL). This two-stage learning algorithm also allows us to reuse the trained DMP controller for different navigation tasks, such as moving through different environmental types and to different goal positions. Our results show that the learned motion planner can navigate swimming and walking deformable robots with thousands of DOFs at realtime.
ER  - 

TY  - CONF
TI  - Grasping Flat Objects by Exploiting Non-Convexity of the Object and Support Surface
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5606
EP  - 5611
AU  - I. Sarantopoulos
AU  - Y. Koveos
AU  - Z. Doulgeri
PY  - 2018
KW  - concave programming
KW  - dexterous manipulators
KW  - geometry
KW  - grippers
KW  - nonconvexity
KW  - support surface
KW  - grasp strategy
KW  - environmental contact
KW  - nonconvex geometry
KW  - object-surface combination
KW  - domestic flat objects grasping
KW  - Grasping
KW  - Robots
KW  - Three-dimensional displays
KW  - Color
KW  - Geometry
KW  - Grippers
KW  - Visualization
DO  - 10.1109/ICRA.2018.8461192
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we propose a grasp strategy which exploits environmental contact for grasping domestic flat objects placed or hinged on support surfaces. The proposed grasp strategy considers the non-convex geometry of the object-surface combination, as this appears in objects like plates on tables or handles on cupboards. Following the fact that state-of-the-art grasp planners fail to produce candidate grasps for flat objects due to the environmental constraint of the support surface, this work utilizes compliant interaction of the hand with the support surface, inspired by human grasp strategies.
ER  - 

TY  - CONF
TI  - Caging Loops in Shape Embedding Space: Theory and Computation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5612
EP  - 5619
AU  - J. Liu
AU  - S. Xin
AU  - Z. Gao
AU  - K. Xu
AU  - C. Tu
AU  - B. Chen
PY  - 2018
KW  - geometry
KW  - grippers
KW  - object detection
KW  - robot vision
KW  - topology
KW  - shape embedding space
KW  - robot gripper
KW  - surface geometry
KW  - caging grasps
KW  - Caging Loops
KW  - target object
KW  - Grasping
KW  - Grippers
KW  - Robots
KW  - Shape
KW  - Geometry
KW  - Topology
KW  - Robustness
DO  - 10.1109/ICRA.2018.8461206
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose to synthesize feasible caging grasps for a target object through computing Caging Loops, a closed curve defined in the shape embedding space of the object. Different from the traditional methods, our approach decouples caging loops from the surface geometry of target objects through working in the embedding space. This enables us to synthesize caging loops encompassing multiple topological holes, instead of always tied with one specific handle which could be too small to be graspable by the robot gripper. Our method extracts caging loops through a topological analysis of the distance field defined for the target surface in the embedding space, based on a rigorous theoretical study on the relation between caging loops and the field topology. Due to the decoupling, our method can tolerate incomplete and noisy surface geometry of an unknown target object captured on-the-fly. We implemented our method with a robotic gripper and demonstrate through extensive experiments that our method can synthesize reliable grasps for objects with complex surface geometry and topology and in various scales.
ER  - 

TY  - CONF
TI  - Dex-Net 3.0: Computing Robust Vacuum Suction Grasp Targets in Point Clouds Using a New Analytic Model and Deep Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5620
EP  - 5627
AU  - J. Mahler
AU  - M. Matl
AU  - X. Liu
AU  - A. Li
AU  - D. Gealy
AU  - K. Goldberg
PY  - 2018
KW  - convolution
KW  - dexterous manipulators
KW  - end effectors
KW  - feedforward neural nets
KW  - grippers
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - deep learning
KW  - vacuum-based end effectors
KW  - multifinger grippers
KW  - suction cup
KW  - external wrenches
KW  - pneumatic suction gripper
KW  - point clouds
KW  - grasp quality convolutional neural network
KW  - robust vacuum suction grasp targets
KW  - gravity wrench
KW  - parallel-jaw grippers
KW  - object pose
KW  - material properties
KW  - GQ-CNN
KW  - ABB YuMi
KW  - adversarial
KW  - Three-dimensional displays
KW  - Robustness
KW  - Robots
KW  - Analytical models
KW  - Seals
KW  - Computational modeling
KW  - Planning
DO  - 10.1109/ICRA.2018.8460887
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Vacuum-based end effectors are widely used in industry and are often preferred over parallel-jaw and multifinger grippers due to their ability to lift objects with a single point of contact. Suction grasp planners often target planar surfaces on point clouds near the estimated centroid of an object. In this paper, we propose a compliant suction contact model that computes the quality of the seal between the suction cup and local target surface and a measure of the ability of the suction grasp to resist an external gravity wrench. To characterize grasps, we estimate robustness to perturbations in end-effector and object pose, material properties, and external wrenches. We analyze grasps across 1,500 3D object models to generate Dex-Net 3.0, a dataset of 2.8 million point clouds, suction grasps, and grasp robustness labels. We use Dex-Net 3.0 to train a Grasp Quality Convolutional Neural Network (GQ-CNN) to classify robust suction targets in point clouds containing a single object. We evaluate the resulting system in 350 physical trials on an ABB YuMi fitted with a pneumatic suction gripper. When evaluated on novel objects that we categorize as Basic (prismatic or cylindrical), Typical (more complex geometry), and Adversarial (with few available suction-grasp points) Dex-Net 3.0 achieves success rates of 98%, 82%, and 58% respectively, improving to 81% in the latter case when the training set includes only adversarial objects. Code, datasets, and supplemental material can be found at http://berkeleyautomation.github.io/dex-net.
ER  - 

TY  - CONF
TI  - Deep Imitation Learning for Complex Manipulation Tasks from Virtual Reality Teleoperation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5628
EP  - 5635
AU  - T. Zhang
AU  - Z. McCarthy
AU  - O. Jow
AU  - D. Lee
AU  - X. Chen
AU  - K. Goldberg
AU  - P. Abbeel
PY  - 2018
KW  - control engineering computing
KW  - human-robot interaction
KW  - learning by example
KW  - manipulators
KW  - neural nets
KW  - robot programming
KW  - robot vision
KW  - telerobotics
KW  - virtual reality
KW  - virtual reality teleoperation
KW  - robot skill acquisition
KW  - raw pixels
KW  - consumer-grade Virtual Reality headsets
KW  - hand tracking hardware
KW  - deep neural network policies
KW  - manipulation tasks
KW  - deep imitation learning
KW  - PR2 robot
KW  - RGB-D images
KW  - Robots
KW  - Task analysis
KW  - Neural networks
KW  - Three-dimensional displays
KW  - Head
KW  - Visualization
KW  - Grippers
DO  - 10.1109/ICRA.2018.8461249
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Imitation learning is a powerful paradigm for robot skill acquisition. However, obtaining demonstrations suitable for learning a policy that maps from raw pixels to actions can be challenging. In this paper we describe how consumer-grade Virtual Reality headsets and hand tracking hardware can be used to naturally teleoperate robots to perform complex tasks. We also describe how imitation learning can learn deep neural network policies (mapping from pixels to actions) that can acquire the demonstrated skills. Our experiments showcase the effectiveness of our approach for learning visuomotor skills.
ER  - 

TY  - CONF
TI  - Accelerated Testing and Evaluation of Autonomous Vehicles via Imitation Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5636
EP  - 5642
AU  - G. E. Mullins
AU  - A. G. Dress
AU  - P. G. Stankiewicz
AU  - J. D. Appler
AU  - S. K. Gupta
PY  - 2018
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - life testing
KW  - mobile robots
KW  - neurocontrollers
KW  - regression analysis
KW  - autonomous vehicle
KW  - imitation learning
KW  - surrogate agents
KW  - test scenario generation
KW  - performance modes
KW  - deep neural networks
KW  - imitator surrogates
KW  - mission performance
KW  - simulation-based testing
KW  - on-line imitation
KW  - complex mission
KW  - target vehicle
KW  - behavioral modes
KW  - dataset aggregation
KW  - collision avoidance
KW  - Testing
KW  - Training
KW  - Autonomous vehicles
KW  - Trajectory
KW  - Adaptation models
KW  - History
DO  - 10.1109/ICRA.2018.8460965
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we investigate the use of surrogate agents to accelerate test scenario generation for autonomous vehicles. Our goal is to train the surrogate to replicate the true performance modes of the system. We create these surrogates by utilizing imitation learning with deep neural networks. By using imitator surrogates in place of the true agent, we are capable of predicting mission performance more quickly, gaining greater throughput for simulation-based testing. We demonstrate that using on-line imitation learning with Dataset Aggregation (DAgger) can not only correctly encode a policy that executes a complex mission, but can also encode multiple different behavioral modes. To improve performance for the target vehicle and mission, we manipulate the training set during each iteration to remove samples which do not contribute to the final policy. We call this approach Quantile-DAgger (Q-DAgger) and demonstrate its ability to replicate the behaviors of an autonomous vehicle in a collision avoidance scenario.
ER  - 

TY  - CONF
TI  - Feature-Based Transfer Learning for Robotic Push Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5643
EP  - 5650
AU  - J. Stüber
AU  - M. Kopicki
AU  - C. Zito
PY  - 2018
KW  - CAD
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - contact models
KW  - motion models
KW  - point cloud object model
KW  - CAD model
KW  - contact-based predictors
KW  - robotic push manipulation
KW  - feature-based transfer learning
KW  - Robots
KW  - Three-dimensional displays
KW  - Predictive models
KW  - Solid modeling
KW  - Kernel
KW  - Probability density function
KW  - Training
DO  - 10.1109/ICRA.2018.8460989
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a data-efficient approach to learning transferable forward models for robotic push manipulation. Our approach extends our previous work on contact-based predictors by leveraging information on the pushed object's local surface features. We test the hypothesis that, by conditioning predictions on local surface features, we can achieve generalisation across objects of different shapes. In doing so, we do not require a CAD model of the object but rather rely on a point cloud object model (PCOM). Our approach involves learning motion models that are specific to contact models. Contact models encode the contacts seen during training time and allow generating similar contacts at prediction time. Predicting on familiar ground reduces the motion models' sample complexity while using local contact information for prediction increases their transferability. In extensive experiments in simulation, our approach is capable of transfer learning for various test objects, outperforming a baseline predictor. We support those results with a proof of concept on a real robot.
ER  - 

TY  - CONF
TI  - Inducing Probabilistic Context-Free Grammars for the Sequencing of Movement Primitives
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5651
EP  - 5658
AU  - R. Lioutikov
AU  - G. Maeda
AU  - F. Veiga
AU  - K. Kersting
AU  - J. Peters
PY  - 2018
KW  - Bayes methods
KW  - context-free grammars
KW  - formal languages
KW  - grammars
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - Monte Carlo methods
KW  - motion control
KW  - probability
KW  - robot dynamics
KW  - robots
KW  - rule-based nature
KW  - formal grammars
KW  - complex robot policies
KW  - composing primitives
KW  - modern robotics
KW  - inducing probabilistic context-free grammars
KW  - simple movement primitives
KW  - complex sequences
KW  - degree-of-freedom lightweight robotic arm
KW  - Markov Chain Monte Carlo optimization
KW  - grammar space
KW  - robot movement primitives
KW  - physical nature
KW  - yet unsolved challenge
KW  - complicated challenge
KW  - way robot policies
KW  - hierarchical concept
KW  - recursively structured tasks
KW  - hierarchically tasks
KW  - Grammar
KW  - Robots
KW  - Task analysis
KW  - Probabilistic logic
KW  - Sequential analysis
KW  - Markov processes
KW  - Optimization
DO  - 10.1109/ICRA.2018.8460190
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Movement Primitives are a well studied and widely applied concept in modern robotics. Composing primitives out of an existing library, however, has shown to be a challenging problem. We propose the use of probabilistic context-free grammars to sequence a series of primitives to generate complex robot policies from a given library of primitives. The rule-based nature of formal grammars allows an intuitive encoding of hierarchically and recursively structured tasks. This hierarchical concept strongly connects with the way robot policies can be learned, organized, and re-used. However, the induction of context-free grammars has proven to be a complicated and yet unsolved challenge. In this work, we exploit the physical nature of robot movement primitives to restrict and efficiently search the grammar space. The grammar is learned applying a Markov Chain Monte Carlo optimization over the posteriors of the grammars given the observations. The proposal distribution is defined as a mixture over the probabilities of the operators connecting the search space. Restrictions to these operators guarantee continuous sequences while reducing the grammar space. We validate our method on a redundant 7 degree-of-freedom lightweight robotic arm on tasks that require the generation of complex sequences consisting of simple movement primitives.
ER  - 

TY  - CONF
TI  - Synthetically Trained Neural Networks for Learning Human-Readable Plans from Real-World Demonstrations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5659
EP  - 5666
AU  - J. Tremblay
AU  - T. To
AU  - A. Molchanov
AU  - S. Tyree
AU  - J. Kautz
AU  - S. Birchfield
PY  - 2018
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - robots
KW  - convolutional pose machines
KW  - human-readable plans learning
KW  - domain randomization
KW  - Baxter robot
KW  - image space
KW  - synthetic images
KW  - perception network
KW  - program execution
KW  - program generation
KW  - human-readable program
KW  - synthetically trained neural networks
KW  - world space
KW  - Task analysis
KW  - Training
KW  - Neural networks
KW  - Robot sensing systems
KW  - Robustness
KW  - Stacking
DO  - 10.1109/ICRA.2018.8460642
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a system to infer and execute a human-readable program from a real-world demonstration. The system consists of a series of neural networks to perform perception, program generation, and program execution. Leveraging convolutional pose machines, the perception network reliably detects the bounding cuboids of objects in real images even when severely occluded, after training only on synthetic images using domain randomization. To increase the applicability of the perception network to new scenarios, the network is formulated to predict in image space rather than in world space. Additional networks detect relationships between objects, generate plans, and determine actions to reproduce a real-world demonstration. The networks are trained entirely in simulation, and the system is tested in the real world on the pick-and-place problem of stacking colored cubes using a Baxter robot.
ER  - 

TY  - CONF
TI  - Generalized Task-Parameterized Skill Learning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5667
EP  - 5474
AU  - Y. Huang
AU  - J. Silvério
AU  - L. Rozo
AU  - D. G. Caldwell
PY  - 2018
KW  - Gaussian processes
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mixture models
KW  - motion control
KW  - robot programming
KW  - generalized task-parameterized skill learning
KW  - human skills
KW  - task-parameterized Gaussian mixture model
KW  - TP-GMM
KW  - human-robot collaboration
KW  - dual-arm manipulation
KW  - learning framework
KW  - task parameters
KW  - robot joint limits
KW  - task-parameterized learning
KW  - learned skills
KW  - real robotic systems
KW  - task constraints
KW  - learning perspective
KW  - Programming by demonstration
KW  - Task analysis
KW  - Trajectory
KW  - Robot kinematics
KW  - Optimization
KW  - Feature extraction
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8461079
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Programming by demonstration has recently gained much attention due to its user-friendly and natural way to transfer human skills to robots. In order to facilitate the learning of multiple demonstrations and meanwhile generalize to new situations, a task-parameterized Gaussian mixture model (TP-GMM) has been recently developed. This model has achieved reliable performance in areas such as human-robot collaboration and dual-arm manipulation. However, the crucial task frames and associated parameters in this learning framework are often set by the human teacher, which renders three problems that have not been addressed yet: (i) task frames are treated equally, without considering their individual importance, (ii) task parameters are defined without taking into account additional task constraints, such as robot joint limits and motion smoothness, and (iii) a fixed number of task frames are pre-defined regardless of whether some of them may be redundant or even irrelevant for the task at hand. In this paper, we generalize the task-parameterized learning by addressing the aforementioned problems. Moreover, we provide a novel learning perspective which allows the robot to refine and adapt previously learned skills in a low dimensional space. Several examples are studied in both simulated and real robotic systems, showing the applicability of our approach.
ER  - 

TY  - CONF
TI  - Teaching Human Teachers to Teach Robot Learners
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5675
EP  - 5681
AU  - A. Sena
AU  - Y. Zhao
AU  - M. J. Howard
PY  - 2018
KW  - automatic programming
KW  - computer aided instruction
KW  - control engineering computing
KW  - data visualisation
KW  - feedback
KW  - human-robot interaction
KW  - robot programming
KW  - robots
KW  - teaching
KW  - robot learners generalisable skills
KW  - demonstration data sets
KW  - ambiguous demonstrations
KW  - teaching phase
KW  - interactive teaching process
KW  - robust teaching process
KW  - human teachers
KW  - heuristic rules
KW  - robot learners teaching
KW  - undemonstrated states
KW  - visual feedback
KW  - programming by demonstration
KW  - PbD
KW  - feedback visualisation
KW  - Task analysis
KW  - Education
KW  - Trajectory
KW  - Robot sensing systems
KW  - Visualization
KW  - Service robots
DO  - 10.1109/ICRA.2018.8461194
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Using Programming by Demonstration to teach robot learners generalisable skills relies on having effective human teachers. This paper aims to address two problems commonly observed in demonstration data sets that arise due to poor teaching strategies; undemonstrated states and ambiguous demonstrations. Overcoming these issues through the use of visual feedback and simple heuristic rules is investigated as a potential way of guiding novice users to more effectively teach robot learners to generalise a task. The proposed method intends to offer the user a more transparent understanding of the robot learner's model state during the teaching phase, to create a more interactive and robust teaching process. Results from a single-factor, three-phase repeated measures study with n=30 participants, comparing the proposed feedback and heuristic rules set against an unguided condition, show a statistically significant (F(2,58)=7.952,p=0.001) improvement of user teaching efficiency of approximately 180% when using the proposed feedback visualisation.
ER  - 

TY  - CONF
TI  - Sensor-Based Reactive Symbolic Planning in Partially Known Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5683
EP  - 5690
AU  - V. Vasilopoulos
AU  - W. Vega-Brown
AU  - O. Arslan
AU  - N. Roy
AU  - D. E. Koditschek
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - sensors
KW  - differential drive robot
KW  - LIDAR sensor
KW  - passive objects
KW  - deliberative planner
KW  - symbolic commands
KW  - obstacle avoidance
KW  - reactive planner
KW  - sensor-based reactive symbolic planning
KW  - nonconvex environments
KW  - convex obstacles
KW  - high-level commands
KW  - Robot sensing systems
KW  - Planning
KW  - Task analysis
KW  - Grippers
KW  - Laser radar
KW  - Collision avoidance
DO  - 10.1109/ICRA.2018.8460861
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper considers the problem of completing assemblies of passive objects in nonconvex environments, cluttered with convex obstacles of unknown position, shape and size that satisfy a specific separation assumption. A differential drive robot equipped with a gripper and a LIDAR sensor, capable of perceiving its environment only locally, is used to position the passive objects in a desired configuration. The method combines the virtues of a deliberative planner generating high-level, symbolic commands, with the formal guarantees of convergence and obstacle avoidance of a reactive planner that requires little onboard computation and is used online. The validity of the proposed method is verified both with formal proofs and numerical simulations.
ER  - 

TY  - CONF
TI  - Near-optimal Irrevocable Sample Selection for Periodic Data Streams with Applications to Marine Robotics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5691
EP  - 5698
AU  - G. Flaspohler
AU  - N. Roy
AU  - Y. Girdhar
PY  - 2018
KW  - autonomous underwater vehicles
KW  - environmental science computing
KW  - mobile robots
KW  - optimisation
KW  - sampling methods
KW  - set theory
KW  - spatiotemporal phenomena
KW  - optimal irrevocable sample selection
KW  - periodic data streams
KW  - marine robotics
KW  - spatiotemporal phenomena
KW  - classical secretary problem
KW  - random order
KW  - environmental monitoring domains
KW  - spatiotemporal structure
KW  - representative samples
KW  - periodic structure
KW  - monotone submodular utility function
KW  - Martha's Vineyard Coastal Observatory
KW  - phytoplankton sample locations
KW  - information-theoretic sense
KW  - periodic secretary algorithm
KW  - theoretical performance guarantees
KW  - sample selection algorithm
KW  - environmental dataset
KW  - optimal sample set
KW  - Entropy
KW  - Mutual information
KW  - Robot sensing systems
KW  - Prediction algorithms
KW  - Real-time systems
KW  - Periodic structures
DO  - 10.1109/ICRA.2018.8460709
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the task of monitoring spatiotemporal phenomena in real-time by deploying limited sampling resources at locations of interest irrevocably and without knowledge of future observations. This task can be modeled as an instance of the classical secretary problem. Although this problem has been studied extensively in theoretical domains, existing algorithms require that data arrive in random order to provide performance guarantees. These algorithms will perform arbitrarily poorly on data streams such as those encountered in robotics and environmental monitoring domains, which tend to have spatiotemporal structure. We focus on the problem of selecting representative samples from phenomena with periodic structure and introduce a novel sample selection algorithm that recovers a near-optimal sample set according to any monotone submodular utility function. We evaluate our algorithm on a seven-year environmental dataset collected at the Martha's Vineyard Coastal Observatory and show that it selects phytoplankton sample locations that are nearly optimal in an information-theoretic sense for predicting phytoplankton concentrations in locations that were not directly sampled. The proposed periodic secretary algorithm can be used with theoretical performance guarantees in many real-time sensing and robotics applications for streaming, irrevocable sample selection from periodic data streams.
ER  - 

TY  - CONF
TI  - Autonomous Feature Tracing and Adaptive Sampling in Real-World Underwater Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5699
EP  - 5704
AU  - A. Quraishi
AU  - A. Bahr
AU  - F. Schill
AU  - A. Martinoli
PY  - 2018
KW  - autonomous underwater vehicles
KW  - lakes
KW  - mobile robots
KW  - temperature sensors
KW  - real-world operation
KW  - adaptive sampling missions
KW  - AUV
KW  - Autonomous feature tracing
KW  - real-world Underwater environments
KW  - underwater environmental sensing
KW  - compact high resolution
KW  - temperature sensing module
KW  - microstructure
KW  - turbulence measurements
KW  - sensing requirements
KW  - horizontal variation capture
KW  - water bodies
KW  - Temperature measurement
KW  - Lakes
KW  - Microorganisms
KW  - Robot sensing systems
KW  - Trajectory
KW  - Temperature sensors
DO  - 10.1109/ICRA.2018.8460627
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Applications of robots for gathering data in underwater environments has been limited due to the challenges posed by the medium. We have developed a miniature, agile, easy to carry and deploy Autonomous Underwater Vehicle (AUV) equipped with a suite of sensors for underwater environmental sensing. We have also developed a compact high resolution fast temperature sensing module for the AUV for microstructure and turbulence measurements in water bodies. In this paper, we describe a number of algorithms and subsystems of the AUV that enable autonomous real-world operation, and present the data gathered in an experimental campaign in collaboration with limnologists. We demonstrate adaptive sampling missions where the AUV could autonomously locate a zone of interest and adapt its trajectory to stay in it. Further, it could execute specific behaviors to accommodate special sensing requirements necessary to enhance the quality of the data collected. In these missions, the AUV could autonomously trace a feature and capture horizontal variation in various quantities, including turbidity and temperature fluctuations, allowing limnologists to study lake phenomena in an additional dimension.
ER  - 

TY  - CONF
TI  - Navigating Congested Environments with Risk Level Sets
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5712
EP  - 5719
AU  - A. Pierson
AU  - W. Schwarting
AU  - S. Karaman
AU  - D. Rus
PY  - 2018
KW  - collision avoidance
KW  - mobile robots
KW  - multi-agent systems
KW  - road vehicles
KW  - risk level set
KW  - congested environment navigation
KW  - cluttered environment
KW  - congestion cost
KW  - occupancy risk
KW  - cost function
KW  - planning space
KW  - agent planning
KW  - autonomous vehicle driving
KW  - risk threshold
KW  - conservative behavior
KW  - aggressive behavior
KW  - Planning
KW  - Level set
KW  - Navigation
KW  - Vehicle dynamics
KW  - Autonomous vehicles
KW  - Collision avoidance
KW  - Cost function
DO  - 10.1109/ICRA.2018.8460697
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we address the problem of navigating in a cluttered environment by introducing a congestion cost that maps the density and motion of objects to an occupancy risk. We propose that an agent can choose a “risk level set” from this cost function and construct a planning space from this set. In choosing different levels of risk, the agent adjusts its interactions with the other agents. From the assumption that agents are self-preserving, we show that any agent planning within their risk level set will avoid collisions with other agents. We then present an application of planning with risk level sets in the framework of an autonomous vehicle driving along a highway. Using the risk level sets, the agent can determine safe zones when planning a sequence of lane changes. Through simulations in Matlab, we demonstrate how the choice of risk threshold manifests as aggressive or conservative behavior.
ER  - 

TY  - CONF
TI  - Algorithms for Routing of Unmanned Aerial Vehicles with Mobile Recharging Stations
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5720
EP  - 5725
AU  - K. Yu
AU  - A. K. Budhiraja
AU  - P. Tokekar
PY  - 2018
KW  - autonomous aerial vehicles
KW  - battery powered vehicles
KW  - computational complexity
KW  - travelling salesman problems
KW  - vehicle routing
KW  - Unmanned Aerial Vehicles
KW  - mobile recharging stations
KW  - energy-limited Unmanned Aerial Vehicle
KW  - stationary recharging stations
KW  - Unmanned Ground Vehicles
KW  - UGV
KW  - Traveling Salesperson Problem
KW  - stationary charging stations
KW  - UAV mission
KW  - Routing
KW  - NP-Hard
KW  - Generalized TSP
KW  - Batteries
KW  - Unmanned aerial vehicles
KW  - Charging stations
KW  - Land vehicles
KW  - Optimization
KW  - Monitoring
KW  - Planning
DO  - 10.1109/ICRA.2018.8460819
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We study the problem of finding a tour for an energy-limited Unmanned Aerial Vehicle (UAV) to visit a set of sites in the least amount of time. We envision scenarios where the UAV can be recharged along the way either by landing on stationary recharging stations or on Unmanned Ground Vehicles (UGVs) acting as mobile recharging stations. This leads to a new variant of the Traveling Salesperson Problem (TSP). We present an algorithm that finds not only the order in which to visit the sites but also when and where to land on the charging stations to recharge. Our algorithm plans tours for the UGVs as well as determines best locations to place stationary charging stations. While the problems we study are NP-Hard, we present a practical solution using Generalized TSP that finds the optimal solution. If the UGVs are slower, the algorithm also finds the minimum number of UGVs required to support the UAV mission such that the UAV is not required to wait for the UGV. Our simulation results show that the running time is acceptable for reasonably sized instances.
ER  - 

TY  - CONF
TI  - Topological Multi-Robot Belief Space Planning in Unknown Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5726
EP  - 5732
AU  - A. Kitanov
AU  - V. Indelman
PY  - 2018
KW  - Bayes methods
KW  - graph theory
KW  - multi-robot systems
KW  - path planning
KW  - topology
KW  - graph pruning
KW  - topological properties
KW  - factor graphs
KW  - topological space
KW  - embedded state space
KW  - high-dimensional state spaces
KW  - announced path approach
KW  - topological multirobot belief space planning
KW  - BSP approaches
KW  - factor graph representation
KW  - posterior beliefs
KW  - Planning
KW  - Robot kinematics
KW  - Simultaneous localization and mapping
KW  - Linear programming
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2018.8460772
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we introduce a novel concept, topological belief space planning (BSP), that uses topological properties of the underlying factor graph representation of future posterior beliefs to direct the search for an optimal solution. This concept deviates from state-of-the-art BSP approaches and is motivated by recent results which indicated, in the context of graph pruning, that topological properties of factor graphs dominantly determine the estimation accuracy. Topological space is also often less dimensional than the embedded state space. In particular, we show how this novel concept can be used in multi-robot belief space planning in high-dimensional state spaces to overcome drawbacks of state-of-the-art approaches: computational intractability of an exhaustive objective evaluation for all candidate path combinations from different robots and dependence on the initial guess in the announced path approach, which can lead to a local minimum of the objective function. We demonstrate our approach in a synthetic simulation.
ER  - 

TY  - CONF
TI  - Efficient Stabilization of Zero-Slope Walking for Bipedal Robots Following Their Passive Fixed-Point Trajectories
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5733
EP  - 5738
AU  - A. Smyrli
AU  - G. A. Bertos
AU  - E. Papadopoulos
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - stability
KW  - trajectory control
KW  - biped walking
KW  - stabilization
KW  - control law
KW  - ankle torques
KW  - hip
KW  - counterweight joint
KW  - energy input
KW  - numerical simulations
KW  - semicircular feet
KW  - compliant legs
KW  - passive fixed-point trajectories
KW  - bipedal robots
KW  - zero-slope walking
KW  - passive gaits
KW  - stable gaits
KW  - nonlinear PD terms
KW  - virtual-gravity components
KW  - Legged locomotion
KW  - Foot
KW  - Gravity
KW  - Hip
KW  - Damping
KW  - Torso
KW  - Stability analysis
DO  - 10.1109/ICRA.2018.8460845
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents an efficient method of stabilizing the gait of an underactuated biped with compliant legs and semicircular feet. First, the model is defined, incorporating elements that are often present in experimental biped robots. The biped's passive behavior is studied through numerical simulations that provide insight into the gravity's contribution as an energy input to the system. Based on this study, it is shown that an augmented biped -with the addition of a counterweight joint at the hip- is able to perform stable gaits with minimal input. This design is implemented easily as it does not require ankle torques; instead, both motors are mounted at the biped's hip. The control law used for the stabilization is the combination of virtual-gravity components with non-linear PD terms. The stable gaits performed by the augmented biped on level floor strongly resemble the passive gaits of the original biped walking on a slope, resulting in an efficient, natural-like motion of low transport cost.
ER  - 

TY  - CONF
TI  - Straight-Leg Walking Through Underconstrained Whole-Body Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5747
EP  - 5754
AU  - R. J. Griffin
AU  - G. Wiedebach
AU  - S. Bertrand
AU  - A. Leonessa
AU  - J. Pratt
PY  - 2018
KW  - humanoid robots
KW  - legged locomotion
KW  - quadratic programming
KW  - reachability analysis
KW  - robot kinematics
KW  - straight-leg walking
KW  - whole-body control
KW  - natural gait
KW  - bipedal robots
KW  - straightened legs
KW  - complex height planning
KW  - whole-body controller
KW  - straightest possible leg configuration
KW  - run-time
KW  - controller solutions
KW  - leg joint angle objectives
KW  - null-space
KW  - quadratic program motion objectives
KW  - toe-off motion
KW  - kinematic reachability
KW  - Legged locomotion
KW  - Iterative closest point algorithm
KW  - Trajectory
KW  - Planning
KW  - Acceleration
KW  - Foot
DO  - 10.1109/ICRA.2018.8460751
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present an approach for achieving a natural, efficient gait on bipedal robots using straightened legs and toe-off. Our algorithm avoids complex height planning by allowing a whole-body controller to determine the straightest possible leg configuration at run-time. The controller solutions are biased towards a straight leg configuration by projecting leg joint angle objectives into the null-space of the other quadratic program motion objectives. To allow the legs to remain straight throughout the gait, toe-off was utilized to increase the kinematic reachability of the legs. The toe-off motion is achieved through underconstraining the foot position, allowing it to emerge naturally. We applied this approach of under-specifying the motion objectives to the Atlas humanoid, allowing it to walk over a variety of terrain. We present both experimental and simulation results and discuss performance limitations and potential improvements.
ER  - 

TY  - CONF
TI  - Agile and Adaptive Hopping Height Control for a Pneumatic Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5755
EP  - 5760
AU  - M. F. Hale
AU  - J. L. Du Bois
AU  - P. Iravani
PY  - 2018
KW  - legged locomotion
KW  - pneumatic actuators
KW  - hop height every step
KW  - discontinuous terrain
KW  - safe footholds
KW  - bipedal running
KW  - quadrupedal running
KW  - constrained vertical hopping
KW  - pneumatic robot
KW  - vertical height
KW  - hopping robot
KW  - pneumatically actuated hopper
KW  - Legged locomotion
KW  - Valves
KW  - Computational modeling
KW  - Actuators
KW  - Atmospheric modeling
KW  - Force
DO  - 10.1109/ICRA.2018.8460557
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a controller for the vertical height of a hopping robot. The ability to accurately change the hop height every step will contribute toward the traversal of discontinuous terrain with limited safe footholds, with application to bipedal or quadrupedal running. A key feature of the approach presented is the use of information from previous hops/steps to inform the control of the current step. As well as avoiding modelling errors, this allows the robot to make on-line adjustments in response to changes in system parameters or the environment. The algorithm is simple enough to be easily implemented on a low power hardware, not requiring computationally demanding optimisation or numerical simulation. The effectiveness of this approach has been demonstrated for constrained vertical hopping in simulation and on a pneumatically actuated hopper.
ER  - 

TY  - CONF
TI  - Robust Rough-Terrain Locomotion with a Quadrupedal Robot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5761
EP  - 5768
AU  - P. Fankhauser
AU  - M. Bjelonic
AU  - C. Dario Bellicoso
AU  - T. Miki
AU  - M. Hutter
PY  - 2018
KW  - collision avoidance
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - path planning
KW  - pose estimation
KW  - robot dynamics
KW  - robot kinematics
KW  - terrain mapping
KW  - robust rough-terrain locomotion
KW  - natural settings
KW  - industrial settings
KW  - motion planner
KW  - perceptive rough-terrain locomotion
KW  - safe footholds
KW  - collision-free swing-leg motions
KW  - acquired terrain map
KW  - optimization approach
KW  - significant obstacles
KW  - quadrupedal robot ANYmal
KW  - locomotion planner
KW  - dynamic environments
KW  - urban settings
KW  - pose optimization approach
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Planning
KW  - Collision avoidance
KW  - Surface treatment
DO  - 10.1109/ICRA.2018.8460731
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robots working in natural, urban, and industrial settings need to be able to navigate challenging environments. In this paper, we present a motion planner for the perceptive rough-terrain locomotion with quadrupedal robots. The planner finds safe footholds along with collision-free swing-leg motions by leveraging an acquired terrain map. To this end, we present a novel pose optimization approach that enables the robot to climb over significant obstacles. We experimentally validate our approach with the quadrupedal robot ANYmal by autonomously traversing obstacles such steps, inclines, and stairs. The locomotion planner re-plans the motion at every step to cope with disturbances and dynamic environments. The robot has no prior knowledge of the scene, and all mapping, state estimation, control, and planning is performed in real-time onboard the robot.
ER  - 

TY  - CONF
TI  - Central Pattern Generator With Inertial Feedback for Stable Locomotion and Climbing in Unstructured Terrain
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5769
EP  - 5775
AU  - G. Sartoretti
AU  - S. Shaw
AU  - K. Lam
AU  - N. Fan
AU  - M. Travers
AU  - H. Choset
PY  - 2018
KW  - feedback
KW  - legged locomotion
KW  - motion control
KW  - neurophysiology
KW  - sensory feedback
KW  - inertial feedback
KW  - open-loop control strategy
KW  - complexity
KW  - terrain steepness
KW  - challenging terrains
KW  - steep terrains
KW  - hexapod robot
KW  - steep terrain
KW  - legged locomotion
KW  - body posture
KW  - CPG framework
KW  - level terrain
KW  - open-loop gait generation
KW  - CPG models
KW  - locomotive performance
KW  - gait adaptation
KW  - swimming legged robots
KW  - crawling legged robots
KW  - articulated robots
KW  - gaits
KW  - central pattern generator models
KW  - unstructured terrain
KW  - stable locomotion
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Limit-cycles
KW  - Robot kinematics
KW  - Adaptation models
KW  - Oscillators
DO  - 10.1109/ICRA.2018.8461013
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Inspired by the locomotor nervous system of vertebrates, central pattern generator (CPG) models can be used to design gaits for articulated robots, such as crawling, swimming or legged robots. Incorporating sensory feedback for gait adaptation in these models can improve the locomotive performance of such robots in challenging terrain. However, many CPG models to date have been developed exclusively for open-loop gait generation for traversing level terrain. In this paper, we present a novel approach for incorporating inertial feedback into the CPG framework for the control of body posture during legged locomotion on steep, unstructured terrain. That is, we adapt the limit cycle of each leg of the robot with time to simultaneously produce locomotion and body posture control. We experimentally validate our approach on a hexapod robot, locomoting in a variety of steep, challenging terrains (grass, rocky slide, stairs). We show how our approach can be used to level the robot's body, allowing it to locomote at a relatively constant speed, even as terrain steepness and complexity prevents the use of an open-loop control strategy.
ER  - 

TY  - CONF
TI  - On Time Optimization of Centroidal Momentum Dynamics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5776
EP  - 5782
AU  - B. Ponton
AU  - A. Herzog
AU  - A. Del Prete
AU  - S. Schaal
AU  - L. Righetti
PY  - 2018
KW  - angular momentum
KW  - concave programming
KW  - convex programming
KW  - humanoid robots
KW  - minimisation
KW  - mobile robots
KW  - path planning
KW  - position control
KW  - robot dynamics
KW  - time optimal control
KW  - fixed timing
KW  - motion plans
KW  - timing optimization
KW  - nonconvex problem
KW  - time-optimized dynamically consistent trajectories
KW  - centroidal dynamics
KW  - time variables
KW  - nonconvexity
KW  - contact forces
KW  - momentum trajectories
KW  - convex relaxation
KW  - trajectory optimization techniques
KW  - multicontact scenarios
KW  - dynamically consistent motions
KW  - centroidal momentum dynamics
KW  - Optimization
KW  - Dynamics
KW  - Robots
KW  - Kinematics
KW  - Torque
KW  - Mathematical model
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8460537
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recently, the centroidal momentum dynamics has received substantial attention to plan dynamically consistent motions for robots with arms and legs in multi-contact scenarios. However, it is also non convex which renders any optimization approach difficult and timing is usually kept fixed in most trajectory optimization techniques to not introduce additional non convexities to the problem. But this can limit the versatility of the algorithms. In our previous work, we proposed a convex relaxation of the problem that allowed to efficiently compute momentum trajectories and contact forces. However, our approach could not minimize a desired angular momentum objective which seriously limited its applicability. Noticing that the non-convexity introduced by the time variables is of similar nature as the centroidal dynamics one, we propose two convex relaxations to the problem based on trust regions and soft constraints. The resulting approaches can compute time-optimized dynamically consistent trajectories sufficiently fast to make the approach realtime capable. The performance of the algorithm is demonstrated in several multi-contact scenarios for a humanoid robot. In particular, we show that the proposed convex relaxation of the original problem finds solutions that are consistent with the original non-convex problem and illustrate how timing optimization allows to find motion plans that would be difficult to plan with fixed timing ††Implementation details and demos can be found in the source code available at https://git-amd.tuebingen.mpg.de/bponton/timeoptimization.
ER  - 

TY  - CONF
TI  - Toward Intuitive Teleoperation in Surgery: Human-Centric Evaluation of Teleoperation Algorithms for Robotic Needle Steering
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5799
EP  - 5806
AU  - Z. Wang
AU  - I. Reed
AU  - A. M. Fey
PY  - 2018
KW  - biomechanics
KW  - cognition
KW  - force feedback
KW  - haptic interfaces
KW  - medical robotics
KW  - needles
KW  - robot kinematics
KW  - steering systems
KW  - surgery
KW  - telerobotics
KW  - robotically steered needles
KW  - joint space control
KW  - Cartesian space control
KW  - hub-centered steering
KW  - user experience
KW  - user cognitive workload
KW  - muscle fatigue
KW  - human-centric metrics
KW  - human-centric evaluation
KW  - teleoperation algorithms
KW  - teleoperated systems
KW  - physiological metrics
KW  - cognitive metrics
KW  - teleoperation performance
KW  - intuitive teleoperation
KW  - robotic needle steering
KW  - kinematic metrics
KW  - teleoperation mappings
KW  - teleoperation strategies
KW  - steering control mapping
KW  - Needles
KW  - Aerospace electronics
KW  - Task analysis
KW  - Kinematics
KW  - Haptic interfaces
KW  - Measurement
KW  - Sensors
DO  - 10.1109/ICRA.2018.8460729
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The effectiveness of control algorithms for teleoperated systems is typically evaluated through experimental performance measures, post-experimental user surveys, and theoretical analysis. However, none of these methods provide an objective assessment of teleoperation algorithms with respect to the real-time changes of human users during teleoperated tasks in terms of physiological, kinematic, or cognitive metrics. In this study, we recruited subjects to control robotically steered needles in a randomized experiment, using four different teleoperation mappings (joint space control, steering control, and Cartesian space control with and without force feedback). We investigated how the choice of these algorithms affect both performance and user response. Our novel steering control mapping, which mimics hub-centered steering, is significantly correlated with decreased cognitive stress and improved teleoperation performance when compared to joint space control. Overall, user experience and teleoperation performance were significantly improved with Cartesian space control, resulting in faster needle insertion, higher targeting accuracy, lower cognitive load, and smoother movements. Furthermore, while additional haptic feedback in Cartesian space provided an improved performance, it may increase user cognitive workload and muscle fatigue. These results highlight the importance of considering human-centric metrics when designing novel teleoperation strategies for complex systems.
ER  - 

TY  - CONF
TI  - Human-guided Optical Manipulation of Multiple Microscopic Objects
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 5807
EP  - 5812
AU  - Q. M. Ta
AU  - S. Lyu
AU  - C. C. Cheah
PY  - 2018
KW  - collision avoidance
KW  - decision making
KW  - manipulators
KW  - micromanipulators
KW  - multi-robot systems
KW  - radiation pressure
KW  - human-guided optical manipulation
KW  - multiple microscopic objects
KW  - control systems
KW  - multiple microobjects
KW  - robotic control technique
KW  - automated optical manipulation system
KW  - precise manipulation
KW  - productive manipulation
KW  - Robots
KW  - Microscopy
KW  - Optical microscopy
KW  - Potential energy
KW  - Biomedical optical imaging
KW  - Collision avoidance
DO  - 10.1109/ICRA.2018.8461258
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Existing control systems for optical manipulation of multiple micro-objects do not allow users to interact with the systems during manipulation to deal with unexpected events, while ensuring stability of the overall control systems. In this paper, we propose a robotic control technique for human-guided optical manipulation of multiple micro-objects using robotic tweezers. Humans, when necessary, are able to interact or intervene with an automated optical manipulation system in a stable manner, and thus guiding a group of micro-objects to be manipulated towards a desired region while ensuring collision avoidance during manipulation. Both the ability of humans, in term of decision making, when needed, and the advantages of an automated optical manipulation system which provides precise and productive manipulation of micro-objects, are consolidated into one single technique. A theoretical foundation is developed and investigated to achieve the control objective. Experimental results are presented to illustrate the effectiveness of the proposed control technique.
ER  - 


