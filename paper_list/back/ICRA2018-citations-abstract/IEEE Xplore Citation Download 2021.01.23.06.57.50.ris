TY  - CONF
TI  - Variable Transmission Series Elastic Actuator for Robotic Prosthesis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2796
EP  - 2803
AU  - X. Sun
AU  - F. Sugai
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - actuators
KW  - artificial limbs
KW  - biomechanics
KW  - elasticity
KW  - legged locomotion
KW  - medical robotics
KW  - motion control
KW  - prosthetics
KW  - robot dynamics
KW  - torque control
KW  - robotic prosthetic knee
KW  - passive mode test
KW  - passive prosthesis
KW  - rotary motion
KW  - linear motion
KW  - slider crank mechanism
KW  - knee angle
KW  - variable transmission mechanism
KW  - SuKnee
KW  - robotic prosthesis
KW  - variable transmission series elastic actuator
KW  - Knee
KW  - Prosthetics
KW  - Legged locomotion
KW  - Springs
KW  - Batteries
KW  - Force
DO  - 10.1109/ICRA.2018.8460796
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we introduce a novel robotic prosthetic knee as shown in Fig. 1 (named as SuKnee) with variable transmission mechanism that could vary transmission ratio while knee angle varies during ambulation activities. A slider crank mechanism is utilized to transform linear motion of series elastic actuator to rotary motion of knee joint. And it contributes to variable transmission ratio with knee angle, which help obtain desired speed variation and torque output in different activities in one mechanism. This feature could uniquely give the SuKnee both: the torque necessary to assist with standing up from a chair and the speed necessary to swing the leg forward during walking. The knee has an active mode, where it operates with batteries and is capable of providing external power, and a passive mode, behaving like a passive prosthesis. Preliminary tests have been performed by a transfemoral amputee and SuKnee could provide user with power to assist walking on level ground and standing up from a chair. And a passive mode test shows it could work like passive prosthesis after battery exhaustion.
ER  - 

TY  - CONF
TI  - Towards Restoring Locomotion for Paraplegics: Realizing Dynamically Stable Walking on Exoskeletons
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2804
EP  - 2811
AU  - T. Gurriet
AU  - S. Finet
AU  - G. Boeris
AU  - A. Duburcq
AU  - A. Hereid
AU  - O. Harib
AU  - M. Masselin
AU  - J. Grizzle
AU  - A. D. Ames
PY  - 2018
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - optimisation
KW  - robot dynamics
KW  - stable walking gaits
KW  - direct collocation optimization formulation
KW  - paraplegics
KW  - crutch-less dynamic walking
KW  - lower-body exoskeleton
KW  - French start-up company Wandercraft
KW  - partial hybrid zero dynamics framework
KW  - PHZD
KW  - legged locomotion
KW  - Exoskeletons
KW  - Legged locomotion
KW  - Foot
KW  - Companies
KW  - Optimization
KW  - Kinematics
DO  - 10.1109/ICRA.2018.8460647
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the first experimental results of crutch-less dynamic walking with paraplegics on a lower-body exoskeleton: ATALANTE, designed by the French start-up company Wandercraft. The methodology used to achieve these results is based on the partial hybrid zero dynamics (PHZD) framework for formally generating stable walking gaits. A direct collocation optimization formulation is used to provide fast and efficient generation of gaits tailored to each patient. These gaits are then implemented on the exoskeleton for three paraplegics. The end result is dynamically stable walking in an exoskeleton without the need for crutches. After a short period of tuning by the engineers and practice by the subjects, each subject was able to dynamically walk across a room of about 10 m up to a speed of 0.15 m/s (0.5 km/h) without the need for crutches or any other kind of assistance.
ER  - 

TY  - CONF
TI  - Autonomous Multi-Joint Soft Exosuit for Assistance with Walking Overground
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2812
EP  - 2819
AU  - S. Lee
AU  - N. Karavas
AU  - B. T. Quinlivan
AU  - D. LouiseRyan
AU  - D. Perry
AU  - A. Eckert-Erdheim
AU  - P. Murphy
AU  - T. Greenberg Goldy
AU  - N. Menard
AU  - M. Athanassiu
AU  - J. Kim
AU  - G. Lee
AU  - I. Galiana
AU  - C. J. Walsh
PY  - 2018
KW  - actuators
KW  - biomechanics
KW  - force control
KW  - gait analysis
KW  - medical robotics
KW  - motion control
KW  - autonomous multijoint soft exosuit
KW  - human locomotion
KW  - assistive torques
KW  - gait assistance
KW  - overground walking
KW  - soft exosuit assists
KW  - ankle plantarflexion
KW  - hip flexion
KW  - hip extension
KW  - mobile actuation system
KW  - high assistive forces
KW  - force profiles
KW  - walking cycle
KW  - control adaptation method
KW  - force consistency
KW  - peak force
KW  - target force
KW  - country-course walking
KW  - RMS error
KW  - human energy economy
KW  - Legged locomotion
KW  - Hip
KW  - Belts
KW  - Force
KW  - Actuators
KW  - Thigh
DO  - 10.1109/ICRA.2018.8460972
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Soft exosuits are a new approach for assisting with human locomotion, which applies assistive torques to the wearer through functional apparel. In this paper, we present a new version of autonomous multi-joint soft exosuit for gait assistance, particularly designed for overground walking. The soft exosuit assists with ankle plantarflexion, hip flexion, and hip extension, equally distributing the forces between ankle plantarflexion and hip flexion. A mobile actuation system was developed to generate high assistive forces, and Bowden cables are used to transmit the forces to the exosuit. A sensor harness connects two load cells and three IMU s per leg that are used to measure real-time data for a controller that commands desired force profiles as a function of the walking cycle. In addition, a control adaptation method was developed which adjusts control parameters while walking on irregular surfaces. In preliminary studies, the proposed method substantially improved the force consistency while walking over uneven terrain. Specifically, the number of steps where the peak force deviated from the target force decreased from 100 to 57 out of 250 steps, and RMS error on the peak force decreased from 90.0 N to 76.6 N with respect to 300 N target force. Also, a two-subject case study on country-course walking demonstrated the potential of this soft exosuit to improve human energy economy while walking overground.
ER  - 

TY  - CONF
TI  - A Lightweight and Efficient Portable Soft Exosuit for Paretic Ankle Assistance in Walking After Stroke
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2820
EP  - 2827
AU  - J. Bae
AU  - C. Siviy
AU  - M. Rouleau
AU  - N. Menard
AU  - K. O'Donnell
AU  - I. Geliana
AU  - M. Athanassiu
AU  - D. Ryan
AU  - C. Bibeau
AU  - L. Sloot
AU  - P. Kudzia
AU  - T. Ellis
AU  - L. Awad
AU  - C. J. Walsh
PY  - 2018
KW  - gait analysis
KW  - medical robotics
KW  - patient rehabilitation
KW  - hemiparetic gait
KW  - paretic ankle assistance
KW  - overground walking
KW  - heterogeneous gait patterns
KW  - mechanical assistance
KW  - clinical gait training
KW  - optimized soft exosuit
KW  - poststroke patients
KW  - soft exosuits
KW  - soft wearable robots
KW  - paretic ankle dorsiflexion
KW  - forward propulsion symmetry
KW  - impaired paretic ankle plantarflexion
KW  - paretic ankle function
KW  - walking deficits
KW  - Legged locomotion
KW  - Prototypes
KW  - Foot
KW  - Actuators
KW  - Force
KW  - Mechanical cables
DO  - 10.1109/ICRA.2018.8461046
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Hemiparetic gait after stroke is typically asymmetric and energetically inefficient. A major contributor to walking deficits is impaired paretic ankle function. Impaired paretic ankle plantarflexion (PF) reduces forward propulsion symmetry and impaired paretic ankle dorsiflexion (DF) diminishes ground clearance during swing. We have developed soft wearable robots (soft exosuits) to assist paretic PF and DF during walking after stroke. Through experimental studies with poststroke patients, we have demonstrated that exosuits can improve forward propulsion symmetry and ground clearance in walking, ultimately reducing the metabolic cost of walking. This paper presents an optimized soft exosuit aimed at use in clinical gait training for patients poststroke. The optimized exosuit is lightweight, easy to don and doff, and capable of efficiently delivering mechanical assistance to the paretic ankle. This paper focuses on the optimized controller that can deliver well-timed consistent ankle assistance to patients. A preliminary study was performed using this exosuit with three poststroke patients with heterogeneous gait patterns. Results showed that compared to a previously published controller, more consistent assistive force profiles could be delivered to individuals poststroke while consuming 50% less electrical power. Additionally, a preliminary biomechanical assessment was performed during overground walking.
ER  - 

TY  - CONF
TI  - Comparing Assistive Admittance Control Algorithms for a Trunk Supporting Exoskeleton
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2828
EP  - 2834
AU  - P. G. Van Lenthe
AU  - S. Verros
AU  - E. E. G. Hekman
AU  - R. Carloni
AU  - H. F. J. M. Koopman
PY  - 2018
KW  - diseases
KW  - feedforward
KW  - handicapped aids
KW  - human-robot interaction
KW  - medical robotics
KW  - muscle
KW  - assistive admittance control algorithms
KW  - trunk supporting exoskeleton
KW  - duchenne muscular dystrophy
KW  - health care
KW  - active exoskeletons
KW  - daily living
KW  - trunk supporting robot
KW  - constant parameters
KW  - variable parameters
KW  - control laws
KW  - feedforward
KW  - variable admittance controllers
KW  - standard admittance
KW  - feed-forward force
KW  - Fitts-like experiment
KW  - Force
KW  - Admittance
KW  - Robots
KW  - Trajectory
KW  - Force measurement
KW  - Exoskeletons
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461062
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Duchenne muscular dystrophy leaves patients with severe dependency on health care. In an effort to increase independence and quality of life, active exoskeletons are developed to support activities of daily living. This study is dedicated to the development and assessment of three different admittance control algorithms for a trunk supporting robot; a law with constant parameters, a law with added feed-forward force, and a law with variable parameters. A Fitts'-like experiment with 12 healthy subjects was performed to compare the control laws. The results show decreased movement times for the feedforward and variable admittance controllers with respect to the standard admittance.
ER  - 

TY  - CONF
TI  - Dynamic Actuator Selection and Robust State-Feedback Control of Networked Soft Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2857
EP  - 2864
AU  - N. Ebrahimi
AU  - S. Nugroho
AU  - A. F. Taha
AU  - N. Gatsis
AU  - W. Gao
AU  - A. Jafari
PY  - 2018
KW  - control system synthesis
KW  - electroactive polymer actuators
KW  - pneumatic actuators
KW  - robots
KW  - robust control
KW  - state feedback
KW  - Electromagnetic Soft Actuator
KW  - logistic constraints
KW  - dynamic actuator selection
KW  - networked soft actuators
KW  - soft robotic systems
KW  - dynamic environments
KW  - robust state-feedback control
KW  - control input bounds
KW  - minimal actuator selection problem
KW  - physical network
KW  - artificial muscle fiber
KW  - soft actuator matrix
KW  - networked ESAs
KW  - robust control
KW  - soft-body actuators
KW  - actuator selection algorithms
KW  - realtime control
KW  - lightweight power sources
KW  - external stimuli
KW  - Actuators
KW  - Muscles
KW  - Force
KW  - Coils
KW  - Robust control
KW  - Magnetic cores
KW  - Springs
DO  - 10.1109/ICRA.2018.8460679
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The design of robots that are light, soft, powerful is a grand challenge. Since they can easily adapt to dynamic environments, soft robotic systems have the potential of changing the status-quo of bulky robotics. A crucial component of soft robotics is a soft actuator that is activated by external stimuli to generate desired motions. Unfortunately, there is a lack of powerful soft actuators that operate through lightweight power sources. To that end, we recently designed a highly scalable, flexible, biocompatible Electromagnetic Soft Actuator (ESA). With ESAs, artificial muscles can be designed by integrating a network of ESAs. The main research gap addressed in this work is in the absence of system-theoretic understanding of the impact of the realtime control and actuator selection algorithms on the performance of networked soft-body actuators and ESAs. The objective of this paper is to establish a framework that guides the analysis and robust control of networked ESAs. A novel ESA is described, and a configuration of soft actuator matrix to resemble artificial muscle fiber is presented. A mathematical model which depicts the physical network is derived, considering the disturbances due to external forces and linearization errors as an integral part of this model. Then, a robust control and minimal actuator selection problem with logistic constraints and control input bounds is formulated, and tractable computational routines are proposed with numerical case studies.
ER  - 

TY  - CONF
TI  - Safety and Guaranteed Stability Through Embedded Energy-Aware Actuators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2902
EP  - 2908
AU  - G. A. Folkertsma
AU  - S. S. Groothuis
AU  - S. Stramigioli
PY  - 2018
KW  - actuators
KW  - human-robot interaction
KW  - stability
KW  - embedded energy-aware actuators
KW  - robots
KW  - control algorithm
KW  - discrete-time computer
KW  - communication delays
KW  - model-free passivity
KW  - safety layer
KW  - complex robotic systems
KW  - physical human-robot interaction
KW  - safety mechanism
KW  - Actuators
KW  - Robots
KW  - Safety
KW  - Force
KW  - Springs
KW  - Shock absorbers
DO  - 10.1109/ICRA.2018.8463174
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Safety is essential for robots in unknown environments, especially when there is physical Human-Robot Interaction (pHRI). Control over energy, or passivity, is an effective safety mechanism. However, when the control algorithm is implemented in a discrete-time computer, computation and communication delays readily lead to loss of passivity and to instability. In this paper, a way to make the actuators aware of the energy that they inject into the system is presented. Passivity and stability are then always guaranteed, even in situations of total communication loss. These Embedded Energy-Aware Actuators are a model-free passivity and safety layer that make complex robotic systems dependable, well-behaved and safe. The proposed method is validated in simulation and experiments.
ER  - 

TY  - CONF
TI  - High-Level MLN-Based Approach for Spatial Context Disambiguation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2909
EP  - 2915
AU  - O. Adjali
AU  - A. Ramdane-Cherif
PY  - 2018
KW  - control engineering computing
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - mobile robots
KW  - probability
KW  - robot dynamics
KW  - sensor fusion
KW  - spatial context disambiguation
KW  - probabilistic MLN-based model
KW  - incomplete knowledge
KW  - High-level task planning
KW  - semantic spatial relations
KW  - robot dynamic
KW  - High-level MLN
KW  - MLN probabilistic reasoning
KW  - Robot sensing systems
KW  - Context modeling
KW  - Semantics
KW  - Probabilistic logic
KW  - Object recognition
DO  - 10.1109/ICRA.2018.8460923
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we propose a probabilistic MLN-based model for spatial context disambiguation. This model serves as a solution for the problem of incomplete knowledge in High-level task planning. By applying the state of the art MLN probabilistic reasoning such as MCSAT, we determine the concept class of the current spatial context of the robot and contribute by combining semantic spatial relations with observed data at different timesteps. The inherent uncertainty of robot dynamic environments makes the proposed approach suitable to deal with partial observability and sensing limitations of robots. Simulation experiments and evaluation results are presented to validate our model.
ER  - 

TY  - CONF
TI  - Pairwise Consistent Measurement Set Maximization for Robust Multi-Robot Map Merging
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2916
EP  - 2923
AU  - J. G. Mangelson
AU  - D. Dominic
AU  - R. M. Eustice
AU  - R. Vasudevan
PY  - 2018
KW  - expectation-maximisation algorithm
KW  - graph theory
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - PCM
KW  - robust multirobot map
KW  - robust selection
KW  - robust SLAM methods
KW  - multirobot case
KW  - simultaneous localization and mapping
KW  - pairwise consistency set maximization
KW  - pairwise consistent measurement set maximization
KW  - odometry backbone
KW  - Simultaneous localization and mapping
KW  - Robot kinematics
KW  - Phase change materials
KW  - Trajectory
KW  - Robustness
KW  - Merging
DO  - 10.1109/ICRA.2018.8460217
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper reports on a method for robust selection of inter-map loop closures in multi-robot simultaneous localization and mapping (SLAM). Existing robust SLAM methods assume a good initialization or an “odometry backbone” to classify inlier and outlier loop closures. In the multi-robot case, these assumptions do not always hold. This paper presents an algorithm called Pairwise Consistency Maximization (PCM) that estimates the largest pairwise internally consistent set of measurements. Finding the largest pairwise internally consistent set can be transformed into an instance of the maximum clique problem from graph theory, and by leveraging the associated literature it can be solved in realtime. This paper evaluates how well PCM approximates the combinatorial gold standard using simulated data. It also evaluates the performance of PCM on synthetic and real-world data sets in comparison with DCS, SCGP, and RANSAC, and shows that PCM significantly outperforms these methods.
ER  - 

TY  - CONF
TI  - Task-Specific Sensor Planning for Robotic Assembly Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2932
EP  - 2939
AU  - G. Rosman
AU  - C. Choi
AU  - M. Dogar
AU  - J. W. Fisher
AU  - D. Rus
PY  - 2018
KW  - feedback
KW  - multi-robot systems
KW  - open loop systems
KW  - path planning
KW  - robotic assembly
KW  - sensors
KW  - task-specific sensor planning
KW  - robotic assembly tasks
KW  - sensory feedback
KW  - task planning
KW  - open-loop simulation
KW  - task-specific uncertainty approximants
KW  - multirobot planner
KW  - multirobot tasks
KW  - Robot sensing systems
KW  - Task analysis
KW  - Uncertainty
KW  - Planning
KW  - Robotic assembly
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460194
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When performing multi-robot tasks, sensory feedback is crucial in reducing uncertainty for correct execution. Yet the utilization of sensors should be planned as an integral part of the task planning, taken into account several factors such as the tolerance of different inferred properties of the scene and interaction with different agents. In this paper we handle this complex problem in a principled, yet efficient way. We use surrogate predictors based on open-loop simulation to estimate and bound the probability of success for specific tasks. We reason about such task-specific uncertainty approximants and their effectiveness. We show how they can be incorporated into a multi-robot planner, and demonstrate results with a team of robots performing assembly tasks.
ER  - 

TY  - CONF
TI  - Map-Aware Particle Filter for Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2940
EP  - 2947
AU  - A. Rechy Rormero
AU  - P. V. K. Borges
AU  - A. Pfrunder
AU  - A. Elfes
PY  - 2018
KW  - distance measurement
KW  - Global Positioning System
KW  - optical radar
KW  - particle filtering (numerical methods)
KW  - SLAM (robots)
KW  - map-aware particle filter
KW  - 2D LiDAR localization
KW  - GPS localization
KW  - map information
KW  - localization sensors
KW  - particle filter framework
KW  - map-matching
KW  - prior occupancy grid
KW  - vehicle localization
KW  - Trajectory
KW  - Roads
KW  - Atmospheric measurements
KW  - Particle measurements
KW  - Sensors
KW  - Particle filters
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2018.8460707
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work presents a method to improve vehicle localization by using the information from a prior occupancy grid to bound the possible poses. The method, named Map-Aware Particle Filter, uses a nonlinear approach to map-matching that can be integrated into a particle filter framework for localization. Each particle is re-weighted based on the validity of its current position in the map. In addition, we buffer the trajectory followed by the vehicle and then append it to each particle's pose. We then quantify the overlap between the trajectory and the map's free space. This serves as a measure of each particle's validity given the trajectory and the shape of the map. We evaluated the method by performing experiments with different types of localization sensors: First, (i) we significantly reduced the drift inherent to dead reckoning. By only using wheel odometry and map information we achieved loop closure over a distance of approximately 3 km. We also (ii) increased the accuracy of GPS localization. Finally, (iii) we fused a fragile 2D LiDAR localization with the map information. The resulting system had a higher robustness and managed to close the loop in an outdated map where it had failed before.
ER  - 

TY  - CONF
TI  - Active Motion-Based Communication for Robots with Monocular Vision
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2948
EP  - 2955
AU  - H. Nishimura
AU  - M. Schwager
PY  - 2018
KW  - Bayes methods
KW  - decoding
KW  - estimation theory
KW  - image classification
KW  - Kalman filters
KW  - Monte Carlo methods
KW  - robot vision
KW  - online Bayesian estimation algorithm
KW  - monocular camera
KW  - receiver robot
KW  - sending robot
KW  - active motion-based communication
KW  - accurate trajectory classification
KW  - trajectory class distribution
KW  - active vision-based control policy
KW  - message decoding
KW  - trajectory identification
KW  - monocular vision model
KW  - receiving robot
KW  - Trajectory
KW  - Receivers
KW  - Cameras
KW  - Robot vision systems
KW  - Bayes methods
KW  - Estimation
DO  - 10.1109/ICRA.2018.8463152
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we consider motion as a means of sending messages between robots. We focus on a scenario in which a message is encoded in a sending robot's trajectory, and decoded by a receiver robot equipped with a monocular camera. The relative pose between the robots is unknown. We introduce an online Bayesian estimation algorithm based on the Multi-hypothesis Extended Kalman Filter for the receiving robot to simultaneously estimate its relative pose to the sender, and the trajectory class of the sender. The difficulty in this problem arises from the monocular vision model of the receiver and the unknown relative pose between robots, which brings inherent ambiguity into the trajectory identification, and hence the message decoding. An active vision-based control policy is derived and combined with the Bayesian estimation in order to deal with this difficulty. The policy is constructed online based on Monte Carlo Tree Search and aims at reducing the entropy over the trajectory class distribution. The algorithm has broad applications, e.g., to intent modeling and motion prediction for autonomous driving and autonomous drone operations. Simulation results demonstrate that the proposed estimation algorithm and the control policy result in an accurate trajectory classification.
ER  - 

TY  - CONF
TI  - A Novel Recurrent Neural Network for Improving Redundant Manipulator Motion Planning Completeness
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2956
EP  - 2961
AU  - Y. Li
AU  - S. Li
AU  - B. Hannaford
PY  - 2018
KW  - collision avoidance
KW  - neurocontrollers
KW  - recurrent neural nets
KW  - redundant manipulators
KW  - Recurrent Neural Networks
KW  - manipulator control optimization
KW  - obstacle avoidance
KW  - RNN control
KW  - redundant manipulator motion planning
KW  - Planning
KW  - Manipulators
KW  - Task analysis
KW  - Recurrent neural networks
KW  - Collision avoidance
KW  - Robustness
KW  - Aerospace electronics
KW  - Motion Planning
KW  - Kinematic Control
KW  - Recurrent Neural Networks
KW  - Redundant Manipulator
KW  - Robot
DO  - 10.1109/ICRA.2018.8461204
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recurrent Neural Networks (RNNs) demonstrated advantages on control precision, system robustness and computational efficiency, and have been widely applied to redundant manipulator control optimization. Existing RNN control schemes locally optimize trajectories and are efficient and reliable on obstacle avoidance. However, for motion planning, they suffer from local minimum and do not have planning completeness. This work explained the cause of the planning incompleteness and addressed the problem with a novel RNN control scheme. The paper presented the proposed method in detail and analyzed the global stability and the planning completeness in theory. The proposed method was compared with other three control schemes on the precision, the robustness and the planning completeness in software simulation and the results shows the proposed method has improved precision and robustness, and planning completeness.
ER  - 

TY  - CONF
TI  - Robust Collision Avoidance via Sliding Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2962
EP  - 2969
AU  - B. T. Lopez
AU  - J. Slotine
AU  - J. P. How
PY  - 2018
KW  - adaptive control
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - nonlinear control systems
KW  - parameter estimation
KW  - robust control
KW  - trajectory control
KW  - uncertain systems
KW  - variable structure systems
KW  - robust collision avoidance
KW  - planning algorithms
KW  - robots
KW  - unknown environments
KW  - cluttered environments
KW  - model uncertainty
KW  - external disturbances
KW  - nonlinear control theory
KW  - CASC
KW  - safe trajectory
KW  - parameter estimation
KW  - composite adaptive sliding controller
KW  - quadrotor navigation
KW  - Trajectory
KW  - Electron tubes
KW  - Uncertainty
KW  - Robustness
KW  - Optimization
KW  - Adaptation models
DO  - 10.1109/ICRA.2018.8460817
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recent advances in perception and planning algorithms have enabled robots to navigate autonomously through unknown, cluttered environments at high-speeds. A key component of these systems is the ability to identify, select, and execute a safe trajectory around obstacles. Many of these systems, however, lack performance guarantees because model uncertainty and external disturbances are ignored when a trajectory is selected for execution. This work leverages results from nonlinear control theory to establish a bound on tracking performance that can be used to select a provably safe trajectory. The Composite Adaptive Sliding Controller (CASC) provides robustness to disturbances and reduces model uncertainty through high-rate parameter estimation. CASC is demonstrated in simulation and hardware to significantly improve the performance of a quadrotor navigating through unknown environments with external disturbances and unknown model parameters.
ER  - 

TY  - CONF
TI  - Optimizing Simulations with Noise-Tolerant Structured Exploration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2970
EP  - 2977
AU  - K. Choromanski
AU  - A. Iscen
AU  - V. Sindhwani
AU  - J. Tan
AU  - E. Coumans
PY  - 2018
KW  - digital simulation
KW  - fast Fourier transforms
KW  - finite difference methods
KW  - gradient methods
KW  - Hadamard transforms
KW  - Jacobian matrices
KW  - legged locomotion
KW  - Newton method
KW  - optimisation
KW  - rendering (computer graphics)
KW  - Walsh functions
KW  - trajectory optimizers
KW  - noisy dynamics
KW  - quasiNewton optimizer
KW  - turning policies
KW  - noise-tolerant structured exploration
KW  - blackbox optimization
KW  - parameter perturbation directions
KW  - structured orthogonal matrices
KW  - structured finite differences
KW  - continuous control tasks
KW  - agile walking learning
KW  - Fast Walsh-Hadamard Fourier Transform
KW  - FWHT FFT
KW  - drop-in noise-tolerant replacement
KW  - quadruped locomotion
KW  - deep reinforcement learning
KW  - Mujoco simulator
KW  - 3D renderers
KW  - Perturbation methods
KW  - Optimization
KW  - Standards
KW  - Smoothing methods
KW  - Robots
KW  - Jacobian matrices
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460492
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose a simple drop-in noise-tolerant replacement for the standard finite difference procedure used ubiquitously in blackbox optimization. In our approach, parameter perturbation directions are defined by a family of structured orthogonal matrices. We show that at the small cost of computing a Fast Walsh-Hadamard/Fourier Transform (FWHT/FFT), such structured finite differences consistently give higher quality approximation of gradients and Jacobians in comparison to vanilla approaches that use coordinate directions or random Gaussian perturbations. We find that trajectory optimizers like Iterative LQR and Differential Dynamic Programming require fewer iterations to solve several classic continuous control tasks when our methods are used to linearize noisy, blackbox dynamics instead of standard finite differences. By embedding structured exploration in a quasi-Newton optimizer (LBFGS), we are able to learn agile walking and turning policies for quadruped locomotion, that successfully transfer from simulation to actual hardware. We theoretically justify our methods via bounds on the quality of gradient reconstruction and provide a basis for applying them also to nonsmooth problems.
ER  - 

TY  - CONF
TI  - Using a Memory of Motion to Efficiently Warm-Start a Nonlinear Predictive Controller
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2986
EP  - 2993
AU  - N. Mansard
AU  - A. DelPrete
AU  - M. Geisert
AU  - S. Tonneau
AU  - O. Stasse
PY  - 2018
KW  - autonomous aerial vehicles
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - nonlinear control systems
KW  - optimal control
KW  - optimisation
KW  - path planning
KW  - predictive control
KW  - sampling methods
KW  - trajectory optimisation (aerospace)
KW  - direct optimal control
KW  - control policy
KW  - optimal state-control trajectories
KW  - nonlinear predictive controller
KW  - nonlinear optimization problem
KW  - model-based methodology
KW  - control cycle
KW  - kinodynamic probabilistic roadmap
KW  - nonlinear solver
KW  - unmanned aerial vehicle
KW  - UAV
KW  - complex dynamical systems
KW  - sampling-based planning
KW  - policy learning
KW  - Computational modeling
KW  - Approximation algorithms
KW  - Optimal control
KW  - Planning
KW  - Robots
KW  - Trajectory optimization
DO  - 10.1109/ICRA.2018.8463154
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Predictive control is an efficient model-based methodology to control complex dynamical systems. In general, it boils down to the resolution at each control cycle of a large nonlinear optimization problem. A critical issue is then to provide a good guess to initialize the nonlinear solver so as to speed up convergence. This is particularly important when disturbances or changes in the environment prevent the use of the trajectory computed at the previous control cycle as initial guess. In this paper, we introduce an original and very efficient solution to automatically build this initial guess. We propose to rely on off-line computation to build an approximation of the optimal trajectories, that can be used on-line to initialize the predictive controller. To that end, we combined the use of sampling-based planning, policy learning with generic representations (such as neural networks), and direct optimal control. We first propose an algorithm to simultaneously build a kinodynamic probabilistic roadmap (PRM) and approximate value function and control policy. This algorithm quickly converges toward an approximation of the optimal state-control trajectories (along with an optimal PRM). Then, we propose two methods to store the optimal trajectories and use them to initialize the predictive controller. We experimentally show that directly storing the state-control trajectories leads the predictive controller to quickly converges (2 to 5 iterations) toward the (global) optimal solution. The results are validated in simulation with an unmanned aerial vehicle (UAV) and other dynamical systems.
ER  - 

TY  - CONF
TI  - Goal Directed Dynamics
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 2994
EP  - 3000
AU  - E. Todorov
PY  - 2018
KW  - control engineering computing
KW  - end effectors
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - motion control
KW  - quadratic programming
KW  - robot dynamics
KW  - telerobotics
KW  - forward dynamics
KW  - greedy optimization
KW  - feature-based control
KW  - control policies
KW  - trajectory optimization
KW  - goal directed dynamics
KW  - general control framework
KW  - low-level optimizer
KW  - robot dynamics
KW  - dynamical system
KW  - high level command
KW  - cost function
KW  - end-effector poses
KW  - soft-constraint physics model
KW  - quadratic programming framework
KW  - teleoperation
KW  - MuJoCo simulator
KW  - Acceleration
KW  - Robots
KW  - Force
KW  - Cost function
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8462904
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We develop a general control framework where a low-level optimizer is built into the robot dynamics. This optimizer together with the robot constitute a goal directed dynamical system, controlled on a higher level. The high level command is a cost function. It can encode desired accelerations, end-effector poses, center of pressure, and other intuitive features that have been studied before. Unlike the currently popular quadratic programming framework, which comes with performance guarantees at the expense of modeling flexibility, the optimization problem we solve at each time step is non-convex and non-smooth. Nevertheless, by exploiting the unique properties of the soft-constraint physics model we have recently developed, we are able to design an efficient solver for goal directed dynamics. It is only two times slower than the forward dynamics solver, and is much faster than real time. The simulation results reveal that complex movements can be generated via greedy optimization of simple costs. This new computational infrastructure can facilitate teleoperation, feature-based control, deep learning of control policies, and trajectory optimization. It will become a standard feature in future releases of the MuJoCo simulator.
ER  - 

TY  - CONF
TI  - Regression-Based Linear Quadratic Regulator
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3001
EP  - 3006
AU  - H. Carlos
AU  - J. Hayer
AU  - R. Murrieta-Cid
PY  - 2018
KW  - control system synthesis
KW  - feedback
KW  - linear quadratic control
KW  - mobile robots
KW  - optimisation
KW  - regression analysis
KW  - search problems
KW  - nonlinear dynamics
KW  - nonquadratic cost functions
KW  - free-derivative algorithm
KW  - local quadratic regressions
KW  - robot motion policy
KW  - locally-optimal control feedback policies
KW  - regression-based linear quadratic regulator
KW  - R-LQR
KW  - search space
KW  - optimization
KW  - Cost function
KW  - Approximation algorithms
KW  - Heuristic algorithms
KW  - Regulators
KW  - Optimal control
KW  - Robots
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2018.8460479
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present the Regression-based Linear Quadratic Regulator (R-LQR), a new approach for determining locally-optimal control feedback policies for robots with non-linear dynamics and non-quadratic cost functions. Our proposal uses a free-derivative algorithm based on local quadratic regressions to obtain the robot motion policy. In addition, our methodology allows to define a notion of scale that translates into the definition of neighborhoods of valid policy and into the exploration of larger areas of the search space to find the optimal policies. The results show that our formulation allows to reach policies with lower costs than existing algorithms and to avoid problems when the behavior of the cost function makes the optimization difficult.
ER  - 

TY  - CONF
TI  - Time-Optimal Path Tracking via Reachability Analysis
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3007
EP  - 3012
AU  - H. Pham
AU  - Q. Pham
PY  - 2018
KW  - control system analysis
KW  - mobile robots
KW  - path planning
KW  - perturbation techniques
KW  - reachability analysis
KW  - time optimal control
KW  - torque control
KW  - trajectory control
KW  - geometric path
KW  - control strategy
KW  - tracking controller
KW  - path parameterization problems
KW  - reachability analysis
KW  - time-optimal path tracking problem
KW  - tracking error regulation
KW  - reference trajectory
KW  - tracking performance degradation
KW  - path controller parameterization
KW  - joint torques
KW  - torque bounds
KW  - perturbations
KW  - Trajectory
KW  - Torque
KW  - Robustness
KW  - Perturbation methods
KW  - Acceleration
KW  - Manipulator dynamics
DO  - 10.1109/ICRA.2018.8460576
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Given a geometric path, the Time-Optimal Path Tracking problem consists in finding the control strategy to traverse the path time-optimally while regulating tracking errors. A simple yet effective approach to this problem is to decompose the controller into two components: (i) a path controller, which modulates the parameterization of the desired path in an online manner, yielding a reference trajectory; and (ii) a tracking controller, which takes the reference trajectory and outputs joint torques for tracking. However, there is one major difficulty: the path controller might not find any feasible reference trajectory that can be tracked by the tracking controller because of torque bounds. In turn, this results in degraded tracking performances. Here, we propose a new path controller that is guaranteed to find feasible reference trajectories by accounting for possible future perturbations. The main technical tool underlying the proposed controller is Reachability Analysis, a new method for analyzing path parameterization problems. Simulations show that the proposed controller outperforms existing methods.
ER  - 

TY  - CONF
TI  - Acceleration of Gradient-Based Path Integral Method for Efficient Optimal and Inverse Optimal Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3013
EP  - 3020
AU  - M. Okada
AU  - T. Taniguchi
PY  - 2018
KW  - convergence of numerical methods
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - optimal control
KW  - optimisation
KW  - predictive control
KW  - gradient-based path integral method
KW  - inverse optimal control
KW  - accelerated path integral method
KW  - gradient descent
KW  - iterative path integral method
KW  - optimization methods
KW  - momentum-based acceleration
KW  - momentum-based methods
KW  - Nesterov Accelerated Gradient
KW  - simulated control systems
KW  - model predictive control
KW  - path integral networks
KW  - accelerated PI-Net
KW  - reinforcement learning
KW  - Iterative methods
KW  - Acceleration
KW  - Optimal control
KW  - Convergence
KW  - Mirrors
KW  - Trajectory
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2018.8463164
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper deals with a new accelerated path integral method, which iteratively searches optimal controls with a small number of iterations. This study is based on the recent observations that a path integral method for reinforcement learning can be interpreted as gradient descent. This observation also applies to an iterative path integral method for optimal control, which sets a convincing argument for utilizing various optimization methods for gradient descent, such as momentum-based acceleration, step-size adaptation and their combination. We introduce these types of methods to the path integral and demonstrate that momentum-based methods, like Nesterov Accelerated Gradient and Adam, can significantly improve the convergence rate to search for optimal controls in simulated control systems. We also demonstrate that the accelerated path integral could improve the performance on model predictive control for various vehicle navigation tasks. Finally, we represent this accelerated path integral method as a recurrent network, which is the accelerated version of the previously proposed path integral networks (PI-Net). We can train the accelerated PI-Net more efficiently for inverse optimal control with less RAM than the original PI-Net.
ER  - 

TY  - CONF
TI  - Charging Station Placement for Indoor Robotic Applications
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3029
EP  - 3036
AU  - T. Kundu
AU  - I. Saha
PY  - 2018
KW  - computability
KW  - mobile robots
KW  - path planning
KW  - indoor robotic application
KW  - battery
KW  - satisfiability modulo theory
KW  - charging station placement problem
KW  - autonomous mobile robot
KW  - Charging stations
KW  - Trajectory
KW  - Batteries
KW  - Planning
KW  - Mobile robots
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461006
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For an autonomous mobile robot, when the available power goes below a certain threshold, the robot needs to abort its current task and move towards a charging station to recharge its battery. The efficiency of an autonomous mobile robot depends significantly on the location of the charging stations. In this paper, we address the charging station placement problem for mobile robots in a controlled workspace. We propose two algorithms to place a number of charging stations so that a robot is always capable of reaching one of the charging stations from any obstacle-free location in the workspace without aborting its task too early. We reduce the charging-station placement problem to a series of Satisfiability Modulo Theory (SMT) problems and use the off-the-shelf SMT solver Z3 to implement our algorithm. The algorithm produces as output the locations of the charging stations in the workspace and the trajectories from any obstacle-free locations to one of the charging stations. Our experimental results show how our algorithm can efficiently find the locations of the charging stations and robot trajectories to reach the charging stations. We demonstrate through simulation how the generated trajectories can be effectively used by a robot to reach a charging stations autonomously without getting depleted with power.
ER  - 

TY  - CONF
TI  - Path Tracking of a Two-Wheel Steering Mobile Robot: An Accurate and Robust Multi-Model Off-Road Steering Strategy
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3037
EP  - 3044
AU  - M. Deremetz
AU  - R. Lenain
AU  - B. Thuilot
PY  - 2018
KW  - control nonlinearities
KW  - mobile robots
KW  - observers
KW  - robot kinematics
KW  - robust control
KW  - steering systems
KW  - wheels
KW  - robust multi-model off-road steering strategy
KW  - path tracking algorithms
KW  - backstepping control strategy
KW  - two-wheel steering mobile robot
KW  - control law
KW  - dynamic models
KW  - kinematic models
KW  - observer
KW  - Mobile robots
KW  - Kinematics
KW  - Mathematical model
KW  - Trajectory
KW  - Observers
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460598
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, the problem associated with accurate control of a two-wheel steering mobile robot following a path is addressed thanks to a backstepping control strategy. This approach involves an observer to estimate the grip conditions, based on previous work, and the proposed control algorithm for the front axle. Since the significant parameters of the grip conditions are available from the observer, namely the sideslip angles and the cornering stiffnesses, it is then suitable to include them into an algorithm to control mobile robots and obtain a more accurate path tracking. This is made possible by gathering into a single backstepping approach both kinematic and dynamic models. This new point of view permits to take account of both kinematic and dynamic behaviors and grip parameters in the control law. The proposed approach is experimentally evaluated at different speeds and compared with two other state-of-the-art path tracking algorithms and evaluated for several values of lateral deviations.
ER  - 

TY  - CONF
TI  - Annotating Traversable Gaps in Walkable Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3045
EP  - 3052
AU  - J. L. Vermeulen
AU  - A. Hillebrand
AU  - R. Geraerts
PY  - 2018
KW  - computational geometry
KW  - mesh generation
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - solid modelling
KW  - virtual reality
KW  - navigation mesh generation
KW  - walkable areas
KW  - 3D virtual environment
KW  - walkable environment
KW  - annotating traversable gaps
KW  - Navigation
KW  - Three-dimensional displays
KW  - Maintenance engineering
KW  - Image edge detection
KW  - Geometry
KW  - Surface morphology
KW  - Path planning
DO  - 10.1109/ICRA.2018.8461152
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous agents typically need a navigation mesh of a 3D virtual environment to allow efficient path planning. This mesh needs as input a continuous representation of the walkable areas. However, the walkable environment (WE), i.e. the parts of the 3D environment that an agent can walk on, may contain gaps. These may be due to the filtering steps performed to compute the WE, because of modelling errors in the 3D model, or simply be part of the geometry of the environment. We provide an algorithm that identifies and fills these gaps. We detect gaps, up to a given distance, between pairs of boundary edges of the walkable environment, and fill them with polygons. We employ a heuristic for choosing which pairs of edges should be connected. We compare our algorithm to Recast [10], a voxel-based method for navigation mesh generation. We find that our method gives more accurate results in many environments: it retains the exact representation of the walkable environment, semantically separates the gaps from the walkable areas, and requires no tweaking of parameters to obtain good results. However, our method is currently slower than Recast, and requires more memory.
ER  - 

TY  - CONF
TI  - Topological Nearest-Neighbor Filtering for Sampling-Based Planners
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3053
EP  - 3060
AU  - R. Sandström
AU  - A. Bregger
AU  - B. Smith
AU  - S. Thomas
AU  - N. M. Amato
PY  - 2018
KW  - filtering theory
KW  - mobile robots
KW  - nearest neighbour methods
KW  - path planning
KW  - sampling methods
KW  - trees (mathematics)
KW  - topological nearest-neighbor filtering
KW  - computational techniques
KW  - locality-sensitive hashing
KW  - workspace connectivity
KW  - nearest-neighbor time
KW  - nearest-neighbor algorithm
KW  - candidate neighbor configurations
KW  - topologically relevant set
KW  - sampling-based motion planning algorithms
KW  - Nearest-neighbor finding
KW  - sampling-based planners
DO  - 10.1109/ICRA.2018.8460896
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Nearest-neighbor finding is a major bottleneck for sampling-based motion planning algorithms. The cost of finding nearest neighbors grows with the size of the roadmap, leading to significant slowdowns for problems which require many configurations to find a solution. Prior work has investigated relieving this pressure with quicker computational techniques, such as kd-trees or locality-sensitive hashing. In this work, we investigate an alternative direction for expediting this process based on workspace connectivity. We present an algorithm called Topological Nearest-Neighbor Filtering, which employs a workspace decomposition to select a topologically relevant set of candidate neighbor configurations as a pre-processing step for a nearest-neighbor algorithm. We investigate the application of this filter to several varieties of RRT and demonstrate that the filter improves both nearest-neighbor time and overall planning performance.
ER  - 

TY  - CONF
TI  - Integration of Local Geometry and Metric Information in Sampling-Based Motion Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3061
EP  - 3068
AU  - V. Pacelli
AU  - O. Arslan
AU  - D. E. Koditschek
PY  - 2018
KW  - geometry
KW  - linear quadratic control
KW  - linear systems
KW  - linearisation techniques
KW  - matrix algebra
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - sampling methods
KW  - sampling-based motion planning algorithms
KW  - steering procedure
KW  - configuration space geometry
KW  - sample configurations
KW  - local system dynamics
KW  - convex subsets
KW  - free space
KW  - local behavior
KW  - LQR cost-to-go function
KW  - system linearization
KW  - linear-Gaussian system
KW  - second-order linear system
KW  - Gram matrix
KW  - Mahalanobis distance
KW  - kinematic unicycle
KW  - local geometry
KW  - metric information
KW  - Measurement
KW  - Heuristic algorithms
KW  - Trajectory
KW  - Geometry
KW  - Robots
KW  - System dynamics
KW  - Planning
DO  - 10.1109/ICRA.2018.8460739
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The efficiency of sampling-based motion planning algorithms is dependent on how well a steering procedure is capable of capturing both system dynamics and configuration space geometry to connect sample configurations. This paper considers how metrics describing local system dynamics may be combined with convex subsets of the free space to describe the local behavior of a steering function for sampling-based planners. Subsequently, a framework for using these subsets to extend the steering procedure to incorporate this information is introduced. To demonstrate our framework, three specific metrics are considered: the LQR cost-to-go function, a Gram matrix derived from system linearization, and the Mahalanobis distance of a linear-Gaussian system. Finally, numerical tests are conducted for a second-order linear system, a kinematic unicycle, and a linear-Gaussian system to demonstrate that our framework increases the connectivity of sampling-based planners and allows them to better explore the free space.
ER  - 

TY  - CONF
TI  - Realization of a Real-Time Optimal Control Strategy to Stabilize a Falling Humanoid Robot with Hand Contact
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3092
EP  - 3098
AU  - S. Wang
AU  - K. Hauser
PY  - 2018
KW  - collision avoidance
KW  - friction
KW  - humanoid robots
KW  - mobile robots
KW  - motion control
KW  - optimal control
KW  - robot dynamics
KW  - stability
KW  - falling humanoid robot
KW  - environmental obstacles
KW  - obstacle geometry
KW  - contact point
KW  - planar dynamic model
KW  - optimal control approach
KW  - three-link robot model
KW  - hand contact optimization
KW  - Darwin-Mini robot
KW  - realtime optimal control strategy
KW  - realtime falling robot stabilization system
KW  - Real-time systems
KW  - Legged locomotion
KW  - Computational modeling
KW  - Humanoid robots
KW  - Robot sensing systems
KW  - Kinetic energy
DO  - 10.1109/ICRA.2018.8460500
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper, we present a real-time falling robot stabilization system for a humanoid robot in which the robot can prevent falling using hand contact with walls and other surfaces in the environment. Instead of ignoring or avoiding interaction with environmental obstacles, our system uses obstacle geometry to determine a contact point that reduces impact and necessary friction. It uses a planar dynamic model that is appropriate for falling stabilization in the robot's sagittal plane and frontal plane. The hand contact is determined with an optimal control approach, and to make the algorithm run in realtime, a simplified three-link robot model and a pre-computed database of subproblems for the hand contact optimization are adopted. Moreover, if the robot is not leaning too far after stabilization, we employ a heuristic push-up strategy to recover the robot to a standing posture. System integration is performed on the Darwin-Mini robot and validation is conducted in several environments and falling scenarios.
ER  - 

TY  - CONF
TI  - Markerless Visual Servoing on Unknown Objects for Humanoid Robot Platforms
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3099
EP  - 3106
AU  - C. Fantacci
AU  - G. Vezzani
AU  - U. Pattacini
AU  - V. Tikhanoff
AU  - L. Natale
PY  - 2018
KW  - Bayes methods
KW  - end effectors
KW  - humanoid robots
KW  - least squares approximations
KW  - Monte Carlo methods
KW  - recursive filters
KW  - stereo image processing
KW  - visual perception
KW  - visual servoing
KW  - least squares minimization problem
KW  - stereo vision
KW  - image-based visual servo control
KW  - nonlinear constrained optimization problem
KW  - Sequential Monte Carlo filtering
KW  - recursive Bayesian filtering technique
KW  - markerless visual servoing
KW  - iCub humanoid robot platform
KW  - Visual servoing
KW  - Grasping
KW  - Solid modeling
KW  - Three-dimensional displays
KW  - Mathematical model
KW  - Humanoid robots
DO  - 10.1109/ICRA.2018.8462914
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To precisely reach for an object with a humanoid robot, it is of central importance to have good knowledge of both end-effector, object pose and shape. In this work we propose a framework for markerless visual servoing on unknown objects, which is divided in four main parts: I) a leastsquares minimization problem is formulated to find the volume of the object graspable by the robot's hand using its stereo vision; II) a recursive Bayesian filtering technique, based on Sequential Monte Carlo (SMC) filtering, estimates the 6D pose (position and orientation) of the robot's end-effector without the use of markers; III) a nonlinear constrained optimization problem is formulated to compute the desired graspable pose about the object; IV) an image-based visual servo control commands the robot's end-effector toward the desired pose. We demonstrate effectiveness and robustness of our approach with extensive experiments on the iCub humanoid robot platform, achieving real-time computation, smooth trajectories and subpixel precisions.
ER  - 

TY  - CONF
TI  - Generating Assistive Humanoid Motions for Co-Manipulation Tasks with a Multi-Robot Quadratic Program Controller
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3107
EP  - 3113
AU  - K. Otani
AU  - K. Bouyarmane
AU  - S. Ivaldi
PY  - 2018
KW  - humanoid robots
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - optimal control
KW  - quadratic programming
KW  - human-humanoid collaborative tasks
KW  - multirobot quadratic program controller
KW  - human dynamics reconstruction
KW  - optimal robot controls
KW  - interaction motions
KW  - interaction forces
KW  - humanoid controller
KW  - co-manipulation tasks
KW  - robot platform simulation
KW  - optimization problem
KW  - Task analysis
KW  - Dynamics
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Optimization
KW  - Humanoid robots
DO  - 10.1109/ICRA.2018.8463167
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Human-humanoid collaborative tasks require that the robot take into account the goals of the task, interaction forces with the human, and its own balance. We present a formulation for a real-time humanoid controller which allows the robot to keep itself balanced, while also assisting the human in achieving their shared objectives. We achieve this with a multi-robot quadratic program controller, which solves for human dynamics reconstruction and optimal robot controls in a single optimization problem. Our experiments on a simulated robot platform demonstrate the ability to generate interaction motions and forces that are similar to what a human collaborator would produce.
ER  - 

TY  - CONF
TI  - Affordance-Based Multi-Contact Whole-Body Pose Sequence Planning for Humanoid Robots in Unknown Environments
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3114
EP  - 3121
AU  - P. Kaiser
AU  - C. Mandery
AU  - A. Boltres
AU  - T. Asfour
PY  - 2018
KW  - end effectors
KW  - humanoid robots
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - stability
KW  - end-effectors
KW  - multicontact contact pose sequence planning
KW  - humanoid robot ARMAR-4
KW  - loco-manipulation tasks
KW  - contacts
KW  - loco-manipulation affordances
KW  - vision-based detection
KW  - whole-body multicontact tasks
KW  - motion planning
KW  - multicontact pose sequences
KW  - goal-directed planning
KW  - end-effector contact opportunities
KW  - autonomous detection
KW  - whole-body loco-manipulation actions
KW  - autonomous planning
KW  - humanoid robotics
KW  - humanoid robots
KW  - whole-body pose sequence planning
KW  - affordance-based multicontact
KW  - Planning
KW  - Humanoid robots
KW  - Task analysis
KW  - Motion segmentation
KW  - Robot sensing systems
KW  - Complexity theory
DO  - 10.1109/ICRA.2018.8461087
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Despite impressive advances of humanoid robotics, the autonomous planning of whole-body loco-manipulation actions in unknown environments is still an open problem. In our previous work, we addressed two fundamental aspects related to this problem: 1) the autonomous detection of end-effector contact opportunities in unknown environments and 2) the goal-directed planning of multi-contact pose sequences, which can serve as the starting point for motion planning and control approaches of reduced complexity. Both problems suffer from the extensive amounts of possible solutions, particularly due to the complexity of humanoid robots and the multitude of available contact opportunities. In this paper, we propose a method for the planning of whole-body multi-contact tasks based on our previous work on vision-based detection of loco-manipulation affordances and whole-body multi-contact pose sequence planning. We demonstrate a combined approach for planning multi-contact pose sequences with a focus on the utilization of available end-effectors for stabilizing contacts with the environment during loco-manipulation tasks. The method is evaluated in simulation in multiple exemplary scenarios based on actual sensor data and the humanoid robot ARMAR-4.
ER  - 

TY  - CONF
TI  - Model-Based External Force/Moment Estimation for Humanoid Robots with no Torque Measurement
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3122
EP  - 3129
AU  - M. Benallegue
AU  - P. Gergondet
AU  - H. Audrerr
AU  - A. Mifsud
AU  - M. Morisawa
AU  - F. Lamiraux
AU  - A. Kheddar
AU  - F. Kanehiro
PY  - 2018
KW  - biomechanics
KW  - force measurement
KW  - force sensors
KW  - humanoid robots
KW  - humanoid robot
KW  - torque measurement
KW  - external forces
KW  - direct force measurements
KW  - regular force sensors
KW  - model-based estimator
KW  - floating-base kinematics
KW  - filtered measurement
KW  - contact force
KW  - additional estimation external force
KW  - model-based external force-moment estimation
KW  - Dynamics
KW  - Robot sensing systems
KW  - Kinematics
KW  - Force
KW  - Mathematical model
DO  - 10.1109/ICRA.2018.8460809
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The dynamics of a humanoid robot cannot be correctly described independently from the external forces acting on it. These forces have to be reconstructed to enable the robot to control them or to compensate for them. Force sensors are usually used to measure these forces, but because of their cost, they are often put only on the ankle/feet and possibly the wrists. This paper addresses the issue of the estimation of external forces and moments that apply at any part of a robot without direct force measurements and without torque measurements. The sensors used are the regular force sensors and the IMUs of the robot. The method relies on a model-based estimator able to make the fusion between these sensors and the whole body dynamics. The estimator reconstructs a single state vector containing the floating-base kinematics, a filtered measurement of contact force and an additional estimation external force that we evaluate in this paper. Validation is performed on HRP-2 in a multi-contact motion.
ER  - 

TY  - CONF
TI  - Nonintuitive Optima for Dynamic Locomotion: The Acrollbot
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3130
EP  - 3136
AU  - G. Bellegarda
AU  - N. Talele
AU  - K. By
PY  - 2018
KW  - legged locomotion
KW  - motion control
KW  - optimal control
KW  - robot dynamics
KW  - velocity control
KW  - wheels
KW  - nonintuitive optima
KW  - dynamic locomotion
KW  - acrollbot
KW  - locally-optimal locomotion
KW  - two-link planar robot
KW  - unactuated wheel
KW  - passive wheel
KW  - ground reaction forces
KW  - net accelerations
KW  - decelerations
KW  - bipedal robot locomotion
KW  - toy system
KW  - locomotion speed
KW  - actuation
KW  - forward velocity
KW  - optimization techniques
KW  - direct collocation optimization framework
KW  - nonintuitive dynamic robot models
KW  - physical robot parameterizations
KW  - locomotion efficiency
KW  - data-driven optimization
KW  - dynamically-stable locomotion
KW  - legged rolling locomotion solutions
KW  - Wheels
KW  - Optimization
KW  - Damping
KW  - Trajectory
KW  - Controllability
KW  - Mobile robots
DO  - 10.1109/ICRA.2018.8461221
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper explores locally-optimal, efficient locomotion of a two-link planar robot balancing on a single, unactuated wheel. Because this model is essentially an acrobot mounted on a passive wheel, we name this model the acrollbot. By actuating an internal degree of freedom, the model can indirectly produce ground reaction forces yielding net accelerations and decelerations, to achieve locomotion. As with bipedal robot locomotion, this toy system is particularly challenging to control due to the need to balance continuously while controlling forward locomotion speed. However, unlike typical legged or rolling locomotion solutions, it is not immediately obvious how best to exploit actuation, internal reconfigurations, and motions to produce and control forward velocity along the ground, providing a useful benchmarking system for exploring optimization techniques. We use a direct collocation optimization framework to study this toy system, both to achieve a range of feasible locomotion solutions for nonintuitive dynamic robot models, and to investigate optimization of physical robot parameterizations, in the sense of improving locomotion efficiency. The framework and example presented throughout are designed with an aim toward bridging the gap between non-intuitive, data-driven optimization and model-based methods for design and control of underactuated and dynamically-stable locomotion.
ER  - 

TY  - CONF
TI  - Simultaneous Planning and Estimation Based on Physics Reasoning in Robot Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3137
EP  - 3144
AU  - M. Murooka
AU  - S. Nozawa
AU  - M. Bando
AU  - I. Yanokura
AU  - K. Okada
AU  - M. Inaba
PY  - 2018
KW  - manipulators
KW  - multi-robot systems
KW  - path planning
KW  - physics reasoning
KW  - robot manipulation
KW  - manipulation planning
KW  - human-robot cooperation
KW  - multi-robot cooperation
KW  - Planning
KW  - Cognition
KW  - Estimation
KW  - Force
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8463156
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For robots to autonomously achieve manipulation tasks in various scenes, advanced operational skills such as tool use, learning from demonstration, and multi-robot/human-robot cooperation are necessary. In this research, we devise a method for robots to realize such operational skills in a unified manner by evaluating physical consistency (referred to as “physics reasoning”) based on the formulation of the manipulation statics constraints. First, we propose manipulation planning and estimation methods in which the operational feasibility and properties' likelihood are derived by physics reasoning. In addition, we propose a framework to manipulate an object with unknown physical properties by executing planning and estimation both sequentially and in parallel. We demonstrate the effectiveness of the proposed methods by performing experiments in which real humanoid robots achieve various manipulation tasks with advanced operational skills.
ER  - 

TY  - CONF
TI  - Learning Modes of Within-Hand Manipulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3145
EP  - 3151
AU  - B. Calli
AU  - K. Srinivasan
AU  - A. Morgan
AU  - A. M. Dollar
PY  - 2018
KW  - actuators
KW  - control engineering computing
KW  - feature extraction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - motion control
KW  - robot vision
KW  - tactile sensors
KW  - learning modes
KW  - prehensile fingertip-based within-hand manipulation
KW  - tactile sensors
KW  - actuator states
KW  - visual data
KW  - supervised learning techniques
KW  - classification performance
KW  - Extra Trees
KW  - Gradient Boosting
KW  - visual features
KW  - classification rate
KW  - actuator loads
KW  - within-hand manipulation movements
KW  - hand/object system
KW  - Actuators
KW  - Visualization
KW  - Task analysis
KW  - Robot sensing systems
KW  - Grippers
KW  - Feature extraction
DO  - 10.1109/ICRA.2018.8461187
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we investigate methods to detect four phenomena (modes) that occur during prehensile fingertip-based within-hand manipulation without the use of tactile sensors. By using actuator states and visual data, we aim to recognize different modes of operation such as interpreting if the hand is about to drop the object, if the object will begin to slide on the fingers, or if the system is at or near a singularity. For this purpose, we utilize supervised learning techniques, which allow us to detect the modes without the use of a mechanical model of the system. We analyze the individual roles of specific features available through both the actuator and visual data, and identify the ones that have the most significance for detecting the operation modes. Our results show classification performance of 96% (using either Extra Trees, Gradient Boosting, or SVM) when using combined actuator and visual features. Interestingly, we were able to achieve a 94% classification rate using only actuator information, and 93 % using only visual information. Overall, the classifiers identified actuator positions, actuator loads, and commanded velocities as the most important features for detecting a mode. These results have implications for enabling the control of within-hand manipulation movements utilizing a minimal amount of sensory information without a model of the hand/object system.
ER  - 

TY  - CONF
TI  - Cost Functions to Specify Full-Body Motion and Multi-Goal Manipulation Tasks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3152
EP  - 3159
AU  - P. Ruppel
AU  - N. Hendrich
AU  - S. Starke
AU  - J. Zhang
PY  - 2018
KW  - control engineering computing
KW  - evolutionary computation
KW  - gradient methods
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - motion control
KW  - operating systems (computers)
KW  - particle swarm optimisation
KW  - public domain software
KW  - robot programming
KW  - trees (mathematics)
KW  - full-body motion generation
KW  - open-source software package
KW  - inverse kinematics
KW  - arbitrary kinematic trees
KW  - evolutionary optimization
KW  - particle swarm optimization
KW  - cost functions
KW  - multigoal manipulation tasks
KW  - serial kinematic chains
KW  - dual-arm manipulation
KW  - multifinger hands
KW  - memetic algorithm
KW  - full-body motion specification
KW  - ROS
KW  - MoveIt!
KW  - Kinematics
KW  - Task analysis
KW  - Cost function
KW  - Robot kinematics
KW  - End effectors
KW  - Quaternions
DO  - 10.1109/ICRA.2018.8460799
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - While the problem of inverse kinematics on serial kinematic chains is well researched, solving motion tasks quickly on more complex robots remains an open problem. Examples include dual-arm manipulation, grasping with multi-finger hands, and full-body motion generation for humanoids. In this paper, we introduce an open-source software package for ROS and MoveIt! that solves inverse kinematics and motion tasks on robots with arbitrary kinematic trees. The underlying memetic algorithm integrates evolutionary optimization, particle swarm optimization, and gradient methods. The optimization respects joint limits, effectively avoids local minima, and achieves fast convergence to accurate solutions. More importantly, the overall motion goal is specified using a set of weighted sub-goals, providing great flexibility and control of secondary objectives. Several application examples demonstrate how to combine the predefined sub-goals to achieve complex motion tasks.
ER  - 

TY  - CONF
TI  - Robot Composite Learning and the Nunchaku Flipping Challenge
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3160
EP  - 3165
AU  - L. Zhao
AU  - Y. Zhao
AU  - S. Patil
AU  - D. Davies
AU  - C. Wang
AU  - L. Lu
AU  - B. Ouyang
PY  - 2018
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot dynamics
KW  - heavily case-specific engineering
KW  - ubiquitous manner
KW  - human demonstration
KW  - LfD
KW  - dynamic skills
KW  - composite learning scheme
KW  - human definition
KW  - advanced motor skills
KW  - dynamic time-critical maneuver
KW  - complex contact control
KW  - partly soft partly rigid objects
KW  - nunchaku flipping challenge
KW  - physical success
KW  - robot composite learning
KW  - robot dynamics
KW  - hyper robot motor capabilities
KW  - robot learning
KW  - Petri nets
KW  - Robot learning
KW  - Mobile robots
KW  - Compounds
KW  - Dynamics
KW  - Real-time systems
DO  - 10.1109/ICRA.2018.8461141
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Advanced motor skills are essential for robots to physically coexist with humans. Much research on robot dynamics and control has achieved success on hyper robot motor capabilities, but mostly through heavily case-specific engineering. Meanwhile, in terms of robot acquiring skills in a ubiquitous manner, robot learning from human demonstration (LfD) has achieved great progress, but still has limitations handling dynamic skills and compound actions. We present a composite learning scheme which goes beyond LfD and integrates robot learning from human definition, demonstration, and evaluation. The method tackles advanced motor skills that require dynamic time-critical maneuver, complex contact control, and handling partly soft partly rigid objects. We also introduce the “nunchaku flipping challenge”, an extreme test that puts hard requirements to all these three aspects. Continued from our previous presentations, this paper introduces the latest update of the composite learning scheme and the physical success of the nunchaku flipping challenge.
ER  - 

TY  - CONF
TI  - Iterative Learning Scheme for Dexterous In-Hand Manipulation with Stochastic Uncertainty
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3166
EP  - 3171
AU  - M. Yashima
AU  - T. Yamawaki
PY  - 2018
KW  - dexterous manipulators
KW  - gradient methods
KW  - iterative learning control
KW  - stochastic processes
KW  - stochastic systems
KW  - uncertain systems
KW  - dexterous manipulation tasks
KW  - model-based approaches
KW  - stochastic uncertainty
KW  - iterative learning scheme
KW  - adaptive learning rate methods
KW  - dexterous in-hand manipulation
KW  - gradient descent-based iterative learning control
KW  - Uncertainty
KW  - Stochastic processes
KW  - Robots
KW  - Torque
KW  - Cost function
KW  - Noise measurement
KW  - Robustness
DO  - 10.1109/ICRA.2018.8462913
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In-hand manipulation has attracted attention because of its potential for performing dexterous manipulation tasks. Few successful examples using real robotic fingers have been reported because model-based approaches have been assumed. A gradient descent-based iterative learning control is one of the typical methods for improving the control performance without the need for a precise model. However, the learning performances deteriorate greatly owing to the stochastic uncertainties, and the learning rates have to be determined manually. We propose a novel iterative learning scheme with adaptive learning rate methods for dexterous in-hand manipulation. The proposed scheme not only eliminates the need for a precise model and manual tuning of a learning rate but also is robust to stochastic uncertainties and insensitive to hyperparameters. The validity of the proposed iterative learning scheme is demonstrated through several experiments.
ER  - 

TY  - CONF
TI  - Dexterous Manipulation by Two Fingers with Coupled Joints
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3172
EP  - 3179
AU  - Y. Jia
AU  - Y. Xue
PY  - 2018
KW  - dexterous manipulators
KW  - humanoid robots
KW  - manipulator kinematics
KW  - mechanical contact
KW  - finger
KW  - links
KW  - coupled joints
KW  - Lagrangian mechanics
KW  - independent joint angles
KW  - contact kinematics
KW  - slip modes
KW  - angular accelerations
KW  - joint accelerations
KW  - joint torques
KW  - proportional-derivative law
KW  - dexterous manipulation
KW  - stick modes
KW  - Acceleration
KW  - Kinematics
KW  - Task analysis
KW  - Thumb
KW  - Service robots
DO  - 10.1109/ICRA.2018.8460531
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper studies dexterous manipulation in the plane by a two-fingered hand in the plane. The dynamics of each finger, which consists of two links with coupled joints, are derived based on Lagrangian mechanics. As an object is being manipulated, its orientation and the two independent joint angles of the hand constitute the state of the entire system. Contact kinematics, accounting for both stick and slip modes, are combined with dynamics to establish a dependence of the object's linear and angular accelerations on joint accelerations. This allows control of joint torques, under a proportional-derivative (PD) law, to move the object to a target position in a desired orientation.
ER  - 

TY  - CONF
TI  - Extrinsic Dexterity Through Active Slip Control Using Deep Predictive Models
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3180
EP  - 3185
AU  - S. Stepputtis
AU  - Y. Yang
AU  - H. Ben Amor
PY  - 2018
KW  - dexterous manipulators
KW  - end effectors
KW  - grippers
KW  - learning (artificial intelligence)
KW  - slip
KW  - tactile sensors
KW  - extrinsic dexterity
KW  - active slip control
KW  - machine learning methodology
KW  - robot dexterity
KW  - recent insights
KW  - deep learning
KW  - tactile sensor information
KW  - manipulated object
KW  - robot end-effector
KW  - deep predictive models
KW  - Grippers
KW  - Training
KW  - Robot sensing systems
KW  - Predictive models
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8461055
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a machine learning methodology for actively controlling slip, in order to increase robot dexterity. Leveraging recent insights in deep learning, we propose a Deep Predictive Model that uses tactile sensor information to reason about slip and its future influence on the manipulated object. The obtained information is then used to precisely manipulate objects within a robot end-effector using external perturbations imposed by gravity or acceleration. We show in a set of experiments that this approach can be used to increase a robot's repertoire of motor skills.
ER  - 

TY  - CONF
TI  - A General Pipeline for 3D Detection of Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3194
EP  - 3200
AU  - X. Du
AU  - M. H. Ang
AU  - S. Karaman
AU  - D. Rus
PY  - 2018
KW  - automobiles
KW  - convolution
KW  - feature extraction
KW  - feedforward neural nets
KW  - mobile robots
KW  - robot vision
KW  - traffic engineering computing
KW  - 2D detection network
KW  - generalised car models
KW  - two-stage convolutional neural network
KW  - 3D detection algorithms
KW  - general pipeline
KW  - autonomous driving
KW  - flexible pipeline
KW  - 3D point cloud
KW  - model fitting algorithm
KW  - 3D box detection
KW  - 2D vehicle detection
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Automobiles
KW  - Pipelines
KW  - Solid modeling
KW  - Proposals
KW  - Laser radar
DO  - 10.1109/ICRA.2018.8461232
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous driving requires 3D perception of vehicles and other objects in the in environment. Much of the current methods support 2D vehicle detection. This paper proposes a flexible pipeline to adopt any 2D detection network and fuse it with a 3D point cloud to generate 3D information with minimum changes of the 2D detection networks. To identify the 3D box, an effective model fitting algorithm is developed based on generalised car models and score maps. A two-stage convolutional neural network (CNN) is proposed to refine the detected 3D box. This pipeline is tested on the KITTI dataset using two different 2D detection networks. The 3D detection results based on these two networks are similar, demonstrating the flexibility of the proposed pipeline. The results rank second among the 3D detection algorithms, indicating its competencies in 3D detection.
ER  - 

TY  - CONF
TI  - Meshed Up: Learnt Error Correction in 3D Reconstructions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3201
EP  - 3206
AU  - M. Tanner
AU  - S. Săftescu
AU  - A. Bewley
AU  - P. Newman
PY  - 2018
KW  - error correction
KW  - feature extraction
KW  - image reconstruction
KW  - inverse problems
KW  - learning (artificial intelligence)
KW  - stereo image processing
KW  - 3D reconstruction accuracy
KW  - sensors
KW  - laser reconstruction
KW  - deep network architecture
KW  - stereo image reconstruction
KW  - two dimensional inverse-depth image extraction
KW  - 2D inverse-depth image extraction
KW  - RMSE
KW  - depth reconstructions
KW  - depth estimate errors
KW  - machine learning technique
KW  - learnt error correction
KW  - Image reconstruction
KW  - Feature extraction
KW  - Cameras
KW  - Three-dimensional displays
KW  - Lasers
KW  - Image color analysis
KW  - Training
DO  - 10.1109/ICRA.2018.8460977
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Dense reconstructions often contain errors that prior work has so far minimised using high quality sensors and regularising the output. Nevertheless, errors still persist. This paper proposes a machine learning technique to identify errors in three dimensional (3D) meshes. Beyond simply identifying errors, our method quantifies both the magnitude and the direction of depth estimate errors when viewing the scene. This enables us to Improve the reconstruction accuracy. We train a suitably deep network architecture with two 3D meshes: a high-quality laser reconstruction, and a lower quality stereo image reconstruction. The network predicts the amount of error in the lower quality reconstruction with respect to the high-quality one, having only view the former through its input. We evaluate our approach by correcting two dimensional (2D) inverse-depth images extracted from the 3D model, and show that our method improves the quality of these depth reconstructions by up to a relative 10% RMSE.
ER  - 

TY  - CONF
TI  - Fast Disparity Estimation Using Dense Networks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3207
EP  - 3212
AU  - R. Atienza
PY  - 2018
KW  - convolution
KW  - feedforward neural nets
KW  - image colour analysis
KW  - stereo image processing
KW  - CNN-based methods
KW  - DenseMapNet
KW  - deep convolutional neural networks
KW  - repetitive regions
KW  - textureless regions
KW  - stereo vision
KW  - color stereo images
KW  - dense networks
KW  - disparity map
KW  - autoencoder method
KW  - Estimation
KW  - Two dimensional displays
KW  - Semantics
KW  - Image resolution
KW  - Three-dimensional displays
KW  - Cameras
KW  - Computer vision
DO  - 10.1109/ICRA.2018.8463172
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Disparity estimation is a difficult problem in stereo vision because the correspondence technique fails in images with textureless and repetitive regions. Recent body of work using deep convolutional neural networks (CNN) overcomes this problem with semantics. Most CNN implementations use an autoencoder method; stereo images are encoded, merged and finally decoded to predict the disparity map. In this paper, we present a CNN implementation inspired by dense networks to reduce the number of parameters. Furthermore, our approach takes into account semantic reasoning in disparity estimation. Our proposed network, called DenseMapNet, is compact, fast and can be trained end-to-end. DenseMapNet requires 290k parameters only and runs at 30Hz or faster on color stereo images in full resolution. Experimental results show that DenseMapNet accuracy is comparable with other significantly bigger CNN-based methods.
ER  - 

TY  - CONF
TI  - SceneCut: Joint Geometric and Object Segmentation for Indoor Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3213
EP  - 3220
AU  - T. T. Pham
AU  - T. Do
AU  - N. Sünderhauf
AU  - I. Reid
PY  - 2018
KW  - geometry
KW  - image colour analysis
KW  - image representation
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object detection
KW  - joint geometric
KW  - object segmentation
KW  - indoor scenes
KW  - unseen objects
KW  - nonobject surfaces
KW  - scene semantics
KW  - scene surfaces
KW  - unified energy function
KW  - hierarchical segmentation trees
KW  - RGB-D image
KW  - deep learning-based methods
KW  - SceneCut
KW  - convolutional oriented boundary network
KW  - Image segmentation
KW  - Semantics
KW  - Silicon
KW  - Object segmentation
KW  - Robots
KW  - Training
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2018.8461108
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents SceneCut, a novel approach to jointly discover previously unseen objects and non-object surfaces using a single RGB-D image. SceneCut's joint reasoning over scene semantics and geometry allows a robot to detect and segment object instances in complex scenes where modern deep learning-based methods either fail to separate object instances, or fail to detect objects that were not seen during training. SceneCut automatically decomposes a scene into meaningful regions which either represent objects or scene surfaces. The decomposition is qualified by an unified energy function over objectness and geometric fitting. We show how this energy function can be optimized efficiently by utilizing hierarchical segmentation trees. Moreover, we leverage a pre-trained convolutional oriented boundary network to predict accurate boundaries from images, which are used to construct high-quality region hierarchies. We evaluate SceneCut on several different indoor environments, and the results show that SceneCut significantly outperforms all the existing methods.
ER  - 

TY  - CONF
TI  - Bayesian Viewpoint-Dependent Robust Classification Under Model and Localization Uncertainty
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3221
EP  - 3228
AU  - Y. Feldman
AU  - V. Indelman
PY  - 2018
KW  - Bayes methods
KW  - image classification
KW  - pattern classification
KW  - Bayesian viewpoint-dependent robust classification
KW  - localization uncertainty
KW  - robust visual classification
KW  - black-box Bayesian classifier
KW  - localization error
KW  - spatial correlation
KW  - Uncertainty
KW  - Measurement uncertainty
KW  - Robots
KW  - Correlation
KW  - Bayes methods
KW  - Robustness
KW  - Training data
DO  - 10.1109/ICRA.2018.8461127
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We propose an algorithm for robust visual classification of an object of interest observed from multiple views using a black-box Bayesian classifier which provides a measure of uncertainty, in the presence of significant ambiguity and classifier noise, and of localization error. The fusion of classifier outputs takes into account viewpoint dependency and spatial correlation among observations, as well as pose uncertainty when these observations are taken and a measure of confidence provided by the classifier itself. Our experiments confirm an improvement in robustness over state-of-the-art.
ER  - 

TY  - CONF
TI  - Signature of Topologically Persistent Points for 3D Point Cloud Description
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3229
EP  - 3234
AU  - W. J. Beksi
AU  - N. Papanikolopoulos
PY  - 2018
KW  - computer graphics
KW  - image resolution
KW  - solid modelling
KW  - object classification
KW  - object detection
KW  - 3D point cloud processing tasks
KW  - RGB-D dataset
KW  - spatial resolutions
KW  - topological invariant encoding
KW  - global descriptor
KW  - topologically persistent point signature
KW  - homology groups
KW  - competitive 3D point cloud descriptor
KW  - topological space
KW  - 3D point cloud data
KW  - STPP
KW  - time 3.0 d
KW  - Three-dimensional displays
KW  - Shape
KW  - Robot sensing systems
KW  - Generators
KW  - Histograms
KW  - Topology
KW  - Face
DO  - 10.1109/ICRA.2018.8460605
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present the Signature of Topologically Persistent Points (STPP), a global descriptor that encodes topological invariants of 3D point cloud data. These topological invariants include the zeroth and first homology groups and are computed using persistent homology, a method for finding the features of a topological space at different spatial resolutions. STPP is a competitive 3D point cloud descriptor when compared to the state of art and is resilient to noisy sensor data. We demonstrate experimentally on a publicly available RGB-D dataset that STPP can be used as a distinctive signature, thus allowing for 3D point cloud processing tasks such as object detection and classification.
ER  - 

TY  - CONF
TI  - Label Fusion: A Pipeline for Generating Ground Truth Labels for Real RGBD Data of Cluttered Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3235
EP  - 3242
AU  - P. Marion
AU  - P. R. Florence
AU  - L. Manuelli
AU  - R. Tedrake
PY  - 2018
KW  - image colour analysis
KW  - image fusion
KW  - image reconstruction
KW  - image representation
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural net architecture
KW  - object detection
KW  - object tracking
KW  - pose estimation
KW  - robot vision
KW  - video cameras
KW  - video signal processing
KW  - reconstruction techniques
KW  - ground truth label generation
KW  - labeled object instances
KW  - object pose
KW  - video scene collection
KW  - annotation pipeline
KW  - DNN architecture
KW  - RGBD image
KW  - object meshes
KW  - human assisted ICP-fitting
KW  - 3D dense reconstruction
KW  - RGBD camera
KW  - pixelwise labels
KW  - specific robotic manipulation task
KW  - training data
KW  - DNN pipelines
KW  - object segmentation
KW  - deep neural network architectures
KW  - cluttered scenes
KW  - real RGBD data
KW  - label fusion
KW  - Pipelines
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Image segmentation
KW  - Cameras
KW  - Image reconstruction
DO  - 10.1109/ICRA.2018.8460950
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Deep neural network (DNN) architectures have been shown to outperform traditional pipelines for object segmentation and pose estimation using RGBD data, but the performance of these DNN pipelines is directly tied to how representative the training data is of the true data. Hence a key requirement for employing these methods in practice is to have a large set of labeled data for your specific robotic manipulation task, a requirement that is not generally satisfied by existing datasets. In this paper we develop a pipeline to rapidly generate high quality RGBD data with pixelwise labels and object poses. We use an RGBD camera to collect video of a scene from multiple viewpoints and leverage existing reconstruction techniques to produce a 3D dense reconstruction. We label the 3D reconstruction using a human assisted ICP-fitting of object meshes. By reprojecting the results of labeling the 3D scene we can produce labels for each RGBD image of the scene. This pipeline enabled us to collect over 1,000,000 labeled object instances in just a few days. We use this dataset to answer questions related to how much training data is required, and of what quality the data must be, to achieve high performance from a DNN architecture. Our dataset and annotation pipeline are available at labelfusion.csail.mit.edu.
ER  - 

TY  - CONF
TI  - Dropout Sampling for Robust Object Detection in Open-Set Conditions
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3243
EP  - 3249
AU  - D. Miller
AU  - L. Nicholson
AU  - F. Dayoub
AU  - N. Sünderhauf
PY  - 2018
KW  - approximation theory
KW  - Bayes methods
KW  - image classification
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - regression analysis
KW  - robot vision
KW  - sampling methods
KW  - dropout sampling network
KW  - dropout variational inference
KW  - approximation technique
KW  - Bayesian deep learning
KW  - mobile robot
KW  - versatile campus environment
KW  - robotic vision
KW  - regression tasks
KW  - image classification
KW  - open-set conditions
KW  - robust object detection
KW  - Object detection
KW  - Uncertainty
KW  - Training
KW  - Bayes methods
KW  - Entropy
KW  - Task analysis
KW  - Robots
DO  - 10.1109/ICRA.2018.8460700
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Dropout Variational Inference, or Dropout Sampling, has been recently proposed as an approximation technique for Bayesian Deep Learning and evaluated for image classification and regression tasks. This paper investigates the utility of Dropout Sampling for object detection for the first time. We demonstrate how label uncertainty can be extracted from a state-of-the-art object detection system via Dropout Sampling. We evaluate this approach on a large synthetic dataset of 30,000 images, and a real-world dataset captured by a mobile robot in a versatile campus environment. We show that this uncertainty can be utilized to increase object detection performance under the open-set conditions that are typically encountered in robotic vision. A Dropout Sampling network is shown to achieve a 12.3 % increase in recall (for the same precision score as a standard network) and a 15.1 % increase in precision (for the same recall score as the standard network).
ER  - 

TY  - CONF
TI  - Early Turn-Taking Prediction with Spiking Neural Networks for Human Robot Collaboration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3250
EP  - 3256
AU  - T. Zhou
AU  - J. P. Wachs
PY  - 2018
KW  - cognition
KW  - control engineering computing
KW  - groupware
KW  - human computer interaction
KW  - human-robot interaction
KW  - medical computing
KW  - medical robotics
KW  - neural nets
KW  - surgery
KW  - team working
KW  - user interfaces
KW  - early prediction capability
KW  - turn-taking actions
KW  - early turn-taking prediction
KW  - Spiking Neural networks
KW  - human robot collaboration
KW  - human teamwork
KW  - Cognitive Turn-taking Model
KW  - turn-taking prediction algorithms
KW  - CTTM
KW  - robotic scrub nurse
KW  - human turn-taking intentions
KW  - multimodal human communication cues
KW  - Neurons
KW  - Robot kinematics
KW  - Task analysis
KW  - Training
KW  - Teamwork
DO  - 10.1109/ICRA.2018.8461208
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Turn-taking is essential to the structure of human teamwork. Humans are typically aware of team members' intention to keep or relinquish their turn before a turn switch, where the responsibility of working on a shared task is shifted. Future co-robots are also expected to provide such competence. To that end, this paper proposes the Cognitive Turn-taking Model (CTTM), which leverages cognitive models (i.e., Spiking Neural Network) to achieve early turn-taking prediction. The CTTM framework can process multimodal human communication cues (both implicit and explicit) and predict human turn-taking intentions in an early stage. The proposed framework is tested on a simulated surgical procedure, where a robotic scrub nurse predicts the surgeon's turn-taking intention. It was found that the proposed CTTM framework outperforms the state-of-the-art turn-taking prediction algorithms by a large margin. It also outperforms humans when presented with partial observations of communication cues (i.e., less than 40 % of full actions). This early prediction capability enables robots to initiate turn-taking actions at an early stage, which facilitates collaboration and increases overall efficiency.
ER  - 

TY  - CONF
TI  - Learning Human Ergonomic Preferences for Handovers
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3257
EP  - 3264
AU  - A. Bestick
AU  - R. Pandya
AU  - R. Bajcsy
AU  - A. D. Dragan
PY  - 2018
KW  - ergonomics
KW  - human-robot interaction
KW  - manipulators
KW  - human ergonomic preferences
KW  - handovers
KW  - robots
KW  - ergonomic human grasping configurations
KW  - ergonomic cost function
KW  - online estimation problem
KW  - in-person user study
KW  - Ergonomics
KW  - Handover
KW  - Cost function
KW  - Training
KW  - Manipulators
DO  - 10.1109/ICRA.2018.8461216
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Our goal is for people to be physically comfortable when taking objects from robots. This puts a burden on the robot to hand over the object in such a way that a person can easily reach it, without needing to strain or twist their arm - a way that is conducive to ergonomic human grasping configurations. To achieve this, the robot needs to understand what makes a configuration more or less ergonomic to the person, i.e. their ergonomic cost function. In this work, we formulate learning a person's ergonomic cost as an online estimation problem. The robot can implicitly make queries to the person by handing them objects in different configurations, and gets observations in response about the way they choose to take the object. We compare the performance of both passive and active approaches for solving this problem in simulation, as well as in an in-person user study.
ER  - 

TY  - CONF
TI  - Joining High-Level Symbolic Planning with Low-Level Motion Primitives in Adaptive HRI: Application to Dressing Assistance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3273
EP  - 3278
AU  - G. Canal
AU  - E. Pignat
AU  - G. Alenyà
AU  - S. Calinon
AU  - C. Torras
PY  - 2018
KW  - control engineering computing
KW  - footwear
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - planning (artificial intelligence)
KW  - robot programming
KW  - service robots
KW  - daily living assistance
KW  - robot motion encoding
KW  - programming
KW  - shoe-dressing scenario
KW  - robot verbosity
KW  - robot speed
KW  - safe living assistance
KW  - dressing assistance
KW  - adaptive HRI
KW  - low-level motion primitives
KW  - high-level symbolic planning
KW  - user preferences
KW  - human-robot interaction
KW  - Task analysis
KW  - Planning
KW  - Robot sensing systems
KW  - Footwear
KW  - Foot
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460606
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - For a safe and successful daily living assistance, far from the highly controlled environment of a factory, robots should be able to adapt to ever-changing situations. Programming such a robot is a tedious process that requires expert knowledge. An alternative is to rely on a high-level planner, but the generic symbolic representations used are not well suited to particular robot executions. Contrarily, motion primitives encode robot motions in a way that can be easily adapted to different situations. This paper presents a combined framework that exploits the advantages of both approaches. The number of required symbolic states is reduced, as motion primitives provide “smart actions” that take the current state and cope online with variations. Symbolic actions can include interactions (e.g., ask and inform) that are difficult to demonstrate. We show that the proposed framework can adapt to the user preferences (in terms of robot speed and robot verbosity), can readjust the trajectories based on the user movements, and can handle unforeseen situations. Experiments are performed in a shoe-dressing scenario. This scenario is particularly interesting because it involves a sufficient number of actions, and the human-robot interaction requires the handling of user preferences and unexpected reactions.
ER  - 

TY  - CONF
TI  - A Passivity-Based Strategy for Coaching in Human-Robot Interaction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3279
EP  - 3284
AU  - C. Talignani Landi
AU  - F. Ferraguti
AU  - C. Fantuzzi
AU  - C. Secchi
PY  - 2018
KW  - control engineering computing
KW  - end effectors
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - robot programming
KW  - end-effector
KW  - initial trajectory
KW  - path tracking
KW  - admittance parameters
KW  - passivity-based strategy
KW  - coaching
KW  - human-robot interaction
KW  - robot programming
KW  - programming techniques
KW  - passivity-based framework
KW  - Dynamical Movement Primitives
KW  - admittance control
KW  - human operator grabs
KW  - Trajectory
KW  - Admittance
KW  - Service robots
KW  - Robot sensing systems
KW  - Hidden Markov models
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8460836
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In order to make robot programming more easy and immediate, walk-through programming techniques can be exploited. However, a modification of a portion of the trajectory usually means to execute the path from the beginning. In this paper we propose a passivity-based framework to modify the trajectory online, manually driving the robot throughout the desired correction. The system follows the initial trajectory, encoded with Dynamical Movement Primitives, by setting high gains in the admittance control. When the human operator grabs the end-effector, the robot becomes compliant and the user can easily teach the desired correction, until he/she releases it at the end of the modification. Finally, the correction is optimally joined to the initial trajectory, restarting the path tracking. To avoid unsafe behaviors, the variation of the admittance parameters is performed exploiting energy tanks, in order to preserve the passivity of the interaction.
ER  - 

TY  - CONF
TI  - A Tensegrity-Inspired Compliant 3-DOF Compliant Joint
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3301
EP  - 3306
AU  - J. M. Friesen
AU  - J. L. Dean
AU  - T. Bewley
AU  - V. Sunspiral
PY  - 2018
KW  - actuators
KW  - design engineering
KW  - geometry
KW  - mechatronics
KW  - motion control
KW  - optimisation
KW  - position control
KW  - robot dynamics
KW  - velocity control
KW  - tensegrity-inspired compliant three degree-of-freedom robotic joint
KW  - continuously soft materials
KW  - embedded sensing
KW  - position information
KW  - velocity information
KW  - geometry selection
KW  - optimization
KW  - theoretical configuration space
KW  - mechatronic design solutions
KW  - hardware prototype
KW  - low order dynamic systems
KW  - soft robotic systems
KW  - robotic limb
KW  - omnidirectional compliance
KW  - Tensegrity-Inspired Compliant 3-DOF Compliant joint
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Geometry
KW  - Force
KW  - Topology
DO  - 10.1109/ICRA.2018.8460593
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Our Tensegrity-Inspired Compliant Three degree-of-freedom (DOF) robotic joint adds omnidirectional compliance to robotic limbs while reducing sprung mass through base mounted actuation. This enables a robotic limb which is safer to operate alongside humans and fragile equipment while still capable of generating quick movements and large forces if required. Unlike many other soft robotic systems which leverage continuously soft materials, our joint is simpler to model with low order dynamic systems and has a host of embedded sensing which provide ample information of its position and velocity. We first discuss geometry selection and optimization to maximize the theoretical configuration space of the joint. We then show several of our mechatronic design solutions, which are easily generalized to a multitude of cable-driven mechanisms, and demonstrate the performance of these mechanisms within the context of our hardware prototype. We then present results on the controllable stiffness of our physical prototype. Finally, we demonstrate the strength of our prototype which is capable of lifting a 7 kg mass at a distance of 0.95 meters from the joint.
ER  - 

TY  - CONF
TI  - Training Deep Neural Networks for Visual Servoing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3307
EP  - 3314
AU  - Q. Bateux
AU  - E. Marchand
AU  - J. Leitner
AU  - F. Chaumette
AU  - P. Corke
PY  - 2018
KW  - feedforward neural nets
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - position control
KW  - robot vision
KW  - servomechanisms
KW  - visual servoing
KW  - 6 DOF robot
KW  - deep neural network-based method
KW  - convolutional neural network
KW  - robust handling
KW  - scene-agnostic network
KW  - deep neural network training
KW  - real-time 6 DOF positioning
KW  - pose-based visual servoing control law
KW  - occlusions
KW  - lighting variations
KW  - Training
KW  - Robots
KW  - Feature extraction
KW  - Task analysis
KW  - Cameras
KW  - Voltage control
KW  - Robustness
DO  - 10.1109/ICRA.2018.8461068
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a deep neural network-based method to perform high-precision, robust and real-time 6 DOF positioning tasks by visual servoing. A convolutional neural network is fine-tuned to estimate the relative pose between the current and desired images and a pose-based visual servoing control law is considered to reach the desired pose. The paper describes how to efficiently and automatically create a dataset used to train the network. We show that this enables the robust handling of various perturbations (occlusions and lighting variations). We then propose the training of a scene-agnostic network by feeding in both the desired and current images into a deep network. The method is validated on a 6 DOF robot.
ER  - 

TY  - CONF
TI  - A Delay Compensation Approach for Pan-Tilt-Unit-based Stereoscopic 360 Degree Telepresence Systems Using Head Motion Prediction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3323
EP  - 3330
AU  - T. Aykut
AU  - C. Zou
AU  - J. Xu
AU  - D. Van Opdenbosch
AU  - E. Steinbach
PY  - 2018
KW  - helmet mounted displays
KW  - motion estimation
KW  - stereo image processing
KW  - telecontrol
KW  - video signal processing
KW  - virtual reality
KW  - Head-Mounted Displays
KW  - immersive experience
KW  - unbearable motion sickness
KW  - teleoperation session
KW  - delay compensation approach
KW  - head motion prediction
KW  - head motion estimation
KW  - quality of experience
KW  - communication delays
KW  - mean compensation rates
KW  - pan-tilt-unit-based stereoscopic 360 degree telepresence systems
KW  - teleoperation applications
KW  - quality-reducing effect
KW  - head movement predictors
KW  - head motion datasets
KW  - 3D 360° video
KW  - time 100.0 ms to 1000.0 ms
KW  - time 3.0 d
KW  - Delays
KW  - Head
KW  - Cameras
KW  - Stereo image processing
KW  - Three-dimensional displays
KW  - Visualization
KW  - Resists
DO  - 10.1109/ICRA.2018.8460750
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The acceptance of teleoperation applications like tele-driving, tele-surgery, tele-maintenance, etc., is challenged by the quality-reducing effect of end-to-end latency. Particularly, when users wear Head-Mounted Displays to enhance the immersive experience, the lag between head motion and display response leads to unbearable motion sickness, indisposition, and, in the worst case, abortion of the teleoperation session. In this paper, we propose a delay compensation approach with head motion prediction that can be applied to pan-tilt-unit-based stereoscopic telepresence systems. We provide the user with the impression of a 3D 360° video that represents the remote scene without noticing the present delay, even when rotating the head. To this end, we propose a novel prediction paradigm for head motion estimation to substantially mitigate the negative impact of the latency on the quality of experience. We re-implemented state-of-the-art head movement predictors and compare them to our proposed approach by means of qualitative measures. In our experiments, we used two real and independent head motion datasets for validation and tested communication delays between 100-1000ms. Our results show that mean compensation rates of more than 99% are able with our approach.
ER  - 

TY  - CONF
TI  - Improving 6D Pose Estimation of Objects in Clutter Via Physics-Aware Monte Carlo Tree Search
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3331
EP  - 3338
AU  - C. Mitash
AU  - A. Boularias
AU  - K. E. Bekris
PY  - 2018
KW  - clutter
KW  - image registration
KW  - Monte Carlo methods
KW  - object detection
KW  - optimisation
KW  - pose estimation
KW  - rendering (computer graphics)
KW  - tree searching
KW  - global point cloud registration techniques
KW  - global optimization process
KW  - cluttered scenes physically-consistent object poses
KW  - 6D pose estimation
KW  - object detection
KW  - physics-aware Monte Carlo tree search
KW  - Cartesian product
KW  - MCTS
KW  - rendering
KW  - upper confidence bound technique
KW  - UCB technique
KW  - Search problems
KW  - Three-dimensional displays
KW  - Solid modeling
KW  - Pose estimation
KW  - Computational modeling
KW  - Training
KW  - Image segmentation
DO  - 10.1109/ICRA.2018.8461163
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This work proposes a process for efficiently searching over combinations of individual object 6D pose hypotheses in cluttered scenes, especially in cases involving occlusions and objects resting on each other. The initial set of candidate object poses is generated from state-of-the-art object detection and global point cloud registration techniques. The best scored pose per object by using these techniques may not be accurate due to overlaps and occlusions. Nevertheless, experimental indications provided in this work show that object poses with lower ranks may be closer to the real poses than ones with high ranks according to registration techniques. This motivates a global optimization process for improving these poses by taking into account scene-level physical interactions between objects. It also implies that the Cartesian product of candidate poses for interacting objects must be searched so as to identify the best scene-level hypothesis. To perform the search efficiently, the candidate poses for each object are clustered so as to reduce their number but still keep a sufficient diversity. Then, searching over the combinations of candidate object poses is performed through a Monte Carlo Tree Search (MCTS) process that uses the similarity between the observed depth image of the scene and a rendering of the scene given the hypothesized pose as a score that guides the search procedure. MCTS handles in a principled way the tradeoff between fine-tuning the most promising poses and exploring new ones, by using the Upper Confidence Bound (UCB) technique. Experimental results indicate that this process is able to quickly identify in cluttered scenes physically-consistent object poses that are significantly closer to ground truth compared to poses found by point cloud registration methods.
ER  - 

TY  - CONF
TI  - SE3-Pose-Nets: Structured Deep Dynamics Models for Visuomotor Control
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3339
EP  - 3346
AU  - A. Byravan
AU  - F. Leeb
AU  - F. Meier
AU  - D. Fox
PY  - 2018
KW  - cameras
KW  - closed loop systems
KW  - control engineering computing
KW  - gradient methods
KW  - image colour analysis
KW  - image segmentation
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - minimisation
KW  - neural nets
KW  - pose estimation
KW  - robot dynamics
KW  - robot vision
KW  - SE3-pose-Nets
KW  - deep visuomotor control
KW  - SE3-Nets
KW  - encoder-decoder structure
KW  - pose embedding
KW  - point-wise data associations
KW  - closed-loop control
KW  - scene dynamics
KW  - structred deep dynamics models
KW  - pose error minimization
KW  - gradient-based methods
KW  - Baxter robot
KW  - Three-dimensional displays
KW  - Predictive models
KW  - Transforms
KW  - Computational modeling
KW  - Data models
KW  - Aerospace electronics
KW  - Training
DO  - 10.1109/ICRA.2018.8461184
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, we present an approach to deep visuomotor control using structured deep dynamics models. Our model, a variant of SE3-Nets, learns a low-dimensional pose embedding for visuomotor control via an encoder-decoder structure. Unlike prior work, our model is structured: given an input scene, our network explicitly learns to segment salient parts and predict their pose embedding and motion, modeled as a change in the pose due to the applied actions. We train our model using a pair of point clouds separated by an action and show that given supervision only through point-wise data associations between the frames our network is able to learn a meaningful segmentation of the scene along with consistent poses. We further show that our model can be used for closed-loop control directly in the learned low-dimensional pose space, where the actions are computed by minimizing pose error using gradient-based methods, similar to traditional model-based control. We present results on controlling a Baxter robot from raw depth data in simulation and RGBD data in the real world and compare against two baseline deep networks. We also test the robustness and generalization performance of our controller under changes in camera pose, lighting, occlusion, and motion. Our method is robust, runs in real-time, achieves good prediction of scene dynamics, and outperforms baselines on multiple control runs. Video results can be found at: https://rse-lab.cs.washington.edu/se3-structured-deep-ctrl/.
ER  - 

TY  - CONF
TI  - Fast Object Learning and Dual-arm Coordination for Cluttered Stowing, Picking, and Packing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3347
EP  - 3354
AU  - M. Schwarz
AU  - C. Lenz
AU  - G. M. García
AU  - S. Koo
AU  - A. S. Periyasamy
AU  - M. Schreiber
AU  - S. Behnke
PY  - 2018
KW  - grippers
KW  - humanoid robots
KW  - human-robot interaction
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - service robots
KW  - robotic picking
KW  - cluttered bins
KW  - 2017 Amazon Robotics Challenge
KW  - ARC
KW  - storage system
KW  - deep object perception pipeline
KW  - custom turntable capture system
KW  - transfer learning
KW  - robot arms
KW  - NimbRo Picking
KW  - stow-and-pick task
KW  - Task analysis
KW  - Training
KW  - Robot kinematics
KW  - Pipelines
KW  - Robot sensing systems
KW  - Semantics
DO  - 10.1109/ICRA.2018.8461195
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Robotic picking from cluttered bins is a demanding task, for which Amazon Robotics holds challenges. The 2017 Amazon Robotics Challenge (ARC) required stowing items into a storage system, picking specific items, and packing them into boxes. In this paper, we describe the entry of team NimbRo Picking. Our deep object perception pipeline can be quickly and efficiently adapted to new items using a custom turntable capture system and transfer learning. It produces high-quality item segments, on which grasp poses are found. A planning component coordinates manipulation actions between two robot arms, minimizing execution time. The system has been demonstrated successfully at ARC, where our team reached second places in both the picking task and the final stow-and-pick task. We also evaluate individual components.
ER  - 

TY  - CONF
TI  - Optical Sensing and Control Methods for Soft Pneumatically Actuated Robotic Manipulators
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3355
EP  - 3362
AU  - J. L. Molnar
AU  - C. Cheng
AU  - L. O. Tiziani
AU  - B. Boots
AU  - F. L. Hammond
PY  - 2018
KW  - elastomers
KW  - manipulators
KW  - mean square error methods
KW  - optical sensors
KW  - pneumatic actuators
KW  - regression analysis
KW  - strain data
KW  - chamber pressures
KW  - gravitational tip loading conditions
KW  - soft continuum robot
KW  - pressure data
KW  - base orientation
KW  - combined optical sensor
KW  - control methods
KW  - soft pneumatically actuated robotic
KW  - soft pneumatic manipulator motion
KW  - optically-diffuse elastomer sensors
KW  - strain mode
KW  - optical sensors measure local strains
KW  - axial center
KW  - optical sensing method
KW  - soft pneumatically actuated robotic manipulators
KW  - regression analyses
KW  - end-effector
KW  - Robot sensing systems
KW  - Optical fiber sensors
KW  - Optical fibers
KW  - Pneumatic systems
DO  - 10.1109/ICRA.2018.8461110
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A low-cost optical sensing method for improved measurement and control of soft pneumatic manipulator motion is presented. The core of a soft continuum robot is embedded with several optically-diffuse elastomer sensors which attenuate light depending on their strain mode and degree. The optical sensors measure local strains at the robot's axial center, and these strain data are combined with measured actuator chamber pressures to determine the pose of the robot under various gravitational and tip loading conditions. Regression analyses using neural networks (NNs) demonstrate that when the soft continuum robot's base orientation is fixed, the position of its end-effector can be estimated with 3.42 times more accuracy (71 % smaller root mean squared error) when using both optical sensor and pressure data (~2.44mm) than when using only pressure data (~8.3mm). When the robot's base orientation was varied, the combined optical sensor and pressure data provide position estimates which are as much as 37.8 times more accurate (~2.76mm) than pressure data alone (~104mm).
ER  - 

TY  - CONF
TI  - Mono-Stixels: Monocular Depth Reconstruction of Dynamic Street Scenes
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3369
EP  - 3375
AU  - F. Brickwedde
AU  - S. Abraham
AU  - R. Mester
PY  - 2018
KW  - cameras
KW  - image motion analysis
KW  - image reconstruction
KW  - image representation
KW  - image segmentation
KW  - image sequences
KW  - stereo image processing
KW  - monocular depth reconstruction
KW  - dynamic street scenes
KW  - semantic information
KW  - pixel-wise semantic segmentation
KW  - camera motion
KW  - optical flow estimation
KW  - depth reconstruction
KW  - stereo depth measurements
KW  - monostixel model
KW  - Semantics
KW  - Cameras
KW  - Optical imaging
KW  - Vehicle dynamics
KW  - Estimation
KW  - Dynamics
KW  - Motion segmentation
DO  - 10.1109/ICRA.2018.8460490
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present mono-stixels, a compact environment representation specially designed for dynamic street scenes. Mono-stixels are a novel approach to estimate stixels from a monocular camera sequence instead of the traditionally used stereo depth measurements. Our approach jointly infers the depth, motion and semantic information of the dynamic scene as a 1D energy minimization problem based on optical flow estimates, pixel-wise semantic segmentation and camera motion. The optical flow of a stixel is described by a homography. By applying the mono-stixel model the degrees of freedom of a stixel-homography are reduced to only up to two degrees of freedom. Furthermore, we exploit a scene model and semantic information to handle moving objects. In our experiments we use the public available DeepFlow for optical flow estimation and FCN8s for the semantic information as inputs and show on the KITTI 2015 dataset that mono-stixels provide a compact and reliable depth reconstruction of both the static and moving parts of the scene. Thereby, mono-stixels overcome the limitation to static scenes of previous structure-from-motion approaches.
ER  - 

TY  - CONF
TI  - The DriveU Traffic Light Dataset: Introduction and Comparison with Existing Datasets
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3376
EP  - 3383
AU  - A. Fregin
AU  - J. Muller
AU  - U. Krebel
AU  - K. Dietmayer
PY  - 2018
KW  - computer vision
KW  - image recognition
KW  - traffic engineering computing
KW  - DriveU traffic light dataset
KW  - traffic light recognition
KW  - autonomous driving
KW  - computer vision
KW  - University of Ulm Traffic Light Dataset
KW  - Daimler AG
KW  - Cameras
KW  - Urban areas
KW  - Benchmark testing
KW  - Lenses
KW  - Training
KW  - Visualization
KW  - Detectors
DO  - 10.1109/ICRA.2018.8460737
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Autonomous driving is a topic in computer vision which has captured a great deal of attention in recent years. One key problem is the detection and state analysis of traffic lights. Even over time, very few datasets for research in this topic have been published and they vary widely in quantity and in quality. To address the complexity of traffic light recognition, we introduce the DriveU**driveU is a joint innovation center of the Daimler AG and the University of Ulm Traffic Light Dataset (DTLD), a large-scale dataset consisting of more than 230,000 annotations. All annotations are hand-labeled according to strict rules and show a high quality. Recordings were made in eleven different cities during different weather conditions. Our dataset exceeds previous traffic light datasets in size, variance, annotation quality and amount of additional sensor data. We prove the extent of our dataset by an extensive comparison with existing traffic light datasets. Miscellaneous dataset criteria are compared, illustrated and statistically analyzed. In the process, metrics to express the quality and variance of datasets are developed and verified. The dataset can be downloaded from http://traffic-light-data.de.
ER  - 

TY  - CONF
TI  - Modeling Driver Behavior from Demonstrations in Dynamic Environments Using Spatiotemporal Lattices
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3384
EP  - 3390
AU  - D. S. González
AU  - O. Erkent
AU  - V. Romero-Cano
AU  - J. Dibangoye
AU  - C. Laugier
PY  - 2018
KW  - collision avoidance
KW  - driver information systems
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - road vehicles
KW  - spatiotemporal lattices
KW  - path planners
KW  - intelligent vehicles
KW  - cost function
KW  - model parameters
KW  - demonstrated driving data
KW  - Inverse Reinforcement
KW  - IRL methods
KW  - forward control problem
KW  - traditional path-planning techniques
KW  - conformal spatiotemporal state lattice
KW  - dynamic obstacles
KW  - model assessment
KW  - IRL framework
KW  - highly dynamic environments
KW  - highway tactical driving task
KW  - instrumented vehicle
KW  - driver behavior modeling
KW  - Trajectory
KW  - Lattices
KW  - Task analysis
KW  - Spatiotemporal phenomena
KW  - Vehicle dynamics
KW  - Learning (artificial intelligence)
KW  - Cost function
DO  - 10.1109/ICRA.2018.8460208
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - One of the most challenging tasks in the development of path planners for intelligent vehicles is the design of the cost function that models the desired behavior of the vehicle. While this task has been traditionally accomplished by hand-tuning the model parameters, recent approaches propose to learn the model automatically from demonstrated driving data using Inverse Reinforcement Learning (IRL). To determine if the model has correctly captured the demonstrated behavior, most IRL methods require obtaining a policy by solving the forward control problem repetitively. Calculating the full policy is a costly task in continuous or large domains and thus often approximated by finding a single trajectory using traditional path-planning techniques. In this work, we propose to find such a trajectory using a conformal spatiotemporal state lattice, which offers two main advantages. First, by conforming the lattice to the environment, the search is focused only on feasible motions for the robot, saving computational power. And second, by considering time as part of the state, the trajectory is optimized with respect to the motion of the dynamic obstacles in the scene. As a consequence, the resulting trajectory can be used for the model assessment. We show how the proposed IRL framework can successfully handle highly dynamic environments by modeling the highway tactical driving task from demonstrated driving data gathered with an instrumented vehicle.
ER  - 

TY  - CONF
TI  - Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3399
EP  - 3406
AU  - E. Schmerling
AU  - K. Leung
AU  - W. Vollprecht
AU  - M. Pavone
PY  - 2018
KW  - decision making
KW  - human-robot interaction
KW  - intelligent transportation systems
KW  - learning (artificial intelligence)
KW  - probability
KW  - highway on-ramp-off-ramps
KW  - human-robot interaction policies
KW  - multimodal probabilistic model-based planning
KW  - traffic weaving scenario
KW  - human-in-the-loop simulation
KW  - candidate future robot actions
KW  - interaction history
KW  - action distributions
KW  - direct learning
KW  - candidate robot action sequences
KW  - human responses
KW  - massively parallel sampling
KW  - real-time robot policy construction
KW  - human-human exemplars
KW  - future human actions
KW  - multimodal probability distributions
KW  - inherent multimodal uncertainty
KW  - experienced drivers
KW  - entering exiting cars
KW  - decision making
KW  - Robots
KW  - Vehicles
KW  - Predictive models
KW  - History
KW  - Cognition
KW  - Probabilistic logic
KW  - Weaving
DO  - 10.1109/ICRA.2018.8460766
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a method for constructing human-robot interaction policies in settings where multimodality, i.e., the possibility of multiple highly distinct futures, plays a critical role in decision making. We are motivated in this work by the example of traffic weaving, e.g., at highway on-ramps/off-ramps, where entering and exiting cars must swap lanes in a short distance-a challenging negotiation even for experienced drivers due to the inherent multimodal uncertainty of who will pass whom. Our approach is to learn multimodal probability distributions over future human actions from a dataset of human-human exemplars and perform real-time robot policy construction in the resulting environment model through massively parallel sampling of human responses to candidate robot action sequences. Direct learning of these distributions is made possible by recent advances in the theory of conditional variational autoencoders (CVAEs), whereby we learn action distributions simultaneously conditioned on the present interaction history, as well as candidate future robot actions in order to take into account response dynamics. We demonstrate the efficacy of this approach with a human-in-the-loop simulation of a traffic weaving scenario.
ER  - 

TY  - CONF
TI  - AA-ICP: Iterative Closest Point with Anderson Acceleration
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3407
EP  - 3412
AU  - A. L. Pavlov
AU  - G. W. Ovchinnikov
AU  - D. Y. Derbyshev
AU  - D. Tsetserukou
AU  - I. V. Oseledets
PY  - 2018
KW  - iterative methods
KW  - PCL
KW  - Point Cloud Library
KW  - fixed point problem
KW  - ICP implementations
KW  - standard Picard iteration
KW  - iterative procedure
KW  - registration
KW  - scan-matching
KW  - Anderson acceleration
KW  - iterative closest point
KW  - AA-ICP
KW  - Iterative closest point algorithm
KW  - Acceleration
KW  - History
KW  - Convergence
KW  - Three-dimensional displays
KW  - Robots
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2018.8461063
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Iterative Closest Point (ICP) is a widely used method for performing scan-matching and registration. Being simple and robust, this method is still computationally expensive and may be challenging to use in real-time applications with limited resources on mobile platforms. In this paper we propose a novel effective method for acceleration of ICP which does not require substantial modifications to the existing code. This method is based on an idea of Anderson acceleration which is an iterative procedure for finding a fixed point of contractive mapping. The latter is often faster than a standard Picard iteration, usually used in ICP implementations. We show that ICP, being a fixed point problem, can be significantly accelerated by this method enhanced by heuristics to improve overall robustness. We implement proposed approach into Point Cloud Library (PCL) and make it available online. Benchmarking on the real-world data fully supports our claims.
ER  - 

TY  - CONF
TI  - Robust and Fast 3D Scan Alignment Using Mutual Information
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3413
EP  - 3420
AU  - N. Mehta
AU  - J. R. McBride
AU  - G. Pandey
PY  - 2018
KW  - graphics processing units
KW  - image registration
KW  - solid modelling
KW  - stereo image processing
KW  - mutual information
KW  - point clouds
KW  - 3D voxel grid
KW  - parallel implementation
KW  - 3D scan alignment
KW  - 6 DOF rigid body transformation
KW  - 6-degree-of-freedom rigid body transformation
KW  - MI
KW  - Three-dimensional displays
KW  - Mutual information
KW  - Robustness
KW  - Histograms
KW  - Iterative closest point algorithm
KW  - Optimization
KW  - Feature extraction
DO  - 10.1109/ICRA.2018.8460716
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a mutual information (MI) based algorithm for the estimation of full 6-degree-of-freedom (DOF) rigid body transformation between two overlapping point clouds. We first divide the scene into a 3D voxel grid and define simple to compute features for each voxel in the scan. The two scans that need to be aligned are considered as a collection of these features and the MI between these voxelized features is maximized to obtain the correct alignment of scans. We have implemented our method with various simple point cloud features (such as number of points in voxel, variance of z-height in voxel) and compared the performance of the proposed method with existing point-to-point and point-to-distribution registration methods. We show that our approach has an efficient and fast parallel implementation on GPU, and evaluate the robustness and speed of the proposed algorithm on two real-world datasets which have variety of dynamic scenes from different environments.
ER  - 

TY  - CONF
TI  - Drive Video Analysis for the Detection of Traffic Near-Miss Incidents
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3421
EP  - 3428
AU  - H. Kataoka
AU  - T. Suzuki
AU  - S. Oikawa
AU  - Y. Matsui
AU  - Y. Satoh
PY  - 2018
KW  - automobiles
KW  - driver information systems
KW  - learning (artificial intelligence)
KW  - object detection
KW  - road safety
KW  - road traffic
KW  - video signal processing
KW  - traffic near-miss incidents
KW  - self-driving cars
KW  - advanced driver assistance system equipped vehicles
KW  - dangerous traffic
KW  - normal drivers
KW  - novel traffic database
KW  - mounting driving recorders
KW  - automated systems
KW  - database instances
KW  - large-scale traffic near-miss incident database
KW  - monocular driving recorder
KW  - NIDB traffic
KW  - primary database-related improvements
KW  - near-miss scenes
KW  - near-miss detection
KW  - drive video analysis
KW  - near-miss incident
KW  - motion representation
KW  - performance level
KW  - Databases
KW  - Vehicles
KW  - Autonomous automobiles
KW  - Semantics
KW  - Advanced driver assistance systems
KW  - Public transportation
KW  - Training
DO  - 10.1109/ICRA.2018.8460812
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Because of their recent introduction, self-driving cars and advanced driver assistance system (ADAS) equipped vehicles have had little opportunity to learn, the dangerous traffic (including near-miss incident) scenarios that provide normal drivers with strong motivation to drive safely. Accordingly, as a means of providing learning depth, this paper presents a novel traffic database that contains information on a large number of traffic near-miss incidents that were obtained by mounting driving recorders in more than 100 taxis over the course of a decade. The study makes the following two main contributions: (i) In order to assist automated systems in detecting near-miss incidents based on database instances, we created a large-scale traffic near-miss incident database (NIDB) that consists of video clip of dangerous events captured by monocular driving recorders. (ii) To illustrate the applicability of NIDB traffic near-miss incidents, we provide two primary database-related improvements: parameter fine-tuning using various near-miss scenes from NIDB, and foreground/background separation into motion representation. Then, using our new database in conjunction with a monocular driving recorder, we developed a near-miss recognition method that provides automated systems with a performance level that is comparable to a human-level understanding of near-miss incidents (64.5% vs. 68.4% at near-miss recognition, 61.3% vs. 78.7% at near-miss detection).
ER  - 

TY  - CONF
TI  - A Modular Dielectric Elastomer Actuator to Drive Miniature Autonomous Underwater Vehicles
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3429
EP  - 3435
AU  - F. Berlinger
AU  - M. Duduta
AU  - H. Gloria
AU  - D. Clarke
AU  - R. Nagpal
AU  - R. Wood
PY  - 2018
KW  - autonomous underwater vehicles
KW  - biomimetics
KW  - control system synthesis
KW  - elastomers
KW  - electroactive polymer actuators
KW  - force control
KW  - mobile robots
KW  - motion control
KW  - remotely operated vehicles
KW  - velocity control
KW  - thrust force
KW  - actuation layers
KW  - fin-like dielectric elastomer actuator
KW  - DEA design
KW  - fish fins undulatory motions
KW  - tunable DEAs
KW  - soft actuators
KW  - autonomous planar swimming
KW  - actuator designs
KW  - swimming speed
KW  - vertical swimming
KW  - underwater operation
KW  - elastomers
KW  - autonomous mobility
KW  - AUV
KW  - miniature autonomous underwater vehicle
KW  - modular dielectric elastomer actuator
KW  - Aquatic robots
KW  - Power supplies
KW  - Propulsion
KW  - Dielectric elastomer actuators
DO  - 10.1109/ICRA.2018.8461217
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present the design of a fin-like dielectric elastomer actuator (DEA) that drives a miniature autonomous underwater vehicle (AUV). The fin-like actuator is modular and independent of the body of the AUV. All electronics required to run the actuator are inside the 100 mm long 3D-printed body, allowing for autonomous mobility of the AUV. The DEA is easy to manufacture, requires no pre-stretch of the elastomers, and is completely sealed for underwater operation. The output thrust force can be tuned by stacking multiple actuation layers and modifying the Young's modulus of the elastomers. The AUV is reconfigurable by a shift of its center of mass, such that both planar and vertical swimming can be demonstrated on a single vehicle. For the DEA we measured thrust force and swimming speed for various actuator designs ran at frequencies from 1 Hz to 5 Hz. For the AUV we demonstrated autonomous planar swimming and closed-loop vertical diving. The actuators capable of outputting the highest thrust forces can power the AUV to swim at speeds of up to 0.55 body lengths per second. The speed falls in the upper range of untethered swimming robots powered by soft actuators. Our tunable DEAs also demonstrate the potential to mimic the undulatory motions of fish fins.
ER  - 

TY  - CONF
TI  - Proprioceptive-Inertial Autonomous Locomotion for Articulated Robots
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3436
EP  - 3441
AU  - F. Ruscelli
AU  - G. Sartoretti
AU  - J. Nan
AU  - Z. Feng
AU  - M. Travers
AU  - H. Choset
PY  - 2018
KW  - collision avoidance
KW  - feedback
KW  - force control
KW  - legged locomotion
KW  - motion control
KW  - parallel controller
KW  - bi-stable dynamical system
KW  - snake robot
KW  - unevenly-spaced obstacles
KW  - proprioceptive controller
KW  - legged locomotion
KW  - hexaprint robot
KW  - proprioceptive-inertial autonomous locomotion
KW  - articulated robots
KW  - proprioception
KW  - vestibular feedback
KW  - gait
KW  - force sensing
KW  - force feedback
KW  - Shape
KW  - Robot sensing systems
KW  - Snake robots
KW  - Legged locomotion
KW  - Force feedback
KW  - Robot motion
DO  - 10.1109/ICRA.2018.8460584
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Inspired by the ability of animals to rely on proprioception and vestibular feedback to adapt their gait, we propose a modular framework for autonomous locomotion that relies on force sensing and inertial information. A first controller exploits anti-compliance, a new application of positive force feedback, to quickly react against obstacles upon impact. We hypothesize that, in situations where a robot experiences occasional impacts with the environment, anti-compliance can help negotiate unknown obstacles, similar to biological systems where positive feedback enables fast responses to external stimuli. A novel parallel controller, based on a bi-stable dynamical system, continuously adjusts the robot's direction of locomotion, and reverts it in reaction to major swerves. We present experimental results, demonstrating how our framework allows a snake robot to autonomously locomote through a row of unevenly-spaced obstacles. Finally, we extend our proprioceptive controller to legged locomotion, showing how a hexaprint robot can adapt its motion to climb over obstacles.
ER  - 

TY  - CONF
TI  - Autonomous Bio-Inspired Small-Object Detection and Avoidance
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3442
EP  - 3447
AU  - M. Ohradzansky
AU  - H. E. Alvarez
AU  - J. Keshavan
AU  - B. N. Ranganathan
AU  - J. S. Humbert
PY  - 2018
KW  - collision avoidance
KW  - Fourier analysis
KW  - helicopters
KW  - image sequences
KW  - mobile robots
KW  - navigation
KW  - object detection
KW  - robot vision
KW  - small-field motion-sensitive interneurons
KW  - insect visuomotor system
KW  - small-field object detection
KW  - artificial potential function-based low-order steering control law
KW  - small-field clutter
KW  - bio-inspired approach
KW  - autonomous robots
KW  - autonomous vehicles
KW  - bio-inspired navigation technique
KW  - Fourier residual analysis
KW  - instantaneous optic flow
KW  - Optical sensors
KW  - Optical imaging
KW  - Navigation
KW  - Biomedical optical imaging
KW  - Insects
KW  - Neurons
DO  - 10.1109/ICRA.2018.8461156
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Small-object detection and avoidance in unknown environments is a significant challenge to overcome for small autonomous vehicles that are generally highly agile and restricted in payload and computational processing power. Typical machine-vision and range measurement based solutions suffer either from restricted fields-of-view or significant computational complexity and are not easily portable to small platforms. In this paper, a novel bio-inspired navigation technique is introduced that is modeled using analogues of the small-field motion-sensitive interneurons of the insect visuomotor system. The proposed technique achieves small-field object detection based on Fourier residual analysis of instantaneous optic flow. The small field signal is used to extract relative range and bearing of the nearest obstacle, which is then combined with an artificial potential function-based low-order steering control law. The proposed sensing and control scheme is experimentally validated with a quadrotor vehicle that is able to effectively navigate an unknown environment laden with small-field clutter. This bio-inspired approach is computationally efficient and serves as a robust, reflexive solution to the problem of small-object detection and avoidance for autonomous robots.
ER  - 

TY  - CONF
TI  - PISRob: A Pneumatic Soft Robot for Locomoting Like an Inchworm
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3448
EP  - 3453
AU  - R. Xie
AU  - M. Su
AU  - Y. Zhang
AU  - M. Li
AU  - H. Zhu
AU  - Y. Guan
PY  - 2018
KW  - actuators
KW  - bending
KW  - mobile robots
KW  - pneumatic actuators
KW  - pneumatic systems
KW  - inchworm-like locomotion
KW  - PISRob
KW  - pneumatic soft robot
KW  - pneumatic actuation
KW  - pneumatic system
KW  - soft climbing robots
KW  - soft parts
KW  - system development
KW  - Legged locomotion
KW  - Soft robotics
KW  - Pneumatic systems
KW  - Strain
KW  - Fabrication
KW  - Glass
DO  - 10.1109/ICRA.2018.8461189
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Climbing or crawling robots may be widely applied in agriculture, forestry, military, construction industry, disaster searching and rescuing, and so on. Soft robots possess better safety, flexibility, dexterity, portability, and adaption to complex environments than traditional robots. However, there are big challenges in system development, modeling and control of soft climbing robots. To address system development of a soft robot as a new type climbing robot, we present a pneumatic soft robot capable of inchworm-like locomotion, PISRob. The presented robot is composed of three soft parts in H-shaped configuration. Each part is able to perform 2D bending. While the middle part, as the main body, can bend in Ω -shape for actuation, the two end parts as legs can conduct simple bending motion for grasping or anchoring during locomotion. The system design and fabrication process of the soft robot is presented in details in this paper. A control system is developed for pneumatic actuation of the robot. Tests are carried out to get the relationship between the actuating air pressure and the step length in locomotion. Experiments of crawling on a floor and climbing on a pole are performed to verify the feasibility of development of the new soft robot and the effectiveness of the control method for the pneumatic system.
ER  - 

TY  - CONF
TI  - Continuous Growth in Plant-Inspired Robots Through 3D Additive Manufacturing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3454
EP  - 3460
AU  - E. Del Dottore
AU  - A. Sadeghi
AU  - A. Mondini
AU  - B. Mazzolai
PY  - 2018
KW  - agriculture
KW  - bending
KW  - bio-inspired materials
KW  - position control
KW  - rapid prototyping (industrial)
KW  - robots
KW  - three-dimensional printing
KW  - three-term control
KW  - plant-inspired robots
KW  - 3D additive manufacturing
KW  - plant growth
KW  - 3D printer-like mechanism
KW  - tubular body
KW  - material deposition process
KW  - turning behavior
KW  - filament height
KW  - position PID control algorithm
KW  - homogeneous structures
KW  - robust structures
KW  - continuous growth
KW  - plotting velocity
KW  - bending
KW  - Magnetic heads
KW  - Force
KW  - Robot sensing systems
KW  - Soil
KW  - Wires
KW  - Fingers
DO  - 10.1109/ICRA.2018.8460616
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents a new material deposition strategy for developing a growing robot capable of building its own body. The growing robot is inspired by plant growth and is based on a 3D printer-like mechanism. The plotting of a filament near the tip allows the forward movement of the robot and results in building a tubular body. A material deposition process is introduced to perform a straight continuous growth as well as a turning behavior in order to permit the navigation of the robot in the environment. Bending is achieved by controlling the filament height in each position of the plotting, lowering or increasing plotting velocity with a position PID control algorithm. We demonstrate that the continuous deposition of the filament allows to obtain homogeneous and robust structures, with a significant improvement of the robot's performance compared to our previous version of the system (i.e., more than 100 N pulling force and 200 N shear force). The current version of the robot can sustain its weight, move efficiently by growing in the environment - both air and soil - and penetrate hard medium (up to 60kPa).
ER  - 

TY  - CONF
TI  - Investigation of Scaling Effect of Copper Microwire Based on in-Situ Nanorobotic Twisting Inside SEM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3461
EP  - 3466
AU  - H. Lu
AU  - F. Xue
AU  - W. Wan
AU  - Y. Shen
PY  - 2018
KW  - copper
KW  - deformation
KW  - fracture
KW  - manipulators
KW  - nanomechanics
KW  - nanostructured materials
KW  - plastic deformation
KW  - scanning electron microscopy
KW  - twinning
KW  - deformation intertwine
KW  - deformation twin
KW  - plastic deformation
KW  - assembly method
KW  - positioning method
KW  - scanning electron microscope
KW  - copper microwire in situ twisting test
KW  - micromaterial
KW  - scaling effects
KW  - nanomaterial
KW  - copper microwire sample fracture morphology
KW  - copper microwire specimen
KW  - degree-of-freedoms nanorobotic manipulator
KW  - nanorobotics manipulation system
KW  - copper microwire mechanical properties
KW  - scaling effect
KW  - microelectron mechanical systems
KW  - SEM
KW  - in-situ nanorobotic twisting
KW  - Cu
KW  - Copper
KW  - Scanning electron microscopy
KW  - Manipulators
KW  - Mechanical factors
KW  - Calibration
DO  - 10.1109/ICRA.2018.8460573
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Copper microwire is an essential metal widely used in micro-electron mechanical systems. Since micro/nano material usually demonstrates unique mechanical properties due to scaling effect, copper microwire mechanical properties need to be investigated for better adhibition. Herein, we propose a nanorobotics manipulation system for copper microwire insitu twisting test. Firstly, a system with six degree-of-freedoms (DOFs) nanorobotic manipulator integrated inside scanning electron microscope (SEM) is introduced. Secondly, a positioning and assembly method for copper microwire specimen are proposed to solve the mismatching problem. Finally, the copper microwire is twisted in-situ and its properties are investigated and analyzed. The copper microwire sample fracture morphology shows a severe plastic deformation and being along with the emergence of deformation twin and intertwine, which exhibit strong scaling effects. This system provides a new method for in-situ twisting test, which paves the way for mechanical characterization inside SEM and benefits the fundamental nanomaterial research immensely.
ER  - 

TY  - CONF
TI  - Optimisation of Trap Design for Vibratory Bowl Feeders
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3467
EP  - 3474
AU  - S. Mathiesen
AU  - L. CarØe SØrensen
AU  - D. Kraft
AU  - L. Ellekilde
PY  - 2018
KW  - assembling
KW  - Bayes methods
KW  - design engineering
KW  - optimisation
KW  - production engineering computing
KW  - prototypes
KW  - regression analysis
KW  - vibrations
KW  - trap design
KW  - vibratory bowl feeders
KW  - industrial part feeding
KW  - VBF design
KW  - optimal parameter
KW  - passive devices
KW  - dynamic simulation
KW  - modified Upper Confidence Bound
KW  - Bayesian optimisation
KW  - kernel density estimation
KW  - regression analysis
KW  - prototypes
KW  - assembling
KW  - Optimization
KW  - Bayes methods
KW  - Task analysis
KW  - Vibrations
KW  - Shape
KW  - Manuals
KW  - Robustness
DO  - 10.1109/ICRA.2018.8460767
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Vibratory bowl feeders (VBFs) are a widely used option for industrial part feeding, but their design is still largely manual. A subtask of VBF design is determining an optimal parameter set for the passive devices, called traps, which the VBF uses to ensure correct part orientation. This paper proposes a fast and robust strategy for optimising traps, which makes use of dynamic simulation to efficiently evaluate the performance of parameter sets. The optimisation strategy is based on Bayesian Optimisation and selects new parameter sets to evaluate, using a modified Upper Confidence Bound with regression by Kernel Density Estimation as function estimator. The optimisation is run for four different traps with an industrial part and the best parameter sets are tested for robustness in simulation. The traps are then combined to create two sequences performing orientation of the parts and the designs are prototyped and tested on a real VBF.
ER  - 

TY  - CONF
TI  - Teach-and-Replay of Mobile Robot with Particle Filter on Episode
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3475
EP  - 3481
AU  - R. Ueda
AU  - M. Kato
AU  - A. Saito
AU  - R. Okazaki
PY  - 2018
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - robust control
KW  - mobile robot
KW  - reinforcement learning method
KW  - task teaching
KW  - micromouse type robot
KW  - Teach-and-Replay
KW  - PFoE
KW  - particle filter on episode
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Education
KW  - Hidden Markov models
KW  - Mobile robots
KW  - Task analysis
DO  - 10.1109/ICRA.2018.8461235
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - A novel method for replaying behavior of a mobile robot from its memory of past experiences is presented in this paper. The method is a version of a particle filter on episode (PFoE), which applies a particle filter on the memory so as to efficiently find some similar situations with the current one. Though the original PFoE was proposed as a reinforcement learning method, we once removed the reward system from the original one so as to apply it to task teaching. In the experiment, we gave several kinds of motion to a micromouse type robot with the proposed method through a gamepad. The robot replayed the behaviors robustly with sensor feedback after several number of repetitive teaching.
ER  - 

TY  - CONF
TI  - Vision-Based Robotic Grasping and Manipulation of USB Wires
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3482
EP  - 3487
AU  - X. Li
AU  - X. Su
AU  - Y. Gao
AU  - Y. Liu
PY  - 2018
KW  - closed loop systems
KW  - grippers
KW  - industrial manipulators
KW  - Lyapunov methods
KW  - peripheral interfaces
KW  - robot vision
KW  - stability
KW  - USB cables
KW  - vision-based controller
KW  - wire alignment
KW  - USB color code
KW  - vision-based robotic grasping
KW  - USB wires
KW  - two-level structure
KW  - dynamic stability
KW  - closed-loop system
KW  - Lyapunov methods
KW  - Wires
KW  - Universal Serial Bus
KW  - Robots
KW  - Grasping
KW  - Grippers
KW  - Strain
KW  - Image color analysis
DO  - 10.1109/ICRA.2018.8460694
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The fast expanding 3C (Computer, Communication, and Consumer electronics) manufacturing leads to a high demand on the fabrication of USB cables. While several commercial machines have been developed to automate the process of stripping and soldering of USB cables, the operation of manipulating USB wires according to the color code is heavily dependent on manual works because of the deformation property of wires, probably resulting in the falling-off or the escape of wires during manipulation. In this paper, a new vision-based controller is proposed for robotic grasping and manipulation of USB wires. A novel two-level structure is developed and embedded into the controller, where Level-I is referred to as the grasping and manipulation of wires, and Level-II is referred to as the wire alignment by following the USB color code. The proposed formulation allows the robot to automatically grasp, manipulate, and align the wires in a sequential, simultaneous, and smooth manner, and hence to deal with the deformation of wires. The dynamic stability of the closed-loop system is rigorously proved with Lyapunov methods, and experiments are performed to validate the proposed controller.
ER  - 

TY  - CONF
TI  - Visual Grasping for a Lightweight Aerial Manipulator Based on NSGA-II and Kinematic Compensation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3488
EP  - 3493
AU  - L. Fang
AU  - H. Chen
AU  - Y. Lou
AU  - Y. Li
AU  - Y. Liu
PY  - 2018
KW  - autonomous aerial vehicles
KW  - calibration
KW  - collision avoidance
KW  - compensation
KW  - genetic algorithms
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - visual grasping
KW  - lightweight aerial manipulator
KW  - complex kinematics/dynamics
KW  - motion constraints
KW  - X8 coaxial octocopter
KW  - 4-DoF manipulator
KW  - grasping control problem
KW  - NSGA-II method
KW  - trajectory planning
KW  - kinematic compensation-based visual trajectory tracking
KW  - trajectory generation
KW  - dynamic parameter calibration
KW  - Manipulator dynamics
KW  - Trajectory
KW  - Grasping
KW  - Kinematics
KW  - Acceleration
KW  - Visualization
DO  - 10.1109/ICRA.2018.8460520
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The grasping control of an aerial manipulator in practical environments is challenging due to its complex kinematics/dynamics and motion constraints. This paper introduces a lightweight aerial manipulator, which is combined with an X8 coaxial octocopter and a 4-DoF manipulator. To address the grasping control problem, we develop an efficient scheme containing trajectory generation, visual trajectory tracking, and kinematic compensation. The NSGA-II method is utilized to implement the multiobjective optimization for trajectory planning. Motion constraints and collision avoidance are also considered in the optimization. A kinematic compensation-based visual trajectory tracking is introduced to address the coupled nature between manipulator and VAV body. No dynamic parameter calibration is needed. Finally, several experiments are performed to verify the stability and feasibility of the proposed approach.
ER  - 

TY  - CONF
TI  - Track, Then Decide: Category-Agnostic Vision-Based Multi-Object Tracking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3494
EP  - 3501
AU  - A. Ošep
AU  - W. Mehner
AU  - P. Voigtlaender
AU  - B. Leibe
PY  - 2018
KW  - computer vision
KW  - image colour analysis
KW  - image recognition
KW  - image segmentation
KW  - object detection
KW  - object tracking
KW  - object category
KW  - tracking-by-detection methods
KW  - segmentation mask-based tracker
KW  - pixel-precise masks
KW  - category-agnostic vision-based multiobject tracking
KW  - generic object proposals
KW  - class-agnostic multiobject tracking
KW  - Proposals
KW  - Three-dimensional displays
KW  - Tracking
KW  - Laser radar
KW  - Semantics
KW  - Detectors
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2018.8460975
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The most common paradigm for vision-based multi-object tracking is tracking-by-detection, due to the availability of reliable detectors for several important object categories such as cars and pedestrians. However, future mobile systems will need a capability to cope with rich human-made environments, in which obtaining detectors for every possible object category would be infeasible. In this paper, we address the problem of class-agnostic multi-object tracking using generic object proposals. We present an efficient segmentation mask-based tracker which associates pixel-precise masks reported by the segmentation. Our approach can utilize semantic information whenever it is available for classifying objects at the track level, while retaining the capability to track generic unknown objects in the absence of such information. We demonstrate experimentally that our approach achieves performance comparable to state-of-the-art tracking-by-detection methods for popular object categories such as cars and pedestrians. Additionally, we show that the proposed method can discover and robustly track a large variety of other objects.
ER  - 

TY  - CONF
TI  - Vision-Based Global Localization Using Ceiling Space Density
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3502
EP  - 3507
AU  - A. Ribacki
AU  - V. A. M. Jorge
AU  - M. Mantelli
AU  - R. Maffei
AU  - E. Prestes
PY  - 2018
KW  - cameras
KW  - mobile robots
KW  - robot vision
KW  - service robots
KW  - home environments
KW  - free space density
KW  - available blueprint information
KW  - ceiling vision
KW  - robust localization information
KW  - robotic vacuum
KW  - superior localization results
KW  - vision-based global localization
KW  - ceiling space density
KW  - service robots
KW  - homes
KW  - self-localize
KW  - man-made constructions
KW  - documented blueprint
KW  - robot localization
KW  - smart home applications
KW  - movable objects
KW  - complicated task
KW  - horizontal range-finders
KW  - effective global localization approach
KW  - Cameras
KW  - Kernel
KW  - Three-dimensional displays
KW  - Robot vision systems
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8460515
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Service robots are becoming a reality across homes. Still, the range of applications supported by such robots remains tied to their ability to self-localize in the environment. Man-made constructions often have a documented blueprint which can be used as input information for robot localization and smart home applications. However, home environments commonly include movable objects and furniture, which can make localization a complicated task, especially for forward-facing horizontal range-finders. In this paper, we present a new and effective global localization approach for home environments which adapts the notion of free space density to a camera pointing to the ceiling. We exploit the available blueprint information, as well as evidence that ceiling vision can provide robust localization information, even in the presence of occlusions. We perform real-world experiments using a robotic vacuum cleaner equipped with an upward-facing camera in two different apartments across multiple trajectories and compare the proposed method with competing approaches. Our solution shows superior localization results using maps where neither furniture or movable objects are not modeled.
ER  - 

TY  - CONF
TI  - Beyond Pixels: Leveraging Geometry and Shape Cues for Online Multi-Object Tracking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3508
EP  - 3515
AU  - S. Sharma
AU  - J. A. Ansari
AU  - J. Krishna Murthy
AU  - K. Madhava Krishna
PY  - 2018
KW  - cameras
KW  - image motion analysis
KW  - object detection
KW  - object tracking
KW  - optimisation
KW  - pose estimation
KW  - data association method
KW  - tracking-by-detection framework
KW  - object detectors
KW  - object motions
KW  - online multiobject tracking
KW  - object shape
KW  - monocular camera
KW  - object pose
KW  - object motion
KW  - Three-dimensional displays
KW  - Shape
KW  - Target tracking
KW  - Roads
KW  - Trajectory
KW  - Cameras
DO  - 10.1109/ICRA.2018.8461018
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper introduces geometry and object shape and pose costs for multi-object tracking in urban driving scenarios. Using images from a monocular camera alone, we devise pairwise costs for object tracks, based on several 3D cues such as object pose, shape, and motion. The proposed costs are agnostic to the data association method and can be incorporated into any optimization framework to output the pairwise data associations. These costs are easy to implement, can be computed in real-time, and complement each other to account for possible errors in a tracking-by-detection framework. We perform an extensive analysis of the designed costs and empirically demonstrate consistent improvement over the state-of-the-art under varying conditions that employ a range of object detectors, exhibit a variety in camera and object motions, and, more importantly, are not reliant on the choice of the association framework. We also show that, by using the simplest of associations frameworks (two-frame Hungarian assignment), we surpass the state-of-the-art in multi-object-tracking on road scenes. More qualitative and quantitative results can be found at https://junaidcs032.github.io/Geometry_ObjectShape_MOT/.
ER  - 

TY  - CONF
TI  - Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from Simulation
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3516
EP  - 3523
AU  - K. Fang
AU  - Y. Bai
AU  - S. Hinterstoisser
AU  - S. Savarese
AU  - M. Kalakrishnan
PY  - 2018
KW  - feature extraction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - robot vision
KW  - multitask domain adaptation
KW  - deep learning
KW  - successful grasping probability
KW  - transfer learning framework
KW  - domain-adversarial loss
KW  - candidate motor command
KW  - specified target object
KW  - instance segmentation mask
KW  - monocular RGB images
KW  - neural network
KW  - cluttered scenes
KW  - instance grasping
KW  - robotic manipulation
KW  - Grasping
KW  - Robots
KW  - Adaptation models
KW  - Data models
KW  - Feature extraction
KW  - Image segmentation
KW  - Neural networks
DO  - 10.1109/ICRA.2018.8461041
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.
ER  - 

TY  - CONF
TI  - Learning Robotic Assembly from CAD
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3524
EP  - 3531
AU  - G. Thomas
AU  - M. Chien
AU  - A. Tamar
AU  - J. A. Ojea
AU  - P. Abbeel
PY  - 2018
KW  - CAD
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - production engineering computing
KW  - robotic assembly
KW  - suboptimal control
KW  - autonomous robotic assembly
KW  - industrial assembly tasks
KW  - contact-rich manipulation skills
KW  - motion planning approaches
KW  - robot controllers
KW  - reinforcement learning
KW  - robot skills
KW  - contact-rich dynamics
KW  - control policy
KW  - robot executions
KW  - locally suboptimal solutions
KW  - RL performance
KW  - CAD design files
KW  - geometric motion plan
KW  - CAD data
KW  - assembly controller
KW  - manufacturing trends
KW  - Task analysis
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Tracking
KW  - Robotic assembly
KW  - Dynamics
DO  - 10.1109/ICRA.2018.8460696
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this work, motivated by recent manufacturing trends, we investigate autonomous robotic assembly. Industrial assembly tasks require contact-rich manipulation skills, which are challenging to acquire using classical control and motion planning approaches. Consequently, robot controllers for assembly domains are presently engineered to solve a particular task, and cannot easily handle variations in the product or environment. Reinforcement learning (RL) is a promising approach for autonomously acquiring robot skills that involve contact-rich dynamics. However, RL relies on random exploration for learning a control policy, which requires many robot executions, and often gets trapped in locally suboptimal solutions. Instead, we posit that prior knowledge, when available, can improve RL performance. We exploit the fact that in modern assembly domains, geometric information about the task is readily available via the CAD design files. We propose to leverage this prior knowledge by guiding RL along a geometric motion plan, calculated using the CAD data. We show that our approach effectively improves over traditional control approaches for tracking the motion plan, and can solve assembly tasks that require high precision, even without accurate state estimation. In addition, we propose a neural network architecture that can learn to track the motion plan, thereby generalizing the assembly controller to changes in the object positions.
ER  - 

TY  - CONF
TI  - Accurate and Adaptive in Situ Fabrication of an Undulated Wall Using an on-Board Visual Sensing System
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3532
EP  - 3539
AU  - M. Lussi
AU  - T. Sandy
AU  - K. Dörfler
AU  - N. Hack
AU  - F. Gramazio
AU  - M. Kohler
AU  - J. Buchli
PY  - 2018
KW  - buildings (structures)
KW  - CAD
KW  - geometry
KW  - mobile robots
KW  - reinforced concrete
KW  - robot vision
KW  - steel
KW  - structural engineering computing
KW  - walls
KW  - wires
KW  - in situ fabrication
KW  - visual sensing system
KW  - curved steel reinforced concrete wall
KW  - steel wire mesh
KW  - building construction
KW  - digital building process
KW  - CAD model
KW  - material deformations
KW  - geometry
KW  - mobile robot
KW  - vision-based sensing
KW  - load-bearing
KW  - building plan
KW  - Buildings
KW  - Robot sensing systems
KW  - Wires
KW  - Fabrication
KW  - Steel
DO  - 10.1109/ICRA.2018.8460480
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In this paper we present a system for the in situ33In the context of building construction, “in situ” means that fabrication takes place at the structure's final location directly on the building site. fabrication of a full-scale, load-bearing, and doubly-curved steel reinforced concrete wall. Two complementary vision-based sensing systems provide the feedback necessary to build a 12 meter long steel wire mesh as part of a novel digital building process. The sensing systems provide estimates of the robot pose, referenced to the CAD model of the building site, as well as feedback on the accuracy of the built structure over the course of construction. This second piece of information is used to adapt the building plan to compensate for system inaccuracies and material deformations which occur during buildup. In this way, the structure was successfully built with 98% of the total geometry within 2 centimeters of the designed position. To the best of our knowledge, this is the largest structure which has been built by a mobile robot using solely vision-based sensing.
ER  - 

TY  - CONF
TI  - Robot Assisted Carpentry for Mass Customization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3540
EP  - 3547
AU  - J. I. Lipton
AU  - A. Schulz
AU  - A. Spielberg
AU  - L. Trueba
AU  - W. Matusik
AU  - D. Rus
PY  - 2018
KW  - design engineering
KW  - furniture
KW  - mass production
KW  - mobile robots
KW  - product customisation
KW  - production engineering computing
KW  - mass customization
KW  - laymen editable templates
KW  - CNC fabrication
KW  - template based system
KW  - robotic fabrication system
KW  - mobile robots
KW  - standard carpentry tools
KW  - end-to-end design
KW  - template design
KW  - laymen users
KW  - robotics system
KW  - design tools
KW  - robot assisted carpentered items
KW  - Fabrication
KW  - Robots
KW  - Solid modeling
KW  - Tools
KW  - Standards
KW  - Face
KW  - Connectors
DO  - 10.1109/ICRA.2018.8460736
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Despite the ubiquity of carpentered items, the customization of carpentered items remains labor intensive. The generation of laymen editable templates for carpentry is difficult. Current design tools rely heavily on CNC fabrication, limiting applicability. We develop a template based system for carpentry and a robotic fabrication system using mobile robots and standard carpentry tools. Our end-to-end design and fabrication tool democratizes design and fabrication of carpentered items. Our method combines expert knowledge for template design, allows laymen users to customize and verify specific designs, and uses robotics system to fabricate parts. We validate our system using multiple designs to make customizable, verifiable templates and fabrication plans and show an end-to-end example that was designed, manufactured, and assembled using our tools.
ER  - 

TY  - CONF
TI  - A General and Flexible Search Framework for Disassembly Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3548
EP  - 3555
AU  - T. Ebinger
AU  - S. Kaden
AU  - S. Thomas
AU  - R. Andre
AU  - N. M. Amato
AU  - U. Thomas
PY  - 2018
KW  - assembly planning
KW  - design for disassembly
KW  - iterative methods
KW  - search problems
KW  - iterative motion planning
KW  - collision information
KW  - subassembly identification
KW  - preemptive scheme
KW  - exhaustive scheme
KW  - search strategies
KW  - hierarchical approach
KW  - disassembly sequence planning
KW  - parallelism
KW  - part separation techniques
KW  - Planning
KW  - Trajectory
KW  - Measurement
KW  - Data structures
KW  - Search problems
KW  - Learning systems
KW  - Containers
DO  - 10.1109/ICRA.2018.8460483
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We present a new general framework for disassembly sequence planning. This framework is versatile allowing different types of search schemes (exhaustive vs. preemptive), various part separation techniques, and the ability to group parts, or not, into subassemblies to improve the solution efficiency and parallelism. This enables a truly hierarchical approach to disassembly sequence planning. We demonstrate two different search strategies using this framework that can either yield a single solution quickly or provide a spectrum of solutions from which an optimal may be selected. We also develop a method for subassembly identification based on collision information. Our results show improved performance over an iterative motion planning based method for finding a single solution and greater functionality through hierarchical planning and optimal solution search.
ER  - 

TY  - CONF
TI  - 1-Actuator 3-DoF Manipulation Using a Virtual Turntable Based on Differential Friction Surface
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3573
EP  - 3580
AU  - K. Yamaguchi
AU  - M. Higashimori
PY  - 2018
KW  - actuators
KW  - dexterous manipulators
KW  - end effectors
KW  - friction
KW  - manipulator dynamics
KW  - motion control
KW  - plates (structures)
KW  - position control
KW  - flat plate
KW  - manipulator
KW  - active-passive hybrid joint mechanism
KW  - surface friction property
KW  - 3- DoF manipulation strategy
KW  - virtual turntable
KW  - 1-actuator 3-DoF manipulation
KW  - differential friction surface
KW  - nonprehensile manipulation
KW  - single actuator
KW  - manipulation strategy
KW  - Friction
KW  - Actuators
KW  - Orbits
KW  - Vibrations
KW  - End effectors
KW  - Frequency control
DO  - 10.1109/ICRA.2018.8460634
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper describes nonprehensile manipulation realized using the vibration of a plate. A novel manipulation strategy is proposed wherein the three degrees-of-freedom (DoF) of a part are controlled by only one actuator. First, a manipulator driven by a single actuator is introduced. The end effector of this manipulator is a flat plate. The manipulator employs an active-passive hybrid joint mechanism with nonparallel axes. Based on the sinusoidal displacement input to the actuator, the manipulator can generate the velocity of a part omnidirectionally on the plate. Next, simulation results are presented to show that the velocity map of the part varies depending upon the surface friction property of the plate. Further, the control of the rotational behavior of the part on the boundary of two areas with different friction properties by means of the input frequency is shown. Based on this control, a 3- DoF manipulation strategy using a virtual turntable is developed to realize the desired position and orientation of the part. Finally, the proposed method is demonstrated via experiments.
ER  - 

TY  - CONF
TI  - A Fish-Like Magnetically Propelled Microswimmer Fabricated by 3D Laser Lithography
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3581
EP  - 3586
AU  - P. Liao
AU  - J. Li
AU  - S. Zhang
AU  - D. Sun
PY  - 2018
KW  - bioMEMS
KW  - biomimetics
KW  - cell motility
KW  - hydrodynamics
KW  - laser materials processing
KW  - magnetic actuators
KW  - medical robotics
KW  - microfabrication
KW  - microorganisms
KW  - microrobots
KW  - nickel
KW  - permanent magnets
KW  - fish-like magnetically propelled microswimmer fabrication
KW  - glass substrate
KW  - detoxification tools
KW  - biosensing tools
KW  - fabricated microswimmers
KW  - permanent magnets
KW  - magnetic control system
KW  - external magnetic field
KW  - oscillating uniform magnetic field
KW  - magnetic actuation
KW  - caudal fin
KW  - 3D laser lithography
KW  - size 50.0 nm
KW  - Ni
KW  - Magnetic fields
KW  - Magnetic domains
KW  - Magnetic heads
KW  - Magnetic flux
KW  - Magnetic resonance imaging
KW  - Propulsion
DO  - 10.1109/ICRA.2018.8460522
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper presents the development of a fish-like magnetically propelled microswimmer fabricated by 3D laser lithography. The microswimmer consists of a head and a caudal fin, just like a natural fish. There is a joint between the head and the fin so that the caudal fin can oscillate around the head to generate thrust, and the oscillation of the fin hardly transfers to the head, which benefits the stable motion of the microswimmer. The caudal fin of the microswimmer is deposited with a layer of 50 nm nickel (Ni) for magnetic actuation. Through applying an oscillating uniform magnetic field, the microswimmer can move along with the direction guided by the external magnetic field. A magnetic control system with permanent magnets is designed to provide such an oscillating uniform magnetic field, where the oscillating frequency and amplitude are controllable. A micro probe operation platform is used to detach the fabricated microswimmers from glass substrate in manufacturing. The proposed magnetically propelled microswimmer can be potentially used as powerful detoxification and biosensing tools for medical diagnosis and treatment in precision medicine.
ER  - 

TY  - CONF
TI  - Liftoff of a 190 mg Laser-Powered Aerial Vehicle: The Lightest Wireless Robot to Fly
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3587
EP  - 3594
AU  - J. James
AU  - V. Iyer
AU  - Y. Chukewad
AU  - S. Gollakota
AU  - S. B. Fuller
PY  - 2018
KW  - aerospace robotics
KW  - autonomous aerial vehicles
KW  - avionics
KW  - electronics packaging
KW  - feedback
KW  - microcontrollers
KW  - microrobots
KW  - mobile robots
KW  - power convertors
KW  - robot dynamics
KW  - wire tethers
KW  - high-voltage power electronics
KW  - severely constrained weight budgets
KW  - wireless liftoff
KW  - fast-turnaround laser based circuit fabrication technique
KW  - onboard electronics
KW  - high voltage bias
KW  - drive signals
KW  - insect scale aerial robots
KW  - aerial vehicle
KW  - power electronics package
KW  - wireless robot
KW  - laser-powered aerial vehicle
KW  - microcontroller
KW  - feedback control
KW  - mass 190.0 mg
KW  - mass 104.0 mg
KW  - wavelength 976.0 nm
KW  - Actuators
KW  - Insects
KW  - Microcontrollers
KW  - High-voltage techniques
KW  - Capacitors
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2018.8460582
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - To date, insect scale aerial robots have required wire tethers for providing power due to the challenges of integrating the required high-voltage power electronics within their severely constrained weight budgets. In this paper we present a significant milestone in the achievement of flight autonomy: the first wireless liftoff of a 190 mg aerial vehicle. Our robot is remotely powered using a 976 nm laser and integrates a complete power electronics package weighing a total of 104 mg, using commercially available components and fabricated using a fast-turnaround laser based circuit fabrication technique. The onboard electronics include a lightweight boost converter capable of producing high voltage bias and drive signals of over 200 V at up to 170 Hz and regulated by a microcontroller performing feedback control. We present our system design and analysis, detailed description of our fabrication method, and results from flight experiments.
ER  - 

TY  - CONF
TI  - Soft Miniaturized Linear Actuators Wirelessly Powered by Rotating Permanent Magnets
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3595
EP  - 3600
AU  - T. Qiu
AU  - S. Palagi
AU  - J. Sachs
AU  - P. Fischer
PY  - 2018
KW  - magnetic actuators
KW  - magnetic fields
KW  - microactuators
KW  - permanent magnets
KW  - torque control
KW  - soft miniaturized linear actuators
KW  - wirelessly powered microactuators
KW  - magnet assembly
KW  - magnetic field generator
KW  - externally applied magnetic torque
KW  - soft miniaturized actuator
KW  - magnetic torques
KW  - untethered miniaturized devices
KW  - wireless actuation
KW  - rotating permanent magnets
KW  - Actuators
KW  - Magnetic fields
KW  - Magnetic resonance imaging
KW  - Permanent magnets
KW  - Magnetic moments
KW  - Torque
KW  - Magnetic flux
DO  - 10.1109/ICRA.2018.8461145
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Wireless actuation by magnetic fields allows for the operation of untethered miniaturized devices, e.g. in biomedical applications. Nevertheless, generating large controlled forces over relatively large distances is challenging. Magnetic torques are easier to generate and control, but they are not always suitable for the tasks at hand. Moreover, strong magnetic fields are required to generate a sufficient torque, which are difficult to achieve with electromagnets. Here, we demonstrate a soft miniaturized actuator that transforms an externally applied magnetic torque into a controlled linear force. We report the design, fabrication and characterization of both the actuator and the magnetic field generator. We show that the magnet assembly, which is based on a set of rotating permanent magnets, can generate strong controlled oscillating fields over a relatively large workspace. The actuator, which is 3D-printed, can lift a load of more than 40 times its weight. Finally, we show that the actuator can be further miniaturized, paving the way towards strong, wirelessly powered microactuators.
ER  - 

TY  - CONF
TI  - Eight-Degrees-of-Freedom Remote Actuation of Small Magnetic Mechanisms
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3608
EP  - 3613
AU  - S. Salmanipour
AU  - E. Diller
PY  - 2018
KW  - magnetic fields
KW  - medical robotics
KW  - microfluidics
KW  - microrobots
KW  - motion control
KW  - microscale devices
KW  - microrobotic devices
KW  - independent motions
KW  - magnetic elements
KW  - independent actuation
KW  - homogeneous magnetic field input
KW  - magnetic field signals
KW  - field generation source
KW  - magnetic microrobots
KW  - complex mechanism motions
KW  - multiagent mechanism motions
KW  - stationary devices
KW  - mobile devices
KW  - microfactories
KW  - microfluidic tools
KW  - medical procedures
KW  - remote applications
KW  - millimeter-scale robotic devices
KW  - magnetic mechanisms
KW  - degrees-of-freedom remote actuation
KW  - size 500.0 mum
KW  - size 0.6 mm
KW  - Magnetic resonance imaging
KW  - Magnetic devices
KW  - Magnetic moments
KW  - Torque
KW  - Mathematical model
KW  - Force
KW  - Wireless communication
DO  - 10.1109/ICRA.2018.8461026
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Magnetically-driven micrometer to millimeter-scale robotic devices have recently shown great capabilities for remote applications in medical procedures, in microfluidic tools and in microfactories. Significant effort recently has been on the creation of mobile or stationary devices with multiple independently-controllable degrees of freedom (DOF) for multiagent or complex mechanism motions. In most applications of magnetic microrobots, however, the relatively large distance from the field generation source and the microscale devices results in controlling magnetic field signals which are applied homogeneously over all agents. While some progress has been made in this area allowing up to six independent DOF to be individually commanded, there has been no rigorous effort in determining the maximum achievable number of DOF for systems with homogeneous magnetic field input. In this work, we show that this maximum is eight and we introduce the theoretical basis for this conclusion, relying on the number of independent usable components in a magnetic field at a point. In order to verify the claim experimentally, we develop a simple demonstration mechanism with 8 DOF designed specifically to show independent actuation. Using this mechanism with 500 μm magnetic elements, we demonstrate eight independent motions of 0.6 mm with 8.6 % coupling using an eight coil system. These results will enable the creation of richer outputs in future microrobotic devices.
ER  - 

TY  - CONF
TI  - Feature-Based SLAM for Imaging Sonar with Under-Constrained Landmarks
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3629
EP  - 3636
AU  - E. Westman
AU  - A. Hinduja
AU  - M. Kaess
PY  - 2018
KW  - feature extraction
KW  - image reconstruction
KW  - image sensors
KW  - reliability
KW  - SLAM (robots)
KW  - sonar imaging
KW  - sonar imaging
KW  - point landmark identification
KW  - feature-point extraction
KW  - general-purpose method
KW  - planar scene assumption
KW  - underwater feature-based SLAM
KW  - under-constrained landmarks
KW  - Feature extraction
KW  - Imaging
KW  - Sonar measurements
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Image reconstruction
DO  - 10.1109/ICRA.2018.8461004
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Recent algorithms have demonstrated the feasibility of underwater feature-based SLAM using imaging sonar. But previous methods have either relied on manual feature extraction and correspondence or used prior knowledge of the scene, such as the planar scene assumption. Our proposed system provides a general-purpose method for feature-point extraction and correspondence in arbitrary scenes. Additionally, we develop a method of identifying point landmarks that are likely to be well-constrained and reliably reconstructed. Finally, we demonstrate that while under-constrained landmarks cannot be accurately reconstructed themselves, they can still be used to constrain and correct the sensor motion. These advances represent a large step towards general-purpose, feature-based SLAM with imaging sonar.
ER  - 

TY  - CONF
TI  - SLAMBench2: Multi-Objective Head-to-Head Benchmarking for Visual SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3637
EP  - 3644
AU  - B. Bodin
AU  - H. Wagstaff
AU  - S. Saecdi
AU  - L. Nardi
AU  - E. Vespa
AU  - J. Mawer
AU  - A. Nisbet
AU  - M. Lujan
AU  - S. Furber
AU  - A. J. Davison
AU  - P. H. J. Kelly
AU  - M. F. P. O'Boyle
PY  - 2018
KW  - augmented reality
KW  - autonomous aerial vehicles
KW  - mobile computing
KW  - mobile robots
KW  - navigation
KW  - robot vision
KW  - SLAM (robots)
KW  - visual SLAM
KW  - augmented reality systems
KW  - nonfunctional requirements
KW  - mobile phone-based AR application
KW  - tight energy budget
KW  - UAV navigation system
KW  - SLAMBench2
KW  - benchmarking framework
KW  - open source
KW  - close source
KW  - performance metrics
KW  - ORB-SLAM2
KW  - publicly-available software framework
KW  - SLAM applications
KW  - SLAM systems
KW  - SLAM algorithms
KW  - multiobjective head-to-head benchmarking
KW  - functional requirements
KW  - Simultaneous localization and mapping
KW  - Measurement
KW  - Trajectory
KW  - Benchmark testing
KW  - User interfaces
KW  - C++ languages
DO  - 10.1109/ICRA.2018.8460558
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - SLAM is becoming a key component of robotics and augmented reality (AR) systems. While a large number of SLAM algorithms have been presented, there has been little effort to unify the interface of such algorithms, or to perform a holistic comparison of their capabilities. This is a problem since different SLAM applications can have different functional and non-functional requirements. For example, a mobile phone-based AR application has a tight energy budget, while a UAV navigation system usually requires high accuracy. SLAMBench2 is a benchmarking framework to evaluate existing and future SLAM systems, both open and close source, over an extensible list of datasets, while using a comparable and clearly specified list of performance metrics. A wide variety of existing SLAM algorithms and datasets is supported, e.g. ElasticFusion, InfiniTAM, ORB-SLAM2, OKVIS, and integrating new ones is straightforward and clearly specified by the framework. SLAMBench2 is a publicly-available software framework which represents a starting point for quantitative, comparable and val-idatable experimental research to investigate trade-offs across SLAM systems.
ER  - 

TY  - CONF
TI  - Don't Look Back: Robustifying Place Categorization for Viewpoint- and Condition-Invariant Place Recognition
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3645
EP  - 3652
AU  - S. Garg
AU  - N. Suenderhauf
AU  - M. Milford
PY  - 2018
KW  - cameras
KW  - feature extraction
KW  - image matching
KW  - image representation
KW  - image sequences
KW  - mobile robots
KW  - neural nets
KW  - object recognition
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - semantics-aware higher-order layers
KW  - deep neural networks
KW  - pure appearance-based techniques
KW  - place categorization
KW  - place-centric characteristics
KW  - condition-invariant place recognition
KW  - rear view mirror
KW  - semantic visual understanding
KW  - visual places
KW  - Semantics
KW  - Visualization
KW  - Robustness
KW  - Databases
KW  - Image recognition
KW  - Cameras
KW  - Neural networks
DO  - 10.1109/ICRA.2018.8461051
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - When a human drives a car along a road for the first time, they later recognize where they are on the return journey typically without needing to look in their rear view mirror or turn around to look back, despite significant viewpoint and appearance change. Such navigation capabilities are typically attributed to our semantic visual understanding of the environment [1] beyond geometry to recognizing the types of places we are passing through such as “passing a shop on the left” or “moving through a forested area”. Humans are in effect using place categorization [2] to perform specific place recognition even when the viewpoint is 180 degrees reversed. Recent advances in deep neural networks have enabled high performance semantic understanding of visual places and scenes, opening up the possibility of emulating what humans do. In this work, we develop a novel methodology for using the semantics-aware higher-order layers of deep neural networks for recognizing specific places from within a reference database. To further improve the robustness to appearance change, we develop a descriptor normalization scheme that builds on the success of normalization schemes for pure appearance-based techniques such as SeqSLAM [3]. Using two different datasets - one road-based, one pedestrian-based, we evaluate the performance of the system in performing place recognition on reverse traversals of a route with a limited field of view camera and no turn-back-and-Iook behaviours, and compare to existing state-of-the-art techniques and vanilla off-the-shelf features. The results demonstrate significant improvements over the existing state of the art, especially for extreme perceptual challenges that involve both great viewpoint change and environmental appearance change. We also provide experimental analyses of the contributions of the various system components: the use of spatio-temporal sequences, place categorization and place-centric characteristics as opposed to object-centric semantics.
ER  - 

TY  - CONF
TI  - Delight: An Efficient Descriptor for Global Localisation Using LiDAR Intensities
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3653
EP  - 3660
AU  - K. P. Cop
AU  - P. V. K. Borges
AU  - R. Dubé
PY  - 2018
KW  - mobile robots
KW  - navigation
KW  - optical information processing
KW  - optical radar
KW  - path planning
KW  - robot vision
KW  - intensity information
KW  - DELIGHT
KW  - distributed histograms
KW  - chi-squared tests
KW  - two-stage solution
KW  - geometry-based verification
KW  - range information
KW  - GPS-denied areas
KW  - robot position
KW  - kidnapped robot problems
KW  - mobile robotics
KW  - place recognition
KW  - global localisation
KW  - intensity-based prior estimation
KW  - LiDAR intensities
KW  - Laser radar
KW  - Histograms
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2018.8460940
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Place recognition is a key element of mobile robotics. It can assist with the “wake-up” and “kidnapped robot” problems, where the robot position needs to be estimated without prior information. Among the different sensors that can be used for the task (e.g., camera, GPS, LiDAR), LiDAR has the advantage of operating in the dark and in GPS-denied areas. We propose a new method that uses solely the LiDAR data and that can be performed without robot motion. In contrast to other methods, our system leverages intensity information (as opposed to only range information) which is encoded into a novel descriptor of LiDAR intensities as a group of histograms, named DELIGHT. The descriptor encodes the distributed histograms of intensity of the surroundings which are compared using chi-squared tests. Our pipeline is a two-stage solution consisting of an intensity-based prior estimation and a geometry-based verification. For a map of 220k square meters, the method achieves localisation in around 3s with a success rate of 97%, illustrating the applicability of the method in real environments.
ER  - 

TY  - CONF
TI  - Online Probabilistic Change Detection in Feature-Based Maps
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3661
EP  - 3668
AU  - F. Nobre
AU  - C. Heckman
AU  - P. Ozog
AU  - R. W. Wolcott
AU  - J. M. Walls
PY  - 2018
KW  - compressed sensing
KW  - feature extraction
KW  - image representation
KW  - object detection
KW  - probability
KW  - sensor fusion
KW  - terrain mapping
KW  - online data association decisions
KW  - online probabilistic change detection
KW  - sparse feature-based maps
KW  - compact representation
KW  - static map features
KW  - feature repeatability
KW  - probabilistically principled approach
KW  - sparse mapping model
KW  - Feature extraction
KW  - Simultaneous localization and mapping
KW  - Robustness
KW  - Heuristic algorithms
KW  - Probabilistic logic
KW  - Visualization
DO  - 10.1109/ICRA.2018.8461111
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Sparse feature-based maps provide a compact representation of the environment that admit efficient algorithms, for example simultaneous localization and mapping. These representations typically assume a static world and therefore contain static map features. However, since the world contains dynamic elements, determining when map features no longer correspond to the environment is essential for long-term utility. This work develops a feature-based model of the environment which evolves over time through feature persistence. Moreover, we augment the state-of-the-art sparse mapping model with a correlative structure that captures spatio-temporal properties, e.g. that nearby features frequently have similar persistence. We show that such relationships, typically addressed through an ad hoc formalism focusing only on feature repeatability, are crucial to evaluate through a probabilistically principled approach. The joint posterior over feature persistence can be computed efficiently and used to improve online data association decisions for localization. The proposed algorithms are validated in numerical simulation and using publicly available data sets.
ER  - 

TY  - CONF
TI  - The Dynamic Bearing Observability Matrix Nonlinear Observability and Estimation for Multi-Agent Systems
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3669
EP  - 3676
AU  - F. Schiano
AU  - R. Tron
PY  - 2018
KW  - geometry
KW  - group theory
KW  - Kalman filters
KW  - Lie groups
KW  - matrix algebra
KW  - multi-agent systems
KW  - multi-robot systems
KW  - nonlinear filters
KW  - multiagent formations
KW  - dynamic agents
KW  - algebraic properties
KW  - first-order derivatives
KW  - nonlinear observability theory
KW  - higher order derivatives
KW  - localization problem
KW  - dynamic bearing observability matrix nonlinear observability
KW  - multiagent systems
KW  - rigidity matrix
KW  - Observability
KW  - Robot sensing systems
KW  - Geometry
KW  - Manifolds
KW  - Cameras
KW  - Estimation
DO  - 10.1109/ICRA.2018.8460792
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We consider the problem of localization in multiagent formations with bearing only measurements, and analyze the fundamental observability properties for dynamic agents. The current well-established approach is based on the socalled rigidity matrix, and its algebraic properties (e.g., its rank and nullspace). This method is typically motivated using first-order derivatives, and shows, among other facts, that the global scale of the formation is not observable. This work shows that current results represent an incomplete view of the problem. In particular, we show that 1) current methods are a particular instantiation of nonlinear observability theory, 2) we can introduce the concept of the dynamic bearing observability matrix from higher order derivatives to study the observability of dynamic formations, and 3) the global scale is, in fact, generally observable when the agents move according to known inputs. We use tools from Riemannian geometry and Lie group theory to tackle, in a general and principled way, the general formulation of the localization problem with states that include both rotations and translations. Finally, we verify our theoretical results by deriving and applying, in both simulations and real experiments on UAVs, a centralized Extended Kalman Filter on Lie groups that is able to estimate the global scale of a moving formation.
ER  - 

TY  - CONF
TI  - CDDT: Fast Approximate 2D Ray Casting for Accelerated Localization
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3677
EP  - 3684
AU  - C. H. Walsh
AU  - S. Karaman
PY  - 2018
KW  - data structures
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - ray tracing
KW  - table lookup
KW  - constant time ray casting performance
KW  - particle filter algorithm
KW  - resource-constrained mobile robots
KW  - localization approach
KW  - approximate 2D ray casting
KW  - mobile robot
KW  - compressed directional distance transform
KW  - two dimensional occupancy grid maps
KW  - autonomous robots
KW  - three dimensional lookup table
KW  - frequency 40.0 Hz
KW  - Casting
KW  - Table lookup
KW  - Robot sensing systems
KW  - Transforms
KW  - Approximation algorithms
KW  - Memory management
KW  - Acceleration
DO  - 10.1109/ICRA.2018.8460743
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Localization is an essential component for autonomous robots. A well-established localization approach combines ray casting with a particle filter, leading to a computationally expensive algorithm that is difficult to run on resource-constrained mobile robots. We present a novel data structure called the Compressed Directional Distance Transform for accelerating ray casting in two dimensional occupancy grid maps. Our approach allows online map updates, and near constant time ray casting performance for a fixed size map, in contrast with other methods exhibit poor worst case performance. Our experimental results show that the proposed algorithm approximates the performance characteristics of reading from a three dimensional lookup table of ray cast solutions while requiring two orders of magnitude less memory and precomputation. This results in a particle filter algorithm which can maintain 2500 particles with 61 ray casts per particle at 40Hz, using a single CPU thread onboard a mobile robot.
ER  - 

TY  - CONF
TI  - Towards Globally Consistent Visual-Inertial Collaborative SLAM
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3685
EP  - 3692
AU  - M. Karrer
AU  - M. Chli
PY  - 2018
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - globally consistent tracking
KW  - autonomous robot navigation
KW  - monocular-inertial odometry
KW  - vision-based perception
KW  - metric scale estimation
KW  - benchmarking datasets
KW  - UAVs
KW  - monocular-inertial sensor suite
KW  - unmanned aerial vehicles
KW  - visual-inertial collaborative SLAM
KW  - drift correction
KW  - Simultaneous localization and mapping
KW  - Collaboration
KW  - Unmanned aerial vehicles
KW  - Optimization
KW  - Measurement
KW  - Trajectory
DO  - 10.1109/ICRA.2018.8461213
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - Motivated by the need for globally consistent tracking and mapping before autonomous robot navigation becomes realistically feasible, this paper presents a novel backend to monocular-inertial odometry. As some of the most challenging platforms for vision-based perception, we evaluate the performance of our system using Unmanned Aerial Vehicles (UAV s). Our experimental validation demonstrates that the proposed approach achieves drift correction and metric scale estimation from a single UAV on benchmarking datasets. Furthermore, the generality of our approach is demonstrated to achieve globally consistent maps built in a collaborative manner from two UAVs, each equipped with a monocular-inertial sensor suite, showing the possible gains opened by collaboration amongst robots to perform SLAM. Video - https://youtu.be/wbX36HBu2Eg.
ER  - 

TY  - CONF
TI  - Modelling Resource Contention in Multi-Robot Task Allocation Problems with Uncertain Timing
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3693
EP  - 3700
AU  - A. W. Palmer
AU  - A. J. Hill
AU  - S. J. Scheding
PY  - 2018
KW  - approximation theory
KW  - Monte Carlo methods
KW  - multi-robot systems
KW  - normal distribution
KW  - optimisation
KW  - probability
KW  - independent normally distributed random events
KW  - conditional probability distributions
KW  - multirobot task allocation problems
KW  - deterministic method
KW  - optimisation method
KW  - travel times
KW  - task durations
KW  - approximation methods
KW  - resource contention modelling
KW  - Robots
KW  - Task analysis
KW  - Uncertainty
KW  - Probability distribution
KW  - Random variables
KW  - Resource management
DO  - 10.1109/ICRA.2018.8460981
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper proposes an analytical framework for modelling resource contention in multi-robot systems, where the travel times and task durations are uncertain. It uses several approximation methods to quickly and accurately calculate the probability distributions describing the times at which the tasks start and finish. Specific contributions include exact and fast approximation methods for calculating the probability of a set of independent normally distributed random events occurring in a given order, a method for calculating the most likely and n-th most likely orders of occurrence for a set of independent normally distributed random events that have equal standard deviations, and a method for approximating the conditional probability distributions of the events given a specific order of the events. The complete framework is shown to be faster than a Monte Carlo approach for the same accuracy in two multi-robot task allocation problems. In addition, the importance of incorporating uncertainty is demonstrated through a comparison with a deterministic method. This is a general framework that is agnostic to the optimisation method and objective function used, and is applicable to a wide range of problems.
ER  - 

TY  - CONF
TI  - Constrained-Action POMDPs for Multi-Agent Intelligent Knowledge Distribution
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3701
EP  - 3708
AU  - M. Fowler
AU  - P. Tokekar
AU  - T. Charles Clancy
AU  - R. K. Williams
PY  - 2018
KW  - decision theory
KW  - intelligent control
KW  - Markov processes
KW  - Monte Carlo methods
KW  - multi-agent systems
KW  - multi-robot systems
KW  - optimal control
KW  - optimisation
KW  - multiagent intelligent knowledge distribution
KW  - infinite-horizon policy
KW  - minimal constraint guarantees
KW  - constraint analysis
KW  - information content
KW  - Markov chain Monte Carlo analysis
KW  - probabilistic constraint satisfaction
KW  - partially observable Markov decision processes
KW  - action-based constraints
KW  - multiagent coordination
KW  - multiagent systems
KW  - communication requirements
KW  - constrained-action POMDPs
KW  - Markov processes
KW  - Collaboration
KW  - Monte Carlo methods
KW  - Bandwidth
KW  - Proposals
KW  - Entropy
KW  - Power capacitors
DO  - 10.1109/ICRA.2018.8461118
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - This paper addresses a fundamental question of multi-agent knowledge distribution: what information should be sent to whom and when, with the limited resources available to each agent? Intelligent Knowledge Distribution is a framework that answers these questions. Communication requirements for multi-agent systems can be rather high when an accurate picture of the environment and the state of other agents must be maintained. To reduce the impact of multi-agent coordination on systems, including communications, this paper introduces the concept of action-based constraints on partially observable Markov decision processes, rewards based upon the value of information driven by Kullback-Leibler Divergence, and probabilistic constraint satisfaction through discrete optimization and Markov chain Monte Carlo analysis. Intelligent Knowledge Distribution is driven by determining the information content an agent believes another agent will obtain by receiving certain information, along with the importance or relevance of that information to the system objective. To perform constraint analysis on an infinite-horizon policy, policies are represented as a Finite State Controller allowing Markov chain Monte Carlo analysis to determine a probabilistic level of guarantee that the constraints will be satisfied. The analysis of performance for an example mission presented in this paper shows the constrained controllers, during the highest constraint seen in simulations, can be constructed to meet minimal constraint guarantees (80%) while impacting the optimal value less than 50%, where the unconstrained optimal controller only satisfied the constraint 10% of the time.
ER  - 

TY  - CONF
TI  - Incorporating Potential Contingency Tasks in Multi-Robot Mission Planning
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3709
EP  - 3715
AU  - S. Shriyam
AU  - S. K. Gupta
PY  - 2018
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - probability
KW  - potential contingency task
KW  - multirobot mission planning
KW  - expected mission completion time
KW  - probability
KW  - Task analysis
KW  - Robot kinematics
KW  - Uncertainty
KW  - Schedules
KW  - Marine vehicles
KW  - Resource management
DO  - 10.1109/ICRA.2018.8460659
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - In most complex missions, unexpected situations arise that may interfere with the planned execution of mission tasks. These situations result in the generation of contingency tasks that need to be executed before the originally planned tasks are completed. Potential contingency tasks may not always affect mission tasks due to the inherent uncertainty in the environment. Deferring action on a potential contingency task may incur a penalty in terms of wasted time due to idle robots if the contingency task becomes a bottleneck in the future. On the other hand, immediate action on a potential contingency task may incur a penalty in terms of wasted time if the contingency task did not actually impact the mission. When a contingency task is reported, the planner generates an updated plan that minimizes expected mission completion time by taking into account the probability of the contingency task impacting mission tasks, its effect on the mission, and its spatial location. We have characterized the performance of the algorithm through simulation experiments. We show that the proactive approach to contingency task management outperforms a conservative approach.
ER  - 

TY  - CONF
TI  - Distributed Simultaneous Action and Target Assignment for Multi-Robot Multi-Target Tracking
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3724
EP  - 3729
AU  - Y. Sung
AU  - A. K. Budhiraja
AU  - R. K. Williams
AU  - P. Tokekar
PY  - 2018
KW  - computational complexity
KW  - distributed control
KW  - multi-robot systems
KW  - target tracking
KW  - O(hlog1/ε) communication rounds
KW  - distributed simultaneous action
KW  - multirobot multitarget tracking
KW  - multirobot assignment problems
KW  - Robot sensing systems
KW  - Target tracking
KW  - Approximation algorithms
KW  - Partitioning algorithms
DO  - 10.1109/ICRA.2018.8460974
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - We study two multi-robot assignment problems for multi-target tracking. We consider distributed approaches in order to deal with limited sensing and communication ranges. We seek to simultaneously assign trajectories and targets to the robots. Our focus is on local algorithms that achieve performance close to the optimal algorithms with limited communication. We show how to use a local algorithm that guarantees a bounded approximate solution within O(hlog1/ε) communication rounds. We compare with a greedy approach that achieves a 2-approximation in as many rounds as the number of robots. Simulation results show that the local algorithm is an effective solution to the assignment problem.
ER  - 

TY  - CONF
TI  - How to Make Fat Autonomous Robots See all Others Fast?
T2  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 3730
EP  - 3735
AU  - G. Sharma
AU  - C. Busch
AU  - S. Mukhopadhyay
PY  - 2018
KW  - collision avoidance
KW  - computational complexity
KW  - deterministic algorithms
KW  - distributed algorithms
KW  - mobile robots
KW  - multi-robot systems
KW  - scheduling
KW  - fat autonomous robots
KW  - coordination problems
KW  - autonomous mobile robots
KW  - distributed robotics community
KW  - convex hull
KW  - nontransparent fat robots
KW  - deterministic distributed algorithm
KW  - semisynchronous scheduler
KW  - Robot kinematics
KW  - Fats
KW  - Cogeneration
KW  - Collision avoidance
KW  - Runtime
KW  - Computational modeling
DO  - 10.1109/ICRA.2018.8460899
JO  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2018 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 21-25 May 2018
AB  - The coordination problems arising in a team of autonomous mobile robots have received a lot of attention in the distributed robotics community. Along those lines, we study in this paper the problem of coordinating autonomous mobile robots to reposition on a convex hull so that each robot sees all others. In particular, we consider non-transparent fat robots operating in the 2-dimensional plane. They are abstracted as unit discs and they make local decisions with vision being the only mean of coordination among them. We develop a (deterministic) distributed algorithm that solves the problem for a team of N ≥ 3 fat robots in O(N) time avoiding collisions under the semi-synchronous scheduler. The main idea is to enforce the robots to reach a configuration in which (i) the robots' centers form a convex hull; (ii) all robots are on the convex hull's boundary; and (iii) each robot can see all other robots. The result is achieved assuming some reasonable conditions on the input configuration and showing that starting from any input configuration that satisfies our conditions, robots reach such a configuration in linear time and terminate.
ER  - 


