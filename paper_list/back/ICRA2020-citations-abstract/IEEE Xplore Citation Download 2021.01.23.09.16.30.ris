TY  - CONF
TI  - Learn-to-Recover: Retrofitting UAVs with Reinforcement Learning-Assisted Flight Control Under Cyber-Physical Attacks
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7358
EP  - 7364
AU  - F. Fei
AU  - Z. Tu
AU  - D. Xu
AU  - X. Deng
PY  - 2020
KW  - actuators
KW  - aerospace computing
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - fault diagnosis
KW  - fault tolerant control
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - position control
KW  - security of data
KW  - stability
KW  - fault-tolerant control policy
KW  - actuator
KW  - stabilizing controller
KW  - detection activation
KW  - sensor faults
KW  - position control
KW  - learn-to-recover
KW  - UAVs
KW  - reinforcement learning-assisted flight control
KW  - cyber-physical attacks
KW  - quadcopter unmanned aerial vehicles
KW  - sensor attack
KW  - Actuators
KW  - Fault tolerance
KW  - Fault tolerant systems
KW  - Vehicle dynamics
KW  - Learning (artificial intelligence)
KW  - Training
KW  - Solid modeling
DO  - 10.1109/ICRA40945.2020.9196611
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we present a generic fault-tolerant control (FTC) strategy via reinforcement learning (RL). We demonstrate the effectiveness of this method on quadcopter unmanned aerial vehicles (UAVs). The fault-tolerant control policy is trained to handle actuator and sensor fault/attack. Unlike traditional FTC, this policy does not require fault detection and diagnosis (FDD) nor tailoring the controller for specific attack scenarios. Instead, the policy is running simultaneously alongside the stabilizing controller without the need for on- detection activation. The effectiveness of the policy is compared with traditional active and passive FTC strategies against actuator and sensor faults. We compare their performance in position control tasks via simulation and experiments on quadcopters. The result shows that the strategy can effectively tolerate different types of attacks/faults and maintain the vehicle's position, outperforming the other two methods.
ER  - 

TY  - CONF
TI  - Towards the Probabilistic Fusion of Learned Priors into Standard Pipelines for 3D Reconstruction
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7373
EP  - 7379
AU  - T. Laidlow
AU  - J. Czarnowski
AU  - A. Nicastro
AU  - R. Clark
AU  - S. Leutenegger
PY  - 2020
KW  - geometry
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - probability
KW  - stereo image processing
KW  - probabilistic fusion
KW  - standard pipelines
KW  - deep learning
KW  - standard 3D reconstruction pipelines
KW  - open problem
KW  - deep neural network
KW  - error models
KW  - standard 3D reconstruction system
KW  - dense depth maps
KW  - discrete probability distributions
KW  - nonparametric probability distributions
KW  - multiview stereo approaches
KW  - geometry- based systems
KW  - learned single-view depth prior
KW  - Standards
KW  - Probability distribution
KW  - Fuses
KW  - Image reconstruction
KW  - Three-dimensional displays
KW  - Uncertainty
KW  - Probability density function
DO  - 10.1109/ICRA40945.2020.9197001
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The best way to combine the results of deep learning with standard 3D reconstruction pipelines remains an open problem. While systems that pass the output of traditional multi-view stereo approaches to a network for regularisation or refinement currently seem to get the best results, it may be preferable to treat deep neural networks as separate components whose results can be probabilistically fused into geometry- based systems. Unfortunately, the error models required to do this type of fusion are not well understood, with many different approaches being put forward. Recently, a few systems have achieved good results by having their networks predict probability distributions rather than single values. We propose using this approach to fuse a learned single-view depth prior into a standard 3D reconstruction system. Our system is capable of incrementally producing dense depth maps for a set of keyframes. We train a deep neural network to predict discrete, nonparametric probability distributions for the depth of each pixel from a single image. We then fuse this "probability volume" with another probability volume based on the photometric consistency between subsequent frames and the keyframe image. We argue that combining the probability volumes from these two sources will result in a volume that is better conditioned. To extract depth maps from the volume, we minimise a cost function that includes a regularisation term based on network predicted surface normals and occlusion boundaries. Through a series of experiments, we demonstrate that each of these components improves the overall performance of the system.
ER  - 

TY  - CONF
TI  - Model Reference Adaptive Control of Multirotor for Missions with Dynamic Change of Payloads During Flight
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7433
EP  - 7439
AU  - T. Maki
AU  - M. Zhao
AU  - F. Shi
AU  - K. Okada
AU  - M. Inaba
PY  - 2020
KW  - aerospace robotics
KW  - aircraft control
KW  - attitude control
KW  - helicopters
KW  - MIMO systems
KW  - model reference adaptive control systems
KW  - nonlinear control systems
KW  - robust control
KW  - stability
KW  - payloads
KW  - multirotor aerial robot
KW  - flight controller
KW  - flight stability
KW  - attitude control
KW  - aerial robot system
KW  - model reference adaptive control
KW  - nonlinear multiple-input and multiple-output
KW  - MRAC
KW  - Attitude control
KW  - Adaptation models
KW  - Payloads
KW  - MIMO communication
KW  - Unmanned aerial vehicles
KW  - Adaptive control
KW  - Gravity
DO  - 10.1109/ICRA40945.2020.9196861
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Carrying payloads in air is a major mission for multirotor aerial robot. However, the presence of payloads on multirotor aerial robot has a risk of degrading the performance of the flight controller. This concern becomes obvious especially when carrying objects not securely attached to the body or performing aerial manipulation. Therefore, controller with the ability to adapt itself to the effects of payloads on flight stability is needed. This paper proposes a novel nonlinear multiple-input and multiple-output (MIMO) model reference adaptive control (MRAC) system for attitude control of multirotor aerial robots which can dynamically compensate change in the position of center of gravity and inertia caused by payloads. Stability and robustness of the controller are experimentally confirmed in quadrotor and transformable multirotor, and experiments modeling practical applications are conducted for each aerial robot system, proving the utility of the controller.
ER  - 

TY  - CONF
TI  - The Tiercel: A novel autonomous micro aerial vehicle that can map the environment by flying into obstacles
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7448
EP  - 7454
AU  - Y. Mulgaonkar
AU  - W. Liu
AU  - D. Thakur
AU  - K. Daniilidis
AU  - C. J. Taylor
AU  - V. Kumar
PY  - 2020
KW  - cameras
KW  - collision avoidance
KW  - image sensors
KW  - mobile robots
KW  - navigation
KW  - robot vision
KW  - SLAM (robots)
KW  - space vehicles
KW  - autonomous microaerial vehicle
KW  - autonomous Tiercel robots
KW  - collision detector design
KW  - fisheye camera
KW  - reflective obstacles
KW  - transparent obstacles
KW  - collision-resilient robot
KW  - Tiercel MAV
KW  - autonomous navigation
KW  - autonomous flight
KW  - Collision avoidance
KW  - Cameras
KW  - Robot vision systems
KW  - Planning
DO  - 10.1109/ICRA40945.2020.9197269
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Autonomous flight through unknown environments in the presence of obstacles is a challenging problem for micro aerial vehicles (MAVs). A majority of the current state-of-art research assumes obstacles as opaque objects that can be easily sensed by optical sensors such as cameras or LiDARs. However in indoor environments with glass walls and windows, or scenarios with smoke and dust, robots (even birds) have a difficult time navigating through the unknown space.In this paper, we present the design of a new class of micro aerial vehicles that achieves autonomous navigation and are robust to collisions. In particular, we present the Tiercel MAV: a small, agile, light weight and collision-resilient robot powered by a cellphone grade CPU. Our design exploits contact to infer the presence of transparent or reflective obstacles like glass walls, integrating touch with visual perception for SLAM. The Tiercel is able to localize using visual-inertial odometry (VIO) running on board the robot with a single downward facing fisheye camera and an IMU. We show how our collision detector design and experimental set up enable us to characterize the impact of collisions on VIO. We further develop a planning strategy to enable the Tiercel to fly autonomously in an unknown space, sustaining collisions and creating a 2D map of the environment. Finally we demonstrate a swarm of three autonomous Tiercel robots safely navigating and colliding through an obstacle field to reach their objectives.
ER  - 

TY  - CONF
TI  - Adaptive Control of Variable-Pitch Propellers: Pursuing Minimum-Effort Operation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7470
EP  - 7476
AU  - T. Henderson
AU  - N. Papanikolopoulos
PY  - 2020
KW  - adaptive control
KW  - aerospace propulsion
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - electric propulsion
KW  - pitch control (position)
KW  - propellers
KW  - state-space methods
KW  - adaptive control
KW  - minimum-effort operation
KW  - unmanned aerial vehicles
KW  - UAV
KW  - electric propulsion systems
KW  - disparate flight modes
KW  - forward-moving flight
KW  - flight mode dissimilarity
KW  - fixed-geometry propulsion systems
KW  - variable-geometry systems
KW  - variable pitch propeller
KW  - propulsion performance
KW  - VPP system control
KW  - operation state space
KW  - hovering
KW  - near-minimum-electrical-effort propulsion system behavior
KW  - Propellers
KW  - Mathematical model
KW  - Servomotors
KW  - Geometry
KW  - Brushless DC motors
KW  - Blades
DO  - 10.1109/ICRA40945.2020.9197208
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - As Unmanned Aerial Vehicles (UAVs) become more commonly used in industry, their performance will continue to be challenged. A performance bottleneck that is crucial to overcome is the design of electric propulsion systems for UAVs that operate in disparate flight modes (e.g., hovering and forward-moving flight). While flight mode dissimilarity presents a fundamental design challenge for fixed-geometry propulsion systems, variable-geometry systems such as the Variable Pitch Propeller (VPP) ones are able to provide superior propulsion performance across a wide range of flight modes. This work builds on previous work by the authors and presents a VPP system control and estimation framework for safe, near-minimum-electrical-effort propulsion system behavior across the whole operation state space of any UAV. Multiple simulated validations are presented to support the feasibility of the approach.
ER  - 

TY  - CONF
TI  - On Simple Reactive Neural Networks for Behaviour-Based Reinforcement Learning
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7477
EP  - 7483
AU  - A. Pore
AU  - G. Aragon-Camarasa
PY  - 2020
KW  - grippers
KW  - learning (artificial intelligence)
KW  - neural net architecture
KW  - neurocontrollers
KW  - reactive neural networks
KW  - fully connected networks
KW  - reactive behaviours
KW  - actor-critic architecture
KW  - robot environment
KW  - end-to-end reinforcement learning
KW  - robotic learning
KW  - pick and place task
KW  - behaviour-based reinforcement learning
KW  - Brook subsumption architecture
KW  - pick and place robotic task
KW  - actor-critic policy
KW  - activation mechanisms
KW  - inhibition mechanisms
KW  - gripper
KW  - degree-of-freedom
KW  - Robots
KW  - Task analysis
KW  - Training
KW  - Computer architecture
KW  - Learning (artificial intelligence)
KW  - Grasping
KW  - Feature extraction
DO  - 10.1109/ICRA40945.2020.9197262
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present a behaviour-based reinforcement learning approach, inspired by Brook's subsumption architecture, in which simple fully connected networks are trained as reactive behaviours. Our working assumption is that a pick and place robotic task can be simplified by leveraging domain knowledge of a robotics developer to decompose and train reactive behaviours; namely, approach, grasp, and retract. Then the robot autonomously learns how to combine reactive behaviours via an Actor-Critic architecture. We use an Actor-Critic policy to determine the activation and inhibition mechanisms of the reactive behaviours in a particular temporal sequence. We validate our approach in a simulated robot environment where the task is about picking a block and taking it to a target position while orienting the gripper from a top grasp. The latter represents an extra degree-of-freedom of which current end-to-end reinforcement learning approaches fail to generalise. Our findings suggest that robotic learning can be more effective if each behaviour is learnt in isolation and then combined them to accomplish the task. That is, our approach learns the pick and place task in 8,000 episodes, which represents a drastic reduction in the number of training episodes required by an end-to-end approach ( 95,000 episodes) and existing state-of-the-art algorithms.
ER  - 

TY  - CONF
TI  - Predicting optimal value functions by interpolating reward functions in scalarized multi-objective reinforcement learning
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7484
EP  - 7490
AU  - A. Kusari
AU  - J. P. How
PY  - 2020
KW  - Gaussian processes
KW  - interpolation
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - smooth interpolation
KW  - reward function weights
KW  - optimal value function
KW  - multiobjective reinforcement learning problems
KW  - Gaussian process
KW  - value function transforms
KW  - MORL problems
KW  - Interpolation
KW  - Training
KW  - Learning (artificial intelligence)
KW  - Gaussian processes
KW  - Mathematical model
KW  - Random variables
KW  - Optimization
DO  - 10.1109/ICRA40945.2020.9197456
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - A common approach for defining a reward function for multi-objective reinforcement learning (MORL) problems is the weighted sum of the multiple objectives. The weights are then treated as design parameters dependent on the expertise (and preference) of the person performing the learning, with the typical result that a new solution is required for any change in these settings. This paper investigates the relationship between the reward function and the optimal value function for MORL; specifically addressing the question of how to approximate the optimal value function well beyond the set of weights for which the optimization problem was actually solved, thereby avoiding the need to recompute for any particular choice. We prove that the value function transforms smoothly given a transformation of weights of the reward function (and thus a smooth interpolation in the policy space). A Gaussian process is used to obtain a smooth interpolation over the reward function weights of the optimal value function for three well-known examples: Gridworld, Objectworld and Pendulum. The results show that the interpolation can provide robust values for sample states and actions in both discrete and continuous domain problems. Significant advantages arise from utilizing this interpolation technique in the domain of autonomous vehicles: easy, instant adaptation of user preferences while driving and true randomization of obstacle vehicle behavior preferences during training.
ER  - 

TY  - CONF
TI  - Integrated moment-based LGMD and deep reinforcement learning for UAV obstacle avoidance
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7491
EP  - 7497
AU  - L. He
AU  - N. Aouf
AU  - J. F. Whidborne
AU  - B. Song
PY  - 2020
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - control engineering computing
KW  - image motion analysis
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - visual perception
KW  - deep reinforcement learning
KW  - UAV obstacle avoidance
KW  - learning-based reaction local planner
KW  - microUAVs
KW  - image moment
KW  - illuminance variation
KW  - mapless navigation
KW  - moment-based LGMD
KW  - bioinspired monocular vision perception method
KW  - Navigation
KW  - Collision avoidance
KW  - Robustness
KW  - Lighting
KW  - Robots
KW  - Optical imaging
KW  - Machine learning
DO  - 10.1109/ICRA40945.2020.9197152
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, a bio-inspired monocular vision perception method combined with a learning-based reaction local planner for obstacle avoidance of micro UAVs is presented. The system is more computationally efficient than other vision-based perception and navigation methods such as SLAM and optical flow because it does not need to calculate accurate distances. To improve the robustness of perception against illuminance change, the input image is remapped using image moment which is independent of illuminance variation. After perception, a local planner is trained using deep reinforcement learning for mapless navigation. The proposed perception and navigation methods are evaluated in some realistic simulation environments. The result shows that this light-weight monocular perception and navigation system works well in different complex environments without accurate depth information.
ER  - 

TY  - CONF
TI  - Interactive Reinforcement Learning with Inaccurate Feedback
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7498
EP  - 7504
AU  - T. A. Kessler Faulkner
AU  - E. Schaertl Short
AU  - A. L. Thomaz
PY  - 2020
KW  - feedback
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - interactive reinforcement learning
KW  - human teachers
KW  - sensor feedback
KW  - learning process
KW  - noninteractive RL
KW  - policy feedback
KW  - feedback source
KW  - interactive RL methods
KW  - revision estimation-from-partially incorrect resources
KW  - REPaIR
KW  - physical robot
KW  - Maintenance engineering
KW  - Robot sensing systems
KW  - Estimation
KW  - Task analysis
KW  - Learning (artificial intelligence)
KW  - Computer science
DO  - 10.1109/ICRA40945.2020.9197219
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Interactive Reinforcement Learning (RL) enables agents to learn from two sources: rewards taken from observations of the environment, and feedback or advice from a secondary critic source, such as human teachers or sensor feedback. The addition of information from a critic during the learning process allows the agents to learn more quickly than non-interactive RL. There are many methods that allow policy feedback or advice to be combined with RL. However, critics can often give imperfect information. In this work, we introduce a framework for characterizing Interactive RL methods with imperfect teachers and propose an algorithm, Revision Estimation from Partially Incorrect Resources (REPaIR), which can estimate corrections to imperfect feedback over time. We run experiments both in simulations and demonstrate performance on a physical robot, and find that when baseline algorithms do not have prior information on the exact quality of a feedback source, using REPaIR matches or improves the expected performance of these algorithms.
ER  - 

TY  - CONF
TI  - Guided Uncertainty-Aware Policy Optimization: Combining Learning and Model-Based Strategies for Sample-Efficient Policy Learning
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7505
EP  - 7512
AU  - M. A. Lee
AU  - C. Florensa
AU  - J. Tremblay
AU  - N. Ratliff
AU  - A. Garg
AU  - F. Ramos
AU  - D. Fox
PY  - 2020
KW  - learning systems
KW  - optimisation
KW  - robots
KW  - guided uncertainty-aware policy optimization
KW  - sample-efficient policy learning
KW  - robust perception system
KW  - reinforcement learning
KW  - model-based methods
KW  - learning-based methods
KW  - model-based strategies
KW  - peg insertion
KW  - GUAPO
KW  - model-based policy
KW  - Task analysis
KW  - Uncertainty
KW  - Robot sensing systems
KW  - Learning (artificial intelligence)
KW  - Cameras
KW  - Switches
DO  - 10.1109/ICRA40945.2020.9197125
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Traditional robotic approaches rely on an accurate model of the environment, a detailed description of how to perform the task, and a robust perception system to keep track of the current state. On the other hand, reinforcement learning approaches can operate directly from raw sensory inputs with only a reward signal to describe the task, but are extremely sampleinefficient and brittle. In this work, we combine the strengths of model-based methods with the flexibility of learning-based methods to obtain a general method that is able to overcome inaccuracies in the robotics perception/actuation pipeline, while requiring minimal interactions with the environment. This is achieved by leveraging uncertainty estimates to divide the space in regions where the given model-based policy is reliable, and regions where it may have flaws or not be well defined. In these uncertain regions, we show that a locally learned-policy can be used directly with raw sensory inputs. We test our algorithm, Guided Uncertainty-Aware Policy Optimization (GUAPO), on a real-world robot performing peg insertion. Videos are available at: https://sites.google.com/view/guapo-rl.
ER  - 

TY  - CONF
TI  - Benchmark for Skill Learning from Demonstration: Impact of User Experience, Task Complexity, and Start Configuration on Performance
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7561
EP  - 7567
AU  - M. A. Rana
AU  - D. Chen
AU  - J. Williams
AU  - V. Chu
AU  - S. R. Ahmadzadeh
AU  - S. Chernova
PY  - 2020
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - user experience
KW  - task reproductions
KW  - demonstration approaches
KW  - multiple motion-based learning
KW  - task complexity
KW  - user experience
KW  - skill learning
KW  - robot executions
KW  - task performance
KW  - starting configuration
KW  - human demonstrator
KW  - physical robot
KW  - task models
KW  - manipulation tasks
KW  - real-world tasks
KW  - relative strengths
KW  - Task analysis
KW  - Robots
KW  - Trajectory
KW  - Videos
KW  - Pressing
KW  - Benchmark testing
KW  - Complexity theory
DO  - 10.1109/ICRA40945.2020.9197470
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We contribute a study benchmarking the performance of multiple motion-based learning from demonstration approaches. Given the number and diversity of existing methods, it is critical that comprehensive empirical studies be performed comparing the relative strengths of these techniques. In particular, we evaluate four approaches based on properties an end user may desire for real-world tasks. To perform this evaluation, we collected data from nine participants, across four manipulation tasks. The resulting demonstrations were used to train 180 task models and evaluated on 720 task reproductions on a physical robot. Our results detail how i) complexity of the task, ii) the expertise of the human demonstrator, and iii) the starting configuration of the robot affect task performance. The collected dataset of demonstrations, robot executions, and evaluations are publicly available. Research insights and guidelines are also provided to guide future research and deployment choices about these approaches.
ER  - 

TY  - CONF
TI  - Robot Programming without Coding
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7576
EP  - 7582
AU  - G. Lentini
AU  - G. Grioli
AU  - M. G. Catalano
AU  - A. Bicchi
PY  - 2020
KW  - control engineering computing
KW  - end effectors
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - teaching
KW  - telerobotics
KW  - robot programming
KW  - wearable consumer devices
KW  - programming tools
KW  - robot teleoperation
KW  - salient features
KW  - off-the-shelf soft-articulated robotic components
KW  - Dynamic Movement Primitives
KW  - human trajectories
KW  - impedance regulation skills
KW  - 7-DOF collaborative robots
KW  - anthropomorphic end-effectors
KW  - robot teaching
KW  - Robots
KW  - Task analysis
KW  - Education
KW  - Trajectory
KW  - Programming
KW  - Three-dimensional displays
KW  - Impedance
DO  - 10.1109/ICRA40945.2020.9196904
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - An approach toward intuitive and easy robot programming, consists to transfer skills from humans to machines, through demonstration. A vast literature exists on learning from multiple demonstrations. This paper, on the other hand, tackles the problem of providing all needed information to execute a certain task by resorting to one single demonstration - hence, a problem closer to programming than to learning. We use wearable consumer devices - but no keyboard nor coding - as programming tools, to let the programmer tele-operate the robot, which in turn records the most salient features and affordances from the object, environment, robot, and human. To enable this goal we combine off-the-shelf soft-articulated robotic components with the framework of Dynamic Movement Primitives, which we contribute to extend to generalize human trajectories and impedance regulation skills. This framework enables to teach robot quickly and in a intuitive way without coding. Experimental tests have been performed on a dual-arm system composed by two 7-dofs collaborative robots equipped with anthropomorphic end-effectors. Experiments show the functionality of the framework and verify the effectiveness of the impedance extension.
ER  - 

TY  - CONF
TI  - Predictive Modeling of Periodic Behavior for Human-Robot Symbiotic Walking
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7599
EP  - 7605
AU  - G. Clark
AU  - J. Campbell
AU  - S. M. Rezayat Sorkhabadi
AU  - W. Zhang
AU  - H. B. Amor
PY  - 2020
KW  - biomechanics
KW  - gait analysis
KW  - humanoid robots
KW  - human-robot interaction
KW  - intelligent robots
KW  - learning systems
KW  - man-machine systems
KW  - medical robotics
KW  - prosthetics
KW  - human-robot symbiotic walking
KW  - probabilistic framework
KW  - periodic behavior
KW  - periodic movement regimes
KW  - customized models
KW  - human walking
KW  - latent variables
KW  - biomechanical variables
KW  - robotic prosthesis
KW  - imitation learning approach
KW  - human participants
KW  - ankle angle control signals
KW  - robotic prosthetic ankle
KW  - predictive modeling
KW  - Periodic Interaction Primitives
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Biomechanics
KW  - Predictive models
KW  - Prosthetics
KW  - Probabilistic logic
DO  - 10.1109/ICRA40945.2020.9196676
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We propose in this paper Periodic Interaction Primitives - a probabilistic framework that can be used to learn compact models of periodic behavior. Our approach extends existing formulations of Interaction Primitives to periodic movement regimes, i.e., walking. We show that this model is particularly well-suited for learning data-driven, customized models of human walking, which can then be used for generating predictions over future states or for inferring latent, biomechanical variables. We also demonstrate how the same framework can be used to learn controllers for a robotic prosthesis using an imitation learning approach. Results in experiments with human participants indicate that Periodic Interaction Primitives efficiently generate predictions and ankle angle control signals for a robotic prosthetic ankle, with MAE of 2.21° in 0.0008s per inference. Performance degrades gracefully in the presence of noise or sensor fall outs. Compared to alternatives, this algorithm functions 20 times faster and performed 4.5 times more accurately on test subjects.
ER  - 

TY  - CONF
TI  - Agile 3D-Navigation of a Helical Magnetic Swimmer
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7638
EP  - 7644
AU  - J. Leclerc
AU  - H. Zhao
AU  - D. Z. Bao
AU  - A. T. Becker
AU  - M. Ghosn
AU  - D. J. Shah
PY  - 2020
KW  - biomechanics
KW  - blood
KW  - blood vessels
KW  - cardiology
KW  - haemodynamics
KW  - patient diagnosis
KW  - complex 3D trajectory
KW  - blood-mimicking solution
KW  - millimeter-scale magnetic helical swimmer navigating
KW  - cardiac structures
KW  - blood vessels
KW  - blood flow
KW  - respiratory motions
KW  - pulmonary embolus
KW  - rotational movement
KW  - magnetic swimmers
KW  - helical magnetic swimmer
KW  - agile 3D-navigation
KW  - Navigation
KW  - Trajectory
KW  - Heart
KW  - Blood
KW  - Valves
KW  - Frequency measurement
KW  - Turning
DO  - 10.1109/ICRA40945.2020.9197323
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Rotating miniature magnetic swimmers are de-vices that could navigate within the bloodstream to access remote locations of the body and perform minimally invasive procedures. The rotational movement could be used, for example, to abrade a pulmonary embolus. Some regions, such as the heart, are challenging to navigate. Cardiac and respiratory motions of the heart combined with a fast and variable blood flow necessitate a highly agile swimmer. This swimmer should minimize contact with the walls of the blood vessels and the cardiac structures to mitigate the risk of complications. This paper presents experimental tests of a millimeter-scale magnetic helical swimmer navigating in a blood-mimicking solution and describes its turning capabilities. The step-out frequency and the position error were measured for different values of turn radius. The paper also introduces rapid movements that increase the swimmer's agility and demonstrates these experimentally on a complex 3D trajectory.
ER  - 

TY  - CONF
TI  - Inferring the Geometric Nullspace of Robot Skills from Human Demonstrations
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7668
EP  - 7675
AU  - C. Cai
AU  - Y. S. Liang
AU  - N. Somani
AU  - W. Yan
PY  - 2020
KW  - geometry
KW  - humanoid robots
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - geometric nullspace
KW  - robot skills
KW  - human demonstrations
KW  - fit geometric nullspaces
KW  - geometric constraints
KW  - powerful mathematical model
KW  - geometric skill description
KW  - skill model
KW  - learnt skill
KW  - simulated industrial robot
KW  - iCub humanoid robot
KW  - geometric constraint models
KW  - Task analysis
KW  - Manifolds
KW  - Adaptation models
KW  - Service robots
KW  - Grasping
KW  - Data models
DO  - 10.1109/ICRA40945.2020.9197174
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper we present a framework to learn skills from human demonstrations in the form of geometric nullspaces, which can be executed using a robot. We collect data of human demonstrations, fit geometric nullspaces to them, and also infer their corresponding geometric constraint models. These geometric constraints provide a powerful mathematical model as well as an intuitive representation of the skill in terms of the involved objects. To execute the skill using a robot, we combine this geometric skill description with the robot's kinematics and other environmental constraints, from which poses can be sampled for the robot's execution. The result of our framework is a system that takes the human demonstrations as input, learns the underlying skill model, and executes the learnt skill with different robots in different dynamic environments. We evaluate our approach on a simulated industrial robot, and execute the final task on the iCub humanoid robot.
ER  - 

TY  - CONF
TI  - A Dynamical System Approach for Adaptive Grasping, Navigation and Co-Manipulation with Humanoid Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7676
EP  - 7682
AU  - N. Figueroa
AU  - S. Faraji
AU  - M. Koptev
AU  - A. Billard
PY  - 2020
KW  - compliance control
KW  - dexterous manipulators
KW  - humanoid robots
KW  - position control
KW  - dynamical system approach
KW  - adaptive grasping
KW  - humanoid robots
KW  - iCub humanoid robot
KW  - state-dependent dynamical systems
KW  - robots hands
KW  - intermediate virtual object
KW  - motion generators
KW  - object moves
KW  - whole-body compliant control strategy
KW  - manipulation tasks
KW  - body manipulation
KW  - iCub robots walk-to-grasp objects
KW  - Robot kinematics
KW  - Legged locomotion
KW  - Grasping
KW  - Task analysis
KW  - Humanoid robots
KW  - Planning
DO  - 10.1109/ICRA40945.2020.9197038
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present an integrated approach that provides compliant control of an iCub humanoid robot and adaptive reaching, grasping, navigating and co-manipulating capabilities. We use state-dependent dynamical systems (DS) to (i) coordinate and drive the robots hands (in both position and orientation) to grasp an object using an intermediate virtual object, and (ii) drive the robot's base while walking/navigating. The use of DS as motion generators allows us to adapt smoothly as the object moves and to re-plan on-line motion of the arms and body to reach the object's new location. The desired motion generated by the DS are used in combination with a whole-body compliant control strategy that absorbs perturbations while walking and offers compliant behaviors for grasping and manipulation tasks. Further, the desired dynamics for the arm and body can be learned from demonstrations. By integrating these components, we achieve unprecedented adaptive behaviors for whole body manipulation. We showcase this in simulations and real-world experiments where iCub robots (i) walk-to-grasp objects, (ii) follow a human (or another iCub) through interaction and (iii) learn to navigate or comanipulate an object from human guided demonstrations; whilst being robust to changing targets and perturbations.
ER  - 

TY  - CONF
TI  - Subspace Projectors for State-Constrained Multi-Robot Consensus
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7705
EP  - 7711
AU  - F. Morbidi
PY  - 2020
KW  - distributed algorithms
KW  - distributed control
KW  - mobile robots
KW  - multi-robot systems
KW  - subspace projectors
KW  - state-constrained multirobot consensus
KW  - distributed algorithms
KW  - subspace projection methods
KW  - consensus value
KW  - constrained 2D rendezvous
KW  - single-integrator robots
KW  - discrete-time agreement protocol
KW  - Symmetric matrices
KW  - Eigenvalues and eigenfunctions
KW  - Protocols
KW  - Matrix decomposition
KW  - Laplace equations
KW  - Two dimensional displays
KW  - Robots
DO  - 10.1109/ICRA40945.2020.9196758
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we study the state-constrained consensus problem and introduce a new family of distributed algorithms based on subspace projection methods which are simple to implement and which preserve, under some suitable conditions, the consensus value of the original discrete-time agreement protocol. The proposed theory is supported by extensive numerical experiments for the constrained 2D rendezvous of single-integrator robots.
ER  - 

TY  - CONF
TI  - Multi-Agent Task Allocation using Cross-Entropy Temporal Logic Optimization
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7712
EP  - 7718
AU  - C. Banks
AU  - S. Wilson
AU  - S. Coogan
AU  - M. Egerstedt
PY  - 2020
KW  - discrete systems
KW  - entropy
KW  - graph theory
KW  - multi-agent systems
KW  - multi-robot systems
KW  - optimisation
KW  - search problems
KW  - stochastic programming
KW  - temporal logic
KW  - task specification
KW  - discrete transition systems
KW  - finite linear temporal logic specifications
KW  - stochastic optimization
KW  - graph based search
KW  - cross entropy temporal logic optimization
KW  - multiagent task allocation cross entropy algorithm
KW  - robot team
KW  - Task analysis
KW  - Automata
KW  - Cost function
KW  - Planning
KW  - Resource management
KW  - Switches
DO  - 10.1109/ICRA40945.2020.9197066
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we propose a graph-based search method to optimally allocate tasks to a team of robots given a global task specification. In particular, we define these agents as discrete transition systems. In order to allocate tasks to the team of robots, we decompose finite linear temporal logic (LTL) specifications and consider agent specific cost functions. We propose to use the stochastic optimization technique, cross entropy, to optimize over this cost function. The multi-agent task allocation cross-entropy (MTAC-E) algorithm is developed to determine both when it is optimal to switch to a new agent to complete a task and minimize the costs associated with individual agent trajectories. The proposed algorithm is verified in simulation and experimental results are included.
ER  - 

TY  - CONF
TI  - Adaptive Task Allocation for Heterogeneous Multi-Robot Teams with Evolving and Unknown Robot Capabilities
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7719
EP  - 7725
AU  - Y. Emam
AU  - S. Mayya
AU  - G. Notomista
AU  - A. Bohannon
AU  - M. Egerstedt
PY  - 2020
KW  - adaptive systems
KW  - multi-robot systems
KW  - adaptive task allocation
KW  - task execution
KW  - robot capabilities
KW  - heterogeneous multirobot teams
KW  - Task analysis
KW  - Resource management
KW  - Cost function
KW  - Mobile robots
KW  - Real-time systems
KW  - Minimization
DO  - 10.1109/ICRA40945.2020.9197283
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - For multi-robot teams with heterogeneous capabilities, typical task allocation methods assign tasks to robots based on the suitability of the robots to perform certain tasks as well as the requirements of the task itself. However, in real-world deployments of robot teams, the suitability of a robot might be unknown prior to deployment, or might vary due to changing environmental conditions. This paper presents an adaptive task allocation and task execution framework which allows individual robots to prioritize among tasks while explicitly taking into account their efficacy at performing the tasks-the parameters of which might be unknown before deployment and/or might vary over time. Such a specialization parameter-encoding the effectiveness of a given robot towards a task-is updated on-the-fly, allowing our algorithm to reassign tasks among robots with the aim of executing them. The developed framework requires no explicit model of the changing environment or of the unknown robot capabilities-it only takes into account the progress made by the robots at completing the tasks. Simulations and experiments demonstrate the efficacy of the proposed approach during variations in environmental conditions and when robot capabilities are unknown before deployment.
ER  - 

TY  - CONF
TI  - Mobile Wireless Network Infrastructure on Demand
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7726
EP  - 7732
AU  - D. Mox
AU  - M. Calvo-Fullana
AU  - M. Gerasimenko
AU  - J. Fink
AU  - V. Kumar
AU  - A. Ribeiro
PY  - 2020
KW  - mobile ad hoc networks
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - optimisation
KW  - telecommunication network routing
KW  - mobile relay nodes
KW  - network team
KW  - wireless connectivity
KW  - task agents
KW  - Mobile wireless network infrastructure
KW  - multirobot teams
KW  - previous multiagent systems
KW  - communication infrastructure
KW  - end-to-end communication requirements
KW  - task team
KW  - arbitrary objective
KW  - joint optimization framework
KW  - optimal network routes
KW  - Task analysis
KW  - Ad hoc networks
KW  - Routing
KW  - Wireless networks
KW  - Hardware
KW  - Probabilistic logic
DO  - 10.1109/ICRA40945.2020.9197460
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this work, we introduce Mobile Wireless Infrastructure on Demand: a framework for providing wireless connectivity to multi-robot teams via autonomously reconfiguring ad-hoc networks. In many cases, previous multi-agent systems either assumed the availability of existing communication infrastructure or were required to create a network in addition to completing their objective. Instead our system explicitly assumes the responsibility of creating and sustaining a wireless network capable of satisfying end-to-end communication requirements of a team of agents, called the task team, performing an arbitrary objective. To accomplish this goal, we propose a joint optimization framework that alternates between finding optimal network routes to support data flows between the task agents and improving the performance of the network by repositioning a collection of mobile relay nodes referred to as the network team. We demonstrate our approach with simulations and experiments wherein wireless connectivity is provided to patrolling task agents.
ER  - 

TY  - CONF
TI  - Monitoring Over the Long Term: Intermittent Deployment and Sensing Strategies for Multi-Robot Teams
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7733
EP  - 7739
AU  - J. Liu
AU  - R. K. Williams
PY  - 2020
KW  - combinatorial mathematics
KW  - Gaussian processes
KW  - greedy algorithms
KW  - matrix algebra
KW  - Monte Carlo methods
KW  - multi-robot systems
KW  - optimisation
KW  - multirobot team
KW  - intermittent deployment problem
KW  - heterogeneous robots
KW  - environmental process
KW  - spatiotemporal process
KW  - intermittent deployment strategy
KW  - spatiotemporal Gaussian process
KW  - Monte Carlo simulations
KW  - greedy algorithm
KW  - submodular optimization
KW  - matroids
KW  - Robot sensing systems
KW  - Monitoring
KW  - Mutual information
KW  - Spatiotemporal phenomena
KW  - Kernel
DO  - 10.1109/ICRA40945.2020.9196826
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we formulate and solve the intermittent deployment problem, which yields strategies that couple when heterogeneous robots should sense an environmental process, with where a deployed team should sense in the environment. As a motivation, suppose that a spatiotemporal process is slowly evolving and must be monitored by a multi-robot team, e.g., unmanned aerial vehicles monitoring pasturelands in a precision agriculture context. In such a case, an intermittent deployment strategy is necessary as persistent deployment or monitoring is not cost-efficient for a slowly evolving process. At the same time, the problem of where to sense once deployed must be solved as process observations yield useful feedback for determining effective future deployment and monitoring decisions. In this context, we model the environmental process to be monitored as a spatiotemporal Gaussian process with mutual information as a criterion to measure our understanding of the environment. To make the sensing resource-efficient, we demonstrate how to use matroid constraints to impose a diverse set of homogeneous and heterogeneous constraints. In addition, to reflect the cost-sensitive nature of real-world applications, we apply budgets on the cost of deployed heterogeneous robot teams. To solve the resulting problem, we exploit the theories of submodular optimization and matroids and present a greedy algorithm with bounds on sub-optimality. Finally, Monte Carlo simulations demonstrate the correctness of the proposed method.
ER  - 

TY  - CONF
TI  - Multi-Robot Coordination for Estimation and Coverage of Unknown Spatial Fields
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7740
EP  - 7746
AU  - A. Benevento
AU  - M. Santos
AU  - G. Notarstefano
AU  - K. Paynabar
AU  - M. Bloch
AU  - M. Egerstedt
PY  - 2020
KW  - Bayes methods
KW  - computational geometry
KW  - Gaussian processes
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - sampling methods
KW  - multirobot coordination
KW  - unknown spatial fields
KW  - multirobot coverage
KW  - initially unknown spatial scalar field
KW  - Bayesian optimization
KW  - control law
KW  - centroidal Voronoi tessellation
KW  - adaptive sequential sampling method
KW  - surrogate function
KW  - density function
KW  - Gaussian processes
KW  - Density functional theory
KW  - Estimation
KW  - Gaussian processes
KW  - Robot sensing systems
KW  - Prediction algorithms
KW  - Bayes methods
DO  - 10.1109/ICRA40945.2020.9197487
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present an algorithm for multi-robot coverage of an initially unknown spatial scalar field characterized by a density function, whereby a team of robots simultaneously estimates and optimizes its coverage of the density function over the domain. The proposed algorithm borrows powerful concepts from Bayesian Optimization with Gaussian Processes that, when combined with control laws to achieve centroidal Voronoi tessellation, give rise to an adaptive sequential sampling method to explore and cover the domain. The crux of the approach is to apply a control law using a surrogate function of the true density function, which is then successively refined as robots gather more samples for estimation. The performance of the algorithm is justified theoretically under slightly idealized assumptions, by demonstrating asymptotic no-regret with respect to the coverage obtained with a known density function. The performance is also evaluated in simulation and on the Robotarium with small teams of robots, confirming the good performance suggested by the theoretical analysis.
ER  - 

TY  - CONF
TI  - Learning Robotic Assembly Tasks with Lower Dimensional Systems by Leveraging Physical Softness and Environmental Constraints
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7747
EP  - 7753
AU  - M. Hamaya
AU  - R. Lee
AU  - K. Tanaka
AU  - F. von Drigalski
AU  - C. Nakashima
AU  - Y. Shibata
AU  - Y. Ijiri
PY  - 2020
KW  - force control
KW  - force sensors
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robotic assembly
KW  - torque control
KW  - high frequency force-torque sensors
KW  - physical softness
KW  - data-driven approaches
KW  - hard robots
KW  - learning robotic assembly tasks
KW  - peg-in-hole tasks
KW  - model-based reinforcement learning method
KW  - lower dimensional systems
KW  - environmental constraints
KW  - soft robot
KW  - high frequency force-torque controllers
KW  - Task analysis
KW  - Soft robotics
KW  - Aerospace electronics
KW  - Force
KW  - Robotic assembly
KW  - Learning (artificial intelligence)
DO  - 10.1109/ICRA40945.2020.9197327
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this study, we present a novel control framework for assembly tasks with a soft robot. Typically, existing hard robots require high frequency controllers and precise force/torque sensors for assembly tasks. The resulting robot system is complex, entailing large amounts of engineering and maintenance. Physical softness allows the robot to interact with the environment easily. We expect soft robots to perform assembly tasks without the need for high frequency force/torque controllers and sensors. However, specific data-driven approaches are needed to deal with complex models involving nonlinearity and hysteresis. If we were to apply these approaches directly, we would be required to collect very large amounts of training data. To solve this problem, we argue that by leveraging softness and environmental constraints, a robot can complete tasks in lower dimensional state and action spaces, which could greatly facilitate the exploration of appropriate assembly skills. Then, we apply a highly efficient model-based reinforcement learning method to lower dimensional systems. To verify our method, we perform a simulation for peg-in-hole tasks. The results show that our method learns the appropriate skills faster than an approach that does not consider lower dimensional systems. Moreover, we demonstrate that our method works on a real robot equipped with a compliant module on the wrist.
ER  - 

TY  - CONF
TI  - Titan: A Parallel Asynchronous Library for Multi-Agent and Soft-Body Robotics using NVIDIA CUDA
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7754
EP  - 7760
AU  - J. Austin
AU  - R. Corrales-Fatou
AU  - S. Wyetzner
AU  - H. Lipson
PY  - 2020
KW  - control engineering computing
KW  - graphics processing units
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - optimisation
KW  - parallel algorithms
KW  - parallel architectures
KW  - CUDA-based C++ robotics simulation library
KW  - multiagent robots
KW  - massively parallel integration scheme
KW  - reinforcement learning iterations
KW  - rapid topology optimization
KW  - simultaneous optimization
KW  - innovative GPU architecture design
KW  - robotics primitives
KW  - GPU-accelerated simulations
KW  - asynchronous computing model
KW  - GPU-accelerated interface
KW  - interacting bodies
KW  - multiagent robotics
KW  - intrinsically serial tasks
KW  - low-dimensional tasks
KW  - robotics simulation libraries
KW  - NVIDIA CUDA
KW  - soft-body robotics
KW  - parallel asynchronous library
KW  - Titan
KW  - Graphics processing units
KW  - Robots
KW  - Libraries
KW  - Springs
KW  - Computational modeling
KW  - Kernel
KW  - Acceleration
DO  - 10.1109/ICRA40945.2020.9196808
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - While most robotics simulation libraries are built for low-dimensional and intrinsically serial tasks, soft-body and multi-agent robotics have created a demand for simulation environments that can model many interacting bodies in parallel. Despite the increasing interest in these fields, no existing simulation library addresses the challenge of providing a unified, highly-parallelized, GPU-accelerated interface for simulating large robotic systems. Titan is a versatile CUDA-based C++ robotics simulation library that employs a novel asynchronous computing model for GPU-accelerated simulations of robotics primitives. The innovative GPU architecture design permits simultaneous optimization and control on the CPU while the GPU runs asynchronously, enabling rapid topology optimization and reinforcement learning iterations. Kinematics are solved with a massively parallel integration scheme that incorporates constraints and environmental forces. We report dramatically improved performance over CPU baselines, simulating as many as 300 million primitive updates per second, while allowing flexibility for a wide range of research applications. We present several applications of Titan to high-performance simulations of soft-body and multi-agent robots.
ER  - 

TY  - CONF
TI  - Motion Planning with Competency-Aware Transition Models for Underactuated Adaptive Hands
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7761
EP  - 7767
AU  - A. Sintov
AU  - A. Kimmel
AU  - K. E. Bekris
AU  - A. Boularias
PY  - 2020
KW  - dexterous manipulators
KW  - optimal control
KW  - path planning
KW  - competency-aware transition models
KW  - underactuated adaptive hands
KW  - in-hand manipulation
KW  - data-driven models
KW  - asymptotically optimal motion planner
KW  - motion planning
KW  - grasping tasks
KW  - dexterity
KW  - Data models
KW  - Planning
KW  - Predictive models
KW  - Adaptation models
KW  - Trajectory
KW  - Training
KW  - Uncertainty
DO  - 10.1109/ICRA40945.2020.9196564
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Underactuated adaptive hands simplify grasping tasks but it is difficult to model their interactions with objects during in-hand manipulation. Learned data-driven models have been recently shown to be efficient in motion planning and control of such hands. Still, the accuracy of the models is limited even with the addition of more data. This becomes important for long horizon predictions, where errors are accumulated along the length of a path. Instead of throwing more data into learning the transition model, this work proposes to rather invest a portion of the training data in a critic model. The critic is trained to estimate the error of the transition model given a state and a sequence of future actions, along with information of past actions. The critic is used to reformulate the cost function of an asymptotically optimal motion planner. Given the critic, the planner directs planned paths to less erroneous regions in the state space. The approach is evaluated against standard motion planning on simulated and real hands. The results show that it outperforms an alternative where all the available data is used for training the transition model without a critic.
ER  - 

TY  - CONF
TI  - Human-like Planning for Reaching in Cluttered Environments
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7784
EP  - 7790
AU  - M. Hasan
AU  - M. Warburton
AU  - W. C. Agboh
AU  - M. R. Dogar
AU  - M. Leonetti
AU  - H. Wang
AU  - F. Mushtaq
AU  - M. Mon-Williams
AU  - A. G. Cohn
PY  - 2020
KW  - collision avoidance
KW  - decision making
KW  - dexterous manipulators
KW  - grippers
KW  - learning (artificial intelligence)
KW  - planning (artificial intelligence)
KW  - robot programming
KW  - robot vision
KW  - trajectory control
KW  - virtual reality
KW  - decision making
KW  - decision classifiers
KW  - cluttered environments
KW  - robot planners
KW  - random sampling
KW  - object manipulation plans
KW  - virtual reality
KW  - trajectory optimisation
KW  - physics based robot simulation
KW  - human-like planning
KW  - depth camera
KW  - Robotiq two finger gripper
KW  - Task analysis
KW  - Planning
KW  - Robots
KW  - Testing
KW  - Feature extraction
KW  - Trajectory
KW  - Standards
DO  - 10.1109/ICRA40945.2020.9196665
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Humans, in comparison to robots, are remarkably adept at reaching for objects in cluttered environments. The best existing robot planners are based on random sampling of configuration space- which becomes excessively high-dimensional with large number of objects. Consequently, most planners often fail to efficiently find object manipulation plans in such environments. We addressed this problem by identifying high-level manipulation plans in humans, and transferring these skills to robot planners. We used virtual reality to capture human participants reaching for a target object on a tabletop cluttered with obstacles. From this, we devised a qualitative representation of the task space to abstract the decision making, irrespective of the number of obstacles. Based on this representation, human demonstrations were segmented and used to train decision classifiers. Using these classifiers, our planner produced a list of waypoints in task space. These waypoints provided a high-level plan, which could be transferred to an arbitrary robot model and used to initialise a local trajectory optimiser. We evaluated this approach through testing on unseen human VR data, a physics-based robot simulation, and a real robot (dataset and code are publicly available1). We found that the human-like planner outperformed a state-of-the-art standard trajectory optimisation algorithm, and was able to generate effective strategies for rapid planning- irrespective of the number of obstacles in the environment.
ER  - 

TY  - CONF
TI  - Where to relocate?: Object rearrangement inside cluttered and confined environments for robotic manipulation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7791
EP  - 7797
AU  - S. Hun Cheong
AU  - B. Y. Cho
AU  - J. Lee
AU  - C. Kim
AU  - C. Nam
PY  - 2020
KW  - collision avoidance
KW  - computational complexity
KW  - graph theory
KW  - industrial robots
KW  - manipulators
KW  - mobile robots
KW  - optimisation
KW  - robot vision
KW  - warehousing
KW  - object rearrangement
KW  - cluttered confined environments
KW  - robotic manipulation
KW  - cluttered confined space
KW  - motion planning
KW  - manipulator
KW  - nonmonotone arrangement problems
KW  - pick-and-place actions
KW  - baseline methods
KW  - Planning
KW  - Manipulators
KW  - Collision avoidance
KW  - Task analysis
KW  - Clutter
KW  - Kinematics
DO  - 10.1109/ICRA40945.2020.9197485
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present an algorithm determining where to relocate objects inside a cluttered and confined space while rearranging objects to retrieve a target object. Although methods that decide what to remove have been proposed, planning for the placement of removed objects inside a workspace has not received much attention. Rather, removed objects are often placed outside the workspace, which incurs additional laborious work (e.g., motion planning and execution of the manipulator and the mobile base, perception of other areas). Some other methods manipulate objects only inside the workspace but without a principle so the rearrangement becomes inefficient. In this work, we consider both monotone (each object is moved only once) and non-monotone arrangement problems which have shown to be NP-hard. Once the sequence of objects to be relocated is given by any existing algorithm, our method aims to minimize the number of pick-and-place actions to place the objects until the target becomes accessible. From extensive experiments, we show that our method reduces the number of pick-and-place actions and the total execution time (the reduction is up to 23.1% and 28.1% respectively) compared to baseline methods while achieving higher success rates.
ER  - 

TY  - CONF
TI  - Autonomous Modification of Unstructured Environments with Found Material
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7798
EP  - 7804
AU  - V. Thangavelu
AU  - M. S. da Silva
AU  - J. Choi
AU  - N. Napp
PY  - 2020
KW  - building materials
KW  - dexterous manipulators
KW  - friction
KW  - grippers
KW  - industrial manipulators
KW  - materials handling equipment
KW  - mechanical contact
KW  - path planning
KW  - sensors
KW  - unseen objects
KW  - adaptive ramp building algorithms
KW  - irregularly shaped stones
KW  - contact geometry
KW  - friction
KW  - high-level algorithm
KW  - physics-based planner
KW  - pickup
KW  - robotic system
KW  - complex grasp planning
KW  - autonomous modification
KW  - manipulation
KW  - found material
KW  - pickup
KW  - motion support structures
KW  - specialized construction algorithm
KW  - unstructured environments
KW  - Uncertainty
KW  - Robot sensing systems
KW  - Physics
KW  - Shape
KW  - Buildings
KW  - physics simulation
KW  - autonomous construction
KW  - robotics
KW  - irregular building materials.
DO  - 10.1109/ICRA40945.2020.9197372
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The ability to autonomously modify their environment dramatically increases the capability of robots to operate in unstructured environments. We develop a specialized construction algorithm and robotic system that can autonomously build motion support structures with previously unseen objects. The approach is based on our prior work on adaptive ramp building algorithms, but it eliminates the assumption of having specialized building materials that simplify manipulation and planning for stability. Utilizing irregularly shaped stones makes the problem significantly more challenging since the outcome of individual placements is sensitive to details of contact geometry and friction, which are difficult to observe. To reuse the same high-level algorithm, we develop a new physics-based planner that explicitly considers the uncertainty produced by incomplete in-situ sensing and imprecision during pickup and placement. We demonstrate the approach on a robotic system that uses a newly developed gripper to reliably pick up stones with minimal additional sensors or complex grasp planning. The resulting system can build structures with more than 70 stones, which in turn provide traversable paths to previously inaccessible locations.
ER  - 

TY  - CONF
TI  - LiStereo: Generate Dense Depth Maps from LIDAR and Stereo Imagery
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7829
EP  - 7836
AU  - J. Zhang
AU  - M. S. Ramanagopal
AU  - R. Vasudevan
AU  - M. Johnson-Roberson
PY  - 2020
KW  - image matching
KW  - image resolution
KW  - optical radar
KW  - stereo image processing
KW  - dense depth maps
KW  - depth information
KW  - light detection and ranging
KW  - accurate depth map
KW  - stereo imagery
KW  - stereo systems
KW  - high-quality dense depth maps
KW  - stereo matching algorithms
KW  - sparse depth map
KW  - high-resolution LIDAR
KW  - Laser radar
KW  - Task analysis
KW  - Training
KW  - Feature extraction
KW  - Estimation
KW  - Convolution
KW  - Correlation
DO  - 10.1109/ICRA40945.2020.9196628
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - An accurate depth map of the environment is critical to the safe operation of autonomous robots and vehicles. Currently, either light detection and ranging (LIDAR) or stereo matching algorithms are used to acquire such depth information. However, a high-resolution LIDAR is expensive and produces sparse depth map at large range; stereo matching algorithms are able to generate denser depth maps but are typically less accurate than LIDAR at long range. This paper combines these approaches together to generate high-quality dense depth maps. Unlike previous approaches that are trained using ground-truth labels, the proposed model adopts a self-supervised training process. Experiments show that the proposed method is able to generate high-quality dense depth maps and performs robustly even with low-resolution inputs. This shows the potential to reduce the cost by using LIDARs with lower resolution in concert with stereo systems while maintaining high resolution.
ER  - 

TY  - CONF
TI  - Monocular Visual-Inertial Odometry in Low-Textured Environments with Smooth Gradients: A Fully Dense Direct Filtering Approach
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7837
EP  - 7843
AU  - A. Hardt-Stremayr
AU  - S. Weiss
PY  - 2020
KW  - calibration
KW  - distance measurement
KW  - gradient methods
KW  - image filtering
KW  - image texture
KW  - inertial systems
KW  - interpolation
KW  - vectors
KW  - low-textured environments
KW  - fully dense direct filtering approach
KW  - visual texture
KW  - direct photometric approaches
KW  - image information
KW  - information propagation
KW  - complexity reduction approach
KW  - state vector
KW  - monocular visual-inertial odometry approaches
KW  - higher order covariance propagation
KW  - state handling improvement
KW  - Cameras
KW  - Uncertainty
KW  - Estimation
KW  - Mathematical model
KW  - Motion estimation
KW  - Integrated circuits
KW  - Robots
DO  - 10.1109/ICRA40945.2020.9196881
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - State of the art visual-inertial odometry approaches suffer from the requirement of high gradients and sufficient visual texture. Even direct photometric approaches select a subset of the image with high-gradient areas and ignore smooth gradients or generally low-textured areas. In this work, we show that taking all image information (i.e. every single pixel) enables visual-inertial odometry even on areas with very low texture and smooth gradients, inherently interpolating and estimating the scene with no texture based on its informative surrounding. This information propagation is only possible as we estimate all states and their uncertainties (robot pose, extrinsic sensor calibration, and scene depth) jointly in a fully dense filter framework. Our complexity reduction approach enables real-time execution despite the large size of the state vector. Compared to our previous basic feasibility study on this topic, this work includes higher order covariance propagation and improved state handling for a significant performance gain, thorough comparisons to state-of-the-art algorithms, larger mapping components with uncertainty, self-calibration capability, and real-data tests.
ER  - 

TY  - CONF
TI  - Interaction Stability Analysis from the Input-Output Viewpoints
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7878
EP  - 7884
AU  - Y. Huang
AU  - Q. Huang
PY  - 2020
KW  - bond graphs
KW  - haptic interfaces
KW  - Hilbert spaces
KW  - human-robot interaction
KW  - input-output stability
KW  - robotic assembly
KW  - mechanical impedance
KW  - linear spatial impedance representation
KW  - bond graph theory
KW  - ideal model
KW  - idealized interaction
KW  - port functions
KW  - ideal interaction model
KW  - collaborative interactions
KW  - competitive interactions
KW  - interaction models
KW  - passivity indices
KW  - interaction stability analysis
KW  - input-output viewpoints
KW  - robot applications
KW  - haptic devices
KW  - parts assembly
KW  - interaction behaviours
KW  - interaction dynamics
KW  - DAlembert principle
KW  - nonsmooth mechanics
KW  - kinematic constraints
KW  - bond graph methodology
KW  - Hilbert function space
KW  - continuous function
KW  - input-output stability condition
KW  - Impedance
KW  - Admittance
KW  - Robots
KW  - Force
KW  - Kinematics
KW  - Stability criteria
DO  - 10.1109/ICRA40945.2020.9196643
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Interaction with the environment is arguably one of the necessary actions for many robot applications such as haptic devices, manipulation, parts assembly, cooperation with humans, and the use of tools. Taxonomy of interaction behaviours is classified into three categories: cooperation, collaboration, and competition. In theory, interaction dynamics may be modelled by D'Alembert's principle or nonsmooth mechanics through seeking equality and/or inequality kinematic constraints. However, it is hard to gain these kinematic constraints in practice since they may be variable or be hardly described in a mathematical form. As a result, bond graph methodology is preferred in interaction dynamics modelling.In this paper, passivity and passivity indices with the differential operator are put forward by restricting its domain from the whole extended Hilbert function space to a set of all continuous function with finite derivative, and then the input-output stability condition, in this case, is derived. Next, mechanical impedance and admittance are defined, and a linear spatial impedance representation is given from the energetic point of view. Base on the bond graph theory, an ideal model is presented to model the idealized interaction, and invariance of port functions derived from the ideal interaction model is introduced; An interaction model is then proposed accounting for nonidealized factors and to describe cooperative, collaborative, and competitive interactions in a unified way. Finally, interaction stabilities are analyzed corresponding to different interaction models, and robustness of interaction stability is addressed based on the passivity indices.
ER  - 

TY  - CONF
TI  - Improving the contact instant detection of sensing antennae using a Super-Twisting algorithm
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7885
EP  - 7890
AU  - D. Feliu-Talegon
AU  - R. Cortez-Vega
AU  - V. Feliu-Batlle
PY  - 2020
KW  - filtering theory
KW  - multi-robot systems
KW  - signal processing
KW  - variable structure systems
KW  - contact instant detection
KW  - antenna devices
KW  - mimic insect antennae
KW  - mammal whiskers
KW  - robotic systems
KW  - signal processing
KW  - flexible antenna
KW  - impact detection
KW  - impact instant estimation
KW  - super-twisting algorithm
KW  - time 5.0 ms
KW  - Antennas
KW  - Estimation
KW  - Vibrations
KW  - Robot sensing systems
KW  - Antenna measurements
KW  - Delays
DO  - 10.1109/ICRA40945.2020.9197107
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Sensing antenna devices, that mimic insect antennae or mammal whiskers, is an active field of research that still needs new developments in order to become efficient and reliable components of robotic systems. This work reports a new result in the area of signal processing of these devices that allows to detect the instant of the impact of a flexible antenna with an object faster than other reported methods. Previous methods require the use of filters that introduce delays in the impact detection. A method based on the Super-Twisting algorithm is proposed here that avoids the use of these filters and reduces such delays improving the impact instant estimation. Experiments show that these delays can be reduced in more than 50%, allowing reliable estimation of the impact instant with an error of less than 5 ms in many cases requiring a limited computational effort.
ER  - 

TY  - CONF
TI  - 6DFC: Efficiently Planning Soft Non-Planar Area Contact Grasps using 6D Friction Cones
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7891
EP  - 7897
AU  - J. Xu
AU  - M. Danielczuk
AU  - E. Steinbach
AU  - K. Goldberg
PY  - 2020
KW  - friction
KW  - grippers
KW  - manipulator dynamics
KW  - path planning
KW  - quadratic programming
KW  - robot vision
KW  - 6D friction cone
KW  - approximate compliant contacts
KW  - soft point contact models
KW  - area contact model
KW  - 6D friction limit surface
KW  - 6DFC algorithm
KW  - soft nonplanar area contact grasp planning
KW  - 3D friction cones
KW  - ABB YuMi robot
KW  - quadratic program
KW  - Friction
KW  - Grippers
KW  - Three-dimensional displays
KW  - Force
KW  - Solid modeling
KW  - Computational modeling
KW  - Ellipsoids
DO  - 10.1109/ICRA40945.2020.9197293
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Analytic grasp planning algorithms typically approximate compliant contacts with soft point contact models to compute grasp quality, but these models are overly conservative and do not capture the full range of grasps available. While area contact models can reduce the number of false negatives predicted by point contact models, they have been restricted to a 3D analysis of the wrench applied at the contact and so are still overly conservative. We extend traditional 3D friction cones and present an efficient algorithm for calculating the 6D friction cone (6DFC) for a non-planar area contact between a compliant gripper and a rigid object. We introduce a novel sampling algorithm to find the 6D friction limit surface for a non-planar area contact and a linearization method for these ellipsoids that reduces the computation of 6DFC constraints to a quadratic program. We show that constraining the wrench applied at the contact in this way increases recall, a metric inversely related to the number of false negative predictions, by 17% and precision, a metric inversely related to the number of false positive predictions, by 2% over soft point contact models on results from 1500 physical grasps on 12 3D printed nonplanar objects with an ABB YuMi robot. The 6DFC algorithm also achieves 6% higher recall with similar precision and 85x faster runtime than a previously proposed area contact model.
ER  - 

TY  - CONF
TI  - Long-Horizon Prediction and Uncertainty Propagation with Residual Point Contact Learners
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7898
EP  - 7904
AU  - N. Fazeli
AU  - A. Ajay
AU  - A. Rodriguez
PY  - 2020
KW  - computer simulation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - self-supervised approach
KW  - rigid-body simulators
KW  - contact models
KW  - predictive performance
KW  - horizon prediction
KW  - uncertainty propagation
KW  - residual point contact learners
KW  - robotic tasks
KW  - Predictive models
KW  - Analytical models
KW  - Uncertainty
KW  - Computational modeling
KW  - Trajectory
KW  - Dynamics
KW  - Stochastic processes
DO  - 10.1109/ICRA40945.2020.9196511
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The ability to simulate and predict the outcome of contacts is paramount to the successful execution of many robotic tasks. Simulators are powerful tools for the design of robots and their behaviors, yet the discrepancy between their predictions and observed data limit their usability. In this paper, we propose a self-supervised approach to learning residual models for rigid-body simulators that exploits corrections of contact models to refine predictive performance and propagate uncertainty. We empirically evaluate the framework by predicting the outcomes of planar dice rolls and compare it's performance to state-of-the-art techniques.
ER  - 

TY  - CONF
TI  - Versatile Trajectory Optimization Using a LCP Wheel Model for Dynamic Vehicle Maneuvers
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7905
EP  - 7911
AU  - G. Bellegarda
AU  - K. Byl
PY  - 2020
KW  - automobiles
KW  - friction
KW  - mechanical contact
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - robot dynamics
KW  - trajectory control
KW  - tyres
KW  - vehicle dynamics
KW  - wheels
KW  - dynamic drift parking
KW  - discontinuous friction model
KW  - tire dynamics model
KW  - cost function
KW  - wheel skidding
KW  - versatile trajectory optimization framework
KW  - vehicle motion
KW  - anisotropic Coulomb friction cone
KW  - multirigid-body contact problems
KW  - linear complementarity problem
KW  - robotics community
KW  - contact dynamics
KW  - real world contact behavior
KW  - empirical friction model
KW  - aggressive maneuvers
KW  - car models
KW  - dynamic vehicle maneuvers
KW  - LCP wheel model
KW  - executing dynamic drift parking
KW  - planning horizon
KW  - Vehicle dynamics
KW  - Wheels
KW  - Friction
KW  - Planning
KW  - Dynamics
KW  - Trajectory optimization
KW  - Tires
DO  - 10.1109/ICRA40945.2020.9197541
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Car models have been extensively studied at varying levels of abstraction, and planning and executing motions under ideal conditions is well researched and understood. For more aggressive maneuvers, for example when drifting or skidding, empirical and/or discontinuous friction models have been used to explain and approximate real world contact behavior. Separately, contact dynamics have been extensively studied by the robotics community, often times formulated as a linear complementarity problem (LCP) for dynamic multi-rigid-body contact problems with Coulomb friction cone approximations. In this work, we explore the validity of using such an anisotropic Coulomb friction cone to model tire dynamics to plan for vehicle motion, and present a versatile trajectory optimization framework using this model that can both avoid and/or exploit wheel skidding, depending on the cost function and planning horizon. Experimental evidence of planning and executing dynamic drift parking is shown on a 1/16 scale model car.
ER  - 

TY  - CONF
TI  - Highly Parallelizable Plane Extraction for Organized Point Clouds Using Spherical Convex Hulls
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7920
EP  - 7926
AU  - H. Möls
AU  - K. Li
AU  - U. D. Hanebeck
PY  - 2020
KW  - geometry
KW  - image colour analysis
KW  - pixelwise plane extraction
KW  - highly parallelizable plane extraction
KW  - organized point clouds
KW  - spherical convex hull
KW  - region growing algorithm
KW  - explicit plane parameterization
KW  - geometric constraints
KW  - GPU
KW  - RGB-D camera
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Robot sensing systems
KW  - Clustering algorithms
KW  - Real-time systems
KW  - Data mining
DO  - 10.1109/ICRA40945.2020.9197139
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present a novel region growing algorithm for plane extraction of organized point clouds using the spherical convex hull. Instead of explicit plane parameterization, our approach interprets potential underlying planes as a series of geometric constraints on the sphere that are refined during region growing. Unlike existing schemes relying on downsampling for sequential execution in real time, our approach enables pixelwise plane extraction that is highly parallelizable. We further test the proposed approach with a fully parallel implementation on a GPU. Evaluation based on public data sets has shown state-of-the-art extraction accuracy and superior speed compared to existing approaches, while guaranteeing real-time processing at full input resolution of a typical RGB-D camera.
ER  - 

TY  - CONF
TI  - View-Invariant Loop Closure with Oriented Semantic Landmarks
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7943
EP  - 7949
AU  - J. Li
AU  - K. Koreitem
AU  - D. Meger
AU  - G. Dudek
PY  - 2020
KW  - geometry
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - view-invariant loop closure
KW  - oriented semantic landmarks
KW  - simultaneous localization and mapping
KW  - monocular semantic SLAM system
KW  - object identity
KW  - inter-object geometry
KW  - view-invariant loop detection
KW  - ORB-SLAM
KW  - local appearance-based features
KW  - indoor scenes
KW  - object orientation estimation
KW  - geometrical detailed semantic maps
KW  - object translation
KW  - object scale
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Trajectory
KW  - Layout
KW  - Robustness
KW  - Estimation
DO  - 10.1109/ICRA40945.2020.9196886
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Recent work on semantic simultaneous localization and mapping (SLAM) have shown the utility of natural objects as landmarks for improving localization accuracy and robustness. In this paper we present a monocular semantic SLAM system that uses object identity and inter-object geometry for view-invariant loop detection and drift correction. Our system's ability to recognize an area of the scene even under large changes in viewing direction allows it to surpass the mapping accuracy of ORB-SLAM, which uses only local appearance-based features that are not robust to large viewpoint changes. Experiments on real indoor scenes show that our method achieves mean drift reduction of 70% when compared directly to ORB-SLAM. Additionally, we propose a method for object orientation estimation, where we leverage the tracked pose of a moving camera under the SLAM setting to overcome ambiguities caused by object symmetry. This allows our SLAM system to produce geometrically detailed semantic maps with object orientation, translation, and scale.
ER  - 

TY  - CONF
TI  - Active Acoustic Contact Sensing for Soft Pneumatic Actuators
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7966
EP  - 7972
AU  - G. Zöller
AU  - V. Wall
AU  - O. Brock
PY  - 2020
KW  - elastic constants
KW  - manipulator dynamics
KW  - pneumatic actuators
KW  - soft pneumatic actuators
KW  - active acoustic sensor
KW  - contact sensors
KW  - soft actuator
KW  - embedded speaker
KW  - PneuFlex actuator
KW  - active sensors
KW  - active acoustic contact sensing
KW  - Panda robot arm
KW  - embedded microphone
KW  - Actuators
KW  - Robot sensing systems
KW  - Acoustics
KW  - Microphones
KW  - Acoustic measurements
DO  - 10.1109/ICRA40945.2020.9196916
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present an active acoustic sensor that turns soft pneumatic actuators into contact sensors. The whole surface of the actuator becomes a sensor, rendering the question of where best to place a contact sensor unnecessary. At the same time, the compliance of the soft actuator remains unaffected. A small, embedded speaker emits a frequency sweep which travels through the actuator before it is recorded with an embedded microphone. The specific contact state of the actuator affects how the sound is modulated while traversing the structure. We learn to recognize these changes in the sound and map them to the corresponding contact locations. We demonstrate the method on the PneuFlex actuator. The active acoustic sensor achieves a classification rate of 93% and mean regression error of 3.7mm. It is robust against background noises and different objects. Finally, we test it on a Panda robot arm and show that it is unaffected by motor noises and other active sensors.
ER  - 

TY  - CONF
TI  - A Bidirectional 3D-printed Soft Pneumatic Actuator and Graphite-based Flex Sensor for Versatile Grasping*
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 7979
EP  - 7985
AU  - J. H. Low
AU  - J. Y. Goh
AU  - N. Cheng
AU  - P. M. Khin
AU  - Q. Q. Han
AU  - C. H. Yeow
PY  - 2020
KW  - actuators
KW  - bending
KW  - data gloves
KW  - grippers
KW  - motion control
KW  - pneumatic actuators
KW  - sensors
KW  - solid modelling
KW  - soft pneumatic actuator
KW  - graphite-based flex sensor
KW  - versatile grasping
KW  - 3D-printing approach
KW  - fabrication complexity
KW  - actuator dimensions
KW  - bidirectional actuators
KW  - gripper system
KW  - functional grasping tasks
KW  - default grasping width
KW  - bidirectional bending characteristic
KW  - bidirectional 3D-printed soft pneumatic actuator
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA40945.2020.9196837
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - THIS paper presents a bidirectional 3D-printed soft pneumatic actuator that is capable of inward and outward bending. A direct 3D-printing approach is adopted to fabricate the actuator, which reduces fabrication complexity and allows for easy customization of actuator dimensions for various applications. To illustrate the applicability of the bidirectional actuators, four of these actuators were incorporated into a gripper system. A suite of various functional grasping tasks, such as packaging, assembly, and alignment tasks, were successfully conducted. It was observed that the unique bidirectional bending characteristic of the actuator allows the gripper to grasp objects with sizes up to 245% larger than its default grasping width. To complement the gripper system, a graphite-based flex sensor that is able to sense bending in two directions is developed to control the bidirectional actuators. A preliminary test was conducted successfully where the user controlled the gripper system to grasp, hold, and release an object using a glove with the sensors.
ER  - 

TY  - CONF
TI  - Simultaneous Learning from Human Pose and Object Cues for Real-Time Activity Recognition
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8006
EP  - 8012
AU  - B. Reily
AU  - Q. Zhu
AU  - C. Reardon
AU  - H. Zhang
PY  - 2020
KW  - feature extraction
KW  - human-robot interaction
KW  - image motion analysis
KW  - image recognition
KW  - image representation
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - pose estimation
KW  - regression analysis
KW  - human activity categories
KW  - real-time human activity recognition
KW  - human pose
KW  - object cues
KW  - real-world human-centered robotics applications
KW  - assisted living
KW  - human-robot collaboration
KW  - frequency 104.0 Hz
KW  - Activity recognition
KW  - Real-time systems
KW  - Optimization
KW  - Object recognition
KW  - Feature extraction
KW  - Robot sensing systems
DO  - 10.1109/ICRA40945.2020.9196632
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Real-time human activity recognition plays an essential role in real-world human-centered robotics applications, such as assisted living and human-robot collaboration. Although previous methods based on skeletal data to encode human poses showed promising results on real-time activity recognition, they lacked the capability to consider the context provided by objects within the scene and in use by the humans, which can provide a further discriminant between human activity categories. In this paper, we propose a novel approach to real-time human activity recognition, through simultaneously learning from observations of both human poses and objects involved in the human activity. We formulate human activity recognition as a joint optimization problem under a unified mathematical framework, which uses a regression-like loss function to integrate human pose and object cues and defines structured sparsity-inducing norms to identify discriminative body joints and object attributes. To evaluate our method, we perform extensive experiments on two benchmark datasets and a physical robot in a home assistance setting. Experimental results have shown that our method outperforms previous methods and obtains real-time performance for human activity recognition with a processing speed of 104 Hz.
ER  - 

TY  - CONF
TI  - Demonstration of Hospital Receptionist Robot with Extended Hybrid Code Network to Select Responses and Gestures
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8013
EP  - 8018
AU  - E. J. Hwang
AU  - B. Kyu Ahn
AU  - B. A. Macdonald
AU  - H. Seok Ahn
PY  - 2020
KW  - gesture recognition
KW  - human-robot interaction
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - recurrent neural nets
KW  - service robots
KW  - hospital receptionist robot
KW  - task-oriented dialogue system
KW  - human-robot interaction
KW  - pipeline
KW  - dialogue states
KW  - end-to-end learning
KW  - recurrent neural networks
KW  - social robot system
KW  - end-to-end dialogue system
KW  - RNN based gesture selector
KW  - dialogue efficiency
KW  - gestures
KW  - extended hybrid code network
KW  - Task analysis
KW  - Robot sensing systems
KW  - Pipelines
KW  - Face detection
KW  - Recurrent neural networks
KW  - Speech recognition
DO  - 10.1109/ICRA40945.2020.9197160
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Task-oriented dialogue system has a vital role in Human-Robot Interaction (HRI). However, it has been developed based on conventional pipeline approach which has several drawbacks; expensive, time-consuming, and so on. Based on this approach, developers manually define a robot's behaviour such as gestures and facial expressions on the corresponding dialogue states. Recently, end-to-end learning of Recurrent Neural Networks (RNNs) is an attractive solution for the dialogue system. In this paper, we proposed a social robot system using end-to-end dialogue system in the context of hospital receptionist. We utilized Hybrid Code Network (HCN) as an end-to-end dialogue system and extended to select both response and gesture using RNN based gesture selector. We evaluate its performance with human users and compare the results with one of the conventional methods. Empirical result shows that the proposed method has benefits in terms of dialogue efficiency, which indicates how efficient users were in performing the given tasks with the help of the robot. Moreover, we achieved the same performance regarding the robot's gesture with the proposed method compared to manually defined gestures.
ER  - 

TY  - CONF
TI  - Can I Trust You? A User Study of Robot Mediation of a Support Group
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8019
EP  - 8026
AU  - C. Birmingham
AU  - Z. Hu
AU  - K. Mahajan
AU  - E. Reber
AU  - M. J. Matarić
PY  - 2020
KW  - human-robot interaction
KW  - robot mediation
KW  - socially assistive robots
KW  - group dynamics
KW  - social settings
KW  - trust dynamics
KW  - robot mediated support group
KW  - dyadic trust scale
KW  - general trust
KW  - average interpersonal trust
KW  - group interaction session
KW  - multiparty setting
KW  - Educational robots
KW  - Mediation
KW  - Sensitivity
KW  - Robot sensing systems
KW  - Atmospheric measurements
KW  - Particle measurements
DO  - 10.1109/ICRA40945.2020.9196875
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Socially assistive robots have the potential to improve group dynamics when interacting with groups of people in social settings. This work contributes to the understanding of those dynamics through a user study of trust dynamics in the novel context of a robot mediated support group. For this study, a novel framework for robot mediation of a support group was developed and validated. To evaluate interpersonal trust in the multi-party setting, a dyadic trust scale was implemented and found to be uni-factorial, validating it as an appropriate measure of general trust. The results of this study demonstrate a significant increase in average interpersonal trust after the group interaction session, and qualitative post-session interview data report that participants found the interaction helpful and successfully supported and learned from one other. The results of the study validate that a robot-mediated support group can improve trust among strangers and allow them to share and receive support for their academic stress.
ER  - 

TY  - CONF
TI  - Coronal Plane Spine Twisting Composes Shape To Adjust the Energy Landscape for Grounded Reorientation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8052
EP  - 8058
AU  - J. D. Caporale
AU  - B. W. McInroe
AU  - C. Ning
AU  - T. Libby
AU  - R. J. Full
AU  - D. E. Koditschek
PY  - 2020
KW  - biomechanics
KW  - bone
KW  - orthopaedics
KW  - CPST
KW  - coronal plane spine twisting composes shape
KW  - energy landscape
KW  - grounded reorientation
KW  - animal locomotion
KW  - legged robots
KW  - self-righting mechanics
KW  - freedom coronal plane representation
KW  - body shape affordance
KW  - cross-sectional geometries
KW  - kinematic model predictions
KW  - elliptical bodies
KW  - rectangular shaped bodies
KW  - quasistatic reorientation maneuvers
KW  - Shape
KW  - Kinematics
KW  - Potential energy
KW  - Hip
KW  - Torso
KW  - Legged locomotion
DO  - 10.1109/ICRA40945.2020.9197026
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Despite substantial evidence for the crucial role played by an active backbone or spine in animal locomotion, its adoption in legged robots remains limited because the added mechanical complexity and resulting dynamical challenges pose daunting obstacles to characterizing even a partial range of potential performance benefits. This paper takes a next step toward such a characterization by exploring the quasistatic terrestrial self-righting mechanics of a model system with coronal plane spine twisting (CPST). Reduction from a full 3D kinematic model of CPST to a two parameter, two degree of freedom coronal plane representation of body shape affordance predicts a substantial benefit to ground righting by lowering the barrier between stable potential energy basins. The reduced model predicts the most advantageous twist angle for several cross-sectional geometries, reducing the required righting torque by up to an order of magnitude depending on constituent shapes. Experiments with a three actuated degree of freedom physical mechanism corroborate the kinematic model predictions using two different quasistatic reorientation maneuvers for both elliptical and rectangular shaped bodies with a range of eccentricities or aspect ratios. More speculative experiments make intuitive use of the kinematic model in a highly dynamic maneuver to suggest still greater benefits of CPST achievable by coordinating kinetic as well as potential energy, for example as in a future multi-appendage system interacting with a contact-rich 3D environment.
ER  - 

TY  - CONF
TI  - Motion Design for a Snake Robot Negotiating Complicated Pipe Structures of a Constant Diameter
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8073
EP  - 8079
AU  - M. Inazawa
AU  - T. Takemori
AU  - M. Tanaka
AU  - F. Matsuno
PY  - 2020
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - pipes
KW  - motion design
KW  - snake robot
KW  - constant diameter
KW  - multiple pipe structures
KW  - target form
KW  - rolling motion
KW  - complicated pipe structures
KW  - Snake robots
KW  - Windings
KW  - Shape
KW  - Robots
KW  - Junctions
KW  - Modeling
KW  - Pins
DO  - 10.1109/ICRA40945.2020.9197224
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - A method for designing the motion of a snake robot negotiating complicated pipe structures having a constant diameter is presented. For such robots moving inside pipes, there are various "obstacles" such as junctions, bends, shears, and blockages. To surmount these obstacles, we propose a method that enables the robot to adapt to multiple pipe structures of a constant diameter. We designed the target form of the snake robot of two helices connected with an arbitrary shape. This method is applicable to various obstacles by designing a part of the target form conforming to the obstacle. The robot negotiates obstacles under shift control by employing a rolling motion. We demonstrated the effectiveness of the proposed method in various experiments.
ER  - 

TY  - CONF
TI  - Single Actuator Peristaltic Robot for Subsurface Exploration and Device Emplacement
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8096
EP  - 8102
AU  - J. De la Fuente
AU  - R. Shor
AU  - S. Larter
PY  - 2020
KW  - actuators
KW  - cams (mechanical)
KW  - data acquisition
KW  - design engineering
KW  - geology
KW  - hydrocarbon reservoirs
KW  - mobile robots
KW  - oil reservoirs
KW  - autonomous robots
KW  - data acquisition
KW  - tool transportation
KW  - petroleum reservoirs
KW  - cam-follower configuration worm robot
KW  - peristaltic displacement
KW  - single actuator peristaltic robot
KW  - subsurface exploration
KW  - device emplacement
KW  - initial testing
KW  - single actuator peristaltic motion robot
KW  - subsurface geological exploration
KW  - design
KW  - nonconsolidated media
KW  - Robots
KW  - Hydrocarbons
KW  - Soil
KW  - Reservoirs
KW  - Actuators
KW  - Oils
KW  - Asphalt
DO  - 10.1109/ICRA40945.2020.9196823
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this work, we present the concept, design, and initial testing of a single actuator peristaltic motion robot for subsurface geological exploration and device emplacement. We are researching unconventional methods, including robotics, for the production of energy from oil reservoirs that do not liberate carbon to the atmosphere. For such application, we are developing autonomous robots for data acquisition and tool transportation inside petroleum reservoirs. The mechanism described in this work is a cam-follower configuration worm robot that utilizes peristaltic displacement. We confirmed that the mechanism works on a plane surface and in non-consolidated media.
ER  - 

TY  - CONF
TI  - Dynamic modeling of robotic manipulators for accuracy evaluation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8144
EP  - 8150
AU  - S. A. Zimmermann
AU  - T. F. C. Berninger
AU  - J. Derkx
AU  - D. J. Rixen
PY  - 2020
KW  - finite element analysis
KW  - flexible manipulators
KW  - manipulator dynamics
KW  - robotic manipulators
KW  - industrial robots
KW  - mechanical stiffness
KW  - multibody models
KW  - finite element model
KW  - flexible link manipulator model
KW  - industrial robot
KW  - stiffness parameters
KW  - robot behavior
KW  - weight-reduced manipulator
KW  - Solid modeling
KW  - Manipulator dynamics
KW  - Mathematical model
KW  - Service robots
KW  - Finite element analysis
DO  - 10.1109/ICRA40945.2020.9197304
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In order to fulfill conflicting requirements in the development of industrial robots, such as increased accuracy of a weightreduced manipulator with lower mechanical stiffness, the robot's dynamical behavior must be evaluated early in the development process. This leads to the need of accurate multibody models of the manipulator under development.This paper deals with multibody models that include flexible bodies, which are exported from the corresponding Finite Element model of the structural parts. It is shown that such a flexible link manipulator model, which is purely based on development and datasheet data, is suitable for an accurate description of an industrial robot's dynamic behavior. No stiffness parameters need to be identified by experimental methods, making this approach especially relevant during the development of new manipulators. This paper presents results of experiments in time and frequency domain for analyzing the modeling approach and for validating the model performance against real robot behavior.
ER  - 

TY  - CONF
TI  - A Real-Robot Dataset for Assessing Transferability of Learned Dynamics Models
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8151
EP  - 8157
AU  - D. Agudelo-España
AU  - A. Zadaianchuk
AU  - P. Wenk
AU  - A. Garg
AU  - J. Akpo
AU  - F. Grimminger
AU  - J. Viereck
AU  - M. Naveau
AU  - L. Righetti
AU  - G. Martius
AU  - A. Krause
AU  - B. Schölkopf
AU  - S. Bauer
AU  - M. Wüthrich
PY  - 2020
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - optimal control
KW  - robot dynamics
KW  - robust control
KW  - trajectory control
KW  - learned dynamics models
KW  - model based reinforcement learning
KW  - robust current dynamics learning
KW  - real robot dataset
KW  - transferability assessment
KW  - 3 degrees of freedom robot trajectories
KW  - optimal control
KW  - robotic learning
KW  - Trajectory
KW  - Robots
KW  - Artificial neural networks
KW  - Heuristic algorithms
KW  - Mathematical model
KW  - Torque measurement
DO  - 10.1109/ICRA40945.2020.9197392
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In the context of model-based reinforcement learning and control, a large number of methods for learning system dynamics have been proposed in recent years. The purpose of these learned models is to synthesize new control policies. An important open question is how robust current dynamics-learning methods are to shifts in the data distribution due to changes in the control policy. We present a real-robot dataset which allows to systematically investigate this question. This dataset contains trajectories of a 3 degrees-of-freedom (DOF) robot being controlled by a diverse set of policies. For comparison, we also provide a simulated version of the dataset. Finally, we benchmark a few widely-used dynamics-learning methods using the proposed dataset. Our results show that the iid test error of a learned model is not necessarily a good indicator of its accuracy under control policies different from the one which generated the training data. This suggests that it may be important to evaluate dynamics-learning methods in terms of their transfer performance, rather than only their iid error.
ER  - 

TY  - CONF
TI  - MagNet: Discovering Multi-agent Interaction Dynamics using Neural Network
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8158
EP  - 8164
AU  - P. Saha
AU  - A. Ali
AU  - B. A. Mudassar
AU  - Y. Long
AU  - S. Mukhopadhyay
PY  - 2020
KW  - differential equations
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - neural nets
KW  - synchronisation
KW  - agents change
KW  - point-mass system
KW  - Kuramoto phase synchronization dynamics
KW  - predator-swarm interaction dynamics
KW  - multiagent interaction dynamics
KW  - neural network-based multiagent interaction model
KW  - governing dynamics
KW  - complex multiagent system
KW  - nonlinear network
KW  - generic ordinary differential equation based state evolution
KW  - neural network-based realization
KW  - time-discretized model
KW  - core dynamics
KW  - agent-specific parameters
KW  - MagNet
KW  - traditional deep learning models
KW  - Mathematical model
KW  - Magnetic cores
KW  - Multi-agent systems
KW  - Force
KW  - Training
KW  - Springs
KW  - Oscillators
DO  - 10.1109/ICRA40945.2020.9196846
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present the MagNet, a neural network-based multi-agent interaction model to discover the governing dynamics and predict evolution of a complex multi-agent system from observations. We formulate a multi-agent system as a coupled non-linear network with a generic ordinary differential equation (ODE) based state evolution, and develop a neural network-based realization of its time-discretized model. MagNet is trained to discover the core dynamics of a multi-agent system from observations, and tuned on-line to learn agent-specific parameters of the dynamics to ensure accurate prediction even when physical or relational attributes of agents, or number of agents change. We evaluate MagNet on a point-mass system in two-dimensional space, Kuramoto phase synchronization dynamics and predator-swarm interaction dynamics demonstrating orders of magnitude improvement in prediction accuracy over traditional deep learning models.
ER  - 

TY  - CONF
TI  - Development of a Robotic System for Automated Decaking of 3D-Printed Parts
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8202
EP  - 8208
AU  - H. Nguyen
AU  - N. Adrian
AU  - J. L. Xin Yan
AU  - J. M. Salfity
AU  - W. Allen
AU  - Q. -C. Pham
PY  - 2020
KW  - force control
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - path planning
KW  - production engineering computing
KW  - three-dimensional printing
KW  - industrial robots
KW  - robotic decaking
KW  - automated decaking
KW  - 3D printed parts
KW  - 3D printing based mass manufacturing
KW  - smart mechanical design
KW  - motion planning
KW  - force control
KW  - deep learning
KW  - Powders
KW  - Cleaning
KW  - Service robots
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Force control
KW  - deep learning
KW  - manipulation
KW  - system design
KW  - 3D-printing
KW  - decaking
DO  - 10.1109/ICRA40945.2020.9197110
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - With the rapid rise of 3D-printing as a competitive mass manufacturing method, manual "decaking" - i.e. removing the residual powder that sticks to a 3D-printed part - has become a significant bottleneck. Here, we introduce, for the first time to our knowledge, a robotic system for automated decaking of 3D-printed parts. Combining Deep Learning for 3D perception, smart mechanical design, motion planning, and force control for industrial robots, we developed a system that can automatically decake parts in a fast and efficient way. Through a series of decaking experiments performed on parts printed by a Multi Jet Fusion printer, we demonstrated the feasibility of robotic decaking for 3D-printing-based mass manufacturing.
ER  - 

TY  - CONF
TI  - A Novel Solar Tracker Driven by Waves: From Idea to Implementation*
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8209
EP  - 8214
AU  - R. Xu
AU  - H. Liu
AU  - C. Liu
AU  - Z. Sun
AU  - T. L. Lam
AU  - H. Qian
PY  - 2020
KW  - attitude control
KW  - power generation control
KW  - solar cell arrays
KW  - solar power stations
KW  - solar tracker
KW  - solar panels
KW  - ocean environment
KW  - electromagnetic brakes
KW  - dynamic model
KW  - angular acceleration
KW  - control algorithm
KW  - real water surface
KW  - time 28.0 s
KW  - Solar panels
KW  - Brakes
KW  - Oceans
KW  - DC motors
KW  - Sun
KW  - Solar energy
KW  - Attitude control
DO  - 10.1109/ICRA40945.2020.9196998
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Traditional solar trackers often adopt motors to automatically adjust the attitude of the solar panels towards the sun for maximum power efficiency. In this paper, a novel design of solar tracker for the ocean environment is introduced. Utilizing the fluctuations due to the waves, electromagnetic brakes are utilized instead of motors to adjust the attitude of the solar panels. Compared with the traditional solar trackers, the proposed one is simpler in hardware while the harvesting efficiency is similar. The desired attitude is calculated out of the local location and time. Then based on the dynamic model of the system, the angular acceleration of the solar panels is estimated and a control algorithm is proposed to decide the release and lock states of the brakes. In such a manner, the adjustment of the attitude of the solar panels can be achieved by using two brakes only. Experiments are conducted to validate the acceleration estimator and the dynamic model. At last, the feasibility of the proposed solar tracker is tested on the real water surface. The results show that the system is able to adjust 40° in two dimensions within 28 seconds.
ER  - 

TY  - CONF
TI  - Design and Implementation of Hydraulic-Cable driven Manipulator for Disaster Response Operation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8215
EP  - 8221
AU  - J. Kim
AU  - J. Seo
AU  - S. Park
AU  - S. Han
AU  - J. Cho
PY  - 2020
KW  - emergency management
KW  - hydraulic actuators
KW  - manipulators
KW  - motion control
KW  - rescue robots
KW  - hydraulic-cable driven actuation modules
KW  - 3DOF manipulator
KW  - hydraulic actuation system
KW  - disaster response mobile-manipulation
KW  - disaster response operation
KW  - hydraulic-cable driven manipulator
KW  - Manipulators
KW  - Blades
KW  - Actuators
KW  - Hydraulic systems
KW  - Torque
KW  - Wires
DO  - 10.1109/ICRA40945.2020.9196554
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper introduces a new hydraulic manipulator with hydraulic-cable driven actuation (HCA) modules for disaster response mobile-manipulation. The hydraulic actuation system has the potential to apply disaster-response application, because it has a higher power-to-weight ratio and robustness to external impacts than electric motor actuation. However, using a conventional hydraulic manipulators is inappropriate because the revolute joint uses conventional actuators, such as linear cylinders and vanes, which have some limitations: 1) linear cylinder: small range of motion, 2) vane: low torque-toweight ratio. To overcome these limitations, we propose new 3DOF manipulator which has a larger workspace than the conventional hydraulic manipulator and comparable payloadto-weight ratio. To this end, we use hydraulic-cable driven actuation modules from our previous research. Experimental results verify the basic performance of the actuator modules and manipulator and their capability to perform various disaster response tasks.
ER  - 

TY  - CONF
TI  - Designs for an Expressive Mechatronic Chordophone
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8222
EP  - 8228
AU  - J. P. Yepez Placencia
AU  - D. A. Carnegie
AU  - J. W. Murphy
PY  - 2020
KW  - hearing
KW  - mechatronics
KW  - music
KW  - musical instruments
KW  - technical exploration
KW  - timbral exploration
KW  - mechatronic chordophones
KW  - musical robotics
KW  - stand-alone instruments
KW  - sound art installations
KW  - expressive potential
KW  - plucked strings
KW  - expressive mechatronic mono-chord
KW  - polystring chordophone
KW  - expressive mechatronic chordophone
KW  - sound generation model
KW  - Mechatronics
KW  - Instruments
KW  - Music
KW  - Actuators
KW  - Robots
KW  - Prototypes
KW  - Solenoids
DO  - 10.1109/ICRA40945.2020.9197255
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Plucked strings are an exciting sound generation model for technical and timbral exploration. Mechatronic chordophones take advantage of this model and have been the focus of extensive research and exploration in musical robotics, often used as stand-alone instruments or as part of sound art installations. However, no existing chordophone designs have utilised the expressive potential of plucked strings to their full extent.In this paper, we introduce an expressive mechatronic mono-chord that serves as a prototyping platform for the construction of a polystring chordophone. This new chordophone has been developed to offer enhanced dynamic range, fast picking speeds, fast pitch shifter displacement, and additional expressive techniques compared to existing systems.
ER  - 

TY  - CONF
TI  - OmBURo: A Novel Unicycle Robot with Active Omnidirectional Wheel
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8237
EP  - 8243
AU  - J. Shen
AU  - D. Hong
PY  - 2020
KW  - mechanical stability
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - robot dynamics
KW  - wheels
KW  - human environments
KW  - ideal locomotion mechanism
KW  - omnidirectional balancing unicycle robot
KW  - mobility mechanism
KW  - OmBURo
KW  - agile mobility
KW  - compact structure
KW  - active omnidirectional wheel
KW  - Wheels
KW  - Mobile robots
KW  - Gears
KW  - Friction
KW  - Mathematical model
KW  - Energy loss
DO  - 10.1109/ICRA40945.2020.9196927
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - A mobility mechanism for robots to be used in tight spaces shared with people requires it to have a small footprint, to move omnidirectionally, as well as to be highly maneuverable. However, currently there exist few such mobility mechanisms that satisfy all these conditions well. Here we introduce Omnidirectional Balancing Unicycle Robot (OmBURo), a novel unicycle robot with active omnidirectional wheel. The effect is that the unicycle robot can drive in both longitudinal and lateral directions simultaneously. Thus, it can dynamically balance itself based on the principle of dual-axis wheeled inverted pendulum. This paper discloses the early development of this novel unicycle robot involving the overall design, modeling, and control, as well as presents some preliminary results including station keeping and path following. With its very compact structure and agile mobility, it might be the ideal locomotion mechanism for robots to be used in human environments in the future.
ER  - 

TY  - CONF
TI  - Recognition and Reconfiguration of Lattice-Based Cellular Structures by Simple Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8252
EP  - 8259
AU  - E. Niehs
AU  - A. Schmidt
AU  - C. Scheffer
AU  - D. E. Biediger
AU  - M. Yannuzzi
AU  - B. Jenett
AU  - A. Abdel-Rahman
AU  - K. C. Cheung
AU  - A. T. Becker
AU  - S. P. Fekete
PY  - 2020
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - flexibility
KW  - cellular components
KW  - robust robots
KW  - cellular building materials
KW  - arbitrary cellular structures
KW  - cellular materials
KW  - lattice-based cellular structures
KW  - Tiles
KW  - Robot sensing systems
KW  - Lattices
KW  - Shape
KW  - Autonomous robots
DO  - 10.1109/ICRA40945.2020.9196700
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We consider recognition and reconfiguration of lattice-based cellular structures by very simple robots with only basic functionality. The underlying motivation is the construction and modification of space facilities of enormous dimensions, where the combination of new materials with extremely simple robots promises structures of previously unthinkable size and flexibility; this is also closely related to the newly emerging field of programmable matter. Aiming for large-scale scalability, both in terms of the number of the cellular components of a structure, as well as the number of robots that are being deployed for construction requires simple yet robust robots and mechanisms, while also dealing with various basic constraints, such as connectivity of a structure during reconfiguration. To this end, we propose an approach that combines ultra-light, cellular building materials with extremely simple robots. We develop basic algorithmic methods that are able to detect and reconfigure arbitrary cellular structures, based on robots that have only constant-sized memory. As a proof of concept, we demonstrate the feasibility of this approach for specific cellular materials and robots that have been developed at NASA.
ER  - 

TY  - CONF
TI  - A Fast Configuration Space Algorithm for Variable Topology Truss Modular Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8260
EP  - 8266
AU  - C. Liu
AU  - S. Yu
AU  - M. Yim
PY  - 2020
KW  - collision avoidance
KW  - mobile robots
KW  - path planning
KW  - topology
KW  - fast configuration space algorithm
KW  - VTT
KW  - self-reconfigurable robot
KW  - truss shape
KW  - motion planning
KW  - shape changing actions
KW  - topology reconfiguration
KW  - geometry reconfiguration actions
KW  - cell decomposition approach
KW  - collision-free space
KW  - simple shape-morphing method
KW  - variable topology truss modular robot
KW  - Topology
KW  - Robots
KW  - Planning
KW  - Geometry
KW  - Shape
KW  - Kinematics
KW  - Actuators
DO  - 10.1109/ICRA40945.2020.9196880
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The Variable Topology Truss (VTT) is a new class of self-reconfigurable robot that can reconfigure its truss shape and topology depending on the task or environment requirements. Motion planning and avoiding self-collision are difficult as these systems usually have dozens of degrees-of-freedom with complex intersecting parallel actuation. There are two different types of shape changing actions for a VTT: geometry reconfiguration and topology reconfiguration. This paper focuses on the geometry reconfiguration actions. A new cell decomposition approach is presented based on a fast and complete method to compute the collision-free space of a node in a truss. A simple shape-morphing method is shown to quickly create motion paths for reconfiguration by moving one node at a time.
ER  - 

TY  - CONF
TI  - ModQuad-DoF: A Novel Yaw Actuation for Modular Quadrotors
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8267
EP  - 8273
AU  - B. Gabrich
AU  - G. Li
AU  - M. Yim
PY  - 2020
KW  - actuators
KW  - aerospace robotics
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - drag
KW  - helicopters
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - vehicle dynamics
KW  - ModQuad-DoF
KW  - modular quadrotors
KW  - robotic structure
KW  - enhanced capabilities
KW  - module design
KW  - freedom relative motion
KW  - flying robot
KW  - cage
KW  - docking mechanism
KW  - structure control authority
KW  - structure yaw control
KW  - yaw actuation method
DO  - 10.1109/ICRA40945.2020.9196735
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this work we introduce ModQuad-DoF, a modular flying robotic structure with enhanced capabilities for yaw actuation. We propose a new module design that allows a one degree of freedom relative motion between the flying robot and the cage, with a docking mechanism allowing rigid connections between cages. A novel method of yaw actuation that increases the structure control authority is also presented. Our new method for the structure yaw control relies on the independent roll angles of each one of the modules, instead of the traditional drag moments from the propellers. In this paper, we propose a controller that allows the ModQuad-DoF to control its position and attitude. In our experiments, we tested a different number of modules flying in cooperation and validated the novel yaw actuation method.
ER  - 

TY  - CONF
TI  - An Actuation Fault Tolerance Approach to Reconfiguration Planning of Modular Self-folding Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8274
EP  - 8280
AU  - M. Yao
AU  - X. Xiao
AU  - Y. Tian
AU  - H. Cui
AU  - J. Paik
PY  - 2020
KW  - actuators
KW  - fault tolerance
KW  - motion control
KW  - robots
KW  - fault tolerant reconfiguration
KW  - self-folding robots
KW  - modular system
KW  - complete actuation failure
KW  - active modules
KW  - imprecise robotic motion
KW  - reconfiguration failure
KW  - intra-module connection
KW  - reconfiguration schemes
KW  - user-specified fault tolerant capability
KW  - arbitrary input initial pattern
KW  - robotic platform
KW  - modular origami robot
KW  - fault tolerant initial patterns
KW  - actuation fault tolerance approach
KW  - reconfiguration planning
KW  - modular self-folding
KW  - Fault tolerance
KW  - Fault tolerant systems
KW  - Robots
KW  - Three-dimensional displays
KW  - Circuit faults
KW  - Shape
KW  - Planning
DO  - 10.1109/ICRA40945.2020.9196574
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents a novel approach to fault tolerant reconfiguration of modular self-folding robots. Among various types of faults that probably occur in the modular system, we focus on the tolerance of complete actuation failure of active modules that might cause imprecise robotic motion and even reconfiguration failure. Our approach is to utilize the reconfigurability of modular self-folding robots and investigate intra-module connection to determine initial patterns that are inherently fault tolerant. We exploit the redundancy of actuation and distribute active modules in both layout-based and target-based scenarios, such that reconfiguration schemes with user-specified fault tolerant capability can be generated for an arbitrary input initial pattern or 3D configuration. Our methods are demonstrated in computer-aided simulation on the robotic platform of Mori, a modular origami robot. The simulation results validate that the proposed algorithms yield fault tolerant initial patterns and distribution schemes of active modules for several 2D and 3D configurations with Mori, while retaining generalizability for a large number of modular self-folding robots.
ER  - 

TY  - CONF
TI  - Parallel Permutation for Linear Full-resolution Reconfiguration of Heterogeneous Sliding-only Cubic Modular Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8281
EP  - 8287
AU  - H. Kawano
PY  - 2020
KW  - computational complexity
KW  - evolutionary computation
KW  - motion control
KW  - robots
KW  - studied cubic modules
KW  - convex motion primitives
KW  - rotating motion primitives
KW  - heterogeneous reconfiguration algorithm
KW  - parallel heterogeneous permutation method
KW  - full-resolution reconfiguration algorithm
KW  - heterogeneous operations
KW  - space saving
KW  - module hardware
KW  - sliding-only motion primitive
KW  - cubic modular robot
KW  - cubic module
KW  - sliding-only cubic modular robots
KW  - parallel permutation algorithm
KW  - heterogeneous sliding-only cubic modular
KW  - linear full-resolution reconfiguration
KW  - linear operating-time cost
KW  - sliding-only cubic modules
KW  - robot structure
KW  - linear operating time cost
KW  - Navigation
KW  - Hardware
KW  - Robot kinematics
KW  - Shape
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/ICRA40945.2020.9197033
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents a parallel permutation algorithm that achieves linear full-resolution reconfiguration of sliding-only cubic modular robots. We assume the use of a cubic module that can only slide across other modules' surfaces. The idea of a cubic modular robot with sliding-only motion primitive is a new concept that has advantages in simplifying the mechanisms of module hardware and space saving in its heterogeneous operations compared with previously studied cubic modules, such as those with sliding and convex motion primitives, or rotating motion primitives. However, because of its limited mobility, there are difficulties in managing the connectivity and scalability of the heterogeneous reconfiguration algorithm for it. To overcome these disadvantages, we introduce a parallel heterogeneous permutation method with linear operating time cost that can be incorporated into our previous full-resolution reconfiguration algorithm. We prove the correctness and completeness of the proposed algorithm. Simulation results show that the full-resolution reconfiguration algorithm that incorporates the proposed permutation algorithm reconfigures the robot structure with sliding-only cubic modules in linear operating-time cost.
ER  - 

TY  - CONF
TI  - Determining and Improving the Localization Accuracy of AprilTag Detection
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8288
EP  - 8294
AU  - J. Kallwies
AU  - B. Forkel
AU  - H. -J. Wuensche
PY  - 2020
KW  - edge detection
KW  - feature extraction
KW  - image colour analysis
KW  - image matching
KW  - location based services
KW  - object detection
KW  - robot vision
KW  - software libraries
KW  - localization accuracy
KW  - AprilTag detection
KW  - fiducial markers
KW  - freely available libraries
KW  - AprilTag 3
KW  - ArUco
KW  - OpenCV algorithm
KW  - AprilTags C++
KW  - robotics
KW  - edge refinement
KW  - grayscale camera image
KW  - template matching
KW  - Cameras
KW  - C++ languages
KW  - Libraries
KW  - Robot vision systems
KW  - Calibration
KW  - Image edge detection
DO  - 10.1109/ICRA40945.2020.9197427
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Fiducial markers like AprilTags play an important role in robotics, e.g., for the calibration of cameras or the localization of robots. One of the most important properties of an algorithm for detecting such tags is its localization accuracy.In this paper, we present the results of an extensive comparison of four freely available libraries capable of detecting AprilTags, namely AprilTag 3, AprilTags C++, ArUco as standalone libraries, and the OpenCV algorithm based on ArUco. The focus of the comparison is on localization accuracy, but the processing time is also examined. Besides working with pure tags, their extension to checkerboard corners is investigated.In addition, we present two new post-processing techniques. Firstly, a method that can filter out very inaccurate detections resulting from partial border occlusion, and secondly a new highly accurate method for edge refinement. With this we achieve a median pixel error of 0.017 px, compared to 0.17 px for standard OpenCV corner refinement.The dataset used for the evaluation, as well as the developed post-processing techniques, are made publicly available to encourage further comparison and improvement of the detection libraries.
ER  - 

TY  - CONF
TI  - Change of Optimal Values: A Pre-calculated Metric
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8295
EP  - 8301
AU  - F. Bai
PY  - 2020
KW  - decision making
KW  - optimisation
KW  - linear least norm optimization problem
KW  - linear least distance optimization problems
KW  - nonlinear least distance optimization
KW  - optimal value
KW  - minimum norm optimization
KW  - Optimization
KW  - Measurement
KW  - Manifolds
KW  - Mathematical model
KW  - Robots
KW  - Covariance matrices
KW  - Gaussian distribution
DO  - 10.1109/ICRA40945.2020.9197163
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - A variety of optimization problems takes the form of a minimum norm optimization. In this paper, we study the change of optimal values between two incrementally constructed least norm optimization problems, with new measurements included in the second one. We prove an exact equation to calculate the change of optimal values in the linear least norm optimization problem. With the result in this paper, the change of the optimal values can be pre-calculated as a metric to guide online decision makings, without solving the second optimization problem as long the solution and covariance of the first optimization problem are available. The result can be extended to linear least distance optimization problems, and nonlinear least distance optimization with (nonlinear) equality constraints through linearizations. This derivation in this paper provides a theoretically sound explanation to the empirical observations shown in [1]. As an additional contribution, we propose another optimization problem, i.e. aligning two trajectories at given poses, to further demonstrate how to use the metric. The accuracy of the metric is validated with numerical examples, which is quite satisfactory in general (see the experiments in [1] as well), unless in some extremely adverse scenarios. Last but not least, calculating the optimal value by the proposed metric is at least one magnitude faster than solving the corresponding optimization problems directly.
ER  - 

TY  - CONF
TI  - A Flexible Method for Performance Evaluation of Robot Localization
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8302
EP  - 8308
AU  - S. Scheideman
AU  - N. Ray
AU  - H. Zhang
PY  - 2020
KW  - image motion analysis
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - robot localization
KW  - research issue
KW  - mobile robotics
KW  - performance assessment
KW  - robot SLAM algorithms
KW  - localization accuracy
KW  - SLAM algorithm
KW  - benchmark datasets
KW  - motion capture
KW  - environment-specific
KW  - spatial coverage
KW  - SLAM performance evaluation
KW  - distinctive markers
KW  - robot navigation environment
KW  - generative latent optimization problem
KW  - local robot-to-marker
KW  - global robot
KW  - Simultaneous localization and mapping
KW  - Navigation
KW  - Cameras
KW  - Performance evaluation
KW  - Robot localization
DO  - 10.1109/ICRA40945.2020.9197275
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - An important research issue in mobile robotics is performance assessment of robot SLAM algorithms in terms of their localization accuracy. Typically, SLAM algorithms are evaluated with the help of benchmark datasets or expensive equipment such as motion capture. Benchmark datasets however, are environment-specific, and use of motion capture constrains spatial coverage and affordability. In this paper, we present a novel method for SLAM performance evaluation, which only uses distinctive markers (such as AR tags), randomly placed in the robot navigation environment at arbitrary locations, and observes these markers with a camera onboard of the robot. Formulated as a generative latent optimization (GLO) problem, our method uses the local robot-to-marker poses to evaluate the global robot pose estimates by a SLAM algorithm and therefore its performance. Through extensive experiments on two robots, three localization/SLAM algorithms and both LiDAR and RGB-D sensors, we demonstrate the feasibility and accuracy of our proposed method.
ER  - 

TY  - CONF
TI  - Quantifying Good Seamanship For Autonomous Surface Vessel Performance Evaluation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8309
EP  - 8315
AU  - P. Stankiewicz
AU  - M. Heistand
AU  - M. Kobilarov
PY  - 2020
KW  - collision avoidance
KW  - decision making
KW  - marine safety
KW  - marine vehicles
KW  - mobile robots
KW  - remotely operated vehicles
KW  - ships
KW  - performance metrics
KW  - ASV decision-making
KW  - collision risk
KW  - ASV planning strategies
KW  - International Regulations for Prevention of Collisions at Sea
KW  - quantified good seamanship
KW  - COLREGS compliance
KW  - vessel interactions
KW  - autonomous surface vehicle decision-making
KW  - autonomous surface vessel performance evaluation
KW  - seamanship performance criteria
KW  - Marine vehicles
KW  - Safety
KW  - Geometry
KW  - Decision making
KW  - Navigation
KW  - Risk management
KW  - Planning
DO  - 10.1109/ICRA40945.2020.9197572
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The current state-of-the-art for testing and evaluation of autonomous surface vehicle (ASV) decision-making is currently limited to one-versus-one vessel interactions by determining compliance with the International Regulations for Prevention of Collisions at Sea, referred to as COLREGS. Strict measurement of COLREGS compliance, however, loses value in multi-vessel encounters, as there can be conflicting rules which make determining compliance extremely subjective. This work proposes several performance metrics to evaluate ASV decision-making based on the concept of "good seamanship," a practice which generalizes to multi-vessel encounters. Methodology for quantifying good seamanship is presented based on the criteria of reducing the overall collision risk of the situation and taking early, appropriate actions. Case study simulation results are presented to showcase the seamanship performance criteria against different ASV planning strategies.
ER  - 

TY  - CONF
TI  - Action-conditioned Benchmarking of Robotic Video Prediction Models: a Comparative Study
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8316
EP  - 8322
AU  - M. S. Nunes
AU  - A. Dehban
AU  - P. Moreno
AU  - J. Santos-Victor
PY  - 2020
KW  - Bayes methods
KW  - image sequences
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - video coding
KW  - video signal processing
KW  - action-conditioned benchmarking
KW  - robotic video prediction models
KW  - intelligent systems
KW  - video prediction systems
KW  - robot actions
KW  - video prediction models
KW  - frame quality
KW  - robot performs
KW  - action inference system
KW  - robot planning systems
KW  - Predictive models
KW  - Measurement
KW  - Visualization
KW  - Stochastic processes
KW  - Planning
KW  - Robot sensing systems
DO  - 10.1109/ICRA40945.2020.9196839
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - A defining characteristic of intelligent systems is the ability to make action decisions based on the anticipated outcomes. Video prediction systems have been demonstrated as a solution for predicting how the future will unfold visually, and thus, many models have been proposed that are capable of predicting future frames based on a history of observed frames (and sometimes robot actions). However, a comprehensive method for determining the fitness of different video prediction models at guiding the selection of actions is yet to be developed.Current metrics assess video prediction models based on human perception of frame quality. In contrast, we argue that if these systems are to be used to guide action, necessarily, the actions the robot performs should be encoded in the predicted frames. In this paper, we are proposing a new metric to compare different video prediction models based on this argument. More specifically, we propose an action inference system and quantitatively rank different models based on how well we can infer the robot actions from the predicted frames. Our extensive experiments show that models with high perceptual scores can perform poorly in the proposed action inference tests and thus, may not be suitable options to be used in robot planning systems.
ER  - 

TY  - CONF
TI  - LyRN (Lyapunov Reaching Network): A Real-Time Closed Loop approach from Monocular Vision
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8331
EP  - 8337
AU  - Z. Zhuang
AU  - X. Yu
AU  - R. Mahony
PY  - 2020
KW  - cameras
KW  - closed loop systems
KW  - convolutional neural nets
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - Lyapunov methods
KW  - manipulator dynamics
KW  - neurocontrollers
KW  - pose estimation
KW  - robot vision
KW  - velocity control
KW  - visual servoing
KW  - GTX 1080Ti GPU
KW  - grasping mugs
KW  - multiinstance control
KW  - real-time closed loop
KW  - LyRN
KW  - single shot RGB 6D pose estimation
KW  - complex multiinstance task
KW  - reaching action
KW  - control Lyapunov function
KW  - learning principles
KW  - visually guided reaching
KW  - Lyapunov reaching network
KW  - pose-based-visual-servo grasping system
KW  - closed-loop control
KW  - over-the-shoulder monocular RGB camera
KW  - multiinstance capability
KW  - visual control
KW  - velocity control
KW  - deep convolution neural network
KW  - manipulator joint angles
KW  - monocular vision
KW  - reaching points
KW  - frequency 85.0 Hz
KW  - Lyapunov methods
KW  - Grasping
KW  - Feature extraction
KW  - Computer architecture
KW  - Task analysis
KW  - Pose estimation
KW  - Velocity control
DO  - 10.1109/ICRA40945.2020.9196781
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We propose a closed-loop, multi-instance control algorithm for visually guided reaching based on novel learning principles. A control Lyapunov function methodology is used to design a reaching action for a complex multi-instance task in the case where full state information (poses of all potential reaching points) is available. The proposed algorithm uses monocular vision and manipulator joint angles as the input to a deep convolution neural network to predict the value of the control Lyapunov function (cLf) and corresponding velocity control. The resulting network output is used in real-time as visual control for the grasping task with the multi-instance capability emerging naturally from the design of the control Lyapunov function. We demonstrate the proposed algorithm grasping mugs (textureless and symmetric objects) on a table-top from an over-the-shoulder monocular RGB camera. The manipulator dynamically converges to the best-suited target among multiple identical instances from any random initial pose within the workspace. The system trained with only simulated data is able to achieve 90.3% grasp success rate in the real-world experiments with up to 85Hz closed-loop control on one GTX 1080Ti GPU and significantly outperforms a Pose-Based-Visual-Servo (PBVS) grasping system adapted from a state-of-the-art single shot RGB 6D pose estimation algorithm. A key contribution of the paper is the inclusion of a first-order differential constraint associated with the cLf as a regularisation term during learning, and we provide evidence that this leads to more robust and reliable reaching/grasping performance than vanilla regression on general control inputs.
ER  - 

TY  - CONF
TI  - Object Finding in Cluttered Scenes Using Interactive Perception
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8338
EP  - 8344
AU  - T. Novkovic
AU  - R. Pautrat
AU  - F. Furrer
AU  - M. Breyer
AU  - R. Siegwart
AU  - J. Nieto
PY  - 2020
KW  - cameras
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - object recognition
KW  - robot vision
KW  - search problems
KW  - object finding
KW  - cases physical interaction
KW  - target object
KW  - complex environment
KW  - object search
KW  - cluttered scenes interactions
KW  - reinforcement learning based active perception system
KW  - reinforcement learning based interactive perception system
KW  - robotic manipulator
KW  - RGB
KW  - depth camera
KW  - Cameras
KW  - Task analysis
KW  - Robot sensing systems
KW  - Search problems
KW  - Clutter
KW  - Detectors
DO  - 10.1109/ICRA40945.2020.9197101
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Object finding in clutter is a skill that requires perception of the environment and in many cases physical interaction. In robotics, interactive perception defines a set of algorithms that leverage actions to improve the perception of the environment, and vice versa use perception to guide the next action. Scene interactions are difficult to model, therefore, most of the current systems use predefined heuristics. This limits their ability to efficiently search for the target object in a complex environment. In order to remove heuristics and the need for explicit models of the interactions, in this work we propose a reinforcement learning based active and interactive perception system for scene exploration and object search. We evaluate our work both in simulated and in real-world experiments using a robotic manipulator equipped with an RGB and a depth camera, and compare our system to two baselines. The results indicate that our approach, trained in simulation only, transfers smoothly to reality and can solve the object finding task efficiently and with more than 88% success rate.
ER  - 

TY  - CONF
TI  - CCAN: Constraint Co-Attention Network for Instance Grasping
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8353
EP  - 8359
AU  - J. Cai
AU  - X. Tao
AU  - H. Cheng
AU  - Z. Zhang
PY  - 2020
KW  - dexterous manipulators
KW  - feature extraction
KW  - grippers
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - query image
KW  - soft constraints
KW  - workspace image
KW  - grasp configuration
KW  - CCAN
KW  - instance grasping
KW  - learning-based method
KW  - constraint co-attention module
KW  - constraint co-attention network
KW  - robotic grasping task
KW  - end-to-end instance grasping method
KW  - grasp affordance predictor
KW  - Feature extraction
KW  - Grasping
KW  - Training
KW  - Task analysis
KW  - Robots
KW  - Data mining
KW  - Correlation
DO  - 10.1109/ICRA40945.2020.9197182
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Instance grasping is a challenging robotic grasping task when a robot aims to grasp a specified target object in cluttered scenes. In this paper, we propose a novel end-to-end instance grasping method using only monocular workspace and query images, where the workspace image includes several objects and the query image only contains the target object. To effectively extract discriminative features and facilitate the training process, a learning-based method, referred to as Constraint Co-Attention Network (CCAN), is proposed which consists of a constraint co-attention module and a grasp affordance predictor. An effective co-attention module is presented to construct the features of a workspace image from the extracted features of the query image. By introducing soft constraints into the co-attention module, it highlights the target object's features while trivializes other objects' features in the workspace image. Using the features extracted from the co-attention module, the cascaded grasp affordance interpreter network only predicts the grasp configuration for the target object. The training of the CCAN is totally based on simulated self-supervision. Extensive qualitative and quantitative experiments show the effectiveness of our method both in simulated and real-world environments even for totally unseen objects.
ER  - 

TY  - CONF
TI  - 3D Object Detection and Tracking Based on Streaming Data
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8376
EP  - 8382
AU  - X. Guo
AU  - J. Gu
AU  - S. Guo
AU  - Z. Xu
AU  - C. Yang
AU  - S. Liu
AU  - L. Cheng
AU  - K. Huang
PY  - 2020
KW  - data analysis
KW  - image motion analysis
KW  - interpolation
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - object tracking
KW  - data streaming
KW  - temporal information
KW  - 3D streaming based object detection
KW  - nonkey frames
KW  - motion based interpolation algorithm
KW  - frame-by-frame paradigm
KW  - KITTI object tracking benchmark
KW  - deep learning
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Proposals
KW  - Object detection
KW  - Prediction algorithms
KW  - Correlation
KW  - Agriculture
DO  - 10.1109/ICRA40945.2020.9197183
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Recent approaches for 3D object detection have made tremendous progresses due to the development of deep learning. However, previous researches are mostly based on individual frames, leading to limited exploitation of information between frames. In this paper, we attempt to leverage the temporal information in streaming data and explore 3D streaming based object detection as well as tracking. Toward this goal, we set up a dual-way network for 3D object detection based on keyframes, and then propagate predictions to non-key frames through a motion based interpolation algorithm guided by temporal information. Our framework is not only shown to have significant improvements on object detection compared with frame-by-frame paradigm, but also proven to produce competitive results on KITTI Object Tracking Benchmark, with 76.68% in MOTA and 81.65% in MOTP respectively.
ER  - 

TY  - CONF
TI  - Object-Centric Stereo Matching for 3D Object Detection
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8383
EP  - 8389
AU  - A. D. Pon
AU  - J. Ku
AU  - C. Li
AU  - S. L. Waslander
PY  - 2020
KW  - cameras
KW  - image matching
KW  - object detection
KW  - optical radar
KW  - pose estimation
KW  - stereo image processing
KW  - LiDAR-based 3D object detector
KW  - object point clouds
KW  - object-centric stereo matching method
KW  - 3D object detection
KW  - stereo cameras
KW  - LiDAR sensor
KW  - stereo 3D object detection
KW  - PSMNet stereo matching network
KW  - 6 DoF pose
KW  - 2D box association
KW  - Three-dimensional displays
KW  - Object detection
KW  - Two dimensional displays
KW  - Laser radar
KW  - Detectors
KW  - Cameras
KW  - Shape
DO  - 10.1109/ICRA40945.2020.9196660
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Safe autonomous driving requires reliable 3D object detection-determining the 6 DoF pose and dimensions of objects of interest. Using stereo cameras to solve this task is a cost-effective alternative to the widely used LiDAR sensor. The current state-of-the-art for stereo 3D object detection takes the existing PSMNet stereo matching network, with no modifications, and converts the estimated disparities into a 3D point cloud, and feeds this point cloud into a LiDAR-based 3D object detector. The issue with existing stereo matching networks is that they are designed for disparity estimation, not 3D object detection; the shape and accuracy of object point clouds are not the focus. Stereo matching networks commonly suffer from inaccurate depth estimates at object boundaries, which we define as streaking, because background and foreground points are jointly estimated. Existing networks also penalize disparity instead of the estimated position of object point clouds in their loss functions. We propose a novel 2D box association and object-centric stereo matching method that only estimates the disparities of the objects of interest to address these two issues. Our method achieves state-of-the-art results on the KITTI 3D and BEV benchmarks.
ER  - 

TY  - CONF
TI  - The Relative Confusion Matrix, a Tool to Assess Classifiablility in Large Scale Picking Applications
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8390
EP  - 8396
AU  - A. Balasch
AU  - M. Beinhofer
AU  - G. Zauner
PY  - 2020
KW  - image classification
KW  - industrial robots
KW  - logistics
KW  - materials handling equipment
KW  - robot vision
KW  - warehousing
KW  - relative confusion matrix
KW  - mixed-product bin
KW  - robot workstation
KW  - manual picking station
KW  - bin picking robot
KW  - logistics installations
KW  - warehouse
KW  - image dataset
KW  - Robots
KW  - Measurement
KW  - Task analysis
KW  - Reliability
KW  - Tools
KW  - Logistics
KW  - Workstations
DO  - 10.1109/ICRA40945.2020.9197540
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - For bin picking robots in real logistics installations, the certainty of picking the correct product out of a mixed-product bin is essential. This paper proposes an approach for the robot to efficiently decide whether it can robustly distinguish the product to pick from the others in the bin. If not, the pick has to be routed not to the robot workstation but to a manual picking station. For this, we introduce a modified version of the confusion matrix, which we call the relative confusion matrix. We show how this matrix can be used to make the required decision, taking into account that all other products in the warehouse can be logically ruled out as they are not contained in the bin. Considering only this subset of products would require a re-computation of the standard confusion matrix. With the relative confusion matrix, no such re-computation is needed, which makes our approach more efficient. We show the usefulness of our approach in extensive experiments with a real bin picking robot, on simulated data, and on a publicly available image dataset.
ER  - 

TY  - CONF
TI  - Pose-guided Auto-Encoder and Feature-Based Refinement for 6-DoF Object Pose Regression
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8397
EP  - 8403
AU  - Z. Li
AU  - X. Ji
PY  - 2020
KW  - computer vision
KW  - feature extraction
KW  - image colour analysis
KW  - neural nets
KW  - pose estimation
KW  - regression analysis
KW  - pose estimation performance
KW  - pose-irrelevant factors
KW  - encoding process
KW  - suitable pose representation
KW  - regression approaches
KW  - single RGB image
KW  - 6-DoF object Pose regression
KW  - Feature-based refinement
KW  - Pose-guided Auto-Encoder
KW  - direct regression-based approaches
KW  - PAE
KW  - Feature-based Pose Refiner
KW  - Feature extraction
KW  - Pose estimation
KW  - Three-dimensional displays
KW  - Training
KW  - Rendering (computer graphics)
KW  - Image reconstruction
KW  - Decoding
DO  - 10.1109/ICRA40945.2020.9196953
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Accurately estimating the 6-DoF object pose from a single RGB image is a challenging task in computer vision. Though pose regression approaches have achieved great progress, the performance is still limited. In this work, we propose Pose-guided Auto-Encoder (PAE), which can distill better pose-related features from the image by utilizing a suitable pose representation, 3D Location Field (3DLF), to guide the encoding process. The features from PAE show strong robustness to pose-irrelevant factors. Compared with traditional auto-encoder, PAE can not only improve the pose estimation performance but also handle the ambiguity viewpoints problem. Further, we propose Feature-based Pose Refiner (FPR), which refines the pose from the extracted features without rendering. Combining PAE with FPR, our approach achieved state-of-the-art performance on the widely used LINEMOD dataset. Our approach not only outperforms the direct regression-based approaches with a large margin but also thrillingly surpasses current state-of-the-art indirect PnP-based approach.
ER  - 

TY  - CONF
TI  - PrimiTect: Fast Continuous Hough Voting for Primitive Detection
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8404
EP  - 8410
AU  - C. Sommer
AU  - Y. Sun
AU  - E. Bylow
AU  - D. Cremers
PY  - 2020
KW  - computational geometry
KW  - feature extraction
KW  - Hough transforms
KW  - object detection
KW  - data abstraction
KW  - geometric primitives
KW  - compact representation
KW  - PrimiTect
KW  - fast continuous Hough voting
KW  - primitive detection
KW  - 3D point sets
KW  - semiglobal Hough voting scheme
KW  - robotics applications
KW  - local low-dimensional parameterization
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Interpolation
KW  - Two dimensional displays
KW  - Transforms
KW  - Computational modeling
KW  - Shape
DO  - 10.1109/ICRA40945.2020.9196988
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper tackles the problem of data abstraction in the context of 3D point sets. Our method classifies points into different geometric primitives, such as planes and cones, leading to a compact representation of the data. Being based on a semi-global Hough voting scheme, the method does not need initialization and is robust, accurate, and efficient. We use a local, low-dimensional parameterization of primitives to determine type, shape and pose of the object that a point belongs to. This makes our algorithm suitable to run on devices with low computational power, as often required in robotics applications. The evaluation shows that our method outperforms state-of-the-art methods both in terms of accuracy and robustness.
ER  - 

TY  - CONF
TI  - FarSee-Net: Real-Time Semantic Segmentation by Efficient Multi-scale Context Aggregation and Feature Space Super-resolution
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8411
EP  - 8417
AU  - Z. Zhang
AU  - K. Zhang
PY  - 2020
KW  - convolutional neural nets
KW  - feature extraction
KW  - image resolution
KW  - image sampling
KW  - image segmentation
KW  - object detection
KW  - real-time systems
KW  - robot vision
KW  - feature space superresolution
KW  - FarSee-Net
KW  - real time semantic segmentation
KW  - cascaded factorized atrous spatial pyramid pooling
KW  - feature maps
KW  - convolutional neural networks
KW  - multiscale context aggregation
KW  - object scale variations
KW  - robotic applications
KW  - subsampled image
KW  - Semantics
KW  - Convolution
KW  - Image segmentation
KW  - Feature extraction
KW  - Real-time systems
KW  - Spatial resolution
DO  - 10.1109/ICRA40945.2020.9196599
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Real-time semantic segmentation is desirable in many robotic applications with limited computation resources. One challenge of semantic segmentation is to deal with the object scale variations and leverage the context. How to perform multi-scale context aggregation within limited computation budget is important. In this paper, firstly, we introduce a novel and efficient module called Cascaded Factorized Atrous Spatial Pyramid Pooling (CF-ASPP). It is a lightweight cas-caded structure for Convolutional Neural Networks (CNNs) to efficiently leverage context information. On the other hand, for runtime efficiency, state-of-the-art methods will quickly decrease the spatial size of the inputs or feature maps in the early network stages. The final high-resolution result is usually obtained by non-parametric up-sampling operation (e.g. bilinear interpolation). Differently, we rethink this pipeline and treat it as a super-resolution process. We use optimized super-resolution operation in the up-sampling step and improve the accuracy, especially in sub-sampled input image scenario for real-time applications. By fusing the above two improvements, our methods provide better latency-accuracy trade-off than the other state-of-the-art methods. In particular, we achieve 68.4% mIoU at 84 fps on the Cityscapes test set with a single Nivida Titan X (Maxwell) GPU card. The proposed module can be plugged into any feature extraction CNN and benefits from the CNN structure development.
ER  - 

TY  - CONF
TI  - Learning 3D-aware Egocentric Spatial-Temporal Interaction via Graph Convolutional Networks
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8418
EP  - 8424
AU  - C. Li
AU  - Y. Meng
AU  - S. H. Chan
AU  - Y. -T. Chen
PY  - 2020
KW  - computer vision
KW  - convolutional neural nets
KW  - driver information systems
KW  - feature extraction
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - road traffic
KW  - road vehicles
KW  - graph convolutional networks
KW  - intelligent automated driving systems
KW  - complicated driving situations
KW  - spatial-temporal interaction framework
KW  - graph convolution networks
KW  - GCN
KW  - interaction modeling
KW  - ego-stuff interaction
KW  - Honda research institute driving dataset
KW  - 3D-aware egocentric spatial-temporal interaction learning
KW  - tactical driver behavior annotations
KW  - ego-thing interactions
KW  - feature extraction
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Roads
KW  - Hidden Markov models
KW  - Vehicles
KW  - Two dimensional displays
KW  - Convolution
DO  - 10.1109/ICRA40945.2020.9197057
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - To enable intelligent automated driving systems, a promising strategy is to understand how human drives and interacts with road users in complicated driving situations. In this paper, we propose a 3D-aware egocentric spatial-temporal interaction framework for automated driving applications. Graph convolution networks (GCN) is devised for interaction modeling. We introduce three novel concepts into GCN. First, we decompose egocentric interactions into ego-thing and ego- stuff interaction, modeled by two GCNs. In both GCNs, ego nodes are introduced to encode the interaction between thing objects (e.g., car and pedestrian), and interaction between stuff objects (e.g., lane marking and traffic light). Second, objects' 3D locations are explicitly incorporated into GCN to better model egocentric interactions. Third, to implement ego-stuff interaction in GCN, we propose a MaskAlign operation to extract features for irregular objects.We validate the proposed framework on tactical driver behavior recognition. Extensive experiments are conducted using Honda Research Institute Driving Dataset, the largest dataset with diverse tactical driver behavior annotations. Our framework demonstrates substantial performance boost over baselines on the two experimental settings by 3.9% and 6.0%, respectively. Furthermore, we visualize the learned affinity matrices, which encode ego-thing and ego-stuff interactions, to showcase the proposed framework can capture interactions effectively.
ER  - 

TY  - CONF
TI  - C-3PO: Cyclic-Three-Phase Optimization for Human-Robot Motion Retargeting based on Reinforcement Learning
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8425
EP  - 8432
AU  - T. Kim
AU  - J. -H. Lee
PY  - 2020
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - human-robot motion retargeting
KW  - kinematic configurations
KW  - kinematic independent general solution
KW  - three-phase optimization method
KW  - deep reinforcement learning
KW  - motion retargeting learning
KW  - motion retargeting policy
KW  - motion retargeting skill
KW  - human skeleton
KW  - cyclic-three-phase optimization
KW  - NAO robot
KW  - Pepper robot
KW  - Baxter robot
KW  - C-3PO robot
KW  - Skeleton
KW  - Robot motion
KW  - Robot kinematics
KW  - Kinematics
KW  - Zirconium
KW  - Torso
DO  - 10.1109/ICRA40945.2020.9196948
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Motion retargeting between heterogeneous polymorphs with different sizes and kinematic configurations requires a comprehensive knowledge of (inverse) kinematics. Moreover, it is non-trivial to provide a kinematic independent general solution. In this study, we developed a cyclic three-phase optimization method based on deep reinforcement learning for human-robot motion retargeting. The motion retargeting learning is performed using refined data in a latent space by the cyclic and filtering paths of our method. In addition, the human- in-the-loop based three-phase approach provides a framework for the improvement of the motion retargeting policy by both quantitative and qualitative manners. Using the proposed C- 3PO method, we were successfully able to learn the motion retargeting skill between the human skeleton and motion of the multiple robots such as NAO, Pepper, Baxter and C-3PO.
ER  - 

TY  - CONF
TI  - AP-MTL: Attention Pruned Multi-task Learning Model for Real-time Instrument Detection and Segmentation in Robot-assisted Surgery
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8433
EP  - 8439
AU  - M. Islam
AU  - V. S. Vibashan
AU  - H. Ren
PY  - 2020
KW  - endoscopes
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - medical robotics
KW  - robot vision
KW  - surgery
KW  - attention pruned multitask learning model
KW  - real-time instrument detection
KW  - robot-assisted surgery
KW  - image-guided robotic surgery
KW  - real-time robotic system
KW  - weight-shared encoder
KW  - task-aware detection
KW  - asynchronous task-aware optimization
KW  - robotic instrument segmentation dataset
KW  - end-to-end trainable realtime multitask learning model
KW  - global attention dynamic pruning
KW  - skip squeeze and excitation module
KW  - Task analysis
KW  - Instruments
KW  - Decoding
KW  - Real-time systems
KW  - Computational modeling
KW  - Optimization
KW  - Surgery
DO  - 10.1109/ICRA40945.2020.9196905
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Surgical scene understanding and multi-tasking learning are crucial for image-guided robotic surgery. Training a real-time robotic system for the detection and segmentation of high-resolution images provides a challenging problem with the limited computational resource. The perception drawn can be applied in effective real-time feedback, surgical skill assessment, and human-robot collaborative surgeries to enhance surgical outcomes. For this purpose, we develop a novel end-to-end trainable real-time Multi-Task Learning (MTL) model with weight-shared encoder and task-aware detection and segmentation decoders. Optimization of multiple tasks at the same convergence point is vital and presents a complex problem. Thus, we propose an asynchronous task-aware optimization (ATO) technique to calculate task-oriented gradients and train the decoders independently. Moreover, MTL models are always computationally expensive, which hinder real-time applications. To address this challenge, we introduce a global attention dynamic pruning (GADP) by removing less significant and sparse parameters. We further design a skip squeeze and excitation (SE) module, which suppresses weak features, excites significant features and performs dynamic spatial and channel-wise feature re-calibration. Validating on the robotic instrument segmentation dataset of MICCAI endoscopic vision challenge, our model significantly outperforms state-of-the-art segmentation and detection models, including best-performed models in the challenge.
ER  - 

TY  - CONF
TI  - Automatic Gesture Recognition in Robot-assisted Surgery with Reinforcement Learning and Tree Search
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8440
EP  - 8446
AU  - X. Gao
AU  - Y. Jin
AU  - Q. Dou
AU  - P. -A. Heng
PY  - 2020
KW  - gesture recognition
KW  - image classification
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - neural nets
KW  - surgery
KW  - tree searching
KW  - video signal processing
KW  - video surveillance
KW  - joint surgical gesture segmentation
KW  - tree search algorithm
KW  - neural networks design
KW  - reinforcement learning framework
KW  - surgical robotic applications
KW  - surgical video classification
KW  - baseline methods
KW  - JIGSAWS dataset
KW  - surgery surveillance
KW  - automatic surgical gesture recognition
KW  - robot-assisted surgery
KW  - Surgery
KW  - Gesture recognition
KW  - Robots
KW  - Hidden Markov models
KW  - Learning (artificial intelligence)
KW  - Feature extraction
KW  - Task analysis
KW  - Surgical gesture recognition
KW  - Deep reinforcement learning in robotics
KW  - Tree search
KW  - Robotic surgery
DO  - 10.1109/ICRA40945.2020.9196674
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Automatic surgical gesture recognition is fundamental for improving intelligence in robot-assisted surgery, such as conducting complicated tasks of surgery surveillance and skill evaluation. However, current methods treat each frame individually and produce the outcomes without effective consideration on future information. In this paper, we propose a framework based on reinforcement learning and tree search for joint surgical gesture segmentation and classification. An agent is trained to segment and classify the surgical video in a human-like manner whose direct decisions are re-considered by tree search appropriately. Our proposed tree search algorithm unites the outputs from two designed neural networks, i.e., policy and value network. With the integration of complementary information from distinct models, our framework is able to achieve the better performance than baseline methods using either of the neural networks. For an overall evaluation, our developed approach consistently outperforms the existing methods on the suturing task of JIGSAWS dataset in terms of accuracy, edit score and F1 score. Our study highlights the utilization of tree search to refine actions in reinforcement learning framework for surgical robotic applications.
ER  - 

TY  - CONF
TI  - ACNN: a Full Resolution DCNN for Medical Image Segmentation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8455
EP  - 8461
AU  - X. -Y. Zhou
AU  - J. -Q. Zheng
AU  - P. Li
AU  - G. -Z. Yang
PY  - 2020
KW  - biomedical MRI
KW  - computerised tomography
KW  - convolutional neural nets
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - medical robotics
KW  - neural nets
KW  - surgery
KW  - medical image segmentation
KW  - robot-assisted Minimally Invasive Surgeries
KW  - current DCNNs
KW  - sampling layer
KW  - receptive field
KW  - spatial dimension
KW  - feature maps
KW  - atrous convolutional layers
KW  - ACNN
KW  - magnetic resonance imaging
KW  - computed tomography image segmentation
KW  - segmentation Intersection
KW  - Atrous convolutional neural network
KW  - full-resolution DCNN
KW  - U-Net
KW  - Deeplabv3+
KW  - Image segmentation
KW  - Convolution
KW  - Biomedical imaging
KW  - Image resolution
KW  - Convolutional neural networks
KW  - Three-dimensional displays
KW  - Robots
DO  - 10.1109/ICRA40945.2020.9197328
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Deep Convolutional Neural Networks (DCNNs) are used extensively in medical image segmentation and hence 3D navigation for robot-assisted Minimally Invasive Surgeries (MISs). However, current DCNNs usually use down sampling layers for increasing the receptive field and gaining abstract semantic information. These down sampling layers decrease the spatial dimension of feature maps, which can be detrimental to image segmentation. Atrous convolution is an alternative for the down sampling layer. It increases the receptive field whilst maintains the spatial dimension of feature maps. In this paper, a method for effective atrous rate setting is proposed to achieve the largest and fully-covered receptive field with a minimum number of atrous convolutional layers. Furthermore, a new and full resolution DCNN - Atrous Convolutional Neural Network (ACNN), which incorporates cascaded atrous II-blocks, residual learning and Instance Normalization (IN) is proposed. Application results of the proposed ACNN to Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) image segmentation demonstrate that the proposed ACNN can achieve higher segmentation Intersection over Unions (IoUs) than U-Net and Deeplabv3+, but with reduced trainable parameters.
ER  - 

TY  - CONF
TI  - Hyperproperties for Robotics: Planning via HyperLTL
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8462
EP  - 8468
AU  - Y. Wang
AU  - S. Nalluri
AU  - M. Pajic
PY  - 2020
KW  - formal specification
KW  - path planning
KW  - robots
KW  - temporal logic
KW  - hyperproperties
KW  - formal methods
KW  - temporal logic objectives
KW  - hyper-temporal logics
KW  - multiple paths
KW  - HyperLTL specifications
KW  - planning strategies
KW  - robotic planning
KW  - discrete transition systems
KW  - Planning
KW  - Robustness
KW  - Privacy
KW  - Automata
KW  - Model checking
KW  - Task analysis
DO  - 10.1109/ICRA40945.2020.9196874
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - There is a growing interest on formal methods-based robotic planning for temporal logic objectives. In this work, we extend the scope of existing synthesis methods to hyper-temporal logics. We are motivated by the fact that important planning objectives, such as optimality, robustness, and privacy, (maybe implicitly) involve the interrelation between multiple paths. Such objectives are thus hyperproperties, and cannot be expressed with usual temporal logics like the linear temporal logic (LTL). We show that such hyperproperties can be expressed by HyperLTL, an extension of LTL to multiple paths. To handle the complexity of planning with HyperLTL specifications, we introduce a symbolic approach for synthesizing planning strategies on discrete transition systems. Our planning method is evaluated on several case studies.
ER  - 

TY  - CONF
TI  - Abstractions for computing all robotic sensors that suffice to solve a planning problem
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8469
EP  - 8475
AU  - Y. Zhang
AU  - D. A. Shell
PY  - 2020
KW  - computational complexity
KW  - control engineering computing
KW  - data structures
KW  - graph theory
KW  - planning (artificial intelligence)
KW  - robots
KW  - search problems
KW  - sensors
KW  - robotic sensors
KW  - planning problem
KW  - search algorithms
KW  - sensor designs
KW  - design trade-offs
KW  - sensor maps
KW  - potential sensors
KW  - outer limits
KW  - search space
KW  - data structures
KW  - single special representative
KW  - task domain knowledge
KW  - sensor technology
KW  - particular problem instances
KW  - sensor characterization pairs
KW  - yielding solutions
KW  - Robot sensing systems
KW  - Planning
KW  - Sensor phenomena and characterization
KW  - Uncertainty
KW  - Collision avoidance
DO  - 10.1109/ICRA40945.2020.9196812
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Whether a robot can perform some specific task depends on several aspects, including the robot's sensors and the plans it possesses. We are interested in search algorithms that treat plans and sensor designs jointly, yielding solutions-i.e., plan and sensor characterization pairs-if and only if they exist. Such algorithms can help roboticists explore the space of sensors to aid in making design trade-offs. Generalizing prior work where sensors are modeled abstractly as sensor maps on p-graphs, the present paper increases the potential sensors which can be sought significantly. But doing so enlarges a problem currently on the outer limits of being considered tractable. Toward taming this complexity, two contributions are made: (1) we show how to represent the search space for this more general problem and describe data structures that enable whole sets of sensors to be summarized via a single special representative; (2) we give a means by which other structure (either task domain knowledge, sensor technology or fabrication constraints) can be incorporated to reduce the sets to be enumerated. These lead to algorithms that we have implemented and which suffice to solve particular problem instances, albeit only of small scale. Nevertheless, the algorithm aids in helping understand what attributes sensors must possess and what information they must provide in order to ensure a robot can achieve its goals despite non-determinism.
ER  - 

TY  - CONF
TI  - T* : A Heuristic Search Based Path Planning Algorithm for Temporal Logic Specifications
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8476
EP  - 8482
AU  - D. Khalidi
AU  - D. Gujarathi
AU  - I. Saha
PY  - 2020
KW  - collision avoidance
KW  - graph theory
KW  - mobile robots
KW  - navigation
KW  - search problems
KW  - temporal logic
KW  - trajectory control
KW  - obstacle avoidance
KW  - heuristic search based path planning algorithm
KW  - temporal logic path planning
KW  - graph search problem
KW  - point-to-point navigation
KW  - temporal logic specifications
KW  - temporal logic query
KW  - optimal trajectory
KW  - Dijkstra's shortest path algorithm
KW  - Automata
KW  - Heuristic algorithms
KW  - Trajectory
KW  - Task analysis
KW  - Robot kinematics
DO  - 10.1109/ICRA40945.2020.9196928
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The fundamental path planning problem for a mobile robot involves generating a trajectory for point-to-point navigation while avoiding obstacles. Heuristic-based search algorithms like A* have been shown to be efficient in solving such planning problems. Recently, there has been an increased interest in specifying complex path planning problem using temporal logic. In the state-of-the-art algorithm, the temporal logic path planning problem is reduced to a graph search problem, and Dijkstra's shortest path algorithm is used to compute the optimal trajectory satisfying the specification. The A* algorithm, when used with an appropriate heuristic for the distance from the destination, can generate an optimal path in a graph more efficiently than Dijkstra's shortest path algorithm. The primary challenge for using A* algorithm in temporal logic path planning is that there is no notion of a single destination state for the robot. We present a novel path planning algorithm T* that uses the A* search procedure opportunistically to generate an optimal trajectory satisfying a temporal logic query. Our experimental results demonstrate that T* achieves an order of magnitude improvement over the state-of-the-art algorithm to solve many temporal logic path planning problems in 2-D as well as 3-D workspaces.
ER  - 

TY  - CONF
TI  - Global/local motion planning based on Dynamic Trajectory Reconfiguration and Dynamical Systems for Autonomous Surgical Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8483
EP  - 8489
AU  - N. Sayols
AU  - A. Sozzi
AU  - N. Piccinelli
AU  - A. Hernansanz
AU  - A. Casals
AU  - M. Bonfè
AU  - R. Muradore
PY  - 2020
KW  - collision avoidance
KW  - medical robotics
KW  - mobile robots
KW  - motion control
KW  - splines (mathematics)
KW  - surgery
KW  - robotic minimally invasive surgery
KW  - geometric constraints
KW  - desired task
KW  - final target
KW  - moving obstacles
KW  - developed motion planner
KW  - two-layer architecture
KW  - global level computes smooth spline-based trajectories
KW  - collision free connections
KW  - realistic surgical scenario
KW  - autonomous surgical
KW  - collision-free trajectories
KW  - autonomous execution
KW  - assistive tasks
KW  - dynamical systems based obstacle avoidance
KW  - Trajectory
KW  - Tools
KW  - Robots
KW  - Collision avoidance
KW  - Task analysis
KW  - Surgery
KW  - Splines (mathematics)
DO  - 10.1109/ICRA40945.2020.9197525
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper addresses the generation of collision-free trajectories for the autonomous execution of assistive tasks in Robotic Minimally Invasive Surgery (R-MIS). The proposed approach takes into account geometric constraints related to the desired task, like for example the direction to approach the final target and the presence of moving obstacles. The developed motion planner is structured as a two-layer architecture: a global level computes smooth spline-based trajectories that are continuously updated using virtual potential fields; a local level, exploiting Dynamical Systems based obstacle avoidance, ensures collision free connections among the spline control points. The proposed architecture is validated in a realistic surgical scenario.
ER  - 

TY  - CONF
TI  - Deep Imitative Reinforcement Learning for Temporal Logic Robot Motion Planning with Noisy Semantic Observations
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8490
EP  - 8496
AU  - Q. Gao
AU  - M. Pajic
AU  - M. M. Zavlanos
PY  - 2020
KW  - Markov processes
KW  - mobile robots
KW  - motion control
KW  - neurocontrollers
KW  - path planning
KW  - probability
KW  - temporal logic
KW  - noisy semantic observations
KW  - mobile robots
KW  - linear temporal logic specifications
KW  - robot sensing error
KW  - probabilistic labels
KW  - labeled transition system
KW  - robot mobility
KW  - labeled Markov decision process
KW  - unknown transition probabilities
KW  - product-based model checkers
KW  - probabilistic labeling functions
KW  - Q-learning agent
KW  - deep imitative reinforcement learning
KW  - temporal logic robot motion planning
KW  - deep imitative Q-learning method
KW  - DIQL
KW  - control policies synthesis
KW  - LTL
KW  - LMDP
KW  - suboptimal instructions
KW  - Robot sensing systems
KW  - Labeling
KW  - Uncertainty
KW  - Semantics
KW  - Probabilistic logic
DO  - 10.1109/ICRA40945.2020.9197297
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we propose a Deep Imitative Q-learning (DIQL) method to synthesize control policies for mobile robots that need to satisfy Linear Temporal Logic (LTL) specifications using noisy semantic observations of their surroundings. The robot sensing error is modeled using probabilistic labels defined over the states of a Labeled Transition System (LTS) and the robot mobility is modeled using a Labeled Markov Decision Process (LMDP) with unknown transition probabilities. We use existing product-based model checkers (PMCs) as experts to guide the Q-learning algorithm to convergence. To the best of our knowledge, this is the first approach that models noise in semantic observations using probabilistic labeling functions and employs existing model checkers to provide suboptimal instructions to the Q-learning agent.
ER  - 

TY  - CONF
TI  - Minimal 3D Dubins Path with Bounded Curvature and Pitch Angle
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8497
EP  - 8503
AU  - P. Váňa
AU  - A. Alves Neto
AU  - J. Faigl
AU  - D. G. Macharet
PY  - 2020
KW  - optimisation
KW  - path planning
KW  - vehicles
KW  - minimal 3D Dubins path
KW  - bounded curvature
KW  - pitch angle
KW  - cost-efficient three-dimensional paths
KW  - two-dimensional Dubins curves
KW  - closed-form solutions
KW  - local optimization
KW  - cost-efficient solution
KW  - lower bound estimation
KW  - optimal path
KW  - vehicle
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Turning
KW  - Path planning
KW  - Atmospheric modeling
KW  - Space vehicles
KW  - Optimization
DO  - 10.1109/ICRA40945.2020.9197084
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we address the problem of finding cost-efficient three-dimensional paths that satisfy the maximum allowed curvature and the pitch angle of the vehicle. For any given initial and final configurations, the problem is decoupled into finding the horizontal and vertical parts of the path separately. Although the individual paths are modeled as two-dimensional Dubins curves using closed-form solutions, the final 3D path is constructed using the proposed local optimization to find a cost-efficient solution. Moreover, based on the decoupled approach, we provide a lower bound estimation of the optimal path that enables us to determine the quality of the found heuristic solution. The proposed solution has been evaluated using existing benchmark instances and compared with state-of-the-art approaches. Based on the reported results and lower bounds, the proposed approach provides paths close to the optimal solution while the computational requirements are in hundreds of microseconds. Besides, the proposed method provides paths with fewer turns than others, which make them easier to be followed by the vehicle's controller.
ER  - 

TY  - CONF
TI  - AU-AIR: A Multi-modal Unmanned Aerial Vehicle Dataset for Low Altitude Traffic Surveillance
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8504
EP  - 8510
AU  - I. Bozcan
AU  - E. Kayacan
PY  - 2020
KW  - autonomous aerial vehicles
KW  - cameras
KW  - computer vision
KW  - image annotation
KW  - image capture
KW  - image colour analysis
KW  - object detection
KW  - video signal processing
KW  - video surveillance
KW  - multimodal unmanned aerial vehicle dataset
KW  - low altitude traffic surveillance
KW  - UAVs
KW  - mounted cameras
KW  - aerial image capture
KW  - aerial visual data
KW  - object detection algorithms
KW  - computer vision community
KW  - object annotations
KW  - flying-cameras
KW  - multipurpose aerial dataset
KW  - multimodal sensor data
KW  - AU-AIR dataset
KW  - meta-data
KW  - traffic-related object category
KW  - mobile object detectors
KW  - real-time object detection
KW  - robotics
KW  - real-world outdoor environments
KW  - bounding box annotation
KW  - RGB videos recording
KW  - YOLOv3-Tiny
KW  - MobileNetv2-SSDLite
KW  - on-board computers
KW  - bird-view image
KW  - data types recording
KW  - Object detection
KW  - Videos
KW  - Visualization
KW  - Cameras
KW  - Detectors
KW  - Surveillance
DO  - 10.1109/ICRA40945.2020.9196845
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Unmanned aerial vehicles (UAVs) with mounted cameras have the advantage of capturing aerial (bird-view) images. The availability of aerial visual data and the recent advances in object detection algorithms led the computer vision community to focus on object detection tasks on aerial images. As a result of this, several aerial datasets have been introduced, including visual data with object annotations. UAVs are used solely as flying-cameras in these datasets, discarding different data types regarding the flight (e.g., time, location, internal sensors). In this work, we propose a multi-purpose aerial dataset (AU-AIR) that has multi-modal sensor data (i.e., visual, time, location, altitude, IMU, velocity) collected in real-world outdoor environments. The AU-AIR dataset includes meta-data for extracted frames (i.e., bounding box annotations for traffic-related object category) from recorded RGB videos. Moreover, we emphasize the differences between natural and aerial images in the context of object detection task. For this end, we train and test mobile object detectors (including YOLOv3-Tiny and MobileNetv2-SSDLite) on the AU-AIR dataset, which are applicable for real-time object detection using on-board computers with UAVs. Since our dataset has diversity in recorded data types, it contributes to filling the gap between computer vision and robotics. The dataset is available at https://bozcani.github.io/auairdataset.
ER  - 

TY  - CONF
TI  - Design and Autonomous Stabilization of a Ballistically-Launched Multirotor
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8511
EP  - 8517
AU  - A. Bouman
AU  - P. Nadan
AU  - M. Anderson
AU  - D. Pastor
AU  - J. Izraelevitz
AU  - J. Burdick
AU  - B. Kennedy
PY  - 2020
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - ballistics
KW  - helicopters
KW  - mobile robots
KW  - robot vision
KW  - aircraft
KW  - drones
KW  - emergency response
KW  - space exploration
KW  - critical situational data
KW  - onboard sensors
KW  - multirotor prototype
KW  - onboard sensor suite
KW  - autonomy pipeline
KW  - aerodynamic stability
KW  - active stabilization
KW  - ballistic launch
KW  - streamlined quick unfolding investigation drone
KW  - vision-based autonomous transition
KW  - SQUID
KW  - SQUIDs
KW  - Electron tubes
KW  - Aerodynamics
KW  - Drones
KW  - Prototypes
KW  - Thermal stability
KW  - Aircraft
DO  - 10.1109/ICRA40945.2020.9197542
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Aircraft that can launch ballistically and convert to autonomous, free-flying drones have applications in many areas such as emergency response, defense, and space exploration, where they can gather critical situational data using onboard sensors. This paper presents a ballistically-launched, autonomously-stabilizing multirotor prototype (SQUID - Streamlined Quick Unfolding Investigation Drone) with an onboard sensor suite, autonomy pipeline, and passive aerodynamic stability. We demonstrate autonomous transition from passive to vision-based, active stabilization, confirming the multirotor's ability to autonomously stabilize after a ballistic launch in a GPS-denied environment.
ER  - 

TY  - CONF
TI  - Asynchronous event-based clustering and tracking for intrusion monitoring in UAS
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8518
EP  - 8524
AU  - J. P. Rodríguez-Gomez
AU  - A. G. Eguíluz
AU  - J. R. Martínez-de Dios
AU  - A. Ollero
PY  - 2020
KW  - autonomous aerial vehicles
KW  - cameras
KW  - image sensors
KW  - object tracking
KW  - pattern clustering
KW  - robot vision
KW  - surveillance
KW  - feature tracking
KW  - intrusion monitoring
KW  - UAS
KW  - unmanned aerial systems
KW  - perception systems
KW  - illumination conditions
KW  - event cameras
KW  - neuromorphic sensors
KW  - illumination changes
KW  - event based vision
KW  - event stream
KW  - intruder monitoring
KW  - event clustering
KW  - event-by-event processing
KW  - asynchronous event-based clustering
KW  - automatic surveillance
KW  - on-board hardware computational constraints
KW  - Cameras
KW  - Robot vision systems
KW  - Tracking
KW  - Surveillance
KW  - Robustness
KW  - event camera
KW  - asynchronous
KW  - intrusion monitoring
KW  - surveillance
KW  - UAS
KW  - clustering
KW  - feature tracking
DO  - 10.1109/ICRA40945.2020.9197341
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Automatic surveillance and monitoring using Unmanned Aerial Systems (UAS) require the development of perception systems that robustly work under different illumination conditions. Event cameras are neuromorphic sensors that capture the illumination changes in the scene with very low latency and high dynamic range. Although recent advances in eventbased vision have explored the use of event cameras onboard UAS, most techniques group events in frames and, therefore, do not fully exploit the sequential and asynchronous nature of the event stream. This paper proposes a fully asynchronous scheme for intruder monitoring using UAS. It employs efficient event clustering and feature tracking modules and includes a sampling mechanism to cope with the computational cost of event-by-event processing adapting to on-board hardware computational constraints. The proposed scheme was tested on a real multirotor in challenging scenarios showing significant accuracy and robustness to lighting conditions.
ER  - 

TY  - CONF
TI  - SHIFT: Selective Heading Image for Translation An onboard monocular optical flow estimator for fast constantly rotating UAVs
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8525
EP  - 8531
AU  - M. Ng
AU  - E. Tang
AU  - G. S. Soh
AU  - S. Foong
PY  - 2020
KW  - aerospace control
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - cameras
KW  - image sensors
KW  - image sequences
KW  - Kalman filters
KW  - motion estimation
KW  - nonlinear filters
KW  - pose estimation
KW  - remotely operated vehicles
KW  - onboard monocular optical flow estimator
KW  - UAV
KW  - pose estimation
KW  - flight control
KW  - unmanned aerial vehicles
KW  - autonomous operations
KW  - onboard sensors
KW  - monocular camera
KW  - free rotors
KW  - flight dynamics
KW  - falling samara seed
KW  - constantly rotating body frame
KW  - optical flow sensing
KW  - optimal images
KW  - rotation vectors
KW  - optical axis
KW  - translation vectors
KW  - flow field
KW  - SHIFT estimation
KW  - selective heading image for translation
KW  - Cameras
KW  - Optical imaging
KW  - Optical sensors
KW  - Adaptive optics
KW  - Optical filters
KW  - Tracking
KW  - Integrated optics
DO  - 10.1109/ICRA40945.2020.9197073
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Pose estimation is of paramount importance for flight control as well as localization and navigation of Unmanned Aerial Vehicles (UAVs) to enable autonomous operations. In environments without GPS, such estimation can only be determined using onboard sensors; optical flow using a monocular camera is a popular approach. Monocopters are a class of nature inspired UAVs known as free rotors where their design and flight dynamics are inspired by the falling samara seed. With a constantly rotating body frame, free rotors introduces some unique challenges for visual perception required during optical flow sensing. This paper addresses these problems with the introduction of SHIFT (Selective Heading Image for Translation) that selects optimal images for determining translation with optical flow. It achieves this by decoupling rotation vectors about the optical axis from translation vectors in a flow field through the separate tracking of orientation and position using an Unscented Kalman Filter with phase correlation in the log-polar and spatial domain. The experiments show that SHIFT's estimation in orientation is stable even under sinusoidal excitation with a median absolute percentage errors of less than 1%. It is able to track position and orientation of a UAV accurately.
ER  - 

TY  - CONF
TI  - Flydar: Magnetometer-based High Angular Rate Estimation during Gyro Saturation for SLAM
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8532
EP  - 8537
AU  - C. H. Tan
AU  - D. Sufiyan bin Shaiful
AU  - E. Tang
AU  - J. -Y. Khaw
AU  - G. S. Soh
AU  - S. Foong
PY  - 2020
KW  - gyroscopes
KW  - Kalman filters
KW  - magnetometers
KW  - mobile robots
KW  - nonlinear filters
KW  - optical radar
KW  - SLAM (robots)
KW  - Flydar
KW  - magnetometer-based high angular rate estimation
KW  - SLAM
KW  - simultaneous localisation and mapping
KW  - Flying Li-DAR
KW  - EKF-based algorithm
KW  - sinusoidal magnetometer measurement
KW  - continuously rotating airframe
KW  - IMU sensors
KW  - gyro measurement
KW  - gyro bias
KW  - gyro saturation condition
KW  - rotating locomotion
KW  - robot hovering angular velocity
KW  - Robots
KW  - Magnetometers
KW  - Sensors
KW  - Estimation
KW  - Frequency measurement
KW  - Saturation magnetization
KW  - Angular velocity
DO  - 10.1109/ICRA40945.2020.9197486
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, the high angular rate estimation for simultaneous localisation and mapping (SLAM) of a Flying Li-DAR (Flydar) is presented. The proposed EKF-based algorithm exploits the sinusoidal magnetometer measurement generated by the continuously rotating airframe for estimation of the robot hovering angular velocity. Significantly, the proposed method does not rely on additional sensors other than existing IMU sensors already being used for flight stabilization. The gyro measurement and the gyro bias are incorporated as a control input and a filter state respectively to enable estimation even under gyro saturation condition. Additionally, this work proposes leveraging on the inherently rotating locomotion to generate a planar lidar scan using only a single-point laser for possible lightweight autonomy. The proposed estimation method was experimentally evaluated on a ground rotating rig up to twice the gyro saturation limit with an effective rms error of 0.0045Hz; and on the proposed aerial platform - Flydar - hovering beyond the saturation limit with a rms error of 0.0056Hz. Lastly, the proposed method for SLAM using the rotating dynamics of Flydar was demonstrated with a localisation accuracy of 0.11m.
ER  - 

TY  - CONF
TI  - Nonlinear MPC with Motor Failure Identification and Recovery for Safe and Aggressive Multicopter Flight
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8538
EP  - 8544
AU  - D. Tzoumanikas
AU  - Q. Yan
AU  - S. Leutenegger
PY  - 2020
KW  - actuators
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - Kalman filters
KW  - nonlinear control systems
KW  - nonlinear filters
KW  - predictive control
KW  - precise reference tracking
KW  - crucial characteristic
KW  - microaerial vehicles
KW  - MAV
KW  - external disturbances
KW  - cluttered environments
KW  - nonlinear model predictive control
KW  - NMPC
KW  - fully physics
KW  - nonlinear dynamics
KW  - control inputs
KW  - feasible actuator commands
KW  - safe operation
KW  - potential loss
KW  - flight experiments
KW  - motor failures
KW  - nonlinear MPC
KW  - aggressive multicopter flight
KW  - extended Kalman filter based motor failure identification algorithm
KW  - Actuators
KW  - Resource management
KW  - Propellers
KW  - Aerodynamics
KW  - Quaternions
KW  - Angular velocity
KW  - Vehicle dynamics
DO  - 10.1109/ICRA40945.2020.9196690
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Safe and precise reference tracking is a crucial characteristic of Micro Aerial Vehicles (MAVs) that have to operate under the influence of external disturbances in cluttered environments. In this paper, we present a Nonlinear Model Predictive Control (NMPC) that exploits the fully physics based non-linear dynamics of the system. We furthermore show how the moment and thrust control inputs can be transformed into feasible actuator commands. In order to guarantee safe operation despite potential loss of a motor under which we show our system keeps operating safely, we developed an Extended Kalman Filter (EKF) based motor failure identification algorithm. We verify the effectiveness of the developed pipeline in flight experiments with and without motor failures.
ER  - 

TY  - CONF
TI  - Temporal information integration for video semantic segmentation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8545
EP  - 8551
AU  - G. Guarino
AU  - T. Chateau
AU  - C. Teulière
AU  - V. Antoine
PY  - 2020
KW  - Bayes methods
KW  - belief networks
KW  - image segmentation
KW  - image sequences
KW  - neural nets
KW  - probability
KW  - video signal processing
KW  - temporal information integration
KW  - video semantic segmentation
KW  - temporal Bayesian filter
KW  - video sequence
KW  - discrete probabilistic distribution function
KW  - possible semantic classes
KW  - Bayesian filtering
KW  - prediction model
KW  - observation model
KW  - datadriven prediction function
KW  - dense optical flow
KW  - deep neural network
KW  - observation function
KW  - semantic segmentation network
KW  - temporal filtering
KW  - Cityscapes
KW  - Optical imaging
KW  - Image segmentation
KW  - Semantics
KW  - Adaptive optics
KW  - Optical filters
KW  - Bayes methods
KW  - Optical fiber networks
DO  - 10.1109/ICRA40945.2020.9197204
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present a temporal Bayesian filter for semantic segmentation of a video sequence. Each pixel is a random variable following a discrete probabilistic distribution function representing possible semantic classes. Bayesian filtering consists in two main steps: 1) a prediction model and 2) an observation model (likelihood). We propose to use a datadriven prediction function derived from a dense optical flow between images t and t + 1 achieved by a deep neural network [1]. Moreover, the observation function uses a semantic segmentation network. The resulting approach is evaluated on the public dataset Cityscapes. We show that using the temporal filtering increases the accuracy of the semantic segmentation.
ER  - 

TY  - CONF
TI  - Map-Predictive Motion Planning in Unknown Environments
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8552
EP  - 8558
AU  - A. Elhafsi
AU  - B. Ivanovic
AU  - L. Janson
AU  - M. Pavone
PY  - 2020
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - predictive control
KW  - trajectory control
KW  - map prediction
KW  - data-driven method
KW  - autonomous navigation
KW  - hallway environments
KW  - naïve frontier pursuit method
KW  - heuristic methods
KW  - map-predictive motion planning
KW  - dynamically-constrained robots
KW  - trajectory planning
KW  - robot position
KW  - frontier selection heuristics
KW  - Robots
KW  - Trajectory
KW  - Planning
KW  - Navigation
KW  - Collision avoidance
KW  - Safety
KW  - Cognition
DO  - 10.1109/ICRA40945.2020.9197522
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Algorithms for motion planning in unknown environments are generally limited in their ability to reason about the structure of the unobserved environment. As such, current methods generally navigate unknown environments by relying on heuristic methods to choose intermediate objectives along frontiers. We present a unified method that combines map prediction and motion planning for safe, time-efficient au-tonomous navigation of unknown environments by dynamically-constrained robots. We propose a data-driven method for predicting the map of the unobserved environment, using the robot's observations of its surroundings as context. These map predictions are then used to plan trajectories from the robot's position to the goal without requiring frontier selection. We applied this map-predictive motion planning strategy to randomly generated winding hallway environments, yielding substantial improvement in trajectory duration over a naïve frontier pursuit method. We also experimentally demonstrate similar performance to methods using more sophisticated fron-tier selection heuristics while significantly reducing computation time.
ER  - 

TY  - CONF
TI  - Using multiple short hops for multicopter navigation with only inertial sensors
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8559
EP  - 8565
AU  - X. Wu
AU  - M. W. Mueller
PY  - 2020
KW  - accelerometers
KW  - closed loop systems
KW  - gyroscopes
KW  - helicopters
KW  - inertial navigation
KW  - Kalman filters
KW  - nonlinear filters
KW  - position control
KW  - state estimation
KW  - closed-loop control
KW  - mean absolute position estimation error
KW  - total flight distance
KW  - standard inertial navigation method
KW  - trajectory tracking error
KW  - multiple short hops
KW  - multicopter navigation
KW  - GPS systems
KW  - multicopter localization
KW  - direct integration
KW  - inertial navigation sensors
KW  - accelerometer
KW  - rate gyroscope
KW  - rapid error accumulation
KW  - motion strategy
KW  - inertial navigation state estimation error
KW  - long duration flight
KW  - multiple short duration hops
KW  - zero-velocity pseudomeasurements
KW  - extended Kalman filter
KW  - LiDAR
KW  - real-world environment
KW  - distance 5.0 m
KW  - distance 10.0 m
KW  - State estimation
KW  - Gyroscopes
KW  - Sensors
KW  - Inertial navigation
KW  - Accelerometers
KW  - Measurement uncertainty
DO  - 10.1109/ICRA40945.2020.9196610
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In certain challenging environments, such as inside buildings on fire, the main sensors (e.g. cameras, LiDARs and GPS systems) used for multicopter localization can become unavailable. Direct integration of the inertial navigation sensors (the accelerometer and rate gyroscope), is however unaffected by external disturbances, but the rapid error accumulation quickly makes a naive application of such a strategy feasible only for very short durations. In this work we propose a motion strategy for reducing the inertial navigation state estimation error of multicopters. The proposed strategy breaks a long duration flight into multiple short duration hops between which the vehicle remains stationary on the ground. When the vehicle is stationary, zero-velocity pseudo-measurements are introduced to an extended Kalman Filter to reduce the state estimation error. We perform experiments for closed-loop control of a multicopter for evaluation. The mean absolute position estimation error was 3.4% over a total flight distance of 5m in the experiments. The results showed a 80% reduction compared to the standard inertial navigation method without using this strategy. In addition, an additional experiment with total flight distance of 10m is conducted to demonstrate the ability of this method to navigate a multicopter in real-world environment. The final trajectory tracking error was 3% of the total flight distance.
ER  - 

TY  - CONF
TI  - An Efficient and Continuous Approach to Information-Theoretic Exploration
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8566
EP  - 8572
AU  - T. Henderson
AU  - V. Sze
AU  - S. Karaman
PY  - 2020
KW  - computational complexity
KW  - information theory
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - information-theoretic exploration
KW  - continuous occupancy map framework
KW  - |Θ| measurement beams
KW  - recursive structure
KW  - robotics applications
KW  - autonomous navigation task
KW  - Robot sensing systems
KW  - Mutual information
KW  - Distortion measurement
KW  - Gain measurement
KW  - Time measurement
DO  - 10.1109/ICRA40945.2020.9196592
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Exploration of unknown environments is embedded and essential in many robotics applications. Traditional algorithms, that decide where to explore by computing the expected information gain of an incomplete map from future sensor measurements, are limited to very powerful computational platforms. In this paper, we describe a novel approach for computing this expected information gain efficiently, as principally derived via mutual information. The key idea behind the proposed approach is a continuous occupancy map framework and the recursive structure it reveals. This structure makes it possible to compute the expected information gain of sensor measurements across an entire map much faster than computing each measurements' expected gain independently. Specifically, for an occupancy map composed of |M| cells and a range sensor that emits |Θ| measurement beams, the algorithm (titled FCMI) computes the information gain corresponding to measurements made at each cell in O(|Θ||M|) steps. To the best of our knowledge, this complexity bound is better than all existing methods for computing information gain. In our experiments, we observe that this novel, continuous approach is two orders of magnitude faster than the state-of-the-art FSMI algorithm.
ER  - 

TY  - CONF
TI  - A Feature-Based Underwater Path Planning Approach using Multiple Perspective Prior Maps
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8573
EP  - 8579
AU  - D. Cagara
AU  - M. Dunbabin
AU  - P. Rigby
PY  - 2020
KW  - autonomous underwater vehicles
KW  - bathymetry
KW  - maximum likelihood estimation
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - remotely operated vehicles
KW  - multiple perspective prior maps
KW  - path planning methodology
KW  - Autonomous Underwater Vehicles
KW  - AUV
KW  - shallow complex environments
KW  - coral reefs
KW  - aerial photographic survey
KW  - bathymetric information
KW  - prior map
KW  - navigation graph
KW  - test points
KW  - shortest paths
KW  - destination points
KW  - maximum likelihood function
KW  - misclassified objects
KW  - photo-realistic simulated environment
KW  - Navigation
KW  - Cameras
KW  - Sensors
KW  - Uncertainty
KW  - Image segmentation
KW  - Feature extraction
KW  - Robots
DO  - 10.1109/ICRA40945.2020.9196680
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents a path planning methodology which enables Autonomous Underwater Vehicles (AUVs) to navigate in shallow complex environments such as coral reefs. The approach leverages prior information from an aerial photographic survey, and derived bathymetric information of the corresponding area. From these prior maps, a set of features is obtained which define an expected arrangement of objects and bathymetry likely to be perceived by the AUV when underwater. A navigation graph is then constructed by predicting the arrangement of features visible from a set of test points within the prior, which allows the calculation of the shortest paths from any pair of start and destination points. A maximum likelihood function is defined which allows the AUV to match its observations to the navigation graph as it undertakes its mission. To improve robustness, the history of observed features are retained to facilitate possible recovery from non-detectable or misclassified objects. The approach is evaluated using a photo-realistic simulated environment, and results illustrate the merits of the approach even when only a relatively small number of features can be identified from the prior map.
ER  - 

TY  - CONF
TI  - Automatic LiDAR-Camera Calibration of Extrinsic Parameters Using a Spherical Target
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8580
EP  - 8586
AU  - T. Tóth
AU  - Z. Pusztai
AU  - L. Hajder
PY  - 2020
KW  - calibration
KW  - computer vision
KW  - optical radar
KW  - radar imaging
KW  - surface topography measurement
KW  - computer vision applications
KW  - fully automatic extrinsic calibration
KW  - LiDAR extrinsic parameters
KW  - automatic LiDAR-camera calibration
KW  - spherical target
KW  - LiDAR-camera imaging system
KW  - point clouds
KW  - Cameras
KW  - Calibration
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Estimation
KW  - Mathematical model
KW  - Robustness
DO  - 10.1109/ICRA40945.2020.9197316
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper investigates a novel calibration process of devices with different modalities, which is a critical step of computer vision applications. We propose a fully automatic extrinsic calibration of a LiDAR-camera system. Our approach applies sphere as their surfaces and contours can be accurately detected on point clouds and camera images, respectively. Experiments on synthetic and real data exhibit that our automatic algorithm is fast and robust and it yields accurate camera and LiDAR extrinsic parameters.
ER  - 

TY  - CONF
TI  - Motion Estimation in Occupancy Grid Maps in Stationary Settings Using Recurrent Neural Networks
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8587
EP  - 8593
AU  - M. Schreiber
AU  - V. Belagiannis
AU  - C. Gläser
AU  - K. Dietmayer
PY  - 2020
KW  - image filtering
KW  - image motion analysis
KW  - motion estimation
KW  - optical radar
KW  - path planning
KW  - probability
KW  - radar imaging
KW  - recurrent neural nets
KW  - traffic engineering computing
KW  - occupancy grid maps
KW  - recurrent neural networks
KW  - grid cell
KW  - occupancy probability
KW  - measurement grid maps
KW  - occupancy probabilities
KW  - filtered occupancy
KW  - network architecture
KW  - Computer architecture
KW  - Microprocessors
KW  - Vehicle dynamics
KW  - Measurement by laser beam
KW  - Time measurement
KW  - Recurrent neural networks
KW  - Dynamics
DO  - 10.1109/ICRA40945.2020.9196702
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this work, we tackle the problem of modeling the vehicle environment as dynamic occupancy grid map in complex urban scenarios using recurrent neural networks. Dynamic occupancy grid maps represent the scene in a bird's eye view, where each grid cell contains the occupancy prob-ability and the two dimensional velocity. As input data, our approach relies on measurement grid maps, which contain occupancy probabilities, generated with lidar measurements. Given this configuration, we propose a recurrent neural net-work architecture to predict a dynamic occupancy grid map, i.e. filtered occupancy and velocity of each cell, by using a sequence of measurement grid maps. Our network architecture contains convolutional long-short term memories in order to sequentially process the input, makes use of spatial context, and captures motion. In the evaluation, we quantify improvements in estimating the velocity of braking and turning vehicles compared to the state-of-the-art. Additionally, we demonstrate that our approach provides more consistent velocity estimates for dynamic objects, as well as, less erroneous velocity estimates in static area.
ER  - 

TY  - CONF
TI  - A Divide and Conquer Method for 3D Registration of Inhomogeneous, Partially Overlapping Scans with Fourier Mellin SOFT (FMS)
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8594
EP  - 8601
AU  - H. Bülow
AU  - C. A. Mueller
AU  - A. Gomez Chavez
AU  - F. Buda
AU  - A. Birk
PY  - 2020
KW  - divide and conquer methods
KW  - image registration
KW  - laser ranging
KW  - high-end laser range-finders
KW  - divide-and-conquer method
KW  - 3D registration method
KW  - Fourier-Mellin-SOFT
KW  - FMS
KW  - partial overlaps
KW  - large-scale cultural heritage site
KW  - Three-dimensional displays
KW  - Frequency modulation
KW  - Robustness
KW  - Underwater vehicles
KW  - Two dimensional displays
KW  - Cultural differences
KW  - Nonhomogeneous media
DO  - 10.1109/ICRA40945.2020.9197453
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - High-end laser range-finders provide accurate 3D data over long ranges. But their scans are inhomogeneous, i.e., the environment is non-uniformly sampled, as there is denser data in the near range than in the far range. Furthermore, the generation of a scan is time-consuming. Thus, it is desirable to cover an area by as few scans as possible, i.e., scanning is more time-efficient if the overlap between scans is as small as possible. However, these factors pose significant challenges for state-of-the-art registration algorithms. In this work, we present a divide-and-conquer method that uses an efficient strategy to check for possible registrations between partitions of two scans. As underlying registration method, Fourier-Mellin-SOFT (FMS) is used. FMS is quite robust against partial overlaps but its performance is significantly boosted by the presented partitioning method. As concrete use case, results from the digitization of a WWII submarine bunker as a large-scale cultural heritage site are presented.
ER  - 

TY  - CONF
TI  - Estimating Motion Uncertainty with Bayesian ICP
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8602
EP  - 8608
AU  - F. A. Maken
AU  - F. Ramos
AU  - L. Ott
PY  - 2020
KW  - Bayes methods
KW  - image fusion
KW  - iterative methods
KW  - Markov processes
KW  - Monte Carlo methods
KW  - motion estimation
KW  - pose estimation
KW  - motion uncertainty
KW  - accurate uncertainty estimation
KW  - pose transformation
KW  - autonomous navigation
KW  - data fusion
KW  - iterative closest point
KW  - point cloud pairs
KW  - motion estimation
KW  - deterministic algorithm
KW  - probabilistic manner
KW  - data association errors
KW  - sensor noise
KW  - overconfident transformation estimates
KW  - pose uncertainty
KW  - Markov Chain Monte Carlo algorithm
KW  - scalable Bayesian sampling
KW  - stochastic gradient Langevin dynamics
KW  - data association uncertainty
KW  - 3D Kinect data
KW  - Bayesian ICP
KW  - Iterative closest point algorithm
KW  - Uncertainty
KW  - Bayes methods
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Standards
KW  - Stochastic processes
DO  - 10.1109/ICRA40945.2020.9197085
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Accurate uncertainty estimation associated with the pose transformation between two 3D point clouds is critical for autonomous navigation, grasping, and data fusion. Iterative closest point (ICP) is widely used to estimate the transformation between point cloud pairs by iteratively performing data association and motion estimation. Despite its success and popularity, ICP is effectively a deterministic algorithm, and attempts to reformulate it in a probabilistic manner generally do not capture all sources of uncertainty, such as data association errors and sensor noise. This leads to overconfident transformation estimates, potentially compromising the robustness of systems relying on them. In this paper we propose a novel method to estimate pose uncertainty in ICP with a Markov Chain Monte Carlo (MCMC) algorithm. Our method combines recent developments in optimization for scalable Bayesian sampling such as stochastic gradient Langevin dynamics (SGLD) to infer a full posterior distribution of the pose transformation between two point clouds. We evaluate our method, called Bayesian ICP, in experiments using 3D Kinect data demonstrating that our method is capable of both quickly and accuractely estimating pose uncertainty, taking into account data association uncertainty as reflected by the shape of the objects.
ER  - 

TY  - CONF
TI  - Actively Mapping Industrial Structures with Information Gain-Based Planning on a Quadruped Robot
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8609
EP  - 8615
AU  - Y. Wang
AU  - M. Ramezani
AU  - M. Fallon
PY  - 2020
KW  - collision avoidance
KW  - image representation
KW  - legged locomotion
KW  - robot vision
KW  - industrial structure
KW  - mapping industrial structures
KW  - information gain-based planning
KW  - quadruped robot
KW  - online active mapping system
KW  - voxel representation
KW  - NBV
KW  - expected information gain
KW  - terrain map
KW  - ANYbotics ANYmal robot
KW  - Robot sensing systems
KW  - Service robots
KW  - Solid modeling
KW  - Planning
KW  - Laser radar
DO  - 10.1109/ICRA40945.2020.9197153
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we develop an online active mapping system to enable a quadruped robot to autonomously survey large physical structures. We describe the perception, planning and control modules needed to scan and reconstruct an object of interest, without requiring a prior model. The system builds a voxel representation of the object, and iteratively determines the Next-Best-View (NBV) to extend the representation, according to both the reconstruction itself and to avoid collisions with the environment. By computing the expected information gain of a set of candidate scan locations sampled on the as-sensed terrain map, as well as the cost of reaching these candidates, the robot decides the NBV for further exploration. The robot plans an optimal path towards the NBV, avoiding obstacles and un-traversable terrain. Experimental results on both simulated and real-world environments show the capability and efficiency of our system. Finally we present a full system demonstration on the real robot, the ANYbotics ANYmal, autonomously reconstructing a building facade and an industrial structure.
ER  - 

TY  - CONF
TI  - Efficient Covisibility-based Image Matching for Large-Scale SfM
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8616
EP  - 8622
AU  - Z. Ye
AU  - G. Zhang
AU  - H. Bao
PY  - 2020
KW  - feature extraction
KW  - image matching
KW  - image motion analysis
KW  - iterative methods
KW  - large-scale SfM
KW  - feature matches
KW  - large-scale structure-from-motion
KW  - unordered image collections
KW  - traditional feature matching method
KW  - region covisibility
KW  - overlapping image pairs
KW  - iterative matching strategy
KW  - unordered image datasets
KW  - robust SfM
KW  - efficient image matching method
KW  - covisibility-based image matching
KW  - Three-dimensional displays
KW  - Vocabulary
KW  - Image reconstruction
KW  - Image retrieval
KW  - Feature extraction
KW  - Robustness
KW  - Cameras
DO  - 10.1109/ICRA40945.2020.9197383
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Obtaining accurate and sufficient feature matches is crucial for robust large-scale Structure-from-Motion. For unordered image collections, a traditional feature matching method with geometric verification requires a huge cost to find sufficient feature matches. Although several methods have been proposed to speed up this stage, none of them makes full use of existing matches. In this paper, we propose a novel efficient image matching method by using the transitivity of region covisibility. The overlapping image pairs can be efficiently found in an iterative matching strategy even only with few inlier feauture matches. The experimental results on unordered image datasets demonstrate that the proposed method is three times faster than the state-of-the-art and the matching result is high-quality enough for robust SfM.
ER  - 


