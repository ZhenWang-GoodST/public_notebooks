TY  - CONF
TI  - Probabilistic TSDF Fusion Using Bayesian Deep Learning for Dense 3D Reconstruction with a Single RGB Camera
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8623
EP  - 8629
AU  - H. Kim
AU  - B. Lee
PY  - 2020
KW  - Bayes methods
KW  - belief networks
KW  - cameras
KW  - image colour analysis
KW  - image fusion
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - Monte Carlo methods
KW  - neural nets
KW  - depth prediction
KW  - robust 3D reconstruction
KW  - Bayesian deep learning framework
KW  - Conventional Bayesian deep learning
KW  - probabilistic TSDF fusion
KW  - dense 3D reconstruction
KW  - global TSDF
KW  - single RGB camera
KW  - 3D reconstruction problem
KW  - single RGB image
KW  - training environment
KW  - test environment
KW  - lightweight Bayesian neural network
KW  - Uncertainty
KW  - Three-dimensional displays
KW  - Probabilistic logic
KW  - Bayes methods
KW  - Predictive models
KW  - Cameras
KW  - Machine learning
DO  - 10.1109/ICRA40945.2020.9196663
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we address a 3D reconstruction problem using depth prediction from a single RGB image. With the recent advances in deep learning, depth prediction shows high performance. However, due to the discrepancy between training environment and test environment, 3D reconstruction can be vulnerable to the uncertainty of depth prediction. To consider the uncertainty of depth prediction for robust 3D reconstruction, we adopt Bayesian deep learning framework. Conventional Bayesian deep learning requires a large amount of time and GPU memory to perform Monte Carlo sampling. To address this problem, we propose a lightweight Bayesian neural network consisting of U-net structure and summation-based skip connections, which is performed in real-time. Estimated uncertainty is utilized in probabilistic TSDF fusion for dense 3D reconstruction by maximizing the posterior of TSDF value per voxel. As a result, global TSDF robust to erroneous depth values can be obtained and then dense 3D reconstruction from the global TSDF is achievable more accurately. To evaluate the performance of depth prediction and 3D reconstruction using our method, we utilized two official datasets and demonstrated the outperformance of the proposed method over other conventional methods.
ER  - 

TY  - CONF
TI  - IF-Net: An Illumination-invariant Feature Network
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8630
EP  - 8636
AU  - P. -H. Chen
AU  - Z. -X. Luo
AU  - Z. -K. Huang
AU  - C. Yang
AU  - K. -W. Chen
PY  - 2020
KW  - computer vision
KW  - feature extraction
KW  - image matching
KW  - image retrieval
KW  - learning (artificial intelligence)
KW  - object detection
KW  - illumination-invariant feature network
KW  - feature descriptor matching
KW  - computer vision applications
KW  - image stitching
KW  - image retrieval
KW  - visual localization
KW  - illumination variations
KW  - descriptor learning
KW  - robust descriptor
KW  - generic descriptor
KW  - training data
KW  - dataset scheduling methods
KW  - ROI loss
KW  - hard-positive mining strategy
KW  - illumination change conditions
KW  - IF-Net
KW  - Lighting
KW  - Training
KW  - Measurement
KW  - Benchmark testing
KW  - Training data
KW  - Schedules
KW  - Cameras
DO  - 10.1109/ICRA40945.2020.9196893
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Feature descriptor matching is a critical step is many computer vision applications such as image stitching, image retrieval and visual localization. However, it is often affected by many practical factors which will degrade its performance. Among these factors, illumination variations are the most influential one, and especially no previous descriptor learning works focus on dealing with this problem. In this paper, we propose IF-Net, aimed to generate a robust and generic descriptor under crucial illumination changes conditions. We find out not only the kind of training data important but also the order it is presented. To this end, we investigate several dataset scheduling methods and propose a separation training scheme to improve the matching accuracy. Further, we propose a ROI loss and hard-positive mining strategy along with the training scheme, which can strengthen the ability of generated descriptor dealing with large illumination change conditions. We evaluate our approach on public patch matching benchmark and achieve the best results compared with several state-of-the-arts methods. To show the practicality, we further evaluate IF-Net on the task of visual localization under large illumination changes scenes, and achieves the best localization accuracy.
ER  - 

TY  - CONF
TI  - Deep-Learning Assisted High-Resolution Binocular Stereo Depth Reconstruction
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8637
EP  - 8643
AU  - Y. Hu
AU  - W. Zhen
AU  - S. Scherer
PY  - 2020
KW  - cameras
KW  - image matching
KW  - image reconstruction
KW  - image resolution
KW  - learning (artificial intelligence)
KW  - stereo image processing
KW  - Middlebury dataset
KW  - nonlearning method
KW  - infrastructure inspection
KW  - downstream process
KW  - stereo reconstruction methods
KW  - semiglobal block matching method
KW  - 3D reconstruction error
KW  - infrastructure inspection experiments
KW  - customized binocular stereo camera
KW  - high-resolution stereo images
KW  - deep-learning assisted method
KW  - predicted disparity
KW  - perpixel searching range
KW  - down-sampled stereo image pair
KW  - initial disparity prediction
KW  - deep-learning model
KW  - accurate stereo reconstruction
KW  - learning-based model
KW  - resource demanding nonlearning method
KW  - task-specific training data
KW  - generalization issue
KW  - learning-based methods
KW  - high-resolution data
KW  - computational resource
KW  - infrastructure inspections
KW  - dense stereo reconstruction
KW  - assisted high-resolution binocular stereo depth reconstruction
KW  - Uncertainty
KW  - Predictive models
KW  - Image reconstruction
KW  - Proposals
KW  - Computational modeling
KW  - Image resolution
KW  - Three-dimensional displays
DO  - 10.1109/ICRA40945.2020.9196655
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This work presents dense stereo reconstruction using high-resolution images for infrastructure inspections. The state-of-the-art stereo reconstruction methods, both learning and non-learning ones, consume too much computational resource on high-resolution data. Recent learning-based methods achieve top ranks on most benchmarks. However, they suffer from the generalization issue due to lack of task-specific training data. We propose to use a less resource demanding non-learning method, guided by a learning-based model, to handle high-resolution images and achieve accurate stereo reconstruction. The deep-learning model produces an initial disparity prediction with uncertainty for each pixel of the down-sampled stereo image pair. The uncertainty serves as a self-measurement of its generalization ability and the perpixel searching range around the initially predicted disparity. The downstream process performs a modified version of the Semi-Global Block Matching method with the up-sampled perpixel searching range. The proposed deep-learning assisted method is evaluated on the Middlebury dataset and high-resolution stereo images collected by our customized binocular stereo camera. The combination of learning and non-learning methods achieves better performance on 12 out of 15 cases of the Middlebury dataset. In our infrastructure inspection experiments, the average 3D reconstruction error is less than 0.004m.
ER  - 

TY  - CONF
TI  - Least-squares Optimal Relative Planar Motion for Vehicle-mounted Cameras
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8644
EP  - 8650
AU  - L. Hajder
AU  - D. Barath
PY  - 2020
KW  - calibration
KW  - computer vision
KW  - image motion analysis
KW  - least squares approximations
KW  - optimisation
KW  - polynomials
KW  - closed-form solver
KW  - point correspondences
KW  - camera movement
KW  - motion parameters
KW  - vehicle-mounted cameras
KW  - least-squares optimal relative planar motion
KW  - 6th degree polynomial
KW  - Cameras
KW  - Transmission line matrix methods
KW  - Robot vision systems
KW  - Estimation
KW  - Automobiles
KW  - Geometry
DO  - 10.1109/ICRA40945.2020.9196755
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - A new closed-form solver is proposed minimizing the algebraic error optimally, in the least squares sense, to estimate the relative planar motion of two calibrated cameras. The main objective is to solve the over-determined case, i.e., when a larger-than-minimal sample of point correspondences is given - thus, estimating the motion from at least three correspondences. The algorithm requires the camera movement to be constrained to a plane, e.g. mounted to a vehicle, and the image plane to be orthogonal to the ground.1 The solver obtains the motion parameters as the roots of a 6th degree polynomial. It is validated both in synthetic experiments and on publicly available real-world datasets that using the proposed solver leads to results superior to the state-of-the-art in terms of geometric accuracy with no noticeable deterioration in the processing time.
ER  - 

TY  - CONF
TI  - Relative planar motion for vehicle-mounted cameras from a single affine correspondence
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8651
EP  - 8657
AU  - L. Hajder
AU  - D. Barath
PY  - 2020
KW  - calibration
KW  - cameras
KW  - computer vision
KW  - image motion analysis
KW  - image sensors
KW  - relative planar motion
KW  - vehicle-mounted cameras
KW  - single affine correspondence
KW  - extrinsic camera parameters
KW  - general planar motion
KW  - camera movement
KW  - image plane
KW  - minimal solver
KW  - semicalibrated case
KW  - common focal length
KW  - fully calibrated case
KW  - Cameras
KW  - Transmission line matrix methods
KW  - Mathematical model
KW  - Estimation
KW  - Geometry
KW  - Robot vision systems
KW  - Robustness
DO  - 10.1109/ICRA40945.2020.9197438
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Two solvers are proposed for estimating the extrinsic camera parameters from a single affine correspondence assuming general planar motion. In this case, the camera movement is constrained to a plane and the image plane is orthogonal to the ground. The algorithms do not assume other constraints, e.g. the non-holonomic one, to hold. A new minimal solver is proposed for the semi-calibrated case, i.e. the camera parameters are known except a common focal length. Another method is proposed for the fully calibrated case. Due to requiring a single correspondence, robust estimation, e.g. histogram voting, leads to a fast and accurate procedure. The proposed methods are tested in our synthetic environment and on publicly available real datasets consisting of videos through tens of kilometers. They are superior to the state-of-the-art both in terms of accuracy and processing time.
ER  - 

TY  - CONF
TI  - Moving object detection for visual odometry in a dynamic environment based on occlusion accumulation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8658
EP  - 8664
AU  - H. Kim
AU  - P. Kim
AU  - H. J. Kim
PY  - 2020
KW  - cameras
KW  - distance measurement
KW  - image colour analysis
KW  - image segmentation
KW  - image sensors
KW  - mobile robots
KW  - object detection
KW  - pose estimation
KW  - regression analysis
KW  - robot vision
KW  - dynamic environment
KW  - simple moving object detection algorithm
KW  - dense visual odometry
KW  - VO algorithms
KW  - occlusion accumulation
KW  - color images
KW  - robotic navigation
KW  - real-time RGBD data
KW  - depth information
KW  - obstacle recognition
KW  - camera pose estimate
KW  - bi-square regression weight
KW  - segmentation accuracy
KW  - public datasets
KW  - Cameras
KW  - Heuristic algorithms
KW  - Object detection
KW  - Robustness
KW  - Trajectory
KW  - Visual odometry
KW  - Feature extraction
DO  - 10.1109/ICRA40945.2020.9196767
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Detection of moving objects is an essential capability in dealing with dynamic environments. Most moving object detection algorithms have been designed for color images without depth. For robotic navigation where real-time RGBD data is often readily available, utilization of the depth information would be beneficial for obstacle recognition. Here, we propose a simple moving object detection algorithm that uses RGB-D images. The proposed algorithm does not require estimating a background model. Instead, it uses an occlusion model which enables us to estimate the camera pose on a background confused with moving objects that dominate the scene. The proposed algorithm allows to separate the moving object detection and visual odometry (VO) so that an arbitrary robust VO method can be employed in a dynamic situation with a combination of moving object detection, whereas other VO algorithms for a dynamic environment are inseparable. In this paper, we use dense visual odometry (DVO) as a VO method with a bi-square regression weight. Experimental results show the segmentation accuracy and the performance improvement of DVO in the situations. We validate our algorithm in public datasets and our dataset which also publicly accessible.
ER  - 

TY  - CONF
TI  - A Low-Rank Matrix Approximation Approach to Multiway Matching with Applications in Multi-Sensory Data Association
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8665
EP  - 8671
AU  - S. Leonardos
AU  - X. Zhou
AU  - K. Daniilidis
PY  - 2020
KW  - approximation theory
KW  - computational complexity
KW  - concave programming
KW  - image matching
KW  - matrix algebra
KW  - sensor fusion
KW  - stochastic processes
KW  - multisensory data association
KW  - multiple visual sensors
KW  - consistent visual perception
KW  - noisy pairwise correspondences
KW  - multiway matching problem
KW  - low-rank matrix approximation problem problem
KW  - alternating direction method of multipliers
KW  - stochastic matrices
KW  - Fisher information metric
KW  - computational complexity
KW  - ADMM
KW  - Convex functions
KW  - Optimization
KW  - Manifolds
KW  - Xenon
KW  - Approximation algorithms
KW  - Clustering algorithms
KW  - Noise measurement
DO  - 10.1109/ICRA40945.2020.9196583
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Consider the case of multiple visual sensors perceiving the same scene from different viewpoints. In order to achieve consistent visual perception, the problem of data association, in this case establishing correspondences between observed features, must be first solved. In this work, we consider multiway matching which is a specific instance of multi-sensory data association. Multiway matching refers to the problem of establishing correspondences among a set of images from noisy pairwise correspondences, typically by exploiting cycle- consistency. We propose a novel optimization-based formulation of multiway matching problem as a nonconvex low-rank matrix approximation problem. We propose two novel algorithms for numerically solving the problem at hand. The first one is an algorithm based on the Alternating Direction Method of Multipliers (ADMM). The second one is a Riemannian trust- region method on the multinomial manifold, the manifold of strictly positive stochastic matrices, equipped with the Fisher information metric. Experimental results demonstrate that the proposed methods have the state of the art performance in multiway matching while reducing the computational complexity compared to the state of the art.
ER  - 

TY  - CONF
TI  - A Parametric Grasping Methodology for Multi-Manual Interactions in Real-Time Dynamic Simulations
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8712
EP  - 8718
AU  - A. Munawar
AU  - N. Srishankar
AU  - L. Fichera
AU  - G. S. Fischer
PY  - 2020
KW  - biomechanics
KW  - control engineering computing
KW  - data visualisation
KW  - kinematics
KW  - manipulators
KW  - medical robotics
KW  - rendering (computer graphics)
KW  - surgery
KW  - telerobotics
KW  - parametric grasping methodology
KW  - multimanual interactions
KW  - interactive simulators
KW  - training simulators
KW  - teleoperated robotic laparoscopic surgery
KW  - stateof-art simulators
KW  - realistic visuals
KW  - accurate dynamics
KW  - kinematic simplification techniques
KW  - truly multimanual manipulation
KW  - actual task
KW  - realistic grasping
KW  - rigid-body dynamics
KW  - collision computation techniques
KW  - state-of-the-art physics libraries
KW  - parametric approach
KW  - multimanual grasping
KW  - real-time dynamic simulation
KW  - accomplishing multimanual tasks
KW  - screwdriver task
KW  - Friction
KW  - Grasping
KW  - Force
KW  - Sensors
KW  - Computational modeling
KW  - Mathematical model
KW  - Robots
DO  - 10.1109/ICRA40945.2020.9197099
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Interactive simulators are used in several important applications which include the training simulators for teleoperated robotic laparoscopic surgery. While stateof-art simulators are capable of rendering realistic visuals and accurate dynamics, grasping is often implemented using kinematic simplification techniques that prevent truly multimanual manipulation, which is often an important requirement of the actual task. Realistic grasping and manipulation in simulation is a challenging problem due to the constraints imposed by the implementation of rigid-body dynamics and collision computation techniques in state-of-the-art physics libraries. We present a penalty based parametric approach to achieve multi-manual grasping and manipulation of complex objects at arbitrary postures in a real-time dynamic simulation. This approach is demonstrated by accomplishing multi-manual tasks modeled after realistic scenarios, which include the grasping and manipulation of a two-handed screwdriver task and the manipulation of a deformable thread.
ER  - 

TY  - CONF
TI  - A methodology for the incorporation of arbitrarily-shaped feet in passive bipedal walking dynamics
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8719
EP  - 8725
AU  - A. Smyrli
AU  - E. Papadopoulos
PY  - 2020
KW  - computational geometry
KW  - legged locomotion
KW  - motion control
KW  - pose estimation
KW  - public domain software
KW  - robot dynamics
KW  - stability
KW  - ankle trajectory
KW  - robot dynamics
KW  - shape dependent foot kinetics
KW  - OpenPose
KW  - open source pose estimation system
KW  - rigid foot passive robot
KW  - walking robot stability
KW  - foot shape optimization
KW  - exact foot geometry
KW  - dynamic model
KW  - biped robot
KW  - passive bipedal walking dynamics
KW  - Foot
KW  - Legged locomotion
KW  - Shape
KW  - Geometry
KW  - Mathematical model
KW  - Dynamics
DO  - 10.1109/ICRA40945.2020.9196617
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - A methodology for implementing arbitrary foot shapes in the passive walking dynamics of biped robots is developed. The dynamic model of a walking robot is defined in a way that allows shape-dependent foot kinetics to contribute to the robot's dynamics, for all convex foot shapes regardless of the exact foot geometry: for the developed method, only the set of points describing the foot profile curve is needed. The method is mathematically derived and then showcased with an application. The open-source pose estimation system OpenPose is used to determine the foot profile that enables the rigid-foot passive robot to reproduce the ankle trajectory of the actively powered, multi-DOF human foot complex. The passive gait of the biped robot walking on the specified foot shape is simulated and analyzed, and a stable walking cycle is found and evaluated. The proposed model enables the study of the effects of foot shape on the walking dynamics of biped robots, eliminating the necessity of solely using simple, and analytically defined geometric shapes as the walking robots' feet. The method can be used for foot shape optimization towards achieving any desired walking pattern in walking robots.
ER  - 

TY  - CONF
TI  - Experimental Analysis of Structural Vibration Problems of a Biped Walking Robot
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8726
EP  - 8731
AU  - T. F. C. Berninger
AU  - F. Sygulla
AU  - S. Fuderer
AU  - D. J. Rixen
PY  - 2020
KW  - closed loop systems
KW  - humanoid robots
KW  - legged locomotion
KW  - modal analysis
KW  - position control
KW  - robot dynamics
KW  - vibrations
KW  - biped using Experimental Modal Analysis
KW  - structural design
KW  - low level position control
KW  - walking control
KW  - control design
KW  - structural dynamics
KW  - LOLA's mechanical structure
KW  - biped walking robot
KW  - control algorithms
KW  - structural vibration problems
KW  - structural resonances
KW  - control loop resonances
KW  - closed-loop identification method
KW  - structural modes
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Foot
KW  - Gears
KW  - Harmonic analysis
DO  - 10.1109/ICRA40945.2020.9197282
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Over the past decade we have been able to vastly improve the control algorithms of our biped walking robot LOLA. Further enhancements, however, are limited by vibration problems caused by the dynamics of LOLA's mechanical structure. In this work, we present small examples how structural dynamics limit our control design for walking control as well as low level position control of the joints. We also provide a procedure to identify weaknesses in the structural design of our biped using Experimental Modal Analysis. Using this method, we could successfully identify the structural modes of the system. Furthermore, we were able to use a closed-loop identification method to show a connection between the control loop resonances and the structural resonances of our robot.
ER  - 

TY  - CONF
TI  - Dynamic Coupling as an Indicator of Gait Robustness for Underactuated Biped Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8732
EP  - 8738
AU  - M. Fevre
AU  - J. P. Schmiedeler
PY  - 2020
KW  - legged locomotion
KW  - robot dynamics
KW  - robust control
KW  - trajectory control
KW  - dynamic coupling
KW  - gait robustness
KW  - velocity decomposition
KW  - underactuated mechanical systems
KW  - two link biped model
KW  - underactuated biped robots
KW  - trajectory optimization
KW  - Couplings
KW  - Mathematical model
KW  - Legged locomotion
KW  - Aerodynamics
KW  - Robustness
DO  - 10.1109/ICRA40945.2020.9197203
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper employs velocity decomposition of underactuated mechanical systems to determine the degree of dynamic coupling in the gaits of a two-link biped model. The degree of coupling between controlled and uncontrolled directions quantifies the control authority the system has over its unactuated degree of freedom. This paper shows that the amount of coupling is directly correlated to gait robustness, as seen through the size of the gait's region of attraction. The analytical measure of coupling is applied in the context of trajectory optimization to generate two-link gaits that maximize or minimize coupling. Simulation studies show that gaits maximizing coupling exhibit significantly superior robustness, as measured by 1) stochastic performance on uneven terrain, 2) ability to maintain desired walking speed under non-vanishing disturbances, 3) size of the region of attraction, and 4) robustness to model uncertainties.
ER  - 

TY  - CONF
TI  - ZMP Constraint Restriction for Robust Gait Generation in Humanoids
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8739
EP  - 8745
AU  - F. M. Smaldone
AU  - N. Scianca
AU  - V. Modugno
AU  - L. Lanari
AU  - G. Oriolo
PY  - 2020
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - predictive control
KW  - robot dynamics
KW  - robust control
KW  - stability
KW  - range amplitude
KW  - internal stability
KW  - IS-MPC method
KW  - constraint modification
KW  - ZMP constraint restriction
KW  - robust gait generation
KW  - humanoids
KW  - humanoid gait generation
KW  - robust performance
KW  - considered disturbance signals
KW  - mid-range value
KW  - sampling time
KW  - stability constraint
KW  - current mid-range disturbance
KW  - appropriate restriction
KW  - control horizon
KW  - Humanoid robots
KW  - Lips
KW  - Robustness
KW  - Stability criteria
KW  - Dynamics
DO  - 10.1109/ICRA40945.2020.9197171
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present an extension of our previously proposed IS-MPC method for humanoid gait generation aimed at obtaining robust performance in the presence of disturbances. The considered disturbance signals vary in a range of known amplitude around a mid-range value that can change at each sampling time, but whose current value is assumed to be available. The method consists in modifying the stability constraint that is at the core of IS-MPC by incorporating the current mid-range disturbance, and performing an appropriate restriction of the ZMP constraint in the control horizon on the basis of the range amplitude of the disturbance. We derive explicit conditions for recursive feasibility and internal stability of the IS-MPC method with constraint modification. Finally, we illustrate its superior performance with respect to the nominal version by performing dynamic simulations on the NAO robot.
ER  - 

TY  - CONF
TI  - Hybrid Zero Dynamics Inspired Feedback Control Policy Design for 3D Bipedal Locomotion using Reinforcement Learning
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8746
EP  - 8752
AU  - G. A. Castillo
AU  - B. Weng
AU  - W. Zhang
AU  - A. Hereid
PY  - 2020
KW  - feedback
KW  - humanoid robots
KW  - learning systems
KW  - legged locomotion
KW  - robot dynamics
KW  - hybrid zero dynamics inspired feedback control policy design
KW  - 3D bipedal locomotion
KW  - model-free reinforcement learning framework
KW  - feedback control policies
KW  - 3D bipedal walking
KW  - RL algorithms
KW  - reference joint trajectories
KW  - policy structure
KW  - hybrid nature
KW  - walking dynamics
KW  - RL framework
KW  - lightweight network structure
KW  - short training time
KW  - 3D bipedal robot
KW  - stable limit walking cycles
KW  - walking speed
KW  - Legged locomotion
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Robustness
KW  - Torso
KW  - Robot kinematics
DO  - 10.1109/ICRA40945.2020.9197175
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents a novel model-free reinforcement learning (RL) framework to design feedback control policies for 3D bipedal walking. Existing RL algorithms are often trained in an end-to-end manner or rely on prior knowledge of some reference joint trajectories. Different from these studies, we propose a novel policy structure that appropriately incorporates physical insights gained from the hybrid nature of the walking dynamics and the well-established hybrid zero dynamics approach for 3D bipedal walking. As a result, the overall RL framework has several key advantages, including lightweight network structure, short training time, and less dependence on prior knowledge. We demonstrate the effectiveness of the proposed method on Cassie, a challenging 3D bipedal robot. The proposed solution produces stable limit walking cycles that can track various walking speed in different directions. Surprisingly, without specifically trained with disturbances to achieve robustness, it also performs robustly against various adversarial forces applied to the torso towards both the forward and the backward directions.
ER  - 

TY  - CONF
TI  - Optimal Reduced-order Modeling of Bipedal Locomotion
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8753
EP  - 8760
AU  - Y. -M. Chen
AU  - M. Posa
PY  - 2020
KW  - legged locomotion
KW  - nonlinear control systems
KW  - pendulums
KW  - reduced order systems
KW  - robot dynamics
KW  - springs (mechanical)
KW  - five-link model
KW  - Cassie bipedal robot
KW  - optimal reduced-order modeling
KW  - bipedal locomotion
KW  - legged locomotion
KW  - LIP
KW  - spring-loaded inverted pendulum
KW  - SLIP
KW  - agile maneuvers
KW  - high-dimensional system
KW  - ground inclines
KW  - Task analysis
KW  - Legged locomotion
KW  - Reduced order systems
KW  - Lips
KW  - Trajectory optimization
DO  - 10.1109/ICRA40945.2020.9197004
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - State-of-the-art approaches to legged locomotion are widely dependent on the use of models like the linear inverted pendulum (LIP) and the spring-loaded inverted pendulum (SLIP), popular because their simplicity enables a wide array of tools for planning, control, and analysis. However, they inevitably limit the ability to execute complex tasks or agile maneuvers. In this work, we aim to automatically synthesize models that remain low-dimensional but retain the capabilities of the high-dimensional system. For example, if one were to restore a small degree of complexity to LIP, SLIP, or a similar model, our approach discovers the form of that additional complexity which optimizes performance. In this paper, we define a class of reduced-order models and provide an algorithm for optimization within this class. To demonstrate our method, we optimize models for walking at a range of speeds and ground inclines, for both a five-link model and the Cassie bipedal robot.
ER  - 

TY  - CONF
TI  - CAPRICORN: Communication Aware Place Recognition using Interpretable Constellations of Objects in Robot Networks
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8761
EP  - 8768
AU  - B. Ramtoula
AU  - R. de Azambuja
AU  - G. Beltrame
PY  - 2020
KW  - feature extraction
KW  - image colour analysis
KW  - image matching
KW  - image representation
KW  - mobile robots
KW  - multi-robot systems
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - particular communication bandwidth
KW  - limited communication bandwidth
KW  - relative object positions
KW  - 2step decentralized loop closure verification
KW  - compact semantic descriptors
KW  - bandwidth requirements
KW  - communication aware place recognition
KW  - interpretable constellations
KW  - robot networks
KW  - multiple robots
KW  - mapping environments
KW  - CAPRICORN
KW  - exploring environments
KW  - 3D points
KW  - compact spatial descriptors
KW  - matching robots
KW  - geometric information
KW  - global image descriptors
KW  - TUM RGB-D SLAM sequence
KW  - Semantics
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Robustness
KW  - Visualization
KW  - Bandwidth
DO  - 10.1109/ICRA40945.2020.9197270
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Using multiple robots for exploring and mapping environments can provide improved robustness and performance, but it can be difficult to implement. In particular, limited communication bandwidth is a considerable constraint when a robot needs to determine if it has visited a location that was previously explored by another robot, as it requires for robots to share descriptions of places they have visited. One way to compress this description is to use constellations, groups of 3D points that correspond to the estimate of a set of relative object positions. Constellations maintain the same pattern from different viewpoints and can be robust to illumination changes or dynamic elements. We present a method to extract from these constellations compact spatial and semantic descriptors of the objects in a scene. We use this representation in a 2step decentralized loop closure verification: first, we distribute the compact semantic descriptors to determine which other robots might have seen scenes with similar objects; then we query matching robots with the full constellation to validate the match using geometric information. The proposed method requires less memory, is more interpretable than global image descriptors, and could be useful for other tasks and interactions with the environment. We validate our system's performance on a TUM RGB-D SLAM sequence and show its benefits in terms of bandwidth requirements.
ER  - 

TY  - CONF
TI  - Online Planning for Quadrotor Teams in 3-D Workspaces via Reachability Analysis On Invariant Geometric Trees
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8769
EP  - 8775
AU  - A. Desai
AU  - N. Michael
PY  - 2020
KW  - aerospace control
KW  - helicopters
KW  - multi-robot systems
KW  - path planning
KW  - position control
KW  - reachability analysis
KW  - robot dynamics
KW  - trees (mathematics)
KW  - collision-free geometric solution guarantees
KW  - online planning
KW  - aerial robots
KW  - quadrotor teams
KW  - cluttered 3D workspaces
KW  - reachability analysis
KW  - kinodynamic multirobot planning problem
KW  - position invariant geometric trees
KW  - kinodynamically feasible trajectories
KW  - multirobot team
KW  - nonstationary initial states
KW  - Collision avoidance
KW  - Planning
KW  - Robot kinematics
KW  - Vegetation
KW  - Trajectory
KW  - Reachability analysis
DO  - 10.1109/ICRA40945.2020.9197195
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We consider the kinodynamic multi-robot planning problem in cluttered 3-D workspaces. Reachability analysis on position invariant geometric trees is leveraged to find kino- dynamically feasible trajectories for the multi-robot team from potentially non-stationary initial states. The key contribution of our approach is that a collision-free geometric solution guarantees a kinodynamically feasible, safe solution without additional refinement. Simulation results with up-to 40 robots and hardware results with 5 robots suggest the viability of the proposed approach for online planning and replanning for large teams of aerial robots in cluttered 3-D workspaces.
ER  - 

TY  - CONF
TI  - Decentralized Visual-Inertial-UWB Fusion for Relative State Estimation of Aerial Swarm
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8776
EP  - 8782
AU  - H. Xu
AU  - L. Wang
AU  - Y. Zhang
AU  - K. Qiu
AU  - S. Shen
PY  - 2020
KW  - autonomous aerial vehicles
KW  - decentralised control
KW  - mobile robots
KW  - robot vision
KW  - state estimation
KW  - decentralized visual-inertial-UWB fusion
KW  - unmanned aerial vehicles
KW  - multiple UAVs
KW  - visual-inertial-UWB fusion framework
KW  - extensive aerial swarm flight experiments
KW  - motion capture system
KW  - vision based method
KW  - Global Positioning System
KW  - estimation consistency
KW  - relative state estimation framework
KW  - aerial swarm applications
KW  - decentralized relative state estimation method
KW  - Drones
KW  - State estimation
KW  - Cameras
KW  - Sensors
KW  - Global Positioning System
KW  - Real-time systems
DO  - 10.1109/ICRA40945.2020.9196944
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The collaboration of unmanned aerial vehicles (UAVs) has become a popular research topic for its practicability in multiple scenarios. The collaboration of multiple UAVs, which is also known as aerial swarm is a highly complex system, which still lacks a state-of-art decentralized relative state estimation method. In this paper, we present a novel fully decentralized visual-inertial-UWB fusion framework for relative state estimation and demonstrate the practicability by performing extensive aerial swarm flight experiments. The comparison result with ground truth data from the motion capture system shows the centimeter-level precision which outperforms all the Ultra-WideBand (UWB) and even vision based method. The system is not limited by the field of view (FoV) of the camera or Global Positioning System (GPS), meanwhile on account of its estimation consistency, we believe that the proposed relative state estimation framework has the potential to be prevalently adopted by aerial swarm applications in different scenarios in multiple scales.
ER  - 

TY  - CONF
TI  - DC-CAPT: Concurrent Assignment and Planning of Trajectories for Dubins Cars
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8791
EP  - 8797
AU  - M. Whitzer
AU  - D. Shishika
AU  - D. Thakur
AU  - V. Kumar
AU  - A. Prorok
PY  - 2020
KW  - collision avoidance
KW  - mobile robots
KW  - path planning
KW  - robot kinematics
KW  - trajectory control
KW  - Dubins curves
KW  - holonomic robots
KW  - separation distance
KW  - trajectory planning
KW  - collision-free trajectories
KW  - Dubins cars
KW  - concurrent assignment
KW  - DC-CAPT
KW  - Automobiles
KW  - Collision avoidance
KW  - Robots
KW  - Trajectory
KW  - Planning
KW  - Turning
KW  - Kinematics
DO  - 10.1109/ICRA40945.2020.9196799
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present an algorithm for the concurrent assignment and planning of collision-free trajectories (DC-CAPT) for robots whose kinematics can be modeled as Dubins cars, i.e., robots constrained in terms of their initial orientation and their minimum turning radius. Coupling the assignment and trajectory planning subproblems allows for a computationally tractable solution. This solution is guaranteed to be collision- free through the use of a single constraint: the start and goal locations have separation distance greater than some threshold. We derive this separation distance by extending a prior work that assumed holonomic robots. We demonstrate the validity of our approach, and show its efficacy through simulations and experiments where groups of robots executing Dubins curves travel to their assigned goal locations without collisions.
ER  - 

TY  - CONF
TI  - Anti-Jackknifing Control of Tractor-Trailer Vehicles via Intrinsically Stable MPC
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8806
EP  - 8812
AU  - M. Beglini
AU  - L. Lanari
AU  - G. Oriolo
PY  - 2020
KW  - feedback
KW  - linearisation techniques
KW  - optimal control
KW  - predictive control
KW  - road vehicles
KW  - stability
KW  - trajectory control
KW  - corrective term
KW  - tracking term
KW  - input-output linearization
KW  - nonminimum-phase systems
KW  - IS-MPC
KW  - antijackknifing control
KW  - feedback control law
KW  - reference Cartesian trajectory
KW  - trailer hitch angle
KW  - tractor-trailer vehicles
KW  - intrinsically stable MPC scheme
KW  - Trajectory
KW  - Agricultural machinery
KW  - Computational modeling
KW  - Vehicle dynamics
KW  - Tracking
KW  - Dynamics
KW  - Linear approximation
DO  - 10.1109/ICRA40945.2020.9197012
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - It is common knowledge that tractor-trailer vehicles are affected by jackknifing, a phenomenon that consists in the divergence of the trailer hitch angle and ultimately causes the vehicle to fold up. For the case of backwards motion, in which jackknifing can also occur at low speeds, we present a control method that drives the vehicle along a reference Cartesian trajectory while avoiding the divergence of the hitch angle. In particular, a feedback control law is obtained by combining two actions: a tracking term, computed using input-output linearization, and a corrective term, generated via IS-MPC, an intrinsically stable MPC scheme which is effective for stable inversion of nonminimum-phase systems. The proposed method has been verified in simulation and experimentally validated on a purposely built prototype.
ER  - 

TY  - CONF
TI  - On sensing-aware model predictive path-following control for a reversing general 2-trailer with a car-like tractor
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8813
EP  - 8819
AU  - O. Ljungqvist
AU  - D. Axehill
AU  - H. Pettersson
PY  - 2020
KW  - control system synthesis
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - predictive control
KW  - road traffic control
KW  - road vehicles
KW  - stability
KW  - vehicle dynamics
KW  - sensing-aware model predictive path
KW  - car-like tractor
KW  - controller-design problem
KW  - joint-angle kinematics
KW  - backward motion
KW  - vehicle segments
KW  - jackknife state
KW  - joint-angle estimation problem
KW  - path-following controller
KW  - Agricultural machinery
KW  - Axles
KW  - Sensors
KW  - Kinematics
KW  - Reliability
KW  - Estimation
KW  - Trajectory
DO  - 10.1109/ICRA40945.2020.9197346
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The design of reliable path-following controllers is a key ingredient for successful deployment of self-driving vehicles. This controller-design problem is especially challenging for a general 2-trailer with a car-like tractor due to the vehicle's structurally unstable joint-angle kinematics in backward motion and the car-like tractor's curvature limitations which can cause the vehicle segments to fold and enter a jackknife state. Furthermore, advanced sensors with a limited field of view have been proposed to solve the joint-angle estimation problem online, which introduce additional restrictions on which vehicle states that can be reliably estimated. To incorporate these restrictions at the level of control, a model predictive path-following controller is proposed. By taking the vehicle's physical and sensing limitations into account, it is shown in real-world experiments that the performance of the proposed path-following controller in terms of suppressing disturbances and recovering from non-trivial initial states is significantly improved compared to a previously proposed solution where the constraints have been neglected.
ER  - 

TY  - CONF
TI  - Offline Practising and Runtime Training Framework for Autonomous Motion Control of Snake Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8820
EP  - 8826
AU  - L. Cheng
AU  - J. Huang
AU  - L. Liu
AU  - Z. Jian
AU  - Y. Huang
AU  - K. Huang
PY  - 2020
KW  - adaptive control
KW  - biomimetics
KW  - feedback
KW  - mobile robots
KW  - motion control
KW  - regression analysis
KW  - robot dynamics
KW  - biomorphic hyperredundant robots
KW  - locomotion gait
KW  - autonomous motion control
KW  - runtime training framework
KW  - offline practising
KW  - snake robot
KW  - linear regression
KW  - dynamic feedback
KW  - Robots
KW  - Snake robots
KW  - Runtime
KW  - Training
KW  - Entropy
KW  - Motion control
KW  - Linear regression
DO  - 10.1109/ICRA40945.2020.9196637
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper proposes an offline and runtime combined framework for the autonomous motion of snake robots. With the dynamic feedback of its state during runtime, the robot utilizes the linear regression to update its control parameters for better performance and thus adaptively reacts to the environment. To reduce interference from infeasible samples and improve efficiency, the data set for runtime training is chosen from one in several clusters categorized from samples collected in offline practice. Moreover, only the most sensitive control parameter is updated at one iteration for better robustness and efficiency. The effectiveness and efficiency of our approach are evaluated by a set of case studies of pole climbing. Experimental results demonstrate that with the proposed framework, the snake robot can adapt its locomotion gait to poles with different unknown diameters.
ER  - 

TY  - CONF
TI  - Control of a differentially driven nonholonomic robot subject to a restricted wheels rotation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8827
EP  - 8832
AU  - D. Pazderski
AU  - K. Koz≈Çowski
PY  - 2020
KW  - controllability
KW  - feedback
KW  - geometry
KW  - position control
KW  - robot kinematics
KW  - motion task scenarios
KW  - virtual geometry constraint
KW  - transverse function
KW  - four-dimensional configuration manifold
KW  - small time local controllability
KW  - two-wheeled nonholonomic robot
KW  - nonstandard motion tasks
KW  - restricted wheels rotation
KW  - Wheels
KW  - Mobile robots
KW  - Kinematics
KW  - Task analysis
KW  - Manifolds
KW  - Trajectory
DO  - 10.1109/ICRA40945.2020.9196519
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The paper deals with non-standard motion tasks specified for a two-wheeled nonholonomic robot. It is assumed that wheels cannot fully rotate which reduces a set of feasible movements significantly. In spite of these constraints, it is expected that position of the robot can be changed without violating nonholonomic constraints. Such a possibility comes from the small time local controllability (STLC) of the kinematics described on four-dimensional configuration manifold. In order to solve these specific tasks a feedback taking advantage of the transverse function approach is designed. Consequently, the system can be virtually released from non-holonomic constraints. The transverse function also defines a virtual geometry constraint which makes it possible to limit wheels rotation.Properties of the designed controller are illustrated by results of numerical simulations in various motion task scenarios.
ER  - 

TY  - CONF
TI  - Inferring Task-Space Central Pattern Generator Parameters for Closed-loop Control of Underactuated Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8833
EP  - 8839
AU  - N. D. Kent
AU  - R. M. Bhirangi
AU  - M. Travers
AU  - T. M. Howard
PY  - 2020
KW  - closed loop systems
KW  - graph theory
KW  - legged locomotion
KW  - motion control
KW  - neurocontrollers
KW  - optimisation
KW  - path planning
KW  - real-time systems
KW  - sampling methods
KW  - optimal behaviors
KW  - gradient free optimization
KW  - closed loop control
KW  - underactuated robots
KW  - legged robot control
KW  - real time applications
KW  - probabilistic graphical model
KW  - locomotive behaviors
KW  - task space central pattern generator
KW  - sampling based motion planner
KW  - neural oscillator network
KW  - Mathematical model
KW  - Robot kinematics
KW  - Adaptation models
KW  - Probability distribution
KW  - Oscillators
KW  - Legged locomotion
DO  - 10.1109/ICRA40945.2020.9196957
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The complexity associated with the control of highly-articulated legged robots scales quickly as the number of joints increases. Traditional approaches to the control of these robots are often impractical for many real-time applications. This work thus presents a novel sampling-based planning approach for highly-articulated robots that utilizes a probabilistic graphical model (PGM) to infer in real-time how to optimally modify goal-driven, locomotive behaviors for use in closed-loop control. Locomotive behaviors are quantified in terms of the parameters associated with a network of neural oscillators, or rather a central pattern generator (CPG). For the first time, we show that the PGM can be used to optimally modulate different behaviors in real-time (i.e., to select of optimal choice of parameter values across the CPG model) in response to changes both in the local environment and in the desired control signal. The PGM is trained offline using a library of optimal behaviors that are generated using a gradient-free optimization framework.
ER  - 

TY  - CONF
TI  - In-Hand Manipulation of Objects with Unknown Shapes
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8848
EP  - 8854
AU  - S. Cruciani
AU  - H. Yin
AU  - D. Kragic
PY  - 2020
KW  - dexterous manipulators
KW  - graph theory
KW  - learning (artificial intelligence)
KW  - unknown shape
KW  - grasp configurations
KW  - deep generative models
KW  - object shapes
KW  - partial visual sensing
KW  - object shape uncertainty
KW  - manipulation actions
KW  - in-hand manipulation tasks
KW  - unknown objects
KW  - dexterous manipulation graph method
KW  - Shape
KW  - Grippers
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Planning
KW  - Robots
KW  - Uncertainty
DO  - 10.1109/ICRA40945.2020.9197273
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This work addresses the problem of changing grasp configurations on objects with an unknown shape through in-hand manipulation. Our approach leverages shape priors, learned as deep generative models, to infer novel object shapes from partial visual sensing. The Dexterous Manipulation Graph method is extended to build incrementally and account for object shape uncertainty when planning a sequence of manipulation actions. We show that our approach successfully solves in-hand manipulation tasks with unknown objects, and demonstrate the validity of these solutions with robot experiments.
ER  - 

TY  - CONF
TI  - Learning Hierarchical Control for Robust In-Hand Manipulation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8855
EP  - 8862
AU  - T. Li
AU  - K. Srinivasan
AU  - M. Q. -H. Meng
AU  - W. Yuan
AU  - J. Bohg
PY  - 2020
KW  - computational complexity
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - hierarchical control
KW  - robotic in-hand manipulation
KW  - finger motion
KW  - complex manipulation sequences
KW  - low-level controllers
KW  - model-free deep reinforcement learning
KW  - hierarchical method
KW  - traditional model-based controllers
KW  - manipulation primitives
KW  - elongated objects
KW  - object models
KW  - Robustness
KW  - Task analysis
KW  - Force
KW  - Robot kinematics
KW  - Torque
KW  - Robot sensing systems
DO  - 10.1109/ICRA40945.2020.9197343
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Robotic in-hand manipulation has been a longstanding challenge due to the complexity of modelling hand and object in contact and of coordinating finger motion for complex manipulation sequences. To address these challenges, the majority of prior work has either focused on model-based, low-level controllers or on model-free deep reinforcement learning that each have their own limitations. We propose a hierarchical method that relies on traditional, model-based controllers on the low-level and learned policies on the mid-level. The low-level controllers can robustly execute different manipulation primitives (reposing, sliding, flipping). The mid-level policy orchestrates these primitives. We extensively evaluate our approach in simulation with a 3-fingered hand that controls three degrees of freedom of elongated objects. We show that our approach can move objects between almost all the possible poses in the workspace while keeping them firmly grasped. We also show that our approach is robust to inaccuracies in the object models and to observation noise. Finally, we show how our approach generalizes to objects of other shapes.
ER  - 

TY  - CONF
TI  - Tactile Dexterity: Manipulation Primitives with Tactile Feedback
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8863
EP  - 8869
AU  - F. R. Hogan
AU  - J. Ballester
AU  - S. Dong
AU  - A. Rodriguez
PY  - 2020
KW  - closed loop systems
KW  - dexterous manipulators
KW  - end effectors
KW  - force control
KW  - manipulator dynamics
KW  - path planning
KW  - perturbation techniques
KW  - robot vision
KW  - tactile sensors
KW  - robot trajectories
KW  - manipulation primitives
KW  - ABB YuMi dual-arm robot
KW  - tactile dexterity
KW  - tactile feedback
KW  - closed-loop tactile controllers
KW  - dexterous robotic manipulation
KW  - dual-palm robotic system
KW  - tactile control
KW  - tactile-based tracking
KW  - end-effector
KW  - Tactile sensors
KW  - Trajectory
KW  - Force
KW  - Friction
KW  - Perturbation methods
DO  - 10.1109/ICRA40945.2020.9196976
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper develops closed-loop tactile controllers for dexterous robotic manipulation with a dual-palm robotic system. Tactile dexterity is an approach to dexterous manipulation that plans for robot/object interactions that render interpretable tactile information for control. We divide the role of tactile control into two goals: 1) control the contact state between the end-effector and the object (contact/no-contact, stick/slip) by regulating the stability of planned contact configurations and monitoring undesired slip events; and 2) control the object state by tactile-based tracking and iterative replanning of the object and robot trajectories. Key to this formulation is the decomposition of manipulation plans into sequences of manipulation primitives with simple mechanics and efficient planners. We consider the scenario of manipulating an object from an initial pose to a target pose on a flat surface while correcting for external perturbations and uncertainty in the initial pose of the object. We experimentally validate the approach with an ABB YuMi dual-arm robot and demonstrate the ability of the tactile controller to react to external perturbations.
ER  - 

TY  - CONF
TI  - Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8870
EP  - 8876
AU  - S. Yuan
AU  - A. D. Epps
AU  - J. B. Nowak
AU  - J. K. Salisbury
PY  - 2020
KW  - control system synthesis
KW  - dexterous manipulators
KW  - grippers
KW  - manipulator kinematics
KW  - motion control
KW  - continuous rotation capability
KW  - fingertips
KW  - object manipulation
KW  - roller-based dexterous hand design
KW  - two-finger manipulation
KW  - nonholonomic spatial motion
KW  - robotic hands
KW  - three-finger manipulation
KW  - actively driven rollers
KW  - nonanthropomorphic robot hand
KW  - within-hand manipulation
KW  - object grasping
KW  - Grasping
KW  - Prototypes
KW  - Kinematics
KW  - Task analysis
KW  - Robot sensing systems
KW  - Thumb
DO  - 10.1109/ICRA40945.2020.9197146
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper describes the development of a novel non-anthropomorphic robot hand with the ability to manipulate objects by means of articulated, actively driven rollers located at the fingertips. An analysis is conducted and systems of equations for two-finger and three-finger manipulation of a sphere are formulated to demonstrate full six degree of freedom nonholonomic spatial motion capability. A prototype version of the hand was constructed and used to grasp and manipulate a variety of objects. Tests conducted with the prototype confirmed the validity of the mathematical analysis. Unlike conventional approaches to within-hand manipulation using legacy robotic hands, the continuous rotation capability of our rolling fingertips allows for unbounded rotation of a grasped object without the need for finger gaiting.
ER  - 

TY  - CONF
TI  - High-Resolution Optical Fiber Shape Sensing of Continuum Robots: A Comparative Study *
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8877
EP  - 8883
AU  - F. Monet
AU  - S. Sefati
AU  - P. Lorre
AU  - A. Poiffaut
AU  - S. Kadoury
AU  - M. Armand
AU  - I. Iordachita
AU  - R. Kashyap
PY  - 2020
KW  - bending
KW  - Bragg gratings
KW  - dexterous manipulators
KW  - fibre optic sensors
KW  - optical fibres
KW  - reflectometry
KW  - flexible medical instruments
KW  - continuum dexterous manipulators
KW  - minimally invasive surgery
KW  - accurate CDM shape reconstruction
KW  - fiber Bragg grating sensors
KW  - sensing locations
KW  - basic shapes
KW  - optical frequency domain reflectometry
KW  - higher spatial resolution
KW  - complex shapes
KW  - ultraviolet laser exposure
KW  - orthopedic surgeries
KW  - maximum tip position error
KW  - OFDR reconstruction
KW  - FBG reconstruction
KW  - more accurate alternative
KW  - FBG sensors
KW  - complex CDM shapes
KW  - continuum robots
KW  - high-resolution optical fiber shape sensing
KW  - random optical gratings
KW  - size 35.0 mm
KW  - size 3.4 mm
KW  - Shape
KW  - Fiber gratings
KW  - Optical sensors
KW  - Robot sensing systems
KW  - Spatial resolution
DO  - 10.1109/ICRA40945.2020.9197454
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Flexible medical instruments, such as Continuum Dexterous Manipulators (CDM), constitute an important class of tools for minimally invasive surgery. Accurate CDM shape reconstruction during surgery is of great importance, yet a challenging task. Fiber Bragg grating (FBG) sensors have demonstrated great potential in shape sensing and consequently tip position estimation of CDMs. However, due to the limited number of sensing locations, these sensors can only accurately recover basic shapes, and become unreliable in the presence of obstacles or many inflection points such as s-bends. Optical Frequency Domain Reflectometry (OFDR), on the other hand, can achieve much higher spatial resolution, and can therefore accurately reconstruct more complex shapes. Additionally, Random Optical Gratings by Ultraviolet laser Exposure (ROGUEs) can be written in the fibers to increase signal to noise ratio of the sensors. In this comparison study, the tip position error is used as a metric to compare both FBG and OFDR shape reconstructions for a 35 mm long CDM developed for orthopedic surgeries, using a pair of stereo cameras as ground truth. Three sets of experiments were conducted to measure the accuracy of each technique in various surgical scenarios. The tip position error for the OFDR (and FBG) technique was found to be 0.32 (0.83) mm in free-bending environment, 0.41 (0.80) mm when interacting with obstacles, and 0.45 (2.27) mm in s-bending. Moreover, the maximum tip position error remains sub-millimeter for the OFDR reconstruction, while it reaches 3.40 mm for FBG reconstruction. These results propose a cost-effective, robust and more accurate alternative to FBG sensors for reconstructing complex CDM shapes.
ER  - 

TY  - CONF
TI  - Local Trajectory Stabilization for Dexterous Manipulation via Piecewise Affine Approximations
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8884
EP  - 8891
AU  - W. Han
AU  - R. Tedrake
PY  - 2020
KW  - approximation theory
KW  - dexterous manipulators
KW  - feedback
KW  - linear programming
KW  - linearisation techniques
KW  - manipulator dynamics
KW  - nonlinear control systems
KW  - stability
KW  - piecewise affine approximations
KW  - dexterous robotic manipulation
KW  - nonsmooth nonlinear system
KW  - trajectory optimization
KW  - local multicontact dynamics
KW  - piecewise affine system
KW  - linearization
KW  - feedback controller
KW  - linear programs
KW  - local trajectory stabilization
KW  - dexterous manipulation
KW  - feedback policy design
KW  - Trajectory optimization
KW  - Manipulator dynamics
KW  - Task analysis
KW  - Planning
DO  - 10.1109/ICRA40945.2020.9196824
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We propose a model-based approach to design feedback policies for dexterous robotic manipulation. The manipulation problem is formulated as reaching the target region from an initial state for some non-smooth nonlinear system. First, we use trajectory optimization to find a feasible trajectory. Next, we characterize the local multi-contact dynamics around the trajectory as a piecewise affine system, and build a funnel around the linearization of the nominal trajectory using polytopes. We prove that the feedback controller at the vicinity of the linearization is guaranteed to drive the nonlinear system to the target region. During online execution, we solve linear programs to track the system trajectory. We validate the algorithm on hardware, showing that even under large external disturbances, the controller is able to accomplish the task.
ER  - 

TY  - CONF
TI  - Monocular Direct Sparse Localization in a Prior 3D Surfel Map
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8892
EP  - 8898
AU  - H. Ye
AU  - H. Huang
AU  - M. Liu
PY  - 2020
KW  - cameras
KW  - geophysical image processing
KW  - object tracking
KW  - optimisation
KW  - photometry
KW  - pose estimation
KW  - rendering (computer graphics)
KW  - solid modelling
KW  - monocular direct sparse localization
KW  - prior 3d surfel map
KW  - monocular camera
KW  - prior surfel map
KW  - vertex
KW  - normal maps
KW  - global planar information
KW  - sparse tracked points
KW  - image frame
KW  - direct photometric errors
KW  - camera localization
KW  - pose tracking
KW  - rendering
KW  - optimization
KW  - global 6-DoF camera poses
KW  - Cameras
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Visualization
KW  - Rendering (computer graphics)
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA40945.2020.9197022
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we introduce an approach to tracking the pose of a monocular camera in a prior surfel map. By rendering vertex and normal maps from the prior surfel map, the global planar information for the sparse tracked points in the image frame is obtained. The tracked points with and without the global planar information involve both global and local constraints of frames to the system. Our approach formulates all constraints in the form of direct photometric errors within a local window of the frames. The final optimization utilizes these constraints to provide the accurate estimation of global 6-DoF camera poses with the absolute scale. The extensive simulation and real-world experiments demonstrate that our monocular method can provide accurate camera localization results under various conditions.
ER  - 

TY  - CONF
TI  - LINS: A Lidar-Inertial State Estimator for Robust and Efficient Navigation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8899
EP  - 8906
AU  - C. Qin
AU  - H. Ye
AU  - C. E. Pranata
AU  - J. Han
AU  - S. Zhang
AU  - M. Liu
PY  - 2020
KW  - distance measurement
KW  - inertial navigation
KW  - iterative methods
KW  - Kalman filters
KW  - motion estimation
KW  - optical radar
KW  - state estimation
KW  - ground vehicles
KW  - 6-axis IMU
KW  - iterated error-state Kalman filter
KW  - feature correspondences
KW  - filter divergence
KW  - LINS
KW  - state-of-the-art lidar-inertial odometry
KW  - lightweight lidar-inertial state estimator
KW  - real-time ego-motion estimation
KW  - robust navigation
KW  - 3D lidar
KW  - robocentric formulation
KW  - Feature extraction
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Kalman filters
KW  - Real-time systems
KW  - Optimization
KW  - Navigation
DO  - 10.1109/ICRA40945.2020.9197567
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present LINS, a lightweight lidar-inertial state estimator, for real-time ego-motion estimation. The proposed method enables robust and efficient navigation for ground vehicles in challenging environments, such as feature-less scenes, via fusing a 6-axis IMU and a 3D lidar in a tightly-coupled scheme. An iterated error-state Kalman filter (ESKF) is designed to correct the estimated state recursively by generating new feature correspondences in each iteration, and to keep the system computationally tractable. Moreover, we use a robocentric formulation that represents the state in a moving local frame in order to prevent filter divergence in a long run. To validate robustness and generalizability, extensive experiments are performed in various scenarios. Experimental results indicate that LINS offers comparable performance with the state-of-the-art lidar-inertial odometry in terms of stability and accuracy and has order-of-magnitude improvement in speed.
ER  - 

TY  - CONF
TI  - Automated Eye-in-Hand Robot-3D Scanner Calibration for Low Stitching Errors
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8906
EP  - 8912
AU  - H. Madhusudanan
AU  - X. Liu
AU  - W. Chen
AU  - D. Li
AU  - L. Du
AU  - J. Li
AU  - J. Ge
AU  - Y. Sun
PY  - 2020
KW  - calibration
KW  - industrial manipulators
KW  - robot kinematics
KW  - robot vision
KW  - DH parameters
KW  - high stitching errors
KW  - long-term routine industrial use
KW  - robot-scanner calibration approach
KW  - low data stitching error
KW  - long-term continuous measurement
KW  - 2D standard calibration board
KW  - low stitching error
KW  - virtual arm-based robot-scanner kinematic model
KW  - trajectory-based robot-world transformation calculation
KW  - cumbersome marker-based method
KW  - lower system downtime
KW  - automated eye-in-hand robot-3D scanner calibration
KW  - industrial robot
KW  - complete measurement
KW  - data stitching process
KW  - single coordinate system
KW  - marker-free stitching
KW  - cumbersome traditional fiducial marker-based method
KW  - align multiple FOV
KW  - Calibration
KW  - DH-HEMTs
KW  - Robot kinematics
KW  - Three-dimensional displays
KW  - Kinematics
KW  - Optimization
DO  - 10.1109/ICRA40945.2020.9196748
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - A 3D measurement system consisting of a 3D scanner and an industrial robot (eye-in-hand) is commonly used to scan large object under test (OUT) from multiple fieldof-views (FOVs) for complete measurement. A data stitching process is required to align multiple FOVs into a single coordinate system. Marker-free stitching assisted by robot's accurate positioning becomes increasingly attractive since it bypasses the cumbersome traditional fiducial marker-based method. Most existing methods directly use initial Denavit-Hartenberg (DH) parameters and hand-eye calibration to calculate the transformations between multiple FOVs. Since accuracy of DH parameters deteriorates over time, such methods suffer from high stitching errors (e.g., 0.2 mm) in long-term routine industrial use. This paper reports a new robot-scanner calibration approach to realize such measurement with low data stitching errors. During long-term continuous measurement, the robot periodically moves towards a 2D standard calibration board to optimize kinematic model's parameters to maintain a low stitching error. This capability is enabled by several techniques including virtual arm-based robot-scanner kinematic model, trajectory-based robot-world transformation calculation, nonlinear optimization. Experimental results demonstrated a low data stitching error (<; 0.1 mm) similar to the cumbersome marker-based method and a lower system downtime (<; 60 seconds vs. 10-15 minutes by traditional DH and hand-eye calibration).
ER  - 

TY  - CONF
TI  - Monocular Visual Odometry using Learned Repeatability and Description
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8913
EP  - 8919
AU  - H. Huang
AU  - H. Ye
AU  - Y. Sun
AU  - M. Liu
PY  - 2020
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - stereo image processing
KW  - monocular visual odometry
KW  - hybrid scheme
KW  - camera pose estimation
KW  - predicted repeatability maps
KW  - patch-wise 3D-2D association
KW  - local feature parameterization
KW  - adapted mapping module
KW  - local reconstruction accuracy
KW  - monocular VO system
KW  - learned repeatability
KW  - learned description
KW  - public datasets
KW  - robust backend
KW  - lightweight backend
KW  - Cameras
KW  - Feature extraction
KW  - Two dimensional displays
KW  - Robustness
KW  - Pose estimation
KW  - Three-dimensional displays
KW  - Visual odometry
DO  - 10.1109/ICRA40945.2020.9197406
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Robustness and accuracy for monocular visual odometry (VO) under challenging environments are widely concerned. In this paper, we present a monocular VO system leveraging learned repeatability and description. In a hybrid scheme, the camera pose is initially tracked on the predicted repeatability maps in a direct manner and then refined with the patch-wise 3D-2D association. The local feature parameterization and the adapted mapping module further boost different functionalities in the system. Extensive evaluations on challenging public datasets are performed. The competitive performance on camera pose estimation demonstrates the effectiveness of our method. Additional studies on the local reconstruction accuracy and running time exhibit that our system is capable of maintaining a robust and lightweight backend.
ER  - 

TY  - CONF
TI  - Interaction Graphs for Object Importance Estimation in On-road Driving Videos
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8920
EP  - 8927
AU  - Z. Zhang
AU  - A. Tawari
AU  - S. Martin
AU  - D. Crandall
PY  - 2020
KW  - decision making
KW  - driver information systems
KW  - graph theory
KW  - learning (artificial intelligence)
KW  - road traffic
KW  - road vehicles
KW  - traffic engineering computing
KW  - interaction graph
KW  - object importance estimation
KW  - on-road driving videos
KW  - human driving behavior
KW  - autonomous driving systems
KW  - ego-vehicle
KW  - Feature extraction
KW  - Automobiles
KW  - Videos
KW  - Convolution
KW  - Estimation
KW  - Visualization
DO  - 10.1109/ICRA40945.2020.9197104
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - A vehicle driving along the road is surrounded by many objects, but only a small subset of them influence the driver's decisions and actions. Learning to estimate the importance of each object on the driver's real-time decision-making may help better understand human driving behavior and lead to more reliable autonomous driving systems. Solving this problem requires models that understand the interactions between the ego-vehicle and the surrounding objects. However, interactions among other objects in the scene can potentially also be very helpful, e.g., a pedestrian beginning to cross the road between the ego-vehicle and the car in front will make the car in front less important. We propose a novel framework for object importance estimation using an interaction graph, in which the features of each object node are updated by interacting with others through graph convolution. Experiments show that our model outperforms state-of-the-art baselines with much less input and pre-processing.
ER  - 

TY  - CONF
TI  - A Robotics Inspection System for Detecting Defects on Semi-specular Painted Automotive Surfaces
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8928
EP  - 8934
AU  - S. Akhtar
AU  - A. Tandiya
AU  - M. Moussa
AU  - C. Tarry
PY  - 2020
KW  - automobile industry
KW  - flaw detection
KW  - inspection
KW  - mobile robots
KW  - painting
KW  - quality control
KW  - vibrations
KW  - semispecular painted automotive surfaces
KW  - real-time robotics system
KW  - tolerate varying lighting conditions
KW  - inspected surface
KW  - defect tracking mechanism
KW  - robotics inspection system
KW  - detecting defects
KW  - painted surface defect detection
KW  - small inherent vibrations
KW  - manufacturing operations
KW  - topographical information
KW  - spectral analysis
KW  - quality control
KW  - Inspection
KW  - Surface treatment
KW  - Cameras
KW  - Surface topography
KW  - Robots
KW  - Automobiles
KW  - Surface reconstruction
DO  - 10.1109/ICRA40945.2020.9196980
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper describes the design and implementation of a real-time robotics system for semi-specular/painted surface defect detection. The system can be used on moving parts, tolerate varying lighting conditions, and can accommodate small inherent vibrations of the inspected surface that is common in manufacturing operations. Topographical information of the inspected surface is first obtained by the analysis of reflections of a known pattern from this surface. Spectral analysis is then applied to identify defects through novelty detection. Finally, a defect tracking mechanism eliminates spurious defects. The proposed system operates continuously at 90 fps. The paper presents field testing results that show the system can be used as a consistent and cost-effective way of quality control.
ER  - 

TY  - CONF
TI  - A Novel Underactuated End-Effector for Planar Sequential Grasping of Multiple Objects
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8935
EP  - 8941
AU  - C. Mucchiani
AU  - M. Yim
PY  - 2020
KW  - actuators
KW  - control system synthesis
KW  - dexterous manipulators
KW  - end effectors
KW  - human-robot interaction
KW  - motion control
KW  - torque control
KW  - underactuated end-effector
KW  - planar sequential grasping
KW  - multiple objects
KW  - underactuated end-effector design
KW  - autonomous grasp
KW  - circular objects
KW  - sequential grasps
KW  - human-robot hand-off interactions
KW  - torque control
KW  - Force
KW  - Grasping
KW  - Sensors
KW  - Estimation
KW  - Shape
KW  - Fasteners
KW  - Torque
DO  - 10.1109/ICRA40945.2020.9197380
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We propose a serpentine type tendon driven underactuated end-effector design with a closing mechanism that is triggered upon contact with an object. This end-effector can grasp objects without knowing the size a priori and is able to grasp a new object while securing another one previously grasped, and so grasp multiple objects sequentially with a single DOF actuation. Design parameters based on the object dimensions are proposed. A low-cost prototype demonstrates two implementations (radius estimation and autonomous grasp of circular objects by torque control, and sequential grasps of multiple objects) of the end-effector through several experiments. A method for estimating applied internal forces is also proposed. This end-effector can benefit robotic manipulation in tasks such as fetching applications, industrial pick-and-place of single or multiple objects and human-robot hand-off interactions.
ER  - 

TY  - CONF
TI  - Design and Analysis of a Synergy-Inspired Three-Fingered Hand
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8942
EP  - 8948
AU  - W. Chen
AU  - Z. Xiao
AU  - J. Lu
AU  - Z. Zhao
AU  - Y. Wang
PY  - 2020
KW  - dexterous manipulators
KW  - grippers
KW  - manipulator kinematics
KW  - motion control
KW  - synergy-inspired hands
KW  - biomechanical characteristics
KW  - human hand synergy
KW  - robot hands
KW  - synergy characteristics
KW  - anthropomorphic hands
KW  - synergy-inspired design
KW  - Thumb
KW  - Robots
KW  - Joints
KW  - Muscles
KW  - Grasping
KW  - Electronics packaging
DO  - 10.1109/ICRA40945.2020.9196901
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Hand synergy from neuroscience provides an effective tool for anthropomorphic hands to realize versatile grasping with simple planning and control. This paper aims to extend the synergy-inspired design from anthropomorphic hands to multi-fingered robot hands. The synergy-inspired hands are not necessarily humanoid in morphology but perform primary characteristics and functions similar to the human hand. At first, the biomechanics of hand synergy is investigated. Three biomechanical characteristics of the human hand synergy are explored as a basis for the mechanical simplification of the robot hands. Secondly, according to the synergy characteristics, a three-fingered hand is designed, and its kinematic model is developed for the analysis of some typical grasping and manipulation functions. Finally, a prototype is developed and preliminary grasping experiments validate the effectiveness of the design and analysis.
ER  - 

TY  - CONF
TI  - Multiplexed Manipulation: Versatile Multimodal Grasping via a Hybrid Soft Gripper
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8949
EP  - 8955
AU  - L. Chin
AU  - F. Barscevicius
AU  - J. Lipton
AU  - D. Rus
PY  - 2020
KW  - compliant mechanisms
KW  - dexterous manipulators
KW  - grippers
KW  - motion control
KW  - multiplexed manipulation
KW  - hybrid soft gripper
KW  - hybrid suction
KW  - parallel jaw grippers
KW  - multimodal grippers
KW  - soft robotic manipulators
KW  - soft fingers
KW  - multimodal grasping
KW  - Amazon Robotics/Picking Challenge
KW  - complaint handed shearing auxetics actuators
KW  - Grasping
KW  - Grippers
KW  - Multiplexing
KW  - Force
KW  - Belts
KW  - Manipulators
DO  - 10.1109/ICRA40945.2020.9196626
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The success of hybrid suction + parallel-jaw grippers in the Amazon Robotics/Picking Challenge have demonstrated the effectiveness of multimodal grasping approaches. However, existing multimodal grippers combine grasping modes in isolation and do not incorporate the benefits of compliance found in soft robotic manipulators. In this paper, we present a gripper that integrates three modes of grasping: suction, parallel jaw, and soft fingers. Using complaint handed shearing auxetics actuators as the foundation, this gripper is able to multiplex manipulation by creating unique grasping primitives through permutations of these grasping techniques. This gripper is able to grasp 88% of tested objects, 14% of which could only be grasped using a combination of grasping modes. The gripper is also able to perform in-hand object re-orientation of flat objects without the need for pre-grasp manipulation.
ER  - 

TY  - CONF
TI  - Underactuated Gecko Adhesive Gripper for Simple and Versatile Grasp
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8964
EP  - 8969
AU  - D. Hirano
AU  - N. Tanishima
AU  - A. Bylard
AU  - T. G. Chen
PY  - 2020
KW  - actuators
KW  - adhesion
KW  - adhesives
KW  - grippers
KW  - controllable activation
KW  - minimal disturbance
KW  - form closure
KW  - robotic grasping
KW  - versatile grasp
KW  - underactuated gecko adhesive gripper
KW  - resulting gripper grasp force
KW  - adhesive contact area
KW  - simple tendon-driven mechanism
KW  - underactuated gecko-inspired adhesive gripper
KW  - multiple activation steps
KW  - complex activation mechanism
KW  - grippers
KW  - Grippers
KW  - Force
KW  - Grasping
KW  - Pulleys
KW  - Adhesives
KW  - Actuators
KW  - Tendons
DO  - 10.1109/ICRA40945.2020.9196806
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Gecko-inspired adhesives have several desirable characteristics in robotic grasping: controllable activation and deactivation of adhesion, ability to grasp and release with minimal disturbance, and grasping without the need of form closure. Previously proposed grippers with this technology either require a complex activation mechanism or multiple activation steps. In this paper, we present an underactuated gecko-inspired adhesive gripper that can grasp a wide range of curved surfaces using a single actuator through a simple tendon-driven mechanism that attaches and adheres in one step. We derive a theoretical model of the adhesive contact area and resulting gripper grasp force, which is verified experimentally. The actual performance of the proposed mechanism is demonstrated by successfully grasping several surfaces with different curvature diameters.
ER  - 

TY  - CONF
TI  - Active Deformation through Visual Servoing of Soft Objects
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8978
EP  - 8984
AU  - R. Lagneau
AU  - A. Krupa
AU  - M. Marchal
PY  - 2020
KW  - control engineering computing
KW  - deformation
KW  - eigenvalues and eigenfunctions
KW  - end effectors
KW  - Jacobian matrices
KW  - least squares approximations
KW  - robot vision
KW  - visual servoing
KW  - soft objects
KW  - online estimation
KW  - deformation Jacobian
KW  - robot end-effector
KW  - deformation behavior
KW  - ADVISEd method
KW  - model-free methods
KW  - marker-based active shaping task
KW  - shape preservation tasks
KW  - active deformation through visual servoing method
KW  - model-free deformation servoing method
KW  - weighted least-squares minimization
KW  - sliding window
KW  - eigenvalue-based confidence criterion
KW  - marker-less active shaping
KW  - model-based methods
KW  - Strain
KW  - Jacobian matrices
KW  - Deformable models
KW  - Shape
KW  - Task analysis
KW  - Adaptation models
KW  - Robots
DO  - 10.1109/ICRA40945.2020.9197506
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we propose the ADVISEd (Active Deformation through VIsual SErvoing) method, a novel model-free deformation servoing method able to deform a soft object towards a desired shape. ADVISEd relies on an online estimation of the deformation Jacobian that relates the motion of the robot end-effector to the deformation behavior of the object. The estimation is based on a weighted least-squares minimization with a sliding window. The robustness of the method to observation noise is ensured using an eigenvalue-based confidence criterion. The ADVISEd method is validated through comparisons with a model-based and a model-free state-of-the-art methods. Two experimental setups are proposed to compare the methods, one to perform a marker-based active shaping task and one to perform several marker-less active shaping and shape preservation tasks. Experiments showed that our approach can interactively control the deformations of an object in different tasks while ensuring better robustness to external perturbations than the state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Visual Geometric Skill Inference by Watching Human Demonstration
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 8985
EP  - 8991
AU  - J. Jin
AU  - L. Petrich
AU  - Z. Zhang
AU  - M. Dehghan
AU  - M. Jagersand
PY  - 2020
KW  - control engineering computing
KW  - data visualisation
KW  - entropy
KW  - feature selection
KW  - graph theory
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - regression analysis
KW  - video signal processing
KW  - visual geometric skill inference
KW  - manipulation skills
KW  - human demonstration video
KW  - association relationships
KW  - eye-hand coordination tasks
KW  - geometric control error
KW  - graph based kernel regression method
KW  - association constraints
KW  - human readable task definition
KW  - control errors
KW  - feature-based visual ser-voing
KW  - incremental maximum entropy inverse reinforcement learning
KW  - feature selection
KW  - robust feature trackers
KW  - Task analysis
KW  - Kernel
KW  - Robustness
KW  - Feature extraction
KW  - Robot kinematics
KW  - Three-dimensional displays
DO  - 10.1109/ICRA40945.2020.9196570
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We study the problem of learning manipulation skills from human demonstration video by inferring the association relationships between geometric features. Motivation for this work stems from the observation that humans perform eye-hand coordination tasks by using geometric primitives to define a task while a geometric control error drives the task through execution. We propose a graph based kernel regression method to directly infer the underlying association constraints from human demonstration video using Incremental Maximum Entropy Inverse Reinforcement Learning (InMaxEnt IRL). The learned skill inference provides human readable task definition and outputs control errors that can be directly plugged into traditional controllers. Our method removes the need for tedious feature selection and robust feature trackers required in traditional approaches (e.g. feature-based visual ser-voing). Experiments show our method infers correct geometric associations even with only one human demonstration video and can generalize well under variance.
ER  - 

TY  - CONF
TI  - DFVS: Deep Flow Guided Scene Agnostic Image Based Visual Servoing
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9000
EP  - 9006
AU  - Y. V. S. Harish
AU  - H. Pandya
AU  - A. Gaud
AU  - S. Terupally
AU  - S. Shankar
AU  - K. M. Krishna
PY  - 2020
KW  - cameras
KW  - feature extraction
KW  - image sensors
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - visual servoing
KW  - optical flow
KW  - visual features
KW  - deep neural network
KW  - diverse scenes
KW  - visual servoing approaches
KW  - robust servoing performance
KW  - camera transformations
KW  - deep flow guided scene agnostic image
KW  - deep learning
KW  - relative camera pose
KW  - photo-realistic 3D simulation
KW  - aerial robot
KW  - DFVS
KW  - interaction matrix
KW  - Visual servoing
KW  - Cameras
KW  - Convergence
KW  - Visualization
KW  - Adaptive optics
KW  - Task analysis
DO  - 10.1109/ICRA40945.2020.9196753
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Existing deep learning based visual servoing approaches regress the relative camera pose between a pair of images. Therefore, they require a huge amount of training data and sometimes fine-tuning for adaptation to a novel scene. Furthermore, current approaches do not consider underlying geometry of the scene and rely on direct estimation of camera pose. Thus, inaccuracies in prediction of the camera pose, especially for distant goals, lead to a degradation in the servoing performance. In this paper, we propose a two-fold solution: (i) We consider optical flow as our visual features, which are predicted using a deep neural network. (ii) These flow features are then systematically integrated with depth estimates provided by another neural network using interaction matrix. We further present an extensive benchmark in a photo-realistic 3D simulation across diverse scenes to study the convergence and generalisation of visual servoing approaches. We show convergence for over 3m and 40 degrees while maintaining precise positioning of under 2cm and 1 degree on our challenging benchmark where the existing approaches that are unable to converge for majority of scenarios for over 1.5m and 20 degrees. Furthermore, we also evaluate our approach for a real scenario on an aerial robot. Our approach generalizes to novel scenarios producing precise and robust servoing performance for 6 degrees of freedom positioning tasks with even large camera transformations without any retraining or fine-tuning.
ER  - 

TY  - CONF
TI  - Photometric Path Planning for Vision-Based Navigation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9007
EP  - 9013
AU  - E. A. Rodr√≠guez Mart√≠nez
AU  - G. Caron
AU  - C. P√©gard
AU  - D. L. Alabazares
PY  - 2020
KW  - cameras
KW  - manipulators
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - photometric path planning
KW  - vision-based navigation system
KW  - visual memory
KW  - topological map
KW  - virtual camera
KW  - navigability
KW  - visual path
KW  - navigation stage
KW  - onboard camera
KW  - top view image
KW  - learning stage
KW  - urban scene
KW  - Visualization
KW  - Navigation
KW  - Cameras
KW  - Visual servoing
DO  - 10.1109/ICRA40945.2020.9197091
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present a vision-based navigation system that uses a visual memory to navigate. Such memory corresponds to a topological map of key images created from moving a virtual camera over a model of the real scene. The advantage of our approach is that it provides a useful insight into the navigability of a visual path without relying on a traditional learning stage. During the navigation stage, the robot is controlled by sequentially comparing the images stored in the memory with the images acquired by the onboard camera.The evaluation is conducted on a robotic arm equipped with a camera and the model of the environment corresponds to a top view image of an urban scene.
ER  - 

TY  - CONF
TI  - A memory of motion for visual predictive control tasks
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9014
EP  - 9020
AU  - A. Paolillo
AU  - T. S. Lembono
AU  - S. Calinon
PY  - 2020
KW  - manipulators
KW  - optimal control
KW  - optimisation
KW  - predictive control
KW  - regression analysis
KW  - robot vision
KW  - visual servoing
KW  - visual predictive control tasks
KW  - regression techniques
KW  - control optimization process
KW  - 7-axis manipulator
KW  - image-based visual servoing
KW  - Visualization
KW  - Microsoft Windows
KW  - Trajectory
KW  - Optimization
KW  - Task analysis
KW  - Computational modeling
KW  - Cameras
DO  - 10.1109/ICRA40945.2020.9197216
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper addresses the problem of efficiently achieving visual predictive control tasks. To this end, a memory of motion, containing a set of trajectories built off-line, is used for leveraging precomputation and dealing with difficult visual tasks. Standard regression techniques, such as k-nearest neighbors and Gaussian process regression, are used to query the memory and provide on-line a warm-start and a way point to the control optimization process. The proposed technique allows the control scheme to achieve high performance and, at the same time, keep the computational time limited. Simulation and experimental results, carried out with a 7-axis manipulator, show the effectiveness of the approach.
ER  - 

TY  - CONF
TI  - Design and Workspace Characterisation of Malleable Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9021
EP  - 9027
AU  - A. B. Clark
AU  - N. Rojas
PY  - 2020
KW  - actuators
KW  - design engineering
KW  - elasticity
KW  - end effectors
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - position control
KW  - bin picking
KW  - variable stiffness link
KW  - low DOF serial robot
KW  - 2-DOF malleable robot
KW  - workspace categories
KW  - serial robot arms
KW  - End effectors
KW  - Robot kinematics
KW  - Task analysis
KW  - Mathematical model
KW  - Topology
DO  - 10.1109/ICRA40945.2020.9197439
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - For the majority of tasks performed by traditional serial robot arms, such as bin picking or pick and place, only two or three degrees of freedom (DOF) are required for motion; however, by augmenting the number of degrees of freedom, further dexterity of robot arms for multiple tasks can be achieved. Instead of increasing the number of joints of a robot to improve flexibility and adaptation, which increases control complexity, weight, and cost of the overall system, malleable robots utilise a variable stiffness link between joints allowing the relative positioning of the revolute pairs at each end of the link to vary, thus enabling a low DOF serial robot to adapt across tasks by varying its workspace. In this paper, we present the design and prototyping of a 2-DOF malleable robot, calculate the general equation of its workspace using a parameterisation based on distance geometry-suitable for robot arms of variable topology, and characterise the workspace categories that the end effector of the robot can trace via reconfiguration. Through the design and construction of the malleable robot we explore design considerations, and demonstrate the viability of the overall concept. By using motion tracking on the physical robot, we show examples of the infinite number of workspaces that the introduced 2-DOF malleable robot can achieve.
ER  - 

TY  - CONF
TI  - A Tri-Stable Soft Robotic Finger Capable of Pinch and Wrap Grasps
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9028
EP  - 9034
AU  - A. K. Nguyen
AU  - A. Russell
AU  - N. Naclerio
AU  - V. Vuong
AU  - H. Huang
AU  - K. Chui
AU  - E. W. Hawkes
PY  - 2020
KW  - bending
KW  - dexterous manipulators
KW  - elastomers
KW  - force control
KW  - grippers
KW  - pneumatic actuators
KW  - position control
KW  - springs (mechanical)
KW  - preprogrammed grasp
KW  - constant-curvature wrap
KW  - finger-sized round objects
KW  - flat objects
KW  - small objects
KW  - adaptable tri-stable
KW  - grasped object
KW  - bi-stable springs
KW  - stable positions
KW  - finger bending
KW  - grasping performance
KW  - control gripper
KW  - soft grippers
KW  - wrap grasps
KW  - soft robotic pneumatic grippers
KW  - delicate objects
KW  - fluidic elastomer grippers
KW  - inextensible gripping surface
KW  - extensible pneumatic chambers
KW  - extensibility results
KW  - finger curling
KW  - simple fingers
KW  - tri-stable soft robotic finger
KW  - pinch grasps
KW  - Grippers
KW  - Springs
KW  - Shape
KW  - Soft robotics
KW  - Grasping
KW  - Force
KW  - Mathematical model
DO  - 10.1109/ICRA40945.2020.9196818
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Soft robotic pneumatic grippers have been shown to be versatile, robust to impacts, and safe for use on delicate objects. One type, fluidic elastomer grippers, are characterized by fingers with an inextensible gripping surface backed by extensible pneumatic chambers; when inflated, this mismatch in extensibility results in the finger curling. However, one drawback of these simple fingers is that they have one preprogrammed grasp, usually a simple constant-curvature wrap. While well-suited for finger-sized round objects, they do not grasp flat or small objects well. Here, we present an adaptable tri-stable soft robotic finger that can form either a pinch or wrap grasp based on the shape of the grasped object. We enable this by incorporating two bi-stable springs into the inextensible layer. The three stable positions are: i) open (unpressurized), ii) pinch (with only the proximal section bending), and iii) wrap (with the entire finger bending). We present a simple model of the behavior of our finger and experimental results verifying the model. Further, we apply forces and moments to grasped objects, and show that the tri-stable finger increases the grasping performance when compared to a control gripper with equal gripping force. Our work presents a novel design modification that is unobtrusive, simple, and passive. Our introduction of inexpensive programmable hardware advances the versatility and adaptability of soft grippers.
ER  - 

TY  - CONF
TI  - A Dexterous Tip-extending Robot with Variable-length Shape-locking
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9035
EP  - 9041
AU  - S. Wang
AU  - R. Zhang
AU  - D. A. Haggerty
AU  - N. D. Naclerio
AU  - E. W. Hawkes
PY  - 2020
KW  - biomechanics
KW  - dexterous manipulators
KW  - mobile robots
KW  - position control
KW  - dexterous tip-extending robot
KW  - variable-length shape-locking
KW  - tip-extending vine robots
KW  - distal end
KW  - inextensible tip-extending
KW  - pressurized tip-extending
KW  - robot body
KW  - locked sections
KW  - free sections
KW  - shape-locking mechanism
KW  - shape-locking concept
KW  - soft robotics
KW  - dexterous workspace
KW  - Electron tubes
KW  - Tendons
KW  - Shape
KW  - Educational robots
KW  - Manipulators
KW  - Pneumatic systems
DO  - 10.1109/ICRA40945.2020.9197311
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Soft, tip-extending "vine" robots offer a unique mode of inspection and manipulation in highly constrained environments. For practicality, it is desirable that the distal end of the robot can be manipulated freely, while the body remains stationary. However, in previous vine robots, either the shape of the body was fixed after growth with no ability to manipulate the distal end, or the whole body moved together with the tip. Here, we present a concept for shape-locking that enables a vine robot to move only its distal tip, while the body is locked in place. This is achieved using two inextensible, pressurized, tip-extending, chambers that "grow" along the sides of the robot body, preserving curvature in the section where they have been deployed. The length of the locked and free sections can be varied by controlling the extension and retraction of these chambers. We present models describing this shape-locking mechanism and workspace of the robot in both free and constrained environments. We experimentally validate these models, showing an increased dexterous workspace compared to previous vine robots. Our shape-locking concept allows improved performance for vine robots, advancing the field of soft robotics for inspection and manipulation in highly constrained environments.
ER  - 

TY  - CONF
TI  - Compliant Electromagnetic Actuator Architecture for Soft Robotics
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9042
EP  - 9049
AU  - N. Kohls
AU  - B. Dias
AU  - Y. Mensah
AU  - B. P. Ruddy
AU  - Y. C. Mazumdar
PY  - 2020
KW  - dexterous manipulators
KW  - electromagnetic actuators
KW  - grippers
KW  - liquid metal ion sources
KW  - pneumatic actuators
KW  - compliant electromagnetic actuator architecture
KW  - soft robotics
KW  - soft materials
KW  - compliant actuation concepts
KW  - soft robotic systems
KW  - electromagnetic actuators
KW  - gallium-indium liquid metal conductors
KW  - soft actuator
KW  - Xenia soft corals
KW  - compliant permanent magnetic tips
KW  - robotic actuator
KW  - frequency 7.0 Hz
KW  - size 6.0 mm
KW  - Iron
KW  - Actuators
KW  - Magnetic cores
KW  - Powders
KW  - Electromagnetics
KW  - Magnetic liquids
DO  - 10.1109/ICRA40945.2020.9197442
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Soft materials and compliant actuation concepts have generated new design and control approaches in areas from robotics to wearable devices. Despite the potential of soft robotic systems, most designs currently use hard pumps, valves, and electromagnetic actuators. In this work, we take a step towards fully soft robots by developing a new compliant electromagnetic actuator architecture using gallium-indium liquid metal conductors, as well as compliant permanent magnetic and compliant iron composites. Properties of the new materials are first characterized and then co-fabricated to create an exemplary biologically-inspired soft actuator with pulsing or grasping motions, similar to Xenia soft corals. As current is applied to the liquid metal coil, the compliant permanent magnetic tips on passive silicone arms are attracted or repelled. The dynamics of the robotic actuator are characterized using stochastic system identification techniques and then operated at the resonant frequency of 7 Hz to generate high-stroke (>6 mm) motions.
ER  - 

TY  - CONF
TI  - Dynamically Reconfigurable Discrete Distributed Stiffness for Inflated Beam Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9050
EP  - 9056
AU  - B. H. Do
AU  - V. Banashek
AU  - A. M. Okamura
PY  - 2020
KW  - beams (structures)
KW  - buckling
KW  - cantilevers
KW  - electromagnets
KW  - electromechanical actuators
KW  - jamming
KW  - motion control
KW  - rigidity
KW  - robot kinematics
KW  - valves
KW  - tip-everting robots
KW  - tendonsteering
KW  - robot kinematics
KW  - cantilevered loads
KW  - electromechanical device
KW  - electromagnet
KW  - passive valves
KW  - pressure layer jamming
KW  - buckle point locations
KW  - compressive loads
KW  - actuators
KW  - motion control
KW  - discrete distributed stiffness control
KW  - inflated beam robot body
KW  - inflated continuum robots
KW  - Valves
KW  - Jamming
KW  - Actuators
KW  - Laser beams
KW  - Soft robotics
KW  - Shape
DO  - 10.1109/ICRA40945.2020.9197237
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Inflated continuum robots are promising for a variety of navigation tasks, but controlling their motion with a small number of actuators is challenging. These inflated beam robots tend to buckle under compressive loads, producing extremely tight local curvature at difficult-to-control buckle point locations. In this paper, we present an inflated beam robot that uses distributed stiffness changing sections enabled by positive pressure layer jamming to control or prevent buckling. Passive valves are actuated by an electromagnet carried by an electromechanical device that travels inside the main inflated beam robot body. The valves themselves require no external connections or wiring, allowing the distributed stiffness control to be scaled to long beam lengths. Multiple layer jamming elements are stiffened simultaneously to achieve global stiffening, allowing the robot to support greater cantilevered loads and longer unsupported lengths. Local stiffening, achieved by leaving certain layer jamming elements unstiffened, allows the robot to produce "virtual joints" that dynamically change the robot kinematics. Implementing these stiffening strategies is compatible with growth through tip eversion and tendonsteering, and enables a number of new capabilities for inflated beam robots and tip-everting robots.
ER  - 

TY  - CONF
TI  - Data-Driven Reinforcement Learning for Walking Assistance Control of a Lower Limb Exoskeleton with Hemiplegic Patients
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9065
EP  - 9071
AU  - Z. Peng
AU  - R. Luo
AU  - R. Huang
AU  - J. Hu
AU  - K. Shi
AU  - H. Cheng
AU  - B. K. Ghosh
PY  - 2020
KW  - adaptive control
KW  - artificial limbs
KW  - handicapped aids
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - neural nets
KW  - optimal control
KW  - patient rehabilitation
KW  - wearable robots
KW  - Data-driven reinforcement learning
KW  - lower limb exoskeleton
KW  - hemiplegic patient
KW  - rehabilitation scenario
KW  - affected leg
KW  - unaffected leg
KW  - exoskeleton system
KW  - DDRL strategy
KW  - optimal control
KW  - policy iteration algorithm
KW  - online adaptation control
KW  - walking assistance control
KW  - walking assistance scenario
KW  - strength augmentation scenario
KW  - Actor-Critic Neural Network
KW  - ACNN
KW  - Legged locomotion
KW  - Exoskeletons
KW  - Adaptation models
KW  - Learning (artificial intelligence)
KW  - Trajectory
KW  - Extremities
KW  - Optimal control
KW  - Data-driven Control
KW  - Reinforcement Learning
KW  - Leader-Follower Multi-Agent System
KW  - Lower Limb Exoskeleton
KW  - Hemiplegic Patients
KW  - Actor-Critic Neural Network
DO  - 10.1109/ICRA40945.2020.9197229
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Lower limb exoskeleton (LLE) has received considerable interests in strength augmentation, rehabilitation and walking assistance scenarios. For walking assistance, the LLE is expected to have the capability of controlling the affected leg to track the unaffected leg's motion naturally. An important issue in this scenario is that the exoskeleton system needs to deal with unpredictable disturbance from the patient, which requires the controller of exoskeleton system to have the ability to adapt to different wearers. This paper proposes a novel Data-Driven Reinforcement Learning (DDRL) control strategy to adapt different hemiplegic patients with unpredictable disturbances. In the proposed DDRL strategy, the interaction between two lower limbs of LLE and the legs of hemiplegic patient are modeled in the context of leader-follower framework. The walking assistance control problem is transformed into a optimal control problem. Then, a policy iteration (PI) algorithm is introduced to learn optimal controller. To achieve online adaptation control for different patients, based on PI algorithm, an Actor-Critic Neural Network (ACNN) technology of the reinforcement learning (RL) is employed in the proposed DDRL. We conduct experiments both on a simulation environment and a real LLE system. Experimental results demonstrate that the proposed control strategy has strong robustness against disturbances and adaptability to different pilots.
ER  - 

TY  - CONF
TI  - On the Effects of Visual Anticipation of Floor Compliance Changes on Human Gait: Towards Model-based Robot-Assisted Rehabilitation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9072
EP  - 9078
AU  - M. Drolet
AU  - E. Q. Yumbla
AU  - B. Hobbs
AU  - P. Artemiadis
PY  - 2020
KW  - biomechanics
KW  - feedback
KW  - gait analysis
KW  - mechanoception
KW  - medical robotics
KW  - muscle
KW  - neurophysiology
KW  - patient rehabilitation
KW  - patient treatment
KW  - virtual reality
KW  - poststroke gait rehabilitation
KW  - variable stiffness treadmill
KW  - robot-assisted gait therapies
KW  - feedback mechanisms
KW  - visual feedback
KW  - surface stiffness changes
KW  - repeatable muscle activation patterns
KW  - predictable muscle activation patterns
KW  - surface changes
KW  - proprioceptive feedback
KW  - manipulated visual feedback
KW  - virtual environment
KW  - real-world compliant surfaces
KW  - walking surface stiffness
KW  - sensorimotor mechanisms
KW  - robotic rehabilitation device
KW  - virtual reality experience
KW  - robot-assisted interventions
KW  - rehabilitation method
KW  - robot assistance
KW  - model-based robot-assisted rehabilitation
KW  - human gait
KW  - floor compliance changes
KW  - visual anticipation
KW  - Legged locomotion
KW  - Visualization
KW  - Muscles
KW  - Robot sensing systems
KW  - Perturbation methods
KW  - Electromyography
DO  - 10.1109/ICRA40945.2020.9197536
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The role of various types of robot assistance in post-stroke gait rehabilitation has gained much attention in recent years. Furthermore, there is increased popularity to use more than one rehabilitation method in order to utilize the different advantages of each. Naturally, this results in the need to study how the different robot-assisted interventions affect the various underlying sensorimotor mechanisms involved in rehabilitation. To answer this important question, this paper combines a virtual reality experience with a unique robotic rehabilitation device, the Variable Stiffness Treadmill (VST), as a way of understanding interactions across different sensorimotor mechanisms involved in gait. The VST changes the walking surface stiffness in order to simulate real-world compliant surfaces while seamlessly interacting with a virtual environment. Through the manipulated visual and proprioceptive feedback, this paper focuses on the muscle activation patterns before, during, and after surface changes that are both visually informed and uninformed. The results show that there are predictable and repeatable muscle activation patterns both before and after surface stiffness changes, and these patterns are affected by the perceived visual and proprioceptive feedback. The interaction of feedback mechanisms and their effect on evoked muscular activation can be used in future robot-assisted gait therapies, where the intended muscle responses are informed by deterministic models and are tailored to a specific patient's needs.
ER  - 

TY  - CONF
TI  - A Visual Positioning System for Indoor Blind Navigation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9079
EP  - 9085
AU  - H. Zhang
AU  - C. Ye
PY  - 2020
KW  - cameras
KW  - collision avoidance
KW  - distance measurement
KW  - graph theory
KW  - handicapped aids
KW  - mobile robots
KW  - navigation
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - robot vision
KW  - visual positioning system
KW  - indoor blind navigation
KW  - VPS
KW  - robotic navigation aid
KW  - RNA
KW  - assistive navigation
KW  - depth-enhanced visual-inertial odometry
KW  - RGB-D camera
KW  - inertial measurement unit
KW  - DVIO method
KW  - geometric feature
KW  - floor plane
KW  - measurement residuals
KW  - inertial data
KW  - graph optimization framework
KW  - Sampson error
KW  - near-range visual features
KW  - known depth
KW  - far-range visual features
KW  - estimation accuracy
KW  - particle filter localization method
KW  - PFL
KW  - visually impaired person
KW  - heading error
KW  - accurate pose estimation
KW  - Cameras
KW  - RNA
KW  - Feature extraction
KW  - Visualization
KW  - Pose estimation
KW  - Navigation
KW  - Three-dimensional displays
DO  - 10.1109/ICRA40945.2020.9196782
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents a visual positioning system (VPS) for real-time pose estimation of a robotic navigation aid (RNA) for assistive navigation. The core of the VPS is a new method called depth-enhanced visual-inertial odometry (DVIO) that uses an RGB-D camera and an inertial measurement unit (IMU) to estimate the RNA's pose. The DVIO method extracts the geometric feature (the floor plane) from the camera's depth data and integrates its measurement residuals with that of the visual features and the inertial data in a graph optimization framework for pose estimation. A new measure based on the Sampson error is introduced to describe the measurement residuals of the near-range visual features with a known depth and that of the far-range visual features whose depths are unknown. The measure allows for the incorporation of both types of visual features into graph optimization. The use of the geometric feature and the Sampson error improves pose estimation accuracy and precision. The DVIO method is paired with a particle filter localization (PFL) method to locate the RNA in a 2D floor plan and the information is used to guide a visually impaired person. The PFL reduces the RNA's position and heading error by aligning the camera's depth data with the floor plan map. Together, the DVIO and the PFL allow for accurate pose estimation for wayfinding and 3D mapping for obstacle avoidance. Experimental results demonstrate the usefulness of the RNA in assistive navigation in indoor spaces.
ER  - 

TY  - CONF
TI  - An Outsole-Embedded Optoelectronic Sensor to Measure Shear Ground Reaction Forces During Locomotion
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9086
EP  - 9092
AU  - T. T. H. Duong
AU  - D. R. Whittaker
AU  - D. Zanotto
PY  - 2020
KW  - closed loop systems
KW  - footwear
KW  - force measurement
KW  - force sensors
KW  - gait analysis
KW  - medical robotics
KW  - muscle
KW  - patient rehabilitation
KW  - foot-mounted sensors
KW  - outsole-embedded optoelectronic sensor configuration
KW  - biaxial shear GRFs
KW  - traditional strain-gauge based solutions
KW  - optoelectronic sensors
KW  - footwear structure
KW  - outsole-embedded sensor
KW  - shear ground reaction forces
KW  - online estimation
KW  - 3D ground reaction forces
KW  - closed-loop control
KW  - lower-extremity robotic exoskeletons
KW  - in-verse dynamics
KW  - optimization models
KW  - net joint torques
KW  - muscle forces
KW  - instrumented footwear
KW  - vertical GRFs
KW  - Robot sensing systems
KW  - Footwear
KW  - Force
KW  - Force measurement
KW  - Instruments
KW  - Legged locomotion
KW  - wearable technology
KW  - optoelectronics
KW  - shear force sensor
KW  - instrumented footwear
DO  - 10.1109/ICRA40945.2020.9196962
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Online estimation of 3D ground reaction forces (GRFs) is becoming increasingly important for closed-loop control of lower-extremity robotic exoskeletons. Through in-verse dynamics and optimization models, 3D GRFs can be used to estimate net joint torques and approximate muscle forces. Although instrumented footwear to measure vertical GRFs in out-of-the-lab environments is available, accurately measuring shear GRFs with foot-mounted sensors still remains a challenging task. In this paper, a new outsole-embedded optoelectronic sensor configuration that is able to measure biaxial shear GRFs is proposed. Compared with traditional strain-gauge based solutions, optoelectronic sensors allow for a more affordable design. To mitigate the risk of altering the wearer's natural gait, the proposed solution does not involve external modifications to the footwear structure. A preliminary validation of the outsole-embedded sensor was conducted against validated laboratory equipment. The test involved two sessions of treadmill walking at different speeds. Experimental results suggest that the proposed design may be a promising solution for measuring shear GRFs in unconstrained environments.
ER  - 

TY  - CONF
TI  - Bump‚Äôem: an Open-Source, Bump-Emulation System for Studying Human Balance and Gait
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9093
EP  - 9099
AU  - G. R. Tan
AU  - M. Raitor
AU  - S. H. Collins
PY  - 2020
KW  - closed loop systems
KW  - force control
KW  - gait analysis
KW  - geriatrics
KW  - injuries
KW  - mechanoception
KW  - medical computing
KW  - medical control systems
KW  - open-source bump-emulation system
KW  - robotic rope-driven system
KW  - human gait
KW  - fall-inducing perturbations
KW  - laboratory-based perturbation systems
KW  - aging population
KW  - fall-related injury
KW  - human balance
KW  - open-loop system
KW  - closed-loop force control
KW  - open-loop force control
KW  - transverse plane
KW  - force-fields
KW  - Brushless motors
KW  - Perturbation methods
KW  - Force
KW  - Force sensors
KW  - Shafts
KW  - Force control
KW  - Legged locomotion
DO  - 10.1109/ICRA40945.2020.9197105
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Fall-related injury is a significant health problem on a global scale and is expected to grow with the aging population. Laboratory-based perturbation systems have the capability of simulating various modes of fall-inducing perturbations in a repeatable way. These systems enable fundamental research on human gait and balance and facilitate the development of devices to assist human balance. We present a robotic, rope-driven system capable of rendering bumps and force-fields at a person's pelvis in any direction in the transverse plane with forces up to 200 N, and a 90% rise time of as little as 44 ms, which is faster than a human's ability to sense and respond to the force. These capabilities enable experiments that require stabilizing or destabilizing subjects as they stand or walk on a treadmill. To facilitate use by researchers from all backgrounds, we designed both a configuration with simpler open-loop force control, and another with higher-performance, closed-loop force control. Both configurations are modular, and the open-loop system is made entirely from 3D-printed and catalog components. The design files and assembly instructions for both are freely available in an online repository.
ER  - 

TY  - CONF
TI  - A Hybrid, Soft Exoskeleton Glove Equipped with a Telescopic Extra Thumb and Abduction Capabilities
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9100
EP  - 9106
AU  - L. Gerez
AU  - A. Dwivedi
AU  - M. Liarokapis
PY  - 2020
KW  - dexterous manipulators
KW  - diseases
KW  - force feedback
KW  - grippers
KW  - handicapped aids
KW  - motion control
KW  - patient rehabilitation
KW  - quality assessment experiments
KW  - inflatable thumb
KW  - grasp stability
KW  - hybrid assistive glove
KW  - grasping capabilities
KW  - hand exoskeletons
KW  - neurological diseases
KW  - musculoskeletal diseases
KW  - wearable gloves
KW  - exoskeleton glove
KW  - pneumatic telescopic extra thumb
KW  - force exertion experiments
KW  - activities of daily living
KW  - Actuators
KW  - Thumb
KW  - Exoskeletons
KW  - Tendons
KW  - Robots
KW  - Pneumatic systems
KW  - Grasping
DO  - 10.1109/ICRA40945.2020.9197473
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Over the last years, hand exoskeletons have become a popular and efficient technical solution for assisting people that suffer from neurological and musculoskeletal diseases and enhance the capabilities of healthy individuals. These devices can vary from rigid and complex structures to soft, lightweight, wearable gloves. Despite the significant progress in the field, most existing solutions do not provide the same dexterity as the healthy human hand. In this paper, we focus on the development of a hybrid (tendon-driven and pneumatic), lightweight, affordable, wearable exoskeleton glove equipped with abduction/adduction capabilities and a pneumatic telescopic extra thumb that increases grasp stability. The efficiency of the proposed device is experimentally validated through three different types of experiments: i) abduction/adduction tests, ii) force exertion experiments that capture the maximum forces that can be applied by the proposed device, and iii) grasp quality assessment experiments that focus on the effect of the inflatable thumb on enhancing grasp stability. The hybrid assistive glove considerably improves the grasping capabilities of the user, being able to exert the forces required to assist people in the execution of activities of daily living.
ER  - 

TY  - CONF
TI  - Controlling an upper-limb exoskeleton by EMG signal while carrying unknown load
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9107
EP  - 9113
AU  - B. Treussart
AU  - F. Geffard
AU  - N. Vignais
AU  - F. Marin
PY  - 2020
KW  - biomechanics
KW  - electromyography
KW  - force sensors
KW  - human-robot interaction
KW  - medical robotics
KW  - medical signal processing
KW  - muscle
KW  - wireless EMG
KW  - movement direction
KW  - intensity estimation
KW  - gravity compensation
KW  - EMG armband
KW  - EMG signal
KW  - traditional gravity compensation
KW  - intuitive control law
KW  - human-robot collaboration
KW  - force sensors
KW  - freedom upper-limb exoskeleton
KW  - Exoskeletons
KW  - Electromyography
KW  - Torque
KW  - Robots
KW  - Muscles
KW  - Gravity
KW  - Task analysis
DO  - 10.1109/ICRA40945.2020.9197087
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Implementing an intuitive control law for an upper-limb exoskeleton dedicated to force augmentation is a challenging issue in the field of human-robot collaboration. The aim of this study is to design an innovative approach to assist carrying an unknown load without using force sensors or specific handle. The method is based on user's intentions estimated through a wireless EMG armband allowing movement direction and intensity estimation along 1 Degree of Freedom. This control law aimed to behave like a gravity compensation except that the mass of the load does not need to be known. The proposed approach was tested on 10 participants during a lifting task with a single Degree of Freedom upper-limb exoskeleton. Participants performed it in three different conditions : without assistance, with an exact gravity compensation and with the proposed method based on EMG armband. The evaluation of the efficiency of the assistance was based on EMG signals captured on seven muscles (objective indicator) and a questionnaire (subjective indicator). Results showed a statically significant reduction of mean activity of the biceps, erector spinae and deltoid by 20%¬±14%, 18%¬±12% and 25% ¬± 16% respectively while comparing the proposed method with no assistance. In addition, similar muscle activities were found both in the proposed method and the traditional gravity compensation. Subjective evaluation showed better precision, efficiency and responsiveness of the proposed method compared to the traditional one.
ER  - 

TY  - CONF
TI  - Learning Grasping Points for Garment Manipulation in Robot-Assisted Dressing
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9114
EP  - 9120
AU  - F. Zhang
AU  - Y. Demiris
PY  - 2020
KW  - assisted living
KW  - clothing
KW  - collision avoidance
KW  - dexterous manipulators
KW  - end effectors
KW  - grippers
KW  - handicapped aids
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - neurocontrollers
KW  - position control
KW  - robot vision
KW  - robot-assisted dressing system
KW  - dressing activities
KW  - grasping point estimations
KW  - Baxter robot
KW  - robot-garment collision avoidance
KW  - orientation computation
KW  - grasping point prediction
KW  - depth images
KW  - supervised deep neural network
KW  - robotic manipulation
KW  - robot end-effector
KW  - robot configuration
KW  - elderly people
KW  - disabled people
KW  - assistive robots
KW  - garment manipulation
KW  - Clothing
KW  - Robots
KW  - Grasping
KW  - Collision avoidance
KW  - Rails
KW  - Neural networks
KW  - Training
DO  - 10.1109/ICRA40945.2020.9196994
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Assistive robots have the potential to provide tremendous support for disabled and elderly people in their daily dressing activities. Recent studies on robot-assisted dressing usually simplify the setup of the initial robot configuration by manually attaching the garments on the robot end-effector and positioning them close to the user's arm. A fundamental challenge in automating such a process for robots is computing suitable grasping points on garments that facilitate robotic manipulation. In this paper, we address this problem by introducing a supervised deep neural network to locate a predefined grasping point on the garment, using depth images for their invariance to color and texture. To reduce the amount of real data required, which is costly to collect, we leverage the power of simulation to produce large amounts of labeled data. The network is jointly trained with synthetic datasets of depth images and a limited amount of real data. We introduce a robot-assisted dressing system that combines the grasping point prediction method, with a grasping and manipulation strategy which takes grasping orientation computation and robot-garment collision avoidance into account. The experimental results demonstrate that our method is capable of yielding accurate grasping point estimations. The proposed dressing system enables the Baxter robot to autonomously grasp a hospital gown hung on a rail, bring it close to the user and successfully dress the upper-body.
ER  - 

TY  - CONF
TI  - TACTO-Selector: Enhanced Hierarchical Fusion of PBVS with Reactive Skin Control for Physical Human-Robot Interaction
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9121
EP  - 9127
AU  - A. E. H. Martin
AU  - E. Dean-Leon
AU  - G. Cheng
PY  - 2020
KW  - haptic interfaces
KW  - human-robot interaction
KW  - industrial robots
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - robot vision
KW  - visual servoing
KW  - reactive skin control
KW  - 6 DOF industrial robot
KW  - physical human-robot interaction
KW  - industrial scenarios
KW  - hierarchical task approaches
KW  - low priority tasks
KW  - standard hierarchical fusion
KW  - tactile interaction
KW  - safety task
KW  - 6 DOF position-based visual servoing task
KW  - interactive task-reconfiguring approach
KW  - TACTO-selector
KW  - PBVS
KW  - Task analysis
KW  - Collision avoidance
KW  - Skin
KW  - Robot sensing systems
KW  - Safety
DO  - 10.1109/ICRA40945.2020.9196979
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In a physical Human-Robot Interaction for industrial scenarios is paramount to guarantee the safety of the user while keeping the robot's performance. Hierarchical task approaches are not sufficient since they tend to sacrifice the low priority tasks in order to guarantee the consistency of the main task. To handle this problem, we enhance the standard hierarchical fusion by introducing a novel interactive task-reconfiguring approach (TACTO-Selector) that uses the information of the tactile interaction to adapt the dimension of the tasks, therefore guaranteeing the execution of the safety task while performing the other task as good as possible. In this work, we hierarchically combine a 6 DOF Position-Based Visual Servoing (PBVS) task with a reactive skin control. This approach was evaluated on a 6 DOF industrial robot showing an improvement of 36.37% on average in tracking error reduction compared with a standard approach.
ER  - 

TY  - CONF
TI  - Towards an Intelligent Collaborative Robotic System for Mixed Case Palletizing
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9128
EP  - 9134
AU  - E. Lamon
AU  - M. Leonori
AU  - W. Kim
AU  - A. Ajoudani
PY  - 2020
KW  - graphical user interfaces
KW  - groupware
KW  - human-robot interaction
KW  - industrial robots
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - palletising
KW  - production engineering computing
KW  - visual perception
KW  - collaborative palletizing tasks
KW  - intelligent collaborative robotic system
KW  - mixed case palletizing
KW  - visual perception algorithms
KW  - high-level optimisation
KW  - graphical user interface
KW  - Mobile COllaborative robotic Assistant
KW  - human-robot collaborative framework
KW  - MOCA
KW  - packing density maximisation
KW  - Pallets
KW  - Task analysis
KW  - Collaboration
KW  - Robots
KW  - Impedance
KW  - Torque
KW  - Resource management
DO  - 10.1109/ICRA40945.2020.9196850
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, a novel human-robot collaborative framework for mixed case palletizing is presented. The framework addresses several challenges associated with the detection and localisation of boxes and pallets through visual perception algorithms, high-level optimisation of the collaborative effort through effective role-allocation principles, and maximisation of packing density. A graphical user interface (GUI) is additionally developed to ensure an intuitive allocation of roles and the optimal placement of the boxes on target pallets. The framework is evaluated in two conditions where humans operate with and without the support of a Mobile COllaborative robotic Assistant (MOCA). The results show that the optimised placement can improve up to the 20% with respect to a manual execution of the same task, and reveal the high potential of MOCA in increasing the performance of collaborative palletizing tasks.
ER  - 

TY  - CONF
TI  - Treadmill Based Three Tether Parallel Robot for Evaluating Auditory Warnings While Running
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9135
EP  - 9142
AU  - N. G. Luttmer
AU  - T. E. Truong
AU  - A. M. Boynton
AU  - D. Carrier
AU  - M. A. Minor
PY  - 2020
KW  - force control
KW  - gait analysis
KW  - human-robot interaction
KW  - medical robotics
KW  - patient rehabilitation
KW  - statistical testing
KW  - three-term control
KW  - virtual reality
KW  - walking running subjects
KW  - treadmill
KW  - T-test
KW  - auditory warnings
KW  - 3 DoF parallel cable system
KW  - Utah's Treadport Active Wind Tunnel
KW  - gait algorithms
KW  - PID force controller
KW  - three tether parallel robot
KW  - Nexus VICON motion capture
KW  - sports related concussions
KW  - hemiparetic rehabilitation
KW  - immersive virtual reality locomotion system
KW  - Perturbation methods
KW  - Force
KW  - Legged locomotion
KW  - Muscles
KW  - Pulleys
KW  - Tracking
DO  - 10.1109/ICRA40945.2020.9196600
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We design and test a 3 DoF parallel cable system capable of applying precise and accurate impulses to walking and running subjects for the University of Utah's Treadport Active Wind Tunnel (TPAWT). Using Nexus VICON motion capture and gait algorithms, perturbations can be applied at different points in the subject's gait. The use of a PID force controller allow the system to create omnidirectional perturbations with walking and running subjects while having the capability to vary amplitude and direction of perturbations. Analysis is presented of the workspace of the large treadmill to test whether the workspace available to activate these perturbations is safe. This paper reports the efficacy of the system and evaluates how warning a runner before impact may affect their displacement. Participants experienced 48 perturbations while running applied with a random combination of a front/back/left/right impact at either toe-off or mid-stance with or without warning. A two sample T-test reveals that warning a runner before impact significantly reduced the magnitude they were displaced for both toe-off (t(46) = 4.98 p<; .001) and mid-stance (t(46) = 3.44, p = .001).
ER  - 

TY  - CONF
TI  - Evaluation of Human-Robot Object Co-manipulation Under Robot Impedance Control
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9143
EP  - 9149
AU  - M. Mujica
AU  - M. Benoussaad
AU  - J. -Y. Fourquet
PY  - 2020
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - trajectory control
KW  - object dynamical properties
KW  - robot impedance control
KW  - human-robot collaboration
KW  - human-robot object co-manipulation
KW  - pHRI
KW  - 7-dof Kuka LBR iiwa 14 R820 robot
KW  - human trajectory
KW  - robot control law
KW  - human forces
KW  - interaction quality metrics
KW  - interaction comfort
KW  - human safety
KW  - physical human-robot interaction
KW  - continuous physical interaction
KW  - Collaboration
KW  - Task analysis
KW  - Impedance
KW  - Manipulators
KW  - Service robots
KW  - Force
DO  - 10.1109/ICRA40945.2020.9197329
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The human-robot collaboration is a promising and challenging field of robotics research. One of the main collaboration tasks is the object co-manipulation where the human and robot are in a continuous physical interaction and forces exerted must be handled. This involves some issues known in robotics as physical Human-Robot Interaction (pHRI), where human safety and interaction comfort are required. Moreover, a definition of interaction quality metrics would be relevant. In the current work, the assessment of Human-Robot object co-manipulation task was explored through the proposed metrics of interaction quality, based on human forces throughout the movement. This analysis is based on co-manipulation of objects with different dynamical properties (weight and inertia), with and without including these properties knowledge in the robot control law. Here, the human is a leader of task and the robot the follower without any information of the human trajectory and movement profile. For the robot control law, a well-known impedance control was applied on a 7-dof Kuka LBR iiwa 14 R820 robot. Results show that the consideration of object dynamical properties in the robot control law is crucial for a good and more comfortable interaction. Besides, human efforts are more significant with a higher no-considered weight, whereas it remains stable when these weights were considered.
ER  - 

TY  - CONF
TI  - Whole-Body Bilateral Teleoperation of a Redundant Aerial Manipulator
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9150
EP  - 9156
AU  - A. Coelho
AU  - H. Singh
AU  - K. Kondak
AU  - C. Ott
PY  - 2020
KW  - autonomous aerial vehicles
KW  - delays
KW  - end effectors
KW  - force feedback
KW  - haptic interfaces
KW  - manipulator dynamics
KW  - mobile robots
KW  - position control
KW  - redundant manipulators
KW  - robot vision
KW  - telerobotics
KW  - video cameras
KW  - redundant aerial manipulator
KW  - robotic manipulator
KW  - flying base
KW  - reachability
KW  - manipulation task
KW  - human capabilities
KW  - telemanipulation tasks
KW  - visual feedback
KW  - task-dependent
KW  - video camera
KW  - end-effector motion
KW  - base position
KW  - stable bilateral teleoperation
KW  - time-delayed telemanipulation
KW  - whole-body bilateral teleoperation
KW  - null-space wall
KW  - haptic concept
KW  - kinematic structure
KW  - task-dependent optimal pose
KW  - Task analysis
KW  - Manipulators
KW  - Haptic interfaces
KW  - Cameras
KW  - Null space
KW  - Robot vision systems
DO  - 10.1109/ICRA40945.2020.9197028
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Attaching a robotic manipulator to a flying base allows for significant improvements in the reachability and versatility of manipulation tasks. In order to explore such systems while taking advantage of human capabilities in terms of perception and cognition, bilateral teleoperation arises as a reasonable solution. However, since most telemanipulation tasks require visual feedback in addition to the haptic one, real-time (task-dependent) positioning of a video camera, which is usually attached to the flying base, becomes an additional objective to be fulfilled. Since the flying base is part of the kinematic structure of the robot, if proper care is not taken, moving the video camera could undesirably disturb the end-effector motion. For that reason, the necessity of controlling the base position in the null space of the manipulation task arises. In order to provide the operator with meaningful information about the limits of the allowed motions in the null space, this paper presents a novel haptic concept called Null-Space Wall. In addition, a framework to allow stable bilateral teleoperation of both tasks is presented. Numerical simulation data confirm that the proposed framework is able to keep the system passive while allowing the operator to perform time-delayed telemanipulation and command the base to a task-dependent optimal pose.
ER  - 

TY  - CONF
TI  - Shared Autonomous Interface for Reducing Physical Effort in Robot Teleoperation via Human Motion Mapping
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9157
EP  - 9163
AU  - T. -C. Lin
AU  - A. Unni Krishnan
AU  - Z. Li
PY  - 2020
KW  - humanoid robots
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - telerobotics
KW  - mobile humanoid robot
KW  - general-purpose assistive tasks
KW  - motion mapping
KW  - human motion
KW  - robot teleoperation
KW  - autonomous interface
KW  - teleoperation interfaces
KW  - task completion time
KW  - assistance function
KW  - teleoperator
KW  - autonomous grasping function
KW  - Task analysis
KW  - Fatigue
KW  - Muscles
KW  - Grasping
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/ICRA40945.2020.9197220
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Motion mapping is an intuitive method of teleoperation with a low learning curve. Our previous study investigates the physical fatigue caused by teleoperating a robot to perform general-purpose assistive tasks and this fatigue affects the operator's performance. The results from that study indicate that physical fatigue happens more in the tasks which involve more precise manipulation and steady posture maintenance. In this paper, we investigate how teleoperation assistance in terms of shared autonomy can reduce the physical workload in robot teleoperation via motion mapping. Specifically, we conduct a user study to compare the muscle effort in teleoperating a mobile humanoid robot to (1) reach and grasp an individual object and (2) collect objects in a cluttered workspace with and without an autonomous grasping function that can be triggered manually by the teleoperator. We also compare the participants' task performance, subjective user experience, and change in attitude towards the usage of teleoperation assistance in the future based on their experience using the assistance function. Our results show that: (1) teleoperation assistance like autonomous grasping can effectively reduce the physical effort, task completion time and number of errors; (2) based on their experience performing the tasks with and without assistance, the teleoperators reported that they would prefer to use automated functions for future teleoperation interfaces.
ER  - 

TY  - CONF
TI  - DexPilot: Vision-Based Teleoperation of Dexterous Robotic Hand-Arm System
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9164
EP  - 9170
AU  - A. Handa
AU  - K. Van Wyk
AU  - W. Yang
AU  - J. Liang
AU  - Y. -W. Chao
AU  - Q. Wan
AU  - S. Birchfield
AU  - N. Ratliff
AU  - D. Fox
PY  - 2020
KW  - dexterous manipulators
KW  - robot vision
KW  - telerobotics
KW  - vision-based teleoperation
KW  - dexterous robotic hand-arm system
KW  - robotic systems
KW  - reasoning skills
KW  - depth-based teleoperation system
KW  - DoA robotic system
KW  - DexPilot
KW  - degree-of-actuation
KW  - multifingered robots
KW  - pick-and-place operations
KW  - Tracking
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Robot sensing systems
KW  - Cameras
KW  - Neural networks
DO  - 10.1109/ICRA40945.2020.9197124
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Teleoperation offers the possibility of imparting robotic systems with sophisticated reasoning skills, intuition, and creativity to perform tasks. However, teleoperation solutions for high degree-of-actuation (DoA), multi-fingered robots are generally cost-prohibitive, while low-cost offerings usually offer reduced degrees of control. Herein, a low-cost, depth-based teleoperation system, DexPilot, was developed that allows for complete control over the full 23 DoA robotic system by merely observing the bare human hand. DexPilot enabled operators to solve a variety of complex manipulation tasks that go beyond simple pick-and-place operations and performance was measured through speed and reliability metrics. DexPilot cost-effectively enables the production of high dimensional, multi-modality, state-action data that can be leveraged in the future to learn sensorimotor policies for challenging manipulation tasks. The videos of the experiments can be found at https://sites.google.com/view/dex-pilot.
ER  - 

TY  - CONF
TI  - Distributed Winner-Take-All Teleoperation of A Multi-Robot System
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9171
EP  - 9177
AU  - Y. Yang
AU  - D. Constantinescu
AU  - Y. Shi
PY  - 2020
KW  - decision making
KW  - Lyapunov methods
KW  - multi-robot systems
KW  - protocols
KW  - stability
KW  - telerobotics
KW  - team cohesion
KW  - dynamic decision-making protocol
KW  - decision variable
KW  - slave robots
KW  - decision-making algorithm
KW  - 3-masters-11-slaves teleoperation
KW  - distributed winner-take-all teleoperation
KW  - multirobot system
KW  - multimaster-multislave teleoperation system
KW  - Lyapunov stability analysis
KW  - Robots
KW  - Decision making
KW  - Protocols
KW  - Heuristic algorithms
KW  - Indexes
KW  - Force
KW  - Multi-robot systems
DO  - 10.1109/ICRA40945.2020.9197535
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In a distributed multi-master-multi-slave teleoperation system, the human users may compete against each other for the control of the team of slave robots. To win the competition, one operator would send the largest command to the slave group. For the sake of team cohesion, the slave group should follow the command of the winning operator and ignore the commands of the other users. To enable (i) the slave team to identify the winning operator, and (ii) each slave to determine whether to admit or discard the command it receives from its operator, this paper proposes a dynamic decision-making protocol that distinguishes the decision variable of the slave commanded by the winner from the decision variables of all other slave robots. The protocol only requires the slaves to exchange and evaluate their decision variables locally. Lyapunov stability analysis proves the theoretical convergence of the proposed decision-making algorithm. An experimental distributed winner-take-all teleoperation in a 3-masters-11-slaves teleoperation testbed validates its practical efficacy.
ER  - 

TY  - CONF
TI  - Enhanced Teleoperation Using Autocomplete
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9178
EP  - 9184
AU  - M. K. Zein
AU  - A. Sidaoui
AU  - D. Asmar
AU  - I. H. Elhajj
PY  - 2020
KW  - autonomous aerial vehicles
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - telerobotics
KW  - enhanced teleoperation
KW  - Autocomplete
KW  - remote location
KW  - skilled teleoperators
KW  - training time
KW  - novice teleoperators
KW  - human input
KW  - desired motion
KW  - machine learning
KW  - motion primitives
KW  - unmanned aerial vehicle
KW  - Task analysis
KW  - Trajectory
KW  - Robots
KW  - Training
KW  - Support vector machines
KW  - Manuals
KW  - Drones
DO  - 10.1109/ICRA40945.2020.9197140
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Controlling and manning robots from a remote location is difficult because of the limitations one faces in perception and available degrees of actuation. Although humans can become skilled teleoperators, the amount of training time required to acquire such skills is typically very high. In this paper, we propose a novel solution (named Autocomplete) to aid novice teleoperators in manning robots adroitly. At the input side, Autocomplete relies on machine learning to detect and categorize human inputs as one from a group of motion primitives. Once a desired motion is recognized, at the actuation side an automated command replaces the human input in performing the desired action. So far, Autocomplete can recognize and synthesize lines, arcs, full circles, 3-D helices, and sine trajectories. Autocomplete was tested in simulation on the teleoperation of an unmanned aerial vehicle, and results demonstrate the advantages of the proposed solution versus manual steering.
ER  - 

TY  - CONF
TI  - Contact-based Bounding Volume Hierarchy for Assembly Tasks
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9185
EP  - 9190
AU  - E. Shellshear
AU  - Y. Li
AU  - R. Bohlin
AU  - J. S. Carlson
PY  - 2020
KW  - assembling
KW  - collision avoidance
KW  - computational geometry
KW  - industrial control
KW  - path planning
KW  - distance computation algorithms
KW  - path planning
KW  - contact-based assembly tasks
KW  - collision queries
KW  - distance queries
KW  - bounding volume hierarchy
KW  - broad phase proximity query algorithm
KW  - contact-based hierarchy for assembly tasks
KW  - CHAT tasks
KW  - Path planning
KW  - Task analysis
KW  - Geometry
KW  - Buildings
KW  - Planning
KW  - Measurement
KW  - Solid modeling
DO  - 10.1109/ICRA40945.2020.9196573
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Path planning of an object which is allowed to be in contact with other objects during assembly process is a significant challenge due to the variety of permitted or forbidden collisions between the distinct parts of the objects to be assembled. In order to put objects together in real-life scenarios, parts of assembled objects may be required to flex, whereas other parts may have to fit exactly. Consequently, existing collision checking and distance computation algorithms have to be modified to enable path planning of objects that can be in contact during the assembly process. In this paper, we analyze an improved broad phase proximity query algorithm to enable such contact-based assembly tasks we call CHAT (Contact-based Hierarchy for Assembly Tasks). We demonstrate that, compared to existing approaches, our proposed method is more than an order of magnitude faster for collision queries and up to three times faster for distance queries when the two objects contain a large number of parts (with some parts containing thousands or tens of thousands of triangles). Due to the nature of the algorithm, we expect the performance improvements to increase as the number of parts in an object becomes larger.
ER  - 

TY  - CONF
TI  - Construction of Bounding Volume Hierarchies for Triangle Meshes with Mixed Face Sizes
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9191
EP  - 9195
AU  - Y. Li
AU  - E. Shellshear
AU  - R. Bohlin
AU  - J. S. Carlson
PY  - 2020
KW  - collision avoidance
KW  - computational geometry
KW  - computer graphics
KW  - manufacturing industries
KW  - mesh generation
KW  - trees (mathematics)
KW  - BVH node
KW  - IPS CDC
KW  - split axis
KW  - split position
KW  - IPS Path Planner
KW  - collision-free disassembly paths
KW  - bounding volume hierarchies
KW  - mixed face sizes
KW  - BVH
KW  - complex 3D geometries
KW  - triangle meshes
KW  - collision and distance computation module
KW  - manufacturing industries
KW  - tighter-fitting bounding volumes
KW  - IP networks
KW  - Covariance matrices
KW  - Three-dimensional displays
KW  - Tensile stress
KW  - Cost function
KW  - Path planning
KW  - Geometry
DO  - 10.1109/ICRA40945.2020.9197113
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We consider the problem of creating tighter-fitting bounding volumes (more specifically rectangular swept spheres) when constructing bounding volume hierarchies (BVHs) for complex 3D geometries given in the form of unstructured triangle meshes/soups with the aim of speeding up our IPS Path Planner for rigid bodies, where the triangles often have very different sizes. Currently, the underlying collision and distance computation module (IPS CDC) does not take into account the sizes of the triangles when it constructs BVHs using a top-down strategy. To split triangles in a BVH node into two BVH nodes, IPS CDC has to compute both the split axis and the split position. In this work, we use the principal axes of the tensor of inertia as the potential split axes and the center of mass as the split position, where the computations of both the tensor of inertia and the center of mass require knowledge of the areas of the triangles. We show that our method improves performance (up to 20 % faster) of our IPS Path Planner when it is used to plan collision-free disassembly paths for three different test cases taken from manufacturing industries.
ER  - 

TY  - CONF
TI  - Strategy for automated dense parking: how to navigate in narrow lanes*
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9196
EP  - 9202
AU  - P. Polack
AU  - L. -M. Dallen
AU  - A. Cord
PY  - 2020
KW  - automobiles
KW  - Global Positioning System
KW  - Lyapunov methods
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - path planning
KW  - road traffic control
KW  - narrow lanes
KW  - high- density parking solution
KW  - car-like robots
KW  - hard constraints
KW  - robot motion
KW  - robot localization
KW  - navigation
KW  - configuration space formulation
KW  - Stanley Robotics robots
KW  - automated dense parking
KW  - Lyapunov- based control strategy
KW  - GPS orientation
KW  - Robots
KW  - Collision avoidance
KW  - Aerospace electronics
KW  - Navigation
KW  - Mathematical model
KW  - Kinematics
KW  - Automobiles
DO  - 10.1109/ICRA40945.2020.9197088
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents the architecture of a high- density parking solution based on car-like robots specifically designed to move cars. The main difficulty is to park the vehicles close to one another which implies hard constraints on the robot motion and localization. In particular, this paper focuses on navigation in narrow lanes. We propose a Lyapunov- based control strategy that has been derived after expressing the problem in a Configuration Space formulation. The current solution has been implemented and tested on Stanley Robotics' robots and has been running in production for several months. Thanks to the Configuration Space formulation, we are able to guarantee the obstacles' integrity. Moreover, a method for calibrating the GPS orientation with a high-precision is derived from the present control strategy.
ER  - 

TY  - CONF
TI  - Multimodal Trajectory Predictions for Urban Environments Using Geometric Relationships between a Vehicle and Lanes
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9203
EP  - 9209
AU  - A. Kawasaki
AU  - A. Seki
PY  - 2020
KW  - feature extraction
KW  - object detection
KW  - road traffic
KW  - road vehicles
KW  - traffic engineering computing
KW  - autonomous driving systems
KW  - traffic behavior
KW  - urban environments
KW  - road geometries
KW  - lane-based multimodal prediction network
KW  - arbitrary shapes
KW  - traffic lanes
KW  - future trajectory
KW  - lane geometry
KW  - lane feature
KW  - generalized geometric relationships
KW  - vehicle state
KW  - vehicle motion model constraint
KW  - prediction method
KW  - multimodal trajectory predictions
KW  - safe driving systems
KW  - LAMP-Net
KW  - Trajectory
KW  - Predictive models
KW  - Hidden Markov models
KW  - Acceleration
KW  - Geometry
KW  - Shape
KW  - Urban areas
DO  - 10.1109/ICRA40945.2020.9196738
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Implementation of safe and efficient autonomous driving systems requires accurate prediction of the long-term trajectories of surrounding vehicles. High uncertainty in traffic behavior makes it difficult to predict trajectories in urban environments, which have various road geometries. To over-come this problem, we propose a method called lane-based multimodal prediction network (LAMP-Net), which can handle arbitrary shapes and numbers of traffic lanes and predict both the future trajectory along each lane and the probability of each lane being selected. A vector map is used to define the lane geometry and a novel lane feature is introduced to represent the generalized geometric relationships between the vehicle state and lanes. Our network takes this feature as the input and is trained to be versatile for arbitrarily shaped lanes. Moreover, we introduce a vehicle motion model constraint to our network. Our prediction method combined with the constraint significantly enhances prediction accuracy. We evaluate the prediction performance on two datasets which contain a wide variety of real-world traffic scenarios. Experimental results show that our proposed LAMP-Net outperforms state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Online optimal motion generation with guaranteed safety in shared workspace
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9210
EP  - 9215
AU  - P. Zheng
AU  - P. -B. Wieber
AU  - O. Aycard
PY  - 2020
KW  - collision avoidance
KW  - industrial manipulators
KW  - motion control
KW  - occupational safety
KW  - path planning
KW  - predictive control
KW  - online optimal motion generation
KW  - guaranteed safety
KW  - shared workspace
KW  - safer manipulator robots
KW  - serious injury
KW  - equip robots
KW  - online motion generation
KW  - partially unknown dynamic environment
KW  - industrial manipulator robots
KW  - model predictive control scheme
KW  - Collision avoidance
KW  - Trajectory
KW  - Safety
KW  - Manipulators
KW  - Robot sensing systems
KW  - Service robots
DO  - 10.1109/ICRA40945.2020.9197018
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - With new, safer manipulator robots, the probability of serious injury due to collisions with humans remains low (5%), even at speeds as high as 2 m.s-1. Collisions would better be avoided nevertheless, because they disrupt the tasks of both the robot and the human. We propose in this paper to equip robots with exteroceptive sensors and online motion generation so that the robot is able to perceive and react to the motion of the human in order to reduce the occurrence of collisions. It's impossible to guarantee that no collision will ever take place in a partially unknown dynamic environment such as a shared workspace, but we can guarantee instead that, if a collision takes place, the robot is at rest at the time of collision, so that it doesn't inject its own kinetic energy in the collision. To do so, we adapt a Model Predictive Control scheme which has been demonstrated previously with two industrial manipulator robots avoiding collisions while sharing their workspace. The proposed control scheme is validated in simulation.
ER  - 

TY  - CONF
TI  - Episodic Koopman Learning of Nonlinear Robot Dynamics with Application to Fast Multirotor Landing
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9216
EP  - 9222
AU  - C. Folkestad
AU  - D. Pastor
AU  - J. W. Burdick
PY  - 2020
KW  - aircraft control
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - nonlinear control systems
KW  - nonlinear dynamical systems
KW  - optimal control
KW  - predictive control
KW  - robot dynamics
KW  - model predictive control
KW  - nonlinear diffeomorphism
KW  - nonlinear dynamical systems
KW  - optimal control
KW  - multirotor landing
KW  - nonlinear robot dynamics
KW  - episodic Koopman learning
KW  - Eigenvalues and eigenfunctions
KW  - Nonlinear dynamical systems
KW  - Robots
KW  - Aerospace electronics
KW  - Heuristic algorithms
KW  - Vehicle dynamics
DO  - 10.1109/ICRA40945.2020.9197510
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents a novel episodic method to learn a robot's nonlinear dynamics model and an increasingly optimal control sequence for a set of tasks. The method is based on the Koopman operator approach to nonlinear dynamical systems analysis, which models the flow of observables in a function space, rather than a flow in a state space. Practically, this method estimates a nonlinear diffeomorphism that lifts the dynamics to a higher dimensional space where they are linear. Efficient Model Predictive Control methods can then be applied to the lifted model. This approach allows for real time implementation in on-board hardware, with rigorous incorporation of both input and state constraints during learning. We demonstrate the method in a real-time implementation of fast multirotor landing, where the nonlinear ground effect is learned and used to improve landing speed and quality.
ER  - 

TY  - CONF
TI  - Eye-in-Hand 3D Visual Servoing of Helical Swimmers Using Parallel Mobile Coils
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9223
EP  - 9229
AU  - Z. Yang
AU  - L. Yang
AU  - L. Zhang
PY  - 2020
KW  - marine systems
KW  - microrobots
KW  - mobile robots
KW  - robot vision
KW  - visual servoing
KW  - refraction-rectified location algorithm
KW  - coil module
KW  - motor module
KW  - eye-in-hand stereo-vision module
KW  - medical applications
KW  - spacial movement
KW  - control methods
KW  - magnetic actuation systems
KW  - narrow space
KW  - magnetic field
KW  - magnetic helical microswimmers
KW  - parallel mobile coils
KW  - eye-in-hand 3D visual servoing
KW  - cylindrical workspace
KW  - prototype system
KW  - long-distance 3D path
KW  - triple-loop stereo visual servoing strategy
KW  - dynamic magnetic fields
KW  - mobile-coil system
KW  - Coils
KW  - Magnetic resonance imaging
KW  - Three-dimensional displays
KW  - Cameras
KW  - Magnetic devices
KW  - Visual servoing
KW  - Magnetic separation
DO  - 10.1109/ICRA40945.2020.9197276
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Magnetic helical microswimmers can be propelled by rotating magnetic field and are adept at passing through narrow space. To date, various magnetic actuation systems and control methods have been developed to drive these microswimmers. However, steering their spacial movement in a large workspace is still challenging, which could be significant for potential medical applications. In this regard, this paper designs an eye-in-hand stereo-vision module and corresponding refraction-rectified location algorithm. Combined with the motor module and the coil module, the mobile-coil system is capable of generating dynamic magnetic fields in a large 3D workspace. Based on the system, a robust triple-loop stereo visual servoing strategy is proposed that operates simultaneous tracking, locating, and steering, through which the helical swimmer is able to follow a long-distance 3D path. A scaled-up magnetic helical swimmer is employed in the path following experiment. Our prototype system reaches a cylindrical workspace with a diameter more than 200 mm, and the mean error of path tracking is less than 2 mm.
ER  - 

TY  - CONF
TI  - A Mobile Paramagnetic Nanoparticle Swarm with Automatic Shape Deformation Control
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9230
EP  - 9236
AU  - L. Yang
AU  - J. Yu
AU  - L. Zhang
PY  - 2020
KW  - control nonlinearities
KW  - deformation
KW  - fuzzy control
KW  - microrobots
KW  - mobile robots
KW  - multi-robot systems
KW  - nanoparticles
KW  - robot dynamics
KW  - EPNS
KW  - mobile paramagnetic nanoparticle swarm
KW  - automatic shape deformation control
KW  - swarm control
KW  - active shape deformation
KW  - elliptical rotating magnetic fields
KW  - swarm pattern
KW  - elliptical paramagnetic nanoparticle swarm
KW  - strength ratio
KW  - elliptical field
KW  - shape ratio
KW  - length ratio
KW  - deformation dynamics
KW  - fuzzy logic-based control
KW  - nanorobot
KW  - microrobotics
KW  - field ratio
KW  - nonlinearity
KW  - planar rotational locomotion
KW  - planar translational locomotion
KW  - Shape
KW  - Strain
KW  - Magnetic resonance imaging
KW  - Nanoparticles
KW  - Virtual private networks
KW  - Micromagnetics
KW  - Magnetic anisotropy
DO  - 10.1109/ICRA40945.2020.9197010
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Recently, swarm control of micro-/nanorobots has drawn much attention in the field of microrobotics. This paper reports a mobile paramagnetic nanoparticle swarm with the capability of active shape deformation that can improve its environment adaptability. We show that, by applying elliptical rotating magnetic fields, a swarm pattern called the elliptical paramagnetic nanoparticle swarm (EPNS) would be formed. When changing the field ratio-Œ± (i.e. the strength ratio between the minor axis and major axis of the elliptical field), the shape ratio-Œ≤ of the EPNS (i.e. the length ratio between the major axis and minor axis) will change accordingly. However, automatically control this shape deformation process has difficulties because the deformation dynamics has strong nonlinearity, model variation and long time requirement. To solve this problem, we propose a fuzzy logic-based control scheme that utilizes the knowledge and control experience from skilled human operators. Experiments show that the proposed control scheme can stably maneuver the shape deformation of the EPNS with small overshoot, which cannot be achieved by conventional PI control. Moreover, experimental results show that, with the automatic shape deformation control, shape of the EPNS is controlled with high reversibility and also can be well maintained during the planar rotational and translational locomotion of the EPNS.
ER  - 

TY  - CONF
TI  - Magnetic miniature swimmers with multiple rigid flagella
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9237
EP  - 9243
AU  - J. Quispe
AU  - S. R√©gnier
PY  - 2020
KW  - biomechanics
KW  - microrobots
KW  - mobile robots
KW  - position control
KW  - propulsion
KW  - magnetic miniature swimmers
KW  - multiple rigid flagella
KW  - multiple rigid tails
KW  - rotating magnetic field
KW  - robot rotation
KW  - tail distribution
KW  - tail height
KW  - multitailed swimmer robots
KW  - spherical helices
KW  - 2-tailed swimmer
KW  - angular position
KW  - Robots
KW  - Propulsion
KW  - Magnetosphere
KW  - Prototypes
KW  - Microorganisms
KW  - Force
KW  - Mathematical model
DO  - 10.1109/ICRA40945.2020.9196531
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we introduce novel miniature swimmers with multiple rigid tails based on spherical helices. The tail distribution of these prototypes enhances its swimming features as well as allowing to carry objects with it. The proposed swimmers are actuated by a rotating magnetic field, generating the robot rotation and thus producing a considerable thrust to start self-propelling. These prototypes achieved propulsion speeds up to 6 mm/s at 3.5 Hz for a 6-mm in size prototypes. We study the efficiency of different tail distribution for a 2-tailed swimmer by varying the angular position between both tails. Moreover, it is demonstrated that these swimmers experience great sensibility when changing their tail height. Besides, these swimmers demonstrate to be effective for cargo carrying tasks since they can displace objects up to 3.5 times their weight. Finally, wall effect is studied with multi-tailed swimmer robots considering 2 containers with 20 and 50-mm in width. Results showed speeds' increments up to 59% when swimmers are actuated in the smaller container.
ER  - 

TY  - CONF
TI  - Design and Control of a Large-Range Nil-Stiffness Electro-Magnetic Active Force Sensor
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9244
EP  - 9250
AU  - J. Cailliez
AU  - A. Weill-Duflos
AU  - M. Boudaoud
AU  - S. R√©gnier
AU  - S. Haliyo
PY  - 2020
KW  - calibration
KW  - closed loop systems
KW  - electromagnetic actuators
KW  - force measurement
KW  - force sensors
KW  - microsensors
KW  - MicroElectro Mechanical Systems
KW  - force measurements
KW  - meso-scale robotics
KW  - meso-scale active force sensor
KW  - novel meso-scale sensor
KW  - nil-stiffness guidance
KW  - loop control
KW  - nil-stiffness characteristic
KW  - infinite stiffness
KW  - sensor architecture
KW  - low frequency forces
KW  - cutoff frequency
KW  - large-range nil-stiffness electro-magnetic active force sensor
KW  - active force sensors
KW  - measurement range
KW  - conventional passive force sensors
KW  - quasiinfinite stiffness
KW  - frequency 73.9 Hz
KW  - Probes
KW  - Force
KW  - Force measurement
KW  - Optical sensors
KW  - Force sensors
KW  - Sensor phenomena and characterization
DO  - 10.1109/ICRA40945.2020.9197096
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Active force sensors are key instruments to get around the tradeoff between the sensitivity and the measurement range of conventional passive force sensors. Thanks to their quasi-infinite stiffness in closed loop, active sensors can be applied for force measurements on samples with a wide range of stiffness without interference with the mechanical parameters of the sensor. MEMS (Micro-Electro Mechanical Systems) active force sensors have been wildly developed in the literature but they are ill adapted for force measurements at the Newton level needed in meso-scale robotics. In this article, a novel structure for a meso-scale active force sensor is proposed for the measurement of forces from the milli-newton to the newton.This novel meso-scale sensor is based on a nil-stiffness guidance and an electromagnetic actuation. This paper deals with its design, identification, calibration and closed loop control. The sensor exhibits nil-stiffness characteristic in open loop and an almost infinite stiffness in closed loop. This allows measuring forces with a large range of gradients. First experiments shows the ability of this new sensor architecture to measure low frequency forces up to 0.8N with a precision of 0.03 N and a closed loop -20 dB cutoff frequency of 73.9Hz.
ER  - 

TY  - CONF
TI  - Modeling Electromagnetic Navigation Systems for Medical Applications using Random Forests and Artificial Neural Networks
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9251
EP  - 9256
AU  - R. Yu
AU  - S. L. Charreyron
AU  - Q. Boehler
AU  - C. Weibel
AU  - C. Chautems
AU  - C. C. Y. Poon
AU  - B. J. Nelson
PY  - 2020
KW  - electromagnetic devices
KW  - learning (artificial intelligence)
KW  - mean square error methods
KW  - medical computing
KW  - neural nets
KW  - surgery
KW  - nonlinear regions
KW  - higher magnetic fields
KW  - random forest
KW  - RF
KW  - artificial neural network
KW  - eMNS
KW  - state-of-the-art linear multipole electromagnet model
KW  - MPEM
KW  - ANN model
KW  - field magnitude
KW  - current range
KW  - high current regions
KW  - field-magnitude RMSE improvement
KW  - error reduction
KW  - machine learning
KW  - medical applications
KW  - complex nonlinear behavior
KW  - accurate field
KW  - magnetic navigation
KW  - modeling electromagnetic Navigation Systems
KW  - multiscale devices
KW  - human body
KW  - remote surgery
KW  - electromagnets
KW  - linear behavior
KW  - significant modeling errors
KW  - Saturation magnetization
KW  - Electromagnets
KW  - Current measurement
KW  - Magnetic cores
KW  - Magnetostatics
KW  - Magnetic resonance imaging
KW  - Magnetic separation
DO  - 10.1109/ICRA40945.2020.9197212
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Electromagnetic Navigation Systems (eMNS) can be used to control a variety of multiscale devices within the human body for remote surgery. Accurate modeling of the magnetic fields generated by the electromagnets of an eMNS is crucial for the precise control of these devices. Existing methods assume a linear behavior of these systems, leading to significant modeling errors within nonlinear regions exhibited at higher magnetic fields, preventing these systems from operating at full capacity. In this paper, we use a random forest (RF) and an artificial neural network (ANN) to model the nonlinear behavior of the magnetic fields generated by an eMNS. Both machine learning methods outperformed the state-of-the-art linear multipole electromagnet model (MPEM). The RF and the ANN model reduced the root mean squared error (RMSE) of the MPEM when predicting the field magnitude by approximately 40% and 87%, respectively, over the entire current range of the eMNS. At high current regions, especially between 30 and 35 A, the field-magnitude RMSE improvement of the ANN model over the MPEM was 37 mT, equivalent to 90% error reduction. This study demonstrates the feasibility of using machine learning to model an eMNS for medical applications, and its ability to account for complex nonlinear behavior at high currents. The use of machine learning thus shows promise in developing accurate field predicting models, and ultimately improving surgical procedures that use magnetic navigation.
ER  - 

TY  - CONF
TI  - Automated Tracking System with Head and Tail Recognition for Time-Lapse Observation of Free-Moving C. elegans
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9257
EP  - 9262
AU  - S. Dong
AU  - X. Liu
AU  - P. Li
AU  - X. Tang
AU  - D. Liu
AU  - M. Kojima
AU  - Q. Huang
AU  - T. Arai
PY  - 2020
KW  - biology computing
KW  - CCD image sensors
KW  - feature extraction
KW  - image motion analysis
KW  - object tracking
KW  - automated tracking system
KW  - time-lapse observation
KW  - tail recognition
KW  - C. elegans
KW  - automated platform
KW  - behavioral analysis
KW  - long-term tracking
KW  - response speed
KW  - tracking time
KW  - Fitting
KW  - Tracking
KW  - Head
KW  - Microscopy
KW  - Mathematical model
KW  - Real-time systems
KW  - Curve fitting
DO  - 10.1109/ICRA40945.2020.9197546
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, an automated tracking system with head and tail recognition for time-lapse observation of free-moving C. elegans is presented. In microscale field, active C. elegans can move out of the view easily without an automated tracking system because of the narrow field of view and rapid speed of C. elegans. In our previous works, we constructed an automated platform with 3D freedom to track centroid region of the nematode successfully. However, tracking time was not long enough to support a full time-lapse observation. Our proposed system in this study integrate the detection method in horizontal plane with depth evaluation more tightly. Tracking time and response speed have been greatly improved. Besides, we make full use of curvature calculation to make the system recognize the head and tail of C. elegans and the recognition rate can be up to 95%. The results demonstrate that the system can fully achieve automated long-term tracking of a free-living nematode and will be a nice tool for C. elegans behavioral analysis.
ER  - 

TY  - CONF
TI  - Towards Adaptive Benthic Habitat Mapping
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9263
EP  - 9270
AU  - J. Shields
AU  - O. Pizarro
AU  - S. B. Williams
PY  - 2020
KW  - bathymetry
KW  - geophysical image processing
KW  - neural nets
KW  - oceanographic techniques
KW  - remotely operated vehicles
KW  - seafloor phenomena
KW  - sonar
KW  - underwater vehicles
KW  - habitat model
KW  - AUV systems
KW  - seafloor imagery
KW  - efficient AUV surveys
KW  - visually-derived habitat classes
KW  - broad-scale bathymetric data
KW  - fewer samples
KW  - benthic surveys
KW  - adaptive benthic habitat
KW  - autonomous underwater vehicles
KW  - benthic habitat mapping
KW  - broadscale bathymetric data
KW  - remotely-sensed acoustic data
KW  - Feature extraction
KW  - Uncertainty
KW  - Biological system modeling
KW  - Bayes methods
KW  - Data models
KW  - Neural networks
KW  - Backscatter
DO  - 10.1109/ICRA40945.2020.9196811
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Autonomous Underwater Vehicles (AUVs) are increasingly being used to support scientific research and monitoring studies. One such application is in benthic habitat mapping where these vehicles collect seafloor imagery that complements broadscale bathymetric data collected using sonar. Using these two data sources, the relationship between remotely-sensed acoustic data and the sampled imagery can be learned, creating a habitat model. As the areas to be mapped are often very large and AUV systems collecting seafloor imagery can only sample from a small portion of the survey area, the information gathered should be maximised for each deployment. This paper illustrates how the habitat models themselves can be used to plan more efficient AUV surveys by identifying where to collect further samples in order to most improve the habitat model. A Bayesian neural network is used to predict visually-derived habitat classes when given broad-scale bathymetric data. This network can also estimate the uncertainty associated with a prediction, which can be deconstructed into its aleatoric (data) and epistemic (model) components. We demonstrate how these structured uncertainty estimates can be utilised to improve the model with fewer samples. Such adaptive approaches to benthic surveys have the potential to reduce costs by prioritizing further sampling efforts. We illustrate the effectiveness of the proposed approach using data collected by an AUV on offshore reefs in Tasmania, Australia.
ER  - 

TY  - CONF
TI  - Multispectral Domain Invariant Image for Retrieval-based Place Recognition
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9271
EP  - 9277
AU  - D. Han
AU  - Y. Hwang
AU  - N. Kim
AU  - Y. Choi
PY  - 2020
KW  - image colour analysis
KW  - image recognition
KW  - image retrieval
KW  - image segmentation
KW  - infrared imaging
KW  - spectral analysis
KW  - multispectral place recognition task
KW  - multispectral semantic segmentation
KW  - multispectral domain invariant image
KW  - retrieval-based place recognition
KW  - multispectral recognition
KW  - thermal image
KW  - RGB domain-based tasks
KW  - multispectral domain invariant framework
KW  - unpaired image translation method
KW  - semantic image
KW  - discriminative invariant image
KW  - Image recognition
KW  - Robot sensing systems
KW  - Task analysis
KW  - Semantics
KW  - Thermal sensors
KW  - Feature extraction
KW  - Imaging
DO  - 10.1109/ICRA40945.2020.9197514
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Multispectral recognition has attracted increasing attention from the research community due to its potential competence for many applications from day to night. However, due to the domain shift between RGB and thermal image, it has still many challenges to apply and to use RGB domain-based tasks. To reduce the domain gap, we propose multispectral domain invariant framework, which leverages the unpaired image translation method to generate a semantic and strongly discriminative invariant image by enforcing novel constraints in the objective function. We demonstrate the efficacy of the proposed method on mainly multispectral place recognition task and achieve significant improvement compared to previous works. Furthermore, we test on multispectral semantic segmentation and unsupervised domain adaptations to prove the scalability and generality of the proposed method. We will open our source code and dataset.
ER  - 

TY  - CONF
TI  - Probabilistic Effect Prediction through Semantic Augmentation and Physical Simulation
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9278
EP  - 9284
AU  - A. S. Bauer
AU  - P. Schmaus
AU  - F. Stulp
AU  - D. Leidner
PY  - 2020
KW  - failure analysis
KW  - humanoid robots
KW  - mobile robots
KW  - planning (artificial intelligence)
KW  - probability
KW  - probabilistic effect prediction
KW  - semantic augmentation
KW  - exact outcome
KW  - failure situations
KW  - failure tolerance
KW  - robot actions
KW  - augmenting collected experience
KW  - semantic knowledge
KW  - realistic physics simulations
KW  - outcome probabilities
KW  - unknown tasks
KW  - simulated experience
KW  - action success probabilities
KW  - world experiments
KW  - humanoid robot
KW  - planning trials
KW  - Rollin Justin
KW  - Robots
KW  - Planning
KW  - Probabilistic logic
KW  - Cognition
KW  - Semantics
KW  - Task analysis
KW  - Predictive models
DO  - 10.1109/ICRA40945.2020.9197477
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Nowadays, robots are mechanically able to perform highly demanding tasks, where AI-based planning methods are used to schedule a sequence of actions that result in the desired effect. However, it is not always possible to know the exact outcome of an action in advance, as failure situations may occur at any time. To enhance failure tolerance, we propose to predict the effects of robot actions by augmenting collected experience with semantic knowledge and leveraging realistic physics simulations. That is, we consider semantic similarity of actions in order to predict outcome probabilities for previously unknown tasks. Furthermore, physical simulation is used to gather simulated experience that makes the approach robust even in extreme cases. We show how this concept is used to predict action success probabilities and how this information can be exploited throughout future planning trials. The concept is evaluated in a series of real world experiments conducted with the humanoid robot Rollin' Justin.
ER  - 

TY  - CONF
TI  - Anytime Integrated Task and Motion Policies for Stochastic Environments
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9285
EP  - 9291
AU  - N. Shah
AU  - D. Kala Vasudevan
AU  - K. Kumar
AU  - P. Kamojjhala
AU  - S. Srivastava
PY  - 2020
KW  - intelligent robots
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - path planning
KW  - planning (artificial intelligence)
KW  - stochastic processes
KW  - multiple execution-time contingencies
KW  - motion policies
KW  - stochastic settings
KW  - stochastic situations
KW  - abstract models
KW  - motion planning
KW  - abstract planning
KW  - intelligent robots
KW  - stochastic environments
KW  - anytime integrated task
KW  - Robots
KW  - Planning
KW  - Task analysis
KW  - Computational modeling
KW  - Collision avoidance
KW  - Stochastic processes
KW  - Trajectory
DO  - 10.1109/ICRA40945.2020.9197574
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In order to solve complex, long-horizon tasks, intelligent robots need to carry out high-level, abstract planning and reasoning in conjunction with motion planning. However, abstract models are typically lossy and plans or policies computed using them can be unexecutable. These problems are exacerbated in stochastic situations where the robot needs to reason about, and plan for multiple contingencies. We present a new approach for integrated task and motion planning in stochastic settings. In contrast to prior work in this direction, we show that our approach can effectively compute integrated task and motion policies whose branching structures encoding agent behaviors handling multiple execution-time contingencies. We prove that our algorithm is probabilistically complete and can compute feasible solution policies in an anytime fashion so that the probability of encountering an unresolved contingency decreases over time. Empirical results on a set of challenging problems show the utility and scope of our methods.
ER  - 

TY  - CONF
TI  - CCRobot-III: a Split-type Wire-driven Cable Climbing Robot for Cable-stayed Bridge Inspection*
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9308
EP  - 9314
AU  - N. Ding
AU  - Z. Zheng
AU  - J. Song
AU  - Z. Sun
AU  - T. L. Lam
AU  - H. Qian
PY  - 2020
KW  - bridges (structures)
KW  - cables (mechanical)
KW  - grippers
KW  - inspection
KW  - mobile robots
KW  - robot dynamics
KW  - wires
KW  - palm-based gripper
KW  - CCRobot-III
KW  - cable climbing robot
KW  - cable-stayed bridge inspection
KW  - mainbody frame
KW  - steel wires
KW  - climbing precursor
KW  - Split-type Wire-driven design
KW  - mass 40.0 kg
KW  - size 90.0 mm to 110.0 mm
KW  - Bridges
KW  - Payloads
KW  - Force
KW  - Wheels
KW  - Winches
KW  - Robots
KW  - Inspection
DO  - 10.1109/ICRA40945.2020.9196772
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents a novel Cable Climbing Robot CCRobot-III, which is the third version designed for bridge cable inspection tasks, aiming at surpassing previous versions in terms of climbing speed and payload capacity. Benefiting from Split-type Wire-driven design, CCRobot-III can climb along a 90-110mm diameter bridge cable in inchworm-like gait at a speed of up to 12m/min, and carrying more than 40kg payload at the same time. CCRobot-III consists of a climbing precursor and a main-body frame. The two parts are connected and driven by steel wires. The climbing precursor, acting as a mobile anchor, moves quickly on a bridge cable. The mainbody frame, acting as a mobile winch, carries payload and pulls itself to a certain position with steel wires. Both parts have one or two pairs of palm-based gripper, which is the key component for providing strong adhesion to support the robot climbing. Experimental results have shown that CCRobotIII possesses outstanding climbing performance, high payload capacity, and good adaptability to complex conditions of cable surface. Moreover, it has potential engineering applications on the cable-stayed bridge for fieldwork.
ER  - 

TY  - CONF
TI  - Omnidirectional Tractable Three Module Robot
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9316
EP  - 9321
AU  - K. Suryavanshi
AU  - R. Vadapalli
AU  - R. Vucha
AU  - A. Sarkar
AU  - K. M. Krishna
PY  - 2020
KW  - control engineering computing
KW  - mobile robots
KW  - motion control
KW  - pipes
KW  - robot kinematics
KW  - omnidirectional tractable three module robot
KW  - omnidirectional modules
KW  - holonomic motion
KW  - motion singularity region
KW  - motion capabilities
KW  - closed-form kinematic model
KW  - MSC ADAMS
KW  - Robots
KW  - Angular velocity
KW  - Turning
KW  - Shafts
KW  - Elbow
KW  - Crawlers
KW  - Kinematics
DO  - 10.1109/ICRA40945.2020.9197210
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper introduces the Omnidirectional Tractable Three Module Robot for traversing inside complex pipe networks. The robot consists of three omnidirectional modules fixed 120¬∞ apart circumferentially which can rotate about their own axis allowing holonomic motion of the robot. The holonomic motion enables the robot to overcome motion singularity when negotiating T-junctions and further allows the robot to arrive in a preferred orientation while taking turns inside a pipe. We have developed a closed-form kinematic model for the robot in the paper and propose the `Motion Singularity Region' that the robot needs to avoid while negotiating T-junction. The design and motion capabilities of the robot are demonstrated both by conducting simulations in MSC ADAMS on a simplified lumped-model of the robot and with experiments on its physical embodiment.
ER  - 

TY  - CONF
TI  - A Practical Climbing Robot for Steel Bridge Inspection
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9322
EP  - 9328
AU  - S. T. Nguyen
AU  - A. Q. Pham
AU  - C. Motley
AU  - H. M. La
PY  - 2020
KW  - bridges (structures)
KW  - design engineering
KW  - inspection
KW  - maintenance engineering
KW  - mobile robots
KW  - steel
KW  - structural engineering
KW  - ARA lab robot
KW  - steel structures
KW  - practical climbing robot
KW  - steel bridge inspection
KW  - cutting edge steel inspection robots
KW  - unified design
KW  - advanced robotic and automation lab
KW  - Bridges
KW  - Steel
KW  - Mobile robots
KW  - Inspection
KW  - Adhesives
KW  - Force
DO  - 10.1109/ICRA40945.2020.9196892
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - The advanced robotic and automation (ARA) lab has developed and successfully implemented a design inspired by many of the various cutting edge steel inspection robots to date. The combination of these robots concepts into a unified design came with its own set of challenges since the parameters for these features sometimes conflicted. An extensive amount of design and analysis work was performed by the ARA lab in order to find a carefully tuned balance between the implemented features on the ARA robot and general functionality. Having successfully managed to implement this conglomerate of features represents a breakthrough to the industry of steel inspection robots as the ARA lab robot is capable of traversing most complex geometries found on steel structures while still maintaining its ability to efficiently travel along these structures; a feat yet to be done until now.
ER  - 

TY  - CONF
TI  - Development of a Wheeled Wall-Climbing Robot with a Shape-Adaptive Magnetic Adhesion Mechanism
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9329
EP  - 9335
AU  - H. Eto
AU  - H. H. Asada
PY  - 2020
KW  - adhesion
KW  - elasticity
KW  - industrial manipulators
KW  - manipulator kinematics
KW  - mobile robots
KW  - permanent magnets
KW  - robotic welding
KW  - steel
KW  - wheels
KW  - nonelastic suspension mechanism
KW  - arbitrary curved shape
KW  - wheeled wall-climbing robot
KW  - curved ferromagnetic surfaces
KW  - magnetic force direction
KW  - magnetic wheels
KW  - spherical shape
KW  - 2 DOF rotational magnetic adhesion
KW  - shape-adaptive magnetic adhesion
KW  - Wheels
KW  - Mobile robots
KW  - Magnetic levitation
KW  - Magnetic forces
KW  - Welding
KW  - Adhesives
DO  - 10.1109/ICRA40945.2020.9196919
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents a wheeled wall-climbing robot with a shape-adaptive magnetic adhesion mechanism for large steel structures. To travel up and down various curved ferromagnetic surfaces, we developed a 2 DOF rotational magnetic adhesion mechanism installed on each wheel that can change the orientation of the magnets to keep the magnetic force direction always normal to the contact surface. These magnetic wheels have a spherical shape and can move relative to the main body by a non-elastic suspension mechanism so that the robot can climb up small obstacles on the ground and find contact points for each wheel on a wall with an arbitrary curved shape. Being geometrically stable is important for the robot because this robot is intended to be a mobile base for a welding manipulator. The detailed design of the mechanism and the results of climbing tests are presented.
ER  - 

TY  - CONF
TI  - Algebraic Fault Detection and Identification for Rigid Robots
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9352
EP  - 9358
AU  - A. Lomakin
AU  - J. Deutscher
PY  - 2020
KW  - fault diagnosis
KW  - manipulators
KW  - nonlinear control systems
KW  - polynomial approximation
KW  - SCARA
KW  - polynomial approximation
KW  - orthonormal Jacobi polynomials
KW  - nonlinear mechanical systems
KW  - rigid robots
KW  - algebraic fault detection
KW  - Fault detection
KW  - Jacobian matrices
KW  - Mathematical model
KW  - Kernel
KW  - Time measurement
KW  - Robot kinematics
DO  - 10.1109/ICRA40945.2020.9197561
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper presents a method for algebraic fault detection and identification of nonlinear mechanical systems, describing rigid robots, by using an approximation with orthonormal Jacobi polynomials. An explicit expression is derived for the fault from the equation of motion, which is decoupled from disturbances and only depends on measurable signals and their time derivatives. Fault detection and identification is then achieved by polynomial approximation of the determined fault term. The results are illustrated by a simulation for a faulty SCARA.
ER  - 

TY  - CONF
TI  - Fault tolerance analysis of a hexarotor with reconfigurable tilted rotors
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9359
EP  - 9365
AU  - C. Pose
AU  - J. Giribet
AU  - I. Mas
PY  - 2020
KW  - aircraft control
KW  - attitude control
KW  - fault tolerance
KW  - helicopters
KW  - fault tolerance analysis
KW  - reconfigurable tilted rotor
KW  - multirotor vehicles
KW  - yaw maneuverability
KW  - attitude control
KW  - hexarotor vehicle
KW  - hexagon-shaped multirotor
KW  - altitude control
KW  - tilt angle
KW  - rotor reconfiguration
KW  - Rotors
KW  - Torque
KW  - Force
KW  - Servomotors
KW  - Fault tolerance
KW  - Fault tolerant systems
KW  - Attitude control
DO  - 10.1109/ICRA40945.2020.9196552
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Tilted rotors in multirotor vehicles have shown to be useful for different practical reasons. For instance, increasing yaw maneuverability or enabling full position and attitude control of hexarotor vehicles. It has also been proven that a hexagon-shaped multirotor is capable of complete attitude and altitude control under failures of one of its rotors. However, when a rotor fails, the torque that can be reached in the worst- case direction decreases considerably.This work proposes to actively change the tilt angle of the rotors when a failure occurs. This rotor reconfiguration increases the maximum torque that can be achieved in the most stressful direction, reducing maneuverability limitations. Experimental validations are shown, where the proposed reconfigurable tilted rotor is used in order to control a hexarotor vehicle when a failure appears mid-flight. The impact of the delay in the reconfiguration when a failure occurs is also addressed.
ER  - 

TY  - CONF
TI  - Detecting Execution Anomalies As an Oracle for Autonomy Software Robustness
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9366
EP  - 9373
AU  - D. S. Katz
AU  - C. Hutchison
AU  - M. Zizyte
AU  - C. L. Goues
PY  - 2020
KW  - fault diagnosis
KW  - pattern clustering
KW  - robot programming
KW  - system monitoring
KW  - execution anomaly detection
KW  - autonomy software robustness
KW  - system monitoring
KW  - clustering algorithm
KW  - autonomy systems
KW  - robotics systems
KW  - real-world industrial system
KW  - autonomous systems
KW  - fault identification
KW  - Testing
KW  - Tools
KW  - Instruments
KW  - Clustering algorithms
KW  - Service robots
KW  - Safety
DO  - 10.1109/ICRA40945.2020.9197060
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We propose a method for detecting execution anomalies in robotics and autonomy software. The algorithm uses system monitoring techniques to obtain profiles of executions. It uses a clustering algorithm to create clusters of those executions, representing nominal execution. A distance metric determines whether additional execution profiles belong to the existing clusters or should be considered anomalies. The method is suitable for identifying faults in robotics and autonomy systems. We evaluate the technique in simulation on two robotics systems, one of which is a real-world industrial system. We find that our technique works well to detect possibly unsafe behavior in autonomous systems.
ER  - 

TY  - CONF
TI  - Reliability Validation of Learning Enabled Vehicle Tracking
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9390
EP  - 9396
AU  - Y. Sun
AU  - Y. Zhou
AU  - S. Maskell
AU  - J. Sharp
AU  - X. Huang
PY  - 2020
KW  - image filtering
KW  - image motion analysis
KW  - Kalman filters
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object tracking
KW  - real-world learning-enabled system
KW  - dynamic vehicle tracking
KW  - high-resolution wide-area motion imagery input
KW  - symbolic components
KW  - Kalman filter
KW  - neural networks
KW  - system-level reliability
KW  - coverage-guided neural network testing tool
KW  - vehicle tracking system
KW  - adversarial examples
KW  - deep learning components
KW  - validation methods
KW  - learning-enabled systems
KW  - neural network components
KW  - DeepConcolic tool
KW  - Testing
KW  - Tools
KW  - Tracking
KW  - Neurons
KW  - Cameras
KW  - Feature extraction
KW  - Reliability
DO  - 10.1109/ICRA40945.2020.9196932
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - This paper studies the reliability of a real-world learning-enabled system, which conducts dynamic vehicle tracking based on a high-resolution wide-area motion imagery input. The system consists of multiple neural network components - to process the imagery inputs - and multiple symbolic (Kalman filter) components - to analyse the processed information for vehicle tracking. It is known that neural networks suffer from adversarial examples, which make them lack robustness. However, it is unclear if and how the adversarial examples over learning components can affect the overall system-level reliability. By integrating a coverage-guided neural network testing tool, DeepConcolic, with the vehicle tracking system, we found that (1) the overall system can be resilient to some adversarial examples thanks to the existence of other components, and (2) the overall system presents an extra level of uncertainty which cannot be determined by analysing the deep learning components only. This research suggests the need for novel verification and validation methods for learning-enabled systems.
ER  - 

TY  - CONF
TI  - Real-Time, Highly Accurate Robotic Grasp Detection using Fully Convolutional Neural Network with Rotation Ensemble Module
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9397
EP  - 9403
AU  - D. Park
AU  - Y. Seo
AU  - S. Y. Chun
PY  - 2020
KW  - convolutional neural nets
KW  - image classification
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - highly accurate robotic grasp detection
KW  - fully convolutional neural network
KW  - rotation ensemble module
KW  - rotation invariance
KW  - computer vision tasks
KW  - rotation anchor box
KW  - multiple objects
KW  - 4-axis robot arm
KW  - Cornell dataset
KW  - REM
KW  - Proposals
KW  - Grasping
KW  - Task analysis
KW  - Robot sensing systems
KW  - Feature extraction
KW  - Kernel
DO  - 10.1109/ICRA40945.2020.9197002
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Rotation invariance has been an important topic in computer vision tasks. Ideally, robot grasp detection should be rotation-invariant. However, rotation-invariance in robotic grasp detection has been only recently studied by using rotation anchor box that are often time-consuming and unreliable for multiple objects. In this paper, we propose a rotation ensemble module (REM) for robotic grasp detection using convolutions that rotates network weights. Our proposed REM was able to outperform current state-of-the-art methods by achieving up to 99.2% (image-wise), 98.6% (object-wise) accuracies on the Cornell dataset with real-time computation (50 frames per second). Our proposed method was also able to yield reliable grasps for multiple objects and up to 93.8% success rate for the real-time robotic grasping task with a 4-axis robot arm for small novel objects that was significantly higher than the baseline methods by 11-56%.
ER  - 

TY  - CONF
TI  - Form2Fit: Learning Shape Priors for Generalizable Assembly from Disassembly
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9404
EP  - 9410
AU  - K. Zakka
AU  - A. Zeng
AU  - J. Lee
AU  - S. Song
PY  - 2020
KW  - CAD
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - pose estimation
KW  - robotic assembly
KW  - kit assembly task
KW  - shape matching problem
KW  - shape descriptor
KW  - object surfaces
KW  - self-supervised data-collection pipeline
KW  - robotic assembly
KW  - 3D CAD models
KW  - task-specific training data
KW  - Task analysis
KW  - Shape
KW  - Visualization
KW  - Training data
KW  - Three-dimensional displays
KW  - Solid modeling
KW  - Training
DO  - 10.1109/ICRA40945.2020.9196733
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Is it possible to learn policies for robotic assembly that can generalize to new objects? We explore this idea in the context of the kit assembly task. Since classic methods rely heavily on object pose estimation, they often struggle to generalize to new objects without 3D CAD models or task-specific training data. In this work, we propose to formulate the kit assembly task as a shape matching problem, where the goal is to learn a shape descriptor that establishes geometric correspondences between object surfaces and their target placement locations from visual input. This formulation enables the model to acquire a broader understanding of how shapes and surfaces fit together for assembly - allowing it to generalize to new objects and kits. To obtain training data for our model, we present a self-supervised data-collection pipeline that obtains ground truth object-to-placement correspondences by disassembling complete kits. Our resulting real-world system, Form2Fit, learns effective pick and place strategies for assembling objects into a variety of kits - achieving 90% average success rates under different initial conditions (e.g. varying object and kit poses), 94% success under new configurations of multiple kits, and over 86% success with completely new objects and kits. Code, videos, and supplemental material are available at https://form2fit.github.io.
ER  - 

TY  - CONF
TI  - Learning Rope Manipulation Policies Using Dense Object Descriptors Trained on Synthetic Depth Data
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9411
EP  - 9418
AU  - P. Sundaresan
AU  - J. Grannen
AU  - B. Thananjeyan
AU  - A. Balakrishna
AU  - M. Laskey
AU  - K. Stone
AU  - J. E. Gonzalez
AU  - K. Goldberg
PY  - 2020
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - ropes
KW  - rope manipulation policies
KW  - dense object descriptors
KW  - synthetic depth data
KW  - robotic manipulation
KW  - deformable 1D objects
KW  - high-fidelity analytic models
KW  - configuration spaces
KW  - end-to-end manipulation policies
KW  - physical interaction
KW  - interpretable deep visual representations
KW  - robot manipulation
KW  - interpretable policies
KW  - transferable geometric policies
KW  - visual reasoning
KW  - point-pair correspondences
KW  - initial goal rope configurations
KW  - geometric structure
KW  - synthetic depth images
KW  - dense depth object descriptors
KW  - ABB YuMi Robot
KW  - interpretable geometric policies
KW  - Task analysis
KW  - Visualization
KW  - Robots
KW  - Strain
KW  - Training
KW  - Videos
KW  - Data models
DO  - 10.1109/ICRA40945.2020.9197121
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Robotic manipulation of deformable 1D objects such as ropes, cables, and hoses is challenging due to the lack of high-fidelity analytic models and large configuration spaces. Furthermore, learning end-to-end manipulation policies directly from images and physical interaction requires significant time on a robot and can fail to generalize across tasks. We address these challenges using interpretable deep visual representations for rope, extending recent work on dense object descriptors for robot manipulation. This facilitates the design of interpretable and transferable geometric policies built on top of the learned representations, decoupling visual reasoning and control. We present an approach that learns point-pair correspondences between initial and goal rope configurations, which implicitly encodes geometric structure, entirely in simulation from synthetic depth images. We demonstrate that the learned representation - dense depth object descriptors (DDODs) - can be used to manipulate a real rope into a variety of different arrangements either by learning from demonstrations or using interpretable geometric policies. In 50 trials of a knot-tying task with the ABB YuMi Robot, the system achieves a 66% knot-tying success rate from previously unseen configurations. See https://tinyurl.com/rope-learning for supplementary material and videos.
ER  - 

TY  - CONF
TI  - Efficient two step optimization for large embedded deformation graph based SLAM
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9419
EP  - 9425
AU  - J. Song
AU  - F. Bai
AU  - L. Zhao
AU  - S. Huang
AU  - R. Xiong
PY  - 2020
KW  - computational complexity
KW  - embedded systems
KW  - graph theory
KW  - Hessian matrices
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - parameter estimation
KW  - computation complexity
KW  - two step optimization
KW  - deformable geometry
KW  - stereo camera
KW  - SLAM applications
KW  - large scale embedded deformation graph
KW  - Hessian matrix
KW  - Simultaneous localization and mapping
KW  - Strain
KW  - Jacobian matrices
KW  - Optimization
KW  - Cameras
KW  - Deformable models
KW  - Geometry
DO  - 10.1109/ICRA40945.2020.9196930
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Embedded deformation graph is a widely used technique in deformable geometry and graphical problems. Although the technique has been transmitted to stereo (or RGB-D) camera based SLAM applications, it remains challenging to compromise the computational cost as the model grows. In practice, the processing time grows rapidly in accordance with the expansion of maps. In this paper, we propose an approach to decouple the nodes of deformation graph in large scale dense deformable SLAM and keep the estimation time to be constant. We observe that only partial deformable nodes in the graph are connected to visible points. Based on this fact, the sparsity of the original Hessian matrix is utilized to split the parameter estimation into two independent steps. With this new technique, we achieve faster parameter estimation with amortized computation complexity reduced from O(n2) to almost O(1). As a result, the computational cost barely increases as the map keeps growing. Based on our strategy, the computational bottleneck in large scale embedded deformation graph based applications will be greatly mitigated. The effectiveness is validated by experiments, featuring large scale deformation scenarios.
ER  - 

TY  - CONF
TI  - Camera-to-Robot Pose Estimation from a Single Image
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9426
EP  - 9432
AU  - T. E. Lee
AU  - J. Tremblay
AU  - T. To
AU  - J. Cheng
AU  - T. Mosier
AU  - O. Kroemer
AU  - D. Fox
AU  - S. Birchfield
PY  - 2020
KW  - cameras
KW  - image colour analysis
KW  - image sensors
KW  - manipulators
KW  - neural nets
KW  - pose estimation
KW  - robot vision
KW  - camera-to-robot pose estimation
KW  - single RGB image
KW  - deep neural network
KW  - perspective-n-point
KW  - robot manipulator
KW  - classic hand-eye calibration systems
KW  - camera sensors
KW  - classic off-line hand-eye calibration
KW  - robot sensors
KW  - Cameras
KW  - Robot vision systems
KW  - Robot kinematics
KW  - Calibration
KW  - Two dimensional displays
KW  - Training
DO  - 10.1109/ICRA40945.2020.9196596
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We present an approach for estimating the pose of an external camera with respect to a robot using a single RGB image of the robot. The image is processed by a deep neural network to detect 2D projections of keypoints (such as joints) associated with the robot. The network is trained entirely on simulated data using domain randomization to bridge the reality gap. Perspective-n-point (PnP) is then used to recover the camera extrinsics, assuming that the camera intrinsics and joint configuration of the robot manipulator are known. Unlike classic hand-eye calibration systems, our method does not require an off-line calibration step. Rather, it is capable of computing the camera extrinsics from a single frame, thus opening the possibility of on-line calibration. We show experimental results for three different robots and camera sensors, demonstrating that our approach is able to achieve accuracy with a single frame that is comparable to that of classic off-line hand-eye calibration using multiple frames. With additional frames from a static pose, accuracy improves even further. Code, datasets, and pretrained models for three widely-used robot manipulators are made available.
ER  - 

TY  - CONF
TI  - PST900: RGB-Thermal Calibration, Dataset and Segmentation Network
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9441
EP  - 9447
AU  - S. S. Shivakumar
AU  - N. Rodrigues
AU  - A. Zhou
AU  - I. D. Miller
AU  - V. Kumar
AU  - C. J. Taylor
PY  - 2020
KW  - calibration
KW  - control engineering computing
KW  - convolutional neural nets
KW  - image colour analysis
KW  - image segmentation
KW  - infrared imaging
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - PST900
KW  - segmentation network
KW  - long wave infrared imagery
KW  - RGB-thermal camera calibration
KW  - thermal image pairs
KW  - DARPA Subterranean Challenge
KW  - RGB imagery
KW  - semantic segmentation
KW  - CNN architecture
KW  - Cameras
KW  - Calibration
KW  - Image segmentation
KW  - Semantics
KW  - Heating systems
KW  - Aluminum
KW  - Three-dimensional displays
DO  - 10.1109/ICRA40945.2020.9196831
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this work we propose long wave infrared (LWIR) imagery as a viable supporting modality for semantic segmentation using learning-based techniques. We first address the problem of RGB-thermal camera calibration by proposing a passive calibration target and procedure that is both portable and easy to use. Second, we present PST900, a dataset of 894 synchronized and calibrated RGB and Thermal image pairs with per pixel human annotations across four distinct classes from the DARPA Subterranean Challenge. Lastly, we propose a CNN architecture for fast semantic segmentation that combines both RGB and Thermal imagery in a way that leverages RGB imagery independently. We compare our method against the state-of-the-art and show that our method outperforms them in our dataset.
ER  - 

TY  - CONF
TI  - Instance Segmentation of LiDAR Point Clouds
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9448
EP  - 9455
AU  - F. Zhang
AU  - C. Guan
AU  - J. Fang
AU  - S. Bai
AU  - R. Yang
AU  - P. H. S. Torr
AU  - V. Prisacariu
PY  - 2020
KW  - feature extraction
KW  - image segmentation
KW  - optical radar
KW  - radar imaging
KW  - stereo image processing
KW  - single-shot instance prediction
KW  - LiDAR instance segmentation
KW  - LiDAR point cloud dataset
KW  - point-wise labels
KW  - robust baseline method
KW  - large-scale outdoor LiDAR point clouds
KW  - dense feature encoding technique
KW  - precise 3D bounding box
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Image segmentation
KW  - Two dimensional displays
KW  - Encoding
KW  - Semantics
KW  - Feature extraction
DO  - 10.1109/ICRA40945.2020.9196622
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - We propose a robust baseline method for instance segmentation which are specially designed for large-scale outdoor LiDAR point clouds. Our method includes a novel dense feature encoding technique, allowing the localization and segmentation of small, far-away objects, a simple but effective solution for single-shot instance prediction and effective strategies for handling severe class imbalances. Since there is no public dataset for the study of LiDAR instance segmentation, we also build a new publicly available LiDAR point cloud dataset to include both precise 3D bounding box and point-wise labels for instance segmentation, while still being about 3~20 times as large as other existing LiDAR datasets. The dataset will be published at https://github.com/feihuzhang/LiDARSeg.
ER  - 

TY  - CONF
TI  - Generation of Object Candidates Through Simply Looking Around
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9456
EP  - 9462
AU  - D. Patar
AU  - H. I. Bozma
PY  - 2020
KW  - cameras
KW  - image segmentation
KW  - image sequences
KW  - mobile robots
KW  - object detection
KW  - object recognition
KW  - robot vision
KW  - video signal processing
KW  - mobile robot
KW  - pan-tilt monocular camera
KW  - camera movements
KW  - robot operating indoors
KW  - object candidates
KW  - Cameras
KW  - Robot vision systems
KW  - Image segmentation
KW  - Visualization
KW  - Coherence
KW  - Tracking
DO  - 10.1109/ICRA40945.2020.9197482
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this paper, we consider the generation of generic object candidates by a mobile robot that is endowed with a pan-tilt monocular camera. This is an important problem because these candidates serve as basis for the robot to categorize and/or recognize the objects in its surroundings. The previously proposed methods either do not have a means of enabling the robot to look around through moving its camera or do not take advantage of the temporal coherence of the video data. We present a novel approach that enables the robot to achieve both of these capabilities simultaneously. In this approach, the robot's camera movements are governed by a family of controllers whose constructions depend on the set of object candidates that have been hitherto generated, but not directly looked at. In parallel, the robot discovers the object candidates through tracking segments and determining spatio-temporally coherent ones. The advantage of the proposed approach is that while the robot can explore its surroundings by simply looking around prior to more sophisticated exploration behavior involving possibly bodily locomotion the generated object candidates turn out to be consolidated across the visual stream in comparison to single-shot methods. This is demonstrated in extensive experimental results with a robot operating indoors varying in clutter as well as outdoors.
ER  - 

TY  - CONF
TI  - Dilated Point Convolutions: On the Receptive Field Size of Point Convolutions on 3D Point Clouds
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9463
EP  - 9469
AU  - F. Engelmann
AU  - T. Kontogianni
AU  - B. Leibe
PY  - 2020
KW  - convolutional neural nets
KW  - image classification
KW  - image representation
KW  - image segmentation
KW  - neural net architecture
KW  - solid modelling
KW  - dilated point convolutions
KW  - receptive field size
KW  - 3D point cloud
KW  - point convolutional networks
KW  - semantic segmentation
KW  - object classification
KW  - 3D data representations
KW  - network architectures
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Semantics
KW  - Network architecture
KW  - Image segmentation
KW  - Two dimensional displays
KW  - Conferences
DO  - 10.1109/ICRA40945.2020.9197503
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - In this work, we propose Dilated Point Convolutions (DPC). In a thorough ablation study, we show that the receptive field size is directly related to the performance of 3D point cloud processing tasks, including semantic segmentation and object classification. Point convolutions are widely used to efficiently process 3D data representations such as point clouds or graphs. However, we observe that the receptive field size of recent point convolutional networks is inherently limited. Our dilated point convolutions alleviate this issue, they significantly increase the receptive field size of point convolutions. Importantly, our dilation mechanism can easily be integrated into most existing point convolutional networks. To evaluate the resulting network architectures, we visualize the receptive field and report competitive scores on popular point cloud benchmarks.
ER  - 

TY  - CONF
TI  - A water-obstacle separation and refinement network for unmanned surface vehicles
T2  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
SP  - 9470
EP  - 9476
AU  - B. Bovcon
AU  - M. Kristan
PY  - 2020
KW  - collision avoidance
KW  - edge detection
KW  - feature extraction
KW  - image fusion
KW  - image segmentation
KW  - inertial navigation
KW  - marine vehicles
KW  - mobile robots
KW  - neural net architecture
KW  - remotely operated vehicles
KW  - robot vision
KW  - refinement network
KW  - unmanned surface vehicles
KW  - obstacle detection
KW  - water reflections
KW  - wakes
KW  - inertial information fusion
KW  - visual features
KW  - deep encoder decoder architecture
KW  - water obstacle separation
KW  - semantic segmentation
KW  - autonomous navigation
KW  - water edge estimation
KW  - inertial measurement unit
KW  - loss function
KW  - water features
KW  - Decoding
KW  - Visualization
KW  - Feature extraction
KW  - Image segmentation
KW  - Semantics
KW  - Image edge detection
KW  - Task analysis
KW  - obstacle detection
KW  - semantic segmentation
KW  - sensor fusion
KW  - unmanned surface vehicles
KW  - separation function
DO  - 10.1109/ICRA40945.2020.9197194
JO  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2020 IEEE International Conference on Robotics and Automation (ICRA)
Y1  - 31 May-31 Aug. 2020
AB  - Obstacle detection by semantic segmentation shows a great promise for autonomous navigation in unmanned surface vehicles (USV). However, existing methods suffer from poor estimation of the water edge in presence of visual ambiguities, poor detection of small obstacles and high false-positive rate on water reflections and wakes. We propose a new deep encoder-decoder architecture, a water-obstacle separation and refinement network (WaSR), to address these issues. Detection and water edge accuracy are improved by a novel decoder that gradually fuses inertial information from inertial measurement unit (IMU) with the visual features from the encoder. In addition, a novel loss function is designed to increase the separation between water and obstacle features early on in the network. Subsequently, the capacity of the remaining layers in the decoder is better utilised, leading to a significant reduction in false positives and increased true positives. Experimental results show that WaSR outperforms the current state-of-the-art by a large margin, yielding a 14% increase in F-measure over the second-best method.
ER  - 


