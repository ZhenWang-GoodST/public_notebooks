total paper: 398
Title: Metrically-Scaled Monocular SLAM using Learned Scale Factors
Key Words: cameras  graph theory  mobile robots  neural nets  robot vision  SLAM (robots)  geometric SLAM factor graph  SLAM systems  relative geometry  learned depth estimation approaches  learned depth predictions  image space  network architecture  coarse images  GPU acceleration  learned metric data  unary scale factors  hardware accelerators  observable epipolar geometry  monocular SLAM  learned scale factors  monocular simultaneous localization and mapping  hardware acceleration  neural network  Simultaneous localization and mapping  Feature extraction  Cameras  Loss measurement  Neural networks  Estimation 
Abstract: We propose an efficient method for monocular simultaneous localization and mapping (SLAM) that is capable of estimating metrically-scaled motion without additional sensors or hardware acceleration by integrating metric depth predictions from a neural network into a geometric SLAM factor graph. Unlike learned end-to-end SLAM systems, ours does not ignore the relative geometry directly observable in the images. Unlike existing learned depth estimation approaches, ours leverages the insight that when used to estimate scale, learned depth predictions need only be coarse in image space. This allows us to shrink our network to the point that performing inference on a standard CPU becomes computationally tractable.We make several improvements to our network architecture and training procedure to address the lack of depth observability when using coarse images, which allows us to estimate spatially coarse, but depth-accurate predictions in only 30 ms per frame without GPU acceleration. At runtime we incorporate the learned metric data as unary scale factors in a Sim(3) pose graph. Our method is able to generate accurate, scaled poses without additional sensors, hardware accelerators, or special maneuvers and does not ignore or corrupt the observable epipolar geometry. We show compelling results on the KITTI benchmark dataset in addition to real-world experiments with a handheld camera.


Title: Inertial-Only Optimization for Visual-Inertial Initialization
Key Words: feature extraction  least squares approximations  maximum likelihood estimation  optimisation  SLAM (robots)  EuRoC dataset show  time visual-inertial initialization  optimal estimation problem  maximum-a-posteriori estimation  algebraic equations  ad-hoc cost functions  ORB-SLAM visual-inertial boosting  inertial-only optimization  IMU measurement uncertainty  MAP estimation  least squares  Estimation  Trajectory  Simultaneous localization and mapping  Gravity  Visualization  Optimization  Accelerometers 
Abstract: We formulate for the first time visual-inertial initialization as an optimal estimation problem, in the sense of maximum-a-posteriori (MAP) estimation. This allows us to properly take into account IMU measurement uncertainty, which was neglected in previous methods that either solved sets of algebraic equations, or minimized ad-hoc cost functions using least squares. Our exhaustive initialization tests on EuRoC dataset show that our proposal largely outperforms the best methods in the literature, being able to initialize in less than 4 seconds in almost any point of the trajectory, with a scale error of 5.3% on average. This initialization has been integrated into ORB-SLAM Visual-Inertial boosting its robustness and efficiency while maintaining its excellent accuracy.


Title: Hierarchical Quadtree Feature Optical Flow Tracking Based Sparse Pose-Graph Visual-Inertial SLAM
Key Words: computational complexity  graph theory  image sequences  optimisation  pose estimation  quadtrees  pose-graph optimization time cost  localization accuracy  sparse pose-graph visual-inertial SLAM algorithms  hierarchical quadtree feature optical flow tracking algorithm  SPVIS  high-precision pose estimation  computational complexity  VIO-VI-SLAM system  GPU  Optical flow  Optimization  Simultaneous localization and mapping  Robustness  Tracking  Feature extraction  Visualization 
Abstract: Accurate, robust and real-time localization under constrained-resources is a critical problem to be solved. In this paper, we present a new sparse pose-graph visual-inertial SLAM (SPVIS). Unlike the existing methods that are costly to deal with a large number of redundant features and 3D map points, which are inefficient for improving positioning accuracy, we focus on the concise visual cues for high-precision pose estimating. We propose a novel hierarchical quadtree based optical flow tracking algorithm, it achieves high accuracy and robustness within very few concise features, which is only about one fifth features of the state-of-the-art visual-inertial SLAM algorithms. Benefiting from the efficient optical flow tracking, our sparse pose-graph optimization time cost achieves bounded complexity. By selecting and optimizing the informative features in sliding window and local VIO, the computational complexity is bounded, it achieves low time cost in long-term operation. We compare with the state-of-the-art VIO/VI-SLAM systems on the challenging public datasets by the embedded platform without GPUs, the results effectively verify that the proposed method has better real-time performance and localization accuracy.


Title: Keypoint Description by Descriptor Fusion Using Autoencoders
Key Words: convolutional neural nets  image fusion  image matching  learning (artificial intelligence)  robot vision  SLAM (robots)  keypoint description  keypoint matching  computer vision  visual simultaneous localization and mapping  SLAM  matching operation  descriptor fusion model  robust keypoint descriptor  CNN-based descriptors  DFM architecture  CNN models  mean mAP  HardNet  DenseNet169  convolutional neural networks  Fuses  Lighting  Robustness  Computer vision  Simultaneous localization and mapping  Image coding 
Abstract: Keypoint matching is an important operation in computer vision and its applications such as visual simultaneous localization and mapping (SLAM) in robotics. This matching operation heavily depends on the descriptors of the keypoints, and it must be performed reliably when images undergo conditional changes such as those in illumination and viewpoint. In this paper, a descriptor fusion model (DFM) is proposed to create a robust keypoint descriptor by fusing CNN-based descriptors using autoencoders. Our DFM architecture can be adapted to either trained or pre-trained CNN models. Based on the performance of existing CNN descriptors, we choose HardNet and DenseNet169 as representatives of trained and pre-trained descriptors. Our proposed DFM is evaluated on the latest benchmark datasets in computer vision with challenging conditional changes. The experimental results show that DFM is able to achieve state-of-the-art performance, with the mean mAP that is 6.45% and 6.53% higher than HardNet and DenseNet169, respectively.


Title: Towards Noise Resilient SLAM
Key Words: cameras  image colour analysis  image sensors  optimisation  photometry  pose estimation  SLAM (robots)  stereo image processing  RGB-D input  TUM datasets  EuRoC datasets  stereo image pairs  adaptive algorithm  error vector  outlier rejection  computational efficiency  map-point consensus  adaptive virtual camera  noise resilient SLAM  ORB-SLAM2  sparse-indirect SLAM systems  virtual camera location  axial depth error  pose optimization  consensus information  axial noise  lateral noise  depth noise components  axial components  lateral components  noise sources  scale information  SLAM frameworks  depth sensors  photometric invariance properties  Cameras  Simultaneous localization and mapping  Three-dimensional displays  Measurement  Feature extraction  Optimization 
Abstract: Sparse-indirect SLAM systems have been dominantly popular due to their computational efficiency and photometric invariance properties. Depth sensors are critical to SLAM frameworks for providing scale information to the 3D world, yet known to be plagued by a wide variety of noise sources, possessing lateral and axial components. In this work, we demonstrate the detrimental impact of these depth noise components on the performance of the state-of-the-art sparse-indirect SLAM system (ORB-SLAM2). We propose (i) Map-Point Consensus based Outlier Rejection (MC-OR) to counter lateral noise, and (ii) Adaptive Virtual Camera (AVC) to combat axial noise accurately. MC-OR utilizes consensus information between multiple sightings of the same landmark to disambiguate noisy depth and filter it out before pose optimization. In AVC, we introduce an error vector as an accurate representation of the axial depth error. We additionally propose an adaptive algorithm to find the virtual camera location for projecting the error used in the objective function of the pose optimization. Our techniques work equally well for stereo image pairs and RGB-D input directly used by sparse-indirect SLAM systems. Our methods were tested on the TUM (RGB-D) and EuRoC (stereo) datasets and we show that they outperform existing state-of-the-art ORB-SLAM2 by 2-3x, especially in sequences critically affected by depth noise.


Title: LAMP: Large-Scale Autonomous Mapping and Positioning for Exploration of Perceptually-Degraded Subterranean Environments
Key Words: distance measurement  geophysical image processing  mobile robots  multi-robot systems  optical radar  robot vision  SLAM (robots)  stereo image processing  terrain mapping  tunnels  long corridors  salient features  spurious loop closures  repetitive appearance  stark contrast  highly-accurate 3D maps  underground extraterrestrial worlds  lidar-based multirobot SLAM system  DARPA subterranean challenge  subterranean operation  accurate lidar-based front-end  perceptually-degraded subterranean environments  complex subterranean environments  off-nominal conditions  uneven terrains  slippery terrains  large-scale autonomous mapping-positioning  simultaneous localization and mapping  unknown subterranean environment  large-scale subterranean environment  complex subterranean environment  inaccurate wheel odometry  disaster response  flexible back-end  robust back-end  tunnel circuit  Simultaneous localization and mapping  Laser radar  Three-dimensional displays  Base stations  Trajectory 
Abstract: Simultaneous Localization and Mapping (SLAM) in large-scale, unknown, and complex subterranean environments is a challenging problem. Sensors must operate in off-nominal conditions; uneven and slippery terrains make wheel odometry inaccurate, while long corridors without salient features make exteroceptive sensing ambiguous and prone to drift; finally, spurious loop closures that are frequent in environments with repetitive appearance, such as tunnels and mines, could result in a significant distortion of the entire map. These challenges are in stark contrast with the need to build highly-accurate 3D maps to support a wide variety of applications, ranging from disaster response to the exploration of underground extraterrestrial worlds. This paper reports on the implementation and testing of a lidar-based multi-robot SLAM system developed in the context of the DARPA Subterranean Challenge. We present a system architecture to enhance subterranean operation, including an accurate lidar-based front-end, and a flexible and robust back-end that automatically rejects outlying loop closures. We present an extensive evaluation in large-scale, challenging subterranean environments, including the results obtained in the Tunnel Circuit of the DARPA Subterranean Challenge. Finally, we discuss potential improvements, limitations of the state of the art, and future research directions.


Title: BayesOD: A Bayesian Approach for Uncertainty Estimation in Deep Object Detectors
Key Words: Bayes methods  Gaussian processes  neural nets  object detection  NonMaximum suppression components  common object detection datasets  BayesOD  minimum Gaussian uncertainty error metric  minimum Categorical uncertainty error metric  Bayesian approach  deep object detectors  deep neural networks  uncertainty measures  output predictions  detectors nonmaximum suppression stage  anchor-based object detection  uncertainty estimation approach  standard object detector inference  Uncertainty  Detectors  Neural networks  Bayes methods  Estimation  Object detection  Measurement uncertainty 
Abstract: When incorporating deep neural networks into robotic systems, a major challenge is the lack of uncertainty measures associated with their output predictions. Methods for uncertainty estimation in the output of deep object detectors (DNNs) have been proposed in recent works, but have had limited success due to 1) information loss at the detectors nonmaximum suppression (NMS) stage, and 2) failure to take into account the multitask, many-to-one nature of anchor-based object detection. To that end, we introduce BayesOD, an uncertainty estimation approach that reformulates the standard object detector inference and Non-Maximum suppression components from a Bayesian perspective. Experiments performed on four common object detection datasets show that BayesOD provides uncertainty estimates that are better correlated with the accuracy of detections, manifesting as a significant reduction of 9.77%-13.13% on the minimum Gaussian uncertainty error metric and a reduction of 1.63%-5.23% on the minimum Categorical uncertainty error metric. Code will be released at https://github.com/asharakeh/bayes-od-rc.


Title: FADNet: A Fast and Accurate Network for Disparity Estimation
Key Words: computer vision  convolutional neural nets  feature extraction  image matching  stereo image processing  deep neural networks  computer vision  disparity estimation problem  stereo matching  traditional hand-crafted feature based methods  designed DNNs  computation resources  3D convolution based networks  real-time applications  computation-efficient networks  expression capability  large-scale datasets  multiscale predictions  FADNet  multiscale weight scheduling training technique  Estimation  Convolution  Correlation  Three-dimensional displays  Training  Feature extraction  Computer architecture 
Abstract: Deep neural networks (DNNs) have achieved great success in the area of computer vision. The disparity estimation problem tends to be addressed by DNNs which achieve much better prediction accuracy in stereo matching than traditional hand-crafted feature based methods. On one hand, however, the designed DNNs require significant memory and computation resources to accurately predict the disparity, especially for those 3D convolution based networks, which makes it difficult for deployment in real-time applications. On the other hand, existing computation-efficient networks lack expression capability in large-scale datasets so that they cannot make an accurate prediction in many scenarios. To this end, we propose an efficient and accurate deep network for disparity estimation named FADNet with three main features: 1) It exploits efficient 2D based correlation layers with stacked blocks to preserve fast computation; 2) It combines the residual structures to make the deeper model easier to learn; 3) It contains multi-scale predictions so as to exploit a multi-scale weight scheduling training technique to improve the accuracy. We conduct experiments to demonstrate the effectiveness of FADNet on two popular datasets, Scene Flow and KITTI 2015. Experimental results show that FADNet achieves state-of-the-art prediction accuracy, and runs at a significant order of magnitude faster speed than existing 3D models. The codes of FADNet are available at https://github.com/HKBU-HPML/FADNet.


Title: Navigating Discrete Difference Equation Governed WMR by Virtual Linear Leader Guided HMPC
Key Words: difference equations  mobile robots  multi-robot systems  nonlinear control systems  path planning  predictive control  reachability analysis  set theory  navigating discrete difference equation governed WMR  virtual linear leader guided HMPC  model predictive control  classical wheeled mobile robot navigation problem  hierarchical MPC  state-of-the-art MPC  WMR navigation  nonexistence  nontrivial linear system  under-approximate reachable set  VLL-MPC  HMPC structure  virtual linear system  under-approximate path  RRT*  Navigation  Linear systems  Stability analysis  Planning  Robots  Mathematical model  Nonlinear dynamical systems 
Abstract: In this paper, we revisit model predictive control (MPC) for the classical wheeled mobile robot (WMR) navigation problem. We prove that the reachable set based hierarchical MPC (HMPC), a state-of-the-art MPC, cannot handle WMR navigation in theory due to the non-existence of non-trivial linear system with an under-approximate reachable set of WMR. Nevertheless, we propose a virtual linear leader guided MPC (VLL-MPC) to enable HMPC structure. Different from current HMPCs, we use a virtual linear system with an under-approximate path set rather than the traditional trace set to guide the WMR. We provide a valid construction of the virtual linear leader. We prove the stability of VLL-MPC, and discuss its complexity. In the experiment, we demonstrate the advantage of VLL-MPC empirically by comparing it with NMPC, LMPC and anytime RRT* in several scenarios.


Title: Stable Control in Climbing and Descending Flight under Upper Walls using Ceiling Effect Model based on Aerodynamics
Key Words: aerodynamics  aircraft control  autonomous aerial vehicles  helicopters  motion control  rotors (mechanical)  stability  wakes  ceiling effect model  flight control stability  multirotor unmanned aerial vehicles  rotor thrust  vertical flight tests  in unsteady state model based controller  aerodynamics based thrust model  vertical climbing  vertical descending  wake interaction  momentum theory  Rotors  Data models  Adaptation models  Aerodynamics  Steady-state  Atmospheric modeling  Sensors 
Abstract: Stable flight control under ceilings is difficult for multirotor Unmanned Aerial Vehicles (UAVs). The wake interaction between rotors and upper walls, called the "ceiling effect", causes an increase of rotor thrust. As a result of the thrust increase, multi-rotors are drawn upward abruptly and collide with ceilings. In previous work, several thrust models of the ceiling effect have been proposed for stable flight under ceilings, assuming that the airflow around rotors is in steady states. However, the airflow around rotors in vertical flight is not in steady states and each thrust model in previous work is skillfully determined based on large amounts of precise experimental data. In this paper, we introduce an aerodynamics-based thrust model and a stable control method under ceilings. This model is derived from the momentum theory and the relationship between vertical climbing/descending rates of rotors and an induced velocity. To confirm our proposed model, we collect thrust data at various vertical rates in flight. In addition, we use only onboard sensors to estimate selfstate for structural inspections. Consequently, we reveal that the proposed model is consistent with the experimental results. Based on an aerodynamic model, we need not collect large amounts of precise experimental data to realize stable flight. Furthermore, the vertical flight tests under ceilings demonstrate that our in-unsteady-state-model-based controller outperforms the conventional steady-state ones.


Title: Unsupervised Anomaly Detection for Self-flying Delivery Drones
Key Words: aerodynamics  autonomous aerial vehicles  control engineering computing  learning (artificial intelligence)  mobile robots  regression analysis  unsupervised anomaly detection  hybrid aerial vehicles  machine learning models  flight profiles  flight log measurements  sensor readings  predictive flight dynamics models  aircraft aerodynamics  self-flying delivery drones  Aerodynamics  Smoothing methods  Robustness  Training  Anomaly detection  Optimization  Aircraft 
Abstract: We propose a novel anomaly detection framework for a fleet of hybrid aerial vehicles executing high-speed package pickup and delivery missions. The detection is based on machine learning models of normal flight profiles, trained on millions of flight log measurements of control inputs and sensor readings. We develop a new scalable algorithm for robust regression which can simultaneously fit predictive flight dynamics models while identifying and discarding abnormal flight missions from the training set. The resulting unsupervised estimator has a very high breakdown point and can withstand massive contamination of training data to uncover what normal flight patterns look like, without requiring any form of prior knowledge of aircraft aerodynamics or manual labeling of anomalies upfront. Across many different anomaly types, spanning simple 3sigma statistical thresholds to turbulence and other equipment anomalies, our models achieve high detection rates across the board. Our method consistently outperforms alternative robust detection methods on synthetic benchmark problems. To the best of our knowledge, dynamics modeling of hybrid delivery drones for anomaly detection at the scale of 100 million measurements from 5000 real flight missions in variable flight conditions is unprecedented.


Title: Keyfilter-Aware Real-Time UAV Object Tracking
Key Words: autonomous aerial vehicles  image filtering  image motion analysis  learning (artificial intelligence)  mobile robots  object detection  object tracking  robot vision  SLAM (robots)  keyframe-based simultaneous localization and mapping  keyfilter restriction  visual tracking  background distraction  filter corruption  boundary effect  unmanned aerial vehicle  correlation filter-based tracking  keyfilter-aware real-time UAV object tracking  Unmanned aerial vehicles  Correlation  Visualization  Object tracking  Frequency-domain analysis  Real-time systems 
Abstract: Correlation filter-based tracking has been widely applied in unmanned aerial vehicle (UAV) with high efficiency. However, it has two imperfections, i.e., boundary effect and filter corruption. Several methods enlarging the search area can mitigate boundary effect, yet introducing undesired background distraction. Existing frame-by-frame context learning strategies for repressing background distraction nevertheless lower the tracking speed. Inspired by keyframe-based simultaneous localization and mapping, keyfilter is proposed in visual tracking for the first time, in order to handle the above issues efficiently and effectively. Keyfilters generated by periodically selected keyframes learn the context intermittently and are used to restrain the learning of filters, so that 1) context awareness can be transmitted to all the filters via keyfilter restriction, and 2) filter corruption can be repressed. Compared to the state-of-the-art results, our tracker performs better on two challenging benchmarks, with enough speed for UAV real-time applications.


Title: Aerial Regrasping: Pivoting with Transformable Multilink Aerial Robot
Key Words: aerospace robotics  dexterous manipulators  grippers  motion control  remotely operated vehicles  stability  aerial regrasping  aerial manipulator  dexterous manipulation  transformable multilink aerial robot  transformable multilink drone  grasping stability  thrust force  continous grasping force  admittance controller  impedance controller  contact aware regrasping  Task analysis  Force  Grasping  Unmanned aerial vehicles  Rotors  End effectors 
Abstract: Regrasping is one of the most common and important manipulation skills used in our daily life. However, aerial regrasping has not been seriously investigated yet, since most of the aerial manipulator lacks dexterous manipulation abilities except for the basic pick-and-place. In this paper, we focus on pivoting a long box, which is one of the most classical problems among regrasping researches, using a transformable multilink aerial robot. First, we improve our previous controller by compensating for the external wrench. Second, we optimize the joints configuration of our transformable multilink drone for stable grasping form under the constraints of thrust force and joints effort. Third, we sequentially optimize the grasping force in the pivoting process. The optimization goal is to generate continous grasping force whilst maximizing the friction force in case of the downwash, which would influence the grasped object and is difficult to model. Fourth, we develop the impedance controller in joint space and admittance controller in task space. As far as we know, it is the first research to achieve extrinsic contact-aware regrasping task on aerial robots.


Title: A Synchronization Approach for Achieving Cooperative Adaptive Cruise Control Based Non-Stop Intersection Passing
Key Words: adaptive control  control system synthesis  distributed control  Lyapunov methods  mobile robots  multi-robot systems  position control  road traffic control  road vehicles  stability  velocity control  synchronization approach  adaptive cruise control based nonstop intersection passing  intelligent vehicles  cruise control performance  traffic congestion  increasing traffic flow capacity  CACC problem  synchronization control  spatial-temporal synchronization mechanism  vehicle platoon control  robust CACC  cross-coupling based space synchronization mechanism  distributed control algorithm  single-lane CACC  vehicle-to-vehicle communications  autonomous vehicles  desired platoon trajectory  expected inter-vehicle distance  enter-time scheduling mechanism  high-level intersection control strategy  Lyapunov-based time-domain stability analysis approach  traditional string stability based approach  CACC system  Synchronization  Stability analysis  Cruise control  Robustness  Autonomous vehicles  Motion control  Acceleration 
Abstract: Cooperative adaptive cruise control (CACC) of intelligent vehicles contributes to improving cruise control performance, reducing traffic congestion, saving energy and increasing traffic flow capacity. In this paper, we resolve the CACC problem from the viewpoint of synchronization control, our main idea is to introduce the spatial-temporal synchronization mechanism into vehicle platoon control to achieve the robust CACC and to further realize the non-stop intersection control. Firstly, by introducing the cross-coupling based space synchronization mechanism, a distributed control algorithm is presented to achieve the single-lane CACC in the presence of vehicle-to-vehicle (V2V) communications, which enables autonomous vehicles to track the desired platoon trajectory while synchronizing their longitudinal velocities to keeping the expected inter-vehicle distance. Secondly, by designing the enter-time scheduling mechanism (temporal synchronization), a high-level intersection control strategy is proposed to command vehicles to form a virtual platoon to pass through the intersection without stopping. Thirdly, a Lyapunov-based time-domain stability analysis approach is presented. Compared with the traditional string stability based approach, the proposed approach guarantees the global asymptotical convergence of the proposed CACC system. Experiments in the small-scale simulated system demonstrate the effectiveness of the proposed approach.


Title: Beyond Photometric Consistency: Gradient-based Dissimilarity for Improving Visual Odometry and Stereo Matching
Key Words: cameras  distance measurement  gradient methods  image matching  image registration  image sensors  pose estimation  robot vision  SLAM (robots)  stereo image processing  visual SLAM systems  photometric consistency  gradient-based dissimilarity  camera pose estimation  map building  central ingredients  autonomous robots  photometric error  gradient orientation  magnitude-dependent scaling term  stereo estimation  visual odometry systems  direct image registration tasks  robust estimates  scene depth  camera trajectory  mapping capabilities  mobile robots  sensor data registration  Measurement  Robustness  Cameras  Estimation  Visual odometry  Simultaneous localization and mapping  Robot vision systems 
Abstract: Pose estimation and map building are central ingredients of autonomous robots and typically rely on the registration of sensor data. In this paper, we investigate a new metric for registering images that builds upon on the idea of the photometric error. Our approach combines a gradient orientation-based metric with a magnitude-dependent scaling term. We integrate both into stereo estimation as well as visual odometry systems and show clear benefits for typical disparity and direct image registration tasks when using our proposed metric. Our experimental evaluation indicate that our metric leads to more robust and more accurate estimates of the scene depth as well as camera trajectory. Thus, the metric improves camera pose estimation and in turn the mapping capabilities of mobile robots. We believe that a series of existing visual odometry and visual SLAM systems can benefit from the findings reported in this paper.


Title: ICS: Incremental Constrained Smoothing for State Estimation
Key Words: matrix decomposition  mobile robots  optimisation  path planning  robot vision  SLAM (robots)  state estimation  ICS  primal-dual method  matrix factorizations  primal-dual methods  incremental factorization  matrix structure  incremental unconstrained optimization  robot state estimate  smoothing-based estimation methods  state estimation  incremental constrained smoothing  Optimization  Smoothing methods  Time measurement  Integrated circuits  Simultaneous localization and mapping 
Abstract: A robot operating in the world constantly receives information about its environment in the form of new measurements at every time step. Smoothing-based estimation methods seek to optimize for the most likely robot state estimate using all measurements up till the current time step. Existing methods solve for this smoothing objective efficiently by framing the problem as that of incremental unconstrained optimization. However, in many cases observed measurements and knowledge of the environment is better modeled as hard constraints derived from real-world physics or dynamics. A key challenge is that the new optimality conditions introduced by the hard constraints break the matrix structure needed for incremental factorization in these incremental optimization methods. Our key insight is that if we leverage primal-dual methods, we can recover a matrix structure amenable to incremental factorization. We propose a framework ICS that combines a primal-dual method like the Augmented Lagrangian with an incremental Gauss Newton approach that reuses previously computed matrix factorizations. We evaluate ICS on a set of simulated and real-world problems involving equality constraints like object contact and inequality constraints like collision avoidance.


Title: Temporal Segmentation of Surgical Sub-tasks through Deep Learning with Multiple Data Sources
Key Words: biomedical ultrasonics  finite state machines  learning (artificial intelligence)  medical computing  medical image processing  medical robotics  surgery  Skill Assessment Working Set  robotic intra-operative ultrasound imaging  da Vinci® Xi surgical system  superior frame-wise state estimation accuracy  temporal segmentation  deep learning  data sources  robot-assisted surgeries  finite-state machines  surgical task  temporal perception  current surgical scene  real-time estimation  task progresses  state estimation models  surgical state estimation models  State estimation  Data models  Task analysis  Feature extraction  Hidden Markov models  Robots  Kinematics 
Abstract: Many tasks in robot-assisted surgeries (RAS) can be represented by finite-state machines (FSMs), where each state represents either an action (such as picking up a needle) or an observation (such as bleeding). A crucial step towards the automation of such surgical tasks is the temporal perception of the current surgical scene, which requires a real-time estimation of the states in the FSMs. The objective of this work is to estimate the current state of the surgical task based on the actions performed or events occurred as the task progresses. We propose Fusion-KVE, a unified surgical state estimation model that incorporates multiple data sources including the Kinematics, Vision, and system Events. Additionally, we examine the strengths and weaknesses of different state estimation models in segmenting states with different representative features or levels of granularity. We evaluate our model on the JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS), as well as a more complex dataset involving robotic intra-operative ultrasound (RIOUS) imaging, created using the da Vinci® Xi surgical system. Our model achieves a superior frame-wise state estimation accuracy up to 89.4%, which improves the state-of-the-art surgical state estimation models in both JIGSAWS suturing dataset and our RIOUS dataset.


Title: On the efficient control of series-parallel compliant articulated robots
Key Words: actuators  legged locomotion  optimisation  position control  robot dynamics  torque  torque control  series-parallel compliant articulated leg prototype  highly-efficient parallel actuation branches  torque allocation  transmission ratio  actuator hardware specifications  periodic squat motions  motion efficiency  parallel actuators  quadratic criteria  optimization based controller  redundant robots  torque distribution  series-parallel compliant articulated robots  Torque  Actuators  Joints  Tendons  Legged locomotion  Topology 
Abstract: Torque distribution in redundant robots that combine the potential of asymmetric series-parallel actuated branches and multi-articulation pose a non-trivial challenge. To address the problem, this work proposes a novel optimization based controller that can accommodate various quadratic criteria to perform the torque distribution among dissimilar series and parallel actuators in order to maximize the motion efficiency. Three candidate criteria are composed and their performances are compared during periodic squat motions with a 3 degree of freedom series-parallel compliant articulated leg prototype. It is first shown that by minimizing a criterion that takes into account the actuator hardware specifications such as torque constant and transmission ratio, the gravity-driven phases can be lengthened. Thereby, this particular criterion results in slightly better performance than when adopting a strategy that maximizes the torque allocation to the higher efficiency actuators. Furthermore, valuable insights such as that the efficacy of maximum utilization of the highly-efficient parallel actuation branches decreases progressively at high frequencies were observed.


Title: UBAT: On Jointly Optimizing UAV Trajectories and Placement of Battery Swap Stations
Key Words: ant colony optimisation  autonomous aerial vehicles  battery powered vehicles  electric vehicles  optimal number  charging stations  UBAT  ant colony optimization  UAV trajectories  battery swap stations  unmanned aerial vehicles  UAVs  flight time  charging station deployment problem  NP-hard problem  Charging stations  Batteries  Trajectory  Optimization  Sensors  Unmanned aerial vehicles  Euclidean distance 
Abstract: Unmanned aerial vehicles (UAVs) have been widely used in many applications. The limited flight time of UAVs, however, still remains as a major challenge. Although numerous approaches have been developed to recharge the battery of UAVs effectively, little is known about optimal methodologies to deploy charging stations. In this paper, we address the charging station deployment problem with an aim to find the optimal number and locations of charging stations such that the system performance is maximized. We show that the problem is NP-Hard and propose UBAT, a heuristic framework based on the ant colony optimization (ACO) to solve the problem. Additionally, a suite of algorithms are designed to enhance the execution time and the quality of the solutions for UBAT. Through extensive simulations, we demonstrate that UBAT effectively performs multi-objective optimization of generation of UAV trajectories and placement of charging stations that are within 8.3% and 7.3% of the true optimal solutions, respectively.


Title: Efficient Multi-Agent Trajectory Planning with Feasibility Guarantee using Relative Bernstein Polynomial
Key Words: collision avoidance  multi-agent systems  optimisation  polynomials  optimization-based approaches  erroneous optimization setup  infeasible collision constraints  sequential optimization method  dummy agents  relative Bernstein polynomial  nonconvex collision avoidance constraints  multiagent trajectory planning problems  obstacle-dense environments  grid-based approaches  Trajectory  Planning  Heuristic algorithms  Collision avoidance  Optimization  System recovery  Three-dimensional displays 
Abstract: This paper presents a new efficient algorithm which guarantees a solution for a class of multi-agent trajectory planning problems in obstacle-dense environments. Our algorithm combines the advantages of both grid-based and optimization-based approaches, and generates safe, dynamically feasible trajectories without suffering from an erroneous optimization setup such as imposing infeasible collision constraints. We adopt a sequential optimization method with dummy agents to improve the scalability of the algorithm, and utilize the convex hull property of Bernstein and relative Bernstein polynomial to replace non-convex collision avoidance constraints to convex ones. The proposed method can compute the trajectory for 64 agents on average 6.36 seconds with Intel Core i7-7700 @ 3.60GHz CPU and 16G RAM, and it reduces more than 50% of the objective cost compared to our previous work. We validate the proposed algorithm through simulation and flight tests.


Title: Optimal Sequential Task Assignment and Path Finding for Multi-Agent Robotic Assembly Planning
Key Words: assembly planning  collision avoidance  mobile robots  multi-agent systems  multi-robot systems  robotic assembly  nonholonomic differential-drive robots  optimal sequential task assignment  collision-free trajectories  robotic manufacturing  collision-free routing  multiagent robotic assembly planning  path finding  Robots  Task analysis  Schedules  Manufacturing  Collision avoidance  Routing  Production facilities 
Abstract: We study the problem of sequential task assignment and collision-free routing for large teams of robots in applications with inter-task precedence constraints (e.g., task A and task B must both be completed before task C may begin). Such problems commonly occur in assembly planning for robotic manufacturing applications, in which sub-assemblies must be completed before they can be combined to form the final product. We propose a hierarchical algorithm for computing makespan-optimal solutions to the problem. The algorithm is evaluated on a set of randomly generated problem instances where robots must transport objects between stations in a "factory" grid world environment. In addition, we demonstrate in high-fidelity simulation that the output of our algorithm can be used to generate collision-free trajectories for non-holonomic differential-drive robots.


Title: Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning
Key Words: control engineering computing  learning (artificial intelligence)  mobile robots  multi-robot systems  navigation  path planning  optimal paths  multiple robots  dynamics randomization  differential drive robots  dynamic environment  obstacle complexities  multirobot navigation problem  deep reinforcement learning framework  optimal target locations  DRL based framework  navigation policy  Collision avoidance  Navigation  Robot sensing systems  Robot kinematics  Training  Adaptation models 
Abstract: The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential drive robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.


Title: Adaptive Directional Path Planner for Real-Time, Energy-Efficient, Robust Navigation of Mobile Robots
Key Words: energy conservation  graph theory  mobile robots  path planning  robust control  sample based methods  sub-optimal memory-intensive  Adaptive Directional Planner algorithm  robust local path planning  autonomous navigation  form factor mobile robots  low memory footprint  robust navigation  unknown environments  complex environments  fundamental capability  robotic applications  optimal robot path planning  complex memory intensive task  adaptive directional path planner  ADP algorithm implementation  memory size 28.0 KByte  Mobile robots  Trajectory  Real-time systems  Navigation  Kinematics 
Abstract: Autonomous navigation through unknown and complex environments is a fundamental capability that is essential in almost all robotic applications. Optimal robot path planning is critical to enable efficient navigation. Path planning is a complex, compute and memory intensive task. Traditional methods employ either graph based search methods or sample based methods to implement path planning, which are sub-optimal and compute/memory-intensive. To this end, an Adaptive Directional Planner (ADP) algorithm is devised to achieve real-time, energy-efficient, memory-optimized, robust local path planning for enabling efficient autonomous navigation of mobile robots. The ADP algorithm ensures that the paths are optimal and kinematically-feasible. Further, the proposed algorithm is tested with different challenging scenarios verifying the functionality and robustness. The ADP algorithm implementation results demonstrate 40- 60X less number of nodes and 40 - 50X less execution time compared to the standard TP-RRT schemes, without compromising on accuracy. Finally, the algorithm has also been implemented as an accelerator for non-holonomic, multi-shape, small form factor mobile robots to provide a silicon solution with high performance and low memory footprint (28KB).


Title: OmniSLAM: Omnidirectional Localization and Dense Mapping for Wide-baseline Multi-camera Systems
Key Words: cameras  computerised instrumentation  distance measurement  image matching  image reconstruction  image sequences  neural nets  stereo image processing  omnidirectional localization  wide-baseline multicamera systems  dense mapping system  wide-baseline multiview stereo setup  ultrawide field-of-view fisheye cameras  stereo observations  light-weighted deep neural networks  loop closing module  efficient feature matching process  omnidirectional depth maps  truncated signed distance function volume  rig estimation  omnidirectional depth map estimation  VO  FOV  TSDF  OmniSLAM  Cameras  Three-dimensional displays  Estimation  Feature extraction  Visual odometry  Sensors  Trajectory 
Abstract: In this paper, we present an omnidirectional localization and dense mapping system for a wide-baseline multiview stereo setup with ultra-wide field-of-view (FOV) fisheye cameras, which has a 360° coverage of stereo observations of the environment. For more practical and accurate reconstruction, we first introduce improved and light-weighted deep neural networks for the omnidirectional depth estimation, which are faster and more accurate than the existing networks. Second, we integrate our omnidirectional depth estimates into the visual odometry (VO) and add a loop closing module for global consistency. Using the estimated depth map, we reproject keypoints onto each other view, which leads to a better and more efficient feature matching process. Finally, we fuse the omnidirectional depth maps and the estimated rig poses into the truncated signed distance function (TSDF) volume to acquire a 3D map. We evaluate our method on synthetic datasets with ground-truth and real-world sequences of challenging environments, and the extensive experiments show that the proposed system generates excellent reconstruction results in both synthetic and real-world environments.


Title: 3D Orientation Estimation and Vanishing Point Extraction from Single Panoramas Using Convolutional Neural Network
Key Words: cameras  computer vision  convolutional neural nets  feature extraction  image classification  regression analysis  stereo image processing  convolutional neural network  3D orientation estimation  computer vision  3D scene understanding  single spherical panorama  labeled 3D orientation  vanishing point extraction  single panoramas  VOP60K  Google Street View  pinhole cameras  panorama geometric information  two column vector regression loss  rotation matrix  CNN architecture  classification loss  edge extractor layer  Cameras  Three-dimensional displays  Feature extraction  Google  Estimation  Data mining  Robot vision systems 
Abstract: 3D orientation estimation is a key component of many important computer vision tasks such as autonomous navigation and 3D scene understanding. This paper presents a new CNN architecture to estimate the 3D orientation of an omnidirectional camera with respect to the world coordinate system from a single spherical panorama. To train the proposed architecture, we leverage a dataset of panoramas named VOP60K from Google Street View with labeled 3D orientation, including 50 thousand panoramas for training and 10 thousand panoramas for testing. Previous approaches usually estimate 3D orientation under pinhole cameras. However, for a panorama, due to its larger field of view, previous approaches cannot be suitable. In this paper, we propose an edge extractor layer to utilize the low-level and geometric information of panorama, an attention module to fuse different features generated by previous layers. A regression loss for two column vectors of the rotation matrix and classification loss for the position of vanishing points are added to optimize our network simultaneously. The proposed algorithm is validated on our benchmark, and experimental results clearly demonstrate that it outperforms previous methods.


Title: Center-of-Mass-based Robust Grasp Planning for Unknown Objects Using Tactile-Visual Sensors
Key Words: dexterous manipulators  grippers  path planning  robot vision  tactile sensors  Franka Emika robot arm  tactile sensors  multisensor modules  regrasp planner  slip detection  visual sensors  center-of-mass-based robust grasp planning  Grasping  Tactile sensors  Force  Robustness 
Abstract: An unstable grasp pose can lead to slip, thus an unstable grasp pose can be predicted by slip detection. A regrasp is required afterwards to correct the grasp pose in order to finish the task. In this work, we propose a novel regrasp planner with multi-sensor modules to plan grasp adjustments with the feedback from a slip detector. Then a regrasp planner is trained to estimate the location of center of mass, which helps robots find an optimal grasp pose. The dataset in this work consists of 1 025 slip experiments and 1 347 regrasps collected by one pair of tactile sensors, an RGB-D camera and one Franka Emika robot arm equipped with joint force/torque sensors. We show that our algorithm can successfully detect and classify the slip for 5 unknown test objects with an accuracy of 76.88% and a regrasp planner increases the grasp success rate by 31.0% compared to the state-of-the-art vision-based grasping algorithm.


Title: OmniTact: A Multi-Directional High-Resolution Touch Sensor
Key Words: cameras  computer vision  convolutional neural nets  dexterous manipulators  gels  image resolution  microsensors  neurocontrollers  sensor fusion  state estimation  tactile sensors  dexterous robotic manipulation  deep convolutional neural networks  electrical connector  multidirectional high-resolution touch sensor  low-resolution signals  multidirectional high-resolution tactile sensor  robotic hands  multiple microcameras  multidirectional deformations  gel-based skin  contact state variables  image processing  computer vision methods  state estimation problem  robotic control task  OmniTact combination  Cameras  Tactile sensors  Sensitivity  Task analysis 
Abstract: Incorporating touch as a sensing modality for robots can enable finer and more robust manipulation skills. Existing tactile sensors are either flat, have small sensitive fields or only provide low-resolution signals. In this paper, we introduce OmniTact, a multi-directional high-resolution tactile sensor. OmniTact is designed to be used as a fingertip for robotic manipulation with robotic hands, and uses multiple micro-cameras to detect multi-directional deformations of a gel-based skin. This provides a rich signal from which a variety of different contact state variables can be inferred using modern image processing and computer vision methods. We evaluate the capabilities of OmniTact on a challenging robotic control task that requires inserting an electrical connector into an outlet, as well as a state estimation problem that is representative of those typically encountered in dexterous robotic manipulation, where the goal is to infer the angle of contact of a curved finger pressing against an object. Both tasks are performed using only touch sensing and deep convolutional neural networks to process images from the sensor's cameras. We compare with a state-of-the-art tactile sensor that is only sensitive on one side, as well as a state-of-the-art multi-directional tactile sensor, and find that OmniTact's combination of high-resolution and multi-directional sensing is crucial for reliably inserting the electrical connector and allows for higher accuracy in the state estimation task. Videos and supplementary material can be found here4.


Title: Tightly-Coupled Single-Anchor Ultra-wideband-Aided Monocular Visual Odometry System
Key Words: distance measurement  feature extraction  graph theory  least squares approximations  optimisation  pose estimation  position measurement  robot vision  Levenberg-Marquardt nonlinear least squares optimization scheme  scale factor  visual features  pose-graph optimization scheme  landmark reprojection errors  visual drift  monocular visual feature observations  distance measurements  ultrawideband-aided monocular visual odometry system  single-anchor monocular visual odometry system  tightly-coupled odometry framework  anchor position estimation  robot operating system  Cameras  Distance measurement  Robot sensing systems  Visualization 
Abstract: In this work, we propose a tightly-coupled odometry framework, which combines monocular visual feature observations with distance measurements provided by a single ultra-wideband (UWB) anchor with an initial guess for its location. Firstly, the scale factor and the anchor position in the vision frame will be simultaneously estimated using a variant of Levenberg-Marquardt non-linear least squares optimization scheme. Once the scale factor is obtained, the map of visual features is updated with the new scale. Subsequent ranging errors in a sliding window are continuously monitored and the estimation procedure will be reinitialized to refine the estimates. Lastly, range measurements and anchor position estimates are fused when needed into a pose-graph optimization scheme to minimize both the landmark reprojection errors and ranging errors, thus reducing the visual drift and improving the system robustness. The proposed method is implemented in Robot Operating System (ROS) and can function in real-time. The performance is validated on both public datasets and real-life experiments and compared with state-of-the-art methods.


Title: CAMI - Analysis, Design and Realization of a Force-Compliant Variable Cam System
Key Words: cams (mechanical)  compliant mechanisms  end effectors  force control  legged locomotion  motion control  path planning  trajectory control  CAMI  multilegged locomotion  continuous gait transition  end effector trajectory  end effector motions  three dimensional cam system  force compliant variable cam system  bipedal robot  Legged locomotion  Trajectory  End effectors  Couplings  Shape  Actuators 
Abstract: This work presents a novel design concept that achieves multi-legged locomotion using a three-dimensional cam system. A computational framework has been developed to analyze and dimension this cam apparatus, that can perform arbitrary end effector motions within its design constraints. The mechanism enables continuous gait transition and inherent force compliance. With only two motors, any trajectory of a continuous set of gaits can be followed. One motor is used to actuate the system and a second one to morph its movement. To illustrate a possible application of this system, a working prototype of a bipedal robot is developed and validated in hardware. It showcases a smooth velocity change by transitioning through different gaits from standing still to walking fast at 124mm/s within 2.0s, while following the given end effector trajectory with an error of only 2.47mm.


Title: Using Manipulation to Enable Adaptive Ground Mobility
Key Words: adhesion  legged locomotion  manipulators  permanent magnets  propulsion  road vehicles  wheels  swappable propulsors  adhesion forces  wheeled locomotion  legged locomotion  autonomous ground vehicles  terrain  whegs  physical adaptation  multipurpose manipulators  propulsion system  adaptive ground mobility  permanent magnets  functional prototype robot  Legged locomotion  Wheels  Manipulators  Steel  Force  Mechanism design  mobile manipulation  wheeled robots 
Abstract: In order to accomplish various missions, autonomous ground vehicles must operate on a wide range of terrain. While many systems such as wheels and whegs can navigate some types of terrain, none are optimal across all. This creates a need for physical adaptation. This paper presents a broad new approach to physical adaptation that relies on manipulation. Specifically, we explore how multipurpose manipulators can enable ground vehicles to dramatically modify their propulsion system in order to optimize performance across various terrain. While this approach is general and widely applicable, this work focuses on physically switching between wheels and legs. We outline the design of "swappable propulsors" that combine the powerful adhesion forces of permanent magnets with geometric features for easy detachment. We provide analysis on how the swappable propulsors can be manipulated, and use these results to create a functional prototype robot. This robot can use its manipulator to change between wheeled and legged locomotion. Our experimental results illustrate how this approach can enhance energy efficiency and versatility.


Title: SNIAE-SSE Deformation Mechanism Enabled Scalable Multicopter: Design, Modeling and Flight Performance Validation
Key Words: actuators  deformation  helicopters  symmetrical deformation  synchronous deformation  multicopter system  flight missions  stable flight behavior  folding  unfolding body deformations  SNIAE-SSE deformation mechanism  flight performance validation  modeling validating  straight scissor-like elements  simple non-intersecting angulated elements  actuation capability  Strain  Rotors  Servomotors  Prototypes  Deformable models  Task analysis  Torque 
Abstract: This paper focuses on designing, modeling and validating a novel scalable multicopter whose deformation mechanism, called SNIAE-SSE, relies on a combination of simple non-intersecting angulated elements (SNIAEs) and straight scissor-like elements (SSEs). The proposed SNIAE-SSE mechanism has the advantages of single degree-of-freedom, fast actuation capability and large deformation ratio. In this work, enabled by the SNIAE-SSE mechanism, a quadcopter prototype with symmetrical and synchronous deformation is firstly developed, which facilitates a novel and controllably scalable multicopter system for us to analyze its modeling, as well as to validate its flight performance and dynamics during the deformation in several flight missions including hover, throwing, and morphing flying through a narrow window. Experimental results demonstrate that the developed scalable multicopter can maintain its stable flight behavior even both the folding and unfolding body deformations are fast performed, which indicates an excellent capability of the scalable multicopter to rapidly adapt to complex and dynamically changed environments.


Title: Cooperative Autonomy and Data Fusion for Underwater Surveillance With Networked AUVs
Key Words: autonomous underwater vehicles  mobile robots  sensor fusion  target tracking  underwater acoustic communication  AUV cooperative strategies  data fusion  realistic underwater surveillance scenarios  networked AUVs  data sharing  robotic networks  underwater surveillance applications  autonomous underwater vehicles  CMRE Anti-Submarine Warfare network  track management module  robot autonomy software  track classification  T2T association  Target tracking  Robot kinematics  Sonar  Receivers  Signal processing algorithms 
Abstract: Cooperative autonomy and data sharing can largely improve the mission performance of robotic networks in underwater surveillance applications. In this paper, we describe the cooperative autonomy used to control the Autonomous Underwater Vehicles (AUVs) acting as sonar receiver nodes in the CMRE Anti-Submarine Warfare (ASW) network. The paper focuses on a track management module that was integrated in the robot autonomy software for enabling the share of information. Track to track (T2T) associations are used for improving track classification and for creating a common tactical picture, necessary for AUV cooperative strategies. We also present a new cooperative data-driven AUV behaviour that exploits the spatial diversity of multiple robots for improving target tracking and for facilitating T2T associations. We report results with real data collected at sea that validate the approach. The reported results are one of the first examples that show the potential of cooperative autonomy and data fusion in realistic underwater surveillance scenarios characterised by limited communications.


Title: Bidirectional Resonant Propulsion and Localization for AUVs
Key Words: autonomous underwater vehicles  diaphragms  electromagnetic actuators  marine control  mobile robots  motion control  robot vision  SLAM (robots)  electromagnetic voice coil motor  bidirectional resonant propulsion  AUV localization  thrust vectors  diaphragm pump mechanism  resonant motion  actuator design  bidirectional resonant pump  autonomous underwater vehicles  Propulsion  Resonant frequency  Strain  Standards  Damping  Reliability engineering 
Abstract: Battery life, reliability, and localization are prominent challenges in the design of autonomous underwater vehicles (AUVs). This work aims to address facets of these challenges using a single system. We describe the design of a bidirectional resonant pump that uses a single electromagnetic voice coil motor (VCM) capable of rotation around a central two degree-of-freedom flexure stage axis. This actuator design produces highly efficient resonant motion that drives two orthogonally oriented diaphragms simultaneously. The operation of this diaphragm pump mechanism produces both adjustable thrust vectors at the aft surface of the AUV and a monotonic relationship between thrust vectors and operating frequency. We propose using the unique frequency to thrust relationship to enhance AUV localization capabilities. We construct a prototype and use it to experimentally demonstrate the feasibility of the directionally-tunable resonance concept.


Title: Underwater Image Super-Resolution using Deep Residual Multipliers
Key Words: image resolution  learning (artificial intelligence)  neural nets  robot vision  underwater vehicles  single image super-resolution  autonomous underwater robots  adversarial training pipeline  perceptual quality  global content  local style information  USR-248  SISR  state-of-the-art models  deep residual multipliers  deep residual network-based generative model  underwater image super-resolution  noisy visual conditions  Training  Image resolution  Robots  Data models  Cameras  Pipelines  Generators 
Abstract: We present a deep residual network-based generative model for single image super-resolution (SISR) of underwater imagery for use by autonomous underwater robots. We also provide an adversarial training pipeline for learning SISR from paired data. In order to supervise the training, we formulate an objective function that evaluates the perceptual quality of an image based on its global content, color, and local style information. Additionally, we present USR-248, a large-scale dataset of three sets of underwater images of `high' (640×480) and `low' (80 × 60, 160 × 120, and 320×240) resolution. USR-248 contains paired instances for supervised training of 2×, 4×, or 8× SISR models. Furthermore, we validate the effectiveness of our proposed model through qualitative and quantitative experiments and compare the results with several state-of-the-art models' performances. We also analyze its practical feasibility for applications such as scene understanding and attention modeling in noisy visual conditions.


Title: Variable Stiffness Springs for Energy Storage Applications
Key Words: actuators  energy storage  mathematical analysis  rigidity  robot dynamics  springs (mechanical)  variable stiffness actuation technology  variable stiffness springs  energy storage capacity  linear helical springs  variable stiffness actuators  human performance augmentation  spring exoskeleton  controllable volume air spring  mathematical conditions  Springs  Energy storage  Actuators  Potential energy  Strain  Force  Valves 
Abstract: Theory suggests an inverse relation between the stiffness and the energy storage capacity for linear helical springs: reducing the active length of the spring by 50% increases its stiffness by 100%, but reduces its energy storage capacity by 50%. State-of-the-art variable stiffness actuators used to drive robots are characterized by a similar inverse relation, implying reduced energy storage capacity for increased spring stiffness. This relation limits the potential of the variable stiffness actuation technology when it comes to human performance augmentation in natural tasks, e.g., jumping, weight-bearing and running, which may necessitate a spring exoskeleton with large stiffness range and high energy storage capacity. In this paper, we theoretically show that the trade-off between stiffness range and energy storage capacity is not fundamental; it is possible to develop variable stiffness springs with simultaneously increasing stiffness and energy storage capacity. Consistent with the theory, we experimentally show that a controllable volume air spring, has a direct relation between its stiffness range and energy storage capacity. The mathematical conditions presented in this paper may be used to develop actuators that could bypass the limited energy storage capacity of current variable stiffness spring technology.


Title: Parallel-motion Thick Origami Structure for Robotic Design
Key Words: art  control system synthesis  grippers  motion control  paper  parallel-motion thick origami structure  robotic design  three-dimensional shapes  zero-thickness flat paper sheets  origami facets  multiple layer origami structures  parallel-motion gripper  Fasteners  Grippers  Robots  Shape  Actuators  Force  Electronic mail 
Abstract: Structures with origami design enable objects to transform into various three-dimensional shapes. Traditionally origami structures are designed with zero-thickness flat paper sheets. However, the thickness and intersection of origami facets are non-negligible in most cases, uniquely when integrating origami design with robotic design because of the more efficient force transfer between thick plates compared with zero-thickness paper-sheets. Meanwhile, the single-layer-paper oriented initial design limited the shape transformation potential as multiple layer origami structures could conduct more variety of deformation. In this article, we are proposing a general design method of parallel-motion thick origami structures that could apply in robotic design like a parallel-motion gripper.


Title: Real-time Simulation of Non-Deformable Continuous Tracks with Explicit Consideration of Friction and Grouser Geometry
Key Words: friction  mobile robots  motion control  tracked vehicles  trajectory control  velocity control  nondeformable continuous tracks  grouser geometry  real-time simulation  circular segments  robot body  segment link  track rotation  friction  rough terrain  track trajectory  velocity constraints  tracked vehicles  Robots  Trajectory  Tracking  Friction  Collision avoidance  Real-time systems  Wheels 
Abstract: In this study, we developed a real-time simulation method for non-deformable continuous tracks having grousers for rough terrain by explicitly considering the collision and friction between the tracks and the ground. In the proposed simulation method, an arbitrary trajectory of a track is represented with multiple linear and circular segments, each of which is a link connected to a robot body. The proposed method sets velocity constraints between each segment link and the robot body, to simulate the track rotation around the body. To maintain the shape of a track, it also restores the positions of the segment links when required. Experimental comparisons with other existing real-time simulation methods demonstrated that while the proposed method considered the grousers and the friction with the ground, it was comparable to them in terms of the computational speed. Experimental comparison of the simulations based on the proposed method and a physical robot exhibited that the former was comparable to the precise motion of the robot on rough or uneven terrain.


Title: Test Your SLAM! The SubT-Tunnel dataset and metric for mapping
Key Words: mobile robots  public domain software  robot vision  SLAM (robots)  SLAM  open source tools  robotic mapping algorithms  DARPA Subterranean challenge  SubT-Tunnel dataset  subterranean mine rescue dataset  Simultaneous localization and mapping  Cameras  Measurement  Laser radar  Robot vision systems 
Abstract: This paper presents an approach and introduces new open-source tools that can be used to evaluate robotic mapping algorithms. Also described is an extensive subterranean mine rescue dataset based upon the DARPA Subterranean (SubT) challenge including professionally surveyed ground truth. Finally, some commonly available approaches are evaluated using this metric.


Title: Wide-range Load Sensor Using Vacuum Sealed Quartz Crystal Resonator for Simultaneous Biosignals Measurement on Bed
Key Words: biomechanics  biomedical equipment  biomedical measurement  cardiology  crystal resonators  electrocardiography  force measurement  force sensors  medical signal detection  medical signal processing  microfabrication  microsensors  patient monitoring  pneumodynamics  pressure sensors  quartz  sensors  wide-range load sensor  vacuum sealed quartz crystal resonator  biosignal measurement  QCR load sensor  measurement range  sensor structure  force sensor  QCR load sensing system  Bonding  Weight measurement  Robot sensing systems  Force  Heart beat  Resists  Stress 
Abstract: Monitoring of biosignals on a daily basis plays important roles for the health management of elderly. The monitoring system for the daily life, the system should not require the subjects to take special effort like wearing a sensor. We propose biosignals measurement using wide-range load sensor on the bed. The sensing system can detect the body weight, heartbeat and respiration simultaneously by just lying on the bed. We have developed load sensor using quartz crystal resonator (QCR load sensor) as wide-range load sensor. However, the measurement range was not sufficient for the simultaneous measurement of biosgnals on bed. To realize such sensing system, we propose a QCR load sensor utilizing vacuum sealing technology for expanding the measurement range. We improved the oscillation characteristics of the QCR by the vacuum sealing to stabilize the sensor output. Accordingly, the resolution of the sensor was improved. Moreover, the load capacity of the sensor was increased by improving the bonding strength of sensor structure. The fabricated sensor had a measurement range of 0.27 mN - 1180 N (4.4 × 106). This wide enough compared with the conventional force sensor (103 - 104).Also, we developed mechanically robust jig of QCR load sensor for practical use of QCR load sensor. We succeed in simultaneous measurement of weight, heart rate, and respiration rate using fabricated QCR load sensing system. The accuracy of heart rate and respiration rate measurement are 0.4 bpm (0.6 %) and 1.1 brpm (6.1 %), respectively, in standard deviation of error compared with ECG signal.


Title: Joint Pedestrian Detection and Risk-level Prediction with Motion-Representation-by-Detection
Key Words: feature extraction  image motion analysis  image representation  object detection  pedestrians  traffic engineering computing  risk-level prediction  pedestrian near-miss detection  risk-level assignment  motion-representation-by-detection  pedestrian near-miss dataset  single-shot multibox detector with motion representation  SSD-MR  motion-based features extraction  Videos  Databases  Detectors  Feature extraction  Object detection  Accidents  Autonomous automobiles 
Abstract: The paper presents a pedestrian near-miss detector with temporal analysis that provides both pedestrian detection and risk-level predictions which are demonstrated on a self-collected database. Our work makes three primary contributions: (i) The framework of pedestrian near-miss detection is proposed by providing both a pedestrian detection and risk-level assignment. Specifically, we have created a Pedestrian Near-Miss (PNM) dataset that categorizes traffic near-miss incidents based on their risk levels (high-, low-, and no-risk). Unlike existing databases, our dataset also includes manually localized pedestrian labels as well as a large number of incident-related videos. (ii) Single-Shot MultiBox Detector with Motion Representation (SSD-MR) is implemented to effectively extract motion-based features in a detected pedestrian. (iii) Using the self-collected PNM dataset and SSD-MR, our proposed method achieved +19.38% (on risk-level prediction) and +13.00% (on joint pedestrian detection and risk-level prediction) higher scores than that of the baseline SSD and LSTM. Additionally, the running time of our system is over 50 fps on a graphics processing unit (GPU).


Title: Long-term Place Recognition through Worst-case Graph Matching to Integrate Landmark Appearances and Spatial Relationships
Key Words: graph theory  image matching  mobile robots  robot vision  SLAM (robots)  robotics applications  simultaneously localization and mapping  spatial relationship similarities  spatial cues  visual cues  old landmarks  long-term environment changes  landmark information  integrate landmark appearances  worst-case graph matching  place recognition performance  long-term place recognition  worst appearance similarity  similar appearances  worst-case scenario  graph matching problem  visual appearances  angular spatial relationships  graph representation  Visualization  Simultaneous localization and mapping  Robustness  Strain  Image recognition  Tensile stress 
Abstract: Place recognition is an important component for simultaneously localization and mapping in a variety of robotics applications. Recently, several approaches using landmark information to represent a place showed promising performance to address long-term environment changes. However, previous approaches do not explicitly consider changes of the landmarks, i,e., old landmarks may disappear and new ones often appear over time. In addition, representations used in these approaches to represent landmarks are limited, based upon visual or spatial cues only. In this paper, we introduce a novel worst-case graph matching approach that integrates spatial relationships of landmarks with their appearances for long-term place recognition. Our method designs a graph representation to encode distance and angular spatial relationships as well as visual appearances of landmarks in order to represent a place. Then, we formulate place recognition as a graph matching problem under the worst-case scenario. Our approach matches places by computing the similarities of distance and angular spatial relationships of the landmarks that have the least similar appearances (i.e., worst-case). If the worst appearance similarity of landmarks is small, two places are identified to be not the same, even though their graph representations have high spatial relationship similarities. We evaluate our approach over two public benchmark datasets for long-term place recognition, including St. Lucia and CMU-VL. The experimental results have validated that our approach obtains the state-of-the-art place recognition performance, with a changing number of landmarks.


Title: Linear RGB-D SLAM for Atlanta World
Key Words: cameras  image colour analysis  Kalman filters  mobile robots  object detection  object tracking  pose estimation  SLAM (robots)  Manhattan world assumption  orthogonal directions  Atlanta world  vertical direction  horizontal directions  SLAM techniques  Atlanta representation  Atlanta frame-aware linear SLAM framework  Atlanta structure  linear Kalman filter  linear RGB-D SLAM  simultaneous localization and mapping  tracking-by-detection scheme  scene structure  camera motion  planar map  synthetic datasets  real datasets  Simultaneous localization and mapping  Cameras  Three-dimensional displays  Tracking  Kalman filters  Visualization  Robustness 
Abstract: We present a new linear method for RGB-D based simultaneous localization and mapping (SLAM). Compared to existing techniques relying on the Manhattan world assumption defined by three orthogonal directions, our approach is designed for the more general scenario of the Atlanta world. It consists of a vertical direction and a set of horizontal directions orthogonal to the vertical direction and thus can represent a wider range of scenes. Our approach leverages the structural regularity of the Atlanta world to decouple the non-linearity of camera pose estimations. This allows us separately to estimate the camera rotation and then the translation, which bypasses the inherent non-linearity of traditional SLAM techniques. To this end, we introduce a novel tracking-by-detection scheme to estimate the underlying scene structure by Atlanta representation. Thereby, we propose an Atlanta frame-aware linear SLAM framework which jointly estimates the camera motion and a planar map supporting the Atlanta structure through a linear Kalman filter. Evaluations on both synthetic and real datasets demonstrate that our approach provides favorable performance compared to existing state-of-the-art methods while extending their working range to the Atlanta world.


Title: Stereo Visual Inertial Odometry with Online Baseline Calibration
Key Words: calibration  cameras  distance measurement  inertial navigation  Jacobian matrices  Kalman filters  stereo image processing  update Jacobian sub-block  feature reprojection error  real-world outdoor dataset  EuRoC dataset  camera poses  IMU  inertial measurement unit  estimation performance  stereo-vision devices  stereo extrinsic parameters  multistate constraint Kalman filter  stereo VIO extrinsic parameters correction  online calibration method  camera extrinsic parameters  stereo visual inertial odometry  extrinsic parameter calibration  online baseline calibration  Cameras  Calibration  Estimation  Visualization  Acceleration  Jacobian matrices  Optimization 
Abstract: Stereo-vision devices have rigorous requirements for extrinsic parameter calibration. In Stereo Visual Inertial Odometry (VIO), inaccuracy in or changes to camera extrinsic parameters may lead to serious degradation in estimation performance. In this manuscript, we propose an online calibration method for stereo VIO extrinsic parameters correction. In particular, we focus on Multi-State Constraint Kalman Filter (MSCKF [1]) framework to implement our method. The key component is to formulate stereo extrinsic parameters as part of the state variables and model the Jacobian of feature reprojection error with respect to stereo extrinsic parameters as sub-block of update Jacobian. Therefore we can estimate stereo extrinsic parameters simultaneously with inertial measurement unit (IMU) states and camera poses. Experiments on EuRoC dataset and real-world outdoor dataset demonstrate that the proposed algorithm produce higher positioning accuracy than the original S-MSCKF [2], and the noise of camera extrinsic parameters are self-corrected within the system.


Title: Probabilistic Data Association via Mixture Models for Robust Semantic SLAM
Key Words: Gaussian processes  image sensors  mobile robots  object detection  probability  robot vision  SLAM (robots)  target tracking  probabilistic data association  mixture models  robust semantic SLAM  robotic systems  cameras  lidar  visual models  reliable navigation  semantic uncertainty inherent  geometric uncertainty inherent  object detection methods  data association ambiguity  nonlinear Gaussian formulation  data association variables  max-marginalization  standard Gaussian posterior assumptions  max-mixture-type model  multiple data association hypotheses  indoor navigation tasks  outdoor semantic navigation tasks  semantic SLAM approaches  simultaneous localization and mapping  noisy odometry  Semantics  Simultaneous localization and mapping  Robustness  Optimization  Object detection  Uncertainty 
Abstract: Modern robotic systems sense the environment geometrically, through sensors like cameras, lidar, and sonar, as well as semantically, often through visual models learned from data, such as object detectors. We aim to develop robots that can use all of these sources of information for reliable navigation, but each is corrupted by noise. Rather than assume that object detection will eventually achieve near perfect performance across the lifetime of a robot, in this work we represent and cope with the semantic and geometric uncertainty inherent in object detection methods. Specifically, we model data association ambiguity, which is typically non-Gaussian, in a way that is amenable to solution within the common nonlinear Gaussian formulation of simultaneous localization and mapping (SLAM). We do so by eliminating data association variables from the inference process through max-marginalization, preserving standard Gaussian posterior assumptions. The result is a max-mixture-type model that accounts for multiple data association hypotheses. We provide experimental results on indoor and outdoor semantic navigation tasks with noisy odometry and object detection and find that the ability of the proposed approach to represent multiple hypotheses, including the "null" hypothesis, gives substantial robustness advantages in comparison to alternative semantic SLAM approaches.


Title: Closed-Loop Benchmarking of Stereo Visual-Inertial SLAM Systems: Understanding the Impact of Drift and Latency on Tracking Accuracy
Key Words: closed loop systems  Global Positioning System  mobile robots  navigation  robot vision  SLAM (robots)  stereo image processing  tracking  representative state-of-the-art visual-inertial SLAM systems  visual estimation module  stereo visual-inertial SLAM systems  open-loop analysis  closed-loop navigation tasks  accurate trajectory tracking  visualinertial SLAM systems  closed-loop benchmarking simulation  visual-inertial estimation  trajectory tracking performance  Visualization  Navigation  Simultaneous localization and mapping  Benchmark testing  Estimation 
Abstract: Visual-inertial SLAM is essential for robot navigation in GPS-denied environments, e.g. indoor, underground. Conventionally, the performance of visual-inertial SLAM is evaluated with open-loop analysis, with a focus on the drift level of SLAM systems. In this paper, we raise the question on the importance of visual estimation latency in closed-loop navigation tasks, such as accurate trajectory tracking. To understand the impact of both drift and latency on visualinertial SLAM systems, a closed-loop benchmarking simulation is conducted, where a robot is commanded to follow a desired trajectory using the feedback from visual-inertial estimation. By extensively evaluating the trajectory tracking performance of representative state-of-the-art visual-inertial SLAM systems, we reveal the importance of latency reduction in visual estimation module of these systems. The findings suggest directions of future improvements for visual-inertial SLAM.


Title: PointAtrousGraph: Deep Hierarchical Encoder-Decoder with Point Atrous Convolution for Unorganized 3D Points
Key Words: codecs  convolutional neural nets  decoding  edge detection  graph theory  image coding  image filtering  image representation  image sampling  learning (artificial intelligence)  stereo image processing  visual perception  deep hierarchical encoder-decoder  unorganized 3D points  multiscale contextual information  image analysis  PointAtrousGraph  PAG  multiscale edge features  point clouds  Point Atrous Convolution  PAC  Edge-preserved Unpooling  multiscale point features  nonoverlapping maxpooling operations  critical edge features  EU modules  deep permutation-invariant hierarchical encoder-decoder  edge preserved pooling  chained skip subsampling-upsampling modules  3D semantic perception applications  Three-dimensional displays  Picture archiving and communication systems  Convolution  Semantics  Image edge detection  Task analysis  Decoding 
Abstract: Motivated by the success of encoding multi-scale contextual information for image analysis, we propose our PointAtrousGraph (PAG) - a deep permutation-invariant hierarchical encoder-decoder for efficiently exploiting multi-scale edge features in point clouds. Our PAG is constructed by several novel modules, such as Point Atrous Convolution (PAC), Edgepreserved Pooling (EP) and Edge-preserved Unpooling (EU). Similar with atrous convolution, our PAC can effectively enlarge receptive fields of filters and thus densely learn multi-scale point features. Following the idea of non-overlapping maxpooling operations, we propose our EP to preserve critical edge features during subsampling. Correspondingly, our EU modules gradually recover spatial information for edge features. In addition, we introduce chained skip subsampling/upsampling modules that directly propagate edge features to the final stage. Particularly, our proposed auxiliary loss functions can further improve our performance. Experimental results show that our PAG outperform previous state-of-the-art methods on various 3D semantic perception applications.


Title: Learning error models for graph SLAM
Key Words: autonomous aerial vehicles  graph theory  mobile robots  path planning  robot vision  SLAM (robots)  resistance distance  covisibility graph  simulated UAV coverage path  uncertainty models  monocular graph SLAM  topological features  error model learning  UAV coverage path planning trajectories  Simultaneous localization and mapping  Resistance  Uncertainty  Computational modeling  Computer architecture  Predictive models  Cameras 
Abstract: Following recent developments, this paper investigates the possibility to predict uncertainty models for monocular graph SLAM using topological features of the problem. An architecture to learn relative (i.e. inter-keyframe) uncertainty models using the resistance distance in the covisibility graph is presented. The proposed architecture is applied to simulated UAV coverage path planning trajectories and an analysis of the approaches strengths and shortcomings is provided.


Title: Learning-based Path Planning for Autonomous Exploration of Subterranean Environments
Key Words: autonomous aerial vehicles  graph theory  learning by example  mobile robots  optical radar  path planning  robot programming  sampled data systems  tunnels  autonomous exploration  subterranean environments  aerial robots  training expert  imitation learning  underground mine drifts  tunnels  graph based path planner  learning based path planning  LiDAR  range data sampling  Robot sensing systems  Path planning  Training  Training data  Planning  Robot kinematics 
Abstract: In this work we present a new methodology on learning-based path planning for autonomous exploration of subterranean environments using aerial robots. Utilizing a recently proposed graph-based path planner as a "training expert" and following an approach relying on the concepts of imitation learning, we derive a trained policy capable of guiding the robot to autonomously explore underground mine drifts and tunnels. The algorithm utilizes only a short window of range data sampled from the onboard LiDAR and achieves an exploratory behavior similar to that of the training expert with a more than an order of magnitude reduction in computational cost, while simultaneously relaxing the need to maintain a consistent and online reconstructed map of the environment. The trained path planning policy is extensively evaluated both in simulation and experimentally within field tests relating to the autonomous exploration of underground mines.


Title: Distributed Rotor-Based Vibration Suppression for Flexible Object Transport and Manipulation
Key Words: autonomous aerial vehicles  control engineering computing  controllability  helicopters  mechanical engineering computing  mobile robots  optimisation  path planning  rotors  vibration control  RVM design  optimal placement  flexible object transport  manipulated object  object size  quadrotor usage  distributed RVMs  constrained optimization problem  aerial-ground manipulator system  robot-based vibration suppression module  distributed rotor-based vibration suppression  controllability gramian  multiple aerial-ground manipulator system  Rotors  Vibrations  Mathematical model  Manipulators  Controllability  Torque 
Abstract: The RVM (Robot-based Vibration Suppression Modules) is proposed for the manipulation and transport of a large flexible object. Since the RVM is easily attachable/detachable to the object, this RVM allows distributing over the manipulated object so that it is scalable to the object size. The composition of the system is partly motivated by the MAGMaS (Multiple Aerial-Ground Manipulator System) [1]- [3], however, since the quadrotor usage is mechanically too complicated and its design is not optimized for manipulation, thus we overcome these limitations using distributed RVMs and newly developed theory. For this, we first provide a constrained optimization problem of RVM design with the minimum number of rotors, so that the feasible thrust force is maximized while it minimizes undesirable wrench and its own weight. Then, we derive the full dynamics and elucidate a controllability condition with multiple distributed RVMs and show that even if multiple, their structures turn out similar to [2] composed with a single quadrotor. We also elucidate the optimal placement of the RVM via the usage of controllability gramian which is not even alluded in [2] and established for the first time here. Experiments are performed to demonstrate the effectiveness of the proposed theory.


Title: Aerial Manipulation using Model Predictive Control for Opening a Hinged Door
Key Words: aerospace robotics  collision avoidance  control system synthesis  dynamic programming  manipulators  observers  position control  predictive control  robust control  three-term control  model predictive control  hinged door  environment interaction  aerial robot  multirotor-based aerial manipulator  daily-life moving structure  collision avoidance  differential dynamic programming  disturbance observer  robust controller  Manipulators  Vehicle dynamics  Mathematical model  Dynamics  Trajectory  Servomotors 
Abstract: Existing studies for environment interaction with an aerial robot have been focused on interaction with static surroundings. However, to fully explore the concept of an aerial manipulation, interaction with moving structures should also be considered. In this paper, a multirotor-based aerial manipulator opening a daily-life moving structure, a hinged door, is presented. In order to address the constrained motion of the structure and to avoid collisions during operation, model predictive control (MPC) is applied to the derived coupled system dynamics between the aerial manipulator and the door involving state constraints. By implementing a constrained version of differential dynamic programming (DDP), MPC can generate position setpoints to the disturbance observer (DOB)-based robust controller in real-time, which is validated by our experimental results.


Title: Integrated Motion Planner for Real-time Aerial Videography with a Drone in a Dense Environment
Key Words: autonomous aerial vehicles  collision avoidance  graph theory  mobile robots  object detection  quadratic programming  video recording  dense environment  drone  autonomous videography task  3-D obstacle environment  moving object  target motion prediction module  hierarchical chasing planner  covariant optimization  bi-level structure  smooth planner  graph-search method  chasing corridor  subsequent phase  smooth trajectory  dynamically feasible trajectory  integrated motion planner  real-time aerial videography  autonomous videography task  source code  quadratic programming  Drones  Trajectory  Safety  Optimization  Measurement  Shape  Real-time systems 
Abstract: This work suggests an integrated approach for a drone (or multirotor) to perform an autonomous videography task in a 3-D obstacle environment by following a moving object. The proposed system includes 1) a target motion prediction module which can be applied to dense environments and 2) a hierarchical chasing planner. Leveraging covariant optimization, the prediction module estimates the future motion of the target assuming it efforts to avoid the obstacles. The other module, chasing planner, is in a bi-level structure composed of preplanner and smooth planner. In the first phase, we exploit a graph-search method to plan a chasing corridor which incorporates safety and visibility of target. In the subsequent phase, we generate a smooth and dynamically feasible trajectory within the corridor using quadratic programming (QP). We validate our approach with multiple complex scenarios and actual experiments. The source code and the experiment video can be found in https://github.com/icsl-Jeon/traj_gen_vis and https://www.youtube.com/watch?v=_JSwXBwYRl8.


Title: Cooperative Perception and Localization for Cooperative Driving
Key Words: cooperative systems  Kalman filters  location based services  mobile robots  multi-robot systems  nonlinear filters  road vehicles  sensor fusion  vehicle sensors  extended Kalman filters  fully autonomous road vehicles  cooperative driving  cooperative perception  high fidelity sensors  low fidelity sensors  localization information  Sensor systems  Time measurement  Roads  Fuses  Current measurement  Bandwidth 
Abstract: Fully autonomous vehicles are expected to share the road with less advanced vehicles for a significant period of time. Furthermore, an increasing number of vehicles on the road are equipped with a variety of low-fidelity sensors which provide some perception and localization data, but not at a high enough quality for full autonomy. In this paper, we develop a perception and localization system that allows a vehicle with low-fidelity sensors to incorporate high-fidelity observations from a vehicle in front of it, allowing both vehicles to operate with full autonomy. The resulting system generates perception and localization information that is both low-noise in regions covered by high-fidelity sensors and avoids false negatives in areas only observed by low-fidelity sensors, while dealing with latency and dropout of the communication link between the two vehicles. At its core, the system uses a set of Extended Kalman filters which incorporate observations from both vehicles' sensors and extrapolate them using information about the road geometry. The perception and localization algorithms are evaluated both in simulation and on real vehicles as part of a full cooperative driving system.


Title: Learning to Drive Off Road on Smooth Terrain in Unstructured Environments Using an On-Board Camera and Sparse Aerial Images
Key Words: collision avoidance  mobile robots  off-road vehicles  robot programming  robot vision  supervised learning  autonomous driving  vision based controllers  navigation learning  model robustmess  planning foresight  self supervised method  collision avoidance  sparse aerial images  off road driving  smooth terrain traversal  visual obstructions  on-board sensors  terrain roughness  model free reinforcement learning  unstructured outdoor environments  on-board camera  rough terrain  Predictive models  Navigation  Cameras  Planning  Computational modeling  Visualization  Robots 
Abstract: We present a method for learning to drive on smooth terrain while simultaneously avoiding collisions in challenging off-road and unstructured outdoor environments using only visual inputs. Our approach applies a hybrid model-based and model-free reinforcement learning method that is entirely self-supervised in labeling terrain roughness and collisions using on-board sensors. Notably, we provide both first-person and overhead aerial image inputs to our model. We nd that the fusion of these complementary inputs improves planning foresight and makes the model robust to visual obstructions. Our results show the ability to generalize to environments with plentiful vegetation, various types of rock, and sandy trails. During evaluation, our policy attained 90% smooth terrain traversal and reduced the proportion of rough terrain driven over by 6.1 times compared to a model using only first-person imagery. Video and project details can be found at www.cim.mcgill.ca/mrl/offroad_driving/.


Title: RoadTrack: Realtime Tracking of Road Agents in Dense and Heterogeneous Environments
Key Words: collision avoidance  image motion analysis  object detection  object tracking  road traffic  traffic engineering computing  video signal processing  traffic videos  road agents  dense environments  heterogeneous environments  Road-Track  tracking-by-detection approach  bounding box region  Simultaneous Collision Avoidance and Interaction model  Tracking  Predictive models  Roads  Videos  Collision avoidance  Automobiles 
Abstract: We present a realtime tracking algorithm, Road-Track, to track heterogeneous road-agents in dense traffic videos. Our approach is designed for dense traffic scenarios that consist of different road-agents such as pedestrians, two-wheelers, cars, buses, etc. sharing the road. We use the tracking-by-detection approach where we track a road-agent by matching the appearance or bounding box region in the current frame with the predicted bounding box region propagated from the previous frame. Roadtrack uses a novel motion model called the Simultaneous Collision Avoidance and Interaction (SimCAI) model to predict the motion of road-agents by modeling collision avoidance and interactions between the road-agents for the next frame. We demonstrate the advantage of RoadTrack on a dataset of dense traffic videos and observe an accuracy of 75.8% on this dataset, outperforming prior state-of-the-art tracking algorithms by at least 5.2%. RoadTrack operates in realtime at approximately 30 fps and is at least 4× faster than prior tracking algorithms on standard tracking datasets.


Title: Association-Free Multilateration Based on Times of Arrival
Key Words: position measurement  radar tracking  target tracking  time-of-arrival estimation  spatially distributed receivers  static measurements  multitarget trackers  association-free multilateration  times of arrival estimation  uncorrelated measurement  initialization routine  Receivers  Noise measurement  Position measurement  Optimization  Acoustic measurements  Target tracking  Acoustics 
Abstract: Multilateration systems reconstruct the location of a target that transmits electromagnetic or acoustic signals. The employed measurements for localization are the times of arrival (TOAs) of the transmitted signal, measured by a number of spatially distributed receivers at known positions. We present a novel multilateration algorithm to localize multiple targets that transmit indistinguishable signals at unknown times. That is, each receiver measures merely a set of TOAs with no association to the targets. Our method does not need any prior information. Therefore, it can provide uncorrelated, static measurements to be introduced into a separate tracker subsequently, or an initialization routine for multi target trackers.


Title: Adversarial Feature Disentanglement for Place Recognition Across Changing Appearance
Key Words: feature extraction  image matching  image sequences  mobile robots  neural nets  robot vision  supervised learning  adversarial feature disentanglement  seasonal variation  visual place recognition  image descriptors  adversarial network  image sequences  domain related features  self supervised manner  image matching  Feature extraction  Training  Image reconstruction  Image recognition  Robustness  Machine learning  Neural networks 
Abstract: When robots move autonomously for long-term, varied appearance such as the transition from day to night and seasonal variation brings challenges to visual place recognition. Defining an appearance condition (e.g. a season, a kind of weather) as a domain, we consider that the desired representation for place recognition (i) should be domain-unrelated so that images from different time can be matched regardless of varied appearance, (ii) should be learned in a self-supervised manner without the need of massive manually labeled data, and (iii) should be able to train among multiple domains in one model to keep limited model complexity. This paper sets to find domain-unrelated features across extremely changing appearance, which can be used as image descriptors to match between images collected at different conditions. We propose to use the adversarial network to disentangle domain-unrelated and domain-related features, which are named place and appearance features respectively. During training, only domain information is needed without requiring manually aligned image sequences. Experiments demonstrated that our method can disentangle place and appearance features in both toy case and images from the real world, and the place feature is qualified in place recognition tasks under different appearance conditions. The proposed network is also adaptable to multiple domains without increasing model capacity and shows favorable generalization.


Title: A Fast and Accurate Solution for Pose Estimation from 3D Correspondences
Key Words: approximation theory  computational geometry  computer vision  convex programming  least squares approximations  minimisation  pose estimation  pose estimation  point-to-plane correspondences  computer vision  least-squares problem  global minimizer  real-time applications  local minimizer  Cayley-Gibbs-Rodriguez parameterization  first-order optimality conditions  3D correspondences  CGR parameterization  Three-dimensional displays  Pose estimation  Cost function  Approximation algorithms  Real-time systems  Iterative closest point algorithm  Simultaneous localization and mapping 
Abstract: Estimating pose from given 3D correspondences, including point-to-point, point-to-line and point-to-plane correspondences, is a fundamental task in computer vision with many applications. We present a fast and accurate solution for the least-squares problem of this task. Previous works mainly focus on studying the way to find the global minimizer of the least-squares problem. However, existing works that show the ability to achieve the global minimizer are still unsuitable for real-time applications. Furthermore, as one of contributions of this paper, we prove that there exist ambiguous configurations for any number of lines and planes. These configurations have several solutions in theory, which makes the correct solution may come from a local minimizer when the data are with noise. Previous works based on convex optimization which is unable to find local minimizers do not work in the ambiguous configuration. Our algorithm is efficient and able to reveal local minimizers. We employ the Cayley-Gibbs-Rodriguez (CGR) parameterization of the rotation to derive a general rational cost for the three cases of 3D correspondences. The main contribution of this paper is to solve the first-order optimality conditions of the least-squares problem, which are of a complicated rational form. The central idea of our algorithm is to introduce some intermediate unknowns to simplify the problem. Extensive experimental results show that our algorithm is more stable than previous algorithms when the number N of correspondences is small. Besides, when N is large, our algorithm achieves the same accuracy as the state-of-the-art algorithm [1], but our algorithm is about 7 times faster than [1] in real applications.


Title: Learning How to Walk: Warm-starting Optimal Control Solver with Memory of Motion
Key Words: humanoid robots  iterative methods  learning (artificial intelligence)  legged locomotion  motion control  optimal control  path planning  regression analysis  trajectory control  optimal control solver  locomotion task  humanoid robot  HPP Loco3D  versatile locomotion planner  whole-body trajectory  regression problem  single-step motion  multistep motion  predicted motion  Crocoddyl control solver  Trajectory  Databases  Optimal control  Task analysis  Legged locomotion  Ground penetrating radar 
Abstract: In this paper, we propose a framework to build a memory of motion for warm-starting an optimal control solver for the locomotion task of a humanoid robot. We use HPP Loco3D, a versatile locomotion planner, to generate offline a set of dynamically consistent whole-body trajectory to be stored as the memory of motion. The learning problem is formulated as a regression problem to predict a single-step motion given the desired contact locations, which is used as a building block for producing multi-step motions. The predicted motion is then used as a warm-start for the fast optimal control solver Crocoddyl. We have shown that the approach manages to reduce the required number of iterations to reach the convergence from ~9.5 to only ~3.0 iterations for the single-step motion and from ~6.2 to ~4.5 iterations for the multi-step motion, while maintaining the solution's quality.


Title: Multi-Task Recurrent Neural Network for Surgical Gesture Recognition and Progress Prediction
Key Words: feature extraction  gesture recognition  image segmentation  medical robotics  recurrent neural nets  robot dynamics  robot kinematics  surgery  multitask recurrent neural network  surgical gesture recognition  surgical data science  computer-aided intervention  robotic kinematic information  robot kinematic data  Task analysis  Training  Kinematics  Estimation  Needles  Gesture recognition  Surgery 
Abstract: Surgical gesture recognition is important for surgical data science and computer-aided intervention. Even with robotic kinematic information, automatically segmenting surgical steps presents numerous challenges because surgical demonstrations are characterized by high variability in style, duration and order of actions. In order to extract discriminative features from the kinematic signals and boost recognition accuracy, we propose a multi-task recurrent neural network for simultaneous recognition of surgical gestures and estimation of a novel formulation of surgical task progress. To show the effectiveness of the presented approach, we evaluate its application on the JIGSAWS dataset, that is currently the only publicly available dataset for surgical gesture recognition featuring robot kinematic data. We demonstrate that recognition performance improves in multi-task frameworks with progress estimation without any additional manual labelling and training.


Title: One-Shot Multi-Path Planning for Robotic Applications Using Fully Convolutional Networks
Key Words: convolutional neural nets  iterative methods  mobile robots  neurocontrollers  path planning  robot action execution  motion trajectory  iterative methods  fully convolutional neural network  network prediction iteration  optimal paths  single path predictions  simultaneously generated paths  shot multipath planning  robotic applications  Two dimensional displays  Three-dimensional displays  Training  Robots  Path planning  Prediction algorithms  Planning 
Abstract: Path planning is important for robot action execution, since a path or a motion trajectory for a particular action has to be defined first before the action can be executed. Most of the current approaches are iterative methods where the trajectory is generated by predicting the next state based on the current state. Here we propose a novel method by utilising a fully convolutional neural network, which allows generation of complete paths even for several agents with one network prediction iteration. We demonstrate that our method is able to successfully generate optimal or close to optimal paths (less than 10% longer) in more than 99% of the cases for single path predictions in 2D and 3D environments. Furthermore, we show that the network is - without specific training on such cases - able to create (close to) optimal paths in 96% of the cases for two and in 84% of the cases for three simultaneously generated paths.


Title: Efficient Iterative Linear-Quadratic Approximations for Nonlinear Multi-Player General-Sum Differential Games
Key Words: approximation theory  decision making  differential games  iterative methods  linear quadratic control  multi-agent systems  multi-robot systems  nonlinear control systems  iterative linear-quadratic regulator  linear dynamics  quadratic costs  linear-quadratic games  complex interactive behavior  efficient iterative linear-quadratic approximations  nonlinear multiplayer general-sum differential games  robotics  multiple decision making agents  expressive theoretical framework  multiagent problems  numerical solution techniques  state dimension  single agent optimal control problem  ILQR  repeated approximations  three-player 14-state simulated intersection problem  hardware collision-avoidance test  time 0.25 s  time 50.0 ms  Games  Heuristic algorithms  Approximation algorithms  Optimal control  Iterative methods  Trajectory  Automobiles 
Abstract: Many problems in robotics involve multiple decision making agents. To operate efficiently in such settings, a robot must reason about the impact of its decisions on the behavior of other agents. Differential games offer an expressive theoretical framework for formulating these types of multi-agent problems. Unfortunately, most numerical solution techniques scale poorly with state dimension and are rarely used in real-time applications. For this reason, it is common to predict the future decisions of other agents and solve the resulting decoupled, i.e., single-agent, optimal control problem. This decoupling neglects the underlying interactive nature of the problem; however, efficient solution techniques do exist for broad classes of optimal control problems. We take inspiration from one such technique, the iterative linear-quadratic regulator (ILQR), which solves repeated approximations with linear dynamics and quadratic costs. Similarly, our proposed algorithm solves repeated linear-quadratic games. We experimentally benchmark our algorithm in several examples with a variety of initial conditions and show that the resulting strategies exhibit complex interactive behavior. Our results indicate that our algorithm converges reliably and runs in real-time. In a three-player, 14-state simulated intersection problem, our algorithm initially converges in <; 0.25 s. Receding horizon invocations converge in <; 50 ms in a hardware collision-avoidance test.


Title: Whole-Body Walking Generation using Contact Parametrization: A Non-Linear Trajectory Optimization Approach
Key Words: humanoid robots  legged locomotion  optimal control  optimisation  robot dynamics  trajectory control  humanoid robot model  walking surface  contact parametrization  complementarity-free  predefined contact sequence  optimal control  walking trajectories  dynamic equations  optimization problem  direct multiple shooting approach  body walking generation  nonlinear trajectory optimization  centroidal dynamics  humanoid robot kinematics  humanoid robot dynamics  Legged locomotion  Foot  Force  Trajectory  Robot kinematics  Mathematical model 
Abstract: In this paper, we describe a planner capable of generating walking trajectories by using the centroidal dynamics and the full kinematics of a humanoid robot model. The interaction between the robot and the walking surface is modeled explicitly through a novel contact parametrization. The approach is complementarity-free and does not need a predefined contact sequence. By solving an optimal control problem we obtain walking trajectories. In particular, through a set of constraints and dynamic equations, we model the robot in contact with the ground. We describe the objective the robot needs to achieve with a set of tasks. The whole optimal control problem is transcribed into an optimization problem via a Direct Multiple Shooting approach and solved with an off-the-shelf solver. We show that it is possible to achieve walking motions automatically by specifying a minimal set of references, such as a constant desired Center of Mass velocity and a reference point on the ground.


Title: Contact-Aware Controller Design for Complementarity Systems
Key Words: control system synthesis  mobile robots  motion control  multi-robot systems  optimisation  robot dynamics  robust control  tactile sensors  multicontact motion  combinatoric structure  real-time control  tactile sensors  robust control  complementarity structure  contact dynamics  control framework  multicontact robotics problems  contact-aware controller design  robotic tasks  locomotion  Lyapunov methods  Control systems  Force  Dynamics  Task analysis  Tactile sensors 
Abstract: While many robotic tasks, like manipulation and locomotion, are fundamentally based in making and breaking contact with the environment, state-of-the-art control policies struggle to deal with the hybrid nature of multi-contact motion. Such controllers often rely heavily upon heuristics or, due to the combinatoric structure in the dynamics, are unsuitable for real-time control. Principled deployment of tactile sensors offers a promising mechanism for stable and robust control, but modern approaches often use this data in an ad hoc manner, for instance to guide guarded moves. In this work, by exploiting the complementarity structure of contact dynamics, we propose a control framework which can close the loop on rich, tactile sensors. Critically, this framework is non-combinatoric, enabling optimization algorithms to automatically synthesize provably stable control policies. We demonstrate this approach on three different underactuated, multi-contact robotics problems.


Title: Learning to Generate 6-DoF Grasp Poses with Reachability Awareness
Key Words: convolutional neural nets  learning systems  manipulators  neurocontrollers  stability  3D CNN  6-DoF grasp poses  reachability awareness  voxel-based deep 3D convolutional neural network  reachability predictor  robot  grasp pose stability  Grasping  Three-dimensional displays  Robot kinematics  Planning  Measurement  Data models  Grasping  Deep Learning in Robotics and Automation  Perception for Grasping and Manipulation 
Abstract: Motivated by the stringent requirements of unstructured real-world where a plethora of unknown objects reside in arbitrary locations of the surface, we propose a voxel-based deep 3D Convolutional Neural Network (3D CNN) that generates feasible 6-DoF grasp poses in unrestricted workspace with reachability awareness. Unlike the majority of works that predict if a proposed grasp pose within the restricted workspace will be successful solely based on grasp pose stability, our approach further learns a reachability predictor that evaluates if the grasp pose is reachable or not from robot's own experience. To avoid the laborious real training data collection, we exploit the power of simulation to train our networks on a large-scale synthetic dataset. This work is an early attempt that simultaneously learns grasping reachability while proposing feasible grasp poses with 3D CNN. Experimental results in both simulation and real-world demonstrate that our approach outperforms several other methods and achieves 82.5% grasping success rate on unknown objects.


Title: Enhancing Grasp Pose Computation in Gripper Workspace Spheres
Key Words: computational geometry  dexterous manipulators  grippers  path planning  pose estimation  position control  robot vision  grasp pose computation  gripper workspace spheres  registered point cloud  gripper position sampling  orientation sampling  object orientation estimation  jaw gripper  Franka Panda gripper  geometric based methods  multifingered hands  Intel RealSense-D435 depth camera  Grippers  Three-dimensional displays  Ellipsoids  Grasping  Measurement  Shape  Planning  grasping  manipulation 
Abstract: In this paper, enhancement to the novel grasp planning algorithm based on gripper workspace spheres is presented. Our development requires a registered point cloud of the target from different views, assuming no prior knowledge of the object, nor any of its properties. This work features a new set of metrics for grasp pose candidates evaluation, as well as exploring the impact of high object sampling on grasp success rates. In addition to gripper position sampling, we now perform orientation sampling about the x, y, and z-axes, hence the grasping algorithm no longer require object orientation estimation. Successful experiments have been conducted on a simple jaw gripper (Franka Panda gripper) as well as a complex, high Degree of Freedom (DoF) hand (Allegro hand) as a proof of its versatility. Higher grasp success rates of 76% and 85.5% respectively has been reported by real world experiments.


Title: Self-Supervised Learning for Alignment of Objects and Sound
Key Words: human-robot interaction  learning (artificial intelligence)  object detection  source separation  human-robot interaction  scene understanding  sound source separation task  self-supervised learning framework  object detection  sound separation modules  sound components  visual information  audio information  Visualization  Videos  Feature extraction  Object detection  Spectrogram  Training  Robots 
Abstract: The sound source separation problem has many useful applications in the field of robotics, such as human-robot interaction, scene understanding, etc. However, it remains a very challenging problem. In this paper, we utilize both visual and audio information of videos to perform the sound source separation task. A self-supervised learning framework is proposed to implement the object detection and sound separation modules simultaneously. Such an approach is designed to better find the alignment between the detected objects and separated sound components. Our experiments, conducted on both the synthetic and real datasets, validate this approach and demonstrate the effectiveness of the proposed model in the task of object and sound alignment.


Title: Calibrating a Soft ERT-Based Tactile Sensor with a Multiphysics Model and Sim-to-real Transfer Learning
Key Words: calibration  inverse problems  learning (artificial intelligence)  neural nets  robots  tactile sensors  tomography  soft ERT-based tactile sensor  sim-to-real transfer learning  electrical resistance tomography  finite element multiphysics model  contact pressure distributions  voltage measurements  model parameters  single-point dataset  contact force  calibration method  ERT-based tactile sensors  Fabrics  Computational modeling  Tactile sensors  Mathematical model  Electrodes  Force  Conductivity 
Abstract: Tactile sensors based on electrical resistance tomography (ERT) have shown many advantages for implementing a soft and scalable whole-body robotic skin; however, calibration is challenging because pressure reconstruction is an ill-posed inverse problem. This paper introduces a method for calibrating soft ERT-based tactile sensors using sim-to-real transfer learning with a finite element multiphysics model. The model is composed of three simple models that together map contact pressure distributions to voltage measurements. We optimized the model parameters to reduce the gap between the simulation and reality. As a preliminary study, we discretized the sensing points into a 6 by 6 grid and synthesized single- and two-point contact datasets from the multiphysics model. We obtained another single-point dataset using the real sensor with the same contact location and force used in the simulation. Our new deep neural network architecture uses a de-noising network to capture the simulation-to-real gap and a reconstruction network to estimate contact force from voltage measurements. The proposed approach showed 82% hit rate for localization and 0.51 N of force estimation error performance in singlecontact tests and 78.5% hit rate for localization and 5.0 N of force estimation error in two-point contact tests. We believe this new calibration method has the possibility to improve the sensing performance of ERT-based tactile sensors.


Title: Reliable frame-to-frame motion estimation for vehicle-mounted surround-view camera systems
Key Words: cameras  distance measurement  mobile robots  motion estimation  optimisation  path planning  robot vision  frame-to-frame visual odometry  vehicle-mounted surround-view camera system  reliable frame-to-frame motion estimation  vehicle-mounted surround-view camera systems  surround-view multicamera system  autonomous driving  3D point related optimization variables  two-view optimization scheme  nonholonomic characteristics  relative displacements  nonholonomic vehicle motion  overly simplified assumptions  single camera  existing camera  relative vehicle displacement  Conferences  Automation  Reliability  Motion estimation  Cameras  Robot vision systems 
Abstract: Modern vehicles are often equipped with a surround-view multi-camera system. The current interest in autonomous driving invites the investigation of how to use such systems for a reliable estimation of relative vehicle displacement. Existing camera pose algorithms either work for a single camera, make overly simplified assumptions, are computationally expensive, or simply become degenerate under non-holonomic vehicle motion. In this paper, we introduce a new, reliable solution able to handle all kinds of relative displacements in the plane despite the possibly non-holonomic characteristics. We furthermore introduce a novel two-view optimization scheme which minimizes a geometrically relevant error without relying on 3D point related optimization variables. Our method leads to highly reliable and accurate frame-to-frame visual odometry with a full-size, vehicle-mounted surround-view camera system.


Title: Enabling Topological Planning with Monocular Vision
Key Words: learning (artificial intelligence)  mobile robots  multi-agent systems  path planning  robot vision  sensors  SLAM (robots)  heuristic priors  intelligent planning  monocular SLAM  low texture  highly cluttered environments  robust sparse map representation  monocular vision  learned sensor  high-level structure  sparse vertices  known free space  mapping technique  subgoal planning applications  enabling topological planning  topological strategies  navigation  possible actions  Planning  Image edge detection  Navigation  Robot sensing systems  Buildings  Robustness 
Abstract: Topological strategies for navigation meaningfully reduce the space of possible actions available to a robot, allowing use of heuristic priors or learning to enable computationally efficient, intelligent planning. The challenges in estimating structure with monocular SLAM in low texture or highly cluttered environments have precluded its use for topological planning in the past. We propose a robust sparse map representation that can be built with monocular vision and overcomes these shortcomings. Using a learned sensor, we estimate high-level structure of an environment from streaming images by detecting sparse "vertices" (e.g., boundaries of walls) and reasoning about the structure between them. We also estimate the known free space in our map, a necessary feature for planning through previously unknown environments. We show that our mapping technique can be used on real data and is sufficient for planning and exploration in simulated multi-agent search and learned subgoal planning applications.


Title: DeepMEL: Compiling Visual Multi-Experience Localization into a Deep Neural Network
Key Words: distance measurement  image colour analysis  mobile robots  neurocontrollers  path planning  pose estimation  robot vision  robust control  stereo image processing  outdoor driving  deep neural network  visual odometry  vision-based path following  unstructured outdoor environments  visual multiexperience localization  colour-constant imaging  multiexperience VT&R  DeepMEL  stereo visual teach and repeat  robust long-range path following  environmental conditions  pose estimates  in-the-loop path following  Pose estimation  Image edge detection  Neural networks  Robots  Lighting  Snow 
Abstract: Vision-based path following allows robots to autonomously repeat manually taught paths. Stereo Visual Teach and Repeat (VT&R) [1] accomplishes accurate and robust long-range path following in unstructured outdoor environments across changing lighting, weather, and seasons by relying on colour-constant imaging [2] and multi-experience localization [3]. We leverage multi-experience VT&R together with two datasets of outdoor driving on two separate paths spanning different times of day, weather, and seasons to teach a deep neural network to predict relative pose for visual odometry (VO) and for localization with respect to a path. In this paper we run experiments exclusively on datasets to study how the network generalizes across environmental conditions. Based on the results we believe that our system achieves relative pose estimates sufficiently accurate for in-the-loop path following and that it is able to localize radically different conditions against each other directly (i.e. winter to spring and day to night), a capability that our hand-engineered system does not have.


Title: Kimera: an Open-Source Library for Real-Time Metric-Semantic Localization and Mapping
Key Words: C++ language  control engineering computing  graph theory  image reconstruction  image segmentation  learning (artificial intelligence)  public domain software  robot vision  SLAM (robots)  open-source C++ library  visual-inertial SLAM libraries  ORB-SLAM  VINS-Mono  semantic labeling  visual-inertial odometry module  state estimation  robust pose graph optimizer  global trajectory estimation  lightweight 3D mesher module  fast mesh reconstruction  3D metric-semantic reconstruction module  semantically labeled images  metric-semantic SLAM  real-time metric-semantic localization and mapping  Kimera  deep learning  Three-dimensional displays  Simultaneous localization and mapping  Robustness  Semantics  Libraries  Visualization  Real-time systems 
Abstract: We provide an open-source C++ library for real-time metric-semantic visual-inertial Simultaneous Localization And Mapping (SLAM). The library goes beyond existing visual and visual-inertial SLAM libraries (e.g., ORB-SLAM, VINS-Mono, OKVIS, ROVIO) by enabling mesh reconstruction and semantic labeling in 3D. Kimera is designed with modularity in mind and has four key components: a visual-inertial odometry (VIO) module for fast and accurate state estimation, a robust pose graph optimizer for global trajectory estimation, a lightweight 3D mesher module for fast mesh reconstruction, and a dense 3D metric-semantic reconstruction module. The modules can be run in isolation or in combination, hence Kimera can easily fall back to a state-of-the-art VIO or a full SLAM system. Kimera runs in real-time on a CPU and produces a 3D metric-semantic mesh from semantically labeled images, which can be obtained by modern deep learning methods. We hope that the flexibility, computational efficiency, robustness, and accuracy afforded by Kimera will build a solid basis for future metric-semantic SLAM and perception research, and will allow researchers across multiple areas (e.g., VIO, SLAM, 3D reconstruction, segmentation) to benchmark and prototype their own efforts without having to start from scratch.


Title: Velocity Field based Active-Assistive Control for Upper Limb Rehabilitation Exoskeleton Robot
Key Words: biomechanics  Kalman filters  medical robotics  motion control  observers  path planning  patient rehabilitation  torque control  wearable robots  upper limb rehabilitation exoskeleton robot  time-dependent trajectories  task-based rehabilitation exercise  multijoint motion  assistive mechanism  active-assistive control system  joint-position-dependent velocity field  task motion pattern  time-independent assistance  active motions  assistive motions  rehabilitation task  single joint tasks  Kalman filter based interactive torque observer  subject active motion intention  subject torque exertion  Task analysis  Torque  Robots  Kalman filters  Observers  Control systems  Sensors 
Abstract: There are limitations of conventional active-assistive control for upper limb rehabilitation exoskeleton robot, such as 1). prior time-dependent trajectories are generally required, 2). task-based rehabilitation exercise involving multi-joint motion is hard to implement, and 3). assistive mechanism normally is so inflexible that the resulting exercise performed by the subjects becomes inefficient. In this paper, we propose a novel velocity field based active-assistive control system to address these issues. First, we design a Kalman filter based interactive torque observer to obtain subjects' active intention of motion. Next, a joint-position-dependent velocity field which can be automatically generated via the task motion pattern is proposed to provide the time-independent assistance to the subjects. We further propose a novel integration method that combines the active and assistive motions based on the performance and the involvement of subjects to guide them to perform the task more voluntarily and precisely. The experiment results show that both the execution time and the subjects' torque exertion are reduced while performing both given single joint tasks and task-oriented multi-joint tasks as compared with the related work in the literature. To sum up, the proposed system not only can efficiently retain subjects' active intention but also can assist them to accomplish the rehabilitation task more precisely.


Title: Impedance Control of a Transfemoral Prosthesis using Continuously Varying Ankle Impedances and Multiple Equilibria
Key Words: artificial limbs  gait analysis  least squares approximations  medical robotics  prosthetics  springs (mechanical)  vibration control  squares estimation  impedance controller  squares optimization method  knee impedance  impedance control  lower limb prostheses  human joint torque  perturbation studies  least squares estimates  ankle impedance parameters  powered transfemoral prosthesis  Impedance  Damping  Torque  Optimization  Knee  Prosthetics  Perturbation methods 
Abstract: Impedance controllers are popularly used in the field of lower limb prostheses and exoskeleton development. Such controllers assume the joint to be a spring-damper system described by a discrete set of equilibria and impedance parameters. These parameters are estimated via a least squares optimization that minimizes the difference between the controller's output torque and human joint torque. Other researchers have used perturbation studies to determine empirical values for ankle impedance. The resulting values vary greatly from the prior least squares estimates. While perturbation studies are more credible, they require immense investment. This paper extended the least squares approach to reproduce the results of perturbation studies. The resulting ankle impedance parameters were successfully tested on a powered transfemoral prosthesis, AMPRO II. Further, the paper investigated the effect of multiple equilibria on the least squares estimation and the performance of the impedance controller. Finally, the paper uses the proposed least squares optimization method to estimate knee impedance.


Title: Human-Centric Active Perception for Autonomous Observation
Key Words: aerospace robotics  Markov processes  mobile communication  mobile robots  optimisation  space vehicles  autonomous observation systems  human activity  multiobjective optimization  autonomous human observation problem  robot-centric costs  scalarization-based MultiObjective MDP methods  NASA Astrobee robot operating  human-centric active perception  robot autonomy  SemiMDP formulation  constrained MDP method  NASA Astrobee robot  Task analysis  Cameras  Robot vision systems  Collision avoidance  Cost function 
Abstract: As robot autonomy improves, robots are increasingly being considered in the role of autonomous observation systems - free-flying cameras capable of actively tracking human activity within some predefined area of interest. In this work, we formulate the autonomous observation problem through multi-objective optimization, presenting a novel Semi-MDP formulation of the autonomous human observation problem that maximizes observation rewards while accounting for both human- and robot-centric costs. We demonstrate that the problem can be solved with both scalarization-based Multi-Objective MDP methods and Constrained MDP methods, and discuss the relative benefits of each approach. We validate our work on activity tracking using a NASA Astrobee robot operating within a simulated International Space Station environment.


Title: Predicting and Optimizing Ergonomics in Physical Human-Robot Cooperation Tasks
Key Words: biomechanics  ergonomics  graph theory  human-robot interaction  mobile robots  multi-robot systems  path planning  telerobotics  32 DoF bimanual mobile robot  ergonomic-enhanced planner  reduced ergonomic cost  physical human-robot cooperation tasks  action sequences  continuous physical interaction  computational model  ergonomics assessment  human motion capture data  prediction model  informed graph search algorithm  ergonomic assessment  bimanual human-robot cooperation tasks  Ergonomics  Robots  Task analysis  Optimization  Predictive models  Computational modeling  Force 
Abstract: This paper presents a method to incorporate ergonomics into the optimization of action sequences for bi-manual human-robot cooperation tasks with continuous physical interaction. Our first contribution is a novel computational model of the human that allows prediction of an ergonomics assessment corresponding to each step in a task. The model is learned from human motion capture data in order to predict the human pose as realistically as possible. The second contribution is a combination of this prediction model with an informed graph search algorithm, which allows computation of human-robot cooperative plans with improved ergonomics according to the incorporated method for ergonomic assessment. The concepts have been evaluated in simulation and in a small user study in which the subjects manipulate a large object with a 32 DoF bimanual mobile robot as partner. For all subjects, the ergonomic-enhanced planner shows their reduced ergonomic cost compared to a baseline planner.


Title: Internally-Balanced Magnetic Mechanisms Using a Magnetic Spring for Producing a Large Amplified Clamping Force
Key Words: clamps  control system synthesis  force control  magnetic devices  mobile robots  multi-robot systems  permanent magnets  springs (mechanical)  magnetic spring  magnetic mechanisms  clamping force  permanent magnet  force control  attractive force  internally-balanced magnetic unit  magnetic devices  internal force  internally-balanced magnetic mechanisms  IB magnet  nonlinear spring  unlike-pole pair  wall-climbing robots  ceiling-dangling drones  modular swarm robots  robotic clamp  Springs  Force  Magnetic noise  Magnetic shielding  Magnetic levitation  Magnetic liquids  Magnetic separation  Mechanism Design of Manipulators  Force Control 
Abstract: To detach a permanent magnet using a control force much smaller than its original attractive force, the internally-balanced magnetic unit (IB Magnet) was invented. It has been applied to magnetic devices such as wall-climbing robots, ceiling-dangling drones, and modular swarm robots. In contrast to its significant reduction rate with regard to the control force, the IB Magnet has two major problems in its nonlinear spring, which serves the purpose of cancelling out the internal force on the magnet. These problems include the complicated design procedure and the trade-off relationship between balancing the precision and the volume of the mechanism. This paper proposes a principle for a new balancing method for the IB Magnet. This method uses a like-pole pair of magnets as a magnetic spring, whose repulsive force should equal the attractive force of an unlike-pole pair. To verify the proposed principle, a prototype of the IB Magnet was designed using a magnetic spring and verified through experiments such that its reduction rate is comparable to those of conventional IB Magnets. Moreover, a robotic clamp was developed as an application example that contains the proposed IB Magnets as its internal mechanism.


Title: How far are Pneumatic Artificial Muscles from biological muscles?
Key Words: biomechanics  elasticity  electroactive polymer actuators  legged locomotion  muscle  pneumatic actuators  pneumatic artificial muscles  biological muscles  artificial copies  force generation mechanism  PAM force-length  additive passive parallel elastic element  PAM dynamic behaviors  dynamic muscle-like model  living creatures  multiplicative formulation  two-segmented leg  legged robots  Muscles  Mathematical model  Force  Biological system modeling  Robots  Dynamics 
Abstract: There is a long history demonstrating humans' tendency to create artificial copies of living creatures. For moving machines called robots, actuators play a key role in developing human-like movements. Among different types of actuation, PAMs (pneumatic artificial muscles) are known as the most similar ones to biological muscles. In addition to similarities in force generation mechanism (tension based), the well-accepted argumentation from Klute et al., states that the PAM force-length (fl) behavior is close to biological muscles, while the force-velocity (fv) pattern is different. Using the multiplicative formulation of the pressure (as an activation term), fl and fv beside an additive passive parallel elastic element, we present a new model of PAM. This muscle-based model can predict PAM dynamic behaviors with high precision. With a second experiment on a two-segmented leg, the proposed model is verified to predict the generated forces of PAMs in an antagonistic arrangement. Such a dynamic muscle-like model of artificial muscles can be used for the design and control of legged robots to generate robust, efficient and versatile gaits.


Title: Semantic Linking Maps for Active Visual Object Search
Key Words: inference mechanisms  manipulators  mobile robots  robot vision  search problems  Semantic Linking Maps model  target object  landmark objects  probabilistic inter-object spatial relations  hybrid search strategy  SLiM-based search strategy  Fetch mobile manipulation robot  mobile robots  common human environments  unseen target objects  reasoning  search space  common spatial relations  active visual object search strategy  Search problems  Robots  Probabilistic logic  Semantics  Buildings  Inference algorithms  Visualization 
Abstract: We aim for mobile robots to function in a variety of common human environments. Such robots need to be able to reason about the locations of previously unseen target objects. Landmark objects can help this reasoning by narrowing down the search space significantly. More specifically, we can exploit background knowledge about common spatial relations between landmark and target objects. For example, seeing a table and knowing that cups can often be found on tables aids the discovery of a cup. Such correlations can be expressed as distributions over possible pairing relationships of objects. In this paper, we propose an active visual object search strategy method through our introduction of the Semantic Linking Maps (SLiM) model. SLiM simultaneously maintains the belief over a target object's location as well as landmark objects' locations, while accounting for probabilistic inter-object spatial relations. Based on SLiM, we describe a hybrid search strategy that selects the next best view pose for searching for the target object based on the maintained belief. We demonstrate the efficiency of our SLiM-based search strategy through comparative experiments in simulated environments. We further demonstrate the realworld applicability of SLiM-based search in scenarios with a Fetch mobile manipulation robot.


Title: VALID: A Comprehensive Virtual Aerial Image Dataset
Key Words: computer vision  feature extraction  image classification  image segmentation  object detection  stereo image processing  aerial imagery  unmanned aerial vehicle tasks  single ground truth type  virtual environment  high-resolution images  virtual scenes  comprehensive virtual aerial image dataset  visual ground truth data  Image segmentation  Semantics  Task analysis  Object detection  Image color analysis  Benchmark testing  Labeling 
Abstract: Aerial imagery plays an important role in land-use planning, population analysis, precision agriculture, and unmanned aerial vehicle tasks. However, existing aerial image datasets generally suffer from the problem of inaccurate labeling, single ground truth type, and few category numbers. In this work, we implement a simulator that can simultaneously acquire diverse visual ground truth data in the virtual environment. Based on that, we collect a comprehensive Virtual AeriaL Image Dataset named VALID, consisting of 6690 high-resolution images, all annotated with panoptic segmentation on 30 categories, object detection with oriented bounding box, and binocular depth maps, collected in 6 different virtual scenes and 5 various ambient conditions (sunny, dusk, night, snow and fog). To our knowledge, VALID is the first aerial image dataset that can provide panoptic level segmentation and complete dense depth maps. We analyze the characteristics of VALID and evaluate state-of-the-art methods for multiple tasks to provide reference baselines. The experiment results demonstrate that VALID is well presented and challenging. The dataset is available at https://sites.google.com/view/valid-dataset/.


Title: Intensity Scan Context: Coding Intensity and Geometry Relations for Loop Closure Detection
Key Words: computational geometry  feature extraction  image matching  mobile robots  optical radar  robot vision  SLAM (robots)  stereo image processing  intensity scan context  light detection and ranging sensor  discard intensity reading  geometric relation  intensity structure re-identification  coding intensity  simultaneous localization and mapping  LiDAR sensor  3D loop closure detection  geometrical only descriptor matching  place recognition  robot navigation  fast point feature histogram  Geometry  Laser radar  Three-dimensional displays  Histograms  Simultaneous localization and mapping  Rough surfaces  Surface roughness 
Abstract: Loop closure detection is an essential and challenging problem in simultaneous localization and mapping (SLAM). It is often tackled with light detection and ranging (LiDAR) sensor due to its view-point and illumination invariant properties. Existing works on 3D loop closure detection often leverage on matching of local or global geometrical-only descriptors which discard intensity reading. In this paper we explore the intensity property from LiDAR scan and show that it can be effective for place recognition. We propose a novel global descriptor, intensity scan context (ISC), that explores both geometry and intensity characteristics. To improve the efficiency for loop closure detection, an efficient two-stage hierarchical re-identification process is proposed, including binary-operation based fast geometric relation retrieval and intensity structure re-identification. Thorough experiments including both local experiment and public datasets test have been conducted to evaluate the performance of the proposed method. Our method achieves better recall rate and recall precision than existing geometric-only methods.


Title: TextSLAM: Visual SLAM with Planar Text Features
Key Words: augmented reality  data visualisation  navigation  robot vision  SLAM (robots)  stereo image processing  text analysis  text detection  text object integration  augmented reality  navigation  scene understanding  illumination-invariant photometric error  TextSLAM  text detection  text-based visual SLAM  3D text maps  visual SLAM pipeline  planar text features  visual SLAM system  planar feature  Simultaneous localization and mapping  Three-dimensional displays  Visualization  Feature extraction  Navigation  Cameras  Robustness 
Abstract: We propose to integrate text objects in man-made scenes tightly into the visual SLAM pipeline. The key idea of our novel text-based visual SLAM is to treat each detected text as a planar feature which is rich of textures and semantic meanings. The text feature is compactly represented by three parameters and integrated into visual SLAM by adopting the illumination-invariant photometric error. We also describe important details involved in implementing a full pipeline of text-based visual SLAM. To our best knowledge, this is the first visual SLAM method tightly coupled with the text features. We tested our method in both indoor and outdoor environments. The results show that with text features, the visual SLAM system becomes more robust and produces much more accurate 3D text maps that could be useful for navigation and scene understanding in robotic or augmented reality applications.


Title: Redesigning SLAM for Arbitrary Multi-Camera Systems
Key Words: cameras  distance measurement  robot vision  SLAM (robots)  stereo image processing  sensor-specific modifications  SLAM systems  robustness  camera configurations  adaptive SLAM system  multicamera setup  visual SLAM  adaptive initialization  scalable voxel-based map  sensor-agnostic information-theoretic keyframe selection algorithm  visual front-end design  visual-inertial odometry  Cameras  Simultaneous localization and mapping  Three-dimensional displays  Uncertainty  Visualization 
Abstract: Adding more cameras to SLAM systems improves robustness and accuracy but complicates the design of the visual front-end significantly. Thus, most systems in the literature are tailored for specific camera configurations. In this work, we aim at an adaptive SLAM system that works for arbitrary multi-camera setups. To this end, we revisit several common building blocks in visual SLAM. In particular, we propose an adaptive initialization scheme, a sensor-agnostic, information- theoretic keyframe selection algorithm, and a scalable voxel- based map. These techniques make little assumption about the actual camera setups and prefer theoretically grounded methods over heuristics. We adapt a state-of-the-art visual- inertial odometry with these modifications, and experimental results show that the modified pipeline can adapt to a wide range of camera setups (e.g., 2 to 6 cameras in one experiment) without the need of sensor-specific modifications or tuning.


Title: Dynamic SLAM: The Need For Speed
Key Words: feature extraction  image motion analysis  image segmentation  mobile robots  path planning  robot vision  SLAM (robots)  rigid moving objects  static structure  dynamic structure  rigid objects  object-aware dynamic SLAM algorithm  model-free  significant motion constraints  3D models  SLAM based approaches  unstructured dynamic environments  autonomous systems  increased deployment  simultaneous localisation  static world assumption  Simultaneous localization and mapping  Heuristic algorithms  Dynamics  Three-dimensional displays  Solid modeling  Tracking 
Abstract: The static world assumption is standard in most simultaneous localisation and mapping (SLAM) algorithms. Increased deployment of autonomous systems to unstructured dynamic environments is driving a need to identify moving objects and estimate their velocity in real-time. Most existing SLAM based approaches rely on a database of 3D models of objects or impose significant motion constraints. In this paper, we propose a new feature-based, model-free, object-aware dynamic SLAM algorithm that exploits semantic segmentation to allow estimation of motion of rigid objects in a scene without the need to estimate the object poses or have any prior knowledge of their 3D models. The algorithm generates a map of dynamic and static structure and has the ability to extract velocities of rigid moving objects in the scene. Its performance is demonstrated on simulated, synthetic and real-world datasets.


Title: ∇SLAM: Dense SLAM meets Automatic Differentiation
Key Words: gradient methods  graph theory  learning (artificial intelligence)  robot vision  SLAM (robots)  automatic differentiation  dense simultaneous localization  learning-based approaches  representation learning approaches  classical SLAM systems  differentiable function  optimize task performance  typical dense SLAM system  ∇SLAM  posing SLAM systems  differentiable computational graphs  differentiable trust-region optimizers  task-based error signals  Simultaneous localization and mapping  Optimization  Three-dimensional displays  Damping  Task analysis  Neural networks 
Abstract: The question of "representation" is central in the context of dense simultaneous localization and mapping (SLAM). Learning-based approaches have the potential to leverage data or task performance to directly inform the representation. However, blending representation learning approaches with "classical" SLAM systems has remained an open question, because of their highly modular and complex nature. A SLAM system transforms raw sensor inputs into a distribution over the state(s) of the robot and the environment. If this transformation (SLAM) were expressible as a differentiable function, we could leverage task-based error signals over the outputs of this function to learn representations that optimize task performance. However, this is infeasible as several components of a typical dense SLAM system are non-differentiable. In this work, we propose ∇SLAM (gradSLAM), a methodology for posing SLAM systems as differentiable computational graphs, which unifies gradient-based learning and SLAM. We propose differentiable trust-region optimizers, surface measurement and fusion schemes, and raycasting, without sacrificing accuracy. This amalgamation of dense SLAM with computational graphs enables us to backprop all the way from 3D maps to 2D pixels, opening up new possibilities in gradient-based learning for SLAM1.


Title: Learning local behavioral sequences to better infer non-local properties in real multi-robot systems
Key Words: learning (artificial intelligence)  multi-robot systems  neurocontrollers  recurrent neural nets  two-wheeled robotic platform  local behavioral sequences  multirobot systems  multirobot team  traditional observer-based approach  machine learning methods  remote teammate localization modules  long-short-term-memory  Robot sensing systems  Robot kinematics  Training  Multi-robot systems  Machine learning  Shape 
Abstract: When members of a multi-robot team follow regular motion rules sensitive to robots and other environmental factors within sensing range, the team itself may become an informational fabric for gaining situational awareness without explicit signalling among robots. In our previous work [1], we used machine learning to develop a scalable module, trained only on data from 3-robot teams, that could predict the positions of all robots in larger multi-robot teams based only on observations of the movement of a robot's nearest neighbor. Not only was this approach scalable from 3-to-many robots, but it did not require knowledge of the control laws of the robots under observation, as would a traditional observer-based approach. However, performance was only tested in simulation and could only be a substitute for explicit communication for short periods of time or in cases of very low sensing noise. In this work, we apply more sophisticated machine learning methods to data from a physically realized robotic team to develop Remote Teammate Localization (ReTLo) modules that can be used in realistic environments. To be specific, we adopt Long-Short-Term-Memory (LSTM) [2] to learn the evolution of behaviors in a modular team, which has the effect of greatly reducing errors from regression outcomes. In contrast with our previous work in simulation, all of the experiments conducted in this work were conducted on the Thymio physical, two-wheeled robotic platform.


Title: A Generative Approach for Socially Compliant Navigation
Key Words: learning (artificial intelligence)  mobile robots  optimisation  path planning  robot vision  socially compliant navigation  robots navigation  socially compliant behavior  optimization objectives  inverse reinforcement learning approaches  natural behavior  generative navigation algorithm  navigation path  latent social rules  trained social navigation behavior  NaviGAN  Navigation  Robots  Force  Generators  Trajectory  Learning (artificial intelligence)  Collision avoidance 
Abstract: Robots navigating in human crowds need to optimize their paths not only for their task performance but also for their compliance to social norms. One of the key challenges in this context is the lack of standard metrics for evaluating and optimizing a socially compliant behavior. Existing works in social navigation can be grouped according to the differences in their optimization objectives. For instance, the reinforcement learning approaches tend to optimize on the comfort aspect of the socially compliant navigation, whereas the inverse reinforcement learning approaches are designed to achieve natural behavior. In this paper, we propose NaviGAN, a generative navigation algorithm that jointly optimizes both of the comfort and naturalness aspects. Our approach is designed as an adversarial training framework that can learn to generate a navigation path that is both optimized for achieving a goal and for complying with latent social rules. A set of experiments has been carried out on multiple datasets to demonstrate the strengths of the proposed approach quantitatively. We also perform extensive experiments using a physical robot in a realworld environment to qualitatively evaluate the trained social navigation behavior. The video recordings of the robot experiments can be found in the link: https://youtu.be/61blDymjCpw.


Title: Scalable Multi-Task Imitation Learning with Autonomous Improvement
Key Words: learning (artificial intelligence)  learning systems  robots  task analysis  deploying learning-based systems  scalable multitask imitation learning  sparse task-agnostic reward signals  reinforcement learning algorithms  continuous improvement  prior imitation learning approaches  initial demonstration dataset  learned latent space  multitask demonstration data  multitask setting  autonomous improvement  supervised imitation  autonomous data collection  imitation learning system  robot learning  stable approach  Task analysis  Robots  Learning (artificial intelligence)  Standards  Trajectory  Data collection  Learning systems 
Abstract: While robot learning has demonstrated promising results for enabling robots to automatically acquire new skills, a critical challenge in deploying learning-based systems is scale: acquiring enough data for the robot to effectively generalize broadly. Imitation learning, in particular, has remained a stable and powerful approach for robot learning, but critically relies on expert operators for data collection. In this work, we target this challenge, aiming to build an imitation learning system that can continuously improve through autonomous data collection, while simultaneously avoiding the explicit use of reinforcement learning, to maintain the stability, simplicity, and scalability of supervised imitation. To accomplish this, we cast the problem of imitation with autonomous improvement into a multi-task setting. We utilize the insight that, in a multi-task setting, a failed attempt at one task might represent a successful attempt at another task. This allows us to leverage the robot's own trials as demonstrations for tasks other than the one that the robot actually attempted. Using an initial dataset of multitask demonstration data, the robot autonomously collects trials which are only sparsely labeled with a binary indication of whether the trial accomplished any useful task or not. We then embed the trials into a learned latent space of tasks, trained using only the initial demonstration dataset, to draw similarities between various trials, enabling the robot to achieve one-shot generalization to new tasks. In contrast to prior imitation learning approaches, our method can autonomously collect data with sparse supervision for continuous improvement, and in contrast to reinforcement learning algorithms, our method can effectively improve from sparse, task-agnostic reward signals.


Title: Reinforcement Learning Based Manipulation Skill Transferring for Robot-assisted Minimally Invasive Surgery
Key Words: end effectors  Gaussian processes  human-robot interaction  learning (artificial intelligence)  manipulator dynamics  medical robotics  motion control  regression analysis  surgery  complex tasks demonstrations  reinforcement learning algorithm based manipulation skill transferring technique  robot-assisted minimally invasive surgery  Gaussian mixture model  Gaussian mixture regression  multiple demonstrations  trial phase performed offline  practical surgical operation  KUKA LWR4+ robot  human manipulation skill  surgical robots  Learning (artificial intelligence)  Robots  Surgery  Trajectory  Task analysis  Shape  Education 
Abstract: The complexity of surgical operation can be released significantly if surgical robots can learn the manipulation skills by imitation from complex tasks demonstrations such as puncture, suturing, and knotting, etc.. This paper proposes a reinforcement learning algorithm based manipulation skill transferring technique for robot-assisted Minimally Invasive Surgery by Teaching by Demonstration. It employed Gaussian mixture model and Gaussian mixture Regression based dynamic movement primitive to model the high-dimensional human-like manipulation skill after multiple demonstrations. Furthermore, this approach fascinates the learning and trial phase performed offline, which reduces the risks and cost for the practical surgical operation. Finally, it is demonstrated by transferring manipulation skills for reaching and puncture using a KUKA LWR4+ robot in a lab setup environment. The results show the effectiveness of the proposed approach for modelling and learning of human manipulation skill.


Title: An Iterative Quadratic Method for General-Sum Differential Games with Feedback Linearizable Dynamics
Key Words: control system synthesis  convergence of numerical methods  differential games  feedback  game theory  iterative methods  linear quadratic control  linearisation techniques  nonlinear control systems  path planning  feedback linearizable dynamics  nonlinear optimal control community  multiplayer general-sum differential games  ILQ methods  local equilibria  interactive motion planning problems  iterative procedures  initial conditions  hyperparameter choices  unsafe trajectories  dynamical systems  algorithmic reliability  feedback linearizable structure  iterative linear-quadratic method  Games  Heuristic algorithms  Planning  Feedback linearization  Iterative methods  Vehicle dynamics  Optimal control 
Abstract: Iterative linear-quadratic (ILQ) methods are widely used in the nonlinear optimal control community. Recent work has applied similar methodology in the setting of multi-player general-sum differential games. Here, ILQ methods are capable of finding local equilibria in interactive motion planning problems in real-time. As in most iterative procedures, however, this approach can be sensitive to initial conditions and hyperparameter choices, which can result in poor computational performance or even unsafe trajectories. In this paper, we focus our attention on a broad class of dynamical systems which are feedback linearizable, and exploit this structure to improve both algorithmic reliability and runtime. We showcase our new algorithm in three distinct traffic scenarios, and observe that in practice our method converges significantly more often and more quickly than was possible without exploiting the feedback linearizable structure.


Title: On the Human Control of a Multiple Quadcopters with a Cable-suspended Payload System
Key Words: actuators  attitude control  autonomous aerial vehicles  control system synthesis  helicopters  mobile robots  multi-robot systems  position control  cable-suspended payload system  human control  multiple quadcopters system  leader quadcopter  payload attitude controller  cable attitude controller  quadcopter-payload system  Payloads  Oscillators  Angular velocity  Attitude control  Vehicle dynamics  Trajectory  Quadcopters  Human control  Cable-suspended payload  Collaborative transportation  Multi-agents 
Abstract: A quadcopter is an under-actuated system with only four control inputs for six degrees of freedom, and yet the human control of a quadcopter is simple enough to be learned with some practice. In this work, we consider the problem of human control of a multiple quadcopters system to transport a cable-suspended payload. The coupled dynamics of the system, due to the inherent physical constraints, is used to develop a leader-follower architecture where the leader quadcopter is controlled directly by a human operator and the followers are controlled with the proposed Payload Attitude Controller and Cable Attitude Controller. Experiments, where a human operator flew a two quadcopters system to transport a cable-suspended payload, were conducted to study the performance of proposed controller. The results demonstrated successful implementation of human control in these systems. This work presents the possibility of enabling manual control for on-the-go maneuvering of the quadcopter-payload system which motivates aerial transportation in the unknown environments.


Title: Fine-Grained Driving Behavior Prediction via Context-Aware Multi-Task Inverse Reinforcement Learning
Key Words: behavioural sciences computing  driver information systems  learning (artificial intelligence)  road accidents  road safety  road traffic  unexpected VRU movements  residential roads  proficient acceleration  deceleration  road width  traffic direction  multilinear reward function  contextual information  long-term prediction  defensive driving strategy  context-aware multitask inverse reinforcement learning  advanced driver assistance systems  vulnerable road users  traffic accident reduction rate  multitask IRL approach  fine-grained driving behavior prediction  inverse reinforcement learning  Roads  Context modeling  Task analysis  Vehicles  Hidden Markov models  Safety  Predictive models 
Abstract: Research on advanced driver assistance systems for reducing risks to vulnerable road users (VRUs) has recently gained popularity because the traffic accident reduction rate for VRUs is still small. Dealing with unexpected VRU movements on residential roads requires proficient acceleration and deceleration. Although fine-grained prediction of driving behavior through inverse reinforcement learning (IRL) has been reported with promising results in recent years, learning of a precise model fails when driving strategies vary with contextual factors, i.e., weather, time of day, road width, and traffic direction. In this work, we propose a novel multi-task IRL approach with a multilinear reward function to incorporate contextual information into the model. This approach can provide precise long-term prediction of fine-grained driving behavior while adjusting to context. Experimental results using actual driving data over 141 km with various contexts and roads confirm the success of this approach in terms of predicting defensive driving strategy even in unknown situations.


Title: UrbanLoco: A Full Sensor Suite Dataset for Mapping and Localization in Urban Scenes
Key Words: cameras  image matching  image registration  inertial navigation  optical radar  satellite navigation  urban canyon  urban terrain  Hong Kong  San Francisco  IMU  GNSS-based solutions  LIDAR  global navigation satellite system  urban scene localization  urban scene mapping  inertia measurement units  camera-based methods  inertia navigation  visual feature matching  point cloud registration  full sensor suite dataset  UrbanLoco  Global navigation satellite system  Cameras  Laser radar  Urban areas  Robot sensing systems  Trajectory  Satellites 
Abstract: Mapping and localization is a critical module of autonomous driving, and significant achievements have been reached in this field. Beyond Global Navigation Satellite System (GNSS), research in point cloud registration, visual feature matching, and inertia navigation has greatly enhanced the accuracy and robustness of mapping and localization in different scenarios. However, highly urbanized scenes are still challenging: LIDAR- and camera-based methods perform poorly with numerous dynamic objects; the GNSS-based solutions experience signal loss and multi-path problems; the inertia measurement units (IMU) suffer from drifting. Unfortunately, current public datasets either do not adequately address this urban challenge or do not provide enough sensor information related to map-ping and localization. Here we present UrbanLoco: a mapping/localization dataset collected in highly-urbanized environments with a full sensor-suite. The dataset includes 13 trajectories collected in San Francisco and Hong Kong, covering a total length of over 40 kilometers. Our dataset includes a wide variety of urban terrains: urban canyons, bridges, tunnels, sharp turns, etc. More importantly, our dataset includes information from LIDAR, cameras, IMU, and GNSS receivers. Now the dataset is publicly available through the link in the footnote 1.


Title: Ultra-High-Accuracy Visual Marker for Indoor Precise Positioning
Key Words: attitude control  attitude measurement  autonomous aerial vehicles  indoor navigation  mobile robots  position control  robot vision  local positioning  marker coordinate system  high-accuracy global positioning  ultra-high-accuracy visual marker  indoor precise positioning  indoor positioning  indoor mobile robots  drones  general-purpose technology  attitude measurement  multiple dynamic moires  lenticular lens  attitude estimation error  marker position error  reprojection error  size 10.0 m  size 1.0 cm  size 10.0 cm  attitude accuracy  Visualization  Lenses  Position measurement  Cameras  Measurement uncertainty  Pose estimation 
Abstract: Indoor positioning technology is essential for indoor mobile robots and drones. However, there has never been a general-purpose technology or infrastructure that enables indoor positioning with an accuracy of less than 10 cm. We have developed an attitude measurement method using multiple dynamic moires with a lenticular lens and developed an ultra- high-accuracy visual marker with an attitude estimation error of less than 0.1°. We also developed a calculation method that minimizes the marker position error by reminimizing reprojection error using its good attitude accuracy. We proved that accurate local positioning with a position error of about 1 cm in a marker coordinate system is possible even when a marker is shot from a distance of 10 m. In addition, a demonstration test was performed in a public space, and it was shown that high-accuracy global positioning with a position error of about 10 cm is possible.


Title: Accurate position tracking with a single UWB anchor
Key Words: inertial systems  Kalman filters  mobile robots  nonlinear filters  object tracking  observability  position measurement  SLAM (robots)  ultra wideband technology  velocity measurement  ultrawideband technology  UWB anchor  UWB range  moving robot tracking  position tracking  robotic applications  localization systems  optical tracking  9 DoF inertial measurement unit  UWB ranging source  UWB technology  robot speed estimation  orientation estimation  IMU sensor  observability  extended Kalman filter  EKF  robot pose estimation  Robot sensing systems  Estimation  Observability  Velocity measurement  Distance measurement  Mobile robots 
Abstract: Accurate localization and tracking are a fundamental requirement for robotic applications. Localization systems like GPS, optical tracking, simultaneous localization and mapping (SLAM) are used for daily life activities, research, and commercial applications. Ultra-wideband (UWB) technology provides another venue to accurately locate devices both indoors and outdoors. In this paper, we study a localization solution with a single UWB anchor, instead of the traditional multi-anchor setup. Besides the challenge of a single UWB ranging source, the only other sensor we require is a low-cost 9 DoF inertial measurement unit (IMU). Under such a configuration, we propose continuous monitoring of UWB range changes to estimate the robot speed when moving on a line. Combining speed estimation with orientation estimation from the IMU sensor, the system becomes temporally observable. We use an Extended Kalman Filter (EKF) to estimate the pose of a robot. With our solution, we can effectively correct the accumulated error and maintain accurate tracking of a moving robot.


Title: Adaptive Neural Trajectory Tracking Control for Flexible-Joint Robots with Online Learning
Key Words: actuators  adaptive control  backpropagation  control system synthesis  feedforward  flexible manipulators  manipulator dynamics  neurocontrollers  nonlinear control systems  position control  stability  online backpropagation  collaborative robots  multilayer neural network  control architecture  flexible joint dynamics  control bandwidth  control design  space manipulators  online learning  flexible-joint robots  adaptive neural trajectory tracking control  series-elastic joint actuators  joint flexibility  Baxter robot  commanded joint position  outer loop control  nonlinear basis functions  internal weights  tracking error  output layer weights  linear output layer  robot dynamics  linear-in-parameter representation  feedforward control  approximate unknown dynamics  Artificial neural networks  Trajectory  Manipulator dynamics  Aerodynamics 
Abstract: Collaborative robots and space manipulators contain significant joint flexibility. It complicates the control design, compromises the control bandwidth, and limits the tracking accuracy. The imprecise knowledge of the flexible joint dynamics compounds the challenge. In this paper, we present a new control architecture for controlling flexible-joint robots. Our approach uses a multi-layer neural network to approximate unknown dynamics needed for the feedforward control. The network may be viewed as a linear-in-parameter representation of the robot dynamics, with the nonlinear basis of the robot dynamics connected to the linear output layer. The output layer weights are updated based on the tracking error and the nonlinear basis. The internal weights of the nonlinear basis are updated by online backpropagation to further reduce the tracking error. To use time scale separation to reduce the coupling of the two steps - the update of the internal weights is at a lower rate compared to the update of the output layer weights. With the update of the output layer weights, our controller adapts quickly to the unknown dynamics change and disturbances (such as attaching a load). The update of the internal weights would continue to improve the converge of the nonlinear basis functions. We show the stability of the proposed scheme under the "outer loop" control, where the commanded joint position is considered as the control input. Simulation and physical experiments are conducted to demonstrate the performance of the proposed controller on a Baxter robot, which exhibits significant joint flexibility due to the series-elastic joint actuators.


Title: Distributed Attack-Robust Submodular Maximization for Multi-Robot Planning
Key Words: control system security  distributed algorithms  divide and conquer methods  multi-robot systems  optimisation  path planning  target tracking  distributed attack-robust submodular maximization  multirobot planning  swarm-robotics applications  multirobot motion  attack-robust algorithms  robust optimization  distributed robust maximization  DRM performance  multiple robots  denial-of-service attacks  DoS attacks  large-scale robotic applications  general-purpose distributed algorithm  divide-and-conquer approach  robot communication range  close-to-optimal performance  active target tracking  Planning  Target tracking  Robot kinematics  Partitioning algorithms  Robot sensing systems  Robustness 
Abstract: We aim to guard swarm-robotics applications against denial-of-service (DoS) attacks that result in withdrawals of robots. We focus on applications requiring the selection of actions for each robot, among a set of available ones, e.g., which trajectory to follow. Such applications are central in large-scale robotic applications, e.g., multi-robot motion planning for target tracking. But the current attack-robust algorithms are centralized, and scale quadratically with the problem size (e.g., number of robots). In this paper, we propose a general-purpose distributed algorithm towards robust optimization at scale, with local communications only. We name it distributed robust maximization (DRM). DRM proposes a divide-and-conquer approach that distributively partitions the problem among K cliques of robots. The cliques optimize in parallel, independently of each other. That way, DRM also offers computational speed-ups up to 1/K2 the running time of its centralized counterparts. K depends on the robots' communication range, which is given as input to DRM. DRM also achieves a close-to-optimal performance. We demonstrate DRM's performance in Gazebo and MATLAB simulations, in scenarios of active target tracking with multiple robots. We observe DRM achieves significant computational speed-ups (it is 3 to 4 orders faster) and, yet, nearly matches the tracking performance of its centralized counterparts.


Title: Multirobot Patrolling Against Adaptive Opponents with Limited Information
Key Words: mobile robots  multi-agent systems  multi-robot systems  optimisation  multirobot patrolling  adaptive opponents  patrolling problem  multiple agents  time consuming  Robot kinematics  Task analysis  Delays  Optimization  Games 
Abstract: We study a patrolling problem where multiple agents are tasked with protecting an environment where one or more adversaries are trying to compromise targets of varying value. The objective of the patrollers is to move between targets to quickly spot when an attack is taking place and then diffuse it. Differently from most related literature, we do not assume that attackers have full knowledge of the strategies followed by the patrollers, but rather build a model at run time through repeated observations of how often they visit certain targets. We study three different solutions to this problem. The first two partition the environment using either a fast heuristic or an exact method that is significantly more time consuming. The third method, instead does not partition the environment, but rather lets every patroller roam over the entire environment. After having identified strengths and weaknesses of each method, we contrast their performances against attackers using different algorithms to decide whether to attack or not.


Title: Distributed Optimization of Nonlinear, Non-Gaussian, Communication-Aware Information using Particle Methods
Key Words: entropy  mobile robots  multi-robot systems  optimisation  wireless sensor networks  mobile robotic sensor networks  neighbor robots  conditional mutual information  communication properties  specific measurement set  particle methods  information computation  distributed optimization  local utility design  communication-aware information gathering  sampling procedures  entropy reduction  Robot sensing systems  Optimization  Mutual information  Planning  Atmospheric measurements  Particle measurements 
Abstract: This paper presents a distributed optimization framework and its local utility design for communication-aware information gathering by mobile robotic sensor networks. The main idea of the optimization is that each robot decides based on its local utility that considers the decisions of other neighbor robots higher in a given hierarchy. The local utility is designed as conditional mutual information that captures sensing and communication properties. Sampling procedures using a specific measurement set and particle methods are applied to compute the designed utility, which allows nonlinear, non-Gaussian properties of targets, sensing, and communication. Simulation results describe the presented distributed optimization shows more improved estimates and entropy reduction than another approach that does not consider communication properties. Simulation results also verify the presented distributed optimization using the described approach for information computation has better results than using other approaches that simplify the communication-aware information.


Title: Crocoddyl: An Efficient and Versatile Framework for Multi-Contact Optimal Control
Key Words: dynamic programming  iterative methods  motion control  optimal control  Crocoddyl  contact robot control by differential dynamic library  open-source framework  multicontact optimal control  state trajectory  control policy  sparse analytical derivatives  differential geometry  floating-base systems  FDDP  computation time  infeasible state-control trajectories  highly-dynamic maneuvers  feasibility-driven differential dynamic programming  Optimal control  Trajectory  Optimization  Heuristic algorithms  Dynamic programming  Robots  Acceleration 
Abstract: We introduce Crocoddyl (Contact RObot COntrol by Differential DYnamic Library), an open-source framework tailored for efficient multi-contact optimal control. Crocoddyl efficiently computes the state trajectory and the control policy for a given predefined sequence of contacts. Its efficiency is due to the use of sparse analytical derivatives, exploitation of the problem structure, and data sharing. It employs differential geometry to properly describe the state of any geometrical system, e.g. floating-base systems. Additionally, we propose a novel optimal control algorithm called Feasibility-driven Differential Dynamic Programming (FDDP). Our method does not add extra decision variables which often increases the computation time per iteration due to factorization. FDDP shows a greater globalization strategy compared to classical Differential Dynamic Programming (DDP) algorithms. Concretely, we propose two modifications to the classical DDP algorithm. First, the backward pass accepts infeasible state-control trajectories. Second, the rollout keeps the gaps open during the early "exploratory" iterations (as expected in multipleshooting methods with only equality constraints). We showcase the performance of our framework using different tasks. With our method, we can compute highly-dynamic maneuvers (e.g. jumping, front-flip) within few milliseconds.


Title: A Spatial-temporal Multiplexing Method for Dense 3D Surface Reconstruction of Moving Objects
Key Words: image coding  image filtering  image matching  image restoration  image texture  multiplexing  object recognition  robot vision  stereo image processing  surface reconstruction  high reconstruction accuracy  fast image acquisition  spatial-temporal multiplexing method  moving objects  three-dimensional reconstruction  robotic applications  robotic recognition  spatial-multiplexing time-multiplexing structured-light techniques  image acquisition time  spatial-temporal encoded patterns  dense 3D surface reconstruction  texture map  image blur  high-frequency phase-shifting fringes  spatial-coded texture  Image reconstruction  Multiplexing  Three-dimensional displays  Surface reconstruction  Robots  Encoding  Reliability 
Abstract: Three-dimensional reconstruction of dynamic objects is important for robotic applications, for example, the robotic recognition and manipulation. In this paper, we present a novel 3D surface reconstruction method for moving objects. The proposed method combines the spatial-multiplexing and time-multiplexing structured-light techniques that have advantages of less image acquisition time and accurate 3D reconstruction, respectively. A set of spatial-temporal encoded patterns are designed, where a spatial-encoded texture map is embedded into the temporal-encoded three-step phase-shifting fringes. The specifically designed spatial-coded texture assigns high-uniqueness codeword to any window on the image which helps to eliminate the phase ambiguity. In addition, the texture is robust to noise and image blur. Combining this texture with high-frequency phase-shifting fringes, high reconstruction accuracy would be ensured. This method only requires 3 patterns to uniquely encode a surface, which facilitates the fast image acquisition for each reconstruction step. A filtering stereo matching algorithm is proposed for the spatial-temporal multiplexing method to improve the matching reliability. Moreover, the reconstruction precision is further enhanced by a correspondence refinement algorithm. Experiments validate the performance of the proposed method including the high accuracy, the robustness to noise and the ability to reconstruct moving objects.


Title: Reducing Uncertainty in Pose Estimation under Complex Contacts via Force Forecast
Key Words: haptic interfaces  manipulators  pose estimation  regression analysis  robotic assembly  trees (mathematics)  sphere-tree representation  least-uncertain estimate  relative contact  multiregion complex contacts  contact types  contact locations  object shapes  object poses  complex shapes  pose estimation  force forecast  autonomous robotic manipulation  simulated complex contacts  force sensing  constraint-based haptic simulation algorithm  three-pin peg-in-hole robotic assembly tasks  contact-rich two-pin peg-in-hole assembly tasks  calibration  regression model  Force  Uncertainty  Robot sensing systems  Task analysis  Calibration 
Abstract: How to reduce uncertainty in object pose estimation under complex contacts is crucial to autonomous robotic manipulation and assembly. In this paper, we introduce an approach through forecasting contact force from simulated complex contacts with calibration based on real force sensing. A constraint-based haptic simulation algorithm is used with sphere-tree representation of contacting objects to compute contact poses and forces, and through matching the computed forces to measured real force data via a regression model, the least-uncertain estimate of the relative contact pose is obtained. Our approach can handle multi-region complex contacts and does not make any assumption about contact types or contact locations. It also does not have restriction on object shapes. We have applied the force forecast approach to reducing uncertainty in estimating object poses in challenging peg-in-hole robotic assembly tasks and demonstrate the effectiveness of the approach by successful completion of contact-rich two-pin and three-pin real peg-in-hole assembly tasks with complex shapes of pins and holes.


Title: Comparison of Constrained and Unconstrained Human Grasp Forces Using Fingernail Imaging and Visual Servoing
Key Words: dexterous manipulators  force measurement  grippers  robot vision  visual servoing  fingernail imaging  force measurement  visual tracking system  force collaboration  constrained human grasp forces  unconstrained human grasp forces  visual servoing  3D fingertip forces  robotic arms  Grasping  Force  Estimation  Cameras  Mathematical model  Force measurement 
Abstract: Fingernail imaging has been proven to be effective in prior works [1], [2] for estimating the 3D fingertip forces with a maximum RMS estimation error of 7%. In the current research, fingernail imaging is used to perform unconstrained grasp force measurement on multiple fingers to study human grasping. Moreover, two robotic arms with mounted cameras and a visual tracking system have been devised to keep the human fingers in the camera frame during the experiments. Experimental tests have been conducted for six human subjects under both constrained and unconstrained grasping conditions, and the results indicate a significant difference in force collaboration among the fingers between the two grasping conditions. Another interesting result according to the experiments is that in comparison to constrained grasping, unconstrained grasp forces are more evenly distributed over the fingers and there is less force variation (more steadiness) in each finger force. These results validate the importance of measuring grasp forces in an unconstrained manner in order to study how humans naturally grasp objects.


Title: Robust and Efficient Estimation of Absolute Camera Pose for Monocular Visual Odometry
Key Words: cameras  distance measurement  optimisation  pose estimation  high generality  absolute camera pose  monocular visual odometry  cost function  branch-and-bound  high outlier ratios  robust estimation  efficient estimation  3D-to-2D point correspondences  projection constraint  local optimizer  effective function bounds  real-time applications  synthetic datasets  real-world datasets  Robustness  Pose estimation  Cameras  Cost function  Three-dimensional displays 
Abstract: Given a set of 3D-to-2D point correspondences corrupted by outliers, we aim to robustly estimate the absolute camera pose. Existing methods robust to outliers either fail to guarantee high robustness and efficiency simultaneously, or require an appropriate initial pose and thus lack generality. In contrast, we propose a novel approach based on the robust "L2-minimizing estimate" (L2E) loss. We first define a novel cost function by integrating the projection constraint into the L2E loss. Then to efficiently obtain the global minimum of this function, we propose a hybrid strategy of a local optimizer and branch-and-bound. For branch-and-bound, we derive effective function bounds. Our approach can handle high outlier ratios, leading to high robustness. It can run reliably regardless of whether the initial pose is appropriate, providing high generality. Moreover, given a decent initial pose, it is suitable for real-time applications. Experiments on synthetic and real-world datasets showed that our approach outperforms state-of-the-art methods in terms of robustness and/or efficiency.


Title: egoTEB: Egocentric, Perception Space Navigation Using Timed-Elastic-Bands
Key Words: aerospace navigation  aerospace robotics  collision avoidance  graph theory  mobile robots  Monte Carlo methods  motion control  optimisation  trajectory control  grid-based representations  optimization graph  local planning map  egoTEB  timed-elastic-bands  TEB hierarchical planner  real-time navigation  collision avoidance  goal directed motion  multitrajectory optimization based synthesis method  topologically distinct trajectory candidates  factor graph approach  egocentric perception space navigation  egocentric perception space representations  Monte Carlo evaluations  autonomous mobile robot  Trajectory  Optimization  Navigation  Planning  Robots  Collision avoidance  Topology 
Abstract: The TEB hierarchical planner for real-time navigation through unknown environments is highly effective at balancing collision avoidance with goal directed motion. Designed over several years and publications, it implements a multi-trajectory optimization based synthesis method for identifying topologically distinct trajectory candidates through navigable space. Unfortunately, the underlying factor graph approach to the optimization problem induces a mismatch between grid-based representations and the optimization graph, which leads to several time and optimization inefficiencies. This paper explores the impact of using egocentric, perception space representations for the local planning map. Doing so alleviates many of the identified issues related to TEB and leads to a new method called egoTEB. Timing experiments and Monte Carlo evaluations in benchmark worlds quantify the benefits of egoTEB for navigation through uncertain environments.


Title: Experience Selection Using Dynamics Similarity for Efficient Multi-Source Transfer Learning Between Robots
Key Words: control engineering computing  helicopters  learning (artificial intelligence)  multi-robot systems  robot programming  robust control  user experience  robot systems  multisource inter-robot transfer learning  quadrotor experiments  real source quadrotor  virtual source quadrotor  experience selection  dynamics similarity  robotics literature  knowledge transfer  learning process  robust control theory  data-efficiency algorithm  Measurement  Task analysis  Heuristic algorithms  Robot sensing systems  Robust control  Trajectory 
Abstract: In the robotics literature, different knowledge transfer approaches have been proposed to leverage the experience from a source task or robot-real or virtual-to accelerate the learning process on a new task or robot. A commonly made but infrequently examined assumption is that incorporating experience from a source task or robot will be beneficial. In practice, inappropriate knowledge transfer can result in negative transfer or unsafe behaviour. In this work, inspired by a system gap metric from robust control theory, the ν-gap, we present a data-efficient algorithm for estimating the similarity between pairs of robot systems. In a multi-source inter-robot transfer learning setup, we show that this similarity metric allows us to predict relative transfer performance and thus informatively select experiences from a source robot before knowledge transfer. We demonstrate our approach with quadrotor experiments, where we transfer an inverse dynamics model from a real or virtual source quadrotor to enhance the tracking performance of a target quadrotor on arbitrary hand-drawn trajectories. We show that selecting experiences based on the proposed similarity metric effectively facilitates the learning of the target quadrotor, improving performance by 62% compared to a poorly selected experience.


Title: Comparison of online algorithms for the tracking of multiple magnetic targets in a myokinetic control interface*
Key Words: Kalman filters  medical robotics  optimisation  prosthetics  surgery  telerobotics  tracking  localization algorithms  optimization  Levenberg-Marquardt algorithm  trust region reflective algorithm  robotics applications  remote tracking  multiple magnetic targets  myokinetic control interface  magnetic tracking algorithms  biomedical applications  teleoperated surgical robots  upper limb prostheses  Magnetostatics  Magnetic separation  Robots  Magnetic sensors  Magnetic devices 
Abstract: Magnetic tracking algorithms can be used to determine the position and orientation of magnetic markers or devices. These techniques are particularly interesting for biomedical applications such as teleoperated surgical robots or the control of upper limb prostheses. The performance of different algorithms used for magnetic tracking was compared in the past. However, in most cases, those algorithms were required to track a single magnet.Here we investigated the performance of three localization algorithms in tracking up to 9 magnets: two optimization-based (Levenberg-Marquardt algorithm, LMA, and Trust Region Reflective algorithm, TRRA) and one recursion-based (Unscented Kalman Filter, UKF). The tracking accuracy of the algorithms and their computation time were investigated through simulations.The accuracy of the three algorithms, when tracking up to six magnets, was similar, leading to estimation errors varying from 0.06 ± 0.02 mm to 2.26 ± 0.07 mm within a 100 mm × 54 mm × 100 mm workspace, at the highest sampling frequency. In all cases, computation times under 300 ms for the UKF and 45 ms for the LMA/TRRA were obtained. The TRRA showed the best tracking performance overall.These outcomes are of interest for a wide range of robotics applications that require remote tracking.


Title: Congestion-aware Evacuation Routing using Augmented Reality Devices
Key Words: augmented reality  emergency management  optimisation  congestion-aware evacuation  congestion-aware routing solution  indoor evacuation  real-time individual-customized evacuation routes  multiple destinations  population density map  obtained on-the-fly  congestion distribution  optimal solution  time-efficient evacuation route  AR devices  user-end augmented reality devices  Sociology  Statistics  Routing  Real-time systems  Path planning  Robots  Headphones 
Abstract: We present a congestion-aware routing solution for indoor evacuation, which produces real-time individual-customized evacuation routes among multiple destinations while keeping tracks of all evacuees' locations. A population density map, obtained on-the-fly by aggregating locations of evacuees from user-end Augmented Reality (AR) devices, is used to model the congestion distribution inside a building. To efficiently search the evacuation route among all destinations, a variant of A* algorithm is devised to obtain the optimal solution in a single pass. In a series of simulated studies, we show that the proposed algorithm is more computationally optimized compared to classic path planning algorithms; it generates a more time-efficient evacuation route for each individual that minimizes the overall congestion. A complete system using AR devices is implemented for a pilot study in real-world environments, demonstrating the efficacy of the proposed approach.


Title: Mechanically Programmed Miniature Origami Grippers
Key Words: actuators  bending  grippers  miniature origami grippers  robotic gripper design  customizable grasping tasks  miniature fingers  single actuator input  grasping tasks  Grippers  Kinematics  Grasping  Actuators  Springs  Steel  Robots 
Abstract: This paper presents a robotic gripper design that can perform customizable grasping tasks at the millimeter scale. The design is based on the origami string, a mechanism with a single degree of freedom that can be mechanically programmed to approximate arbitrary paths in space. By using this concept, we create miniature fingers that bend at multiple joints with a single actuator input. The shape and stiffness of these fingers can be varied to fit different grasping tasks by changing the crease pattern of the string. We show that the experimental behavior of these strings follows their analytical models and that they can perform a variety of tasks including pinching, wrapping, and twisting common objects such as pencils, bottle caps, and blueberries.


Title: Investigation of a Multistable Tensegrity Robot applied as Tilting Locomotion System*
Key Words: actuators  bifurcation  mechanical stability  mobile robots  motion control  numerical analysis  robot dynamics  robot kinematics  vibration control  locomotion characteristics  actuation strategy  compliant tensegrity structure  multistable tensegrity robot  multiple stable equilibrium configurations  tilting locomotion system  Prototypes  Bifurcation  Robots  Mathematical model  Shape  Reliability  Topology 
Abstract: This paper describes the development of a tilting locomotion system based on a compliant tensegrity structure with multiple stable equilibrium configurations. A tensegrity structure featuring 4 stable equilibrium states is considered. The mechanical model of the structure is presented and the according equations of motion are derived. The variation of the length of selected structural members allows to influence the prestress state and the corresponding shape of the tensegrity structure. Based on bifurcation analyses a reliable actuation strategy to control the current equilibrium state is designed. In this work, the tensegrity structure is assumed to be in contact with a horizontal plane due to gravity. The derived actuation strategy is utilized to generate tilting locomotion by successively changing the equilibrium state. Numerical simulations are evaluated considering the locomotion characteristics. In order to validate this theoretical approach a prototype is developed. Experiments regarding to the equilibrium configurations, the actuation strategy and the locomotion characteristics are evaluated using image processing tools and motion capturing. The results verify the theoretical data and confirm the working principle of the investigated tilting locomotion system. This approach represents a feasible actuation strategy to realize a reliable tilting locomotion utilizing the multistability of compliant tensegrity structures.


Title: Modeling and Experiments on the Swallowing and Disgorging Characteristics of an Underwater Continuum Manipulator
Key Words: bending  elasticity  grippers  hydraulic systems  manipulator dynamics  muscle  pneumatic actuators  underwater continuum manipulator  compliant materials  McKibben water hydraulic artificial muscle  WHAM  mechanical properties  kinematics model  soft grippers  bending procedure  disgorging procedure  mouth-tongue collaborative soft robot  single-segment soft robot arm  swallowing procedure  Manipulators  Muscles  Grippers  Kinematics  Hydraulic systems  Actuators 
Abstract: Soft robots apply compliant materials to perform motions and behaviors not typically achievable by rigid robots. An underwater, compliant, multi-segment continuum manipulator that can bend, swallow, disgorge is developed in this study. The manipulator is driven by McKibben water hydraulic artificial muscle (WHAM). The mechanical properties of the WHAM are tested and analyzed experimentally. The kinematics model, which concerns about the variable diameter structure of the soft grippers, are established to simulate the behaviors of the manipulator among the bending, swallowing and disgorging procedure. A mouth-tongue collaborative soft robot assembled with another single-segment soft robot arm is presented. And its functions are experimentally testified. The distinctive functions were verified according to the experimental results.


Title: Flexure Hinge-based Biomimetic Thumb with a Rolling-Surface Metacarpal Joint
Key Words: biomimetics  bone  control system synthesis  dexterous manipulators  end effectors  manipulator kinematics  motion control  position control  surgery  flexure hinge-based biomimetic thumb  rolling-surface metacarpal joint  grasping  dexterous manipulation  kinematic multiplicity  robotic hand  kinematic model  surgical techniques  motion capture data  end effector  task-space velocities  tendon excursion velocity  human thumb state contribution  data representation  effector velocity  Joints  Fasteners  Thumb  Ellipsoids  Robots  Prototypes  Ceramics 
Abstract: The human thumb's state contribution to grasping and dexterous manipulation of objects is a function of the kinematic multiplicity of joints and structure of the bones, joints, and ligaments. This paper looks at the design and evaluation of a human-like thumb for use in a robotic hand, where the thumb's state contribution to grasping and dexterous manipulation is a function of a simplified kinematic model based on that of the human thumb, but also on empirical trials of surgical techniques to retain functionality while reducing the number of joints in the thumb. Motion Capture Data of the End Effector is analyzed with the measured excursion of the tendons to determine the relationship between tendon velocities and task-space velocities. After validating the procedure experimentally, a simplified metric is proposed to represent this data, and shows that our prototype is predicted to have a relatively smooth mapping between tendon excursion velocity and end effector velocity.


Title: Day and Night Collaborative Dynamic Mapping in Unstructured Environment Based on Multimodal Sensors
Key Words: groupware  image fusion  mobile robots  multi-robot systems  path planning  sensor fusion  SLAM (robots)  dynamic collaborative mapping  multimodal environmental perception  heterogeneous sensor fusion model  local 3D maps  night rainforest  3D map fusion missions  multimodal sensors  long-term operation  collaborative robots  dynamic environment  dynamic objects  Collaboration  Three-dimensional displays  Simultaneous localization and mapping  Cameras  Robot vision systems 
Abstract: Enabling long-term operation during day and night for collaborative robots requires a comprehensive understanding of the unstructured environment. Besides, in the dynamic environment, robots must be able to recognize dynamic objects and collaboratively build a global map. This paper proposes a novel approach for dynamic collaborative mapping based on multimodal environmental perception. For each mission, robots first apply heterogeneous sensor fusion model to detect humans and separate them to acquire static observations. Then, the collaborative mapping is performed to estimate the relative position between robots and local 3D maps are integrated into a globally consistent 3D map. The experiment is conducted in the day and night rainforest with moving people. The results show the accuracy, robustness, and versatility in 3D map fusion missions.


Title: Generating Locomotion with Effective Wheel Radius Manipulation
Key Words: mobile robots  motion control  motor drives  road vehicles  robot dynamics  vehicle dynamics  wheels  motor drives  sloped terrain  wheel rotation  plain centre hub drive  active ride height selection  wheel radius manipulation  locomotion generation  slope traversability  wheel pose control  centre of gravity manipulation  Wheels  Gravity  Acceleration  Mathematical model  Torque  Axles  Actuators 
Abstract: Travel over sloped terrain is difficult as an incline changes the interaction between each wheel and the ground resulting in an unbalanced load distribution which can lead to loss of traction and instability. This paper presents a novel approach to generating wheel rotation for primary locomotion by only changing its centre of rotation, or as a complimentary locomotion source to increase versatility of a plain centre hub drive. This is done using linear actuators within a wheel to control the position of the centre hub and induce a moment on the wheel from gravity. In doing so our platform allows for active ride height selection and individual wheel pose control. We present the system with calculations outlining the theoretical properties and perform experiments to validate the concept under loading via multiple gaits to show motion on slopes, and sustained motion over extended distance. We envision applications in conjunction to assist current motor drives and increasing slope traversability by allowing body pose and centre of gravity manipulation, or as a primary locomotion system.


Title: Image-Based Place Recognition on Bucolic Environment Across Seasons From Semantic Edge Description
Key Words: edge detection  feature extraction  image matching  image retrieval  image texture  object recognition  wavelet transforms  multiseason environment-monitoring datasets  urban scenes  image-based place recognition  bucolic environment  semantic edge description  urban environments  natural scenes  semantic content  vegetation state  bucolic scene  global image description  semantic information  topological information  matching two images  semantic edge transforms  state-of-the-art image retrieval performance  Image edge detection  Semantics  Image segmentation  Image retrieval  Feature extraction  Geometry 
Abstract: Most of the research effort on image-based place recognition is designed for urban environments. In bucolic environments such as natural scenes with low texture and little semantic content, the main challenge is to handle the variations in visual appearance across time such as illumination, weather, vegetation state or viewpoints. The nature of the variations is different and this leads to a different approach to describing a bucolic scene. We introduce a global image description computed from its semantic and topological information. It is built from the wavelet transforms of the image's semantic edges. Matching two images is then equivalent to matching their semantic edge transforms. This method reaches state-of-the-art image retrieval performance on two multi-season environment-monitoring datasets: the CMU-Seasons and the Symphony Lake dataset. It also generalizes to urban scenes on which it is on par with the current baselines NetVLAD and DELF.


Title: A Multilayer-Multimodal Fusion Architecture for Pattern Recognition of Natural Manipulations in Percutaneous Coronary Interventions
Key Words: control engineering computing  human-robot interaction  manipulators  medical computing  medical robotics  sensor fusion  multilayer-multimodal fusion architecture  pattern recognition  natural manipulations  percutaneous coronary interventions  robotic systems  robot-assisted procedures  human-robot interfaces  guidewire manipulations  multimodal behaviors  rule-based fusion algorithms  singlelayer recognition architecture  robot-assisted PCI  HRI  X-ray radiation reduction  medical staff  Sensors  Robots  Muscles  Feature extraction  Force  Catheters  Surgery 
Abstract: The increasingly-used robotic systems can provide precise delivery and reduce X-ray radiation to medical staff in percutaneous coronary interventions (PCI), but natural manipulations of interventionalists are forgone in most robot-assisted procedures. Therefore, it is necessary to explore natural manipulations to design more advanced human-robot interfaces (HRI). In this study, a multilayer-multimodal fusion architecture is proposed to recognize six typical subpatterns of guidewire manipulations in conventional PCI. The synchronously acquired multimodal behaviors from ten subjects are used as the inputs of the fusion architecture. Six classification-based and two rule-based fusion algorithms are evaluated for performance comparisons. Experimental results indicate that the multimodal fusion brings significant accuracy improvement in comparison with single-modal schemes. Furthermore, the proposed architecture can achieve the overall accuracy of 96.90%, much higher than that of a singlelayer recognition architecture (92.56%). These results have indicated the potential of the proposed method for facilitating the development of HRI for robot-assisted PCI.


Title: Real-Time Graph-Based SLAM with Occupancy Normal Distributions Transforms
Key Words: graph theory  least squares approximations  mobile robots  normal distribution  robot vision  SLAM (robots)  occupancy grid map  graph-based SLAM  occupancy normal distribution transforms  normal distributions transforms  simultaneous localization and mapping  mobile robotics  least squares problem  nonlinear optimizers  global NDT scan matcher  Simultaneous localization and mapping  Cost function  Google  Jacobian matrices  Gaussian distribution 
Abstract: Simultaneous Localization and Mapping (SLAM) is one of the basic problems in mobile robotics. While most approaches are based on occupancy grid maps, Normal Distributions Transforms (NDT) and mixtures like Occupancy Normal Distribution Transforms (ONDT) have been shown to represent sensor measurements more accurately. In this work, we slightly re-formulate the (O)NDT matching function such that it becomes a least squares problem that can be solved with various robust numerical and analytical non-linear optimizers. Further, we propose a novel global (O)NDT scan matcher for loop closure. In our evaluation, our NDT and ONDT methods are able to outperform the occupancy grid map based ones we adopted from Google's Cartographer implementation.


Title: Spatio-Temporal Non-Rigid Registration of 3D Point Clouds of Plants
Key Words: agriculture  cameras  image registration  robot vision  spatio-temporal nonrigid registration  3D point clouds  sensor data  agricultural robotics  plant science  agricultural tasks  automated temporal plant-trait analysis  plant performance monitoring  plant registration  Three-dimensional displays  Skeleton  Hidden Markov models  Strain  Topology  Simultaneous localization and mapping 
Abstract: Analyzing sensor data of plants and monitoring plant performance is a central element in different agricultural robotics applications. In plant science, phenotyping refers to analyzing plant traits for monitoring growth, for describing plant properties, or characterizing the plant's overall performance. It plays a critical role in the agricultural tasks and in plant breeding. Recently, there is a rising interest in using 3D data obtained from laser scanners and 3D cameras to develop automated non-intrusive techniques for estimating plant traits. In this paper, we address the problem of registering 3D point clouds of the plants over time, which is a backbone of applications interested in tracking spatio-temporal traits of individual plants. Registering plants over time is challenging due to its changing topology, anisotropic growth, and non-rigid motion in between scans. We propose a novel approach that exploits the skeletal structure of the plant and determines correspondences over time and drives the registration process. Our approach explicitly accounts for the non-rigidity and the growth of the plant over time in the registration. We tested our approach on a challenging dataset acquired over the course of two weeks and successfully registered the 3D plant point clouds recorded with a laser scanner forming a basis for developing systems for automated temporal plant-trait analysis.


Title: Loam livox: A fast, robust, high-precision LiDAR odometry and mapping package for LiDARs of small FoV
Key Words: distance measurement  mobile robots  optical radar  path planning  robot vision  SLAM (robots)  FoV  autonomous vehicles  autonomous navigation  path planning  LOAM algorithm  LiDAR odometry and mapping  robot pose localization  Laser radar  Feature extraction  Three-dimensional displays  Measurement by laser beam  Laser noise  Real-time systems  Spinning 
Abstract: LiDAR odometry and mapping (LOAM) has been playing an important role in autonomous vehicles, due to its ability to simultaneously localize the robot's pose and build high-precision, high-resolution maps of the surrounding environment. This enables autonomous navigation and safe path planning of autonomous vehicles. In this paper, we present a robust, real-time LOAM algorithm for LiDARs with small FoV and irregular samplings. By taking effort on both frontend and back-end, we address several fundamental challenges arising from such LiDARs, and achieve better performance in both precision and efficiency compared to existing baselines. To share our findings and to make contributions to the community, we open source our codes on Github1.


Title: Active SLAM using 3D Submap Saliency for Underwater Volumetric Exploration
Key Words: graph theory  mobile robots  navigation  path planning  robot vision  SLAM (robots)  underwater volumetric exploration  active SLAM framework  3D underwater environments  multibeam sonar  integrated SLAM  volumetric free-space information  informative loop closures  navigation policy  3D visual dictionary  submap saliency  sensor information  pose-graph SLAM formulation  global occupancy grid map  uncertainty-agnostic framework  Simultaneous localization and mapping  Three-dimensional displays  Uncertainty  Conferences  Automation  Sonar  Planning 
Abstract: In this paper, we present an active SLAM framework for volumetric exploration of 3D underwater environments with multibeam sonar. Recent work in integrated SLAM and planning performs localization while maintaining volumetric free-space information. However, an absence of informative loop closures can lead to imperfect maps, and therefore unsafe behavior. To solve this, we propose a navigation policy that reduces vehicle pose uncertainty by balancing between volumetric exploration and revisitation. To identify locations to revisit, we build a 3D visual dictionary from real-world sonar data and compute a metric of submap saliency. Revisit actions are chosen based on propagated pose uncertainty and sensor information gain. Loop closures are integrated as constraints in our pose-graph SLAM formulation and these deform the global occupancy grid map. We evaluate our performance in simulation and real-world experiments, and highlight the advantages over an uncertainty-agnostic framework.


Title: Are We Ready for Service Robots? The OpenLORIS-Scene Datasets for Lifelong SLAM
Key Words: mobile robots  path planning  pose estimation  robot vision  service robots  SLAM (robots)  simultaneous localization and mapping  data sequences  robotic autonomy  service robots  real-world indoor scenes  OpenLORIS-Scene datasets  SLAM problems  pose estimation  Simultaneous localization and mapping  Robot kinematics  Cameras  Synchronization  Trajectory 
Abstract: Service robots should be able to operate autonomously in dynamic and daily changing environments over an extended period of time. While Simultaneous Localization And Mapping (SLAM) is one of the most fundamental problems for robotic autonomy, most existing SLAM works are evaluated with data sequences that are recorded in a short period of time. In real-world deployment, there can be out-of-sight scene changes caused by both natural factors and human activities. For example, in home scenarios, most objects may be movable, replaceable or deformable, and the visual features of the same place may be significantly different in some successive days. Such out-of-sight dynamics pose great challenges to the robustness of pose estimation, and hence a robot's long-term deployment and operation. To differentiate the forementioned problem from the conventional works which are usually evaluated in a static setting in a single run, the term lifelong SLAM is used here to address SLAM problems in an ever-changing environment over a long period of time. To accelerate lifelong SLAM research, we release the OpenLORIS-Scene datasets. The data are collected in real-world indoor scenes, for multiple times in each place to include scene changes in real life. We also design benchmarking metrics for lifelong SLAM, with which the robustness and accuracy of pose estimation are evaluated separately. The datasets and benchmark are available online at lifelong-robotic-vision.github.io/dataset/scene.


Title: Full-Scale Continuous Synthetic Sonar Data Generation with Markov Conditional Generative Adversarial Networks*
Key Words: acoustic signal processing  autonomous underwater vehicles  data analysis  environmental factors  Markov processes  naval engineering computing  neural nets  object recognition  realistic images  sonar imaging  statistical analysis  bootstrapping ATR systems  autonomous underwater vehicles  autonomous target recognition systems  realistic synthetic sonar imagery  Markov conditional generative adversarial networks  continuous synthetic sonar data generation  Markov conditional pix2pix  environmental factors  acoustic sensors  Sonar  Training  Semantics  Data models  Gallium nitride  Training data  Markov processes 
Abstract: Deployment and operation of autonomous underwater vehicles is expensive and time-consuming. High-quality realistic sonar data simulation could be of benefit to multiple applications, including training of human operators for post-mission analysis, as well as tuning and validation of autonomous target recognition (ATR) systems for underwater vehicles. Producing realistic synthetic sonar imagery is a challenging problem as the model has to account for specific artefacts of real acoustic sensors, vehicle attitude, and a variety of environmental factors. We propose a novel method for generating realistic-looking sonar side-scans of full-length missions, called Markov Conditional pix2pix (MC-pix2pix). Quantitative assessment results confirm that the quality of the produced data is almost indistinguishable from real. Furthermore, we show that bootstrapping ATR systems with MC-pix2pix data can improve the performance. Synthetic data is generated 18 times faster than real acquisition speed, with full user control over the topography of the generated data.


Title: Adaptively Informed Trees (AIT*): Fast Asymptotically Optimal Path Planning through Adaptive Heuristics
Key Words: path planning  sampling methods  search problems  trees (mathematics)  heuristic estimates  AIT*  asymmetric bidirectional search  optimal path planning  informed sampling-based planning algorithm  adaptively informed trees  Search problems  Image edge detection  Approximation algorithms  Planning  Heuristic algorithms  Databases  Path planning 
Abstract: Informed sampling-based planning algorithms exploit problem knowledge for better search performance. This knowledge is often expressed as heuristic estimates of solution cost and used to order the search. The practical improvement of this informed search depends on the accuracy of the heuristic. Selecting an appropriate heuristic is difficult. Heuristics applicable to an entire problem domain are often simple to define and inexpensive to evaluate but may not be beneficial for a specific problem instance. Heuristics specific to a problem instance are often difficult to define or expensive to evaluate but can make the search itself trivial. This paper presents Adaptively Informed Trees (AIT*), an almost-surely asymptotically optimal sampling-based planner based on BIT*. AIT* adapts its search to each problem instance by using an asymmetric bidirectional search to simultaneously estimate and exploit a problem-specific heuristic. This allows it to quickly find initial solutions and converge towards the optimum. AIT* solves the tested problems as fast as RRT-Connect while also converging towards the optimum.


Title: Informing Multi-Modal Planning with Synergistic Discrete Leads
Key Words: continuous systems  discrete systems  manipulators  multimodal planning  robotic manipulation problems  continuous infinity  object grasping  manipulation plan  single-mode motions  valid transitions  manipulation planners  multimodal structure  mode-specific planners  general layered planning approach  pick-and-place manipulation domain  synergistic discrete leads  specific mode transitions  useful mode transitions  bias search  Planning  Manifolds  Task analysis  Lead  Probabilistic logic  Robot motion 
Abstract: Robotic manipulation problems are inherently continuous, but typically have underlying discrete structure, e.g., whether or not an object is grasped. This means many problems are multi-modal and in particular have a continuous infinity of modes. For example, in a pick-and-place manipulation domain, every grasp and placement of an object is a mode. Usually manipulation problems require the robot to transition into different modes, e.g., going from a mode with an object placed to another mode with the object grasped. To successfully find a manipulation plan, a planner must find a sequence of valid single-mode motions as well as valid transitions between these modes. Many manipulation planners have been proposed to solve tasks with multi-modal structure. However, these methods require mode-specific planners and fail to scale to very cluttered environments or to tasks that require long sequences of transitions. This paper presents a general layered planning approach to multi-modal planning that uses a discrete "lead" to bias search towards useful mode transitions. The difficulty of achieving specific mode transitions is captured online and used to bias search towards more promising sequences of modes. We demonstrate our planner on complex scenes and show that significant performance improvements are tied to both our discrete "lead" and our continuous representation.


Title: Hierarchical Coverage Path Planning in Complex 3D Environments
Key Words: autonomous aerial vehicles  hierarchical systems  image resolution  image sampling  mobile robots  path planning  robot vision  complex three-dimensional environment  nooks  crannies  coverage planning  multiresolution hierarchical framework  three-dimensional scenes  hierarchical coverage path planning  lightweight UAV  low-level sampling  complex 3D environments  Planning  Robot sensing systems  Cameras  Octrees  Three-dimensional displays  Surface treatment 
Abstract: State-of-the-art coverage planning methods perform well in simple environments but take an ineffectively long time to converge to an optimal solution in complex three-dimensional (3D) environments. As more structures are present in the same volume of workspace, these methods slow down as they spend more time searching for all of the nooks and crannies concealed in three-dimensional spaces. This work presents a method for coverage planning that employs a multi-resolution hierarchical framework to solve the problem at two different levels, producing much higher efficiency than the state-of-the-art. First, a high-level algorithm separates the environment into multiple subspaces at different resolutions and computes an order of the subspaces for traversal. Second, a low-level sampling-based algorithm solves for paths within the subspaces for detailed coverage. In experiments, we evaluate our method using real-world datasets from complex three-dimensional scenes. Our method finds paths that are constantly shorter and converges at least ten times faster than the state-of-the-art. Further, we show results of a physical experiment where a lightweight UAV follows the paths to realize the coverage.


Title: Distributed Consensus Control of Multiple UAVs in a Constrained Environment
Key Words: autonomous aerial vehicles  control system synthesis  decentralised control  distributed control  multi-robot systems  position control  tracking  trees (mathematics)  multiple UAVs  constrained environment  consensus problem  multiple unmanned aerial vehicles  environmental constraints  general communication topology  directed spanning tree  position transformation function  dynamic reference position  yaw angle  asymmetric topology  local tracking controller  distributed consensus control  Topology  Decentralized control  Protocols  Unmanned aerial vehicles  Tracking loops  Heuristic algorithms  Attitude control 
Abstract: In this paper, we investigate the consensus problem of multiple unmanned aerial vehicles (UAVs) in the presence of environmental constraints under a general communication topology containing a directed spanning tree. First, based on a position transformation function, we propose a novel dynamic reference position and yaw angle for each UAV to cope with both the asymmetric topology and the constraints. Then, the backstepping-like design methodology is presented to derive a local tracking controller for each UAV such that its position and yaw angle can converge to the reference ones. The proposed protocol is distributed in the sense that, the input update of each UAV dynamically relies only on local state information from its neighborhood set and the constraints, and it does not require any additional centralized information. It is demonstrated that under the proposed protocol, all UAVs reach consensus without violation of the environmental constraints. Finally, simulation and experimental results are provided to demonstrate the performance of the protocol.


Title: Neural-Swarm: Decentralized Close-Proximity Multirotor Control Using Learned Interactions
Key Words: aerodynamics  aerospace robotics  control system synthesis  decentralised control  learning (artificial intelligence)  multi-robot systems  neurocontrollers  nonlinear control systems  particle swarm optimisation  stability  close-proximity multirotor control  learned interactions  Neural-Swarm  nonlinear decentralized stable controller  close-proximity flight  multirotor swarms  close-proximity control  complex aerodynamic interaction effects  safety distances  nominal dynamics model  regularized permutation-invariant Deep Neural Network  high-order multivehicle interactions  larger swarm sizes  baseline nonlinear  stable nonlinear tracking controller  Vehicle dynamics  Aerodynamics  Neural networks  Rotors  Stability analysis  Training  Robots 
Abstract: In this paper, we present Neural-Swarm, a nonlinear decentralized stable controller for close-proximity flight of multirotor swarms. Close-proximity control is challenging due to the complex aerodynamic interaction effects between multirotors, such as downwash from higher vehicles to lower ones. Conventional methods often fail to properly capture these interaction effects, resulting in controllers that must maintain large safety distances between vehicles, and thus are not capable of close-proximity flight. Our approach combines a nominal dynamics model with a regularized permutation-invariant Deep Neural Network (DNN) that accurately learns the high-order multi-vehicle interactions. We design a stable nonlinear tracking controller using the learned model. Experimental results demonstrate that the proposed controller significantly outperforms a baseline nonlinear tracking controller with up to four times smaller worst-case height tracking errors. We also empirically demonstrate the ability of our learned model to generalize to larger swarm sizes.


Title: Line Coverage with Multiple Robots
Key Words: computational complexity  graph theory  integer programming  linear programming  mobile robots  multi-robot systems  path planning  robot tour generation  multiple robots  line coverage problem  mixed integer linear program  NP-hard  merge-embed-merge  MEM algorithm  graph simplification  graph partitioning  Roads  Task analysis  Robot sensing systems  Routing  Heuristic algorithms  Partitioning algorithms 
Abstract: The line coverage problem is the coverage of linear environment features (e.g., road networks, power lines), modeled as 1D segments, by one or more robots while respecting resource constraints (e.g., battery capacity, flight time) for each of the robots. The robots incur direction dependent costs and resource demands as they traverse the edges. We treat the line coverage problem as an optimization problem, with the total cost of the tours as the objective, by formulating it as a mixed integer linear program (MILP). The line coverage problem is NP-hard and hence we develop a heuristic algorithm, Merge-Embed-Merge (MEM). We compare it against the optimal MILP approach and a baseline heuristic algorithm, Extended Path Scanning. We show the MEM algorithm is fast and suitable for real-time applications. To tackle large-scale problems, our approach performs graph simplification and graph partitioning, followed by robot tour generation for each of the partitioned subgraphs. We demonstrate our approach on a large graph with 4,658 edges and 4,504 vertices that represents an urban region of about 16 sq. km. We compare the performance of the algorithms on several small road networks and experimentally demonstrate the approach using UAVs on the UNC Charlotte campus road network.


Title: Visual Coverage Maintenance for Quadcopters Using Nonsmooth Barrier Functions
Key Words: aircraft control  helicopters  image sensors  mobile robots  multi-robot systems  robot vision  quadcopters  visual sensors  coverage holes  coverage quality  sufficient conditions  nonsmooth barrier functions  visual coverage maintenance  coverage control  necessary conditions  Visualization  Monitoring  Robot sensing systems  Switches  Space missions 
Abstract: This paper presents a coverage control algorithm for teams of quadcopters with downward facing visual sensors that prevents the appearance of coverage holes in-between the monitored areas while maximizing the coverage quality as much as possible. We derive necessary and sufficient conditions for preventing the appearance of holes in-between the fields of views among trios of robots. Because this condition can be expressed as logically combined constraints, control nonsmooth barrier functions are implemented to enforce it. An algorithm which extends control nonsmooth barrier functions to hybrid systems is implemented to manage the switching among barrier functions caused by the changes of the robots composing trio. The performance and validity of the proposed algorithm are evaluated in simulation as well as on a team of quadcopters.


Title: Goal-Directed Occupancy Prediction for Lane-Following Actors
Key Words: mobile robots  motion estimation  prediction theory  road safety  road traffic  road vehicles  roads  robot vision  traffic engineering computing  complex road networks  mapped road topology  dynamic road actors  mapped lane geometry  mode collapse problem  goal-directed occupancy prediction  lane-following actors  shared roads  safe autonomous driving  possible vehicle behaviors  possible goal reasoning  local scene context multimodality  high-level action set  future spatial occupancy prediction  Roads  Predictive models  Trajectory  Topology  Geometry  Task analysis  Autonomous vehicles 
Abstract: Predicting the possible future behaviors of vehicles that drive on shared roads is a crucial task for safe autonomous driving. Many existing approaches to this problem strive to distill all possible vehicle behaviors into a simplified set of high-level actions. However, these action categories do not suffice to describe the full range of maneuvers possible in the complex road networks we encounter in the real world. To combat this deficiency, we propose a new method that leverages the mapped road topology to reason over possible goals and predict the future spatial occupancy of dynamic road actors. We show that our approach is able to accurately predict future occupancy that remains consistent with the mapped lane geometry and naturally captures multi-modality based on the local scene context while also not suffering from the mode collapse problem observed in prior work.


Title: Efficient Uncertainty-aware Decision-making for Automated Driving Using Guided Branching
Key Words: decision making  decision theory  Markov processes  multi-agent systems  road traffic  trees (mathematics)  dense traffic scenarios  automated vehicles  stochastic behaviors  traffic participants  perception uncertainties  partially observable Markov decision process  efficient uncertainty-aware decision-making  longitudinal behaviors  complex driving environments  automated driving  guided branching  domain-specific closed-loop policy tree structure  DCP-Tree  conditional focused branching mechanism  CFB  domain-specific expert knowledge  Planning  Decision making  Uncertainty  Semantics  Vegetation  Aerospace electronics  Safety 
Abstract: Decision-making in dense traffic scenarios is challenging for automated vehicles (AVs) due to potentially stochastic behaviors of other traffic participants and perception uncertainties (e.g., tracking noise and prediction errors, etc.). Although the partially observable Markov decision process (POMDP) provides a systematic way to incorporate these uncertainties, it quickly becomes computationally intractable when scaled to the real-world large-size problem. In this paper, we present an efficient uncertainty-aware decision-making (EUDM) framework, which generates long-term lateral and longitudinal behaviors in complex driving environments in real-time. The computation complexity is controlled to an appropriate level by two novel techniques, namely, the domain-specific closed-loop policy tree (DCP-Tree) structure and conditional focused branching (CFB) mechanism. The key idea is utilizing domain-specific expert knowledge to guide the branching in both action and intention space. The proposed framework is validated using both onboard sensing data captured by a real vehicle and an interactive multi-agent simulation platform. We also release the code of our framework to accommodate benchmarking.


Title: Hierarchical Multi-Process Fusion for Visual Place Recognition
Key Words: image fusion  mobile robots  object recognition  robot vision  hierarchical multiprocess fusion  multiple complementary techniques  visual localization  multisensor fusion  varying performance characteristics  hierarchical localization system  localization hypotheses  localization performance  final localization stage  parallel fusion  visual place recognition  Databases  Visualization  Feature extraction  Robots  Pipelines  Histograms 
Abstract: Combining multiple complementary techniques together has long been regarded as a way to improve performance. In visual localization, multi-sensor fusion, multi-process fusion of a single sensing modality, and even combinations of different localization techniques have been shown to result in improved performance. However, merely fusing together different localization techniques does not account for the varying performance characteristics of different localization techniques. In this paper we present a novel, hierarchical localization system that explicitly benefits from three varying characteristics of localization techniques: the distribution of their localization hypotheses, their appearance- and viewpointinvariant properties, and the resulting differences in where in an environment each system works well and fails. We show how two techniques deployed hierarchically work better than in parallel fusion, how combining two different techniques works better than two levels of a single technique, even when the single technique has superior individual performance, and develop two and three-tier hierarchical structures that progressively improve localization performance. Finally, we develop a stacked hierarchical framework where localization hypotheses from techniques with complementary characteristics are concatenated at each layer, significantly improving retention of the correct hypothesis through to the final localization stage. Using two challenging datasets, we show the proposed system outperforming state-of-the-art techniques.


Title: Vision-based Multi-MAV Localization with Anonymous Relative Measurements Using Coupled Probabilistic Data Association Filter
Key Words: aerospace robotics  microrobots  mobile robots  multi-robot systems  pose estimation  probability  robot vision  SLAM (robots)  target tracking  multiMAV system  robot team  vision based detection  distance measurements  coupled probabilistic data association filter  nonlinear measurements  visual based robot to robot detection  vision based multiMAV localization  robot localization  robot pose estimation  multiple microaerial vehicles  Robot kinematics  Robot sensing systems  Noise measurement  Probabilistic logic  Task analysis  Cameras 
Abstract: We address the localization of robots in a multi-MAV system where external infrastructure like GPS or motion capture systems may not be available. Our approach lends itself to implementation on platforms with several constraints on size, weight, and power (SWaP). Particularly, our framework fuses the onboard VIO with the anonymous, visual-based robot-to-robot detection to estimate all robot poses in one common frame, addressing three main challenges: 1) the initial configuration of the robot team is unknown, 2) the data association between each vision-based detection and robot targets is unknown, and 3) the vision-based detection yields false negatives, false positives, inaccurate, and provides noisy bearing, distance measurements of other robots. Our approach extends the Coupled Probabilistic Data Association Filter [1] to cope with nonlinear measurements. We demonstrate the superior performance of our approach over a simple VIO-based method in a simulation with the measurement models statistically modeled using the real experimental data. We also show how onboard sensing, estimation, and control can be used for formation flight.


Title: MANGA: Method Agnostic Neural-policy Generalization and Adaptation
Key Words: learning (artificial intelligence)  robot dynamics  MANGA  multiple environments  dynamics parameters  motor noise variations  policy learning  system identification  unknown environment  dynamics configurations  dynamics conditioned policies  off-policy state-transition rollouts  training method  method agnostic neural-policy generalization and adaptation  transferring policies  Training  Robots  Task analysis  Encoding  Decoding  Heuristic algorithms  Adaptation models 
Abstract: In this paper we target the problem of transferring policies across multiple environments with different dynamics parameters and motor noise variations, by introducing a framework that decouples the processes of policy learning and system identification. Efficiently transferring learned policies to an unknown environment with changes in dynamics configurations in the presence of motor noise is very important for operating robots in the real world, and our work is a novel attempt in that direction. We introduce MANGA: Method Agnostic Neural-policy Generalization and Adaptation, that trains dynamics conditioned policies and efficiently learns to estimate the dynamics parameters of the environment given off-policy state-transition rollouts in the environment. Our scheme is agnostic to the type of training method used - both reinforcement learning (RL) and imitation learning (IL) strategies can be used. We demonstrate the effectiveness of our approach by experimenting with four different MuJoCo agents and comparing against previously proposed transfer baselines.


Title: Variational Inference with Mixture Model Approximation for Applications in Robotics
Key Words: approximation theory  Bayes methods  control engineering computing  inference mechanisms  mixture models  robots  statistical distributions  variational inference  mixture model approximation  robot configurations  Bayesian computation  Robots  Mixture models  Kinematics  Bayes methods  Optimization  Task analysis  Planning 
Abstract: We propose to formulate the problem of representing a distribution of robot configurations (e.g. joint angles) as that of approximating a product of experts. Our approach uses variational inference, a popular method in Bayesian computation, which has several practical advantages over sampling-based techniques. To be able to represent complex and multimodal distributions of configurations, mixture models are used as approximate distribution. We show that the problem of approximating a distribution of robot configurations while satisfying multiple objectives arises in a wide range of problems in robotics, for which the properties of the proposed approach have relevant consequences. Several applications are discussed, including learning objectives from demonstration, planning, and warm-starting inverse kinematics problems. Simulated experiments are presented with a 7-DoF Panda arm and a 28-DoF Talos humanoid.


Title: Injection of a Fluorescent Microsensor into a Specific Cell by Laser Manipulation and Heating with Multiple Wavelengths of Light
Key Words: biomedical optical imaging  cellular biophysics  dyes  fluorescence  infrared spectra  kidney  microsensors  refractive index  Rhodamine B  temperature-sensitive fluorescent dye  refractive index  polystyrene particle  cell injection  laser manipulation  multiple wavelengths  fluorescent microsensor  Microsensors  Fluorescence  Semiconductor lasers  Heating systems  Measurement by laser beam  Laser excitation  Temperature measurement 
Abstract: In this study, we propose the manipulation and cell injection of a fluorescent microsensor using multiple wavelengths of light. The fluorescent microsensor is made of a 1-μm polystyrene particle containing infrared (IR: 808 nm) absorbing dye and Rhodamine B. The polystyrene particle can be manipulated in water using a 1064-nm laser because the refractive index of the polystyrene is 1.6 (refractive index of water: 1.3). The IR absorbing dye absorbs 808-nm light but does not absorb the 1064-nm laser. Rhodamine B is a temperature-sensitive fluorescent dye (excitation wavelength: 488 nm, emission wavelength: 560 nm). The functions of manipulation, heating for injection, and temperature measurement are achieved by different wavelengths of 1064 nm, 808 nm, and 488 nm, respectively. The temperature increase of fluorescent microsensor with 808-nm (40 mW, 10 s) laser was approximately 15°C, and enough for injection of fluorescent microsensor. We demonstrated manipulation and injection of the microsensor into Madin-Darby canine kidney cell using 1064-nm and 808-nm lasers. These results confirmed the effectiveness of our proposed cell injection of a fluorescent microsensor using multiple wavelengths of light.


Title: Correspondence Identification in Collaborative Robot Perception through Maximin Hypergraph Matching
Key Words: concave programming  graph theory  image matching  image representation  multi-robot systems  object detection  robot vision  collaborative multirobot perception  nonconvex noncontinuous optimization problem  multirobot coordination  collaborative robot perception  hypergraph matching approach  Collaboration  Robot kinematics  Object recognition  Optimization  Robot sensing systems  Robustness 
Abstract: Correspondence identification is an essential problem for collaborative multi-robot perception, with the objective of deciding the correspondence of objects that are observed in the field of view of each robot. In this paper, we introduce a novel maximin hypergraph matching approach that formulates correspondence identification as a hypergraph matching problem. The proposed approach incorporates both spatial relationships and appearance features of objects to improve representation capabilities. It also integrates the maximin theorem to optimize the worst-case scenario in order to address distractions caused by non-covisible objects. In addition, we design an optimization algorithm to address the formulated non-convex non-continuous optimization problem. We evaluate our approach and compare it with seven previous techniques in two application scenarios, including multi-robot coordination on real robots and connected autonomous driving in simulations. Experimental results have validated the effectiveness of our approach in identifying object correspondence from partially overlapped views in collaborative perception, and have shown that the proposed maximin hypergraph matching approach outperforms previous techniques and obtains state-of-the-art performance.


Title: Distributed Multi-Target Tracking for Autonomous Vehicle Fleets
Key Words: cameras  Kalman filters  maximum likelihood estimation  target tracking  vehicular ad hoc networks  wireless sensor networks  Consensus Kalman Filter  fixed communication bandwidth  high fidelity urban driving simulator  autonomous cars  time-varying communication network  distributed multitarget tracking  autonomous vehicle fleets  scalable distributed target tracking algorithm  alternating direction method of multipliers  vehicle-to-vehicle network  sensing vehicle  Kalman filter-like update  centralized maximum a posteriori estimate  CARLA  on-board cameras  Sensors  Target tracking  Kalman filters  Microsoft Windows  Estimation  Trajectory  Optimization 
Abstract: We present a scalable distributed target tracking algorithm based on the alternating direction method of multipliers that is well-suited for a fleet of autonomous cars communicating over a vehicle-to-vehicle network. Each sensing vehicle communicates with its neighbors to execute iterations of a Kalman filter-like update such that each agent's estimate approximates the centralized maximum a posteriori estimate without requiring the communication of measurements. We show that our method outperforms the Consensus Kalman Filter in recovering the centralized estimate given a fixed communication bandwidth. We also demonstrate the algorithm in a high fidelity urban driving simulator (CARLA), in which 50 autonomous cars connected on a time-varying communication network track the positions and velocities of 50 target vehicles using on-board cameras.


Title: Flying batteries: In-flight battery switching to increase multirotor flight time
Key Words: aerospace control  helicopters  mobile robots  secondary cells  in-flight battery switching  multirotor flight time  mid-air docking  primary battery  quadcopter flight  docking platform  flying battery  secondary battery  arbitrary switching  Batteries  Switches  Legged locomotion  Switching circuits  Aerodynamics  Connectors  Propellers 
Abstract: We present a novel approach to increase the flight time of a multirotor via mid-air docking and in-flight battery switching. A main quadcopter flying using a primary battery has a docking platform attached to it. A `flying battery' - a small quadcopter carrying a secondary battery - is equipped with docking legs that can mate with the main quadcopter's platform. Connectors between the legs and the platform establish electrical contact on docking, and enable power transfer from the secondary battery to the main quadcopter. A custom-designed circuit allows arbitrary switching between the primary battery and secondary battery. We demonstrate the concept in a flight experiment involving repeated docking, battery switching, and undocking. This is shown in the video attachment. The experiment increases the flight time of the main quadcopter by a factor of 4.7× compared to solo flight, and 2.2× a theoretical limit for that given multirotor. Importantly, this increase in flight time is not associated with a large increase in overall vehicle mass or size, leaving the main quadcopter in fundamentally the same safety class.


Title: PointNet++ Grasping: Learning An End-to-end Spatial Grasp Generation Algorithm from Sparse Point Clouds
Key Words: edge detection  feature extraction  image annotation  image colour analysis  learning (artificial intelligence)  manipulators  neural nets  robot vision  PointNet++ grasping  sparse point clouds  robot manipulation  local feature extractor  deep learning  multiobject scene  multiobject dataset  grasp generation algorithm  multiobject grasp detection algorithm  Ferrari-Canny metrics  PointNet++ based network  Three-dimensional displays  Feature extraction  Grasping  Measurement  Training  Cameras  Pipelines 
Abstract: Grasping for novel objects is important for robot manipulation in unstructured environments. Most of current works require a grasp sampling process to obtain grasp candidates, combined with local feature extractor using deep learning. This pipeline is time-costly, expecially when grasp points are sparse such as at the edge of a bowl.In this paper, we propose an end-to-end approach to directly predict the poses, categories and scores (qualities) of all the grasps. It takes the whole sparse point clouds as the input and requires no sampling or search process. Moreover, to generate training data of multi-object scene, we propose a fast multi-object grasp detection algorithm based on Ferrari Canny metrics. A single-object dataset (79 objects from YCB object set, 23.7k grasps) and a multi-object dataset (20k point clouds with annotations and masks) are generated. A PointNet++ based network combined with multi-mask loss is introduced to deal with different training points. The whole weight size of our network is only about 11.6M, which takes about 102ms for a whole prediction process using a GeForce 840M GPU. Our experiment shows our work get 71.43% success rate and 91.60% completion rate, which performs better than current state-of-art works.


Title: YCB-M: A Multi-Camera RGB-D Dataset for Object Recognition and 6DoF Pose Estimation
Key Words: cameras  feature extraction  image colour analysis  image segmentation  object detection  object recognition  pose estimation  stereo image processing  2D bounding boxes  3D cameras  YCB-M  multicamera RGB-D dataset  estimation system  object recognition  3D bounding boxes  ground truth 6DoF poses  YCB object  camera model  robust algorithms  estimation algorithms  6DoF pose estimation  Cameras  Robot vision systems  Three-dimensional displays  Pose estimation  Two dimensional displays 
Abstract: While a great variety of 3D cameras have been introduced in recent years, most publicly available datasets for object recognition and pose estimation focus on one single camera. In this work, we present a dataset of 32 scenes that have been captured by 7 different 3D cameras, totaling 49,294 frames. This allows evaluating the sensitivity of pose estimation algorithms to the specifics of the used camera and the development of more robust algorithms that are more independent of the camera model. Vice versa, our dataset enables researchers to perform a quantitative comparison of the data from several different cameras and depth sensing technologies and evaluate their algorithms before selecting a camera for their specific task. The scenes in our dataset contain 20 different objects from the common benchmark YCB object and model set [1], [2]. We provide full ground truth 6DoF poses for each object, per-pixel segmentation, 2D and 3D bounding boxes and a measure of the amount of occlusion of each object. We have also performed an initial evaluation of the cameras using our dataset on a state-of-the-art object recognition and pose estimation system [3].


Title: Evaluation of Non-collocated Force Feedback Driven by Signal-independent Noise
Key Words: brain-computer interfaces  feedback  force feedback  haptic interfaces  medical computing  neurophysiology  prosthetics  exploratory action  conventional haptic interface  iBCI-based prostheses control strategies  neural prostheses  intracortical brain computer interface  input signal  robotic prostheses  paralysis  signal-independent noise  noncollocated force feedback  signal-to-noise ratio  virtual environment  noncollocated haptic feedback  Force  Haptic interfaces  Task analysis  Noise measurement  Virtual environments  Signal to noise ratio  Probes 
Abstract: Individuals living with paralysis or amputation can operate robotic prostheses using input signals based on their intent or attempt to move. Because sensory function is lost or diminished in these individuals, haptic feedback must be non-collocated. The intracortical brain computer interface (iBCI) has enabled a variety of neural prostheses for people with paralysis. An important attribute of the iBCI is that its input signal contains signal-independent noise. To understand the effects of signal-independent noise on a system with non-collocated haptic feedback and inform iBCI-based prostheses control strategies, we conducted an experiment with a conventional haptic interface as a proxy for the iBCI. Ablebodied users were tasked with locating an indentation within a virtual environment using input from their right hand. Non-collocated haptic feedback of the interaction forces in the virtual environment was augmented with noise of three different magnitudes and simultaneously rendered on users' left hands. We found increases in distance error of the guess of the indentation location, mean time per trial, mean peak absolute displacement and speed of tool movements during localization for the highest noise level compared to the other two levels. The findings suggest that users have a threshold of disturbance rejection and that they attempt to increase their signal-to-noise ratio through their exploratory actions.


Title: Highly Robust Visual Place Recognition Through Spatial Matching of CNN Features
Key Words: convolutional neural nets  image coding  image matching  image resolution  visual databases  image resolution  VGG16 CNN architecture  matching CNN features  query image  VGG16 Convolutional Neural Network architecture  Spatial Matching Visual Place Recognition  SSM-VPR  optimal image resolutions  Visualization  Robustness  Semantics  Task analysis  Histograms  Correlation  Simultaneous localization and mapping  Visual Place Recognition  Convolutional Neural Networks  SLAM  Loop Closure  Life-long Navigation 
Abstract: We revise, improve and extend the system previously introduced by us and named SSM-VPR (Semantic and Spatial Matching Visual Place Recognition), largely boosting its performance above the current state of the art. The system encodes images of places by employing the activations of different layers of a pre-trained, off-the-shelf, VGG16 Convolutional Neural Network (CNN) architecture. It consists of two stages: given a query image of a place, (1) a list of candidates is selected from a database of places and (2) the candidates are geometrically compared with the query. The comparison is made by matching CNN features and, equally important, their spatial locations, selecting the best candidate as the recognized place. The performance of the system is maximized by finding optimal image resolutions during the second stage and by exploiting temporal correlation between consecutive frames in the employed datasets.


Title: Decentralized Task Allocation in Multi-Agent Systems Using a Decentralized Genetic Algorithm
Key Words: genetic algorithms  multi-agent systems  min-time objective  decentralized GA approach  task execution  multiagent collaborative search missions  decentralized genetic algorithm  multiagent systems  decentralized task allocation problem  decentralized evolutionary approaches  min-time performance  min-sum objective  Task analysis  Resource management  Genetic algorithms  Sociology  Statistics  Cost function  Message systems 
Abstract: In multi-agent collaborative search missions, task allocation is required to determine which agents will perform which tasks. We propose a new approach for decentralized task allocation based on a decentralized genetic algorithm (GA). The approach parallelizes a genetic algorithm across the team of agents, making efficient use of their computational resources. In the proposed approach, the agents continuously search for and share better solutions during task execution. We conducted simulation experiments to compare the decentralized GA approach and several existing approaches. Two objectives were considered: a min-sum objective (minimizing the total distance traveled by all agents) and a min-time objective (minimizing the time to visit all locations of interest). The results showed that the decentralized GA approach yielded task allocations that were better on the min-time objective than those created by existing approaches and solutions that were reasonable on the min-sum objective. The decentralized GA improved min-time performance by an average of 5.6% on the larger instances. The results indicate that decentralized evolutionary approaches have a strong potential for solving the decentralized task allocation problem.


Title: Simultaneous Estimations of Joint Angle and Torque in Interactions with Environments using EMG
Key Words: biomechanics  decoding  electromyography  medical signal processing  muscle  time series  decoding method  LSTM network  decoding approach  wrist joint  long-time span  time series  core processor  short-term memory network  electromyography  decoding technique  joint angle  learning EMG signals  Electromyography  Torque  Decoding  Wrist  Logic gates  Neural networks  Kinematics  Human-machine interaction  Electromyography (EMG)  Decoding  Machine learning  Prosthesis 
Abstract: We develop a decoding technique that estimates both the position and torque of a joint of the limb in interaction with an environment based on activities of the agonist-antagonist pair of muscles using electromyography in real time. The long short-term memory (LSTM) network is employed as the core processor of the proposed technique that is capable of learning time series of a long-time span with varying time lags. A validation that is conducted on the wrist joint shows that the decoding approach provides an agreement of greater than 95% in kinetics (i.e. torque) estimation and an agreement of greater than 85% in kinematics (i.e. angle) estimation, between the actual and estimated variables, during interactions with an environment. Also demonstrated is the fact that the proposed decoding method inherits the strengths of the LSTM network in terms of the capability of learning EMG signals and the corresponding responses with time dependency.


Title: Real-Time Adaptive Assembly Scheduling in Human-Multi-Robot Collaboration According to Human Capability*
Key Words: assembling  genetic algorithms  multi-agent systems  multi-robot systems  robotic assembly  scheduling  human-multirobot collaboration  human capability  optimal assembly scheduling  robot adaptation  human-single-robot interaction  human-multirobot interaction  multiagent interactions  real-time adaptive assembly scheduling approach  formulated adaptive assembly scheduling problem  human-multirobot assembly tasks  Robots  Job shop scheduling  Task analysis  Real-time systems  Schedules  Adaptive scheduling  Adaptation models 
Abstract: Human-multi-robot collaboration is becoming more and more common in intelligent manufacturing. Optimal assembly scheduling of such systems plays a critical role in their production efficiency. Existing approaches mostly consider humans as agents with assumed or known capabilities, which leads to suboptimal performance in realistic applications where human capabilities usually change. In addition, most robot adaptation focuses on human-single-robot interaction and the adaptation in human-multi-robot interaction with changing human capability still remains challenging due to the complexity of the heterogeneous multi-agent interactions. This paper proposes a real-time adaptive assembly scheduling approach for human-multi-robot collaboration by modeling and incorporating changing human capability. A genetic algorithm is also designed to derive implementable solutions for the formulated adaptive assembly scheduling problem. The proposed approaches are validated through different simulated human-multi-robot assembly tasks and the results demonstrate the effectiveness and advantages of the proposed approaches.


Title: Microscope-Guided Autonomous Clear Corneal Incision
Key Words: eye  medical computing  medical robotics  ophthalmic lenses  surgery  ex-vivo porcine eyes  microscope-guided autonomous clear corneal incision  ophthalmic microscope system  multiaxes robot  self-sealing incision  autonomous robotic system  cataract surgery  Robots  Surgery  Feature extraction  Iris  Cameras  Mirrors  Cataracts 
Abstract: Clear Corneal Incision, a challenging step in cataract surgery, and important to the overall quality of the surgery. New surgeons usually spend one full year trying to perfect their incision, but even after such rigorous training deficient incisions can still occur. This paper proposes an autonomous robotic system for this self-sealing incision. A conventional ophthalmic microscope system with a monocular camera is utilized to capture the surgical scene, ascertain the robot's position, and estimate depth information. Kinematics with a remote centre of motion (RCM) is designed for a multi-axes robot to perform the incision route. The experimental results on ex-vivo porcine eyes show the autonomous Clear Corneal Incision has a stricter three-plane structure than a surgeon-made incision, which is closer to the ideal incision.


Title: Mechanics for Tendon Actuated Multisection Continuum Arms
Key Words: actuators  bending  biomechanics  inspection  medical robotics  robot kinematics  tendon actuated multisection continuum arms  bending deformations  high mechanical coupling  variable length-based kinematic models  continuum arm curve parameter kinematics  robot  Tendons  Robots  Computational modeling  Strain  Numerical models  Kinematics  Deformable models 
Abstract: Tendon actuated multisection continuum arms have high potential for inspection applications in highly constrained spaces. They generate motion by axial and bending deformations. However, because of the high mechanical coupling between continuum sections, variable length-based kinematic models produce poor results. A new mechanics model for tendon actuated multisection continuum arms is proposed in this paper. The model combines the continuum arm curve parameter kinematics and concentric tube kinematics to correctly account for the large axial and bending deformations observed in the robot. Also, the model is computationally efficient and utilizes tendon tensions as the joint space variables thus eliminating the actuator length related problems such as slack and backlash. A recursive generalization of the model is also presented. Despite the high coupling between continuum sections, numerical results show that the model can be used for generating correct forward and inverse kinematic results. The model is then tested on a thin and long multisection continuum arm. The results show that the model can be used to successfully model the deformation.


Title: Trajectory Optimization for a Six-DOF Cable-Suspended Parallel Robot with Dynamic Motions Beyond the Static Workspace
Key Words: cables (mechanical)  manipulator dynamics  optimisation  path planning  position control  trajectory control  cable-suspended parallel robot  static workspace  trajectory optimization formulation  dynamic trajectories  six-degree-of-freedom  low-dimensional dynamic models  narrow feasible state space  dynamic similarity  point-mass CSPR  feasible force polyhedra  transition trajectories  highly dynamic motions  periodic trajectories  Dynamics  Planning  Robots  Trajectory optimization  Chebyshev approximation  Dynamic trajectory planning  optimization and optimal control  cable-suspended parallel robots 
Abstract: This paper presents a trajectory optimization formulation for planning dynamic trajectories of a six-degree-of-freedom (six-DOF) cable-suspended parallel robot (CSPR) that extend beyond the static workspace. The optimization is guided by low-dimensional dynamic models to overcome the local minima and accelerate the exploration of the narrow feasible state space. The dynamic similarity between the six-DOF CSPR and the three-DOF point-mass CSPR is discussed with the analyses of their feasible force polyhedra. Finally, the transition trajectories of a three-DOF CSPR are used as the initial guess of the translational part of the six-DOF motion. With the proposed approach, highly dynamic motions for a six-DOF CSPR are efficiently generated with multiple oscillations. The feasibility is demonstrated by point-to-point and periodic trajectories in the physics simulation.


Title: Singularity-Free Inverse Dynamics for Underactuated Systems with a Rotating Mass
Key Words: manipulator dynamics  matrix algebra  motion control  nonlinear control systems  path planning  position control  singularity-free inverse dynamics  underactuated system  rotating mass  motion control  configuration singularities  configuration space  inertial coupling  small-amplitude sine wave  nonlinear dynamics  rolling system  singularity regions  coupling singularities  rolling carrier  Mathematical model  Couplings  Integrated circuits  Trajectory  Kinematics  Robots  Tensile stress 
Abstract: Motion control of underactuated systems through the inverse dynamics contains configuration singularities. These limitations in configuration space mainly stem from the inertial coupling that passive joints/bodies create. In this study, we present a model that is free from singularity while the trajectory of the rotating mass has a small-amplitude sine wave around its circle. First, we derive the modified non-linear dynamics for a rolling system. Also, the singularity regions for this underactuated system is demonstrated. Then, the wave parameters are designed under certain conditions to remove the coupling singularities. We obtain these conditions from the positive definiteness of the inertia matrix in the inverse dynamics. Finally, the simulation results are confirmed by using a prescribed Beta function on the specified states of the rolling carrier. Because our algebraic method is integrated into the non-linear dynamics, the proposed solution has a great potential to be extended to the Lagrangian mechanics with multiple degrees-of-freedom.


Title: SUMMIT: A Simulator for Urban Driving in Massive Mixed Traffic
Key Words: control engineering computing  multi-agent systems  road traffic  road vehicles  telecommunication traffic  traffic engineering computing  SUMMIT  urban driving  massive mixed traffic  unregulated urban crowd  high-speed traffic participants  high-fidelity simulator  crowd-driving algorithms  open-source OpenStreetMap map database  multiagent motion prediction model  unregulated urban traffic  heterogeneous agents  autonomous driving simulation  realistic traffic behaviors  crowd-driving settings  Roads  Robot sensing systems  Context modeling  Planning  Automobiles  Geometry  Kinematics 
Abstract: Autonomous driving in an unregulated urban crowd is an outstanding challenge, especially, in the presence of many aggressive, high-speed traffic participants. This paper presents SUMMIT, a high-fidelity simulator that facilitates the development and testing of crowd-driving algorithms. By leveraging the open-source OpenStreetMap map database and a heterogeneous multi-agent motion prediction model developed in our earlier work, SUMMIT simulates dense, unregulated urban traffic for heterogeneous agents at any worldwide locations that OpenStreetMap supports. SUMMIT is built as an extension of CARLA and inherits from it the physics and visual realism for autonomous driving simulation. SUMMIT supports a wide range of applications, including perception, vehicle control and planning, and end-to-end learning. We provide a context-aware planner together with benchmark scenarios and show that SUMMIT generates complex, realistic traffic behaviors in challenging crowd-driving settings.


Title: A Model-Based Reinforcement Learning and Correction Framework for Process Control of Robotic Wire Arc Additive Manufacturing
Key Words: learning (artificial intelligence)  process control  rapid prototyping (industrial)  robotic welding  three-dimensional printing  welds  wires  integrated learning-correction framework  model-based reinforcement learning  process parameters  inter-layer geometric digression  process control  robot arm  3D metallic objects  layer by layer fashion  multilayer multibead deposition control  robotic wire arc additive manufacturing  weld beads  error stacking  material wastage reduction  MLMB print  Training  Predictive models  Process control  Adaptation models  Printing  Robots  Three-dimensional displays 
Abstract: Robotic Wire Arc Additive Manufacturing (WAAM) utilizes a robot arm as a motion system to build 3D metallic objects by depositing weld beads one above the other in a layer by layer fashion. A key part of this approach is the process study and control of Multi-Layer Multi-Bead (MLMB) deposition, which is very sensitive to process parameters and prone to error stacking. Despite its importance, it has been receiving less attention than its single bead counterpart in literature, probably due to the higher experimental overhead and complexity of modeling. To address these challenges, this paper proposes an integrated learning-correction framework, adapted from Model-Based Reinforcement Learning, to iteratively learn the direct effect of process parameters on MLMB print while simultaneously correct for any inter-layer geometric digression such that the final output is still satisfactory. The advantage is that this learning architecture can be used in conjunction with actual parts printing (hence, in-situ study), thus minimizing the required training time and material wastage. The proposed learning framework is implemented on an actual robotic WAAM system and experimentally evaluated.


Title: Towards Practical Multi-Object Manipulation using Relational Reinforcement Learning
Key Words: graph theory  learning (artificial intelligence)  manipulators  mobile robots  neural nets  multiobject manipulation  relational reinforcement learning  learning robotic manipulation tasks  outrageous data requirements  task curriculum  graph-based relational architectures  simulated block stacking task  step-wise sparse rewards  zero-shot generalization  Task analysis  Stacking  Robots  Learning (artificial intelligence)  Poles and towers  Training  Three-dimensional displays 
Abstract: Learning robotic manipulation tasks using reinforcement learning with sparse rewards is currently impractical due to the outrageous data requirements. Many practical tasks require manipulation of multiple objects, and the complexity of such tasks increases with the number of objects. Learning from a curriculum of increasingly complex tasks appears to be a natural solution, but unfortunately, does not work for many scenarios. We hypothesize that the inability of the state- of-the-art algorithms to effectively utilize a task curriculum stems from the absence of inductive biases for transferring knowledge from simpler to complex tasks. We show that graph-based relational architectures overcome this limitation and enable learning of complex tasks when provided with a simple curriculum of tasks with increasing numbers of objects. We demonstrate the utility of our framework on a simulated block stacking task. Starting from scratch, our agent learns to stack six blocks into a tower. Despite using step-wise sparse rewards, our method is orders of magnitude more data- efficient and outperforms the existing state-of-the-art method that utilizes human demonstrations. Furthermore, the learned policy exhibits zero-shot generalization, successfully stacking blocks into taller towers and previously unseen configurations such as pyramids, without any further training.


Title: SwarmMesh: A Distributed Data Structure for Cooperative Multi-Robot Applications
Key Words: control engineering computing  data handling  data structures  distributed processing  mobile robots  multi-robot systems  storage management  topology  data item position  near-perfect data retention  distributed data structure  cooperative multirobot applications  distributed storage  mobile robots  shared global memory  external storage infrastructure  swarm topology  data storage  SwarmMesh  data type  Robots  Data structures  Peer-to-peer computing  Overlay networks  Routing  Distributed databases  Topology 
Abstract: We present an approach to the distributed storage of data across a swarm of mobile robots that forms a shared global memory. We assume that external storage infrastructure is absent, and that each robot is capable of devoting a quota of memory and bandwidth to distributed storage. Our approach is motivated by the insight that in many applications data is collected at the periphery of a swarm topology, but the periphery also happens to be the most dangerous location for storing data, especially in exploration missions. Our approach is designed to promote data storage in the locations in the swarm that best suit a specific feature of interest in the data, while accounting for the constantly changing topology due to individual motion. We analyze two possible features of interest: the data type and the data item position in the environment. We assess the performance of our approach in a large set of simulated experiments. The evaluation shows that our approach is capable of storing quantities of data that exceed the memory of individual robots, while maintaining near-perfect data retention in high-load conditions.


Title: Avalanche victim search via robust observers
Key Words: adaptive control  autonomous aerial vehicles  emergency management  multi-robot systems  observers  rescue robots  robust control  sensor fusion  avalanche victim search  robust observers  victim localization  ARVA sensor  adaptive control  UAVs  least square identifier  Receivers  Transmitters  Drones  Observers  Trajectory  Electromagnetics  Adaptive control  Search and Rescue  Robust Control 
Abstract: This paper introduces a new approach for victim localization in avalanches that will be exploited by UAVs using the ARVA sensor. We show that the nominal ARVA measurement can be linearly related to a quantity that is sufficient to reconstruct the victim position. We explicitly deal with a robust scenario in which the measurement is actually perturbed by a noise that grows with the distance to the victim and we propose an adaptive control scheme made of a least-square identifier and a trajectory generator whose role is both to guarantee the persistence of excitation for the identifier and to steer the ARVA receiver towards the victim. We show that the system succeeds in localizing the victim in a domain where the ARVA output is sufficiently informative and illustrate its performance in simulation. This new approach could significantly reduce the searching time by providing an exploitable estimate before having reached the victim. The work is framed within the EU project AirBorne whose goals is to develop at TRL8 a drone for quick localization of victims in avalanche scenarios.


Title: Online LiDAR-SLAM for Legged Robots with Robust Registration and Deep-Learned Loop Closure
Key Words: feature extraction  graph theory  image matching  image registration  image segmentation  learning (artificial intelligence)  legged locomotion  neural nets  optical radar  optimisation  pose estimation  robot vision  SLAM (robots)  stereo image processing  online LiDAR-SLAM  legged robot  robust registration  deep-learned loop closure  3D factor-graph LiDAR-SLAM system  industrial environments  point clouds  inertial-kinematic state estimator  ICP registration  loop proposal mechanism  deep learning method  odometry  loop closure factors  pose graph optimization  SLAM map  risk alignment prediction method  deeply learned feature-based loop closure detector  Laser radar  Legged locomotion  Three-dimensional displays  Simultaneous localization and mapping  Iterative closest point algorithm 
Abstract: In this paper, we present a 3D factor-graph LiDAR-SLAM system which incorporates a state-of-the-art deeply learned feature-based loop closure detector to enable a legged robot to localize and map in industrial environments. Point clouds are accumulated using an inertial-kinematic state estimator before being aligned using ICP registration. To close loops we use a loop proposal mechanism which matches individual segments between clouds. We trained a descriptor offline to match these segments. The efficiency of our method comes from carefully designing the network architecture to minimize the number of parameters such that this deep learning method can be deployed in real-time using only the CPU of a legged robot, a major contribution of this work. The set of odometry and loop closure factors are updated using pose graph optimization. Finally we present an efficient risk alignment prediction method which verifies the reliability of the registrations. Experimental results at an industrial facility demonstrated the robustness and flexibility of our system, including autonomous following paths derived from the SLAM map.


Title: Voxel Map for Visual SLAM
Key Words: computer vision  feature extraction  image representation  image retrieval  SLAM (robots)  visual SLAM systems  camera field-of-view  voxel map representation  keyframe map  map points retrieval  simultaneous localization and mapping  Simultaneous localization and mapping  Three-dimensional displays  Cameras  Visualization  Cognition  Feature extraction  Task analysis 
Abstract: In modern visual SLAM systems, it is a standard practice to retrieve potential candidate map points from overlapping keyframes for further feature matching or direct tracking. In this work, we argue that keyframes are not the optimal choice for this task, due to several inherent limitations, such as weak geometric reasoning and poor scalability. We propose a voxel-map representation to efficiently retrieve map points for visual SLAM. In particular, we organize the map points in a regular voxel grid. Visible points from a camera pose are queried by sampling the camera frustum in a raycasting manner, which can be done in constant time using an efficient voxel hashing method. Compared with keyframes, the retrieved points using our method are geometrically guaranteed to fall in the camera field-of-view, and occluded points can be identified and removed to a certain extend. This method also naturally scales up to large scenes and complicated multi-camera configurations. Experimental results show that our voxel map representation is as efficient as a keyframe map with 5 keyframes and provides significantly higher localization accuracy (average 46% improvement in RMSE) on the EuRoC dataset. The proposed voxel-map representation is a general approach to a fundamental functionality in visual SLAM and widely applicable.


Title: Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video
Key Words: interactive video  learning (artificial intelligence)  robot vision  video signal processing  adversarial skill-transfer loss  task domain  learned skill embeddings  entropy-regularized adversarial skill-transfer loss  temporal video coherence  metric learning loss  adversarial loss  task context  unlabeled multiview videos  task-agnostic skill embedding space  reinforcement learning agents  unsupervised robot skill learning  adversarial skill networks  learned embedding  Task analysis  Entropy  Measurement  Training  Robots  Interpolation  Learning (artificial intelligence) 
Abstract: Key challenges for the deployment of reinforcement learning (RL) agents in the real world are the discovery, representation and reuse of skills in the absence of a reward function. To this end, we propose a novel approach to learn a task-agnostic skill embedding space from unlabeled multi-view videos. Our method learns a general skill embedding independently from the task context by using an adversarial loss. We combine a metric learning loss, which utilizes temporal video coherence to learn a state representation, with an entropy-regularized adversarial skill-transfer loss. The metric learning loss learns a disentangled representation by attracting simultaneous viewpoints of the same observations and repelling visually similar frames from temporal neighbors. The adversarial skill-transfer loss enhances re-usability of learned skill embeddings over multiple task domains. We show that the learned embedding enables training of continuous control policies to solve novel tasks that require the interpolation of previously seen skills. Our extensive evaluation with both simulation and real world data demonstrates the effectiveness of our method in learning transferable skills from unlabeled interaction videos and composing them for new tasks. Code, pretrained models and dataset are available at http://robotskills.cs.uni-freiburg.de.


Title: ACDER: Augmented Curiosity-Driven Experience Replay
Key Words: augmented reality  control engineering computing  learning (artificial intelligence)  learning systems  manipulators  augmented curiosity-driven experience replay  hindsight experience replay  sample-efficiency  automatic exploratory curriculum  dynamic initial states selection  task-relevant states  goal-oriented curiosity-driven exploration  action space  high dimensional continuous state  low exploration efficiency  RL agent  reinforcement learning  sparse feed-back  ACDER  multistep robotic task learning  basic tasks  challenging robotic manipulation tasks  valuable states  Task analysis  Robots  Learning (artificial intelligence)  Training  Incentive schemes  Buffer storage  Games 
Abstract: Exploration in environments with sparse feed-back remains a challenging research problem in reinforcement learning (RL). When the RL agent explores the environment randomly, it results in low exploration efficiency, especially in robotic manipulation tasks with high dimensional continuous state and action space. In this paper, we propose a novel method, called Augmented Curiosity-Driven Experience Replay (ACDER), which leverages (i) a new goal-oriented curiosity-driven exploration to encourage the agent to pursue novel and task-relevant states more purposefully and (ii) the dynamic initial states selection as an automatic exploratory curriculum to further improve the sample-efficiency. Our approach complements Hindsight Experience Replay (HER) by introducing a new way to pursue valuable states. Experiments conducted on four challenging robotic manipulation tasks with binary rewards, including Reach, Push, Pick&Place and Multi-step Push. The empirical results show that our proposed method significantly outperforms existing methods in the first three basic tasks and also achieves satisfactory performance in multi-step robotic task learning.


Title: R3T: Rapidly-exploring Random Reachable Set Tree for Optimal Kinodynamic Planning of Nonlinear Hybrid Systems
Key Words: control engineering computing  formal verification  nonlinear control systems  reachability analysis  robot dynamics  sampling methods  trees (mathematics)  R3T  random reachable set tree  optimal kinodynamic planning  nonlinear hybrid systems  reachability-based variant  rapidly-exploring random tree  multiple polytopes  reachability analysis  nonlinear systems  contact-rich robotic systems  formal verification  Planning  Approximation algorithms  Trajectory  Heuristic algorithms  Measurement  Robots  Silicon 
Abstract: We introduce R3T, a reachability-based variant of the rapidly-exploring random tree (RRT) algorithm that is suitable for (optimal) kinodynamic planning in nonlinear and hybrid systems. We developed tools to approximate reachable sets using polytopes and perform sampling-based planning with them. This method has a unique advantage in hybrid systems: different dynamic modes in the reachable set can be explicitly represented using multiple polytopes. We prove that under mild assumptions, R3T is probabilistically complete in kinodynamic systems, and asymptotically optimal through rewiring. Moreover, R3T provides a formal verification method for reachability analysis of nonlinear systems. The advantages of R3T are demonstrated with case studies on nonlinear, hybrid, and contact-rich robotic systems.


Title: DeepSemanticHPPC: Hypothesis-based Planning over Uncertain Semantic Point Clouds
Key Words: belief networks  computational geometry  image reconstruction  mobile robots  neural nets  path planning  robot vision  DeepSemanticHPPC  hypothesis-based planning  uncertain semantic point clouds  deep Bayesian neural network  flexible point cloud scene representation  sparse visual measurements  hypothesis-based path planner  uncertainty-aware hypothesis-based planner  Uncertainty  Three-dimensional displays  Trajectory  Semantics  Robots  Planning  Neural networks 
Abstract: Planning in unstructured environments is challenging - it relies on sensing, perception, scene reconstruction, and reasoning about various uncertainties. We propose DeepSemanticHPPC, a novel uncertainty-aware hypothesis-based planner for unstructured environments. Our algorithmic pipeline consists of: a deep Bayesian neural network which segments surfaces with uncertainty estimates; a flexible point cloud scene representation; a next-best-view planner which minimizes the uncertainty of scene semantics using sparse visual measurements; and a hypothesis-based path planner that proposes multiple kinematically feasible paths with evolving safety confidences given next-best-view measurements. Our pipeline iteratively decreases semantic uncertainty along planned paths, filtering out unsafe paths with high confidence. We show that our framework plans safe paths in real-world environments where existing path planners typically fail.


Title: Identification and evaluation of a force model for multirotor UAVs*
Key Words: aerodynamics  autonomous aerial vehicles  blades  momentum  propellers  rotors (mechanical)  vehicle dynamics  force model  multirotor UAV  model identification method  propellers  blade element theories  aerodynamics  momentum theory  actuation dynamics  Propellers  Aerodynamics  Atmospheric modeling  Predictive models  Blades  Acceleration  Computational modeling 
Abstract: This paper proposes a model identification method and evaluation of a force model for multirotor UAVs. The model incorporates propellers' aerodynamics derived from momentum and blade element theories, as well as aerodynamics of the UAV's structure and actuation dynamics. A two-steps identification approach of the model parameters is proposed. The model is identified and evaluated from outdoor experiments with flight speeds exceeding 10m/s.


Title: Perception-constrained and Motor-level Nonlinear MPC for both Underactuated and Tilted-propeller UAVS
Key Words: actuators  aircraft control  autonomous aerial vehicles  control system synthesis  helicopters  motion control  nonlinear control systems  predictive control  propellers  rotors (mechanical)  vehicle dynamics  motor-level Nonlinear MPC  tilted-propeller  Perception-constrained Nonlinear Model Predictive Control framework  real-time control  multirotor aerial vehicles  perceptive sensor  realistic actuator limitations  rotor minimum  maximum speeds  multirotor platforms  underactuated quadrotors  tilted-propellers hexarotors  motor-torque level  Propellers  Task analysis  Robot sensing systems  Real-time systems  Actuators  Vehicle dynamics  Torque 
Abstract: In this paper, we present a Perception-constrained Nonlinear Model Predictive Control (NMPC) framework for the real-time control of multi-rotor aerial vehicles. Our formulation considers both constraints from a perceptive sensor and realistic actuator limitations that are the rotor minimum and maximum speeds and accelerations. The formulation is meant to be generic and considers a large range of multi-rotor platforms (such as underactuated quadrotors or tilted-propellers hexarotors) since it does not rely on differential flatness for the dynamical equations, and a broad range of sensors, such as cameras, lidars, etc.... The perceptive constraints are expressed to maintain visibility of a feature point in the sensor's field of view, while performing a reference maneuver. We demonstrate both in simulation and real experiments that our framework is able to exploit the full capabilities of the multi-rotor, to achieve the motion under the aforementioned constraints, and control in real-time the platform at a motor-torque level, avoiding the use of an intermediate unconstrained trajectory tracker.


Title: CMTS: A Conditional Multiple Trajectory Synthesizer for Generating Safety-Critical Driving Scenarios
Key Words: Bayes methods  data analysis  mobile robots  road safety  road vehicles  safety-critical software  trajectory control  CMTS  conditional multiple trajectory synthesizer  safety-critical driving scenarios  naturalistic driving trajectory generation  autonomous driving algorithms  collision-free scenarios  safety-critical cases  near-miss scenarios  off-the-shelf datasets  generative model  conditional probability  trajectory predictions  autonomous vehicle safety  safety-critical data synthesizing framework  variational Bayesian methods  Trajectory  Interpolation  Roads  Training  Aerospace electronics  Data models  Autonomous vehicles 
Abstract: Naturalistic driving trajectory generation is crucial for the development of autonomous driving algorithms. However, most of the data is collected in collision-free scenarios leading to the sparsity of the safety-critical cases. When considering safety, testing algorithms in near-miss scenarios that rarely show up in off-the-shelf datasets and are costly to accumulate is a vital part of the evaluation. As a remedy, we propose a safety-critical data synthesizing framework based on variational Bayesian methods and term it as Conditional Multiple Trajectory Synthesizer (CMTS). We extend a generative model to connect safe and collision driving data by representing their distribution in the latent space and use conditional probability to adapt to different maps. Sampling from the mixed distribution enables us to synthesize the safety-critical data not shown in the safe or collision datasets. Experimental results demonstrate that the generated dataset covers many different realistic scenarios, especially the near-misses. We conclude that the use of data generated by CMTS can improve the accuracy of trajectory predictions and autonomous vehicle safety.


Title: LiDAR Inertial Odometry Aided Robust LiDAR Localization System in Changing City Scenes
Key Words: distance measurement  graph theory  inertial systems  maximum likelihood estimation  motion estimation  optical radar  localization estimation  inertial LiDAR intensity  matching estimation  LiDAR localization system  environmental change detection method  kinematic estimation  frame-to-frame motion estimation  multiresolution occupancy grid based LiDAR inertial odometry  pose graph fusion framework  Apollo-SouthBay dataset  MAP estimation problem  Laser radar  Estimation  Robustness  Roads  Windows  Optimization  Autonomous vehicles 
Abstract: Environmental fluctuations pose crucial challenges to a localization system in autonomous driving. We present a robust LiDAR localization system that maintains its kinematic estimation in changing urban scenarios by using a dead reckoning solution implemented through a LiDAR inertial odometry. Our localization framework jointly uses information from complementary modalities such as global matching and LiDAR inertial odometry to achieve accurate and smooth localization estimation. To improve the performance of the LiDAR odometry, we incorporate inertial and LiDAR intensity cues into an occupancy grid based LiDAR odometry to enhance frame-to-frame motion and matching estimation. Multi-resolution occupancy grid is implemented yielding a coarse-to-fine approach to balance the odometry's precision and computational requirement. To fuse both the odometry and global matching results, we formulate a MAP estimation problem in a pose graph fusion framework that can be efficiently solved. An effective environmental change detection method is proposed that allows us to know exactly when and what portion of the map requires an update. We comprehensively validate the effectiveness of the proposed approaches using both the Apollo-SouthBay dataset and our internal dataset. The results confirm that our efforts lead to a more robust and accurate localization system, especially in dynamically changing urban scenarios.


Title: Dynamic Interaction-Aware Scene Understanding for Reinforcement Learning in Autonomous Driving
Key Words: convolutional neural nets  decision making  graph theory  image representation  image sequences  learning (artificial intelligence)  neural net architecture  traffic engineering computing  DeepScene-Q off-policy reinforcement learning algorithms  graph-Q  graph convolutional networks  multiple variable-length sequences  novel deep scene architecture  complex interaction-aware scene representations  traffic participants  traffic signs  object types  high-level decision making  deep reinforcement learning  high-level decision component  perception component  autonomous driving systems  dynamic interaction-aware scene understanding  traffic simulator SUMO  Computer architecture  Autonomous vehicles  Lenses  Learning (artificial intelligence)  Decision making  Predictive models  Neural networks 
Abstract: The common pipeline in autonomous driving systems is highly modular and includes a perception component which extracts lists of surrounding objects and passes these lists to a high-level decision component. In this case, leveraging the benefits of deep reinforcement learning for high-level decision making requires special architectures to deal with multiple variable-length sequences of different object types, such as vehicles, lanes or traffic signs. At the same time, the architecture has to be able to cover interactions between traffic participants in order to find the optimal action to be taken. In this work, we propose the novel Deep Scenes architecture, that can learn complex interaction-aware scene representations based on extensions of either 1) Deep Sets or 2) Graph Convolutional Networks. We present the Graph-Q and DeepScene-Q off-policy reinforcement learning algorithms, both outperforming state-ofthe-art methods in evaluations with the publicly available traffic simulator SUMO.


Title: Navigation Command Matching for Vision-based Autonomous Driving
Key Words: control engineering computing  image colour analysis  learning (artificial intelligence)  mobile robots  multi-agent systems  navigation  path planning  road traffic control  robot vision  robust control  traffic engineering computing  suboptimal policy  CARLA driving benchmark  vision-based autonomous driving  imitative reinforcement learning  robust driving policy  nonsmooth rewards  state-action pairs  smooth rewards  matching measurer  navigation rewards  navigation command matching  attention-guided agent  salient regions  RGB images  Navigation  Task analysis  Trajectory  Learning (artificial intelligence)  Autonomous vehicles  Smoothing methods  Current measurement 
Abstract: Learning an optimal policy for autonomous driving task to confront with complex environment is a long- studied challenge. Imitative reinforcement learning is accepted as a promising approach to learn a robust driving policy through expert demonstrations and interactions with environments. However, this model utilizes non-smooth rewards, which have a negative impact on matching between navigation commands and trajectory (state-action pairs), and degrade the generalizability of an agent. Smooth rewards are crucial to discriminate actions generated from sub-optimal policy. In this paper, we propose a navigation command matching (NCM) model to address this issue. There are two key components in NCM, 1) a matching measurer produces smooth navigation rewards that measure matching between navigation commands and trajectory; 2) attention-guided agent performs actions given states where salient regions in RGB images (i.e. roadsides, lane markings and dynamic obstacles) are highlighted to amplify their influence on the final model. We obtain navigation rewards and store transitions to replay buffer after an episode, so NCM is able to discriminate actions generated from suboptimal policy. Experiments on CARLA driving benchmark show our proposed NCM outperforms previous state-of-the- art models on various tasks in terms of the percentage of successfully completed episodes. Moreover, our model improves generalizability of the agent and obtains good performance even in unseen scenarios.


Title: GraphRQI: Classifying Driver Behaviors Using Graph Spectrums
Key Words: computational complexity  driver information systems  eigenvalues and eigenfunctions  graph theory  multi-agent systems  pattern classification  supervised learning  GraphRQI  graph spectrums  road-agent trajectories  driving traits  aggressive driving  conservative driving  nearby road-agents  interagent interactions  unweighted traffic graphs  undirected traffic graphs  supervised learning algorithm  traffic graph  eigenvalue algorithm  autonomous driving datasets  prior driver behavior classification algorithms  Vehicles  Trajectory  Heuristic algorithms  Eigenvalues and eigenfunctions  Laplace equations  Classification algorithms  Topology 
Abstract: We present a novel algorithm (GraphRQI) to identify driver behaviors from road-agent trajectories. Our approach assumes that the road-agents exhibit a range of driving traits, such as aggressive or conservative driving. Moreover, these traits affect the trajectories of nearby road-agents as well as the interactions between road-agents. We represent these inter-agent interactions using unweighted and undirected traffic graphs. Our algorithm classifies the driver behavior using a supervised learning algorithm by reducing the computation to the spectral analysis of the traffic graph. Moreover, we present a novel eigenvalue algorithm to compute the spectrum efficiently. We provide theoretical guarantees for the running time complexity of our eigenvalue algorithm and show that it is faster than previous methods by 2 times. We evaluate the classification accuracy of our approach on traffic videos and autonomous driving datasets corresponding to urban traffic. In practice, GraphRQI achieves an accuracy improvement of up to 25% over prior driver behavior classification algorithms. We also use our classification algorithm to predict the future trajectories of road-agents.


Title: Set-membership state estimation by solving data association
Key Words: mobile robots  position control  robot vision  sensor fusion  SLAM (robots)  state estimation  deterministic approach  data association  underwater robot  sonar data  membership state estimation  localization problem  indistinguishable landmarks  diving phase  unknown initial position  Sonar  State estimation  Rocks  Trajectory  Robot sensing systems  Reliability 
Abstract: This paper deals with the localization problem of a robot in an environment made of indistinguishable landmarks, and assuming the initial position of the vehicle is unknown. This scenario is typically encountered in underwater applications for which landmarks such as rocks all look alike. Furthermore, the position of the robot may be lost during a diving phase, which obliges us to consider unknown initial position. We propose a deterministic approach to solve simultaneously the problems of data association and state estimation, without combinatorial explosion. The efficiency of the method is shown on an actual experiment involving an underwater robot and sonar data.


Title: A Linearly Constrained Nonparametric Framework for Imitation Learning
Key Words: Bayes methods  end effectors  learning systems  predictive control  trajectory control  imitation learning  constrained skills  linearly constrained optimization problem  nonparametric solution  linearly constrained nonparametric framework  human skills learning  constrained motor skills learning  robotic systems  end-effector trajectory  linearly constrained kernelized movement primitives  LC-KMP  probabilistic properties  predictive control  locomotion tasks  grasping tasks  human robot collaborations  Trajectory  Probabilistic logic  Robots  Task analysis  Optimization  Kernel  Grasping 
Abstract: In recent years, a myriad of advanced results have been reported in the community of imitation learning, ranging from parametric to non-parametric, probabilistic to non-probabilistic and Bayesian to frequentist approaches. Meanwhile, ample applications (e.g., grasping tasks and humanrobot collaborations) further show the applicability of imitation learning in a wide range of domains. While numerous literature is dedicated to the learning of human skills in unconstrained environments, the problem of learning constrained motor skills, however, has not received equal attention. In fact, constrained skills exist widely in robotic systems. For instance, when a robot is demanded to write letters on a board, its end-effector trajectory must comply with the plane constraint from the board. In this paper, we propose linearly constrained kernelized movement primitives (LC-KMP) to tackle the problem of imitation learning with linear constraints. Specifically, we propose to exploit the probabilistic properties of multiple demonstrations, and subsequently incorporate them into a linearly constrained optimization problem, which finally leads to a non-parametric solution. In addition, a connection between our framework and the classical model predictive control is provided. Several examples including simulated writing and locomotion tasks are presented to show the effectiveness of our framework.


Title: Collaborative Multi-Robot Localization in Natural Terrain*
Key Words: autonomous underwater vehicles  filtering theory  mobile robots  Monte Carlo methods  multi-robot systems  path planning  sensor fusion  Monterey Bay  terrain relative navigation  filter architecture  collaborative multirobot localization  standard TRN  Monte Carlo simulation  inter-vehicle range measurements  autonomous underwater vehicle  multirobot information  TRN techniques  covariance intersection  Robots  Correlation  Atmospheric measurements  Particle measurements  Extraterrestrial measurements  Collaboration  Navigation 
Abstract: This paper presents a novel filter architecture that allows a team of vehicles to collaboratively localize using Terrain Relative Navigation (TRN). The work explores several causes of measurement correlation that preclude the use of traditional estimators, and proposes an estimator structure that eliminates one source of measurement correlation while properly incorporating others through the use of Covariance Intersection. The result is a consistent estimator that is able to augment proven TRN techniques with multi-robot information, significantly improving localization for vehicles in uninformative terrain. The approach is demonstrated using field data from an Autonomous Underwater Vehicle (AUV) navigating with TRN in Monterey Bay and simulated inter-vehicle range measurements. In addition, a Monte Carlo simulation was used to quantify the algorithm's performance on one example mission. Monte Carlo results show that a vehicle operating in uninformative terrain has 62% lower localization error when fusing range measurements to two converged AUVs than it would using standard TRN.


Title: Multi-Robot Control Using Coverage Over Time-Varying Non-Convex Domains
Key Words: computational geometry  linearisation techniques  multi-robot systems  time-varying systems  time-varying domains  nonconvex shape  nonconvex coverage problem  control law  time-varying density  time-varying diffeomorphism  multirobot control  time-varying nonconvex domains  coverage control  Robot kinematics  Multi-robot systems  Time-varying systems  Collision avoidance  Robot sensing systems  Transforms 
Abstract: This paper addresses the problem of a domain becoming non-convex while using coverage control of a multirobot system over time-varying domains. When the domain moves around in the workspace, its motion and the presence of obstacles might cause it to deform into some non-convex shape, and the robot team should act in a coordinating manner to maintain coverage. The proposed solution is based on a framework for constructing a diffeomorphism to transform a non-convex coverage problem into a convex one. A control law is developed to capture the effects of time variations (e.g., from a time-varying density, time-varying convex hull of the domain and time-varying diffeomorphism) in the system. Analytic expressions of each term in the control law are found for uniform density case. A simulation and robotic implementation are used to validate the proposed algorithm.


Title: Efficient Large-Scale Multi-Drone Delivery Using Transit Networks
Key Words: autonomous aerial vehicles  computational complexity  graph theory  multi-robot systems  optimisation  near-optimal polynomial-time task allocation algorithm  delivery sequences  two-layer approach  multifaceted complexity  maximum time  comprehensive algorithmic framework  public transit vehicles  efficient large-scale multidrone delivery  transit network  bounded-suboptimal multiagent pathfinding techniques  Drones  Task analysis  Resource management  Routing  Urban areas  Planning 
Abstract: We consider the problem of controlling a large fleet of drones to deliver packages simultaneously across broad urban areas. To conserve energy, drones hop between public transit vehicles (e.g., buses and trams). We design a comprehensive algorithmic framework that strives to minimize the maximum time to complete any delivery. We address the multifaceted complexity of the problem through a two-layer approach. First, the upper layer assigns drones to package delivery sequences with a near-optimal polynomial-time task allocation algorithm. Then, the lower layer executes the allocation by periodically routing the fleet over the transit network while employing efficient bounded-suboptimal multi-agent pathfinding techniques tailored to our setting. Experiments demonstrate the efficiency of our approach on settings with up to 200 drones, 5000 packages, and transit networks with up to 8000 stops in San Francisco and Washington DC. Our results show that the framework computes solutions within a few seconds (up to 2 minutes at most) on commodity hardware, and that drones travel up to 450% of their flight range with public transit.


Title: Resilience in multi-robot target tracking through reconfiguration
Key Words: convex programming  covariance matrices  integer programming  Kalman filters  mobile robots  multi-robot systems  target tracking  multirobot target  resource availability  networked multirobot system  target tracking  sensing resources  computational resources  distributed Kalman filter  sensor measurement noise covariance matrix  sensing quality deteriorates  systems communication graph  sensor quality  active communication links  mixed integer semidefinite programming formulations  agent-centric strategy  team-centric strategy  greedy strategy  Robot sensing systems  Target tracking  Covariance matrices  Kalman filters  Robot kinematics 
Abstract: We address the problem of maintaining resource availability in a networked multi-robot system performing distributed target tracking. In our model, robots are equipped with sensing and computational resources enabling them to track a target's position using a Distributed Kalman Filter (DKF). We use the trace of each robot's sensor measurement noise covariance matrix as a measure of sensing quality. When a robot's sensing quality deteriorates, the systems communication graph is modified by adding edges such that the robot with deteriorating sensor quality may share information with other robots to improve the team's target tracking ability. This computation is performed centrally and is designed to work without a large change in the number of active communication links. We propose two mixed integer semi-definite programming formulations (an `agent-centric' strategy and a `team-centric' strategy) to achieve this goal. We implement both formulations and a greedy strategy in simulation and show that the team-centric strategy outperforms the agent-centric and greedy strategies.


Title: Teleoperation of Multi-Robot Systems to Relax Topological Constraints
Key Words: graph theory  mobile robots  multi-robot systems  telerobotics  motion pattern  graph  multirobot teleoperation  mobile robots  topological constraints  Multi-robot systems  Force  Mobile robots  Force feedback  Collision avoidance  Damping 
Abstract: Multi-robot systems are able to achieve common objectives exchanging information among each other. This is possible exploiting a communication structure, usually modeled as a graph, whose topological properties (such as connectivity) are very relevant in the overall performance of the multirobot system. When considering mobile robots, such properties can change over time: robots are then controlled to preserve them, thus guaranteeing the possibility, for the overall system, to achieve its goals. This, however, implies limitations on the possible motion patterns of the robots, thus reducing the flexibility of the overall multi-robot system. In this paper we introduce teleoperation as a means to reduce these limitations, allowing temporary violations of topological properties, with the aim of increasing the flexibility of the multi-robot system.


Title: Eciton robotica: Design and Algorithms for an Adaptive Self-Assembling Soft Robot Collective
Key Words: mobile robots  multi-robot systems  search problems  self-adjusting systems  Eciton robotica  self-assembling soft robot collective  social insects  centralized control system  army ants build bridges  flexible materials  robotic collectives  flexible robots  self-assembling robotic systems  lattice-based structures  soft robots  amorphous structures  Robot sensing systems  Bridges  Grippers  Vibrations  Self-assembly  Hardware 
Abstract: Social insects successfully create bridges, rafts, nests and other structures out of their own bodies and do so with no centralized control system, simply by following local rules. For example, while traversing rough terrain, army ants (genus Eciton) build bridges which grow and dissolve in response to local traffic. Because these self-assembled structures incorporate smart, flexible materials (i.e. ant bodies) and emerge from local behavior, the bridges are adaptive and dynamic. With the goal of realizing robotic collectives with similar features, we designed a hardware system, Eciton robotica, consisting of flexible robots that can climb over each other to assemble compliant structures and communicate locally using vibration. In simulation, we demonstrate self-assembly of structures: using only local rules and information, robots build and dissolve bridges in response to local traffic and varying terrain. Unlike previous self-assembling robotic systems that focused on lattice-based structures and predetermined shapes, our system takes a new approach where soft robots attach to create amorphous structures whose final self-assembled shape can adapt to the needs of the group.


Title: Learning Precise 3D Manipulation from Multiple Uncalibrated Cameras
Key Words: calibration  cameras  image colour analysis  image representation  image sensors  learning (artificial intelligence)  pose estimation  robot vision  stereo image processing  multiple depth sensors  imperfect camera calibration  uncalibrated cameras  camera-views  single view robotic agents  voxel grid  relative pose estimation  3D scene representations  registered output  explicit 3D representations  sensor dropout  insertion tasks  task performance  multicamera approach  uncalibrated RGB camera  precise manipulation tasks  closed-loop end-to-end learning  multiview approach  multiple uncalibrated cameras  precise 3D manipulation  Task analysis  Cameras  Robot vision systems  Three-dimensional displays  Robot kinematics 
Abstract: In this work, we present an effective multi-view approach to closed-loop end-to-end learning of precise manipulation tasks that are 3D in nature. Our method learns to accomplish these tasks using multiple statically placed but uncalibrated RGB camera views without building an explicit 3D representation such as a pointcloud or voxel grid. This multi-camera approach achieves superior task performance on difficult stacking and insertion tasks compared to single-view baselines. Single view robotic agents struggle from occlusion and challenges in estimating relative poses between points of interest. While full 3D scene representations (voxels or pointclouds) are obtainable from registered output of multiple depth sensors, several challenges complicate operating off such explicit 3D representations. These challenges include imperfect camera calibration, poor depth maps due to object properties such as reflective surfaces, and slower inference speeds over 3D representations compared to 2D images. Our use of static but uncalibrated cameras does not require camera-robot or camera-camera calibration making the proposed approach easy to setup and our use of sensor dropout during training makes it resilient to the loss of camera-views after deployment.


Title: Learning Affordance Space in Physical World for Vision-based Robotic Object Manipulation
Key Words: image texture  learning (artificial intelligence)  manipulators  neural nets  probability  robot vision  pixel-wise probability affordance map  image space  world space  viewpoints  multiple-object pushing  multiple-object grasping  physical world  vision-based robotic object manipulation  Affordance Space Perception Network  deep neural network  3D affordance space  training strategy  task-agnostic framework  singular-object pushing  singular-object grasping  Robots  Task analysis  Robustness  Grasping  Data models  Calibration  Adaptation models 
Abstract: What is a proper representation for objects in manipulation? What would human try to perceive when manipulating a new object in a new environment? In fact, instead of focusing on the texture and illumination, human can infer the "affordance" [36] of the objects from vision. Here "affordance" describes the object's intrinsic property that affords a particular type of manipulation. In this work, we investigate whether such affordance can be learned by a deep neural network. In particular, we propose an Affordance Space Perception Network (ASPN) that takes an image as input and outputs an affordance map. Different from existing works that infer the pixel-wise probability affordance map in image space, our affordance is defined in the real world space, thus eliminates the need of hand-eye calibration. In addition, we extend the representation ability of affordance by defining it in a 3D affordance space and propose a novel training strategy to improve the performance. Trained purely with simulation data, ASPN can achieve significant performance in the real world. It is a task-agnostic framework and can handle different objects, scenes and viewpoints. Extensive real-world experiments demonstrate the accuracy and robustness of our approach. We achieve the success rates of 94.2% for singular-object pushing and 92.4% for multiple-object pushing. We also achieve the success rates of 97.2% for singular-object grasping and 95.4% for multiple-object grasping, which outperform current state-of-the-art methods.


Title: Observability Analysis of Flight State Estimation for UAVs and Experimental Validation
Key Words: inertial systems  Kalman filters  magnetic sensors  nonlinear filters  observability  pressure sensors  remotely operated vehicles  singular value decomposition  state estimation  UAV  cost-efficient onboard flight state estimation  robustness  MEMS-based inertial system  static pressure sensors  dynamic pressure sensors  magnetic sensor  weak magnetic field  necessary condition  system state  in-depth observability analysis  sensor data  test flights  EKF  undisturbed estimates  wind state variable  observable spaces  multisensor extended Kalman filter  singular value decomposition  SVD  glider  Observability  Mathematical model  Aerodynamics  State estimation  Global Positioning System  Magnetometers  Pressure measurement 
Abstract: UAVs require reliable, cost-efficient onboard flight state estimation that achieves high accuracy and robustness to perturbation. We analyze a multi-sensor extended Kalman filter (EKF) based on the work by Leutenegger. The EKF uses measurements from a MEMS-based inertial system, static and dynamic pressure sensors as well as GPS. As opposed to other implementations we do not use a magnetic sensor because the weak magnetic field of the earth is subject to disturbances. Observability of the state is a necessary condition for the EKF to work. In this paper, we demonstrate that the system state is observable - which is in contrast to statements in the literature - if the random nature of the air mass is taken into account. Therefore, we carry out an in-depth observability analysis based on a singular value decomposition (SVD). The numerical SVD delivers a wealth of information regarding the observable (sub)spaces. We validated the theoretical findings based on sensor data recorded in test flights on a glider. Most importantly, we demonstrate that the EKF works. It is capable of absorbing large perturbations in the wind state variable converging to the undisturbed estimates.


Title: Second-order Kinematics for Floating-base Robots using the Redundant Acceleration Feedback of an Artificial Sensory Skin
Key Words: calibration  estimation theory  feedback  humanoid robots  Kalman filters  manipulator kinematics  motion control  redundant manipulators  floating-base robots  redundant acceleration feedback  artificial sensory skin  estimation method  second-order kinematics  highly redundant distributed inertial feedback  linear acceleration  robot link  skin acceleration data  link level  state dimensionality reduction  main inertial measurement unit  Sigma-point Kalman filter  joint velocities  REEM-C humanoid robot  Acceleration  Robot sensing systems  Skin  Gyroscopes  Accelerometers  Acceleration Feedback  Artificial Robot Skin  Sigma-point Kalman Filter 
Abstract: In this work, we propose a new estimation method for second-order kinematics for floating-base robots, based on highly redundant distributed inertial feedback. The linear acceleration of each robot link is measured at multiple points using a multimodal, self-configuring and self-calibrating artificial skin. The proposed algorithm is two-fold: i) the skin acceleration data is fused at the link level for state dimensionality reduction; ii) the estimated values are then fused limb-wise with data from the joint encoders and the main inertial measurement unit (IMU), using a Sigma-point Kalman filter. In this manner, it is possible to estimate the joint velocities and accelerations while avoiding the lag and noise amplification phenomena associated with conventional numerical derivation approaches. Experiments performed on the right arm and torso of a REEM-C humanoid robot, demonstrate the consistency of the proposed estimation method.


Title: Arm-hand motion-force coordination for physical interactions with non-flat surfaces using dynamical systems: Toward compliant robotic massage
Key Words: biomechanics  dexterous manipulators  force control  motion control  path planning  regression analysis  support vector machines  unified motion-force control approach  human limb  compliant robotic massage  dynamical system approach  skin surface  robot fingers  complexity increases  manipulation tasks  dynamical systems  nonflat surface  physical interactions  arm-hand motion-force coordination  desired motion patterns  unknown surface  mannequin arm  Allegro robotic hand  KUKA IIWA robotic arm  robotic fingers  DS-based impedance control  desired motions  distance-to-surface mapping  Surface impedance  Robot kinematics  Task analysis  Force  Manipulators  Thumb 
Abstract: Many manipulation tasks require coordinated motions for arm and fingers. Complexity increases when the task requires to control for the force at contact against a non-flat surface; This becomes even more challenging when this contact is done on a human. All these challenges are regrouped when one, for instance, massages a human limb. When massaging, the robotic arm is required to continuously adapt its orientation and distance to the limb while the robot fingers exert desired patterns of forces and motion on the skin surface. To address these challenges, we adopt a Dynamical System (DS) approach that offers a unified motion-force control approach and enables to easily coordinate multiple degrees of freedom. As each human limb may slightly differ, we learn a model of the surface using support vector regression (SVR) which enable us to obtain a distance-to-surface mapping. The gradient of this mapping, along with the DS, generates the desired motions for the interaction with the surface. A DS-based impedance control for the robotic fingers allows to control separately for force along the normal direction of the surface while moving in the tangential plane. We validate our approach using the KUKA IIWA robotic arm and Allegro robotic hand for massaging a mannequin arm covered with a skin-like material. We show that our approach allows for 1) reactive motion planning to reach for an unknown surface, 2) following desired motion patterns on the surface, and 3) exerting desired interaction forces profiles. Our results show the effectiveness of our approach; especially the robustness toward uncertainties for shape and the given location of the surface.


Title: Attentive Task-Net: Self Supervised Task-Attention Network for Imitation Learning using Video Demonstration
Key Words: convolutional neural nets  feature extraction  image representation  learning (artificial intelligence)  video signal processing  task-specific objects  intended task  imitation learning  video demonstration  end-to-end self-supervised feature representation network  video-based task imitation  multilevel spatial attention module  spatial features  weighted combination  multiple intermediate feature maps  respective feature maps  metric learning loss  multiple view points  AT-Net features  reinforcement learning problem  attentive task-net  self supervised task-attention network  neural connections  learning task-specific feature embeddings  temporally consecutive frames  publicly available multiview pouring dataset  RL agent  Gazebo simulator  CNN pipeline  Task analysis  Measurement  Robots  Feature extraction  Training  Visualization  Pipelines 
Abstract: This paper proposes an end-to-end self-supervised feature representation network named Attentive Task-Net or AT-Net for video-based task imitation. The proposed AT-Net incorporates a novel multi-level spatial attention module to highlight spatial features corresponding to the intended task demonstrated by the expert. The neural connections in AT-Net ensure the relevant information in the demonstration is amplified and the irrelevant information is suppressed while learning task-specific feature embeddings. This is achieved by a weighted combination of multiple intermediate feature maps of the input image at different stages of the CNN pipeline. The weights of the combination are given by the compatibility scores, predicted by the attention module for respective feature maps. The AT-Net is trained using a metric learning loss which aims to decrease the distance between the feature representations of concurrent frames from multiple view points and increase the distance between temporally consecutive frames. The AT-Net features are then used to formulate a reinforcement learning problem for task imitation. Through experiments on the publicly available Multi-view pouring dataset, it is demonstrated that the output of the attention module highlights the task-specific objects while suppressing the rest of the background. The efficacy of the proposed method is further validated by qualitative and quantitative comparison with a state-of-the-art technique along with intensive ablation studies. The proposed method is implemented to imitate a pouring task where an RL agent is learned with the AT-Net in Gazebo simulator. Our findings show that the AT-Net achieves 6.5% decrease in alignment error along with a reduction in the number of training iterations by almost 155k over the state-of-the-art while satisfactorily imitating the intended task.


Title: Soft, Round, High Resolution Tactile Fingertip Sensors for Dexterous Robotic Manipulation
Key Words: dexterous manipulators  geometry  tactile sensors  tactile fingertip sensors  dexterous robotic manipulation  dexterous multifingered hands  illumination geometry  dexterous manipulation tasks  Three-dimensional displays  Robot sensing systems  Plastics  Geometry  Light emitting diodes  Cameras 
Abstract: High resolution tactile sensors are often bulky and have shape profiles that make them awkward for use in manipulation. This becomes important when using such sensors as fingertips for dexterous multi-fingered hands, where boxy or planar fingertips limit the available set of smooth manipulation strategies. High resolution optical based sensors such as GelSight have until now been constrained to relatively flat geometries due to constraints on illumination geometry. Here, we show how to construct a rounded fingertip that utilizes a form of light piping for directional illumination. Our sensors can replace the standard rounded fingertips of the Allegro hand. They can capture high resolution maps of the contact surfaces, and can be used to support various dexterous manipulation tasks.


Title: Soft Sensing Shirt for Shoulder Kinematics Estimation
Key Words: biomechanics  biomedical measurement  capacitive sensors  coaxial cables  inertial systems  kinematics  mean square error methods  motion measurement  patient monitoring  patient rehabilitation  readout electronics  regression analysis  strain sensors  wearable motion tracking  ground truth optical motion capture system  strain sensor data  joint angle estimation  normalized root mean square errors  joint velocity estimation  recursive feature elimination-based sensor selection analysis  shoulder kinematics estimation  soft strain sensors  unobtrusive approach  noncyclic joint movements  cyclic arm movements  random arm movements  shoulder joint  customized readout electronics board  sewn microcoaxial cables  textile-based capacitive strain sensors  multidegree-of-freedom noncyclic joint movements  Tracking  Shoulder  Electrodes  Capacitive sensors  Robot sensing systems  Strain 
Abstract: Soft strain sensors have been explored as an unobtrusive approach for wearable motion tracking. However, accurate tracking of multi degree-of-freedom (DOF) noncyclic joint movements remains a challenge. This paper presents a soft sensing shirt for tracking shoulder kinematics of both cyclic and random arm movements in 3 DOFs: adduction/abduction, horizontal flexion/extension, and internal/external rotation. The sensing shirt consists of 8 textile-based capacitive strain sensors sewn around the shoulder joint that communicate to a customized readout electronics board through sewn micro-coaxial cables. An optimized sensor design includes passive shielding and demonstrates high linearity and low hysteresis, making it suitable for wearable motion tracking. In a study with a single human subject, we evaluated the tracking capability of the integrated shirt in comparison with a ground truth optical motion capture system. An ensemble-based regression algorithm was implemented in post-processing to estimate joint angles and angular velocities from the strain sensor data. Results demonstrated root mean square errors (RMSEs) less than 4.5° for joint angle estimation and normalized root mean square errors (NRMSEs) less than 4% for joint velocity estimation. Furthermore, we applied a recursive feature elimination (RFE)-based sensor selection analysis to down select the number of sensors for future shirt designs. This sensor selection analysis found that 5 sensors out of 8 were sufficient to generate comparable accuracies.


Title: Visual Servoing-based Navigation for Monitoring Row-Crop Fields
Key Words: agricultural robots  agriculture  agrochemicals  crops  mobile robots  path planning  robot vision  visual servoing  visual servoing-based navigation  autonomous navigation  field robots  precision agriculture tasks  agrochemicals  visual-based navigation framework  crop-row structure  row-crop fields monitoring  Agriculture  Navigation  Cameras  Robot vision systems  Visualization  Monitoring 
Abstract: Autonomous navigation is a pre-requisite for field robots to carry out precision agriculture tasks. Typically, a robot has to navigate along a crop field multiple times during a season for monitoring the plants, for applying agrochemicals, or for performing targeted interventions. In this paper, we propose a visual-based navigation framework tailored to row-crop fields that exploits the regular crop-row structure present in fields. Our approach uses only the images from on-board cameras without the need for performing explicit localization or maintaining a map of the field. Thus, it can operate without expensive RTK-GPS solutions often used in agricultural automation systems. Our navigation approach allows the robot to follow the crop rows accurately and handles the switch to the next row seamlessly within the same framework. We implemented our approach using C++ and ROS and thoroughly tested it in several simulated fields with different shapes and sizes. We also demonstrated the system running at frame-rate on an actual robot operating on a test row-crop field. The code and data have been published.


Title: Push and Drag: An Active Obstacle Separation Method for Fruit Harvesting Robots
Key Words: agricultural robots  collision avoidance  control engineering computing  grippers  image colour analysis  image segmentation  industrial robots  mobile robots  object detection  robot vision  point cloud operation  deep learning  object detection  color thresholding  image processing  active obstacle separation  linear motions  zig-zag push  trajectory  separation motion  drag motions  obstacle avoidance  target fruit  fruit harvesting robots  Grippers  Robots  Three-dimensional displays  Drag  Trajectory  Force  Radio frequency 
Abstract: Selectively picking a target fruit surrounded by obstacles is one of the major challenges for fruit harvesting robots. Different from traditional obstacle avoidance methods, this paper presents an active obstacle separation strategy that combines push and drag motions. The separation motion and trajectory are generated based on the 3D visual perception of the obstacle information around the target. A linear push is used to clear the obstacles from the area below the target, while a zig-zag push that contains several linear motions is proposed to push aside more dense obstacles. The zig-zag push can generate multi-directional pushes and the side-to-side motion can break the static contact force between the target and obstacles, thus helping the gripper to receive a target in more complex situations. Moreover, we propose a novel drag operation to address the issue of mis-capturing obstacles located above the target, in which the gripper drags the target to a place with fewer obstacles and then pushes back to move the obstacles aside for further detachment. Furthermore, an image processing pipeline consisting of color thresholding, object detection using deep learning and point cloud operation, is developed to implement the proposed method on a harvesting robot. Field tests show that the proposed method can improve the picking performance substantially. This method helps to enable complex clusters of fruits to be harvested with a higher success rate than conventional methods.


Title: A Novel Calibration Method between a Camera and a 3D LiDAR with Infrared Images
Key Words: calibration  cameras  image filtering  infrared imaging  optical radar  3D LiDAR  infrared images  infrared filter  calibration method  simultaneous location and mapping  Velodyne VLP-16 sensor  Conferences  Automation 
Abstract: Fusions of LiDARs (light detection and ranging) and cameras have been effectively and widely employed in the communities of autonomous vehicles, virtual reality and mobile mapping systems (MMS) for different purposes, such as localization, high definition map or simultaneous location and mapping. However, the extrinsic calibration between a camera and a 3D LiDAR is a fundamental prerequisite to guarantee its performance. Some previous methods are inaccurate, have calibration error that is several times the beam divergence, and often require special calibration objects, thereby limiting their ubiquitous use for calibration. To overcome these shortcomings, we propose a novel and high-accuracy method for the extrinsic calibration between a camera and a 3D LiDAR. Our approach relies on the infrared images from a camera with an infrared filter, and the 2D-3D corresponding points in a scene with the corners of a wall can be extracted to calculate the six extrinsic parameters. Experiments using the Velodyne VLP-16 sensor show that the method can achieve an extrinsic accuracy at the level of the beam divergence, which is fully analyzed and validated from two different aspects. Therefore, the calibration method in this paper is highly accurate, effective and does not require special complicated calibration objects; thus, it meets the requirements of practical applications.


Title: Precise 3D Calibration of Wafer Handling Robot by Visual Detection and Tracking of Elliptic-shape Wafers
Key Words: calibration  cameras  feature extraction  Gaussian processes  image reconstruction  image registration  image segmentation  industrial robots  optimisation  pose estimation  production engineering computing  robot kinematics  robot vision  semiconductor device manufacture  semiconductor technology  precise 3D calibration  visual detection  elliptic-shape wafers  3D poses  robot kinematics  robust ellipse detection  tracking algorithm  calibration parameters  robot-camera system  Three-dimensional displays  Image segmentation  Robots  Optimization  Image edge detection  Calibration  Cameras 
Abstract: This work provides a framework for the 3D calibration of wafers and a wafer handling robot by monocular vision. The proposed method precisely reconstructs the 3D poses of wafers from a set of images captured by the camera mounted on the robot. In addition, it calibrates the robot kinematics simultaneously. A robust ellipse detection and tracking algorithm based on the edge arcs is developed to recognize wafers among images. Then a joint optimization is constructed from a multi-object pose graph to solve the 3D poses of wafers and other calibration parameters of the robot-camera system. The proposed tracking method is able to associate multiple incomplete elliptic segments using a Gaussian Mixture Model-based registration algorithm. The algorithm is point-based where no feature descriptor is required. The proposed 3D pose optimization incorporates shape constraints, and is more accurate than the point-wise reconstruction produced by classic bundle adjustment methods.


Title: Robotic General Parts Feeder: Bin-picking, Regrasping, and Kitting
Key Words: grippers  industrial manipulators  materials handling  multi-robot systems  robotic general parts feeder  multiple objects  manufacturing industry  multirobot system  kitting  automatic multiple parts feeding problem  coarse-to-fine manipulation process  multiple robot arms  MPPH  traditional parts feeder  various-shaped industrial parts  robotic bin-picking system  automatic parts feeding  mean picks per hour  Pipelines  Robot sensing systems  Shape  Grippers  Service robots  Manipulators 
Abstract: The automatic parts feeding of multiple objects is an unsolved problem in the manufacturing industry. In this paper, we tackle the problem by proposing a multi-robot system. The system comprises three sub-components which perform bin-picking, regrasping, and kitting. The three subcomponents divide and conquer the automatic multiple parts feeding problem by considering a coarse-to-fine manipulation process. Multiple robot arms are connected in series as a pipeline. The robots are separated into three groups to perform the roles of each sub-component. The accuracy of the state and manipulation are getting higher along with the changes of the sub-components in the pipeline. In the experimental section, the performance of the system is evaluated by using the Mean Picks Per Hour (MPPH) metric and success rate, which are compared to traditional parts feeder and manual labor. The results show that the Mean Picks Per Hour (MPPH) of the proposed system is 351 with eleven various-shaped industrial parts, which is faster than the state-of-the-art robotic bin-picking system. The lead time of the proposed system for new parts is less than that of a traditional parts feeders and/or manual labor.


Title: Planning, Learning and Reasoning Framework for Robot Truck Unloading
Key Words: control engineering computing  decision making  industrial manipulators  inference mechanisms  learning (artificial intelligence)  path planning  production engineering computing  unloading  reasoning framework  industrial manipulator robot  real-time motion planning  complex robotic system  high-level decision-making  belief space planning  offline learning  execution module  robot truck unloading  online decision-making  Planning  Robot sensing systems  Task analysis  Decision making  Collision avoidance  Real-time systems 
Abstract: We consider the task of autonomously unloading boxes from trucks using an industrial manipulator robot. There are multiple challenges that arise: (1) real-time motion planning for a complex robotic system carrying two articulated mechanisms, an arm and a scooper, (2) decision-making in terms of what action to execute next given imperfect information about boxes such as their masses, (3) accounting for the sequential nature of the problem where current actions affect future state of the boxes, and (4) real-time execution that interleaves high-level decision-making with lower level motion planning. In this work, we propose a planning, learning, and reasoning framework to tackle these challenges, and describe its components including motion planning, belief space planning for offline learning, online decision-making based on offline learning, and an execution module to combine decision-making with motion planning. We analyze the performance of the framework on real-world scenarios. In particular, motion planning and execution modules are evaluated in simulation and on a real robot, while offline learning and online decision-making are evaluated in simulated real-world scenarios.


Title: Directional Mechanical Impedance of the Human Ankle During Standing with Active Muscles
Key Words: gait analysis  muscle  neurophysiology  prosthetics  torque  muscle activity  human ankle function  directional mechanical impedance  active muscles  standing posture  reconstructed torque  ankle states  ankle angle  Conferences  Automation 
Abstract: The directional mechanical impedance of the human ankle was identified from subjects in a standing posture with varying levels of muscle activity. The impedance modeled the different torque responses to angle perturbations about different axes of rotation. This work proposed a novel impedance model that incorporated the coupling between multiple degrees of freedom of the ankle and was validated theoretically and experimentally. The reconstructed torque had an average variance accounted above 94% across twelve subjects. In addition, the impedance varied between and within trials and this variation was explained by changes in the ankle states, i.e., the ankle angle, torque, and muscle activities. These results have implications in the design of new prostheses controllers and the understanding of the human ankle function.


Title: Local Policy Optimization for Trajectory-Centric Reinforcement Learning
Key Words: control engineering computing  learning (artificial intelligence)  manipulators  nonlinear control systems  nonlinear programming  open loop systems  local policy optimization  trajectory-centric reinforcement learning  local stabilizing policy optimization  trajectory-centric model-based reinforcement learning  global policy optimization  nonlinear systems  robotic manipulation tasks  open-loop trajectory optimization  local policy synthesis  single optimization problem  nonlinear programming  Robustness  Trajectory optimization  Uncertainty  Learning (artificial intelligence)  Robots 
Abstract: The goal of this paper is to present a method for simultaneous trajectory and local stabilizing policy optimization to generate local policies for trajectory-centric model-based reinforcement learning (MBRL). This is motivated by the fact that global policy optimization for non-linear systems could be a very challenging problem both algorithmically and numerically. However, a lot of robotic manipulation tasks are trajectory-centric, and thus do not require a global model or policy. Due to inaccuracies in the learned model estimates, an open-loop trajectory optimization process mostly results in very poor performance when used on the real system. Motivated by these problems, we try to formulate the problem of trajectory optimization and local policy synthesis as a single optimization problem. It is then solved simultaneously as an instance of nonlinear programming. We provide some results for analysis as well as achieved performance of the proposed technique under some simplifying assumptions.


Title: GOMP: Grasp-Optimized Motion Planning for Bin Picking
Key Words: collision avoidance  concave programming  dexterous manipulators  grippers  industrial manipulators  manipulator dynamics  motion control  quadratic programming  warehouse automation  GOMP  bin-picking robot  robot dynamics  grasp planner  motion planner  robot bin picking  picks-per-hour  PPH  grasp-analysis tools  robot gripper  grasp-optimized motion planning  warehouse automation  Dex-Net  degree of freedom  sequential quadratic programming  obstacle avoidance  time-minimization  Trajectory  Grippers  Robot sensing systems  Planning  Manipulators  Optimization 
Abstract: Rapid and reliable robot bin picking is a critical challenge in automating warehouses, often measured in picks-per-hour (PPH). We explore increasing PPH using faster motions based on optimizing over a set of candidate grasps. The source of this set of grasps is two-fold: (1) grasp-analysis tools such as Dex-Net generate multiple candidate grasps, and (2) each of these grasps has a degree of freedom about which a robot gripper can rotate. In this paper, we present Grasp-Optimized Motion Planning (GOMP), an algorithm that speeds up the execution of a bin-picking robot's operations by incorporating robot dynamics and a set of candidate grasps produced by a grasp planner into an optimizing motion planner. We compute motions by optimizing with sequential quadratic programming (SQP) and iteratively updating trust regions to account for the non-convex nature of the problem. In our formulation, we constrain the motion to remain within the mechanical limits of the robot while avoiding obstacles. We further convert the problem to a time-minimization by repeatedly shorting a time horizon of a trajectory until the SQP is infeasible. In experiments with a UR5, GOMP achieves a speedup of 9x over a baseline planner.


Title: Motion Planning and Task Allocation for a Jumping Rover Team
Key Words: collision avoidance  integer programming  linear programming  mobile robots  multi-robot systems  planetary rovers  travelling salesman problems  trees (mathematics)  jumping rover team  robotic team  unmanned ground vehicles  hybrid operational modes  multiple traveling salesman problem  mTSP  ground surface  jumping capability  optimal path  mixed-integer linear programming problem  RRT*  multiple UGV  optimized motion  customized jumping rovers  Planning  Task analysis  Smoothing methods  Resource management  Mobile robots  Wheels  Jumping Robots  Multiple Traveling Salesman Problem  Path Planning  Rapidly-exploring Random Tree  Mixed-Integer Linear Programming 
Abstract: This paper presents a cooperative robotic team composed of unmanned ground vehicles (UGVs) with hybrid operational modes to tackle the multiple traveling salesman problem (mTSP) with obstacles. The hybrid operational modes allow every UGV in the team to not only travel on a ground surface but also jump over obstacles. We name these UGVs jumping rovers. The jumping capability provides a flexible form of locomotion by leaping and landing on top of obstacles instead of navigating around obstacles. To solve the mTSP, an optimal path between any two objective points in an mTSP is determined by the optimized rapidly-exploring random tree method, named RRT*, and is further improved through a refined RRT* algorithm to find a smoother path between targets. We then formulate the mTSP as a mixed-integer linear programming (MILP) problem to search for the most cost-effective combination of paths for multiple UGVs. The effectiveness of the hybrid operational modes and optimized motion with assigned tasks is verified in an indoor, physical experimental environment using the customized jumping rovers.


Title: Active 3D Modeling via Online Multi-View Stereo
Key Words: image reconstruction  stereo image processing  low-quality surfaces  exploration trial  active 3D modeling  online multiview stereo  large-scale structure monitoring  image acquisition  reconstruction quality  view path-planning method  online MVS system  online feedbacks  image reconstruction  camera trajectory  real-time three-dimensional model construction  Three-dimensional displays  Image reconstruction  Surface reconstruction  Computational modeling  Solid modeling  Trajectory  Cameras 
Abstract: Multi-view stereo (MVS) algorithms have been commonly used to model large-scale structures. When processing MVS, image acquisition is an important issue because its reconstruction quality depends heavily on the acquired images. Recently, an explore-then-exploit strategy has been used to acquire images for MVS. This method first constructs a coarse model by exploring an entire scene using a pre-allocated camera trajectory. Then, it rescans the unreconstructed regions from the coarse model. However, this strategy is inefficient because of the frequent overlap of the initial and rescanning trajectories. Furthermore, given the complete coverage of images, MVS algorithms do not guarantee an accurate reconstruction result.In this study, we propose a novel view path-planning method based on an online MVS system. This method aims to incrementally construct the target three-dimensional (3D) model in real time. View paths are continually planned based on online feedbacks from the partially constructed model. The obtained paths fully cover low-quality surfaces while maximizing the reconstruction performance of MVS. Experimental results demonstrate that the proposed method can construct high quality 3D models with one exploration trial, without any rescanning trial as in the explore-then-exploit method.


Title: Nonlinear Vector-Projection Control for Agile Fixed-Wing Unmanned Aerial Vehicles
Key Words: aerospace components  aircraft control  attitude control  autonomous aerial vehicles  cascade control  helicopters  mobile robots  nonlinear control systems  trajectory control  nonlinear vector-projection control  agile fixed-wing aircraft  fixed-wing platforms  nonlinear control strategy  autonomous flight  cascaded control structure  inner attitude control loop  Special Orthornormal group  outer position control loop  thrust command  attitude references  lift forces  agile fixed-wing unmanned aerial vehicles  rotorcraft  Aircraft  Control systems  Attitude control  Aerodynamics  Position measurement  Aircraft propulsion 
Abstract: Agile fixed-wing aircraft integrate the efficient, high-speed capabilities of conventional fixed-wing platforms with the extreme maneuverability of rotorcraft. This work presents a nonlinear control strategy that harnesses these capabilities to enable autonomous flight through aggressive, time-constrained, three-dimensional trajectories. The cascaded control structure consists of two parts; an inner attitude control loop developed on the Special Orthornormal group that avoids singularities commonly associated with other parametrizations, and an outer position control loop that jointly determines the thrust command and attitude references by implementing a novel vector-projection algorithm. The objective of the algorithm is to decouple roll from the reference attitude to ensure that thrust and lift forces can always be pointed such that position errors converge to zero. The proposed control system represents a single, unified solution that remains effective throughout the aircraft's flight envelope, including aerobatic operation. Controller performance is verified through simulations and experimental flight tests; results show the unified control scheme is capable of performing a wide range of operations that would normally require multiple, single-purpose controllers, and their associated switching logic.


Title: The Reconfigurable Aerial Robotic Chain: Modeling and Control
Key Words: aerospace robotics  control system synthesis  mobile robots  position control  ARC-Alpha prototype  multilinked microaerial vehicles  reconfigurable aerial robotic chain  multiple parallel angular controllers  model predictive position control loop  controller design  connected aerial vehicles  system dynamics  system extendability  distributed sensing  Robot sensing systems  Robot kinematics  Payloads  Shape  Prototypes 
Abstract: This paper overviews the system design, modeling and control of the Aerial Robotic Chain. This new design corresponds to a reconfigurable robotic system of systems consisting of multilinked micro aerial vehicles that presents the ability to cross narrow sections, morph its shape, ferry significant payloads, offer the potential of distributed sensing and processing, and enable system extendability. We present the system dynamics for any number of connected aerial vehicles, followed by the controller design involving a model predictive position control loop combined with multiple parallel angular controllers on SO(3). Evaluation studies both in simulation and through experiments based on our ARC-Alpha prototype are depicted and involve coordinated maneuvering and shape configuration to cross narrow windows.


Title: Game theoretic decision making based on real sensor data for autonomous vehicles’ maneuvers in high traffic
Key Words: decision making  game theory  learning (artificial intelligence)  mobile robots  Monte Carlo methods  road vehicles  sensors  sensor data  autonomous vehicles  iterative multiplayer game  game model  ego-vehicle  vehicle-to-vehicle communication  traffic simulator  game theoretic decision making  cognitive hierarchy reasoning  Monte Carlo reinforcement learning  Games  Automobiles  Mathematical model  Game theory  Autonomous vehicles  Robot sensing systems 
Abstract: This paper presents an approach for implementing game theoretic decision making in combination with realistic sensory data input so as to allow an autonomous vehicle to perform maneuvers, such as lane change or merge in high traffic scenarios. The main novelty of this work, is the use of realistic sensory data input to obtain the observations as input of an iterative multi-player game in a realistic simulator. The game model allows to anticipate reactions of additional vehicles to the movements of the ego-vehicle without using any specific coordination or vehicle-to-vehicle communication. Moreover, direct information from the simulator, such as position or speed of the vehicles is also avoided.The solution of the game is based on cognitive hierarchy reasoning and it uses Monte Carlo reinforcement learning in order to obtain a near-optimal policy towards a specific goal. Moreover, the game proposed is capable of solving different situations using a single policy. The system has been successfully tested and compared with previous techniques using a realistic hybrid simulator, where the ego-vehicle and its sensors are simulated on a 3D simulator and the additional vehicles' behavior is obtained from a traffic simulator.


Title: Cross-context Visual Imitation Learning from Demonstrations
Key Words: learning (artificial intelligence)  robots  general imitation learning method  robotic system  context translation model  depth prediction model  multimodal inverse dynamics model  depth observation  inverse model maps  multimodal observations  cross-context learning advantage  cross-context visual imitation learning  color observation  block stacking tasks  Context modeling  Robots  Task analysis  Inverse problems  Visualization  Predictive models  Feature extraction 
Abstract: Imitation learning enables robots to learn a task by simply watching the demonstration of the task. Current imitation learning methods usually require the learner and demonstrator to occur in the same context. This limits their scalability to practical applications. In this paper, we propose a more general imitation learning method which allows the learner and the demonstrator to come from different contexts, such as different viewpoints, backgrounds, and object positions and appearances. Specifically, we design a robotic system consisting of three models: context translation model, depth prediction model and multi-modal inverse dynamics model. First, the context translation model translates the demonstration to the context of learner from a different context. Then combining the color observation and depth observation as inputs, the inverse model maps the multi-modal observations into actions to reproduce the demonstration, where the depth observation is provided by a depth prediction model. By performing the block stacking tasks both in simulation and real world, we prove the cross-context learning advantage of the proposed robotic system over other systems.


Title: Improved Multiple Objects Tracking based Autonomous Simultaneous Magnetic Actuation & Localization for WCE
Key Words: biological organs  biomedical optical imaging  endoscopes  interpolation  medical image processing  object tracking  phantoms  autonomous simultaneous magnetic actuation & localization  wireless capsule endoscopy  gastrointestinal examinations  clinical applications  rotating magnet  robotic arm  internal magnetic ring  magnetic fields  external sensor array  spherical linear interpolation  actuation-localization loop  Bezier Curve Gradient  normal vector fitting  frequency 25.0 Hz  Magnetic moments  Magnetic separation  Object tracking  Magnetic resonance imaging  Interpolation  Actuators  Fitting  Simultaneous Magnetic Actuation and Localization  Multiple Objects Tracking  Wireless Capsule Endoscopy 
Abstract: Wireless Capsule Endoscopy (WCE) has the advantage of reducing the invasiveness and pain of gastrointestinal examinations. In this work, we propose a system aimed at autonomously accelerating and locating the WCE inside the intestine for clinical applications. A rotating magnet controlled by a robotic arm is placed outside the patient's body to actuate the capsule with an internal magnetic ring, and the magnetic fields of the two sources are measured by an external sensor array. The original Multiple Objects Tracking method is improved by combining Normal Vector Fitting, Bézier Curve Gradient, and Spherical Linear Interpolation to estimate the 6-D pose of the WCE from a 5-D pose sequence. In order to close the actuation-localization loop, a strategy is presented to react to different states of the capsule. The proposed method is validated via experiments on phantoms as well as on animal intestines. The localization of the capsule shows an accuracy of 3.5mm in position and 9.4° in orientation, and the average update frequency of the estimated 6-D pose reaches 25Hz.


Title: Probe-before-step walking strategy for multi-legged robots on terrain with risk of collapse
Key Words: gait analysis  legged locomotion  mobile robots  stability  probe-before-step walking strategy  multilegged robots  rough terrain  safe footholds  hexapod robot  terrain probing approach  follow-the-leader strategy  stabilisation  Legged locomotion  Probes  Foot  Robot sensing systems  Force  Australia 
Abstract: Multi-legged robots are effective at traversing rough terrain. However, terrains that include collapsible footholds (i.e. regions that can collapse when stepped on) remain a significant challenge, especially since such situations can be extremely difficult to anticipate using only exteroceptive sensing. State-of-the-art methods typically use various stabilisation techniques to regain balance and counter changing footholds. However, these methods are likely to fail if safe footholds are sparse and spread out or if the robot does not respond quickly enough after a foothold collapse. This paper presents a novel method for multi-legged robots to probe and test the terrain for collapses using its legs while walking. The proposed method improves on existing terrain probing approaches, and integrates the probing action into a walking cycle. A follow-the-leader strategy with a suitable gait and stance is presented and implemented on a hexapod robot. The proposed method is experimentally validated, demonstrating the robot can safely traverse terrain containing collapsible footholds.


Title: Representing Multi-Robot Structure through Multimodal Graph Embedding for the Selection of Robot Teams
Key Words: directed graphs  mobile robots  multi-robot systems  unsupervised learning  multirobot system  multirobot structure  human-robot teaming  multimodal graph embedding  robot teams selection  directed graphs  asymmetrical relationships  unsupervised learning  physical robots  multifaceted internal structures  graph embedding-based division methods  Robots  Task analysis  Multi-robot systems  Indexes  Organizations  Resource management  Biology 
Abstract: Multi-robot systems of increasing size and complexity are used to solve large-scale problems, such as area exploration and search and rescue. A key decision in human-robot teaming is dividing a multi-robot system into teams to address separate issues or to accomplish a task over a large area. In order to address the problem of selecting teams in a multi-robot system, we propose a new multimodal graph embedding method to construct a unified representation that fuses multiple information modalities to describe and divide a multi-robot system. The relationship modalities are encoded as directed graphs that can encode asymmetrical relationships, which are embedded into a unified representation for each robot. Then, the constructed multimodal representation is used to determine teams based upon unsupervised learning. We per-form experiments to evaluate our approach on expert-defined team formations, large-scale simulated multi-robot systems, and a system of physical robots. Experimental results show that our method successfully decides correct teams based on the multifaceted internal structures describing multi-robot systems, and outperforms baseline methods based upon only one mode of information, as well as other graph embedding-based division methods.


Title: MAMS-A*: Multi-Agent Multi-Scale A*
Key Words: graph theory  multi-agent systems  path planning  search problems  local search  local inconsistency conditions  common subgraph  provably optimal path  informative graph  search algorithm  distributed agents  single-query shortest path  search space  common environment  multiresolution graph  multiagent multiscale A*  Planning  Hypercubes  Search problems  Legged locomotion  Wavelet transforms  Aerospace engineering  Electronic mail 
Abstract: We present a multi-scale forward search algorithm for distributed agents to solve single-query shortest path planning problems. Each agent first builds a representation of its own search space of the common environment as a multi-resolution graph, it communicates with the other agents the result of its local search, and it uses received information from other agents to refine its own graph and update the local inconsistency conditions. As a result, all agents attain a common subgraph that includes a provably optimal path in the most informative graph available among all agents, if one exists, without necessarily communicating the entire graph. We prove the completeness and optimality of the proposed algorithm, and present numerical results supporting the advantages of the proposed approach.


Title: Connectivity Maintenance: Global and Optimized approach through Control Barrier Functions
Key Words: mobile robots  multi-robot systems  optimal control  optimisation  connectivity maintenance  Control Barrier functions  multirobot system  local connectivity  global connectivity  formation control  Control Barrier Function  control strategy  Robots  Laplace equations  Multi-robot systems  Eigenvalues and eigenfunctions  Maintenance engineering  Task analysis  Control systems 
Abstract: Connectivity maintenance is an essential aspect to consider while controlling a multi-robot system. In general, a multi-robot system should be connected to obtain a certain common objective. Connectivity must be kept regardless of the control strategy or the objective of the multi-robot system. Two main methods exist for connectivity maintenance: keep the initial connections (local connectivity) or allow modifications to the initial connections, but always keeping the overall system connected (global connectivity). In this paper we present a method that allows, at the same time, to maintain global connectivity and to implement the desired control strategy (e.g., consensus, formation control, coverage), all in an optimized fashion. For this purpose, we defined and implemented a Control Barrier Function that can incorporate constraints and objectives. We provide a mathematical proof of the method, and we demonstrate its versatility with simulations of different applications.


Title: Controller Synthesis for Infinitesimally Shape-Similar Formations
Key Words: control system synthesis  decentralised control  multi-robot systems  multirobot team  network structure  controller synthesis  formation control  communication requirements  differential-drive robots  infinitesimally shape-similar formations  network topology  Robot sensing systems  Robot kinematics  Lyapunov methods  Trajectory  Shape 
Abstract: The interplay between network topology and the interaction modalities of a multi-robot team fundamentally impact the types of formations that can be achieved. To explore the trade-offs between network structure and the sensing and communication capabilities of individual robots, this paper applies controller synthesis to formation control of infinitesimally shape-similar frameworks, for which maintaining the relative angles between robots ensures invariance of the framework to translation, rotation, and uniform scaling. Beginning with the development of a controller for the sole purpose of maintaining the formation, the controller-synthesis approach is introduced as a mechanism for incorporating user- designated objectives while ensuring that the formation is maintained. Both centralized and decentralized formulations of the synthesized controller are presented, the resulting sensing and communication requirements are discussed, and the method is demonstrated on a team of differential-drive robots.


Title: A Distributed Source Term Estimation Algorithm for Multi-Robot Systems
Key Words: distributed control  mobile robots  multi-robot systems  airborne chemicals  mobile sensing systems  intelligent systems  odor source localization  homogeneous multirobot systems  multiple mobile robots  distributed system  distributed source term estimation  Robot kinematics  Robot sensing systems  Estimation  Navigation  Probabilistic logic 
Abstract: Finding sources of airborne chemicals with mobile sensing systems finds applications in safety, security, and emergency situations related to medical, domestic, and environmental domains. Given the often critical nature of all the applications, it is important to reduce the amount of time necessary to accomplish this task through intelligent systems and algorithms. In this paper, we extend a previously presented algorithm based on source term estimation for odor source localization for homogeneous multi-robot systems. By gradually increasing the level of coordination among multiple mobile robots, we study the benefits of a distributed system on reducing the amount of time and resources necessary to achieve the task at hand. The method has been evaluated systematically through high-fidelity simulations and in a wind tunnel emulating realistic and repeatable conditions in different coordination scenarios and with different number of robots.


Title: Weighted Buffered Voronoi Cells for Distributed Semi-Cooperative Behavior
Key Words: collision avoidance  computational geometry  game theory  mobile robots  multi-agent systems  multi-robot systems  selfish agent  relative cell  collision-free configuration  egoistic weights  altruistic agents  distributed semi  semicooperative multiagent navigation policies  collision avoidance  dynamic weights  lower relative weight  buffered distance  agent weights  selfish behavior  prioritized behavior  weighted buffered Voronoi tessellation  weighted buffered Voronoi cells  Navigation  Robot kinematics  Collision avoidance  Games  Planning  Safety 
Abstract: This paper introduces the Weighted Buffered Voronoi tessellation, which allows us to define distributed, semicooperative multi-agent navigation policies with guarantees on collision avoidance. We generate the Voronoi cells with dynamic weights that bias the boundary towards the agent with the lower relative weight while always maintaining a buffered distance between two agents. By incorporating agent weights, we can encode selfish or prioritized behavior among agents, where a more selfish agent will have a larger relative cell over less selfish agents. We consider this semi-cooperative since agents do not cooperate in symmetric ways. Furthermore, when all agents start in a collision-free configuration and plan their control actions within their cells, we prove that no agents will collide. Simulations demonstrate the performance of our algorithm for agents navigating to goal locations in a position-swapping game. We observe that agents with more egoistic weights consistently travel shorter paths to their goal than more altruistic agents.


Title: Incorporating Motion Planning Feasibility Considerations during Task-Agent Assignment to Perform Complex Tasks Using Mobile Manipulators
Key Words: manipulators  mobile robots  multi-robot systems  path planning  task-agent assignment  complex tasks  multiarm mobile manipulators  multiple robotic agents  expensive motion planning queries  speed-up techniques  spatial constraint checking  conservative surrogates  symbolic conditions  high-DOF robotic agents  Task analysis  Planning  Manipulators  Robot kinematics  Containers  Trajectory 
Abstract: Multi-arm mobile manipulators can be represented as a combination of multiple robotic agents from the perspective of task-assignment and motion planning. Depending upon the task, agents might collaborate or work independently. Integrating motion planning with task-agent assignment is a computationally slow process as infeasible assignments can only be detected through expensive motion planning queries. We present three speed-up techniques for addressing this problem-(1) spatial constraint checking using conservative surrogates for motion planners, (2) instantiating symbolic conditions for pruning infeasible assignments, and (3) efficiently caching and reusing previously generated motion plans. We show that the developed method is useful for real-world operations that require complex interaction and coordination among high-DOF robotic agents.


Title: Online Replanning in Belief Space for Partially Observable Task and Motion Problems
Key Words: manipulators  mobile robots  motion control  path planning  execution system  deterministic cost-sensitive planning  hybrid belief states  partially observable problems  online replanning  belief space  multistep manipulation tasks  autonomous robot  Planning  Task analysis  Bayes methods  Manipulators  Aerospace electronics  Uncertainty 
Abstract: To solve multi-step manipulation tasks in the real world, an autonomous robot must take actions to observe its environment and react to unexpected observations. This may require opening a drawer to observe its contents or moving an object out of the way to examine the space behind it. Upon receiving a new observation, the robot must update its belief about the world and compute a new plan of action. In this work, we present an online planning and execution system for robots faced with these challenges. We perform deterministic cost-sensitive planning in the space of hybrid belief states to select likely-to-succeed observation actions and continuous control actions. After execution and observation, we replan using our new state estimate. We initially enforce that planner reuses the structure of the unexecuted tail of the last plan. This both improves planning efficiency and ensures that the overall policy does not undo its progress towards achieving the goal. Our approach is able to efficiently solve partially observable problems both in simulation and in a real-world kitchen.


Title: UNO: Uncertainty-aware Noisy-Or Multimodal Fusion for Unanticipated Input Degradation
Key Words: learning (artificial intelligence)  neural nets  probability  sensor fusion  uncertainty handling  multimodal fusion  unanticipated input degradation  multiple sensor modalities  deep learning architectures  modality-specific output softmax probabilities  uncertainty measures  uncertainty-scaled output  fusion architectures  probabilistic noisy-fusion  data-dependent spatial temperature scaling  uncertainty-aware fusion  UNO  uncertainty-aware noisy fusion  Uncertainty  Degradation  Training  Noise measurement  Robot sensing systems  Entropy 
Abstract: The fusion of multiple sensor modalities, especially through deep learning architectures, has been an active area of study. However, an under-explored aspect of such work is whether the methods can be robust to degradation across their input modalities, especially when they must generalize to degradation not seen during training. In this work, we propose an uncertainty-aware fusion scheme to effectively fuse inputs that might suffer from a range of known and unknown degradation. Specifically, we analyze a number of uncertainty measures, each of which captures a different aspect of uncertainty, and we propose a novel way to fuse degraded inputs by scaling modality-specific output softmax probabilities. We additionally propose a novel data-dependent spatial temperature scaling method to complement these existing uncertainty measures. Finally, we integrate the uncertainty-scaled output from each modality using a probabilistic noisy-or fusion method. In a photo-realistic simulation environment (AirSim), we show that our method achieves significantly better results on a semantic segmentation task, as compared to state-of-art fusion architectures, on a range of degradation (e.g. fog, snow, frost, and various other types of noise), some of which are unknown during training.


Title: SwarmRail: A Novel Overhead Robot System for Indoor Transport and Mobile Manipulation
Key Words: manipulators  mobile robots  multi-robot systems  rails  robotic manipulator arm overhead  continuous overhead manipulation  rail crossings  robot swarm  mobile SwarmRail units  single rail network  indoor transport  mobile manipulation  omnidirectional mobile platform  rail profiles  rail-structure  overhead robot system  Rails  Wheels  Robot sensing systems  Manipulators  Layout 
Abstract: SwarmRail represents a novel solution to overhead manipulation from a mobile unit that drives in an aboveground rail-structure. The concept is based on the combination of omnidirectional mobile platform and L-shaped rail profiles that form a through-going central gap. This gap makes possible mounting a robotic manipulator arm overhead at the underside of the mobile platform. Compared to existing solutions, SwarmRail enables continuous overhead manipulation while traversing rail crossings. It also can be operated in a robot swarm, as it allows for concurrent operation of a group of mobile SwarmRail units inside a single rail network. Experiments on a first functional demonstrator confirm the functional capability of the concept. Potential fields of applications reach from industry over logistics to vertical farming.


Title: Fast Local Planning and Mapping in Unknown Off-Road Terrain
Key Words: collision avoidance  graph theory  mobile robots  motion control  remotely operated vehicles  SLAM (robots)  trajectory control  off-road terrain  on-line mapping  planning solution  obstacle detection  terrain gradient map  simple cost map  adaptable cost map  optimal paths  control input space  kinematic forward simulation  generated feasible trajectories  optimal trajectory  time operation  frequency 10.0 Hz  frequency 30.0 Hz  Trajectory  Robots  Planning  Aerospace electronics  Microsoft Windows  Three-dimensional displays  Real-time systems 
Abstract: In this paper, we present a fast, on-line mapping and planning solution for operation in unknown, off-road, environments. We combine obstacle detection along with a terrain gradient map to make simple and adaptable cost map. This map can be created and updated at 10 Hz. An A* planner finds optimal paths over the map. Finally, we take multiple samples over the control input space and do a kinematic forward simulation to generated feasible trajectories. Then the most optimal trajectory, as determined by the cost map and proximity to A* path, is chosen and sent to the controller. Our method allows real time operation at rates of 30 Hz. We demonstrate the efficiency of our method in various off-road terrain at high speed.


Title: Scaled Autonomy: Enabling Human Operators to Control Robot Fleets
Key Words: mobile robots  multi-robot systems  telerobotics  utility function  real-world mobile robot navigation  robot fleets control  autonomous robots  human operator  teleoperation  Task analysis  Mathematical model  Navigation  Autonomous robots  Hardware  Predictive models 
Abstract: Autonomous robots often encounter challenging situations where their control policies fail and an expert human operator must briefly intervene, e.g., through teleoperation. In settings where multiple robots act in separate environments, a single human operator can manage a fleet of robots by identifying and teleoperating one robot at any given time. The key challenge is that users have limited attention: as the number of robots increases, users lose the ability to decide which robot requires teleoperation the most. Our goal is to automate this decision, thereby enabling users to supervise more robots than their attention would normally allow for. Our insight is that we can model the user's choice of which robot to control as an approximately optimal decision that maximizes the user's utility function. We learn a model of the user's preferences from observations of the user's choices in easy settings with a few robots, and use it in challenging settings with more robots to automatically identify which robot the user would most likely choose to control, if they were able to evaluate the states of all robots at all times. We run simulation experiments and a user study with twelve participants that show our method can be used to assist users in performing a simulated navigation task. We also run a hardware demonstration that illustrates how our method can be applied to a real-world mobile robot navigation task.


Title: Joint Inference of States, Robot Knowledge, and Human (False-)Beliefs
Key Words: belief networks  cognition  cognitive systems  graph theory  inference mechanisms  learning (artificial intelligence)  robots  robot knowledge  human interactions  graphical model  object states  parse graph  single-view spatiotemporal parsing  learned representation  inference algorithm  joint pg  effective reasoning  inference capability  states joint inference  human beliefs  socio-cognitive ability  false-beliefs  individual parse graph  small object tracking dataset  Robots  Cognition  Visualization  Graphical models  Psychology  Noise measurement  Object tracking 
Abstract: Aiming to understand how human (false-)belief- a core socio-cognitive ability-would affect human interactions with robots, this paper proposes to adopt a graphical model to unify the representation of object states, robot knowledge, and human (false-)beliefs. Specifically, a parse graph (pg) is learned from a single-view spatiotemporal parsing by aggregating various object states along the time; such a learned representation is accumulated as the robot's knowledge. An inference algorithm is derived to fuse individual pg from all robots across multi-views into a joint pg, which affords more effective reasoning and inference capability to overcome the errors originated from a single view. In the experiments, through the joint inference over pgs, the system correctly recognizes human (false-)belief in various settings and achieves better cross-view accuracy on a challenging small object tracking dataset.


Title: Unified Intrinsic and Extrinsic Camera and LiDAR Calibration under Uncertainties
Key Words: calibration  cameras  optical radar  LiDAR calibration  intrinsic parameters  probabilistic sense  cameras  probabilistic formulation  camera model  additional LiDAR measurements  intrinsic camera calibration  state-of-the-art calibration precision  extrinsic parameters  Cameras  Calibration  Laser radar  Three-dimensional displays  Image edge detection  Detectors 
Abstract: Many approaches for camera and LiDAR calibration are presented in literature but none of them estimates all intrinsic and extrinsic parameters simultaneously and therefore optimally in a probabilistic sense.In this work, we present a method to simultaneously estimate intrinsic and extrinsic parameters of cameras and LiDARs in a unified problem. We derive a probabilistic formulation that enables flawless integration of different measurement types without hand-tuned weights. An arbitrary number of cameras and LiDARs can be calibrated simultaneously. Measurements are not required to be time-synchronized. The method is designed to work with any camera model.In evaluation, we show that additional LiDAR measurements significantly improve intrinsic camera calibration. Further, we show on real data that our method achieves state-of-the-art calibration precision with high reliability.


Title: AC/DCC : Accurate Calibration of Dynamic Camera Clusters for Visual SLAM
Key Words: calibration  cameras  sensitivity analysis  SLAM (robots)  calibration parameters  calibration sensitivity analysis  joint angle noise  joint angle values  calibration code  dynamic camera clusters  visual SLAM  time-varying set  extrinsic calibration transformations  DCC calibration accuracy  configuration space  pixel re-projection error  fiducial target  dynamic camera cluster  pose-loop error optimization  Cameras  Calibration  Robot vision systems  Simultaneous localization and mapping  Vehicle dynamics  Optimization  Measurement uncertainty 
Abstract: In order to relate information across cameras in a Dynamic Camera Cluster (DCC), an accurate time-varying set of extrinsic calibration transformations need to be determined. Previous calibration approaches rely solely on collecting measurements from a known fiducial target which limits calibration accuracy as insufficient excitation of the gimbal is achieved. In this paper, we improve DCC calibration accuracy by collecting measurements over the entire configuration space of the gimbal and achieve a 10X improvement in pixel re-projection error. We perform a joint optimization over the calibration parameters between any number of cameras and unknown joint angles using a pose-loop error optimization approach, thereby avoiding the need for overlapping fields-of-view. We test our method in simulation and provide a calibration sensitivity analysis for different levels of camera intrinsic and joint angle noise. In addition, we provide a novel analysis of the degenerate parameters in the calibration when joint angle values are unknown, which avoids situations in which the calibration cannot be uniquely recovered. The calibration code will be made available at https://github.com/TRAILab/AC-DCC.


Title: An End-Effector Wrist Module for the Kinematically Redundant Manipulation of Arm-Type Robots
Key Words: collision avoidance  end effectors  industrial robots  motion control  redundant manipulators  end effector path tracking  6-DoF robot  8-DoF robot  redundant robot  kinematically redundant manipulation  industrial arm-type robots  dexterity  roll-pitch-roll wrist configuration  singularity free motion  end effector wrist module  collision avoidance  Wrist  Collision avoidance  Kinematics  Redundancy  Jacobian matrices  Service robots  Kinematically redundant manipulation  wrist module  roll-pitch-yaw  wrist singularity  inverse kinematics 
Abstract: Industrial arm-type robots have multiple degrees-of-freedom (DoFs) and high dexterity but the use of the roll-pitch-roll wrist configuration yields singularities inside the reachable workspace. Excessive joint velocities will occur when encountering these singularities. Arm-type robots currently don't have enough dexterity to move the end-effector path away from the wrist singularities. Robots with redundant DoFs can be used to provide additional dexterity to avoid the singularities and reduce the excessive joint velocity. An end-effector wrist module is proposed to provide two redundant DoFs when interfaced with an existing 6-DoF robot. The new 8-DoF robot has a compact roll-pitch-yaw wrist that has no singularities inside the reachable workspace. The highly redundant robot can also be used to avoid collisions in various directions. Path tracking simulation examples are provided to show the advantages of the proposed design when compared with existing redundant or nonredundant robots. We expect that this module can serve as a cost-effective solution in applications where singularity-free motion or collision-free motion is required.


Title: Online Trajectory Planning for an Industrial Tractor Towing Multiple Full Trailers
Key Words: agricultural machinery  nonlinear dynamical systems  path planning  trajectory control  vehicle dynamics  vehicle dynamics model  online trajectory planning  car-like tractor  passive full trailers  motion planning  complex nonlinear dynamics  simulation based prediction  industrial tractor-trailers vehicle  obstacle free trajectories  Agricultural machinery  Vehicle dynamics  Planning  Trajectory  Dynamics  Wheels  Lead 
Abstract: This paper presents a novel solution for online trajectory planning of a full-size tractor-trailers vehicle composed of a car-like tractor and arbitrary number of passive full trailers. The motion planning problem for such systems was rarely addressed due to the complex nonlinear dynamics. A simulation-based prediction method is proposed to easily handle the complicated nonlinear dynamics and efficiently generate the obstacle-free and dynamically feasible trajectories. The vehicle dynamics model and a two-layer controller are used in the prediction. Implementation results on the real-world full-size industrial tractor-trailers vehicle are presented to validate the performance of the proposed methods.


Title: A Bio-Inspired Transportation Network for Scalable Swarm Foraging
Key Words: collision avoidance  mobile robots  multi-robot systems  swarm intelligence  transportation  interrobot collisions  swarm robot foraging  scale-invariant swarm foraging algorithm  hierarchical branching transportation network  ubiquitous fractal branching networks  bioinspired transportation network  Robots  Transportation  Biology  Collision avoidance  Scalability  Task analysis  Explosions 
Abstract: Scalability is a significant challenge for robot swarms. Generally, larger groups of cooperating robots produce more inter-robot collisions, and in swarm robot foraging, larger search arenas result in larger travel costs. This paper demonstrates a scale-invariant swarm foraging algorithm that ensures that each robot finds and delivers targets to a central collection zone at the same rate regardless of the size of the swarm or the search area. Dispersed mobile depots aggregate locally collected targets and transport them to a central place via a hierarchical branching transportation network. This approach is inspired by ubiquitous fractal branching networks such as tree branches and animal cardiovascular networks that deliver resources to cells and determine the scale and pace of life. We demonstrate that biological scaling laws predict how quickly robots forage in simulations of up to thousands of robots searching over thousands of square meters. We then use biological scaling to predict the capacity of depot robots that overcome scaling constraints to produce scale-invariant robot swarms. We verify the claims for large swarms in simulation and implement a simple depot design in hardware.


Title: Error estimation and correction in a spiking neural network for map formation in neuromorphic hardware
Key Words: error correction  mobile robots  neural chips  neural nets  path planning  pose estimation  SLAM (robots)  error correction  SNN mechanism  neuromorphic device  form-factor neuromorphic chip  spiking neural network  map formation  neuromorphic hardware  neural networks  robot control  error estimation  simultaneous localization and mapping  robot pose estimation  SNN-based SLAM  path integration speed  Neurons  Robots  Sociology  Statistics  Light emitting diodes  Neuromorphics  Synapses 
Abstract: Neuromorphic hardware offers computing platforms for the efficient implementation of spiking neural networks (SNNs) that can be used for robot control. Here, we present such an SNN on a neuromorphic chip that solves a number of tasks related to simultaneous localization and mapping (SLAM): forming a map of an unknown environment and, at the same time, estimating the robot's pose. In particular, we present an SNN mechanism to detect and estimate errors when the robot revisits a known landmark and updates both the map and the path integration speed to reduce the error. The whole system is fully realized in a neuromorphic device, showing the feasibility of a purely SNN-based SLAM, which could be efficiently implemented in a small form-factor neuromorphic chip.


Title: Backlash-Compensated Active Disturbance Rejection Control of Nonlinear Multi-Input Series Elastic Actuators
Key Words: active disturbance rejection control  actuators  clutches  compensation  elasticity  force control  gears  manipulator dynamics  nonlinear control systems  position measurement  power transmission (mechanical)  three-term control  hybrid motor-brake-clutch series elastic actuator  positional measurement error  backlash-compensated active disturbance rejection control  nonlinear multiinput series elastic actuators  passive compliance  force-controlled robotic manipulators  elastic element  dedicated torque sensors  deflection control  nonlinear deformation  torque requirements  mechanical backlash  multiinput active disturbance rejection controller  error-based controllers  backlash-compensated ADRC  Actuators  Torque  Springs  Brakes  DC motors  Sea measurements  Hysteresis motors 
Abstract: Series elastic actuators with passive compliance have been gaining increasing popularity in force-controlled robotic manipulators. One of the reasons is the actuator's ability to infer the applied torque by measuring the deflection of the elastic element as opposed to directly with dedicated torque sensors. Proper deflection control is pinnacle to achieve a desired output torque and, therefore, small deviances in positional measurements or a nonlinear deformation can have adverse effects on performance. In applications with larger torque requirements, the actuators typically use gear reductions which inherently result in mechanical backlash. This combined with the nonlinear behaviour of the elastic element and unmodelled dynamics, can severely compromise force fidelity.This paper proposes a backlash compensating active disturbance rejection controller (ADRC) for multi-input series elastic actuators. In addition to proper deflection control, a multiinput active disturbance rejection controller is derived and implemented experimentally to mitigate any unmodelled nonlinearities or perturbations to the plant model. The controller is experimentally validated on a hybrid motor-brake-clutch series elastic actuator and the controller performance is compared against traditional error-based controllers. It is shown that the backlash compensated ADRC outperforms classical PID and ADRC methods and is a viable solution to positional measurement error in elastic actuators.


Title: Single Shot 6D Object Pose Estimation
Key Words: convolutional neural nets  object detection  pose estimation  regression analysis  stereo image processing  rigid objects  depth images  convolutional neural network  3D input data  volume elements  optimized end-to-end  multiple objects  single shot 6D object pose estimation  single shot approach  object pose network  regression task  GPU  synthetic data  public benchmark datasets  Three-dimensional displays  Solid modeling  Data models  Task analysis  Pose estimation  Image segmentation  Two dimensional displays 
Abstract: In this paper, we introduce a novel single shot approach for 6D object pose estimation of rigid objects based on depth images. For this purpose, a fully convolutional neural network is employed, where the 3D input data is spatially discretized and pose estimation is considered as a regression task that is solved locally on the resulting volume elements. With 65 fps on a GPU, our Object Pose Network (OP-Net) is extremely fast, is optimized end-to-end, and estimates the 6D pose of multiple objects in the image simultaneously. Our approach does not require manually 6D pose-annotated real-world datasets and transfers to the real world, although being entirely trained on synthetic data. The proposed method is evaluated on public benchmark datasets, where we can demonstrate that state-of-the-art methods are significantly outperformed.


Title: MulRan: Multimodal Range Dataset for Urban Place Recognition
Key Words: geophysical image processing  geophysical techniques  image recognition  mobile robots  object recognition  optical radar  radar imaging  robot vision  multimodal range dataset  radio detection and ranging  light detection and ranging  urban environment  range sensor-based place recognition  6D baseline trajectories  place recognition ground truth  image-format data  time-stamped 1D intensity arrays  polar images  image data  radar place recognition method  LiDAR  longer-range measurements  urban place recognition  MulRan  Laser radar  Radar imaging  Three-dimensional displays  Urban areas  Simultaneous localization and mapping 
Abstract: This paper introduces a multimodal range dataset namely for radio detection and ranging (radar) and light detection and ranging (LiDAR) specifically targeting the urban environment. By extending our workshop paper [1] to a larger scale, this dataset focuses on the range sensor-based place recognition and provides 6D baseline trajectories of a vehicle for place recognition ground truth. Provided radar data support both raw-level and image-format data, including a set of time-stamped 1D intensity arrays and 360° polar images, respectively. In doing so, we provide flexibility between raw data and image data depending on the purpose of the research. Unlike existing datasets, our focus is at capturing both temporal and structural diversities for range-based place recognition research. For evaluation, we applied and validated that our previous location descriptor and its search algorithm [2] are highly effective for radar place recognition method. Furthermore, the result shows that radar-based place recognition outperforms LiDAR-based one exploiting its longer-range measurements. The dataset is available from https://sites.google.com/view/mulran-pr.


Title: GPO: Global Plane Optimization for Fast and Accurate Monocular SLAM Initialization
Key Words: cameras  optimisation  pose estimation  robot vision  SLAM (robots)  GPO  global plane optimization  homography estimation  homography decomposition  monocular SLAM initialization  monocular simultaneous localization and mapping problem  camera poses  chessboard dataset  Cameras  Simultaneous localization and mapping  Optimization  Matrix decomposition  Transmission line matrix methods  Estimation  Three-dimensional displays 
Abstract: Initialization is essential to monocular Simultaneous Localization and Mapping (SLAM) problems. This paper focuses on a novel initialization method for monocular SLAM based on planar features. The algorithm starts by homography estimation in a sliding window. It then proceeds to a global plane optimization (GPO) to obtain camera poses and the plane normal. 3D points can be recovered using planar constraints without triangulation. The proposed method fully exploits the plane information from multiple frames and avoids the ambiguities in homography decomposition. We validate our algorithm on the collected chessboard dataset against baseline implementations and present extensive analysis. Experimental results show that our method outperforms the ne-tuned baselines in both accuracy and real-time.


Title: Topological Mapping for Manhattan-like Repetitive Environments
Key Words: convolutional neural nets  graph theory  image representation  optimisation  SLAM (robots)  topology  Manhattan properties  topological graph  unoptimized Pose Graph  topological Manhattan relations  ground-truth Pose Graph  real-world indoor warehouse scenes  Manhattan-like repetitive environments  topological mapping framework  neighbouring nodes  indoor warehouse setting  warehouse topological construct  deep convolutional network  Siamese-style neural network  backend pose graph optimization framework  Manhattan graph aided loop closure relations  Topology  Network topology  Simultaneous localization and mapping  Neural networks  Optimization 
Abstract: We showcase a topological mapping framework for a challenging indoor warehouse setting. At the most abstract level, the warehouse is represented as a Topological Graph where the nodes of the graph represent a particular warehouse topological construct (e.g. rackspace, corridor) and the edges denote the existence of a path between two neighbouring nodes or topologies. At the intermediate level, the map is represented as a Manhattan Graph where the nodes and edges are characterized by Manhattan properties and as a Pose Graph at the lower-most level of detail. The topological constructs are learned via a Deep Convolutional Network while the relational properties between topological instances are learnt via a Siamese-style Neural Network. In the paper, we show that maintaining abstractions such as Topological Graph and Manhattan Graph help in recovering an accurate Pose Graph starting from a highly erroneous and unoptimized Pose Graph. We show how this is achieved by embedding topological and Manhattan relations as well as Manhattan Graph aided loop closure relations as constraints in the backend Pose Graph optimization framework. The recovery of near ground-truth Pose Graph on real-world indoor warehouse scenes vindicate the efficacy of the proposed framework.


Title: Robust quadcopter control with artificial vector fields*
Key Words: autonomous aerial vehicles  control system synthesis  helicopters  mobile robots  multi-robot systems  nonlinear control systems  path planning  position control  robust control  time-varying systems  robust quadcopter control  artificial vector fields  path tracking control strategy  control laws  vector field  controlled second order integrator  quadcopter model  input-to-state stable  control inputs  Robots  Vehicle dynamics  Robustness  Convergence  Level set  Mathematical model  Force 
Abstract: This article presents a path tracking control strategy for a quadcopter to follow a time varying curve. The control is based on artificial vector fields. The construction of the field is based on a well known technique in the literature. Next, control laws are developed to impose the behavior of the vector field to a second order integrator model. Finally, control laws are developed to impose the dynamics of the controlled second order integrator to a quadcopter model, which assumes the thrust and the angular rates as input commands. Asymptotic convergence of the whole system is proved by showing that the individual systems in cascade connection are input-to-state stable. We also analyze the influence of norm-bounded disturbances in the control inputs to evaluate the robustness of the controller. We show that bounded disturbances originate limited deviations from the target curve. Simulations and a real robot experiment exemplify and validate the developed theory.


Title: Multi-modal Experts Network for Autonomous Driving
Key Words: computational complexity  control engineering computing  expert systems  inference mechanisms  learning (artificial intelligence)  mobile robots  road vehicles  sensory data  autonomous driving  autonomous vehicles  computational complexity  multistage training procedure  end-to-end learning  multimodal experts network architecture  inference time step  mixed discrete-continuous policy  Laser radar  Feature extraction  Cameras  Training  Autonomous vehicles  Robot sensing systems 
Abstract: End-to-end learning from sensory data has shown promising results in autonomous driving. While employing many sensors enhances world perception and should lead to more robust and reliable behavior of autonomous vehicles, it is challenging to train and deploy such network and at least two problems are encountered in the considered setting. The first one is the increase of computational complexity with the number of sensing devices. The other is the phenomena of network overfitting to the simplest and most informative input. We address both challenges with a novel, carefully tailored multi-modal experts network architecture and propose a multi-stage training procedure. The network contains a gating mechanism, which selects the most relevant input at each inference time step using a mixed discrete-continuous policy. We demonstrate the plausibility of the proposed approach on our 1/6 scale truck equipped with three cameras and one LiDAR.


Title: Hybrid Localization using Model- and Learning-Based Methods: Fusion of Monte Carlo and E2E Localizations via Importance Sampling
Key Words: convolutional neural nets  importance sampling  learning (artificial intelligence)  mobile robots  Monte Carlo methods  neurocontrollers  particle filtering (numerical methods)  path planning  motion model  importance sampling  convolutional neural network  CNN  Monte Carlo localization  particle filter  hybrid localization method  learning-based method  model-based method  E2E localization  MCL  CNN predictions  posterior distributions  Atmospheric measurements  Particle measurements  Proposals  Predictive models  Fuses  Learning systems  Monte Carlo methods 
Abstract: This paper proposes a hybrid localization method that fuses Monte Carlo localization (MCL) and convolutional neural network (CNN)-based end-to-end (E2E) localization. MCL is based on particle filter and requires proposal distributions to sample the particles. The proposal distribution is generally predicted using a motion model. However, because the motion model cannot handle unanticipated errors, the predicted distribution is sometimes inaccurate. The use of other ideal proposal distributions, such as the measurement model, can improve robustness against such unanticipated errors. This technique is called importance sampling (IS). However, it is difficult to sample the particles from such ideal distributions because they are not represented in the closed form. Recent works have proved that CNNs with dropout layers represent the posterior distributions over their outputs conditioned on the inputs and the CNN predictions are equivalent to sampling the outputs from the posterior. Therefore, the proposed method utilizes a CNN to sample the particles and fuses them with MCL via IS. Consequently, the advantages of both MCL and E2E localization can be simultaneously leveraged while preventing their disadvantages. Experiments demonstrate that the proposed method can smoothly estimate the robot pose, similar to the model-based method, and quickly re-localize it from the failures, similar to the learning-based method.


Title: Visual Localization with Google Earth Images for Robust Global Pose Estimation of UAVs
Key Words: autonomous aerial vehicles  distance measurement  Global Positioning System  image filtering  image registration  image sensors  mobile robots  multi-robot systems  pose estimation  rendering (computer graphics)  robot vision  Google Earth images  georeferenced rendered images  dense mutual information technique  outdoor GPS-denied environments  image registrations  gimballed visual odometry pipeline  visual localization  robust global pose estimation  multirotor UAV  typical feature-based localizer  Cameras  Image registration  Three-dimensional displays  Visualization  Earth  Robustness  Google 
Abstract: We estimate the global pose of a multirotor UAV by visually localizing images captured during a flight with Google Earth images pre-rendered from known poses. We metrically localize real images with georeferenced rendered images using a dense mutual information technique to allow accurate global pose estimation in outdoor GPS-denied environments. We show the ability to consistently localize throughout a sunny summer day despite major lighting changes while demonstrating that a typical feature-based localizer struggles under the same conditions. Successful image registrations are used as measurements in a filtering framework to apply corrections to the pose estimated by a gimballed visual odometry pipeline. We achieve less than 1 m and 1° RMSE on a 303 m flight and less than 3 m and 3° RMSE on six 1132 m flights as low as 36 m above ground level conducted at different times of the day from sunrise to sunset.


Title: Accept Synthetic Objects as Real: End-to-End Training of Attentive Deep Visuomotor Policies for Manipulation in Clutter
Key Words: clutter  computer vision  learning (artificial intelligence)  manipulators  data augmentation procedure  network architectures  implicit attention ASOR-IA  explicit attention ASOR-EA  training data  uncluttered environment  cluttered environments  end-to-end training  attentive deep visuomotor policies  end-to-end train multitask deep visuomotor policies  robotic manipulation  reinforcement learning  end-to-end LfD architectures  Accept Synthetic Objects as Real  Clutter  Robots  Training data  Task analysis  Training  Encoding  Visualization 
Abstract: Recent research demonstrated that it is feasible to end-to-end train multi-task deep visuomotor policies for robotic manipulation using variations of learning from demonstration (LfD) and reinforcement learning (RL). In this paper, we extend the capabilities of end-to-end LfD architectures to object manipulation in clutter. We start by introducing a data augmentation procedure called Accept Synthetic Objects as Real (ASOR). Using ASOR we develop two network architectures: implicit attention ASOR-IA and explicit attention ASOR-EA. Both architectures use the same training data (demonstrations in uncluttered environments) as previous approaches. Experimental results show that ASOR-IA and ASOR-EA succeed in a significant fraction of trials in cluttered environments where previous approaches never succeed. In addition, we find that both ASOR-IA and ASOR-EA outperform previous approaches even in uncluttered environments, with ASOR-EA performing better even in clutter compared to the previous best baseline in an uncluttered environment.


Title: An Open-Source Framework for Rapid Development of Interactive Soft-Body Simulations for Real-Time Training
Key Words: control engineering computing  force feedback  haptic interfaces  manipulators  medical computing  medical robotics  surgery  telerobotics  virtual reality  real-time simulation  interactive manipulation  human-readable front-end interface  commercially available haptic devices  game controllers  da Vinci Research Kit  real-time haptic feedback  multiuser training  manipulation problems  soft-body manipulation  open-source framework  interactive soft-body simulations  real-time training  master telemanipulators  Visualization  Computational modeling  Real-time systems  Training  Robots  Faces  Three-dimensional displays 
Abstract: We present an open-source framework that provides a low barrier to entry for real-time simulation, visualization, and interactive manipulation of user-specifiable soft-bodies, environments, and robots (using a human-readable front-end interface). The simulated soft-bodies can be interacted by a variety of input interface devices including commercially available haptic devices, game controllers, and the Master Tele-Manipulators (MTMs) of the da Vinci Research Kit (dVRK) with real-time haptic feedback. We propose this framework for carrying out multi-user training, user-studies, and improving the control strategies for manipulation problems. In this paper, we present the associated challenges to the development of such a framework and our proposed solutions. We also demonstrate the performance of this framework with examples of soft-body manipulation and interaction with various input devices.


Title: Towards 5-DoF Control of an Untethered Magnetic Millirobot via MRI Gradient Coils
Key Words: biomedical MRI  medical image processing  medical robotics  microrobots  path planning  surgery  untethered magnetic millirobot  MRI gradient coils  electromagnetic field gradients  magnetic resonance imaging devices  power untethered magnetic robots  MRI devices  magnetic pulling forces  drug delivery  MRI-powered untethered magnetic robots  orientation control  three-dimensional fluids  3-DoF position control  path-planning-based 5-DoF control algorithm  optimal controller  robot manufacturing errors  pitch angle  neutral pitching angle  3D Bezier curves  worst-case path-tracking error  position-tracking error  orientation-tracking error  pitch angles  future MRI-powered active imaging  laser surgery  biopsy robots  Magnetic resonance imaging  Robots  Magnetic devices  Coils  Three-dimensional displays  Force  Medical robotics  miniature robots  magnetic actuation  magnetic resonance imaging  optimal control 
Abstract: Electromagnetic field gradients generated by magnetic resonance imaging (MRI) devices pave the way to power untethered magnetic robots remotely. This innovative use of MRI devices allows exerting magnetic pulling forces on untethered magnetic robots, which could be used for navigation, diagnosis, drug delivery and therapeutic procedures inside a human body. So far, MRI-powered untethered magnetic robots lack simultaneous position and orientation control inside three-dimensional (3D) fluids, and therefore, their control has been limited to 3-DoF position control. In this paper, we present a path-planning-based 5-DoF control algorithm to steer and control an MRI-powered untethered robot's position and orientation simultaneously in 3D workspaces in fluids. Eventhough the simulation results show that the proposed optimal controller can successfully control the robot for 5-DoF, in the experiments, we observe a reduced 5-DoF controllability due to the robot manufacturing errors, which result in pitch angle to remain at around the neutral pitching angle at the steady state. The proposed controller was evaluated to track four different paths (linear, planar-horizontal, planar-vertical and 3D paths) generated by 3D Bezier curves. The worst-case path-tracking error was observed for 3D path-following experiments. For this case, the position-tracking error was 2.7±1.8 mm, and the orientation-tracking error was 13.5± 28.7 and 3.7± 10.2 degrees for yaw and pitch angles, respectively. The overall path is completed within 19.6 seconds with 23.6 mm overall displacement and 61.2 and 41.2 degrees of yaw and pitch angle rotation, respectively. Such robots can be used in future MRI-powered active imaging, laser surgery and biopsy robots inside a fluid-filled stomach type of organs.


Title: Balance of Humanoid Robots in a Mix of Fixed and Sliding Multi-Contact Scenarios
Key Words: approximation theory  humanoid robots  legged locomotion  quadratic programming  humanoid robots  multilegged robots  multicontact setting  desired sliding-task motions  center-of-mass  admissible convex area  contact positions  CoM support area  CSA  appropriate CoM position  multiple fixed sliding contacts  HRP-4 humanoid robot  quadratic programming  QP optimization problems  Humanoid robots  Mathematical model  Friction  Task analysis  Gravity  Humanoid and multi-legged robots  balance  multi-contacts  sliding contacts 
Abstract: This study deals with the balance of humanoid or multi-legged robots in a multi-contact setting where a chosen subset of contacts is undergoing desired sliding-task motions. One method to keep balance is to hold the center-of-mass (CoM) within an admissible convex area. This area is calculated based on the contact positions and forces. We introduce a methodology to compute this CoM support area (CSA) for multiple fixed and intentionally sliding contacts. To select the most appropriate CoM position within CSA, we account for (i) constraints of multiple fixed and sliding contacts, (ii) desired wrench distribution for contacts, and (iii) desired CoM position (eventually dictated by other tasks). These are formulated as a quadratic programming (QP) optimization problems. We illustrate our approach with pushing against a wall and wiping, and conducted experiments using the HRP-4 humanoid robot.


Title: Finding Locomanipulation Plans Quickly in the Locomotion Constrained Manifold
Key Words: end effectors  humanoid robots  legged locomotion  manipulator dynamics  mobile robots  motion control  path planning  robot programming  locomanipulation plans  locomotion constrained manifold  end-effector trajectory  injective locomotion constraint manifold  locomotion scheme  admissible manipulation trajectories  weighted-A* graph search  planner output  contact transitions  path progression trajectory  whole-body kinodynamic locomanipulation plan  locomanipulability region  edge transition feasibility  NASA Valkyrie robot platform  dynamic locomotion approach  example locomanipulation scenarios  divergent-component-of-motion  Trajectory  Task analysis  Foot  Manifolds  Pelvis  Legged locomotion 
Abstract: We present a method that finds locomanipulation plans that perform simultaneous locomotion and manipulation of objects for a desired end-effector trajectory. Key to our approach is to consider an injective locomotion constraint manifold that defines the locomotion scheme of the robot and then using this constraint manifold to search for admissible manipulation trajectories. The problem is formulated as a weighted-A* graph search whose planner output is a sequence of contact transitions and a path progression trajectory to construct the whole-body kinodynamic locomanipulation plan. We also provide a method for computing, visualizing, and learning the locomanipulability region, which is used to efficiently evaluate the edge transition feasibility during the graph search. Numerical simulations are performed with the NASA Valkyrie robot platform that utilizes a dynamic locomotion approach, called the divergent-component-of-motion (DCM), on two example locomanipulation scenarios.


Title: Dense r-robust formations on lattices
Key Words: energy consumption  multi-robot systems  network theory (graphs)  cubic lattices  dense r-robust formations  robot networks  malicious robots  defective robots  high energy consumption  communication network  robot formations  square lattices  triangular lattices  Lattices  Robot kinematics  Communication networks  Robustness  Robot sensing systems  Energy consumption 
Abstract: Robot networks are susceptible to fail under the presence of malicious or defective robots. Resilient networks in the literature require high connectivity and large communication ranges, leading to high energy consumption in the communication network. This paper presents robot formations with guaranteed resiliency that use smaller communication ranges than previous results in the literature. The formations can be built on triangular and square lattices in the plane, and cubic lattices in the three-dimensional space. We support our theoretical framework with simulations.


Title: Optimizing Topologies for Probabilistically Secure Multi-Robot Systems
Key Words: combinatorial mathematics  computational complexity  graph theory  matrix algebra  Monte Carlo methods  multi-robot systems  optimisation  set theory  statistical distributions  multirobot system  MRS  robot interactions  probability distribution  optimal solution  rooted k-connections problem  graph transformations  weighted matroid intersection algorithm  edge set  interaction graph  optimal security solution  secure multirobot systems  Robots  Probabilistic logic  Security  Optimization  Topology  Observers  Multi-robot systems 
Abstract: In this paper, we optimize the interaction graph of a multi-robot system (MRS) by maximizing its probability of security while requiring the MRS to have the fewest edges possible. Edges that represent robot interactions exist according to a probability distribution and security is defined using the control theoretic notion of left invertibility. To compute an optimal solution to our problem, we first start by reducing our problem to a variation of the rooted k-connections problem using three graph transformations. Then, we apply a weighted matroid intersection algorithm (WMIA) on matroids defined on the edge set of the interaction graph. Although the optimal solution can be found in polynomial time, MRSs are dynamic and their topologies may change faster than the rate at which the optimal security solution can be found. To cope with dynamic behavior, we present two heuristics that relax optimality but execute with much lower time complexity. Finally, we validate our results through Monte Carlo simulations.


Title: Efficient Communication in Large Multi-robot Networks
Key Words: multi-robot systems  peer-to-peer computing  radiocommunication  communication routing  ground-level communication  multirobot coordination frameworks  multirobot system  multirobot networks  peer-to-peer radio communication  Robot kinematics  Routing  Multi-robot systems  Complexity theory  Relays  Communication networks 
Abstract: To achieve coordination in a multi-robot system, the robots typically resort to some form of communication among each other. In most of the multi-robot coordination frameworks, high-level coordination strategies are studied but `how' the ground-level communication takes place, is assumed to be taken care of by another program. In this paper, we study the communication routing problem for large multi-robot systems where the robots have limited communication ranges. The objective is to send a message from a robot to another in the network, routed through a low number of other robots. To this end, we propose a communication model between any pair of robots using peer-to-peer radio communication. Our proposed model is generic to any type of message and guarantees a low hop routing between any pair of robots in this network. These help the robots to exchange large messages (e.g., multi-spectral images) in a short amount of time. Results show that our proposed approach easily scales up to 1000 robots while drastically reducing the space complexity for maintaining the network information.


Title: CyPhyHouse: A programming, simulation, and deployment toolchain for heterogeneous distributed coordination
Key Words: control engineering computing  control system synthesis  learning (artificial intelligence)  middleware  mobile computing  mobile robots  multi-threading  path planning  program debugging  specification languages  heterogeneous distributed coordination  libraries  development tools  application development processes  mobile computing  machine learning  CyPhyHouse  debugging  distributed mobile robotic applications  distributed applications  Koord programming language  controller design  distributed network protocols  platform-independent middleware  path planning  multithreaded simulator  Koord applications  application code  heterogeneous agents  heterogeneous mobile platforms  design cycles  robotic testbed  distributed task allocation  deployment toolchain  hardware-agnostic application  Robot kinematics  Task analysis  Middleware  Collision avoidance  Python 
Abstract: Programming languages, libraries, and development tools have transformed the application development processes for mobile computing and machine learning. This paper introduces CyPhyHouse-a toolchain that aims to provide similar programming, debugging, and deployment benefits for distributed mobile robotic applications. Users can develop hardware-agnostic, distributed applications using the high-level, event driven Koord programming language, without requiring expertise in controller design or distributed network protocols. The modular, platform-independent middleware of CyPhyHouse implements these functionalities using standard algorithms for path planning (RRT), control (MPC), mutual exclusion, etc. A high-fidelity, scalable, multi-threaded simulator for Koord applications is developed to simulate the same application code for dozens of heterogeneous agents. The same compiled code can also be deployed on heterogeneous mobile platforms. The effectiveness of CyPhyHouse in improving the design cycles is explicitly illustrated in a robotic testbed through development, simulation, and deployment of a distributed task allocation application on in-house ground and aerial vehicles.


Title: Chance Constrained Simultaneous Path Planning and Task Assignment for Multiple Robots with Stochastic Path Costs
Key Words: distributed algorithms  graph theory  multi-robot systems  path planning  probability  stochastic processes  simultaneous path planning  multiple robots  stochastic path costs  stochastic edge costs  robot team  stochastic travel costs  chance-constrained simultaneous task assignment  deterministic simultaneous task assignment  shortest paths  task locations  linear assignment problem  CC-STAP  Robots  Task analysis  Collision avoidance  Path planning  Resource management  Random variables  Planning 
Abstract: We present a novel algorithm for simultaneous task assignment and path planning on a graph (or roadmap) with stochastic edge costs. In this problem, the initially unassigned robots and tasks are located at known positions in a roadmap. We want to assign a unique task to each robot and compute a path for the robot to go to its assigned task location. Given the mean and variance of travel cost of each edge, our goal is to develop algorithms that, with high probability, the total path cost of the robot team is below a minimum value in any realization of the stochastic travel costs. We formulate the problem as a chance-constrained simultaneous task assignment and path planning problem (CC-STAP). We prove that the optimal solution of CC-STAP can be obtained by solving a sequence of deterministic simultaneous task assignment and path planning problems in which the travel cost is a linear combination of mean and variance of the edge cost. We show that the deterministic problem can be solved in two steps. In the first step, robots compute the shortest paths to the task locations and in the second step, the robots solve a linear assignment problem with the costs obtained in the first step. We also propose a distributed algorithm that solves CC-STAP near-optimally. We present simulation results on randomly generated networks and data to demonstrate that our algorithm is scalable with the number of robots (or tasks) and the size of the network.


Title: Optimal Topology Selection for Stable Coordination of Asymmetrically Interacting Multi-Robot Systems
Key Words: integer programming  mathematical programming  motion control  multi-robot systems  topology  stable coordinated motion  robot-to-robot interactions  asymmetric interaction topologies  multirobot motion  mixed integer semidefinite programming  multirobot systems  asymmetric interactions  optimal topology selection  Robot kinematics  Topology  Robot sensing systems  Multi-robot systems  Symmetric matrices  Laplace equations 
Abstract: In this paper, we address the problem of optimal topology selection for stable coordination of multi-robot systems with asymmetric interactions. This problem arises naturally for multi-robot systems that interact based on sensing, e.g., with limited field of view (FOV) cameras. From our previous efforts on motion control in such settings, we have shown that not all interaction topologies yield stable coordinated motion when asymmetry exists. At the same time, not all robot-to-robot interactions are of equal quality, and thus we seek to optimize asymmetric interaction topologies subject to the constraint that the topology yields stable multi-robot motion. In this context, we formulate an optimal topology selection problem (OTSP) as a mixed integer semidefinite programming (MISDP) problem to compute optimal topologies that yield stable coordinated motion. Simulation results are provided to corroborate the effectiveness of the proposed OTSP formulation.


Title: Low Latency And Low-Level Sensor Fusion For Automotive Use-Cases
Key Words: belief networks  image fusion  object detection  sensor synchronization  multiple sensors  object detection  low-level sensor fusion  automotive use-cases  probabilistic low level automotive sensor fusion approach  camera data  associated data  sensor modalities  probabilistic fusion  association method  Cameras  Three-dimensional displays  Object detection  Sensor fusion  Robot sensing systems  Two dimensional displays  Radar  sensor fusion  object detection  Bayesian networks 
Abstract: This work proposes a probabilistic low level automotive sensor fusion approach using LiDAR, RADAR and camera data. The method is stateless and directly operates on associated data from all sensor modalities. Tracking is not used, in order to reduce the object detection latency and create existence hypotheses per frame. The probabilistic fusion uses input from 3D and 2D space. An association method using a combination of overlap and distance metrics, avoiding the need for sensor synchronization is proposed. A Bayesian network executes the sensor fusion. The proposed approach is compared with a state of the art fusion system, which is using multiple sensors of the same modality and relies on tracking for object detection. Evaluation was done using low level sensor data recorded in an urban environment. The test results show that the low level sensor fusion reduces the object detection latency.


Title: Who2com: Collaborative Perception via Learnable Handshake Communication
Key Words: aircraft communication  autonomous aerial vehicles  image segmentation  learning (artificial intelligence)  multi-agent systems  multi-robot systems  neural nets  visual perception  degraded sensor data  compressed request  aerial robots  semantic segmentation task  collaborative perception  learnable handshake communication  local observations  neighboring agents  multiagent reinforcement learning  bandwidth-sensitive manner  scene understanding tasks  communication protocols  multistage handshake communication mechanism  neural network  Who2com  AirSim simulator  AirSim-CP dataset  Task analysis  Bandwidth  Semantics  Training  Collaboration  Robot sensing systems 
Abstract: In this paper, we propose the problem of collaborative perception, where robots can combine their local observations with those of neighboring agents in a learnable way to improve accuracy on a perception task. Unlike existing work in robotics and multi-agent reinforcement learning, we formulate the problem as one where learned information must be shared across a set of agents in a bandwidth-sensitive manner to optimize for scene understanding tasks such as semantic segmentation. Inspired by networking communication protocols, we propose a multi-stage handshake communication mechanism where the neural network can learn to compress relevant information needed for each stage. Specifically, a target agent with degraded sensor data sends a compressed request, the other agents respond with matching scores, and the target agent determines who to connect with (i.e., receive information from). We additionally develop the AirSim-CP dataset and metrics based on the AirSim simulator where a group of aerial robots perceive diverse landscapes, such as roads, grasslands, buildings, etc. We show that for the semantic segmentation task, our handshake communication method significantly improves accuracy by approximately 20% over decentralized baselines, and is comparable to centralized ones using a quarter of the bandwidth.


Title: Comparing View-Based and Map-Based Semantic Labelling in Real-Time SLAM
Key Words: data visualisation  image representation  learning (artificial intelligence)  mobile robots  SLAM (robots)  view-based labelling  spatial AI systems  real-time height map fusion  map-based labelling  generated scene model  input view-wise data  estimate labels  clear groups  labelling scenes  semantic labels  geometric models  persistent scene representations  real-time SLAM  map-based semantic labelling  Labeling  Semantics  Three-dimensional displays  Simultaneous localization and mapping  Cameras  Image reconstruction  Real-time systems 
Abstract: Generally capable Spatial AI systems must build persistent scene representations where geometric models are combined with meaningful semantic labels. The many approaches to labelling scenes can be divided into two clear groups: view-based which estimate labels from the input view-wise data and then incrementally fuse them into the scene model as it is built; and map-based which label the generated scene model. However, there has so far been no attempt to quantitatively compare view-based and map-based labelling. Here, we present an experimental framework and comparison which uses real-time height map fusion as an accessible platform for a fair comparison, opening up the route to further systematic research in this area.


Title: Real-time Continuous Hand Motion Myoelectric Decoding by Automated Data Labeling*
Key Words: biomechanics  electromyography  gesture recognition  image motion analysis  learning (artificial intelligence)  medical signal processing  prosthetics  sEMG data  hand motion measurement  automated data labeling neural network  hand motion myoelectric decoding  hand motion labels  unsupervised neural network  unlabeled sEMG  hand motion signals  bio-signals  surface electromyography array  dataset collecting  Muscles  Neurons  Wrist  Training  Feature extraction  Neural networks  Principal component analysis 
Abstract: In this paper an automated data labeling (ADL) neural network is proposed to streamline dataset collecting for real-time predicting the continuous motion of hand and wrist, these gestures are only decoded from a surface electromyography (sEMG) array of eight channels. Unlike collecting both the bio-signals and hand motion signals as samples and labels in supervised learning, this algorithm only collects unlabeled sEMG into an unsupervised neural network, in which the hand motion labels are auto-generated. The coefficient of determination (R2) for three DOFs, i.e. wrist flex/extension, wrist pro/supination, hand open/close, was 0.86, 0.89 and 0.87 respectively. The comparison between real motion labels and auto-generated labels shows that the latter has earlier response than former. The results of Fitts' law test indicate that ADL has capability of controlling multi-DOFs simultaneously even though the training set only contains sEMG data from single DOF gesture. Moreover, no more hand motion measurement needed which greatly helps upper limb amputee imagine the gesture of residual limb to control a dexterous prosthesis.


Title: Real-time Stereo Visual Servoing for Rose Pruning with Robotic Arm
Key Words: cutting  end effectors  gardening  real-time systems  robot vision  service robots  stereo image processing  visual servoing  multiple cameras  single stereo camera  end effector  robotic arm  real time stereo visual servoing  automated robotic rose cutter  rose bush pruning  gardening  rose pruning robots  Cameras  Robot vision systems  Manipulators  Real-time systems  Pipelines  Task analysis 
Abstract: The paper presents a working pipeline which integrates hardware and software in an automated robotic rose cutter. To the best of our knowledge, this is the first robot able to prune rose bushes in a natural environment. Unlike similar approaches like tree stem cutting, the proposed method does not require to scan the full plant, have multiple cameras around the bush, or assume that a stem does not move. It relies on a single stereo camera mounted on the end-effector of the robot and real-time visual servoing to navigate to the desired cutting location on the stem. The evaluation of the whole pipeline shows a good performance in a garden with unconstrained conditions, where finding and approaching a specific location on a stem is challenging due to occlusions caused by other stems and dynamic changes caused by the wind.


Title: Interval Search Genetic Algorithm Based on Trajectory to Solve Inverse Kinematics of Redundant Manipulators and Its Application
Key Words: end effectors  genetic algorithms  kinematics  redundant manipulators  search problems  trajectory control  tunnels  interval search strategy  reference point strategy  redundant manipulators  continuous motion  interval search genetic algorithm  inverse kinematics problem  parametric joint angle method  population continuity strategy  trajectory control  evolutionary generation  fitness function  tunnel shotcrete robot  end effector  Manipulators  Kinematics  Sociology  Statistics  Trajectory  Genetic algorithms  Task analysis 
Abstract: In this paper, a new method is proposed to solve the inverse kinematics problem of redundant manipulators. This method demonstrates superior performance on continuous motion by combining interval search genetic algorithm based on trajectory which we propose with parametric joint angle method. In this method, population continuity strategy is utilized to improve search speed and reduce evolutionary generation, interval search strategy is introduced to enhance the search ability and overcome the influence of singularity, and reference point strategy is used to avoid sudden changes of joint variables. By introducing those three strategies, this method is especially suitable for redundant manipulators that perform continuous motion. It can not only obtain solutions of inverse kinematics quickly, but also ensure the motion continuity of manipulator and accuracy of the end effector. Moreover, this algorithm can also perform multi-objective tasks by adjusting the fitness function. Finally, this algorithm is applied to an 8 degree of freedom tunnel shotcrete robot. Field experiments and data analysis show that the algorithm can solve the problem quickly in industrial field, and ensure the motion continuity and accuracy.


Title: Multi-task closed-loop inverse kinematics stability through semidefinite programming
Key Words: closed loop systems  control system synthesis  discrete time systems  humanoid robots  linear matrix inequalities  Lyapunov methods  mathematical programming  mobile robots  robot kinematics  stability  multitask closed-loop inverse kinematics stability  multiobjective task resolution  humanoid robots  local stability problem  closed-loop inverse kinematics algorithm  highly redundant robots  system stability  closed-loop control gains  semidefinite programming problem  discrete-time Lyapunov stability condition  SDP optimization problem  stability conditions  Task analysis  Stability analysis  Robots  Kinematics  Thermal stability  Numerical stability  Asymptotic stability 
Abstract: Today's complex robotic designs comprise in some cases a large number of degrees of freedom, enabling for multi-objective task resolution (e.g., humanoid robots or aerial manipulators). This paper tackles the local stability problem of a hierarchical closed-loop inverse kinematics algorithm for such highly redundant robots. We present a method to guarantee this system stability by performing an online tuning of the closed-loop control gains. We define a semi-definite programming problem (SDP) with these gains as decision variables and a discrete-time Lyapunov stability condition as a linear matrix inequality, constraining the SDP optimization problem and guaranteeing the local stability of the prioritized tasks. To the best of authors' knowledge, this work represents the first mathematical development of an SDP formulation that introduces these stability conditions for a multi-objective closed-loop inverse kinematic problem for highly redundant robots. The validity of the proposed approach is demonstrated through simulation case studies, including didactic examples and a Matlab toolbox for the benefit of the community.


Title: Trajectory Planning with Safety Guaranty for a Multirotor based on the Forward and Backward Reachability Analysis
Key Words: aircraft control  collision avoidance  helicopters  reachability analysis  robust control  set theory  trajectory control  obstacle avoidance  risk free flight  backward reachable sets  forward reachable sets  robust trajectory planning algorithm  safety guarantee  multirotor  Hamilton-Jacobi reachability analysis  Trajectory  Planning  Safety  Reachability analysis  Robustness  Optimization  Aerospace engineering 
Abstract: Planning a trajectory with guaranteed safety is a core part for a risk-free flight of a multirotor. If a trajectory planner only aims to ensure safety, it may generate trajectories which overly bypass risky regions and prevent the system from achieving specific missions. This work presents a robust trajectory planning algorithm which simultaneously guarantees the safety and reachability to the target state in the presence of unknown disturbances. We first characterize how the forward and backward reachable sets (FRSs and BRSs) are constructed by using Hamilton-Jacobi reachability analysis. Based on the analysis, we present analytic expressions for the reachable sets and then propose minimal ellipsoids which closely approximate the reachable sets. In the planning process, we optimize the reference trajectory to connect the FRSs and BRSs, while avoiding obstacles. By combining the FRSs and BRSs, we can guarantee that any state inside of the initial set reaches the target set. We validate the proposed algorithm through a simulation of traversing a narrow gap.


Title: Segregation of Heterogeneous Swarms of Robots in Curves
Key Words: collision avoidance  decentralised control  mobile robots  multi-robot systems  topology  decentralized control strategy  heterogeneous robot swarms  formation control  collision avoidance strategy  multiple heterogeneous robots  heterogeneous swarm segregation  Collision avoidance  Robot kinematics  Heuristic algorithms  Topology  Convergence  Damping 
Abstract: This paper proposes a decentralized control strategy to reach segregation in heterogeneous robot swarms distributed in curves. The approach is based on a formation control algorithm applied to each robot and a heuristics to compute the distance between the groups, i.e. the distance from the beginning of the curve. We consider that robots can communicate through a fixed underlying topology and also when they are within a certain distance. A convergence proof with a collision avoidance strategy is presented. Simulations and experimental results show that our approach allows a swarm of multiple heterogeneous robots to segregate into groups.


Title: A Fast, Accurate, and Scalable Probabilistic Sample-Based Approach for Counting Swarm Size
Key Words: control engineering computing  distributed algorithms  multi-robot systems  particle swarm optimisation  path planning  counting swarm  distributed algorithm  neighboring robots  robot swarm  Robots  Estimation  Shape  Task analysis  Heuristic algorithms  Random variables  Clocks 
Abstract: This paper describes a distributed algorithm for computing the number of robots in a swarm, only requiring communication with neighboring robots. The algorithm can adjust the estimated count when the number of robots in the swarm changes, such as the addition or removal of robots. Probabilistic guarantees are given, which show the accuracy of this method, and the trade-off between accuracy, speed, and adaptability to changing numbers. The proposed approach is demonstrated in simulation as well as a real swarm of robots.


Title: Bayes Bots: Collective Bayesian Decision-Making in Decentralized Robot Swarms
Key Words: Bayes methods  decision making  multi-robot systems  collective Bayesian decision-making  decentralized robot swarms  distributed Bayesian algorithm  spatially distributed feature  farm field  robotics  decentralized Bayesian algorithms  sparsely distributed robots  decision-making accuracy  bio-inspired positive feedback  fixed-time benchmark algorithm  Bayes bots  bio-inspired approaches  Robot sensing systems  Bayes methods  Decision making  Classification algorithms  Task analysis  Color 
Abstract: We present a distributed Bayesian algorithm for robot swarms to classify a spatially distributed feature of an environment. This type of "go/no-go" decision appears in applications where a group of robots must collectively choose whether to take action, such as determining if a farm field should be treated for pests. Previous bio-inspired approaches to decentralized decision-making in robotics lack a statistical foundation, while decentralized Bayesian algorithms typically require a strongly connected network of robots. In contrast, our algorithm allows simple, sparsely distributed robots to quickly reach accurate decisions about a binary feature of their environment. We investigate the speed vs. accuracy tradeoff in decision-making by varying the algorithm's parameters. We show that making fewer, less-correlated observations can improve decision-making accuracy, and that a well-chosen combination of prior and decision threshold allows for fast decisions with a small accuracy cost. Both speed and accuracy also improved with the addition of bio-inspired positive feedback. This algorithm is also adaptable to the difficulty of the environment. Compared to a fixed-time benchmark algorithm with accuracy guarantees, our Bayesian approach resulted in equally accurate decisions, while adapting its decision time to the difficulty of the environment.


Title: Supervisory Control of Robot Swarms Using Public Events
Key Words: discrete event systems  mobile robots  multi-robot systems  robot swarms  public events  supervisory control theory  formal framework  discrete event systems  correct-by-construction controllers  swarm robotics systems  extended SCT framework  mobile robots  e-puck robots  Collision avoidance  Robot sensing systems  Mobile robots  Generators  Supervisory control 
Abstract: Supervisory Control Theory (SCT) provides a formal framework for controlling discrete event systems. It has recently been used to generate correct-by-construction controllers for swarm robotics systems. Current SCT frameworks are limited, as they support only (private) events that are observable within the same robot. In this paper, we propose an extended SCT framework that incorporates (public) events that are shared among robots. The extended framework allows to model formally the interactions among the robots. It is evaluated using a case study, where a group of mobile robots need to synchronise their movements in space and time-a requirement that is specified at the formal level. We validate our approach through experiments with groups of e-puck robots.


Title: Automatic tool for Gazebo world construction: from a grayscale image to a 3D solid model
Key Words: control engineering computing  laser ranging  mobile robots  SLAM (robots)  solid modelling  Gazebo world construction  grayscale image  3D solid model  robot simulators  simulated physical environment  2D image  2D laser range finder data  Gazebo simulator  3D Collada  simultaneous localization and mapping  real-time factor  SLAM missions  RTF  Tools  Solid modeling  Three-dimensional displays  Robot sensing systems  Gray-scale  Collision avoidance 
Abstract: Robot simulators provide an easy way for evaluation of new concepts and algorithms in a simulated physical environment reducing development time and cost. Therefore it is convenient to have a tool that quickly creates a 3D landscape from an arbitrary 2D image or 2D laser range finder data. This paper presents a new tool that automatically constructs such landscapes for Gazebo simulator. The tool converts a grayscale image into a 3D Collada format model, which could be directly imported into Gazebo. We run three different simultaneous localization and mapping (SLAM) algorithms within three varying complexity environments that were constructed with our tool. A real-time factor (RTF) was used as an efficiency benchmark. Successfully completed SLAM missions with acceptable RTF levels demonstrated the efficiency of the tool. The source code is available for free academic use.


Title: Toward Sim-to-Real Directional Semantic Grasping
Key Words: control engineering computing  end effectors  grippers  image colour analysis  learning (artificial intelligence)  rendering (computer graphics)  robot vision  directional semantic grasping  deep reinforcement learning  double deep Q-network  robot simulator  rendering  monocular RGB images  wrist mounted camera  cartesian robot control  crossentropy method  domain randomization  end effector  Grippers  Grasping  Cameras  Training  Robot vision systems 
Abstract: We address the problem of directional semantic grasping, that is, grasping a specific object from a specific direction. We approach the problem using deep reinforcement learning via a double deep Q-network (DDQN) that learns to map downsampled RGB input images from a wrist-mounted camera to Q-values, which are then translated into Cartesian robot control commands via the cross-entropy method (CEM). The network is learned entirely on simulated data generated by a custom robot simulator that models both physical reality (contacts) and perceptual quality (high-quality rendering). The reality gap is bridged using domain randomization. The system is an example of end-to-end (mapping input monocular RGB images to output Cartesian motor commands) grasping of objects from multiple pre-defined object-centric orientations, such as from the side or top. We show promising results in both simulation and the real world, along with some challenges faced and the need for future research in this area.


Title: A Single Multi-Task Deep Neural Network with Post-Processing for Object Detection with Reasoning and Robotic Grasp Detection
Key Words: humanoid robots  inference mechanisms  manipulators  neural nets  object detection  robot vision  robotic grasp detection  object detection  separate networks  target objects  single RGB-D camera  multitask DNN  accurate detections  relationship reasoning  state-of-the-art performance  object grasping tasks  humanoid robot  single multitask deep neural network  deep neural network based object  network output  high-level reasoning  VMRD  Cornell datasets  Robots  Grasping  Cognition  Task analysis  Neural networks  Grippers  Object detection 
Abstract: Applications of deep neural network (DNN) based object and grasp detections could be expanded significantly when the network output is processed by a high-level reasoning over relationship of objects. Recently, robotic grasp detection and object detection with reasoning have been investigated using DNNs. There have been efforts to combine these multitasks using separate networks so that robots can deal with situations of grasping specific target objects in the cluttered, stacked, complex piles of novel objects from a single RGB-D camera. We propose a single multi-task DNN that yields accurate detections of objects, grasp position and relationship reasoning among objects. Our proposed methods yield state-of-the-art performance with the accuracy of 98.6% and 74.2% with the computation speed of 33 and 62 frame per second on VMRD and Cornell datasets, respectively. Our methods also yielded 95.3% grasp success rate for novel object grasping tasks with a 4-axis robot arm and 86.7% grasp success rate in cluttered novel objects with a humanoid robot.


Title: Practical Persistence Reasoning in Visual SLAM
Key Words: mobile robots  robot vision  SLAM (robots)  static environments  dynamic environments  persistence filters  ORB-SLAM  visual SLAM algorithm  persistence filtering  persistence reasoning  semistatic environments  Simultaneous localization and mapping  Visualization  Estimation  Cognition  Probability  Feature extraction 
Abstract: Many existing SLAM approaches rely on the assumption of static environments for accurate performance. However, several robot applications require them to traverse repeatedly in semi-static or dynamic environments. There has been some recent research interest in designing persistence filters to reason about persistence in such scenarios. Our goal in this work is to incorporate such persistence reasoning in visual SLAM. To this end, we incorporate persistence filters [1] into ORB-SLAM, a well-known visual SLAM algorithm. We observe that the simple integration of their proposal results in inefficient persistence reasoning. Through a series of modifications and using two locally collected datasets, we demonstrate the utility of such persistence filtering as well as our customizations in ORB-SLAM. Overall, incorporating persistence filtering could result in a significant reduction in map size (about 30% in the best case) and a corresponding reduction in run-time while retaining similar accuracy to methods that use much larger maps.


Title: FlowFusion: Dynamic Dense RGB-D SLAM Based on Optical Flow
Key Words: cameras  image colour analysis  image motion analysis  image reconstruction  image segmentation  image sequences  mobile robots  motion estimation  robot vision  SLAM (robots)  dynamic environments  visual SLAM  moving objects  static environment features  lead  wrong camera motion estimation  dense RGB-D SLAM solution  camera ego-motion estimation  static background reconstructions  optical flow residuals  dynamic semantics  RGB-D point clouds  camera tracking  background reconstruction  dense reconstruction results  dynamic scenes  static environments  dynamic dense RGB-D SLAM  Cameras  Dynamics  Optical imaging  Simultaneous localization and mapping  Three-dimensional displays  Two dimensional displays  Robustness 
Abstract: Dynamic environments are challenging for visual SLAM since the moving objects occlude the static environment features and lead to wrong camera motion estimation. In this paper, we present a novel dense RGB-D SLAM solution that simultaneously accomplishes the dynamic/static segmentation and camera ego-motion estimation as well as the static background reconstructions. Our novelty is using optical flow residuals to highlight the dynamic semantics in the RGB-D point clouds and provide more accurate and efficient dynamic/static segmentation for camera tracking and background reconstruction. The dense reconstruction results on public datasets and real dynamic scenes indicate that the proposed approach achieved accurate and efficient performances in both dynamic and static environments compared to state-of-the-art approaches.


Title: Learn-to-Recover: Retrofitting UAVs with Reinforcement Learning-Assisted Flight Control Under Cyber-Physical Attacks
Key Words: actuators  aerospace computing  autonomous aerial vehicles  control engineering computing  fault diagnosis  fault tolerant control  helicopters  learning (artificial intelligence)  position control  security of data  stability  fault-tolerant control policy  actuator  stabilizing controller  detection activation  sensor faults  position control  learn-to-recover  UAVs  reinforcement learning-assisted flight control  cyber-physical attacks  quadcopter unmanned aerial vehicles  sensor attack  Actuators  Fault tolerance  Fault tolerant systems  Vehicle dynamics  Learning (artificial intelligence)  Training  Solid modeling 
Abstract: In this paper, we present a generic fault-tolerant control (FTC) strategy via reinforcement learning (RL). We demonstrate the effectiveness of this method on quadcopter unmanned aerial vehicles (UAVs). The fault-tolerant control policy is trained to handle actuator and sensor fault/attack. Unlike traditional FTC, this policy does not require fault detection and diagnosis (FDD) nor tailoring the controller for specific attack scenarios. Instead, the policy is running simultaneously alongside the stabilizing controller without the need for on- detection activation. The effectiveness of the policy is compared with traditional active and passive FTC strategies against actuator and sensor faults. We compare their performance in position control tasks via simulation and experiments on quadcopters. The result shows that the strategy can effectively tolerate different types of attacks/faults and maintain the vehicle's position, outperforming the other two methods.


Title: Towards the Probabilistic Fusion of Learned Priors into Standard Pipelines for 3D Reconstruction
Key Words: geometry  image reconstruction  learning (artificial intelligence)  neural nets  probability  stereo image processing  probabilistic fusion  standard pipelines  deep learning  standard 3D reconstruction pipelines  open problem  deep neural network  error models  standard 3D reconstruction system  dense depth maps  discrete probability distributions  nonparametric probability distributions  multiview stereo approaches  geometry- based systems  learned single-view depth prior  Standards  Probability distribution  Fuses  Image reconstruction  Three-dimensional displays  Uncertainty  Probability density function 
Abstract: The best way to combine the results of deep learning with standard 3D reconstruction pipelines remains an open problem. While systems that pass the output of traditional multi-view stereo approaches to a network for regularisation or refinement currently seem to get the best results, it may be preferable to treat deep neural networks as separate components whose results can be probabilistically fused into geometry- based systems. Unfortunately, the error models required to do this type of fusion are not well understood, with many different approaches being put forward. Recently, a few systems have achieved good results by having their networks predict probability distributions rather than single values. We propose using this approach to fuse a learned single-view depth prior into a standard 3D reconstruction system. Our system is capable of incrementally producing dense depth maps for a set of keyframes. We train a deep neural network to predict discrete, nonparametric probability distributions for the depth of each pixel from a single image. We then fuse this "probability volume" with another probability volume based on the photometric consistency between subsequent frames and the keyframe image. We argue that combining the probability volumes from these two sources will result in a volume that is better conditioned. To extract depth maps from the volume, we minimise a cost function that includes a regularisation term based on network predicted surface normals and occlusion boundaries. Through a series of experiments, we demonstrate that each of these components improves the overall performance of the system.


Title: Model Reference Adaptive Control of Multirotor for Missions with Dynamic Change of Payloads During Flight
Key Words: aerospace robotics  aircraft control  attitude control  helicopters  MIMO systems  model reference adaptive control systems  nonlinear control systems  robust control  stability  payloads  multirotor aerial robot  flight controller  flight stability  attitude control  aerial robot system  model reference adaptive control  nonlinear multiple-input and multiple-output  MRAC  Attitude control  Adaptation models  Payloads  MIMO communication  Unmanned aerial vehicles  Adaptive control  Gravity 
Abstract: Carrying payloads in air is a major mission for multirotor aerial robot. However, the presence of payloads on multirotor aerial robot has a risk of degrading the performance of the flight controller. This concern becomes obvious especially when carrying objects not securely attached to the body or performing aerial manipulation. Therefore, controller with the ability to adapt itself to the effects of payloads on flight stability is needed. This paper proposes a novel nonlinear multiple-input and multiple-output (MIMO) model reference adaptive control (MRAC) system for attitude control of multirotor aerial robots which can dynamically compensate change in the position of center of gravity and inertia caused by payloads. Stability and robustness of the controller are experimentally confirmed in quadrotor and transformable multirotor, and experiments modeling practical applications are conducted for each aerial robot system, proving the utility of the controller.


Title: Adaptive Control of Variable-Pitch Propellers: Pursuing Minimum-Effort Operation
Key Words: adaptive control  aerospace propulsion  aircraft control  autonomous aerial vehicles  control system synthesis  electric propulsion  pitch control (position)  propellers  state-space methods  adaptive control  minimum-effort operation  unmanned aerial vehicles  UAV  electric propulsion systems  disparate flight modes  forward-moving flight  flight mode dissimilarity  fixed-geometry propulsion systems  variable-geometry systems  variable pitch propeller  propulsion performance  VPP system control  operation state space  hovering  near-minimum-electrical-effort propulsion system behavior  Propellers  Mathematical model  Servomotors  Geometry  Brushless DC motors  Blades 
Abstract: As Unmanned Aerial Vehicles (UAVs) become more commonly used in industry, their performance will continue to be challenged. A performance bottleneck that is crucial to overcome is the design of electric propulsion systems for UAVs that operate in disparate flight modes (e.g., hovering and forward-moving flight). While flight mode dissimilarity presents a fundamental design challenge for fixed-geometry propulsion systems, variable-geometry systems such as the Variable Pitch Propeller (VPP) ones are able to provide superior propulsion performance across a wide range of flight modes. This work builds on previous work by the authors and presents a VPP system control and estimation framework for safe, near-minimum-electrical-effort propulsion system behavior across the whole operation state space of any UAV. Multiple simulated validations are presented to support the feasibility of the approach.


Title: Predicting optimal value functions by interpolating reward functions in scalarized multi-objective reinforcement learning
Key Words: Gaussian processes  interpolation  learning (artificial intelligence)  optimisation  smooth interpolation  reward function weights  optimal value function  multiobjective reinforcement learning problems  Gaussian process  value function transforms  MORL problems  Interpolation  Training  Learning (artificial intelligence)  Gaussian processes  Mathematical model  Random variables  Optimization 
Abstract: A common approach for defining a reward function for multi-objective reinforcement learning (MORL) problems is the weighted sum of the multiple objectives. The weights are then treated as design parameters dependent on the expertise (and preference) of the person performing the learning, with the typical result that a new solution is required for any change in these settings. This paper investigates the relationship between the reward function and the optimal value function for MORL; specifically addressing the question of how to approximate the optimal value function well beyond the set of weights for which the optimization problem was actually solved, thereby avoiding the need to recompute for any particular choice. We prove that the value function transforms smoothly given a transformation of weights of the reward function (and thus a smooth interpolation in the policy space). A Gaussian process is used to obtain a smooth interpolation over the reward function weights of the optimal value function for three well-known examples: Gridworld, Objectworld and Pendulum. The results show that the interpolation can provide robust values for sample states and actions in both discrete and continuous domain problems. Significant advantages arise from utilizing this interpolation technique in the domain of autonomous vehicles: easy, instant adaptation of user preferences while driving and true randomization of obstacle vehicle behavior preferences during training.


Title: Benchmark for Skill Learning from Demonstration: Impact of User Experience, Task Complexity, and Start Configuration on Performance
Key Words: human-robot interaction  learning (artificial intelligence)  user experience  task reproductions  demonstration approaches  multiple motion-based learning  task complexity  user experience  skill learning  robot executions  task performance  starting configuration  human demonstrator  physical robot  task models  manipulation tasks  real-world tasks  relative strengths  Task analysis  Robots  Trajectory  Videos  Pressing  Benchmark testing  Complexity theory 
Abstract: We contribute a study benchmarking the performance of multiple motion-based learning from demonstration approaches. Given the number and diversity of existing methods, it is critical that comprehensive empirical studies be performed comparing the relative strengths of these techniques. In particular, we evaluate four approaches based on properties an end user may desire for real-world tasks. To perform this evaluation, we collected data from nine participants, across four manipulation tasks. The resulting demonstrations were used to train 180 task models and evaluated on 720 task reproductions on a physical robot. Our results detail how i) complexity of the task, ii) the expertise of the human demonstrator, and iii) the starting configuration of the robot affect task performance. The collected dataset of demonstrations, robot executions, and evaluations are publicly available. Research insights and guidelines are also provided to guide future research and deployment choices about these approaches.


Title: Robot Programming without Coding
Key Words: control engineering computing  end effectors  learning (artificial intelligence)  robot programming  teaching  telerobotics  robot programming  wearable consumer devices  programming tools  robot teleoperation  salient features  off-the-shelf soft-articulated robotic components  Dynamic Movement Primitives  human trajectories  impedance regulation skills  7-DOF collaborative robots  anthropomorphic end-effectors  robot teaching  Robots  Task analysis  Education  Trajectory  Programming  Three-dimensional displays  Impedance 
Abstract: An approach toward intuitive and easy robot programming, consists to transfer skills from humans to machines, through demonstration. A vast literature exists on learning from multiple demonstrations. This paper, on the other hand, tackles the problem of providing all needed information to execute a certain task by resorting to one single demonstration - hence, a problem closer to programming than to learning. We use wearable consumer devices - but no keyboard nor coding - as programming tools, to let the programmer tele-operate the robot, which in turn records the most salient features and affordances from the object, environment, robot, and human. To enable this goal we combine off-the-shelf soft-articulated robotic components with the framework of Dynamic Movement Primitives, which we contribute to extend to generalize human trajectories and impedance regulation skills. This framework enables to teach robot quickly and in a intuitive way without coding. Experimental tests have been performed on a dual-arm system composed by two 7-dofs collaborative robots equipped with anthropomorphic end-effectors. Experiments show the functionality of the framework and verify the effectiveness of the impedance extension.


Title: Subspace Projectors for State-Constrained Multi-Robot Consensus
Key Words: distributed algorithms  distributed control  mobile robots  multi-robot systems  subspace projectors  state-constrained multirobot consensus  distributed algorithms  subspace projection methods  consensus value  constrained 2D rendezvous  single-integrator robots  discrete-time agreement protocol  Symmetric matrices  Eigenvalues and eigenfunctions  Protocols  Matrix decomposition  Laplace equations  Two dimensional displays  Robots 
Abstract: In this paper, we study the state-constrained consensus problem and introduce a new family of distributed algorithms based on subspace projection methods which are simple to implement and which preserve, under some suitable conditions, the consensus value of the original discrete-time agreement protocol. The proposed theory is supported by extensive numerical experiments for the constrained 2D rendezvous of single-integrator robots.


Title: Multi-Agent Task Allocation using Cross-Entropy Temporal Logic Optimization
Key Words: discrete systems  entropy  graph theory  multi-agent systems  multi-robot systems  optimisation  search problems  stochastic programming  temporal logic  task specification  discrete transition systems  finite linear temporal logic specifications  stochastic optimization  graph based search  cross entropy temporal logic optimization  multiagent task allocation cross entropy algorithm  robot team  Task analysis  Automata  Cost function  Planning  Resource management  Switches 
Abstract: In this paper, we propose a graph-based search method to optimally allocate tasks to a team of robots given a global task specification. In particular, we define these agents as discrete transition systems. In order to allocate tasks to the team of robots, we decompose finite linear temporal logic (LTL) specifications and consider agent specific cost functions. We propose to use the stochastic optimization technique, cross entropy, to optimize over this cost function. The multi-agent task allocation cross-entropy (MTAC-E) algorithm is developed to determine both when it is optimal to switch to a new agent to complete a task and minimize the costs associated with individual agent trajectories. The proposed algorithm is verified in simulation and experimental results are included.


Title: Adaptive Task Allocation for Heterogeneous Multi-Robot Teams with Evolving and Unknown Robot Capabilities
Key Words: adaptive systems  multi-robot systems  adaptive task allocation  task execution  robot capabilities  heterogeneous multirobot teams  Task analysis  Resource management  Cost function  Mobile robots  Real-time systems  Minimization 
Abstract: For multi-robot teams with heterogeneous capabilities, typical task allocation methods assign tasks to robots based on the suitability of the robots to perform certain tasks as well as the requirements of the task itself. However, in real-world deployments of robot teams, the suitability of a robot might be unknown prior to deployment, or might vary due to changing environmental conditions. This paper presents an adaptive task allocation and task execution framework which allows individual robots to prioritize among tasks while explicitly taking into account their efficacy at performing the tasks-the parameters of which might be unknown before deployment and/or might vary over time. Such a specialization parameter-encoding the effectiveness of a given robot towards a task-is updated on-the-fly, allowing our algorithm to reassign tasks among robots with the aim of executing them. The developed framework requires no explicit model of the changing environment or of the unknown robot capabilities-it only takes into account the progress made by the robots at completing the tasks. Simulations and experiments demonstrate the efficacy of the proposed approach during variations in environmental conditions and when robot capabilities are unknown before deployment.


Title: Mobile Wireless Network Infrastructure on Demand
Key Words: mobile ad hoc networks  mobile robots  multi-agent systems  multi-robot systems  optimisation  telecommunication network routing  mobile relay nodes  network team  wireless connectivity  task agents  Mobile wireless network infrastructure  multirobot teams  previous multiagent systems  communication infrastructure  end-to-end communication requirements  task team  arbitrary objective  joint optimization framework  optimal network routes  Task analysis  Ad hoc networks  Routing  Wireless networks  Hardware  Probabilistic logic 
Abstract: In this work, we introduce Mobile Wireless Infrastructure on Demand: a framework for providing wireless connectivity to multi-robot teams via autonomously reconfiguring ad-hoc networks. In many cases, previous multi-agent systems either assumed the availability of existing communication infrastructure or were required to create a network in addition to completing their objective. Instead our system explicitly assumes the responsibility of creating and sustaining a wireless network capable of satisfying end-to-end communication requirements of a team of agents, called the task team, performing an arbitrary objective. To accomplish this goal, we propose a joint optimization framework that alternates between finding optimal network routes to support data flows between the task agents and improving the performance of the network by repositioning a collection of mobile relay nodes referred to as the network team. We demonstrate our approach with simulations and experiments wherein wireless connectivity is provided to patrolling task agents.


Title: Monitoring Over the Long Term: Intermittent Deployment and Sensing Strategies for Multi-Robot Teams
Key Words: combinatorial mathematics  Gaussian processes  greedy algorithms  matrix algebra  Monte Carlo methods  multi-robot systems  optimisation  multirobot team  intermittent deployment problem  heterogeneous robots  environmental process  spatiotemporal process  intermittent deployment strategy  spatiotemporal Gaussian process  Monte Carlo simulations  greedy algorithm  submodular optimization  matroids  Robot sensing systems  Monitoring  Mutual information  Spatiotemporal phenomena  Kernel 
Abstract: In this paper, we formulate and solve the intermittent deployment problem, which yields strategies that couple when heterogeneous robots should sense an environmental process, with where a deployed team should sense in the environment. As a motivation, suppose that a spatiotemporal process is slowly evolving and must be monitored by a multi-robot team, e.g., unmanned aerial vehicles monitoring pasturelands in a precision agriculture context. In such a case, an intermittent deployment strategy is necessary as persistent deployment or monitoring is not cost-efficient for a slowly evolving process. At the same time, the problem of where to sense once deployed must be solved as process observations yield useful feedback for determining effective future deployment and monitoring decisions. In this context, we model the environmental process to be monitored as a spatiotemporal Gaussian process with mutual information as a criterion to measure our understanding of the environment. To make the sensing resource-efficient, we demonstrate how to use matroid constraints to impose a diverse set of homogeneous and heterogeneous constraints. In addition, to reflect the cost-sensitive nature of real-world applications, we apply budgets on the cost of deployed heterogeneous robot teams. To solve the resulting problem, we exploit the theories of submodular optimization and matroids and present a greedy algorithm with bounds on sub-optimality. Finally, Monte Carlo simulations demonstrate the correctness of the proposed method.


Title: Multi-Robot Coordination for Estimation and Coverage of Unknown Spatial Fields
Key Words: Bayes methods  computational geometry  Gaussian processes  mobile robots  multi-robot systems  optimisation  sampling methods  multirobot coordination  unknown spatial fields  multirobot coverage  initially unknown spatial scalar field  Bayesian optimization  control law  centroidal Voronoi tessellation  adaptive sequential sampling method  surrogate function  density function  Gaussian processes  Density functional theory  Estimation  Gaussian processes  Robot sensing systems  Prediction algorithms  Bayes methods 
Abstract: We present an algorithm for multi-robot coverage of an initially unknown spatial scalar field characterized by a density function, whereby a team of robots simultaneously estimates and optimizes its coverage of the density function over the domain. The proposed algorithm borrows powerful concepts from Bayesian Optimization with Gaussian Processes that, when combined with control laws to achieve centroidal Voronoi tessellation, give rise to an adaptive sequential sampling method to explore and cover the domain. The crux of the approach is to apply a control law using a surrogate function of the true density function, which is then successively refined as robots gather more samples for estimation. The performance of the algorithm is justified theoretically under slightly idealized assumptions, by demonstrating asymptotic no-regret with respect to the coverage obtained with a known density function. The performance is also evaluated in simulation and on the Robotarium with small teams of robots, confirming the good performance suggested by the theoretical analysis.


Title: Titan: A Parallel Asynchronous Library for Multi-Agent and Soft-Body Robotics using NVIDIA CUDA
Key Words: control engineering computing  graphics processing units  learning (artificial intelligence)  mobile robots  multi-agent systems  multi-robot systems  optimisation  parallel algorithms  parallel architectures  CUDA-based C++ robotics simulation library  multiagent robots  massively parallel integration scheme  reinforcement learning iterations  rapid topology optimization  simultaneous optimization  innovative GPU architecture design  robotics primitives  GPU-accelerated simulations  asynchronous computing model  GPU-accelerated interface  interacting bodies  multiagent robotics  intrinsically serial tasks  low-dimensional tasks  robotics simulation libraries  NVIDIA CUDA  soft-body robotics  parallel asynchronous library  Titan  Graphics processing units  Robots  Libraries  Springs  Computational modeling  Kernel  Acceleration 
Abstract: While most robotics simulation libraries are built for low-dimensional and intrinsically serial tasks, soft-body and multi-agent robotics have created a demand for simulation environments that can model many interacting bodies in parallel. Despite the increasing interest in these fields, no existing simulation library addresses the challenge of providing a unified, highly-parallelized, GPU-accelerated interface for simulating large robotic systems. Titan is a versatile CUDA-based C++ robotics simulation library that employs a novel asynchronous computing model for GPU-accelerated simulations of robotics primitives. The innovative GPU architecture design permits simultaneous optimization and control on the CPU while the GPU runs asynchronously, enabling rapid topology optimization and reinforcement learning iterations. Kinematics are solved with a massively parallel integration scheme that incorporates constraints and environmental forces. We report dramatically improved performance over CPU baselines, simulating as many as 300 million primitive updates per second, while allowing flexibility for a wide range of research applications. We present several applications of Titan to high-performance simulations of soft-body and multi-agent robots.


Title: Improving the contact instant detection of sensing antennae using a Super-Twisting algorithm
Key Words: filtering theory  multi-robot systems  signal processing  variable structure systems  contact instant detection  antenna devices  mimic insect antennae  mammal whiskers  robotic systems  signal processing  flexible antenna  impact detection  impact instant estimation  super-twisting algorithm  time 5.0 ms  Antennas  Estimation  Vibrations  Robot sensing systems  Antenna measurements  Delays 
Abstract: Sensing antenna devices, that mimic insect antennae or mammal whiskers, is an active field of research that still needs new developments in order to become efficient and reliable components of robotic systems. This work reports a new result in the area of signal processing of these devices that allows to detect the instant of the impact of a flexible antenna with an object faster than other reported methods. Previous methods require the use of filters that introduce delays in the impact detection. A method based on the Super-Twisting algorithm is proposed here that avoids the use of these filters and reduces such delays improving the impact instant estimation. Experiments show that these delays can be reduced in more than 50%, allowing reliable estimation of the impact instant with an error of less than 5 ms in many cases requiring a limited computational effort.


Title: Versatile Trajectory Optimization Using a LCP Wheel Model for Dynamic Vehicle Maneuvers
Key Words: automobiles  friction  mechanical contact  mobile robots  optimisation  path planning  robot dynamics  trajectory control  tyres  vehicle dynamics  wheels  dynamic drift parking  discontinuous friction model  tire dynamics model  cost function  wheel skidding  versatile trajectory optimization framework  vehicle motion  anisotropic Coulomb friction cone  multirigid-body contact problems  linear complementarity problem  robotics community  contact dynamics  real world contact behavior  empirical friction model  aggressive maneuvers  car models  dynamic vehicle maneuvers  LCP wheel model  executing dynamic drift parking  planning horizon  Vehicle dynamics  Wheels  Friction  Planning  Dynamics  Trajectory optimization  Tires 
Abstract: Car models have been extensively studied at varying levels of abstraction, and planning and executing motions under ideal conditions is well researched and understood. For more aggressive maneuvers, for example when drifting or skidding, empirical and/or discontinuous friction models have been used to explain and approximate real world contact behavior. Separately, contact dynamics have been extensively studied by the robotics community, often times formulated as a linear complementarity problem (LCP) for dynamic multi-rigid-body contact problems with Coulomb friction cone approximations. In this work, we explore the validity of using such an anisotropic Coulomb friction cone to model tire dynamics to plan for vehicle motion, and present a versatile trajectory optimization framework using this model that can both avoid and/or exploit wheel skidding, depending on the cost function and planning horizon. Experimental evidence of planning and executing dynamic drift parking is shown on a 1/16 scale model car.


Title: View-Invariant Loop Closure with Oriented Semantic Landmarks
Key Words: geometry  pose estimation  robot vision  SLAM (robots)  view-invariant loop closure  oriented semantic landmarks  simultaneous localization and mapping  monocular semantic SLAM system  object identity  inter-object geometry  view-invariant loop detection  ORB-SLAM  local appearance-based features  indoor scenes  object orientation estimation  geometrical detailed semantic maps  object translation  object scale  Cameras  Simultaneous localization and mapping  Semantics  Trajectory  Layout  Robustness  Estimation 
Abstract: Recent work on semantic simultaneous localization and mapping (SLAM) have shown the utility of natural objects as landmarks for improving localization accuracy and robustness. In this paper we present a monocular semantic SLAM system that uses object identity and inter-object geometry for view-invariant loop detection and drift correction. Our system's ability to recognize an area of the scene even under large changes in viewing direction allows it to surpass the mapping accuracy of ORB-SLAM, which uses only local appearance-based features that are not robust to large viewpoint changes. Experiments on real indoor scenes show that our method achieves mean drift reduction of 70% when compared directly to ORB-SLAM. Additionally, we propose a method for object orientation estimation, where we leverage the tracked pose of a moving camera under the SLAM setting to overcome ambiguities caused by object symmetry. This allows our SLAM system to produce geometrically detailed semantic maps with object orientation, translation, and scale.


Title: Simultaneous Learning from Human Pose and Object Cues for Real-Time Activity Recognition
Key Words: feature extraction  human-robot interaction  image motion analysis  image recognition  image representation  learning (artificial intelligence)  optimisation  pose estimation  regression analysis  human activity categories  real-time human activity recognition  human pose  object cues  real-world human-centered robotics applications  assisted living  human-robot collaboration  frequency 104.0 Hz  Activity recognition  Real-time systems  Optimization  Object recognition  Feature extraction  Robot sensing systems 
Abstract: Real-time human activity recognition plays an essential role in real-world human-centered robotics applications, such as assisted living and human-robot collaboration. Although previous methods based on skeletal data to encode human poses showed promising results on real-time activity recognition, they lacked the capability to consider the context provided by objects within the scene and in use by the humans, which can provide a further discriminant between human activity categories. In this paper, we propose a novel approach to real-time human activity recognition, through simultaneously learning from observations of both human poses and objects involved in the human activity. We formulate human activity recognition as a joint optimization problem under a unified mathematical framework, which uses a regression-like loss function to integrate human pose and object cues and defines structured sparsity-inducing norms to identify discriminative body joints and object attributes. To evaluate our method, we perform extensive experiments on two benchmark datasets and a physical robot in a home assistance setting. Experimental results have shown that our method outperforms previous methods and obtains real-time performance for human activity recognition with a processing speed of 104 Hz.


Title: Can I Trust You? A User Study of Robot Mediation of a Support Group
Key Words: human-robot interaction  robot mediation  socially assistive robots  group dynamics  social settings  trust dynamics  robot mediated support group  dyadic trust scale  general trust  average interpersonal trust  group interaction session  multiparty setting  Educational robots  Mediation  Sensitivity  Robot sensing systems  Atmospheric measurements  Particle measurements 
Abstract: Socially assistive robots have the potential to improve group dynamics when interacting with groups of people in social settings. This work contributes to the understanding of those dynamics through a user study of trust dynamics in the novel context of a robot mediated support group. For this study, a novel framework for robot mediation of a support group was developed and validated. To evaluate interpersonal trust in the multi-party setting, a dyadic trust scale was implemented and found to be uni-factorial, validating it as an appropriate measure of general trust. The results of this study demonstrate a significant increase in average interpersonal trust after the group interaction session, and qualitative post-session interview data report that participants found the interaction helpful and successfully supported and learned from one other. The results of the study validate that a robot-mediated support group can improve trust among strangers and allow them to share and receive support for their academic stress.


Title: Coronal Plane Spine Twisting Composes Shape To Adjust the Energy Landscape for Grounded Reorientation
Key Words: biomechanics  bone  orthopaedics  CPST  coronal plane spine twisting composes shape  energy landscape  grounded reorientation  animal locomotion  legged robots  self-righting mechanics  freedom coronal plane representation  body shape affordance  cross-sectional geometries  kinematic model predictions  elliptical bodies  rectangular shaped bodies  quasistatic reorientation maneuvers  Shape  Kinematics  Potential energy  Hip  Torso  Legged locomotion 
Abstract: Despite substantial evidence for the crucial role played by an active backbone or spine in animal locomotion, its adoption in legged robots remains limited because the added mechanical complexity and resulting dynamical challenges pose daunting obstacles to characterizing even a partial range of potential performance benefits. This paper takes a next step toward such a characterization by exploring the quasistatic terrestrial self-righting mechanics of a model system with coronal plane spine twisting (CPST). Reduction from a full 3D kinematic model of CPST to a two parameter, two degree of freedom coronal plane representation of body shape affordance predicts a substantial benefit to ground righting by lowering the barrier between stable potential energy basins. The reduced model predicts the most advantageous twist angle for several cross-sectional geometries, reducing the required righting torque by up to an order of magnitude depending on constituent shapes. Experiments with a three actuated degree of freedom physical mechanism corroborate the kinematic model predictions using two different quasistatic reorientation maneuvers for both elliptical and rectangular shaped bodies with a range of eccentricities or aspect ratios. More speculative experiments make intuitive use of the kinematic model in a highly dynamic maneuver to suggest still greater benefits of CPST achievable by coordinating kinetic as well as potential energy, for example as in a future multi-appendage system interacting with a contact-rich 3D environment.


Title: Motion Design for a Snake Robot Negotiating Complicated Pipe Structures of a Constant Diameter
Key Words: collision avoidance  mobile robots  motion control  path planning  pipes  motion design  snake robot  constant diameter  multiple pipe structures  target form  rolling motion  complicated pipe structures  Snake robots  Windings  Shape  Robots  Junctions  Modeling  Pins 
Abstract: A method for designing the motion of a snake robot negotiating complicated pipe structures having a constant diameter is presented. For such robots moving inside pipes, there are various "obstacles" such as junctions, bends, shears, and blockages. To surmount these obstacles, we propose a method that enables the robot to adapt to multiple pipe structures of a constant diameter. We designed the target form of the snake robot of two helices connected with an arbitrary shape. This method is applicable to various obstacles by designing a part of the target form conforming to the obstacle. The robot negotiates obstacles under shift control by employing a rolling motion. We demonstrated the effectiveness of the proposed method in various experiments.


Title: Dynamic modeling of robotic manipulators for accuracy evaluation
Key Words: finite element analysis  flexible manipulators  manipulator dynamics  robotic manipulators  industrial robots  mechanical stiffness  multibody models  finite element model  flexible link manipulator model  industrial robot  stiffness parameters  robot behavior  weight-reduced manipulator  Solid modeling  Manipulator dynamics  Mathematical model  Service robots  Finite element analysis 
Abstract: In order to fulfill conflicting requirements in the development of industrial robots, such as increased accuracy of a weightreduced manipulator with lower mechanical stiffness, the robot's dynamical behavior must be evaluated early in the development process. This leads to the need of accurate multibody models of the manipulator under development.This paper deals with multibody models that include flexible bodies, which are exported from the corresponding Finite Element model of the structural parts. It is shown that such a flexible link manipulator model, which is purely based on development and datasheet data, is suitable for an accurate description of an industrial robot's dynamic behavior. No stiffness parameters need to be identified by experimental methods, making this approach especially relevant during the development of new manipulators. This paper presents results of experiments in time and frequency domain for analyzing the modeling approach and for validating the model performance against real robot behavior.


Title: MagNet: Discovering Multi-agent Interaction Dynamics using Neural Network
Key Words: differential equations  learning (artificial intelligence)  multi-agent systems  neural nets  synchronisation  agents change  point-mass system  Kuramoto phase synchronization dynamics  predator-swarm interaction dynamics  multiagent interaction dynamics  neural network-based multiagent interaction model  governing dynamics  complex multiagent system  nonlinear network  generic ordinary differential equation based state evolution  neural network-based realization  time-discretized model  core dynamics  agent-specific parameters  MagNet  traditional deep learning models  Mathematical model  Magnetic cores  Multi-agent systems  Force  Training  Springs  Oscillators 
Abstract: We present the MagNet, a neural network-based multi-agent interaction model to discover the governing dynamics and predict evolution of a complex multi-agent system from observations. We formulate a multi-agent system as a coupled non-linear network with a generic ordinary differential equation (ODE) based state evolution, and develop a neural network-based realization of its time-discretized model. MagNet is trained to discover the core dynamics of a multi-agent system from observations, and tuned on-line to learn agent-specific parameters of the dynamics to ensure accurate prediction even when physical or relational attributes of agents, or number of agents change. We evaluate MagNet on a point-mass system in two-dimensional space, Kuramoto phase synchronization dynamics and predator-swarm interaction dynamics demonstrating orders of magnitude improvement in prediction accuracy over traditional deep learning models.


Title: Development of a Robotic System for Automated Decaking of 3D-Printed Parts
Key Words: force control  industrial robots  learning (artificial intelligence)  neural nets  path planning  production engineering computing  three-dimensional printing  industrial robots  robotic decaking  automated decaking  3D printed parts  3D printing based mass manufacturing  smart mechanical design  motion planning  force control  deep learning  Powders  Cleaning  Service robots  Three-dimensional displays  Task analysis  Force control  deep learning  manipulation  system design  3D-printing  decaking 
Abstract: With the rapid rise of 3D-printing as a competitive mass manufacturing method, manual "decaking" - i.e. removing the residual powder that sticks to a 3D-printed part - has become a significant bottleneck. Here, we introduce, for the first time to our knowledge, a robotic system for automated decaking of 3D-printed parts. Combining Deep Learning for 3D perception, smart mechanical design, motion planning, and force control for industrial robots, we developed a system that can automatically decake parts in a fast and efficient way. Through a series of decaking experiments performed on parts printed by a Multi Jet Fusion printer, we demonstrated the feasibility of robotic decaking for 3D-printing-based mass manufacturing.


Title: OmBURo: A Novel Unicycle Robot with Active Omnidirectional Wheel
Key Words: mechanical stability  mobile robots  motion control  nonlinear control systems  pendulums  robot dynamics  wheels  human environments  ideal locomotion mechanism  omnidirectional balancing unicycle robot  mobility mechanism  OmBURo  agile mobility  compact structure  active omnidirectional wheel  Wheels  Mobile robots  Gears  Friction  Mathematical model  Energy loss 
Abstract: A mobility mechanism for robots to be used in tight spaces shared with people requires it to have a small footprint, to move omnidirectionally, as well as to be highly maneuverable. However, currently there exist few such mobility mechanisms that satisfy all these conditions well. Here we introduce Omnidirectional Balancing Unicycle Robot (OmBURo), a novel unicycle robot with active omnidirectional wheel. The effect is that the unicycle robot can drive in both longitudinal and lateral directions simultaneously. Thus, it can dynamically balance itself based on the principle of dual-axis wheeled inverted pendulum. This paper discloses the early development of this novel unicycle robot involving the overall design, modeling, and control, as well as presents some preliminary results including station keeping and path following. With its very compact structure and agile mobility, it might be the ideal locomotion mechanism for robots to be used in human environments in the future.


Title: A Flexible Method for Performance Evaluation of Robot Localization
Key Words: image motion analysis  mobile robots  path planning  pose estimation  robot vision  SLAM (robots)  robot localization  research issue  mobile robotics  performance assessment  robot SLAM algorithms  localization accuracy  SLAM algorithm  benchmark datasets  motion capture  environment-specific  spatial coverage  SLAM performance evaluation  distinctive markers  robot navigation environment  generative latent optimization problem  local robot-to-marker  global robot  Simultaneous localization and mapping  Navigation  Cameras  Performance evaluation  Robot localization 
Abstract: An important research issue in mobile robotics is performance assessment of robot SLAM algorithms in terms of their localization accuracy. Typically, SLAM algorithms are evaluated with the help of benchmark datasets or expensive equipment such as motion capture. Benchmark datasets however, are environment-specific, and use of motion capture constrains spatial coverage and affordability. In this paper, we present a novel method for SLAM performance evaluation, which only uses distinctive markers (such as AR tags), randomly placed in the robot navigation environment at arbitrary locations, and observes these markers with a camera onboard of the robot. Formulated as a generative latent optimization (GLO) problem, our method uses the local robot-to-marker poses to evaluate the global robot pose estimates by a SLAM algorithm and therefore its performance. Through extensive experiments on two robots, three localization/SLAM algorithms and both LiDAR and RGB-D sensors, we demonstrate the feasibility and accuracy of our proposed method.


Title: Quantifying Good Seamanship For Autonomous Surface Vessel Performance Evaluation
Key Words: collision avoidance  decision making  marine safety  marine vehicles  mobile robots  remotely operated vehicles  ships  performance metrics  ASV decision-making  collision risk  ASV planning strategies  International Regulations for Prevention of Collisions at Sea  quantified good seamanship  COLREGS compliance  vessel interactions  autonomous surface vehicle decision-making  autonomous surface vessel performance evaluation  seamanship performance criteria  Marine vehicles  Safety  Geometry  Decision making  Navigation  Risk management  Planning 
Abstract: The current state-of-the-art for testing and evaluation of autonomous surface vehicle (ASV) decision-making is currently limited to one-versus-one vessel interactions by determining compliance with the International Regulations for Prevention of Collisions at Sea, referred to as COLREGS. Strict measurement of COLREGS compliance, however, loses value in multi-vessel encounters, as there can be conflicting rules which make determining compliance extremely subjective. This work proposes several performance metrics to evaluate ASV decision-making based on the concept of "good seamanship," a practice which generalizes to multi-vessel encounters. Methodology for quantifying good seamanship is presented based on the criteria of reducing the overall collision risk of the situation and taking early, appropriate actions. Case study simulation results are presented to showcase the seamanship performance criteria against different ASV planning strategies.


Title: LyRN (Lyapunov Reaching Network): A Real-Time Closed Loop approach from Monocular Vision
Key Words: cameras  closed loop systems  convolutional neural nets  image colour analysis  learning (artificial intelligence)  Lyapunov methods  manipulator dynamics  neurocontrollers  pose estimation  robot vision  velocity control  visual servoing  GTX 1080Ti GPU  grasping mugs  multiinstance control  real-time closed loop  LyRN  single shot RGB 6D pose estimation  complex multiinstance task  reaching action  control Lyapunov function  learning principles  visually guided reaching  Lyapunov reaching network  pose-based-visual-servo grasping system  closed-loop control  over-the-shoulder monocular RGB camera  multiinstance capability  visual control  velocity control  deep convolution neural network  manipulator joint angles  monocular vision  reaching points  frequency 85.0 Hz  Lyapunov methods  Grasping  Feature extraction  Computer architecture  Task analysis  Pose estimation  Velocity control 
Abstract: We propose a closed-loop, multi-instance control algorithm for visually guided reaching based on novel learning principles. A control Lyapunov function methodology is used to design a reaching action for a complex multi-instance task in the case where full state information (poses of all potential reaching points) is available. The proposed algorithm uses monocular vision and manipulator joint angles as the input to a deep convolution neural network to predict the value of the control Lyapunov function (cLf) and corresponding velocity control. The resulting network output is used in real-time as visual control for the grasping task with the multi-instance capability emerging naturally from the design of the control Lyapunov function. We demonstrate the proposed algorithm grasping mugs (textureless and symmetric objects) on a table-top from an over-the-shoulder monocular RGB camera. The manipulator dynamically converges to the best-suited target among multiple identical instances from any random initial pose within the workspace. The system trained with only simulated data is able to achieve 90.3% grasp success rate in the real-world experiments with up to 85Hz closed-loop control on one GTX 1080Ti GPU and significantly outperforms a Pose-Based-Visual-Servo (PBVS) grasping system adapted from a state-of-the-art single shot RGB 6D pose estimation algorithm. A key contribution of the paper is the inclusion of a first-order differential constraint associated with the cLf as a regularisation term during learning, and we provide evidence that this leads to more robust and reliable reaching/grasping performance than vanilla regression on general control inputs.


Title: FarSee-Net: Real-Time Semantic Segmentation by Efficient Multi-scale Context Aggregation and Feature Space Super-resolution
Key Words: convolutional neural nets  feature extraction  image resolution  image sampling  image segmentation  object detection  real-time systems  robot vision  feature space superresolution  FarSee-Net  real time semantic segmentation  cascaded factorized atrous spatial pyramid pooling  feature maps  convolutional neural networks  multiscale context aggregation  object scale variations  robotic applications  subsampled image  Semantics  Convolution  Image segmentation  Feature extraction  Real-time systems  Spatial resolution 
Abstract: Real-time semantic segmentation is desirable in many robotic applications with limited computation resources. One challenge of semantic segmentation is to deal with the object scale variations and leverage the context. How to perform multi-scale context aggregation within limited computation budget is important. In this paper, firstly, we introduce a novel and efficient module called Cascaded Factorized Atrous Spatial Pyramid Pooling (CF-ASPP). It is a lightweight cas-caded structure for Convolutional Neural Networks (CNNs) to efficiently leverage context information. On the other hand, for runtime efficiency, state-of-the-art methods will quickly decrease the spatial size of the inputs or feature maps in the early network stages. The final high-resolution result is usually obtained by non-parametric up-sampling operation (e.g. bilinear interpolation). Differently, we rethink this pipeline and treat it as a super-resolution process. We use optimized super-resolution operation in the up-sampling step and improve the accuracy, especially in sub-sampled input image scenario for real-time applications. By fusing the above two improvements, our methods provide better latency-accuracy trade-off than the other state-of-the-art methods. In particular, we achieve 68.4% mIoU at 84 fps on the Cityscapes test set with a single Nivida Titan X (Maxwell) GPU card. The proposed module can be plugged into any feature extraction CNN and benefits from the CNN structure development.


Title: C-3PO: Cyclic-Three-Phase Optimization for Human-Robot Motion Retargeting based on Reinforcement Learning
Key Words: human-robot interaction  learning (artificial intelligence)  mobile robots  motion control  multi-robot systems  human-robot motion retargeting  kinematic configurations  kinematic independent general solution  three-phase optimization method  deep reinforcement learning  motion retargeting learning  motion retargeting policy  motion retargeting skill  human skeleton  cyclic-three-phase optimization  NAO robot  Pepper robot  Baxter robot  C-3PO robot  Skeleton  Robot motion  Robot kinematics  Kinematics  Zirconium  Torso 
Abstract: Motion retargeting between heterogeneous polymorphs with different sizes and kinematic configurations requires a comprehensive knowledge of (inverse) kinematics. Moreover, it is non-trivial to provide a kinematic independent general solution. In this study, we developed a cyclic three-phase optimization method based on deep reinforcement learning for human-robot motion retargeting. The motion retargeting learning is performed using refined data in a latent space by the cyclic and filtering paths of our method. In addition, the human- in-the-loop based three-phase approach provides a framework for the improvement of the motion retargeting policy by both quantitative and qualitative manners. Using the proposed C- 3PO method, we were successfully able to learn the motion retargeting skill between the human skeleton and motion of the multiple robots such as NAO, Pepper, Baxter and C-3PO.


Title: AP-MTL: Attention Pruned Multi-task Learning Model for Real-time Instrument Detection and Segmentation in Robot-assisted Surgery
Key Words: endoscopes  image segmentation  learning (artificial intelligence)  medical image processing  medical robotics  robot vision  surgery  attention pruned multitask learning model  real-time instrument detection  robot-assisted surgery  image-guided robotic surgery  real-time robotic system  weight-shared encoder  task-aware detection  asynchronous task-aware optimization  robotic instrument segmentation dataset  end-to-end trainable realtime multitask learning model  global attention dynamic pruning  skip squeeze and excitation module  Task analysis  Instruments  Decoding  Real-time systems  Computational modeling  Optimization  Surgery 
Abstract: Surgical scene understanding and multi-tasking learning are crucial for image-guided robotic surgery. Training a real-time robotic system for the detection and segmentation of high-resolution images provides a challenging problem with the limited computational resource. The perception drawn can be applied in effective real-time feedback, surgical skill assessment, and human-robot collaborative surgeries to enhance surgical outcomes. For this purpose, we develop a novel end-to-end trainable real-time Multi-Task Learning (MTL) model with weight-shared encoder and task-aware detection and segmentation decoders. Optimization of multiple tasks at the same convergence point is vital and presents a complex problem. Thus, we propose an asynchronous task-aware optimization (ATO) technique to calculate task-oriented gradients and train the decoders independently. Moreover, MTL models are always computationally expensive, which hinder real-time applications. To address this challenge, we introduce a global attention dynamic pruning (GADP) by removing less significant and sparse parameters. We further design a skip squeeze and excitation (SE) module, which suppresses weak features, excites significant features and performs dynamic spatial and channel-wise feature re-calibration. Validating on the robotic instrument segmentation dataset of MICCAI endoscopic vision challenge, our model significantly outperforms state-of-the-art segmentation and detection models, including best-performed models in the challenge.


Title: Hyperproperties for Robotics: Planning via HyperLTL
Key Words: formal specification  path planning  robots  temporal logic  hyperproperties  formal methods  temporal logic objectives  hyper-temporal logics  multiple paths  HyperLTL specifications  planning strategies  robotic planning  discrete transition systems  Planning  Robustness  Privacy  Automata  Model checking  Task analysis 
Abstract: There is a growing interest on formal methods-based robotic planning for temporal logic objectives. In this work, we extend the scope of existing synthesis methods to hyper-temporal logics. We are motivated by the fact that important planning objectives, such as optimality, robustness, and privacy, (maybe implicitly) involve the interrelation between multiple paths. Such objectives are thus hyperproperties, and cannot be expressed with usual temporal logics like the linear temporal logic (LTL). We show that such hyperproperties can be expressed by HyperLTL, an extension of LTL to multiple paths. To handle the complexity of planning with HyperLTL specifications, we introduce a symbolic approach for synthesizing planning strategies on discrete transition systems. Our planning method is evaluated on several case studies.


Title: AU-AIR: A Multi-modal Unmanned Aerial Vehicle Dataset for Low Altitude Traffic Surveillance
Key Words: autonomous aerial vehicles  cameras  computer vision  image annotation  image capture  image colour analysis  object detection  video signal processing  video surveillance  multimodal unmanned aerial vehicle dataset  low altitude traffic surveillance  UAVs  mounted cameras  aerial image capture  aerial visual data  object detection algorithms  computer vision community  object annotations  flying-cameras  multipurpose aerial dataset  multimodal sensor data  AU-AIR dataset  meta-data  traffic-related object category  mobile object detectors  real-time object detection  robotics  real-world outdoor environments  bounding box annotation  RGB videos recording  YOLOv3-Tiny  MobileNetv2-SSDLite  on-board computers  bird-view image  data types recording  Object detection  Videos  Visualization  Cameras  Detectors  Surveillance 
Abstract: Unmanned aerial vehicles (UAVs) with mounted cameras have the advantage of capturing aerial (bird-view) images. The availability of aerial visual data and the recent advances in object detection algorithms led the computer vision community to focus on object detection tasks on aerial images. As a result of this, several aerial datasets have been introduced, including visual data with object annotations. UAVs are used solely as flying-cameras in these datasets, discarding different data types regarding the flight (e.g., time, location, internal sensors). In this work, we propose a multi-purpose aerial dataset (AU-AIR) that has multi-modal sensor data (i.e., visual, time, location, altitude, IMU, velocity) collected in real-world outdoor environments. The AU-AIR dataset includes meta-data for extracted frames (i.e., bounding box annotations for traffic-related object category) from recorded RGB videos. Moreover, we emphasize the differences between natural and aerial images in the context of object detection task. For this end, we train and test mobile object detectors (including YOLOv3-Tiny and MobileNetv2-SSDLite) on the AU-AIR dataset, which are applicable for real-time object detection using on-board computers with UAVs. Since our dataset has diversity in recorded data types, it contributes to filling the gap between computer vision and robotics. The dataset is available at https://bozcani.github.io/auairdataset.


Title: Design and Autonomous Stabilization of a Ballistically-Launched Multirotor
Key Words: aerodynamics  autonomous aerial vehicles  ballistics  helicopters  mobile robots  robot vision  aircraft  drones  emergency response  space exploration  critical situational data  onboard sensors  multirotor prototype  onboard sensor suite  autonomy pipeline  aerodynamic stability  active stabilization  ballistic launch  streamlined quick unfolding investigation drone  vision-based autonomous transition  SQUID  SQUIDs  Electron tubes  Aerodynamics  Drones  Prototypes  Thermal stability  Aircraft 
Abstract: Aircraft that can launch ballistically and convert to autonomous, free-flying drones have applications in many areas such as emergency response, defense, and space exploration, where they can gather critical situational data using onboard sensors. This paper presents a ballistically-launched, autonomously-stabilizing multirotor prototype (SQUID - Streamlined Quick Unfolding Investigation Drone) with an onboard sensor suite, autonomy pipeline, and passive aerodynamic stability. We demonstrate autonomous transition from passive to vision-based, active stabilization, confirming the multirotor's ability to autonomously stabilize after a ballistic launch in a GPS-denied environment.


Title: Asynchronous event-based clustering and tracking for intrusion monitoring in UAS
Key Words: autonomous aerial vehicles  cameras  image sensors  object tracking  pattern clustering  robot vision  surveillance  feature tracking  intrusion monitoring  UAS  unmanned aerial systems  perception systems  illumination conditions  event cameras  neuromorphic sensors  illumination changes  event based vision  event stream  intruder monitoring  event clustering  event-by-event processing  asynchronous event-based clustering  automatic surveillance  on-board hardware computational constraints  Cameras  Robot vision systems  Tracking  Surveillance  Robustness  event camera  asynchronous  intrusion monitoring  surveillance  UAS  clustering  feature tracking 
Abstract: Automatic surveillance and monitoring using Unmanned Aerial Systems (UAS) require the development of perception systems that robustly work under different illumination conditions. Event cameras are neuromorphic sensors that capture the illumination changes in the scene with very low latency and high dynamic range. Although recent advances in eventbased vision have explored the use of event cameras onboard UAS, most techniques group events in frames and, therefore, do not fully exploit the sequential and asynchronous nature of the event stream. This paper proposes a fully asynchronous scheme for intruder monitoring using UAS. It employs efficient event clustering and feature tracking modules and includes a sampling mechanism to cope with the computational cost of event-by-event processing adapting to on-board hardware computational constraints. The proposed scheme was tested on a real multirotor in challenging scenarios showing significant accuracy and robustness to lighting conditions.


Title: Flydar: Magnetometer-based High Angular Rate Estimation during Gyro Saturation for SLAM
Key Words: gyroscopes  Kalman filters  magnetometers  mobile robots  nonlinear filters  optical radar  SLAM (robots)  Flydar  magnetometer-based high angular rate estimation  SLAM  simultaneous localisation and mapping  Flying Li-DAR  EKF-based algorithm  sinusoidal magnetometer measurement  continuously rotating airframe  IMU sensors  gyro measurement  gyro bias  gyro saturation condition  rotating locomotion  robot hovering angular velocity  Robots  Magnetometers  Sensors  Estimation  Frequency measurement  Saturation magnetization  Angular velocity 
Abstract: In this paper, the high angular rate estimation for simultaneous localisation and mapping (SLAM) of a Flying Li-DAR (Flydar) is presented. The proposed EKF-based algorithm exploits the sinusoidal magnetometer measurement generated by the continuously rotating airframe for estimation of the robot hovering angular velocity. Significantly, the proposed method does not rely on additional sensors other than existing IMU sensors already being used for flight stabilization. The gyro measurement and the gyro bias are incorporated as a control input and a filter state respectively to enable estimation even under gyro saturation condition. Additionally, this work proposes leveraging on the inherently rotating locomotion to generate a planar lidar scan using only a single-point laser for possible lightweight autonomy. The proposed estimation method was experimentally evaluated on a ground rotating rig up to twice the gyro saturation limit with an effective rms error of 0.0045Hz; and on the proposed aerial platform - Flydar - hovering beyond the saturation limit with a rms error of 0.0056Hz. Lastly, the proposed method for SLAM using the rotating dynamics of Flydar was demonstrated with a localisation accuracy of 0.11m.


Title: Nonlinear MPC with Motor Failure Identification and Recovery for Safe and Aggressive Multicopter Flight
Key Words: actuators  autonomous aerial vehicles  helicopters  Kalman filters  nonlinear control systems  nonlinear filters  predictive control  precise reference tracking  crucial characteristic  microaerial vehicles  MAV  external disturbances  cluttered environments  nonlinear model predictive control  NMPC  fully physics  nonlinear dynamics  control inputs  feasible actuator commands  safe operation  potential loss  flight experiments  motor failures  nonlinear MPC  aggressive multicopter flight  extended Kalman filter based motor failure identification algorithm  Actuators  Resource management  Propellers  Aerodynamics  Quaternions  Angular velocity  Vehicle dynamics 
Abstract: Safe and precise reference tracking is a crucial characteristic of Micro Aerial Vehicles (MAVs) that have to operate under the influence of external disturbances in cluttered environments. In this paper, we present a Nonlinear Model Predictive Control (NMPC) that exploits the fully physics based non-linear dynamics of the system. We furthermore show how the moment and thrust control inputs can be transformed into feasible actuator commands. In order to guarantee safe operation despite potential loss of a motor under which we show our system keeps operating safely, we developed an Extended Kalman Filter (EKF) based motor failure identification algorithm. We verify the effectiveness of the developed pipeline in flight experiments with and without motor failures.


Title: Using multiple short hops for multicopter navigation with only inertial sensors
Key Words: accelerometers  closed loop systems  gyroscopes  helicopters  inertial navigation  Kalman filters  nonlinear filters  position control  state estimation  closed-loop control  mean absolute position estimation error  total flight distance  standard inertial navigation method  trajectory tracking error  multiple short hops  multicopter navigation  GPS systems  multicopter localization  direct integration  inertial navigation sensors  accelerometer  rate gyroscope  rapid error accumulation  motion strategy  inertial navigation state estimation error  long duration flight  multiple short duration hops  zero-velocity pseudomeasurements  extended Kalman filter  LiDAR  real-world environment  distance 5.0 m  distance 10.0 m  State estimation  Gyroscopes  Sensors  Inertial navigation  Accelerometers  Measurement uncertainty 
Abstract: In certain challenging environments, such as inside buildings on fire, the main sensors (e.g. cameras, LiDARs and GPS systems) used for multicopter localization can become unavailable. Direct integration of the inertial navigation sensors (the accelerometer and rate gyroscope), is however unaffected by external disturbances, but the rapid error accumulation quickly makes a naive application of such a strategy feasible only for very short durations. In this work we propose a motion strategy for reducing the inertial navigation state estimation error of multicopters. The proposed strategy breaks a long duration flight into multiple short duration hops between which the vehicle remains stationary on the ground. When the vehicle is stationary, zero-velocity pseudo-measurements are introduced to an extended Kalman Filter to reduce the state estimation error. We perform experiments for closed-loop control of a multicopter for evaluation. The mean absolute position estimation error was 3.4% over a total flight distance of 5m in the experiments. The results showed a 80% reduction compared to the standard inertial navigation method without using this strategy. In addition, an additional experiment with total flight distance of 10m is conducted to demonstrate the ability of this method to navigate a multicopter in real-world environment. The final trajectory tracking error was 3% of the total flight distance.


Title: A Feature-Based Underwater Path Planning Approach using Multiple Perspective Prior Maps
Key Words: autonomous underwater vehicles  bathymetry  maximum likelihood estimation  mobile robots  navigation  path planning  remotely operated vehicles  multiple perspective prior maps  path planning methodology  Autonomous Underwater Vehicles  AUV  shallow complex environments  coral reefs  aerial photographic survey  bathymetric information  prior map  navigation graph  test points  shortest paths  destination points  maximum likelihood function  misclassified objects  photo-realistic simulated environment  Navigation  Cameras  Sensors  Uncertainty  Image segmentation  Feature extraction  Robots 
Abstract: This paper presents a path planning methodology which enables Autonomous Underwater Vehicles (AUVs) to navigate in shallow complex environments such as coral reefs. The approach leverages prior information from an aerial photographic survey, and derived bathymetric information of the corresponding area. From these prior maps, a set of features is obtained which define an expected arrangement of objects and bathymetry likely to be perceived by the AUV when underwater. A navigation graph is then constructed by predicting the arrangement of features visible from a set of test points within the prior, which allows the calculation of the shortest paths from any pair of start and destination points. A maximum likelihood function is defined which allows the AUV to match its observations to the navigation graph as it undertakes its mission. To improve robustness, the history of observed features are retained to facilitate possible recovery from non-detectable or misclassified objects. The approach is evaluated using a photo-realistic simulated environment, and results illustrate the merits of the approach even when only a relatively small number of features can be identified from the prior map.


Title: A Low-Rank Matrix Approximation Approach to Multiway Matching with Applications in Multi-Sensory Data Association
Key Words: approximation theory  computational complexity  concave programming  image matching  matrix algebra  sensor fusion  stochastic processes  multisensory data association  multiple visual sensors  consistent visual perception  noisy pairwise correspondences  multiway matching problem  low-rank matrix approximation problem problem  alternating direction method of multipliers  stochastic matrices  Fisher information metric  computational complexity  ADMM  Convex functions  Optimization  Manifolds  Xenon  Approximation algorithms  Clustering algorithms  Noise measurement 
Abstract: Consider the case of multiple visual sensors perceiving the same scene from different viewpoints. In order to achieve consistent visual perception, the problem of data association, in this case establishing correspondences between observed features, must be first solved. In this work, we consider multiway matching which is a specific instance of multi-sensory data association. Multiway matching refers to the problem of establishing correspondences among a set of images from noisy pairwise correspondences, typically by exploiting cycle- consistency. We propose a novel optimization-based formulation of multiway matching problem as a nonconvex low-rank matrix approximation problem. We propose two novel algorithms for numerically solving the problem at hand. The first one is an algorithm based on the Alternating Direction Method of Multipliers (ADMM). The second one is a Riemannian trust- region method on the multinomial manifold, the manifold of strictly positive stochastic matrices, equipped with the Fisher information metric. Experimental results demonstrate that the proposed methods have the state of the art performance in multiway matching while reducing the computational complexity compared to the state of the art.


Title: A Parametric Grasping Methodology for Multi-Manual Interactions in Real-Time Dynamic Simulations
Key Words: biomechanics  control engineering computing  data visualisation  kinematics  manipulators  medical robotics  rendering (computer graphics)  surgery  telerobotics  parametric grasping methodology  multimanual interactions  interactive simulators  training simulators  teleoperated robotic laparoscopic surgery  stateof-art simulators  realistic visuals  accurate dynamics  kinematic simplification techniques  truly multimanual manipulation  actual task  realistic grasping  rigid-body dynamics  collision computation techniques  state-of-the-art physics libraries  parametric approach  multimanual grasping  real-time dynamic simulation  accomplishing multimanual tasks  screwdriver task  Friction  Grasping  Force  Sensors  Computational modeling  Mathematical model  Robots 
Abstract: Interactive simulators are used in several important applications which include the training simulators for teleoperated robotic laparoscopic surgery. While stateof-art simulators are capable of rendering realistic visuals and accurate dynamics, grasping is often implemented using kinematic simplification techniques that prevent truly multimanual manipulation, which is often an important requirement of the actual task. Realistic grasping and manipulation in simulation is a challenging problem due to the constraints imposed by the implementation of rigid-body dynamics and collision computation techniques in state-of-the-art physics libraries. We present a penalty based parametric approach to achieve multi-manual grasping and manipulation of complex objects at arbitrary postures in a real-time dynamic simulation. This approach is demonstrated by accomplishing multi-manual tasks modeled after realistic scenarios, which include the grasping and manipulation of a two-handed screwdriver task and the manipulation of a deformable thread.


Title: A methodology for the incorporation of arbitrarily-shaped feet in passive bipedal walking dynamics
Key Words: computational geometry  legged locomotion  motion control  pose estimation  public domain software  robot dynamics  stability  ankle trajectory  robot dynamics  shape dependent foot kinetics  OpenPose  open source pose estimation system  rigid foot passive robot  walking robot stability  foot shape optimization  exact foot geometry  dynamic model  biped robot  passive bipedal walking dynamics  Foot  Legged locomotion  Shape  Geometry  Mathematical model  Dynamics 
Abstract: A methodology for implementing arbitrary foot shapes in the passive walking dynamics of biped robots is developed. The dynamic model of a walking robot is defined in a way that allows shape-dependent foot kinetics to contribute to the robot's dynamics, for all convex foot shapes regardless of the exact foot geometry: for the developed method, only the set of points describing the foot profile curve is needed. The method is mathematically derived and then showcased with an application. The open-source pose estimation system OpenPose is used to determine the foot profile that enables the rigid-foot passive robot to reproduce the ankle trajectory of the actively powered, multi-DOF human foot complex. The passive gait of the biped robot walking on the specified foot shape is simulated and analyzed, and a stable walking cycle is found and evaluated. The proposed model enables the study of the effects of foot shape on the walking dynamics of biped robots, eliminating the necessity of solely using simple, and analytically defined geometric shapes as the walking robots' feet. The method can be used for foot shape optimization towards achieving any desired walking pattern in walking robots.


Title: CAPRICORN: Communication Aware Place Recognition using Interpretable Constellations of Objects in Robot Networks
Key Words: feature extraction  image colour analysis  image matching  image representation  mobile robots  multi-robot systems  object detection  robot vision  SLAM (robots)  particular communication bandwidth  limited communication bandwidth  relative object positions  2step decentralized loop closure verification  compact semantic descriptors  bandwidth requirements  communication aware place recognition  interpretable constellations  robot networks  multiple robots  mapping environments  CAPRICORN  exploring environments  3D points  compact spatial descriptors  matching robots  geometric information  global image descriptors  TUM RGB-D SLAM sequence  Semantics  Three-dimensional displays  Simultaneous localization and mapping  Robustness  Visualization  Bandwidth 
Abstract: Using multiple robots for exploring and mapping environments can provide improved robustness and performance, but it can be difficult to implement. In particular, limited communication bandwidth is a considerable constraint when a robot needs to determine if it has visited a location that was previously explored by another robot, as it requires for robots to share descriptions of places they have visited. One way to compress this description is to use constellations, groups of 3D points that correspond to the estimate of a set of relative object positions. Constellations maintain the same pattern from different viewpoints and can be robust to illumination changes or dynamic elements. We present a method to extract from these constellations compact spatial and semantic descriptors of the objects in a scene. We use this representation in a 2step decentralized loop closure verification: first, we distribute the compact semantic descriptors to determine which other robots might have seen scenes with similar objects; then we query matching robots with the full constellation to validate the match using geometric information. The proposed method requires less memory, is more interpretable than global image descriptors, and could be useful for other tasks and interactions with the environment. We validate our system's performance on a TUM RGB-D SLAM sequence and show its benefits in terms of bandwidth requirements.


Title: Online Planning for Quadrotor Teams in 3-D Workspaces via Reachability Analysis On Invariant Geometric Trees
Key Words: aerospace control  helicopters  multi-robot systems  path planning  position control  reachability analysis  robot dynamics  trees (mathematics)  collision-free geometric solution guarantees  online planning  aerial robots  quadrotor teams  cluttered 3D workspaces  reachability analysis  kinodynamic multirobot planning problem  position invariant geometric trees  kinodynamically feasible trajectories  multirobot team  nonstationary initial states  Collision avoidance  Planning  Robot kinematics  Vegetation  Trajectory  Reachability analysis 
Abstract: We consider the kinodynamic multi-robot planning problem in cluttered 3-D workspaces. Reachability analysis on position invariant geometric trees is leveraged to find kino- dynamically feasible trajectories for the multi-robot team from potentially non-stationary initial states. The key contribution of our approach is that a collision-free geometric solution guarantees a kinodynamically feasible, safe solution without additional refinement. Simulation results with up-to 40 robots and hardware results with 5 robots suggest the viability of the proposed approach for online planning and replanning for large teams of aerial robots in cluttered 3-D workspaces.


Title: Decentralized Visual-Inertial-UWB Fusion for Relative State Estimation of Aerial Swarm
Key Words: autonomous aerial vehicles  decentralised control  mobile robots  robot vision  state estimation  decentralized visual-inertial-UWB fusion  unmanned aerial vehicles  multiple UAVs  visual-inertial-UWB fusion framework  extensive aerial swarm flight experiments  motion capture system  vision based method  Global Positioning System  estimation consistency  relative state estimation framework  aerial swarm applications  decentralized relative state estimation method  Drones  State estimation  Cameras  Sensors  Global Positioning System  Real-time systems 
Abstract: The collaboration of unmanned aerial vehicles (UAVs) has become a popular research topic for its practicability in multiple scenarios. The collaboration of multiple UAVs, which is also known as aerial swarm is a highly complex system, which still lacks a state-of-art decentralized relative state estimation method. In this paper, we present a novel fully decentralized visual-inertial-UWB fusion framework for relative state estimation and demonstrate the practicability by performing extensive aerial swarm flight experiments. The comparison result with ground truth data from the motion capture system shows the centimeter-level precision which outperforms all the Ultra-WideBand (UWB) and even vision based method. The system is not limited by the field of view (FoV) of the camera or Global Positioning System (GPS), meanwhile on account of its estimation consistency, we believe that the proposed relative state estimation framework has the potential to be prevalently adopted by aerial swarm applications in different scenarios in multiple scales.


Title: Local Trajectory Stabilization for Dexterous Manipulation via Piecewise Affine Approximations
Key Words: approximation theory  dexterous manipulators  feedback  linear programming  linearisation techniques  manipulator dynamics  nonlinear control systems  stability  piecewise affine approximations  dexterous robotic manipulation  nonsmooth nonlinear system  trajectory optimization  local multicontact dynamics  piecewise affine system  linearization  feedback controller  linear programs  local trajectory stabilization  dexterous manipulation  feedback policy design  Trajectory optimization  Manipulator dynamics  Task analysis  Planning 
Abstract: We propose a model-based approach to design feedback policies for dexterous robotic manipulation. The manipulation problem is formulated as reaching the target region from an initial state for some non-smooth nonlinear system. First, we use trajectory optimization to find a feasible trajectory. Next, we characterize the local multi-contact dynamics around the trajectory as a piecewise affine system, and build a funnel around the linearization of the nominal trajectory using polytopes. We prove that the feedback controller at the vicinity of the linearization is guaranteed to drive the nonlinear system to the target region. During online execution, we solve linear programs to track the system trajectory. We validate the algorithm on hardware, showing that even under large external disturbances, the controller is able to accomplish the task.


Title: Monocular Direct Sparse Localization in a Prior 3D Surfel Map
Key Words: cameras  geophysical image processing  object tracking  optimisation  photometry  pose estimation  rendering (computer graphics)  solid modelling  monocular direct sparse localization  prior 3d surfel map  monocular camera  prior surfel map  vertex  normal maps  global planar information  sparse tracked points  image frame  direct photometric errors  camera localization  pose tracking  rendering  optimization  global 6-DoF camera poses  Cameras  Laser radar  Three-dimensional displays  Visualization  Rendering (computer graphics)  Simultaneous localization and mapping 
Abstract: In this paper, we introduce an approach to tracking the pose of a monocular camera in a prior surfel map. By rendering vertex and normal maps from the prior surfel map, the global planar information for the sparse tracked points in the image frame is obtained. The tracked points with and without the global planar information involve both global and local constraints of frames to the system. Our approach formulates all constraints in the form of direct photometric errors within a local window of the frames. The final optimization utilizes these constraints to provide the accurate estimation of global 6-DoF camera poses with the absolute scale. The extensive simulation and real-world experiments demonstrate that our monocular method can provide accurate camera localization results under various conditions.


Title: Automated Eye-in-Hand Robot-3D Scanner Calibration for Low Stitching Errors
Key Words: calibration  industrial manipulators  robot kinematics  robot vision  DH parameters  high stitching errors  long-term routine industrial use  robot-scanner calibration approach  low data stitching error  long-term continuous measurement  2D standard calibration board  low stitching error  virtual arm-based robot-scanner kinematic model  trajectory-based robot-world transformation calculation  cumbersome marker-based method  lower system downtime  automated eye-in-hand robot-3D scanner calibration  industrial robot  complete measurement  data stitching process  single coordinate system  marker-free stitching  cumbersome traditional fiducial marker-based method  align multiple FOV  Calibration  DH-HEMTs  Robot kinematics  Three-dimensional displays  Kinematics  Optimization 
Abstract: A 3D measurement system consisting of a 3D scanner and an industrial robot (eye-in-hand) is commonly used to scan large object under test (OUT) from multiple fieldof-views (FOVs) for complete measurement. A data stitching process is required to align multiple FOVs into a single coordinate system. Marker-free stitching assisted by robot's accurate positioning becomes increasingly attractive since it bypasses the cumbersome traditional fiducial marker-based method. Most existing methods directly use initial Denavit-Hartenberg (DH) parameters and hand-eye calibration to calculate the transformations between multiple FOVs. Since accuracy of DH parameters deteriorates over time, such methods suffer from high stitching errors (e.g., 0.2 mm) in long-term routine industrial use. This paper reports a new robot-scanner calibration approach to realize such measurement with low data stitching errors. During long-term continuous measurement, the robot periodically moves towards a 2D standard calibration board to optimize kinematic model's parameters to maintain a low stitching error. This capability is enabled by several techniques including virtual arm-based robot-scanner kinematic model, trajectory-based robot-world transformation calculation, nonlinear optimization. Experimental results demonstrated a low data stitching error (<; 0.1 mm) similar to the cumbersome marker-based method and a lower system downtime (<; 60 seconds vs. 10-15 minutes by traditional DH and hand-eye calibration).


Title: A Novel Underactuated End-Effector for Planar Sequential Grasping of Multiple Objects
Key Words: actuators  control system synthesis  dexterous manipulators  end effectors  human-robot interaction  motion control  torque control  underactuated end-effector  planar sequential grasping  multiple objects  underactuated end-effector design  autonomous grasp  circular objects  sequential grasps  human-robot hand-off interactions  torque control  Force  Grasping  Sensors  Estimation  Shape  Fasteners  Torque 
Abstract: We propose a serpentine type tendon driven underactuated end-effector design with a closing mechanism that is triggered upon contact with an object. This end-effector can grasp objects without knowing the size a priori and is able to grasp a new object while securing another one previously grasped, and so grasp multiple objects sequentially with a single DOF actuation. Design parameters based on the object dimensions are proposed. A low-cost prototype demonstrates two implementations (radius estimation and autonomous grasp of circular objects by torque control, and sequential grasps of multiple objects) of the end-effector through several experiments. A method for estimating applied internal forces is also proposed. This end-effector can benefit robotic manipulation in tasks such as fetching applications, industrial pick-and-place of single or multiple objects and human-robot hand-off interactions.


Title: Design and Analysis of a Synergy-Inspired Three-Fingered Hand
Key Words: dexterous manipulators  grippers  manipulator kinematics  motion control  synergy-inspired hands  biomechanical characteristics  human hand synergy  robot hands  synergy characteristics  anthropomorphic hands  synergy-inspired design  Thumb  Robots  Joints  Muscles  Grasping  Electronics packaging 
Abstract: Hand synergy from neuroscience provides an effective tool for anthropomorphic hands to realize versatile grasping with simple planning and control. This paper aims to extend the synergy-inspired design from anthropomorphic hands to multi-fingered robot hands. The synergy-inspired hands are not necessarily humanoid in morphology but perform primary characteristics and functions similar to the human hand. At first, the biomechanics of hand synergy is investigated. Three biomechanical characteristics of the human hand synergy are explored as a basis for the mechanical simplification of the robot hands. Secondly, according to the synergy characteristics, a three-fingered hand is designed, and its kinematic model is developed for the analysis of some typical grasping and manipulation functions. Finally, a prototype is developed and preliminary grasping experiments validate the effectiveness of the design and analysis.


Title: Multiplexed Manipulation: Versatile Multimodal Grasping via a Hybrid Soft Gripper
Key Words: compliant mechanisms  dexterous manipulators  grippers  motion control  multiplexed manipulation  hybrid soft gripper  hybrid suction  parallel jaw grippers  multimodal grippers  soft robotic manipulators  soft fingers  multimodal grasping  Amazon Robotics/Picking Challenge  complaint handed shearing auxetics actuators  Grasping  Grippers  Multiplexing  Force  Belts  Manipulators 
Abstract: The success of hybrid suction + parallel-jaw grippers in the Amazon Robotics/Picking Challenge have demonstrated the effectiveness of multimodal grasping approaches. However, existing multimodal grippers combine grasping modes in isolation and do not incorporate the benefits of compliance found in soft robotic manipulators. In this paper, we present a gripper that integrates three modes of grasping: suction, parallel jaw, and soft fingers. Using complaint handed shearing auxetics actuators as the foundation, this gripper is able to multiplex manipulation by creating unique grasping primitives through permutations of these grasping techniques. This gripper is able to grasp 88% of tested objects, 14% of which could only be grasped using a combination of grasping modes. The gripper is also able to perform in-hand object re-orientation of flat objects without the need for pre-grasp manipulation.


Title: Underactuated Gecko Adhesive Gripper for Simple and Versatile Grasp
Key Words: actuators  adhesion  adhesives  grippers  controllable activation  minimal disturbance  form closure  robotic grasping  versatile grasp  underactuated gecko adhesive gripper  resulting gripper grasp force  adhesive contact area  simple tendon-driven mechanism  underactuated gecko-inspired adhesive gripper  multiple activation steps  complex activation mechanism  grippers  Grippers  Force  Grasping  Pulleys  Adhesives  Actuators  Tendons 
Abstract: Gecko-inspired adhesives have several desirable characteristics in robotic grasping: controllable activation and deactivation of adhesion, ability to grasp and release with minimal disturbance, and grasping without the need of form closure. Previously proposed grippers with this technology either require a complex activation mechanism or multiple activation steps. In this paper, we present an underactuated gecko-inspired adhesive gripper that can grasp a wide range of curved surfaces using a single actuator through a simple tendon-driven mechanism that attaches and adheres in one step. We derive a theoretical model of the adhesive contact area and resulting gripper grasp force, which is verified experimentally. The actual performance of the proposed mechanism is demonstrated by successfully grasping several surfaces with different curvature diameters.


Title: Design and Workspace Characterisation of Malleable Robots
Key Words: actuators  design engineering  elasticity  end effectors  manipulator dynamics  manipulator kinematics  position control  bin picking  variable stiffness link  low DOF serial robot  2-DOF malleable robot  workspace categories  serial robot arms  End effectors  Robot kinematics  Task analysis  Mathematical model  Topology 
Abstract: For the majority of tasks performed by traditional serial robot arms, such as bin picking or pick and place, only two or three degrees of freedom (DOF) are required for motion; however, by augmenting the number of degrees of freedom, further dexterity of robot arms for multiple tasks can be achieved. Instead of increasing the number of joints of a robot to improve flexibility and adaptation, which increases control complexity, weight, and cost of the overall system, malleable robots utilise a variable stiffness link between joints allowing the relative positioning of the revolute pairs at each end of the link to vary, thus enabling a low DOF serial robot to adapt across tasks by varying its workspace. In this paper, we present the design and prototyping of a 2-DOF malleable robot, calculate the general equation of its workspace using a parameterisation based on distance geometry-suitable for robot arms of variable topology, and characterise the workspace categories that the end effector of the robot can trace via reconfiguration. Through the design and construction of the malleable robot we explore design considerations, and demonstrate the viability of the overall concept. By using motion tracking on the physical robot, we show examples of the infinite number of workspaces that the introduced 2-DOF malleable robot can achieve.


Title: Dynamically Reconfigurable Discrete Distributed Stiffness for Inflated Beam Robots
Key Words: beams (structures)  buckling  cantilevers  electromagnets  electromechanical actuators  jamming  motion control  rigidity  robot kinematics  valves  tip-everting robots  tendonsteering  robot kinematics  cantilevered loads  electromechanical device  electromagnet  passive valves  pressure layer jamming  buckle point locations  compressive loads  actuators  motion control  discrete distributed stiffness control  inflated beam robot body  inflated continuum robots  Valves  Jamming  Actuators  Laser beams  Soft robotics  Shape 
Abstract: Inflated continuum robots are promising for a variety of navigation tasks, but controlling their motion with a small number of actuators is challenging. These inflated beam robots tend to buckle under compressive loads, producing extremely tight local curvature at difficult-to-control buckle point locations. In this paper, we present an inflated beam robot that uses distributed stiffness changing sections enabled by positive pressure layer jamming to control or prevent buckling. Passive valves are actuated by an electromagnet carried by an electromechanical device that travels inside the main inflated beam robot body. The valves themselves require no external connections or wiring, allowing the distributed stiffness control to be scaled to long beam lengths. Multiple layer jamming elements are stiffened simultaneously to achieve global stiffening, allowing the robot to support greater cantilevered loads and longer unsupported lengths. Local stiffening, achieved by leaving certain layer jamming elements unstiffened, allows the robot to produce "virtual joints" that dynamically change the robot kinematics. Implementing these stiffening strategies is compatible with growth through tip eversion and tendonsteering, and enables a number of new capabilities for inflated beam robots and tip-everting robots.


Title: Data-Driven Reinforcement Learning for Walking Assistance Control of a Lower Limb Exoskeleton with Hemiplegic Patients
Key Words: adaptive control  artificial limbs  handicapped aids  iterative methods  learning (artificial intelligence)  medical robotics  neural nets  optimal control  patient rehabilitation  wearable robots  Data-driven reinforcement learning  lower limb exoskeleton  hemiplegic patient  rehabilitation scenario  affected leg  unaffected leg  exoskeleton system  DDRL strategy  optimal control  policy iteration algorithm  online adaptation control  walking assistance control  walking assistance scenario  strength augmentation scenario  Actor-Critic Neural Network  ACNN  Legged locomotion  Exoskeletons  Adaptation models  Learning (artificial intelligence)  Trajectory  Extremities  Optimal control  Data-driven Control  Reinforcement Learning  Leader-Follower Multi-Agent System  Lower Limb Exoskeleton  Hemiplegic Patients  Actor-Critic Neural Network 
Abstract: Lower limb exoskeleton (LLE) has received considerable interests in strength augmentation, rehabilitation and walking assistance scenarios. For walking assistance, the LLE is expected to have the capability of controlling the affected leg to track the unaffected leg's motion naturally. An important issue in this scenario is that the exoskeleton system needs to deal with unpredictable disturbance from the patient, which requires the controller of exoskeleton system to have the ability to adapt to different wearers. This paper proposes a novel Data-Driven Reinforcement Learning (DDRL) control strategy to adapt different hemiplegic patients with unpredictable disturbances. In the proposed DDRL strategy, the interaction between two lower limbs of LLE and the legs of hemiplegic patient are modeled in the context of leader-follower framework. The walking assistance control problem is transformed into a optimal control problem. Then, a policy iteration (PI) algorithm is introduced to learn optimal controller. To achieve online adaptation control for different patients, based on PI algorithm, an Actor-Critic Neural Network (ACNN) technology of the reinforcement learning (RL) is employed in the proposed DDRL. We conduct experiments both on a simulation environment and a real LLE system. Experimental results demonstrate that the proposed control strategy has strong robustness against disturbances and adaptability to different pilots.


Title: Towards an Intelligent Collaborative Robotic System for Mixed Case Palletizing
Key Words: graphical user interfaces  groupware  human-robot interaction  industrial robots  mobile robots  multi-robot systems  optimisation  palletising  production engineering computing  visual perception  collaborative palletizing tasks  intelligent collaborative robotic system  mixed case palletizing  visual perception algorithms  high-level optimisation  graphical user interface  Mobile COllaborative robotic Assistant  human-robot collaborative framework  MOCA  packing density maximisation  Pallets  Task analysis  Collaboration  Robots  Impedance  Torque  Resource management 
Abstract: In this paper, a novel human-robot collaborative framework for mixed case palletizing is presented. The framework addresses several challenges associated with the detection and localisation of boxes and pallets through visual perception algorithms, high-level optimisation of the collaborative effort through effective role-allocation principles, and maximisation of packing density. A graphical user interface (GUI) is additionally developed to ensure an intuitive allocation of roles and the optimal placement of the boxes on target pallets. The framework is evaluated in two conditions where humans operate with and without the support of a Mobile COllaborative robotic Assistant (MOCA). The results show that the optimised placement can improve up to the 20% with respect to a manual execution of the same task, and reveal the high potential of MOCA in increasing the performance of collaborative palletizing tasks.


Title: DexPilot: Vision-Based Teleoperation of Dexterous Robotic Hand-Arm System
Key Words: dexterous manipulators  robot vision  telerobotics  vision-based teleoperation  dexterous robotic hand-arm system  robotic systems  reasoning skills  depth-based teleoperation system  DoA robotic system  DexPilot  degree-of-actuation  multifingered robots  pick-and-place operations  Tracking  Three-dimensional displays  Task analysis  Robot sensing systems  Cameras  Neural networks 
Abstract: Teleoperation offers the possibility of imparting robotic systems with sophisticated reasoning skills, intuition, and creativity to perform tasks. However, teleoperation solutions for high degree-of-actuation (DoA), multi-fingered robots are generally cost-prohibitive, while low-cost offerings usually offer reduced degrees of control. Herein, a low-cost, depth-based teleoperation system, DexPilot, was developed that allows for complete control over the full 23 DoA robotic system by merely observing the bare human hand. DexPilot enabled operators to solve a variety of complex manipulation tasks that go beyond simple pick-and-place operations and performance was measured through speed and reliability metrics. DexPilot cost-effectively enables the production of high dimensional, multi-modality, state-action data that can be leveraged in the future to learn sensorimotor policies for challenging manipulation tasks. The videos of the experiments can be found at https://sites.google.com/view/dex-pilot.


Title: Distributed Winner-Take-All Teleoperation of A Multi-Robot System
Key Words: decision making  Lyapunov methods  multi-robot systems  protocols  stability  telerobotics  team cohesion  dynamic decision-making protocol  decision variable  slave robots  decision-making algorithm  3-masters-11-slaves teleoperation  distributed winner-take-all teleoperation  multirobot system  multimaster-multislave teleoperation system  Lyapunov stability analysis  Robots  Decision making  Protocols  Heuristic algorithms  Indexes  Force  Multi-robot systems 
Abstract: In a distributed multi-master-multi-slave teleoperation system, the human users may compete against each other for the control of the team of slave robots. To win the competition, one operator would send the largest command to the slave group. For the sake of team cohesion, the slave group should follow the command of the winning operator and ignore the commands of the other users. To enable (i) the slave team to identify the winning operator, and (ii) each slave to determine whether to admit or discard the command it receives from its operator, this paper proposes a dynamic decision-making protocol that distinguishes the decision variable of the slave commanded by the winner from the decision variables of all other slave robots. The protocol only requires the slaves to exchange and evaluate their decision variables locally. Lyapunov stability analysis proves the theoretical convergence of the proposed decision-making algorithm. An experimental distributed winner-take-all teleoperation in a 3-masters-11-slaves teleoperation testbed validates its practical efficacy.


Title: Multimodal Trajectory Predictions for Urban Environments Using Geometric Relationships between a Vehicle and Lanes
Key Words: feature extraction  object detection  road traffic  road vehicles  traffic engineering computing  autonomous driving systems  traffic behavior  urban environments  road geometries  lane-based multimodal prediction network  arbitrary shapes  traffic lanes  future trajectory  lane geometry  lane feature  generalized geometric relationships  vehicle state  vehicle motion model constraint  prediction method  multimodal trajectory predictions  safe driving systems  LAMP-Net  Trajectory  Predictive models  Hidden Markov models  Acceleration  Geometry  Shape  Urban areas 
Abstract: Implementation of safe and efficient autonomous driving systems requires accurate prediction of the long-term trajectories of surrounding vehicles. High uncertainty in traffic behavior makes it difficult to predict trajectories in urban environments, which have various road geometries. To over-come this problem, we propose a method called lane-based multimodal prediction network (LAMP-Net), which can handle arbitrary shapes and numbers of traffic lanes and predict both the future trajectory along each lane and the probability of each lane being selected. A vector map is used to define the lane geometry and a novel lane feature is introduced to represent the generalized geometric relationships between the vehicle state and lanes. Our network takes this feature as the input and is trained to be versatile for arbitrarily shaped lanes. Moreover, we introduce a vehicle motion model constraint to our network. Our prediction method combined with the constraint significantly enhances prediction accuracy. We evaluate the prediction performance on two datasets which contain a wide variety of real-world traffic scenarios. Experimental results show that our proposed LAMP-Net outperforms state-of-the-art methods.


Title: Episodic Koopman Learning of Nonlinear Robot Dynamics with Application to Fast Multirotor Landing
Key Words: aircraft control  helicopters  learning (artificial intelligence)  nonlinear control systems  nonlinear dynamical systems  optimal control  predictive control  robot dynamics  model predictive control  nonlinear diffeomorphism  nonlinear dynamical systems  optimal control  multirotor landing  nonlinear robot dynamics  episodic Koopman learning  Eigenvalues and eigenfunctions  Nonlinear dynamical systems  Robots  Aerospace electronics  Heuristic algorithms  Vehicle dynamics 
Abstract: This paper presents a novel episodic method to learn a robot's nonlinear dynamics model and an increasingly optimal control sequence for a set of tasks. The method is based on the Koopman operator approach to nonlinear dynamical systems analysis, which models the flow of observables in a function space, rather than a flow in a state space. Practically, this method estimates a nonlinear diffeomorphism that lifts the dynamics to a higher dimensional space where they are linear. Efficient Model Predictive Control methods can then be applied to the lifted model. This approach allows for real time implementation in on-board hardware, with rigorous incorporation of both input and state constraints during learning. We demonstrate the method in a real-time implementation of fast multirotor landing, where the nonlinear ground effect is learned and used to improve landing speed and quality.


Title: Eye-in-Hand 3D Visual Servoing of Helical Swimmers Using Parallel Mobile Coils
Key Words: marine systems  microrobots  mobile robots  robot vision  visual servoing  refraction-rectified location algorithm  coil module  motor module  eye-in-hand stereo-vision module  medical applications  spacial movement  control methods  magnetic actuation systems  narrow space  magnetic field  magnetic helical microswimmers  parallel mobile coils  eye-in-hand 3D visual servoing  cylindrical workspace  prototype system  long-distance 3D path  triple-loop stereo visual servoing strategy  dynamic magnetic fields  mobile-coil system  Coils  Magnetic resonance imaging  Three-dimensional displays  Cameras  Magnetic devices  Visual servoing  Magnetic separation 
Abstract: Magnetic helical microswimmers can be propelled by rotating magnetic field and are adept at passing through narrow space. To date, various magnetic actuation systems and control methods have been developed to drive these microswimmers. However, steering their spacial movement in a large workspace is still challenging, which could be significant for potential medical applications. In this regard, this paper designs an eye-in-hand stereo-vision module and corresponding refraction-rectified location algorithm. Combined with the motor module and the coil module, the mobile-coil system is capable of generating dynamic magnetic fields in a large 3D workspace. Based on the system, a robust triple-loop stereo visual servoing strategy is proposed that operates simultaneous tracking, locating, and steering, through which the helical swimmer is able to follow a long-distance 3D path. A scaled-up magnetic helical swimmer is employed in the path following experiment. Our prototype system reaches a cylindrical workspace with a diameter more than 200 mm, and the mean error of path tracking is less than 2 mm.


Title: A Mobile Paramagnetic Nanoparticle Swarm with Automatic Shape Deformation Control
Key Words: control nonlinearities  deformation  fuzzy control  microrobots  mobile robots  multi-robot systems  nanoparticles  robot dynamics  EPNS  mobile paramagnetic nanoparticle swarm  automatic shape deformation control  swarm control  active shape deformation  elliptical rotating magnetic fields  swarm pattern  elliptical paramagnetic nanoparticle swarm  strength ratio  elliptical field  shape ratio  length ratio  deformation dynamics  fuzzy logic-based control  nanorobot  microrobotics  field ratio  nonlinearity  planar rotational locomotion  planar translational locomotion  Shape  Strain  Magnetic resonance imaging  Nanoparticles  Virtual private networks  Micromagnetics  Magnetic anisotropy 
Abstract: Recently, swarm control of micro-/nanorobots has drawn much attention in the field of microrobotics. This paper reports a mobile paramagnetic nanoparticle swarm with the capability of active shape deformation that can improve its environment adaptability. We show that, by applying elliptical rotating magnetic fields, a swarm pattern called the elliptical paramagnetic nanoparticle swarm (EPNS) would be formed. When changing the field ratio-α (i.e. the strength ratio between the minor axis and major axis of the elliptical field), the shape ratio-β of the EPNS (i.e. the length ratio between the major axis and minor axis) will change accordingly. However, automatically control this shape deformation process has difficulties because the deformation dynamics has strong nonlinearity, model variation and long time requirement. To solve this problem, we propose a fuzzy logic-based control scheme that utilizes the knowledge and control experience from skilled human operators. Experiments show that the proposed control scheme can stably maneuver the shape deformation of the EPNS with small overshoot, which cannot be achieved by conventional PI control. Moreover, experimental results show that, with the automatic shape deformation control, shape of the EPNS is controlled with high reversibility and also can be well maintained during the planar rotational and translational locomotion of the EPNS.


Title: Magnetic miniature swimmers with multiple rigid flagella
Key Words: biomechanics  microrobots  mobile robots  position control  propulsion  magnetic miniature swimmers  multiple rigid flagella  multiple rigid tails  rotating magnetic field  robot rotation  tail distribution  tail height  multitailed swimmer robots  spherical helices  2-tailed swimmer  angular position  Robots  Propulsion  Magnetosphere  Prototypes  Microorganisms  Force  Mathematical model 
Abstract: In this paper, we introduce novel miniature swimmers with multiple rigid tails based on spherical helices. The tail distribution of these prototypes enhances its swimming features as well as allowing to carry objects with it. The proposed swimmers are actuated by a rotating magnetic field, generating the robot rotation and thus producing a considerable thrust to start self-propelling. These prototypes achieved propulsion speeds up to 6 mm/s at 3.5 Hz for a 6-mm in size prototypes. We study the efficiency of different tail distribution for a 2-tailed swimmer by varying the angular position between both tails. Moreover, it is demonstrated that these swimmers experience great sensibility when changing their tail height. Besides, these swimmers demonstrate to be effective for cargo carrying tasks since they can displace objects up to 3.5 times their weight. Finally, wall effect is studied with multi-tailed swimmer robots considering 2 containers with 20 and 50-mm in width. Results showed speeds' increments up to 59% when swimmers are actuated in the smaller container.


Title: Modeling Electromagnetic Navigation Systems for Medical Applications using Random Forests and Artificial Neural Networks
Key Words: electromagnetic devices  learning (artificial intelligence)  mean square error methods  medical computing  neural nets  surgery  nonlinear regions  higher magnetic fields  random forest  RF  artificial neural network  eMNS  state-of-the-art linear multipole electromagnet model  MPEM  ANN model  field magnitude  current range  high current regions  field-magnitude RMSE improvement  error reduction  machine learning  medical applications  complex nonlinear behavior  accurate field  magnetic navigation  modeling electromagnetic Navigation Systems  multiscale devices  human body  remote surgery  electromagnets  linear behavior  significant modeling errors  Saturation magnetization  Electromagnets  Current measurement  Magnetic cores  Magnetostatics  Magnetic resonance imaging  Magnetic separation 
Abstract: Electromagnetic Navigation Systems (eMNS) can be used to control a variety of multiscale devices within the human body for remote surgery. Accurate modeling of the magnetic fields generated by the electromagnets of an eMNS is crucial for the precise control of these devices. Existing methods assume a linear behavior of these systems, leading to significant modeling errors within nonlinear regions exhibited at higher magnetic fields, preventing these systems from operating at full capacity. In this paper, we use a random forest (RF) and an artificial neural network (ANN) to model the nonlinear behavior of the magnetic fields generated by an eMNS. Both machine learning methods outperformed the state-of-the-art linear multipole electromagnet model (MPEM). The RF and the ANN model reduced the root mean squared error (RMSE) of the MPEM when predicting the field magnitude by approximately 40% and 87%, respectively, over the entire current range of the eMNS. At high current regions, especially between 30 and 35 A, the field-magnitude RMSE improvement of the ANN model over the MPEM was 37 mT, equivalent to 90% error reduction. This study demonstrates the feasibility of using machine learning to model an eMNS for medical applications, and its ability to account for complex nonlinear behavior at high currents. The use of machine learning thus shows promise in developing accurate field predicting models, and ultimately improving surgical procedures that use magnetic navigation.


Title: Multispectral Domain Invariant Image for Retrieval-based Place Recognition
Key Words: image colour analysis  image recognition  image retrieval  image segmentation  infrared imaging  spectral analysis  multispectral place recognition task  multispectral semantic segmentation  multispectral domain invariant image  retrieval-based place recognition  multispectral recognition  thermal image  RGB domain-based tasks  multispectral domain invariant framework  unpaired image translation method  semantic image  discriminative invariant image  Image recognition  Robot sensing systems  Task analysis  Semantics  Thermal sensors  Feature extraction  Imaging 
Abstract: Multispectral recognition has attracted increasing attention from the research community due to its potential competence for many applications from day to night. However, due to the domain shift between RGB and thermal image, it has still many challenges to apply and to use RGB domain-based tasks. To reduce the domain gap, we propose multispectral domain invariant framework, which leverages the unpaired image translation method to generate a semantic and strongly discriminative invariant image by enforcing novel constraints in the objective function. We demonstrate the efficacy of the proposed method on mainly multispectral place recognition task and achieve significant improvement compared to previous works. Furthermore, we test on multispectral semantic segmentation and unsupervised domain adaptations to prove the scalability and generality of the proposed method. We will open our source code and dataset.


Title: Anytime Integrated Task and Motion Policies for Stochastic Environments
Key Words: intelligent robots  mobile robots  multi-agent systems  multi-robot systems  path planning  planning (artificial intelligence)  stochastic processes  multiple execution-time contingencies  motion policies  stochastic settings  stochastic situations  abstract models  motion planning  abstract planning  intelligent robots  stochastic environments  anytime integrated task  Robots  Planning  Task analysis  Computational modeling  Collision avoidance  Stochastic processes  Trajectory 
Abstract: In order to solve complex, long-horizon tasks, intelligent robots need to carry out high-level, abstract planning and reasoning in conjunction with motion planning. However, abstract models are typically lossy and plans or policies computed using them can be unexecutable. These problems are exacerbated in stochastic situations where the robot needs to reason about, and plan for multiple contingencies. We present a new approach for integrated task and motion planning in stochastic settings. In contrast to prior work in this direction, we show that our approach can effectively compute integrated task and motion policies whose branching structures encoding agent behaviors handling multiple execution-time contingencies. We prove that our algorithm is probabilistically complete and can compute feasible solution policies in an anytime fashion so that the probability of encountering an unresolved contingency decreases over time. Empirical results on a set of challenging problems show the utility and scope of our methods.


Title: Fault tolerance analysis of a hexarotor with reconfigurable tilted rotors
Key Words: aircraft control  attitude control  fault tolerance  helicopters  fault tolerance analysis  reconfigurable tilted rotor  multirotor vehicles  yaw maneuverability  attitude control  hexarotor vehicle  hexagon-shaped multirotor  altitude control  tilt angle  rotor reconfiguration  Rotors  Torque  Force  Servomotors  Fault tolerance  Fault tolerant systems  Attitude control 
Abstract: Tilted rotors in multirotor vehicles have shown to be useful for different practical reasons. For instance, increasing yaw maneuverability or enabling full position and attitude control of hexarotor vehicles. It has also been proven that a hexagon-shaped multirotor is capable of complete attitude and altitude control under failures of one of its rotors. However, when a rotor fails, the torque that can be reached in the worst- case direction decreases considerably.This work proposes to actively change the tilt angle of the rotors when a failure occurs. This rotor reconfiguration increases the maximum torque that can be achieved in the most stressful direction, reducing maneuverability limitations. Experimental validations are shown, where the proposed reconfigurable tilted rotor is used in order to control a hexarotor vehicle when a failure appears mid-flight. The impact of the delay in the reconfiguration when a failure occurs is also addressed.


Title: Reliability Validation of Learning Enabled Vehicle Tracking
Key Words: image filtering  image motion analysis  Kalman filters  learning (artificial intelligence)  neural nets  object tracking  real-world learning-enabled system  dynamic vehicle tracking  high-resolution wide-area motion imagery input  symbolic components  Kalman filter  neural networks  system-level reliability  coverage-guided neural network testing tool  vehicle tracking system  adversarial examples  deep learning components  validation methods  learning-enabled systems  neural network components  DeepConcolic tool  Testing  Tools  Tracking  Neurons  Cameras  Feature extraction  Reliability 
Abstract: This paper studies the reliability of a real-world learning-enabled system, which conducts dynamic vehicle tracking based on a high-resolution wide-area motion imagery input. The system consists of multiple neural network components - to process the imagery inputs - and multiple symbolic (Kalman filter) components - to analyse the processed information for vehicle tracking. It is known that neural networks suffer from adversarial examples, which make them lack robustness. However, it is unclear if and how the adversarial examples over learning components can affect the overall system-level reliability. By integrating a coverage-guided neural network testing tool, DeepConcolic, with the vehicle tracking system, we found that (1) the overall system can be resilient to some adversarial examples thanks to the existence of other components, and (2) the overall system presents an extra level of uncertainty which cannot be determined by analysing the deep learning components only. This research suggests the need for novel verification and validation methods for learning-enabled systems.


Title: Real-Time, Highly Accurate Robotic Grasp Detection using Fully Convolutional Neural Network with Rotation Ensemble Module
Key Words: convolutional neural nets  image classification  learning (artificial intelligence)  object detection  robot vision  highly accurate robotic grasp detection  fully convolutional neural network  rotation ensemble module  rotation invariance  computer vision tasks  rotation anchor box  multiple objects  4-axis robot arm  Cornell dataset  REM  Proposals  Grasping  Task analysis  Robot sensing systems  Feature extraction  Kernel 
Abstract: Rotation invariance has been an important topic in computer vision tasks. Ideally, robot grasp detection should be rotation-invariant. However, rotation-invariance in robotic grasp detection has been only recently studied by using rotation anchor box that are often time-consuming and unreliable for multiple objects. In this paper, we propose a rotation ensemble module (REM) for robotic grasp detection using convolutions that rotates network weights. Our proposed REM was able to outperform current state-of-the-art methods by achieving up to 99.2% (image-wise), 98.6% (object-wise) accuracies on the Cornell dataset with real-time computation (50 frames per second). Our proposed method was also able to yield reliable grasps for multiple objects and up to 93.8% success rate for the real-time robotic grasping task with a 4-axis robot arm for small novel objects that was significantly higher than the baseline methods by 11-56%.


Title: Form2Fit: Learning Shape Priors for Generalizable Assembly from Disassembly
Key Words: CAD  learning (artificial intelligence)  object recognition  pose estimation  robotic assembly  kit assembly task  shape matching problem  shape descriptor  object surfaces  self-supervised data-collection pipeline  robotic assembly  3D CAD models  task-specific training data  Task analysis  Shape  Visualization  Training data  Three-dimensional displays  Solid modeling  Training 
Abstract: Is it possible to learn policies for robotic assembly that can generalize to new objects? We explore this idea in the context of the kit assembly task. Since classic methods rely heavily on object pose estimation, they often struggle to generalize to new objects without 3D CAD models or task-specific training data. In this work, we propose to formulate the kit assembly task as a shape matching problem, where the goal is to learn a shape descriptor that establishes geometric correspondences between object surfaces and their target placement locations from visual input. This formulation enables the model to acquire a broader understanding of how shapes and surfaces fit together for assembly - allowing it to generalize to new objects and kits. To obtain training data for our model, we present a self-supervised data-collection pipeline that obtains ground truth object-to-placement correspondences by disassembling complete kits. Our resulting real-world system, Form2Fit, learns effective pick and place strategies for assembling objects into a variety of kits - achieving 90% average success rates under different initial conditions (e.g. varying object and kit poses), 94% success under new configurations of multiple kits, and over 86% success with completely new objects and kits. Code, videos, and supplemental material are available at https://form2fit.github.io.


Title: Efficient two step optimization for large embedded deformation graph based SLAM
Key Words: computational complexity  embedded systems  graph theory  Hessian matrices  robot vision  SLAM (robots)  stereo image processing  parameter estimation  computation complexity  two step optimization  deformable geometry  stereo camera  SLAM applications  large scale embedded deformation graph  Hessian matrix  Simultaneous localization and mapping  Strain  Jacobian matrices  Optimization  Cameras  Deformable models  Geometry 
Abstract: Embedded deformation graph is a widely used technique in deformable geometry and graphical problems. Although the technique has been transmitted to stereo (or RGB-D) camera based SLAM applications, it remains challenging to compromise the computational cost as the model grows. In practice, the processing time grows rapidly in accordance with the expansion of maps. In this paper, we propose an approach to decouple the nodes of deformation graph in large scale dense deformable SLAM and keep the estimation time to be constant. We observe that only partial deformable nodes in the graph are connected to visible points. Based on this fact, the sparsity of the original Hessian matrix is utilized to split the parameter estimation into two independent steps. With this new technique, we achieve faster parameter estimation with amortized computation complexity reduced from O(n2) to almost O(1). As a result, the computational cost barely increases as the map keeps growing. Based on our strategy, the computational bottleneck in large scale embedded deformation graph based applications will be greatly mitigated. The effectiveness is validated by experiments, featuring large scale deformation scenarios.


Title: Camera-to-Robot Pose Estimation from a Single Image
Key Words: cameras  image colour analysis  image sensors  manipulators  neural nets  pose estimation  robot vision  camera-to-robot pose estimation  single RGB image  deep neural network  perspective-n-point  robot manipulator  classic hand-eye calibration systems  camera sensors  classic off-line hand-eye calibration  robot sensors  Cameras  Robot vision systems  Robot kinematics  Calibration  Two dimensional displays  Training 
Abstract: We present an approach for estimating the pose of an external camera with respect to a robot using a single RGB image of the robot. The image is processed by a deep neural network to detect 2D projections of keypoints (such as joints) associated with the robot. The network is trained entirely on simulated data using domain randomization to bridge the reality gap. Perspective-n-point (PnP) is then used to recover the camera extrinsics, assuming that the camera intrinsics and joint configuration of the robot manipulator are known. Unlike classic hand-eye calibration systems, our method does not require an off-line calibration step. Rather, it is capable of computing the camera extrinsics from a single frame, thus opening the possibility of on-line calibration. We show experimental results for three different robots and camera sensors, demonstrating that our approach is able to achieve accuracy with a single frame that is comparable to that of classic off-line hand-eye calibration using multiple frames. With additional frames from a static pose, accuracy improves even further. Code, datasets, and pretrained models for three widely-used robot manipulators are made available.


Title: Generation of Object Candidates Through Simply Looking Around
Key Words: cameras  image segmentation  image sequences  mobile robots  object detection  object recognition  robot vision  video signal processing  mobile robot  pan-tilt monocular camera  camera movements  robot operating indoors  object candidates  Cameras  Robot vision systems  Image segmentation  Visualization  Coherence  Tracking 
Abstract: In this paper, we consider the generation of generic object candidates by a mobile robot that is endowed with a pan-tilt monocular camera. This is an important problem because these candidates serve as basis for the robot to categorize and/or recognize the objects in its surroundings. The previously proposed methods either do not have a means of enabling the robot to look around through moving its camera or do not take advantage of the temporal coherence of the video data. We present a novel approach that enables the robot to achieve both of these capabilities simultaneously. In this approach, the robot's camera movements are governed by a family of controllers whose constructions depend on the set of object candidates that have been hitherto generated, but not directly looked at. In parallel, the robot discovers the object candidates through tracking segments and determining spatio-temporally coherent ones. The advantage of the proposed approach is that while the robot can explore its surroundings by simply looking around prior to more sophisticated exploration behavior involving possibly bodily locomotion the generated object candidates turn out to be consolidated across the visual stream in comparison to single-shot methods. This is demonstrated in extensive experimental results with a robot operating indoors varying in clutter as well as outdoors.


Title: Under the Radar: Learning to Predict Robust Keypoints for Odometry Estimation and Metric Localisation in Radar
Key Words: distance measurement  feature extraction  image colour analysis  image sensors  image sequences  mobile robots  motion estimation  object recognition  object tracking  radar computing  robot vision  SLAM (robots)  supervised learning  predict robust keypoints  odometry estimation  metric localisation  self-supervised framework  differentiable point-based motion estimator  localisation error  Oxford Radar RobotCar Dataset  point-based radar odometry  Radar  Measurement  Task analysis  Estimation  Robot sensing systems  Computer architecture 
Abstract: This paper presents a self-supervised framework for learning to detect robust keypoints for odometry estimation and metric localisation in radar. By embedding a differentiable point-based motion estimator inside our architecture, we learn keypoint locations, scores and descriptors from localisation error alone. This approach avoids imposing any assumption on what makes a robust keypoint and crucially allows them to be optimised for our application. Furthermore the architecture is sensor agnostic and can be applied to most modalities. We run experiments on 280km of real world driving from the Oxford Radar RobotCar Dataset and improve on the state-of-the-art in point-based radar odometry, reducing errors by up to 45% whilst running an order of magnitude faster, simultaneously solving metric loop closures. Combining these outputs, we provide a framework capable of full mapping and localisation with radar in urban environments.


Title: Learned Sampling Distributions for Efficient Planning in Hybrid Geometric and Object-Level Representations
Key Words: geometry  image representation  learning (artificial intelligence)  mobile robots  multi-agent systems  path planning  robot vision  linear regression  efficiency planning  sampling distribution learning  sampling-based planners  object-level semantics  myopic behavior  geometric information  navigation  robotic agent  object-level representations  hybrid geometric  Navigation  Planning  Semantics  Trajectory  Mathematical model  Optimization  Robots 
Abstract: We would like to enable a robotic agent to quickly and intelligently find promising trajectories through structured, unknown environments. Many approaches to navigation in unknown environments are limited to considering geometric information only, which leads to myopic behavior. In this work, we show that learning a sampling distribution that incorporates both geometric information and explicit, object-level semantics for sampling-based planners enables efficient planning at longer horizons in partially-known environments. We demonstrate that our learned planner is up to 2.7 times more likely to find a plan than the baseline, and can result in up to a 16% reduction in traversal costs as calculated by linear regression. We also show promising qualitative results on real-world data.


Title: Deep Visual Heuristics: Learning Feasibility of Mixed-Integer Programs for Manipulation Planning
Key Words: integer programming  learning (artificial intelligence)  manipulators  neurocontrollers  path planning  robot vision  deep visual heuristics  mixed-integer program  deep neural network  visual input  robot manipulation planning  motion planning  learning algorithm  goal encoding  optimization problems  Planning  Task analysis  Robot sensing systems  Neural networks  Grasping  Search problems 
Abstract: In this paper, we propose a deep neural network that predicts the feasibility of a mixed-integer program from visual input for robot manipulation planning. Integrating learning into task and motion planning is challenging, since it is unclear how the scene and goals can be encoded as input to the learning algorithm in a way that enables to generalize over a variety of tasks in environments with changing numbers of objects and goals. To achieve this, we propose to encode the scene and the target object directly in the image space.Our experiments show that our proposed network generalizes to scenes with multiple objects, although during training only two objects are present at the same time. By using the learned network as a heuristic to guide the search over the discrete variables of the mixed-integer program, the number of optimization problems that have to be solved to find a feasible solution or to detect infeasibility can greatly be reduced.


Title: Dynamic Landing of an Autonomous Quadrotor on a Moving Platform in Turbulent Wind Conditions
Key Words: aircraft landing guidance  autonomous aerial vehicles  Global Positioning System  helicopters  Kalman filters  mobile robots  nonlinear filters  robot dynamics  robot vision  robust control  turbulence  variable structure systems  vehicle dynamics  dynamic landing  autonomous quadrotor  moving platform  turbulent wind conditions  autonomous landing  fast trajectory planning  wind disturbance  fully autonomous vision-based system  quadrotor-platform distance  landing trajectory  receding horizon control  boundary layer sliding controller  extended Kalman filter  GPS measurements  robust control  precise control  Trajectory  Cameras  Vehicle dynamics  Planning  Global Positioning System  Visualization  Acceleration  Unmanned aerial vehicles  autonomous vehicles  landing on a moving platform  disturbance compensation 
Abstract: Autonomous landing on a moving platform presents unique challenges for multirotor vehicles, including the need to accurately localize the platform, fast trajectory planning, and precise/robust control. Previous works studied this problem but most lack explicit consideration of the wind disturbance, which typically leads to slow descents onto the platform. This work presents a fully autonomous vision-based system that addresses these limitations by tightly coupling the localization, planning, and control, thereby enabling fast and accurate landing on a moving platform. The platform's position, orientation, and velocity are estimated by an extended Kalman filter using simulated GPS measurements when the quadrotor-platform distance is large, and by a visual fiducial system when the platform is nearby. The landing trajectory is computed online using receding horizon control and is followed by a boundary layer sliding controller that provides tracking performance guarantees in the presence of unknown, but bounded, disturbances. To improve the performance, the characteristics of the turbulent conditions are accounted for in the controller. The landing trajectory is fast, direct, and does not require hovering over the platform, as is typical of most stateof-the-art approaches. Simulations and hardware experiments are presented to validate the robustness of the approach.


Title: Multi-Head Attention for Multi-Modal Joint Vehicle Motion Forecasting
Key Words: position control  probability  road vehicles  tracking  joint forecast  multimodal probability density functions  vehicle position tracks  multimodal joint vehicle motion forecasting  maneuver definitions  road scene  long short-term memory layers  spatial grid  Forecasting  Predictive models  Roads  Uncertainty  Computer architecture  Tensile stress  Probability density function 
Abstract: This paper presents a novel vehicle motion forecasting method based on multi-head attention. It produces joint forecasts for all vehicles on a road scene as sequences of multi-modal probability density functions of their positions. Its architecture uses multi-head attention to account for interactions between all vehicles, and long short-term memory layers for encoding and forecasting. It relies solely on vehicle position tracks, does not need maneuver definitions, and does not rasterize the scene as a spatial grid. This allows it to be more versatile than similar model while combining many forecasting capabilities, namely joint forecast with interactions, uncertainty estimation, and multi-modality. The resulting prediction likelihood outperforms state-of-the-art models on the same dataset.


Title: A Volumetric Albedo Framework for 3D Imaging Sonar Reconstruction
Key Words: autonomous underwater vehicles  image reconstruction  optimisation  robot vision  solid modelling  sonar  sonar imaging  stereo image processing  3D imaging sonar reconstruction  object-level 3D underwater reconstruction  imaging sonar sensors  nonline-of-sight reconstruction  convex linear optimization problem  alternating direction method of multipliers  ADMM  sonar elevation apertures  autonomous underwater vehicles  volumetric Albedo framework  Sonar  Image reconstruction  Imaging  Three-dimensional displays  Sensors  Nonlinear optics  Surface reconstruction 
Abstract: We present a novel framework for object-level 3D underwater reconstruction using imaging sonar sensors. We demonstrate that imaging sonar reconstruction is analogous to the problem of confocal non-line-of-sight (NLOS) reconstruction. Drawing upon this connection, we formulate the problem as one of solving for volumetric albedo, where the scene of interest is modeled as a directionless albedo field. After discretization, reconstruction reduces to a convex linear optimization problem, which we can augment with a variety of priors and regularization terms. We show how to solve the resulting regularized problems using the alternating direction method of multipliers (ADMM) algorithm. We demonstrate the effectiveness of the proposed approach in simulation and on real-world datasets collected in a controlled, test tank environment with several different sonar elevation apertures.


Title: Map Management Approach for SLAM in Large-Scale Indoor and Outdoor Areas
Key Words: image registration  iterative methods  mobile robots  navigation  robot vision  SLAM (robots)  link-points  multiple indoor areas  outdoor areas  map quality  single map approaches  semantic map management approach  multiple maps  modular map structure  utilized SLAM method  laser scan data  appropriate SLAM configuration  single independent maps  appearance-based method  iterative closest point registration  point clouds  simultaneous localization and mapping configurations  Simultaneous localization and mapping  Lasers  Navigation  Feature extraction  Three-dimensional displays 
Abstract: This work presents a semantic map management approach for various environments by triggering multiple maps with different simultaneous localization and mapping (SLAM) configurations. A modular map structure allows to add, modify or delete maps without influencing other maps of different areas. The hierarchy level of our algorithm is above the utilized SLAM method. Evaluating laser scan data (e.g. the detection of passing a doorway) triggers a new map, automatically choosing the appropriate SLAM configuration from a manually predefined list. Single independent maps are connected by link-points, which are located in an overlapping zone of both maps, enabling global navigation over several maps. Loop- closures between maps are detected by an appearance-based method, using feature matching and iterative closest point (ICP) registration between point clouds. Based on the arrangement of maps and link-points, a topological graph is extracted for navigation purpose and tracking the global robot's position over several maps. Our approach is evaluated by mapping a university campus with multiple indoor and outdoor areas and abstracting a metrical-topological graph. It is compared to a single map running with different SLAM configurations. Our approach enhances the overall map quality compared to the single map approaches by automatically choosing predefined SLAM configurations for different environmental setups.


Title: A Hierarchical Framework for Collaborative Probabilistic Semantic Mapping
Key Words: Bayes methods  expectation-maximisation algorithm  geometry  mobile robots  multi-robot systems  robot vision  single robot semantic mapping  collaborative geometry mapping  semantic point cloud  heterogeneous sensor fusion model  collaborative robots level  3D semantic map fusion algorithm  hierarchical collaborative probabilistic semantic mapping framework  Bayesian rule  probability  expectation-maximization  mathematical modeling  Semantics  Collaboration  Three-dimensional displays  Robot sensing systems  Geometry  Robot kinematics 
Abstract: Performing collaborative semantic mapping is a critical challenge for cooperative robots to maintain a comprehensive contextual understanding of the surroundings. Most of the existing work either focus on single robot semantic mapping or collaborative geometry mapping. In this paper, a novel hierarchical collaborative probabilistic semantic mapping framework is proposed, where the problem is formulated in a distributed setting. The key novelty of this work is the mathematical modeling of the overall collaborative semantic mapping problem and the derivation of its probability decomposition. In the single robot level, the semantic point cloud is obtained based on heterogeneous sensor fusion model and is used to generate local semantic maps. Since the voxel correspondence is unknown in collaborative robots level, an Expectation-Maximization approach is proposed to estimate the hidden data association, where Bayesian rule is applied to perform semantic and occupancy probability update. The experimental results show the high quality global semantic map, demonstrating the accuracy and utility of 3D semantic map fusion algorithm in real missions.


Title: Resolving Marker Pose Ambiguity by Robust Rotation Averaging with Clique Constraints*
Key Words: computer vision  object detection  optimisation  path planning  pose estimation  robot vision  SLAM (robots)  lifted algorithm  combinatorial complexity  heuristic criterion  planar pose estimation  marker-based mapping  highly ambiguous inputs  PPE ambiguities  possible marker orientation solutions  rotation averaging formulation  marker corners  computer vision  planar markers  clique constraints  robust rotation averaging  marker pose ambiguity  Cameras  Pipelines  Machine-to-machine communications  Image edge detection  Pose estimation  Simultaneous localization and mapping  Histograms 
Abstract: Planar markers are useful in robotics and computer vision for mapping and localisation. Given a detected marker in an image, a frequent task is to estimate the 6DOF pose of the marker relative to the camera, which is an instance of planar pose estimation (PPE). Although there are mature techniques, PPE suffers from a fundamental ambiguity problem, in that there can be more than one plausible pose solutions for a PPE instance. Especially when localisation of the marker corners is noisy, it is often difficult to disambiguate the pose solutions based on reprojection error alone. Previous methods choose between the possible solutions using a heuristic criterion, or simply ignore ambiguous markers.We propose to resolve the ambiguities by examining the consistencies of a set of markers across multiple views. Our specific contributions include a novel rotation averaging formulation that incorporates long-range dependencies between possible marker orientation solutions that arise from PPE ambiguities. We analyse the combinatorial complexity of the problem, and develop a novel lifted algorithm to effectively resolve marker pose ambiguities, without discarding any marker observations. Results on real and synthetic data show that our method is able to handle highly ambiguous inputs, and provides more accurate and/or complete marker-based mapping and localisation.


Title: Look, Listen, and Act: Towards Audio-Visual Embodied Navigation
Key Words: acoustic signal processing  audio signal processing  audio-visual systems  human computer interaction  mobile agents  navigation  path planning  audio-visual embodied navigation  mobile intelligent agents  multiple sensory inputs  sound source  indoor environment  raw egocentric visual data  audio sensory data  audio signal  visual environment  visual pieces  audio pieces  visual perception mapper module  sound perception module  audio-visual observations  simulated multimodal environment  visual-audio-room dataset  Navigation  Visualization  Task analysis  Robot sensing systems  Visual perception  Acoustics  Feature extraction 
Abstract: A crucial ability of mobile intelligent agents is to integrate the evidence from multiple sensory inputs in an environment and to make a sequence of actions to reach their goals. In this paper, we attempt to approach the problem of Audio-Visual Embodied Navigation, the task of planning the shortest path from a random starting location in a scene to the sound source in an indoor environment, given only raw egocentric visual and audio sensory data. To accomplish this task, the agent is required to learn from various modalities, i.e., relating the audio signal to the visual environment. Here we describe an approach to audio-visual embodied navigation that takes advantage of both visual and audio pieces of evidence. Our solution is based on three key ideas: a visual perception mapper module that constructs its spatial memory of the environment, a sound perception module that infers the relative location of the sound source from the agent, and a dynamic path planner that plans a sequence of actions based on the audio-visual observations and the spatial memory of the environment to navigate toward the goal. Experimental results on a newly collected Visual-Audio-Room dataset using the simulated multi-modal environment demonstrate the effectiveness of our approach over several competitive baselines.


Title: Training-Set Distillation for Real-Time UAV Object Tracking
Key Words: autonomous aerial vehicles  correlation methods  image filtering  image motion analysis  minimisation  mobile robots  object detection  object tracking  robot vision  training-set distillation  UAV object tracking  correlation filter  visual object tracking  unmanned aerial vehicle  energy minimization function  scoring process  time slot-based distillation approach  Training  Unmanned aerial vehicles  Correlation  Reliability  Real-time systems  Optimization  Visualization 
Abstract: Correlation filter (CF) has recently exhibited promising performance in visual object tracking for unmanned aerial vehicle (UAV). Such online learning method heavily depends on the quality of the training-set, yet complicated aerial scenarios like occlusion or out of view can reduce its reliability. In this work, a novel time slot-based distillation approach is proposed to efficiently and effectively optimize the training-set's quality on the fly. A cooperative energy minimization function is established to score the historical samples adaptively. To accelerate the scoring process, frames with high confident tracking results are employed as the keyframes to divide the tracking process into multiple time slots. After the establishment of a new slot, the weighted fusion of the previous samples generates one key-sample, in order to reduce the number of samples to be scored. Besides, when the current time slot exceeds the maximum frame number, which can be scored, the sample with the lowest score will be discarded. Consequently, the training-set can be efficiently and reliably distilled. Comprehensive tests on two well-known UAV benchmarks prove the effectiveness of our method with real-time speed on single CPU.


Title: CNN-Based Simultaneous Dehazing and Depth Estimation
Key Words: computer vision  convolutional neural nets  correlation methods  image coding  image colour analysis  image denoising  image representation  image sensors  learning (artificial intelligence)  spatial variables measurement  single hazy RGB input  single dense encoder  encoded image representation  dehazing image depth estimation  single image depth estimation  image dehazing  computer vision  convolutional neural networks  CNN  dehazing depth estimation algorithms  traditional haze modeling  depth estimation network  fully scaled depth map  depth-transmission consistency loss  separate decoders  Decoding  Propagation losses  Estimation  Training  Image reconstruction  Task analysis  Scattering 
Abstract: It is difficult for both cameras and depth sensors to obtain reliable information in hazy scenes. Therefore, image dehazing is still one of the most challenging problems to solve in computer vision and robotics. With the development of convolutional neural networks (CNNs), lots of dehazing and depth estimation algorithms using CNNs have emerged. However, very few of those try to solve these two problems at the same time. Focusing on the fact that traditional haze modeling contains depth information in its formula, we propose a CNN-based simultaneous dehazing and depth estimation network. Our network aims to estimate both a dehazed image and a fully scaled depth map from a single hazy RGB input with end-to-end training. The network contains a single dense encoder and four separate decoders; each of them shares the encoded image representation while performing individual tasks. We suggest a novel depth-transmission consistency loss in the training scheme to fully utilize the correlation between the depth information and transmission map. To demonstrate the robustness and effectiveness of our algorithm, we performed various ablation studies and compared our results to those of state-of-the-art algorithms in dehazing and single image depth estimation, both qualitatively and quantitatively. Furthermore, we show the generality of our network by applying it to some real-world examples.


Title: Internet of Things (IoT)-based Collaborative Control of a Redundant Manipulator for Teleoperated Minimally Invasive Surgeries
Key Words: control engineering computing  end effectors  human-robot interaction  Internet of Things  medical robotics  motion control  phantoms  redundant manipulators  surgery  telerobotics  Things-based collaborative control  teleoperated Minimally Invasive surgeries  Robot-assisted Minimally Invasive Surgery scenario  hierarchical operational space formulation  7-DoFs redundant manipulator  multiple operational tasks  motion constraint  collision avoidance  undergoing surgical operation  Internet of Robotic Things  human-robot interaction  compliant swivel motion  HTC VIVE PRO controllers  robot elbow  smooth swivel motion  KUKA LWR4+ slave robot  SIGMA 7 master manipulator  Internet of Things-based human-robot collaborative control scheme  priority levels  Collision avoidance  Manipulators  Surgery  Task analysis  Force  Tools 
Abstract: In this paper, an Internet of Things-based human-robot collaborative control scheme is developed in Robot-assisted Minimally Invasive Surgery scenario. A hierarchical operational space formulation is designed to exploit the redundancies of the 7-DoFs redundant manipulator to handle multiple operational tasks based on their priority levels, such as guaranteeing a remote center of motion constraint and avoiding collision with a swivel motion without influencing the undergoing surgical operation. Furthermore, the concept of the Internet of Robotic Things is exploited to facilitate the best action of the robot in human-robot interaction. Instead of utilizing compliant swivel motion, HTC VIVE PRO controllers, used as the Internet of Things technology, is adopted to detect the collision. A virtual force is applied to the robot elbow, enabling a smooth swivel motion for human-robot interaction. The effectiveness of the proposed strategy is validated using experiments performed on a patient phantom in a lab setup environment, with a KUKA LWR4+ slave robot and a SIGMA 7 master manipulator. By comparison with previous works, the results show improved performances in terms of the accuracy of the RCM constraint and surgical tip.


Title: Multi-Robot Path Deconfliction through Prioritization by Path Prospects
Key Words: mobile robots  multi-robot systems  path planning  path prospects  prioritization rule  heterogeneous robot teams  multirobot path deconfliction  conflict-free path planning  mobile robots  conflict-free path plans  prioritization heuristics  Robot kinematics  Collision avoidance  Planning  Trajectory  Heuristic algorithms  Couplings 
Abstract: This work deals with the problem of planning conflict-free paths for mobile robots in cluttered environments. Since centralized, coupled planning algorithms are computationally intractable for large numbers of robots, we consider decoupled planning, in which robots plan their paths sequentially in order of priority. Choosing how to prioritize the robots is a key consideration. State-of-the-art prioritization heuristics, however, do not model the coupling between a robot's mobility and its environment. This is particularly relevant when prioritizing between robots with different degrees of mobility. In this paper, we propose a prioritization rule that can be computed online by each robot independently, and that provides consistent, conflict-free path plans. Our innovation is to formalize a robot's path prospects to reach its goal from its current location. To this end, we consider the number of homology classes of trajectories, which capture distinct prospects of paths for each robot. This measure is used as a prioritization rule, whenever any robots enter negotiation to deconflict path plans. We perform simulations with heterogeneous robot teams and compare our method to five benchmarks. Our method achieves the highest success rate, and strikes a good balance between makespan and flowtime objectives.


Title: A Connectivity-Prediction Algorithm and its Application in Active Cooperative Localization for Multi-Robot Systems
Key Words: Markov processes  mobile robots  motion control  multi-robot systems  path planning  probability  infinite power series expansion theorem  finite-term approximation  computational feasibility  adverse impacts  higher order series terms  active CL  leader-follower architecture  Markov decision process  one-step planning horizon  optimal motion strategy  MDP model  connectivity-prediction algorithm  multirobot systems  future connectivity  mobile robots  range-limited communication  active motion planning  quadratic forms  random normal variables  Prediction algorithms  Robot sensing systems  Planning  Uncertainty  Computational modeling  Gaussian distribution 
Abstract: This paper presents a method for predicting the probability of future connectivity between mobile robots with range-limited communication. In particular, we focus on its application to active motion planning for cooperative localization (CL). The probability of connection is modeled by the distribution of quadratic forms in random normal variables and is computed by the infinite power series expansion theorem. A finite-term approximation is made to realize the computational feasibility and three more modifications are designed to handle the adverse impacts introduced by the omission of the higher order series terms. On the basis of this algorithm, an active and CL problem with leader-follower architecture is then reformulated into a Markov Decision Process (MDP) with a one-step planning horizon, and the optimal motion strategy is generated by minimizing the expected cost of the MDP. Extensive simulations and comparisons are presented to show the effectiveness and efficiency of both the proposed prediction algorithm and the MDP model.


Title: Behavior Mixing with Minimum Global and Subgroup Connectivity Maintenance for Large-Scale Multi-Robot Systems
Key Words: collision avoidance  distributed algorithms  mobile robots  multi-robot systems  trees (mathematics)  large-scale multirobot systems  robot team  connected communication graph  minimum inter-robot connectivity constraints  activated connectivity constraints  behavior mixing controllers  distributed minimum connectivity constraint spanning tree algorithm  provably minimum connectivity maintenance  subgroup connectivity maintenance  minimum global connectivity maintenance  collision avoidance  distributed MCCST algorithm  Collision avoidance  Robot kinematics  Task analysis  Safety  Multi-robot systems  Real-time systems 
Abstract: In many cases the multi-robot systems are desired to execute simultaneously multiple behaviors with different controllers, and sequences of behaviors in real time, which we call behavior mixing. Behavior mixing is accomplished when different subgroups of the overall robot team change their controllers to collectively achieve given tasks while maintaining connectivity within and across subgroups in one connected communication graph. In this paper, we present a provably minimum connectivity maintenance framework to ensure the subgroups and overall robot team stay connected at all times while providing the highest freedom for behavior mixing. In particular, we propose a real-time distributed Minimum Connectivity Constraint Spanning Tree (MCCST) algorithm to select the minimum inter-robot connectivity constraints preserving subgroup and global connectivity that are least likely to be violated by the original controllers. With the employed safety and connectivity barrier certificates for the activated connectivity constraints and collision avoidance, the behavior mixing controllers are thus minimally modified from the original controllers. We demonstrate the effectiveness and scalability of our approach via simulations of up to 100 robots with multiple behaviors.


Title: Energy-Optimal Cooperative Manipulation via Provable Internal-Force Regulation
Key Words: cooperative systems  decentralised control  force control  manipulator dynamics  mobile robots  multi-robot systems  position control  internal-force regulation  optimal cooperative robotic manipulation problem  energy resources  rigid cooperative manipulation systems  rigid grasping contacts  energy-optimal conditions  arising internal forces  inter-agent forces  closed form expression  standard inverse dynamics  force distribution  robotic agents  nonzero inter-agent internal force vector  internal force minimization  Grasping  Force  Robots  Dynamics  Acceleration  Jacobian matrices  Task analysis 
Abstract: This paper considers the optimal cooperative robotic manipulation problem in terms of energy resources. In particular, we consider rigid cooperative manipulation systems, i.e., with rigid grasping contacts, and study energy-optimal conditions in the sense of minimization of the arising internal forces, which are inter-agent forces that do not contribute to object motion. Firstly, we use recent results to derive a closed form expression for the internal forces. Secondly, by using a standard inverse dynamics control protocol, we provide novel conditions on the force distribution to the robotic agents for provable internal force minimization. Moreover, we derive novel results on the provable achievement of a desired non-zero inter-agent internal force vector. Extensive simulation results in a realistic environment verify the theoretical analysis.


Title: A Set-Theoretic Approach to Multi-Task Execution and Prioritization
Key Words: optimisation  redundant manipulators  safety-critical software  set theory  task analysis  time-varying systems  constrained optimization problem  redundant robotic manipulator  set theoretic approach  multitask execution  safety critical tasks  robotic system  optimization based task execution  set based tasks  time varying priorities  multitask prioritization  control barrier functions  Task analysis  Robot kinematics  Jacobian matrices  Aerospace electronics  Manipulators  Safety 
Abstract: Executing multiple tasks concurrently is important in many robotic applications. Moreover, the prioritization of tasks is essential in applications where safety-critical tasks need to precede application-related objectives, in order to protect both the robot from its surroundings and vice versa. Furthermore, the possibility of switching the priority of tasks during their execution gives the robotic system the flexibility of changing its objectives over time. In this paper, we present an optimization-based task execution and prioritization framework that lends itself to the case of time-varying priorities as well as variable number of tasks. We introduce the concept of extended set-based tasks, encode them using control barrier functions, and execute them by means of a constrained-optimization problem, which can be efficiently solved in an online fashion. Finally, we show the application of the proposed approach to the case of a redundant robotic manipulator.


Title: MagicHand: Context-Aware Dexterous Grasping Using an Anthropomorphic Robotic Hand
Key Words: dexterous manipulators  infrared spectra  object detection  robot vision  target object  grasping poses  grasp strategies  MagicHand system  context-aware dexterous grasping  robotic grasping  context-aware anthropomorphic robotic hand grasping system  NIR spectra  molecular level  RGB-D images  Grasping  Three-dimensional displays  Neurons  Cameras  Robot vision systems  Dexterous Grasping  Characteristics of Objects Recognition  NIR Spectrum  RGB-D Images 
Abstract: Understanding of characteristics of objects such as fragility, rigidity, texture and dimensions facilitates and innovates robotic grasping. In this paper, we propose a context- aware anthropomorphic robotic hand (MagicHand) grasping system which is able to gather various information about its target object and generate grasping strategies based on the perceived information. In this work, NIR spectra of target objects are perceived to recognize materials on a molecular level and RGB-D images are collected to estimate dimensions of the objects. We selected six most used grasping poses and our system is able to decide the most suitable grasp strategies based on the characteristics of an object. Through multiple experiments, the performance of the MagicHand system is demonstrated.


Title: Robust and Accurate 3D Curve to Surface Registration with Tangent and Normal Vectors
Key Words: biomechanics  image reconstruction  image registration  medical image processing  surgery  image-guided surgery  pre-to-intraoperative registration  intra-operative 3D data  tangent vectors  sparse intraoperative data points  pre-operative model points  probabilistic distribution  multidimensional point  maximum likelihood problem  rigid registration  intraoperative point  mean target registration error value  size 0.6795 mm  Three-dimensional displays  Surgery  Robustness  Probes  Probabilistic logic  Robots  Biomedical imaging 
Abstract: This paper presents a robust and accurate approach for the rigid registration of pre-operative and intraoperative point sets in image-guided surgery (IGS). Three challenges are identified in the pre-to-intraoperative registration: the intra-operative 3D data (usually forms a 3D curve in space) (1) is often contaminated with noise and outliers; (2) usually only covers a partial region of the whole pre-operative model; (3) is usually sparse. To tackle those challenges, we utilize the tangent vectors extracted from the sparse intraoperative data points and the normal vectors extracted from the pre-operative model points. Our first contribution is to formulate a novel probabilistic distribution of the error between a pair of corresponding tangent and normal vectors. The second contribution is, based on the novel distribution, we formulate the registration of two multi-dimensional (6D) point sets as a maximum likelihood (ML) problem and solve it under the expectation maximization (EM) framework. Our last contribution is, in order to facilitate the computation process, the derivatives of the objective function with respect to desired parameters are presented. We conduct extensive experiments to demonstrate that our approach outperforms the state-of-the-art methods. Importantly, in the context of anteriro cruciate ligament (ACL) reconstruction, our method can achieve as low as 0.6795 mm mean target registration error (TRE) value with considerable noises and very limited overlapping ratios.


Title: A Shape Memory Polymer Adhesive Gripper For Pick-and-Place Applications
Key Words: adhesion  adhesives  control system synthesis  grippers  manipulators  polymers  shape memory effects  shape memory polymer adhesive gripper  smart adhesive applications  pick-and-place applications  reversible dry adhesion  gecko grippers  high adhesion strength  SMP adhesive mechanics  reversible dry adhesive properties  single surface contact grippers  SMP adhesive gripper  Switched mode power supplies  Grippers  Adhesives  Heating systems  Shape  Rough surfaces  Surface roughness 
Abstract: Over the past few years, shape memory polymer (SMP) has been extensively studied in terms of its remarkable reversible dry adhesive properties and related smart adhesive applications. However, its exceptional properties have not been exploited for further opportunities such as pick-and-place applications, which would otherwise advance the robotic manipulation. This work explores the use of an SMP to design an adhesive gripper that picks and places a target solid object employing the reversible dry adhesion of an SMP. Compared with other single surface contact grippers including vacuum, electromagnetic, electroadhesion, and gecko grippers, the SMP adhesive gripper interacts with not only flat and smooth dry surfaces but also moderately rough and even wet surfaces for pick-and-place with high adhesion strength (> 2 atmospheres). In this work, associated physical mechanisms, SMP adhesive mechanics, and thermal conditions are studied. In particular, the numerical and experimental study elucidates that the optimal compositional and topological SMP design may substantially enhance its adhesion strength and reversibility, which leads to a strong grip force simultaneously with a minimized releasing force. Finally, the versatility and utility of the SMP adhesive gripper are highlighted through diverse pick-and-place demonstrations.


Title: Multi-person Pose Tracking using Sequential Monte Carlo with Probabilistic Neural Pose Predictor
Key Words: image matching  Monte Carlo methods  neural nets  pose estimation  probability  multiperson pose tracking  sequential Monte Carlo  probabilistic neural pose predictor  uncertainty-aware modeling  critical tracking errors  tracking scheme  multiple predictions  prediction errors  proposal distribution  epistemic uncertainty  heteroscedastic aleatoric uncertainty  neural modeling  MOTA score  PoseTrack2018 validation dataset  pose matching  time-sequence information  Uncertainty  Probabilistic logic  Adaptive optics  Optical imaging  Pose estimation  Optical sensors  Predictive models 
Abstract: It is an effective strategy for the multi-person pose tracking task in videos to employ prediction and pose matching in a frame-by-frame manner. For this type of approach, uncertainty-aware modeling is essential because precise prediction is impossible. However, previous studies have relied on only a single prediction without incorporating uncertainty, which can cause critical tracking errors if the prediction is unreliable. This paper proposes an extension to this approach with Sequential Monte Carlo (SMC). This naturally reformulates the tracking scheme to handle multiple predictions (or hypotheses) of poses, thereby mitigating the negative effect of prediction errors. An important component of SMC, i.e., a proposal distribution, is designed as a probabilistic neural pose predictor, which can propose diverse and plausible hypotheses by incorporating epistemic uncertainty and heteroscedastic aleatoric uncertainty. In addition, a recurrent architecture is introduced to our neural modeling to utilize time-sequence information of poses to manage difficult situations, such as the frequent disappearance and reappearances of poses. Compared to existing baselines, the proposed method achieves a state-of-the-art MOTA score on the PoseTrack2018 validation dataset by reducing approximately 50% of tracking errors from a state-of-the art baseline method.


Title: Simultaneous Tracking and Elasticity Parameter Estimation of Deformable Objects
Key Words: deformation  finite element analysis  image colour analysis  manipulators  parameter estimation  robot vision  visual information  simulated object  elasticity parameter estimation  tracked object  soft objects  deformable object  simultaneous tracking  interactive finite element method simulations  RGB-D sensor  robotic manipulation  Strain  Elasticity  Estimation  Deformable models  Force measurement  Force  Force sensors 
Abstract: In this paper, we propose a novel method to simultaneously track the deformation of soft objects and estimate their elasticity parameters. The tracking of the deformable object is performed by combining the visual information captured by a RGB-D sensor with interactive Finite Element Method simulations of the object. The visual information is more particularly used to distort the simulated object. In parallel, the elasticity parameter estimation minimizes the error between the tracked object and a simulated object deformed by the forces that are measured using a force sensor. Once the elasticity parameters are estimated, our tracking algorithm can be used to estimate the deformation forces applied to an object without the use of a force sensor. We validated our method on several soft objects with different shape complexities. Our evaluations show the ability of our method to estimate the elasticity parameters as well as its use to estimate the forces applied to a deformable object without any force sensor. These results open novel perspectives to better track and control deformable objects during robotic manipulations.


Title: AVOT: Audio-Visual Object Tracking of Multiple Objects for Robotics
Key Words: audio signal processing  audio-visual systems  learning (artificial intelligence)  object detection  object tracking  robot vision  tracking  multiple objects  visually based trackers  object collisions  audio-visual object tracking neural network  tracking error  AVOT end  audio-visual inputs  visually based object detection  tracking methods  OpenCV object tracking implementations  deep learning method  audio-visual dataset  single-modality deep learning methods  audio onset  multimodal object tracking  state-of-the-art object tracking  Object tracking  Object detection  Visualization  Neural networks  Machine learning  Feature extraction  Streaming media 
Abstract: Existing state-of-the-art object tracking can run into challenges when objects collide, occlude, or come close to one another. These visually based trackers may also fail to differentiate between objects with the same appearance but different materials. Existing methods may stop tracking or incorrectly start tracking another object. These failures are uneasy for trackers to recover from since they often use results from previous frames. By using audio of the impact sounds from object collisions, rolling, etc., our audio-visual object tracking (AVOT) neural network can reduce tracking error and drift. We train AVOT end to end and use audio-visual inputs over all frames. Our audio-based technique may be used in conjunction with other neural networks to augment visually based object detection and tracking methods. We evaluate its runtime frames-per-second (FPS) performance and intersection over union (IoU) performance against OpenCV object tracking implementations and a deep learning method. Our experiments, using the synthetic Sound-20K audio-visual dataset, demonstrate that AVOT outperforms single-modality deep learning methods, when there is audio from object collisions. A proposed scheduler network to switch between AVOT and other methods based on audio onset maximizes accuracy and performance over all frames in multimodal object tracking.


Title: Designing Ferromagnetic Soft Robots (FerroSoRo) with Level-Set-Based Multiphysics Topology Optimization
Key Words: actuators  deformation  design engineering  elastomers  grippers  optimisation  sensitivity analysis  topology  shape sensitivity analysis  gripper  flytrap structure  material layout  innovative structures  bionic medical devices  compliant actuators  level-set-based multiphysics topology optimization method  adjoint variable method  material time derivative  sub-objective function  architect ferromagnetic soft active structures  design domain  structural topology optimization  ferromagnetic soft elastomers  external magnetic field  shift morphology  soft elastomer matrix  ferromagnetic particles  flexible electronics  soft machines  external environmental stimulus  change configurations  flexible locomotion  soft active materials  FerroSoRo  designing ferromagnetic soft robots  Soft magnetic materials  Optimization  Topology  Magnetic domains  Magnetoacoustic effects  Level set  Shape 
Abstract: Soft active materials can generate flexible locomotion and change configurations through large deformations when subjected to an external environmental stimulus. They can be engineered to design 'soft machines' such as soft robots, compliant actuators, flexible electronics, or bionic medical devices. By embedding ferromagnetic particles into soft elastomer matrix, the ferromagnetic soft matter can generate flexible movement and shift morphology in response to the external magnetic field. By taking advantage of this physical property, soft active structures undergoing desired motions can be generated by tailoring the layouts of the ferromagnetic soft elastomers. Structural topology optimization has emerged as an attractive tool to achieve innovative structures by optimizing the material layout within a design domain, and it can be utilized to architect ferromagnetic soft active structures. In this paper, the level-set-based topology optimization method is employed to design ferromagnetic soft robots (FerroSoRo). The objective function comprises a sub-objective function for the kinematics requirement and a sub-objective function for minimum compliance. Shape sensitivity analysis is derived using the material time derivative and adjoint variable method. Three examples, including a gripper, an actuator, and a flytrap structure, are studied to demonstrate the effectiveness of the proposed framework.


Title: Exoskeleton-covered soft finger with vision-based proprioception and tactile sensing
Key Words: actuators  convolutional neural nets  dexterous manipulators  grippers  intelligent sensors  learning (artificial intelligence)  mobile robots  robot vision  tactile sensors  high-resolution proprioceptive sensing  rich tactile sensing  highly underactuated exoskeleton  robotic gripper  tactile information  proprioception CNN  human finger proprioception  proprioceptive state  peripheral environment  vision-based proprioception  rigid-body robots  soft robots  accurate proprioception  elasticity  tactile sensor  previous GelSight sensing techniques  exoskeleton-covered soft finger  size 0.77 mm  Soft robotics  Cameras  Robot vision systems  Ink 
Abstract: Soft robots offer significant advantages in adaptability, safety, and dexterity compared to conventional rigid-body robots. However, it is challenging to equip soft robots with accurate proprioception and tactile sensing due to their high flexibility and elasticity. In this work, we describe the development of a vision-based proprioceptive and tactile sensor for soft robots called GelFlex, which is inspired by previous GelSight sensing techniques. More specifically, we develop a novel exoskeleton-covered soft finger with embedded cameras and deep learning methods that enable high-resolution proprioceptive sensing and rich tactile sensing. To do so, we design features along the axial direction of the finger, which enable high-resolution proprioceptive sensing, and incorporate a reflective ink coating on the surface of the finger to enable rich tactile sensing. We design a highly underactuated exoskeleton with a tendon-driven mechanism to actuate the finger. Finally, we assemble 2 of the fingers together to form a robotic gripper and successfully perform a bar stock classification task, which requires both shape and tactile information. We train neural networks for proprioception and shape (box versus cylinder) classification using data from the embedded sensors. The proprioception CNN had over 99% accuracy on our testing set (all six joint angles were within 1° of error) and had an average accumulative distance error of 0.77 mm during live testing, which is better than human finger proprioception. These proposed techniques offer soft robots the high-level ability to simultaneously perceive their proprioceptive state and peripheral environment, providing potential solutions for soft robots to solve everyday manipulation tasks. We believe the methods developed in this work can be widely applied to different designs and applications.


Title: Motion Intensity Extraction Scheme for Simultaneous Recognition of Wrist/Hand Motions
Key Words: electromyography  gesture recognition  medical signal processing  muscle  pattern classification  sEMG signals  motion intensity feature  grasping motions  motion intensity extraction scheme  surface electromyography  muscular information representing gestures  sEMG-based motion recognition methods  Muscles  Crosstalk  Feature extraction  Wrist  Pattern recognition  Microsoft Windows  Electrodes 
Abstract: Surface electromyography contains muscular information representing gestures and corresponding forces. However, conventional sEMG-based motion recognition methods, such as pattern classification and regression, have intrinsic limitations due to the complex characteristics of sEMG signals. In this paper, motion intensity, a highly selective sEMG feature proportional to the level of muscle contraction, is proposed. The motion intensity feature allows proportional and simultaneous recognition of multiple degrees of freedom. The proposed method was demonstrated in terms of simultaneous recognition of wrist/hand motions. The result shows that the proposed method can successfully decompose sEMG signals into highly selective signals to target motions. In future works, the proposed method will be adapted for more subjects and to sEMG applications for practical evaluation considering various grasping motions.


Title: Simultaneous Online Motion Discrimination and Evaluation of Whole-body Exercise by Synergy Probes for Home Rehabilitation
Key Words: biomechanics  image motion analysis  learning (artificial intelligence)  patient rehabilitation  synergy probe  whole-body exercise  simultaneous online motion discrimination  home rehabilitation sessions  reconstructed movement  online data  training data  Task analysis  Probes  Training data  Hidden Markov models  Torso  Real-time systems  Feature extraction 
Abstract: The development of algorithms for motion discrimination in home rehabilitation sessions poses numerous challenges. Recent studies have used the concept of synergies to discriminate a set of movements. However, the discrimination depends on the correlation of the reconstructed movement with the online data, and the training data requires well-defined movements. In this paper, we introduced the concept of a synergy probe, which makes a direct comparison between synergies and online data. The system represents synergies and movements in the same space and monitors their behavior. The results indicated that conventional methods are influenced by the segmentation of training data, and even though the reconstructed movement is similar to the ground-truth, it does not provide sufficient information to evaluate the data in real time. The synergy probes were used to discriminate and evaluate the performance of natural whole-body exercises without segmentation or previous determination of movements. An analysis of the results also demonstrated the possibility to identify the strategies used by the subjects for movement. Such information aids in gaining a better insight and can prove beneficial in home rehabilitation.


Title: Assistive Gym: A Physics Simulation Framework for Assistive Robotics
Key Words: human-robot interaction  learning (artificial intelligence)  manipulators  medical robotics  mobile robots  robot programming  service robots  physics simulation framework  autonomous robots  physical interaction  physics simulations  physical assistance  open source physics  assistive robots  simulated environments  robotic manipulator  assistive gym models  commercial robots  assistive robotics research  ADL  activities of daily living  Task analysis  Manipulators  Physics  Tools  Human-robot interaction  Mobile robots 
Abstract: Autonomous robots have the potential to serve as versatile caregivers that improve quality of life for millions of people worldwide. Yet, conducting research in this area presents numerous challenges, including the risks of physical interaction between people and robots. Physics simulations have been used to optimize and train robots for physical assistance, but have typically focused on a single task. In this paper, we present Assistive Gym, an open source physics simulation framework for assistive robots that models multiple tasks. It includes six simulated environments in which a robotic manipulator can attempt to assist a person with activities of daily living (ADLs): itch scratching, drinking, feeding, body manipulation, dressing, and bathing. Assistive Gym models a person's physical capabilities and preferences for assistance, which are used to provide a reward function. We present baseline policies trained using reinforcement learning for four different commercial robots in the six environments. We demonstrate that modeling human motion results in better assistance and we compare the performance of different robots. Overall, we show that Assistive Gym is a promising tool for assistive robotics research.


Title: Learning Whole-Body Human-Robot Haptic Interaction in Social Contexts
Key Words: control engineering computing  force sensors  haptic interfaces  human-robot interaction  learning (artificial intelligence)  telerobotics  whole-body human-robot haptic interaction  learning-from-demonstration framework  human-robot social interactions  human-robot contact  LfD framework  teleoperated bimanual robot  force sensors  Robot sensing systems  Haptic interfaces  Force  Spatiotemporal phenomena  Training 
Abstract: This paper presents a learning-from-demonstration (LfD) framework for teaching human-robot social interactions that involve whole-body haptic interaction, i.e. direct human-robot contact over the full robot body. The performance of existing LfD frameworks suffers in such interactions due to the high dimensionality and spatiotemporal sparsity of the demonstration data. We show that by leveraging this sparsity, we can reduce the data dimensionality without incurring a significant accuracy penalty, and introduce three strategies for doing so. By combining these techniques with an LfD framework for learning multimodal human-robot interactions, we can model the spatiotemporal relationship between the tactile and kinesthetic information during whole-body haptic interactions. Using a teleoperated bimanual robot equipped with 61 force sensors, we experimentally demonstrate that a model trained with 121 sample hugs from 4 participants generalizes well to unseen inputs and human partners.


Title: MOCA-MAN: A MObile and reconfigurable Collaborative Robot Assistant for conjoined huMAN-robot actions
Key Words: gesture recognition  human-robot interaction  manipulators  medical robotics  mobile robots  multi-robot systems  mobile manipulators  supernumerary limbs  reconfiguration potential  MObile Collaborative robot Assistant  supernumerary body  MOCA-MAN  hand gesture recognition system  mobile base  long distance co-carrying tasks  manipulating tools  conjoined actions  performing heavy manipulation tasks  prolonged manipulation tasks  close-proximity manipulation  mobile robot assistant  reconfigurable collaborative robot assistant  conjoined huMAN-robot actions  collaborative robotic system  Admittance  Task analysis  Collaboration  Robot sensing systems  Clamps  Manipulators 
Abstract: The objective of this paper is to create a new collaborative robotic system that subsumes the advantages of mobile manipulators and supernumerary limbs. By exploiting the reconfiguration potential of a MObile Collaborative robot Assistant (MOCA), we create a collaborative robot that can function autonomously, in close proximity to humans, or be physically coupled to the human counterpart as a supernumerary body (MOCA-MAN). Through an admittance interface and a hand gesture recognition system, the controller can give higher priority to the mobile base (e.g., for long distance co-carrying tasks) or the arm movements (e.g., for manipulating tools), when performing conjoined actions. The resulting system has a high potential not only to reduce waste associated with the equipment waiting and setup times, but also to mitigate the human effort when performing heavy or prolonged manipulation tasks. The performance of the proposed system, i.e., MOCA-MAN, is evaluated by multiple subjects in two different use-case scenarios, which require large mobility or close-proximity manipulation.


Title: Closing the Force Loop to Enhance Transparency in Time-delayed Teleoperation
Key Words: delays  force control  human-robot interaction  stability  telerobotics  master-slave teleoperation system  bilateral controllers  force transparency  force loop  force control  time delayed teleoperation  KUKA lightweight robots  time domain passivity  Force  Iron  Force measurement  Robots  Stability analysis  Delays  Task analysis 
Abstract: In the present paper, we first adopt explicit force control from general robotics and embed it into teleoperation systems to enhance the transparency by reducing the effect of the perceived inertia to the human operator and simultaneously improve contact perception. To ensure stability of the proposed teleoperation system considering time-delays, we propose a sequential design procedure based on time domain passivity approach. Experimental results of master-slave teleoperation system, based on KUKA light-weight-robots, for different values of delays are presented. Comparative analysis is conducted considering two existing approaches, namely 2-channel and 4-channel architecture based bilateral controllers, and its results clearly indicate significant improvement in force transparency owing to the proposed method. The proposed system is finally validated considering a real industrial assembly scenario.


Title: Evaluation of an Exoskeleton-based Bimanual Teleoperation Architecture with Independently Passivated Slave Devices
Key Words: delays  motion control  stability  telerobotics  simulated time delay  control loop frequency  multiDoFs devices  TDPA  time domain passivity approach  exoskeletal master  bimanual teleoperation system  communication delay  bilateral teleoperation  haptic feedback  robotic platforms  rescue robotics  independently passivated slave devices  exoskeleton-based bimanual teleoperation architecture  Exoskeletons  Task analysis  Computer architecture  Stability analysis  Robots  Delays  Haptic interfaces 
Abstract: Search and rescue robotics is becoming a relevant topic in the last years and the growing number of robotic platforms and dedicated projects is the evidence of the interest in this area. In this context, the possibility to drive a remote robot with an exoskeleton is a promising strategy to enhance dexterity, reduce operator effort and save time. However, the use of haptic feedback (bilateral teleoperation) may lead to instability in the presence of communication delay and more complex is the case of bimanual teleoperation where the two arms can exchange energy. In this work, we present a bimanual teleoperation system based on an exoskeletal master, where multi-degrees of freedom (multi-DoFs) and kinematically different devices are involved. In the implemented architecture the two slaves are managed in parallel and independently passivated using the Time Domain Passivity Approach (TDPA) extended for multi-DoFs devices. To investigate the stability of the architecture we designed two tasks highly related to real disaster scenarios: the first one was useful to verify the system behavior in case of small movements and constrained configurations, whereas the second experiment was designed to involve larger contact forces and movements. Moreover, we compared the effect of both delay and low control loop frequency on the stability of the system when TDPA was applied. From the results, it was evident that the overall system exhibited a stable behavior with the use of the TDPA, even passivating the two slaves independently, under simulated time delay and in presence of a low control loop frequency.


Title: Toward Human-like Teleoperated Robot Motion: Performance and Perception of a Choreography-inspired Method in Static and Dynamic Tasks for Rapid Pose Selection of Articulated Robots
Key Words: control engineering computing  human-robot interaction  mobile robots  service robots  telerobotics  virtual reality  remotely-operated robot  remote telepresence  Baxter robot  Xbox One controller  JBJ  limb  multiple joints  successfully completed tasks  joint-by-joint method  choreography-inspired method  performance data  static tasks  RCC method  dynamic tasks  human-likeness  robotic motion  teleoperated robot motion  rapid pose selection  articulated robots  robot choreography center  Task analysis  Training  Dynamics  Joints  Robot motion  Manipulators 
Abstract: In some applications, operators may want to create fluid, human-like motion on a remotely-operated robot, for example, a device used for remote telepresence. This paper examines two methods of controlling the pose of a Baxter robot via an Xbox One controller. The first method is a joint- by-joint (JBJ) method in which one joint of each limb is specified in sequence. The second method of control, named Robot Choreography Center (RCC), utilizes choreographic abstractions in order to simultaneously move multiple joints of the limb of the robot in a predictable manner. Thirty-eight users were asked to perform four tasks with each method. Success rate and duration of successfully completed tasks were used to analyze the performances of the participants. Analysis of the preferences of the users found that the joint-by-joint (JBJ) method was considered to be more precise, easier to use, safer, and more articulate, while the choreography-inspired (RCC) method of control was perceived as faster, more fluid, and more expressive. Moreover, performance data found that while both methods of control were over 80% successful for the two static tasks, the RCC method was an average of 11.85% more successful for the two more difficult, dynamic tasks. Future work will leverage this framework to investigate ideas of fluidity, expressivity, and human-likeness in robotic motion through online user studies with larger participant pools.


Title: Helping Robots Learn: A Human-Robot Master-Apprentice Model Using Demonstrations via Virtual Reality Teleoperation
Key Words: control engineering computing  human-robot interaction  learning (artificial intelligence)  multi-robot systems  robot programming  telerobotics  virtual reality  grasping task  human perception  human-robot master-apprentice model  virtual reality teleoperation  artificial intelligence  self-supervised learning  Robots  Grasping  Task analysis  Three-dimensional displays  Solid modeling  Virtual reality  Pipelines 
Abstract: As artificial intelligence becomes an increasingly prevalent method of enhancing robotic capabilities, it is important to consider effective ways to train these learning pipelines and to leverage human expertise. Working towards these goals, a master-apprentice model is presented and is evaluated during a grasping task for effectiveness and human perception. The apprenticeship model augments self-supervised learning with learning by demonstration, efficiently using the human's time and expertise while facilitating future scalability to supervision of multiple robots; the human provides demonstrations via virtual reality when the robot cannot complete the task autonomously. Experimental results indicate that the robot learns a grasping task with the apprenticeship model faster than with a solely self-supervised approach and with fewer human interventions than a solely demonstration-based approach; 100% grasping success is obtained after 150 grasps with 19 demonstrations. Preliminary user studies evaluating workload, usability, and effectiveness of the system yield promising results for system scalability and deployability. They also suggest a tendency for users to overestimate the robot's skill and to generalize its capabilities, especially as learning improves.


Title: Maneuver at Micro Scale: Steering by Actuation Frequency Control in Micro Bristle Robots*
Key Words: microactuators  microrobots  piezoelectric actuators  steering systems  vibrations  resonance-based steering mechanism  differential steering  on-board piezoelectric actuator  frequency-controlled locomotion  steering mechanism  microbristle robots  actuation frequency control  principal actuation frequency components  size 6.0 mm  size 400.0 mum  size 12.0 mm  size 8.0 mm  Robots  Resonant frequency  Actuators  Vibrations  Steady-state  Wires  Mathematical model 
Abstract: This paper presents a novel steering mechanism, which leads to frequency-controlled locomotion demonstrated for the first time in micro bristle robots. The miniaturized robots are 3D-printed, 12 mm × 8 mm × 6 mm in size, with bristle feature sizes down to 400 μm. The robots can be steered by utilizing the distinct resonance behaviors of the asymmetrical bristle sets. The left and right sets of the bristles have different diameters, and thus different stiffnesses and resonant frequencies. The unique response of each bristle side to the vertical vibrations of a single on-board piezoelectric actuator causes differential steering of the robot. The robot can be modeled as two coupled uniform bristle robots, representing the left and the right sides. At distinct frequencies, the robots can move in all four principal directions: forward, backward, left and right. Furthermore, the full 360° 2D plane can be covered by superimposing the principal actuation frequency components with desired amplitudes. In addition to miniaturized robots, the presented resonance-based steering mechanism can be applied over multiple scales and to other mechanical systems.


Title: Scaling down an insect-size microrobot, HAMR-VI into HAMR-Jr
Key Words: gait analysis  legged locomotion  microrobots  motion control  insect-size microrobot  mechanically dexterous legged robot  HAMR-Jr's open-loop locomotion  HAMR-VI microrobot  design process  fabrication process  independently actuated degrees of freedom  mass 320.0 mg  frequency 1.0 Hz to 200.0 Hz  size 22.5 mm  Legged locomotion  Actuators  Resonant frequency  Heat-assisted magnetic recording  Fabrication  Robot sensing systems 
Abstract: Here we present HAMR-Jr, a 22.5mm, 320mg quadrupedal microrobot. With eight independently actuated degrees of freedom, HAMR-Jr is, to our knowledge, the most mechanically dexterous legged robot at its scale and is capable of high-speed locomotion (13.91bodylengthss-1) at a variety of stride frequencies (1-200Hz) using multiple gaits. We achieved this using a design and fabrication process that is flexible, allowing scaling with minimum changes to our workflow. We further characterized HAMR-Jr's open-loop locomotion and compared it with the larger scale HAMR-VI microrobot to demonstrate the effectiveness of scaling laws in predicting running performance.


Title: Reality as a simulation of reality: robot illusions, fundamental limits, and a physical demonstration
Key Words: collision avoidance  human-robot interaction  mobile robots  multi-robot systems  fundamental limits  physical demonstration  robot behavior  potential mismatches  convincing illusion  system simulation  simulated systems  simple multirobot experiment  robot navigating  robot illusions  Robot sensing systems  Software  Sensor systems  Mobile robots  Emulation 
Abstract: We consider problems in which robots conspire to present a view of the world that differs from reality. The inquiry is motivated by the problem of validating robot behavior physically despite there being a discrepancy between the robots we have at hand and those we wish to study, or the environment for testing that is available versus that which is desired, or other potential mismatches in this vein. After formulating the concept of a convincing illusion, essentially a notion of system simulation that takes place in the real world, we examine the implications of this type of simulability in terms of infrastructure requirements. Time is one important resource: some robots may be able to simulate some others but, perhaps, only at a rate that is slower than real-time. This difference gives a way of relating the simulating and the simulated systems in a form that is relative. We establish some theorems, including one with the flavor of an impossibility result, and providing several examples throughout. Finally, we present data from a simple multi-robot experiment based on this theory, with a robot navigating amid an unbounded field of obstacles."Truth is beautiful, without doubt; but so are lies."-Ralph Waldo Emerson.


Title: High-Flexibility Locomotion and Whole-Torso Control for a Wheel-Legged Robot on Challenging Terrain*
Key Words: mobile robots  motion control  robot kinematics  wheels  high-flexibility locomotion  whole-torso control  challenging terrain  six-wheel-legged robot  irregular terrain  heavy-duty work  Stewart platforms  wheels  diverse degrees  traversability  rough terrain  sand-gravel terrain  parallel suspension system  Legged locomotion  Wheels  Torso  Force  Kinematics 
Abstract: In this paper, we propose a parallel six-wheel-legged robot that can traverse irregular terrain while carrying objectives to do heavy-duty work. This robot is equipped with six Stewart platforms as legs and tightly integrates the additional degrees of freedom introduced by the wheels. The presented control strategy with physical system used to adapt the diverse degrees of each leg to irregular terrain such that robot increases the traversability, and simultaneously to maintain the horizontal whole-torso pose. This strategy makes use of Contact Scheduler (CS) and Whole-Torso Control (WTC) to control the multiple degrees of freedom (DOF) leg for performing high-flexibility locomotion and adapting the rough terrain like actively parallel suspension system. We conducted experiments on flat, slope, soft and sand-gravel surface, which validate the proposed control method and physical system. Especially, we attempt to traverse over sand-gravel terrain with 3 people about 240kg payload.


Title: Trajectory optimization for a class of robots belonging to Constrained Collaborative Mobile Agents (CCMA) family
Key Words: actuators  collision avoidance  end effectors  manipulator kinematics  mobile robots  multi-robot systems  optimisation  position control  constrained collaborative mobile agents family  ground mobile bases  mobile robots  closed-loop kinematic chains  revolute joints  closed- loop kinematic chains  standalone trajectory optimization method  CCMA system  fixed design parameters  control policy optimization  manipulation capabilities  tracked mobile bases  Kinematics  Mobile robots  Trajectory optimization  Mobile agents  Task analysis  Parallel Robots  Optimization and Optimal Control  Multi-Robot Systems 
Abstract: We present a novel class of robots belonging to Constrained Collaborative Mobile Agents (CCMA) family which consists of ground mobile bases with non-holonomic constraints. Moreover, these mobile robots are constrained by closed-loop kinematic chains consisting of revolute joints which can be either passive or actuated. We also describe a novel trajectory optimization method which is general with respect to number of mobile robots, topology of the closed- loop kinematic chains and placement of the actuators at the revolute joints. We also extend the standalone trajectory optimization method to optimize concurrently the design parameters and the control policy. We describe various CCMA system examples, in simulation, differing in design, topology, number of mobile robots and actuation space. The simulation results for standalone trajectory optimization with fixed design parameters is presented for CCMA system examples. We also show how this method can be used for tasks other than end-effector positioning such as internal collision avoidance and external obstacle avoidance. The concurrent design and control policy optimization is demonstrated, in simulations, to increase the CCMA system workspace and manipulation capabilities. Finally, the trajectory optimization method is validated in experiments through two 4-DOF prototypes consisting of 3 tracked mobile bases.


Title: Radar Sensors in Collaborative Robotics: Fast Simulation and Experimental Validation
Key Words: collision avoidance  CW radar  FM radar  frequency modulation  image sensors  learning (artificial intelligence)  mobile robots  object detection  radar computing  road vehicle radar  sensors  collaborative robotics  radar systems  robot systems  optimization  machine learning approaches  realistic simulation models  radar sensor simulations  relative velocities  Lambertian reflectance model  reflection estimates  frequency modulated continuous wave radar  simulation environments  Radar  Robot sensing systems  Radar antennas  Chirp  Computational modeling 
Abstract: With the availability of small system in package realizations, radar systems become more and more attractive for a variety of applications in robotics, in particular also for collaborative robotics. As the simulation of robot systems in realistic scenarios has become an important tool, not only for design and optimization, but also e.g. for machine learning approaches, realistic simulation models are needed. In the case of radar sensor simulations, this means providing more realistic results than simple proximity sensors, e.g. in the presence of multiple objects and/or humans, objects with different relative velocities and differentiation between background and foreground movement. Due to the short wavelength in the millimeter range, we propose to utilize methods known from computer graphics (e.g. z-buffer, Lambertian reflectance model) to quickly acquire depth images and reflection estimates. This information is used to calculate an estimate of the received signal for a Frequency Modulated Continuous Wave (FMCW) radar by superposition of the corresponding signal contributions. Due to the moderate computational complexity, the approach can be used with various simulation environments such as V-Rep or Gazebo. Validity and benefits of the approach are demonstrated by means of a comparison with experimental data obtained with a radar sensor on a UR10 arm in different scenarios.


Title: Transferable Task Execution from Pixels through Deep Planning Domain Learning
Key Words: learning systems  manipulators  neurocontrollers  robot vision  symbolic operators  manipulation tasks  transferable task execution  visual input  symbolic planning methods  partially-observable world  hierarchical model  high-level model  deep planning domain learning  symbolic world state  DPDL  STRIPS  logical predicates  low-level policy learning  photorealistic kitchen scenario  Task analysis  Planning  Robot sensing systems  Grounding  Robustness  Feature extraction 
Abstract: While robots can learn models to solve many manipulation tasks from raw visual input, they cannot usually use these models to solve new problems. On the other hand, symbolic planning methods such as STRIPS have long been able to solve new problems given only a domain definition and a symbolic goal, but these approaches often struggle on the real world robotic tasks due to the challenges of grounding these symbols from sensor data in a partially-observable world. We propose Deep Planning Domain Learning (DPDL), an approach that combines the strengths of both methods to learn a hierarchical model. DPDL learns a high-level model which predicts values for a large set of logical predicates consisting of the current symbolic world state, and separately learns a low-level policy which translates symbolic operators into executable actions on the robot. This allows us to perform complex, multistep tasks even when the robot has not been explicitly trained on them. We show our method on manipulation tasks in a photorealistic kitchen scenario.


Title: Visual Prediction of Priors for Articulated Object Interaction
Key Words: feature extraction  intelligent robots  mobile robots  object detection  visual servoing  exploratory behavior  visual features learning  contextual multiarmed bandit  parameterized action space  articulated object interaction  contextual prior prediction  Robots  Visualization  Training  Kinematics  Gaussian processes  Optimization  Kernel 
Abstract: Exploration in novel settings can be challenging without prior experience in similar domains. However, humans are able to build on prior experience quickly and efficiently. Children exhibit this behavior when playing with toys. For example, given a toy with a yellow and blue door, a child will explore with no clear objective, but once they have discovered how to open the yellow door, they will most likely be able to open the blue door much faster. Adults also exhibit this behaviour when entering new spaces such as kitchens. We develop a method, Contextual Prior Prediction, which provides a means of transferring knowledge between interactions in similar domains through vision. We develop agents that exhibit exploratory behavior with increasing efficiency, by learning visual features that are shared across environments, and how they correlate to actions. Our problem is formulated as a Contextual Multi-Armed Bandit where the contexts are images, and the robot has access to a parameterized action space. Given a novel object, the objective is to maximize reward with few interactions. A domain which strongly exhibits correlations between visual features and motion is kinemetically constrained mechanisms. We evaluate our method on simulated prismatic and revolute joints1.


Title: MT-DSSD: Deconvolutional Single Shot Detector Using Multi Task Learning for Object Detection, Segmentation, and Grasping Detection
Key Words: convolutional neural nets  image segmentation  learning (artificial intelligence)  manipulators  object detection  MT-DSSD  object detection  semantic object segmentation  grasping point detection  multitask learning  grasping operation  multitask deconvolutional single shot detector  robot manipulation  Amazon Robotics Challenge dataset  Grasping  Robots  Object detection  Semantics  Task analysis  Deconvolution  Feature extraction 
Abstract: This paper presents the multi-task Deconvolutional Single Shot Detector (MT-DSSD), which runs three tasks-object detection, semantic object segmentation, and grasping detection for a suction cup-in a single network based on the DSSD. Simultaneous execution of object detection and segmentation by multi-task learning improves the accuracy of these two tasks. Additionally, the model detects grasping points and performs the three recognition tasks necessary for robot manipulation. The proposed model can perform fast inference, which reduces the time required for grasping operation. Evaluations using the Amazon Robotics Challenge (ARC) dataset showed that our model has better object detection and segmentation performance than comparable methods, and robotic experiments for grasping show that our model can detect the appropriate grasping point.


Title: Using Synthetic Data and Deep Networks to Recognize Primitive Shapes for Object Grasping
Key Words: convolutional neural nets  dexterous manipulators  image segmentation  learning (artificial intelligence)  mobile robots  object recognition  path planning  robot vision  shape recognition  synthetic data  deep networks  primitive shape  object grasping  segmentation-based architecture  monocular depth input  backbone deep network  parametrized grasp families  shape primitive region  task-free grasping  shape primitives  task-relevant grasp prediction  ranking algorithm  task-free grasp prediction  Shape  Grasping  Image segmentation  Three-dimensional displays  Task analysis  Robot sensing systems 
Abstract: A segmentation-based architecture is proposed to decompose objects into multiple primitive shapes from monocular depth input for robotic manipulation. The backbone deep network is trained on synthetic data with 6 classes of primitive shapes generated by a simulation engine. Each primitive shape is designed with parametrized grasp families, permitting the pipeline to identify multiple grasp candidates per shape primitive region. The grasps are priority ordered via proposed ranking algorithm, with the first feasible one chosen for execution. On task-free grasping of individual objects, the method achieves a 94% success rate. On task-oriented grasping, it achieves a 76% success rate. Overall, the method supports the hypothesis that shape primitives can support task-free and task-relevant grasp prediction.


Title: A Generative Approach Towards Improved Robotic Detection of Marine Litter
Key Words: image classification  learning (artificial intelligence)  object detection  support vector machines  data scarcity problems  underwater image datasets  visual detection  marine debris  two-stage variational autoencoder  generated imagery  two-stage VAE  binary classifier  multiclass classifier  augmentation process  trash images  underwater trash classification problem  data-dependent task  quality images  Training  Image color analysis  Plastics  Gallium nitride  Task analysis  Shape  Decoding 
Abstract: This paper presents an approach to address data scarcity problems in underwater image datasets for visual detection of marine debris. The proposed approach relies on a two-stage variational autoencoder (VAE) and a binary classifier to evaluate the generated imagery for quality and realism. From the images generated by the two-stage VAE, the binary classifier selects "good quality" images and augments the given dataset with them. Lastly, a multi-class classifier is used to evaluate the impact of the augmentation process by measuring the accuracy of an object detector trained on combinations of real and generated trash images. Our results show that the classifier trained with the augmented data outperforms the one trained only with the real data. This approach will not only be valid for the underwater trash classification problem presented in this paper, but it will also be useful for any data-dependent task for which collecting more images is challenging or infeasible.


Title: Spatiotemporal Representation Learning with GAN Trained LSTM-LSTM Networks
Key Words: convolutional neural nets  learning (artificial intelligence)  learning systems  robots  unstructured environments  unsupervised representation learning architecture  underlying representation  high-dimensional raw video inputs  spatiotemporal representation learning  lower-dimensional latent space  two-stage learning approach  convolutional neural network  Long Short-Term Network  LSTM-LSTM cells  hierarchical representation learning  low-dimensional representation  video prediction task  GAN trained LSTM-LSTM networks  robot behavior learning  layered spatiotemporal memory long short-term memory  generative adversarial network  ConvNet  Spatiotemporal phenomena  Gallium nitride  Task analysis  Training  Generative adversarial networks  Robots  Feature extraction 
Abstract: Learning robot behaviors in unstructured environments often requires handcrafting the features for a given task. In this paper, we present and evaluate an unsupervised representation learning architecture, Layered Spatiotemporal Memory Long Short-Term Memory (LSTM-LSTM), that learns the underlying representation without knowledge of the task. The goal of this architecture is to learn the dynamics of the environment from high-dimensional raw video inputs. Using a Generative Adversarial Network (GAN) framework with the proposed network, this architecture is able to learn a spatiotemporal representation in its lower-dimensional latent space directly from raw input sequences. We show that our approach learns the spatial and temporal information simultaneously as opposed to a two-stage learning approach of alternating between training a Convolutional Neural Network (ConvNet) and a Long Short-Term Network (LSTM). Furthermore, by using LSTM-LSTM cells that shrink in size with the increase in the number of layers, the network learns a hierarchical representation with a low-dimensional representation at the top layer. We show that this architecture achieves state-of-the-art results with a substantially lower-dimensional representation than existing methods. We evaluate our approach on a video prediction task with standard benchmark datasets like Moving MNIST and KTH Action, as well as a simulated robot dataset.


Title: Belief Regulated Dual Propagation Nets for Learning Action Effects on Groups of Articulated Objects
Key Words: backpropagation  graph theory  neural nets  robot programming  groups of articulated objects  learning action effects  complex robotic systems  graph neural networks  Belief Regulated Dual Propagation nets  object interaction  object trajectory level  belief regulator  physics predictor  PropNets  general-purpose learnable physics engine  BRDPN  robotics domain  Robots  Physics  Engines  Predictive models  History  Neural networks  Trajectory 
Abstract: In recent years, graph neural networks have been successfully applied for learning the dynamics of complex and partially observable physical systems. However, their use in the robotics domain is, to date, still limited. In this paper, we introduce Belief Regulated Dual Propagation Networks (BRDPN), a general-purpose learnable physics engine, which enables a robot to predict the effects of its actions in scenes containing groups of articulated multi-part objects. Specifically, our framework extends recently proposed propagation networks (PropNets) and consists of two complementary components, a physics predictor and a belief regulator. While the former predicts the future states of the object(s) manipulated by the robot, the latter constantly corrects the robot's knowledge regarding the objects and their relations. Our results showed that after training in a simulator, the robot can reliably predict the consequences of its actions in object trajectory level and exploit its own interaction experience to correct its belief about the state of the environment, enabling better predictions in partially observable environments. Furthermore, the trained model was transferred to the real world and verified in predicting trajectories of pushed interacting objects whose joint relations were initially unknown. We compared BRDPN against PropNets, and showed that BRDPN performs consistently well. Moreover, BRDPN can adapt its physic predictions, since the relations can be predicted online.


Title: Learning of Key Pose Evaluation for Efficient Multi-contact Motion Planner
Key Words: humanoid robots  learning (artificial intelligence)  legged locomotion  motion control  neural nets  path planning  pose estimation  robot vision  robust control  transfer functions  locomotion  uneven terrain  multicontact motion planning  pose evaluation  neural network  activation function  robust robotics system  humanoid robots  deep learning  depth image  Planning  Trajectory  Torque  Legged locomotion  Jacobian matrices  Knee  Collision avoidance 
Abstract: It is necessary to use not only foot but also hand, knee and other body parts to support body weight for locomotion in uneven terrain. Such multi-contact motion planning is an important research topic including lots of previous works; however, a problem of computational speed of planning is still remaining. In this paper, we propose a learning-based algorithm to speed up the planning. The algorithm reduces replanning of contact states by learning an evaluation function of key pose to reach goal. We investigated the learning performance by comparing three neural network configurations and two activation function. This research aims at achieving robust robotics system in unknown environments.


Title: EVDodgeNet: Deep Dynamic Obstacle Dodging with Event Cameras
Key Words: cameras  collision avoidance  control engineering computing  helicopters  learning (artificial intelligence)  neural nets  object detection  robot vision  deep dynamic obstacle dodging  dynamic obstacle avoidance  quadrotor  deep learning  single event camera  shallow neural networks  ego-motion  low light testing scenario  EVDodgeNet  Cameras  Collision avoidance  Motion segmentation  Machine learning  Optical imaging  Robot vision systems  Image segmentation 
Abstract: Dynamic obstacle avoidance on quadrotors requires low latency. A class of sensors that are particularly suitable for such scenarios are event cameras. In this paper, we present a deep learning based solution for dodging multiple dynamic obstacles on a quadrotor with a single event camera and on-board computation. Our approach uses a series of shallow neural networks for estimating both the ego-motion and the motion of independently moving objects. The networks are trained in simulation and directly transfer to the real world without any fine-tuning or retraining. We successfully evaluate and demonstrate the proposed approach in many real-world experiments with obstacles of different shapes and sizes, achieving an overall success rate of 70% including objects of unknown shape and a low light testing scenario. To our knowledge, this is the first deep learning - based solution to the problem of dynamic obstacle avoidance using event cameras on a quadrotor. Finally, we also extend our work to the pursuit task by merely reversing the control policy, proving that our navigation stack can cater to different scenarios.


Title: Dynamic Actor-Advisor Programming for Scalable Safe Reinforcement Learning
Key Words: learning (artificial intelligence)  mobile robots  scalable safe reinforcement learning  real-world robots  complex strict constraints  safe reinforcement learning algorithms  high-dimensional systems  DAAP  sample efficiency  dynamic actor-advisor programming  dynamic policy programming framework  constraint violation risk  Dynamic programming  Programming  Robots  Learning (artificial intelligence)  Heuristic algorithms  Task analysis  Training 
Abstract: Real-world robots have complex strict constraints. Therefore, safe reinforcement learning algorithms that can simultaneously minimize the total cost and the risk of constraint violation are crucial. However, almost no algorithms exist that can scale to high-dimensional systems to the best of our knowledge. In this paper, we propose Dynamic Actor-Advisor Programming (DAAP), as an algorithm for sample-efficient and scalable safe reinforcement learning. DAAP employs two control policies, actor and advisor. They are updated to minimize total cost and risk of constraint violation intertwiningly and smoothly towards each other's direction by using the other as the baseline policy in the Kullback-Leibler divergence of Dynamic Policy Programming framework. We demonstrate the scalability and sample efficiency of DAAP through its application on simulated robot arm control tasks with performance comparisons to baselines.


Title: Discrete Deep Reinforcement Learning for Mapless Navigation
Key Words: discrete systems  gradient methods  learning (artificial intelligence)  mobile robots  navigation  optimisation  state-space methods  mapless navigation  discrete state space algorithms  continuous alternatives  double deep Q-network  parallel asynchronous training  training time  proximal policy optimization algorithms  original discrete algorithm  continuous algorithms  continuous deep deterministic policy gradient  multibatch priority experience replay  discrete deep reinforcement  Training  Navigation  Robot kinematics  Robot sensing systems  Optimization  Machine learning 
Abstract: Our goal is to investigate whether discrete state space algorithms are a viable solution to continuous alternatives for mapless navigation. To this end we present an approach based on Double Deep Q-Network and employ parallel asynchronous training and a multi-batch Priority Experience Replay to reduce the training time. Experiments show that our method trains faster and outperforms both the continuous Deep Deterministic Policy Gradient and Proximal Policy Optimization algorithms. Moreover, we train the models in a custom environment built on the recent Unity learning toolkit and show that they can be exported on the TurtleBot3 simulator and to the real robot without further training. Overall our optimized method is 40% faster compared to the original discrete algorithm. This setting significantly reduces the training times with respect to the continuous algorithms, maintaining a similar level of success rate hence being a viable alternative for mapless navigation.


Title: Learning Multi-Robot Decentralized Macro-Action-Based Policies via a Centralized Q-Net
Key Words: decentralised control  learning (artificial intelligence)  mobile robots  multi-agent systems  multi-robot systems  recurrent neural nets  multirobot decentralized macro-action-based policies  centralized Q-net  decentralized control  decentralized multiagent reinforcement learning  decentralized Q-net  decentralized exploration  macro-action based decentralized multiagent double deep recurrent Q-net  Parallel-MacDec-MADDRQN  Robot kinematics  Training  Tools  Task analysis  Machine learning  History 
Abstract: In many real-world multi-robot tasks, high-quality solutions often require a team of robots to perform asynchronous actions under decentralized control. Decentralized multi-agent reinforcement learning methods have difficulty learning decentralized policies because of the environment appearing to be non-stationary due to other agents also learning at the same time. In this paper, we address this challenge by proposing a macro-action-based decentralized multi-agent double deep recurrent Q-net (MacDec-MADDRQN) which trains each decentralized Q-net using a centralized Q-net for action selection. A generalized version of MacDec-MADDRQN with two separate training environments, called Parallel-MacDec-MADDRQN, is also presented to leverage either centralized or decentralized exploration. The advantages and the practical nature of our methods are demonstrated by achieving near-centralized results in simulation and having real robots accomplish a warehouse tool delivery task in an efficient way.


Title: Robust Model-free Reinforcement Learning with Multi-objective Bayesian Optimization
Key Words: Bayes methods  learning (artificial intelligence)  neural nets  optimisation  pendulums  robust model-free reinforcement learning  multiobjective Bayesian optimization  autonomous agent  exogenous reward signal  test conditions  pure reward maximization  model-free case  robust model-free RL problem  multiobjective optimization problem  robustness indicators  robust formulation  Robustness  Optimization  Training  Control theory  Computational modeling  Learning (artificial intelligence)  Bayes methods 
Abstract: In reinforcement learning (RL), an autonomous agent learns to perform complex tasks by maximizing an exogenous reward signal while interacting with its environment. In real world applications, test conditions may differ substantially from the training scenario and, therefore, focusing on pure reward maximization during training may lead to poor results at test time. In these cases, it is important to trade-off between performance and robustness while learning a policy. While several results exist for robust, model-based RL, the model-free case has not been widely investigated. In this paper, we cast the robust, model-free RL problem as a multi-objective optimization problem. To quantify the robustness of a policy, we use delay margin and gain margin, two robustness indicators that are common in control theory. We show how these metrics can be estimated from data in the model-free setting. We use multi-objective Bayesian optimization (MOBO) to solve efficiently this expensive-to-evaluate, multi-objective optimization problem. We show the benefits of our robust formulation both in sim-to-real and pure hardware experiments to balance a Furuta pendulum.


Title: Real-Time Semantic Stereo Matching
Key Words: image matching  image segmentation  inference mechanisms  neural nets  semantic networks  stereo image processing  augmented reality  deep neural networks  semantic segmentation  inference  semantic stereo image matching  coarse-to-fine estimations  embedded devices  GPU  embedded Jetson TX2  Semantics  Feature extraction  Task analysis  Estimation  Three-dimensional displays  Image segmentation  Computer architecture 
Abstract: Scene understanding is paramount in robotics, self-navigation, augmented reality, and many other fields. To fully accomplish this task, an autonomous agent has to infer the 3D structure of the sensed scene (to know where it looks at) and its content (to know what it sees). To tackle the two tasks, deep neural networks trained to infer semantic segmentation and depth from stereo images are often the preferred choices. Specifically, Semantic Stereo Matching can be tackled by either standalone models trained for the two tasks independently or joint end-to-end architectures. Nonetheless, as proposed so far, both solutions are inefficient because requiring two forward passes in the former case or due to the complexity of a single network in the latter, although jointly tackling both tasks is usually beneficial in terms of accuracy. In this paper, we propose a single compact and lightweight architecture for real-time semantic stereo matching. Our framework relies on coarse-to-fine estimations in a multi-stage fashion, allowing: i) very fast inference even on embedded devices, with marginal drops in accuracy, compared to state-of-the-art networks, ii) trade accuracy for speed, according to the specific application requirements. Experimental results on high-end GPUs as well as on an embedded Jetson TX2 confirm the superiority of semantic stereo matching compared to standalone tasks and highlight the versatility of our framework on any hardware and for any application.


Title: Multi-Task Learning for Single Image Depth Estimation and Segmentation Based on Unsupervised Network
Key Words: computer vision  convolutional neural nets  image segmentation  learning (artificial intelligence)  regression analysis  single image depth estimation  unsupervised network  deep neural networks  computer vision tasks  image segmentation  encoder-decoder-based interactive convolutional neural network  multitask learning framework  CNN  pixel depth regression  Image segmentation  Estimation  Task analysis  Training  Feature extraction  Neural networks  Image reconstruction 
Abstract: Deep neural networks have significantly enhanced the performance of various computer vision tasks, including single image depth estimation and image segmentation. However, most existing approaches handle them in supervised manners and require a large number of ground truth labels that consume extensive human efforts and are not always available in real scenarios. In this paper, we propose a novel framework to estimate disparity maps and segment images simultaneously by jointly training an encoder-decoder-based interactive convolutional neural network (CNN) for single image depth estimation and a multiple class CNN for image segmentation. Learning the neural network for one task can be beneficial from simultaneously learning from another one under a multi-task learning framework. We show that our proposed model can learn per-pixel depth regression and segmentation from just a single image input. Extensive experiments on available public datasets, including KITTI, Cityscapes urban, and PASCAL-VOC demonstrate the effectiveness of our model compared with other state-of-the-art methods for both tasks.


Title: Planning an Efficient and Robust Base Sequence for a Mobile Manipulator Performing Multiple Pick-and-place Tasks
Key Words: collision avoidance  mobile robots  motion control  redundant manipulators  mobile manipulator  planned base positions  robust base sequence  precomputed reachability database  base positioning uncertainty  collision free inverse kinematics solutions  multiple pick and place tasks  kinematic redundancy  Manipulators  Databases  Task analysis  Robustness  Grasping  Uncertainty  Planning 
Abstract: In this paper, we address efficiently and robustly collecting objects stored in different trays using a mobile manipulator. A resolution complete method, based on precomputed reachability database, is proposed to explore collision-free inverse kinematics (IK) solutions and then a resolution complete set of feasible base positions can be determined. This method approximates a set of representative IK solutions that are especially helpful when solving IK and checking collision are treated separately. For real world applications, we take into account the base positioning uncertainty and plan a sequence of base positions that reduce the number of necessary base movements for collecting the target objects, the base sequence is robust in that the mobile manipulator is able to complete the part-supply task even there is certain deviation from the planned base positions. Our experiments demonstrate both the efficiency compared to regular base sequence and the feasibility in real world applications.


Title: Towards Mobile Multi-Task Manipulation in a Confined and Integrated Environment with Irregular Objects
Key Words: assembling  control engineering computing  industrial manipulators  machining  mobile robots  production engineering computing  software architecture  irregular objects  mechanical parts  complex task sets  integrated task sets  IEEE International Conference on Robots and Automation  FetchIt! Mobile Manipulation Challenge  mobile multitask manipulation  confined environment  integrated environment  confined space  machining  assembly  software architecture  Gears  Navigation  Task analysis  Manipulators  Three-dimensional displays  Robot sensing systems 
Abstract: The FetchIt! Mobile Manipulation Challenge, held at the IEEE International Conference on Robots and Automation (ICRA) in May 2019, offered an environment with complex and integrated task sets, irregular objects, confined space, and machining, introducing new challenges in the mobile manipulation domain. Here we describe our efforts to address these challenges by demonstrating the assembly of a kit of mechanical parts in a caddy. In addition to implementation details, we examine the issues in this task set extensively, and we discuss our software architecture in the hope of providing a base for other researchers. To evaluate performance and consistency, we conducted 20 full runs, then examined failure cases with possible solutions. We conclude by identifying future research directions to address the open challenges.


Title: A Mobile Manipulation System for One-Shot Teaching of Complex Tasks in Homes
Key Words: control engineering computing  force control  humanoid robots  learning (artificial intelligence)  manipulators  mobile robots  motion control  position control  virtual reality  mobile manipulation system  one-shot teaching  mobile manipulation hardware  software system  human-level tasks  single demonstration  virtual reality  highly capable mobile manipulation robot  parameterized primitives  robust learned dense visual embeddings representation  task graph  taught behaviors  Task analysis  Robot kinematics  Robustness  Visualization  Aerospace electronics  Education 
Abstract: We describe a mobile manipulation hardware and software system capable of autonomously performing complex human-level tasks in real homes, after being taught the task with a single demonstration from a person in virtual reality. This is enabled by a highly capable mobile manipulation robot, whole-body task space hybrid position/force control, teaching of parameterized primitives linked to a robust learned dense visual embeddings representation of the scene, and a task graph of the taught behaviors. We demonstrate the robustness of the approach by presenting results for performing a variety of tasks, under different environmental conditions, in multiple real homes. Our approach achieves 85% overall success rate on three tasks that consist of an average of 45 behaviors each. The video is available at: https://youtu.be/HSyAGMGikLk.


Title: 2D to 3D Line-Based Registration with Unknown Associations via Mixed-Integer Programming
Key Words: calibration  image registration  integer programming  iterative methods  mobile robots  robot vision  iterative nearest-neighbor  mixed-integer program  data association  integer variables  3D line-based registration  mixed-integer programming  rigid-body transformation  3D point cloud data  mobile robotics  sensor calibration  linear line-based 2D-3D registration  Three-dimensional displays  Two dimensional displays  Cameras  Cost function  Robot sensing systems  Transforms  Symmetric matrices 
Abstract: Determining the rigid-body transformation be-tween 2D image data and 3D point cloud data has applications for mobile robotics including sensor calibration and localizing into a prior map. Common approaches to 2D-3D registration use least-squares solvers assuming known associations often provided by heuristic front-ends, or iterative nearest-neighbor. We present a linear line-based 2D-3D registration algorithm formulated as a mixed-integer program to simultaneously solve for the correct transformation and data association. Our formulation is explicitly formulated to handle outliers, by modeling associations as integer variables. Additionally, we can constrain the registration to SE(2) to improve runtime and accuracy. We evaluate this search over multiple real-world data sets demonstrating adaptability to scene variation.


Title: End-to-end Learning for Inter-Vehicle Distance and Relative Velocity Estimation in ADAS with a Monocular Camera
Key Words: cameras  driver information systems  feature extraction  image sequences  learning (artificial intelligence)  mobile robots  neural nets  object detection  road safety  robot vision  video signal processing  end-to-end learning  inter-vehicle distance  ADAS  monocular camera  advanced driver-assistance systems  relative velocity estimation method  multiple visual clues  time-consecutive monocular frames  deep feature clue  scene geometry clue  temporal optical flow clue  vehicle-centric sampling mechanism  light-weight deep neural network  Estimation  Three-dimensional displays  Cameras  Optical imaging  Two dimensional displays  Feature extraction  Neural networks 
Abstract: Inter-vehicle distance and relative velocity estimations are two basic functions for any ADAS (Advanced driver-assistance systems). In this paper, we propose a monocular camera based inter-vehicle distance and relative velocity estimation method based on end-to-end training of a deep neural network. The key novelty of our method is the integration of multiple visual clues provided by any two time-consecutive monocular frames, which include deep feature clue, scene geometry clue, as well as temporal optical flow clue. We also propose a vehicle-centric sampling mechanism to alleviate the effect of perspective distortion in the motion field (i.e. optical flow). We implement the method by a light-weight deep neural network. Extensive experiments are conducted which confirm the superior performance of our method over other state-of-the-art methods, in terms of estimation accuracy, computational speed, and memory footprint.


Title: Multimodal tracking framework for visual odometry in challenging illumination conditions
Key Words: cameras  distance measurement  feature extraction  image matching  motion estimation  robot vision  stereo image processing  visible spectrum  electromagnetic spectrum  extreme illumination conditions  camera setups  multimodal monocular visual odometry solution  multimodal tracking framework  stereo matching techniques  long wave infrared spectral bands  LWIR  MMS-VO  windowed bundle adjustment framework  motion estimation process  visible-thermal datasets  feature tracking  visual odometry trajectory  Cameras  Feature extraction  Bundle adjustment  Visual odometry  Lighting  Tracking 
Abstract: Research on visual odometry and localisation is largely dominated by solutions developed in the visible spectrum, where illumination is a critical factor. Other parts of the electromagnetic spectrum are currently being investigated to generate solutions dealing with extreme illumination conditions. Multispectral setups are particularly interesting as they provide information from different parts of the spectrum at once. However, the main challenge of such camera setups is the lack of similarity between the images produced, which makes conventional stereo matching techniques obsolete.This work investigates a new way of concurrently processing images from different spectra for application to visual odometry. It particularly focuses on the visible and Long Wave InfraRed (LWIR) spectral bands where dissimilarity between pixel intensities is maximal. A new Multimodal Monocular Visual Odometry solution (MMS-VO) is presented. With this novel approach, features are tracked simultaneously, but only the camera providing the best tracking quality is used to estimate motion. Visual odometry is performed within a windowed bundle adjustment framework, by alternating between the cameras as the nature of the scene changes. Furthermore, the motion estimation process is robustified by selecting adequate keyframes based on parallax.The algorithm was tested on a series of visible-thermal datasets, acquired from a car with real driving conditions. It is shown that feature tracking could be performed in both modalities with the same set of parameters. Additionally, the MMS-VO provides a superior visual odometry trajectory as one camera can compensate when the other is not working.


Title: Realtime Multi-Diver Tracking and Re-identification for Underwater Human-Robot Collaboration
Key Words: autonomous underwater vehicles  control engineering computing  convolutional neural nets  feature extraction  human-robot interaction  mobile robots  object detection  object tracking  custom CNN  deep SORT algorithm  realtime tracking-by-detection  realtime diver detection  initial diver detection  appearance metric  simple online realtime tracking  human divers  autonomous underwater robots  underwater human-robot collaboration  realtime multidiver tracking re-identification  on-board tracking  on-board autonomous robot operations  multiperson tracking  Robots  Tracking  Feature extraction  Collaboration  Unmanned underwater vehicles  Task analysis 
Abstract: Autonomous underwater robots working with teams of human divers may need to distinguish between different divers, e.g., to recognize a lead diver or to follow a specific team member. This paper describes a technique that enables autonomous underwater robots to track divers in real time as well as to reidentify them. The approach is an extension of Simple Online Realtime Tracking (SORT) with an appearance metric (deep SORT). Initial diver detection is performed with a custom CNN designed for realtime diver detection, and appearance features are subsequently extracted for each detected diver. Next, realtime tracking-by-detection is performed with an extension of the deep SORT algorithm. We evaluate this technique on a series of videos of divers performing human-robot collaborative tasks and show that our methods result in more divers being accurately identified during tracking. We also discuss the practical considerations of applying multi-person tracking to on-board autonomous robot operations, and we consider how failure cases can be addressed during on-board tracking.


Title: Collision-free Navigation of Human-centered Robots via Markov Games
Key Words: collision avoidance  learning (artificial intelligence)  Markov processes  mobile robots  multi-agent systems  multi-robot systems  collision-free navigation  human-centered robots  Markov games  robot navigation  single-agent Markov decision process  static environment  multiagent formulation  primary agent  remaining auxiliary agents  path-following type adversarial training strategy  robust decentralized collision avoidance policy  real-world mobile robots  Collision avoidance  Robots  Markov processes  Navigation  Games  Robustness  Training  Collision-free navigation  human-centered robotics  deep reinforcement learning  multi-agent system  adversarial training 
Abstract: We exploit Markov games as a framework for collision-free navigation of human-centered robots. Unlike the classical methods which formulate robot navigation as a single-agent Markov decision process with a static environment, our framework of Markov games adopts a multi-agent formulation with one primary agent representing the robot and the remaining auxiliary agents form a dynamic or even competing environment. Such a framework allows us to develop a path-following type adversarial training strategy to learn a robust decentralized collision avoidance policy. Through thorough experiments on both simulated and real-world mobile robots, we show that the learnt policy outperforms the state-of-the-art algorithms in both sample complexity and runtime robustness.


Title: DenseCAvoid: Real-time Navigation in Dense Crowds using Anticipatory Behaviors
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  pedestrians  trajectory control  DenseCAvoid  real-time navigation  dense crowds  anticipatory behaviors  pedestrian behaviors  visual sensors  pedestrian trajectory prediction algorithm  input frames  compute bounding boxes  pedestrian positions  future time  hybrid approach  deep reinforcement learning-based collision avoidance method  robust trajectories  static scenarios  dynamic scenarios  multiple pedestrians  robot freezing  trajectory lengths  mean arrival times  Collision avoidance  Navigation  Trajectory  Robot sensing systems  Robustness  Tracking 
Abstract: We present DenseCAvoid, a novel algorithm for navigating a robot through dense crowds and avoiding collisions by anticipating pedestrian behaviors. Our formulation uses visual sensors and a pedestrian trajectory prediction algorithm to track pedestrians in a set of input frames and compute bounding boxes that extrapolate to the pedestrian positions in a future time. Our hybrid approach combines this trajectory prediction with a Deep Reinforcement Learning-based collision avoidance method to train a policy to generate smoother, safer, and more robust trajectories during run-time. We train our policy in realistic 3-D simulations of static and dynamic scenarios with multiple pedestrians. In practice, our hybrid approach generalizes well to unseen, real-world scenarios and can navigate a robot through dense crowds (~1-2 humans per square meter) in indoor scenarios, including narrow corridors and lobbies. As compared to cases where prediction was not used, we observe that our method reduces the occurrence of the robot freezing in a crowd by up to 48%, and performs comparably with respect to trajectory lengths and mean arrival times to goal.


Title: Simultaneous task allocation and motion scheduling for complex tasks executed by multiple robots
Key Words: cutting  industrial manipulators  motion control  multi-robot systems  optimisation  rapid prototyping (industrial)  scheduling  spot welding  time-varying portion  generic optimization method  varying complexity  dual-arm robot  robot arm  motion scheduling  multiple robot coordination  simultaneous task allocation  additive manufacturing  cutting  spot welding  bolt tightening  bolt inserting  robot kinematics  Task analysis  Robot kinematics  Planning  Collision avoidance  Job shop scheduling  Resource management  task scheduling  dual-arm manipulation  motion planning  multi-robot systems 
Abstract: The coordination of multiple robots operating simultaneously in the same workspace requires the integration of task allocation and motion scheduling. We focus on tasks in which the robot's actions are not confined to small volumes, but can also occupy a large time-varying portion of the workspace, such as in welding along a line. The optimization of such tasks presents a considerable challenge mainly due to the fact that different variants of task execution exist, for instance, there can be multiple starting points of lines or closed curves, differentfilling patterns of areas, etc. We propose a generic and computationally efficient optimization method which is based on constraint programming. It takes into account the kinematics of the robots and guarantees that the motions of the robots are collision-free while minimizing the overall makespan. We evaluate our approach on several use-cases of varying complexity: cutting, additive manufacturing, spot welding, inserting and tightening bolts, performed by a dual-arm robot. In terms of the makespan, the result is superior to task execution by one robot arm as well as by two arms not working simultaneously.


Title: Evaluating Adaptation Performance of Hierarchical Deep Reinforcement Learning
Key Words: learning (artificial intelligence)  multi-agent systems  neural nets  differentiated sub-policies  hierarchical controller  adaptation performance  hierarchical deep reinforcement learning  policy performance  confidence- based training process  Training  Adaptation models  Trajectory  Games  Learning (artificial intelligence)  Robots  Switches 
Abstract: Deep Reinforcement Learning has been used to exploit specific environments, but has difficulty transferring learned policies to new situations. This issue poses a problem for practical applications of Reinforcement Learning, as real-world scenarios may introduce unexpected differences that drastically reduce policy performance. We propose the use of differentiated sub-policies governed by a hierarchical controller to support adaptation in such scenarios. We also introduce a confidence- based training process for the hierarchical controller which improves training stability and convergence times. We evaluate these methods in a new Capture the Flag environment designed to explore adaptation in autonomous multi-agent settings.


Title: Reactive Temporal Logic Planning for Multiple Robots in Unknown Environments
Key Words: mobile robots  multi-robot systems  path planning  robot dynamics  temporal logic  multiple robots  reactive mission  unknown environment  temporal logic planning approaches  robot dynamics  known environments  abstraction-free LTL planning algorithm  complex mission planning  complex planning tasks  co-safe linear temporal logic formulas  reactive temporal logic planning  Robot sensing systems  Planning  Task analysis  Heuristic algorithms  Automata 
Abstract: This paper proposes a new reactive mission planning algorithm for multiple robots that operate in unknown environments. The robots are equipped with individual sensors that allow them to collectively learn and continuously update a map of the unknown environment. The goal of the robots is to accomplish complex tasks, captured by global co-safe Linear Temporal Logic (LTL) formulas. The majority of existing temporal logic planning approaches rely on discrete abstractions of the robot dynamics operating in known environments and, as a result, they cannot be applied to the more realistic scenarios where the environment is initially unknown. In this paper, we address this novel challenge by proposing the first reactive, and abstraction-free LTL planning algorithm that can be applied for complex mission planning of multiple robots operating in unknown environments. Our algorithm is reactive in the sense that temporal logic planning is adapting to the updated map of the environment and abstraction-free as it does not rely on designing abstractions of robot dynamics. Our proposed algorithm is complete under mild assumptions on the structure of the environment and the sensor models. Our paper provides extensive numerical simulations and hardware experiments that illustrate the theoretical analysis and show that the proposed algorithm can address complex planning tasks in unknown environments.


Title: Higher Order Function Networks for View Planning and Multi-View Reconstruction
Key Words: image reconstruction  learning (artificial intelligence)  neural nets  object detection  robot vision  shape recognition  solid modelling  stereo image processing  Higher Order function networks  multiview reconstruction  visual inspection  neural network  shape information  deep learning  complete 3D reconstruction  Higher Order Functions  reconstruction quality  multiview HOF network  image acquisition  view planning  visibility quality  shape representation  Three-dimensional displays  Image reconstruction  Planning  Cameras  Surface reconstruction  Inspection  Shape 
Abstract: We consider the problem of planning views for a robot to acquire images of an object for visual inspection and reconstruction. In contrast to offline methods which require a 3D model of the object as input or online methods which rely on only local measurements, our method uses a neural network which encodes shape information for a large number of objects. We build on recent deep learning methods capable of generating a complete 3D reconstruction of an object from a single image. Specifically, in this work, we extend a recent method which uses Higher Order Functions (HOF) to represent the shape of the object. We present a new generalization of this method to incorporate multiple images as input and establish a connection between visibility and reconstruction quality. This relationship forms the foundation of our view planning method where we compute viewpoints to visually cover the output of the multiview HOF network with as few images as possible. Experiments indicate that our method provides a good compromise between online and offline methods: Similar to online methods, our method does not require the true object model as input. In terms of number of views, it is much more efficient. In most cases, its performance is comparable to the optimal offline case even on object classes the network has not been trained on.


