total paper: 339
Title: Dynamic Movement Primitives for moving goals with temporal scaling adaptation
Key Words: human-robot interaction  learning (artificial intelligence)  mobile robots  motion control  human robot collaboration  motion profiles  learned kinematic pattern  KUKA LWR4+ robot  DMP  dynamic movement primitives framework  adaptive temporal scaling  static goal  temporal scaling adaptation  moving goal  Trajectory  Robots  Dynamics  Encoding  Collaboration  Adaptation models  Kinematics 
Abstract: In this work, we propose an augmentation to the Dynamic Movement Primitives (DMP) framework which allows the system to generalize to moving goals without the use of any known or approximation model for estimating the goal's motion. We aim to maintain the demonstrated velocity levels during the execution to the moving goal, generating motion profiles appropriate for human robot collaboration. The proposed method employs a modified version of a DMP, learned by a demonstration to a static goal, with adaptive temporal scaling in order to achieve reaching of the moving goal with the learned kinematic pattern. Only the current position and velocity of the goal are required. The goal's reaching error and its derivative is proved to converge to zero via contraction analysis. The theoretical results are verified by simulations and experiments on a KUKA LWR4+ robot.


Title: Aggregation and localization of simple robots in curved environments
Key Words: friction  microrobots  mobile robots  path planning  curved environments  extremely simple robots  biomedical applications  tiny robots moves  shared external stimulus  low-friction models  environment boundaries  Robot sensing systems  Collision avoidance  Computational modeling  Biological system modeling  Propulsion 
Abstract: This paper is about the closely-related problems of localization and aggregation for extremely simple robots, for which the only available action is to move in a given direction as far as the geometry of the environment allows. Such problems may arise, for example, in biomedical applications, wherein a large group of tiny robots moves in response to a shared external stimulus. Specifically, we extend the prior work on these kinds of problems presenting two algorithms for localization in environments with curved (rather than polygonal) boundaries and under low-friction models of interaction with the environment boundaries. We present both simulations and physical demonstrations to validate the approach.


Title: Deep Merging: Vehicle Merging Controller Based on Deep Reinforcement Learning with Embedding Network
Key Words: control engineering computing  learning (artificial intelligence)  road traffic control  road vehicles  traffic engineering computing  traffic conditions  traffic flow  Deep Merging  vehicle Merging controller  embedding network  highway merging sections  lane change  vehicle controller  merging efficiency  merging section  target vehicle speed  controlled vehicle speed  deep reinforcement learning network architecture  learning efficiency  merging behavior  Merging  Machine learning  Feature extraction  Acceleration  Road transportation  Vehicle dynamics  Network architecture 
Abstract: Vehicles at highway merging sections must make lane changes to join the highway. This lane change can generate congestion. To reduce congestion, vehicles should merge so as not to affect traffic flow as much as possible. In our study, we propose a vehicle controller called Deep Merging that uses deep reinforcement learning to improve the merging efficiency of vehicles while considering the impact on traffic flow. The system uses the images of a merging section as input to output the target vehicle speed. Moreover, an embedding network for estimating the controlled vehicle speed is introduced to the deep reinforcement learning network architecture to improve the learning efficiency. In order to show the effectiveness of the proposed method, the merging behavior and traffic conditions in several situations are verified by experiments using a traffic simulator. Through these experiments, it is confirmed that the proposed method enables controlled vehicles to effectively merge without adversely affecting to the traffic flow.


Title: A Synchronization Approach for Achieving Cooperative Adaptive Cruise Control Based Non-Stop Intersection Passing
Key Words: adaptive control  control system synthesis  distributed control  Lyapunov methods  mobile robots  multi-robot systems  position control  road traffic control  road vehicles  stability  velocity control  synchronization approach  adaptive cruise control based nonstop intersection passing  intelligent vehicles  cruise control performance  traffic congestion  increasing traffic flow capacity  CACC problem  synchronization control  spatial-temporal synchronization mechanism  vehicle platoon control  robust CACC  cross-coupling based space synchronization mechanism  distributed control algorithm  single-lane CACC  vehicle-to-vehicle communications  autonomous vehicles  desired platoon trajectory  expected inter-vehicle distance  enter-time scheduling mechanism  high-level intersection control strategy  Lyapunov-based time-domain stability analysis approach  traditional string stability based approach  CACC system  Synchronization  Stability analysis  Cruise control  Robustness  Autonomous vehicles  Motion control  Acceleration 
Abstract: Cooperative adaptive cruise control (CACC) of intelligent vehicles contributes to improving cruise control performance, reducing traffic congestion, saving energy and increasing traffic flow capacity. In this paper, we resolve the CACC problem from the viewpoint of synchronization control, our main idea is to introduce the spatial-temporal synchronization mechanism into vehicle platoon control to achieve the robust CACC and to further realize the non-stop intersection control. Firstly, by introducing the cross-coupling based space synchronization mechanism, a distributed control algorithm is presented to achieve the single-lane CACC in the presence of vehicle-to-vehicle (V2V) communications, which enables autonomous vehicles to track the desired platoon trajectory while synchronizing their longitudinal velocities to keeping the expected inter-vehicle distance. Secondly, by designing the enter-time scheduling mechanism (temporal synchronization), a high-level intersection control strategy is proposed to command vehicles to form a virtual platoon to pass through the intersection without stopping. Thirdly, a Lyapunov-based time-domain stability analysis approach is presented. Compared with the traditional string stability based approach, the proposed approach guarantees the global asymptotical convergence of the proposed CACC system. Experiments in the small-scale simulated system demonstrate the effectiveness of the proposed approach.


Title: Urban Driving with Conditional Imitation Learning
Key Words: cameras  computer vision  decision making  driver information systems  learning (artificial intelligence)  mobile robots  road traffic  road vehicles  real-world urban autonomous driving  human driving demonstrations  user-defined route  single camera view  heavily cropped frames  lateral control  longitudinal control  real-world complexities  end-to-end conditional imitation learning approach  urban routes  simple traffic  autonomous vehicle  European urban streets  urban driving  hand-crafting generalised decision-making rules  Cameras  Sensor fusion  Autonomous vehicles  Roads  Computational modeling  Aerospace electronics  Training 
Abstract: Hand-crafting generalised decision-making rules for real-world urban autonomous driving is hard. Alternatively, learning behaviour from easy-to-collect human driving demonstrations is appealing. Prior work has studied imitation learning (IL) for autonomous driving with a number of limitations. Examples include only performing lane-following rather than following a user-defined route, only using a single camera view or heavily cropped frames lacking state observability, only lateral (steering) control, but not longitudinal (speed) control and a lack of interaction with traffic. Importantly, the majority of such systems have been primarily evaluated in simulation - a simple domain, which lacks real-world complexities. Motivated by these challenges, we focus on learning representations of semantics, geometry and motion with computer vision for IL from human driving demonstrations. As our main contribution, we present an end-to-end conditional imitation learning approach, combining both lateral and longitudinal control on a real vehicle for following urban routes with simple traffic. We address inherent dataset bias by data balancing, training our final policy on approximately 30 hours of demonstrations gathered over six months. We evaluate our method on an autonomous vehicle by driving 35km of novel routes in European urban streets.


Title: ICS: Incremental Constrained Smoothing for State Estimation
Key Words: matrix decomposition  mobile robots  optimisation  path planning  robot vision  SLAM (robots)  state estimation  ICS  primal-dual method  matrix factorizations  primal-dual methods  incremental factorization  matrix structure  incremental unconstrained optimization  robot state estimate  smoothing-based estimation methods  state estimation  incremental constrained smoothing  Optimization  Smoothing methods  Time measurement  Integrated circuits  Simultaneous localization and mapping 
Abstract: A robot operating in the world constantly receives information about its environment in the form of new measurements at every time step. Smoothing-based estimation methods seek to optimize for the most likely robot state estimate using all measurements up till the current time step. Existing methods solve for this smoothing objective efficiently by framing the problem as that of incremental unconstrained optimization. However, in many cases observed measurements and knowledge of the environment is better modeled as hard constraints derived from real-world physics or dynamics. A key challenge is that the new optimality conditions introduced by the hard constraints break the matrix structure needed for incremental factorization in these incremental optimization methods. Our key insight is that if we leverage primal-dual methods, we can recover a matrix structure amenable to incremental factorization. We propose a framework ICS that combines a primal-dual method like the Augmented Lagrangian with an incremental Gauss Newton approach that reuses previously computed matrix factorizations. We evaluate ICS on a set of simulated and real-world problems involving equality constraints like object contact and inequality constraints like collision avoidance.


Title: Drone-aided Localization in LoRa IoT Networks
Key Words: autonomous aerial vehicles  Internet of Things  wide area networks  realistic simulated scenario  fully autonomous localization system  ten-fold improvement  localization precision  fixed network  UAV  localization accuracy  LoRa IoT networks  node localization  widespread IoT communication technologies  Long Range Wide Area Network  long communication distances  drone-aided localization system  communication system  search algorithm  Internet of Things  3D mobility  Logic gates  Drones  Estimation  Receivers  Servers  Internet of Things  Global navigation satellite system 
Abstract: Besides being part of the Internet of Things (IoT), drones can play a relevant role in it as enablers. The 3D mobility of UAVs can be exploited to improve node localization in IoT networks for, e.g., search and rescue or goods localization and tracking. One of the widespread IoT communication technologies is Long Range Wide Area Network (LoRaWAN), which allows achieving long communication distances with low power. In this work, we present a drone-aided localization system for LoRa networks in which a UAV is used to improve the estimation of a node's location initially provided by the network. We characterize the relevant parameters of the communication system and use them to develop and test a search algorithm in a realistic simulated scenario. We then move to the full implementation of a real system in which a drone is seamlessly integrated into Swisscom's LoRa network. The drone coordinates with the network with a two-way exchange of information which results in an accurate and fully autonomous localization system. The results obtained in our field tests show a ten-fold improvement in localization precision with respect to the estimation provided by the fixed network. Up to our knowledge, this is the first time a UAV is successfully integrated in a LoRa network to improve its localization accuracy.


Title: Sample-and-computation-efficient Probabilistic Model Predictive Control with Random Features
Key Words: approximation theory  Gaussian processes  learning (artificial intelligence)  predictive control  random features  Gaussian processes  reinforcement learning methods  model predictive control  MPC  computational cost  linear Gaussian model  approximated GP dynamics  state prediction  simulated robot control tasks  sample-and-computation-efficient nature  model-based RL method  analytic moment-matching scheme  Training  Predictive models  Kernel  Probabilistic logic  Computational modeling  Computational efficiency  Uncertainty 
Abstract: Gaussian processes (GPs) based Reinforcement Learning (RL) methods with Model Predictive Control (MPC) have demonstrated their excellent sample efficiency. However, since the computational cost of GPs largely depends on the training sample size, learning an accurate dynamics using GPs result in low control frequency in MPC. To alleviate this trade-off and achieve a sample-and-computation-efficient nature, we propose a novel model-based RL method with MPC. Our approach employs a linear Gaussian model with randomized features using the Fastfood as an approximated GP dynamics. Then, we derive an analytic moment-matching scheme in state prediction with the model and uncertain inputs. As a result, the computational cost of the MPC in our RL method does not depend on the training sample size and can improve the control frequency over previous methods. Through experiments with simulated and real robot control tasks, the sample efficiency, as well as the computation efficiency of our model-based RL method, are demonstrated.


Title: Iterative Learning based feedforward control for Transition of a Biplane-Quadrotor Tailsitter UAS
Key Words: aerodynamics  aircraft control  attitude control  autonomous aerial vehicles  error compensation  feedforward  helicopters  iterative learning control  learning systems  neurocontrollers  pitch control (position)  polynomials  propellers  robust control  wind tunnels  iterative learning based feedforward control  biplane-quadrotor tailsitter UAS  time on-board algorithm  forward transition maneuver  repeated flight trials  pitch angle  propeller thrust  polynomials  simplified aerodynamics  optimal coefficients  terminal conditions  air speed  modeling error compensation  geometric attitude controller  flight modes  feedforward law  high-fidelity thrust model  orientation angle  neural network model  experimental flight trials  learning algorithm  maneuver control  wind tunnel data  feedforward thrust  robustness  UAS  Aerodynamics  Propellers  Wind tunnels  Atmospheric modeling  Feedforward systems  Data models  Trajectory  VTOL UAS  transition maneuver  iterative learning 
Abstract: This paper provides a real time on-board algorithm for a biplane-quadrotor to iteratively learn a forward transition maneuver via repeated flight trials. The maneuver is controlled by regulating the pitch angle and propeller thrust according to feedforward control laws that are parameterized by polynomials. Based on a nominal model with simplified aerodynamics, the optimal coefficients of the polynomials are chosen through simulation such that the maneuver is completed with specified terminal conditions on altitude and air speed. In order to compensate for modeling errors, repeated flight trials are performed by updating the feedforward control parameters according to an iterative learning algorithm until the maneuver is perfected. A geometric attitude controller, valid for all flight modes is employed in order to track the pitch angle according to the feedforward law. Further, a high-fidelity thrust model of the propeller for varying advance-ratio and orientation angle is obtained from wind tunnel data which is captured using a neural network model. This facilitates accurate application of feedforward thrust for varying flow conditions during transition. Experimental flight trials are performed to demonstrate the robustness and rapid convergence of the proposed learning algorithm.


Title: Reinforcement Learning for Adaptive Illumination with X-rays
Key Words: convolutional neural nets  image resolution  image sampling  image segmentation  learning (artificial intelligence)  X-ray imaging  adaptive illumination  reinforcement learning  image sampling  image surface  convolutional neural network  rastering method  X-rays  Apertures  Trajectory  Learning (artificial intelligence)  Time measurement  Imaging  Image reconstruction  X-rays 
Abstract: We propose a learning algorithm for automating image sampling in scientific applications. We consider settings where images are sampled by controlling a probe beam's scanning trajectory over the image surface. We explore alternatives to obtaining images by the standard rastering method. We formulate the scanner control problem as a reinforcement learning (RL) problem and train a policy to adaptively sample only the highest value regions of the image, choosing the acquisition time and resolution for each sample position based on an observation of previous readings. We use convolutional neural network (CNN) policies to control the scanner as a way to generalize our approach to larger samples. We show simulation results for a simple policy on both synthetic data and real world data from an archaeological application.


Title: Extracting Legged Locomotion Heuristics with Regularized Predictive Control
Key Words: adaptive control  control system synthesis  learning (artificial intelligence)  legged locomotion  motion control  optimisation  predictive control  legged locomotion heuristics  regularized predictive control  legged robots  dynamic maneuvers  difficult terrains  meaningful cost functions  high-fidelity models  timing restrictions  principled regularization heuristics  legged locomotion optimization control  cost space offline  desired commands  optimal control actions  robot states  heuristic candidates  adaptation laws  models online  powerful heuristics  approximate complex dynamics  model simplifications  parameter uncertainty  parameter tuning process  increased capabilities  newly extracted heuristics  controller structure  mini cheetah robot  Cost function  Legged locomotion  Data models  Tuning  Predictive control 
Abstract: Optimization based predictive control is a powerful tool that has improved the ability of legged robots to execute dynamic maneuvers and traverse increasingly difficult terrains. However, it is often challenging and unintuitive to design meaningful cost functions and build high-fidelity models while adhering to timing restrictions. A novel framework to extract and design principled regularization heuristics for legged locomotion optimization control is presented. By allowing a simulation to fully explore the cost space offline, certain states and actions can be constrained or isolated. Data is fit with simple models relating the desired commands, optimal control actions, and robot states to identify new heuristic candidates. Basic parameter learning and adaptation laws are then applied to the models online. This method extracts simple, but powerful heuristics that can approximate complex dynamics and account for errors stemming from model simplifications and parameter uncertainty without the loss of physical intuition while generalizing the parameter tuning process. Results on the Mini Cheetah robot verify the increased capabilities due to the newly extracted heuristics without any modification to the controller structure or gains.


Title: Learning Generalizable Locomotion Skills with Hierarchical Reinforcement Learning
Key Words: learning (artificial intelligence)  legged locomotion  path planning  predictive control  robot dynamics  robot kinematics  generalizable locomotion skills  hierarchical reinforcement learning  arbitrary goals  hierarchical framework  sample-efficiency  generalizability  learned locomotion skills  real-world robots  goal-oriented locomotion  diverse primitives skills  freedom robot  coarse dynamics models  primitive cycles  model predictive control framework  Daisy hexapod hardware  size 12.0 m  Hardware  Legged locomotion  Training  Task analysis  Planning  Heuristic algorithms 
Abstract: Learning to locomote to arbitrary goals on hardware remains a challenging problem for reinforcement learning. In this paper, we present a hierarchical framework that improves sample-efficiency and generalizability of learned locomotion skills on real-world robots. Our approach divides the problem of goal-oriented locomotion into two sub-problems: learning diverse primitives skills, and using model-based planning to sequence these skills. We parametrize our primitives as cyclic movements, improving sample-efficiency of learning from scratch on a 18 degrees of freedom robot. Then, we learn coarse dynamics models over primitive cycles and use them in a model predictive control framework. This allows us to learn to walk to arbitrary goals up to 12m away, after about two hours of training from scratch on hardware. Our results on a Daisy hexapod hardware and simulation demonstrate the efficacy of our approach at reaching distant targets, in different environments, and with sensory noise.


Title: SoRX: A Soft Pneumatic Hexapedal Robot to Traverse Rough, Steep, and Unstable Terrain
Key Words: actuators  legged locomotion  motion control  pneumatic actuators  SoRX  soft pneumatic hexapedal robot  2-degree-of-freedom soft pneumatic actuator  tripod gait  pneumatically-actuated legged robots  rough terrain  steep terrain  open-loop control  cyclic foot trajectories  legged locomotion  physical testing  Legged locomotion  Pneumatic systems  Soft robotics  Pneumatic actuators  Trajectory 
Abstract: Soft robotics technology creates new ways for legged robots to interact with and adapt to their environment. In this paper we develop i) a new 2-degree-of-freedom soft pneumatic actuator, and ii) a novel soft robotic hexapedal robot called SoRX that leverages the new actuators. Simulation and physical testing confirm that the proposed actuator can generate cyclic foot trajectories that are appropriate for legged locomotion. Consistent with other hexapedal robots (and animals), SoRX employs an alternating tripod gait to propel itself forward. Experiments reveal that SoRX can reach forward speeds of up to 0.44 body lengths per second, or equivalently 101 mm/s. With a size of 230 mm length, 140 mm width and 100 mm height, and weight of 650 grams, SoRX is among the fastest tethered soft pneumatically-actuated legged robots to date. The motion capabilities of SoRX are evaluated through five experiments: running, step climbing, and traversing rough terrain, steep terrain, and unstable terrain. Experimental results show that SoRX is able to operate over challenging terrains in open-loop control and by following the same alternating tripod gait across all experimental cases.


Title: UBAT: On Jointly Optimizing UAV Trajectories and Placement of Battery Swap Stations
Key Words: ant colony optimisation  autonomous aerial vehicles  battery powered vehicles  electric vehicles  optimal number  charging stations  UBAT  ant colony optimization  UAV trajectories  battery swap stations  unmanned aerial vehicles  UAVs  flight time  charging station deployment problem  NP-hard problem  Charging stations  Batteries  Trajectory  Optimization  Sensors  Unmanned aerial vehicles  Euclidean distance 
Abstract: Unmanned aerial vehicles (UAVs) have been widely used in many applications. The limited flight time of UAVs, however, still remains as a major challenge. Although numerous approaches have been developed to recharge the battery of UAVs effectively, little is known about optimal methodologies to deploy charging stations. In this paper, we address the charging station deployment problem with an aim to find the optimal number and locations of charging stations such that the system performance is maximized. We show that the problem is NP-Hard and propose UBAT, a heuristic framework based on the ant colony optimization (ACO) to solve the problem. Additionally, a suite of algorithms are designed to enhance the execution time and the quality of the solutions for UBAT. Through extensive simulations, we demonstrate that UBAT effectively performs multi-objective optimization of generation of UAV trajectories and placement of charging stations that are within 8.3% and 7.3% of the true optimal solutions, respectively.


Title: Efficient Multi-Agent Trajectory Planning with Feasibility Guarantee using Relative Bernstein Polynomial
Key Words: collision avoidance  multi-agent systems  optimisation  polynomials  optimization-based approaches  erroneous optimization setup  infeasible collision constraints  sequential optimization method  dummy agents  relative Bernstein polynomial  nonconvex collision avoidance constraints  multiagent trajectory planning problems  obstacle-dense environments  grid-based approaches  Trajectory  Planning  Heuristic algorithms  Collision avoidance  Optimization  System recovery  Three-dimensional displays 
Abstract: This paper presents a new efficient algorithm which guarantees a solution for a class of multi-agent trajectory planning problems in obstacle-dense environments. Our algorithm combines the advantages of both grid-based and optimization-based approaches, and generates safe, dynamically feasible trajectories without suffering from an erroneous optimization setup such as imposing infeasible collision constraints. We adopt a sequential optimization method with dummy agents to improve the scalability of the algorithm, and utilize the convex hull property of Bernstein and relative Bernstein polynomial to replace non-convex collision avoidance constraints to convex ones. The proposed method can compute the trajectory for 64 agents on average 6.36 seconds with Intel Core i7-7700 @ 3.60GHz CPU and 16G RAM, and it reduces more than 50% of the objective cost compared to our previous work. We validate the proposed algorithm through simulation and flight tests.


Title: Optimal Sequential Task Assignment and Path Finding for Multi-Agent Robotic Assembly Planning
Key Words: assembly planning  collision avoidance  mobile robots  multi-agent systems  multi-robot systems  robotic assembly  nonholonomic differential-drive robots  optimal sequential task assignment  collision-free trajectories  robotic manufacturing  collision-free routing  multiagent robotic assembly planning  path finding  Robots  Task analysis  Schedules  Manufacturing  Collision avoidance  Routing  Production facilities 
Abstract: We study the problem of sequential task assignment and collision-free routing for large teams of robots in applications with inter-task precedence constraints (e.g., task A and task B must both be completed before task C may begin). Such problems commonly occur in assembly planning for robotic manufacturing applications, in which sub-assemblies must be completed before they can be combined to form the final product. We propose a hierarchical algorithm for computing makespan-optimal solutions to the problem. The algorithm is evaluated on a set of randomly generated problem instances where robots must transport objects between stations in a "factory" grid world environment. In addition, we demonstrate in high-fidelity simulation that the output of our algorithm can be used to generate collision-free trajectories for non-holonomic differential-drive robots.


Title: Cooperative Multi-Robot Navigation in Dynamic Environment with Deep Reinforcement Learning
Key Words: control engineering computing  learning (artificial intelligence)  mobile robots  multi-robot systems  navigation  path planning  optimal paths  multiple robots  dynamics randomization  differential drive robots  dynamic environment  obstacle complexities  multirobot navigation problem  deep reinforcement learning framework  optimal target locations  DRL based framework  navigation policy  Collision avoidance  Navigation  Robot sensing systems  Robot kinematics  Training  Adaptation models 
Abstract: The challenges of multi-robot navigation in dynamic environments lie in uncertainties in obstacle complexities, partially observation of robots, and policy implementation from simulations to the real world. This paper presents a cooperative approach to address the multi-robot navigation problem (MRNP) under dynamic environments using a deep reinforcement learning (DRL) framework, which can help multiple robots jointly achieve optimal paths despite a certain degree of obstacle complexities. The novelty of this work includes threefold: (1) developing a cooperative architecture that robots can exchange information with each other to select the optimal target locations; (2) developing a DRL based framework which can learn a navigation policy to generate the optimal paths for multiple robots; (3) developing a training mechanism based on dynamics randomization which can make the policy generalized and achieve the maximum performance in the real world. The method is tested with Gazebo simulations and 4 differential drive robots. Both simulation and experiment results validate the superior performance of the proposed method in terms of success rate and travel time when compared with the other state-of-art technologies.


Title: Wasserstein Distributionally Robust Motion Planning and Control with Safety Constraints Using Conditional Value-at-Risk
Key Words: collision avoidance  decision making  mobile robots  optimisation  path planning  predictive control  probability  robust control  Wasserstein distributionally robust motion planning  safety constraints  conditional value-at-risk  optimization-based decision-making tool  safe motion planning  pre-specified threshold  probability distribution  obstacles  Wasserstein ball  available empirical distribution  out-of-sample performance guarantee  risk constraint  computationally tractable method  distributionally robust model predictive control problem  distributionally robust method  Robustness  Safety  Planning  Robots  Trajectory  Probability distribution  Collision avoidance 
Abstract: In this paper, we propose an optimization-based decision-making tool for safe motion planning and control in an environment with randomly moving obstacles. The unique feature of the proposed method is that it limits the risk of unsafety by a pre-specified threshold even when the true probability distribution of the obstacles' movements deviates, within a Wasserstein ball, from an available empirical distribution. Another advantage is that it provides a probabilistic out-of-sample performance guarantee of the risk constraint. To develop a computationally tractable method for solving the distributionally robust model predictive control problem, we propose a set of reformulation procedures using (i) the Kantorovich duality principle, (ii) the extremal representation of conditional value-at-risk, and (iii) a geometric expression of the distance to the union of halfspaces. The performance and utility of this distributionally robust method are demonstrated through simulations using a 12D quadrotor model in a 3D environment.


Title: Beyond Top-Grasps Through Scene Completion
Key Words: cameras  end effectors  grippers  image colour analysis  image sensors  path planning  position control  robot vision  camera images  grasp success rate  simulated images  top-grasps  scene completion  six-degree-of-freedom grasps  simulated viewpoints  generation method  fully convolutional grasp quality CNN  end-to-end grasp  Shape  Cameras  Grasping  Planning  Robot vision systems  Pipelines 
Abstract: Current end-to-end grasp planning methods propose grasps in the order of seconds that attain high grasp success rates on a diverse set of objects, but often by constraining the workspace to top-grasps. In this work, we present a method that allows end-to-end top-grasp planning methods to generate full six-degree-of-freedom grasps using a single RGBD view as input. This is achieved by estimating the complete shape of the object to be grasped, then simulating different viewpoints of the object, passing the simulated viewpoints to an end-to-end grasp generation method, and finally executing the overall best grasp. The method was experimentally validated on a Franka Emika Panda by comparing 429 grasps generated by the state-of-the-art Fully Convolutional Grasp Quality CNN, both on simulated and real camera images. The results show statistically significant improvements in terms of grasp success rate when using simulated images over real camera images, especially when the real camera viewpoint is angled. Code and video are available at https://irobotics.aalto.fi/beyond-topgrasps-through-scene-completion/.


Title: Schmidt-EKF-based Visual-Inertial Moving Object Tracking
Key Words: image motion analysis  image representation  Kalman filters  object tracking  pose estimation  robot vision  target tracking  tracking sensor  target motion model  Schmidt-EKF-based visual-inertial moving object tracking  tightly-coupled estimation  visual-inertial localization  joint estimation system  Schmidt-Kalman Filter  ego-motion accuracy degradation  robot-centric representation  object pose tracking  Target tracking  Robot sensing systems  Estimation  Three-dimensional displays  Dynamics 
Abstract: In this paper we investigate the effect of tightly-coupled estimation on the performance of visual-inertial localization and dynamic object pose tracking. In particular, we show that while a joint estimation system outperforms its decoupled counterpart when given a "proper" model for the target's motion, inconsistent modeling, such as choosing improper levels for the target's propagation noises, can actually lead to a degradation in ego-motion accuracy. To address the realistic scenario where a good prior knowledge of the target's motion model is not available, we design a new system based on the Schmidt-Kalman Filter (SKF), in which target measurements do not update the navigation states, however all correlations are still properly tracked. This allows for both consistent modeling of the target errors and the ability to update target estimates whenever the tracking sensor receives non-target data such as bearing measurements to static, 3D environmental features. We show in extensive simulation that this system, along with a robot-centric representation of the target, leads to robust estimation performance even in the presence of an inconsistent target motion model. Finally, the system is validated in a real-world experiment, and is shown to offer accurate localization and object pose tracking performance.


Title: Learning View and Target Invariant Visual Servoing for Navigation
Key Words: convolutional neural nets  feedback  learning (artificial intelligence)  mobile robots  path planning  robot vision  visual servoing  deep reinforcement learning  mobile robot navigation  deep convolutional network controller  viewpoint invariant visual servoing  target invariant visual servoing  feedback control error  Visual servoing  Navigation  Visualization  Feature extraction  Task analysis  Semantics  Cameras 
Abstract: The advances in deep reinforcement learning recently revived interest in data-driven learning based approaches to navigation. In this paper we propose to learn viewpoint invariant and target invariant visual servoing for local mobile robot navigation; given an initial view and the goal view or an image of a target, we train deep convolutional network controller to reach the desired goal. We present a new architecture for this task which rests on the ability of establishing correspondences between the initial and goal view and novel reward structure motivated by the traditional feedback control error. The advantage of the proposed model is that it does not require calibration and depth information and achieves robust visual servoing in a variety of environments and targets without any parameter fine tuning. We present comprehensive evaluation of the approach and comparison with other deep learning architectures as well as classical visual servoing methods in visually realistic simulation environment [1]. The presented model overcomes the brittleness of classical visual servoing based methods and achieves significantly higher generalization capability compared to the previous learning approaches.


Title: Zero-shot Imitation Learning from Demonstrations for Legged Robot Visual Navigation
Key Words: graphical user interfaces  humanoid robots  human-robot interaction  learning (artificial intelligence)  mobile robots  path planning  robot vision  cost-effective data collection  third-person demonstrations  camera perspectives  perspective-invariant state features  model-based imitation learning approach  action-labeled human demonstrations  effective policy  zero-shot imitation  legged robot visual navigation  training effective visual navigation policies  expert demonstrations  goal-driven visual navigation policy  high-quality navigation  Feature extraction  Navigation  Legged locomotion  Visualization  Training 
Abstract: Imitation learning is a popular approach for training effective visual navigation policies. However, collecting expert demonstrations for legged robots is challenging as these robots can be hard to control, move slowly, and cannot operate continuously for long periods of time. In this work, we propose a zero-shot imitation learning framework for training a goal-driven visual navigation policy on a legged robot from human demonstrations (third-person perspective), allowing for high-quality navigation and cost-effective data collection. However, imitation learning from third-person demonstrations raises unique challenges. First, these demonstrations are captured from different camera perspectives, which we address via a feature disentanglement network (FDN) that extracts perspective-invariant state features. Second, as transition dynamics vary between systems, we reconstruct missing action labels by either building an inverse model of the robot's dynamics in the feature space and applying it to the human demonstrations or developing a Graphic User Interface (GUI) to label human demonstrations. To train a navigation policy we use a model-based imitation learning approach with FDN and action-labeled human demonstrations. We show that our framework can learn an effective policy for a legged robot, Laikago, from human demonstrations in both simulated and real-world environments. Our approach is zero-shot as the robot never navigates the same paths during training as those at testing time. We justify our framework by performing a comparative study.


Title: Knowledge-Guided Reinforcement Learning Control for Robotic Lower Limb Prosthesis
Key Words: artificial limbs  biomechanics  gait analysis  learning (artificial intelligence)  medical robotics  neurophysiology  patient rehabilitation  knowledge transfer  control tuning performance  amputee subject  AB subjects  transfer knowledge  data requirements  RL controller  robotic prosthetic limb  control method  knowledge-guided Q-learning  RL agents learn  controlled prosthesis  prosthesis control  prosthesis device  trans-femoral amputees  passive prostheses  lost functions  robotic lower limb prosthesis  guided reinforcement learning control  Prosthetics  Task analysis  Impedance  Knee  Legged locomotion  Tuning 
Abstract: Robotic prostheses provide new opportunities to better restore lost functions than passive prostheses for trans-femoral amputees. But controlling a prosthesis device automatically for individual users in different task environments is an unsolved problem. Reinforcement learning (RL) is a naturally promising tool. For prosthesis control with a user in the loop, it is desirable that the controlled prosthesis can adapt to different task environments as quickly and smoothly as possible. However, most RL agents learn or relearn from scratch when the environment changes. To address this issue, we propose the knowledge-guided Q-learning (KG-QL) control method as a principled way for the problem. In this report, we collected and used data from two able-bodied (AB) subjects wearing a RL controlled robotic prosthetic limb walking on level ground. Our ultimate goal is to build an efficient RL controller with reduced time and data requirements and transfer knowledge from AB subjects to amputee subjects. Toward this goal, we demonstrate its feasibility by employing OpenSim, a well-established human locomotion simulator. Our results show the OpenSim simulated amputee subject improved control tuning performance over learning from scratch by utilizing knowledge transfer from AB subjects. Also in this paper, we will explore the possibility of information transfer from AB subjects to help tuning for the amputee subjects.


Title: A Novel Portable Lower Limb Exoskeleton for Gravity Compensation during Walking
Key Words: gait analysis  gears  handicapped aids  man-machine systems  medical robotics  motion control  patient rehabilitation  robot kinematics  springs (mechanical)  torque  gravity compensation  walking assistance  spring mechanisms  hip  knee joints  gravity balancing  human leg  mating gears  tension force  springs  safety  user acceptance  design principle  limb joints  single leg exoskeleton  portable passive lower limb exoskeleton  driving torques  Springs  Exoskeletons  Gravity  Legged locomotion  Gears  Potential energy  Hip 
Abstract: This paper presents a novel portable passive lower limb exoskeleton for walking assistance. The exoskeleton is designed with built-in spring mechanisms at the hip and knee joints to realize gravity balancing of the human leg. A pair of mating gears is used to convert the tension force from the built-in springs into balancing torques at hip and knee joints for overcoming the influence of gravity. Such a design makes the exoskeleton has a compact layout with small protrusion, which improves its safety and user acceptance. In this paper, the design principle of gravity balancing is described. Simulation results show a significant reduction of driving torques at the limb joints. A prototype of single leg exoskeleton has been constructed and preliminary test results show the effectiveness of the exoskeleton.


Title: Steerable Burrowing Robot: Design, Modeling and Experiments
Key Words: drag  impact (mechanical)  mobile robots  numerical analysis  robot dynamics  vehicle dynamics  thrusting mechanism  depth dependent model  steerable burrowing robot  vibro-impact mechanism  rotating bevel-tip head  nonholonomic model  steering mechanism  hybrid dynamics model  S-shaped trajectory  Robot kinematics  Needles  Numerical models  Solid modeling  Trajectory  Springs 
Abstract: This paper investigates a burrowing robot that can maneuver and steer while being submerged in a granular medium. The robot locomotes using an internal vibro-impact mechanism and steers using a rotating bevel-tip head. We formulate and investigate a non-holonomic model for the steering mechanism and a hybrid dynamics model for the thrusting mechanism. We perform a numerical analysis of the dynamics of the robot's thrusting mechanism using a simplified, orientation and depth dependent model for the drag forces acting on the robot. We first show, in simulation, that by carefully tuning various control input parameters, the thrusting mechanism can drive the robot both forward and backward. We present several experiments designed to evaluate and verify the simulative results using a proof-of-concept robot. We show that different input amplitudes indeed affect the direction of motion, as suggested by the simulation. We further demonstrate the ability of the robot to perform a simple S-shaped trajectory. These experiments demonstrate the feasibility of the robot's design and fidelity of the model.


Title: Stiffness optimization of a cable driven parallel robot for additive manufacturing
Key Words: cables (mechanical)  industrial robots  optimisation  position control  rigidity  three-dimensional printing  vibration control  stiffness optimization  cable driven parallel robot  additive manufacturing  anchor points  robot stiffness  tool path  platform rigidity  CDPR  3D printing  vibration modes 
Abstract: In this paper, the optimization of the anchor points of a cable driven parallel robot (CDPR) for 3D printing is proposed in order to maximize the rigidity. Indeed, in the context of 3D printing, robot stiffness should guarantee a high level of tool path following accuracy. The optimized platform showed a rigidity improvement in simulation, but also experimentally with a first study of vibration modes. In the same time, this study illustrates the influence of preload in cables on the platform rigidity.


Title: Navigation in the Presence of Obstacles for an Agile Autonomous Underwater Vehicle
Key Words: autonomous underwater vehicles  collision avoidance  feature extraction  mobile robots  navigation  optimisation  robot vision  stereo image processing  fly-overs  AUV  cluttered space  navigation framework  sampling-based correction procedure  obstacles detection  real-time 3D autonomous navigation  agile autonomous underwater vehicle  Trajopt  3D path-optimization planning  visual features detection  Planning  Three-dimensional displays  Navigation  Optimization  Robots  Trajectory  Cameras 
Abstract: Navigation underwater traditionally is done by keeping a safe distance from obstacles, resulting in "fly-overs" of the area of interest. Movement of an autonomous underwater vehicle (AUV) through a cluttered space, such as a shipwreck or a decorated cave, is an extremely challenging problem that has not been addressed in the past. This paper proposes a novel navigation framework utilizing an enhanced version of Trajopt for fast 3D path-optimization planning for AUVs. A sampling-based correction procedure ensures that the planning is not constrained by local minima, enabling navigation through narrow spaces. Two different modalities are proposed: planning with a known map results in efficient trajectories through cluttered spaces; operating in an unknown environment utilizes the point cloud from the visual features detected to navigate efficiently while avoiding the detected obstacles. The proposed approach is rigorously tested, both on simulation and in-pool experiments, proven to be fast enough to enable safe real-time 3D autonomous navigation for an AUV.


Title: Nonlinear Synchronization Control for Short-Range Mobile Sensors Drifting in Geophysical Flows
Key Words: actuators  mobile radio  oceanographic techniques  synchronisation  telecommunication control  wireless sensor networks  short-range mobile sensors drifting  geophysical flows  ocean monitoring applications  minimal actuation capabilities  active drifters  gyre flows  data exchange  nonlinear synchronization control strategy  rendezvous regions  large-scale mobile sensor networks  numerical simulations  small-scale experiments  Synchronization  Sensors  Vehicle dynamics  Orbits  Robots  Oscillators  Dynamics 
Abstract: This paper presents a synchronization controller for mobile sensors that are minimally actuated and can only communicate with each other over a very short range. This work is motivated by ocean monitoring applications where large-scale sensor networks consisting of drifters with minimal actuation capabilities, i.e., active drifters, are employed. We assume drifters are tasked to monitor regions consisting of gyre flows where their trajectories are periodic. As drifters in neighboring regions move into each other's proximity, it presents an opportunity for data exchange and synchronization to ensure future rendezvous. We present a nonlinear synchronization control strategy to ensure that drifters will periodically rendezvous and maximize the time they are in their rendezvous regions. Numerical simulations and small-scale experiments validate the efficacy of the control strategy and hint at extensions to large-scale mobile sensor networks.


Title: Real-time Simulation of Non-Deformable Continuous Tracks with Explicit Consideration of Friction and Grouser Geometry
Key Words: friction  mobile robots  motion control  tracked vehicles  trajectory control  velocity control  nondeformable continuous tracks  grouser geometry  real-time simulation  circular segments  robot body  segment link  track rotation  friction  rough terrain  track trajectory  velocity constraints  tracked vehicles  Robots  Trajectory  Tracking  Friction  Collision avoidance  Real-time systems  Wheels 
Abstract: In this study, we developed a real-time simulation method for non-deformable continuous tracks having grousers for rough terrain by explicitly considering the collision and friction between the tracks and the ground. In the proposed simulation method, an arbitrary trajectory of a track is represented with multiple linear and circular segments, each of which is a link connected to a robot body. The proposed method sets velocity constraints between each segment link and the robot body, to simulate the track rotation around the body. To maintain the shape of a track, it also restores the positions of the segment links when required. Experimental comparisons with other existing real-time simulation methods demonstrated that while the proposed method considered the grousers and the friction with the ground, it was comparable to them in terms of the computational speed. Experimental comparison of the simulations based on the proposed method and a physical robot exhibited that the former was comparable to the precise motion of the robot on rough or uneven terrain.


Title: Closed-Loop Benchmarking of Stereo Visual-Inertial SLAM Systems: Understanding the Impact of Drift and Latency on Tracking Accuracy
Key Words: closed loop systems  Global Positioning System  mobile robots  navigation  robot vision  SLAM (robots)  stereo image processing  tracking  representative state-of-the-art visual-inertial SLAM systems  visual estimation module  stereo visual-inertial SLAM systems  open-loop analysis  closed-loop navigation tasks  accurate trajectory tracking  visualinertial SLAM systems  closed-loop benchmarking simulation  visual-inertial estimation  trajectory tracking performance  Visualization  Navigation  Simultaneous localization and mapping  Benchmark testing  Estimation 
Abstract: Visual-inertial SLAM is essential for robot navigation in GPS-denied environments, e.g. indoor, underground. Conventionally, the performance of visual-inertial SLAM is evaluated with open-loop analysis, with a focus on the drift level of SLAM systems. In this paper, we raise the question on the importance of visual estimation latency in closed-loop navigation tasks, such as accurate trajectory tracking. To understand the impact of both drift and latency on visualinertial SLAM systems, a closed-loop benchmarking simulation is conducted, where a robot is commanded to follow a desired trajectory using the feedback from visual-inertial estimation. By extensively evaluating the trajectory tracking performance of representative state-of-the-art visual-inertial SLAM systems, we reveal the importance of latency reduction in visual estimation module of these systems. The findings suggest directions of future improvements for visual-inertial SLAM.


Title: Learning error models for graph SLAM
Key Words: autonomous aerial vehicles  graph theory  mobile robots  path planning  robot vision  SLAM (robots)  resistance distance  covisibility graph  simulated UAV coverage path  uncertainty models  monocular graph SLAM  topological features  error model learning  UAV coverage path planning trajectories  Simultaneous localization and mapping  Resistance  Uncertainty  Computational modeling  Computer architecture  Predictive models  Cameras 
Abstract: Following recent developments, this paper investigates the possibility to predict uncertainty models for monocular graph SLAM using topological features of the problem. An architecture to learn relative (i.e. inter-keyframe) uncertainty models using the resistance distance in the covisibility graph is presented. The proposed architecture is applied to simulated UAV coverage path planning trajectories and an analysis of the approaches strengths and shortcomings is provided.


Title: SMArT: Training Shallow Memory-aware Transformers for Robotic Explainability
Key Words: human-robot interaction  natural language processing  robot vision  video signal processing  video captioning  computational requirements  fully-attentive captioning algorithm  language generation  transformer layers  decoding stages  image regions  caption quality  autonomous agents  domestic robots  SMArT  robotic explainability  natural language explanations  visual perception  shallow memory-aware transformer training  memory-aware encoding  image captioning  image captioning  Decoding  Computational modeling  Visualization  Magnetic heads  Robots  Natural languages  Encoding 
Abstract: The ability to generate natural language explanations conditioned on the visual perception is a crucial step towards autonomous agents which can explain themselves and communicate with humans. While the research efforts in image and video captioning are giving promising results, this is often done at the expense of the computational requirements of the approaches, limiting their applicability to real contexts. In this paper, we propose a fully-attentive captioning algorithm which can provide state-of-the-art performances on language generation while restricting its computational demands. Our model is inspired by the Transformer model and employs only two Transformer layers in the encoding and decoding stages. Further, it incorporates a novel memory-aware encoding of image regions. Experiments demonstrate that our approach achieves competitive results in terms of caption quality while featuring reduced computational demands. Further, to evaluate its applicability on autonomous agents, we conduct experiments on simulated scenes taken from the perspective of domestic robots.


Title: Efficient Bimanual Manipulation Using Learned Task Schemas
Key Words: control engineering computing  learning (artificial intelligence)  manipulators  parameterizations  sparse-reward tasks  robotic bimanual manipulation tasks  parameterized skills  state-independent task schema  model-free reinforcement learning  robotic systems  Task analysis  Learning (artificial intelligence)  Neural networks  Force  Geometry  End effectors 
Abstract: We address the problem of effectively composing skills to solve sparse-reward tasks in the real world. Given a set of parameterized skills (such as exerting a force or doing a top grasp at a location), our goal is to learn policies that invoke these skills to efficiently solve such tasks. Our insight is that for many tasks, the learning process can be decomposed into learning a state-independent task schema (a sequence of skills to execute) and a policy to choose the parameterizations of the skills in a state-dependent manner. For such tasks, we show that explicitly modeling the schema's state-independence can yield significant improvements in sample efficiency for model-free reinforcement learning algorithms. Furthermore, these schemas can be transferred to solve related tasks, by simply re-learning the parameterizations with which the skills are invoked. We find that doing so enables learning to solve sparse-reward tasks on real-world robotic systems very efficiently. We validate our approach experimentally over a suite of robotic bimanual manipulation tasks, both in simulation and on real hardware. See videos at http://tinyurl.com/chitnis-schema.


Title: A Fast Marching Gradient Sampling Strategy for Motion Planning using an Informed Certificate Set
Key Words: collision avoidance  gradient methods  graph theory  mobile robots  path planning  sampling methods  convergence speed  safety certificate algorithms  fast marching gradient sampling strategy  sampling-based motion planning algorithms  marching seed  goal set  informed certificate set  planning space  RRT* algorithms  Planning  Safety  Convergence  Algorithms  Robots  Data structures  Collision avoidance 
Abstract: We present a novel fast marching gradient sampling strategy to accelerate the convergence speed of sampling-based motion planning algorithms. This strategy is based on an informed certificate set which consists of the robot states with exact collision status as well as the minimum distance and the gradient to the nearest obstacle. The informed certificate set covers almost the whole planning space such that it contains rich information for the planner. The best quality point in this set is selected as the marching seed to guide the search graph move steadily to the goal set. The distance and gradient information of the marching seed helps to generate a new sample with almost sure collision status. When a feasible solution has been found, this set can construct the restricted subset that can improve current path quality. This marching gradient sampling strategy is applied to the RRT and RRT* algorithms. Simulation experiments demonstrate that the convergence speed to a feasible solution or to the optimal solution is almost twice faster than that of the safety certificate algorithms.


Title: Privacy-Aware UAV Flights through Self-Configuring Motion Planning
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  data privacy  decision making  mobile robots  motion control  privacy-aware UAV flights  unmanned aerial vehicle  uncertain obstacles  motion planning algorithms  privacy-preserving requirements  privacy risk aware motion planning method  privacy-sensitive sensor  safety  energy hard constraints  dynamically detected restricted areas  decision making method  test flights  DJI Matrice 100 UAV  self-configuring motion planning  Privacy  Planning  Cameras  Sensors  Trajectory  Safety  Unmanned aerial vehicles 
Abstract: During flights, an unmanned aerial vehicle (UAV) may not be allowed to move across certain areas due to soft constraints such as privacy restrictions. Current methods on self-adaption focus mostly on motion planning such that the trajectory does not trespass predetermined restricted areas. When the environment is cluttered with uncertain obstacles, however, these motion planning algorithms are not flexible enough to find a trajectory that satisfies additional privacy-preserving requirements within a tight time budget during the flights. In this paper, we propose a privacy risk aware motion planning method through the reconfiguration of privacy-sensitive sensors. It minimises environmental impact by re-configuring the sensor during flight, while still guaranteeing the safety and energy hard constraints such as collision avoidance and timeliness. First, we formulate a model for assessing privacy risks of dynamically detected restricted areas. In case the UAV cannot find a feasible solution to satisfy both hard and soft constraints from the current configuration, our decision making method can then produce an optimal reconfiguration of the privacy-sensitive sensor with a more efficient trajectory. We evaluate the proposal through various simulations with different settings in a virtual environment and also validate the approach through real test flights on DJI Matrice 100 UAV.


Title: Tuning-Free Contact-Implicit Trajectory Optimization
Key Words: humanoid robots  manipulators  mobile robots  tuning-free contact-implicit trajectory optimization  contact-implicit trajectory optimization framework  contact-interaction trajectories  robot architectures  trivial initial guess  parameter tuning  relaxed contact model  automatic penalty adjustment loop  contact information  mobile robot  nonprehensile manipulation  7-DOF arm  planar locomotion  Robots  Task analysis  Trajectory optimization  Tuning  Computational modeling 
Abstract: We present a contact-implicit trajectory optimization framework that can plan contact-interaction trajectories for different robot architectures and tasks using a trivial initial guess and without requiring any parameter tuning. This is achieved by using a relaxed contact model along with an automatic penalty adjustment loop for suppressing the relaxation. Moreover, the structure of the problem enables us to exploit the contact information implied by the use of relaxation in the previous iteration, such that the solution is explicitly improved with little computational overhead. We test the proposed approach in simulation experiments for non-prehensile manipulation using a 7-DOF arm and a mobile robot and for planar locomotion using a humanoid-like robot in zero gravity. The results demonstrate that our method provides an out-of-the-box solution with good performance for a wide range of applications.


Title: Learning-based Path Planning for Autonomous Exploration of Subterranean Environments
Key Words: autonomous aerial vehicles  graph theory  learning by example  mobile robots  optical radar  path planning  robot programming  sampled data systems  tunnels  autonomous exploration  subterranean environments  aerial robots  training expert  imitation learning  underground mine drifts  tunnels  graph based path planner  learning based path planning  LiDAR  range data sampling  Robot sensing systems  Path planning  Training  Training data  Planning  Robot kinematics 
Abstract: In this work we present a new methodology on learning-based path planning for autonomous exploration of subterranean environments using aerial robots. Utilizing a recently proposed graph-based path planner as a "training expert" and following an approach relying on the concepts of imitation learning, we derive a trained policy capable of guiding the robot to autonomously explore underground mine drifts and tunnels. The algorithm utilizes only a short window of range data sampled from the onboard LiDAR and achieves an exploratory behavior similar to that of the training expert with a more than an order of magnitude reduction in computational cost, while simultaneously relaxing the need to maintain a consistent and online reconstructed map of the environment. The trained path planning policy is extensively evaluated both in simulation and experimentally within field tests relating to the autonomous exploration of underground mines.


Title: Cooperative Perception and Localization for Cooperative Driving
Key Words: cooperative systems  Kalman filters  location based services  mobile robots  multi-robot systems  nonlinear filters  road vehicles  sensor fusion  vehicle sensors  extended Kalman filters  fully autonomous road vehicles  cooperative driving  cooperative perception  high fidelity sensors  low fidelity sensors  localization information  Sensor systems  Time measurement  Roads  Fuses  Current measurement  Bandwidth 
Abstract: Fully autonomous vehicles are expected to share the road with less advanced vehicles for a significant period of time. Furthermore, an increasing number of vehicles on the road are equipped with a variety of low-fidelity sensors which provide some perception and localization data, but not at a high enough quality for full autonomy. In this paper, we develop a perception and localization system that allows a vehicle with low-fidelity sensors to incorporate high-fidelity observations from a vehicle in front of it, allowing both vehicles to operate with full autonomy. The resulting system generates perception and localization information that is both low-noise in regions covered by high-fidelity sensors and avoids false negatives in areas only observed by low-fidelity sensors, while dealing with latency and dropout of the communication link between the two vehicles. At its core, the system uses a set of Extended Kalman filters which incorporate observations from both vehicles' sensors and extrapolate them using information about the road geometry. The perception and localization algorithms are evaluated both in simulation and on real vehicles as part of a full cooperative driving system.


Title: Context-Aware Task Execution Using Apprenticeship Learning
Key Words: human-robot interaction  learning (artificial intelligence)  service robots  ubiquitous computing  demonstrated motion  learned policy  perceived behaviour  context-aware task execution  apprenticeship learning  assistive service robots  human-oriented tasks  task parameters  optimal behaviour  robot-to-human object hand-over  reinforcement learning  demonstrator  contextualized variants  demonstrated action  dynamic movement primitives  compact motion representations  model-based C-REPS algorithm  hand-over position  context variables  simulated task executions  evaluating emergent behaviours  context-aware action generalization  Robots  Task analysis  Trajectory  Context modeling  Encoding  Adaptation models  Learning (artificial intelligence) 
Abstract: An essential measure of autonomy in assistive service robots is adaptivity to the various contexts of human-oriented tasks, which are subject to subtle variations in task parameters that determine optimal behaviour. In this work, we propose an apprenticeship learning approach to achieving context-aware action generalization on the task of robot-to-human object hand-over. The procedure combines learning from demonstration and reinforcement learning: a robot first imitates a demonstrator's execution of the task and then learns contextualized variants of the demonstrated action through experience. We use dynamic movement primitives as compact motion representations, and a model-based C-REPS algorithm for learning policies that can specify hand-over position, conditioned on context variables. Policies are learned using simulated task executions, before transferring them to the robot and evaluating emergent behaviours. We additionally conduct a user study involving participants assuming different postures and receiving an object from a robot, which executes hand-overs by either imitating a demonstrated motion, or adapting its motion to hand-over positions suggested by the learned policy. The results confirm the hypothesized improvements in the robot's perceived behaviour when it is context-aware and adaptive, and provide useful insights that can inform future developments.


Title: Feedback Linearization for Uncertain Systems via Reinforcement Learning
Key Words: approximation theory  continuous time systems  control system synthesis  feedback  function approximation  learning (artificial intelligence)  linearisation techniques  nonlinear control systems  optimisation  uncertain systems  model-free policy optimization techniques  feedback linearization  nonlinear control  nonlinear plant  feedback controller  linear control techniques  exact linearizing controllers  learned linearizing controller  model-free policy optimization algorithms  Feedback linearization  Conferences  Automation  Uncertain systems  Learning (artificial intelligence)  Control design  Nonlinear systems 
Abstract: We present a novel approach to control design for nonlinear systems which leverages model-free policy optimization techniques to learn a linearizing controller for a physical plant with unknown dynamics. Feedback linearization is a technique from nonlinear control which renders the input-output dynamics of a nonlinear plant linear under application of an appropriate feedback controller. Once a linearizing controller has been constructed, desired output trajectories for the nonlinear plant can be tracked using a variety of linear control techniques. However, the calculation of a linearizing controller requires a precise dynamics model for the system. As a result, model-based approaches for learning exact linearizing controllers generally require a simple, highly structured model of the system with easily identifiable parameters. In contrast, the model-free approach presented in this paper is able to approximate the linearizing controller for the plant using general function approximation architectures. Specifically, we formulate a continuous-time optimization problem over the parameters of a learned linearizing controller whose optima are the set of parameters which best linearize the plant. We derive conditions under which the learning problem is (strongly) convex and provide guarantees which ensure the true linearizing controller for the plant is recovered. We then discuss how model-free policy optimization algorithms can be used to solve a discrete-time approximation to the problem using data collected from the real-world plant. The utility of the framework is demonstrated in simulation and on a real-world robotic platform.


Title: On the Hardware Feasibility of Nonlinear Trajectory Optimization for Legged Locomotion based on a Simplified Dynamics
Key Words: hydraulic actuators  legged locomotion  motion control  path planning  position control  robot dynamics  HyQ robot  Hydraulically actuated Quadruped robot  simplified nonlinear nonconvex trajectory optimization  single rigid body dynamics-based trajectory optimizer  leg collision  leg model  joint positions  admissible contact forces  joint-torque limits  challenging terrain  robust motions  feasibility constraints  motion planning  computational efficiency  simplified dynamics  legged locomotion  nonlinear trajectory optimization  hardware feasibility  Legged locomotion  Foot  Collision avoidance  Force  Trajectory  Aerodynamics 
Abstract: Simplified models are useful to increase the computational efficiency of a motion planning algorithm, but their lack of accuracy have to be managed. We propose two feasibility constraints to be included in a Single Rigid Body Dynamics-based trajectory optimizer in order to obtain robust motions in challenging terrain. The first one finds an approximate relationship between joint-torque limits and admissible contact forces, without requiring the joint positions. The second one proposes a leg model to prevent leg collision with the environment. Such constraints have been included in a simplified nonlinear non-convex trajectory optimization problem. We demonstrate the feasibility of the resulting motion plans both in simulation and on the Hydraulically actuated Quadruped (HyQ) robot, considering experiments on an irregular terrain.


Title: Agile Legged-Wheeled Reconfigurable Navigation Planner Applied on the CENTAURO Robot
Key Words: legged locomotion  motion control  navigation  path planning  search problems  CENTAURO robot  agile legged wheeled reconfigurable navigation planner  hybrid legged-wheeled robots  Theta* based planner  trapezium-like search  Robot kinematics  Mobile robots  Planning  Wheels  Navigation  Collision avoidance 
Abstract: Hybrid legged-wheeled robots such as the CEN-TAURO, are capable of varying their footprint polygon to carry out various agile motions. This property can be advantageous for wheeled-only planning in cluttered spaces, which is our focus. In this paper, we present an improved algorithm that builds upon our previously introduced preliminary footprint varying A* planner, which was based on the rectangular symmetry of the foot support polygon. In particular, we introduce a Theta* based planner with trapezium-like search, which aims to further reduce the limitations imposed upon the wheeled-only navigation of the CENTAURO robot by the low-dimensional search space, maintaining the real-time computational efficiency. The method is tested on the simulated and real full-size CENTAURO robot in cluttered environments.


Title: Efficient Iterative Linear-Quadratic Approximations for Nonlinear Multi-Player General-Sum Differential Games
Key Words: approximation theory  decision making  differential games  iterative methods  linear quadratic control  multi-agent systems  multi-robot systems  nonlinear control systems  iterative linear-quadratic regulator  linear dynamics  quadratic costs  linear-quadratic games  complex interactive behavior  efficient iterative linear-quadratic approximations  nonlinear multiplayer general-sum differential games  robotics  multiple decision making agents  expressive theoretical framework  multiagent problems  numerical solution techniques  state dimension  single agent optimal control problem  ILQR  repeated approximations  three-player 14-state simulated intersection problem  hardware collision-avoidance test  time 0.25 s  time 50.0 ms  Games  Heuristic algorithms  Approximation algorithms  Optimal control  Iterative methods  Trajectory  Automobiles 
Abstract: Many problems in robotics involve multiple decision making agents. To operate efficiently in such settings, a robot must reason about the impact of its decisions on the behavior of other agents. Differential games offer an expressive theoretical framework for formulating these types of multi-agent problems. Unfortunately, most numerical solution techniques scale poorly with state dimension and are rarely used in real-time applications. For this reason, it is common to predict the future decisions of other agents and solve the resulting decoupled, i.e., single-agent, optimal control problem. This decoupling neglects the underlying interactive nature of the problem; however, efficient solution techniques do exist for broad classes of optimal control problems. We take inspiration from one such technique, the iterative linear-quadratic regulator (ILQR), which solves repeated approximations with linear dynamics and quadratic costs. Similarly, our proposed algorithm solves repeated linear-quadratic games. We experimentally benchmark our algorithm in several examples with a variety of initial conditions and show that the resulting strategies exhibit complex interactive behavior. Our results indicate that our algorithm converges reliably and runs in real-time. In a three-player, 14-state simulated intersection problem, our algorithm initially converges in <; 0.25 s. Receding horizon invocations converge in <; 50 ms in a hardware collision-avoidance test.


Title: Path-Following Model Predictive Control of Ballbots
Key Words: mobile robots  predictive control  robot dynamics  model predictive control  path-following tasks  dynamically unstable mobile robots  single ball  simplied version  physical ballbot system  high fidelity model  online implementation  quaternion-based model  Robots  Solid modeling  Friction  Quaternions  Planning  Acceleration  Trajectory 
Abstract: This paper introduces a novel approach for model predictive control of ballbots for path-following tasks. Ballbots are dynamically unstable mobile robots which are designed to balance on a single ball. The model presented in this paper is a simplied version of a full quaternion-based model of ballbots' underactuated dynamics which is suited for online implementation. Furthermore, the approach is extended to handle nearby obstacles directly in the MPC formulation. The presented controller is validated through simulation on a high fidelity model as well as through real-world experiments on a physical ballbot system.


Title: Learning to Generate 6-DoF Grasp Poses with Reachability Awareness
Key Words: convolutional neural nets  learning systems  manipulators  neurocontrollers  stability  3D CNN  6-DoF grasp poses  reachability awareness  voxel-based deep 3D convolutional neural network  reachability predictor  robot  grasp pose stability  Grasping  Three-dimensional displays  Robot kinematics  Planning  Measurement  Data models  Grasping  Deep Learning in Robotics and Automation  Perception for Grasping and Manipulation 
Abstract: Motivated by the stringent requirements of unstructured real-world where a plethora of unknown objects reside in arbitrary locations of the surface, we propose a voxel-based deep 3D Convolutional Neural Network (3D CNN) that generates feasible 6-DoF grasp poses in unrestricted workspace with reachability awareness. Unlike the majority of works that predict if a proposed grasp pose within the restricted workspace will be successful solely based on grasp pose stability, our approach further learns a reachability predictor that evaluates if the grasp pose is reachable or not from robot's own experience. To avoid the laborious real training data collection, we exploit the power of simulation to train our networks on a large-scale synthetic dataset. This work is an early attempt that simultaneously learns grasping reachability while proposing feasible grasp poses with 3D CNN. Experimental results in both simulation and real-world demonstrate that our approach outperforms several other methods and achieves 82.5% grasping success rate on unknown objects.


Title: Hierarchical 6-DoF Grasping with Approaching Direction Selection
Key Words: convolutional neural nets  entropy  geometry  grippers  hierarchical systems  iterative methods  learning systems  neurocontrollers  optimisation  position control  cluttered objects  cross entropy method  iterative direction optimization  derivative-free optimization  geometry-based prior  point clouds  input grasp representations  robot arm  detection problem  hierarchical approach  robot grasping  hierarchical 6-DoF grasping  surface normal directions  approaching direction selection method  grasp quality  fully convolutional grasp quality network  Grasping  Three-dimensional displays  Grippers  Service robots  Manipulators  Geometry 
Abstract: In this paper, we tackle the problem of 6-DoF grasp detection which is crucial for robot grasping in cluttered real-world scenes. Unlike existing approaches which synthesize 6-DoF grasp data sets and train grasp quality networks with input grasp representations based on point clouds, we rather take a novel hierarchical approach which does not use any 6-DoF grasp data. We cast the 6-DoF grasp detection problem as a robot arm approaching direction selection problem using the existing 4-DoF grasp detection algorithm, by exploiting a fully convolutional grasp quality network for evaluating the quality of an approaching direction. To select the best approaching direction with the highest grasp quality, we propose an approaching direction selection method which leverages a geometry-based prior and a derivative-free optimization method. Specifically, we optimize the direction iteratively using the cross entropy method with initial samples of surface normal directions. Our algorithm efficiently finds diverse 6-DoF grasps by the novel way of evaluating and optimizing approaching directions. We validate that the proposed method outperforms other selection methods in scenarios with cluttered objects in a physics-based simulator. Finally, we show that our method outperforms the state-of-the-art grasp detection method in real-world experiments with robots.


Title: The OmniScape Dataset
Key Words: cameras  image segmentation  motorcycles  object detection  stereo image processing  traffic engineering computing  omnidirectional images  semantic segmentation  depth map  ground truth images  CARLA Simulator  open-source simulator  catadioptric images  OmniScape dataset  autonomous driving research  Grand Theft Auto V  two-wheeled vehicles  motorcycle  Cameras  Semantics  Vehicle dynamics  Motorcycles  Image segmentation  Virtual environments  Roads 
Abstract: Despite the utility and benefits of omnidirectional images in robotics and automotive applications, there are no datasets of omnidirectional images available with semantic segmentation, depth map, and dynamic properties. This is due to the time cost and human effort required to annotate ground truth images. This paper presents a framework for generating omnidirectional images using images that are acquired from a virtual environment. For this purpose, we demonstrate the relevance of the proposed framework on two well-known simulators: CARLA Simulator, which is an open-source simulator for autonomous driving research, and Grand Theft Auto V (GTA V), which is a very high quality video game. We explain in details the generated OmniScape dataset, which includes stereo fisheye and catadioptric images acquired from the two front sides of a motorcycle, including semantic segmentation, depth map, intrinsic parameters of the cameras and the dynamic parameters of the motorcycle. It is worth noting that the case of two-wheeled vehicles is more challenging than cars due to the specific dynamic of these vehicles.


Title: An ERT-based Robotic Skin with Sparsely Distributed Electrodes: Structure, Fabrication, and DNN-based Signal Processing
Key Words: biomedical electrodes  carbon nanotubes  manipulators  neural nets  tactile sensors  tomography  cylindrical surface  sensor output images  3D-shaped sensors  ERT-based robotic skin  sparsely distributed electrodes  DNN-based signal processing  electrical resistance tomography  large-scale tactile sensor  conductivity distribution  physical model  curved surface  electrode configuration  edge region  sensor performance  carbon nanotube-dispersed solution  conductive sensing domain  Robot sensing systems  Electrodes  Conductivity  Image reconstruction  Inverse problems 
Abstract: Electrical resistance tomography (ERT) has previously been utilized to develop a large-scale tactile sensor because this approach enables the estimation of the conductivity distribution among the electrodes based on a known physical model. Such a sensor made with a stretchable material can conform to a curved surface. However, this sensor cannot fully cover a cylindrical surface because in such a configuration, the edges of the sensor must meet each other. The electrode configuration becomes irregular in this edge region, which may degrade the sensor performance. In this paper, we introduce an ERT-based robotic skin with evenly and sparsely distributed electrodes. For implementation, we sprayed a carbon nanotube (CNT)-dispersed solution to form a conductive sensing domain on a cylindrical surface. The electrodes were firmly embedded in the surface so that the wires were not exposed to the outside. The sensor output images were estimated using a deep neural network (DNN), which was trained with noisy simulation data. An indentation experiment revealed that the localization error of the sensor was 5.2  3.3 mm, which is remarkable performance with only 30 electrodes. A frame rate of up to 120 Hz could be achieved with a sensing domain area of 90 cm2. The proposed approach simplifies the fabrication of 3D-shaped sensors, allowing them to be easily applied to existing robot arms in a seamless and robust manner.


Title: Calibrating a Soft ERT-Based Tactile Sensor with a Multiphysics Model and Sim-to-real Transfer Learning
Key Words: calibration  inverse problems  learning (artificial intelligence)  neural nets  robots  tactile sensors  tomography  soft ERT-based tactile sensor  sim-to-real transfer learning  electrical resistance tomography  finite element multiphysics model  contact pressure distributions  voltage measurements  model parameters  single-point dataset  contact force  calibration method  ERT-based tactile sensors  Fabrics  Computational modeling  Tactile sensors  Mathematical model  Electrodes  Force  Conductivity 
Abstract: Tactile sensors based on electrical resistance tomography (ERT) have shown many advantages for implementing a soft and scalable whole-body robotic skin; however, calibration is challenging because pressure reconstruction is an ill-posed inverse problem. This paper introduces a method for calibrating soft ERT-based tactile sensors using sim-to-real transfer learning with a finite element multiphysics model. The model is composed of three simple models that together map contact pressure distributions to voltage measurements. We optimized the model parameters to reduce the gap between the simulation and reality. As a preliminary study, we discretized the sensing points into a 6 by 6 grid and synthesized single- and two-point contact datasets from the multiphysics model. We obtained another single-point dataset using the real sensor with the same contact location and force used in the simulation. Our new deep neural network architecture uses a de-noising network to capture the simulation-to-real gap and a reconstruction network to estimate contact force from voltage measurements. The proposed approach showed 82% hit rate for localization and 0.51 N of force estimation error performance in singlecontact tests and 78.5% hit rate for localization and 5.0 N of force estimation error in two-point contact tests. We believe this new calibration method has the possibility to improve the sensing performance of ERT-based tactile sensors.


Title: Sim-to-Real Transfer for Optical Tactile Sensing
Key Words: cameras  learning (artificial intelligence)  mobile robots  neural nets  tactile sensors  sim-to-real transfer methods  TacTip optical tactile sensor  deformable tip  soft body simulation  Unity physics engine  domain randomisation techniques  real-world data  optical tactile sensing  deep learning  reinforcement learning methods  flexible robot controllers  complex robot controllers  training data  data collection  size 1.0 mm  Robot sensing systems  Pins  Force  Strain  Data models 
Abstract: Deep learning and reinforcement learning methods have been shown to enable learning of flexible and complex robot controllers. However, the reliance on large amounts of training data often requires data collection to be carried out in simulation, with a number of sim-to-real transfer methods being developed in recent years. In this paper, we study these techniques for tactile sensing using the TacTip optical tactile sensor, which consists of a deformable tip with a camera observing the positions of pins inside this tip. We designed a model for soft body simulation which was implemented using the Unity physics engine, and trained a neural network to predict the locations and angles of edges when in contact with the sensor. Using domain randomisation techniques for sim-to-real transfer, we show how this framework can be used to accurately predict edges with less than 1 mm prediction error in real-world testing, without any real-world data at all.


Title: Semi-Empirical Simulation of Learned Force Response Models for Heterogeneous Elastic Objects
Key Words: elastic deformation  image representation  robot vision  elastically deformable objects  data-driven models  point-based surface representation  inhomogeneous force response model  nonlinear force response model  robotic arm  arbitrary rigid object  Hertzian contact model  heterogeneous elastic objects  semiempirical method  point stiffness models  Force  Probes  Deformable models  Data models  Robot sensing systems  Strain 
Abstract: This paper presents a semi-empirical method for simulating contact with elastically deformable objects whose force response is learned using entirely data-driven models. A point-based surface representation and an inhomogeneous, nonlinear force response model are learned from a robotic arm acquiring force-displacement curves from a small number of poking interactions. The simulator then estimates displacement and force response when the deformable object is in contact with an arbitrary rigid object. It does so by estimating displacements by solving a Hertzian contact model, and sums the expected forces at individual surface points through querying the learned point stiffness models as a function of their expected displacements. Experiments on a variety of challenging objects show that our approach learns force response with sufficient accuracy to generate plausible contact response for novel rigid objects.


Title: Enabling Topological Planning with Monocular Vision
Key Words: learning (artificial intelligence)  mobile robots  multi-agent systems  path planning  robot vision  sensors  SLAM (robots)  heuristic priors  intelligent planning  monocular SLAM  low texture  highly cluttered environments  robust sparse map representation  monocular vision  learned sensor  high-level structure  sparse vertices  known free space  mapping technique  subgoal planning applications  enabling topological planning  topological strategies  navigation  possible actions  Planning  Image edge detection  Navigation  Robot sensing systems  Buildings  Robustness 
Abstract: Topological strategies for navigation meaningfully reduce the space of possible actions available to a robot, allowing use of heuristic priors or learning to enable computationally efficient, intelligent planning. The challenges in estimating structure with monocular SLAM in low texture or highly cluttered environments have precluded its use for topological planning in the past. We propose a robust sparse map representation that can be built with monocular vision and overcomes these shortcomings. Using a learned sensor, we estimate high-level structure of an environment from streaming images by detecting sparse "vertices" (e.g., boundaries of walls) and reasoning about the structure between them. We also estimate the known free space in our map, a necessary feature for planning through previously unknown environments. We show that our mapping technique can be used on real data and is sufficient for planning and exploration in simulated multi-agent search and learned subgoal planning applications.


Title: SnapNav: Learning Mapless Visual Navigation with Sparse Directional Guidance and Visual Reference
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  navigation  neurocontrollers  robot vision  robust control  SnapNav  mapless visual navigation  sparse directional guidance  visual reference  robotics  deep neural network  visual navigation system  two-level hierarchy  directional commands  real-time control  obstacle avoidance  autonomous navigation  learning-based visual navigation  robust control  Robots  Navigation  Visualization  Task analysis  Training  Collision avoidance  Turning 
Abstract: Learning-based visual navigation still remains a challenging problem in robotics, with two overarching issues: how to transfer the learnt policy to unseen scenarios, and how to deploy the system on real robots. In this paper, we propose a deep neural network based visual navigation system, SnapNav. Unlike map-based navigation or Visual-Teach-and-Repeat (VT&R), SnapNav only receives a few snapshots of the environment combined with directional guidance to allow it to execute the navigation task. Additionally, SnapNav can be easily deployed on real robots due to a two-level hierarchy: a high level commander that provides directional commands and a low level controller that provides real-time control and obstacle avoidance. This also allows us to effectively use simulated and real data to train the different layers of the hierarchy, facilitating robust control. Extensive experimental results show that SnapNav achieves a highly autonomous navigation ability compared to baseline models, enabling sparse, map-less navigation in previously unseen environments.


Title: Human-Centric Active Perception for Autonomous Observation
Key Words: aerospace robotics  Markov processes  mobile communication  mobile robots  optimisation  space vehicles  autonomous observation systems  human activity  multiobjective optimization  autonomous human observation problem  robot-centric costs  scalarization-based MultiObjective MDP methods  NASA Astrobee robot operating  human-centric active perception  robot autonomy  SemiMDP formulation  constrained MDP method  NASA Astrobee robot  Task analysis  Cameras  Robot vision systems  Collision avoidance  Cost function 
Abstract: As robot autonomy improves, robots are increasingly being considered in the role of autonomous observation systems - free-flying cameras capable of actively tracking human activity within some predefined area of interest. In this work, we formulate the autonomous observation problem through multi-objective optimization, presenting a novel Semi-MDP formulation of the autonomous human observation problem that maximizes observation rewards while accounting for both human- and robot-centric costs. We demonstrate that the problem can be solved with both scalarization-based Multi-Objective MDP methods and Constrained MDP methods, and discuss the relative benefits of each approach. We validate our work on activity tracking using a NASA Astrobee robot operating within a simulated International Space Station environment.


Title: Predicting and Optimizing Ergonomics in Physical Human-Robot Cooperation Tasks
Key Words: biomechanics  ergonomics  graph theory  human-robot interaction  mobile robots  multi-robot systems  path planning  telerobotics  32 DoF bimanual mobile robot  ergonomic-enhanced planner  reduced ergonomic cost  physical human-robot cooperation tasks  action sequences  continuous physical interaction  computational model  ergonomics assessment  human motion capture data  prediction model  informed graph search algorithm  ergonomic assessment  bimanual human-robot cooperation tasks  Ergonomics  Robots  Task analysis  Optimization  Predictive models  Computational modeling  Force 
Abstract: This paper presents a method to incorporate ergonomics into the optimization of action sequences for bi-manual human-robot cooperation tasks with continuous physical interaction. Our first contribution is a novel computational model of the human that allows prediction of an ergonomics assessment corresponding to each step in a task. The model is learned from human motion capture data in order to predict the human pose as realistically as possible. The second contribution is a combination of this prediction model with an informed graph search algorithm, which allows computation of human-robot cooperative plans with improved ergonomics according to the incorporated method for ergonomic assessment. The concepts have been evaluated in simulation and in a small user study in which the subjects manipulate a large object with a 32 DoF bimanual mobile robot as partner. For all subjects, the ergonomic-enhanced planner shows their reduced ergonomic cost compared to a baseline planner.


Title: Active Reward Learning for Co-Robotic Vision Based Exploration in Bandwidth Limited Environments
Key Words: decision theory  learning (artificial intelligence)  Markov processes  mobile robots  query processing  robot vision  making queries  regret-based criterion  active reward learning strategy  co-robotic vision based exploration  robotic explorer  bandwidth-limited environments  autonomous visual exploration  high-dimensional observation space  communication strategy  reward model  observation model  human operator  scientifically relevant images  POMDP problem formulation  Robot sensing systems  Semantics  Bandwidth  Computational modeling  Visualization  Trajectory 
Abstract: We present a novel POMDP problem formulation for a robot that must autonomously decide where to go to collect new and scientifically relevant images given a limited ability to communicate with its human operator. From this formulation we derive constraints and design principles for the observation model, reward model, and communication strategy of such a robot, exploring techniques to deal with the very high-dimensional observation space and scarcity of relevant training data. We introduce a novel active reward learning strategy based on making queries to help the robot minimize path "regret" online, and evaluate it for suitability in autonomous visual exploration through simulations. We demonstrate that, in some bandwidth-limited environments, this novel regret-based criterion enables the robotic explorer to collect up to 17% more reward per mission than the next-best criterion.


Title: Distance and Steering Heuristics for Streamline-Based Flow Field Planning
Key Words: computational fluid dynamics  flow simulation  marine robots  mobile robots  path planning  robot dynamics  artificial flow field  East Australian current  streamline-based flow field planning  motion planning  streamline-based planning  fluid dynamics  travel distance  incompressible flows  ocean currents  distance functions  Euclidean distance  stream function  steering heuristics  ocean prediction data  autonomous marine robots  Planning  Aerospace electronics  Vehicle dynamics  Two dimensional displays  Space exploration  Space vehicles  Oceans 
Abstract: Motion planning for vehicles under the influence of flow fields can benefit from the idea of streamline-based planning, which exploits ideas from fluid dynamics to achieve computational efficiency. Important to such planners is an efficient means of computing the travel distance and direction between two points in free space, but this is difficult to achieve in strong incompressible flows such as ocean currents. We propose two useful distance functions in analytical form that combine Euclidean distance with values of the stream function associated with a flow field, and with an estimation of the strength of the opposing flow between two points. Further, we propose steering heuristics that are useful for steering towards a sampled point. We evaluate these ideas by integrating them with RRT* and comparing the algorithm's performance with state-of-the-art methods in an artificial flow field and in actual ocean prediction data in the region of the dominant East Australian Current between Sydney and Brisbane. Results demonstrate the method's computational efficiency and ability to find high-quality paths outperforming state-of-the-art methods, and show promise for practical use with autonomous marine robots.


Title: DOB-Net: Actively Rejecting Unknown Excessive Time-Varying Disturbances
Key Words: control system synthesis  feedback  learning (artificial intelligence)  neurocontrollers  observers  optimal control  position control  recurrent neural nets  robots  robot control capabilities  disturbance dynamics observer network  controller network  conventional DOB mechanisms  recurrent neural networks  optimal control signals  conventional feedback controllers  DOB-Net  disturbance OB-server network  observer-integrated reinforcement learning  Observers  History  Vehicle dynamics  Robots  Optimization  Optimal control  Dynamics 
Abstract: This paper presents an observer-integrated Reinforcement Learning (RL) approach, called Disturbance OB-server Network (DOB-Net), for robots operating in environments where disturbances are unknown and time-varying, and may frequently exceed robot control capabilities. The DOB-Net integrates a disturbance dynamics observer network and a controller network. Originated from conventional DOB mechanisms, the observer is built and enhanced via Recurrent Neural Networks (RNNs), encoding estimation of past values and prediction of future values of unknown disturbances in RNN hidden state. Such encoding allows the controller generate optimal control signals to actively reject disturbances, under the constraints of robot control capabilities. The observer and the controller are jointly learned within policy optimization by advantage actor critic. Numerical simulations on position regulation tasks have demonstrated that the proposed DOB-Net significantly outperforms conventional feedback controllers and classical RL policy.


Title: Demonstration of Autonomous Nested Search for Local Maxima Using an Unmanned Underwater Vehicle
Key Words: autonomous underwater vehicles  oceanographic equipment  oceanographic techniques  search problems  hydrothermal plume model  hydrothermal vent emissions  local maxima  autonomous nested search method  hydrothermal venting  sufficient autonomy  mission concept  solar system  extra-terrestrial life  Ocean World  unmanned underwater vehicle  Vents  Oceans  Vehicle dynamics  Underwater vehicles  Earth  Numerical models  Base stations 
Abstract: Ocean Worlds represent one of the best chances for extra-terrestrial life in our solar system. A new mission concept must be developed to explore these oceans. This mission would require traversing the 10s of km thick icy shell and releasing a submersible into the ocean below. During the transit of the icy shell and the exploration of the ocean, the vehicle(s) would be out of contact with Earth for weeks or potentially months at a time. During this time the vehicle must have sufficient autonomy to locate and study scientific targets of interest. One such target of interest is hydrothermal venting. We have previously developed an autonomous nested search method to locate and investigate sources of hydrothermal venting by locating local maxima in hydrothermal vent emissions. In this work we demonstrate this approach on board an OceanServer Iver2 AUV in Chesapeake Bay, MD using simulated sensor data from a hydrothermal plume model. This represents the first step towards the deployment of this approach in conditions analogous to those that we might expect on an Ocean World.


Title: Semantic Linking Maps for Active Visual Object Search
Key Words: inference mechanisms  manipulators  mobile robots  robot vision  search problems  Semantic Linking Maps model  target object  landmark objects  probabilistic inter-object spatial relations  hybrid search strategy  SLiM-based search strategy  Fetch mobile manipulation robot  mobile robots  common human environments  unseen target objects  reasoning  search space  common spatial relations  active visual object search strategy  Search problems  Robots  Probabilistic logic  Semantics  Buildings  Inference algorithms  Visualization 
Abstract: We aim for mobile robots to function in a variety of common human environments. Such robots need to be able to reason about the locations of previously unseen target objects. Landmark objects can help this reasoning by narrowing down the search space significantly. More specifically, we can exploit background knowledge about common spatial relations between landmark and target objects. For example, seeing a table and knowing that cups can often be found on tables aids the discovery of a cup. Such correlations can be expressed as distributions over possible pairing relationships of objects. In this paper, we propose an active visual object search strategy method through our introduction of the Semantic Linking Maps (SLiM) model. SLiM simultaneously maintains the belief over a target object's location as well as landmark objects' locations, while accounting for probabilistic inter-object spatial relations. Based on SLiM, we describe a hybrid search strategy that selects the next best view pose for searching for the target object based on the maintained belief. We demonstrate the efficiency of our SLiM-based search strategy through comparative experiments in simulated environments. We further demonstrate the realworld applicability of SLiM-based search in scenarios with a Fetch mobile manipulation robot.


Title: Active Depth Estimation: Stability Analysis and its Applications
Key Words: cameras  image sequences  Lyapunov methods  mobile robots  robot vision  solid modelling  stability  SfM  incremental active depth estimation  chronological sequence  image frames  camera actuation  stability analysis  control inputs  image plane  vision-controlled structure-from-motion scheme  depth estimation filter  Lyapunov theory  Cameras  Three-dimensional displays  Stability analysis  Asymptotic stability  Convergence  Estimation error 
Abstract: Recovering the 3D structure of the surrounding environment is an essential task in any vision-controlled Structure-from-Motion (SfM) scheme. This paper focuses on the theoretical properties of the SfM, known as the incremental active depth estimation. The term incremental stands for estimating the 3D structure of the scene over a chronological sequence of image frames. Active means that the camera actuation is such that it improves estimation performance. Starting from a known depth estimation filter, this paper presents the stability analysis of the filter in terms of the control inputs of the camera. By analyzing the convergence of the estimator using the Lyapunov theory, we relax the constraints on the projection of the 3D point in the image plane when compared to previous results. Nonetheless, our method is capable of dealing with the cameras' limited field-of-view constraints. The main results are validated through experiments with simulated data.


Title: VALID: A Comprehensive Virtual Aerial Image Dataset
Key Words: computer vision  feature extraction  image classification  image segmentation  object detection  stereo image processing  aerial imagery  unmanned aerial vehicle tasks  single ground truth type  virtual environment  high-resolution images  virtual scenes  comprehensive virtual aerial image dataset  visual ground truth data  Image segmentation  Semantics  Task analysis  Object detection  Image color analysis  Benchmark testing  Labeling 
Abstract: Aerial imagery plays an important role in land-use planning, population analysis, precision agriculture, and unmanned aerial vehicle tasks. However, existing aerial image datasets generally suffer from the problem of inaccurate labeling, single ground truth type, and few category numbers. In this work, we implement a simulator that can simultaneously acquire diverse visual ground truth data in the virtual environment. Based on that, we collect a comprehensive Virtual AeriaL Image Dataset named VALID, consisting of 6690 high-resolution images, all annotated with panoptic segmentation on 30 categories, object detection with oriented bounding box, and binocular depth maps, collected in 6 different virtual scenes and 5 various ambient conditions (sunny, dusk, night, snow and fog). To our knowledge, VALID is the first aerial image dataset that can provide panoptic level segmentation and complete dense depth maps. We analyze the characteristics of VALID and evaluate state-of-the-art methods for multiple tasks to provide reference baselines. The experiment results demonstrate that VALID is well presented and challenging. The dataset is available at https://sites.google.com/view/valid-dataset/.


Title: Dynamic SLAM: The Need For Speed
Key Words: feature extraction  image motion analysis  image segmentation  mobile robots  path planning  robot vision  SLAM (robots)  rigid moving objects  static structure  dynamic structure  rigid objects  object-aware dynamic SLAM algorithm  model-free  significant motion constraints  3D models  SLAM based approaches  unstructured dynamic environments  autonomous systems  increased deployment  simultaneous localisation  static world assumption  Simultaneous localization and mapping  Heuristic algorithms  Dynamics  Three-dimensional displays  Solid modeling  Tracking 
Abstract: The static world assumption is standard in most simultaneous localisation and mapping (SLAM) algorithms. Increased deployment of autonomous systems to unstructured dynamic environments is driving a need to identify moving objects and estimate their velocity in real-time. Most existing SLAM based approaches rely on a database of 3D models of objects or impose significant motion constraints. In this paper, we propose a new feature-based, model-free, object-aware dynamic SLAM algorithm that exploits semantic segmentation to allow estimation of motion of rigid objects in a scene without the need to estimate the object poses or have any prior knowledge of their 3D models. The algorithm generates a map of dynamic and static structure and has the ability to extract velocities of rigid moving objects in the scene. Its performance is demonstrated on simulated, synthetic and real-world datasets.


Title: Learning local behavioral sequences to better infer non-local properties in real multi-robot systems
Key Words: learning (artificial intelligence)  multi-robot systems  neurocontrollers  recurrent neural nets  two-wheeled robotic platform  local behavioral sequences  multirobot systems  multirobot team  traditional observer-based approach  machine learning methods  remote teammate localization modules  long-short-term-memory  Robot sensing systems  Robot kinematics  Training  Multi-robot systems  Machine learning  Shape 
Abstract: When members of a multi-robot team follow regular motion rules sensitive to robots and other environmental factors within sensing range, the team itself may become an informational fabric for gaining situational awareness without explicit signalling among robots. In our previous work [1], we used machine learning to develop a scalable module, trained only on data from 3-robot teams, that could predict the positions of all robots in larger multi-robot teams based only on observations of the movement of a robot's nearest neighbor. Not only was this approach scalable from 3-to-many robots, but it did not require knowledge of the control laws of the robots under observation, as would a traditional observer-based approach. However, performance was only tested in simulation and could only be a substitute for explicit communication for short periods of time or in cases of very low sensing noise. In this work, we apply more sophisticated machine learning methods to data from a physically realized robotic team to develop Remote Teammate Localization (ReTLo) modules that can be used in realistic environments. To be specific, we adopt Long-Short-Term-Memory (LSTM) [2] to learn the evolution of behaviors in a modular team, which has the effect of greatly reducing errors from regression outcomes. In contrast with our previous work in simulation, all of the experiments conducted in this work were conducted on the Thymio physical, two-wheeled robotic platform.


Title: A New Path Planning Architecture to Consider Motion Uncertainty in Natural Environment
Key Words: collision avoidance  mobile robots  motion control  probability  random processes  trees (mathematics)  uncertain systems  rough environments  uncertainty propagation  rapidly-exploring random tree  position uncertainty  motion uncertainty  natural environment  wheeled robots  path planning architecture  path-following  path replanning  probability  collision avoidance  Uncertainty  Robot kinematics  Path planning  Mobile robots  Planning  Global Positioning System 
Abstract: This paper proposes a new path planning algorithm to consider motion uncertainty for wheeled robots in rough environments. The proposed method uses particles to express the uncertainty propagation in complicated environments constructed with various types of terrain. Also, RRT (Rapidly-exploring Random Tree) is expanded based on the uncertainty of each node in order to prevent increasing the accumulated position uncertainty. As a result, the generated path reduces the times of path-following and re-planning based on inaccurate localization information. The effectiveness of the proposed method is evaluated in simulation using motion uncertainty models obtained by experiments. The results show that the proposed method decreases the position uncertainty while keeping the probability to avoid collisions and to reach the goal area compared with conventional approaches.


Title: An Autonomous Intercept Drone with Image-based Visual Servo
Key Words: autonomous aerial vehicles  cameras  robot vision  visual servoing  autonomous intercept drone  unwanted drone  radio wave gun  image-based visual servo algorithm  Cameras  Visualization  Mathematical model  Drones  Channel models  Servomotors  Angular velocity 
Abstract: For most people on the ground, facing an unwanted drone buzzing around overhead, there is not a lot that we can do, especially if it is out of gun (radio wave gun or shotgun) range. A solution to this is to use intercept drones that seek out and bring down other drones. In order to make the interception autonomous, an image-based visual servo algorithm is designed with a forward-looking monocular camera. The control command, namely the angular velocity and thrust, is generated for intercept drones to implement accurate and fast interception. The proposed method is demonstrated in both hardware-in-the-loop simulation and demonstrative flight experiments.


Title: Preference-Based Learning for Exoskeleton Gait Optimization
Key Words: gait analysis  learning (artificial intelligence)  legged locomotion  optimisation  wearable robots  personalized gait optimization framework  lower-body exoskeleton  numerical objectives  preference-based interactive learning  CoSpar algorithm  pairwise preferences  exoskeleton walking  nonintuitive behavior  numerical feedback  human walking trajectory features  user-preferred parameters  adapting personalizing exoskeletons  exoskeleton gait optimization  Exoskeletons  Legged locomotion  Optimization  Bayes methods  Reliability  Trajectory 
Abstract: This paper presents a personalized gait optimization framework for lower-body exoskeletons. Rather than optimizing numerical objectives such as the mechanical cost of transport, our approach directly learns from user prefer-ences, e.g., for comfort. Building upon work in preference-based interactive learning, we present the CoSpar algorithm. CoSpar prompts the user to give pairwise preferences between trials and suggest improvements; as exoskeleton walking is a non-intuitive behavior, users can provide preferences more easily and reliably than numerical feedback. We show that CoSpar performs competitively in simulation and demonstrate a prototype implementation of CoSpar on a lower-body exoskeleton to optimize human walking trajectory features. In the experiments, CoSpar consistently found user-preferred parameters of the exoskeleton's walking gait, which suggests that it is a promising starting point for adapting and personalizing exoskeletons (or other assistive devices) to individual users.


Title: Adaptive Neural Trajectory Tracking Control for Flexible-Joint Robots with Online Learning
Key Words: actuators  adaptive control  backpropagation  control system synthesis  feedforward  flexible manipulators  manipulator dynamics  neurocontrollers  nonlinear control systems  position control  stability  online backpropagation  collaborative robots  multilayer neural network  control architecture  flexible joint dynamics  control bandwidth  control design  space manipulators  online learning  flexible-joint robots  adaptive neural trajectory tracking control  series-elastic joint actuators  joint flexibility  Baxter robot  commanded joint position  outer loop control  nonlinear basis functions  internal weights  tracking error  output layer weights  linear output layer  robot dynamics  linear-in-parameter representation  feedforward control  approximate unknown dynamics  Artificial neural networks  Trajectory  Manipulator dynamics  Aerodynamics 
Abstract: Collaborative robots and space manipulators contain significant joint flexibility. It complicates the control design, compromises the control bandwidth, and limits the tracking accuracy. The imprecise knowledge of the flexible joint dynamics compounds the challenge. In this paper, we present a new control architecture for controlling flexible-joint robots. Our approach uses a multi-layer neural network to approximate unknown dynamics needed for the feedforward control. The network may be viewed as a linear-in-parameter representation of the robot dynamics, with the nonlinear basis of the robot dynamics connected to the linear output layer. The output layer weights are updated based on the tracking error and the nonlinear basis. The internal weights of the nonlinear basis are updated by online backpropagation to further reduce the tracking error. To use time scale separation to reduce the coupling of the two steps - the update of the internal weights is at a lower rate compared to the update of the output layer weights. With the update of the output layer weights, our controller adapts quickly to the unknown dynamics change and disturbances (such as attaching a load). The update of the internal weights would continue to improve the converge of the nonlinear basis functions. We show the stability of the proposed scheme under the "outer loop" control, where the commanded joint position is considered as the control input. Simulation and physical experiments are conducted to demonstrate the performance of the proposed controller on a Baxter robot, which exhibits significant joint flexibility due to the series-elastic joint actuators.


Title: Context-aware Cost Shaping to Reduce the Impact of Model Error in Receding Horizon Control
Key Words: mobile robots  predictive control  probability  remotely operated vehicles  robot dynamics  stochastic systems  model error  receding horizon control  repetitive path-following task  robot dynamics  simple learned dynamics model  MPC horizon  stochastic MPC  prediction horizon  online model learning  ground robot  context-aware cost shaping  stochastic model predictive control  Robots  Computational modeling  Predictive models  Aerodynamics  Cost function  Task analysis  Stochastic processes 
Abstract: This paper presents a method to enable a robot using stochastic Model Predictive Control (MPC) to achieve high performance on a repetitive path-following task. In particular, we consider the case where the accuracy of the model for robot dynamics varies significantly over the path-motivated by the fact that the models used in MPC must be computationally efficient, which limits their expressive power. Our approach is based on correcting the cost predicted using a simple learned dynamics model over the MPC horizon. This discourages the controller from taking actions that lead to higher cost than would have been predicted using the dynamics model. In addition, stochastic MPC provides a quantitative measure of safety by limiting the probability of violating state and input constraints over the prediction horizon. Our approach is unique in that it combines both online model learning and cost learning over the prediction horizon and is geared towards operating a robot in changing conditions. We demonstrate our algorithm in simulation and experiment on a ground robot that uses a stereo camera for localization.


Title: Aortic 3D Deformation Reconstruction using 2D X-ray Fluoroscopy and 3D Pre-operative Data for Endovascular Interventions
Key Words: biomedical MRI  catheters  computerised tomography  deformation  diagnostic radiography  image reconstruction  image registration  medical image processing  phantoms  live 3D aortic deformation  static 3D model  stereo images  reconstruction process  deformation graph approach  reconstruction accuracy  aortic 3D deformation reconstruction  2D X-ray fluoroscopy  current clinical endovascular interventions  catheter manipulation  aortic 3D surface  deformation reconstruction frameworks  3D intraoperative guidance  Three-dimensional displays  Strain  Solid modeling  Image reconstruction  X-ray imaging  Two dimensional displays  Deformable models  aortic deformation reconstruction  fluoroscopy  endovascular interventions 
Abstract: Current clinical endovascular interventions rely on 2D guidance for catheter manipulation. Although an aortic 3D surface is available from the pre-operative CT/MRI imaging, it cannot be used directly as a 3D intra-operative guidance since the vessel will deform during the procedure. This paper aims to reconstruct the live 3D aortic deformation by fusing the static 3D model from the pre-operative data and the 2D live imaging from fluoroscopy. In contrast to some existing deformation reconstruction frameworks which require 3D observations such as RGB-D or stereo images, fluoroscopy only presents 2D information. In the proposed framework, a 2D-3D registration is performed and the reconstruction process is formulated as a non-linear optimization problem based on the deformation graph approach. Detailed simulations and phantom experiments are conducted and the result demonstrates the reconstruction accuracy and robustness, as well as the potential clinical value of this framework.


Title: Robotic needle insertion in moving soft tissues using constraint-based inverse Finite Element simulation
Key Words: biological tissues  end effectors  finite element analysis  inverse problems  medical image processing  medical robotics  needles  robotic needle insertion  soft tissues  robotic steering  flexible needle  predefined path  inverse problem  robot end effector  constraint-based formulation  simulation-guided needle insertion  direct simulation  respiratory motion  numerical simulation  constraint-based inverse finite element simulation  Needles  Robots  Mathematical model  Linear programming  Computational modeling  Numerical models  Inverse problems 
Abstract: This paper introduces a method for robotic steering of a flexible needle inside moving and deformable tissues. The method relies on a set of objective functions allowing to automatically steer the needle along a predefined path. In order to follow the desired trajectory, an inverse problem linking the motion of the robot end effector with the objective functions is solved using a Finite Element simulation. The main contribution of the article is the new constraint-based formulation of the objective functions allowing to: 1) significantly reduce the computation time; 2) increase the accuracy and stability of the simulation-guided needle insertion. The method is illustrated, and its performances are characterized in a realistic framework, using a direct simulation of the respiratory motion generated from in vivo data of a pig. Despite the highly non-linear behavior of the numerical simulation and the significant deformations occurring during the insertion, the obtained performances enable the possibility to follow the trajectory with the desired accuracy for medical purpose.


Title: MPC-based Controller with Terrain Insight for Dynamic Legged Locomotion
Key Words: convolutional neural nets  hydraulic actuators  legged locomotion  neurocontrollers  predictive control  robot dynamics  on-board mapping  contact sequence task  convolutional neural network  model predictive controller  on-board sensing  MPC-based controller  terrain insight  dynamic legged locomotion  hydraulically actuated quadruped robot HyQReal  Legged locomotion  Trajectory  Task analysis  Computational modeling  Dynamics  Foot 
Abstract: We present a novel control strategy for dynamic legged locomotion in complex scenarios that considers information about the morphology of the terrain in contexts when only on-board mapping and computation are available. The strategy is built on top of two main elements: first a contact sequence task that provides safe foothold locations based on a convolutional neural network to perform fast and continuous evaluation of the terrain in search of safe foothold locations; then a model predictive controller that considers the foothold locations given by the contact sequence task to optimize target ground reaction forces. We assess the performance of our strategy through simulations of the hydraulically actuated quadruped robot HyQReal traversing rough terrain under realistic on-board sensing and computing conditions.


Title: Improved Performance on Moving-Mass Hopping Robots with Parallel Elasticity
Key Words: actuators  elasticity  legged locomotion  robot dynamics  springs (mechanical)  stability  mechanical design  robotic hopping  moving-mass hopping robots  hop heights  single-spring model  double-spring model  hopping effort  parallel spring  hybrid systems models  rigorous trajectory optimization method  one-dimensional hopping robot  actuator  single spring  moving-mass robot  stable hopping  ground contact  Springs  Actuators  Force  Robot kinematics  Dynamics  Jacobian matrices 
Abstract: Robotic Hopping is challenging from the perspective of both modeling the dynamics as well as the mechanical design due to the short period of ground contact in which to actuate on the world. Previous work has demonstrated stable hopping on a moving-mass robot, wherein a single spring was utilized below the body of the robot. This paper finds that the addition of a spring in parallel to the actuator greatly improves the performance of moving mass hopping robots. This is demonstrated through the design of a novel one-dimensional hopping robot. For this robot, a rigorous trajectory optimization method is developed using hybrid systems models with experimentally tuned parameters. Simulation results are used to study the effects of a parallel spring on energetic efficiency, stability, and hopping effort. We find that the double-spring model had 2.5x better energy efficiency than the single-spring model, and was able to hop using 40% less peak force from the actuator. Furthermore, the double-spring model produces stable hopping without the need for stabilizing controllers. These concepts are demonstrated experimentally on a novel hopping robot, wherein hop heights up to 40cm were achieved with comparable efficiency and stability.


Title: Distributed Attack-Robust Submodular Maximization for Multi-Robot Planning
Key Words: control system security  distributed algorithms  divide and conquer methods  multi-robot systems  optimisation  path planning  target tracking  distributed attack-robust submodular maximization  multirobot planning  swarm-robotics applications  multirobot motion  attack-robust algorithms  robust optimization  distributed robust maximization  DRM performance  multiple robots  denial-of-service attacks  DoS attacks  large-scale robotic applications  general-purpose distributed algorithm  divide-and-conquer approach  robot communication range  close-to-optimal performance  active target tracking  Planning  Target tracking  Robot kinematics  Partitioning algorithms  Robot sensing systems  Robustness 
Abstract: We aim to guard swarm-robotics applications against denial-of-service (DoS) attacks that result in withdrawals of robots. We focus on applications requiring the selection of actions for each robot, among a set of available ones, e.g., which trajectory to follow. Such applications are central in large-scale robotic applications, e.g., multi-robot motion planning for target tracking. But the current attack-robust algorithms are centralized, and scale quadratically with the problem size (e.g., number of robots). In this paper, we propose a general-purpose distributed algorithm towards robust optimization at scale, with local communications only. We name it distributed robust maximization (DRM). DRM proposes a divide-and-conquer approach that distributively partitions the problem among K cliques of robots. The cliques optimize in parallel, independently of each other. That way, DRM also offers computational speed-ups up to 1/K2 the running time of its centralized counterparts. K depends on the robots' communication range, which is given as input to DRM. DRM also achieves a close-to-optimal performance. We demonstrate DRM's performance in Gazebo and MATLAB simulations, in scenarios of active target tracking with multiple robots. We observe DRM achieves significant computational speed-ups (it is 3 to 4 orders faster) and, yet, nearly matches the tracking performance of its centralized counterparts.


Title: Distributed Optimization of Nonlinear, Non-Gaussian, Communication-Aware Information using Particle Methods
Key Words: entropy  mobile robots  multi-robot systems  optimisation  wireless sensor networks  mobile robotic sensor networks  neighbor robots  conditional mutual information  communication properties  specific measurement set  particle methods  information computation  distributed optimization  local utility design  communication-aware information gathering  sampling procedures  entropy reduction  Robot sensing systems  Optimization  Mutual information  Planning  Atmospheric measurements  Particle measurements 
Abstract: This paper presents a distributed optimization framework and its local utility design for communication-aware information gathering by mobile robotic sensor networks. The main idea of the optimization is that each robot decides based on its local utility that considers the decisions of other neighbor robots higher in a given hierarchy. The local utility is designed as conditional mutual information that captures sensing and communication properties. Sampling procedures using a specific measurement set and particle methods are applied to compute the designed utility, which allows nonlinear, non-Gaussian properties of targets, sensing, and communication. Simulation results describe the presented distributed optimization shows more improved estimates and entropy reduction than another approach that does not consider communication properties. Simulation results also verify the presented distributed optimization using the described approach for information computation has better results than using other approaches that simplify the communication-aware information.


Title: Targeted Drug Delivery: Algorithmic Methods for Collecting a Swarm of Particles with Uniform, External Forces
Key Words: computational complexity  deterministic algorithms  drug delivery systems  drugs  learning (artificial intelligence)  neural nets  optimisation  actuation steps  deterministic algorithms  targeted drug delivery  maze-like environment  vascular system  basic scenario  global external force  fluidic flow  deep learning  Magnetic resonance imaging  Robots  Tumors  Force  Blood  Electromagnetics  Machine learning 
Abstract: We investigate algorithmic approaches for targeted drug delivery in a complex, maze-like environment, such as a vascular system. The basic scenario is given by a large swarm of micro-scale particles ("agents") and a particular target region ("tumor") within a system of passageways. Agents are too small to contain on-board power or computation and are instead controlled by a global external force that acts uniformly on all particles, such as an applied fluidic flow or electromagnetic field. The challenge is to deliver all agents to the target region with a minimum number of actuation steps. We provide a number of results for this challenge. We show that the underlying problem is NP-hard, which explains why previous work did not provide provably efficient algorithms. We also develop a number of algorithmic approaches that greatly improve the worst-case guarantees for the number of required actuation steps. We evaluate our algorithmic approaches by a number of simulations, both for deterministic algorithms and searches supported by deep learning, which show that the performance is practically promising.


Title: Constrained Sampling-based Trajectory Optimization using Stochastic Approximation
Key Words: approximation theory  discrete systems  gradient methods  optimal control  optimisation  sampling methods  stochastic processes  constrained problems  stochastic search  box control constraints  nonlinear state constraints  discrete dynamical systems  sampling-based trajectory optimization methodology  stochastic approximation  constrained sampling-based trajectory optimization  nonsmooth penalty functions  control inputs  truncated parameterized distributions  Heuristic algorithms  Trajectory optimization  Convergence  Approximation algorithms  Robots 
Abstract: We propose a sampling-based trajectory optimization methodology for constrained problems. We extend recent works on stochastic search to deal with box control constraints, as well as nonlinear state constraints for discrete dynamical systems. Regarding the former, our strategy is to optimize over truncated parameterized distributions on control inputs. Furthermore, we show how non-smooth penalty functions can be incorporated into our framework to handle state constraints. Simulations on cartpole and quadcopter show that our approach outperforms previous methods on constrained sampling-based optimization, in terms of quality of solutions and convergence speed.


Title: Learning Control Policies from Optimal Trajectories
Key Words: feedback  Gaussian processes  industrial robots  learning systems  mobile robots  nonlinear control systems  optimal control  optimisation  pendulums  trajectory control  time-dependent optimal trajectories  optimal feedback control policies  real-world systems  frequent correction  model errors  optimal reference trajectories  high dimensional state space  learning control policies  optimally control robotic systems  high dimensional nonlinear system dynamic models  Gaussian processes  swing-up problem  underactuated pendulum  energy-minimal point-to-point movement  3-DOF industrial robot  Trajectory  Computational modeling  Task analysis  Numerical models  Robots  Feedback control  Optimal control 
Abstract: The ability to optimally control robotic systems offers significant advantages for their performance. While time-dependent optimal trajectories can numerically be computed for high dimensional nonlinear system dynamic models, constraints and objectives, finding optimal feedback control policies for such systems is hard. This is unfortunate, as without a policy, the control of real-world systems requires frequent correction or replanning to compensate for disturbances and model errors.In this paper, a feedback control policy is learned from a set of optimal reference trajectories using Gaussian processes. Information from existing trajectories and the current policy is used to find promising start points for the computation of further optimal trajectories. This aspect is important as it avoids exhaustive sampling of the complete state space, which is impractical due to the high dimensional state space, and to focus on the relevant region.The presented method has been applied in simulation to a swing-up problem of an underactuated pendulum and an energy-minimal point-to-point movement of a 3-DOF industrial robot.


Title: Grasp for Stacking via Deep Reinforcement Learning
Key Words: grippers  industrial manipulators  learning systems  neurocontrollers  optimal control  stacking  deep reinforcement learning  integrated robotic arm system  object grasping  model-free deep Q-learning method  grasping-stacking task  GSN  grasping for stacking network  industrial environments  GNet  optimal location  long-range planning  Grasping  Stacking  Task analysis  Feature extraction  Manipulators  Training 
Abstract: Integrated robotic arm system should contain both grasp and place actions. However, most grasping methods focus more on how to grasp objects, while ignoring the placement of the grasped objects, which limits their applications in various industrial environments. In this research, we propose a model-free deep Q-learning method to learn the grasping-stacking strategy end-to-end from scratch. Our method maps the images to the actions of the robotic arm through two deep networks: the grasping network (GNet) using the observation of the desk and the pile to infer the gripper's position and orientation for grasping, and the stacking network (SNet) using the observation of the platform to infer the optimal location when placing the grasped object. To make a long-range planning, the two observations are integrated in the grasping for stacking network (GSN). We evaluate the proposed GSN on a grasping-stacking task in both simulated and real-world scenarios.


Title: Physics-based Simulation of Continuous-Wave LIDAR for Localization, Calibration and Tracking
Key Words: calibration  computerised instrumentation  differentiation  gradient methods  optical radar  optical sensors  optical tracking  optimisation  radar receivers  parameter estimation  2D continuous-wave LIDAR sensors  light detection and ranging sensors  depth measurements  localization pipelines  autonomous robots  perception stack  physics-based simulation  sensor measurements  gradient-based optimization  Hokuyo URG-04LX LIDAR  surface-light interactions  physically plausible model  laser light  calibration  time-of-flight cameras  depth sensors  Laser radar  Measurement by laser beam  Mathematical model  Sensor phenomena and characterization  Surface emitting lasers  Laser modes 
Abstract: Light Detection and Ranging (LIDAR) sensors play an important role in the perception stack of autonomous robots, supplying mapping and localization pipelines with depth measurements of the environment. While their accuracy outperforms other types of depth sensors, such as stereo or time-of-flight cameras, the accurate modeling of LIDAR sensors requires laborious manual calibration that typically does not take into account the interaction of laser light with different surface types, incidence angles and other phenomena that significantly influence measurements. In this work, we introduce a physically plausible model of a 2D continuous-wave LIDAR that accounts for the surface-light interactions and simulates the measurement process in the Hokuyo URG-04LX LIDAR. Through automatic differentiation, we employ gradient-based optimization to estimate model parameters from real sensor measurements.


Title: Reducing Uncertainty in Pose Estimation under Complex Contacts via Force Forecast
Key Words: haptic interfaces  manipulators  pose estimation  regression analysis  robotic assembly  trees (mathematics)  sphere-tree representation  least-uncertain estimate  relative contact  multiregion complex contacts  contact types  contact locations  object shapes  object poses  complex shapes  pose estimation  force forecast  autonomous robotic manipulation  simulated complex contacts  force sensing  constraint-based haptic simulation algorithm  three-pin peg-in-hole robotic assembly tasks  contact-rich two-pin peg-in-hole assembly tasks  calibration  regression model  Force  Uncertainty  Robot sensing systems  Task analysis  Calibration 
Abstract: How to reduce uncertainty in object pose estimation under complex contacts is crucial to autonomous robotic manipulation and assembly. In this paper, we introduce an approach through forecasting contact force from simulated complex contacts with calibration based on real force sensing. A constraint-based haptic simulation algorithm is used with sphere-tree representation of contacting objects to compute contact poses and forces, and through matching the computed forces to measured real force data via a regression model, the least-uncertain estimate of the relative contact pose is obtained. Our approach can handle multi-region complex contacts and does not make any assumption about contact types or contact locations. It also does not have restriction on object shapes. We have applied the force forecast approach to reducing uncertainty in estimating object poses in challenging peg-in-hole robotic assembly tasks and demonstrate the effectiveness of the approach by successful completion of contact-rich two-pin and three-pin real peg-in-hole assembly tasks with complex shapes of pins and holes.


Title: Self-Supervised Sim-to-Real Adaptation for Visual Robotic Manipulation
Key Words: learning (artificial intelligence)  manipulators  neural nets  robot vision  visual robotic manipulation  robotic visual data  reinforcement learning algorithms  robotic learning  state estimation  latent state representation  deep reinforcement learning  unlabeled real robot data  robot experience  time-contrastive techniques  learned state representation  vision-based reinforcement learning agent  standard visual domain adaptation techniques  self-supervised sim-to-real adaptation  sequence-based supervised objectives  contrastive forward dynamics loss  Robots  Task analysis  Adaptation models  Visualization  Stacking  Data models  Training 
Abstract: Collecting and automatically obtaining reward signals from real robotic visual data for the purposes of training reinforcement learning algorithms can be quite challenging and time-consuming. Methods for utilizing unlabeled data can have a huge potential to further accelerate robotic learning. We consider here the problem of performing manipulation tasks from pixels. In such tasks, choosing an appropriate state representation is crucial for planning and control. This is even more relevant with real images where noise, occlusions and resolution affect the accuracy and reliability of state estimation. In this work, we learn a latent state representation implicitly with deep reinforcement learning in simulation, and then adapt it to the real domain using unlabeled real robot data. We propose to do so by optimizing sequence-based self- supervised objectives. These use the temporal nature of robot experience, and can be common in both the simulated and real domains, without assuming any alignment of underlying states in simulated and unlabeled real images. We further propose a novel such objective, the Contrastive Forward Dynamics loss, which combines dynamics model learning with time-contrastive techniques. The learned state representation that results from our methods can be used to robustly solve a manipulation task in simulation and to successfully transfer the learned skill on a real system. We demonstrate the effectiveness of our approaches by training a vision-based reinforcement learning agent for cube stacking. Agents trained with our method, using only 5 hours of unlabeled real robot data for adaptation, shows a clear improvement over domain randomization, and standard visual domain adaptation techniques for sim-to-real transfer.


Title: Meta Reinforcement Learning for Sim-to-real Domain Adaptation
Key Words: learning (artificial intelligence)  medical robotics  dynamic conditions  task-specific trajectory generation model  KUKA LBR 4+ robot  sim-to-real domain transfer  robotic policy training  meta reinforcement learning  Adaptation models  Task analysis  Trajectory  Robots  Training  Learning (artificial intelligence)  Heuristic algorithms 
Abstract: Modern reinforcement learning methods suffer from low sample efficiency and unsafe exploration, making it infeasible to train robotic policies entirely on real hardware. In this work, we propose to address the problem of sim-to-real domain transfer by using meta learning to train a policy that can adapt to a variety of dynamic conditions, and using a task-specific trajectory generation model to provide an action space that facilitates quick exploration. We evaluate the method by performing domain adaptation in simulation and analyzing the structure of the latent space during adaptation. We then deploy this policy on a KUKA LBR 4+ robot and evaluate its performance on a task of hitting a hockey puck to a target. Our method shows more consistent and stable domain adaptation than the baseline, resulting in better overall performance.


Title: Variational Auto-Regularized Alignment for Sim-to-Real Control
Key Words: control engineering computing  learning (artificial intelligence)  manipulators  neural nets  variational auto-regularized alignment  sim-to-real control  general-purpose simulators  variational autoencoder  black-box simulation  latent space  encoder training  simulation parameter distribution  matching parameter distributions  ABB YuMi robot hardware  Hardware  Decoding  Computational modeling  Neural networks  Training  Trajectory  Benchmark testing 
Abstract: General-purpose simulators can be a valuable data source for flexible learning and control approaches. However, training models or control policies in simulation and then directly applying to hardware can yield brittle control. Instead, we propose a novel way to use simulators as regularizers. Our approach regularizes a decoder of a variational autoencoder to a black-box simulation, with the latent space bound to a subset of simulator parameters. This enables successful encoder training from a small number of real-world trajectories (10 in our experiments), yielding a latent space with simulation parameter distribution that matches the real-world setting. We use a learnable mixture for the latent prior/posterior, which implies a highly flexible class of densities for the posterior fit. Our approach is scalable and does not require restrictive distributional assumptions. We demonstrate ability to recover matching parameter distributions on a range of benchmarks, challenging custom simulation environments and several real-world scenarios. Our experiments using ABB YuMi robot hardware show ability to help reinforcement learning approaches overcome cases of severe sim-to-real mismatch.


Title: DeepRacer: Autonomous Racing Platform for Experimentation with Sim2Real Reinforcement Learning
Key Words: intelligent robots  learning (artificial intelligence)  mobile robots  path planning  robot dynamics  robot vision  reality gap  joint perception  on-demand compute architecture  training optimal policies  robust evaluation  deep reinforcement learning  robotic control agent  raw camera images  robust path planning  DeepRacer  autonomous racing platform  Sim2Real reinforcement learning  end-to-end experimentation  RL  intelligent control systems  monocular camera  physical world  robust reinforcement learning  model-free learning  Training  Automobiles  Robots  Computational modeling  Cameras  Robustness  Navigation 
Abstract: DeepRacer is a platform for end-to-end experimentation with RL and can be used to systematically investigate the key challenges in developing intelligent control systems. Using the platform, we demonstrate how a 1/18th scale car can learn to drive autonomously using RL with a monocular camera. It is trained in simulation with no additional tuning in the physical world and demonstrates: 1) formulation and solution of a robust reinforcement learning algorithm, 2) narrowing the reality gap through joint perception and dynamics, 3) distributed on-demand compute architecture for training optimal policies, and 4) a robust evaluation method to identify when to stop training. It is the first successful large-scale deployment of deep reinforcement learning on a robotic control agent that uses only raw camera images as observations and a model-free learning method to perform robust path planning. We open source our code and video demo on GitHub2.


Title: Comparison of online algorithms for the tracking of multiple magnetic targets in a myokinetic control interface*
Key Words: Kalman filters  medical robotics  optimisation  prosthetics  surgery  telerobotics  tracking  localization algorithms  optimization  Levenberg-Marquardt algorithm  trust region reflective algorithm  robotics applications  remote tracking  multiple magnetic targets  myokinetic control interface  magnetic tracking algorithms  biomedical applications  teleoperated surgical robots  upper limb prostheses  Magnetostatics  Magnetic separation  Robots  Magnetic sensors  Magnetic devices 
Abstract: Magnetic tracking algorithms can be used to determine the position and orientation of magnetic markers or devices. These techniques are particularly interesting for biomedical applications such as teleoperated surgical robots or the control of upper limb prostheses. The performance of different algorithms used for magnetic tracking was compared in the past. However, in most cases, those algorithms were required to track a single magnet.Here we investigated the performance of three localization algorithms in tracking up to 9 magnets: two optimization-based (Levenberg-Marquardt algorithm, LMA, and Trust Region Reflective algorithm, TRRA) and one recursion-based (Unscented Kalman Filter, UKF). The tracking accuracy of the algorithms and their computation time were investigated through simulations.The accuracy of the three algorithms, when tracking up to six magnets, was similar, leading to estimation errors varying from 0.06  0.02 mm to 2.26  0.07 mm within a 100 mm  54 mm  100 mm workspace, at the highest sampling frequency. In all cases, computation times under 300 ms for the UKF and 45 ms for the LMA/TRRA were obtained. The TRRA showed the best tracking performance overall.These outcomes are of interest for a wide range of robotics applications that require remote tracking.


Title: Congestion-aware Evacuation Routing using Augmented Reality Devices
Key Words: augmented reality  emergency management  optimisation  congestion-aware evacuation  congestion-aware routing solution  indoor evacuation  real-time individual-customized evacuation routes  multiple destinations  population density map  obtained on-the-fly  congestion distribution  optimal solution  time-efficient evacuation route  AR devices  user-end augmented reality devices  Sociology  Statistics  Routing  Real-time systems  Path planning  Robots  Headphones 
Abstract: We present a congestion-aware routing solution for indoor evacuation, which produces real-time individual-customized evacuation routes among multiple destinations while keeping tracks of all evacuees' locations. A population density map, obtained on-the-fly by aggregating locations of evacuees from user-end Augmented Reality (AR) devices, is used to model the congestion distribution inside a building. To efficiently search the evacuation route among all destinations, a variant of A* algorithm is devised to obtain the optimal solution in a single pass. In a series of simulated studies, we show that the proposed algorithm is more computationally optimized compared to classic path planning algorithms; it generates a more time-efficient evacuation route for each individual that minimizes the overall congestion. A complete system using AR devices is implemented for a pilot study in real-world environments, demonstrating the efficacy of the proposed approach.


Title: Human-robot interaction for robotic manipulator programming in Mixed Reality
Key Words: augmented reality  human-robot interaction  manipulators  robot programming  human-robot interaction  robotic manipulator programming  mixed reality  interactive programming  HoloLens glasses  robotic operation system  robotic manipulators  robot location  point cloud analysis  virtual markers  menus  pick-and-place operation  contact operations execution  UR10e robot  KUKA iiwa robot  Virtual reality  Trajectory  Collision avoidance  Manipulators  Programming  Service robots 
Abstract: The paper presents an approach for interactive programming of the robotic manipulator using mixed reality. The developed system is based on the HoloLens glasses connected through Robotic Operation System to Unity engine and robotic manipulators. The system gives a possibility to recognize the real robot location by the point cloud analysis, to use virtual markers and menus for the task creation, to generate a trajectory for execution in the simulator or on the real manipulator. It also provides the possibility of scaling virtual and real worlds for more accurate planning. The proposed framework has been tested on pick-and-place and contact operations execution by UR10e and KUKA iiwa robots.


Title: Investigation of a Multistable Tensegrity Robot applied as Tilting Locomotion System*
Key Words: actuators  bifurcation  mechanical stability  mobile robots  motion control  numerical analysis  robot dynamics  robot kinematics  vibration control  locomotion characteristics  actuation strategy  compliant tensegrity structure  multistable tensegrity robot  multiple stable equilibrium configurations  tilting locomotion system  Prototypes  Bifurcation  Robots  Mathematical model  Shape  Reliability  Topology 
Abstract: This paper describes the development of a tilting locomotion system based on a compliant tensegrity structure with multiple stable equilibrium configurations. A tensegrity structure featuring 4 stable equilibrium states is considered. The mechanical model of the structure is presented and the according equations of motion are derived. The variation of the length of selected structural members allows to influence the prestress state and the corresponding shape of the tensegrity structure. Based on bifurcation analyses a reliable actuation strategy to control the current equilibrium state is designed. In this work, the tensegrity structure is assumed to be in contact with a horizontal plane due to gravity. The derived actuation strategy is utilized to generate tilting locomotion by successively changing the equilibrium state. Numerical simulations are evaluated considering the locomotion characteristics. In order to validate this theoretical approach a prototype is developed. Experiments regarding to the equilibrium configurations, the actuation strategy and the locomotion characteristics are evaluated using image processing tools and motion capturing. The results verify the theoretical data and confirm the working principle of the investigated tilting locomotion system. This approach represents a feasible actuation strategy to realize a reliable tilting locomotion utilizing the multistability of compliant tensegrity structures.


Title: Modeling and Experiments on the Swallowing and Disgorging Characteristics of an Underwater Continuum Manipulator
Key Words: bending  elasticity  grippers  hydraulic systems  manipulator dynamics  muscle  pneumatic actuators  underwater continuum manipulator  compliant materials  McKibben water hydraulic artificial muscle  WHAM  mechanical properties  kinematics model  soft grippers  bending procedure  disgorging procedure  mouth-tongue collaborative soft robot  single-segment soft robot arm  swallowing procedure  Manipulators  Muscles  Grippers  Kinematics  Hydraulic systems  Actuators 
Abstract: Soft robots apply compliant materials to perform motions and behaviors not typically achievable by rigid robots. An underwater, compliant, multi-segment continuum manipulator that can bend, swallow, disgorge is developed in this study. The manipulator is driven by McKibben water hydraulic artificial muscle (WHAM). The mechanical properties of the WHAM are tested and analyzed experimentally. The kinematics model, which concerns about the variable diameter structure of the soft grippers, are established to simulate the behaviors of the manipulator among the bending, swallowing and disgorging procedure. A mouth-tongue collaborative soft robot assembled with another single-segment soft robot arm is presented. And its functions are experimentally testified. The distinctive functions were verified according to the experimental results.


Title: Ibex: A reconfigurable ground vehicle with adaptive terrain navigation capability
Key Words: friction  mobile robots  off-road vehicles  optimisation  remotely operated vehicles  robot dynamics  stability  vehicle dynamics  reconfigurable ground vehicle  adaptive terrain navigation capability  unmanned ground vehicle  dynamic wheelbase  adaptive thrust  friction optimization  steep slopes  slippery surfaces  surface topography  impedance-based stabilization module  mechanical oscillatory transients  Ibex  Force  Wheels  Surface topography  Surface impedance  Land vehicles  Kinematics  Drag 
Abstract: This paper presents a unique unmanned ground vehicle with a dynamic wheelbase and an adaptive thrust based friction optimization scheme that aids in the traversal of steep slopes and slippery surfaces. The vehicle is capable of adapting itself to the surface topography using an impedance-based stabilization module to minimize the mechanical oscillatory transients induced during its motion. A detailed analysis of its modules has been elucidated in this paper based on the vehicle parameters. The proposed methodologies have been integrated and tested on a customized prototype. Experimental validation and simulation for the proposed modules at various terrain conditions have been carried out to authenticate its performance.


Title: Learning Face Recognition Unsupervisedly by Disentanglement and Self-Augmentation
Key Words: face recognition  feature extraction  home automation  unsupervised learning  video surveillance  triplet network  augmentation network  identity-aware features  face samples  identity-irrelevant features  home robot applications  face recognition system  smart home environment  environment-specific face recognition model  unsupervised learning  self-augmentation  healthcare application  camera position  surveillance video  identity-aware feature extraction  spatiotemporal characteristic  face image disentanglement 
Abstract: As the growth of smart home, healthcare, and home robot applications, learning a face recognition system which is specific for a particular environment and capable of self-adapting to the temporal changes in appearance (e.g., caused by illumination or camera position) is nowadays an important topic. In this paper, given a video of a group of people, which simulates the surveillance video in a smart home environment, we propose a novel approach which unsuper- visedly learns a face recognition model based on two main components: (1) a triplet network that extracts identity-aware feature from face images for performing face recognition by clustering, and (2) an augmentation network that is conditioned on the identity-aware features and aims at synthesizing more face samples. Particularly, the training data for the triplet network is obtained by using the spatiotemporal characteristic of face samples within a video, while the augmentation network learns to disentangle a face image into identity-aware and identity-irrelevant features thus is able to generate new faces of the same identity but with variance in appearance. With taking the richer training data produced by augmentation network, the triplet network is further fine-tuned and achieves better performance in face recognition. Extensive experiments not only show the efficacy of our model in learning an environment- specific face recognition model unsupervisedly, but also verify its adaptability to various appearance changes.


Title: Active SLAM using 3D Submap Saliency for Underwater Volumetric Exploration
Key Words: graph theory  mobile robots  navigation  path planning  robot vision  SLAM (robots)  underwater volumetric exploration  active SLAM framework  3D underwater environments  multibeam sonar  integrated SLAM  volumetric free-space information  informative loop closures  navigation policy  3D visual dictionary  submap saliency  sensor information  pose-graph SLAM formulation  global occupancy grid map  uncertainty-agnostic framework  Simultaneous localization and mapping  Three-dimensional displays  Uncertainty  Conferences  Automation  Sonar  Planning 
Abstract: In this paper, we present an active SLAM framework for volumetric exploration of 3D underwater environments with multibeam sonar. Recent work in integrated SLAM and planning performs localization while maintaining volumetric free-space information. However, an absence of informative loop closures can lead to imperfect maps, and therefore unsafe behavior. To solve this, we propose a navigation policy that reduces vehicle pose uncertainty by balancing between volumetric exploration and revisitation. To identify locations to revisit, we build a 3D visual dictionary from real-world sonar data and compute a metric of submap saliency. Revisit actions are chosen based on propagated pose uncertainty and sensor information gain. Loop closures are integrated as constraints in our pose-graph SLAM formulation and these deform the global occupancy grid map. We evaluate our performance in simulation and real-world experiments, and highlight the advantages over an uncertainty-agnostic framework.


Title: Full-Scale Continuous Synthetic Sonar Data Generation with Markov Conditional Generative Adversarial Networks*
Key Words: acoustic signal processing  autonomous underwater vehicles  data analysis  environmental factors  Markov processes  naval engineering computing  neural nets  object recognition  realistic images  sonar imaging  statistical analysis  bootstrapping ATR systems  autonomous underwater vehicles  autonomous target recognition systems  realistic synthetic sonar imagery  Markov conditional generative adversarial networks  continuous synthetic sonar data generation  Markov conditional pix2pix  environmental factors  acoustic sensors  Sonar  Training  Semantics  Data models  Gallium nitride  Training data  Markov processes 
Abstract: Deployment and operation of autonomous underwater vehicles is expensive and time-consuming. High-quality realistic sonar data simulation could be of benefit to multiple applications, including training of human operators for post-mission analysis, as well as tuning and validation of autonomous target recognition (ATR) systems for underwater vehicles. Producing realistic synthetic sonar imagery is a challenging problem as the model has to account for specific artefacts of real acoustic sensors, vehicle attitude, and a variety of environmental factors. We propose a novel method for generating realistic-looking sonar side-scans of full-length missions, called Markov Conditional pix2pix (MC-pix2pix). Quantitative assessment results confirm that the quality of the produced data is almost indistinguishable from real. Furthermore, we show that bootstrapping ATR systems with MC-pix2pix data can improve the performance. Synthetic data is generated 18 times faster than real acquisition speed, with full user control over the topography of the generated data.


Title: Perception-aware time optimal path parameterization for quadrotors
Key Words: autonomous aerial vehicles  helicopters  mobile robots  optimisation  path planning  perception-aware time optimal path parameterization  quadrotors  perception-aware time optimal path parametrization  quadrotor systems  on-board navigation  estimation algorithms  planning  efficient time optimal path parametrization algorithm  quadrotor platform  vision-driven vehicles  Trajectory  Cameras  Planning  Task analysis  Aerodynamics  Heuristic algorithms  Navigation 
Abstract: The increasing popularity of quadrotors has given rise to a class of predominantly vision-driven vehicles. This paper addresses the problem of perception-aware time optimal path parametrization for quadrotors. Although many different choices of perceptual modalities are available, the low weight and power budgets of quadrotor systems makes a camera ideal for on-board navigation and estimation algorithms. However, this does come with a set of challenges. The limited field of view of the camera can restrict the visibility of salient regions in the environment, which dictates the necessity to consider perception and planning jointly. The main contribution of this paper is an efficient time optimal path parametrization algorithm for quadrotors with limited field of view constraints. We show in a simulation study that a state-of-the-art controller can track planned trajectories, and we validate the proposed algorithm on a quadrotor platform in experiments.


Title: Generating Visibility-Aware Trajectories for Cooperative and Proactive Motion Planning
Key Words: mobile robots  motion estimation  object detection  path planning  road traffic  road vehicles  vehicles  autonomous vehicle  ego vehicle  visibility-aware planning  visibility-aware trajectories  proactive motion planning  cooperative motion planning  partially-occluded intersection  emergent behavior  Trajectory  Uncertainty  Planning  Safety  Autonomous vehicles  Splines (mathematics) 
Abstract: The safety of an autonomous vehicle not only depends on its own perception of the world around it, but also on the perception and recognition from other vehicles. If an ego vehicle considers the uncertainty other vehicles have about itself, then by reducing the estimated uncertainty it can increase its safety. In this paper, we focus on how an ego vehicle plans its trajectories through the blind spots of other vehicles. We create visibility-aware planning, where the ego vehicle chooses its trajectories such that it reduces the perceived uncertainty other vehicles may have about the state of the ego vehicle. We present simulations of traffic and highway environments, where an ego vehicle must pass another vehicle, make a lane change, or traverse a partially-occluded intersection. Emergent behavior shows that when using visibility-aware planning, the ego vehicle spends less time in a blind spot, and may slow down before entering the blind spot so as to increase the likelihood other vehicles perceive the ego vehicle.


Title: An obstacle-interaction planning method for navigation of actuated vine robots
Key Words: bending  collision avoidance  mobile robots  motion control  soft robotics  reliable robot-environment interaction models  obstacle-interaction model  robot tip  obstacle-interaction planning method  actuated vine robot navigation  wrinkling deformation  bending deformation  Soft robotics  Strain  Deformable models  Planning  Kinematics  Pneumatic systems 
Abstract: The field of soft robotics is grounded on the idea that, due to their inherent compliance, soft robots can safely interact with the environment. Thus, the development of effective planning and control pipelines for soft robots should incorporate reliable robot-environment interaction models. This strategy enables soft robots to effectively exploit contacts to autonomously navigate and accomplish tasks in the environment. However, for a class of soft robots, namely vine-inspired, tip-extending or "vine" robots, such interaction models and the resulting planning and control strategies do not exist. In this paper, we analyze the behavior of vine robots interacting with their environment and propose an obstacle-interaction model that characterizes the bending and wrinkling deformation induced by the environment. Starting from this, we devise a novel obstacle-interaction planning method for these robots. We show how obstacle interactions can be effectively leveraged to enlarge the set of reachable workspace for the robot tip, and verify our findings with both simulated and real experiments. Our work improves the capabilities of this new class of soft robot, helping to advance the field of soft robotics.


Title: Distributed Consensus Control of Multiple UAVs in a Constrained Environment
Key Words: autonomous aerial vehicles  control system synthesis  decentralised control  distributed control  multi-robot systems  position control  tracking  trees (mathematics)  multiple UAVs  constrained environment  consensus problem  multiple unmanned aerial vehicles  environmental constraints  general communication topology  directed spanning tree  position transformation function  dynamic reference position  yaw angle  asymmetric topology  local tracking controller  distributed consensus control  Topology  Decentralized control  Protocols  Unmanned aerial vehicles  Tracking loops  Heuristic algorithms  Attitude control 
Abstract: In this paper, we investigate the consensus problem of multiple unmanned aerial vehicles (UAVs) in the presence of environmental constraints under a general communication topology containing a directed spanning tree. First, based on a position transformation function, we propose a novel dynamic reference position and yaw angle for each UAV to cope with both the asymmetric topology and the constraints. Then, the backstepping-like design methodology is presented to derive a local tracking controller for each UAV such that its position and yaw angle can converge to the reference ones. The proposed protocol is distributed in the sense that, the input update of each UAV dynamically relies only on local state information from its neighborhood set and the constraints, and it does not require any additional centralized information. It is demonstrated that under the proposed protocol, all UAVs reach consensus without violation of the environmental constraints. Finally, simulation and experimental results are provided to demonstrate the performance of the protocol.


Title: Visual Coverage Maintenance for Quadcopters Using Nonsmooth Barrier Functions
Key Words: aircraft control  helicopters  image sensors  mobile robots  multi-robot systems  robot vision  quadcopters  visual sensors  coverage holes  coverage quality  sufficient conditions  nonsmooth barrier functions  visual coverage maintenance  coverage control  necessary conditions  Visualization  Monitoring  Robot sensing systems  Switches  Space missions 
Abstract: This paper presents a coverage control algorithm for teams of quadcopters with downward facing visual sensors that prevents the appearance of coverage holes in-between the monitored areas while maximizing the coverage quality as much as possible. We derive necessary and sufficient conditions for preventing the appearance of holes in-between the fields of views among trios of robots. Because this condition can be expressed as logically combined constraints, control nonsmooth barrier functions are implemented to enforce it. An algorithm which extends control nonsmooth barrier functions to hybrid systems is implemented to manage the switching among barrier functions caused by the changes of the robots composing trio. The performance and validity of the proposed algorithm are evaluated in simulation as well as on a team of quadcopters.


Title: Efficient Uncertainty-aware Decision-making for Automated Driving Using Guided Branching
Key Words: decision making  decision theory  Markov processes  multi-agent systems  road traffic  trees (mathematics)  dense traffic scenarios  automated vehicles  stochastic behaviors  traffic participants  perception uncertainties  partially observable Markov decision process  efficient uncertainty-aware decision-making  longitudinal behaviors  complex driving environments  automated driving  guided branching  domain-specific closed-loop policy tree structure  DCP-Tree  conditional focused branching mechanism  CFB  domain-specific expert knowledge  Planning  Decision making  Uncertainty  Semantics  Vegetation  Aerospace electronics  Safety 
Abstract: Decision-making in dense traffic scenarios is challenging for automated vehicles (AVs) due to potentially stochastic behaviors of other traffic participants and perception uncertainties (e.g., tracking noise and prediction errors, etc.). Although the partially observable Markov decision process (POMDP) provides a systematic way to incorporate these uncertainties, it quickly becomes computationally intractable when scaled to the real-world large-size problem. In this paper, we present an efficient uncertainty-aware decision-making (EUDM) framework, which generates long-term lateral and longitudinal behaviors in complex driving environments in real-time. The computation complexity is controlled to an appropriate level by two novel techniques, namely, the domain-specific closed-loop policy tree (DCP-Tree) structure and conditional focused branching (CFB) mechanism. The key idea is utilizing domain-specific expert knowledge to guide the branching in both action and intention space. The proposed framework is validated using both onboard sensing data captured by a real vehicle and an interactive multi-agent simulation platform. We also release the code of our framework to accommodate benchmarking.


Title: Vision-based Multi-MAV Localization with Anonymous Relative Measurements Using Coupled Probabilistic Data Association Filter
Key Words: aerospace robotics  microrobots  mobile robots  multi-robot systems  pose estimation  probability  robot vision  SLAM (robots)  target tracking  multiMAV system  robot team  vision based detection  distance measurements  coupled probabilistic data association filter  nonlinear measurements  visual based robot to robot detection  vision based multiMAV localization  robot localization  robot pose estimation  multiple microaerial vehicles  Robot kinematics  Robot sensing systems  Noise measurement  Probabilistic logic  Task analysis  Cameras 
Abstract: We address the localization of robots in a multi-MAV system where external infrastructure like GPS or motion capture systems may not be available. Our approach lends itself to implementation on platforms with several constraints on size, weight, and power (SWaP). Particularly, our framework fuses the onboard VIO with the anonymous, visual-based robot-to-robot detection to estimate all robot poses in one common frame, addressing three main challenges: 1) the initial configuration of the robot team is unknown, 2) the data association between each vision-based detection and robot targets is unknown, and 3) the vision-based detection yields false negatives, false positives, inaccurate, and provides noisy bearing, distance measurements of other robots. Our approach extends the Coupled Probabilistic Data Association Filter [1] to cope with nonlinear measurements. We demonstrate the superior performance of our approach over a simple VIO-based method in a simulation with the measurement models statistically modeled using the real experimental data. We also show how onboard sensing, estimation, and control can be used for formation flight.


Title: Variational Inference with Mixture Model Approximation for Applications in Robotics
Key Words: approximation theory  Bayes methods  control engineering computing  inference mechanisms  mixture models  robots  statistical distributions  variational inference  mixture model approximation  robot configurations  Bayesian computation  Robots  Mixture models  Kinematics  Bayes methods  Optimization  Task analysis  Planning 
Abstract: We propose to formulate the problem of representing a distribution of robot configurations (e.g. joint angles) as that of approximating a product of experts. Our approach uses variational inference, a popular method in Bayesian computation, which has several practical advantages over sampling-based techniques. To be able to represent complex and multimodal distributions of configurations, mixture models are used as approximate distribution. We show that the problem of approximating a distribution of robot configurations while satisfying multiple objectives arises in a wide range of problems in robotics, for which the properties of the proposed approach have relevant consequences. Several applications are discussed, including learning objectives from demonstration, planning, and warm-starting inverse kinematics problems. Simulated experiments are presented with a 7-DoF Panda arm and a 28-DoF Talos humanoid.


Title: Passive Quadrupedal Gait Synchronization for Extra Robotic Legs Using a Dynamically Coupled Double Rimless Wheel Model
Key Words: gait analysis  legged locomotion  motion control  robot dynamics  springs (mechanical)  synchronisation  wheels  extra robotic legs system  robotic augmentation  human operator  articulated robot legs  human-XRL quadruped system  rear legs  quadrupedal robots  quadrupedal locomotion  coupler design parameters  passive quadrupedal gait synchronization  dynamically coupled double rimless wheel system  Poincar return map  numerical simulation  Legged locomotion  Wheels  Synchronization  Couplers  Robot kinematics  Human Augmentation  Supernumerary Robotic Limbs  Exoskeletons  Locomotion  Nonlinear Dynamics 
Abstract: The Extra Robotic Legs (XRL) system is a robotic augmentation worn by a human operator consisting of two articulated robot legs that walk with the operator and help bear a heavy backpack payload. It is desirable for the Human-XRL quadruped system to walk with the rear legs lead the front by 25% of the gait period, minimizing the energy lost from foot impacts while maximizing balance stability. Unlike quadrupedal robots, the XRL cannot command the human's limbs to coordinate quadrupedal locomotion. Using a pair of Rimless Wheel models, it is shown that the systems coupled with a spring and damper converge to the desired 25% phase difference. A Poincar return map was generated using numerical simulation to examine the convergence properties to different coupler design parameters, and initial conditions. The Dynamically Coupled Double Rimless Wheel system was physically realized with a spring and dashpot chosen from the theoretical results, and initial experiments indicate that the desired synchronization properties may be achieved within several steps using this set of passive components alone.


Title: Optimal Fast Entrainment Waveform for Indirectly Controlled Limit Cycle Walker Against External Disturbances
Key Words: legged locomotion  limit cycles  numerical analysis  oscillators  robot dynamics  stability  optimal fast entrainment waveform  phase recovery  phase reduction theory  entrainment effect  limit cycle walking  indirectly controlled limit cycle walker  external disturbances  occasional perturbation  closed orbit  phase space  successive perturbation  accumulated deviation  control law  disturbed phase  wobbling mass  wobbling motion  Limit-cycles  Legged locomotion  Perturbation methods  Mathematical model  Oscillators  Convergence  Trajectory 
Abstract: After occasional perturbation, it is crucial to spontaneously control the limit cycle walking so that it quickly returns to its closed orbit in phase space. Otherwise, its stability can not be sufficiently guaranteed if the speed of recovery is slow while successive perturbation is applied. The accumulated deviation may eventually drive the phase outside the basin of attraction, leading to failure of the walking. In this sense, a control law that quickly recovers the disturbed phase before encountering the following perturbations is indispensable. With this consideration, here we analytically derive an optimal fast entrainment waveform that maximizes the speed of phase recovery based on phase reduction theory. Our theoretical method is numerically evaluated using a limit cycle walker, which is indirectly controlled by the oscillation of a wobbling mass via entrainment effect. The obtained waveform is used as the desired trajectory of the wobbling motion. The simulation results show that the waveform we derived achieves the best performance among all candidates. Our method helps to enhance the stability of limit cycle walking.


Title: Correspondence Identification in Collaborative Robot Perception through Maximin Hypergraph Matching
Key Words: concave programming  graph theory  image matching  image representation  multi-robot systems  object detection  robot vision  collaborative multirobot perception  nonconvex noncontinuous optimization problem  multirobot coordination  collaborative robot perception  hypergraph matching approach  Collaboration  Robot kinematics  Object recognition  Optimization  Robot sensing systems  Robustness 
Abstract: Correspondence identification is an essential problem for collaborative multi-robot perception, with the objective of deciding the correspondence of objects that are observed in the field of view of each robot. In this paper, we introduce a novel maximin hypergraph matching approach that formulates correspondence identification as a hypergraph matching problem. The proposed approach incorporates both spatial relationships and appearance features of objects to improve representation capabilities. It also integrates the maximin theorem to optimize the worst-case scenario in order to address distractions caused by non-covisible objects. In addition, we design an optimization algorithm to address the formulated non-convex non-continuous optimization problem. We evaluate our approach and compare it with seven previous techniques in two application scenarios, including multi-robot coordination on real robots and connected autonomous driving in simulations. Experimental results have validated the effectiveness of our approach in identifying object correspondence from partially overlapped views in collaborative perception, and have shown that the proposed maximin hypergraph matching approach outperforms previous techniques and obtains state-of-the-art performance.


Title: Distributed Multi-Target Tracking for Autonomous Vehicle Fleets
Key Words: cameras  Kalman filters  maximum likelihood estimation  target tracking  vehicular ad hoc networks  wireless sensor networks  Consensus Kalman Filter  fixed communication bandwidth  high fidelity urban driving simulator  autonomous cars  time-varying communication network  distributed multitarget tracking  autonomous vehicle fleets  scalable distributed target tracking algorithm  alternating direction method of multipliers  vehicle-to-vehicle network  sensing vehicle  Kalman filter-like update  centralized maximum a posteriori estimate  CARLA  on-board cameras  Sensors  Target tracking  Kalman filters  Microsoft Windows  Estimation  Trajectory  Optimization 
Abstract: We present a scalable distributed target tracking algorithm based on the alternating direction method of multipliers that is well-suited for a fleet of autonomous cars communicating over a vehicle-to-vehicle network. Each sensing vehicle communicates with its neighbors to execute iterations of a Kalman filter-like update such that each agent's estimate approximates the centralized maximum a posteriori estimate without requiring the communication of measurements. We show that our method outperforms the Consensus Kalman Filter in recovering the centralized estimate given a fixed communication bandwidth. We also demonstrate the algorithm in a high fidelity urban driving simulator (CARLA), in which 50 autonomous cars connected on a time-varying communication network track the positions and velocities of 50 target vehicles using on-board cameras.


Title: Optimal Control of an Energy-Recycling Actuator for Mobile Robotics Applications
Key Words: actuators  clutches  electric motors  energy consumption  gears  integer programming  mobile robots  optimal control  power consumption  quadratic programming  springs (mechanical)  torque  actuator power consumption  mobile robot design  elastic energy  electrical energy consumption  optimal control  given actuator design  optimized actuator energy consumption  optimized gear motor  simulated energy-recycling actuator  mobile robotics applications  Springs  Actuators  Torque  Power demand  Force  Robots  Gears  Optimization and optimal control  force control  prosthetics and exoskeletons 
Abstract: Actuator power consumption is a limiting factor in mobile robot design. In this paper we introduce the concept of an energy-recycling actuator, which uses an array of springs and clutches to capture and return elastic energy in parallel with an electric motor. Engaging and disengaging clutches appropriately could reduce electrical energy consumption without sacrificing controllability, but presents a challenging control problem. We formulated the optimal control objective of minimizing actuator power consumption as a mixed-integer quadratic program (MIQP) and solved for the global minimum. For a given actuator design and a wide range of simulated torque and rotation patterns, all corresponding to zero net work over one cycle, we compared optimized actuator energy consumption to that of an optimized gear motor with simple parallel elasticity. The simulated energy-recycling actuator consumed less electrical energy: 57% less on average and 80% less in the best case. These results demonstrate an effective approach to optimal control of this type of system, and suggest that energy-recycling actuators could substantially reduce power consumption in some robotics applications.


Title: Action Image Representation: Learning Scalable Deep Grasping Policies with Zero Real World Data
Key Words: convolutional neural nets  feature extraction  grippers  image colour analysis  image representation  learning (artificial intelligence)  robot vision  vectors  Action image representation  zero real world data  end-to-end deep-grasping policy  grasp quality  object-gripper relationship  deep convolutional network  Action Image representation  color images  depth images  combined color-depth  scalable deep grasping policy learning  salient feature extraction  Grasping  Robot sensing systems  Image representation  Proposals  Grippers  Task analysis 
Abstract: This paper introduces Action Image, a new grasp proposal representation that allows learning an end-to-end deep-grasping policy. Our model achieves 84% grasp success on 172 real world objects while being trained only in simulation on 48 objects with just naive domain randomization. Similar to computer vision problems, such as object detection, Action Image builds on the idea that object features are invariant to translation in image space. Therefore, grasp quality is invariant when evaluating the object-gripper relationship; a successful grasp for an object depends on its local context, but is independent of the surrounding environment. Action Image represents a grasp proposal as an image and uses a deep convolutional network to infer grasp quality. We show that by using an Action Image representation, trained networks are able to extract local, salient features of grasping tasks that generalize across different objects and environments. We show that this representation works on a variety of inputs, including color images (RGB), depth images (D), and combined color-depth (RGB-D). Our experimental results demonstrate that networks utilizing an Action Image representation exhibit strong domain transfer between training on simulated data and inference on real-world sensor streams. Finally, our experiments show that a network trained with Action Image improves grasp success (84% vs. 53%) over a baseline model with the same structure, but using actions encoded as vectors.


Title: Transferable Active Grasping and Real Embodied Dataset
Key Words: image colour analysis  learning (artificial intelligence)  manipulators  robot vision  stereo image processing  cluttered scenes  robot vision systems  reinforcement learning framework  3D vision architectures  RGB-D cameras  3-stage transferable active grasping pipeline  real embodied dataset  RED  Grasping  Clutter  Cameras  Image segmentation  Robot vision systems 
Abstract: Grasping in cluttered scenes is challenging for robot vision systems, as detection accuracy can be hindered by partial occlusion of objects. We adopt a reinforcement learning (RL) framework and 3D vision architectures to search for feasible viewpoints for grasping by the use of hand-mounted RGB-D cameras. To overcome the disadvantages of photo-realistic environment simulation, we propose a large-scale dataset called Real Embodied Dataset (RED), which includes full-viewpoint real samples on the upper hemisphere with amodal annotation and enables a simulator that has real visual feedback. Based on this dataset, a practical 3-stage transferable active grasping pipeline is developed, that is adaptive to unseen clutter scenes. In our pipeline, we propose a novel mask-guided reward to overcome the sparse reward issue in grasping and ensure category-irrelevant behavior. The grasping pipeline and its possible variants are evaluated with extensive experiments both in simulation and on a real-world UR-5 robotic arm.


Title: Self-supervised 6D Object Pose Estimation for Robot Manipulation
Key Words: image segmentation  intelligent robots  manipulators  pose estimation  robot vision  supervised learning  robot manipulation  self-supervised 6D object pose estimation  self-supervised learning  object configuration  pose estimation modules  object segmentation  6D pose estimation performance  robots skill teaching  Three-dimensional displays  Pose estimation  Cameras  Training  Manipulators  Grasping 
Abstract: To teach robots skills, it is crucial to obtain data with supervision. Since annotating real world data is time-consuming and expensive, enabling robots to learn in a self- supervised way is important. In this work, we introduce a robot system for self-supervised 6D object pose estimation. Starting from modules trained in simulation, our system is able to label real world images with accurate 6D object poses for self-supervised learning. In addition, the robot interacts with objects in the environment to change the object configuration by grasping or pushing objects. In this way, our system is able to continuously collect data and improve its pose estimation modules. We show that the self-supervised learning improves object segmentation and 6D pose estimation performance, and consequently enables the system to grasp objects more reliably. A video showing the experiments can be found at https://youtu.be/W1Y0Mmh1Gd8.


Title: Decentralized Task Allocation in Multi-Agent Systems Using a Decentralized Genetic Algorithm
Key Words: genetic algorithms  multi-agent systems  min-time objective  decentralized GA approach  task execution  multiagent collaborative search missions  decentralized genetic algorithm  multiagent systems  decentralized task allocation problem  decentralized evolutionary approaches  min-time performance  min-sum objective  Task analysis  Resource management  Genetic algorithms  Sociology  Statistics  Cost function  Message systems 
Abstract: In multi-agent collaborative search missions, task allocation is required to determine which agents will perform which tasks. We propose a new approach for decentralized task allocation based on a decentralized genetic algorithm (GA). The approach parallelizes a genetic algorithm across the team of agents, making efficient use of their computational resources. In the proposed approach, the agents continuously search for and share better solutions during task execution. We conducted simulation experiments to compare the decentralized GA approach and several existing approaches. Two objectives were considered: a min-sum objective (minimizing the total distance traveled by all agents) and a min-time objective (minimizing the time to visit all locations of interest). The results showed that the decentralized GA approach yielded task allocations that were better on the min-time objective than those created by existing approaches and solutions that were reasonable on the min-sum objective. The decentralized GA improved min-time performance by an average of 5.6% on the larger instances. The results indicate that decentralized evolutionary approaches have a strong potential for solving the decentralized task allocation problem.


Title: Real-Time Adaptive Assembly Scheduling in Human-Multi-Robot Collaboration According to Human Capability*
Key Words: assembling  genetic algorithms  multi-agent systems  multi-robot systems  robotic assembly  scheduling  human-multirobot collaboration  human capability  optimal assembly scheduling  robot adaptation  human-single-robot interaction  human-multirobot interaction  multiagent interactions  real-time adaptive assembly scheduling approach  formulated adaptive assembly scheduling problem  human-multirobot assembly tasks  Robots  Job shop scheduling  Task analysis  Real-time systems  Schedules  Adaptive scheduling  Adaptation models 
Abstract: Human-multi-robot collaboration is becoming more and more common in intelligent manufacturing. Optimal assembly scheduling of such systems plays a critical role in their production efficiency. Existing approaches mostly consider humans as agents with assumed or known capabilities, which leads to suboptimal performance in realistic applications where human capabilities usually change. In addition, most robot adaptation focuses on human-single-robot interaction and the adaptation in human-multi-robot interaction with changing human capability still remains challenging due to the complexity of the heterogeneous multi-agent interactions. This paper proposes a real-time adaptive assembly scheduling approach for human-multi-robot collaboration by modeling and incorporating changing human capability. A genetic algorithm is also designed to derive implementable solutions for the formulated adaptive assembly scheduling problem. The proposed approaches are validated through different simulated human-multi-robot assembly tasks and the results demonstrate the effectiveness and advantages of the proposed approaches.


Title: Trajectory Optimization for a Six-DOF Cable-Suspended Parallel Robot with Dynamic Motions Beyond the Static Workspace
Key Words: cables (mechanical)  manipulator dynamics  optimisation  path planning  position control  trajectory control  cable-suspended parallel robot  static workspace  trajectory optimization formulation  dynamic trajectories  six-degree-of-freedom  low-dimensional dynamic models  narrow feasible state space  dynamic similarity  point-mass CSPR  feasible force polyhedra  transition trajectories  highly dynamic motions  periodic trajectories  Dynamics  Planning  Robots  Trajectory optimization  Chebyshev approximation  Dynamic trajectory planning  optimization and optimal control  cable-suspended parallel robots 
Abstract: This paper presents a trajectory optimization formulation for planning dynamic trajectories of a six-degree-of-freedom (six-DOF) cable-suspended parallel robot (CSPR) that extend beyond the static workspace. The optimization is guided by low-dimensional dynamic models to overcome the local minima and accelerate the exploration of the narrow feasible state space. The dynamic similarity between the six-DOF CSPR and the three-DOF point-mass CSPR is discussed with the analyses of their feasible force polyhedra. Finally, the transition trajectories of a three-DOF CSPR are used as the initial guess of the translational part of the six-DOF motion. With the proposed approach, highly dynamic motions for a six-DOF CSPR are efficiently generated with multiple oscillations. The feasibility is demonstrated by point-to-point and periodic trajectories in the physics simulation.


Title: Context Dependant Iterative Parameter Optimisation for Robust Robot Navigation
Key Words: genetic algorithms  iterative methods  mobile robots  motion control  navigation  path planning  simulated environments  genetic algorithm  resulting parameter sets  substantial performance improvements  agricultural robots  context dependant iterative parameter optimisation  robust robot navigation  autonomous mobile robotics  motion control  path planning  robust performance  robot model  parameter tuning  underlying algorithm  substantial combinatorial challenge  extensive manual tuning  navigation actions  spatial context  navigation task  respective navigation algorithms  iterative optimisation  performance metrics  Navigation  Robots  Optimization  Tuning  Robustness  Genetic algorithms  Measurement 
Abstract: Progress in autonomous mobile robotics has seen significant advances in the development of many algorithms for motion control and path planning. However, robust performance from these algorithms can often only be expected if the parameters controlling them are tuned specifically for the respective robot model, and optimised for specific scenarios in the environment the robot is working in. Such parameter tuning can, depending on the underlying algorithm, amount to a substantial combinatorial challenge, often rendering extensive manual tuning of these parameters intractable. In this paper, we present a framework that permits the use of different navigation actions and/or parameters depending on the spatial context of the navigation task. We consider the respective navigation algorithms themselves mostly as a "black box", and find suitable parameters by means of an iterative optimisation, improving for performance metrics in simulated environments. We present a genetic algorithm incorporated into the framework, and empirically show that the resulting parameter sets lead to substantial performance improvements in both simulated and real-world environments in the domain of agricultural robots.


Title: Extending Riemmanian Motion Policies to a Class of Underactuated Wheeled-Inverted-Pendulum Robots
Key Words: collision avoidance  humanoid robots  manipulators  mobile robots  motion control  pendulums  robot dynamics  wheels  RMP formalism  underacutated systems  fully-actuated subsystem  residual dynamics  manipulation tasks  7-DoF system  second-order motion policies  RMP-based approaches  operational space control  fully state-dependent  collision avoidance bahaviors  control input  Riemmanian motion policies  underactuated wheeled-inverted-pendulum humanoid robot  Task analysis  Manifolds  Manipulator dynamics  Aerospace electronics  Humanoid robots  Measurement 
Abstract: Riemannian Motion Policies (RMPs) have recently been introduced as a way to specify second-order motion policies defined on robot task spaces. RMP-based approaches have the advantage of being more general than traditional approaches based on operational space control; for example, the generalized task inertia in an RMP can be fully state-dependent, which is particularly effective in designing collision avoidance bahaviors. But until now RMPs have been applied only to fully actuated systems, i.e. systems for which each degree of freedom (DoF) can be directly actuated by a control input. In this paper, we present a method that extends the RMP formalism to a class of underacutated systems whose dynamics are amenable to a decomposition into a fully-actuated subsystem and a residual dynamics. We show the efficacy of the approach by constructing a suitable decomposition for a Wheeled-Inverted-Pendulum (WIP) humanoid robot and applying our method to derive motion policies for combined locomotion and manipulation tasks. Simulation results are presented for a 7-DoF system with one degree of underactuation.


Title: Singularity-Free Inverse Dynamics for Underactuated Systems with a Rotating Mass
Key Words: manipulator dynamics  matrix algebra  motion control  nonlinear control systems  path planning  position control  singularity-free inverse dynamics  underactuated system  rotating mass  motion control  configuration singularities  configuration space  inertial coupling  small-amplitude sine wave  nonlinear dynamics  rolling system  singularity regions  coupling singularities  rolling carrier  Mathematical model  Couplings  Integrated circuits  Trajectory  Kinematics  Robots  Tensile stress 
Abstract: Motion control of underactuated systems through the inverse dynamics contains configuration singularities. These limitations in configuration space mainly stem from the inertial coupling that passive joints/bodies create. In this study, we present a model that is free from singularity while the trajectory of the rotating mass has a small-amplitude sine wave around its circle. First, we derive the modified non-linear dynamics for a rolling system. Also, the singularity regions for this underactuated system is demonstrated. Then, the wave parameters are designed under certain conditions to remove the coupling singularities. We obtain these conditions from the positive definiteness of the inertia matrix in the inverse dynamics. Finally, the simulation results are confirmed by using a prescribed Beta function on the specified states of the rolling carrier. Because our algebraic method is integrated into the non-linear dynamics, the proposed solution has a great potential to be extended to the Lagrangian mechanics with multiple degrees-of-freedom.


Title: SUMMIT: A Simulator for Urban Driving in Massive Mixed Traffic
Key Words: control engineering computing  multi-agent systems  road traffic  road vehicles  telecommunication traffic  traffic engineering computing  SUMMIT  urban driving  massive mixed traffic  unregulated urban crowd  high-speed traffic participants  high-fidelity simulator  crowd-driving algorithms  open-source OpenStreetMap map database  multiagent motion prediction model  unregulated urban traffic  heterogeneous agents  autonomous driving simulation  realistic traffic behaviors  crowd-driving settings  Roads  Robot sensing systems  Context modeling  Planning  Automobiles  Geometry  Kinematics 
Abstract: Autonomous driving in an unregulated urban crowd is an outstanding challenge, especially, in the presence of many aggressive, high-speed traffic participants. This paper presents SUMMIT, a high-fidelity simulator that facilitates the development and testing of crowd-driving algorithms. By leveraging the open-source OpenStreetMap map database and a heterogeneous multi-agent motion prediction model developed in our earlier work, SUMMIT simulates dense, unregulated urban traffic for heterogeneous agents at any worldwide locations that OpenStreetMap supports. SUMMIT is built as an extension of CARLA and inherits from it the physics and visual realism for autonomous driving simulation. SUMMIT supports a wide range of applications, including perception, vehicle control and planning, and end-to-end learning. We provide a context-aware planner together with benchmark scenarios and show that SUMMIT generates complex, realistic traffic behaviors in challenging crowd-driving settings.


Title: Optimizing performance in automation through modular robots
Key Words: flexible manufacturing systems  industrial robots  mobile robots  robot dynamics  robot kinematics  modular robots  flexible manufacturing  module composition  cycle time  energy efficiency  kinematic constraints  dynamic constraints  industrial robots  randomly generated tasks  performance metrics  modular robot  proModular.1  obstacle constraints  Cartesian space  Kinematics  Service robots  Collision avoidance  Trajectory  Task analysis  Heuristic algorithms 
Abstract: Flexible manufacturing and automation require robots that can be adapted to changing tasks. We propose to use modular robots that are customized from given modules for a specific task. This work presents an algorithm for proposing a module composition that is optimal with respect to performance metrics such as cycle time and energy efficiency, while considering kinematic, dynamic, and obstacle constraints. Tasks are defined as trajectories in Cartesian space, as a list of poses for the robot to reach as fast as possible, or as dexterity in a desired workspace. In a simulated comparison with commercially available industrial robots, we demonstrate the superiority of our approach in randomly generated tasks with respect to the chosen performance metrics. We use our modular robot proModular.1 for the comparison.


Title: Towards Practical Multi-Object Manipulation using Relational Reinforcement Learning
Key Words: graph theory  learning (artificial intelligence)  manipulators  mobile robots  neural nets  multiobject manipulation  relational reinforcement learning  learning robotic manipulation tasks  outrageous data requirements  task curriculum  graph-based relational architectures  simulated block stacking task  step-wise sparse rewards  zero-shot generalization  Task analysis  Stacking  Robots  Learning (artificial intelligence)  Poles and towers  Training  Three-dimensional displays 
Abstract: Learning robotic manipulation tasks using reinforcement learning with sparse rewards is currently impractical due to the outrageous data requirements. Many practical tasks require manipulation of multiple objects, and the complexity of such tasks increases with the number of objects. Learning from a curriculum of increasingly complex tasks appears to be a natural solution, but unfortunately, does not work for many scenarios. We hypothesize that the inability of the state- of-the-art algorithms to effectively utilize a task curriculum stems from the absence of inductive biases for transferring knowledge from simpler to complex tasks. We show that graph-based relational architectures overcome this limitation and enable learning of complex tasks when provided with a simple curriculum of tasks with increasing numbers of objects. We demonstrate the utility of our framework on a simulated block stacking task. Starting from scratch, our agent learns to stack six blocks into a tower. Despite using step-wise sparse rewards, our method is orders of magnitude more data- efficient and outperforms the existing state-of-the-art method that utilizes human demonstrations. Furthermore, the learned policy exhibits zero-shot generalization, successfully stacking blocks into taller towers and previously unseen configurations such as pyramids, without any further training.


Title: SwarmMesh: A Distributed Data Structure for Cooperative Multi-Robot Applications
Key Words: control engineering computing  data handling  data structures  distributed processing  mobile robots  multi-robot systems  storage management  topology  data item position  near-perfect data retention  distributed data structure  cooperative multirobot applications  distributed storage  mobile robots  shared global memory  external storage infrastructure  swarm topology  data storage  SwarmMesh  data type  Robots  Data structures  Peer-to-peer computing  Overlay networks  Routing  Distributed databases  Topology 
Abstract: We present an approach to the distributed storage of data across a swarm of mobile robots that forms a shared global memory. We assume that external storage infrastructure is absent, and that each robot is capable of devoting a quota of memory and bandwidth to distributed storage. Our approach is motivated by the insight that in many applications data is collected at the periphery of a swarm topology, but the periphery also happens to be the most dangerous location for storing data, especially in exploration missions. Our approach is designed to promote data storage in the locations in the swarm that best suit a specific feature of interest in the data, while accounting for the constantly changing topology due to individual motion. We analyze two possible features of interest: the data type and the data item position in the environment. We assess the performance of our approach in a large set of simulated experiments. The evaluation shows that our approach is capable of storing quantities of data that exceed the memory of individual robots, while maintaining near-perfect data retention in high-load conditions.


Title: Avalanche victim search via robust observers
Key Words: adaptive control  autonomous aerial vehicles  emergency management  multi-robot systems  observers  rescue robots  robust control  sensor fusion  avalanche victim search  robust observers  victim localization  ARVA sensor  adaptive control  UAVs  least square identifier  Receivers  Transmitters  Drones  Observers  Trajectory  Electromagnetics  Adaptive control  Search and Rescue  Robust Control 
Abstract: This paper introduces a new approach for victim localization in avalanches that will be exploited by UAVs using the ARVA sensor. We show that the nominal ARVA measurement can be linearly related to a quantity that is sufficient to reconstruct the victim position. We explicitly deal with a robust scenario in which the measurement is actually perturbed by a noise that grows with the distance to the victim and we propose an adaptive control scheme made of a least-square identifier and a trajectory generator whose role is both to guarantee the persistence of excitation for the identifier and to steer the ARVA receiver towards the victim. We show that the system succeeds in localizing the victim in a domain where the ARVA output is sufficiently informative and illustrate its performance in simulation. This new approach could significantly reduce the searching time by providing an exploitable estimate before having reached the victim. The work is framed within the EU project AirBorne whose goals is to develop at TRL8 a drone for quick localization of victims in avalanche scenarios.


Title: Information Theoretic Active Exploration in Signed Distance Fields
Key Words: deterministic algorithms  mobile robots  optimisation  path planning  sensors  tree searching  robot sensing trajectories  autonomous TSDF mapping  TSDF uncertainty  sensor measurements  efficient uncertainty prediction  long-horizon optimization  deterministic tree-search algorithm  information gain  TSDF distribution  efficient planning  uninformative sensing trajectories  active TSDF mapping approach  simulated environments  information theoretic active exploration  occupancy mapping  mobile robot  truncated signed distance field  robot motion primitive sequences  branch-and-bound pruning  complex visibility constraints  Robot sensing systems  Trajectory  Measurement uncertainty  Standards  Uncertainty 
Abstract: This paper focuses on exploration and occupancy mapping of unknown environments using a mobile robot. While a truncated signed distance field (TSDF) is a popular, efficient, and highly accurate representation of occupancy, few works have considered optimizing robot sensing trajectories for autonomous TSDF mapping. We propose an efficient approach for maintaining TSDF uncertainty and predicting its evolution from potential future sensor measurements without actually receiving them. Efficient uncertainty prediction is critical for long-horizon optimization of potential sensing trajectories. We develop a deterministic tree-search algorithm that evaluates the information gain between the TSDF distribution and potential observations along sequences of robot motion primitives. Efficient planning is achieved by branch-and-bound pruning of uninformative sensing trajectories. The effectiveness of our active TSDF mapping approach is evaluated in several simulated environments with complex visibility constraints.


Title: Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video
Key Words: interactive video  learning (artificial intelligence)  robot vision  video signal processing  adversarial skill-transfer loss  task domain  learned skill embeddings  entropy-regularized adversarial skill-transfer loss  temporal video coherence  metric learning loss  adversarial loss  task context  unlabeled multiview videos  task-agnostic skill embedding space  reinforcement learning agents  unsupervised robot skill learning  adversarial skill networks  learned embedding  Task analysis  Entropy  Measurement  Training  Robots  Interpolation  Learning (artificial intelligence) 
Abstract: Key challenges for the deployment of reinforcement learning (RL) agents in the real world are the discovery, representation and reuse of skills in the absence of a reward function. To this end, we propose a novel approach to learn a task-agnostic skill embedding space from unlabeled multi-view videos. Our method learns a general skill embedding independently from the task context by using an adversarial loss. We combine a metric learning loss, which utilizes temporal video coherence to learn a state representation, with an entropy-regularized adversarial skill-transfer loss. The metric learning loss learns a disentangled representation by attracting simultaneous viewpoints of the same observations and repelling visually similar frames from temporal neighbors. The adversarial skill-transfer loss enhances re-usability of learned skill embeddings over multiple task domains. We show that the learned embedding enables training of continuous control policies to solve novel tasks that require the interpolation of previously seen skills. Our extensive evaluation with both simulation and real world data demonstrates the effectiveness of our method in learning transferable skills from unlabeled interaction videos and composing them for new tasks. Code, pretrained models and dataset are available at http://robotskills.cs.uni-freiburg.de.


Title: TrueRMA: Learning Fast and Smooth Robot Trajectories with Recursive Midpoint Adaptations in Cartesian Space
Key Words: learning (artificial intelligence)  motion control  neurocontrollers  robot kinematics  time optimal control  trajectory control  TrueRMA  robot trajectory learning  recursive midpoint adaptations  Cartesian space  differentiable path  inverse kinematics  time optimal parameterization  reinforcement learning  robot movement  neural network training  KUKA iiwa robot  Trajectory  Robots  Kinematics  Task analysis  Training  Neural networks 
Abstract: We present TrueRMA, a data-efficient, model-free method to learn cost-optimized robot trajectories over a wide range of starting points and endpoints. The key idea is to calculate trajectory waypoints in Cartesian space by recursively predicting orthogonal adaptations relative to the midpoints of straight lines. We generate a differentiable path by adding circular blends around the waypoints, calculate the corresponding joint positions with an inverse kinematics solver and calculate a time-optimal parameterization considering velocity and acceleration limits. During training, the trajectory is executed in a physics simulator and costs are assigned according to a user-specified cost function which is not required to be differentiable. Given a starting point and an endpoint as input, a neural network is trained to predict midpoint adaptations that minimize the cost of the resulting trajectory via reinforcement learning. We successfully train a KUKA iiwa robot to keep a ball on a plate while moving between specified points and compare the performance of TrueRMA against two baselines. The results show that our method requires less training data to learn the task while generating shorter and faster trajectories.


Title: Fog Robotics Algorithms for Distributed Motion Planning Using Lambda Serverless Computing
Key Words: computational complexity  control engineering computing  manipulators  mobile robots  motion control  parallel processing  path planning  distributed motion planning  Lambda serverless computing  motion planning algorithms  RRT  computational load  local environment changes  cloud-based serverless lambda computing  parallel computation  serverless computers  learned parallel allocation  Amazon Lambda  sporadically computationally intensive motion planning tasks  fog robotics algorithms  Planning  Parallel processing  FAA  Robot kinematics  Cloud computing  Probabilistic logic 
Abstract: For robots using motion planning algorithms such as RRT and RRT*, the computational load can vary by orders of magnitude as the complexity of the local environment changes. To adaptively provide such computation, we propose Fog Robotics algorithms in which cloud-based serverless lambda computing provides parallel computation on demand. To use this parallelism, we propose novel motion planning algorithms that scale effectively with an increasing number of serverless computers. However, given that the allocation of computing is typically bounded by both monetary and time constraints, we show how prior learning can be used to efficiently allocate resources at runtime. We demonstrate the algorithms and application of learned parallel allocation in both simulation and with the Fetch commercial mobile manipulator using Amazon Lambda to complete a sequence of sporadically computationally intensive motion planning tasks.


Title: Exploration of 3D terrains using potential fields with elevation-based local distortions
Key Words: mobile robots  optical radar  radar receivers  stereo image processing  terrain mapping  exploration approach  potential fields  uneven terrains  high declivity regions  ground robot  elevation-based local distortions  mobile robots  numerous outdoor tasks  military applications  3D terrain exploration  patrolling application  delivery application  2D LIDAR sensors  Distortion  Robot sensing systems  Three-dimensional displays  Boundary conditions  Two dimensional displays 
Abstract: Mobile robots can be used in numerous outdoor tasks such as patrolling, delivery and military applications. In order to deploy mobile robots in this kind of environment, where there are different challenges like slopes, elevations, or even holes, they should be able to detect such challenges and determine the best path to accomplish their tasks. In this paper, we are proposing an exploration approach based on potential fields with local distortions, in which we define preferences in uneven terrains to avoid high declivity regions without compromising the best path. The approach was implemented and tested in simulated environments, considering a ground robot embedded with two 2D LIDAR sensors, and the experiments demonstrated the efficiency of our method.


Title: Upset Recovery Control for Quadrotors Subjected to a Complete Rotor Failure from Large Initial Disturbances
Key Words: attitude control  autonomous aerial vehicles  cascade control  control system synthesis  helicopters  Monte Carlo methods  quadratic programming  upset recovery control  fault-tolerant controller  arbitrary initial orientations  angular velocities  control method  post-failure quadrotor  Monte-Carlo simulation  control allocator  quadratic programming  control allocation method  almost-global convergence attitude controller  Rotors  Attitude control  Angular velocity  Fault tolerance  Fault tolerant systems  Resource management  Drones 
Abstract: This study has developed a fault-tolerant controller that is able to recover a quadrotor from arbitrary initial orientations and angular velocities, despite the complete failure of a rotor. This cascaded control method includes a position/altitude controller, an almost-global convergence attitude controller, and a control allocation method based on quadratic programming. As a major novelty, a constraint of undesirable angular velocity is derived and fused into the control allocator, which significantly improves the recovery performance. For validation, we have conducted a set of Monte-Carlo simulation to test the reliability of the proposed method of recovering the quadrotor from arbitrary initial attitude/rate conditions. In addition, real-life flight tests have been performed. The results demonstrate that the post-failure quadrotor can recover after being casually tossed into the air.


Title: Preliminary Study of an Aerial Manipulator with Elastic Suspension
Key Words: actuators  aerospace robotics  feedback  manipulator dynamics  propellers  vibration control  elastic suspension  aerial manipulator  contra-rotating propellers  computed torque control strategy  active vibration canceling  feedback linearization control strategy  robotic carrier  Springs  Manipulators  Propellers  Task analysis  Grippers 
Abstract: This paper presents a preliminary study of an Aerial Manipulator suspended by a spring to a robotic carrier. The suspended aerial manipulator is actuated by six pairs of contra-rotating propellers generating a 6-DoF wrench. Simulations show path following results using a computed torque (feedback linearization) control strategy. Active vibration canceling is validated experimentally on a first prototype.


Title: Perception-constrained and Motor-level Nonlinear MPC for both Underactuated and Tilted-propeller UAVS
Key Words: actuators  aircraft control  autonomous aerial vehicles  control system synthesis  helicopters  motion control  nonlinear control systems  predictive control  propellers  rotors (mechanical)  vehicle dynamics  motor-level Nonlinear MPC  tilted-propeller  Perception-constrained Nonlinear Model Predictive Control framework  real-time control  multirotor aerial vehicles  perceptive sensor  realistic actuator limitations  rotor minimum  maximum speeds  multirotor platforms  underactuated quadrotors  tilted-propellers hexarotors  motor-torque level  Propellers  Task analysis  Robot sensing systems  Real-time systems  Actuators  Vehicle dynamics  Torque 
Abstract: In this paper, we present a Perception-constrained Nonlinear Model Predictive Control (NMPC) framework for the real-time control of multi-rotor aerial vehicles. Our formulation considers both constraints from a perceptive sensor and realistic actuator limitations that are the rotor minimum and maximum speeds and accelerations. The formulation is meant to be generic and considers a large range of multi-rotor platforms (such as underactuated quadrotors or tilted-propellers hexarotors) since it does not rely on differential flatness for the dynamical equations, and a broad range of sensors, such as cameras, lidars, etc.... The perceptive constraints are expressed to maintain visibility of a feature point in the sensor's field of view, while performing a reference maneuver. We demonstrate both in simulation and real experiments that our framework is able to exploit the full capabilities of the multi-rotor, to achieve the motion under the aforementioned constraints, and control in real-time the platform at a motor-torque level, avoiding the use of an intermediate unconstrained trajectory tracker.


Title: Coordinate-Free Dynamics and Differential Flatness of a Class of 6DOF Aerial Manipulators
Key Words: control system synthesis  end effectors  manipulator dynamics  manipulator kinematics  path planning  position control  simulated aerial videography task  differential flatness  6DOF aerial manipulators  coordinate-free formulation  coupled dynamics  2DOF articulated manipulator  end effector frame  Manipulator dynamics  End effectors  Trajectory  Task analysis  Planning  Vehicle dynamics 
Abstract: In this work, we derive a coordinate-free formulation of the coupled dynamics of a class of 6DOF aerial manipulators consisting of an underactuated quadrotor equipped with a 2DOF articulated manipulator, and demonstrate that the system is differentially flat with respect to the end effector pose. In particular, we require the center of mass of the entire system to be fixed in the end effector frame, suggesting a reasonable mechanical design criterion. We make use of an inertial decoupling transformation to demonstrate differential flatness, allowing us to plan dynamically feasible trajectories for the system in the space of the 6DOF pose of the end effector, which is ideal for achieving precise manipulator tasks. Simulation results validate the flatness-based planning methodology for our dynamic model, and its usefulness is demonstrated in a simulated aerial videography task.


Title: Dynamic Interaction-Aware Scene Understanding for Reinforcement Learning in Autonomous Driving
Key Words: convolutional neural nets  decision making  graph theory  image representation  image sequences  learning (artificial intelligence)  neural net architecture  traffic engineering computing  DeepScene-Q off-policy reinforcement learning algorithms  graph-Q  graph convolutional networks  multiple variable-length sequences  novel deep scene architecture  complex interaction-aware scene representations  traffic participants  traffic signs  object types  high-level decision making  deep reinforcement learning  high-level decision component  perception component  autonomous driving systems  dynamic interaction-aware scene understanding  traffic simulator SUMO  Computer architecture  Autonomous vehicles  Lenses  Learning (artificial intelligence)  Decision making  Predictive models  Neural networks 
Abstract: The common pipeline in autonomous driving systems is highly modular and includes a perception component which extracts lists of surrounding objects and passes these lists to a high-level decision component. In this case, leveraging the benefits of deep reinforcement learning for high-level decision making requires special architectures to deal with multiple variable-length sequences of different object types, such as vehicles, lanes or traffic signs. At the same time, the architecture has to be able to cover interactions between traffic participants in order to find the optimal action to be taken. In this work, we propose the novel Deep Scenes architecture, that can learn complex interaction-aware scene representations based on extensions of either 1) Deep Sets or 2) Graph Convolutional Networks. We present the Graph-Q and DeepScene-Q off-policy reinforcement learning algorithms, both outperforming state-ofthe-art methods in evaluations with the publicly available traffic simulator SUMO.


Title: A Linearly Constrained Nonparametric Framework for Imitation Learning
Key Words: Bayes methods  end effectors  learning systems  predictive control  trajectory control  imitation learning  constrained skills  linearly constrained optimization problem  nonparametric solution  linearly constrained nonparametric framework  human skills learning  constrained motor skills learning  robotic systems  end-effector trajectory  linearly constrained kernelized movement primitives  LC-KMP  probabilistic properties  predictive control  locomotion tasks  grasping tasks  human robot collaborations  Trajectory  Probabilistic logic  Robots  Task analysis  Optimization  Kernel  Grasping 
Abstract: In recent years, a myriad of advanced results have been reported in the community of imitation learning, ranging from parametric to non-parametric, probabilistic to non-probabilistic and Bayesian to frequentist approaches. Meanwhile, ample applications (e.g., grasping tasks and humanrobot collaborations) further show the applicability of imitation learning in a wide range of domains. While numerous literature is dedicated to the learning of human skills in unconstrained environments, the problem of learning constrained motor skills, however, has not received equal attention. In fact, constrained skills exist widely in robotic systems. For instance, when a robot is demanded to write letters on a board, its end-effector trajectory must comply with the plane constraint from the board. In this paper, we propose linearly constrained kernelized movement primitives (LC-KMP) to tackle the problem of imitation learning with linear constraints. Specifically, we propose to exploit the probabilistic properties of multiple demonstrations, and subsequently incorporate them into a linearly constrained optimization problem, which finally leads to a non-parametric solution. In addition, a connection between our framework and the classical model predictive control is provided. Several examples including simulated writing and locomotion tasks are presented to show the effectiveness of our framework.


Title: Contact Stability Analysis of Magnetically-Actuated Robotic Catheter Under Surface Motion
Key Words: biological tissues  biomedical MRI  cardiology  catheters  medical image processing  medical robotics  contact stability analysis  magnetically-actuated robotic catheter  contact force quality  lesion formation  lesion size  gap-free lesion  tissue surface motion  contact model  contact force control schemes  heart surface motions  magnetic resonance imaging-actuated robotic catheter  Catheters  Force  Force control  Robots  Stability analysis  Magnetic resonance imaging  Friction 
Abstract: Contact force quality is one of the most critical factors for safe and effective lesion formation during cardiac ablation. The contact force and contact stability plays important roles in determining the lesion size and creating a gap-free lesion. In this paper, the contact stability of a novel magnetic resonance imaging (MRI)-actuated robotic catheter under tissue surface motion is studied. The robotic catheter is modeled using a pseudo-rigid-body model, and the contact model under surface constraint is provided. Two contact force control schemes to improve the contact stability of the catheter under heart surface motions are proposed and their performance are evaluated in simulation.


Title: Fast and accurate intracorporeal targeting through an anatomical orifice exhibiting unknown behavior.
Key Words: adaptive control  biomechanics  biomedical equipment  force control  manipulators  medical robotics  motion control  position control  surgery  anatomical orifice  minimally invasive surgery  interaction forces  patient anatomy  orifice behavior  adaptive control scheme  wrist velocity  tip velocity  intracorporeal targeting  instrument tip positioning  3DOF wrist center positioning problem  Robots  Instruments  Wrist  Surgery  Force  Adaptation models  Kinematics 
Abstract: Surgery may involve precise instrument tip positioning in a minimally invasive way. During these operations, the instrument is inserted in the body through an orifice. The movements of the instrument are constrained by interaction forces arising at the orifice level. The physical constraints may drastically vary depending on the patient's anatomy. This introduces uncertainties that challenge the positioning task for a robot. Indeed, it raises an antagonism: On one side, the required precision appeals for a rigid behavior. On the other side, forces applied at the entry point should be limited, which requires softness. In this paper we choose to minimize forces at the orifice by using a passive ball joint wrist to manipulate the instrument. From a control perspective, this leads to consider the task as a 3 DOF wrist center positioning problem, whose softness can be achieved through conventional low impedance control. However, positioning the wrist center, even with a high static precision, does not allow to achieve a high precision of the instrument tip positioning when the orifice behavior is not known. To cope with this problem, we implement a controller that servos the tip position by commanding the wrist position. In order to deal with uncertainties, we exploit an adaptive control scheme that identifies in real-time the unknown mapping between the wrist velocity and the tip velocity. Both simulations and in vitro experimental results show the efficiency of the control law.


Title: From Bipedal Walking to Quadrupedal Locomotion: Full-Body Dynamics Decomposition for Rapid Gait Generation
Key Words: gait analysis  legged locomotion  robot dynamics  trajectory control  full-order dynamics  rapid generation  stepping-in-place gaits  diagonally symmetric ambling gait  dynamic bipedal walking  quadrupedal locomotion  rapid gait generation  hybrid dynamics  three-dimensional quadrupedal robot  hybrid zero dynamics framework  bipedal robots  bipedal walking gaits  quadrupedal trajectory  Legged locomotion  Robot kinematics  Dynamics  Nonlinear dynamical systems  Jacobian matrices  Trajectory 
Abstract: This paper systematically decomposes a quadrupedal robot into bipeds to rapidly generate walking gaits and then recomposes these gaits to obtain quadrupedal locomotion. We begin by decomposing the full-order, nonlinear and hybrid dynamics of a three-dimensional quadrupedal robot, including its continuous and discrete dynamics, into two bipedal systems that are subject to external forces. Using the hybrid zero dynamics (HZD) framework, gaits for these bipedal robots can be rapidly generated (on the order of seconds) along with corresponding controllers. The decomposition is achieved in such a way that the bipedal walking gaits and controllers can be composed to yield dynamic walking gaits for the original quadrupedal robot - the result is the rapid generation of dynamic quadruped gaits utilizing the full-order dynamics. This methodology is demonstrated through the rapid generation (3.96 seconds on average) of four stepping-in-place gaits and one diagonally symmetric ambling gait at 0.35 m/s on a quadrupedal robot - the Vision 60, with 36 state variables and 12 control inputs - both in simulation and through outdoor experiments. This suggested a new approach for fast quadrupedal trajectory planning using full-body dynamics, without the need for empirical model simplification, wherein methods from dynamic bipedal walking can be directly applied to quadrupeds.


Title: Collaborative Multi-Robot Localization in Natural Terrain*
Key Words: autonomous underwater vehicles  filtering theory  mobile robots  Monte Carlo methods  multi-robot systems  path planning  sensor fusion  Monterey Bay  terrain relative navigation  filter architecture  collaborative multirobot localization  standard TRN  Monte Carlo simulation  inter-vehicle range measurements  autonomous underwater vehicle  multirobot information  TRN techniques  covariance intersection  Robots  Correlation  Atmospheric measurements  Particle measurements  Extraterrestrial measurements  Collaboration  Navigation 
Abstract: This paper presents a novel filter architecture that allows a team of vehicles to collaboratively localize using Terrain Relative Navigation (TRN). The work explores several causes of measurement correlation that preclude the use of traditional estimators, and proposes an estimator structure that eliminates one source of measurement correlation while properly incorporating others through the use of Covariance Intersection. The result is a consistent estimator that is able to augment proven TRN techniques with multi-robot information, significantly improving localization for vehicles in uninformative terrain. The approach is demonstrated using field data from an Autonomous Underwater Vehicle (AUV) navigating with TRN in Monterey Bay and simulated inter-vehicle range measurements. In addition, a Monte Carlo simulation was used to quantify the algorithm's performance on one example mission. Monte Carlo results show that a vehicle operating in uninformative terrain has 62% lower localization error when fusing range measurements to two converged AUVs than it would using standard TRN.


Title: Multi-Robot Control Using Coverage Over Time-Varying Non-Convex Domains
Key Words: computational geometry  linearisation techniques  multi-robot systems  time-varying systems  time-varying domains  nonconvex shape  nonconvex coverage problem  control law  time-varying density  time-varying diffeomorphism  multirobot control  time-varying nonconvex domains  coverage control  Robot kinematics  Multi-robot systems  Time-varying systems  Collision avoidance  Robot sensing systems  Transforms 
Abstract: This paper addresses the problem of a domain becoming non-convex while using coverage control of a multirobot system over time-varying domains. When the domain moves around in the workspace, its motion and the presence of obstacles might cause it to deform into some non-convex shape, and the robot team should act in a coordinating manner to maintain coverage. The proposed solution is based on a framework for constructing a diffeomorphism to transform a non-convex coverage problem into a convex one. A control law is developed to capture the effects of time variations (e.g., from a time-varying density, time-varying convex hull of the domain and time-varying diffeomorphism) in the system. Analytic expressions of each term in the control law are found for uniform density case. A simulation and robotic implementation are used to validate the proposed algorithm.


Title: Resilience in multi-robot target tracking through reconfiguration
Key Words: convex programming  covariance matrices  integer programming  Kalman filters  mobile robots  multi-robot systems  target tracking  multirobot target  resource availability  networked multirobot system  target tracking  sensing resources  computational resources  distributed Kalman filter  sensor measurement noise covariance matrix  sensing quality deteriorates  systems communication graph  sensor quality  active communication links  mixed integer semidefinite programming formulations  agent-centric strategy  team-centric strategy  greedy strategy  Robot sensing systems  Target tracking  Covariance matrices  Kalman filters  Robot kinematics 
Abstract: We address the problem of maintaining resource availability in a networked multi-robot system performing distributed target tracking. In our model, robots are equipped with sensing and computational resources enabling them to track a target's position using a Distributed Kalman Filter (DKF). We use the trace of each robot's sensor measurement noise covariance matrix as a measure of sensing quality. When a robot's sensing quality deteriorates, the systems communication graph is modified by adding edges such that the robot with deteriorating sensor quality may share information with other robots to improve the team's target tracking ability. This computation is performed centrally and is designed to work without a large change in the number of active communication links. We propose two mixed integer semi-definite programming formulations (an `agent-centric' strategy and a `team-centric' strategy) to achieve this goal. We implement both formulations and a greedy strategy in simulation and show that the team-centric strategy outperforms the agent-centric and greedy strategies.


Title: Eciton robotica: Design and Algorithms for an Adaptive Self-Assembling Soft Robot Collective
Key Words: mobile robots  multi-robot systems  search problems  self-adjusting systems  Eciton robotica  self-assembling soft robot collective  social insects  centralized control system  army ants build bridges  flexible materials  robotic collectives  flexible robots  self-assembling robotic systems  lattice-based structures  soft robots  amorphous structures  Robot sensing systems  Bridges  Grippers  Vibrations  Self-assembly  Hardware 
Abstract: Social insects successfully create bridges, rafts, nests and other structures out of their own bodies and do so with no centralized control system, simply by following local rules. For example, while traversing rough terrain, army ants (genus Eciton) build bridges which grow and dissolve in response to local traffic. Because these self-assembled structures incorporate smart, flexible materials (i.e. ant bodies) and emerge from local behavior, the bridges are adaptive and dynamic. With the goal of realizing robotic collectives with similar features, we designed a hardware system, Eciton robotica, consisting of flexible robots that can climb over each other to assemble compliant structures and communicate locally using vibration. In simulation, we demonstrate self-assembly of structures: using only local rules and information, robots build and dissolve bridges in response to local traffic and varying terrain. Unlike previous self-assembling robotic systems that focused on lattice-based structures and predetermined shapes, our system takes a new approach where soft robots attach to create amorphous structures whose final self-assembled shape can adapt to the needs of the group.


Title: Periodic movement learning in a soft-robotic arm*
Key Words: end effectors  learning (artificial intelligence)  medical robotics  motion control  trajectory control  cyclic rhythmic patterns  oscillatory signals  actuator  central pattern generator  periodic motion  end-effector  model-free neurodynamic scheme  CPG model  simulation model  learning architecture  periodic movement learning  modular bio-inspired soft-robotic arm  Oscillators  Trajectory  Manipulators  Biological system modeling  Soft robotics  Mathematical model  Reinforcement learning  Central pattern generators  Soft Robotics  Rhythmic movements 
Abstract: In this paper we introduce a novel technique that aims to dynamically control a modular bio-inspired soft-robotic arm in order to perform cyclic rhythmic patterns. Oscillatory signals are produced at the actuator's level by a central pattern generator (CPG), resulting in the generation of a periodic motion by the robot's end-effector. The proposed controller is based on a model-free neurodynamic scheme and is assigned with the task of training a policy that computes the parameters of the CPG model which generates a trajectory with desired features. The proposed methodology is first evaluated with a simulation model, which successfully reproduces the trained targets. Then experiments are also conducted using the real robot. Both procedures validate the efficiency of the learning architecture to successfully complete these tasks.


Title: Mechanism and Model of a Soft Robot for Head Stabilization in Cancer Radiation Therapy
Key Words: actuators  biomechanics  cancer  deformation  elastic deformation  elasticity  electric actuators  finite element analysis  kinematics  medical image processing  medical robotics  radiation therapy  robot kinematics  stress-strain relations  soft robot  head stabilization  cancer radiation  parallel robot mechanism  constituent soft actuators  real-time motion-correction  treatment machine  stress-strain constitutive laws  inverse kinematics  radially symmetric displacement formulation  finite elastic deformation framework  Strain  Actuators  Adaptation models  Stress  Real-time systems  Robots  Cancer 
Abstract: We present a parallel robot mechanism and the constitutive laws that govern the deformation of its constituent soft actuators. Our ultimate goal is the real-time motion-correction of a patient's head deviation from a target pose where the soft actuators control the position of the patient's cranial region on a treatment machine. We describe the mechanism, derive the stress-strain constitutive laws for the individual actuators and the inverse kinematics that prescribes a given deformation, and then present simulation results that validate our mathematical formulation. Our results demonstrate deformations consistent with our radially symmetric displacement formulation under a finite elastic deformation framework.


Title: Learning to combine primitive skills: A step towards versatile robotic manipulation 
Key Words: image motion analysis  learning (artificial intelligence)  manipulators  path planning  robot vision  dynamic scene changes  visual inputs  task-specific reward engineering  previous limitations  reinforcement learning approach  primitive skills  learning methods  intermediate rewards  complete task demonstrations  vision-based task planning  basic skills  synthetic demonstrations  data augmentation  manipulation tasks  UR5 robotic arm  versatile robotic manipulation  robotics  traditional task  motion planning methods  state observability  Task analysis  Robots  Planning  Learning (artificial intelligence)  Training  Trajectory  Visualization 
Abstract: Manipulation tasks such as preparing a meal or assembling furniture remain highly challenging for robotics and vision. Traditional task and motion planning (TAMP) methods can solve complex tasks but require full state observability and are not adapted to dynamic scene changes. Recent learning methods can operate directly on visual inputs but typically require many demonstrations and/or task-specific reward engineering. In this work we aim to overcome previous limitations and propose a reinforcement learning (RL) approach to task planning that learns to combine primitive skills. First, compared to previous learning methods, our approach requires neither intermediate rewards nor complete task demonstrations during training. Second, we demonstrate the versatility of our vision-based task planning in challenging settings with temporary occlusions and dynamic scene changes. Third, we propose an efficient training of basic skills from few synthetic demonstrations by exploring recent CNN architectures and data augmentation. Notably, while all of our policies are learned on visual inputs in simulated environments, we demonstrate the successful transfer and high success rates when applying such policies to manipulation tasks on a real UR5 robotic arm.


Title: Learning Affordance Space in Physical World for Vision-based Robotic Object Manipulation
Key Words: image texture  learning (artificial intelligence)  manipulators  neural nets  probability  robot vision  pixel-wise probability affordance map  image space  world space  viewpoints  multiple-object pushing  multiple-object grasping  physical world  vision-based robotic object manipulation  Affordance Space Perception Network  deep neural network  3D affordance space  training strategy  task-agnostic framework  singular-object pushing  singular-object grasping  Robots  Task analysis  Robustness  Grasping  Data models  Calibration  Adaptation models 
Abstract: What is a proper representation for objects in manipulation? What would human try to perceive when manipulating a new object in a new environment? In fact, instead of focusing on the texture and illumination, human can infer the "affordance" [36] of the objects from vision. Here "affordance" describes the object's intrinsic property that affords a particular type of manipulation. In this work, we investigate whether such affordance can be learned by a deep neural network. In particular, we propose an Affordance Space Perception Network (ASPN) that takes an image as input and outputs an affordance map. Different from existing works that infer the pixel-wise probability affordance map in image space, our affordance is defined in the real world space, thus eliminates the need of hand-eye calibration. In addition, we extend the representation ability of affordance by defining it in a 3D affordance space and propose a novel training strategy to improve the performance. Trained purely with simulation data, ASPN can achieve significant performance in the real world. It is a task-agnostic framework and can handle different objects, scenes and viewpoints. Extensive real-world experiments demonstrate the accuracy and robustness of our approach. We achieve the success rates of 94.2% for singular-object pushing and 92.4% for multiple-object pushing. We also achieve the success rates of 97.2% for singular-object grasping and 95.4% for multiple-object grasping, which outperform current state-of-the-art methods.


Title: OpenVINS: A Research Platform for Visual-Inertial Estimation
Key Words: calibration  cameras  estimation theory  image filtering  Kalman filters  robot vision  SLAM (robots)  research platform  visual-inertial estimation research  open sourced codebase  visual-inertial systems  visual-inertial estimation features  on-manifold sliding window Kalman filter  consistent First-Estimates Jacobian treatments  modular type system  extendable visual-inertial system simulator  competing estimation performance  OpenVINS  online camera intrinsic calibration  open sourced algorithms  online camera extrinsic calibration  inertial sensor time offset calibration  SLAM landmarks  state management  Cameras  Current measurement  Jacobian matrices  Calibration  Documentation  Estimation  Robot sensing systems 
Abstract: In this paper, we present an open platform, termed OpenVINS, for visual-inertial estimation research for both the academic community and practitioners from industry. The open sourced codebase provides a foundation for researchers and engineers to quickly start developing new capabilities for their visual-inertial systems. This codebase has out of the box support for commonly desired visual-inertial estimation features, which include: (i) on-manifold sliding window Kalman filter, (ii) online camera intrinsic and extrinsic calibration, (iii) camera to inertial sensor time offset calibration, (iv) SLAM landmarks with different representations and consistent First-Estimates Jacobian (FEJ) treatments, (v) modular type system for state management, (vi) extendable visual-inertial system simulator, and (vii) extensive toolbox for algorithm evaluation. Moreover, we have also focused on detailed documentation and theoretical derivations to support rapid development and research, which are greatly lacked in the current open sourced algorithms. Finally, we perform comprehensive validation of the proposed OpenVINS against state-of-the-art open sourced algorithms, showing its competing estimation performance.


Title: Decentralized Collaborative State Estimation for Aided Inertial Navigation
Key Words: communication complexity  inertial navigation  Kalman filters  nonlinear filters  position measurement  state estimation  communication links  versatile filter formulation  independent state estimation  relative position measurements  aided inertial navigation  Q-ESEKF  IMU propagation  communication complexity  decentralized collaborative state estimation  quaternion-based error-state extended Kalman filter  CSE concept  probabilistic reinitialization  prominent benchmark datasets  Cameras  Sensors  Collaboration  State estimation  Three-dimensional displays  Calibration  Robots 
Abstract: In this paper, we present a Quaternion-based Error-State Extended Kalman Filter (Q-ESEKF) based on IMU propagation with an extension for Collaborative State Estimation (CSE) and a communication complexity of O(1) (in terms of required communication links). Our approach combines a versatile filter formulation with the concept of CSE, allowing independent state estimation on each of the agents and at the same time leveraging and statistically maintaining interdependencies between agents, after joint measurements and communication (i.e. relative position measurements) occur. We discuss the development of the overall framework and the probabilistic (re-)initialization of the agent's states upon initial or recurring joint observations. Our approach is evaluated in a simulation framework on two prominent benchmark datasets in 3D.


Title: Analytic Combined IMU Integration (ACI2) For Visual Inertial Navigation
Key Words: calibration  inertial navigation  maximum likelihood estimation  Monte Carlo methods  optimisation  robot vision  sensor fusion  SLAM (robots)  analytic combined IMU integration  visual inertial navigation  batch optimization  visual sensor fusion  robotic tasks  maximum likelihood estimation  partial-fixed estimates  ACI2  inertial measurement unit  Monte-Carlo simulations  Optimization  Jacobian matrices  Maximum likelihood estimation  Time measurement  Cameras  Visualization  Calibration 
Abstract: Batch optimization based inertial measurement unit (IMU) and visual sensor fusion enables high rate localization for many robotic tasks. However, it remains a challenge to ensure that the batch optimization is computationally efficient while being consistent for high rate IMU measurements without marginalization. In this paper, we derive inspiration from maximum likelihood estimation with partial-fixed estimates to provide a unified approach for handing both IMU preintegration and time-offset calibration. We present a modularized analytic combined IMU integrator (ACI2) with elegant derivations for IMU integrations, bias Jabcobians and related covariances. To simplify our derivation, we also prove that the right Jacobians for Hamilton quaterions and SO(3) are equivalent. Finally, we present a time offset calibrator that operates by fixing the linearization point for a given time offset. This reduces re-integration of the IMU measurements and thus improve efficiency. The proposed ACI2 and time-offset calibration is verified by intensive Monte-Carlo simulations generated from real world datasets. A proof-of-concept real world experiment is also conducted to verify the proposed ACI2 estimator.


Title: Kinematic Modeling and Compliance Modulation of Redundant Manipulators Under Bracing Constraints
Key Words: actuators  biomechanics  design engineering  dexterous manipulators  end effectors  manipulator kinematics  motion control  redundant manipulators  kinematic modeling  compliance modulation  redundant manipulators  bracing constraints  low torque actuators  passive safety reasons  human operator  in-situ collaborative robots  conflicting demands  low torque actuation  deep confined spaces  constrained kinematics  endeffector compliance  redundancy resolution framework  directional compliance  end-effector dexterity  kinematic simulation results  redundancy resolution strategy  kinematic conditioning  bracing task  admittance control framework  collaborative control  ISCR  Kinematics  Robots  Redundancy  Task analysis  Collaboration  Torque  Safety  Bracing  redundancy resolution  stiffness modulation  compliance  collaborative robots 
Abstract: Collaborative robots should ideally use low torque actuators for passive safety reasons. However, some applications require these collaborative robots to reach deep into confined spaces while assisting a human operator in physically demanding tasks. In this paper, we consider the use of in-situ collaborative robots (ISCRs) that balance the conflicting demands of passive safety dictating low torque actuation and the need to reach into deep confined spaces. We consider the judicious use of bracing as a possible solution to these conflicting demands and present a modeling framework that takes into account the constrained kinematics and the effect of bracing on the endeffector compliance. We then define a redundancy resolution framework that minimizes the directional compliance of the end-effector while maximizing end-effector dexterity. Kinematic simulation results show that the redundancy resolution strategy successfully decreases compliance and improves kinematic conditioning while satisfying the constraints imposed by the bracing task. Applications of this modeling framework can support future research on the choice of bracing locations and support the formation of an admittance control framework for collaborative control of ISCRs under bracing constraints. Such robots can benefit workers in the future by reducing the physiological burdens that contribute to musculoskeletal injury.


Title: Differentiable Mapping Networks: Learning Structured Map Representations for Sparse Visual Localization
Key Words: gradient methods  image representation  learning (artificial intelligence)  neural net architecture  particle filtering (numerical methods)  robot vision  DMN architecture  end-to-end differentiable  sparse visual localization  end-to-end learning  differentiable mapping network  spatially structured view-embedding map  subsequent visual localization  learning structured map representations  Street View dataset  particle filter  gradient descent  robotics  neural network architecture  Task analysis  Visualization  Feature extraction  Neural networks  Robot kinematics  Three-dimensional displays 
Abstract: Mapping and localization, preferably from a small number of observations, are fundamental tasks in robotics. We address these tasks by combining spatial structure (differentiable mapping) and end-to-end learning in a novel neural network architecture: the Differentiable Mapping Network (DMN). The DMN constructs a spatially structured view-embedding map and uses it for subsequent visual localization with a particle filter. Since the DMN architecture is end-to-end differentiable, we can jointly learn the map representation and localization using gradient descent. We apply the DMN to sparse visual localization, where a robot needs to localize in a new environment with respect to a small number of images from known viewpoints. We evaluate the DMN using simulated environments and a challenging real-world Street View dataset. We find that the DMN learns effective map representations for visual localization. The benefit of spatial structure increases with larger environments, more viewpoints for mapping, and when training data is scarce. Project website: https://sites.google.com/view/differentiable-mapping.


Title: Attentive Task-Net: Self Supervised Task-Attention Network for Imitation Learning using Video Demonstration
Key Words: convolutional neural nets  feature extraction  image representation  learning (artificial intelligence)  video signal processing  task-specific objects  intended task  imitation learning  video demonstration  end-to-end self-supervised feature representation network  video-based task imitation  multilevel spatial attention module  spatial features  weighted combination  multiple intermediate feature maps  respective feature maps  metric learning loss  multiple view points  AT-Net features  reinforcement learning problem  attentive task-net  self supervised task-attention network  neural connections  learning task-specific feature embeddings  temporally consecutive frames  publicly available multiview pouring dataset  RL agent  Gazebo simulator  CNN pipeline  Task analysis  Measurement  Robots  Feature extraction  Training  Visualization  Pipelines 
Abstract: This paper proposes an end-to-end self-supervised feature representation network named Attentive Task-Net or AT-Net for video-based task imitation. The proposed AT-Net incorporates a novel multi-level spatial attention module to highlight spatial features corresponding to the intended task demonstrated by the expert. The neural connections in AT-Net ensure the relevant information in the demonstration is amplified and the irrelevant information is suppressed while learning task-specific feature embeddings. This is achieved by a weighted combination of multiple intermediate feature maps of the input image at different stages of the CNN pipeline. The weights of the combination are given by the compatibility scores, predicted by the attention module for respective feature maps. The AT-Net is trained using a metric learning loss which aims to decrease the distance between the feature representations of concurrent frames from multiple view points and increase the distance between temporally consecutive frames. The AT-Net features are then used to formulate a reinforcement learning problem for task imitation. Through experiments on the publicly available Multi-view pouring dataset, it is demonstrated that the output of the attention module highlights the task-specific objects while suppressing the rest of the background. The efficacy of the proposed method is further validated by qualitative and quantitative comparison with a state-of-the-art technique along with intensive ablation studies. The proposed method is implemented to imitate a pouring task where an RL agent is learned with the AT-Net in Gazebo simulator. Our findings show that the AT-Net achieves 6.5% decrease in alignment error along with a reduction in the number of training iterations by almost 155k over the state-of-the-art while satisfactorily imitating the intended task.


Title: Learning a Control Policy for Fall Prevention on an Assistive Walking Device
Key Words: biomechanics  gait analysis  handicapped aids  humanoid robots  legged locomotion  assistive walking device  fall prevention  control policy  augmented assistive device  models realistic human gait  robust human walking policy  actuators  onboard sensors  recovery policy  fall predictor  Legged locomotion  Perturbation methods  Assistive devices  Sensors  Adaptation models  Biological system modeling 
Abstract: Fall prevention is one of the most important components in senior care. We present a technique to augment an assistive walking device with the ability to prevent falls. Given an existing walking device, our method develops a fall predictor and a recovery policy by utilizing the onboard sensors and actuators. The key component of our method is a robust human walking policy that models realistic human gait under a moderate level of perturbations. We use this human walking policy to provide training data for the fall predictor, as well as to teach the recovery policy how to best modify the person's gait when a fall is imminent. Our evaluation shows that the human walking policy generates walking sequences similar to those reported in biomechanics literature. Our experiments in simulation show that the augmented assistive device can indeed help recover balance from a variety of external perturbations. We also provide a quantitative method to evaluate the design choices for an assistive device.


Title: Towards Safe Human-Robot Collaboration Using Deep Reinforcement Learning
Key Words: hazards  human-robot interaction  industrial robots  learning (artificial intelligence)  mobile robots  neural nets  occupational safety  risk management  hazard source  safety engineers  risk assessment processes  deep RL agents  human-robot collaboration  HRC-productivity  deep reinforcement learning  systematic methodology  core components  Task analysis  Training  Hazards  Robot sensing systems  Service robots 
Abstract: Safety in Human-Robot Collaboration (HRC) is a bottleneck to HRC-productivity in industry. With robots being the main source of hazards, safety engineers use over-emphasized safety measures, and carry out lengthy and expensive risk assessment processes on each HRC-layout reconfiguration. Recent advances in deep Reinforcement Learning (RL) offer solutions to add intelligence and comprehensibility of the environment to robots. In this paper, we propose a framework that uses deep RL as an enabling technology to enhance intelligence and safety of the robots in HRC scenarios and, thus, reduce hazards incurred by the robots. The framework offers a systematic methodology to encode the task and safety requirements and context of applicability into RL settings. The framework also considers core components, such as behavior explainer and verifier, which aim for transferring learned behaviors from research labs to industry. In the evaluations, the proposed framework shows the capability of deep RL agents learning collision-free point-to-point motion on different robots inside simulation, as shown in the supplementary video.


Title: Learning User Preferences from Corrections on State Lattices
Key Words: human-robot interaction  learning (artificial intelligence)  learning systems  mobile robots  path planning  robot programming  state lattices  autonomous mobile robots  motion planning problem  robot traffic  motion features  learned user preferences  learning from corrections  algorithm completeness proving  human robot interaction  Task analysis  Lattices  Cost function  Mobile robots  Robot motion  Learning (artificial intelligence) 
Abstract: Enabling a broader range of users to efficiently deploy autonomous mobile robots requires intuitive frameworks for specifying a robot's task and behaviour. We present a novel approach using learning from corrections (LfC), where a user is iteratively presented with a solution to a motion planning problem. Users might have preferences about parts of a robot's environment that are suitable for robot traffic or that should be avoided as well as preferences on the control actions a robot can take. The robot is initially unaware of these preferences; thus, we ask the user to provide a correction to the presented path. We assume that the user evaluates paths based on environment and motion features. From a sequence of corrections we learn weights for these features, which are then considered by the motion planner, resulting in future paths that better fit the user's preferences. We prove completeness of our algorithm and demonstrate its performance in simulations. Thereby, we show that the learned preferences yield good results not only for a set of training tasks but also for test tasks, as well as for different types of user behaviour.


Title: Visual Servoing-based Navigation for Monitoring Row-Crop Fields
Key Words: agricultural robots  agriculture  agrochemicals  crops  mobile robots  path planning  robot vision  visual servoing  visual servoing-based navigation  autonomous navigation  field robots  precision agriculture tasks  agrochemicals  visual-based navigation framework  crop-row structure  row-crop fields monitoring  Agriculture  Navigation  Cameras  Robot vision systems  Visualization  Monitoring 
Abstract: Autonomous navigation is a pre-requisite for field robots to carry out precision agriculture tasks. Typically, a robot has to navigate along a crop field multiple times during a season for monitoring the plants, for applying agrochemicals, or for performing targeted interventions. In this paper, we propose a visual-based navigation framework tailored to row-crop fields that exploits the regular crop-row structure present in fields. Our approach uses only the images from on-board cameras without the need for performing explicit localization or maintaining a map of the field. Thus, it can operate without expensive RTK-GPS solutions often used in agricultural automation systems. Our navigation approach allows the robot to follow the crop rows accurately and handles the switch to the next row seamlessly within the same framework. We implemented our approach using C++ and ROS and thoroughly tested it in several simulated fields with different shapes and sizes. We also demonstrated the system running at frame-rate on an actual robot operating on a test row-crop field. The code and data have been published.


Title: Optimal Routing Schedules for Robots Operating in Aisle-Structures
Key Words: computational complexity  graph theory  mobile robots  optimisation  scheduling  COP-FR  computational complexity  optimal solutions  highly unbalanced rewards  optimal routing schedules  aisle-structures  constant-cost orienteering problem  travel budget  aisle-graph  loosely connected rows  Robots  Optimized production technology  Routing  Heuristic algorithms  Task analysis  Irrigation  Automation 
Abstract: In this paper, we consider the Constant-cost Orienteering Problem (COP) where a robot, constrained by a limited travel budget, aims at selecting a path with the largest reward in an aisle-graph. The aisle-graph consists of a set of loosely connected rows where the robot can change lane only at either end, but not in the middle. Even when considering this special type of graphs, the orienteering problem is known to be intractable. We optimally solve in polynomial time two special cases, COP-FR where the robot can only traverse full rows, and COP-SC where the robot can access the rows only from one side. To solve the general COP, we then apply our special case algorithms as well as a new heuristic that suitably combines them. Despite its light computational complexity and being confined into a very limited class of paths, the optimal solutions for COP-FR turn out to be competitive in terms of achieved rewards even for COP. This is shown by means of extended simulations performed on both real and synthetic scenarios. Furthermore, our new heuristic for the general case outperforms state-of-art algorithms, especially for input with highly unbalanced rewards.


Title: Time Optimal Motion Planning with ZMP Stability Constraint for Timber Manipulation
Key Words: humanoid robots  legged locomotion  mobile robots  motion control  optimisation  path planning  robot kinematics  stability  timber  time optimal motion planning  ZMP stability constraint  timber manipulation  dynamic stability-constrained optimal motion  timber harvesting machine  rough terrain  kinematics model  optimization problem  computation time  motion plan  dynamic stability constraint  zero moment point stability measure  Planning  Kinematics  Manipulator dynamics  Acceleration  Stability analysis  Computational modeling 
Abstract: This paper presents a dynamic stability-constrained optimal motion planning algorithm developed for a timber harvesting machine working on rough terrain. First, the kinematics model of the machine, and the Zero Moment Point (ZMP) stability measure is presented. Then, an approach to simplify the model to gain insight and achieve a fast solution of the optimization problem is introduced. The performance and computation time of the motion plan obtained with the simplified model is compared against that obtained with the full kinematics model of the machine with the help of MATLAB simulations. The results demonstrate feasibility of fast motion planning while satisfying the dynamic stability constraint.


Title: Online calibration of exterior orientations of a vehicle-mounted surround-view camera system
Key Words: calibration  cameras  computer vision  motion estimation  path planning  road vehicles  large-scale outdoor experiments  indoor experiments  exterior orientation parameters  highly practicable online optimisation strategy  complete online optimisation strategy  camera-to-camera transformations  camera-to-vehicle rotations  camera positions  exterior orientation calibration  vision-based vehicle motion estimation  neighbouring views  extrinsic calibration  intelligent vehicle behaviour  exterior perception modality  passenger vehicles  vehicle-mounted surround-view camera system  online calibration  Cameras  Calibration  Optimization  Motion estimation  Geometry  Automobiles  Mirrors 
Abstract: The increasing availability of surround-view camera systems in passenger vehicles motivates their use as an exterior perception modality for intelligent vehicle behaviour. An important problem within this context is the extrinsic calibration between the cameras, which is challenging due to the often reduced overlap between the fields of view of neighbouring views. Our work is motivated by two insights. First, we argue that the accuracy of vision-based vehicle motion estimation depends crucially on the quality of exterior orientation calibration, while design parameters for camera positions typically provide sufficient accuracy. Second, we demonstrate how planar vehicle motion related direction vectors can be used to accurately identify individual camera-to-vehicle rotations, which are more useful than the commonly and tediously derived camera-to-camera transformations. We present a complete and highly practicable online optimisation strategy to obtain the exterior orientation parameters and conclude with successful tests on simulated, indoor, and large-scale outdoor experiments.


Title: Planning, Learning and Reasoning Framework for Robot Truck Unloading
Key Words: control engineering computing  decision making  industrial manipulators  inference mechanisms  learning (artificial intelligence)  path planning  production engineering computing  unloading  reasoning framework  industrial manipulator robot  real-time motion planning  complex robotic system  high-level decision-making  belief space planning  offline learning  execution module  robot truck unloading  online decision-making  Planning  Robot sensing systems  Task analysis  Decision making  Collision avoidance  Real-time systems 
Abstract: We consider the task of autonomously unloading boxes from trucks using an industrial manipulator robot. There are multiple challenges that arise: (1) real-time motion planning for a complex robotic system carrying two articulated mechanisms, an arm and a scooper, (2) decision-making in terms of what action to execute next given imperfect information about boxes such as their masses, (3) accounting for the sequential nature of the problem where current actions affect future state of the boxes, and (4) real-time execution that interleaves high-level decision-making with lower level motion planning. In this work, we propose a planning, learning, and reasoning framework to tackle these challenges, and describe its components including motion planning, belief space planning for offline learning, online decision-making based on offline learning, and an execution module to combine decision-making with motion planning. We analyze the performance of the framework on real-world scenarios. In particular, motion planning and execution modules are evaluated in simulation and on a real robot, while offline learning and online decision-making are evaluated in simulated real-world scenarios.


Title: Assembly of randomly placed parts realized by using only one robot arm with a general parallel-jaw gripper
Key Words: cost reduction  dexterous manipulators  grippers  industrial manipulators  legged locomotion  materials handling  position control  robotic assembly  robotic assembly  robot arm  peg-in-hole assembly  parallel-jaw gripper  industry assembly lines  parting feeding machine  sorting process  cost reduction  grasping process  two-fingered gripper  design engineering  orientation control  offset position control  Grippers  Fasteners  Robotic assembly  Manipulators  Industries  Sensors 
Abstract: In industry assembly lines, parts feeding machines are widely employed as the prologue of the whole procedure. They play the role of sorting the parts randomly placed in bins to the state with specified pose. With the help of the parts feeding machines, the subsequent assembly processes by robot arm can always start from the same condition. Thus it is expected that function of parting feeding machine and the robotic assembly can be integrated with one robot arm. This scheme can provide great flexibility and can also contribute to reduce the cost. The difficulties involved in this scheme lie in the fact that in the part feeding phase, the pose of the part after grasping may be not proper for the subsequent assembly. Sometimes it can not even guarantee a stable grasp. In this paper, we proposed a method to integrate parts feeding and assembly within one robot arm. This proposal utilizes a specially designed gripper tip mounted on the jaws of a two-fingered gripper. With the modified gripper, in-hand manipulation of the grasped object is realized, which can ensure the control of the orientation and offset position of the grasped object. The proposal in this paper is verified by a simulated assembly in which a robot arm completed the assembly process including parts picking from bin and a subsequent peg-in-hole assembly.


Title: A bio-inspired 3-DOF light-weight manipulator with tensegrity X-joints*
Key Words: actuators  manipulator kinematics  motion control  light-weight manipulator  tensegrity X-joints  manipulators  anti-parallelogram joints  tensegrity one-degree-of-freedom mechanism  3-degree-of-freedom manipulator  tensegrity X-joint  Bars  Springs  Birds  Neck  Manipulator dynamics  Trajectory 
Abstract: This paper proposes a new kind of light-weight manipulators suitable for safe interactions. The proposed manipulators use anti-parallelogram joints in series, referred to as X-joints. Each X-joint is remotely actuated with cables and springs in parallel, thus realizing a tensegrity one-degree-of-freedom mechanism. As compared to manipulators built with simple revolute joints in series, manipulators with tensegrity X-joint offer a number of advantages, such as an intrinsic stability, variable stiffness and lower inertia. This new design was inspired by the musculosleketon architecture of the bird neck that is known to have remarkable features such as a high dexterity. The paper analyzes in detail the kinetostatics of a X-joint and proposes a 3-degree-of-freedom manipulator made of three such joints in series. Both simulation results and experiment results conducted on a test-bed prototype are presented and discussed.


Title: Contact Surface Estimation via Haptic Perception
Key Words: haptic interfaces  legged locomotion  contact surface estimation  haptic perception  legged systems  contact force  surface geometry  vision system  harsh weather  surface information  haptic exploration  Robot sensing systems  Estimation  Friction  Legged locomotion  Foot  Force 
Abstract: Legged systems need to optimize contact force in order to maintain contacts. For this, the controller needs to have the knowledge of the surface geometry and how slippery the terrain is. We can use a vision system to realize the terrain, but the accuracy of the vision system degrades in harsh weather, and it cannot visualize the terrain if it is covered with water or grass. Also, the degree of friction cannot be directly visualized. In this paper, we propose an online method to estimate the surface information via haptic exploration. We also introduce a probabilistic criterion to measure the quality of the estimation. The method is validated on both simulation and a real robot platform.


Title: On-board Deep-learning-based Unmanned Aerial Vehicle Fault Cause Detection and Identification
Key Words: aerospace computing  autonomous aerial vehicles  convolutional neural nets  fault diagnosis  learning (artificial intelligence)  neural net architecture  pattern classification  real-time systems  recurrent neural nets  sensor fusion  raw sensor data  drone misoperations  unmanned aerial vehicle fault cause detection  deep learning architectures  fault cause identification  drone software cyberattack  deep convolutional neural network  long short term memory neural network  autoencoder  real time sensor data classification  Drones  Computer crashes  Real-time systems  Robot sensing systems  Computer architecture  Neural networks  Data models 
Abstract: With the increase in use of Unmanned Aerial Vehicles (UAVs)/drones, it is important to detect and identify causes of failure in real time for proper recovery from a potential crash-like scenario or post incident forensics analysis. The cause of crash could be either a fault in the sensor/actuator system, a physical damage/attack, or a cyber attack on the drone's software. In this paper, we propose novel architectures based on deep Convolutional and Long Short-Term Memory Neural Networks (CNNs and LSTMs) to detect (via Autoencoder) and classify drone mis-operations based on real-time sensor data. The proposed architectures are able to learn high-level features automatically from the raw sensor data and learn the spatial and temporal dynamics in the sensor data. We validate the proposed deep-learning architectures via simulations and realworld experiments on a drone. Empirical results show that our solution is able to detect (with over 90% accuracy) and classify various types of drone mis-operations (with about 99% accuracy (simulation data) and upto 85% accuracy (experimental data)).


Title: Nonlinear Vector-Projection Control for Agile Fixed-Wing Unmanned Aerial Vehicles
Key Words: aerospace components  aircraft control  attitude control  autonomous aerial vehicles  cascade control  helicopters  mobile robots  nonlinear control systems  trajectory control  nonlinear vector-projection control  agile fixed-wing aircraft  fixed-wing platforms  nonlinear control strategy  autonomous flight  cascaded control structure  inner attitude control loop  Special Orthornormal group  outer position control loop  thrust command  attitude references  lift forces  agile fixed-wing unmanned aerial vehicles  rotorcraft  Aircraft  Control systems  Attitude control  Aerodynamics  Position measurement  Aircraft propulsion 
Abstract: Agile fixed-wing aircraft integrate the efficient, high-speed capabilities of conventional fixed-wing platforms with the extreme maneuverability of rotorcraft. This work presents a nonlinear control strategy that harnesses these capabilities to enable autonomous flight through aggressive, time-constrained, three-dimensional trajectories. The cascaded control structure consists of two parts; an inner attitude control loop developed on the Special Orthornormal group that avoids singularities commonly associated with other parametrizations, and an outer position control loop that jointly determines the thrust command and attitude references by implementing a novel vector-projection algorithm. The objective of the algorithm is to decouple roll from the reference attitude to ensure that thrust and lift forces can always be pointed such that position errors converge to zero. The proposed control system represents a single, unified solution that remains effective throughout the aircraft's flight envelope, including aerobatic operation. Controller performance is verified through simulations and experimental flight tests; results show the unified control scheme is capable of performing a wide range of operations that would normally require multiple, single-purpose controllers, and their associated switching logic.


Title: The Reconfigurable Aerial Robotic Chain: Modeling and Control
Key Words: aerospace robotics  control system synthesis  mobile robots  position control  ARC-Alpha prototype  multilinked microaerial vehicles  reconfigurable aerial robotic chain  multiple parallel angular controllers  model predictive position control loop  controller design  connected aerial vehicles  system dynamics  system extendability  distributed sensing  Robot sensing systems  Robot kinematics  Payloads  Shape  Prototypes 
Abstract: This paper overviews the system design, modeling and control of the Aerial Robotic Chain. This new design corresponds to a reconfigurable robotic system of systems consisting of multilinked micro aerial vehicles that presents the ability to cross narrow sections, morph its shape, ferry significant payloads, offer the potential of distributed sensing and processing, and enable system extendability. We present the system dynamics for any number of connected aerial vehicles, followed by the controller design involving a model predictive position control loop combined with multiple parallel angular controllers on SO(3). Evaluation studies both in simulation and through experiments based on our ARC-Alpha prototype are depicted and involve coordinated maneuvering and shape configuration to cross narrow windows.


Title: Optimal Oscillation Damping Control of cable-Suspended Aerial Manipulator with a Single IMU Sensor
Key Words: control system synthesis  damping  feedback  linear quadratic control  linearisation techniques  manipulators  nonlinear control systems  optimal control  pendulums  robust control  vibration control  control action  simplified SAM model  model uncertainties  optimal oscillation damping control  cable-suspended aerial manipulator  single IMU sensor  double pendulum  output feedback linear quadratic regulation problem  minimal energy consumption  Oscillators  Damping  Manipulators  Robot sensing systems  Task analysis  Cranes 
Abstract: This paper presents a design of oscillation damping control for the cable-Suspended Aerial Manipulator (SAM). The SAM is modeled as a double pendulum, and it can generate a body wrench as a control action. The main challenge is the fact that there is only one onboard IMU sensor which does not provide full information on the system state. To overcome this difficulty, we design a controller motivated by a simplified SAM model. The proposed controller is very simple yet robust to model uncertainties. Moreover, we propose a gain tuning rule by formulating the proposed controller in the form of output feedback linear quadratic regulation problem. Consequently, it is possible to quickly dampen oscillations with minimal energy consumption. The proposed approach is validated through simulations and experiments.


Title: TUNERCAR: A Superoptimization Toolchain for Autonomous Racing
Key Words: automobiles  mobile robots  optimisation  path planning  random processes  search problems  autonomous vehicles  online planning  TUNERCAR  superoptimization toolchain  autonomous racing  vehicle parameters  autonomous racecar  systems infrastructure  parallel implementation  CMA-ES  lap time  naive random search  racing strategy  Optimization  Sociology  Statistics  Vehicle dynamics  Hardware  Robots  Planning 
Abstract: TUNERCAR is a toolchain that jointly optimizes racing strategy, planning methods, control algorithms, and vehicle parameters for an autonomous racecar. In this paper, we detail the target hardware, software, simulators, and systems infrastructure for this toolchain. Our methodology employs a parallel implementation of CMA-ES which enables simulations to proceed 6 times faster than real-world rollouts. We show our approach can reduce the lap times in autonomous racing, given a fixed computational budget. For all tested tracks, our method provides the lowest lap time, and relative improvements in lap time between 7-21%. We demonstrate improvements over a naive random search method with equivalent computational budget of over 15 seconds/lap, and improvements over expert solutions of over 2 seconds/lap. We further compare the performance of our method against hand-tuned solutions submitted by over 30 international teams, comprised of graduate students working in the field of autonomous vehicles. Finally, we discuss the effectiveness of utilizing an online planning mechanism to reduce the reality gap between our simulation and actual tests.


Title: Game theoretic decision making based on real sensor data for autonomous vehicles maneuvers in high traffic
Key Words: decision making  game theory  learning (artificial intelligence)  mobile robots  Monte Carlo methods  road vehicles  sensors  sensor data  autonomous vehicles  iterative multiplayer game  game model  ego-vehicle  vehicle-to-vehicle communication  traffic simulator  game theoretic decision making  cognitive hierarchy reasoning  Monte Carlo reinforcement learning  Games  Automobiles  Mathematical model  Game theory  Autonomous vehicles  Robot sensing systems 
Abstract: This paper presents an approach for implementing game theoretic decision making in combination with realistic sensory data input so as to allow an autonomous vehicle to perform maneuvers, such as lane change or merge in high traffic scenarios. The main novelty of this work, is the use of realistic sensory data input to obtain the observations as input of an iterative multi-player game in a realistic simulator. The game model allows to anticipate reactions of additional vehicles to the movements of the ego-vehicle without using any specific coordination or vehicle-to-vehicle communication. Moreover, direct information from the simulator, such as position or speed of the vehicles is also avoided.The solution of the game is based on cognitive hierarchy reasoning and it uses Monte Carlo reinforcement learning in order to obtain a near-optimal policy towards a specific goal. Moreover, the game proposed is capable of solving different situations using a single policy. The system has been successfully tested and compared with previous techniques using a realistic hybrid simulator, where the ego-vehicle and its sensors are simulated on a 3D simulator and the additional vehicles' behavior is obtained from a traffic simulator.


Title: Driving in Dense Traffic with Model-Free Reinforcement Learning
Key Words: collision avoidance  learning (artificial intelligence)  predictive control  road traffic control  traffic engineering computing  dense traffic  model-free reinforcement learning  control methods  autonomous vehicle  obstacle-free volume  deep reinforcement learning  continuous control policy  target road lane  model-predictive control-based algorithms  Roads  Autonomous vehicles  Learning (artificial intelligence)  Task analysis  Benchmark testing  Trajectory 
Abstract: Traditional planning and control methods could fail to find a feasible trajectory for an autonomous vehicle to execute amongst dense traffic on roads. This is because the obstacle-free volume in spacetime is very small in these scenarios for the vehicle to drive through. However, that does not mean the task is infeasible since human drivers are known to be able to drive amongst dense traffic by leveraging the cooperativeness of other drivers to open a gap. The traditional methods fail to take into account the fact that the actions taken by an agent affect the behaviour of other vehicles on the road. In this work, we rely on the ability of deep reinforcement learning to implicitly model such interactions and learn a continuous control policy over the action space of an autonomous vehicle. The application we consider requires our agent to negotiate and open a gap in the road in order to successfully merge or change lanes. Our policy learns to repeatedly probe into the target road lane while trying to find a safe spot to move in to. We compare against two model-predictive control-based algorithms and show that our policy outperforms them in simulation. As part of this work, we introduce a benchmark for driving in dense traffic for use by the community.


Title: Enhancing Game-Theoretic Autonomous Car Racing Using Control Barrier Functions
Key Words: collision avoidance  computer games  game theory  game-theoretic autonomous car  control barrier functions  two-player racing game  autonomous ego vehicle  opponent vehicle  two-car racing game  game-theoretic control method hinges  sensitivity-enhanced Nash equilibrium  Collision avoidance  Trajectory  Robots  Acceleration  Safety  Bicycles  Automobiles 
Abstract: In this paper, we consider a two-player racing game, where an autonomous ego vehicle has to be controlled to race against an opponent vehicle, which is either autonomous or human-driven. The approach to control the ego vehicle is based on a Sensitivity-ENhanced NAsh equilibrium seeking (SENNA) method, which uses an iterated best response algorithm in order to optimize for a trajectory in a two-car racing game. This method exploits the interactions between the ego and the opponent vehicle that take place through a collision avoidance constraint. This game-theoretic control method hinges on the ego vehicle having an accurate model and correct knowledge of the state of the opponent vehicle. However, when an accurate model for the opponent vehicle is not available, or the estimation of its state is corrupted by noise, the performance of the approach might be compromised. For this reason, we augment the SENNA algorithm by enforcing Permissive RObust SafeTy (PROST) conditions using control barrier functions. The objective is to successfully overtake or to remain in the front of the opponent vehicle, even when the information about the latter is not fully available. The successful synergy between SENNA and PROST-antithetical to the notable rivalry between the two namesake Formula 1 drivers-is demonstrated through extensive simulated experiments.


Title: Gershgorin Loss Stabilizes the Recurrent Neural Network Compartment of an End-to-end Robot Learning Scheme
Key Words: collision avoidance  control engineering computing  eigenvalues and eigenfunctions  gradient methods  learning (artificial intelligence)  mobile robots  neural nets  neurocontrollers  recurrent neural nets  mobile robot  traditional robotic control suits  profound task-specific knowledge  building  testing control software  deep learning  end-to-end solutions  minimal knowledge  end-to-end linear dynamical systems  LDS  robotic domains  regularization loss component  learning algorithm  learned autonomous system  simulated robotic experiments  stabilizing method  end-to-end robot learning scheme  recurrent neural network compartment  gershgorin loss  Stability analysis  Eigenvalues and eigenfunctions  Recurrent neural networks  Training  Robots  Heuristic algorithms  Task analysis 
Abstract: Traditional robotic control suits require profound task-specific knowledge for designing, building and testing control software. The rise of Deep Learning has enabled end-to-end solutions to be learned entirely from data, requiring minimal knowledge about the application area. We design a learning scheme to train end-to-end linear dynamical systems (LDS)s by gradient descent in imitation learning robotic domains. We introduce a new regularization loss component together with a learning algorithm that improves the stability of the learned autonomous system, by forcing the eigenvalues of the internal state updates of an LDS to be negative reals. We evaluate our approach on a series of real-life and simulated robotic experiments, in comparison to linear and nonlinear Recurrent Neural Network (RNN) architectures. Our results show that our stabilizing method significantly improves test performance of LDS, enabling such linear models to match the performance of contemporary nonlinear RNN architectures. A video of the obstacle avoidance performance of our method on a mobile robot, in unseen environments, compared to other methods can be viewed at https://youtu.be/mhEsCoNao5E.


Title: Cross-context Visual Imitation Learning from Demonstrations
Key Words: learning (artificial intelligence)  robots  general imitation learning method  robotic system  context translation model  depth prediction model  multimodal inverse dynamics model  depth observation  inverse model maps  multimodal observations  cross-context learning advantage  cross-context visual imitation learning  color observation  block stacking tasks  Context modeling  Robots  Task analysis  Inverse problems  Visualization  Predictive models  Feature extraction 
Abstract: Imitation learning enables robots to learn a task by simply watching the demonstration of the task. Current imitation learning methods usually require the learner and demonstrator to occur in the same context. This limits their scalability to practical applications. In this paper, we propose a more general imitation learning method which allows the learner and the demonstrator to come from different contexts, such as different viewpoints, backgrounds, and object positions and appearances. Specifically, we design a robotic system consisting of three models: context translation model, depth prediction model and multi-modal inverse dynamics model. First, the context translation model translates the demonstration to the context of learner from a different context. Then combining the color observation and depth observation as inputs, the inverse model maps the multi-modal observations into actions to reproduce the demonstration, where the depth observation is provided by a depth prediction model. By performing the block stacking tasks both in simulation and real world, we prove the cross-context learning advantage of the proposed robotic system over other systems.


Title: Improving Generalisation in Learning Assistance by Demonstration for Smart Wheelchairs
Key Words: Gaussian processes  generalisation (artificial intelligence)  handicapped aids  human-robot interaction  learning (artificial intelligence)  neural nets  wheelchairs  Gaussian process  learning assistance by demonstration  human agent  machine learning models  dimensionality reduction techniques  learning system  custom teleoperation  LAD  generalisation capability  assistive power  learned assistive policy  customised assistance  smart wheelchairs  Wheelchairs  Training  Robots  Vehicles  Haptic interfaces  Sensors  Navigation 
Abstract: Learning Assistance by Demonstration (LAD) is concerned with using demonstrations of a human agent to teach a robot how to assist another human. The concept has previously been used with smart wheelchairs to provide customised assistance to individuals with driving difficulties. A basic premise of this technique is that the learned assistive policy should be able to generalise to environments different than the ones used for training; but this has not been tested before. In this work we evaluate the assistive power and the generalisation capability of LAD using our custom teleoperation and learning system for smart wheelchairs, while seeking to improve it by experimenting with different combinations of dimensionality reduction techniques and machine learning models. Using Autoencoders to reduce the dimension of laserscan data and a Gaussian Process as the learning model, we achieved a 23% improvement in prediction performance against the combination used by the latest work on the field. Using this model to assist a driver exposed to a simulated disability, we observed a 9.8% reduction in track completion times when compared to driving without assistance.


Title: Representing Multi-Robot Structure through Multimodal Graph Embedding for the Selection of Robot Teams
Key Words: directed graphs  mobile robots  multi-robot systems  unsupervised learning  multirobot system  multirobot structure  human-robot teaming  multimodal graph embedding  robot teams selection  directed graphs  asymmetrical relationships  unsupervised learning  physical robots  multifaceted internal structures  graph embedding-based division methods  Robots  Task analysis  Multi-robot systems  Indexes  Organizations  Resource management  Biology 
Abstract: Multi-robot systems of increasing size and complexity are used to solve large-scale problems, such as area exploration and search and rescue. A key decision in human-robot teaming is dividing a multi-robot system into teams to address separate issues or to accomplish a task over a large area. In order to address the problem of selecting teams in a multi-robot system, we propose a new multimodal graph embedding method to construct a unified representation that fuses multiple information modalities to describe and divide a multi-robot system. The relationship modalities are encoded as directed graphs that can encode asymmetrical relationships, which are embedded into a unified representation for each robot. Then, the constructed multimodal representation is used to determine teams based upon unsupervised learning. We per-form experiments to evaluate our approach on expert-defined team formations, large-scale simulated multi-robot systems, and a system of physical robots. Experimental results show that our method successfully decides correct teams based on the multifaceted internal structures describing multi-robot systems, and outperforms baseline methods based upon only one mode of information, as well as other graph embedding-based division methods.


Title: Connectivity Maintenance: Global and Optimized approach through Control Barrier Functions
Key Words: mobile robots  multi-robot systems  optimal control  optimisation  connectivity maintenance  Control Barrier functions  multirobot system  local connectivity  global connectivity  formation control  Control Barrier Function  control strategy  Robots  Laplace equations  Multi-robot systems  Eigenvalues and eigenfunctions  Maintenance engineering  Task analysis  Control systems 
Abstract: Connectivity maintenance is an essential aspect to consider while controlling a multi-robot system. In general, a multi-robot system should be connected to obtain a certain common objective. Connectivity must be kept regardless of the control strategy or the objective of the multi-robot system. Two main methods exist for connectivity maintenance: keep the initial connections (local connectivity) or allow modifications to the initial connections, but always keeping the overall system connected (global connectivity). In this paper we present a method that allows, at the same time, to maintain global connectivity and to implement the desired control strategy (e.g., consensus, formation control, coverage), all in an optimized fashion. For this purpose, we defined and implemented a Control Barrier Function that can incorporate constraints and objectives. We provide a mathematical proof of the method, and we demonstrate its versatility with simulations of different applications.


Title: A Distributed Source Term Estimation Algorithm for Multi-Robot Systems
Key Words: distributed control  mobile robots  multi-robot systems  airborne chemicals  mobile sensing systems  intelligent systems  odor source localization  homogeneous multirobot systems  multiple mobile robots  distributed system  distributed source term estimation  Robot kinematics  Robot sensing systems  Estimation  Navigation  Probabilistic logic 
Abstract: Finding sources of airborne chemicals with mobile sensing systems finds applications in safety, security, and emergency situations related to medical, domestic, and environmental domains. Given the often critical nature of all the applications, it is important to reduce the amount of time necessary to accomplish this task through intelligent systems and algorithms. In this paper, we extend a previously presented algorithm based on source term estimation for odor source localization for homogeneous multi-robot systems. By gradually increasing the level of coordination among multiple mobile robots, we study the benefits of a distributed system on reducing the amount of time and resources necessary to achieve the task at hand. The method has been evaluated systematically through high-fidelity simulations and in a wind tunnel emulating realistic and repeatable conditions in different coordination scenarios and with different number of robots.


Title: Weighted Buffered Voronoi Cells for Distributed Semi-Cooperative Behavior
Key Words: collision avoidance  computational geometry  game theory  mobile robots  multi-agent systems  multi-robot systems  selfish agent  relative cell  collision-free configuration  egoistic weights  altruistic agents  distributed semi  semicooperative multiagent navigation policies  collision avoidance  dynamic weights  lower relative weight  buffered distance  agent weights  selfish behavior  prioritized behavior  weighted buffered Voronoi tessellation  weighted buffered Voronoi cells  Navigation  Robot kinematics  Collision avoidance  Games  Planning  Safety 
Abstract: This paper introduces the Weighted Buffered Voronoi tessellation, which allows us to define distributed, semicooperative multi-agent navigation policies with guarantees on collision avoidance. We generate the Voronoi cells with dynamic weights that bias the boundary towards the agent with the lower relative weight while always maintaining a buffered distance between two agents. By incorporating agent weights, we can encode selfish or prioritized behavior among agents, where a more selfish agent will have a larger relative cell over less selfish agents. We consider this semi-cooperative since agents do not cooperate in symmetric ways. Furthermore, when all agents start in a collision-free configuration and plan their control actions within their cells, we prove that no agents will collide. Simulations demonstrate the performance of our algorithm for agents navigating to goal locations in a position-swapping game. We observe that agents with more egoistic weights consistently travel shorter paths to their goal than more altruistic agents.


Title: Grasping Unknown Objects by Coupling Deep Reinforcement Learning, Generative Adversarial Networks, and Visual Servoing
Key Words: grippers  learning (artificial intelligence)  neural nets  object recognition  pose estimation  robot vision  visual servoing  semicompliant objects  grasping experiments  deep learning  inaccurate agent gripper  visual servoing grasping task  CycleGAN  DRL  deep reinforcement learning grasping agent  generative adversarial networks  Grasping  Robots  Grippers  Training  Task analysis  Gallium nitride  Image segmentation 
Abstract: In this paper, we propose a novel approach for transferring a deep reinforcement learning (DRL) grasping agent from simulation to a real robot, without fine tuning in the real world. The approach utilises a CycleGAN to close the reality gap between the simulated and real environments, in a reverse real-to-sim manner, effectively "tricking" the agent into believing it is still in the simulator. Furthermore, a visual servoing (VS) grasping task is added to correct for inaccurate agent gripper pose estimations derived from deep learning. The proposed approach is evaluated by means of real grasping experiments, achieving a success rate of 83 % on previously seen objects, and the same success rate for previously unseen, semi-compliant objects. The robustness of the approach is demonstrated by comparing it with two baselines, DRL plus CycleGAN, and VS only. The results clearly show that our approach outperforms both baselines.


Title: Learning to Scaffold the Development of Robotic Manipulation Skills
Key Words: learning systems  manipulators  position control  robust control  peg insertion  inaccurate motor control  robotic manipulation skills  shallow-depth insertion  wrench manipulation  robot positions  learning loops  learning system  scaffold manipulation skill learning  robot actions  robust manipulation  Task analysis  Tools  Uncertainty  Robot sensing systems  Robustness  Motor drives 
Abstract: Learning contact-rich, robotic manipulation skills is a challenging problem due to the high-dimensionality of the state and action space as well as uncertainty from noisy sensors and inaccurate motor control. To combat these factors and achieve more robust manipulation, humans actively exploit contact constraints in the environment. By adopting a similar strategy, robots can also achieve more robust manipulation. In this paper, we enable a robot to autonomously modify its environment and thereby discover how to ease manipulation skill learning. Specifically, we provide the robot with fixtures that it can freely place within the environment. These fixtures provide hard constraints that limit the outcome of robot actions. Thereby, they funnel uncertainty from perception and motor control and scaffold manipulation skill learning. We propose a learning system that consists of two learning loops. In the outer loop, the robot positions the fixture in the workspace. In the inner loop, the robot learns a manipulation skill and after a fixed number of episodes, returns the reward to the outer loop. Thereby, the robot is incentivised to place the fixture such that the inner loop quickly achieves a high reward. We demonstrate our framework both in simulation and in the real world on three tasks: peg insertion, wrench manipulation and shallow- depth insertion. We show that manipulation skill learning is dramatically sped up through this way of scaffolding.


Title: Online Replanning in Belief Space for Partially Observable Task and Motion Problems
Key Words: manipulators  mobile robots  motion control  path planning  execution system  deterministic cost-sensitive planning  hybrid belief states  partially observable problems  online replanning  belief space  multistep manipulation tasks  autonomous robot  Planning  Task analysis  Bayes methods  Manipulators  Aerospace electronics  Uncertainty 
Abstract: To solve multi-step manipulation tasks in the real world, an autonomous robot must take actions to observe its environment and react to unexpected observations. This may require opening a drawer to observe its contents or moving an object out of the way to examine the space behind it. Upon receiving a new observation, the robot must update its belief about the world and compute a new plan of action. In this work, we present an online planning and execution system for robots faced with these challenges. We perform deterministic cost-sensitive planning in the space of hybrid belief states to select likely-to-succeed observation actions and continuous control actions. After execution and observation, we replan using our new state estimate. We initially enforce that planner reuses the structure of the unexecuted tail of the last plan. This both improves planning efficiency and ensures that the overall policy does not undo its progress towards achieving the goal. Our approach is able to efficiently solve partially observable problems both in simulation and in a real-world kitchen.


Title: UNO: Uncertainty-aware Noisy-Or Multimodal Fusion for Unanticipated Input Degradation
Key Words: learning (artificial intelligence)  neural nets  probability  sensor fusion  uncertainty handling  multimodal fusion  unanticipated input degradation  multiple sensor modalities  deep learning architectures  modality-specific output softmax probabilities  uncertainty measures  uncertainty-scaled output  fusion architectures  probabilistic noisy-fusion  data-dependent spatial temperature scaling  uncertainty-aware fusion  UNO  uncertainty-aware noisy fusion  Uncertainty  Degradation  Training  Noise measurement  Robot sensing systems  Entropy 
Abstract: The fusion of multiple sensor modalities, especially through deep learning architectures, has been an active area of study. However, an under-explored aspect of such work is whether the methods can be robust to degradation across their input modalities, especially when they must generalize to degradation not seen during training. In this work, we propose an uncertainty-aware fusion scheme to effectively fuse inputs that might suffer from a range of known and unknown degradation. Specifically, we analyze a number of uncertainty measures, each of which captures a different aspect of uncertainty, and we propose a novel way to fuse degraded inputs by scaling modality-specific output softmax probabilities. We additionally propose a novel data-dependent spatial temperature scaling method to complement these existing uncertainty measures. Finally, we integrate the uncertainty-scaled output from each modality using a probabilistic noisy-or fusion method. In a photo-realistic simulation environment (AirSim), we show that our method achieves significantly better results on a semantic segmentation task, as compared to state-of-art fusion architectures, on a range of degradation (e.g. fog, snow, frost, and various other types of noise), some of which are unknown during training.


Title: Intermittent GPS-aided VIO: Online Initialization and Calibration
Key Words: calibration  cameras  distance measurement  Global Positioning System  Monte Carlo methods  sensor fusion  GPS reference frame  GPS signal  intermittent GPS-aided VIO  online initialization  IMU-camera data fusion  intermittent GPS measurements  sensor fusion  spatiotemporal sensor calibration  sensor reference frames  online calibration method  reference frame initialization procedure  GPS sensor noise  GPS-VIO system  VIO reference frame  online calibration  robust GPS-aided visual inertial odometry  GPS-IMU extrinsics  Monte-Carlo simulations  large-scale real-world experiment  Global Positioning System  Robot sensing systems  Calibration  Cameras  Cloning  Robustness  Visualization 
Abstract: In this paper, we present an efficient and robust GPS-aided visual inertial odometry (GPS-VIO) system that fuses IMU-camera data with intermittent GPS measurements. To perform sensor fusion, spatiotemporal sensor calibration and initialization of the transform between the sensor reference frames are required. We propose an online calibration method for both the GPS-IMU extrinsics and time offset as well as a reference frame initialization procedure that is robust to GPS sensor noise. In addition, we prove the existence of four unobservable directions of the GPS-VIO system when estimating in the VIO reference frame, and advocate a state transformation to the GPS reference frame for full observability. We extensively evaluate the proposed approach in Monte-Carlo simulations where we investigate the system's robustness to different levels of GPS noise and loss of GPS signal, and additionally study the hyper-parameters used in the initialization procedure. Finally, the proposed system is validated in a large-scale real-world experiment.


Title: Fast Local Planning and Mapping in Unknown Off-Road Terrain
Key Words: collision avoidance  graph theory  mobile robots  motion control  remotely operated vehicles  SLAM (robots)  trajectory control  off-road terrain  on-line mapping  planning solution  obstacle detection  terrain gradient map  simple cost map  adaptable cost map  optimal paths  control input space  kinematic forward simulation  generated feasible trajectories  optimal trajectory  time operation  frequency 10.0 Hz  frequency 30.0 Hz  Trajectory  Robots  Planning  Aerospace electronics  Microsoft Windows  Three-dimensional displays  Real-time systems 
Abstract: In this paper, we present a fast, on-line mapping and planning solution for operation in unknown, off-road, environments. We combine obstacle detection along with a terrain gradient map to make simple and adaptable cost map. This map can be created and updated at 10 Hz. An A* planner finds optimal paths over the map. Finally, we take multiple samples over the control input space and do a kinematic forward simulation to generated feasible trajectories. Then the most optimal trajectory, as determined by the cost map and proximity to A* path, is chosen and sent to the controller. Our method allows real time operation at rates of 30 Hz. We demonstrate the efficiency of our method in various off-road terrain at high speed.


Title: Scaled Autonomy: Enabling Human Operators to Control Robot Fleets
Key Words: mobile robots  multi-robot systems  telerobotics  utility function  real-world mobile robot navigation  robot fleets control  autonomous robots  human operator  teleoperation  Task analysis  Mathematical model  Navigation  Autonomous robots  Hardware  Predictive models 
Abstract: Autonomous robots often encounter challenging situations where their control policies fail and an expert human operator must briefly intervene, e.g., through teleoperation. In settings where multiple robots act in separate environments, a single human operator can manage a fleet of robots by identifying and teleoperating one robot at any given time. The key challenge is that users have limited attention: as the number of robots increases, users lose the ability to decide which robot requires teleoperation the most. Our goal is to automate this decision, thereby enabling users to supervise more robots than their attention would normally allow for. Our insight is that we can model the user's choice of which robot to control as an approximately optimal decision that maximizes the user's utility function. We learn a model of the user's preferences from observations of the user's choices in easy settings with a few robots, and use it in challenging settings with more robots to automatically identify which robot the user would most likely choose to control, if they were able to evaluate the states of all robots at all times. We run simulation experiments and a user study with twelve participants that show our method can be used to assist users in performing a simulated navigation task. We also run a hardware demonstration that illustrates how our method can be applied to a real-world mobile robot navigation task.


Title: Planetary Rover Exploration Combining Remote and In Situ Measurements for Active Spectroscopic Mapping
Key Words: aerospace robotics  learning (artificial intelligence)  mobile robots  path planning  planetary rovers  planetary rover exploration combining remote  active spectroscopic mapping  planetary rover missions  heavy reliance  ground control  real-time information  autonomous mapping  exploration approach  planetary rovers  machine learning model  rover measurements  spectroscopic data  information theory  nonmyopic path  exploration productivity  actual rover  Feature extraction  Extraterrestrial measurements  Robot kinematics  Adaptation models  Productivity  Mars 
Abstract: Maintaining high levels of productivity for planetary rover missions is very difficult due to limited communication and heavy reliance on ground control. There is a need for autonomy that enables more adaptive and efficient actions based on real-time information. This paper presents an autonomous mapping and exploration approach for planetary rovers. We first describe a machine learning model that actively combines remote and rover measurements for mapping. We focus on spectroscopic data because they are commonly used to investigate surface composition. We then incorporate notions from information theory and non-myopic path planning to improve exploration productivity. Finally, we demonstrate the feasibility and successful performance of our approach via spectroscopic investigations of Cuprite, Nevada; a well-studied region of mineralogical and geological interest. We first perform a detailed analysis in simulations, and then validate those results with an actual rover in the field in Nevada.


Title: Deep Learning for Spacecraft Pose Estimation from Photorealistic Rendering
Key Words: aerospace computing  image classification  learning (artificial intelligence)  mixture models  neural nets  pose estimation  rendering (computer graphics)  space vehicles  photorealistic rendering  on-orbit proximity operations  6D pose estimation  monocular pose estimation  Unreal Engine 4  neural networks  deep learning framework  orientation soft classification  orientation ambiguity  mixture model  URSO  spacecraft pose estimation  Space vehicles  Quaternions  Pose estimation  Earth  Cameras  Three-dimensional displays 
Abstract: On-orbit proximity operations in space rendezvous, docking and debris removal require precise and robust 6D pose estimation under a wide range of lighting conditions and against highly textured background, i.e., the Earth. This paper investigates leveraging deep learning and photorealistic rendering for monocular pose estimation of known uncooperative spacecraft. We first present a simulator built on Unreal Engine 4, named URSO, to generate labeled images of spacecraft orbiting the Earth, which can be used to train and evaluate neural networks. Secondly, we propose a deep learning framework for pose estimation based on orientation soft classification, which allows modelling orientation ambiguity as a mixture model. This framework was evaluated both on URSO datasets and the European Space Agency pose estimation challenge. In this competition, our best model achieved 3rd place on the synthetic test set and 2nd place on the real test set. Moreover, our results show the impact of several architectural and training aspects, and we demonstrate qualitatively how models learned on URSO datasets can perform on real images from space.


Title: Concurrent Parameter Identification and Control for Free-Floating Robotic Systems During On-Orbit Servicing
Key Words: aerospace control  aerospace robotics  Jacobian matrices  mobile robots  motion control  parameter estimation  path planning  position control  concurrent parameter identification  free-floating robotic system  on-orbit servicing  uncertain parameters  fast parameter identification method  accurate parameter estimates  system dynamic properties  control scheme compensates  robotic servicer base  parameter information  transposed Jacobian controller  RW angular momentum disturbance rejection  OOS tasks  Task analysis  Parameter estimation  Aerospace electronics  Manipulator dynamics  Adaptive control 
Abstract: To control a free-floating robotic system with uncertain parameters in OOS tasks with high accuracy, a fast parameter identification method, previously developed by the authors, is enhanced further and used concurrently with a controller. The method provides accurate parameter estimates, without any prior knowledge of any system dynamic properties. This control scheme compensates for the accumulated angular momentum on the reaction wheels (RWs), which acts as a disturbance to the robotic servicer base. While any controller using parameter information can be used, a transposed Jacobian controller, modified to include RW angular momentum disturbance rejection, is employed here. Threedimensional simulations demonstrate the method's validity.


Title: A Dual Quaternion-Based Discrete Variational Approach for Accurate and Online Inertial Parameter Estimation in Free-Flying obots
Key Words: aerospace robotics  attitude control  control system synthesis  linear matrix inequalities  manipulator dynamics  mobile robots  motion control  recursive estimation  robust control  dual quaternion-based discrete variational approach  online inertial parameter estimation  free-flying robots  model-based motion control  rigid body inertial parameter estimation  discrete dual quaternion equations  variational mechanics  linear parameter estimation problem  standard localization algorithms  rotational inertia  linear matrix inequality constraints  pseudoinertia matrix  recursive semidefinite programming  Quaternions  Mathematical model  Parameter estimation  Robots  Linear matrix inequalities  Estimation  Programming 
Abstract: The performance of model-based motion control for free-flying robots relies on accurate estimation of their parameters. In this work, a method of rigid body inertial parameter estimation which relies on a variational approach is presented. Instead of discretizing the continuous equations of motion, discrete dual quaternion equations based on variational mechanics are used to formulate a linear parameter estimation problem. This method depends only on the pose of the rigid body obtained from standard localization algorithms. Recursive semi-definite programming is used to estimate the inertial parameters (mass, rotational inertia and center of mass offset) online. Linear Matrix Inequality constraints based on the pseudo-inertia matrix ensure that the estimates obtained are fully physically consistent. Simulation results demonstrate that this method is robust to disturbances and the produced estimates are at least one order of magnitude more accurate when compared to discretization using finite differences.


Title: AC/DCC : Accurate Calibration of Dynamic Camera Clusters for Visual SLAM
Key Words: calibration  cameras  sensitivity analysis  SLAM (robots)  calibration parameters  calibration sensitivity analysis  joint angle noise  joint angle values  calibration code  dynamic camera clusters  visual SLAM  time-varying set  extrinsic calibration transformations  DCC calibration accuracy  configuration space  pixel re-projection error  fiducial target  dynamic camera cluster  pose-loop error optimization  Cameras  Calibration  Robot vision systems  Simultaneous localization and mapping  Vehicle dynamics  Optimization  Measurement uncertainty 
Abstract: In order to relate information across cameras in a Dynamic Camera Cluster (DCC), an accurate time-varying set of extrinsic calibration transformations need to be determined. Previous calibration approaches rely solely on collecting measurements from a known fiducial target which limits calibration accuracy as insufficient excitation of the gimbal is achieved. In this paper, we improve DCC calibration accuracy by collecting measurements over the entire configuration space of the gimbal and achieve a 10X improvement in pixel re-projection error. We perform a joint optimization over the calibration parameters between any number of cameras and unknown joint angles using a pose-loop error optimization approach, thereby avoiding the need for overlapping fields-of-view. We test our method in simulation and provide a calibration sensitivity analysis for different levels of camera intrinsic and joint angle noise. In addition, we provide a novel analysis of the degenerate parameters in the calibration when joint angle values are unknown, which avoids situations in which the calibration cannot be uniquely recovered. The calibration code will be made available at https://github.com/TRAILab/AC-DCC.


Title: Analytic Plane Covariances Construction for Precise Planarity-based Extrinsic Calibration of Camera and LiDAR
Key Words: calibration  feature extraction  optical radar  stereo image processing  planar feature correspondences  plane parameter covariance  3D corner points  plane measurement covariance  out-of-plane errors  analytic plane covariances construction  plane parameter errors  planarity-based extrinsic calibration  LiDAR  Three-dimensional displays  Calibration  Cameras  Laser radar  Linear programming  Solid modeling  Two dimensional displays 
Abstract: Planarity of checkerboards is a widely used feature for extrinsic calibration of camera and LiDAR. In this study, we propose two analytically derived covariances of (i) plane parameters and (ii) plane measurement, for precise extrinsic calibration of camera and LiDAR. These covariances allow the graded approach in planar feature correspondences by exploiting the uncertainty of a set of given features in calibration. To construct plane parameter covariance, we employ the error model of 3D corner points and the analytically formulated plane parameter errors. Next, plane measurement covariance is directly derived from planar regions of point clouds using the out-of-plane errors. In simulation validation, our method is compared to an existing uncertainty-excluding method using the different number of target poses and the different levels of noise. In field experiment, we validated the applicability of the proposed analytic plane covariances for precise calibration using the basic planarity-based method and the latest planarity-and-linearity-based method.


Title: An End-Effector Wrist Module for the Kinematically Redundant Manipulation of Arm-Type Robots
Key Words: collision avoidance  end effectors  industrial robots  motion control  redundant manipulators  end effector path tracking  6-DoF robot  8-DoF robot  redundant robot  kinematically redundant manipulation  industrial arm-type robots  dexterity  roll-pitch-roll wrist configuration  singularity free motion  end effector wrist module  collision avoidance  Wrist  Collision avoidance  Kinematics  Redundancy  Jacobian matrices  Service robots  Kinematically redundant manipulation  wrist module  roll-pitch-yaw  wrist singularity  inverse kinematics 
Abstract: Industrial arm-type robots have multiple degrees-of-freedom (DoFs) and high dexterity but the use of the roll-pitch-roll wrist configuration yields singularities inside the reachable workspace. Excessive joint velocities will occur when encountering these singularities. Arm-type robots currently don't have enough dexterity to move the end-effector path away from the wrist singularities. Robots with redundant DoFs can be used to provide additional dexterity to avoid the singularities and reduce the excessive joint velocity. An end-effector wrist module is proposed to provide two redundant DoFs when interfaced with an existing 6-DoF robot. The new 8-DoF robot has a compact roll-pitch-yaw wrist that has no singularities inside the reachable workspace. The highly redundant robot can also be used to avoid collisions in various directions. Path tracking simulation examples are provided to show the advantages of the proposed design when compared with existing redundant or nonredundant robots. We expect that this module can serve as a cost-effective solution in applications where singularity-free motion or collision-free motion is required.


Title: Online Trajectory Planning for an Industrial Tractor Towing Multiple Full Trailers
Key Words: agricultural machinery  nonlinear dynamical systems  path planning  trajectory control  vehicle dynamics  vehicle dynamics model  online trajectory planning  car-like tractor  passive full trailers  motion planning  complex nonlinear dynamics  simulation based prediction  industrial tractor-trailers vehicle  obstacle free trajectories  Agricultural machinery  Vehicle dynamics  Planning  Trajectory  Dynamics  Wheels  Lead 
Abstract: This paper presents a novel solution for online trajectory planning of a full-size tractor-trailers vehicle composed of a car-like tractor and arbitrary number of passive full trailers. The motion planning problem for such systems was rarely addressed due to the complex nonlinear dynamics. A simulation-based prediction method is proposed to easily handle the complicated nonlinear dynamics and efficiently generate the obstacle-free and dynamically feasible trajectories. The vehicle dynamics model and a two-layer controller are used in the prediction. Implementation results on the real-world full-size industrial tractor-trailers vehicle are presented to validate the performance of the proposed methods.


Title: A Bio-Inspired Transportation Network for Scalable Swarm Foraging
Key Words: collision avoidance  mobile robots  multi-robot systems  swarm intelligence  transportation  interrobot collisions  swarm robot foraging  scale-invariant swarm foraging algorithm  hierarchical branching transportation network  ubiquitous fractal branching networks  bioinspired transportation network  Robots  Transportation  Biology  Collision avoidance  Scalability  Task analysis  Explosions 
Abstract: Scalability is a significant challenge for robot swarms. Generally, larger groups of cooperating robots produce more inter-robot collisions, and in swarm robot foraging, larger search arenas result in larger travel costs. This paper demonstrates a scale-invariant swarm foraging algorithm that ensures that each robot finds and delivers targets to a central collection zone at the same rate regardless of the size of the swarm or the search area. Dispersed mobile depots aggregate locally collected targets and transport them to a central place via a hierarchical branching transportation network. This approach is inspired by ubiquitous fractal branching networks such as tree branches and animal cardiovascular networks that deliver resources to cells and determine the scale and pace of life. We demonstrate that biological scaling laws predict how quickly robots forage in simulations of up to thousands of robots searching over thousands of square meters. We then use biological scaling to predict the capacity of depot robots that overcome scaling constraints to produce scale-invariant robot swarms. We verify the claims for large swarms in simulation and implement a simple depot design in hardware.


Title: Stance Control Inspired by Cerebellum Stabilizes Reflex-Based Locomotion on HyQ Robot
Key Words: compliant mechanisms  feedback  legged locomotion  motion control  predictive control  robot dynamics  robust control  reflex based dynamic locomotion  stance control  cerebellum  legged robotics  central pattern generators  cyclic motion  robotic locomotion  reflex feedback  musculoskeletal simulation models  compliant quadruped robots  predictive control  gravity compensation mechanism  HyQ robot  stability module  robust locomotion  Legged locomotion  Cerebellum  Foot  Stability analysis  Robot kinematics 
Abstract: Advances in legged robotics are strongly rooted in animal observations. A clear illustration of this claim is the generalization of Central Pattern Generators (CPG), first identified in the cat spinal cord, to generate cyclic motion in robotic locomotion. Despite a global endorsement of this model, physiological and functional experiments in mammals have also indicated the presence of descending signals from the cerebellum, and reflex feedback from the lower limb sensory cells, that closely interact with CPGs. To this day, these interactions are not fully understood. In some studies, it was demonstrated that pure reflex-based locomotion in the absence of oscillatory signals could be achieved in realistic musculoskeletal simulation models or small compliant quadruped robots. At the same time, biological evidence has attested the functional role of the cerebellum for predictive control of balance and stance within mammals. In this paper, we promote both approaches and successfully apply reflex-based dynamic locomotion, coupled with a balance and gravity compensation mechanism, on the state-of-art HyQ robot. We discuss the importance of this stability module to ensure a correct foot lift-off and maintain a reliable gait. The robotic platform is further used to test two different architectural hypotheses inspired by the cerebellum. An analysis of experimental results demonstrates that the most biologically plausible alternative also leads to better results for robust locomotion.


Title: In-Hand Object Pose Tracking via Contact Feedback and GPU-Accelerated Robotic Simulation
Key Words: coprocessors  graphics processing units  manipulators  object tracking  optimisation  particle filtering (numerical methods)  pose estimation  robot vision  complex contact dynamics  GPU-accelerated parallel robot simulations  sample-based optimizers  contact feedback  robot-object interactions  GPU-accelerated robotic simulation  robot hand  vision-based methods  particle filters  static grasp setting  in-hand object pose tracking  manipulation  physics simulation  forward model  point cloud distance error  Pose estimation  Robot sensing systems  Physics  Heuristic algorithms  Cost function 
Abstract: Tracking the pose of an object while it is being held and manipulated by a robot hand is difficult for vision-based methods due to significant occlusions. Prior works have explored using contact feedback and particle filters to localize in-hand objects. However, they have mostly focused on the static grasp setting and not when the object is in motion, as doing so requires modeling of complex contact dynamics. In this work, we propose using GPU-accelerated parallel robot simulations and derivative-free, sample-based optimizers to track in-hand object poses with contact feedback during manipulation. We use physics simulation as the forward model for robot-object interactions, and the algorithm jointly optimizes for the state and the parameters of the simulations, so they better match with those of the real world. Our method runs in real-time (30Hz) on a single GPU, and it achieves an average point cloud distance error of 6mm in simulation experiments and 13mm in the real-world ones.


Title: Split Deep Q-Learning for Robust Object Singulation*
Key Words: collision avoidance  grippers  learning systems  manipulators  neurocontrollers  policy learning  split deep Q-learning  robust object singulation  robotic manipulation  robotic applications  grasping techniques  pushing policy  lateral pushing movements  reinforcement learning  optimal push policies  split DQN  target object extraction  Grasping  Task analysis  Clutter  Image segmentation  Robustness  Service robots 
Abstract: Extracting a known target object from a pile of other objects in a cluttered environment is a challenging robotic manipulation task encountered in many robotic applications. In such conditions, the target object touches or is covered by adjacent obstacle objects, thus rendering traditional grasping techniques ineffective. In this paper, we propose a pushing policy aiming at singulating the target object from its surrounding clutter, by means of lateral pushing movements of both the neighboring objects and the target object until sufficient 'grasping room' has been achieved. To achieve the above goal we employ reinforcement learning and particularly Deep Qlearning (DQN) to learn optimal push policies by trial and error. A novel Split DQN is proposed to improve the learning rate and increase the modularity of the algorithm. Experiments show that although learning is performed in a simulated environment the transfer of learned policies to a real environment is effective thanks to robust feature selection. Finally, we demonstrate that the modularity of the algorithm allows the addition of extra primitives without retraining the model from scratch.


Title: Aggressive Online Control of a Quadrotor via Deep Network Representations of Optimality Principles
Key Words: aircraft control  autonomous aerial vehicles  control engineering computing  helicopters  mobile robots  neural nets  optimisation  time optimal control  power optimality  time optimality  deep neural network  robotic applications  optimality principles  deep network representations  aggressive online control  time-optimal maneuvers  offline optimal control method  aggressive quadrotor control  Trajectory  Optimal control  Stability analysis  Neural networks  Delays  Training  Drones 
Abstract: Optimal control holds great potential to improve a variety of robotic applications. The application of optimal control on-board limited platforms has been severely hindered by the large computational requirements of current state of the art implementations. In this work, we make use of a deep neural network to directly map the robot states to control actions. The network is trained offline to imitate the optimal control computed by a time consuming direct nonlinear method. A mixture of time optimality and power optimality is considered with a continuation parameter used to select the predominance of each objective. We apply our networks (termed G&CNets) to aggressive quadrotor control, first in simulation and then in the real world. We give insight into the factors that influence the `reality gap' between the quadrotor model used by the offline optimal control method and the real quadrotor. Furthermore, we explain how we set up the model and the control structure on-board of the real quadrotor to successfully close this gap and perform time-optimal maneuvers in the real world. Finally, G&CNet's performance is compared to state-of-the-art differential-flatness-based optimal control methods. We show, in the experiments, that G&CNets lead to significantly faster trajectory execution due to, in part, the less restrictive nature of the allowed state-to-input mappings.


Title: Robust quadcopter control with artificial vector fields*
Key Words: autonomous aerial vehicles  control system synthesis  helicopters  mobile robots  multi-robot systems  nonlinear control systems  path planning  position control  robust control  time-varying systems  robust quadcopter control  artificial vector fields  path tracking control strategy  control laws  vector field  controlled second order integrator  quadcopter model  input-to-state stable  control inputs  Robots  Vehicle dynamics  Robustness  Convergence  Level set  Mathematical model  Force 
Abstract: This article presents a path tracking control strategy for a quadcopter to follow a time varying curve. The control is based on artificial vector fields. The construction of the field is based on a well known technique in the literature. Next, control laws are developed to impose the behavior of the vector field to a second order integrator model. Finally, control laws are developed to impose the dynamics of the controlled second order integrator to a quadcopter model, which assumes the thrust and the angular rates as input commands. Asymptotic convergence of the whole system is proved by showing that the individual systems in cascade connection are input-to-state stable. We also analyze the influence of norm-bounded disturbances in the control inputs to evaluate the robustness of the controller. We show that bounded disturbances originate limited deviations from the target curve. Simulations and a real robot experiment exemplify and validate the developed theory.


Title: Simulation-Based Reinforcement Learning for Real-World Autonomous Driving
Key Words: image segmentation  learning (artificial intelligence)  road vehicles  traffic engineering computing  simulation-based reinforcement learning  real-world autonomous driving  driving system  real-world vehicle  driving policy  RGB images  single camera  semantic segmentation  synthetic data  real-world data  segmentation network  real-world experiments  sim-to-real policy transfer  real-world performance  Training  Visualization  Learning (artificial intelligence)  Semantics  Robots  Image segmentation  Predictive models 
Abstract: We use reinforcement learning in simulation to obtain a driving system controlling a full-size real-world vehicle. The driving policy takes RGB images from a single camera and their semantic segmentation as input. We use mostly synthetic data, with labelled real-world data appearing only in the training of the segmentation network.Using reinforcement learning in simulation and synthetic data is motivated by lowering costs and engineering effort.In real-world experiments we confirm that we achieved successful sim-to-real policy transfer. Based on the extensive evaluation, we analyze how design decisions about perception, control, and training impact the real-world performance.


Title: Adaptive Curriculum Generation from Demonstrations for Sim-to-Real Visuomotor Control
Key Words: computer vision  control engineering computing  learning (artificial intelligence)  shaped reward functions  ACGD  policy transfer  real-world manipulation tasks  sim-to-real visuomotor control  reinforcement learning  adaptive curriculum generation  vision-based control policies  Task analysis  Training  Robots  Trajectory  Learning (artificial intelligence)  Adaptation models  Stacking 
Abstract: We propose Adaptive Curriculum Generation from Demonstrations (ACGD) for reinforcement learning in the presence of sparse rewards. Rather than designing shaped reward functions, ACGD adaptively sets the appropriate task difficulty for the learner by controlling where to sample from the demonstration trajectories and which set of simulation parameters to use. We show that training vision-based control policies in simulation while gradually increasing the difficulty of the task via ACGD improves the policy transfer to the real world. The degree of domain randomization is also gradually increased through the task difficulty. We demonstrate zero-shot transfer for two real-world manipulation tasks: pick-and-stow and block stacking. A video showing the results can be found at https://lmb.informatik.uni-freiburg.de/projects/curriculum/.


Title: An Open-Source Framework for Rapid Development of Interactive Soft-Body Simulations for Real-Time Training
Key Words: control engineering computing  force feedback  haptic interfaces  manipulators  medical computing  medical robotics  surgery  telerobotics  virtual reality  real-time simulation  interactive manipulation  human-readable front-end interface  commercially available haptic devices  game controllers  da Vinci Research Kit  real-time haptic feedback  multiuser training  manipulation problems  soft-body manipulation  open-source framework  interactive soft-body simulations  real-time training  master telemanipulators  Visualization  Computational modeling  Real-time systems  Training  Robots  Faces  Three-dimensional displays 
Abstract: We present an open-source framework that provides a low barrier to entry for real-time simulation, visualization, and interactive manipulation of user-specifiable soft-bodies, environments, and robots (using a human-readable front-end interface). The simulated soft-bodies can be interacted by a variety of input interface devices including commercially available haptic devices, game controllers, and the Master Tele-Manipulators (MTMs) of the da Vinci Research Kit (dVRK) with real-time haptic feedback. We propose this framework for carrying out multi-user training, user-studies, and improving the control strategies for manipulation problems. In this paper, we present the associated challenges to the development of such a framework and our proposed solutions. We also demonstrate the performance of this framework with examples of soft-body manipulation and interaction with various input devices.


Title: Towards 5-DoF Control of an Untethered Magnetic Millirobot via MRI Gradient Coils
Key Words: biomedical MRI  medical image processing  medical robotics  microrobots  path planning  surgery  untethered magnetic millirobot  MRI gradient coils  electromagnetic field gradients  magnetic resonance imaging devices  power untethered magnetic robots  MRI devices  magnetic pulling forces  drug delivery  MRI-powered untethered magnetic robots  orientation control  three-dimensional fluids  3-DoF position control  path-planning-based 5-DoF control algorithm  optimal controller  robot manufacturing errors  pitch angle  neutral pitching angle  3D Bezier curves  worst-case path-tracking error  position-tracking error  orientation-tracking error  pitch angles  future MRI-powered active imaging  laser surgery  biopsy robots  Magnetic resonance imaging  Robots  Magnetic devices  Coils  Three-dimensional displays  Force  Medical robotics  miniature robots  magnetic actuation  magnetic resonance imaging  optimal control 
Abstract: Electromagnetic field gradients generated by magnetic resonance imaging (MRI) devices pave the way to power untethered magnetic robots remotely. This innovative use of MRI devices allows exerting magnetic pulling forces on untethered magnetic robots, which could be used for navigation, diagnosis, drug delivery and therapeutic procedures inside a human body. So far, MRI-powered untethered magnetic robots lack simultaneous position and orientation control inside three-dimensional (3D) fluids, and therefore, their control has been limited to 3-DoF position control. In this paper, we present a path-planning-based 5-DoF control algorithm to steer and control an MRI-powered untethered robot's position and orientation simultaneously in 3D workspaces in fluids. Eventhough the simulation results show that the proposed optimal controller can successfully control the robot for 5-DoF, in the experiments, we observe a reduced 5-DoF controllability due to the robot manufacturing errors, which result in pitch angle to remain at around the neutral pitching angle at the steady state. The proposed controller was evaluated to track four different paths (linear, planar-horizontal, planar-vertical and 3D paths) generated by 3D Bezier curves. The worst-case path-tracking error was observed for 3D path-following experiments. For this case, the position-tracking error was 2.71.8 mm, and the orientation-tracking error was 13.5 28.7 and 3.7 10.2 degrees for yaw and pitch angles, respectively. The overall path is completed within 19.6 seconds with 23.6 mm overall displacement and 61.2 and 41.2 degrees of yaw and pitch angle rotation, respectively. Such robots can be used in future MRI-powered active imaging, laser surgery and biopsy robots inside a fluid-filled stomach type of organs.


Title: SL1M: Sparse L1-norm Minimization for contact planning on uneven terrain
Key Words: integer programming  legged locomotion  linear programming  minimisation  trajectory control  kinematic reachability  contact effectors  quasistatic COM trajectory  quasiflat contacts  contact surfaces  SL1M  uneven terrain  legged locomotion  combinatorial contact selection problem  mixed-integer optimization solvers  sparsity properties  L1 norm minimization techniques  online contact replanning  sparse L1-norm minimization  Silicon  Planning  Foot  Minimization  Kinematics  Legged locomotion 
Abstract: One of the main challenges of planning legged locomotion in complex environments is the combinatorial contact selection problem. Recent contributions propose to use integer variables to represent which contact surface is selected, and then to rely on modern mixed-integer (MI) optimization solvers to handle this combinatorial issue. To reduce the computational cost of MI, we exploit the sparsity properties of L1 norm minimization techniques to relax the contact planning problem into a feasibility linear program. Our approach accounts for kinematic reachability of the center of mass (COM) and of the contact effectors. We ensure the existence of a quasi-static COM trajectory by restricting our plan to quasi-flat contacts. For planning 10 steps with less than 10 potential contact surfaces for each phase, our approach is 50 to 100 times faster that its MI counterpart, which suggests potential applications for online contact re-planning. The method is demonstrated in simulation with the humanoid robots HRP-2 and Talos over various scenarios.


Title: Finding Locomanipulation Plans Quickly in the Locomotion Constrained Manifold
Key Words: end effectors  humanoid robots  legged locomotion  manipulator dynamics  mobile robots  motion control  path planning  robot programming  locomanipulation plans  locomotion constrained manifold  end-effector trajectory  injective locomotion constraint manifold  locomotion scheme  admissible manipulation trajectories  weighted-A* graph search  planner output  contact transitions  path progression trajectory  whole-body kinodynamic locomanipulation plan  locomanipulability region  edge transition feasibility  NASA Valkyrie robot platform  dynamic locomotion approach  example locomanipulation scenarios  divergent-component-of-motion  Trajectory  Task analysis  Foot  Manifolds  Pelvis  Legged locomotion 
Abstract: We present a method that finds locomanipulation plans that perform simultaneous locomotion and manipulation of objects for a desired end-effector trajectory. Key to our approach is to consider an injective locomotion constraint manifold that defines the locomotion scheme of the robot and then using this constraint manifold to search for admissible manipulation trajectories. The problem is formulated as a weighted-A* graph search whose planner output is a sequence of contact transitions and a path progression trajectory to construct the whole-body kinodynamic locomanipulation plan. We also provide a method for computing, visualizing, and learning the locomanipulability region, which is used to efficiently evaluate the edge transition feasibility during the graph search. Numerical simulations are performed with the NASA Valkyrie robot platform that utilizes a dynamic locomotion approach, called the divergent-component-of-motion (DCM), on two example locomanipulation scenarios.


Title: Dense r-robust formations on lattices
Key Words: energy consumption  multi-robot systems  network theory (graphs)  cubic lattices  dense r-robust formations  robot networks  malicious robots  defective robots  high energy consumption  communication network  robot formations  square lattices  triangular lattices  Lattices  Robot kinematics  Communication networks  Robustness  Robot sensing systems  Energy consumption 
Abstract: Robot networks are susceptible to fail under the presence of malicious or defective robots. Resilient networks in the literature require high connectivity and large communication ranges, leading to high energy consumption in the communication network. This paper presents robot formations with guaranteed resiliency that use smaller communication ranges than previous results in the literature. The formations can be built on triangular and square lattices in the plane, and cubic lattices in the three-dimensional space. We support our theoretical framework with simulations.


Title: Optimizing Topologies for Probabilistically Secure Multi-Robot Systems
Key Words: combinatorial mathematics  computational complexity  graph theory  matrix algebra  Monte Carlo methods  multi-robot systems  optimisation  set theory  statistical distributions  multirobot system  MRS  robot interactions  probability distribution  optimal solution  rooted k-connections problem  graph transformations  weighted matroid intersection algorithm  edge set  interaction graph  optimal security solution  secure multirobot systems  Robots  Probabilistic logic  Security  Optimization  Topology  Observers  Multi-robot systems 
Abstract: In this paper, we optimize the interaction graph of a multi-robot system (MRS) by maximizing its probability of security while requiring the MRS to have the fewest edges possible. Edges that represent robot interactions exist according to a probability distribution and security is defined using the control theoretic notion of left invertibility. To compute an optimal solution to our problem, we first start by reducing our problem to a variation of the rooted k-connections problem using three graph transformations. Then, we apply a weighted matroid intersection algorithm (WMIA) on matroids defined on the edge set of the interaction graph. Although the optimal solution can be found in polynomial time, MRSs are dynamic and their topologies may change faster than the rate at which the optimal security solution can be found. To cope with dynamic behavior, we present two heuristics that relax optimality but execute with much lower time complexity. Finally, we validate our results through Monte Carlo simulations.


Title: CyPhyHouse: A programming, simulation, and deployment toolchain for heterogeneous distributed coordination
Key Words: control engineering computing  control system synthesis  learning (artificial intelligence)  middleware  mobile computing  mobile robots  multi-threading  path planning  program debugging  specification languages  heterogeneous distributed coordination  libraries  development tools  application development processes  mobile computing  machine learning  CyPhyHouse  debugging  distributed mobile robotic applications  distributed applications  Koord programming language  controller design  distributed network protocols  platform-independent middleware  path planning  multithreaded simulator  Koord applications  application code  heterogeneous agents  heterogeneous mobile platforms  design cycles  robotic testbed  distributed task allocation  deployment toolchain  hardware-agnostic application  Robot kinematics  Task analysis  Middleware  Collision avoidance  Python 
Abstract: Programming languages, libraries, and development tools have transformed the application development processes for mobile computing and machine learning. This paper introduces CyPhyHouse-a toolchain that aims to provide similar programming, debugging, and deployment benefits for distributed mobile robotic applications. Users can develop hardware-agnostic, distributed applications using the high-level, event driven Koord programming language, without requiring expertise in controller design or distributed network protocols. The modular, platform-independent middleware of CyPhyHouse implements these functionalities using standard algorithms for path planning (RRT), control (MPC), mutual exclusion, etc. A high-fidelity, scalable, multi-threaded simulator for Koord applications is developed to simulate the same application code for dozens of heterogeneous agents. The same compiled code can also be deployed on heterogeneous mobile platforms. The effectiveness of CyPhyHouse in improving the design cycles is explicitly illustrated in a robotic testbed through development, simulation, and deployment of a distributed task allocation application on in-house ground and aerial vehicles.


Title: Chance Constrained Simultaneous Path Planning and Task Assignment for Multiple Robots with Stochastic Path Costs
Key Words: distributed algorithms  graph theory  multi-robot systems  path planning  probability  stochastic processes  simultaneous path planning  multiple robots  stochastic path costs  stochastic edge costs  robot team  stochastic travel costs  chance-constrained simultaneous task assignment  deterministic simultaneous task assignment  shortest paths  task locations  linear assignment problem  CC-STAP  Robots  Task analysis  Collision avoidance  Path planning  Resource management  Random variables  Planning 
Abstract: We present a novel algorithm for simultaneous task assignment and path planning on a graph (or roadmap) with stochastic edge costs. In this problem, the initially unassigned robots and tasks are located at known positions in a roadmap. We want to assign a unique task to each robot and compute a path for the robot to go to its assigned task location. Given the mean and variance of travel cost of each edge, our goal is to develop algorithms that, with high probability, the total path cost of the robot team is below a minimum value in any realization of the stochastic travel costs. We formulate the problem as a chance-constrained simultaneous task assignment and path planning problem (CC-STAP). We prove that the optimal solution of CC-STAP can be obtained by solving a sequence of deterministic simultaneous task assignment and path planning problems in which the travel cost is a linear combination of mean and variance of the edge cost. We show that the deterministic problem can be solved in two steps. In the first step, robots compute the shortest paths to the task locations and in the second step, the robots solve a linear assignment problem with the costs obtained in the first step. We also propose a distributed algorithm that solves CC-STAP near-optimally. We present simulation results on randomly generated networks and data to demonstrate that our algorithm is scalable with the number of robots (or tasks) and the size of the network.


Title: Optimal Topology Selection for Stable Coordination of Asymmetrically Interacting Multi-Robot Systems
Key Words: integer programming  mathematical programming  motion control  multi-robot systems  topology  stable coordinated motion  robot-to-robot interactions  asymmetric interaction topologies  multirobot motion  mixed integer semidefinite programming  multirobot systems  asymmetric interactions  optimal topology selection  Robot kinematics  Topology  Robot sensing systems  Multi-robot systems  Symmetric matrices  Laplace equations 
Abstract: In this paper, we address the problem of optimal topology selection for stable coordination of multi-robot systems with asymmetric interactions. This problem arises naturally for multi-robot systems that interact based on sensing, e.g., with limited field of view (FOV) cameras. From our previous efforts on motion control in such settings, we have shown that not all interaction topologies yield stable coordinated motion when asymmetry exists. At the same time, not all robot-to-robot interactions are of equal quality, and thus we seek to optimize asymmetric interaction topologies subject to the constraint that the topology yields stable multi-robot motion. In this context, we formulate an optimal topology selection problem (OTSP) as a mixed integer semidefinite programming (MISDP) problem to compute optimal topologies that yield stable coordinated motion. Simulation results are provided to corroborate the effectiveness of the proposed OTSP formulation.


Title: Non-Prehensile Manipulation in Clutter with Human-In-The-Loop
Key Words: manipulators  mobile robots  path planning  human-operator guided planning  low-level planner  fully autonomous sampling-based planners  human-in-the-loop  high-level plan  control-based randomized planning  pushing-based manipulation  clutter  nonprehensile manipulation  Robots  Planning  Clutter  Aerospace electronics  1/f noise  Task analysis  Automation 
Abstract: We propose a human-operator guided planning approach to pushing-based manipulation in clutter. Most recent approaches to manipulation in clutter employs randomized planning. The problem, however, remains a challenging one where the planning times are still in the order of tens of seconds or minutes, and the success rates are low for difficult instances of the problem. We build on these control-based randomized planning approaches, but we investigate using them in conjunction with human-operator input. In our framework, the human operator supplies a high-level plan, in the form of an ordered sequence of objects and their approximate goal positions. We present experiments in simulation and on a real robotic setup, where we compare the success rate and planning times of our human-in-the-loop approach with fully autonomous sampling-based planners. We show that with a minimal amount of human input, the low-level planner can solve the problem faster and with higher success rates.


Title: Accurate Vision-based Manipulation through Contact Reasoning
Key Words: control engineering computing  inference mechanisms  manipulators  neural nets  robot vision  state estimation  vision-based manipulation  contact reasoning  contact interactions  motion optimization  state estimation  state representation  neural networks  Shape  Predictive models  Planning  Analytical models  Robots  Computational modeling  Task analysis 
Abstract: Planning contact interactions is one of the core challenges of many robotic tasks. Optimizing contact locations while taking dynamics into account is computationally costly and, in environments that are only partially observable, executing contact-based tasks often suffers from low accuracy. We present an approach that addresses these two challenges for the problem of vision-based manipulation. First, we propose to disentangle contact from motion optimization. Thereby, we improve planning efficiency by focusing computation on promising contact locations. Second, we use a hybrid approach for perception and state estimation that combines neural networks with a physically meaningful state representation. In simulation and real-world experiments on the task of planar pushing, we show that our method is more efficient and achieves a higher manipulation accuracy than previous vision-based approaches.


Title: Planning with Selective Physics-based Simulation for Manipulation Among Movable Objects
Key Words: computer simulation  manipulators  path planning  planning model  robot manipulator  planning with selective physics based simulation  Planning  Collision avoidance  Manipulators  Physics  Computational modeling  Task analysis 
Abstract: Use of physics-based simulation as a planning model enables a planner to reason and generate plans that involve non-trivial interactions with the world. For example, grasping a milk container out of a cluttered refrigerator may involve moving a robot manipulator in between other objects, pushing away the ones that are moveable and avoiding interactions with certain fragile containers. A physics-based simulator allows a planner to reason about the effects of interactions with these objects and to generate a plan that grasps the milk container successfully. The use of physics-based simulation for planning however is underutilized. One of the reasons for it being that physics-based simulations are typically way too slow for being used within a planning loop that typically requires tens of thousands of actions to be evaluated within a matter of a second or two. In this work, we develop a planning algorithm that tries to address this challenge. In particular, it builds on the observation that only a small number of actions actually need to be simulated using physics, and the remaining set of actions, such as moving an arm around obstacles, can be evaluated using a much simpler internal planning model, e.g., a simple collision-checking model. Motivated by this, we develop an algorithm called Planning with Selective Physics-based Simulation that automatically discovers what should be simulated with physics and what can utilize an internal planning model for pick-and-place tasks.


Title: Who2com: Collaborative Perception via Learnable Handshake Communication
Key Words: aircraft communication  autonomous aerial vehicles  image segmentation  learning (artificial intelligence)  multi-agent systems  multi-robot systems  neural nets  visual perception  degraded sensor data  compressed request  aerial robots  semantic segmentation task  collaborative perception  learnable handshake communication  local observations  neighboring agents  multiagent reinforcement learning  bandwidth-sensitive manner  scene understanding tasks  communication protocols  multistage handshake communication mechanism  neural network  Who2com  AirSim simulator  AirSim-CP dataset  Task analysis  Bandwidth  Semantics  Training  Collaboration  Robot sensing systems 
Abstract: In this paper, we propose the problem of collaborative perception, where robots can combine their local observations with those of neighboring agents in a learnable way to improve accuracy on a perception task. Unlike existing work in robotics and multi-agent reinforcement learning, we formulate the problem as one where learned information must be shared across a set of agents in a bandwidth-sensitive manner to optimize for scene understanding tasks such as semantic segmentation. Inspired by networking communication protocols, we propose a multi-stage handshake communication mechanism where the neural network can learn to compress relevant information needed for each stage. Specifically, a target agent with degraded sensor data sends a compressed request, the other agents respond with matching scores, and the target agent determines who to connect with (i.e., receive information from). We additionally develop the AirSim-CP dataset and metrics based on the AirSim simulator where a group of aerial robots perceive diverse landscapes, such as roads, grasslands, buildings, etc. We show that for the semantic segmentation task, our handshake communication method significantly improves accuracy by approximately 20% over decentralized baselines, and is comparable to centralized ones using a quarter of the bandwidth.


Title: Studying Navigation as a Form of Interaction: a Design Approach for Social Robot Navigation Methods*
Key Words: human-robot interaction  mobile robots  motion control  navigation  social robot navigation methods  social navigation methods  human sciences fields  mobile robot navigation  robot behavior  social hierarchy  socio-physical context  robot motion  human-robot interaction  human behavior  Navigation  Biological system modeling  Robot sensing systems  Mobile robots  Design methodology  Task analysis 
Abstract: Social Navigation methods attempt to integrate knowledge from Human Sciences fields such as the notion of Proxemics into mobile robot navigation. They are often evaluated in simulations, or lab conditions with informed participants, and studies of the impact of the robot behavior on humans are rare. Humans communicate and interact through many vectors, among which are motion and positioning, which can be related to social hierarchy and the socio-physical context. If a robot is to be deployed among humans, the methods it uses should be designed with this in mind. This work acts as the first step in an ongoing project in which we explore how to design navigation methods for mobile robots destined to be deployed among humans. We aim to consider navigation as more than just a functionality of the robot, and to study the impact of robot motion on humans. In this paper, we focus on the person-following task. We selected a state of the art person-following method as the basis for our method, which we modified and extended in order for it to be more general and adaptable. We conducted pilot experiments using this method on a real mobile robot in ecological contexts. We used results from the experiments to study the Human-Robot Interaction as a whole by analysing both the person-following method and the human behavior. Our preliminary results show that the way in which the robot followed a person had an impact on the interaction that emerged between them.


Title: Mapless Navigation among Dynamics with Social-safety-awareness: a reinforcement learning approach from 2D laser scans
Key Words: collision avoidance  control engineering computing  learning (artificial intelligence)  mobile robots  navigation  path planning  robot dynamics  robot programming  time-efficient path planning behavior  dynamic crowds  social-safety-awareness  reinforcement learning  2D laser scans  mapless collision-avoidance navigation  ego-safety  pedestrians  robot tests  Collision avoidance  Navigation  Training  Robot sensing systems  Lasers  Path planning 
Abstract: We consider the problem of mapless collision-avoidance navigation where humans are present using 2D laser scans. Our proposed method uses ego-safety to measure collision from the robot's perspective and social-safety to measure the impact of robot's actions on surrounding pedestrians. Specifically, the social-safety part predicts the intrusion impact of the robot's action into the interaction area with surrounding humans. We train the policy using reinforcement learning on a simple simulator and directly evaluate the learned policy in Gazebo and real robot tests. Experiments show the learned policy smoothly transferred to different scenarios without any fine tuning. We observe that our method demonstrates time-efficient path planning behavior with high success rate in the mapless navigation task. Furthermore, we test our method in a navigation task among dynamic crowds, considering both low and high volume traffic. Our learned policy demonstrates cooperative behavior that actively drives our robot into traffic flows while showing respect to nearby pedestrians. Evaluation videos are at https://sites.google.com/view/ssw-batman.


Title: Steering Control of Magnetic Helical Swimmers in Swirling Flows due to Confinement
Key Words: biomechanics  cell motility  computational fluid dynamics  flow simulation  hydrodynamics  magnetic actuators  microrobots  mobile robots  Navier-Stokes equations  position control  propulsion  swirling flow  trajectory control  vortices  prospective robotic agents  rotating magnetic field  magnetized swimmer  helical tail  helical paths  pusher-mode swimmers  rotating magnetic head  microswimmers  swimmer orientation  render orientation-based methods  confined swimmer  control law  swimmer position  swirling flow  helical pusher-mode trajectories  steering control  magnetic helical swimmers  Magnetic fields  Magnetosphere  Magnetic confinement  Magnetohydrodynamics  Propulsion  Navigation  microswimmers  helical swimming  low Reynolds number  steering  control  stability 
Abstract: Artificial microswimmers are prospective robotic agents especially in biomedical applications. A rotating magnetic field can actuate a magnetized swimmer with a helical tail and enable propulsion. Such swimmers exhibit several modes of instability. Inside conduits, for example, hydrodynamic interactions with the boundaries lead to helical paths for pusher-mode swimmers; in this mode the helical tail pushes a rotating magnetic head. State-of-the-art in controlled navigation of micro-swimmers is based on aligning the swimmer orientation according to a reference path, thereby requiring both swimmer orientation and position to be known. Object-orientation is hard to track especially in in vivo scenarios which render orientation-based methods practically unfeasible. Here, we show that the kinematics for a confined swimmer can be linearized by assuming a low wobbling angle. This allows for a control law solely based on the swimmer position. The approach is demonstrated through experiments and two different numerical models: the first is based on the resistive force theory for a swimmer inside a swirling flow represented by a forced vortex and the second is a computational fluid dynamics model, which solves Stokes equations for a swimmer inside a circular channel. Helical pusher-mode trajectories are suppressed significantly for the straight path following problem. The error in real-life experiments remains comparable to those in the state-of-the-art methods.


Title: Sim2real gap is non-monotonic with robot complexity for morphology-in-the-loop flapping wing design
Key Words: aerospace components  aerospace control  learning (artificial intelligence)  mobile robots  biological exemplars  robot design  morphology-in-the-loop flapping wing design  robot complexity  sim2real gap  design complexity  sim2real transfer  high performance robot morphologies  parameterised morphology design space  flapping wing flight  machine learning  Morphology  Robots  Shape  Finite element analysis  Complexity theory  Computational modeling  Machine learning  morphology  simulation to reality  evolution  bio-inspired 
Abstract: Morphology of a robot design is important to its ability to achieve a stated goal and therefore applying machine learning approaches that incorporate morphology in the design space can provide scope for significant advantage. Our study is set in a domain known to be reliant on morphology: flapping wing flight. We developed a parameterised morphology design space that draws features from biological exemplars and apply automated design to produce a set of high performance robot morphologies in simulation. By performing sim2real transfer on a selection, for the first time we measured the shape of the reality gap for variations in design complexity. We found for the flapping wing that the reality gap changes non-monotonically with complexity, suggesting that certain morphology details narrow the gap more than others, and that such details could be identified and further optimised in a future end-to-end automated morphology design process.


Title: A Linearized Model for an Ornithopter in Gliding Flight: Experiments and Simulations
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  linearisation techniques  position control  velocity control  longitudinal gliding flight configuration  aerodynamic forces  linearized potential theory  flat plate  flapping-wing episodes  linear potential theory  steady-state descent  terminal velocity  pitching  gliding angles  tail position  flapping-wing configuration  flight velocity  climbing episodes  realistic simulation tool  flapping frequencies  ornithopter flight  linearized model  flapping-wings UAV  Unreal Engine 4  Numerical models  Force  Mathematical model  Hardware  Steady-state  Computed tomography  Aerodynamics 
Abstract: This work studies the accuracy of a simple but effective analytical model for a flapping-wings UAV in longitudinal gliding flight configuration comparing it with experimental results of a real ornithopter. The aerodynamic forces are modeled following the linearized potential theory for a flat plate in gliding configuration, extended to flapping-wing episodes modeled also by the (now unsteady) linear potential theory, which are studied numerically. In the gliding configuration, the model reaches a steady-state descent at given terminal velocity and pitching and gliding angles, governed by the wings and tail position. In the flapping-wing configuration, it is noticed that the vehicle can increase its flight velocity and perform climbing episodes. A realistic simulation tool based on Unreal Engine 4 was developed to visualize the effect of the tail position and flapping frequencies and amplitudes on the ornithopter flight in real time. The paper also includes the experimental validation of the gliding flight and the data has been released for the community.


Title: GPR-based Subsurface Object Detection and Reconstruction Using Random Motion and DepthNet
Key Words: feature extraction  geophysical image processing  geophysical techniques  ground penetrating radar  image reconstruction  inspection  learning (artificial intelligence)  neural nets  object detection  radar detection  radar imaging  stereo image processing  GPR-based subsurface object detection  DepthNet  Ground Penetrating Radar  nondestructive evaluation devices  underground scene  GPR based inspection  underground targets  pose information  GPR device  GPR image  B-scan data  GPR scan data  B-scan image  Geophysical Survey System Inc.  synthetic GPR data  B-scan feature detection  underground target depth prediction  GSSI  visual inertial fusion module  VIF module  gprMax3.0 simulator  NDE devices  3D GPR migration  dielectric prediction system  deep neural network module  Ground penetrating radar  Three-dimensional displays  Image reconstruction  Dielectrics  Feature extraction  Object detection  Inspection 
Abstract: Ground Penetrating Radar (GPR) is one of the most important non-destructive evaluation (NDE) devices to detect the subsurface objects (i.e. rebars, utility pipes) and reveal the underground scene. One of the biggest challenges in GPR based inspection is the subsurface targets reconstruction. In order to address this issue, this paper presents a 3D GPR migration and dielectric prediction system to detect and reconstruct underground targets. This system is composed of three modules: 1) visual inertial fusion (VIF) module to generate the pose information of GPR device, 2) deep neural network module (i.e., DepthNet) which detects B-scan of GPR image, extracts hyperbola features to remove the noise in B-scan data and predicts dielectric to determine the depth of the objects, 3) 3D GPR migration module which synchronizes the pose information with GPR scan data processed by DepthNet to reconstruct and visualize the 3D underground targets. Our proposed DepthNet processes the GPR data by removing the noise in B-scan image as well as predicting depth of subsurface objects. For DepthNet model training and testing, we collect the real GPR data in the concrete test pit at Geophysical Survey System Inc. (GSSI) and create the synthetic GPR data by using gprMax3.0 simulator. The dataset we create includes 350 labeled GPR images. The DepthNet achieves an average accuracy of 92.64% for B-scan feature detection and an 0.112 average error for underground target depth prediction. In addition, the experimental results verify that our proposed method improve the migration accuracy and performance in generating 3D GPR image compared with the traditional migration methods.


Title: Multi-task closed-loop inverse kinematics stability through semidefinite programming
Key Words: closed loop systems  control system synthesis  discrete time systems  humanoid robots  linear matrix inequalities  Lyapunov methods  mathematical programming  mobile robots  robot kinematics  stability  multitask closed-loop inverse kinematics stability  multiobjective task resolution  humanoid robots  local stability problem  closed-loop inverse kinematics algorithm  highly redundant robots  system stability  closed-loop control gains  semidefinite programming problem  discrete-time Lyapunov stability condition  SDP optimization problem  stability conditions  Task analysis  Stability analysis  Robots  Kinematics  Thermal stability  Numerical stability  Asymptotic stability 
Abstract: Today's complex robotic designs comprise in some cases a large number of degrees of freedom, enabling for multi-objective task resolution (e.g., humanoid robots or aerial manipulators). This paper tackles the local stability problem of a hierarchical closed-loop inverse kinematics algorithm for such highly redundant robots. We present a method to guarantee this system stability by performing an online tuning of the closed-loop control gains. We define a semi-definite programming problem (SDP) with these gains as decision variables and a discrete-time Lyapunov stability condition as a linear matrix inequality, constraining the SDP optimization problem and guaranteeing the local stability of the prioritized tasks. To the best of authors' knowledge, this work represents the first mathematical development of an SDP formulation that introduces these stability conditions for a multi-objective closed-loop inverse kinematic problem for highly redundant robots. The validity of the proposed approach is demonstrated through simulation case studies, including didactic examples and a Matlab toolbox for the benefit of the community.


Title: Securing Industrial Operators with Collaborative Robots: Simulation and Experimental Validation for a Carpentry task
Key Words: industrial robots  machine tools  milling  mobile robots  safety  wood  industrial operators  collaborative robot  carpentry task  robotic assistance strategy  machine-tool  wood milling  accidentogenic aspect  physical model  tooling process  safety  Task analysis  Cutting tools  Milling  Force  Service robots  Safety 
Abstract: In this work, a robotic assistance strategy is developed to improve the safety in an artisanal task that involves a strong interaction between a machine-tool and an operator. Wood milling is chosen as a pilot task due to its importance in carpentry and its accidentogenic aspect. A physical model of the tooling process including a human is proposed and a simulator is thereafter developed to better understand situations that are dangerous for the craftsman. This simulator is validated with experiments on three subjects using an harmless mock-up. This validation shows the pertinence of the proposed control approach for the collaborative robot used to increase the safety of the task.


Title: Learning Shape-based Representation for Visual Localization in Extremely Changing Conditions
Key Words: convolutional neural nets  disasters  image representation  image texture  learning (artificial intelligence)  natural scenes  pose estimation  shape recognition  shape-based representation  visual localization  extremely changing conditions  convolutional neural network  layout changes  approximate scene coordinates  scene layout  CNN  stylized images  estimated dominant planes  query images  simulated disaster dataset  reliable camera pose predictions  Visualization  Shape  Cameras  Semantics  Robustness  Geometry  Buildings 
Abstract: Visual localization is an important task for applications such as navigation and augmented reality, but is a challenging problem when there are changes in scene appearances through day, seasons, or environments. In this paper, we present a convolutional neural network (CNN)-based approach for visual localization across normal to drastic appearance variations such as pre- and post-disaster cases. Our approach aims to address two key challenges: (1) to reduce the biases based on scene textures as in traditional CNNs, our model learns a shape-based representation by training on stylized images; (2) to make the model robust against layout changes, our approach uses the estimated dominant planes of query images as approximate scene coordinates. Our method is evaluated on various scenes including a simulated disaster dataset to demonstrate the effectiveness of our method in significant changes of scene layout. Experimental results show that our method provides reliable camera pose predictions in various changing conditions.


Title: Trajectory Planning with Safety Guaranty for a Multirotor based on the Forward and Backward Reachability Analysis
Key Words: aircraft control  collision avoidance  helicopters  reachability analysis  robust control  set theory  trajectory control  obstacle avoidance  risk free flight  backward reachable sets  forward reachable sets  robust trajectory planning algorithm  safety guarantee  multirotor  Hamilton-Jacobi reachability analysis  Trajectory  Planning  Safety  Reachability analysis  Robustness  Optimization  Aerospace engineering 
Abstract: Planning a trajectory with guaranteed safety is a core part for a risk-free flight of a multirotor. If a trajectory planner only aims to ensure safety, it may generate trajectories which overly bypass risky regions and prevent the system from achieving specific missions. This work presents a robust trajectory planning algorithm which simultaneously guarantees the safety and reachability to the target state in the presence of unknown disturbances. We first characterize how the forward and backward reachable sets (FRSs and BRSs) are constructed by using Hamilton-Jacobi reachability analysis. Based on the analysis, we present analytic expressions for the reachable sets and then propose minimal ellipsoids which closely approximate the reachable sets. In the planning process, we optimize the reference trajectory to connect the FRSs and BRSs, while avoiding obstacles. By combining the FRSs and BRSs, we can guarantee that any state inside of the initial set reaches the target set. We validate the proposed algorithm through a simulation of traversing a narrow gap.


Title: A Hamilton-Jacobi Reachability-Based Framework for Predicting and Analyzing Human Motion for Safe Planning
Key Words: Bayes methods  belief networks  continuous time systems  motion control  path planning  predictive control  probability  reachability analysis  robots  stochastic processes  probabilistic predictive models  human behavior  future motion  observation models  state predictions  robot motion plan  human behavioral data  human motion prediction  Hamilton-Jacobi reachability problem  continuous-time dynamical system  model parameters  worst-case forward reachable set  future state distributions  robust planning  Hamilton-Jacobi reachability-based framework  human motion analysis  safe planning  real-world autonomous systems  Predictive models  Robots  Stochastic processes  Planning  Data models  Computational modeling  Robustness 
Abstract: Real-world autonomous systems often employ probabilistic predictive models of human behavior during planning to reason about their future motion. Since accurately modeling human behavior a priori is challenging, such models are often parameterized, enabling the robot to adapt predictions based on observations by maintaining a distribution over the model parameters. Although this enables data and priors to improve the human model, observation models are difficult to specify and priors may be incorrect, leading to erroneous state predictions that can degrade the safety of the robot motion plan. In this work, we seek to design a predictor which is more robust to misspecified models and priors, but can still leverage human behavioral data online to reduce conservatism in a safe way. To do this, we cast human motion prediction as a Hamilton-Jacobi reachability problem in the joint state space of the human and the belief over the model parameters. We construct a new continuous-time dynamical system, where the inputs are the observations of human behavior, and the dynamics include how the belief over the model parameters change. The results of this reachability computation enable us to both analyze the effect of incorrect priors on future predictions in continuous state and time, as well as to make predictions of the human state in the future. We compare our approach to the worst-case forward reachable set and a stochastic predictor which uses Bayesian inference and produces full future state distributions. Our comparisons in simulation and in hardware demonstrate how our framework can enable robust planning while not being overly conservative, even when the human model is inaccurate. Videos of our experiments can be found at the project website1.


Title: Robust Model Predictive Shielding for Safe Reinforcement Learning with Stochastic Dynamics
Key Words: learning (artificial intelligence)  mobile robots  nonlinear control systems  nonlinear dynamical systems  predictive control  probability  robust control  stochastic processes  stochastic systems  backup policy  learned policy  control policy  additive stochastic disturbances  nominal dynamics  stochastic nonlinear dynamical systems  stochastic dynamics  safe reinforcement learning  robust model predictive shielding  stochastic systems  statistical learning theory  backup controller  tube-based robust nonlinear model predictive controller  Safety  Robustness  Stochastic processes  Robots  Trajectory  Nonlinear dynamical systems  Heuristic algorithms 
Abstract: We propose a framework for safe reinforcement learning that can handle stochastic nonlinear dynamical systems. We focus on the setting where the nominal dynamics are known, and are subject to additive stochastic disturbances with known distribution. Our goal is to ensure the safety of a control policy trained using reinforcement learning, e.g., in a simulated environment. We build on the idea of model predictive shielding (MPS), where a backup controller is used to override the learned policy as needed to ensure safety. The key challenge is how to compute a backup policy in the context of stochastic dynamics. We propose to use a tube-based robust nonlinear model predictive controller (NMPC) as the backup controller. We estimate the tubes using sampled trajectories, leveraging ideas from statistical learning theory to obtain high-probability guarantees. We empirically demonstrate that our approach can ensure safety in stochastic systems, including cart-pole and a non-holonomic particle with random obstacles.


Title: Segregation of Heterogeneous Swarms of Robots in Curves
Key Words: collision avoidance  decentralised control  mobile robots  multi-robot systems  topology  decentralized control strategy  heterogeneous robot swarms  formation control  collision avoidance strategy  multiple heterogeneous robots  heterogeneous swarm segregation  Collision avoidance  Robot kinematics  Heuristic algorithms  Topology  Convergence  Damping 
Abstract: This paper proposes a decentralized control strategy to reach segregation in heterogeneous robot swarms distributed in curves. The approach is based on a formation control algorithm applied to each robot and a heuristics to compute the distance between the groups, i.e. the distance from the beginning of the curve. We consider that robots can communicate through a fixed underlying topology and also when they are within a certain distance. A convergence proof with a collision avoidance strategy is presented. Simulations and experimental results show that our approach allows a swarm of multiple heterogeneous robots to segregate into groups.


Title: A Fast, Accurate, and Scalable Probabilistic Sample-Based Approach for Counting Swarm Size
Key Words: control engineering computing  distributed algorithms  multi-robot systems  particle swarm optimisation  path planning  counting swarm  distributed algorithm  neighboring robots  robot swarm  Robots  Estimation  Shape  Task analysis  Heuristic algorithms  Random variables  Clocks 
Abstract: This paper describes a distributed algorithm for computing the number of robots in a swarm, only requiring communication with neighboring robots. The algorithm can adjust the estimated count when the number of robots in the swarm changes, such as the addition or removal of robots. Probabilistic guarantees are given, which show the accuracy of this method, and the trade-off between accuracy, speed, and adaptability to changing numbers. The proposed approach is demonstrated in simulation as well as a real swarm of robots.


Title: Automatic tool for Gazebo world construction: from a grayscale image to a 3D solid model
Key Words: control engineering computing  laser ranging  mobile robots  SLAM (robots)  solid modelling  Gazebo world construction  grayscale image  3D solid model  robot simulators  simulated physical environment  2D image  2D laser range finder data  Gazebo simulator  3D Collada  simultaneous localization and mapping  real-time factor  SLAM missions  RTF  Tools  Solid modeling  Three-dimensional displays  Robot sensing systems  Gray-scale  Collision avoidance 
Abstract: Robot simulators provide an easy way for evaluation of new concepts and algorithms in a simulated physical environment reducing development time and cost. Therefore it is convenient to have a tool that quickly creates a 3D landscape from an arbitrary 2D image or 2D laser range finder data. This paper presents a new tool that automatically constructs such landscapes for Gazebo simulator. The tool converts a grayscale image into a 3D Collada format model, which could be directly imported into Gazebo. We run three different simultaneous localization and mapping (SLAM) algorithms within three varying complexity environments that were constructed with our tool. A real-time factor (RTF) was used as an efficiency benchmark. Successfully completed SLAM missions with acceptable RTF levels demonstrated the efficiency of the tool. The source code is available for free academic use.


Title: A ROS Gazebo plugin to simulate ARVA sensors
Key Words: aerospace communication  autonomous aerial vehicles  control engineering computing  operating systems (computers)  radio transceivers  rescue robots  robot programming  sensors  ROS Gazebo plugin  forefront technology  Search & Rescue operations  ARVA sensor simulation  transceiver sensor  Appareil de Recherche de Victims en Avalanche  Unmanned Aerial Vehicle  Receivers  Transmitters  Sensors  Electromagnetics  Antennas  Robots  Unmanned aerial vehicles 
Abstract: This paper addresses the problem to simulate ARVA sensors using ROS and Gazebo. ARVA is a French acronym which stands for Appareil de Recherche de Victims en Avalanche and represents the forefront technology adopted in Search & Rescue operations to localize victims of avalanches buried under the snow. The aim of this paper is to describe the mathematical and theoretical background of the transceiver, discussing its implementation and integration with ROS allowing researchers to develop faster and smarter Search &Rescue strategies based on ARVA receiver data. To assess the effectiveness of the proposed sensor model, We present a simulation scenario in which an Unmanned Aerial Vehicle equipped with the transceiver sensor performs a basic S&R pattern using the output of ARVA system.


Title: Is That a Chair? Imagining Affordances Using Simulations of an Articulated Human Body
Key Words: CAD  cameras  image classification  learning (artificial intelligence)  object recognition  pose estimation  articulated human body  object affordances  physical interactions  physical simulations  arbitrarily oriented object  physical sitting interaction  object affordance reasoning  object classification  chair classification  appearance-based deep learning methods  affordances imagining  synthetic 3D CAD models  training data  functional pose predictions  depth camera  Robots  Solid modeling  Cognition  Physics  Three-dimensional displays  Data models  Geometry 
Abstract: For robots to exhibit a high level of intelligence in the real world, they must be able to assess objects for which they have no prior knowledge. Therefore, it is crucial for robots to perceive object affordances by reasoning about physical interactions with the object. In this paper, we propose a novel method to provide robots with an ability to imagine object affordances using physical simulations. The class of chair is chosen here as an initial category of objects to illustrate a more general paradigm. In our method, the robot "imagines" the affordance of an arbitrarily oriented object as a chair by simulating a physical sitting interaction between an articulated human body and the object. This object affordance reasoning is used as a cue for object classification (chair vs non-chair). Moreover, if an object is classified as a chair, the affordance reasoning can also predict the upright pose of the object which allows the sitting interaction to take place. We call this type of poses the functional pose. We demonstrate our method in chair classification on synthetic 3D CAD models. Although our method uses only 30 models for training, it outperforms appearance-based deep learning methods, which require a large amount of training data, when the upright orientation is not assumed to be known a priori. In addition, we showcase that the functional pose predictions of our method align well with human judgments on both synthetic models and real objects scanned by a depth camera.


Title: Toward Sim-to-Real Directional Semantic Grasping
Key Words: control engineering computing  end effectors  grippers  image colour analysis  learning (artificial intelligence)  rendering (computer graphics)  robot vision  directional semantic grasping  deep reinforcement learning  double deep Q-network  robot simulator  rendering  monocular RGB images  wrist mounted camera  cartesian robot control  crossentropy method  domain randomization  end effector  Grippers  Grasping  Cameras  Training  Robot vision systems 
Abstract: We address the problem of directional semantic grasping, that is, grasping a specific object from a specific direction. We approach the problem using deep reinforcement learning via a double deep Q-network (DDQN) that learns to map downsampled RGB input images from a wrist-mounted camera to Q-values, which are then translated into Cartesian robot control commands via the cross-entropy method (CEM). The network is learned entirely on simulated data generated by a custom robot simulator that models both physical reality (contacts) and perceptual quality (high-quality rendering). The reality gap is bridged using domain randomization. The system is an example of end-to-end (mapping input monocular RGB images to output Cartesian motor commands) grasping of objects from multiple pre-defined object-centric orientations, such as from the side or top. We show promising results in both simulation and the real world, along with some challenges faced and the need for future research in this area.


Title: Inferring the Material Properties of Granular Media for Robotic Tasks
Key Words: Bayes methods  calibration  granular flow  granular materials  industrial robots  rolling friction  sliding friction  material properties  granular media  robotic tasks  cereal grains  plastic resin pellets  robotics-integrated industries  pharmaceutical development  accurate simulation  hardware framework  fast physics simulator  granular materials  real-world depth images  grain formations  likelihood-free Bayesian inference  calibrated simulator  unseen granular formations  simulator predictions  Robots  Friction  Numerical models  Bayes methods  Material properties  Task analysis 
Abstract: Granular media (e.g., cereal grains, plastic resin pellets, and pills) are ubiquitous in robotics-integrated industries, such as agriculture, manufacturing, and pharmaceutical development. This prevalence mandates the accurate and efficient simulation of these materials. This work presents a software and hardware framework that automatically calibrates a fast physics simulator to accurately simulate granular materials by inferring material properties from real-world depth images of granular formations (i.e., piles and rings). Specifically, coefficients of sliding friction, rolling friction, and restitution of grains are estimated from summary statistics of grain formations using likelihood-free Bayesian inference. The calibrated simulator accurately predicts unseen granular formations in both simulation and experiment; furthermore, simulator predictions are shown to generalize to more complex tasks, including using a robot to pour grains into a bowl, as well as to create a desired pattern of piles and rings.


Title: Uncertainty Quantification with Statistical Guarantees in End-to-End Autonomous Driving Control
Key Words: Bayes methods  belief networks  collision avoidance  decision making  inference mechanisms  neurocontrollers  probability  road safety  Bayesian inference methods  uncertainty computation  pointwise uncertainty measures  end-to-end Bayesian controllers  autonomous driving scenarios  Bayesian neural networks  sensor noise  controller behaviour  safety guarantees  neural network controllers  end-to-end autonomous driving control  statistical guarantees  uncertainty quantification  Uncertainty  Safety  Autonomous vehicles  Neural networks  Automobiles  Probabilistic logic 
Abstract: Deep neural network controllers for autonomous driving have recently benefited from significant performance improvements, and have begun deployment in the real world. Prior to their widespread adoption, safety guarantees are needed on the controller behaviour that properly take account of the uncertainty within the model as well as sensor noise. Bayesian neural networks, which assume a prior over the weights, have been shown capable of producing such uncertainty measures, but properties surrounding their safety have not yet been quantified for use in autonomous driving scenarios. In this paper, we develop a framework based on a state-of-the-art simulator for evaluating end-to-end Bayesian controllers. In addition to computing pointwise uncertainty measures that can be computed in real time and with statistical guarantees, we also provide a method for estimating the probability that, given a scenario, the controller keeps the car safe within a finite horizon. We experimentally evaluate the quality of uncertainty computation by three Bayesian inference methods in different scenarios and show how the uncertainty measures can be combined and calibrated for use in collision avoidance. Our results suggest that uncertainty estimates can greatly aid decision making in autonomous driving.


Title: Autonomously Navigating a Surgical Tool Inside the Eye by Learning from Demonstration
Key Words: end effectors  eye  learning by example  medical robotics  navigation  position control  robot programming  surgery  visual servoing  retinal surgery  auditory feedback  autonomous navigation system  needle surgical tool navigation  learning from demonstration  haptic feedback  deep network training  visual servoing  steady hand eye robot  SHER surgical robot  end effector  Tools  Retina  Surgery  Navigation  Task analysis  Trajectory  Robots 
Abstract: A fundamental challenge in retinal surgery is safely navigating a surgical tool to a desired goal position on the retinal surface while avoiding damage to surrounding tissues, a procedure that typically requires tens-of-microns accuracy. In practice, the surgeon relies on depth-estimation skills to localize the tool-tip with respect to the retina in order to perform the tool-navigation task, which can be prone to human error. To alleviate such uncertainty, prior work has introduced ways to assist the surgeon by estimating the tooltip distance to the retina and providing haptic or auditory feedback. However, automating the tool-navigation task itself remains unsolved and largely unexplored. Such a capability, if reliably automated, could serve as a building block to streamline complex procedures and reduce the chance for tissue damage. Towards this end, we propose to automate the tool-navigation task by learning to mimic expert demonstrations of the task. Specifically, a deep network is trained to imitate expert trajectories toward various locations on the retina based on recorded visual servoing to a given goal specified by the user. The proposed autonomous navigation system is evaluated in simulation and in physical experiments using a silicone eye phantom. We show that the network can reliably navigate a needle surgical tool to various desired locations within 137 m accuracy in physical experiments and 94 m in simulation on average, and generalizes well to unseen situations such as in the presence of auxiliary surgical tools, variable eye backgrounds, and brightness conditions.


Title: Learn-to-Recover: Retrofitting UAVs with Reinforcement Learning-Assisted Flight Control Under Cyber-Physical Attacks
Key Words: actuators  aerospace computing  autonomous aerial vehicles  control engineering computing  fault diagnosis  fault tolerant control  helicopters  learning (artificial intelligence)  position control  security of data  stability  fault-tolerant control policy  actuator  stabilizing controller  detection activation  sensor faults  position control  learn-to-recover  UAVs  reinforcement learning-assisted flight control  cyber-physical attacks  quadcopter unmanned aerial vehicles  sensor attack  Actuators  Fault tolerance  Fault tolerant systems  Vehicle dynamics  Learning (artificial intelligence)  Training  Solid modeling 
Abstract: In this paper, we present a generic fault-tolerant control (FTC) strategy via reinforcement learning (RL). We demonstrate the effectiveness of this method on quadcopter unmanned aerial vehicles (UAVs). The fault-tolerant control policy is trained to handle actuator and sensor fault/attack. Unlike traditional FTC, this policy does not require fault detection and diagnosis (FDD) nor tailoring the controller for specific attack scenarios. Instead, the policy is running simultaneously alongside the stabilizing controller without the need for on- detection activation. The effectiveness of the policy is compared with traditional active and passive FTC strategies against actuator and sensor faults. We compare their performance in position control tasks via simulation and experiments on quadcopters. The result shows that the strategy can effectively tolerate different types of attacks/faults and maintain the vehicle's position, outperforming the other two methods.


Title: Adaptive Control of Variable-Pitch Propellers: Pursuing Minimum-Effort Operation
Key Words: adaptive control  aerospace propulsion  aircraft control  autonomous aerial vehicles  control system synthesis  electric propulsion  pitch control (position)  propellers  state-space methods  adaptive control  minimum-effort operation  unmanned aerial vehicles  UAV  electric propulsion systems  disparate flight modes  forward-moving flight  flight mode dissimilarity  fixed-geometry propulsion systems  variable-geometry systems  variable pitch propeller  propulsion performance  VPP system control  operation state space  hovering  near-minimum-electrical-effort propulsion system behavior  Propellers  Mathematical model  Servomotors  Geometry  Brushless DC motors  Blades 
Abstract: As Unmanned Aerial Vehicles (UAVs) become more commonly used in industry, their performance will continue to be challenged. A performance bottleneck that is crucial to overcome is the design of electric propulsion systems for UAVs that operate in disparate flight modes (e.g., hovering and forward-moving flight). While flight mode dissimilarity presents a fundamental design challenge for fixed-geometry propulsion systems, variable-geometry systems such as the Variable Pitch Propeller (VPP) ones are able to provide superior propulsion performance across a wide range of flight modes. This work builds on previous work by the authors and presents a VPP system control and estimation framework for safe, near-minimum-electrical-effort propulsion system behavior across the whole operation state space of any UAV. Multiple simulated validations are presented to support the feasibility of the approach.


Title: On Simple Reactive Neural Networks for Behaviour-Based Reinforcement Learning
Key Words: grippers  learning (artificial intelligence)  neural net architecture  neurocontrollers  reactive neural networks  fully connected networks  reactive behaviours  actor-critic architecture  robot environment  end-to-end reinforcement learning  robotic learning  pick and place task  behaviour-based reinforcement learning  Brook subsumption architecture  pick and place robotic task  actor-critic policy  activation mechanisms  inhibition mechanisms  gripper  degree-of-freedom  Robots  Task analysis  Training  Computer architecture  Learning (artificial intelligence)  Grasping  Feature extraction 
Abstract: We present a behaviour-based reinforcement learning approach, inspired by Brook's subsumption architecture, in which simple fully connected networks are trained as reactive behaviours. Our working assumption is that a pick and place robotic task can be simplified by leveraging domain knowledge of a robotics developer to decompose and train reactive behaviours; namely, approach, grasp, and retract. Then the robot autonomously learns how to combine reactive behaviours via an Actor-Critic architecture. We use an Actor-Critic policy to determine the activation and inhibition mechanisms of the reactive behaviours in a particular temporal sequence. We validate our approach in a simulated robot environment where the task is about picking a block and taking it to a target position while orienting the gripper from a top grasp. The latter represents an extra degree-of-freedom of which current end-to-end reinforcement learning approaches fail to generalise. Our findings suggest that robotic learning can be more effective if each behaviour is learnt in isolation and then combined them to accomplish the task. That is, our approach learns the pick and place task in 8,000 episodes, which represents a drastic reduction in the number of training episodes required by an end-to-end approach ( 95,000 episodes) and existing state-of-the-art algorithms.


Title: Integrated moment-based LGMD and deep reinforcement learning for UAV obstacle avoidance
Key Words: autonomous aerial vehicles  collision avoidance  control engineering computing  image motion analysis  image sequences  learning (artificial intelligence)  mobile robots  neural nets  object detection  robot vision  SLAM (robots)  visual perception  deep reinforcement learning  UAV obstacle avoidance  learning-based reaction local planner  microUAVs  image moment  illuminance variation  mapless navigation  moment-based LGMD  bioinspired monocular vision perception method  Navigation  Collision avoidance  Robustness  Lighting  Robots  Optical imaging  Machine learning 
Abstract: In this paper, a bio-inspired monocular vision perception method combined with a learning-based reaction local planner for obstacle avoidance of micro UAVs is presented. The system is more computationally efficient than other vision-based perception and navigation methods such as SLAM and optical flow because it does not need to calculate accurate distances. To improve the robustness of perception against illuminance change, the input image is remapped using image moment which is independent of illuminance variation. After perception, a local planner is trained using deep reinforcement learning for mapless navigation. The proposed perception and navigation methods are evaluated in some realistic simulation environments. The result shows that this light-weight monocular perception and navigation system works well in different complex environments without accurate depth information.


Title: Interactive Reinforcement Learning with Inaccurate Feedback
Key Words: feedback  interactive systems  learning (artificial intelligence)  mobile robots  interactive reinforcement learning  human teachers  sensor feedback  learning process  noninteractive RL  policy feedback  feedback source  interactive RL methods  revision estimation-from-partially incorrect resources  REPaIR  physical robot  Maintenance engineering  Robot sensing systems  Estimation  Task analysis  Learning (artificial intelligence)  Computer science 
Abstract: Interactive Reinforcement Learning (RL) enables agents to learn from two sources: rewards taken from observations of the environment, and feedback or advice from a secondary critic source, such as human teachers or sensor feedback. The addition of information from a critic during the learning process allows the agents to learn more quickly than non-interactive RL. There are many methods that allow policy feedback or advice to be combined with RL. However, critics can often give imperfect information. In this work, we introduce a framework for characterizing Interactive RL methods with imperfect teachers and propose an algorithm, Revision Estimation from Partially Incorrect Resources (REPaIR), which can estimate corrections to imperfect feedback over time. We run experiments both in simulations and demonstrate performance on a physical robot, and find that when baseline algorithms do not have prior information on the exact quality of a feedback source, using REPaIR matches or improves the expected performance of these algorithms.


Title: Inferring the Geometric Nullspace of Robot Skills from Human Demonstrations
Key Words: geometry  humanoid robots  industrial robots  learning (artificial intelligence)  robot vision  geometric nullspace  robot skills  human demonstrations  fit geometric nullspaces  geometric constraints  powerful mathematical model  geometric skill description  skill model  learnt skill  simulated industrial robot  iCub humanoid robot  geometric constraint models  Task analysis  Manifolds  Adaptation models  Service robots  Grasping  Data models 
Abstract: In this paper we present a framework to learn skills from human demonstrations in the form of geometric nullspaces, which can be executed using a robot. We collect data of human demonstrations, fit geometric nullspaces to them, and also infer their corresponding geometric constraint models. These geometric constraints provide a powerful mathematical model as well as an intuitive representation of the skill in terms of the involved objects. To execute the skill using a robot, we combine this geometric skill description with the robot's kinematics and other environmental constraints, from which poses can be sampled for the robot's execution. The result of our framework is a system that takes the human demonstrations as input, learns the underlying skill model, and executes the learnt skill with different robots in different dynamic environments. We evaluate our approach on a simulated industrial robot, and execute the final task on the iCub humanoid robot.


Title: A Dynamical System Approach for Adaptive Grasping, Navigation and Co-Manipulation with Humanoid Robots
Key Words: compliance control  dexterous manipulators  humanoid robots  position control  dynamical system approach  adaptive grasping  humanoid robots  iCub humanoid robot  state-dependent dynamical systems  robots hands  intermediate virtual object  motion generators  object moves  whole-body compliant control strategy  manipulation tasks  body manipulation  iCub robots walk-to-grasp objects  Robot kinematics  Legged locomotion  Grasping  Task analysis  Humanoid robots  Planning 
Abstract: We present an integrated approach that provides compliant control of an iCub humanoid robot and adaptive reaching, grasping, navigating and co-manipulating capabilities. We use state-dependent dynamical systems (DS) to (i) coordinate and drive the robots hands (in both position and orientation) to grasp an object using an intermediate virtual object, and (ii) drive the robot's base while walking/navigating. The use of DS as motion generators allows us to adapt smoothly as the object moves and to re-plan on-line motion of the arms and body to reach the object's new location. The desired motion generated by the DS are used in combination with a whole-body compliant control strategy that absorbs perturbations while walking and offers compliant behaviors for grasping and manipulation tasks. Further, the desired dynamics for the arm and body can be learned from demonstrations. By integrating these components, we achieve unprecedented adaptive behaviors for whole body manipulation. We showcase this in simulations and real-world experiments where iCub robots (i) walk-to-grasp objects, (ii) follow a human (or another iCub) through interaction and (iii) learn to navigate or comanipulate an object from human guided demonstrations; whilst being robust to changing targets and perturbations.


Title: Multi-Agent Task Allocation using Cross-Entropy Temporal Logic Optimization
Key Words: discrete systems  entropy  graph theory  multi-agent systems  multi-robot systems  optimisation  search problems  stochastic programming  temporal logic  task specification  discrete transition systems  finite linear temporal logic specifications  stochastic optimization  graph based search  cross entropy temporal logic optimization  multiagent task allocation cross entropy algorithm  robot team  Task analysis  Automata  Cost function  Planning  Resource management  Switches 
Abstract: In this paper, we propose a graph-based search method to optimally allocate tasks to a team of robots given a global task specification. In particular, we define these agents as discrete transition systems. In order to allocate tasks to the team of robots, we decompose finite linear temporal logic (LTL) specifications and consider agent specific cost functions. We propose to use the stochastic optimization technique, cross entropy, to optimize over this cost function. The multi-agent task allocation cross-entropy (MTAC-E) algorithm is developed to determine both when it is optimal to switch to a new agent to complete a task and minimize the costs associated with individual agent trajectories. The proposed algorithm is verified in simulation and experimental results are included.


Title: Adaptive Task Allocation for Heterogeneous Multi-Robot Teams with Evolving and Unknown Robot Capabilities
Key Words: adaptive systems  multi-robot systems  adaptive task allocation  task execution  robot capabilities  heterogeneous multirobot teams  Task analysis  Resource management  Cost function  Mobile robots  Real-time systems  Minimization 
Abstract: For multi-robot teams with heterogeneous capabilities, typical task allocation methods assign tasks to robots based on the suitability of the robots to perform certain tasks as well as the requirements of the task itself. However, in real-world deployments of robot teams, the suitability of a robot might be unknown prior to deployment, or might vary due to changing environmental conditions. This paper presents an adaptive task allocation and task execution framework which allows individual robots to prioritize among tasks while explicitly taking into account their efficacy at performing the tasks-the parameters of which might be unknown before deployment and/or might vary over time. Such a specialization parameter-encoding the effectiveness of a given robot towards a task-is updated on-the-fly, allowing our algorithm to reassign tasks among robots with the aim of executing them. The developed framework requires no explicit model of the changing environment or of the unknown robot capabilities-it only takes into account the progress made by the robots at completing the tasks. Simulations and experiments demonstrate the efficacy of the proposed approach during variations in environmental conditions and when robot capabilities are unknown before deployment.


Title: Mobile Wireless Network Infrastructure on Demand
Key Words: mobile ad hoc networks  mobile robots  multi-agent systems  multi-robot systems  optimisation  telecommunication network routing  mobile relay nodes  network team  wireless connectivity  task agents  Mobile wireless network infrastructure  multirobot teams  previous multiagent systems  communication infrastructure  end-to-end communication requirements  task team  arbitrary objective  joint optimization framework  optimal network routes  Task analysis  Ad hoc networks  Routing  Wireless networks  Hardware  Probabilistic logic 
Abstract: In this work, we introduce Mobile Wireless Infrastructure on Demand: a framework for providing wireless connectivity to multi-robot teams via autonomously reconfiguring ad-hoc networks. In many cases, previous multi-agent systems either assumed the availability of existing communication infrastructure or were required to create a network in addition to completing their objective. Instead our system explicitly assumes the responsibility of creating and sustaining a wireless network capable of satisfying end-to-end communication requirements of a team of agents, called the task team, performing an arbitrary objective. To accomplish this goal, we propose a joint optimization framework that alternates between finding optimal network routes to support data flows between the task agents and improving the performance of the network by repositioning a collection of mobile relay nodes referred to as the network team. We demonstrate our approach with simulations and experiments wherein wireless connectivity is provided to patrolling task agents.


Title: Monitoring Over the Long Term: Intermittent Deployment and Sensing Strategies for Multi-Robot Teams
Key Words: combinatorial mathematics  Gaussian processes  greedy algorithms  matrix algebra  Monte Carlo methods  multi-robot systems  optimisation  multirobot team  intermittent deployment problem  heterogeneous robots  environmental process  spatiotemporal process  intermittent deployment strategy  spatiotemporal Gaussian process  Monte Carlo simulations  greedy algorithm  submodular optimization  matroids  Robot sensing systems  Monitoring  Mutual information  Spatiotemporal phenomena  Kernel 
Abstract: In this paper, we formulate and solve the intermittent deployment problem, which yields strategies that couple when heterogeneous robots should sense an environmental process, with where a deployed team should sense in the environment. As a motivation, suppose that a spatiotemporal process is slowly evolving and must be monitored by a multi-robot team, e.g., unmanned aerial vehicles monitoring pasturelands in a precision agriculture context. In such a case, an intermittent deployment strategy is necessary as persistent deployment or monitoring is not cost-efficient for a slowly evolving process. At the same time, the problem of where to sense once deployed must be solved as process observations yield useful feedback for determining effective future deployment and monitoring decisions. In this context, we model the environmental process to be monitored as a spatiotemporal Gaussian process with mutual information as a criterion to measure our understanding of the environment. To make the sensing resource-efficient, we demonstrate how to use matroid constraints to impose a diverse set of homogeneous and heterogeneous constraints. In addition, to reflect the cost-sensitive nature of real-world applications, we apply budgets on the cost of deployed heterogeneous robot teams. To solve the resulting problem, we exploit the theories of submodular optimization and matroids and present a greedy algorithm with bounds on sub-optimality. Finally, Monte Carlo simulations demonstrate the correctness of the proposed method.


Title: Multi-Robot Coordination for Estimation and Coverage of Unknown Spatial Fields
Key Words: Bayes methods  computational geometry  Gaussian processes  mobile robots  multi-robot systems  optimisation  sampling methods  multirobot coordination  unknown spatial fields  multirobot coverage  initially unknown spatial scalar field  Bayesian optimization  control law  centroidal Voronoi tessellation  adaptive sequential sampling method  surrogate function  density function  Gaussian processes  Density functional theory  Estimation  Gaussian processes  Robot sensing systems  Prediction algorithms  Bayes methods 
Abstract: We present an algorithm for multi-robot coverage of an initially unknown spatial scalar field characterized by a density function, whereby a team of robots simultaneously estimates and optimizes its coverage of the density function over the domain. The proposed algorithm borrows powerful concepts from Bayesian Optimization with Gaussian Processes that, when combined with control laws to achieve centroidal Voronoi tessellation, give rise to an adaptive sequential sampling method to explore and cover the domain. The crux of the approach is to apply a control law using a surrogate function of the true density function, which is then successively refined as robots gather more samples for estimation. The performance of the algorithm is justified theoretically under slightly idealized assumptions, by demonstrating asymptotic no-regret with respect to the coverage obtained with a known density function. The performance is also evaluated in simulation and on the Robotarium with small teams of robots, confirming the good performance suggested by the theoretical analysis.


Title: Learning Robotic Assembly Tasks with Lower Dimensional Systems by Leveraging Physical Softness and Environmental Constraints
Key Words: force control  force sensors  industrial manipulators  learning (artificial intelligence)  mobile robots  robotic assembly  torque control  high frequency force-torque sensors  physical softness  data-driven approaches  hard robots  learning robotic assembly tasks  peg-in-hole tasks  model-based reinforcement learning method  lower dimensional systems  environmental constraints  soft robot  high frequency force-torque controllers  Task analysis  Soft robotics  Aerospace electronics  Force  Robotic assembly  Learning (artificial intelligence) 
Abstract: In this study, we present a novel control framework for assembly tasks with a soft robot. Typically, existing hard robots require high frequency controllers and precise force/torque sensors for assembly tasks. The resulting robot system is complex, entailing large amounts of engineering and maintenance. Physical softness allows the robot to interact with the environment easily. We expect soft robots to perform assembly tasks without the need for high frequency force/torque controllers and sensors. However, specific data-driven approaches are needed to deal with complex models involving nonlinearity and hysteresis. If we were to apply these approaches directly, we would be required to collect very large amounts of training data. To solve this problem, we argue that by leveraging softness and environmental constraints, a robot can complete tasks in lower dimensional state and action spaces, which could greatly facilitate the exploration of appropriate assembly skills. Then, we apply a highly efficient model-based reinforcement learning method to lower dimensional systems. To verify our method, we perform a simulation for peg-in-hole tasks. The results show that our method learns the appropriate skills faster than an approach that does not consider lower dimensional systems. Moreover, we demonstrate that our method works on a real robot equipped with a compliant module on the wrist.


Title: Titan: A Parallel Asynchronous Library for Multi-Agent and Soft-Body Robotics using NVIDIA CUDA
Key Words: control engineering computing  graphics processing units  learning (artificial intelligence)  mobile robots  multi-agent systems  multi-robot systems  optimisation  parallel algorithms  parallel architectures  CUDA-based C++ robotics simulation library  multiagent robots  massively parallel integration scheme  reinforcement learning iterations  rapid topology optimization  simultaneous optimization  innovative GPU architecture design  robotics primitives  GPU-accelerated simulations  asynchronous computing model  GPU-accelerated interface  interacting bodies  multiagent robotics  intrinsically serial tasks  low-dimensional tasks  robotics simulation libraries  NVIDIA CUDA  soft-body robotics  parallel asynchronous library  Titan  Graphics processing units  Robots  Libraries  Springs  Computational modeling  Kernel  Acceleration 
Abstract: While most robotics simulation libraries are built for low-dimensional and intrinsically serial tasks, soft-body and multi-agent robotics have created a demand for simulation environments that can model many interacting bodies in parallel. Despite the increasing interest in these fields, no existing simulation library addresses the challenge of providing a unified, highly-parallelized, GPU-accelerated interface for simulating large robotic systems. Titan is a versatile CUDA-based C++ robotics simulation library that employs a novel asynchronous computing model for GPU-accelerated simulations of robotics primitives. The innovative GPU architecture design permits simultaneous optimization and control on the CPU while the GPU runs asynchronously, enabling rapid topology optimization and reinforcement learning iterations. Kinematics are solved with a massively parallel integration scheme that incorporates constraints and environmental forces. We report dramatically improved performance over CPU baselines, simulating as many as 300 million primitive updates per second, while allowing flexibility for a wide range of research applications. We present several applications of Titan to high-performance simulations of soft-body and multi-agent robots.


Title: Motion Planning with Competency-Aware Transition Models for Underactuated Adaptive Hands
Key Words: dexterous manipulators  optimal control  path planning  competency-aware transition models  underactuated adaptive hands  in-hand manipulation  data-driven models  asymptotically optimal motion planner  motion planning  grasping tasks  dexterity  Data models  Planning  Predictive models  Adaptation models  Trajectory  Training  Uncertainty 
Abstract: Underactuated adaptive hands simplify grasping tasks but it is difficult to model their interactions with objects during in-hand manipulation. Learned data-driven models have been recently shown to be efficient in motion planning and control of such hands. Still, the accuracy of the models is limited even with the addition of more data. This becomes important for long horizon predictions, where errors are accumulated along the length of a path. Instead of throwing more data into learning the transition model, this work proposes to rather invest a portion of the training data in a critic model. The critic is trained to estimate the error of the transition model given a state and a sequence of future actions, along with information of past actions. The critic is used to reformulate the cost function of an asymptotically optimal motion planner. Given the critic, the planner directs planned paths to less erroneous regions in the state space. The approach is evaluated against standard motion planning on simulated and real hands. The results show that it outperforms an alternative where all the available data is used for training the transition model without a critic.


Title: Human-like Planning for Reaching in Cluttered Environments
Key Words: collision avoidance  decision making  dexterous manipulators  grippers  learning (artificial intelligence)  planning (artificial intelligence)  robot programming  robot vision  trajectory control  virtual reality  decision making  decision classifiers  cluttered environments  robot planners  random sampling  object manipulation plans  virtual reality  trajectory optimisation  physics based robot simulation  human-like planning  depth camera  Robotiq two finger gripper  Task analysis  Planning  Robots  Testing  Feature extraction  Trajectory  Standards 
Abstract: Humans, in comparison to robots, are remarkably adept at reaching for objects in cluttered environments. The best existing robot planners are based on random sampling of configuration space- which becomes excessively high-dimensional with large number of objects. Consequently, most planners often fail to efficiently find object manipulation plans in such environments. We addressed this problem by identifying high-level manipulation plans in humans, and transferring these skills to robot planners. We used virtual reality to capture human participants reaching for a target object on a tabletop cluttered with obstacles. From this, we devised a qualitative representation of the task space to abstract the decision making, irrespective of the number of obstacles. Based on this representation, human demonstrations were segmented and used to train decision classifiers. Using these classifiers, our planner produced a list of waypoints in task space. These waypoints provided a high-level plan, which could be transferred to an arbitrary robot model and used to initialise a local trajectory optimiser. We evaluated this approach through testing on unseen human VR data, a physics-based robot simulation, and a real robot (dataset and code are publicly available1). We found that the human-like planner outperformed a state-of-the-art standard trajectory optimisation algorithm, and was able to generate effective strategies for rapid planning- irrespective of the number of obstacles in the environment.


Title: Autonomous Modification of Unstructured Environments with Found Material
Key Words: building materials  dexterous manipulators  friction  grippers  industrial manipulators  materials handling equipment  mechanical contact  path planning  sensors  unseen objects  adaptive ramp building algorithms  irregularly shaped stones  contact geometry  friction  high-level algorithm  physics-based planner  pickup  robotic system  complex grasp planning  autonomous modification  manipulation  found material  pickup  motion support structures  specialized construction algorithm  unstructured environments  Uncertainty  Robot sensing systems  Physics  Shape  Buildings  physics simulation  autonomous construction  robotics  irregular building materials. 
Abstract: The ability to autonomously modify their environment dramatically increases the capability of robots to operate in unstructured environments. We develop a specialized construction algorithm and robotic system that can autonomously build motion support structures with previously unseen objects. The approach is based on our prior work on adaptive ramp building algorithms, but it eliminates the assumption of having specialized building materials that simplify manipulation and planning for stability. Utilizing irregularly shaped stones makes the problem significantly more challenging since the outcome of individual placements is sensitive to details of contact geometry and friction, which are difficult to observe. To reuse the same high-level algorithm, we develop a new physics-based planner that explicitly considers the uncertainty produced by incomplete in-situ sensing and imprecision during pickup and placement. We demonstrate the approach on a robotic system that uses a newly developed gripper to reliably pick up stones with minimal additional sensors or complex grasp planning. The resulting system can build structures with more than 70 stones, which in turn provide traversable paths to previously inaccessible locations.


Title: Long-Horizon Prediction and Uncertainty Propagation with Residual Point Contact Learners
Key Words: computer simulation  learning (artificial intelligence)  mobile robots  self-supervised approach  rigid-body simulators  contact models  predictive performance  horizon prediction  uncertainty propagation  residual point contact learners  robotic tasks  Predictive models  Analytical models  Uncertainty  Computational modeling  Trajectory  Dynamics  Stochastic processes 
Abstract: The ability to simulate and predict the outcome of contacts is paramount to the successful execution of many robotic tasks. Simulators are powerful tools for the design of robots and their behaviors, yet the discrepancy between their predictions and observed data limit their usability. In this paper, we propose a self-supervised approach to learning residual models for rigid-body simulators that exploits corrections of contact models to refine predictive performance and propagate uncertainty. We empirically evaluate the framework by predicting the outcomes of planar dice rolls and compare it's performance to state-of-the-art techniques.


Title: A Real-Robot Dataset for Assessing Transferability of Learned Dynamics Models
Key Words: learning (artificial intelligence)  learning systems  optimal control  robot dynamics  robust control  trajectory control  learned dynamics models  model based reinforcement learning  robust current dynamics learning  real robot dataset  transferability assessment  3 degrees of freedom robot trajectories  optimal control  robotic learning  Trajectory  Robots  Artificial neural networks  Heuristic algorithms  Mathematical model  Torque measurement 
Abstract: In the context of model-based reinforcement learning and control, a large number of methods for learning system dynamics have been proposed in recent years. The purpose of these learned models is to synthesize new control policies. An important open question is how robust current dynamics-learning methods are to shifts in the data distribution due to changes in the control policy. We present a real-robot dataset which allows to systematically investigate this question. This dataset contains trajectories of a 3 degrees-of-freedom (DOF) robot being controlled by a diverse set of policies. For comparison, we also provide a simulated version of the dataset. Finally, we benchmark a few widely-used dynamics-learning methods using the proposed dataset. Our results show that the iid test error of a learned model is not necessarily a good indicator of its accuracy under control policies different from the one which generated the training data. This suggests that it may be important to evaluate dynamics-learning methods in terms of their transfer performance, rather than only their iid error.


Title: An Actuation Fault Tolerance Approach to Reconfiguration Planning of Modular Self-folding Robots
Key Words: actuators  fault tolerance  motion control  robots  fault tolerant reconfiguration  self-folding robots  modular system  complete actuation failure  active modules  imprecise robotic motion  reconfiguration failure  intra-module connection  reconfiguration schemes  user-specified fault tolerant capability  arbitrary input initial pattern  robotic platform  modular origami robot  fault tolerant initial patterns  actuation fault tolerance approach  reconfiguration planning  modular self-folding  Fault tolerance  Fault tolerant systems  Robots  Three-dimensional displays  Circuit faults  Shape  Planning 
Abstract: This paper presents a novel approach to fault tolerant reconfiguration of modular self-folding robots. Among various types of faults that probably occur in the modular system, we focus on the tolerance of complete actuation failure of active modules that might cause imprecise robotic motion and even reconfiguration failure. Our approach is to utilize the reconfigurability of modular self-folding robots and investigate intra-module connection to determine initial patterns that are inherently fault tolerant. We exploit the redundancy of actuation and distribute active modules in both layout-based and target-based scenarios, such that reconfiguration schemes with user-specified fault tolerant capability can be generated for an arbitrary input initial pattern or 3D configuration. Our methods are demonstrated in computer-aided simulation on the robotic platform of Mori, a modular origami robot. The simulation results validate that the proposed algorithms yield fault tolerant initial patterns and distribution schemes of active modules for several 2D and 3D configurations with Mori, while retaining generalizability for a large number of modular self-folding robots.


Title: Parallel Permutation for Linear Full-resolution Reconfiguration of Heterogeneous Sliding-only Cubic Modular Robots
Key Words: computational complexity  evolutionary computation  motion control  robots  studied cubic modules  convex motion primitives  rotating motion primitives  heterogeneous reconfiguration algorithm  parallel heterogeneous permutation method  full-resolution reconfiguration algorithm  heterogeneous operations  space saving  module hardware  sliding-only motion primitive  cubic modular robot  cubic module  sliding-only cubic modular robots  parallel permutation algorithm  heterogeneous sliding-only cubic modular  linear full-resolution reconfiguration  linear operating-time cost  sliding-only cubic modules  robot structure  linear operating time cost  Navigation  Hardware  Robot kinematics  Shape  Cameras  Robot vision systems 
Abstract: This paper presents a parallel permutation algorithm that achieves linear full-resolution reconfiguration of sliding-only cubic modular robots. We assume the use of a cubic module that can only slide across other modules' surfaces. The idea of a cubic modular robot with sliding-only motion primitive is a new concept that has advantages in simplifying the mechanisms of module hardware and space saving in its heterogeneous operations compared with previously studied cubic modules, such as those with sliding and convex motion primitives, or rotating motion primitives. However, because of its limited mobility, there are difficulties in managing the connectivity and scalability of the heterogeneous reconfiguration algorithm for it. To overcome these disadvantages, we introduce a parallel heterogeneous permutation method with linear operating time cost that can be incorporated into our previous full-resolution reconfiguration algorithm. We prove the correctness and completeness of the proposed algorithm. Simulation results show that the full-resolution reconfiguration algorithm that incorporates the proposed permutation algorithm reconfigures the robot structure with sliding-only cubic modules in linear operating-time cost.


Title: Quantifying Good Seamanship For Autonomous Surface Vessel Performance Evaluation
Key Words: collision avoidance  decision making  marine safety  marine vehicles  mobile robots  remotely operated vehicles  ships  performance metrics  ASV decision-making  collision risk  ASV planning strategies  International Regulations for Prevention of Collisions at Sea  quantified good seamanship  COLREGS compliance  vessel interactions  autonomous surface vehicle decision-making  autonomous surface vessel performance evaluation  seamanship performance criteria  Marine vehicles  Safety  Geometry  Decision making  Navigation  Risk management  Planning 
Abstract: The current state-of-the-art for testing and evaluation of autonomous surface vehicle (ASV) decision-making is currently limited to one-versus-one vessel interactions by determining compliance with the International Regulations for Prevention of Collisions at Sea, referred to as COLREGS. Strict measurement of COLREGS compliance, however, loses value in multi-vessel encounters, as there can be conflicting rules which make determining compliance extremely subjective. This work proposes several performance metrics to evaluate ASV decision-making based on the concept of "good seamanship," a practice which generalizes to multi-vessel encounters. Methodology for quantifying good seamanship is presented based on the criteria of reducing the overall collision risk of the situation and taking early, appropriate actions. Case study simulation results are presented to showcase the seamanship performance criteria against different ASV planning strategies.


Title: LyRN (Lyapunov Reaching Network): A Real-Time Closed Loop approach from Monocular Vision
Key Words: cameras  closed loop systems  convolutional neural nets  image colour analysis  learning (artificial intelligence)  Lyapunov methods  manipulator dynamics  neurocontrollers  pose estimation  robot vision  velocity control  visual servoing  GTX 1080Ti GPU  grasping mugs  multiinstance control  real-time closed loop  LyRN  single shot RGB 6D pose estimation  complex multiinstance task  reaching action  control Lyapunov function  learning principles  visually guided reaching  Lyapunov reaching network  pose-based-visual-servo grasping system  closed-loop control  over-the-shoulder monocular RGB camera  multiinstance capability  visual control  velocity control  deep convolution neural network  manipulator joint angles  monocular vision  reaching points  frequency 85.0 Hz  Lyapunov methods  Grasping  Feature extraction  Computer architecture  Task analysis  Pose estimation  Velocity control 
Abstract: We propose a closed-loop, multi-instance control algorithm for visually guided reaching based on novel learning principles. A control Lyapunov function methodology is used to design a reaching action for a complex multi-instance task in the case where full state information (poses of all potential reaching points) is available. The proposed algorithm uses monocular vision and manipulator joint angles as the input to a deep convolution neural network to predict the value of the control Lyapunov function (cLf) and corresponding velocity control. The resulting network output is used in real-time as visual control for the grasping task with the multi-instance capability emerging naturally from the design of the control Lyapunov function. We demonstrate the proposed algorithm grasping mugs (textureless and symmetric objects) on a table-top from an over-the-shoulder monocular RGB camera. The manipulator dynamically converges to the best-suited target among multiple identical instances from any random initial pose within the workspace. The system trained with only simulated data is able to achieve 90.3% grasp success rate in the real-world experiments with up to 85Hz closed-loop control on one GTX 1080Ti GPU and significantly outperforms a Pose-Based-Visual-Servo (PBVS) grasping system adapted from a state-of-the-art single shot RGB 6D pose estimation algorithm. A key contribution of the paper is the inclusion of a first-order differential constraint associated with the cLf as a regularisation term during learning, and we provide evidence that this leads to more robust and reliable reaching/grasping performance than vanilla regression on general control inputs.


Title: Object Finding in Cluttered Scenes Using Interactive Perception
Key Words: cameras  image colour analysis  learning (artificial intelligence)  manipulators  object recognition  robot vision  search problems  object finding  cases physical interaction  target object  complex environment  object search  cluttered scenes interactions  reinforcement learning based active perception system  reinforcement learning based interactive perception system  robotic manipulator  RGB  depth camera  Cameras  Task analysis  Robot sensing systems  Search problems  Clutter  Detectors 
Abstract: Object finding in clutter is a skill that requires perception of the environment and in many cases physical interaction. In robotics, interactive perception defines a set of algorithms that leverage actions to improve the perception of the environment, and vice versa use perception to guide the next action. Scene interactions are difficult to model, therefore, most of the current systems use predefined heuristics. This limits their ability to efficiently search for the target object in a complex environment. In order to remove heuristics and the need for explicit models of the interactions, in this work we propose a reinforcement learning based active and interactive perception system for scene exploration and object search. We evaluate our work both in simulated and in real-world experiments using a robotic manipulator equipped with an RGB and a depth camera, and compare our system to two baselines. The results indicate that our approach, trained in simulation only, transfers smoothly to reality and can solve the object finding task efficiently and with more than 88% success rate.


Title: CCAN: Constraint Co-Attention Network for Instance Grasping
Key Words: dexterous manipulators  feature extraction  grippers  learning (artificial intelligence)  robot vision  query image  soft constraints  workspace image  grasp configuration  CCAN  instance grasping  learning-based method  constraint co-attention module  constraint co-attention network  robotic grasping task  end-to-end instance grasping method  grasp affordance predictor  Feature extraction  Grasping  Training  Task analysis  Robots  Data mining  Correlation 
Abstract: Instance grasping is a challenging robotic grasping task when a robot aims to grasp a specified target object in cluttered scenes. In this paper, we propose a novel end-to-end instance grasping method using only monocular workspace and query images, where the workspace image includes several objects and the query image only contains the target object. To effectively extract discriminative features and facilitate the training process, a learning-based method, referred to as Constraint Co-Attention Network (CCAN), is proposed which consists of a constraint co-attention module and a grasp affordance predictor. An effective co-attention module is presented to construct the features of a workspace image from the extracted features of the query image. By introducing soft constraints into the co-attention module, it highlights the target object's features while trivializes other objects' features in the workspace image. Using the features extracted from the co-attention module, the cascaded grasp affordance interpreter network only predicts the grasp configuration for the target object. The training of the CCAN is totally based on simulated self-supervision. Extensive qualitative and quantitative experiments show the effectiveness of our method both in simulated and real-world environments even for totally unseen objects.


Title: The Relative Confusion Matrix, a Tool to Assess Classifiablility in Large Scale Picking Applications
Key Words: image classification  industrial robots  logistics  materials handling equipment  robot vision  warehousing  relative confusion matrix  mixed-product bin  robot workstation  manual picking station  bin picking robot  logistics installations  warehouse  image dataset  Robots  Measurement  Task analysis  Reliability  Tools  Logistics  Workstations 
Abstract: For bin picking robots in real logistics installations, the certainty of picking the correct product out of a mixed-product bin is essential. This paper proposes an approach for the robot to efficiently decide whether it can robustly distinguish the product to pick from the others in the bin. If not, the pick has to be routed not to the robot workstation but to a manual picking station. For this, we introduce a modified version of the confusion matrix, which we call the relative confusion matrix. We show how this matrix can be used to make the required decision, taking into account that all other products in the warehouse can be logically ruled out as they are not contained in the bin. Considering only this subset of products would require a re-computation of the standard confusion matrix. With the relative confusion matrix, no such re-computation is needed, which makes our approach more efficient. We show the usefulness of our approach in extensive experiments with a real bin picking robot, on simulated data, and on a publicly available image dataset.


Title: A Feature-Based Underwater Path Planning Approach using Multiple Perspective Prior Maps
Key Words: autonomous underwater vehicles  bathymetry  maximum likelihood estimation  mobile robots  navigation  path planning  remotely operated vehicles  multiple perspective prior maps  path planning methodology  Autonomous Underwater Vehicles  AUV  shallow complex environments  coral reefs  aerial photographic survey  bathymetric information  prior map  navigation graph  test points  shortest paths  destination points  maximum likelihood function  misclassified objects  photo-realistic simulated environment  Navigation  Cameras  Sensors  Uncertainty  Image segmentation  Feature extraction  Robots 
Abstract: This paper presents a path planning methodology which enables Autonomous Underwater Vehicles (AUVs) to navigate in shallow complex environments such as coral reefs. The approach leverages prior information from an aerial photographic survey, and derived bathymetric information of the corresponding area. From these prior maps, a set of features is obtained which define an expected arrangement of objects and bathymetry likely to be perceived by the AUV when underwater. A navigation graph is then constructed by predicting the arrangement of features visible from a set of test points within the prior, which allows the calculation of the shortest paths from any pair of start and destination points. A maximum likelihood function is defined which allows the AUV to match its observations to the navigation graph as it undertakes its mission. To improve robustness, the history of observed features are retained to facilitate possible recovery from non-detectable or misclassified objects. The approach is evaluated using a photo-realistic simulated environment, and results illustrate the merits of the approach even when only a relatively small number of features can be identified from the prior map.


Title: Actively Mapping Industrial Structures with Information Gain-Based Planning on a Quadruped Robot
Key Words: collision avoidance  image representation  legged locomotion  robot vision  industrial structure  mapping industrial structures  information gain-based planning  quadruped robot  online active mapping system  voxel representation  NBV  expected information gain  terrain map  ANYbotics ANYmal robot  Robot sensing systems  Service robots  Solid modeling  Planning  Laser radar 
Abstract: In this paper, we develop an online active mapping system to enable a quadruped robot to autonomously survey large physical structures. We describe the perception, planning and control modules needed to scan and reconstruct an object of interest, without requiring a prior model. The system builds a voxel representation of the object, and iteratively determines the Next-Best-View (NBV) to extend the representation, according to both the reconstruction itself and to avoid collisions with the environment. By computing the expected information gain of a set of candidate scan locations sampled on the as-sensed terrain map, as well as the cost of reaching these candidates, the robot decides the NBV for further exploration. The robot plans an optimal path towards the NBV, avoiding obstacles and un-traversable terrain. Experimental results on both simulated and real-world environments show the capability and efficiency of our system. Finally we present a full system demonstration on the real robot, the ANYbotics ANYmal, autonomously reconstructing a building facade and an industrial structure.


Title: A Parametric Grasping Methodology for Multi-Manual Interactions in Real-Time Dynamic Simulations
Key Words: biomechanics  control engineering computing  data visualisation  kinematics  manipulators  medical robotics  rendering (computer graphics)  surgery  telerobotics  parametric grasping methodology  multimanual interactions  interactive simulators  training simulators  teleoperated robotic laparoscopic surgery  stateof-art simulators  realistic visuals  accurate dynamics  kinematic simplification techniques  truly multimanual manipulation  actual task  realistic grasping  rigid-body dynamics  collision computation techniques  state-of-the-art physics libraries  parametric approach  multimanual grasping  real-time dynamic simulation  accomplishing multimanual tasks  screwdriver task  Friction  Grasping  Force  Sensors  Computational modeling  Mathematical model  Robots 
Abstract: Interactive simulators are used in several important applications which include the training simulators for teleoperated robotic laparoscopic surgery. While stateof-art simulators are capable of rendering realistic visuals and accurate dynamics, grasping is often implemented using kinematic simplification techniques that prevent truly multimanual manipulation, which is often an important requirement of the actual task. Realistic grasping and manipulation in simulation is a challenging problem due to the constraints imposed by the implementation of rigid-body dynamics and collision computation techniques in state-of-the-art physics libraries. We present a penalty based parametric approach to achieve multi-manual grasping and manipulation of complex objects at arbitrary postures in a real-time dynamic simulation. This approach is demonstrated by accomplishing multi-manual tasks modeled after realistic scenarios, which include the grasping and manipulation of a two-handed screwdriver task and the manipulation of a deformable thread.


Title: A methodology for the incorporation of arbitrarily-shaped feet in passive bipedal walking dynamics
Key Words: computational geometry  legged locomotion  motion control  pose estimation  public domain software  robot dynamics  stability  ankle trajectory  robot dynamics  shape dependent foot kinetics  OpenPose  open source pose estimation system  rigid foot passive robot  walking robot stability  foot shape optimization  exact foot geometry  dynamic model  biped robot  passive bipedal walking dynamics  Foot  Legged locomotion  Shape  Geometry  Mathematical model  Dynamics 
Abstract: A methodology for implementing arbitrary foot shapes in the passive walking dynamics of biped robots is developed. The dynamic model of a walking robot is defined in a way that allows shape-dependent foot kinetics to contribute to the robot's dynamics, for all convex foot shapes regardless of the exact foot geometry: for the developed method, only the set of points describing the foot profile curve is needed. The method is mathematically derived and then showcased with an application. The open-source pose estimation system OpenPose is used to determine the foot profile that enables the rigid-foot passive robot to reproduce the ankle trajectory of the actively powered, multi-DOF human foot complex. The passive gait of the biped robot walking on the specified foot shape is simulated and analyzed, and a stable walking cycle is found and evaluated. The proposed model enables the study of the effects of foot shape on the walking dynamics of biped robots, eliminating the necessity of solely using simple, and analytically defined geometric shapes as the walking robots' feet. The method can be used for foot shape optimization towards achieving any desired walking pattern in walking robots.


Title: Dynamic Coupling as an Indicator of Gait Robustness for Underactuated Biped Robots
Key Words: legged locomotion  robot dynamics  robust control  trajectory control  dynamic coupling  gait robustness  velocity decomposition  underactuated mechanical systems  two link biped model  underactuated biped robots  trajectory optimization  Couplings  Mathematical model  Legged locomotion  Aerodynamics  Robustness 
Abstract: This paper employs velocity decomposition of underactuated mechanical systems to determine the degree of dynamic coupling in the gaits of a two-link biped model. The degree of coupling between controlled and uncontrolled directions quantifies the control authority the system has over its unactuated degree of freedom. This paper shows that the amount of coupling is directly correlated to gait robustness, as seen through the size of the gait's region of attraction. The analytical measure of coupling is applied in the context of trajectory optimization to generate two-link gaits that maximize or minimize coupling. Simulation studies show that gaits maximizing coupling exhibit significantly superior robustness, as measured by 1) stochastic performance on uneven terrain, 2) ability to maintain desired walking speed under non-vanishing disturbances, 3) size of the region of attraction, and 4) robustness to model uncertainties.


Title: ZMP Constraint Restriction for Robust Gait Generation in Humanoids
Key Words: humanoid robots  legged locomotion  motion control  predictive control  robot dynamics  robust control  stability  range amplitude  internal stability  IS-MPC method  constraint modification  ZMP constraint restriction  robust gait generation  humanoids  humanoid gait generation  robust performance  considered disturbance signals  mid-range value  sampling time  stability constraint  current mid-range disturbance  appropriate restriction  control horizon  Humanoid robots  Lips  Robustness  Stability criteria  Dynamics 
Abstract: We present an extension of our previously proposed IS-MPC method for humanoid gait generation aimed at obtaining robust performance in the presence of disturbances. The considered disturbance signals vary in a range of known amplitude around a mid-range value that can change at each sampling time, but whose current value is assumed to be available. The method consists in modifying the stability constraint that is at the core of IS-MPC by incorporating the current mid-range disturbance, and performing an appropriate restriction of the ZMP constraint in the control horizon on the basis of the range amplitude of the disturbance. We derive explicit conditions for recursive feasibility and internal stability of the IS-MPC method with constraint modification. Finally, we illustrate its superior performance with respect to the nominal version by performing dynamic simulations on the NAO robot.


Title: Online Planning for Quadrotor Teams in 3-D Workspaces via Reachability Analysis On Invariant Geometric Trees
Key Words: aerospace control  helicopters  multi-robot systems  path planning  position control  reachability analysis  robot dynamics  trees (mathematics)  collision-free geometric solution guarantees  online planning  aerial robots  quadrotor teams  cluttered 3D workspaces  reachability analysis  kinodynamic multirobot planning problem  position invariant geometric trees  kinodynamically feasible trajectories  multirobot team  nonstationary initial states  Collision avoidance  Planning  Robot kinematics  Vegetation  Trajectory  Reachability analysis 
Abstract: We consider the kinodynamic multi-robot planning problem in cluttered 3-D workspaces. Reachability analysis on position invariant geometric trees is leveraged to find kino- dynamically feasible trajectories for the multi-robot team from potentially non-stationary initial states. The key contribution of our approach is that a collision-free geometric solution guarantees a kinodynamically feasible, safe solution without additional refinement. Simulation results with up-to 40 robots and hardware results with 5 robots suggest the viability of the proposed approach for online planning and replanning for large teams of aerial robots in cluttered 3-D workspaces.


Title: DC-CAPT: Concurrent Assignment and Planning of Trajectories for Dubins Cars
Key Words: collision avoidance  mobile robots  path planning  robot kinematics  trajectory control  Dubins curves  holonomic robots  separation distance  trajectory planning  collision-free trajectories  Dubins cars  concurrent assignment  DC-CAPT  Automobiles  Collision avoidance  Robots  Trajectory  Planning  Turning  Kinematics 
Abstract: We present an algorithm for the concurrent assignment and planning of collision-free trajectories (DC-CAPT) for robots whose kinematics can be modeled as Dubins cars, i.e., robots constrained in terms of their initial orientation and their minimum turning radius. Coupling the assignment and trajectory planning subproblems allows for a computationally tractable solution. This solution is guaranteed to be collision- free through the use of a single constraint: the start and goal locations have separation distance greater than some threshold. We derive this separation distance by extending a prior work that assumed holonomic robots. We demonstrate the validity of our approach, and show its efficacy through simulations and experiments where groups of robots executing Dubins curves travel to their assigned goal locations without collisions.


Title: Anti-Jackknifing Control of Tractor-Trailer Vehicles via Intrinsically Stable MPC
Key Words: feedback  linearisation techniques  optimal control  predictive control  road vehicles  stability  trajectory control  corrective term  tracking term  input-output linearization  nonminimum-phase systems  IS-MPC  antijackknifing control  feedback control law  reference Cartesian trajectory  trailer hitch angle  tractor-trailer vehicles  intrinsically stable MPC scheme  Trajectory  Agricultural machinery  Computational modeling  Vehicle dynamics  Tracking  Dynamics  Linear approximation 
Abstract: It is common knowledge that tractor-trailer vehicles are affected by jackknifing, a phenomenon that consists in the divergence of the trailer hitch angle and ultimately causes the vehicle to fold up. For the case of backwards motion, in which jackknifing can also occur at low speeds, we present a control method that drives the vehicle along a reference Cartesian trajectory while avoiding the divergence of the hitch angle. In particular, a feedback control law is obtained by combining two actions: a tracking term, computed using input-output linearization, and a corrective term, generated via IS-MPC, an intrinsically stable MPC scheme which is effective for stable inversion of nonminimum-phase systems. The proposed method has been verified in simulation and experimentally validated on a purposely built prototype.


Title: Control of a differentially driven nonholonomic robot subject to a restricted wheels rotation
Key Words: controllability  feedback  geometry  position control  robot kinematics  motion task scenarios  virtual geometry constraint  transverse function  four-dimensional configuration manifold  small time local controllability  two-wheeled nonholonomic robot  nonstandard motion tasks  restricted wheels rotation  Wheels  Mobile robots  Kinematics  Task analysis  Manifolds  Trajectory 
Abstract: The paper deals with non-standard motion tasks specified for a two-wheeled nonholonomic robot. It is assumed that wheels cannot fully rotate which reduces a set of feasible movements significantly. In spite of these constraints, it is expected that position of the robot can be changed without violating nonholonomic constraints. Such a possibility comes from the small time local controllability (STLC) of the kinematics described on four-dimensional configuration manifold. In order to solve these specific tasks a feedback taking advantage of the transverse function approach is designed. Consequently, the system can be virtually released from non-holonomic constraints. The transverse function also defines a virtual geometry constraint which makes it possible to limit wheels rotation.Properties of the designed controller are illustrated by results of numerical simulations in various motion task scenarios.


Title: Learning Hierarchical Control for Robust In-Hand Manipulation
Key Words: computational complexity  learning (artificial intelligence)  manipulators  hierarchical control  robotic in-hand manipulation  finger motion  complex manipulation sequences  low-level controllers  model-free deep reinforcement learning  hierarchical method  traditional model-based controllers  manipulation primitives  elongated objects  object models  Robustness  Task analysis  Force  Robot kinematics  Torque  Robot sensing systems 
Abstract: Robotic in-hand manipulation has been a longstanding challenge due to the complexity of modelling hand and object in contact and of coordinating finger motion for complex manipulation sequences. To address these challenges, the majority of prior work has either focused on model-based, low-level controllers or on model-free deep reinforcement learning that each have their own limitations. We propose a hierarchical method that relies on traditional, model-based controllers on the low-level and learned policies on the mid-level. The low-level controllers can robustly execute different manipulation primitives (reposing, sliding, flipping). The mid-level policy orchestrates these primitives. We extensively evaluate our approach in simulation with a 3-fingered hand that controls three degrees of freedom of elongated objects. We show that our approach can move objects between almost all the possible poses in the workspace while keeping them firmly grasped. We also show that our approach is robust to inaccuracies in the object models and to observation noise. Finally, we show how our approach generalizes to objects of other shapes.


Title: Monocular Direct Sparse Localization in a Prior 3D Surfel Map
Key Words: cameras  geophysical image processing  object tracking  optimisation  photometry  pose estimation  rendering (computer graphics)  solid modelling  monocular direct sparse localization  prior 3d surfel map  monocular camera  prior surfel map  vertex  normal maps  global planar information  sparse tracked points  image frame  direct photometric errors  camera localization  pose tracking  rendering  optimization  global 6-DoF camera poses  Cameras  Laser radar  Three-dimensional displays  Visualization  Rendering (computer graphics)  Simultaneous localization and mapping 
Abstract: In this paper, we introduce an approach to tracking the pose of a monocular camera in a prior surfel map. By rendering vertex and normal maps from the prior surfel map, the global planar information for the sparse tracked points in the image frame is obtained. The tracked points with and without the global planar information involve both global and local constraints of frames to the system. Our approach formulates all constraints in the form of direct photometric errors within a local window of the frames. The final optimization utilizes these constraints to provide the accurate estimation of global 6-DoF camera poses with the absolute scale. The extensive simulation and real-world experiments demonstrate that our monocular method can provide accurate camera localization results under various conditions.


Title: DFVS: Deep Flow Guided Scene Agnostic Image Based Visual Servoing
Key Words: cameras  feature extraction  image sensors  image sequences  learning (artificial intelligence)  neural nets  pose estimation  robot vision  stereo image processing  visual servoing  optical flow  visual features  deep neural network  diverse scenes  visual servoing approaches  robust servoing performance  camera transformations  deep flow guided scene agnostic image  deep learning  relative camera pose  photo-realistic 3D simulation  aerial robot  DFVS  interaction matrix  Visual servoing  Cameras  Convergence  Visualization  Adaptive optics  Task analysis 
Abstract: Existing deep learning based visual servoing approaches regress the relative camera pose between a pair of images. Therefore, they require a huge amount of training data and sometimes fine-tuning for adaptation to a novel scene. Furthermore, current approaches do not consider underlying geometry of the scene and rely on direct estimation of camera pose. Thus, inaccuracies in prediction of the camera pose, especially for distant goals, lead to a degradation in the servoing performance. In this paper, we propose a two-fold solution: (i) We consider optical flow as our visual features, which are predicted using a deep neural network. (ii) These flow features are then systematically integrated with depth estimates provided by another neural network using interaction matrix. We further present an extensive benchmark in a photo-realistic 3D simulation across diverse scenes to study the convergence and generalisation of visual servoing approaches. We show convergence for over 3m and 40 degrees while maintaining precise positioning of under 2cm and 1 degree on our challenging benchmark where the existing approaches that are unable to converge for majority of scenarios for over 1.5m and 20 degrees. Furthermore, we also evaluate our approach for a real scenario on an aerial robot. Our approach generalizes to novel scenarios producing precise and robust servoing performance for 6 degrees of freedom positioning tasks with even large camera transformations without any retraining or fine-tuning.


Title: A memory of motion for visual predictive control tasks
Key Words: manipulators  optimal control  optimisation  predictive control  regression analysis  robot vision  visual servoing  visual predictive control tasks  regression techniques  control optimization process  7-axis manipulator  image-based visual servoing  Visualization  Microsoft Windows  Trajectory  Optimization  Task analysis  Computational modeling  Cameras 
Abstract: This paper addresses the problem of efficiently achieving visual predictive control tasks. To this end, a memory of motion, containing a set of trajectories built off-line, is used for leveraging precomputation and dealing with difficult visual tasks. Standard regression techniques, such as k-nearest neighbors and Gaussian process regression, are used to query the memory and provide on-line a warm-start and a way point to the control optimization process. The proposed technique allows the control scheme to achieve high performance and, at the same time, keep the computational time limited. Simulation and experimental results, carried out with a 7-axis manipulator, show the effectiveness of the approach.


Title: Data-Driven Reinforcement Learning for Walking Assistance Control of a Lower Limb Exoskeleton with Hemiplegic Patients
Key Words: adaptive control  artificial limbs  handicapped aids  iterative methods  learning (artificial intelligence)  medical robotics  neural nets  optimal control  patient rehabilitation  wearable robots  Data-driven reinforcement learning  lower limb exoskeleton  hemiplegic patient  rehabilitation scenario  affected leg  unaffected leg  exoskeleton system  DDRL strategy  optimal control  policy iteration algorithm  online adaptation control  walking assistance control  walking assistance scenario  strength augmentation scenario  Actor-Critic Neural Network  ACNN  Legged locomotion  Exoskeletons  Adaptation models  Learning (artificial intelligence)  Trajectory  Extremities  Optimal control  Data-driven Control  Reinforcement Learning  Leader-Follower Multi-Agent System  Lower Limb Exoskeleton  Hemiplegic Patients  Actor-Critic Neural Network 
Abstract: Lower limb exoskeleton (LLE) has received considerable interests in strength augmentation, rehabilitation and walking assistance scenarios. For walking assistance, the LLE is expected to have the capability of controlling the affected leg to track the unaffected leg's motion naturally. An important issue in this scenario is that the exoskeleton system needs to deal with unpredictable disturbance from the patient, which requires the controller of exoskeleton system to have the ability to adapt to different wearers. This paper proposes a novel Data-Driven Reinforcement Learning (DDRL) control strategy to adapt different hemiplegic patients with unpredictable disturbances. In the proposed DDRL strategy, the interaction between two lower limbs of LLE and the legs of hemiplegic patient are modeled in the context of leader-follower framework. The walking assistance control problem is transformed into a optimal control problem. Then, a policy iteration (PI) algorithm is introduced to learn optimal controller. To achieve online adaptation control for different patients, based on PI algorithm, an Actor-Critic Neural Network (ACNN) technology of the reinforcement learning (RL) is employed in the proposed DDRL. We conduct experiments both on a simulation environment and a real LLE system. Experimental results demonstrate that the proposed control strategy has strong robustness against disturbances and adaptability to different pilots.


Title: On the Effects of Visual Anticipation of Floor Compliance Changes on Human Gait: Towards Model-based Robot-Assisted Rehabilitation
Key Words: biomechanics  feedback  gait analysis  mechanoception  medical robotics  muscle  neurophysiology  patient rehabilitation  patient treatment  virtual reality  poststroke gait rehabilitation  variable stiffness treadmill  robot-assisted gait therapies  feedback mechanisms  visual feedback  surface stiffness changes  repeatable muscle activation patterns  predictable muscle activation patterns  surface changes  proprioceptive feedback  manipulated visual feedback  virtual environment  real-world compliant surfaces  walking surface stiffness  sensorimotor mechanisms  robotic rehabilitation device  virtual reality experience  robot-assisted interventions  rehabilitation method  robot assistance  model-based robot-assisted rehabilitation  human gait  floor compliance changes  visual anticipation  Legged locomotion  Visualization  Muscles  Robot sensing systems  Perturbation methods  Electromyography 
Abstract: The role of various types of robot assistance in post-stroke gait rehabilitation has gained much attention in recent years. Furthermore, there is increased popularity to use more than one rehabilitation method in order to utilize the different advantages of each. Naturally, this results in the need to study how the different robot-assisted interventions affect the various underlying sensorimotor mechanisms involved in rehabilitation. To answer this important question, this paper combines a virtual reality experience with a unique robotic rehabilitation device, the Variable Stiffness Treadmill (VST), as a way of understanding interactions across different sensorimotor mechanisms involved in gait. The VST changes the walking surface stiffness in order to simulate real-world compliant surfaces while seamlessly interacting with a virtual environment. Through the manipulated visual and proprioceptive feedback, this paper focuses on the muscle activation patterns before, during, and after surface changes that are both visually informed and uninformed. The results show that there are predictable and repeatable muscle activation patterns both before and after surface stiffness changes, and these patterns are affected by the perceived visual and proprioceptive feedback. The interaction of feedback mechanisms and their effect on evoked muscular activation can be used in future robot-assisted gait therapies, where the intended muscle responses are informed by deterministic models and are tailored to a specific patient's needs.


Title: Bumpem: an Open-Source, Bump-Emulation System for Studying Human Balance and Gait
Key Words: closed loop systems  force control  gait analysis  geriatrics  injuries  mechanoception  medical computing  medical control systems  open-source bump-emulation system  robotic rope-driven system  human gait  fall-inducing perturbations  laboratory-based perturbation systems  aging population  fall-related injury  human balance  open-loop system  closed-loop force control  open-loop force control  transverse plane  force-fields  Brushless motors  Perturbation methods  Force  Force sensors  Shafts  Force control  Legged locomotion 
Abstract: Fall-related injury is a significant health problem on a global scale and is expected to grow with the aging population. Laboratory-based perturbation systems have the capability of simulating various modes of fall-inducing perturbations in a repeatable way. These systems enable fundamental research on human gait and balance and facilitate the development of devices to assist human balance. We present a robotic, rope-driven system capable of rendering bumps and force-fields at a person's pelvis in any direction in the transverse plane with forces up to 200 N, and a 90% rise time of as little as 44 ms, which is faster than a human's ability to sense and respond to the force. These capabilities enable experiments that require stabilizing or destabilizing subjects as they stand or walk on a treadmill. To facilitate use by researchers from all backgrounds, we designed both a configuration with simpler open-loop force control, and another with higher-performance, closed-loop force control. Both configurations are modular, and the open-loop system is made entirely from 3D-printed and catalog components. The design files and assembly instructions for both are freely available in an online repository.


Title: Learning Grasping Points for Garment Manipulation in Robot-Assisted Dressing
Key Words: assisted living  clothing  collision avoidance  dexterous manipulators  end effectors  grippers  handicapped aids  learning (artificial intelligence)  learning systems  neurocontrollers  position control  robot vision  robot-assisted dressing system  dressing activities  grasping point estimations  Baxter robot  robot-garment collision avoidance  orientation computation  grasping point prediction  depth images  supervised deep neural network  robotic manipulation  robot end-effector  robot configuration  elderly people  disabled people  assistive robots  garment manipulation  Clothing  Robots  Grasping  Collision avoidance  Rails  Neural networks  Training 
Abstract: Assistive robots have the potential to provide tremendous support for disabled and elderly people in their daily dressing activities. Recent studies on robot-assisted dressing usually simplify the setup of the initial robot configuration by manually attaching the garments on the robot end-effector and positioning them close to the user's arm. A fundamental challenge in automating such a process for robots is computing suitable grasping points on garments that facilitate robotic manipulation. In this paper, we address this problem by introducing a supervised deep neural network to locate a predefined grasping point on the garment, using depth images for their invariance to color and texture. To reduce the amount of real data required, which is costly to collect, we leverage the power of simulation to produce large amounts of labeled data. The network is jointly trained with synthetic datasets of depth images and a limited amount of real data. We introduce a robot-assisted dressing system that combines the grasping point prediction method, with a grasping and manipulation strategy which takes grasping orientation computation and robot-garment collision avoidance into account. The experimental results demonstrate that our method is capable of yielding accurate grasping point estimations. The proposed dressing system enables the Baxter robot to autonomously grasp a hospital gown hung on a rail, bring it close to the user and successfully dress the upper-body.


Title: Whole-Body Bilateral Teleoperation of a Redundant Aerial Manipulator
Key Words: autonomous aerial vehicles  delays  end effectors  force feedback  haptic interfaces  manipulator dynamics  mobile robots  position control  redundant manipulators  robot vision  telerobotics  video cameras  redundant aerial manipulator  robotic manipulator  flying base  reachability  manipulation task  human capabilities  telemanipulation tasks  visual feedback  task-dependent  video camera  end-effector motion  base position  stable bilateral teleoperation  time-delayed telemanipulation  whole-body bilateral teleoperation  null-space wall  haptic concept  kinematic structure  task-dependent optimal pose  Task analysis  Manipulators  Haptic interfaces  Cameras  Null space  Robot vision systems 
Abstract: Attaching a robotic manipulator to a flying base allows for significant improvements in the reachability and versatility of manipulation tasks. In order to explore such systems while taking advantage of human capabilities in terms of perception and cognition, bilateral teleoperation arises as a reasonable solution. However, since most telemanipulation tasks require visual feedback in addition to the haptic one, real-time (task-dependent) positioning of a video camera, which is usually attached to the flying base, becomes an additional objective to be fulfilled. Since the flying base is part of the kinematic structure of the robot, if proper care is not taken, moving the video camera could undesirably disturb the end-effector motion. For that reason, the necessity of controlling the base position in the null space of the manipulation task arises. In order to provide the operator with meaningful information about the limits of the allowed motions in the null space, this paper presents a novel haptic concept called Null-Space Wall. In addition, a framework to allow stable bilateral teleoperation of both tasks is presented. Numerical simulation data confirm that the proposed framework is able to keep the system passive while allowing the operator to perform time-delayed telemanipulation and command the base to a task-dependent optimal pose.


Title: Enhanced Teleoperation Using Autocomplete
Key Words: autonomous aerial vehicles  learning (artificial intelligence)  mobile robots  telerobotics  enhanced teleoperation  Autocomplete  remote location  skilled teleoperators  training time  novice teleoperators  human input  desired motion  machine learning  motion primitives  unmanned aerial vehicle  Task analysis  Trajectory  Robots  Training  Support vector machines  Manuals  Drones 
Abstract: Controlling and manning robots from a remote location is difficult because of the limitations one faces in perception and available degrees of actuation. Although humans can become skilled teleoperators, the amount of training time required to acquire such skills is typically very high. In this paper, we propose a novel solution (named Autocomplete) to aid novice teleoperators in manning robots adroitly. At the input side, Autocomplete relies on machine learning to detect and categorize human inputs as one from a group of motion primitives. Once a desired motion is recognized, at the actuation side an automated command replaces the human input in performing the desired action. So far, Autocomplete can recognize and synthesize lines, arcs, full circles, 3-D helices, and sine trajectories. Autocomplete was tested in simulation on the teleoperation of an unmanned aerial vehicle, and results demonstrate the advantages of the proposed solution versus manual steering.


Title: Online optimal motion generation with guaranteed safety in shared workspace
Key Words: collision avoidance  industrial manipulators  motion control  occupational safety  path planning  predictive control  online optimal motion generation  guaranteed safety  shared workspace  safer manipulator robots  serious injury  equip robots  online motion generation  partially unknown dynamic environment  industrial manipulator robots  model predictive control scheme  Collision avoidance  Trajectory  Safety  Manipulators  Robot sensing systems  Service robots 
Abstract: With new, safer manipulator robots, the probability of serious injury due to collisions with humans remains low (5%), even at speeds as high as 2 m.s-1. Collisions would better be avoided nevertheless, because they disrupt the tasks of both the robot and the human. We propose in this paper to equip robots with exteroceptive sensors and online motion generation so that the robot is able to perceive and react to the motion of the human in order to reduce the occurrence of collisions. It's impossible to guarantee that no collision will ever take place in a partially unknown dynamic environment such as a shared workspace, but we can guarantee instead that, if a collision takes place, the robot is at rest at the time of collision, so that it doesn't inject its own kinetic energy in the collision. To do so, we adapt a Model Predictive Control scheme which has been demonstrated previously with two industrial manipulator robots avoiding collisions while sharing their workspace. The proposed control scheme is validated in simulation.


Title: Probabilistic Effect Prediction through Semantic Augmentation and Physical Simulation
Key Words: failure analysis  humanoid robots  mobile robots  planning (artificial intelligence)  probability  probabilistic effect prediction  semantic augmentation  exact outcome  failure situations  failure tolerance  robot actions  augmenting collected experience  semantic knowledge  realistic physics simulations  outcome probabilities  unknown tasks  simulated experience  action success probabilities  world experiments  humanoid robot  planning trials  Rollin Justin  Robots  Planning  Probabilistic logic  Cognition  Semantics  Task analysis  Predictive models 
Abstract: Nowadays, robots are mechanically able to perform highly demanding tasks, where AI-based planning methods are used to schedule a sequence of actions that result in the desired effect. However, it is not always possible to know the exact outcome of an action in advance, as failure situations may occur at any time. To enhance failure tolerance, we propose to predict the effects of robot actions by augmenting collected experience with semantic knowledge and leveraging realistic physics simulations. That is, we consider semantic similarity of actions in order to predict outcome probabilities for previously unknown tasks. Furthermore, physical simulation is used to gather simulated experience that makes the approach robust even in extreme cases. We show how this concept is used to predict action success probabilities and how this information can be exploited throughout future planning trials. The concept is evaluated in a series of real world experiments conducted with the humanoid robot Rollin' Justin.


Title: Omnidirectional Tractable Three Module Robot
Key Words: control engineering computing  mobile robots  motion control  pipes  robot kinematics  omnidirectional tractable three module robot  omnidirectional modules  holonomic motion  motion singularity region  motion capabilities  closed-form kinematic model  MSC ADAMS  Robots  Angular velocity  Turning  Shafts  Elbow  Crawlers  Kinematics 
Abstract: This paper introduces the Omnidirectional Tractable Three Module Robot for traversing inside complex pipe networks. The robot consists of three omnidirectional modules fixed 120 apart circumferentially which can rotate about their own axis allowing holonomic motion of the robot. The holonomic motion enables the robot to overcome motion singularity when negotiating T-junctions and further allows the robot to arrive in a preferred orientation while taking turns inside a pipe. We have developed a closed-form kinematic model for the robot in the paper and propose the `Motion Singularity Region' that the robot needs to avoid while negotiating T-junction. The design and motion capabilities of the robot are demonstrated both by conducting simulations in MSC ADAMS on a simplified lumped-model of the robot and with experiments on its physical embodiment.


Title: Algebraic Fault Detection and Identification for Rigid Robots
Key Words: fault diagnosis  manipulators  nonlinear control systems  polynomial approximation  SCARA  polynomial approximation  orthonormal Jacobi polynomials  nonlinear mechanical systems  rigid robots  algebraic fault detection  Fault detection  Jacobian matrices  Mathematical model  Kernel  Time measurement  Robot kinematics 
Abstract: This paper presents a method for algebraic fault detection and identification of nonlinear mechanical systems, describing rigid robots, by using an approximation with orthonormal Jacobi polynomials. An explicit expression is derived for the fault from the equation of motion, which is decoupled from disturbances and only depends on measurable signals and their time derivatives. Fault detection and identification is then achieved by polynomial approximation of the determined fault term. The results are illustrated by a simulation for a faulty SCARA.


Title: Detecting Execution Anomalies As an Oracle for Autonomy Software Robustness
Key Words: fault diagnosis  pattern clustering  robot programming  system monitoring  execution anomaly detection  autonomy software robustness  system monitoring  clustering algorithm  autonomy systems  robotics systems  real-world industrial system  autonomous systems  fault identification  Testing  Tools  Instruments  Clustering algorithms  Service robots  Safety 
Abstract: We propose a method for detecting execution anomalies in robotics and autonomy software. The algorithm uses system monitoring techniques to obtain profiles of executions. It uses a clustering algorithm to create clusters of those executions, representing nominal execution. A distance metric determines whether additional execution profiles belong to the existing clusters or should be considered anomalies. The method is suitable for identifying faults in robotics and autonomy systems. We evaluate the technique in simulation on two robotics systems, one of which is a real-world industrial system. We find that our technique works well to detect possibly unsafe behavior in autonomous systems.


Title: Learning Rope Manipulation Policies Using Dense Object Descriptors Trained on Synthetic Depth Data
Key Words: intelligent robots  learning (artificial intelligence)  manipulators  robot vision  ropes  rope manipulation policies  dense object descriptors  synthetic depth data  robotic manipulation  deformable 1D objects  high-fidelity analytic models  configuration spaces  end-to-end manipulation policies  physical interaction  interpretable deep visual representations  robot manipulation  interpretable policies  transferable geometric policies  visual reasoning  point-pair correspondences  initial goal rope configurations  geometric structure  synthetic depth images  dense depth object descriptors  ABB YuMi Robot  interpretable geometric policies  Task analysis  Visualization  Robots  Strain  Training  Videos  Data models 
Abstract: Robotic manipulation of deformable 1D objects such as ropes, cables, and hoses is challenging due to the lack of high-fidelity analytic models and large configuration spaces. Furthermore, learning end-to-end manipulation policies directly from images and physical interaction requires significant time on a robot and can fail to generalize across tasks. We address these challenges using interpretable deep visual representations for rope, extending recent work on dense object descriptors for robot manipulation. This facilitates the design of interpretable and transferable geometric policies built on top of the learned representations, decoupling visual reasoning and control. We present an approach that learns point-pair correspondences between initial and goal rope configurations, which implicitly encodes geometric structure, entirely in simulation from synthetic depth images. We demonstrate that the learned representation - dense depth object descriptors (DDODs) - can be used to manipulate a real rope into a variety of different arrangements either by learning from demonstrations or using interpretable geometric policies. In 50 trials of a knot-tying task with the ABB YuMi Robot, the system achieves a 66% knot-tying success rate from previously unseen configurations. See https://tinyurl.com/rope-learning for supplementary material and videos.


Title: Camera-to-Robot Pose Estimation from a Single Image
Key Words: cameras  image colour analysis  image sensors  manipulators  neural nets  pose estimation  robot vision  camera-to-robot pose estimation  single RGB image  deep neural network  perspective-n-point  robot manipulator  classic hand-eye calibration systems  camera sensors  classic off-line hand-eye calibration  robot sensors  Cameras  Robot vision systems  Robot kinematics  Calibration  Two dimensional displays  Training 
Abstract: We present an approach for estimating the pose of an external camera with respect to a robot using a single RGB image of the robot. The image is processed by a deep neural network to detect 2D projections of keypoints (such as joints) associated with the robot. The network is trained entirely on simulated data using domain randomization to bridge the reality gap. Perspective-n-point (PnP) is then used to recover the camera extrinsics, assuming that the camera intrinsics and joint configuration of the robot manipulator are known. Unlike classic hand-eye calibration systems, our method does not require an off-line calibration step. Rather, it is capable of computing the camera extrinsics from a single frame, thus opening the possibility of on-line calibration. We show experimental results for three different robots and camera sensors, demonstrating that our approach is able to achieve accuracy with a single frame that is comparable to that of classic off-line hand-eye calibration using multiple frames. With additional frames from a static pose, accuracy improves even further. Code, datasets, and pretrained models for three widely-used robot manipulators are made available.


Title: A Data-driven Planning Framework for Robotic Texture Painting on 3D Surfaces
Key Words: geometry  image texture  industrial robots  mixing  painting  path planning  recurrent neural nets  robot vision  supervised learning  robotic texture painting  painting textures  surface geometry  paint mixing  self-supervised learning framework  painting process  paint simulation environment  robot executes  data-driven planning framework  paint delivery tool flow rate  3D surfaces  recurrent neural network  RNN  Painting  Paints  Robots  Three-dimensional displays  Solid modeling  Two dimensional displays 
Abstract: Painting textures on 3D surfaces requires an understanding of the surface geometry, paint flow and paint mixing. This work formulates automated painting as a planning problem and proposes a solution based on a self-supervised learning framework that enables a robot to paint monochromatic non-uniform textures on 3D surfaces. We developed a method that iteratively decides the actions to take based on constant feedback of the painting process. Inspired by recent results, we formulate our solution using a recurrent neural network (RNN) to decide where and what to paint on the surface at each time instant. Specifically, the paint delivery tool's flow rate, orientation and position relative to the surface at each time instant are evaluated. This data can then be processed by a robot's planner of choice for generating a painting mission that can achieve the desired end result. We evaluate the proposed approach by providing qualitative and quantitative results of the different components. Furthermore, we validate the effectiveness of the approach for the application by providing renderings from a paint simulation environment and show how a robot executes the planned painting mission on a generic 3D surface.


Title: Learning Heuristic A*: Efficient Graph Search using Neural Network
Key Words: graph theory  learning (artificial intelligence)  neural nets  optimisation  path planning  search problems  path planning problem  computation load  neural network  optimal paths  optimal cost  global optimality  admissible heuristic function  efficient graph search  learning heuristic A*  LHA*  suboptimality bound  maze-like map  Heuristic algorithms  Training  Path planning  Biological neural networks  Robots  Navigation 
Abstract: In this paper, we consider the path planning problem on a graph. To reduce computation load by efficiently exploring the graph, we model the heuristic function as a neural network, which is trained by a training set derived from optimal paths to estimate the optimal cost between a pair of vertices on the graph. As such heuristic function cannot be proved to be an admissible heuristic to guarantee the global optimality of the path, we adapt an admissible heuristic function for the terminating criteria. Thus, proposed Learning Heuristic A* (LHA*) guarantees the bounded suboptimality of the path. The performance of LHA* was demonstrated by simulations in a maze-like map and compared with the performance of weighted A* with the same suboptimality bound.


Title: Fast Frontier-based Information-driven Autonomous Exploration with an MAV
Key Words: autonomous aerial vehicles  collision avoidance  entropy  microrobots  mobile robots  navigation  octrees  probability  robot vision  MAV  collision-free navigation  autonomous robots  microaerial vehicles  map entropy  occupancy probabilities  utility function  frontier extraction  frontier-based exploration  frontier voxels  map frontiers  frontier-based information-driven autonomous exploration  exploration planner  octree map representation  visual-based navigation  motion planning  octree-based occupancy mapping  sampling-based exploration  Planning  Octrees  Entropy  Robot sensing systems  Measurement  Task analysis  Aerial Systems: Perception and Autonomy  Visual-Based Navigation 
Abstract: Exploration and collision-free navigation through an unknown environment is a fundamental task for autonomous robots. In this paper, a novel exploration strategy for Micro Aerial Vehicles (MAVs) is presented. The goal of the exploration strategy is the reduction of map entropy regarding occupancy probabilities, which is reflected in a utility function to be maximised. We achieve fast and efficient exploration performance with tight integration between our octree-based occupancy mapping approach, frontier extraction, and motion planning-as a hybrid between frontier-based and sampling-based exploration methods. The computationally expensive frontier clustering employed in classic frontier-based exploration is avoided by exploiting the implicit grouping of frontier voxels in the underlying octree map representation. Candidate next-views are sampled from the map frontiers and are evaluated using a utility function combining map entropy and travel time, where the former is computed efficiently using sparse raycasting. These optimisations along with the targeted exploration of frontier-based methods result in a fast and computationally efficient exploration planner. The proposed method is evaluated using both simulated and real-world experiments, demonstrating clear advantages over state-of-the-art approaches.


Title: Dynamic Landing of an Autonomous Quadrotor on a Moving Platform in Turbulent Wind Conditions
Key Words: aircraft landing guidance  autonomous aerial vehicles  Global Positioning System  helicopters  Kalman filters  mobile robots  nonlinear filters  robot dynamics  robot vision  robust control  turbulence  variable structure systems  vehicle dynamics  dynamic landing  autonomous quadrotor  moving platform  turbulent wind conditions  autonomous landing  fast trajectory planning  wind disturbance  fully autonomous vision-based system  quadrotor-platform distance  landing trajectory  receding horizon control  boundary layer sliding controller  extended Kalman filter  GPS measurements  robust control  precise control  Trajectory  Cameras  Vehicle dynamics  Planning  Global Positioning System  Visualization  Acceleration  Unmanned aerial vehicles  autonomous vehicles  landing on a moving platform  disturbance compensation 
Abstract: Autonomous landing on a moving platform presents unique challenges for multirotor vehicles, including the need to accurately localize the platform, fast trajectory planning, and precise/robust control. Previous works studied this problem but most lack explicit consideration of the wind disturbance, which typically leads to slow descents onto the platform. This work presents a fully autonomous vision-based system that addresses these limitations by tightly coupling the localization, planning, and control, thereby enabling fast and accurate landing on a moving platform. The platform's position, orientation, and velocity are estimated by an extended Kalman filter using simulated GPS measurements when the quadrotor-platform distance is large, and by a visual fiducial system when the platform is nearby. The landing trajectory is computed online using receding horizon control and is followed by a boundary layer sliding controller that provides tracking performance guarantees in the presence of unknown, but bounded, disturbances. To improve the performance, the characteristics of the turbulent conditions are accounted for in the controller. The landing trajectory is fast, direct, and does not require hovering over the platform, as is typical of most stateof-the-art approaches. Simulations and hardware experiments are presented to validate the robustness of the approach.


Title: A Flight Envelope Determination and Protection System for Fixed-Wing UAVs
Key Words: aerospace components  aircraft control  autonomous aerial vehicles  convex programming  nonlinear control systems  predictive control  remotely operated vehicles  flight envelope determination  protection system  fixed-wing UAV  generic model  nonlinear numerical model  model predictive controller  flight envelope constraints  trim flight envelope  MPC  Iron  Aircraft  Numerical models  Atmospheric modeling  Approximation algorithms  Mathematical model  Aerospace control 
Abstract: In this work we present a novel, approximate, efficient algorithm for determining the Trim Flight Envelope of a fixed-wing UAV, based on a generic, nonlinear numerical model. The resulting Flight Envelope is expressed as a convex intersection of half-spaces. Subsequently, a Model Predictive Controller (MPC) is designed which takes into account the Flight Envelope constraints, to avoid Loss-of-Control. The overall system is shown to operate in real-time in a simulation environment.


Title: A Volumetric Albedo Framework for 3D Imaging Sonar Reconstruction
Key Words: autonomous underwater vehicles  image reconstruction  optimisation  robot vision  solid modelling  sonar  sonar imaging  stereo image processing  3D imaging sonar reconstruction  object-level 3D underwater reconstruction  imaging sonar sensors  nonline-of-sight reconstruction  convex linear optimization problem  alternating direction method of multipliers  ADMM  sonar elevation apertures  autonomous underwater vehicles  volumetric Albedo framework  Sonar  Image reconstruction  Imaging  Three-dimensional displays  Sensors  Nonlinear optics  Surface reconstruction 
Abstract: We present a novel framework for object-level 3D underwater reconstruction using imaging sonar sensors. We demonstrate that imaging sonar reconstruction is analogous to the problem of confocal non-line-of-sight (NLOS) reconstruction. Drawing upon this connection, we formulate the problem as one of solving for volumetric albedo, where the scene of interest is modeled as a directionless albedo field. After discretization, reconstruction reduces to a convex linear optimization problem, which we can augment with a variety of priors and regularization terms. We show how to solve the resulting regularized problems using the alternating direction method of multipliers (ADMM) algorithm. We demonstrate the effectiveness of the proposed approach in simulation and on real-world datasets collected in a controlled, test tank environment with several different sonar elevation apertures.


Title: Hybrid Topological and 3D Dense Mapping through Autonomous Exploration for Large Indoor Environments
Key Words: image representation  indoor navigation  mobile robots  path planning  robot vision  SLAM (robots)  stereo image processing  topology  indoor environments  topological global representations  3D dense submaps  hybrid global map  autonomous exploration  autonomous navigation  path planning  dense 3D maps  3D dense representations  3D dense mapping systems  hybrid topological mapping  metric 3D maps  standard CPU  Three-dimensional displays  Measurement  Robots  Semantics  Two dimensional displays  Indoor environments  Path planning 
Abstract: Robots require a detailed understanding of the 3D structure of the environment for autonomous navigation and path planning. A popular approach is to represent the environment using metric, dense 3D maps such as 3D occupancy grids. However, in large environments the computational power required for most state-of-the-art 3D dense mapping systems is compromising precision and real-time capability. In this work, we propose a novel mapping method that is able to build and maintain 3D dense representations for large indoor environments using standard CPUs. Topological global representations and 3D dense submaps are maintained as hybrid global map. Submaps are generated for every new visited place. A place (room) is identified as an isolated part of the environment connected to other parts through transit areas (doors). This semantic partitioning of the environment allows for a more efficient mapping and path-planning. We also propose a method for autonomous exploration that directly builds the hybrid representation in real time.We validate the real-time performance of our hybrid system on simulated and real environments regarding mapping and path-planning. The improvement in execution time and memory requirements upholds the contribution of the proposed work.


Title: Look, Listen, and Act: Towards Audio-Visual Embodied Navigation
Key Words: acoustic signal processing  audio signal processing  audio-visual systems  human computer interaction  mobile agents  navigation  path planning  audio-visual embodied navigation  mobile intelligent agents  multiple sensory inputs  sound source  indoor environment  raw egocentric visual data  audio sensory data  audio signal  visual environment  visual pieces  audio pieces  visual perception mapper module  sound perception module  audio-visual observations  simulated multimodal environment  visual-audio-room dataset  Navigation  Visualization  Task analysis  Robot sensing systems  Visual perception  Acoustics  Feature extraction 
Abstract: A crucial ability of mobile intelligent agents is to integrate the evidence from multiple sensory inputs in an environment and to make a sequence of actions to reach their goals. In this paper, we attempt to approach the problem of Audio-Visual Embodied Navigation, the task of planning the shortest path from a random starting location in a scene to the sound source in an indoor environment, given only raw egocentric visual and audio sensory data. To accomplish this task, the agent is required to learn from various modalities, i.e., relating the audio signal to the visual environment. Here we describe an approach to audio-visual embodied navigation that takes advantage of both visual and audio pieces of evidence. Our solution is based on three key ideas: a visual perception mapper module that constructs its spatial memory of the environment, a sound perception module that infers the relative location of the sound source from the agent, and a dynamic path planner that plans a sequence of actions based on the audio-visual observations and the spatial memory of the environment to navigate toward the goal. Experimental results on a newly collected Visual-Audio-Room dataset using the simulated multi-modal environment demonstrate the effectiveness of our approach over several competitive baselines.


Title: Autonomous Tool Construction with Gated Graph Neural Network
Key Words: convolutional neural nets  graph theory  learning (artificial intelligence)  robot vision  tools  gated graph neural network  autonomous tool construction  reference tool  robotics  GGNN  RCNN-like structure  TC-GRCNN  large-scale training data generation  large-scale testing data generation  tool construction graph RCNN  region based convolutional neural network  candidate part pairs  Tools  Data models  Robots  Task analysis  Training  Solid modeling  Neural networks 
Abstract: Autonomous tool construction is a significant but challenging task in robotics. This task can be interpreted as when given a reference tool, selecting some available candidate parts to reconstruct it. Most of the existing works perform tool construction in the form of action part and grasp part, which is only a specific construction pattern and limits its application to some extent. In general scenarios, a tool can be constructed in various patterns with different part pairs. Therefore, whether a part pair is most suitable for constructing the tool depends not only on itself, but on other parts in the same scene. To solve this problem, we construct a Gated Graph Neural Network (GGNN) to model the relations between all part pairs, so that we can select the candidate parts in consideration of the global information. Afterwards, we embed the constructed GGNN into a RCNN-like structure to finally accomplish tool construction. The whole model will be named Tool Construction Graph RCNN (TC-GRCNN). In addition, we develop a mechanism that can generate large-scale training and testing data in simulation environments, by which we can save the time of data collection and annotation. Finally, the proposed model is deployed on the physical robot. The experiment results show that TC-GRCNN can perform well in the general scenarios of tool construction.


Title: Interconnection and Damping Assignment Passivity-Based Control for Gait Generation in Underactuated Compass-Like Robots
Key Words: control system synthesis  damping  gait analysis  legged locomotion  motion control  robot dynamics  robot kinematics  robust control  interconnection and damping assignment passivity-based control  gait generation  compass-like biped robot  dynamic parameter  port-Hamiltonian framework  controller discretization  parametric uncertainties  Legged locomotion  Potential energy  Damping  Transmission line matrix methods  Mathematical model  Robustness 
Abstract: A compass-like biped robot can go down a gentle slope without the need of actuation through a proper choice of its dynamic parameter and starting from a suitable initial condition. Addition of control actions is requested to generate additional gaits and robustify the existing one. This paper designs an interconnection and damping assignment passivity-based control, rooted within the port-Hamiltonian framework, to generate further gaits with respect to state-of-the-art methodologies, enlarge the basin of attraction of existing gaits, and further robustify the system against controller discretization and parametric uncertainties. The performance of the proposed algorithm is validated through numerical simulations and comparison with existing passivity-based techniques.


Title: Multi-Robot Path Deconfliction through Prioritization by Path Prospects
Key Words: mobile robots  multi-robot systems  path planning  path prospects  prioritization rule  heterogeneous robot teams  multirobot path deconfliction  conflict-free path planning  mobile robots  conflict-free path plans  prioritization heuristics  Robot kinematics  Collision avoidance  Planning  Trajectory  Heuristic algorithms  Couplings 
Abstract: This work deals with the problem of planning conflict-free paths for mobile robots in cluttered environments. Since centralized, coupled planning algorithms are computationally intractable for large numbers of robots, we consider decoupled planning, in which robots plan their paths sequentially in order of priority. Choosing how to prioritize the robots is a key consideration. State-of-the-art prioritization heuristics, however, do not model the coupling between a robot's mobility and its environment. This is particularly relevant when prioritizing between robots with different degrees of mobility. In this paper, we propose a prioritization rule that can be computed online by each robot independently, and that provides consistent, conflict-free path plans. Our innovation is to formalize a robot's path prospects to reach its goal from its current location. To this end, we consider the number of homology classes of trajectories, which capture distinct prospects of paths for each robot. This measure is used as a prioritization rule, whenever any robots enter negotiation to deconflict path plans. We perform simulations with heterogeneous robot teams and compare our method to five benchmarks. Our method achieves the highest success rate, and strikes a good balance between makespan and flowtime objectives.


Title: A Connectivity-Prediction Algorithm and its Application in Active Cooperative Localization for Multi-Robot Systems
Key Words: Markov processes  mobile robots  motion control  multi-robot systems  path planning  probability  infinite power series expansion theorem  finite-term approximation  computational feasibility  adverse impacts  higher order series terms  active CL  leader-follower architecture  Markov decision process  one-step planning horizon  optimal motion strategy  MDP model  connectivity-prediction algorithm  multirobot systems  future connectivity  mobile robots  range-limited communication  active motion planning  quadratic forms  random normal variables  Prediction algorithms  Robot sensing systems  Planning  Uncertainty  Computational modeling  Gaussian distribution 
Abstract: This paper presents a method for predicting the probability of future connectivity between mobile robots with range-limited communication. In particular, we focus on its application to active motion planning for cooperative localization (CL). The probability of connection is modeled by the distribution of quadratic forms in random normal variables and is computed by the infinite power series expansion theorem. A finite-term approximation is made to realize the computational feasibility and three more modifications are designed to handle the adverse impacts introduced by the omission of the higher order series terms. On the basis of this algorithm, an active and CL problem with leader-follower architecture is then reformulated into a Markov Decision Process (MDP) with a one-step planning horizon, and the optimal motion strategy is generated by minimizing the expected cost of the MDP. Extensive simulations and comparisons are presented to show the effectiveness and efficiency of both the proposed prediction algorithm and the MDP model.


Title: Behavior Mixing with Minimum Global and Subgroup Connectivity Maintenance for Large-Scale Multi-Robot Systems
Key Words: collision avoidance  distributed algorithms  mobile robots  multi-robot systems  trees (mathematics)  large-scale multirobot systems  robot team  connected communication graph  minimum inter-robot connectivity constraints  activated connectivity constraints  behavior mixing controllers  distributed minimum connectivity constraint spanning tree algorithm  provably minimum connectivity maintenance  subgroup connectivity maintenance  minimum global connectivity maintenance  collision avoidance  distributed MCCST algorithm  Collision avoidance  Robot kinematics  Task analysis  Safety  Multi-robot systems  Real-time systems 
Abstract: In many cases the multi-robot systems are desired to execute simultaneously multiple behaviors with different controllers, and sequences of behaviors in real time, which we call behavior mixing. Behavior mixing is accomplished when different subgroups of the overall robot team change their controllers to collectively achieve given tasks while maintaining connectivity within and across subgroups in one connected communication graph. In this paper, we present a provably minimum connectivity maintenance framework to ensure the subgroups and overall robot team stay connected at all times while providing the highest freedom for behavior mixing. In particular, we propose a real-time distributed Minimum Connectivity Constraint Spanning Tree (MCCST) algorithm to select the minimum inter-robot connectivity constraints preserving subgroup and global connectivity that are least likely to be violated by the original controllers. With the employed safety and connectivity barrier certificates for the activated connectivity constraints and collision avoidance, the behavior mixing controllers are thus minimally modified from the original controllers. We demonstrate the effectiveness and scalability of our approach via simulations of up to 100 robots with multiple behaviors.


Title: Energy-Optimal Cooperative Manipulation via Provable Internal-Force Regulation
Key Words: cooperative systems  decentralised control  force control  manipulator dynamics  mobile robots  multi-robot systems  position control  internal-force regulation  optimal cooperative robotic manipulation problem  energy resources  rigid cooperative manipulation systems  rigid grasping contacts  energy-optimal conditions  arising internal forces  inter-agent forces  closed form expression  standard inverse dynamics  force distribution  robotic agents  nonzero inter-agent internal force vector  internal force minimization  Grasping  Force  Robots  Dynamics  Acceleration  Jacobian matrices  Task analysis 
Abstract: This paper considers the optimal cooperative robotic manipulation problem in terms of energy resources. In particular, we consider rigid cooperative manipulation systems, i.e., with rigid grasping contacts, and study energy-optimal conditions in the sense of minimization of the arising internal forces, which are inter-agent forces that do not contribute to object motion. Firstly, we use recent results to derive a closed form expression for the internal forces. Secondly, by using a standard inverse dynamics control protocol, we provide novel conditions on the force distribution to the robotic agents for provable internal force minimization. Moreover, we derive novel results on the provable achievement of a desired non-zero inter-agent internal force vector. Extensive simulation results in a realistic environment verify the theoretical analysis.


Title: Simultaneous Tracking and Elasticity Parameter Estimation of Deformable Objects
Key Words: deformation  finite element analysis  image colour analysis  manipulators  parameter estimation  robot vision  visual information  simulated object  elasticity parameter estimation  tracked object  soft objects  deformable object  simultaneous tracking  interactive finite element method simulations  RGB-D sensor  robotic manipulation  Strain  Elasticity  Estimation  Deformable models  Force measurement  Force  Force sensors 
Abstract: In this paper, we propose a novel method to simultaneously track the deformation of soft objects and estimate their elasticity parameters. The tracking of the deformable object is performed by combining the visual information captured by a RGB-D sensor with interactive Finite Element Method simulations of the object. The visual information is more particularly used to distort the simulated object. In parallel, the elasticity parameter estimation minimizes the error between the tracked object and a simulated object deformed by the forces that are measured using a force sensor. Once the elasticity parameters are estimated, our tracking algorithm can be used to estimate the deformation forces applied to an object without the use of a force sensor. We validated our method on several soft objects with different shape complexities. Our evaluations show the ability of our method to estimate the elasticity parameters as well as its use to estimate the forces applied to a deformable object without any force sensor. These results open novel perspectives to better track and control deformable objects during robotic manipulations.


Title: Transient Behavior and Predictability in Manipulating Complex Objects
Key Words: feedback  feedforward  haptic interfaces  human-robot interaction  manipulator dynamics  motion control  virtual reality  robot control  internal dynamics  transient behavior  predictable dynamics  virtual object  robotic manipulandum  predictable steady state  feedforward controller  inverse dynamics  haptic feedback  Transient analysis  Robots  Steady-state  Task analysis  Dynamics  Force  Haptic interfaces 
Abstract: Relatively little work in human and robot control has examined the control of underactuated objects with internal dynamics, such as transporting a cup of coffee, a task that presents little problems for humans. This study examined how humans move a `cup of coffee' with a view to identify principles that may be useful for robot control. The specific focus was on how humans choose initial conditions to safely reach a steady state. We hypothesized that subjects choose initial conditions that minimized the transient duration to reach the steady state faster, as it presented more predictable dynamics. In the experiment, the cup of coffee was reduced to a 2-D cup with a sliding ball inside which was simulated in a virtual environment. Human subjects interacted with this virtual object via a robotic manipulandum that provided haptic feedback. Participants moved the cup between two targets without losing the ball; they were instructed to explore different initial conditions before initiating the continuous interaction. Results showed that subjects converged to a small set of initial conditions that decreased their transient durations and achieved a predictable steady state faster. Simulations with a simple feedforward controller and inverse dynamics calculations confirmed that these initial conditions indeed led to shorter transients and less complex interaction forces. These results may inform robot control of objects with internal dynamics where the effects of initial conditions need further investigation.


Title: Assistive Gym: A Physics Simulation Framework for Assistive Robotics
Key Words: human-robot interaction  learning (artificial intelligence)  manipulators  medical robotics  mobile robots  robot programming  service robots  physics simulation framework  autonomous robots  physical interaction  physics simulations  physical assistance  open source physics  assistive robots  simulated environments  robotic manipulator  assistive gym models  commercial robots  assistive robotics research  ADL  activities of daily living  Task analysis  Manipulators  Physics  Tools  Human-robot interaction  Mobile robots 
Abstract: Autonomous robots have the potential to serve as versatile caregivers that improve quality of life for millions of people worldwide. Yet, conducting research in this area presents numerous challenges, including the risks of physical interaction between people and robots. Physics simulations have been used to optimize and train robots for physical assistance, but have typically focused on a single task. In this paper, we present Assistive Gym, an open source physics simulation framework for assistive robots that models multiple tasks. It includes six simulated environments in which a robotic manipulator can attempt to assist a person with activities of daily living (ADLs): itch scratching, drinking, feeding, body manipulation, dressing, and bathing. Assistive Gym models a person's physical capabilities and preferences for assistance, which are used to provide a reward function. We present baseline policies trained using reinforcement learning for four different commercial robots in the six environments. We demonstrate that modeling human motion results in better assistance and we compare the performance of different robots. Overall, we show that Assistive Gym is a promising tool for assistive robotics research.


Title: Evaluation of an Exoskeleton-based Bimanual Teleoperation Architecture with Independently Passivated Slave Devices
Key Words: delays  motion control  stability  telerobotics  simulated time delay  control loop frequency  multiDoFs devices  TDPA  time domain passivity approach  exoskeletal master  bimanual teleoperation system  communication delay  bilateral teleoperation  haptic feedback  robotic platforms  rescue robotics  independently passivated slave devices  exoskeleton-based bimanual teleoperation architecture  Exoskeletons  Task analysis  Computer architecture  Stability analysis  Robots  Delays  Haptic interfaces 
Abstract: Search and rescue robotics is becoming a relevant topic in the last years and the growing number of robotic platforms and dedicated projects is the evidence of the interest in this area. In this context, the possibility to drive a remote robot with an exoskeleton is a promising strategy to enhance dexterity, reduce operator effort and save time. However, the use of haptic feedback (bilateral teleoperation) may lead to instability in the presence of communication delay and more complex is the case of bimanual teleoperation where the two arms can exchange energy. In this work, we present a bimanual teleoperation system based on an exoskeletal master, where multi-degrees of freedom (multi-DoFs) and kinematically different devices are involved. In the implemented architecture the two slaves are managed in parallel and independently passivated using the Time Domain Passivity Approach (TDPA) extended for multi-DoFs devices. To investigate the stability of the architecture we designed two tasks highly related to real disaster scenarios: the first one was useful to verify the system behavior in case of small movements and constrained configurations, whereas the second experiment was designed to involve larger contact forces and movements. Moreover, we compared the effect of both delay and low control loop frequency on the stability of the system when TDPA was applied. From the results, it was evident that the overall system exhibited a stable behavior with the use of the TDPA, even passivating the two slaves independently, under simulated time delay and in presence of a low control loop frequency.


Title: Hand-worn Haptic Interface for Drone Teleoperation
Key Words: autonomous aerial vehicles  data gloves  human-robot interaction  mobile robots  motion control  robot vision  telerobotics  trajectory control  drone teleoperation  remote radio controllers  wearable interface  drone trajectory  hand motion  haptic system  robotic systems  teleoperation performance  remote controllers  human-robot interfaces  hand-worn haptic interface  data glove  line of sight  search-and-rescue missions  Haptic interfaces  Drones  Task analysis  Robot sensing systems  Hardware 
Abstract: Drone teleoperation is usually accomplished using remote radio controllers, devices that can be hard to master for inexperienced users. Moreover, the limited amount of information fed back to the user about the robot's state, often limited to vision, can represent a bottleneck for operation in several conditions. In this work, we present a wearable interface for drone teleoperation and its evaluation through a user study. The two main features of the proposed system are a data glove to allow the user to control the drone trajectory by hand motion and a haptic system used to augment their awareness of the environment surrounding the robot. This interface can be employed for the operation of robotic systems in line of sight (LoS) by inexperienced operators and allows them to safely perform tasks common in inspection and search-and-rescue missions such as approaching walls and crossing narrow passages with limited visibility conditions. In addition to the design and implementation of the wearable interface, we performed a systematic study to assess the effectiveness of the system through three user studies (n = 36) to evaluate the users' learning path and their ability to perform tasks with limited visibility. We validated our ideas in both a simulated and a real-world environment. Our results demonstrate that the proposed system can improve teleoperation performance in different cases compared to standard remote controllers, making it a viable alternative to standard Human-Robot Interfaces.


Title: Local Obstacle-Skirting Path Planning for a Fast Bi-steerable Rover using Bzier Curves
Key Words: automatic guided vehicles  collision avoidance  curve fitting  mobile robots  navigation  off-road vehicles  predictive control  stability  steering systems  vehicle dynamics  local obstacle-skirting path planning  obstacle avoidance  off-road mobile robots  global reference path  smooth path  lateral stability  double-steering rover  online cubic Bezier curves  bi-steerable rover  constrained model predictive control  navigation  autonomous guided vehicles  Safety  Collision avoidance  Mobile robots  Lead  Path planning  Robot kinematics 
Abstract: This paper focuses on local path planning for obstacle avoidance tasks dedicated to off-road mobile robots. This approach calculates a new local path for the vehicle using a set of cubic Bezier curves once the safety distance is not respected; otherwise, the vehicle follows the global reference path which is defined off-line. Two basic steps are used to determine this new path. Firstly, some significant points that should belong to the planned path are extracted on-line according to the obstacle's sizes and the current state of the vehicle, these points are approved as waypoints. Secondly, on-line cubic Bezier curves are computed to create a smooth path for these points such that the safety and lateral stability of the vehicle are ensured (i.e., preventing huge curvatures and wide-variation in steering angles). This path will be used as a reference to be performed by the vehicle using a constrained model predictive control. The validation of our navigation strategy is performed via numerical simulations and experiments using a fast double-steering rover.


Title: Collision Avoidance with Proximity Servoing for Redundant Serial Robot Manipulators
Key Words: collision avoidance  human-robot interaction  manipulators  motion control  quadratic programming  repulsive motions  instantaneous optimal joint velocities  quadratic optimization problem  proximity sensing skins  collision avoidance  low-latency perception  proximity sensors  fastreacting motions  safe human-robot interaction  redundant serial robot manipulators  proximity servoing  Collision avoidance  Robot sensing systems  Task analysis  Manipulators  Skin 
Abstract: Collision avoidance is a key technology towards safe human-robot interaction, especially on-line and fastreacting motions are required. Skins with proximity sensors mounted on the robot's outer shell provide an interesting approach to occlusion-free and low-latency perception. However, collision avoidance algorithms which make extensive use of these properties for fast-reacting motions have not yet been fully investigated. We present an improved collision avoidance algorithm for proximity sensing skins by formulating a quadratic optimization problem with inequality constraints to compute instantaneous optimal joint velocities. Compared to common repulsive force methods, our algorithm confines the approach velocity to obstacles and keeps motions pointing away from obstacles unrestricted. Since with repulsive motions the robot only moves in one direction, opposite to obstacles, our approach has better exploitation of the redundancy space to maintain the task motion and gets stuck less likely in local minima. Furthermore, our method incorporates an active behaviour for avoiding obstacles and evaluates all potentially colliding obstacles for the whole arm, rather than just the single nearest obstacle. We demonstrate the effectiveness of our method with simulations and on real robot manipulators in comparison with commonly used repulsive force methods and our prior proposed approach.


Title: Predicting Obstacle Footprints from 2D Occupancy Maps by Learning from Physical Interactions
Key Words: collision avoidance  convolutional neural nets  laser ranging  learning (artificial intelligence)  mobile robots  navigation  robot vision  indoor robot localization  obstacle avoidance  laser scanners  collision events  2D occupancy maps  obstacle footprint prediction  physical interaction learning  horizontal scanning 2D laser range finders  convolutional neural network  Two dimensional displays  Collision avoidance  Image segmentation  Training  Robot sensing systems 
Abstract: Horizontally scanning 2D laser rangefinders are a popular approach for indoor robot localization because of the high accuracy of the sensors and the compactness of the required 2D maps. As the scanners in this configuration only provide information about one slice of the environment, the measurements typically do not capture the full extent of a large variety of obstacles, including chairs or tables. Accordingly, obstacle avoidance based on laser scanners mounted in such a fashion is likely to fail. In this paper, we propose a learning-based approach to predict collisions in 2D occupancy maps. Our approach is based on a convolutional neural network which is trained on a 2D occupancy map and collision events recorded with a bumper while the robot is navigating in its environment. As the network operates on local structures only, it can generalize to new environments. In addition, the robot can collect and integrate new collision examples after an initial training phase. Extensive experiments carried out in simulation and a realistic real-world environment confirm that our approach allows robots to learn from collision events to avoid collisions in the future.


Title: Path Planning in Dynamic Environments using Generative RNNs and Monte Carlo Tree Search
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  Monte Carlo methods  recurrent neural nets  tree searching  Monte Carlo tree search  generative recurrent neural networks  integrated path  motion models  traffic  robotic path planning  dynamic environments  effective path planning  motion prediction accuracy  planned robotic actions  generative RNNs  action space  crowd dynamics  social response  learnt model  Robots  Predictive models  Path planning  Decoding  Collision avoidance  Training  Dynamics 
Abstract: State of the art methods for robotic path planning in dynamic environments, such as crowds or traffic, rely on hand crafted motion models for agents. These models often do not reflect interactions of agents in real world scenarios. To overcome this limitation, this paper proposes an integrated path planning framework using generative Recurrent Neural Networks within a Monte Carlo Tree Search (MCTS). This approach uses a learnt model of social response to predict crowd dynamics during planning across the action space. This extends our recent work using generative RNNs to learn the relationship between planned robotic actions and the likely response of a crowd. We show that the proposed framework can considerably improve motion prediction accuracy during interactions, allowing more effective path planning. The performance of our method is compared in simulation with existing methods for collision avoidance in a crowd of pedestrians, demonstrating the ability to control future states of nearby individuals. We also conduct preliminary real world tests to validate the effectiveness of our method.


Title: Safety-Critical Rapid Aerial Exploration of Unknown Environments
Key Words: autonomous aerial vehicles  collision avoidance  helicopters  mobile robots  sensors  uncertain systems  high-speed flight  uncertain environments  controller level  state uncertainty  nonlinear system dynamics  high-fidelity simulation  cave environment  safety-critical rapid aerial exploration  collision avoidance  aerial vehicles  unknown environments  quadrotor  onboard sensors  Safety  Collision avoidance  Three-dimensional displays  Drones  Trajectory  Vehicle dynamics  Planning 
Abstract: This paper details a novel approach to collision avoidance for aerial vehicles that enables high-speed flight in uncertain environments. This framework is applied at the controller level and provides safety regardless of the planner that is used. The method is shown to be robust to state uncertainty and disturbances, and is computed entirely online utilizing the full nonlinear system dynamics. The effectiveness of this method is shown in a high-fidelity simulation of a quadrotor with onboard sensors rapidly and safely exploring a cave environment utilizing a simple planner.


Title: Reconfigurable Magnetic Microswarm for Thrombolysis under Ultrasound Imaging
Key Words: biochemistry  biological tissues  biomedical materials  biomedical ultrasonics  blood  magnetic particles  microrobots  nanomedicine  nanoparticles  patient treatment  reconfigurable magnetic microswarm  thrombolysis  ultrasound imaging  magnetic nanoparticle microswarm  tissue plasminogen activator  oscillating magnetic field  aspect ratio  out-of-plane fluid convection  lysis rate  microswarm-induced fluid convection  Ultrasonic imaging  Magnetic resonance imaging  Convection  Coagulation  Coils  Micro/nanorobot  magnetic control  collective behavior  thrombolysis  ultrasound imaging 
Abstract: We propose thrombolysis using a magnetic nanoparticle microswarm with tissue plasminogen activator (tPA) under ultrasound imaging. The microswarm is generated in blood using an oscillating magnetic field and can be navigated with locomotion along both the long and short axis. By modulating the input field, the aspect ratio of the microswarm can be reversibly tuned, showing the ability to adapt to different confined environments. Simulation results indicate that both in-plane and out-of-plane fluid convection are induced around the microswarm, which can be further enhanced by tuning the aspect ratio of the microswarm. Under ultrasound imaging, the microswarm is navigated in a microchannel towards a blood clot and deformed to obtain optimal lysis. Experimental results show that the lysis rate reaches -0.1725  0.0612 mm3/min in the 37C blood environment under the influence of the microswarm-induced fluid convection and tPA. The lysis rate is enhanced 2.5-fold compared to that without the microswarm (-0.0681  0.0263 mm3/min). Our method provides a new strategy to increase the efficiency of thrombolysis by applying microswarm-induced fluid convection, indicating that swarming micro/nanorobots have the potential to act as effective tools towards targeted therapy.


Title: Reality as a simulation of reality: robot illusions, fundamental limits, and a physical demonstration
Key Words: collision avoidance  human-robot interaction  mobile robots  multi-robot systems  fundamental limits  physical demonstration  robot behavior  potential mismatches  convincing illusion  system simulation  simulated systems  simple multirobot experiment  robot navigating  robot illusions  Robot sensing systems  Software  Sensor systems  Mobile robots  Emulation 
Abstract: We consider problems in which robots conspire to present a view of the world that differs from reality. The inquiry is motivated by the problem of validating robot behavior physically despite there being a discrepancy between the robots we have at hand and those we wish to study, or the environment for testing that is available versus that which is desired, or other potential mismatches in this vein. After formulating the concept of a convincing illusion, essentially a notion of system simulation that takes place in the real world, we examine the implications of this type of simulability in terms of infrastructure requirements. Time is one important resource: some robots may be able to simulate some others but, perhaps, only at a rate that is slower than real-time. This difference gives a way of relating the simulating and the simulated systems in a form that is relative. We establish some theorems, including one with the flavor of an impossibility result, and providing several examples throughout. Finally, we present data from a simple multi-robot experiment based on this theory, with a robot navigating amid an unbounded field of obstacles."Truth is beautiful, without doubt; but so are lies."-Ralph Waldo Emerson.


Title: Finding Missing Skills for High-Level Behaviors
Key Words: robots  temporal logic  KUKA IIWA arm  Baxter robot  LTL specifications  correct-by-construction robot control  LTL synthesis  high-level robot tasks  linear temporal logic  Task analysis  Maintenance engineering  Games  Robot control  Manipulators  Safety 
Abstract: Recently, Linear Temporal Logic (LTL) has been used as a formalism for defining high-level robot tasks, and LTL synthesis has been used to automatically create correct-by-construction robot control. The underlying premise of this approach is that the robot has a set of actions, or skills, that can be composed to achieve the high- level task. In this paper we consider LTL specifications that cannot be synthesized into robot control due to lack of appropriate skills; we present algorithms for automatically suggesting new or modified skills for the robot that will guarantee the task will be achieved. We demonstrate our approach with a physical Baxter robot and a simulated KUKA IIWA arm.


Title: R-Min: a Fast Collaborative Underactuated Parallel Robot for Pick-and-Place Operations
Key Words: collision avoidance  end effectors  human-robot interaction  springs (mechanical)  trajectory control  parallel manipulator  pick-and-place operations  human operator  acceleration  planar five-bar mechanism  passive joints  planar seven-bar mechanism  supplementary passive leg  collaborative parallel robot  pick-and-place trajectory  R-Min  collaborative underactuated parallel robot  tension spring  end-effector  degrees of freedom  impact force  Collision avoidance  Collaboration  Prototypes  Parallel robots  Robot sensing systems  Springs 
Abstract: This paper introduces an intrinsically safe parallel manipulator dedicated to fast pick-and-place operations, called R-Min. It has been designed to reduce the risk of injury during a collision with a human operator, while maintaining high speed and acceleration. The proposed architecture is based on a modification of the well-known planar five-bar mechanism, where additional passive joints are introduced to the distal links in order to create a planar seven-bar mechanism with two degrees of underactuation, so that it can passively reconfigure in case of collision. A supplementary passive leg, in which a tension spring is mounted, is added between the base and the end-effector in order to constrain the additional degrees of freedom. A prototype of this new collaborative parallel robot is designed and its equilibrium configurations under several types of loadings are analyzed. Its dynamics is also studied. We analyze the impact force occurring during a collision between our prototype and the head of an operator and compare these results with those that would have been obtained with a rigid five-bar mechanism. Simulation results of impact during a standard pick-and-place trajectory of duration 0.3 s show that a regular five-bar mechanism would injure a human, while our robot would avoid the trauma.


Title: Trajectory optimization for a class of robots belonging to Constrained Collaborative Mobile Agents (CCMA) family
Key Words: actuators  collision avoidance  end effectors  manipulator kinematics  mobile robots  multi-robot systems  optimisation  position control  constrained collaborative mobile agents family  ground mobile bases  mobile robots  closed-loop kinematic chains  revolute joints  closed- loop kinematic chains  standalone trajectory optimization method  CCMA system  fixed design parameters  control policy optimization  manipulation capabilities  tracked mobile bases  Kinematics  Mobile robots  Trajectory optimization  Mobile agents  Task analysis  Parallel Robots  Optimization and Optimal Control  Multi-Robot Systems 
Abstract: We present a novel class of robots belonging to Constrained Collaborative Mobile Agents (CCMA) family which consists of ground mobile bases with non-holonomic constraints. Moreover, these mobile robots are constrained by closed-loop kinematic chains consisting of revolute joints which can be either passive or actuated. We also describe a novel trajectory optimization method which is general with respect to number of mobile robots, topology of the closed- loop kinematic chains and placement of the actuators at the revolute joints. We also extend the standalone trajectory optimization method to optimize concurrently the design parameters and the control policy. We describe various CCMA system examples, in simulation, differing in design, topology, number of mobile robots and actuation space. The simulation results for standalone trajectory optimization with fixed design parameters is presented for CCMA system examples. We also show how this method can be used for tasks other than end-effector positioning such as internal collision avoidance and external obstacle avoidance. The concurrent design and control policy optimization is demonstrated, in simulations, to increase the CCMA system workspace and manipulation capabilities. Finally, the trajectory optimization method is validated in experiments through two 4-DOF prototypes consisting of 3 tracked mobile bases.


Title: Radar Sensors in Collaborative Robotics: Fast Simulation and Experimental Validation
Key Words: collision avoidance  CW radar  FM radar  frequency modulation  image sensors  learning (artificial intelligence)  mobile robots  object detection  radar computing  road vehicle radar  sensors  collaborative robotics  radar systems  robot systems  optimization  machine learning approaches  realistic simulation models  radar sensor simulations  relative velocities  Lambertian reflectance model  reflection estimates  frequency modulated continuous wave radar  simulation environments  Radar  Robot sensing systems  Radar antennas  Chirp  Computational modeling 
Abstract: With the availability of small system in package realizations, radar systems become more and more attractive for a variety of applications in robotics, in particular also for collaborative robotics. As the simulation of robot systems in realistic scenarios has become an important tool, not only for design and optimization, but also e.g. for machine learning approaches, realistic simulation models are needed. In the case of radar sensor simulations, this means providing more realistic results than simple proximity sensors, e.g. in the presence of multiple objects and/or humans, objects with different relative velocities and differentiation between background and foreground movement. Due to the short wavelength in the millimeter range, we propose to utilize methods known from computer graphics (e.g. z-buffer, Lambertian reflectance model) to quickly acquire depth images and reflection estimates. This information is used to calculate an estimate of the received signal for a Frequency Modulated Continuous Wave (FMCW) radar by superposition of the corresponding signal contributions. Due to the moderate computational complexity, the approach can be used with various simulation environments such as V-Rep or Gazebo. Validity and benefits of the approach are demonstrated by means of a comparison with experimental data obtained with a radar sensor on a UR10 arm in different scenarios.


Title: Visual Prediction of Priors for Articulated Object Interaction
Key Words: feature extraction  intelligent robots  mobile robots  object detection  visual servoing  exploratory behavior  visual features learning  contextual multiarmed bandit  parameterized action space  articulated object interaction  contextual prior prediction  Robots  Visualization  Training  Kinematics  Gaussian processes  Optimization  Kernel 
Abstract: Exploration in novel settings can be challenging without prior experience in similar domains. However, humans are able to build on prior experience quickly and efficiently. Children exhibit this behavior when playing with toys. For example, given a toy with a yellow and blue door, a child will explore with no clear objective, but once they have discovered how to open the yellow door, they will most likely be able to open the blue door much faster. Adults also exhibit this behaviour when entering new spaces such as kitchens. We develop a method, Contextual Prior Prediction, which provides a means of transferring knowledge between interactions in similar domains through vision. We develop agents that exhibit exploratory behavior with increasing efficiency, by learning visual features that are shared across environments, and how they correlate to actions. Our problem is formulated as a Contextual Multi-Armed Bandit where the contexts are images, and the robot has access to a parameterized action space. Given a novel object, the objective is to maximize reward with few interactions. A domain which strongly exhibits correlations between visual features and motion is kinemetically constrained mechanisms. We evaluate our method on simulated prismatic and revolute joints1.


Title: Using Synthetic Data and Deep Networks to Recognize Primitive Shapes for Object Grasping
Key Words: convolutional neural nets  dexterous manipulators  image segmentation  learning (artificial intelligence)  mobile robots  object recognition  path planning  robot vision  shape recognition  synthetic data  deep networks  primitive shape  object grasping  segmentation-based architecture  monocular depth input  backbone deep network  parametrized grasp families  shape primitive region  task-free grasping  shape primitives  task-relevant grasp prediction  ranking algorithm  task-free grasp prediction  Shape  Grasping  Image segmentation  Three-dimensional displays  Task analysis  Robot sensing systems 
Abstract: A segmentation-based architecture is proposed to decompose objects into multiple primitive shapes from monocular depth input for robotic manipulation. The backbone deep network is trained on synthetic data with 6 classes of primitive shapes generated by a simulation engine. Each primitive shape is designed with parametrized grasp families, permitting the pipeline to identify multiple grasp candidates per shape primitive region. The grasps are priority ordered via proposed ranking algorithm, with the first feasible one chosen for execution. On task-free grasping of individual objects, the method achieves a 94% success rate. On task-oriented grasping, it achieves a 76% success rate. Overall, the method supports the hypothesis that shape primitives can support task-free and task-relevant grasp prediction.


Title: Stillleben: Realistic Scene Synthesis for Deep Learning in Robotics
Key Words: cameras  image segmentation  iterative methods  learning (artificial intelligence)  neural nets  pose estimation  rendering (computer graphics)  robot vision  realistic scene synthesis  robotics  training data  deep learning  synthesis pipeline  cluttered scene perception tasks  semantic segmentation  object detection  physically realistic scenes  high-quality rasterization  material parameters  camera sensors  deep neural network  training frames  iterative render-and-compare approaches  YCB-Video dataset  Stillleben  Training  Rendering (computer graphics)  Robots  Engines  Pipelines  Task analysis  Cameras 
Abstract: Training data is the key ingredient for deep learning approaches, but difficult to obtain for the specialized domains often encountered in robotics. We describe a synthesis pipeline capable of producing training data for cluttered scene perception tasks such as semantic segmentation, object detection, and correspondence or pose estimation. Our approach arranges object meshes in physically realistic, dense scenes using physics simulation. The arranged scenes are rendered using high-quality rasterization with randomized appearance and material parameters. Noise and other transformations introduced by the camera sensors are simulated. Our pipeline can be run online during training of a deep neural network, yielding applications in life-long learning and in iterative render-and-compare approaches. We demonstrate the usability by learning semantic segmentation on the challenging YCB-Video dataset without actually using any training frames, where our method achieves performance comparable to a conventionally trained model. Additionally, we show successful application in a real-world regrasping system.


Title: Spatiotemporal Representation Learning with GAN Trained LSTM-LSTM Networks
Key Words: convolutional neural nets  learning (artificial intelligence)  learning systems  robots  unstructured environments  unsupervised representation learning architecture  underlying representation  high-dimensional raw video inputs  spatiotemporal representation learning  lower-dimensional latent space  two-stage learning approach  convolutional neural network  Long Short-Term Network  LSTM-LSTM cells  hierarchical representation learning  low-dimensional representation  video prediction task  GAN trained LSTM-LSTM networks  robot behavior learning  layered spatiotemporal memory long short-term memory  generative adversarial network  ConvNet  Spatiotemporal phenomena  Gallium nitride  Task analysis  Training  Generative adversarial networks  Robots  Feature extraction 
Abstract: Learning robot behaviors in unstructured environments often requires handcrafting the features for a given task. In this paper, we present and evaluate an unsupervised representation learning architecture, Layered Spatiotemporal Memory Long Short-Term Memory (LSTM-LSTM), that learns the underlying representation without knowledge of the task. The goal of this architecture is to learn the dynamics of the environment from high-dimensional raw video inputs. Using a Generative Adversarial Network (GAN) framework with the proposed network, this architecture is able to learn a spatiotemporal representation in its lower-dimensional latent space directly from raw input sequences. We show that our approach learns the spatial and temporal information simultaneously as opposed to a two-stage learning approach of alternating between training a Convolutional Neural Network (ConvNet) and a Long Short-Term Network (LSTM). Furthermore, by using LSTM-LSTM cells that shrink in size with the increase in the number of layers, the network learns a hierarchical representation with a low-dimensional representation at the top layer. We show that this architecture achieves state-of-the-art results with a substantially lower-dimensional representation than existing methods. We evaluate our approach on a video prediction task with standard benchmark datasets like Moving MNIST and KTH Action, as well as a simulated robot dataset.


Title: Belief Regulated Dual Propagation Nets for Learning Action Effects on Groups of Articulated Objects
Key Words: backpropagation  graph theory  neural nets  robot programming  groups of articulated objects  learning action effects  complex robotic systems  graph neural networks  Belief Regulated Dual Propagation nets  object interaction  object trajectory level  belief regulator  physics predictor  PropNets  general-purpose learnable physics engine  BRDPN  robotics domain  Robots  Physics  Engines  Predictive models  History  Neural networks  Trajectory 
Abstract: In recent years, graph neural networks have been successfully applied for learning the dynamics of complex and partially observable physical systems. However, their use in the robotics domain is, to date, still limited. In this paper, we introduce Belief Regulated Dual Propagation Networks (BRDPN), a general-purpose learnable physics engine, which enables a robot to predict the effects of its actions in scenes containing groups of articulated multi-part objects. Specifically, our framework extends recently proposed propagation networks (PropNets) and consists of two complementary components, a physics predictor and a belief regulator. While the former predicts the future states of the object(s) manipulated by the robot, the latter constantly corrects the robot's knowledge regarding the objects and their relations. Our results showed that after training in a simulator, the robot can reliably predict the consequences of its actions in object trajectory level and exploit its own interaction experience to correct its belief about the state of the environment, enabling better predictions in partially observable environments. Furthermore, the trained model was transferred to the real world and verified in predicting trajectories of pushed interacting objects whose joint relations were initially unknown. We compared BRDPN against PropNets, and showed that BRDPN performs consistently well. Moreover, BRDPN can adapt its physic predictions, since the relations can be predicted online.


Title: Environment Prediction from Sparse Samples for Robotic Information Gathering
Key Words: handwritten character recognition  learning (artificial intelligence)  mobile robots  neural net architecture  robot vision  environment prediction  sparse samples  robotics applications  neural network architecture  spatially correlated data fields  spatially continuous samples  biased loss functions  reconstruction error  robotic information gathering trials  MNIST hand written digits dataset  ocean monitoring  regional ocean modeling system ocean dataset  ROMS  Robots  Data models  Oceans  Neural networks  Convolution  Network architecture  Logic gates 
Abstract: Robots often require a model of their environment to make informed decisions. In unknown environments, the ability to infer the value of a data field from a limited number of samples is essential to many robotics applications. In this work, we propose a neural network architecture to model these spatially correlated data fields based on a limited number of spatially continuous samples. Additionally, we provide a method based on biased loss functions to suggest future areas of exploration to minimize reconstruction error. We run simulated robotic information gathering trials on both the MNIST hand written digits dataset and a Regional Ocean Modeling System (ROMS) ocean dataset for ocean monitoring. Our method outperforms Gaussian process regression in both environments for modeling the data field and action selection.


Title: Predicting Pushing Action Effects on Spatial Object Relations by Learning Internal Prediction Models
Key Words: graph theory  humanoid robots  learning (artificial intelligence)  manipulators  spatial object relations  learning internal prediction models  robot tasks  possible action consequences  action parameters  desired goal states  parametrizing pushing actions  high-level planner  object-centric graphs  synthetic data set  goal state  possible pushing action candidates  high prediction accuracy  humanoid robot ARMAR-6  learned internal model  pushing action effects  Predictive models  Two dimensional displays  Robots  Data models  Physics  Three-dimensional displays  Analytical models 
Abstract: Understanding the effects of actions is essential for planning and executing robot tasks. By imagining possible action consequences, a robot can choose specific action parameters to achieve desired goal states. We present an approach for parametrizing pushing actions based on learning internal prediction models. These pushing actions must fulfill constraints given by a high-level planner, e. g., after the push the brown box must be to the right of the orange box. In this work, we represent the perceived scenes as object-centric graphs and learn an internal model, which predicts object pose changes due to pushing actions. We train this internal model on a large synthetic data set, which was generated in simulation, and record a smaller data set on the real robot for evaluation. For a given scene and goal state, the robot generates a set of possible pushing action candidates by sampling the parameter space and then evaluating the candidates by internal simulation, i. e., by comparing the predicted effect resulting from the internal model with the desired effect provided by the high-level planner. In the evaluation, we show that our model achieves high prediction accuracy in scenes with a varying number of objects and, in contrast to state-of-the-art approaches, is able to generalize to scenes with more objects than seen during training. In experiments on the humanoid robot ARMAR-6, we validate the transfer from simulation and show that the learned internal model can be used to manipulate scenes into desired states effectively.


Title: EVDodgeNet: Deep Dynamic Obstacle Dodging with Event Cameras
Key Words: cameras  collision avoidance  control engineering computing  helicopters  learning (artificial intelligence)  neural nets  object detection  robot vision  deep dynamic obstacle dodging  dynamic obstacle avoidance  quadrotor  deep learning  single event camera  shallow neural networks  ego-motion  low light testing scenario  EVDodgeNet  Cameras  Collision avoidance  Motion segmentation  Machine learning  Optical imaging  Robot vision systems  Image segmentation 
Abstract: Dynamic obstacle avoidance on quadrotors requires low latency. A class of sensors that are particularly suitable for such scenarios are event cameras. In this paper, we present a deep learning based solution for dodging multiple dynamic obstacles on a quadrotor with a single event camera and on-board computation. Our approach uses a series of shallow neural networks for estimating both the ego-motion and the motion of independently moving objects. The networks are trained in simulation and directly transfer to the real world without any fine-tuning or retraining. We successfully evaluate and demonstrate the proposed approach in many real-world experiments with obstacles of different shapes and sizes, achieving an overall success rate of 70% including objects of unknown shape and a low light testing scenario. To our knowledge, this is the first deep learning - based solution to the problem of dynamic obstacle avoidance using event cameras on a quadrotor. Finally, we also extend our work to the pursuit task by merely reversing the control policy, proving that our navigation stack can cater to different scenarios.


Title: Dynamic Actor-Advisor Programming for Scalable Safe Reinforcement Learning
Key Words: learning (artificial intelligence)  mobile robots  scalable safe reinforcement learning  real-world robots  complex strict constraints  safe reinforcement learning algorithms  high-dimensional systems  DAAP  sample efficiency  dynamic actor-advisor programming  dynamic policy programming framework  constraint violation risk  Dynamic programming  Programming  Robots  Learning (artificial intelligence)  Heuristic algorithms  Task analysis  Training 
Abstract: Real-world robots have complex strict constraints. Therefore, safe reinforcement learning algorithms that can simultaneously minimize the total cost and the risk of constraint violation are crucial. However, almost no algorithms exist that can scale to high-dimensional systems to the best of our knowledge. In this paper, we propose Dynamic Actor-Advisor Programming (DAAP), as an algorithm for sample-efficient and scalable safe reinforcement learning. DAAP employs two control policies, actor and advisor. They are updated to minimize total cost and risk of constraint violation intertwiningly and smoothly towards each other's direction by using the other as the baseline policy in the Kullback-Leibler divergence of Dynamic Policy Programming framework. We demonstrate the scalability and sample efficiency of DAAP through its application on simulated robot arm control tasks with performance comparisons to baselines.


Title: Discrete Deep Reinforcement Learning for Mapless Navigation
Key Words: discrete systems  gradient methods  learning (artificial intelligence)  mobile robots  navigation  optimisation  state-space methods  mapless navigation  discrete state space algorithms  continuous alternatives  double deep Q-network  parallel asynchronous training  training time  proximal policy optimization algorithms  original discrete algorithm  continuous algorithms  continuous deep deterministic policy gradient  multibatch priority experience replay  discrete deep reinforcement  Training  Navigation  Robot kinematics  Robot sensing systems  Optimization  Machine learning 
Abstract: Our goal is to investigate whether discrete state space algorithms are a viable solution to continuous alternatives for mapless navigation. To this end we present an approach based on Double Deep Q-Network and employ parallel asynchronous training and a multi-batch Priority Experience Replay to reduce the training time. Experiments show that our method trains faster and outperforms both the continuous Deep Deterministic Policy Gradient and Proximal Policy Optimization algorithms. Moreover, we train the models in a custom environment built on the recent Unity learning toolkit and show that they can be exported on the TurtleBot3 simulator and to the real robot without further training. Overall our optimized method is 40% faster compared to the original discrete algorithm. This setting significantly reduces the training times with respect to the continuous algorithms, maintaining a similar level of success rate hence being a viable alternative for mapless navigation.


Title: Learning Multi-Robot Decentralized Macro-Action-Based Policies via a Centralized Q-Net
Key Words: decentralised control  learning (artificial intelligence)  mobile robots  multi-agent systems  multi-robot systems  recurrent neural nets  multirobot decentralized macro-action-based policies  centralized Q-net  decentralized control  decentralized multiagent reinforcement learning  decentralized Q-net  decentralized exploration  macro-action based decentralized multiagent double deep recurrent Q-net  Parallel-MacDec-MADDRQN  Robot kinematics  Training  Tools  Task analysis  Machine learning  History 
Abstract: In many real-world multi-robot tasks, high-quality solutions often require a team of robots to perform asynchronous actions under decentralized control. Decentralized multi-agent reinforcement learning methods have difficulty learning decentralized policies because of the environment appearing to be non-stationary due to other agents also learning at the same time. In this paper, we address this challenge by proposing a macro-action-based decentralized multi-agent double deep recurrent Q-net (MacDec-MADDRQN) which trains each decentralized Q-net using a centralized Q-net for action selection. A generalized version of MacDec-MADDRQN with two separate training environments, called Parallel-MacDec-MADDRQN, is also presented to leverage either centralized or decentralized exploration. The advantages and the practical nature of our methods are demonstrated by achieving near-centralized results in simulation and having real robots accomplish a warehouse tool delivery task in an efficient way.


Title: Informative Path Planning for Active Field Mapping under Localization Uncertainty
Key Words: Gaussian processes  mobile robots  path planning  informative path planning  active field mapping  localization uncertainty  information gathering algorithms  efficient data collection  fundamental problem  implicit requirement  high-quality maps  informative planning framework  active mapping  Gaussian process model  target environmental field  utility function  field mapping objectives  GP-based mapping scenarios  mean pose uncertainty  map error  indoor temperature mapping scenario  Uncertainty  Planning  Robot sensing systems  Trajectory  Manuals  Robot localization 
Abstract: Information gathering algorithms play a key role in unlocking the potential of robots for efficient data collection in a wide range of applications. However, most existing strategies neglect the fundamental problem of the robot pose uncertainty, which is an implicit requirement for creating robust, high-quality maps. To address this issue, we introduce an informative planning framework for active mapping that explicitly accounts for the pose uncertainty in both the mapping and planning tasks. Our strategy exploits a Gaussian Process (GP) model to capture a target environmental field given the uncertainty on its inputs. For planning, we formulate a new utility function that couples the localization and field mapping objectives in GP-based mapping scenarios in a principled way, without relying on manually-tuned parameters. Extensive simulations show that our approach outperforms existing strategies, reducing mean pose uncertainty and map error. We present a proof of concept in an indoor temperature mapping scenario.


Title: DISCO: Double Likelihood-free Inference Stochastic Control
Key Words: Bayes methods  control system synthesis  differential equations  Monte Carlo methods  predictive control  probability  robust control  sampling methods  stochastic systems  transforms  uncertain systems  double likelihood-free inference stochastic control  complex physical systems  control strategies  analytical tractability  probabilistic inference  simulation parameters  likelihood function  modern simulators  nonanalytical model  classical control  model parameters  DISCO  differential equations  numerical solvers  uncertainty assessment  Bayesian statistics  likelihood-free inference  control framework design  unscented transform  information theoretical model predictive control  Monte Carlo sampling  robotics tasks  posterior distribution  Uncertainty  Trajectory  Mathematical model  Computational modeling  Numerical models  Stochastic processes  Cost function 
Abstract: Accurate simulation of complex physical systems enables the development, testing, and certification of control strategies before they are deployed into the real systems. As simulators become more advanced, the analytical tractability of the differential equations and associated numerical solvers incorporated in the simulations diminishes, making them difficult to analyse. A potential solution is the use of probabilistic inference to assess the uncertainty of the simulation parameters given real observations of the system. Unfortunately the likelihood function required for inference is generally expensive to compute or totally intractable. In this paper we propose to leverage the power of modern simulators and recent techniques in Bayesian statistics for likelihood-free inference to design a control framework that is efficient and robust with respect to the uncertainty over simulation parameters. The posterior distribution over simulation parameters is propagated through a potentially non-analytical model of the system with the unscented transform, and a variant of the information theoretical model predictive control. This approach provides a more efficient way to evaluate trajectory roll outs than Monte Carlo sampling, reducing the online computation burden. Experiments show that the controller proposed attained superior performance and robustness on classical control and robotics tasks when compared to models not accounting for the uncertainty over model parameters.


Title: Sufficiently Accurate Model Learning
Key Words: learning (artificial intelligence)  control algorithms  primal-dual method  sufficiently accurate models  traditional control  error characteristics  inaccurate physical measurements  planning algorithms  robot  accurate model learning  Task analysis  Optimization  Data models  Adaptation models  Heuristic algorithms  Neural networks  Planning 
Abstract: Modeling how a robot interacts with the environment around it is an important prerequisite for designing control and planning algorithms. In fact, the performance of controllers and planners is highly dependent on the quality of the model. One popular approach is to learn data driven models in order to compensate for inaccurate physical measurements and to adapt to systems that evolve over time. In this paper, we investigate a method to regularize model learning techniques to provide better error characteristics for traditional control and planning algorithms. This work proposes learning "Sufficiently Accurate" models of dynamics using a primal-dual method that can explicitly enforce constraints on the error in pre-defined parts of the state-space. The result of this method is that the error characteristics of the learned model is more predictable and can be better utilized by planning and control algorithms. The characteristics of Sufficiently Accurate models are analyzed through experiments on a simulated ball paddle system.


Title: Towards Plan Transformations for Real-World Mobile Fetch and Place
Key Words: manipulators  mobile robots  path planning  service robots  cleaning tasks  mobile manipulation plans  plan transformations  mobile fetch and place  robot behavior  table setting tasks  Task analysis  Planning  Runtime  Manipulators  Transforms  Complexity theory 
Abstract: In this paper, we present an approach and an implemented framework for applying plan transformations to real-world mobile manipulation plans, in order to specialize them to the specific situation at hand. The framework can improve execution cost and achieve better performance by autonomously transforming robot's behavior at runtime. To demonstrate the feasibility of our approach, we apply three example transformations to the plan of a PR2 robot performing simple table setting and cleaning tasks in the real world. Based on a large amount of experiments in a fast plan projection simulator, we make conclusions on improved execution performance.


Title: Linear Time-Varying MPC for Nonprehensile Object Manipulation with a Nonholonomic Mobile Robot
Key Words: collision avoidance  friction  linear systems  manipulators  mobile robots  motion control  predictive control  time-varying systems  trajectory control  wheels  linear time-varying MPC  nonprehensile object manipulation  nonholonomic mobile robot  nonprehensile manipulation motion primitive  unilateral constraint  manipulated object  linear time-varying model predictive control  pushing manipulation  Mobile robots  Friction  Task analysis  Dynamics  Mathematical model  Force 
Abstract: This paper proposes a technique to manipulate an object with a nonholonomic mobile robot by pushing, which is a nonprehensile manipulation motion primitive. Such a primitive involves unilateral constraints associated with the friction between the robot and the manipulated object. Violating this constraint produces the slippage of the object during the manipulation, preventing the correct achievement of the task. A linear time-varying model predictive control is designed to include the unilateral constraint within the control action properly. The approach is verified in a dynamic simulation environment through a Pioneer 3-DX wheeled robot executing the pushing manipulation of a package.


Title: RAVEN-S: Design and Simulation of a Robot for Teleoperated Microgravity Rodent Dissection Under Time Delay
Key Words: aerospace instrumentation  biocontrol  manipulators  medical robotics  mobile robots  space research  space vehicles  surgery  telerobotics  zero gravity experiments  teleoperated Microgravity Rodent dissection  International Space Station  ISS  biological effects  spaceflight  Rodent Habitat  Microgravity Science Glovebox  teleoperation  RAVEN II  rudimentary interaction force estimation  onboard dissection robot  RAVEN-S prototype design  communications time delay  robot design  robot simulation  Tools  Task analysis  Rodents  Delay effects  Delays  Force  Robots 
Abstract: The International Space Station (ISS) serves as a research lab for a wide variety of experiments including some that study the biological effects of microgravity and spaceflight using the Rodent Habitat and Microgravity Science Glovebox (MSG). Astronauts train for onboard dissections of rodents following basic training. An alternative approach for conducting these experiments is teleoperation of a robot located on the ISS from earth by a scientist who is proficient in rodent dissection. This pilot study addresses (1) the effects of extreme time delay on skill degradation during Fundamentals of Laparoscopic Surgery (FLS) tasks and rodent dissections using RAVEN II; (2) derivation and testing of rudimentary interaction force estimation; (3) elicitation of design requirements for an onboard dissection robot, RAVEN-S; and (4) simulation of the RAVEN-S prototype design with dissection data. The results indicate that the tasks' completion times increased by a factor of up to 9 for a 3 s time delay while performing manipulation and cutting tasks (FLS model) and by a factor of up to 3 for a 0.75 s time delay during mouse dissection tasks (animal model). Average robot forces/torques of 14N/0.1Nm (peak 90N/0.75Nm) were measured along with average linear/angular velocities of 0.02m/s/4rad/s (peak 0.1m/s/40rad/s) during dissection. A triangular configuration of three arms with respect to the operation site showed the best configuration given the MSG geometry and the dissection tasks. In conclusion, the results confirm the feasibility of utilizing a surgically-inspired RAVEN-S robot for teleoperated rodent dissection for successful completion of the predefined tasks in the presence of communications time delay between the ISS and ground control.


Title: Collision-free Navigation of Human-centered Robots via Markov Games
Key Words: collision avoidance  learning (artificial intelligence)  Markov processes  mobile robots  multi-agent systems  multi-robot systems  collision-free navigation  human-centered robots  Markov games  robot navigation  single-agent Markov decision process  static environment  multiagent formulation  primary agent  remaining auxiliary agents  path-following type adversarial training strategy  robust decentralized collision avoidance policy  real-world mobile robots  Collision avoidance  Robots  Markov processes  Navigation  Games  Robustness  Training  Collision-free navigation  human-centered robotics  deep reinforcement learning  multi-agent system  adversarial training 
Abstract: We exploit Markov games as a framework for collision-free navigation of human-centered robots. Unlike the classical methods which formulate robot navigation as a single-agent Markov decision process with a static environment, our framework of Markov games adopts a multi-agent formulation with one primary agent representing the robot and the remaining auxiliary agents form a dynamic or even competing environment. Such a framework allows us to develop a path-following type adversarial training strategy to learn a robust decentralized collision avoidance policy. Through thorough experiments on both simulated and real-world mobile robots, we show that the learnt policy outperforms the state-of-the-art algorithms in both sample complexity and runtime robustness.


Title: DenseCAvoid: Real-time Navigation in Dense Crowds using Anticipatory Behaviors
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  pedestrians  trajectory control  DenseCAvoid  real-time navigation  dense crowds  anticipatory behaviors  pedestrian behaviors  visual sensors  pedestrian trajectory prediction algorithm  input frames  compute bounding boxes  pedestrian positions  future time  hybrid approach  deep reinforcement learning-based collision avoidance method  robust trajectories  static scenarios  dynamic scenarios  multiple pedestrians  robot freezing  trajectory lengths  mean arrival times  Collision avoidance  Navigation  Trajectory  Robot sensing systems  Robustness  Tracking 
Abstract: We present DenseCAvoid, a novel algorithm for navigating a robot through dense crowds and avoiding collisions by anticipating pedestrian behaviors. Our formulation uses visual sensors and a pedestrian trajectory prediction algorithm to track pedestrians in a set of input frames and compute bounding boxes that extrapolate to the pedestrian positions in a future time. Our hybrid approach combines this trajectory prediction with a Deep Reinforcement Learning-based collision avoidance method to train a policy to generate smoother, safer, and more robust trajectories during run-time. We train our policy in realistic 3-D simulations of static and dynamic scenarios with multiple pedestrians. In practice, our hybrid approach generalizes well to unseen, real-world scenarios and can navigate a robot through dense crowds (~1-2 humans per square meter) in indoor scenarios, including narrow corridors and lobbies. As compared to cases where prediction was not used, we observe that our method reduces the occurrence of the robot freezing in a crowd by up to 48%, and performs comparably with respect to trajectory lengths and mean arrival times to goal.


Title: DeepCrashTest: Turning Dashcam Videos into Virtual Crash Tests for Automated Driving Systems
Key Words: cameras  Internet  public domain software  road safety  road vehicles  traffic engineering computing  video signal processing  real-world collision scenarios  autonomous vehicles  uncalibrated monocular camera source  DeepCrashTest  virtual crash tests  automated driving systems  dashcam crash videos  3D vehicle trajectories  open-source implementation  Internet  Three-dimensional displays  Trajectory  Cameras  Videos  Tracking  Vehicle crash testing  Data mining 
Abstract: The goal of this paper is to generate simulations with real-world collision scenarios for training and testing autonomous vehicles. We use numerous dashcam crash videos uploaded on the internet to extract valuable collision data and recreate the crash scenarios in a simulator. We tackle the problem of extracting 3D vehicle trajectories from videos recorded by an unknown and uncalibrated monocular camera source using a modular approach. A working architecture and demonstration videos along with the open-source implementation are provided with the paper.


Title: Efficient Planning for High-Speed MAV Flight in Unknown Environments Using Online Sparse Topological Graphs
Key Words: aerospace navigation  air safety  autonomous aerial vehicles  collision avoidance  graph theory  infinite horizon  microrobots  mobile robots  probability  robot vision  search problems  high-speed MAV flight  online sparse topological graphs  safe high-speed autonomous navigation  local planning grid  computationally-efficient planning architecture  safe high-speed operation  longer-term memory  motion primitive-based local receding horizon planner  memory-efficient sparse topological graph  planning system  complex simulation environments  robot decision making  probabilistic collision avoidance  safe rerouting  Planning  Collision avoidance  Robot sensing systems  Libraries  Safety  Trajectory 
Abstract: Safe high-speed autonomous navigation for MAVs in unknown environments requires fast planning to enable the robot to adapt and react quickly to incoming information about obstacles within the world. Furthermore, when operating in environments not known a priori, the robot may make decisions that lead to dead ends, necessitating global replanning through a map of the environment outside of a local planning grid. This work proposes a computationally-efficient planning architecture for safe high-speed operation in unknown environments that incorporates a notion of longer-term memory into the planner enabling the robot to accurately plan to locations no longer contained within a local map. A motion primitive-based local receding horizon planner that uses a probabilistic collision avoidance methodology enables the robot to generate safe plans at fast replan rates. To provide global guidance, a memory-efficient sparse topological graph is created online from a time history of the robot's path and a geometric notion of visibility within the environment to search for alternate pathways towards the desired goal if a dead end is encountered. The safety and performance of the proposed planning system is evaluated at speeds up to 10m/s, and the approach is tested in a set of large-scale, complex simulation environments containing dead ends. These scenarios lead to failure cases for competing methods; however, the proposed approach enables the robot to safely reroute and reach the desired goal.


Title: Iterator-Based Temporal Logic Task Planning
Key Words: autonomous aerial vehicles  control system synthesis  discrete event systems  mobile robots  path planning  temporal logic  task specifications  universally quantified locations  constant time  hybrid control  discrete event controller  synthesised plan  iterator-based temporal logic task planning  robotic systems  state explosion  discrete locations  fixed-wing unmanned aerial vehicle  Task analysis  Robot sensing systems  Planning  Fires  Unmanned aerial vehicles 
Abstract: Temporal logic task planning for robotic systems suffers from state explosion when specifications involve large numbers of discrete locations. We provide a novel approach, particularly suited for task specifications with universally quantified locations, that has constant time with respect to the number of locations, enabling synthesis of plans for an arbitrary number of them. We propose a hybrid control framework that uses an iterator to manage the discretised workspace hiding it from a plan enacted by a discrete event controller. A downside of our approach is that it incurs in increased overhead when executing a synthesised plan. We demonstrate that the overhead is reasonable for missions of a fixed-wing Unmanned Aerial Vehicle in simulated and real scenarios for up to 700000 locations.


Title: Reactive Temporal Logic Planning for Multiple Robots in Unknown Environments
Key Words: mobile robots  multi-robot systems  path planning  robot dynamics  temporal logic  multiple robots  reactive mission  unknown environment  temporal logic planning approaches  robot dynamics  known environments  abstraction-free LTL planning algorithm  complex mission planning  complex planning tasks  co-safe linear temporal logic formulas  reactive temporal logic planning  Robot sensing systems  Planning  Task analysis  Heuristic algorithms  Automata 
Abstract: This paper proposes a new reactive mission planning algorithm for multiple robots that operate in unknown environments. The robots are equipped with individual sensors that allow them to collectively learn and continuously update a map of the unknown environment. The goal of the robots is to accomplish complex tasks, captured by global co-safe Linear Temporal Logic (LTL) formulas. The majority of existing temporal logic planning approaches rely on discrete abstractions of the robot dynamics operating in known environments and, as a result, they cannot be applied to the more realistic scenarios where the environment is initially unknown. In this paper, we address this novel challenge by proposing the first reactive, and abstraction-free LTL planning algorithm that can be applied for complex mission planning of multiple robots operating in unknown environments. Our algorithm is reactive in the sense that temporal logic planning is adapting to the updated map of the environment and abstraction-free as it does not rely on designing abstractions of robot dynamics. Our proposed algorithm is complete under mild assumptions on the structure of the environment and the sensor models. Our paper provides extensive numerical simulations and hardware experiments that illustrate the theoretical analysis and show that the proposed algorithm can address complex planning tasks in unknown environments.


Title: Online Grasp Plan Refinement for Reducing Defects During Robotic Layup of Composite Prepreg Sheets
Key Words: dexterous manipulators  Gaussian processes  path planning  quality control  regression analysis  sheet materials  online grasp plan refinement  robotic layup  composite prepreg  high-performance composites  sheet layup  composite components  deformable sheets  robotic cell  layup process  manual layup  online refinement  environmental factors  Gaussian process regression model offline  grasp plans  GPR  Trajectory  Grasping  Grippers  Robot sensing systems  Computational modeling  Service robots 
Abstract: High-performance composites are increasingly being used in the industry. Sheet layup is a process of manufacturing composite components using deformable sheets. We have developed a robotic cell to automate the layup process and overcome the limitations of the manual layup. Generating offline trajectories for robots and executing them without online refinement can introduce defects in the process due to uncertainties in the model of the sheet and environmental factors. Our system computes layup and grasping trajectories for the robots and refines them during the layup process based on the sensor data. We use an approach that augments physical experiments with simulations to train a Gaussian process regression model offline. The use of GPR enables us to quickly refine grasp plans and perform a defect-free layup without slowing down the layup process. We present experimental results on two components.


