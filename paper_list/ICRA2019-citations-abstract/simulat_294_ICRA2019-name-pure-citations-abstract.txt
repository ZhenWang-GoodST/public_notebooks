total paper: 294
Title: Trajectory-based Probabilistic Policy Gradient for Learning Locomotion Behaviors
Key Words: control engineering computing  gradient methods  learning (artificial intelligence)  legged locomotion  probability  robot programming  moderate sample complexity  trajectory-based probabilistic policy gradient  trajectory-based reinforcement learning method  deep latent policy gradient  DLPG  policy function  probability distribution  deep latent variable model  curriculum learning  locomotion skills  Snapbot  four-legged walking robot  Trajectory  Legged locomotion  Task analysis  Gradient methods  Stochastic processes  Training 
Abstract: In this paper, we propose a trajectory-based reinforcement learning method named deep latent policy gradient (DLPG) for learning locomotion skills. We define the policy function as a probability distribution over trajectories and train the policy using a deep latent variable model to achieve sample efficient skill learning. We first evaluate the sample efficiency of DLPG compared to the state-of-the-art reinforcement learning methods in simulated environments. Then, we apply the proposed method to a four-legged walking robot named Snapbot to learn three basic locomotion skills of turn left, go straight, and turn right. We demonstrate that, by properly designing two reward functions for curriculum learning, Snapbot successfully learns the desired locomotion skills with moderate sample complexity.


Title: BaRC: Backward Reachability Curriculum for Robotic Reinforcement Learning
Key Words: learning (artificial intelligence)  Markov processes  optimisation  path planning  robots  BaRC  initial state distribution backwards  model-free RL algorithm  goal-directed continuous control MDPs  curriculum strategy  representative dynamic robotic learning problems  goal-directed tasks  learning signal  model-free policy optimization algorithm  backward reachability curriculum  curriculum generation techniques  robotic reinforcement learning  model-free reinforcement learning  model-free algorithms  reward function  exploration strategies  Robots  Task analysis  Training  Computational modeling  Heuristic algorithms  Complexity theory  Approximation algorithms 
Abstract: Model-free Reinforcement Learning (RL) offers an attractive approach to learn control policies for high dimensional systems, but its relatively poor sample complexity often necessitates training in simulated environments. Even in simulation, goal-directed tasks whose natural reward function is sparse remain intractable for state-of-the-art model-free algorithms for continuous control. The bottleneck in these tasks is the prohibitive amount of exploration required to obtain a learning signal from the initial state of the system. In this work, we leverage physical priors in the form of an approximate system dynamics model to design a curriculum for a model-free policy optimization algorithm. Our Backward Reachability Curriculum (BaRC) begins policy training from states that require a small number of actions to accomplish the task, and expands the initial state distribution backwards in a dynamically-consistent manner once the policy optimization algorithm demonstrates sufficient performance. BaRC is general, in that it can accelerate training of any model-free RL algorithm on a broad class of goal-directed continuous control MDPs. Its curriculum strategy is physically intuitive, easy-to-tune, and allows incorporating physical priors to accelerate training without hindering the performance, flexibility, and applicability of the model-free RL algorithm. We evaluate our approach on two representative dynamic robotic learning problems and find substantial performance improvement relative to previous curriculum generation techniques and naive exploration strategies.


Title: Active Sampling based Safe Identification of Dynamical Systems using Extreme Learning Machines and Barrier Certificates
Key Words: cyber-physical systems  feedforward neural nets  function approximation  Gaussian processes  learning (artificial intelligence)  manipulators  nonlinear dynamical systems  optimisation  robot programming  dynamical system model  robot learning applications  cyber-physical systems  model learning method  ELM learning  invariance property  invariant trajectories  barrier certificates  parameter learning problem  active sampling based safe identification  extreme learning machines  infinite constraint problem  robot arm  barrier constraints  Robots  Trajectory  Safety  Stability analysis  Heuristic algorithms  Neurons  Convergence 
Abstract: Learning the dynamical system (DS) model from data that preserves dynamical system properties is an important problem in many robot learning applications. Typically, the joint data coming from cyber-physical systems, such as robots have some underlying DS properties associated with it, e.g., convergence, invariance to a set, etc. In this paper, a model learning method is developed such that the trajectories of the DS are invariant in a given compact set. Such invariant DS models can be used to generate trajectories of the robot that will always remain in a prescribed set. In order to achieve invariance to a set, Barrier certificates are employed. The DS is approximated using Extreme Learning Machine (ELM), and a parameter learning problem subject to Barrier certificates enforced at all the points in the prescribed set is solved. To solve an infinite constraint problem for enforcing Barrier Certificates at every point in a given compact set, a modified constraint is developed that is sufficient to hold the Barrier certificates in the entire set. An active sampling strategy is formulated to minimize the number of constraints in learning. Simulation results of ELM learning with and without Barrier certificates are presented which show the invariance property being preserved in the ELM learning when learning procedure involves Barrier constraints. The method is validated using experiments conducted on a robot arm recreating invariant trajectories inside a prescribed set.


Title: Navigating Dynamically Unknown Environments Leveraging Past Experience
Key Words: adaptive control  collision avoidance  mobile robots  navigation  autonomous robot navigation  unknown dynamic obstacles  real-time adaptive motion planner  robot motion online  sensed environmental data  limited sensing range  RAMP framework  probabilistic model  unknown dynamic environment  sensing information  RAMP robot  dynamic environment changes  unknown ways  learned probabilistic data  Hilbert maps framework  dynamically unknown environment navigation  Robot sensing systems  Trajectory  Sociology  Statistics  Planning 
Abstract: To enable autonomous robot navigation among unknown dynamic obstacles, a real-time adaptive motion planner (RAMP) plans the robot motion online based on sensing the environment as the robot moves with sensors mounted on the robot. However, the sensed environmental data from the robot's local view is usually incomplete due to occlusions from obstacles and limited sensing range.This paper incorporates learning about the environment into the RAMP framework by leveraging the Hilbert Maps framework to generate a probabilistic model of occupancy of the unknown dynamic environment based on past observations. Utilizing this probabilistic model enables RAMP to reason about trajectory fitness when sensing information is partial and incomplete. This allows the RAMP robot to take advantage of what it has experienced from being in the dynamic environment before to inform its subsequent executions even though the dynamic environment changes in unknown ways. The effectiveness of incorporating such learned probabilistic data into RAMP is shown in both simulation and real experiments.


Title: VPE: Variational Policy Embedding for Transfer Reinforcement Learning
Key Words: learning (artificial intelligence)  Markov processes  pendulums  variational techniques  variational policy embedding  transfer reinforcement Learning  complex problems  deployment conditions  data collection  simulation training  Q-function  master policy  latent variables  latent space  low-dimensional space  simulation-to-real transfer  reinforcement learning methods  Markov decision processes  Optimization  Training  Task analysis  Robots  Adaptation models  Reinforcement learning  Supervised learning 
Abstract: Reinforcement Learning methods are capable of solving complex problems, but resulting policies might perform poorly in environments that are even slightly different. In robotics especially, training and deployment conditions often vary and data collection is expensive, making retraining undesirable. Simulation training allows for feasible training times, but on the other hand suffer from a reality-gap when applied in real-world settings. This raises the need of efficient adaptation of policies acting in new environments.We consider the problem of transferring knowledge within a family of similar Markov decision processes. We assume that Q-functions are generated by some low-dimensional latent variable. Given such a Q-function, we can find a master policy that can adapt given different values of this latent variable. Our method learns both the generative mapping and an approximate posterior of the latent variables, enabling identification of policies for new tasks by searching only in the latent space, rather than the space of all policies. The low-dimensional space, and master policy found by our method enables policies to quickly adapt to new environments. We demonstrate the method on both a pendulum swing-up task in simulation, and for simulation-to-real transfer on a pushing task.


Title: Design and Characterization of a Novel Robotic Surface for Application to Compressed Physical Environments *
Key Words: biomechanics  design engineering  mobile robots  compressed physical environments  robot arms  robot surface  compliant surfaces  habitable space  physical space  tendon-driven robotic surface  herringbone pattern  3D-printed panels  Prototypes  Service robots  Springs  Surface treatment  Robot kinematics  Surface waves 
Abstract: Developments of robot arms are countless, but there has been little focus on robot surfaces for the reshaping of a habitable space - especially compliant surfaces. In this paper we introduce a novel, tendon-driven, robot surface comprised of aggregated, overlapping panels organized in a herringbone pattern. The individual 3D-printed panels and their behavior as an aggregation are inspired by the form and behavior of a pinecone. This paper presents our concept, design, and realization of this robot, and compares our prototype to simulations of four physical configurations that are formally distinct and suggestive of how the surface might be applied to habitable, physical space in response to human needs and wants. For the four configurations studied, we found a validating match between prototype and simulations. The paper concludes with a consideration of potential applications for robot surfaces like this one.


Title: Learning Extreme Hummingbird Maneuvers on Flapping Wing Robots
Key Words: aerodynamics  aerospace components  aerospace robotics  aircraft control  control engineering computing  learning (artificial intelligence)  mobile robots  nonlinear control systems  position control  robot dynamics  robot kinematics  stability  extreme aerobatic maneuvers  visual stimulus  180-degree yaw turn  wingbeat frequency  flight control strategy  hybrid control policy  model-based nonlinear control  model-free reinforcement learning policy  hummingbird-like fast evasive maneuvers  extreme hummingbird maneuvers  flapping wing robots  backward translation  posture stabilization  hummingbird robot  frequency 40.0 Hz  time 0.2 s  Aerodynamics  Vehicle dynamics  Uncertainty  Robots  Adaptation models  Torque  Actuators 
Abstract: Biological studies show that hummingbirds can perform extreme aerobatic maneuvers during fast escape. Given a sudden looming visual stimulus at hover, a hummingbird initiates a fast backward translation coupled with a 180-degree yaw turn, which is followed by instant posture stabilization in just under 10 wingbeats. Consider the wingbeat frequency of 40Hz, this aggressive maneuver is carried out in just 0.2 seconds. Inspired by the hummingbirds' near-maximal performance during such extreme maneuvers, we developed a flight control strategy and experimentally demonstrated that such maneuverability can be achieved by an at-scale 12-gram hummingbird robot equipped with just two actuators driving a pair of flapping wings up to 40Hz. The proposed hybrid control policy combines model-based nonlinear control with model-free reinforcement learning. We used the model-based nonlinear control for nominal flight conditions where dynamic models are relatively accurate. During extreme maneuvers when the modeling error becomes unmanageable, we use a model-free reinforcement learning policy trained and optimized in simulation to 'destabilize' the system for peak performance during maneuvering. The hybrid policy manifests a maneuver that is close to that observed in hummingbirds. Direct simulation-to-real transfer is achieved, demonstrating the hummingbird-like fast evasive maneuvers on the at-scale hummingbird robot.


Title: GEN-SLAM: Generative Modeling for Monocular Simultaneous Localization and Mapping
Key Words: cameras  collision avoidance  convolutional neural nets  learning (artificial intelligence)  mobile robots  pose estimation  robot vision  SLAM (robots)  depth estimation system  GEN-SLAM  generative modeling  Deep Learning based system  obstacle avoidance  mobile robot  conventional geometric SLAM  single camera  topological map  camera image  topological location estimation  monocular localization  monocular simultaneous localization and mapping  Cameras  Image reconstruction  Simultaneous localization and mapping  Decoding  Training 
Abstract: We present a Deep Learning based system for the twin tasks of localization and obstacle avoidance essential to any mobile robot. Our system learns from conventional geometric SLAM, and outputs, using a single camera, the topological pose of the camera in an environment, and the depth map of obstacles around it. We use a CNN to localize in a topological map, and a conditional VAE to output depth for a camera image, conditional on this topological location estimation. We demonstrate the effectiveness of our monocular localization and depth estimation system on simulated and real datasets.


Title: On-line 3D active pose-graph SLAM based on key poses using graph topology and sub-maps
Key Words: autonomous aerial vehicles  computational complexity  graph theory  mobile robots  optimisation  path planning  remotely operated vehicles  robot vision  SLAM (robots)  graph topology  pose-graph simultaneous localization  three-dimensional environments  D-optimality metrics  weighted node degree  T-optimality metric  sampling-based path  continuous-time trajectory optimization method  large-scale active SLAM problems  submap joining method  online 3D active pose-graph SLAM  Simultaneous localization and mapping  Measurement  Trajectory  Planning  Three-dimensional displays  Uncertainty 
Abstract: In this paper, we present an on-line active pose-graph simultaneous localization and mapping (SLAM) frame-work for robots in three-dimensional (3D) environments using graph topology and sub-maps. This framework aims to find the best trajectory for loop-closure by re-visiting old poses based on the T-optimality and D-optimality metrics of the Fisher information matrix (FIM) in pose-graph SLAM. In order to reduce computational complexity, graph topologies are introduced, including weighted node degree (T-optimality metric) and weighted tree-connectivity (D-optimality metric), to choose a candidate trajectory and several key poses. With the help of the key poses, a sampling-based path planning method and a continuous-time trajectory optimization method are combined hierarchically and applied in the whole framework. So as to further improve the real-time capability of the method, the sub-map joining method is used in the estimation and planning process for large-scale active SLAM problems. In simulations and experiments, we validate our approach by comparing against existing methods, and we demonstrate the on-line planning part using a quad-rotor unmanned aerial vehicle (UAV).


Title: Modeling and Planning Manipulation in Dynamic Environments
Key Words: collision avoidance  manipulator dynamics  mobile robots  pose estimation  robot vision  steering systems  kinodynamic manipulation planner  dynamic environments  robot dynamics  time-variant environments  manipulation modeling  manipulation planning  online collision avoidance  object pose estimation  steering functions  Planning  Task analysis  Collision avoidance  Manipulator dynamics  Grippers 
Abstract: In this paper we propose a new model for sequential manipulation tasks that also considers robot dynamics and time-variant environments. From this model we automatically derive constraint-based controllers and use them as steering functions in a kinodynamic manipulation planner. The resulting plan is not a trajectory but a sequence of controllers that react online to disturbances. We validated our approach in simulation and on a real robot. In the experiments our approach plans and executes dual-robot manipulation tasks with online collision avoidance and reactions to estimates of object poses.


Title: Efficient Obstacle Rearrangement for Object Manipulation Tasks in Cluttered Environments
Key Words: collision avoidance  computational complexity  manipulators  mobile robots  navigation  object manipulation tasks  cluttered environments  robotic manipulator  constrained confined space  collision-free path  object rearrangement  NP-hard  service domains  collision avoidance scheme  mobile robot navigation  object poses  obstacle rearrangement  polynomial time  Histograms  Planning  Task analysis  Grasping  End effectors 
Abstract: We present an algorithm that produces a plan for relocating obstacles in order to grasp a target in clutter by a robotic manipulator without collisions. We consider configurations where objects are densely populated in a constrained and confined space. Thus, there exists no collision-free path for the manipulator without relocating obstacles. Since the problem of planning for object rearrangement has shown to be NP-hard, it is difficult to perform manipulation tasks efficiently which could frequently happen in service domains (e.g., taking out a target from a shelf or a fridge). Our proposed planner employs a collision avoidance scheme which has been widely used in mobile robot navigation. The planner determines an obstacle to be removed quickly in real time. It also can deal with dynamic changes in the configuration (e.g., changes in object poses). Our method is shown to be complete and runs in polynomial time. Experimental results in a realistic simulated environment show that our method improves up to 31% of the execution time compared to other competitors.


Title: optimization-Based Human-in-the-Loop Manipulation Using Joint Space Polytopes
Key Words: collision avoidance  geometry  manipulator kinematics  mobile robots  optimisation  motion planner  human-in-the-loop manipulation  optimization  robot operation  Cartesian polyhedron  fast collision-free inverse kinematic  joint space polytopes  singular configurations  constrained manipulability polytopes  operator commands  End effectors  Trajectory  Kinematics  Task analysis  Collision avoidance  Aerospace electronics 
Abstract: This paper presents a new method of maximizing the free space for a robot operating in a constrained environment under operator supervision. The objective is to make the resulting trajectories more robust to operator commands and/or changes in the environment. To represent the volume of free space, the constrained manipulability polytopes are used. These polytopes embed the distance to obstacles, the distance to joint limits and the distance to singular configurations. The volume of the resulting Cartesian polyhedron is used in an optimization-based motion planner to create the trajectories. Additionally, we show how fast collision-free inverse kinematic solutions can be obtained by exploiting the pre-computed inequality constraints. The proposed algorithm is validated in simulation and experimentally.


Title: Large-Scale Multi-Object Rearrangement
Key Words: iterative methods  optimisation  robot vision  search problems  robotic tabletop rearrangement system  high packing factor forces  simulated pushing actions  vision system  iterated local search technique  large-scale multiobject rearrangement  Planning  Task analysis  Grasping  Robots  Annealing  Trajectory  Markov processes 
Abstract: This paper describes a new robotic tabletop rearrangement system, and presents experimental results. The tasks involve rearranging as many as 30 to 100 blocks, sometimes packed with a density of up to 40%. The high packing factor forces the system to push several objects at a time, making accurate simulation difficult, if not impossible. Nonetheless, the system achieves goals specifying the pose of every object, with an average precision of ± 1 mm and ± 2°. The system searches through policy rollouts of simulated pushing actions, using an Iterated Local Search technique to escape local minima. In real world execution, the system executes just one action from a policy, then uses a vision system to update the estimated task state, and replans. The system accepts a fully general description of task goals, which means it can solve the singulation and separation problems addressed in prior work, but can also solve sorting problems and spell out words, among other things. The paper includes examples of several solved problems, statistical analysis of the system's behavior on different types of problems, and some discussion of limitations, insights, and future work.


Title: ChevBot – An Untethered Microrobot Powered by Laser for Microfactory Applications
Key Words: displacement measurement  industrial robots  integrated circuit manufacture  laser beam applications  microactuators  micromechanical devices  microrobots  semiconductor technology  silicon-on-insulator  ChevBot  microfactory applications  dry environments  thermal MicroElectro Mechanical actuator  laser light  opto-thermal-mechanical energy conversion  opto-thermal simulation model  static displacement measurements  dynamic extension  directional locomotion  laser power  actuator displacements  locomotion velocity  submillimeter robot  laser beam  untethered microrobot  microrobot designs  silicon on insulator wafer  Laser modes  Actuators  Laser beams  Measurement by laser beam  Power lasers  Silicon  Predictive models 
Abstract: In this paper, we introduce a new class of submillimeter robot (ChevBot) for microfactory applications in dry environments, powered by a 532 nm laser beam. ChevBot is an untethered microrobot propelled by a thermal Micro Electro Mechanical (MEMS) actuator upon exposure to the laser light. Novel models for opto-thermal-mechanical energy conversion are proposed to describe the microrobot's locomotion mechanism. First, an opto-thermal simulation model is presented which is experimentally validated with static displacement measurements with microrobots tethered to the substrate. Then, stick and slip motion of the microrobot was predicted using a dynamic extension of our simulation model, and experiments were conducted to validate this model in one dimension. Promising microrobot designs were fabricated on a silicon on insulator (SOI) wafer with 20 μm device layer and a dimple was assembled at the bottom to initiate directional locomotion on a silicon substrate. Validation experiments demonstrate that exposure to laser power below 2W and repetition frequencies below 60 kHz can generate actuator displacements of a few microns, and 46 μm/s locomotion velocity.


Title: Resolved Viscoelasticity Control Considering Singularity for Knee-stretched Walking of a Humanoid
Key Words: humanoid robots  legged locomotion  motion control  viscoelasticity  task-space  mass viscoelasticity  joint-space viscoelasticity  robust motion  compliant motion  RVC method  kinematic singularity  knee joint torque  RVC capable  humanoid  stable knee-stretched walking  knee-bent posture  resolved viscoelasticity control  Task analysis  Knee  Legged locomotion  Kinematics  Trajectory  Foot  Humanoid robots 
Abstract: This paper describes a stable knee-stretched walking of a humanoid by the resolved viscoelasticity control (RVC). The RVC method resolves multiple viscoelasticities in task-space, including the center of mass viscoelasticity for balancing, into joint-space viscoelasticity. Although a robust and compliant motion was achieved by the RVC method in previous studies, the conventional knee-bent posture to avoid the kinematic singularity suffered large knee joint torque. In this study, we propose an extension of the RVC capable of the kinematic singularity. We demonstrate through simulations and experiments that the RVC method considering the singularity achieves a stable and human-like walking, reducing the knee joint torque and improving the energy efficiency.


Title: Versatile Reactive Bipedal Locomotion Planning Through Hierarchical Optimization
Key Words: control nonlinearities  humanoid robots  legged locomotion  linear systems  motion control  nonlinear control systems  optimisation  path planning  pendulums  predictive control  robot dynamics  step frequency  humanoid robots  hierarchical optimization  angular momentum  nonlinear model predictive control  reactive bipedal locomotion planning  nonlinearities  walking dynamics  step time abilities  step location adjustment  Center of Mass height variation  linear inverted pendulum model  robot gait generation  Legged locomotion  Optimization  Trajectory  Humanoid robots  Linear programming  Dynamics 
Abstract: When experiencing disturbances during locomotion, human beings use several strategies to maintain balance, e.g. changing posture, modulating step frequency and location. However, when it comes to the gait generation for humanoid robots, modifying step time or body posture in real time introduces nonlinearities in the walking dynamics, thus increases the complexity of the planning. In this paper, we propose a two-layer hierarchical optimization framework to address this issue and provide the humanoids with the abilities of step time and step location adjustment, Center of Mass (CoM) height variation and angular momentum adaptation. In the first layer, times and locations of consecutive two steps are modulated online based on the current CoM state using the Linear Inverted Pendulum Model. By introducing new optimization variables to substitute the hyperbolic functions of step time, the derivatives of the objective function and feasibility constraints are analytically derived, thus reduces the computational cost. Then, taking the generated horizontal CoM trajectory, step times and step locations as inputs, CoM height and angular momentum changes are optimized by the second layer nonlinear model predictive control. This whole procedure will be repeated until the termination condition is met. The improved recovery capability under external disturbances is validated in simulation studies.


Title: Using Deep Reinforcement Learning to Learn High-Level Policies on the ATRIAS Biped
Key Words: control system synthesis  learning (artificial intelligence)  legged locomotion  neurocontrollers  deep reinforcement learning  expert knowledge  domain randomization  stable controllers  high-fidelity simulators  neural network policy  ATRIAS robot  bipedal robots  Neural networks  Hardware  Legged locomotion  Reinforcement learning  Torso  Foot 
Abstract: Learning controllers for bipedal robots is a challenging problem, often requiring expert knowledge and extensive tuning of parameters that vary in different situations. Recently, deep reinforcement learning has shown promise at automatically learning controllers for complex systems in simulation. This has been followed by a push towards learning controllers that can be transferred between simulation and hardware, primarily with the use of domain randomization. However, domain randomization can make the problem of finding stable controllers even more challenging, especially for under actuated bipedal robots. In this work, we explore whether policies learned in simulation can be transferred to hardware with the use of high-fidelity simulators and structured controllers. We learn a neural network policy which is a part of a more structured controller. While the neural network is learned in simulation, the rest of the controller stays fixed, and can be tuned by the expert as needed. We show that using this approach can greatly speed up the rate of learning in simulation, as well as enable transfer of policies between simulation and hardware. We present our results on an ATRIAS robot and explore the effect of action spaces and cost functions on the rate of transfer between simulation and hardware. Our results show that structured policies can indeed be learned in simulation and implemented on hardware successfully. This has several advantages, as the structure preserves the intuitive nature of the policy, and the neural network improves the performance of the hand-designed policy. In this way, we propose a way of using neural networks to improve expert designed controllers, while maintaining ease of understanding.


Title: Unsupervised Gait Phase Estimation for Humanoid Robot Walking*
Key Words: data acquisition  data reduction  humanoid robots  legged locomotion  pattern clustering  phase estimation  robot dynamics  robust control  state estimation  unsupervised learning  unsupervised gait phase estimation  humanoid robot walking  contact detection  feet contact status  proprioceptive sensing  inertial measurement unit  data acquisition  dimensionality reduction  state estimation  unsupervised learning  feature representation  gait phase dynamics  joint encoder  force data  torque data  clustering  robustness  legged robots  Legged locomotion  Humanoid robots  Robot sensing systems  Kinematics  Unsupervised learning 
Abstract: Contact detection is an important topic in contemporary humanoid robotic research. Up to date control and state estimation schemes readily assume that feet contact status is known in advance. In this work, we elaborate on a broader question: in which gait phase is the robot currently in? We introduce an unsupervised learning framework for gait phase estimation based solely on proprioceptive sensing, namely joint encoder, inertial measurement unit and force/torque data. Initially, a meaningful physical explanation on data acquisition is presented. Subsequently, dimensionality reduction is performed to obtain a compact low-dimensional feature representation followed by clustering into three groups, one for each gait phase. The proposed framework is qualitatively and quantitatively assessed in simulation with ground-truth data of uneven/rough terrain walking gaits and insights about the latent gait phase dynamics are drawn. Additionally, its efficacy and robustness is demonstrated when incorporated in leg odometry computation. Since our implementation is based on sensing that is commonly available on humanoids today, we release an open-source ROS/Python package to reinforce further research endeavors.


Title: Event-based, Direct Camera Tracking from a Photometric 3D Map using Nonlinear Optimization
Key Words: cameras  image reconstruction  image sensors  maximum likelihood estimation  motion estimation  motion measurement  nonlinear programming  photometry  pose estimation  asynchronous sensors  low power consumption  photometric 3D map  classic dense 3D reconstruction algorithms  bioinspired vision sensors  video imaging  output pixel-level intensity  event-based direct camera tracking  nonlinear optimization  robot localization  AR-VR  6-DOF pose tracking  maximum-likelihood framework  event camera motion estimation  Cameras  Robot vision systems  Three-dimensional displays  Optimization 
Abstract: Event cameras are novel bio-inspired vision sensors that output pixel-level intensity changes, called “events”, instead of traditional video images. These asynchronous sensors naturally respond to motion in the scene with very low latency (microseconds) and have a very high dynamic range. These features, along with a very low power consumption, make event cameras an ideal sensor for fast robot localization and wearable applications, such as AR/VR and gaming. Considering these applications, we present a method to track the 6-DOF pose of an event camera in a known environment, which we contemplate to be described by a photometric 3D map (i.e., intensity plus depth information) built via classic dense 3D reconstruction algorithms. Our approach uses the raw events, directly, without intermediate features, within a maximum-likelihood framework to estimate the camera motion that best explains the events via a generative model. We successfully evaluate the method using both simulated and real data, and show improved results over the state of the art. We release the datasets to the public to foster reproducibility and research in this topic.


Title: Linear Heterogeneous Reconfiguration of Cubic Modular Robots via Simultaneous Tunneling and Permutation
Key Words: computational complexity  control engineering computing  distributed control  evolutionary computation  mobile robots  multi-robot systems  reconfigurable architectures  heterogeneous lattice modular robots  linear operation time cost  2×2×2 cubic meta-module-based connected robot structure  heterogeneous modular robots  linear heterogeneous reconfiguration  cubic modular robots  ordinary heterogeneous reconfiguration  linear homogeneous transformation  linear heterogeneous permutation  simultaneous tunneling and permutation  Tunneling  Computer aided software engineering  Cameras  Robot vision systems  Robot kinematics  Lattices 
Abstract: Reconfiguring heterogeneous modular robots in which all modules are not identical is much more time consuming than reconfiguring homogeneous ones, because ordinary heterogeneous reconfiguration is a combination of homogeneous transformation and heterogeneous permutation. While linear homogeneous transformation has been accomplished in previous research, linear heterogeneous permutation has not. This paper studies a reconfiguration algorithm for heterogeneous lattice modular robots with linear operation time cost. The algorithm is based on simultaneous tunneling and permutation, where a robot transforms its configuration via tunneling motion while permutation of each module's position is performed simultaneously during the tunneling transformation. To achieve this, we introduce the idea of a transparent meta-module that allows modules belonging to a meta-module to pass through the spaces occupied by other meta-modules. We prove the correctness and completeness of the proposed algorithm for a 2×2×2 cubic meta-module-based connected robot structure. We also show examples of the reconfiguration simulations of heterogeneous modular robots by the proposed algorithm.


Title: Autonomous Sheet Pile Driving Robots for Soil Stabilization
Key Words: construction equipment  construction industry  erosion  foundations  geotechnical engineering  hammers (machines)  mobile robots  soil  stability  autonomous sheet pile  soil stabilization  construction projects  environmental restoration projects  autonomous robot  continuous linear structures  vibratory hammer  hardware parameters  spray-based stabilizing agent  hydraulic erosion  Robots  Soil  Task analysis  Dams  Force  Actuators  Automation 
Abstract: Soil stabilization is a fundamental component of nearly all construction projects, ranging from commercial construction to environmental restoration projects. Previous work in autonomous construction has generally not considered these essential stabilization and anchoring tasks. In this work we present Romu, an autonomous robot capable of building continuous linear structures by using a vibratory hammer to drive interlocking sheet piles into soil. We report on hardware parameters and their effects on pile driving performance, and demonstrate autonomous operation in both controlled and natural environments. Finally, we present simulations in which a small swarm of robots build with sheet piles in example terrains, or apply an alternate spray-based stabilizing agent, and quantify the ability of each intervention to mitigate hydraulic erosion.


Title: Robotic endoscopy system (easyEndo) with a robotic arm mountable on a conventional endoscope
Key Words: biological tissues  biomechanics  endoscopes  manipulators  medical robotics  tissue traction  lesion  rubber band  robotic arm  flexible endoscope  robotic manipulations  intuitive hand-held controllers  solo-endoscopy  conventional endoscope  robotic endoscopy system  Endoscopes  Manipulators  Instruments  Medical services  Cameras  Gears 
Abstract: The use of flexible endoscope has been rising inconveniences. Steering of the distal section is not intuitive and the weight of the endoscope burdens a physical pressure on physicians who use it continuously for a long time. Also, the limited dexterity of an instrument makes therapeutic procedures more difficult, and further the unintended communications often occur during cooperation with assistants. These degrade the efficiency and thus increase the procedure time. In this paper, we propose a robotic endoscopy system (easyEndo) that can be mounted on a conventional endoscope and facilitate solo-endoscopy with two intuitive hand-held controllers. Furthermore, a robotic arm is presented that can be attached to the endoscope to assist with tissue traction. To validate the robotic endoscopy system, experiments to simulate biopsy and lesion marking were conducted with novices. The results showed that the robotic manipulations improved efficiency and reduced workload than manual manipulation. Subsequently, a prototype of the robotic arm was attached at the distal end of the endoscope, and the feasibility of tissue traction was confirmed by a simulation of pulling a rubber band.


Title: Vision-based Teleoperation of Shadow Dexterous Hand using End-to-End Deep Neural Network
Key Words: dexterous manipulators  human-robot interaction  image classification  learning (artificial intelligence)  neurocontrollers  pose estimation  robot vision  telerobotics  TeachNet  Shadow dexterous hand  end-to-end deep neural network  intuitive vision-based teleoperation  markerless vision-based teleoperation  dexterous robotic hands  robot joint angles  human hand  visually similar robot hand  consistency loss function  human hands  human-robot training set  labeled depth images  simulated depth images  Shadow C6 robotic hand  pairwise depth images  vision-based teleoperation method  Training  Pose estimation  Three-dimensional displays  Neural networks  Robot sensing systems 
Abstract: In this paper, we present TeachNet, a novel neural network architecture for intuitive and markerless vision-based teleoperation of dexterous robotic hands. Robot joint angles are directly generated from depth images of the human hand that produce visually similar robot hand poses in an end-to-end fashion. The special structure of TeachNet, combined with a consistency loss function, handles the differences in appearance and anatomy between human and robotic hands. A synchronized human-robot training set is generated from an existing dataset of labeled depth images of the human hand and simulated depth images of a robotic hand. The final training set includes 400K pairwise depth images and joint angles of a Shadow C6 robotic hand. The network evaluation results verify the superiority of TeachNet, especially regarding the high-precision condition. Imitation experiments and grasp tasks teleoperated by novice users demonstrate that TeachNet is more reliable and faster than the state-of-the-art vision-based teleoperation method.


Title: Passive Task-Prioritized Shared-Control Teleoperation with Haptic Guidance
Key Words: control engineering computing  haptic interfaces  telerobotics  passive task-prioritized shared-control teleoperation  robot teleoperation  teleoperator capabilities shared-control methods  passive task-prioritized shared-control method  redundant robots  task-prioritized control architecture  haptic guidance techniques  shared-control framework  semiautonomous telerobotic system safety  energy-tanks passivity-based controller  simulated slave robot  Task analysis  Haptic interfaces  Jacobian matrices  Manipulators  Robot kinematics  Couplings 
Abstract: Robot teleoperation is widely used for several hazardous applications. To increase teleoperator capabilities shared-control methods can be employed. In this paper, we present a passive task-prioritized shared-control method for remote telemanipulation of redundant robots. The proposed method fuses the task-prioritized control architecture with haptic guidance techniques to realize a shared-control framework for teleoperation systems. To preserve the semi-autonomous telerobotic system safety, passivity is analyzed and an energy-tanks passivity-based controller is developed. The proposed theoretical results are validated through experiments involving a real haptic device and a simulated slave robot.


Title: Stability Optimization of Two-Fingered Anthropomorphic Hands for Precision Grasping with a Single Actuator
Key Words: actuators  biomechanics  dexterous manipulators  grippers  prosthetics  link length ratios  anthropomorphic design parameters  grasp planning applications  optimal configuration  heuristically evaluated optimal solutions  post-contact system work  upper limb prosthetic design  palm width  joint stiffness ratios  transmission ratios  post-contact stability  constrained optimization framework  single actuator  precision grasping  two-fingered anthropomorphic hands  stability optimization  Force  Grasping  Actuators  Tendons  Optimization  Stability criteria 
Abstract: In this paper, we present a constrained optimization framework for evaluating the post-contact stability of underactuated precision grasping configurations with a single degree of actuation. Relationships between key anthropomorphic design parameters including link length ratios, transmission ratios, joint stiffness ratios and palm width are developed with applications in upper limb prosthetic design. In addition to grasp stability, we examine post-contact system work, to reduce reconfiguration, and consider the range of objects that can be stably grasped. External wrenches were simulated on a subset of the heuristically evaluated optimal solutions and an optimal configuration was experimentally tested to determine favorable wrench resistible gripper orientations for grasp planning applications.


Title: A new Approach for an Adaptive Linear Quadratic Regulated Motion Cueing Algorithm for an 8 DoF Full Motion Driving Simulator
Key Words: linear quadratic control  minimisation  motion control  road vehicles  vehicle dynamics  8 DoF full motion driving simulator  Stuttgart Driving Simulator  state-flow chart  kinematic vehicle movements  motion driving simulator  adaptive motion cueing algorithm  adaptive linear quadratic regulated motion cueing algorithm  linear quadratic error minimization  Acceleration  Switches  Vehicles  Heuristic algorithms  Vehicle dynamics  Kinematics 
Abstract: In this contribution, a new adaptive motion cueing algorithm for a full motion driving simulator at the University of Stuttgart is presented, which allows kinematic vehicle movements to be taken into account. These are adequately processed via a state-flow chart and transferred to the motion cueing algorithm in such a way that the dynamic of the Stuttgart Driving Simulator can be used much more efficiently. Furthermore, a linear quadratic error minimization of the mentioned algorithm is presented. The primary objective is to provide a more realistic driving experience to the driver.


Title: Julia for robotics: simulation and real-time control in a high-level programming language
Key Words: computer simulation  control engineering computing  high level languages  humanoid robots  programming languages  quadratic programming  robot dynamics  robot programming  real-time control  high-level programming language  robotics applications  two-language problem  performance-sensitive components  high-level language  software complexity  Julia programming language  online control  Julia packages  Boston Dynamics Atlas humanoid robot  quadratic-programming-based controller  Robots  Libraries  Software packages  C++ languages  Productivity  Resource management 
Abstract: Robotics applications often suffer from the `two-language problem', requiring a low-level language for performance-sensitive components and a high-level language for interactivity and experimentation, which tends to increase software complexity. We demonstrate the use of the Julia programming language to solve this problem by being fast enough for online control of a humanoid robot and flexible enough for prototyping. We present several Julia packages developed by the authors, which together enable roughly 2× realtime simulation of the Boston Dynamics Atlas humanoid robot balancing on flat ground using a quadratic-programming-based controller. Benchmarks show a sufficiently low variation in control frequency to make deployment on the physical robot feasible. We also show that Julia's naturally generic programming style results in versatile packages that are easy to compose and adapt to a wide variety of computational tasks in robotics.


Title: Robust Object-based SLAM for High-speed Autonomous Navigation
Key Words: cameras  helicopters  image sequences  image texture  mobile robots  object detection  path planning  robot vision  SLAM (robots)  ROSHAN  object-level mapping  ellipsoid-based SLAM  object surface  autonomous quadrotor  bounding box detections  median shape error  forward-moving camera sequence  planar constraint  vehicle motions  semantic knowledge  robust object-based SLAM for high-speed autonomous navigation  Ellipsoids  Image edge detection  Semantics  Simultaneous localization and mapping  Cameras  Shape  Shape measurement 
Abstract: We present Robust Object-based SLAM for High-speed Autonomous Navigation (ROSHAN), a novel approach to object-level mapping suitable for autonomous navigation. In ROSHAN, we represent objects as ellipsoids and infer their parameters using three sources of information - bounding box detections, image texture, and semantic knowledge - to overcome the observability problem in ellipsoid-based SLAM under common forward-translating vehicle motions. Each bounding box provides four planar constraints on an object surface and we add a fifth planar constraint using the texture on the objects along with a semantic prior on the shape of ellipsoids. We demonstrate ROSHAN in simulation where we outperform the baseline, reducing the median shape error by 83% and the median position error by 72% in a forward-moving camera sequence. We demonstrate similar qualitative result on data collected on a fast-moving autonomous quadrotor.


Title: Pose and Posture Estimation of Aerial Skeleton Systems for Outdoor Flying
Key Words: Kalman filters  pose estimation  satellite navigation  outdoor flying  posture estimation framework  system modular  GNSS module  global navigation satellite system  EKF estimates  three-link aerial skeleton system  inertial measurement unit  extended Kalman filtering  Skeleton  Estimation  Kinematics  Global navigation satellite system  Rotors  Kalman filters  Force 
Abstract: We present a novel pose and posture estimation framework of aerial skeleton system for outdoor flying. To exploit redundant/independent sensing while rendering the system “modular”, we attach an IMU (inertial measurement unit) sensor and a GNSS (global navigation satellite system) module on each link and perform SE(3)-motion EKF (extended Kalman filtering). We then apply the kinematic constraints of the aerial skeleton system to these EKF estimates of all the links through SCKF (smoothly constrained Kalman filtering), thereby, enforcing the kinematic coherency of the skeleton system and, consequently, significantly enhancing the estimation accuracy and the control performance/stability of the aerial skeleton system. A semi-distributed version of the obtained estimation framework is also presented to address the issue of scalability. The theory is then verified/demonstrated with real outdoor flying experiments and simulation studies of a three-link aerial skeleton system.


Title: Obstacle-aware Adaptive Informative Path Planning for UAV-based Target Search
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  Gaussian processes  mobile robots  object detection  robot vision  target occupancy  UAV-based target search  Gaussian process based model  flight time constraints  planning strategy  obstacle-aware adaptive informative path planning algorithm  target detection  unmanned aerial vehicles  collision avoidance  Planning  Search problems  Three-dimensional displays  Optimization  Trajectory  Unmanned aerial vehicles  Robot sensing systems 
Abstract: Target search with unmanned aerial vehicles (UAVs) is relevant problem to many scenarios, e.g., search and rescue (SaR). However, a key challenge is planning paths for maximal search efficiency given flight time constraints. To address this, we propose the Obstacle-aware Adaptive Informative Path Planning (OA-IPP) algorithm for target search in cluttered environments using UAVs. Our approach leverages a layered planning strategy using a Gaussian Process (GP)based model of target occupancy to generate informative paths in continuous 3D space. Within this framework, we introduce an adaptive replanning scheme which allows us to trade off between information gain, field coverage, sensor performance, and collision avoidance for efficient target detection. Extensive simulations show that our OA-IPP method performs better than state-of-the-art planners, and we demonstrate its application in a realistic urban SaR scenario.


Title: Real-Time Planning with Multi-Fidelity Models for Agile Flights in Unknown Environments
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  sensors  low-fidelity models  fast planner  planning framework  agile flights  replanning times  cluttered environments  multifidelity models  autonomous navigation  real-time localization  lightweight sensing  planning methodologies  hierarchical planning architecture  low-fidelity global planner  high-fidelity local planner  erratic behavior  unstable behavior  global plan  higher-order dynamics  real-time planning  sensor data  collision check  UAV  time 5.0 ms to 40.0 ms  Planning  Trajectory  Computational modeling  Vehicle dynamics  Robot sensing systems  Optimization 
Abstract: Autonomous navigation through unknown environments is a challenging task that entails real-time localization, perception, planning, and control. UAVs with this capability have begun to emerge in the literature with advances in lightweight sensing and computing. Although the planning methodologies vary from platform to platform, many algorithms adopt a hierarchical planning architecture where a slow, low-fidelity global planner guides a fast, high-fidelity local planner. However, in unknown environments, this approach can lead to erratic or unstable behavior due to the interaction between the global planner, whose solution is changing constantly, and the local planner; a consequence of not capturing higher-order dynamics in the global plan. This work proposes a planning framework in which multi-fidelity models are used to reduce the discrepancy between the local and global planner. Our approach uses high-, medium-, and low-fidelity models to compose a path that captures higher-order dynamics while remaining computationally tractable. In addition, we address the interaction between a fast planner and a slower mapper by considering the sensor data not yet fused into the map during the collision check. This novel mapping and planning framework for agile flights is validated in simulation and hardware experiments, showing replanning times of 5-40 ms in cluttered environments.


Title: Efficient Trajectory Planning for High Speed Flight in Unknown Environments
Key Words: aircraft control  autonomous aerial vehicles  closed loop systems  collision avoidance  inertial navigation  mobile robots  motion control  optimal control  predictive control  sampling methods  trajectory control  motion planning  motion capture systems  receding horizon planning architecture  reactive obstacle avoidance  closed-form trajectory generation method  spatial partitioning data structures  obstacle density  sampling-based motion planner  minimum-jerk trajectories  closed-loop tracking  high-speed flight  autonomous quadrotor flights  urban environment  trajectory planning  visual-inertial navigation  distance 22.0 km  Trajectory  Planning  Sensors  Three-dimensional displays  Cameras  Vehicle dynamics  Tracking 
Abstract: There has been considerable recent work in motion planning for UAVs to enable aggressive, highly dynamic flight in known environments with motion capture systems. However, these existing planners have not been shown to enable the same kind of flight in unknown, outdoor environments. In this paper we present a receding horizon planning architecture that enables the fast replanning necessary for reactive obstacle avoidance by combining three techniques. First, we show how previous work in computationally efficient, closed-form trajectory generation method can be coupled with spatial partitioning data structures to reason about the geometry of the environment in real-time. Second, we show how to maintain safety margins during fast flight in unknown environments by planning velocities according to obstacle density. Third, our receding-horizon, sampling-based motion planner uses minimum-jerk trajectories and closed-loop tracking to enable smooth, robust, high-speed flight with the low angular rates necessary for accurate visual-inertial navigation. We compare against two state-of-the-art, reactive motion planners in simulation and benchmark solution quality against an offline global planner. Finally, we demonstrate our planner over 80 flights with a combined distance of 22km of autonomous quadrotor flights in an urban environment at speeds up to 9.4ms $^{-1}$.


Title: A Practical Approach to Insertion with Variable Socket Position Using Deep Reinforcement Learning
Key Words: control engineering computing  industrial robots  learning (artificial intelligence)  neural nets  production engineering computing  variable socket position  visual control problem  model-based robotics community  task geometry  off-the-shelf Deep-RL algorithm  narrow-clearance peg-insertion task  deformable clip-insertion task  deep reinforcement learning  haptic control problem  Task analysis  Robots  Sockets  Visualization  Training  Plugs  Feature extraction 
Abstract: Insertion is a challenging haptic and visual control problem with significant practical value for manufacturing. Existing approaches in the model-based robotics community can be highly effective when task geometry is known, but are complex and cumbersome to implement, and must be tailored to each individual problem by a qualified engineer. Within the learning community there is a long history of insertion research, but existing approaches are either too sample-inefficient to run on real robots, or assume access to high-level object features, e.g. socket pose. In this paper we show that relatively minor modifications to an off-the-shelf Deep-RL algorithm (DDPG), combined with a small number of human demonstrations, allows the robot to quickly learn to solve these tasks efficiently and robustly. Our approach requires no modeling or simulation, no parameterized search or alignment behaviors, no vision system aside from raw images, and no reward shaping. We evaluate our approach on a narrow-clearance peg-insertion task and a deformable clip-insertion task, both of which include variability in the socket position. Our results show that these tasks can be solved reliably on the real robot in less than 10 minutes of interaction time, and that the resulting policies are robust to variance in the socket position and orientation.


Title: Uncertainty-Aware Data Aggregation for Deep Imitation Learning
Key Words: data aggregation  learning (artificial intelligence)  Monte Carlo methods  uncertain systems  uncertainty estimation method  UAIL  uncertainty-aware data aggregation  deep imitation learning  statistical uncertainties  autonomous agents  task execution  safety-critical domains  autonomous driving  uncertainty-aware imitation learning algorithm  end-to-end control systems  Monte Carlo Dropout  control output  end-to-end systems  training data  prior data aggregation algorithms  sub-optimal states  simulated driving tasks  Uncertainty  Data aggregation  Task analysis  Switches  Estimation  Data models 
Abstract: Estimating statistical uncertainties allows autonomous agents to communicate their confidence during task execution and is important for applications in safety-critical domains such as autonomous driving. In this work, we present the uncertainty-aware imitation learning (UAIL) algorithm for improving end-to-end control systems via data aggregation. UAIL applies Monte Carlo Dropout to estimate uncertainty in the control output of end-to-end systems, using states where it is uncertain to selectively acquire new training data. In contrast to prior data aggregation algorithms that force human experts to visit sub-optimal states at random, UAIL can anticipate its own mistakes and switch control to the expert in order to prevent visiting a series of sub-optimal states. Our experimental results from simulated driving tasks demonstrate that our proposed uncertainty estimation method can be leveraged to reliably predict infractions. Our analysis shows that UAIL outperforms existing data aggregation algorithms on a series of benchmark tasks.


Title: Uncertainty Aware Learning from Demonstrations in Multiple Contexts using Bayesian Neural Networks
Key Words: Bayes methods  belief networks  intelligent robots  learning (artificial intelligence)  learning systems  neurocontrollers  Bayesian neural networks  robotic controllers  evaluation conditions  learned controller  testing conditions  high-dimensional simulated domains  real robotic domains  uncertainty based solution  uncertainty aware learning  Uncertainty  Task analysis  Neural networks  Training  Robots  Bayes methods  Measurement uncertainty 
Abstract: Diversity of environments is a key challenge that causes learned robotic controllers to fail due to the discrepancies between the training and evaluation conditions. Training from demonstrations in various conditions can mitigate - but not completely prevent - such failures. Learned controllers such as neural networks typically do not have a notion of uncertainty that allows to diagnose an offset between training and testing conditions, and potentially intervene. In this work, we propose to use Bayesian Neural Networks, which have such a notion of uncertainty. We show that uncertainty can be leveraged to consistently detect situations in high-dimensional simulated and real robotic domains in which the performance of the learned controller would be sub-par. Also, we show that such an uncertainty based solution allows making an informed decision about when to invoke a fallback strategy. One fallback strategy is to request more data. We empirically show that providing data only when requested results in increased data-efficiency.


Title: A Data-Efficient Framework for Training and Sim-to-Real Transfer of Navigation Policies
Key Words: gradient methods  image coding  learning (artificial intelligence)  mobile robots  path planning  data-efficient framework  sim-to-real transfer  navigation policies  effective visuomotor policies  learning-based system  manual tuning  robot operating  training process  leverage simulation  off-policy data  initial image  lower dimensional latent state  planner modules  meta-learning strategy  adversarial domain transfer  simulated environments  similarly distributed latent representation  fine tuning  encoder + planner  planning performances  navigation tasks  unlabelled random images  Robots  Data models  Planning  Task analysis  Trajectory  Training  Navigation 
Abstract: Learning effective visuomotor policies for robots purely from data is challenging, but also appealing since a learning-based system should not require manual tuning or calibration. In the case of a robot operating in a real environment the training process can be costly, time-consuming, and even dangerous since failures are common at the start of training. For this reason, it is desirable to be able to leverage simulation and off-policy data to the extent possible to train the robot. In this work, we introduce a robust framework that plans in simulation and transfers well to the real environment. Our model incorporates a gradient-descent based planning module, which, given the initial image and goal image, encodes the images to a lower dimensional latent state and plans a trajectory to reach the goal. The model, consisting of the encoder and planner modules, is first trained through a meta-learning strategy in simulation. We subsequently perform adversarial domain transfer on the encoder by using a bank of unlabelled but random images from the simulation and real environments to enable the encoder to map images from the real and simulated environments to a similarly distributed latent representation. By fine tuning the entire model (encoder + planner) with only a few real world expert demonstrations, we show successful planning performances in different navigation tasks.


Title: Simulating Emergent Properties of Human Driving Behavior Using Multi-Agent Reward Augmented Imitation Learning
Key Words: behavioural sciences computing  convergence  learning (artificial intelligence)  multi-agent systems  traffic engineering computing  multiagent settings  multiagent imitation learning  human drivers  reward augmentation  imitation learning process  multiagent reward augmented imitation learning  traffic behaviors  imitation learning algorithms  human driving behavior modeling  prior knowledge specification  convergence guarantees  driving policies  Rails  Convergence  Biological system modeling  Trajectory  Computational modeling  Autonomous vehicles 
Abstract: Recent developments in multi-agent imitation learning have shown promising results for modeling the behavior of human drivers. However, it is challenging to capture emergent traffic behaviors that are observed in real-world datasets. Such behaviors arise due to the many local interactions between agents that are not commonly accounted for in imitation learning. This paper proposes Reward Augmented Imitation Learning (RAIL), which integrates reward augmentation into the multi-agent imitation learning framework and allows the designer to specify prior knowledge in a principled fashion. We prove that convergence guarantees for the imitation learning process are preserved under the application of reward augmentation. This method is validated in a driving scenario, where an entire traffic scene is controlled by driving policies learned using our proposed algorithm. Further, we demonstrate improved performance in comparison to traditional imitation learning algorithms both in terms of the local actions of a single agent and the behavior of emergent properties in complex, multi-agent settings.


Title: A Supervised Approach to Predicting Noise in Depth Images
Key Words: cameras  convolutional neural nets  image denoising  image fusion  image reconstruction  image sensors  object detection  pose estimation  robot vision  supervised learning  supervised approach  modern robotic systems  detailed sensor noise models  robotic behavior  scene-dependent pixel-wise dropouts  depth camera simulations  data driven approach  convolutional neural network  no-depth-return pixels  NDP  ground truth depth  noisy depth image  resulting noise-free  noise-free image  depth sensor  cluttered scenes  uncorrupted depth images  noise prediction  scenes reconstruction  CNN  unsupervised domain adaptation baselines  object pose estimation  noise-free depth image  label fusion dataset  Cameras  Image reconstruction  Data models  Noise measurement  Robot vision systems 
Abstract: Modern robotic systems are very complex and need to be tested in simulations with detailed sensor noise models to effectively verify robotic behavior. Depth imagery in particular comes with significant noise in the form of scene-dependent pixel-wise dropouts and distortions. Unfortunately, many depth camera simulations contain limited noise models, or can only support generating realistic depth images of simple scenes, which limits their usefulness in effectively testing perception algorithms. We propose a data driven approach to generate more realistic noise for complex simulated environments by using a convolutional neural network (CNN) to predict which pixels of a simulated noise-free depth image will not have returns (no-depth-return pixels, or NDP). We choose to focus on NDP here, as these dropouts are the most common and dramatic form of depth image noise. To train this network, we use reconstructed real-world scenes from the Label Fusion dataset to provide ground truth depth for each noisy depth image used to scan the scene. We use the resulting noise-free and noisy depth image pairs as labeled examples and train the network to predict which pixels of the noise-free image will be NDP. When used to post-process a simulation of a depth sensor, this system produces realistic depth images, even in cluttered scenes. To demonstrate that our approach successfully closes the reality gap for depth imagery, we show that the popular ICP algorithm for object pose estimation fails more realistically on our CNN-corrupted simulated depth images than on uncorrupted depth images and unsupervised domain adaptation baselines.


Title: A Learning Framework for High Precision Industrial Assembly
Key Words: assembling  optimisation  production engineering computing  supervised learning  learning framework  high precision industrial assembly  reinforcement learning  automatic assembly  supervised learning  assembly tasks  trajectory optimization  actor-critic algorithm  Task analysis  Trajectory  Optimization  Dynamics  Supervised learning  Computational modeling  Space exploration 
Abstract: Automatic assembly has broad applications in industries. Traditional assembly tasks utilize predefined trajectories or tuned force control parameters, which make the automatic assembly time-consuming, difficult to generalize, and not robust to uncertainties. In this paper, we propose a learning framework for high precision industrial assembly. The framework combines both the supervised learning and the reinforcement learning. The supervised learning utilizes trajectory optimization to provide the initial guidance to the policy, while the reinforcement learning utilizes actor-critic algorithm to establish the evaluation system even the supervisor is not accurate. The proposed learning framework is more efficient compared with the reinforcement learning and achieves better stability performance than the supervised learning. The effectiveness of the method is verified by both the simulation and experiment. Experimental videos are available at [1].


Title: A Large-Deflection FBG Bending Sensor for SMA Bending Modules for Steerable Surgical Robots
Key Words: bending  biomedical measurement  Bragg gratings  closed loop systems  fibre optic sensors  manipulators  medical robotics  shape memory effects  surgery  steerable surgical robots  disposable surgical robots  minimally invasive procedures  closed-loop control  superelastic substrate  flexible adhesive  sensor-actuator assembly  SMA actuation  intrinsic bending sensor  shape memory alloy bending modules  fiber Bragg grating bending sensor  SMA bending module  large-deflection FBG bending sensor  Robot sensing systems  Fiber gratings  Substrates  Wires  Strain  Gratings 
Abstract: This paper presents the development of a fiber Bragg grating (FBG) bending sensor for shape memory alloy (SMA) bending modules. Due to the small form factor, low cost, and large-deflection capability, SMA bending modules can be used to construct disposable surgical robots for a variety of minimally invasive procedures. To realize a closed-loop control of SMA bending modules, an intrinsic bending sensor is imperative. Due to the lack of bending sensors for SMA bending modules, we have developed an FBG bending sensor by integrating FBG fibers with a superelastic substrate using flexible adhesive. Since the substrate is ultra-thin and adhesive is flexible, the sensor has low stiffness and can measure large curvatures. Additionally, due to the orthogonal arrangement of the sensor/actuator assembly, the influence of temperature variation caused by SMA actuation can be compensated. The working principle of the developed sensor was modeled followed by simulations. After experimentally evaluating the developed model, the sensor was integrated with an SMA bending module and cyclically bi-directionally deflected. The experimental results proved the relatively high measurement accuracy, high repeatability, and large measurable curvatures of the sensor, although hysteresis was observed due to friction.


Title: Fast Stochastic Functional Path Planning in Occupancy Maps
Key Words: computational complexity  Gaussian processes  optimisation  path planning  robots  sampling methods  trajectory control  occupancy map  stochastic trajectory optimiser  Gaussian process path representation  trajectory optimisation  fast stochastic functional path planning  path planners  highly expressive path representation  sampling-based planners  fully defined artificial potential field  partially observed model  cubic complexity  kernel approximation  computational complexity  stochastic sampling  sampling-based methods  Planning  Optimization  Trajectory  Kernel  Robots  Stochastic processes 
Abstract: Path planners are generally categorised as either trajectory optimisers or sampling-based planners. The latter is the predominant planning paradigm for occupancy maps. Most trajectory optimisers require a fully defined artificial potential field for planning and cannot incorporate updates from a partially observed model such as an occupancy map. A stochastic trajectory optimiser capable of planning over occupancy map was presented in [1]. However, its scalability is limited by the cubic complexity of the Gaussian process path representation. In this work, we introduce a novel highly expressive path representation based on kernel approximation to perform trajectory optimisation over occupancy maps. This approach reduces the computational complexity to a fixed cost that only depends on the number of features. We show that stochastic sampling is crucial for planning in occupancy maps and present comparisons to other state-of-the-art planning methods, using simulated and real occupancy data. These experiments demonstrate the significant reduction in runtime, resulting in performance comparable to or better than sampling-based methods.


Title: A Scalable Framework For Real-Time Multi-Robot, Multi-Human Collision Avoidance
Key Words: collision avoidance  human-robot interaction  multi-robot systems  robust control  trajectory control  robust motion planning  robotics literature  robot navigation  high-order system dynamics  confidence-aware human motion predictions  sequential priority ordering  trajectory planning  multirobot multihuman collision avoidance  Planning  Trajectory  Robot sensing systems  Robot kinematics  Predictive models  Real-time systems 
Abstract: Robust motion planning is a well-studied problem in the robotics literature, yet current algorithms struggle to operate scalably and safely in the presence of other moving agents, such as humans. This paper introduces a novel framework for robot navigation that accounts for high-order system dynamics and maintains safety in the presence of external disturbances, other robots, and humans. Our approach precomputes a tracking error margin for each robot, generates confidence-aware human motion predictions, and coordinates multiple robots with a sequential priority ordering, effectively enabling scalable safe trajectory planning and execution. We demonstrate our approach in hardware with two robots and two humans, and showcase scalability in a larger simulation.


Title: Lazy Evaluation of Goal Specifications Guided by Motion Planning
Key Words: mobile robots  motion control  path planning  lazy evaluation  collaborative environments  robot motion commands  delayed grounding  lazy variable grounding  motion planning algorithm  semantic interpretation  goal specifications  reward-penalty strategy  Semantics  Planning  Robot kinematics  Grounding  Automobiles  Collaboration 
Abstract: Nowadays robotic systems are expected to share workspaces and collaborate with humans. In such collaborative environments, an important challenge is to ground or establish the correct semantic interpretation of a human request. Once such an interpretation is available, the request must be translated into robot motion commands in order to complete the desired task. It is not unusual that a human request cannot be grounded to a unique interpretation, thus leading to an ambiguous request. A simple example is to ask a robot to “put a cup on the table,” when there are multiple cups available. In order to deal with this kind of ambiguous request, we propose a delayed or lazy variable grounding. The focus of this paper is a motion planning algorithm that, given goal regions that represent different valid groundings, lazily finds a feasible path to any one valid grounding. This algorithm includes a reward-penalty strategy, which attempts to prioritize those goal regions that seem more promising to provide a solution. We validate our approach by solving requests with multiple valid alternatives in both simulation and real-world experiments.


Title: Reconfigurable Motion Planning and Control in Obstacle Cluttered Environments under Timed Temporal Tasks
Key Words: collision avoidance  convex programming  formal verification  mobile robots  motion control  path planning  temporal logic  high-level specification  timed temporal logic formula  obstacle avoidance  motion controller  safe navigation  transition system  standard formal verification  convex optimization techniques  reconfigurable motion planning  obstacle cluttered environments  timed temporal tasks  robot navigation  hybrid control strategy  temporal specifications  agent motion abstraction  Clocks  Task analysis  Planning  Navigation  Automata 
Abstract: This work addresses the problem of robot navigation under timed temporal specifications in workspaces cluttered with obstacles. We propose a hybrid control strategy that guarantees the accomplishment of a high-level specification expressed as a timed temporal logic formula, while preserving safety (i.e., obstacle avoidance) of the system. In particular, we utilize a motion controller that achieves safe navigation inside the workspace in predetermined time, thus allowing us to abstract the motion of the agent as a finite timed transition system among certain regions of interest. Next, we employ standard formal verification and convex optimization techniques to derive high-level timed plans that satisfy the agent's specifications. A simulation study illustrates and clarifies the proposed scheme.


Title: An Algorithm for Odor Source Localization based on Source Term Estimation
Key Words: estimation theory  Markov processes  mobile robots  path planning  wind tunnels  odor source localization  source term estimation  airborne chemicals  mobile sensing systems  navigation method  partially observable Markov decision processes  wind tunnel  Robot sensing systems  Estimation  Navigation  Probabilistic logic  Heuristic algorithms  Mobile robots 
Abstract: Finding sources of airborne chemicals with mobile sensing systems finds applications across the security, safety, domestic, medical, and environmental domains. In this paper, we present an algorithm based on source term estimation for odor source localization that is coupled with a navigation method based on partially observable Markov decision processes. We propose an innovative strategy to balance exploration and exploitation in navigation. The method has been evaluated systematically through high-fidelity simulations and in a wind tunnel emulating realistic and repeatable conditions. The impact of multiple algorithmic and environmental parameters has been studied in the experiments.


Title: Feasible coordination of multiple homogeneous or heterogeneous mobile vehicles with various constraints
Key Words: algebra  mobile robots  motion control  multi-robot systems  path planning  nonholonomic motion constraints  holonomic coordination constraints  differential-algebraic equations  viability theory  coordinated motion control  heterogeneous vehicle dynamics  multivehicle coordination  control schemes  coordination control  heterogeneous mobile vehicles  Task analysis  Kinematics  Mathematical model  Vehicle dynamics  Trajectory  Tools 
Abstract: We consider the problem of feasible coordination control for multiple homogeneous or heterogeneous mobile vehicles subject to various constraints (nonholonomic motion constraints, holonomic coordination constraints, equality/inequality constraints etc). We develop a general framework involving differential-algebraic equations and viability theory to describe and determine coordination feasibility for a coordinated motion control under heterogeneous vehicle dynamics and various constraints. A heuristic algorithm is proposed for generating feasible trajectories for each individual vehicle. We show several application examples and simulation experiments on multi-vehicle coordination under various constraints to validate the theory and the effectiveness of the proposed algorithm and control schemes.


Title: Dynamically-consistent Generalized Hierarchical Control
Key Words: C++ language  control engineering computing  manipulator dynamics  manipulator kinematics  Matlab  redundant manipulators  robot programming  source code (software)  dynamically-consistent generalized hierarchical control  redundant robots  strict prioritization schemes  GHC  nullspace projection operator  dynamically-consistent stack-of-tasks hierarchies  DynGHC  soft prioritization schemes  Matlab  C++ source code  Task analysis  Jacobian matrices  Robots  Couplings  Matrix decomposition  Transmission line matrix methods  Matlab 
Abstract: Tracking multiple prioritized tasks simultaneously with redundant robots have been investigated extensively over the last decades. Recent research focuses on combining advantages from both classical soft and strict prioritization schemes which is non-trivial. Among the proposed methods to tackle this issue, Generalized Hierarchical Control (GHC) seems to have a reasonable performance, however, it does not include a weighting matrix in the computation of the nullspace projection operator and hence cannot construct dynamically-consistent stack-of-tasks hierarchies as a special case. We extend GHC by adding dynamic-consistency to the control scheme and refer to it as DynGHC. The extension is also advantageous when choosing non-strict priorities because inertia coupling between tasks is reduced. DynGHC allows to smoothly rearrange priorities which is important for robots acting in dynamically changing contexts. Comparative simulations with a 4 DOF planar manipulator and a KUKA LWR validate our approach. Matlab and C++ source code is made available.


Title: Model Reference Adaptive Control of a Two-Wheeled Mobile Robot
Key Words: adaptive control  control system synthesis  mobile robots  model reference adaptive control systems  nonlinear control systems  pendulums  two-wheeled mobile robot  dynamically unstable system  environmental conditions  loading conditions  nonlinear controller  control systems  fixed parameter controllers  single-input multioutput nature  adaptive controller  SIMO systems  hidden dynamic effects  model reference adaptive control  Vehicle dynamics  Adaptation models  Mathematical model  Control systems  Adaptive control  Mobile robots 
Abstract: The inverted pendulum is by nature a dynamically unstable system and may be subjected to severe disturbances due to its environmental or loading conditions. This paper formulates a design for a nonlinear controller to balance a two-wheeled mobile robot (TWMR) based on Model Reference Adaptive Control. The proposed solution overcomes the limitations of control systems that rely on fixed parameter controllers. Given the nonlinear single-input multi-output (SIMO) nature of the TWMR platform, the proposed adaptive controller can handle non-linearities without the need for linearization, and inherently dealing with SIMO systems. By studying the influence that hidden dynamic effects can cause, we show the preference of the proposed controller over other designs. Simulation results demonstrate the applicability and efficiency of our proposed design, and experimental results validate the effectiveness of the proposed scheme in guaranteeing asymptotic output tracking, even in the presence of unknown disturbances.


Title: A Robust Tracking Controller for Robot Manipulators: Embedding Internal Model of Disturbances
Key Words: closed loop systems  control system synthesis  manipulators  nonlinear control systems  observers  robust control  trajectory control  uncertain systems  robust tracking controller  uncertain robot manipulators  disturbance observer based controller  internal model embedding  sinusoids frequencies  stability analysis  2-DOF manipulator  closed-loop system  Disturbance observers  Manipulators  Uncertainty  Stability analysis  Closed loop systems  Torque 
Abstract: This paper presents a robust controller for uncertain robot manipulators subject to disturbances which are composed of sinusoids. The controller employs the disturbance observer based controller which can effectively estimate and compensate the effect of plant uncertainties and the disturbances. Assuming that the frequencies of sinusoids are known, we embed the internal model of disturbances into the proposed controller so that the design parameters of the controller can be chosen without using the magnitude of disturbance or its time derivative. A rigorous stability analysis shows that the closed-loop system under the proposed controller behaves like the nominal closed-loop system free of disturbances. Simulation results for a 2-DOF manipulator show the effectiveness of the proposed controller.


Title: Receding horizon estimation and control with structured noise blocking for mobile robot slip compensation
Key Words: adaptive control  compensation  mobile robots  motion control  optimisation  parameter estimation  predictive control  statistical analysis  wheels  parameter estimation  overlapping-block strategy  receding horizon estimation  mobile robot slip compensation  field robots  uncertain terrain conditions  autonomous navigation  online estimation  wheel-terrain slip characteristics  off-road environments  constrained estimation  receding horizon control  adaptive optimisation-based control method  estimation horizon  structured noise blocking  control predictions  tracking trajectories  RHE  RHC  structured blocking approach  state estimation  Estimation  Adaptation models  Optimization  Wheels  Mobile robots  Parameter estimation 
Abstract: The control of field robots in varying and uncertain terrain conditions presents a challenge for autonomous navigation. Online estimation of the wheel-terrain slip characteristics is essential for generating the accurate control predictions necessary for tracking trajectories in off-road environments. Receding horizon estimation (RHE) provides a powerful framework for constrained estimation, and when combined with receding horizon control (RHC), yields an adaptive optimisation-based control method. Presently, such methods assume slip to be constant over the estimation horizon, while our proposed structured blocking approach relaxes this assumption, resulting in improved state and parameter estimation. We demonstrate and compare the performance of this method in simulation, and propose an overlapping-block strategy to ameliorate some of the limitations encountered in applying noise-blocking in a receding horizon estimation and control (RHEC) context.


Title: Decoupled Control of Position and / or Force of Tendon Driven Fingers
Key Words: actuators  dexterous manipulators  force control  humanoid robots  motion control  position control  torque control  vectors  inner loop impedance controller  joint angle vector  joint torque vector  Cartesian position  finger endpoint  DLR David hand  decoupled control  tendon driven fingers  underactuated robotic hands  DLR AWIWI II hand  David robot  joint torques  generalized forces  motor torques  force control  position control  Tendons  Force  Torque  Robots  Couplings  Position control  Routing 
Abstract: In contrast to underactuated robotic hands the DLR AWIWI II hand of the David robot is fully controllable because each finger with 4 joints is actuated by 6 or 8 tendons respectively. For such fingers all joint angles (generalized positions) or joint torques (generalized forces) can be controlled independently. Usually, the specifications in joint space are converted to desired tendon forces or motor torques, which are regulated by an inner loop impedance controller. However, this conversion typically exhibits couplings between the components of the joint angle vector or the joint torque vector respectively, which arise when using the well known equations. Therefore the usual force control and position control schemes are reviewed and a generic computation of the desired tendon forces is presented. This is also done for the control of the Cartesian position and force at the finger endpoint. Thus the main contribution of the paper is the inhibition of couplings in joint space or at the Cartesian endpoint. This is demonstrated in simulations of the index finger of the DLR David hand.


Title: Learned Map Prediction for Enhanced Mobile Robot Exploration
Key Words: information theory  learning (artificial intelligence)  mobile robots  neural nets  autonomous ground robot  geometric heuristics  information theory  deep learning  mobile robot exploration  generative neural network  2D maps  reinforcement learning  robots behavior  Deep learning  Robot sensing systems  Decoding  Gain measurement  Navigation  Training 
Abstract: We demonstrate an autonomous ground robot capable of exploring unknown indoor environments for reconstructing their 2D maps. This problem has been traditionally tackled by geometric heuristics and information theory. More recently, deep learning and reinforcement learning based approaches have been proposed to learn exploration behavior in an end-to-end manner. We present a method that combines the strengths of these different approaches. Specifically, we employ a state-of-the-art generative neural network to predict unknown regions of a partially explored map, and use the prediction to enhance the exploration in an information-theoretic manner. We evaluate our system in simulation using floor plans of real buildings. We also present comparisons with traditional methods which demonstrate the advantage of our method in terms of exploration efficiency. We retain an advantage over end-to-end learned exploration methods in that the robot's behavior is easily explicable in terms of the predicted map.


Title: Propagation Networks for Model-Based Control Under Partial Observation
Key Words: learning (artificial intelligence)  mobile robots  off-the-shelf physics engines  interaction networks  pairwise interactions  propagation networks  differentiable dynamics model  learnable dynamics model  partially observable scenarios  model-based control  deep reinforcement learning algorithms  robot planning  PropNet  Engines  Task analysis  Force  Robots  Computational modeling  Adaptation models 
Abstract: There has been an increasing interest in learning dynamics simulators for model-based control. Compared with off-the-shelf physics engines, a learnable simulator can quickly adapt to unseen objects, scenes, and tasks. However, existing models like interaction networks only work for fully observable systems; they also only consider pairwise interactions within a single time step, both restricting their use in practical systems. We introduce Propagation Networks (PropNet), a differentiable, learnable dynamics model that handles partially observable scenarios and enables instantaneous propagation of signals beyond pairwise interactions. With these innovations, our propagation networks not only outperform current learnable physics engines in forward simulation, but also achieves superior performance on various control tasks. Compared with existing deep reinforcement learning algorithms, model-based control with propagation networks is more accurate, efficient, and generalizable to novel, partially observable scenes and tasks.


Title: MH-iSAM2: Multi-hypothesis iSAM using Bayes Tree and Hypo-tree
Key Words: Bayes methods  data structures  mobile robots  optimisation  SLAM (robots)  original Bayes tree  hypothesis pruning strategy  multihypothesis iSAM  nonlinear incremental optimization algorithm  MH-iSAM2  simultaneous localization and mapping problems  SLAM problems  hypo-tree  multihypothesis inference  data structures  Simultaneous localization and mapping  Zirconium  Maximum likelihood estimation  Optimization  Inference algorithms  Robustness 
Abstract: A novel nonlinear incremental optimization algorithm MH-iSAM2 is developed to handle ambiguity in simultaneous localization and mapping (SLAM) problems in a multi-hypothesis fashion. It can output multiple possible solutions for each variable according to the ambiguous inputs, which is expected to greatly enhance the robustness of autonomous systems as a whole. The algorithm consists of two data structures: an extension of the original Bayes tree that allows efficient multi-hypothesis inference, and a Hypo-tree that is designed to explicitly track and associate the hypotheses of each variable as well as all the inference processes for optimization. With our proposed hypothesis pruning strategy, MH-iSAM2 enables fast optimization and avoids the exponential growth of hypotheses. We evaluate MH-iSAM2 using both simulated datasets and real-world experiments, demonstrating its improvements on the robustness and accuracy of SLAM systems.


Title: Learning Robust Manipulation Strategies with Multimodal State Transition Models and Recovery Heuristics
Key Words: control engineering computing  learning (artificial intelligence)  manipulator dynamics  mobile robots  optimisation  robot programming  contact dynamics  reinforcement learning  recovery skills  multiple contact state changes  multimodal state transition model  recovery heuristics  contact-based manipulations  robust manipulation strategies learning  skill selections  Task analysis  End effectors  Robustness  Data models  Planning  Clustering algorithms 
Abstract: Robots are prone to making mistakes when performing manipulation tasks in unstructured environments. Robust policies are thus needed to not only avoid mistakes but also to recover from them. We propose a framework for increasing the robustness of contact-based manipulations by modeling the task structure and optimizing a policy for selecting skills and recovery skills. A multimodal state transition model is acquired based on the contact dynamics of the task and the observed transitions. A policy is then learned from the model using reinforcement learning. The policy is incrementally improved by expanding the action space by generating recovery skills with a heuristic. Evaluations on three simulated manipulation tasks demonstrate the effectiveness of the framework. The robot was able to complete the tasks despite multiple contact state changes and errors encountered, increasing the success rate averaged across the tasks from 70.0% to 95.3%.


Title: Adaptive Critic Based Optimal Kinematic Control for a Robot Manipulator
Key Words: adaptive control  closed loop systems  control system synthesis  end effectors  Lyapunov methods  manipulator dynamics  manipulator kinematics  motion control  optimal control  position control  stability  time-varying systems  tracking  robot manipulator  robot end effector position  task space trajectory  desired velocity profile  single network adaptive critic  forward kinematics  input affine system  critic weight update law  desired optimal cost  closed loop kinematic control  optimal regulation problem  SNAC based kinematic control  optimal tracking problem  tracking error  reference trajectory  optimal control policy  kinematic control scheme  Universal Robot 10 manipulator  adaptive critic based optimal kinematic control  Kinematics  Manipulators  Trajectory  Optimal control  Cost function  Stability analysis 
Abstract: This paper is concerned with the optimal kinematic control of a robot manipulator where the robot end effector position follows a task space trajectory. The joints are actuated with the desired velocity profile to achieve this task. This problem has been solved using a single network adaptive critic (SNAC) by expressing the forward kinematics as input affine system. Usually in SNAC, the critic weights are updated using back propagation algorithm while little attention is given to convergence to the optimal cost. In this paper, we propose a critic weight update law that ensures convergence to the desired optimal cost while guaranteeing the stability of the closed loop kinematic control. In kinematic control, the robot is required to reach a specific target position. This has been solved as an optimal regulation problem in the context of SNAC based kinematic control. When the robot is required to follow a time varying task space trajectory, then the kinematic control has been framed as an optimal tracking problem. For tracking, an augmented system consisting of tracking error and reference trajectory is constructed and the optimal control policy is derived using SNAC framework. The stability and performance of the system under the proposed novel weight tuning law is guaranteed using Lyapunov approach. The proposed kinematic control scheme has been validated in simulations and experimentally executed using a real six degrees of freedom (DOF) Universal Robot (UR) 10 manipulator.


Title: Adapting Everyday Manipulation Skills to Varied Scenarios
Key Words: control engineering computing  manipulators  mobile robots  motion control  robot vision  service robots  point clouds  target object  tool-using manipulation skills  motion trajectories  scraping material  robot perception module  PR2 robot  Tools  Task analysis  Robots  Three-dimensional displays  Trajectory  Containers  Dairy products 
Abstract: We address the problem of executing tool-using manipulation skills in scenarios where the objects to be used may vary. We assume that point clouds of the tool and target object can be obtained, but no interpretation or further knowledge about these objects is provided. The system must interpret the point clouds and decide how to use the tool to complete a manipulation task with a target object; this means it must adjust motion trajectories appropriately to complete the task. We tackle three everyday manipulations: scraping material from a tool into a container, cutting, and scooping from a container. Our solution encodes these manipulation skills in a generic way, with parameters that can be filled in at run-time via queries to a robot perception module; the perception module abstracts the functional parts of the tool and extracts key parameters that are needed for the task. The approach is evaluated in simulation and with selected examples on a PR2 robot.


Title: Data-Driven Gait Segmentation for Walking Assistance in a Lower-Limb Assistive Device
Key Words: biomechanics  gait analysis  legged locomotion  medical robotics  nonlinear control systems  patient rehabilitation  predictive control  robot dynamics  robot kinematics  data-driven gait segmentation  walking assistance  lower-limb assistive device  hybrid systems  bipedal walker  nonlinear dynamics  hybrid mode  reliable state sensing  data-driven analysis  data-driven dynamics identification  model predictive control  hybrid SLIP model  gait partitioning  human walking data  kinematics data  online assistance  predefined gait structure  healthy gaits  pathological gaits  impairment-specific rehabilitation strategies  Heuristic algorithms  Mathematical model  Data models  Predictive models  Prediction algorithms  System dynamics  Switches 
Abstract: Hybrid systems, such as bipedal walkers, are challenging to control because of discontinuities in their nonlinear dynamics. Little can be predicted about the systems' evolution without modeling the guard conditions that govern transitions between hybrid modes, so even systems with reliable state sensing can be difficult to control. We propose an algorithm that allows for determining the hybrid mode of a system in real-time using data-driven analysis. The algorithm is used with data-driven dynamics identification to enable model predictive control based entirely on data. Two examples-a simulated hopper and experimental data from a bipedal walker-are used. In the context of the first example, we are able to closely approximate the dynamics of a hybrid SLIP model and then successfully use them for control in simulation. In the second example, we demonstrate gait partitioning of human walking data, accurately differentiating between stance and swing, as well as selected subphases of swing. We identify contact events, such as heel strike and toe-off, without a contact sensor using only kinematics data from the knee and hip joints, which could be particularly useful in providing online assistance during walking. Our algorithm does not assume a predefined gait structure or gait phase transitions, lending itself to segmentation of both healthy and pathological gaits. With this flexibility, impairment-specific rehabilitation strategies or assistance could be designed.


Title: A Deployable Soft Robotic Arm with Stiffness Modulation for Assistive Living Applications
Key Words: actuators  assisted living  biomechanics  handicapped aids  human-robot interaction  manipulator kinematics  medical robotics  mobile robots  motion control  pneumatic actuators  service robots  deployable soft robotic arm  assistive living applications  three-tendon actuated continuum robot  elderly impaired individuals  physically impaired individuals  daily living  Yoshimura pattern  controlled deployment  length variation  pneumatic stiffness mechanism  stiffness modulation approach  actuation system  assistive robots  Manipulators  Modulation  Pneumatic systems  Tendons  Soft robotics 
Abstract: This paper presents a three-tendon actuated continuum robot with an origami backbone to assist the elderly and physically impaired individuals in performing activities of daily living. The proposed design solution is an inherently safe and cost-effective alternative to current assistive robots. The origami backbone based on a variation of the Yoshimura pattern provides controlled deployment of the robot and enables length variation (15 cm - 56 cm) in order to increase the reachable workspace. A pneumatic stiffness mechanism was implemented, increasing the weight bearing capabilities of the continuum robot to 500 g. This new stiffness modulation approach was assessed with the use of several testing rigs. Additionally, the robot is joypad controlled and is easily transportable due to its high packing efficiency of 73% and light weight of 1.3 kg for the main body (including the actuation system). For demonstration of usability studies, the robot was successfully tested at a simulated kitchen terminal and also performed pick and place tasks.


Title: A Noninvasive Approach to Recovering the Lost Force Feedback for a Robotic-Assisted Insertable Laparoscopic Surgical Camera
Key Words: biological tissues  biomedical optical imaging  cameras  force measurement  medical robotics  surgery  camera actuation  rotation camera behaviors  simulated abdominal cavity  noninvasive real-time camera-tissue interaction force measurement approach  abdominal wall tissue  robotic-assisted camera control experiment  laparoscopic imaging  transabdominal magnetic coupling  minimally invasive surgery  conventional trocar-based laparoscopes  insertable laparoscopic camera  robotic-assisted insertable laparoscopic surgical camera  lost force feedback  noninvasive approach  Cameras  Force  Robot vision systems  Stators  Actuators  Force measurement 
Abstract: Fully insertable laparoscopic cameras feature more locomotive flexibility in a larger workspace compared to conventional trocar-based laparoscopes and thus represent a promising future of minimally invasive surgery. These cameras are principally anchored and actuated by transabdominal magnetic coupling. Although several proof-of-concept prototypes have shown the technical feasibility in terms of camera actuation and laparoscopic imaging, none of them are getting close to clinical practice due to concerns about safety. One common problem lies in that the interaction force between the camera and the abdominal wall tissue is completely unknown and not controlled. The camera is being manipulated in an open loop which exposes the patient to a high risk of being injured. In this paper, a noninvasive real-time camera-tissue interaction force measurement approach for an insertable laparoscopic camera is proposed, implemented, and validated.Ex-vivo experiments using a simulated abdominal cavity have demonstrated the effectiveness of this approach during anchoring, translation, and rotation camera behaviors. Potential surgical impacts enabled by the force feedback have also been exemplified by a robotic-assisted camera control experiment using shared autonomy.


Title: Feasibility Study of Robotic Needles with a Rotational Tip-Joint and Notch Patterns
Key Words: industrial robots  needles  nickel alloys  rods (structures)  springs (mechanical)  titanium alloys  laser machining  cosserat rod theory  spring model  dynamic region RRT  planning algorithm  tissue reaction  microtools  embedded rotational tip joint  proximal notch patterns  steerable needle  robotic needles  Needles  Fasteners  Electron tubes  Tendons  Force  Robots  Planning 
Abstract: In this paper, we present the design of a steerable needle with proximal notch patterns for compliance and an embedded rotational tip joint for articulation. The device is fabricated by laser machining NiTi tube so that an inner working channel exists (to enable delivery of fluids, drugs or microtools) and no assembly is required for the joints. We formulate its model based on the classical Cosserat Rod theory. This is extended with incremental state prediction and a simple spring model for tissue reaction to integrate into a planning algorithm based on Dynamic Region RRT which efficiently explores the needle's state space. The planner was initialized with a target zone and arbitrary anatomical obstacles before running simulations which propagated incremental state changes at every step while adhering to constraints based on the physical system. Finally, we demonstrate the steering capability of the needle through insertion tests into a phantom.


Title: Energy Budget Transaction Protocol for Distributed Robotic Systems
Key Words: energy management systems  protocols  robots  telecommunication power management  energy transaction protocol  distributed robotic system  simulated unreliable communication channel  energy budget transaction protocol  necessary condition  energy generating system  energy-aware actuation  allocated energy budget  system stability  energy monitoring  accidental energy generation  naive communication strategy  Protocols  Robots  Communication channels  Task analysis  Real-time systems  Stability criteria  Network architecture 
Abstract: Passivity is a necessary condition for a system's stability, meaning that an energy generating system may readily become unstable. Energy-aware actuation can enforce passivity by monitoring the amount of energy that is exchanged with a system, while using an allocated energy budget to execute a task. Careful communication of the energy budgets is important to prevent accidental generation of energy. Therefore, this paper proposes an energy transaction protocol to communicate energy budgets in a distributed robotic system to guarantee that passivity is kept. Simulations are performed with a model of the protocol that is applied to a simulated unreliable communication channel. It is verified that the proposed protocol keeps passivity in the system, while a naive communication strategy either violates passivity or is unnecessarily dissipative.


Title: Robust object grasping in clutter via singulation
Key Words: function approximation  learning (artificial intelligence)  manipulators  neural nets  object detection  robot vision  robust object grasping  singulation  cluttered environment  collision free grasp affordances  optimal push policies  action-value function approximation  robot training  deep neural network  reinforcement learning  Robots  Task analysis  Image segmentation  Reinforcement learning  Clutter  Neural networks  Collision avoidance 
Abstract: Grasping objects in a cluttered environment is challenging due to the lack of collision free grasp affordances. In such conditions, the target object touches or is covered by other objects in the scene, resulting in a failed grasp. To address this problem, we propose a strategy of singulating the object from its surrounding clutter, which consists of previously unseen objects, by means of lateral pushing movements. We employ reinforcement learning for obtaining optimal push policies given depth observations of the scene. The action-value function(Q-function) is approximated with a deep neural network. We train the robot in simulation and we demonstrate that the transfer of learned policies to the real environment is robust.


Title: Design Principles and Optimization of a Planar Underactuated Hand for Caging Grasps
Key Words: design engineering  dexterous manipulators  elastic constants  grippers  pulleys  springs (mechanical)  planar underactuated hand  underactuated grippers  passive adaptability  finger phalanx length  design parameters  caging grasp performance  mechanical compliance  free-swing motion  joint spring stiffness  pulley radius  Tendons  Pulleys  Measurement  Springs  Grasping  Torque  Mathematical model 
Abstract: In this paper we address the problem of creating planar caging grasps on objects using simple, underactuated grippers with no sensing or control. Specifically, we examine how changes in mechanical compliance, passive adaptability due to underactuation, and finger phalanx length affect the ability to create caging grasps passively, by altering the free-swing motion of the fingers. We present a simple model for simulating the underactuated hand, develop a metric for quantifying a hand design's caging ability, and perform a design parameter space search to reveal the important design factors influencing passive caging behavior. The results show that both palm width and the interplay between joint spring stiffness and pulley radius ratios play the largest roles in determining caging behavior. The effect of varying design parameters on the caging grasp performance of the hand is discussed, the best resulting design is shown, and a list of principles to guide the design of simple underactuated hands for caging grasps is presented.


Title: Mechanical Search: Multi-Step Retrieval of a Target Object Occluded by Clutter
Key Words: image colour analysis  object recognition  robot vision  mechanical search  distractor objects  robots  RGBD perception system  target object multistep retrieval  Search problems  Task analysis  Grasping  Image segmentation  Visualization  Robot sensing systems 
Abstract: When operating in unstructured environments such as warehouses, homes, and retail centers, robots are frequently required to interactively search for and retrieve specific objects from cluttered bins, shelves, or tables. Mechanical Search describes the class of tasks where the goal is to locate and extract a known target object. In this paper, we formalize Mechanical Search and study a version where distractor objects are heaped over the target object in a bin. The robot uses an RGBD perception system and control policies to iteratively select, parameterize, and perform one of 3 actions - push, suction, grasp - until the target object is extracted, or either a time limit is exceeded, or no high confidence push or grasp is available. We present a study of 5 algorithmic policies for mechanical search, with 15,000 simulated trials and 300 physical trials for heaps ranging from 10 to 20 objects. Results suggest that success can be achieved in this long-horizon task with algorithmic policies in over 95% of instances and that the number of actions required scales approximately linearly with the size of the heap. Code and supplementary material can be found at http://ai.stanford.edu/mech-search.


Title: Analytic Collision Risk Calculation for Autonomous Vehicle Navigation
Key Words: collision avoidance  mobile robots  Monte Carlo methods  navigation  probability  road traffic control  road vehicles  autonomous vehicle navigation  Monte Carlo simulations  autonomous systems  self-driving car  Freie Universität Berlin  collision octagon  analytic collision risk calculation  trajectory prediction  ground vehicle navigation  autonomous driving  planning system  Trajectory  Integral equations  Autonomous vehicles  Monte Carlo methods  Uncertainty 
Abstract: Collision checking and avoidance is an import part of the perception and planning system for autonomous driving. We present a new analytic approach to calculate the probability of a future collision and extend another already known solution to be suitable for ground vehicle navigation. Our new concept of the collision octagon facilitates in both cases the derivation of an analytic solution. Both approaches are compared to each other using simulated and real world scenarios. By comparing the results of the analytic solutions to the corresponding Monte Carlo simulations, their accuracy and real-time capability is demonstrated. The suitability of the analytic solutions for real world autonomous systems is further proven by integrating them into the trajectory prediction and planning system of the self-driving car of the Freie Universität Berlin.


Title: Goal-Driven Navigation for Non-holonomic Multi-Robot System by Learning Collision
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  multi-robot systems  goal-driven navigation  nonholonomic multirobot system  learning collision  reinforcement learning  multirobot collision avoidance approach  training agent robots  agent robot  trained policy  multiple obstacle robots  robot simulation  robot experiment  Robots  Collision avoidance  Training  Planning  Task analysis  Servers  Heuristic algorithms 
Abstract: In this paper, we propose the reinforcement learning based multi-robot collision avoidance approach by learning collision. Dynamical path re-planning, which is massively used in classical collision avoidance methods, needs overall information of the environment. Also, training agent robots to avoid the collision and pursue a goal point simultaneously is inefficient since the agent should learn two tasks. As the number of tasks that the agent should learn increases, it is difficult to make the performance of an algorithm consistent, which is known as reproducibility issue. To overcome these limitations, Collision Avoidance by Learning Collision (CALC), which learns collision instead of avoiding an obstacle robot is suggested. To solve the collision avoidance problem efficiently, the proposed method divides the problem into training and planning. In the training algorithm, an agent robot learns how to collide with a single obstacle robot and then generates a trained policy. With the trained policy, the agent can pursue a goal point since the policy leads the agent to `collide' with the goal. Furthermore, by taking action in a reverse way from the trained policy, the agent can avoid multiple obstacle robots in the planning algorithm at once. The proposed method is validated both in the robot simulation and real robot experiment, and compared with the existing collision avoidance method.


Title: Visual Appearance Analysis of Forest Scenes for Monocular SLAM
Key Words: autonomous aerial vehicles  mobile robots  path planning  remotely operated vehicles  robot vision  SLAM (robots)  managed forests  tree health  SLAM research  structured human environments  unstructured forests  forest data  photorealistic simulated forest  straightforward forest terrain  forest scenes  natural scenes  visual appearance analysis  cheap energy efficient way  unmanned aerial vehicles  monocular SLAM systems  SLAM systems  visual appearance statistics  Forestry  Simultaneous localization and mapping  Cameras  Visualization  Vegetation  Feature extraction  Lighting 
Abstract: Monocular simultaneous localisation and mapping (SLAM) is a cheap and energy efficient way to enable Unmanned Aerial Vehicles (UAVs) to safely navigate managed forests and gather data crucial for monitoring tree health. SLAM research, however, has mostly been conducted in structured human environments, and as such is poorly adapted to unstructured forests. In this paper, we compare the performance of state of the art monocular SLAM systems on forest data and use visual appearance statistics to characterise the differences between forests and other environments, including a photorealistic simulated forest. We find that SLAM systems struggle with all but the most straightforward forest terrain and identify key attributes (lighting changes and in-scene motion) which distinguish forest scenes from “classic” urban datasets. These differences offer an insight into what makes forests harder to map and open the way for targeted improvements. We also demonstrate that even simulations that look impressive to the human eye can fail to properly reflect the difficult attributes of the environment they simulate, and provide suggestions for more closely mimicking natural scenes.


Title: Thermal Image Based Navigation System for Skid-Steering Mobile Robots in Sugarcane Crops*
Key Words: agricultural machinery  agriculture  crops  Global Positioning System  infrared imaging  mobile robots  path planning  robot vision  thermal image  navigation system  skid-steering mobile robots  sugarcane crops  autonomous navigation  sugarcane plantations  ordinary agricultural fields  sugarcane farms  row crop tunnels  low-cost skid-steering mobile robot  bioenergy farm  infrared thermal imaging  laser-based sensors  image analysis  navigation methodology  robot swarm  tankette for intelligent bioenergy agriculture  Agriculture  Robot kinematics  Navigation  Mobile robots  Computed tomography  Image color analysis 
Abstract: This work proposes a new strategy for autonomous navigation of mobile robots in sugarcane plantations based on thermal imaging. Unlike ordinary agricultural fields, sugarcane farms are generally vast and accommodates numerous arrangements of row crop tunnels, which are very tall, dense and hard-to-access. Moreover, sugarcane crops lie in harsh regions, which hinder the logistics for employing staff and heavy machinery for mapping, monitoring, and sampling. One solution for this problem is TIBA (Tankette for Intelligent BioEnergy Agriculture), a low-cost skid-steering mobile robot capable of infiltrating the crop tunnels with several sensing/sampling systems. The project concept is to reduce the product cost for making the deployment of a robot swarm feasible over a larger area. A prototype was built and tested in a bioenergy farm in order to improve the understanding of the environment and bring about the challenges for the next development steps. The major problem is the navigation through the crop tunnels, since most of the developed systems are suitable for open field operations and employ laser scanners and/or GPS/IMU, which in general are expensive technologies. In this context, we propose a low-cost solution based on infrared (IR) thermal imaging. IR cameras are simple and inexpensive devices, which do not pose risks to the user health, unlike laser-based sensors. This idea was highly motivated by the data collected in the field, which have shown a significant temperature difference between the ground and the crop. From the image analysis, it is possible to clearly visualize a distinguishable corridor and, consequently, generate a straight path for the robot to follow by using computationally efficient approaches. A rigorous analysis of the collected thermal data, numerical simulations and preliminary experiments in the real environment were included to illustrate the efficiency and feasibility of the proposed navigation methodology.


Title: UAV Pose Estimation using Cross-view Geolocalization with Satellite Imagery
Key Words: autonomous aerial vehicles  cameras  distance measurement  feature extraction  Kalman filters  neural nets  pose estimation  unseen images  visual odometry  trajectory estimation errors  UAV pose estimation  image-based cross-view geolocalization method  georeferenced satellite imagery  Siamese neural networks  UAV camera  satellite images  crossview geolocalization  Satellites  Geology  Cameras  Feature extraction  Training  Visual odometry  Google 
Abstract: We propose an image-based cross-view geolocalization method that estimates the global pose of a UAV with the aid of georeferenced satellite imagery. Our method consists of two Siamese neural networks that extract relevant features despite large differences in viewpoints. The input to our method is an aerial UAV image and nearby satellite images, and the output is the weighted global pose estimate of the UAV camera. We also present a framework to integrate our crossview geolocalization output with visual odometry through a Kalman filter. We build a dataset of simulated UAV images and satellite imagery to train and test our networks. We show that our method performs better than previous camera pose estimation methods, and we demonstrate our networks ability to generalize well to test datasets with unseen images. Finally, we show that integrating our method with visual odometry significantly reduces trajectory estimation errors.


Title: Design and Experiments for MultI-Section-Transformable (MIST)-UAV
Key Words: autonomous aerial vehicles  mobile robots  multiple sequential transformations  shape-shifting transformation  MIST-UAV  in-air transformation  multirotor  multisection-transformable-UAV  transformable vertical take off and landing UAV  transformable VTOL UAV  tail-sitter  fixed-wing operation  Fasteners  Propulsion  Mathematical model  Attitude control  Batteries  Actuators  Servomotors 
Abstract: Presented in this paper are the design and experiments for a transformable Vertical Take Off and Landing (VTOL) UAV. This work demonstrates shape-shifting transformation, building upon the conceptual designs put forth in [1] and [2], along with hardware prototyping and component testing from [3]. A deterministic model is presented to characterize the flight of the MIST-UAV in simulation. Experimental results from the platform demonstrate for the first time successful in-air transformation from multi-rotor, tail-sitter, and fixed-wing operation. Experiments also validated transformation repeatability, successfully testing multiple sequential transformations.


Title: Hunting Drones with Other Drones: Tracking a Moving Radio Target
Key Words: aerospace communication  aerospace robotics  mobile radio  mobile robots  path planning  remotely operated vehicles  target tracking  telemetry  moving radio target  unauthorized drone flights  antennas  commodity radios  telemetry radio emissions  passenger safety  bystander safety  Drones  Antenna measurements  Telemetry  Target tracking  Antennas  Aircraft  Radio frequency 
Abstract: Unauthorized drone flights near aircraft, airports, and emergency operations compromise the safety of passengers and bystanders. A detection system that can quickly find and track drones could help mitigate the risk of unauthorized drone flights. In this work, we show how a consumer drone outfitted with antennas and commodity radios can autonomously localize another drone by its telemetry radio emissions. We show how a non-myopic planner improves tracking performance over traditionally used greedy, one-step planners. Improved tracking is validated with simulations and the system is demonstrated with real drones in flight tests.


Title: Asynchronous Network Formation in Unknown Unbounded Environments*
Key Words: mobile robots  multi-robot systems  path planning  trees (mathematics)  mobile multirobot system  arbitrary robot deployments  robot initial positions  robot configuration  online network formation problem  asynchronous network formation  unknown unbounded environments  ONFP  bounded communication range  competitive ratio  Euclidean minimum spanning tree  Robot kinematics  Task analysis  Partitioning algorithms  Vegetation  Protocols  Peer-to-peer computing 
Abstract: In this paper, we study the Online Network Formation Problem (ONFP) for a mobile multi-robot system. Consider a group of robots with a bounded communication range operating in a large open area. One of the robots has a piece of information which has to be propagated to all other robots. What strategy should the robots pursue to disseminate the information to the rest of the robots as quickly as possible? The initial locations of the robots are unknown to each other, therefore the problem must be solved in an online fashion. For this problem, we present an algorithm whose competitive ratio is O(H · max{M, √MH}) for arbitrary robot deployments, where M is the largest edge length in the Euclidean minimum spanning tree on the initial robot configuration and H is the height of the tree. We also study the case when the robot initial positions are chosen uniformly at random and improve the ratio to O(M). Finally, we present simulation results to validate the performance in larger scales and demonstrate our algorithm using three robots in a field experiment.


Title: Multi-Vehicle Trajectory optimisation On Road Networks
Key Words: integer programming  linear programming  path planning  multivehicle trajectory optimisation  road networks  planning time-optimal trajectories  multiple cooperative agents  static road network  vehicle interactions  nontrivial decisions  complex flow-on effects  globally optimal time trajectory  minimum time trajectory  MILP  computational performance  binary variables  collision constraints  open-pit mining scenario  mixed integer linear programming  goal constraints  heuristic method  Roads  Trajectory  Planning  Automation  Optimization  Iterative methods  Mixed integer linear programming 
Abstract: This paper addresses the problem of planning time-optimal trajectories for multiple cooperative agents along specified paths through a static road network. Vehicle interactions at intersections create non-trivial decisions, with complex flow-on effects for subsequent interactions. A globally optimal, minimum time trajectory is found for all vehicles using Mixed Integer Linear Programming (MILP). Computational performance is improved by minimising binary variables using iteratively applied targeted collision constraints, and efficient goal constraints. Simulation results in an open-pit mining scenario compare the proposed method against a fast heuristic method and a reactive approach based on site practices. The heuristic is found to scale better with problem size while the MILP is able to avoid local minima.


Title: A Generic Optimization Based Cartesian Controller for Robotic Mobile Manipulation
Key Words: angular velocity control  closed loop systems  end effectors  mobile robots  motion control  optimisation  probability  robot vision  service robots  sequential phases  closed loop perspective  generic optimization-based Cartesian controller  motion commands  robotic system  mobile platform  velocity space  end effector velocity  joint platform velocities  base platform velocities  mobile service robot architecture  domestic tasks  robotic mobile manipulation  random arm configurations  Optimization  Kinematics  Manipulators  Robot sensing systems  Real-time systems  Planning 
Abstract: Typically, the problem of robotic manipulation is divided among two sequential phases: a planning one and an execution one. However, since the second one is executed in open loop, the robot is unable to react in real time to changes in the task (e.g. moving object). This paper addresses the mobile manipulation problem from a real-time, closed loop perspective. In particular, we propose a generic optimization-based Cartesian controller, that given a continuous monitoring of the goal, determines the best motion commands. We target our controller to a robotic system comprising an arm and a mobile platform. However, the approach can in principle be extended to more complex mechanisms. The approach is based on shifting the problem to velocity space, where end effector velocity is a linear function of joint and base platform velocities. Our approach was quantitatively evaluated both on simulation and on a real service robot. It was also integrated into a mobile service robot architecture targeting domestic tasks and evaluated on the RoboCup@Home scientific competition. Our results show that the controller is able to reach random arm configurations with a high probability of success.


Title: Task-Driven Estimation and Control via Information Bottlenecks
Key Words: information theory  iterative methods  robots  state estimation  general algorithmic framework  task-driven estimation  state representations  state estimation  task-driven representation  task-relevant variables  performant control policy  robotic system control  principled algorithmic framework  iterative algorithms  information bottleneck optimization problem  Task analysis  Robot sensing systems  Robustness  Optimized production technology  Estimation 
Abstract: Our goal is to develop a principled and general algorithmic framework for task-driven estimation and control for robotic systems. State-of-the-art approaches for controlling robotic systems typically rely heavily on accurately estimating the full state of the robot (e.g., a running robot might estimate joint angles and velocities, torso state, and position relative to a goal). However, full state representations are often excessively rich for the specific task at hand and can lead to significant computational inefficiency and brittleness to errors in state estimation. In contrast, we present an approach that eschews such rich representations and seeks to create task-driven representations. The key technical insight is to leverage the theory of information bottlenecks to formalize the notion of a “task-driven representation” in terms of information theoretic quantities that measure the minimality of a representation. We propose novel iterative algorithms for automatically synthesizing (offline) a task-driven representation (given in terms of a set of task-relevant variables (TRVs)) and a performant control policy that is a function of the TRVs. We present online algorithms for estimating the TRVs in order to apply the control policy. We demonstrate that our approach results in significant robustness to unmodeled measurement uncertainty both theoretically and via thorough simulation experiments including a spring-loaded inverted pendulum running to a goal location.


Title: Feasibility Analysis For Constrained Model Predictive Control Based Motion Cueing Algorithm
Key Words: closed loop systems  motion control  optimal control  predictive control  road traffic control  stability  feasibility issues  implicit model predictive control-based motion cueing algorithms  prediction horizons  control inputs  feasibility analysis  constrained model predictive control based motion cueing algorithm  motion control  constrained optimal control  high performance driving simulator  Acceleration  Force  Stability criteria  Cost function  Heuristic algorithms 
Abstract: This paper deals with motion control for an 8-degree-of-freedom (DOF) high performance driving simulator. We formulate a constrained optimal control that defines the dynamical behavior of the system. Furthermore, the paper brings together various methodologies for addressing feasibility issues arising in implicit model predictive control-based motion cueing algorithms. The implementation of different techniques is described and discussed subsequently. Several simulations are carried out in the simulator platform. It is observed that the only technique that can provide ensured closed-loop stability by assuring feasibility over all prediction horizons is a braking law that basically saturates the control inputs in the constrained form.


Title: Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty
Key Words: Bayes methods  belief networks  control engineering computing  learning (artificial intelligence)  mobile robots  neurocontrollers  robust control  uncertainty-aware robotic perception  explicit generative model  observation distribution  action-conditioned collision prediction task  Bayesian neural network techniques  task-aware generative uncertainty  deep learning  open world  real-world robotic systems  mobile robots  out-of-distribution observations  neural network predictions  robotic perception  approximate Bayesian approach  Uncertainty  Robots  Predictive models  Bayes methods  Neural networks  Training  Collision avoidance 
Abstract: Deep learning provides a powerful tool for robotic perception in the open world. However, real-world robotic systems, especially mobile robots, must be able to react intelligently and safely even in unexpected circumstances. This requires a system that knows what it knows, and can estimate its own uncertainty for unfamiliar, out-of-distribution observations. Approximate Bayesian approaches are commonly used to estimate uncertainty for neural network predictions, but struggle with out-of-distribution observations. Generative models can in principle detect out-of-distribution observations as those with a low estimated density, but overly pessimistic as an uncertainty measure, since the mere presence of an out-of-distribution input does not by itself indicate an unsafe situation. Intuitively, we would like a perception system that can detect when task-salient parts of the image are unfamiliar or uncertain, while ignoring task-irrelevant features. In this paper, we present a method for uncertainty-aware robotic perception that combines generative modeling and model uncertainty. Our method estimates an uncertainty measure about the model's prediction, taking into account an explicit generative model of the observation distribution to handle out-of-distribution inputs. We evaluate our method on an action-conditioned collision prediction task with both simulated and real data, and demonstrate that our approach improves on a variety of Bayesian neural network techniques.


Title: Reinforcement Learning in Topology-based Representation for Human Body Movement with Whole Arm Manipulation
Key Words: humanoid robots  human-robot interaction  learning (artificial intelligence)  manipulator dynamics  medical robotics  path planning  patient care  position control  topology-based representation  human body movement  bulky object  WAM  manipulation places  global properties  local contacts  grasping  reinforcement learning problem  robot behavior  human motion  robot-human interaction  topology-based coordinates  torso positions  learned policy  body shapes  dynamic sea rescue scenario  unseen scenarios  differently-shaped humans  whole arm manipulation  Robot kinematics  Humanoid robots  Manipulators  Laplace equations  Torso  Shape 
Abstract: Moving a human body or a large and bulky object may require the strength of whole arm manipulation (WAM). This type of manipulation places the load on the robot's arms and relies on global properties of the interaction to succeed- rather than local contacts such as grasping or non-prehensile pushing. In this paper, we learn to generate motions that enable WAM for holding and transporting of humans in certain rescue or patient care scenarios. We model the task as a reinforcement learning problem in order to provide a robot behavior that can directly respond to external perturbation and human motion. For this, we represent global properties of the robot-human interaction with topology-based coordinates that are computed from arm and torso positions. These coordinates also allow transferring the learned policy to other body shapes and sizes. For training and evaluation, we simulate a dynamic sea rescue scenario and show in quantitative experiments that the policy can solve unseen scenarios with differently-shaped humans, floating humans, or with perception noise. Our qualitative experiments show the subsequent transporting after holding is achieved and we demonstrate that the policy can be directly transferred to a real world setting.


Title: Deformation-based shape control with a multirobot system
Key Words: feedback  gradient methods  manipulators  mobile robots  multi-robot systems  2D space  useful team behaviors  deformation-based control framework  manipulation task  resulting multirobot controller  robot motions  feedback loop  global measure  typical goal  deformable object  application scenario  robotic team  multirobot system  deformation-based shape control  Robot kinematics  Shape  Strain  Task analysis  Geometry  Shape control 
Abstract: We present a novel method to control the relative positions of the members of a robotic team. The application scenario we consider is the cooperative manipulation of a deformable object in 2D space. A typical goal in this kind of scenario is to minimize the deformation of the object with respect to a desired state. Our contribution, then, is to use a global measure of deformation directly in the feedback loop. In particular, the robot motions are based on the descent along the gradient of a metric that expresses the difference between the team's current configuration and its desired shape. Crucially, the resulting multirobot controller has a simple expression and is inexpensive to compute, and the approach lends itself to analysis of both the transient and asymptotic dynamics of the system. This analysis reveals a number of properties that are interesting for a manipulation task: fundamental geometric parameters of the team (size, orientation, centroid, and distances between robots) can be suitably steered or bounded. We describe different policies within the proposed deformation-based control framework that produce useful team behaviors. We illustrate the methodology with computer simulations.


Title: One-to-many bipartite matching based coalition formation for multi-robot task allocation
Key Words: approximation theory  computational complexity  graph theory  multi-robot systems  multirobot task allocation  multirobot coalition formation  OTMaM problem  multiple robots  robot-task pairs  worst-case approximation ratio  worst-case time complexity  NP-hard problem  one-to-many bipartite matching based coalition formation  Task analysis  Robot kinematics  Resource management  Bipartite graph  Approximation algorithms  Time complexity 
Abstract: In this paper, we study the NP-Hard problem of multi-robot coalition formation for task allocation. To tackle this notoriously difficult problem, we model it as a variant of classical bipartite matching, which we call One-To-Many Bipartite Matching (OTMaM). Unlike the classical bipartite matching techniques used for matching a unique robot to a unique task, in the OTMaM problem, we let multiple robots to be matched to a single task while restricting the opposite. To this end, we propose a novel heuristic algorithm that allocates robots to tasks by finding mutually best robot-task pairs. Our algorithm provides a similar theoretical worst-case approximation ratio and guarantees a better worst-case time complexity than a comparable algorithm from the literature. The proposed approach in this paper is proved to be deterministic and the resultant matching is perfect. Simulation results also demonstrate the scalability of the presented algorithm (taking less than 1 millisecond with 100 robots and 10 tasks).


Title: Multi-Agent Synchronization Using Online Model-Free Action Dependent Dual Heuristic Dynamic Programming Approach
Key Words: adaptive control  approximation theory  discrete time systems  dynamic programming  iterative methods  learning systems  multi-agent systems  neurocontrollers  nonlinear control systems  optimal control  action dependent dual heuristic dynamic programming schemes  fast solution platforms  unknown models  uncertain dynamical models  online model-free adaptive  dynamic graphical games  approximate the optimal value function  associated model-free control strategy  model-free coupled Bellman optimality equation  multiagent synchronization  online model-free action dependent dual heuristic dynamic programming approach  approximate dynamic programming platforms  agents interaction  communication graphs  policy iteration process  Mathematical model  Adaptation models  Optimal control  Dynamic programming  Synchronization  Games  Neural networks 
Abstract: Approximate dynamic programming platforms are employed to solve dynamic graphical games, where the agents interact among each other using communication graphs in order to achieve synchronization. Although the action dependent dual heuristic dynamic programming schemes provide fast solution platforms for several control problems, their capabilities degrade for systems with unknown or uncertain dynamical models. An online model-free adaptive learning solution based on action dependent dual heuristic dynamic programming is proposed to solve the dynamic graphical games. It employs distributed actor-critic neural networks to approximate the optimal value function and the associated model-free control strategy for each agent. This is done using a policy iteration process where it does not employ any extensive computational effort, as traditionally observed. The duality between the model-free coupled Bellman optimality equation and the underlying coupled Riccati equation is highlighted. This is followed by a graph simulation scenario to test the usefulness of the proposed policy iteration process.


Title: A Fuzzy Based Accessibility Model for Disaster Environment
Key Words: angular velocity control  collision avoidance  disasters  fuzzy control  fuzzy reasoning  mobile robots  motion control  navigation  terrain accessibility index  robots position  angular velocities  VFH algorithm  disaster prone environment  FISVFH algorithm  fuzzy based accessibility model  disaster environment  autonomous maneuvering  robot estimate  two-output fuzzy inference system  sector accessibility index  fuzzy inference system vector field histogram method  obstacle distance  linear velocities  two-input fuzzy inference system  Indexes  Angular velocity  Fuzzy logic  Robot sensing systems  Histograms  Mobile robots 
Abstract: Robots that perform autonomous maneuvering in a disaster environment usually dont have perfect understanding of the environment in advance. The robot is continuously evaluating the environment as it proceeds, deciding the optimal way to traverse the environment to get to the goal. A critical aspect of this decision is the robot estimate of the terrain accessibility index, which quantifies how easy it is to navigate through the immediate terrain. This paper represents a new method to calculate terrain accessibility index based on obstacle distance to the robots position. In addition, a Fuzzy Inference System Vector Field Histogram (FISVFH) method has been designed for automating the selection of the robots linear and angular velocities in the VFH (Vector Field Histogram) algorithm, based on the calculated sector accessibility index. The proposed method is a two-input and two-output Fuzzy Inference System, where the current robot heading, and sector accessibility index serve as the input, and the corresponding linear and angular velocities to the VFH algorithm are outputs. The VFH, VFH + and FISVFH are tested both in simulation and experimentation in 4 environments that are known to result in failures in VFH and VFH +, for comparison purposes. In addition, the algorithm was verified through experimental setup of a disaster prone environment. In both simulation and experimentation the results show that FISVFH outperforms VFH and VFH +. It is also shown that the FISVFH algorithm is capable of handling the disaster prone environment. Overall, the FISVFH algorithm enables the robot to get to the goal faster and also produces a smoother path while doing so.


Title: Distributed Radiation Field Estimation and Informative Path Planning for Nuclear Environment Characterization
Key Words: Global Positioning System  mobile robots  optical radar  path planning  photomultipliers  scintillation counters  solid scintillation detectors  thallium  distributed radiation field estimation  informative path planning  nuclear environment characterization  autonomous estimation  distributed nuclear radiation fields  GPS-denied environments  sensing apparatus  radially placed Thallium-doped Cesium Iodide  Silicon Photomultipliers  pulse counting circuitry  provided readings  LiDAR-based localization  radiation intensity readings  immediate field gradient  believed field intensity  local measurement  field gradient co-estimation  informative data gathering  path planning strategy  uncertainty  admissible paths  autonomous exploration  SiPm  Estimation  Detectors  Robot sensing systems  Path planning  Uncertainty  Area measurement 
Abstract: This paper details the system and methods designed to enable the autonomous estimation of distributed nuclear radiation fields within complex and possibly GPS-denied environments. A sensing apparatus consisting of three radially placed Thallium-doped Cesium Iodide (CsI(Tl)) scintillators and Silicon Photomultipliers (SiPm) combined with custom- built pulse counting circuitry is designed and the provided readings are pose-annotated using LiDAR-based localization. Given this capacity, a method that utilizes the radiation intensity readings to first calculate the immediate field gradient and then combine this information to update and co-estimate the believed field intensity and gradient across the whole environment is developed. The strategy propagates the effect of each local measurement through field gradient co-estimation and simultaneously derives a model of the underlying uncertainty. To further support the need for informative data gathering, especially in the framework of emergency and rapid reconnaissance missions, a path planning strategy is also developed that first utilizes the field intensity and uncertainty estimates to select its new waypoint and then performs terrain traversability analysis to derive admissible paths. The complete system is evaluated both in simulation and experimentally. The experimental results refer to the autonomous exploration and field estimation inside an indoor facility within which actual radioactive uranium and thorium ore sources have been distributed.


Title: Multimodal Semantic SLAM with Probabilistic Data Association
Key Words: image fusion  image representation  inference mechanisms  mobile robots  object detection  path planning  probability  robot vision  SLAM (robots)  nonGaussian sensor model  multimodal semantic SLAM  probabilistic data association  robot navigation  semantic SLAM problem  discrete inference problem  object class labels  measurement-landmark correspondences  continuous inference problem  robot poses  object detection systems  simultaneous localization and mapping  object-based representations  object locations  nonGaussian inference problem  Simultaneous localization and mapping  Semantics  Belief propagation  Maximum likelihood estimation  Maximum likelihood detection 
Abstract: The recent success of object detection systems motivates object-based representations for robot navigation; i.e. semantic simultaneous localization and mapping (SLAM). The semantic SLAM problem can be decomposed into a discrete inference problem: determining object class labels and measurement-landmark correspondences (the data association problem), and a continuous inference problem: obtaining the set of robot poses and object locations in the environment. A solution to the semantic SLAM problem necessarily addresses this joint inference, but under ambiguous data associations this is in general a non-Gaussian inference problem, while the majority of previous work focuses on Gaussian inference. Previous solutions to data association either produce solutions between potential hypotheses or maintain multiple explicit hypotheses for each association. We propose a solution that represents hypotheses as multiple modes of an equivalent non-Gaussian sensor model. We then solve the resulting non-Gaussian inference problem using nonparametric belief propagation. We validate our approach in a simulated hallway environment under a variety of sensor noise characteristics, as well as using real data from the KITTI dataset, demonstrating improved robustness to perceptual aliasing and odometry uncertainty.


Title: Multimodal Policy Search using Overlapping Mixtures of Sparse Gaussian Process Prior
Key Words: Bayes methods  Gaussian processes  inference mechanisms  learning (artificial intelligence)  mobile robots  search problems  OMSGPs  optimal policies  reinforcement learning  multimodal policy search algorithm  overlapping mixtures of sparse Gaussian process  Bayesian inference  object grasping  table-sweep tasks  Task analysis  Grasping  Kernel  Gaussian processes  Robots  Inference algorithms  Prediction algorithms 
Abstract: In this paper, we present a novel policy search reinforcement learning algorithm that can deal with multimodality in control policies based on Gaussian processes. Our approach employs Overlapping Mixtures of Gaussian Processes (OMGPs) for a control policy, in which all the GPs in the mixture are global and overlapped in the input space. We first extend the OMGPs by combing sparse pseudo-input GPs as OMSGPs to reduce its computational cost of learning and prediction suitable for policy search. Then, we derive a novel multimodal policy search algorithm based on variational Bayesian inference by placing the OMSGPs as the prior of the multimodal control policy. To validate the effectiveness of our algorithm, we applied it to two typical robotic tasks in simulation: 1) object grasping and 2) table-sweep tasks since they both require the multimodality in the optimal policies. Simulation results demonstrate that our algorithm can efficiently learn multimodal policies even with high dimensional observations.


Title: Online adaptation of uncertain models using neural network priors and partially observable planning
Key Words: Markov processes  mobile robots  neural nets  planning (artificial intelligence)  uncertain systems  online adaptation  uncertain models  neural network priors  partially observable planning  manipulation tasks  encode prior experiences  physics engine  online POMDP solver  observed environments  prediction model  domain complexity  Adaptation models  Task analysis  Physics  Planning  Robots  Engines  Neural networks 
Abstract: One of the key challenges in realizing a robot that is capable of completing a variety of manipulation tasks in the real world is the need to utilize sufficiently compact and rich world models. If the assumed prediction model does not match real observations, planning systems are unable to perform properly. We propose a system that corrects the models based on information collected from the robot's sensors. We encode prior experiences in a neural network to generate possible parameters of the models for a physics engine from real observations. An online POMDP solver is used to plan actions to complete the task while progressively validating and improving the models. We perform experiments in simulations and on a real robot. The results show that this approach appropriately clarifies observed environments, can handle dynamics with discontinuities, and with increasing domain complexity achieves a better success rate than baseline methods.


Title: Data-efficient Learning of Morphology and Controller for a Microrobot
Key Words: Bayes methods  control engineering computing  learning (artificial intelligence)  legged locomotion  microrobots  optimisation  data-efficient learning  robot design  HPC-BBO  hierarchical Bayesian optimization process  morphology configurations  controller learning process  hardware validation  hardware configurations design  6-legged microrobot  Morphology  Optimization  Robots  Bayes methods  Hardware  Process control  Task analysis 
Abstract: Robot design is often a slow and difficult process requiring the iterative construction and testing of prototypes, with the goal of sequentially optimizing the design. For most robots, this process is further complicated by the need, when validating the capabilities of the hardware to solve the desired task, to already have an appropriate controller, which is in turn designed and tuned for the specific hardware. In this paper, we propose a novel approach, HPC-BBO, to efficiently and automatically design hardware configurations, and evaluate them by also automatically tuning the corresponding controller. HPC-BBO is based on a hierarchical Bayesian optimization process which iteratively optimizes morphology configurations (based on the performance of the previous designs during the controller learning process) and subsequently learns the corresponding controllers (exploiting the knowledge collected from optimizing for previous morphologies). Moreover, HPC-BBO can select a “batch” of multiple morphology designs at once, thus parallelizing hardware validation and reducing the number of time-consuming production cycles. We validate HPC-BBO on the design of the morphology and controller for a simulated 6-legged microrobot. Experimental results show that HPC-BBO outperforms multiple competitive baselines, and yields a 360% reduction in production cycles over standard Bayesian optimization, thus reducing the hypothetical manufacturing time of our microrobot from 21 to 4 months.


Title: Prediction Maps for Real-Time 3D Footstep Planning in Dynamic Environments
Key Words: collision avoidance  humanoid robots  mobile robots  robot vision  humanoids  smaller wheeled robots  planar regions  simple 2D occupancy map  environment representation  height information  prediction maps  real-time 3D footstep planning  mobile robots  dynamic obstacle detection  time 10.0 ms  Three-dimensional displays  Tracking  Real-time systems  Mobile robots  Task analysis  Humanoid robots 
Abstract: Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments. Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions. For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information. Considering dynamic obstacles introduces another level of complexity, since they can lead to necessary replanning or collisions at later stages. In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be efficiently planned in real time at low CPU cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.


Title: Automated Models of Human Everyday Activity based on Game and Virtual Reality Technology
Key Words: computer games  knowledge acquisition  virtual reality  virtual reality technology  human everyday manipulation activity  virtual human living  working environments  recorded activity data  knowledge acquisition  human manipulation activities  AMEvA  automated models of everyday activities  knowledge interpretation  knowledge processing system  KNOWROB  Solid modeling  Task analysis  Robots  Force  Games  Virtual reality 
Abstract: In this paper, we will describe AMEvA (Automated Models of Everyday Activities), a special-purpose knowledge acquisition, interpretation, and processing system for human everyday manipulation activity that can automatically: (1) create and simulate virtual human living and working environments (such as kitchens and apartments) with a scope, extent, level of detail, physics, and close to photorealism that facilitates and promotes the natural and realistic execution of human everyday manipulation activities; (2) record human manipulation activities performed in the respective virtual reality environment as well as their effects on the environment and detect force-dynamic states and events; (3) decompose and segment the recorded activity data into meaningful motions and categorize the motions according to action models used in cognitive science; and (4) represent the interpreted activities symbolically in KNOWROB [1] using a first-order time interval logic representation.


Title: Compliant four degree-of-freedom manipulator with locally deformable elastic elements for minimally invasive surgery
Key Words: bending  finite element analysis  manipulators  medical robotics  needles  optimisation  surgery  locally deformable elastic elements  minimally invasive surgery  MIS  surgical robots  robotic technology  compliant four degree-of-freedom manipulator  mechanical parts  robotic instruments  optimization method  FEA  prototype implementation  Springs  Instruments  Strain  Surgery  Manipulators  Medical robotics 
Abstract: Minimally Invasive Surgery (MIS) is one of the most successful applications of surgical robots. Although the introduction of robotic technology has brought a number of benefits, further advancements in MIS are limited by the size and bending radius of instruments. In this paper, we present a compliant four degree-of-freedom manipulator that consists of elastic elements with partly thinner structures. The proposed mechanism allows the elastic element to deform locally, thus minimizing its bending radius while the low number of mechanical parts greatly contributes to its compactness. This paper describes the design strategy, optimization method using FEA, prototype implementation, and evaluations. The evaluations reveal high accuracy and repeat accuracy, which are key elements for robotic instruments in MIS. Further, the prototype is able to exert sufficient force and it is possible to perform a simulated needle insertion task using the manipulator, demonstrating the feasibility of the proposed mechanism.


Title: Learning To Grasp Under Uncertainty Using POMDPs
Key Words: grippers  humanoid robots  learning (artificial intelligence)  Markov processes  object detection  recurrent neural nets  robust control  service robots  uncertainty handling  visual sensing  partially observable Markov decision process  grasp policy  deep recurrent neural network  imitation learning  model-based POMDP planning  G3DB object dataset  service robots  far-field sensors  open-loop grasp  tactile sensing  adaptive grasping  robust object grasping strategy  uncertainty handling  Uncertainty  Grippers  Grasping  Planning  Sensors  Shape  Computational modeling 
Abstract: Robust object grasping under uncertainty is an essential capability of service robots. Many existing approaches rely on far-field sensors, such as cameras, to compute a grasp pose and perform open-loop grasp after placing gripper under the pose. This often fails as a result of sensing or environment uncertainty. This paper presents a principled, general and efficient approach to adaptive grasping, using both tactile and visual sensing as feedback. We first model adaptive grasping as a partially observable Markov decision process (POMDP), which handles uncertainty naturally. We solve the POMDP for sampled objects from a set, in order to generate data for learning. Finally, we train a grasp policy, represented as a deep recurrent neural network (RNN), in simulation through imitation learning. By combining model-based POMDP planning and imitation learning, the proposed approach achieves robustness under uncertainty, generalization over many objects, and fast execution. In particular, we show that modeling only a small sample of objects enables us to learn a robust strategy to grasp previously unseen objects of varying shapes and recover from failure over multiple steps. Experiments on the G3DB object dataset in simulation and a smaller object set with a real robot indicate promising results.


Title: Detection and Tracking of Small Objects in Sparse 3D Laser Range Data
Key Words: autonomous aerial vehicles  data structures  image segmentation  image sensors  laser ranging  median filters  mobile robots  object detection  object tracking  robot vision  solid modelling  autonomous behavior  microaerial vehicles  multiobject tracking  lightweight sensors  sparse point clouds  Velodyne VLP-16 sensor  MAV hardware  unlabeled data  sparse 3d laser range data  objects detection  median filters  data structure  Three-dimensional displays  Sensors  Target tracking  Object tracking  Real-time systems  Vehicle dynamics  Heuristic algorithms 
Abstract: Detection and tracking of dynamic objects is a key feature for autonomous behavior in a continuously changing environment. With the increasing popularity and capability of micro aerial vehicles (MAVs) efficient algorithms have to be utilized to enable multi object tracking on limited hardware and data provided by lightweight sensors. We present a novel segmentation approach based on a combination of median filters and an efficient pipeline for detection and tracking of small objects within sparse point clouds generated by a Velodyne VLP-16 sensor. We achieve real-time performance on a single core of our MAV hardware by exploiting the inherent structure of the data. Our approach is evaluated on simulated and real scans of in- and outdoor environments, obtaining results comparable to the state of the art. Additionally, we provide an application for filtering the dynamic and mapping the static part of the data, generating further insights into the performance of the pipeline on unlabeled data.


Title: Visual Coverage Control for Teams of Quadcopters via Control Barrier Functions
Key Words: computational geometry  distributed control  gradient methods  mobile robots  multi-robot systems  position control  visual coverage control  quadcopters  control barrier functions  coverage control strategy  visual sensors  locational cost  cost function  distributed control law  gradient ascent control law  Space missions  Monitoring  Visualization  Robot sensing systems  Cameras 
Abstract: This paper presents a coverage control strategy for teams of quadcopters that ensures that no area is left unsurveyed in between the fields of view of the visual sensors mounted on the quadcopters. We present a locational cost that quantifies the team's coverage performance according to the sensors' performance function. Moreover, the cost function penalizes overlaps between the fields of view of the different sensors, with the objective of increasing the area covered by the team. A distributed control law is derived for the quadcopters so that they adjust their position and zoom according to the direction of ascent of the cost. Control barrier functions are implemented to ensure that, while executing the gradient ascent control law, no holes appear in between the fields of view of neighboring robots. The performance of the algorithm is evaluated in simulated experiments.


Title: Exact Modal Characterization of the Non Conservative Non Linear Radial Mass Spring System
Key Words: damping  elasticity  linear systems  modal analysis  nonlinear dynamical systems  robot dynamics  shock absorbers  springs (mechanical)  vibration control  exact modal characterization  modal analysis  linear mechanical systems  nonlinear elastic robot  nonlinear normal modes  nonlinear oscillatory behaviors  dissipative effects  damping  nonconservative nonlinear radial mass spring damper system  Manifolds  Springs  Force  Damping  Soft robotics  Dynamics 
Abstract: Since the spread of robotic systems embedding in their mechanics purposefully designed elastic elements, the interest in characterizing and exploiting non-linear oscillatory behaviors has progressively grown. However, few works so far looked at the problem from the point of view of modal analysis. This is particularly surprising if considered the central role that modal theory had in the development of classic results in analysis and control of linear mechanical systems. With the aim of making a step toward translating and extending this powerful tool to the robotic field, we present the complete modal characterization of a simple yet representative non-linear elastic robot: the 2D planar mass-spring-damper system. Generic non-linear elastic forces and dissipative effects are considered. We provide here exact descriptions of the two non-linear normal modes of the system. We then extend the analysis to generic combinations of the modes in conservative case and for small damping. Simulations are provided to illustrate the theoretical results. This is one of the very firsts applications of normal mode theory to dynamically coupled non-linear systems, and the first exact result in the field.


Title: Every Hop is an Opportunity: Quickly Classifying and Adapting to Terrain During Targeted Hopping
Key Words: control engineering computing  learning (artificial intelligence)  learning systems  mobile robots  pattern classification  robot programming  terrain properties  terrain-informed learning  low shot learning  targeted hopping  task-relevant objectives  hopping robot  control strategies  jumping task  closed-loop jumping  real-world jumping data  terrain classification  online learning experiments  Task analysis  Optimal control  Solids  Force  Robot sensing systems  Solid modeling 
Abstract: Practical use of robots in diverse domains requires programming for, or adapting to, each domain and its unique characteristics. Failure to do so compromises the ability of the robot to achieve task-relevant objectives. Here we describe how the learned terrain reaction force profiles of a hopping robot serve the additional objectives of classifying terrain and quickly learning control strategies to accomplish a jumping task on novel terrain. We show that the reaction forces experienced during closed-loop jumping are sufficient to discriminate between three different terrain types (granular, trampoline, and rigid) when using the learned models as discriminators. Building on this, we show that applying the classification to unknown terrain types leads to faster task completion, where the task objective is to meet a specific jump height. The classification experiments, utilizing real-world jumping data, achieve 95% prediction accuracy. The online learning experiments leverage simulation as there is more control over the terrain properties. Terrain-informed learning achieves the target hop heights more than 2x faster than without terrain knowledge when the prediction is correct, and 1.5x faster when the prediction is incorrect. Thus, applying the closest approximately known terrain knowledge facilitates low shot learning when hopping on unknown terrain.


Title: Semantic Predictive Control for Explainable and Efficient Policy Learning
Key Words: image motion analysis  image representation  learning (artificial intelligence)  optimisation  predictive control  visual explanation  policy decisions  SPC  future semantic segmentation  multiscale feature maps  guidance model  multiple simulation environments  model-based reinforcement  data efficiency  short time horizons  human-level performance  complex environments  driving policy learning framework  feature representations  sampling-based optimization  semantic predictive control framework  Semantics  Predictive models  Feature extraction  Visualization  Task analysis  Predictive control  Optimization 
Abstract: Visual anticipation of ego and object motion over a short time horizons is a key feature of human-level performance in complex environments. We propose a driving policy learning framework that predicts feature representations of future visual inputs; our predictive model infers not only future events but also semantics, which provide a visual explanation of policy decisions. Our Semantic Predictive Control (SPC) framework predicts future semantic segmentation and events by aggregating multi-scale feature maps. A guidance model assists action selection and enables efficient sampling-based optimization. Experiments on multiple simulation environments show that networks which implement SPC can outperform existing model-based reinforcement learning algorithms in terms of data efficiency and total rewards while providing clear explanations for the policy's behavior.


Title: Combining Physical Simulators and Object-Based Networks for Control
Key Words: learning (artificial intelligence)  mobile robots  neural nets  object-based neural network  interacting objects  complex control tasks  object shapes  physical simulators  physics engine  robot planning  real-world control problems  complex contact dynamics  hybrid dynamics model  simulator-augmented interaction networks  Physics  Engines  Analytical models  Task analysis  Robots  Predictive models  Mathematical model 
Abstract: Physics engines play an important role in robot planning and control; however, many real-world control problems involve complex contact dynamics that cannot be characterized analytically. Most physics engines therefore employ approximations that lead to a loss in precision. In this paper, we propose a hybrid dynamics model, simulator-augmented interaction networks (SAIN), combining a physics engine with an object-based neural network for dynamics modeling. Compared with existing models that are purely analytical or purely data-driven, our hybrid model captures the dynamics of interacting objects in a more accurate and data-efficient manner. Experiments both in simulation and on a real robot suggest that it also leads to better performance when used in complex control tasks. Finally, we show that our model generalizes to novel environments with varying object shapes and materials.


Title: Using Data-Driven Domain Randomization to Transfer Robust Control Policies to Mobile Robots
Key Words: automobiles  collision avoidance  mobile robots  motion control  probability  robust control  stochastic processes  trajectory control  deep stochastic dynamics model  collision avoidance  1/5 scale agile ground vehicle  robust control policies  vehicle data  collision probability  trajectory tracking accuracy  stochasticity  simple analytic car model  high quality stochastic dynamics model  robot motion trajectories  mobile robots  data-driven domain randomization  Stochastic processes  Data models  Vehicle dynamics  Optimization  Robots  Uncertainty  Computational modeling 
Abstract: This work develops a technique for using robot motion trajectories to create a high quality stochastic dynamics model that is then leveraged in simulation to train control policies with associated performance guarantees. We demonstrate the idea by collecting dynamics data from a 1/5 scale agile ground vehicle, fitting a stochastic dynamics model, and training a policy in simulation to drive around an oval track at up to 6.5 m/s while avoiding obstacles. We show that the control policy can be transferred back to the real vehicle with little loss in predicted performance. We compare this to an approach that uses a simple analytic car model to train a policy in simulation and show that using a model with stochasticity learned from data leads to higher performance in terms of trajectory tracking accuracy and collision probability. Furthermore, we show empirically that simulation-derived performance guarantees transfer to the actual vehicle when executing a policy optimized using a deep stochastic dynamics model fit to vehicle data.


Title: Coordinating multi-robot systems through environment partitioning for adaptive informative sampling
Key Words: image segmentation  mobile robots  multi-robot systems  robot vision  sampling methods  coordinating multirobot systems  environment partitioning  adaptive informative sampling  robotic platforms  time sensitive applications  sensor measurements  highest expected information  multiple robots  system partitions  information rate adaptive sampling approach  simulation environment  region segmentation approach  adaptive information gain rate tasking  naïve closest point approach  region segmentation technique  real world robots  Robot kinematics  Robot sensing systems  Adaptation models  Entropy  Task analysis  Data models 
Abstract: As robotic platforms have become more capable and autonomous, they have increasingly been utilized in time sensitive applications such as search and rescue. To that end, we have developed a system for teams of robots to efficiently explore an environment while taking sensor measurements. The system utilizes an information seeking algorithm that generates high priority points of interest based on the highest expected information gained per distance travelled. In order to coordinate multiple robots, the system partitions the area into different regions according to the effort needed to explore each region. Robots are assigned different regions to measure in order to minimize repetition of work and reduce interference between each robot.We present an information rate adaptive sampling approach for tasking robots within an environment to gather sensor measurements. We evaluated our approach within a simulation environment with one to four robots. Multiple robots are coordinated through our region segmentation approach. The data shows efficiency gains through the use of adaptive information gain rate tasking above a naïve closest point approach. We also see positive results from using the region segmentation technique. We further the experimentation by testing the algorithm on real world robots and verify the results in real world experimentation.


Title: Coverage of an Environment Using Energy-Constrained Unmanned Aerial Vehicles
Key Words: approximation theory  autonomous aerial vehicles  computational complexity  mobile robots  path planning  travelling salesman problems  UGV  area coverage problem  energy-constrained unmanned aerial vehicle  unmanned ground vehicle  symbiotic UAV  NP-hard problem  generalized traveling salesperson problem  boustrophedon cells  limited battery capacity  Batteries  Unmanned aerial vehicles  Agriculture  Robot sensing systems  Strips  Routing 
Abstract: We study the problem of covering an environment using an Unmanned Aerial Vehicle (UAV) with limited battery capacity. We consider a scenario where the UAV can land on an Unmanned Ground Vehicle (UGV) and recharge the onboard battery. The UGV can also recharge the UAV while transporting the UAV to the next take-off site. We present an algorithm to solve a new variant of the area coverage problem that takes into account this symbiotic UAV and UGV system. The input consists of a set of boustrophedon cells - rectangular strips whose width is equal to the field-of-view of the sensor on the UAV. The goal is to find a tour for the UAV that visits and covers all cells in minimum time. This includes flight time for visiting and covering all cells, recharging time, as well as the take-off and landing times. We show how to reduce this problem to a known NP-hard problem, Generalized Traveling Salesperson Problem (GTSP). Given an optimal GTSP solver, our approach finds the optimal coverage paths for the UAV and UGV. We evaluate our algorithm through simulations and proof-of-concept experiments.


Title: Online Plan Repair in Multi-robot Coordination with Disturbances
Key Words: collision avoidance  Gaussian processes  multi-robot systems  path planning  RMTRACK control law  Gaussian process  coordination space obstacle  disturbance probabilities  multirobot coordination  online plan repair  Robot kinematics  Collision avoidance  Trajectory  Maintenance engineering  System recovery  Delays 
Abstract: This paper addresses the problem of multi-robot coordination in scenarios where the robots may experience unexpected delays in their movements. Prior work by Čáp, Gregoire, and Frazzołi introduced a control law, called RMTRACK, which enables robots in such scenarios to execute preplanned paths in spite of disturbances in the execution speed of each robot, while guaranteeing that each robot can reach its goal without collisions and without deadlocks. We extend that approach to handle scenarios in which the disturbance probabilities are unknown at the start and non-uniform across the environment. The key idea is to `repair' a plan on-the-fly, by swapping the order in which a pair of robots passes through a mutual collision region (i.e. a coordination space obstacle), when making such a change can be estimated to improve the overall performance of the system. We introduce a technique based on Gaussian Processes to estimate future disturbances, and propose two algorithms for testing, at appropriate times, whether a swap of a given obstacle would be beneficial. Tests in simulation demonstrate that our algorithm achieves significantly smaller average travel time than RMTRACK at only a modest computational expense.


Title: Active Perception in Adversarial Scenarios using Maximum Entropy Deep Reinforcement Learning
Key Words: belief networks  entropy  learning (artificial intelligence)  multi-agent systems  neural nets  planning (artificial intelligence)  stochastic processes  partial observability  adversary agent  autonomous agent  belief space planning  generative adversary modeling  maximum entropy reinforcement learning  stochastic belief space policy  unmodeled adversarial strategies  maximum entropy deep reinforcement learning  active perception problem  potentially adversarial behaviors  uncertainty modeling  standard chance-constraint partially observable Markov decision  Uncertainty  Games  Autonomous agents  Reinforcement learning  Nash equilibrium  Planning  Adaptation models 
Abstract: We pose an active perception problem where an autonomous agent actively interacts with a second agent with potentially adversarial behaviors. Given the uncertainty in the intent of the other agent, the objective is to collect further evidence to help discriminate potential threats. The main technical challenges are the partial observability of the agent intent, the adversary modeling, and the corresponding uncertainty modeling. Note that an adversary agent may act to mislead the autonomous agent by using a deceptive strategy that is learned from past experiences. We propose an approach that combines belief space planning, generative adversary modeling, and maximum entropy reinforcement learning to obtain a stochastic belief space policy. By accounting for various adversarial behaviors in the simulation framework and minimizing the predictability of the autonomous agent's action, the resulting policy is more robust to unmodeled adversarial strategies. This improved robustness is empirically shown against an adversary that adapts to and exploits the autonomous agent's policy when compared with a standard Chance-Constraint Partially Observable Markov Decision Process robust approach.


Title: A Competitive Algorithm for Online Multi-Robot Exploration of a Translating Plume
Key Words: autonomous aerial vehicles  mobile robots  multi-robot systems  velocity control  arbitrary shape  plume shape  plume speed  robot speed  tour  aerial robots  translating plume  online multirobot exploration  competitive algorithm  Robot kinematics  Two dimensional displays  Approximation algorithms  Shape  Unmanned aerial vehicles  Binary trees 
Abstract: In this paper, we study the problem of exploring a translating plume with a team of aerial robots. The shape and the size of the plume are unknown to the robots. The objective is to find a tour for each robot such that they collectively explore the plume. Specifically, the tours must be such that each point in the plume must be visible from the field-of-view of some robot along its tour. We propose a recursive Depth-First Search (DFS)-based algorithm that yields a constant competitive ratio for the exploration problem. The competitive ratio is 2(Sr + Sp)(R+⌊log R⌋)/(Sr + Sp)(R+⌊log R⌋) where R is the number of robots, and Sr and Sp are the robot speed and the plume speed, respectively. We also consider a more realistic scenario where the plume shape is not restricted to grid cells but an arbitrary shape. We show our algorithm has 2(Sr + Sp)(18 R+⌊log R⌋)/(Sr + Sp)(1+⌊log R⌋) competitive ratio under the fat condition. We empirically verify our algorithm using simulations.


Title: Online Estimation of Ocean Current from Sparse GPS Data for Underwater Vehicles
Key Words: expectation-maximisation algorithm  Gaussian processes  Global Positioning System  mobile robots  position control  regression analysis  underwater vehicles  online estimation  Gaussian process-based expectation-maximisation algorithm  dead-reckoned position estimates  specialised GP regression scheme  best-fitting ocean  ocean current field  underwater vehicles  underwater robots  Oceans  Sea measurements  Current measurement  Global Positioning System  Trajectory  Estimation 
Abstract: Underwater robots are subject to position drift due to the effect of ocean currents and the lack of accurate localisation while submerged. We are interested in exploiting such position drift to estimate the ocean current in the surrounding area, thereby assisting navigation and planning. We present a Gaussian process (GP)-based expectation-maximisation (EM) algorithm that estimates the underlying ocean current using sparse GPS data obtained on the surface and dead-reckoned position estimates. We first develop a specialised GP regression scheme that exploits the incompressibility of ocean currents to counteract the underdetermined nature of the problem. We then use the proposed regression scheme in an EM algorithm that estimates the best-fitting ocean current in between each GPS fix. The proposed algorithm is validated in simulation and on a real dataset, and is shown to be capable of reconstructing the underlying ocean current field. We expect to use this algorithm to close the loop between planning and estimation for underwater navigation in unknown ocean currents.


Title: Working towards Adaptive Sensing for Terrain-aided Navigation
Key Words: adaptive signal processing  altimeters  autonomous underwater vehicles  Kalman filters  marine navigation  particle filtering (numerical methods)  sonar  underwater vehicles  velocity measurement  terrain-aided navigation  adaptive sensing method  pinging rate  localization accuracy  TAN  sonar pinging interval  local seafloor topography  modified Teager Kaiser energy operator  pinging interval  downward-looking sonar  autonomous underwater vehicle  particle filter  bias velocity estimator  Kalman filter  depth variation  Atmospheric measurements  Sea measurements  Particle measurements  Sonar navigation  Sensors  Sonar 
Abstract: An adaptive sensing method is presented to control the pinging interval of a downward-looking sonar on an Autonomous Underwater Vehicle. The goal is to conserve energy via adjusting the pinging rate automatically without reducing the localization accuracy when using terrain-aided navigation (TAN). In this paper, the TAN is implemented using a particle filter and a bias velocity estimator developed based on a Kalman filter. The adaptation on the sonar pinging interval is determined based on the depth variation of local seafloor topography which is quantified using a modified Teager Kaiser energy operator. As a result, more measurements are collected on high relief regions, and less measurements are obtained on relatively flat and smooth regions. We evaluated the adaptive sensing method in a simulated environment and applied it to a field data set. The results show that the adaptive sensing method produces an improved navigational accuracy compared to the missions with fixed sonar pinging rates. In the offline field missions, the energy consumed by the altimeter is reduced to about 30% in the adaptive sensing missions compared to continuously sensing missions where the altimeter is pinging consistently without switching off.


Title: Underwater Terrain Reconstruction from Forward-Looking Sonar Imagery
Key Words: feature extraction  Gaussian processes  graph theory  image reconstruction  mobile robots  remotely operated vehicles  SLAM (robots)  sonar imaging  terrain mapping  underwater vehicles  terrain reconstruction  forward-looking sonar imagery  underwater simultaneous localization  multibeam imaging sonar  3D terrain mapping tasks  elevation angle information  data association  accurate 3D mapping  Euclidean space  optical flow  bearing-range images  subsea terrain  Gaussian Process random field  terrain factors  factor graph  terrain elevation estimate  variable-elevation tank environment  smooth height estimate  sonar images  Chow-Liu tree  extracted feature tracking  Feature extraction  Sonar measurements  Simultaneous localization and mapping  Three-dimensional displays  Gaussian processes  Imaging 
Abstract: In this paper, we propose a novel approach for underwater simultaneous localization and mapping using a multibeam imaging sonar for 3D terrain mapping tasks. The high levels of noise and the absence of elevation angle information in sonar images present major challenges for data association and accurate 3D mapping. Instead of repeatedly projecting extracted features into Euclidean space, we apply optical flow within bearing-range images for tracking extracted features. To deal with degenerate cases, such as when tracking is interrupted by noise, we model the subsea terrain as a Gaussian Process random field on a Chow-Liu tree. Terrain factors are incorporated into the factor graph, aimed at smoothing the terrain elevation estimate. We demonstrate the performance of our proposed algorithm in a simulated environment, which shows that terrain factors effectively reduce estimation error. We also show ROV experiments performed in a variable-elevation tank environment, where we are able to construct a descriptive and smooth height estimate of the tank bottom.


Title: Learning Object Localization and 6D Pose Estimation from Simulation and Weakly Labeled Real Images
Key Words: image annotation  image classification  image segmentation  object detection  pose estimation  robot vision  unsupervised learning  6D pose estimation  computer vision models  object localization  multiple domain classifiers  synthetic images  object poses  time-consuming annotations  occluded scenes  cluttered scenes  weak object detector  deep learning approaches  cluttered environments  robust robotic grasping  Feature extraction  Pose estimation  Training  Robots  Heating systems  Solid modeling  Task analysis 
Abstract: Accurate pose estimation is often a requirement for robust robotic grasping and manipulation of objects placed in cluttered, tight environments, such as a shelf with multiple objects. When deep learning approaches are employed to perform this task, they typically require a large amount of training data. However, obtaining precise 6 degrees of freedom for ground-truth can be prohibitively expensive. This work therefore proposes an architecture and a training process to solve this issue. More precisely, we present a weak object detector that enables localizing objects and estimating their 6D poses in cluttered and occluded scenes. To minimize the human labor required for annotations, the proposed detector is trained with a combination of synthetic and a few weakly annotated real images (as little as 10 images per object), for which a human provides only a list of objects present in each image (no time-consuming annotations, such as bounding boxes, segmentation masks and object poses). To close the gap between real and synthetic images, we use multiple domain classifiers trained adversarially. During the inference phase, the resulting class-specific heatmaps of the weak detector are used to guide the search of 6D poses of objects. Our proposed approach is evaluated on several publicly available datasets for pose estimation. We also evaluated our model on classification and localization in unsupervised and semi-supervised settings. The results clearly indicate that this approach could provide an efficient way toward fully automating the training process of computer vision models used in robotics.


Title: Learning Pose Estimation for High-Precision Robotic Assembly Using Simulated Depth Images
Key Words: CAD  cameras  convolutional neural nets  end effectors  industrial manipulators  learning (artificial intelligence)  pose estimation  production engineering computing  robot vision  robotic assembly  3D CAD models  depth camera  deep convolutional neural networks  industrial robotic assembly tasks  depth images  pose estimation learning  two-stage pose estimation procedure  end-effector  Conferences  Automation 
Abstract: Most of industrial robotic assembly tasks today require fixed initial conditions for successful assembly. These constraints induce high production costs and low adaptability to new tasks. In this work we aim towards flexible and adaptable robotic assembly by using 3D CAD models for all parts to be assembled. We focus on a generic assembly task - the Siemens Innovation Challenge - in which a robot needs to assemble a gear-like mechanism with high precision into an operating system. To obtain the millimeter-accuracy required for this task and industrial settings alike, we use a depth camera mounted near the robot's end-effector. We present a high-accuracy two-stage pose estimation procedure based on deep convolutional neural networks, which includes detection, pose estimation, refinement, and handling of near- and full symmetries of parts. The networks are trained on simulated depth images with means to ensure successful transfer to the real robot. We obtain an average pose estimation error of 2.16 millimeters and 0.64 degree leading to 91% success rate for robotic assembly of randomly distributed parts. To the best of our knowledge, this is the first time that the Siemens Innovation Challenge is fully addressed, with all the parts assembled with high success rates.


Title: Aided Inertial Navigation: Unified Feature Representations and Observability Analysis
Key Words: inertial navigation  Jacobian matrices  Monte Carlo methods  observability  global yaw rotation  line features  closest point parameterization  observability properties  unified representations  closest point form  unified parameterizations  CP representations  EKF-based vision-aided INS  geometrical features  unified feature representations  aided inertial navigation systems  homogeneous geometric features  general aided INS  linearized aided INS  minimal representation  observability analysis  4D Euclidean vector  analytically-computed Jacobians  Monte-Carlo simulations  Observability  Quaternions  Jacobian matrices  Noise measurement  Pollution measurement  Three-dimensional displays  Q measurement 
Abstract: Extending our recent work [1] that focuses on the observability analysis of aided inertial navigation systems (INS) using homogeneous geometric features including points, lines and planes, in this paper, we complete the analysis for the general aided INS using different combinations of geometric features (i.e., points, lines and planes). We analytically show that the linearized aided INS with different feature combinations generally possesses the same observability properties as those with same features, i.e., 4 unobservable directions, corresponding to the global yaw rotation and the global position of the sensor platform. During the analysis, we particularly propose a novel minimal representation of line features, i.e., the “closest point” parameterization, which uses a 4D Euclidean vector to describe a line and is proved to preserve the same observability properties. Based on that, for the first time, we provide two sets of unified representations for points, lines and planes, i.e., the quaternion form and the closest point (CP) form, and perform extensive observability analysis with analytically-computed Jacobians for these unified parameterizations. We validate the proposed CP representations and observability analysis with Monte-Carlo simulations, in which EKF-based vision-aided INS (VINS) with combinations of geometrical features in CP form are developed and compared.


Title: Sensor-Failure-Resilient Multi-IMU Visual-Inertial Navigation
Key Words: calibration  inertial navigation  sensor fusion  sensor-failure-resilient multiIMU visual-inertial navigation  real-time multiIMU visual-inertial navigation system  multiple inertial measurement units  mi-VINS formulation  auxiliary sensors  base IMU failure  sensor failure  conventional VINS  multiple IMUs  Calibration  Cameras  Robot sensing systems  Navigation  Covariance matrices  Fuses  Visualization 
Abstract: In this paper, we present a real-time multi-IMU visual-inertial navigation system (mi-VINS) that utilizes the information from multiple inertial measurement units (IMUs) and thus is resilient to IMU sensor failures. In particular, in the proposed mi-VINS formulation, one of the IMUs serves as the “base” of the system, while the rest act as auxiliary sensors aiding in state estimation. A key advantage of this architecture is the ability to seamlessly “promote” an auxiliary IMU as a new base, for example, upon detection of the base IMU failure, thus being resilient to the single point of sensor failure as seen in conventional VINS. Moreover, in order to properly fuse the information of multiple IMUs, both the spatial (relative pose) and temporal (time offset) calibration parameters between each sensor and the base IMU are estimated online. The proposed miVINS with online spatial and temporal calibration is validated in both simulations and real-world experiments, and is shown to be able to provide accurate localization and calibration even in scenarios with IMU sensor failures.


Title: Central Pattern Generators Control of Momentum Driven Compliant Structures
Key Words: actuators  legged locomotion  motion control  optimisation  robot dynamics  co-evolved structures  control-only optimized equivalent  MDS  inertially actuated units  compliant elements  control method  bio-inspired concept  compliance distribution  locomotion performance  population based optimization techniques  momentum driven compliant structures  central pattern generator control  hardware complexity  CPG  rough environment exploration  Robots  Torque  Three-dimensional displays  Complexity theory  Generators  Aerospace electronics  Space exploration 
Abstract: We introduce the concept of Momentum Driven Structures (MDS) made of inertially actuated units linked together by compliant elements as a potential solution for rough environments exploration. We propose a control method for MDS based on the bio-inspired concept of Central Pattern Generator (CPG) and study in simulation the impact of compliance distribution on locomotion performance using population based optimization techniques. Our results suggest that compliant structures outperform their rigid counterparts in terms of distance traveled. In addition, we show that co-evolved structures perform only marginally better than their control-only optimized equivalent, highlighting the fact that compliance modulation may not be a significant asset in such experiments, considering the related hardware complexity it introduces.


Title: PointNetGPD: Detecting Grasp Configurations from Point Sets
Key Words: computational geometry  feature extraction  grippers  image colour analysis  learning (artificial intelligence)  PointNetGPD  end-to-end grasp evaluation  object grasping  3D point cloud  grasp configuration detection  point sets  robot grasp configurations  complex geometric structure  gripper  3D geometry information  deep neural network  RGB-D camera  Three-dimensional displays  Robot sensing systems  Measurement  Grippers  Grasping  Solid modeling  Geometry 
Abstract: In this paper, we propose an end-to-end grasp evaluation model to address the challenging problem of localizing robot grasp configurations directly from the point cloud. Compared to recent grasp evaluation metrics that are based on handcrafted depth features and a convolutional neural network (CNN), our proposed PointNetGPD is lightweight and can directly process the 3D point cloud that locates within the gripper for grasp evaluation. Taking the raw point cloud as input, our proposed grasp evaluation network can capture the complex geometric structure of the contact area between the gripper and the object even if the point cloud is very sparse. To further improve our proposed model, we generate a large-scale grasp dataset with 350k real point cloud and grasps with the YCB object set for training. The performance of the proposed model is quantitatively measured both in simulation and on robotic hardware. Experiments on object grasping and clutter removal show that our proposed model generalizes well to novel objects and outperforms state-of-the-art methods. Code and video are available at https://lianghongzhuo.github.io/PointNetGPD.


Title: Learning Deep Visuomotor Policies for Dexterous Hand Manipulation
Key Words: dexterous manipulators  learning (artificial intelligence)  tactile sensors  touch sensing information  expert demonstration trajectories  high dimensional visual observations  manipulation tasks  imitation learning  on-board sensors  tactile sensors  external tracking  on-board sensing capabilities  in-hand manipulation  multifingered dexterous hands  dexterous hand manipulation  deep visuomotor policies  Task analysis  Visualization  Training  Tactile sensors 
Abstract: Multi-fingered dexterous hands are versatile and capable of acquiring a diverse set of skills such as grasping, in-hand manipulation, and tool use. To fully utilize their versatility in real-world scenarios, we require algorithms and policies that can control them using on-board sensing capabilities, without relying on external tracking or motion capture systems. Cameras and tactile sensors are the most widely used on-board sensors that do not require instrumentation of the world. In this work, we demonstrate an imitation learning based approach to train deep visuomotor policies for a variety of manipulation tasks with a simulated five fingered dexterous hand. These policies directly control the hand using high dimensional visual observations of the world and propreoceptive observations from the robot, and can be trained efficiently with a few hundred expert demonstration trajectories. We also find that using touch sensing information enables faster learning and better asymptotic performance for tasks with high degree of occlusions. Video demonstration of our results are available at: https://sites.google.com/view/hand-vil/.


Title: Dexterous Manipulation with Deep Reinforcement Learning: Efficient, General, and Low-Cost
Key Words: control engineering computing  dexterous manipulators  learning (artificial intelligence)  neural nets  robot programming  deep reinforcement learning  multifingered hands  contact-rich manipulation behavior  model-free deep RL algorithms  complex multifingered manipulation skills  direct deep RL training  model-based control  dexterous manipulation  dexterous multifingered robotic hands  general-purpose robotic manipulators  autonomous control  complex intermittent contact interactions  Task analysis  Valves  Acceleration  Reinforcement learning  Robot sensing systems  Hardware 
Abstract: Dexterous multi-fingered robotic hands can perform a wide range of manipulation skills, making them an appealing component for general-purpose robotic manipulators. However, such hands pose a major challenge for autonomous control, due to the high dimensionality of their configuration space and complex intermittent contact interactions. In this work, we propose deep reinforcement learning (deep RL) as a scalable solution for learning complex, contact rich behaviors with multi-fingered hands. Deep RL provides an end-to-end approach to directly map sensor readings to actions, without the need for task specific models or policy classes. We show that contact-rich manipulation behavior with multi-fingered hands can be learned by directly training with model-free deep RL algorithms in the real world, with minimal additional assumption and without the aid of simulation. We learn to perform a variety of tasks on two different low-cost hardware platforms entirely from scratch, and further study how the learning can be accelerated by using a small number of human demonstrations. Our experiments demonstrate that complex multi-fingered manipulation skills can be learned in the real world in about 4-7 hours for most tasks, and that demonstrations can decrease this to 2-3 hours, indicating that direct deep RL training in the real world is a viable and practical alternative to simulation and model-based control. https:// sites.google.com/view/deeprl-handmanipulation.


Title: Generative Deformation: Procedural Perforation for Elastic Structures
Key Words: deformation  elasticity  finite element analysis  solid modelling  stress analysis  three-dimensional printing  generative deformation  procedural perforation  elastic structures  procedural generation  controlling designing 3D printed deformable object behaviors  generative algorithms  cohesive process  variable elasticity  automated method  simulated deformations  cohesive pipeline model  volumetric structures  stress analysis  consumer-level 3D printers  finite element analysis metrics  elastic 3D prints  design objectives  elastic material behaviors  heterogeneous geometric structure  3D print deformations  automated pipeline  design environment  perforated deformation models  heterogeneous lattice structures  automated generation  3D print procedure  elastic material capabilities  Three-dimensional displays  Strain  Deformable models  Stress  Pipelines  Solid modeling  Printers 
Abstract: Procedural generation of elastic structures provides the fundamental basis for controlling and designing 3D printed deformable object behaviors. The automation through generative algorithms provides flexibility in how design and functionality can be seamlessly integrated into a cohesive process that generates 3D prints with variable elasticity. Generative deformation introduces an automated method for perforating existing volumetric structures, promoting simulated deformations, and integrating stress analysis into a cohesive pipeline model that can be used with existing consumer-level 3D printers with elastic material capabilities. In this work, we present a consolidated implementation of the design, simulate, refine, and 3D print procedure based on the automated generation of heterogeneous lattice structures. We utilize Finite Element Analysis (FEA) metrics to generate perforated deformation models that adhere to deformation behaviors created within our design environment. We present the core algorithms, automated pipeline, and 3D print deformations of various objects. Quantitative results illustrate how the heterogeneous geometric structure can influence elastic material behaviors towards design objectives. Our method provides an automated open-source tool for quickly prototyping elastic 3D prints.


Title: Dynamic Walking on Slippery Surfaces : Demonstrating Stable Bipedal Gaits with Planned Ground Slippage*
Key Words: legged locomotion  nonlinear control systems  optimisation  robot dynamics  stability  stick-slip  trajectory control  lubricated surface  rough no-slip surface  foot slippage  slippery surfaces  stable bipedal gaits  planned ground slippage  dynamic bipedal robot locomotion  trajectory generation  nonlinear control  stabilization  low-friction surfaces  outdoor terrains  trajectory optimization  stick-slip transitions  point foot contact  Coulomb's friction law  slippery walking gait  AMBER-3M planar biped robot  dynamic walking  robot stance foot  Legged locomotion  Foot  Friction  Dynamics  Rough surfaces  Surface roughness 
Abstract: Dynamic bipedal robot locomotion has achieved remarkable success due in part to recent advances in trajectory generation and nonlinear control for stabilization. A key assumption utilized in both theory and experiments is that the robot's stance foot always makes no-slip contact with the ground, including at impacts. This assumption breaks down on slippery low-friction surfaces, as commonly encountered in outdoor terrains, leading to failure and loss of stability. In this work, we extend the theoretical analysis and trajectory optimization to account for stick-slip transitions at point foot contact using Coulomb's friction law. Using AMBER-3M planar biped robot as an experimental platform, we demonstrate for the first time a slippery walking gait which can be stabilized successfully both on a lubricated surface and on a rough no-slip surface. We also study the influence of foot slippage on reducing the mechanical cost of transport, and compare energy efficiency in both numerical simulation and experimental measurement.


Title: Torque and velocity controllers to perform jumps with a humanoid robot: theory and implementation on the iCub robot
Key Words: angular velocity control  humanoid robots  legged locomotion  motion control  optimisation  torque control  torque controller  velocity controller  velocity controllers  iCub robot  jumping  iCub humanoid robot  optimization  predefined CoM trajectory  centroidal angular momentum  Legged locomotion  Humanoid robots  Trajectory  Angular velocity  Optimization  Task analysis 
Abstract: Jumping can be an effective way of locomotion to overcome small terrain gaps or obstacles. In this paper we propose two different approaches to perform jumps with a humanoid robot. Specifically, starting from a pre-defined CoM trajectory we develop the theory for a velocity controller and for a torque controller based on an optimization technique for the evaluation of the joints input. The controllers have been tested both in simulation and on the humanoid robot iCub. In simulation the robot was able to jump using both controllers, while the real system jumped with the velocity controller only. The results highlight the importance of controlling the centroidal angular momentum and they suggest that the joint performances, namely maximum power, of the legs and torso joints, and the low level control performances are fundamental to achieve acceptable results.


Title: State Estimation in Contact-Rich Manipulation
Key Words: Bayes methods  manipulator dynamics  multi-robot systems  robot kinematics  robot vision  state estimation  torque control  complex manipulation scenario  state estimation  Bayesian state estimator  nonprehensile manipulation  industrial assembly  in-hand localization  contact dynamics  torque-based robot controller  robot kinematics  multiple robots  articulated objects  physical robot  freedom object  multimodal distributions  Dynamics  Computational modeling  Manipulators  Bayes methods  Estimation  Probabilistic logic 
Abstract: This paper introduces a Bayesian state estimator for contact-rich manipulation tasks with application in non-prehensile manipulation, industrial assembly or in-hand localization. The core idea of our approach is to explicitly model both the contact dynamics and a torque-based robot controller as part of the underlying system model. Our approach is capable of estimating the state of movable objects for various robot kinematics and geometries of robots and objects. This includes complex scenarios with multiple robots, multiple objects and articulated objects. We have validated our approach in simulation and on a physical robot. The experiments show that multimodal distributions of six degrees of freedom object poses can be accurately tracked in real-time in a complex manipulation scenario.


Title: Autonomous Tissue Manipulation via Surgical Robot Using Learning Based Model Predictive Control
Key Words: biological tissues  learning (artificial intelligence)  manipulators  medical robotics  mobile robots  predictive control  robot vision  surgery  autonomous tissue manipulation  soft tissue  AI learning  vision strategies  Raven IV surgical robotic system  predictive control algorithms  reinforcement learning  Robots  Heuristic algorithms  Prediction algorithms  Surgery  Neural networks  Task analysis  Aerospace electronics  Robotic Tissue Manipulation  Reinforcement Learning  Learning from Demonstration  Neural Networks  Simulation  Surgery  Automation  Machine Learning  Artificial Intelligence  AI  Raven Surgical Robot  Medical Robotics 
Abstract: Tissue manipulation is a frequently used fundamental subtask of any surgical procedures, and in some cases it may require the involvement of a surgeon's assistant. The complex dynamics of soft tissue as an unstructured environment is one of the main challenges in any attempt to automate the manipulation of it via a surgical robotic system. Two AI learning based model predictive control algorithms using vision strategies are proposed and studied: (1) reinforcement learning and (2) learning from demonstration. Comparison of the performance of these AI algorithms in a simulation setting indicated that the learning from demonstration algorithm can boost the learning policy by initializing the predicted dynamics with given demonstrations. Furthermore, the learning from demonstration algorithm is implemented on a Raven IV surgical robotic system and successfully demonstrated feasibility of the proposed algorithm using an experimental approach. This study is part of a profound vision in which the role of a surgeon will be redefined as a pure decision maker whereas the vast majority of the manipulation will be conducted autonomously by a surgical robotic system. A supplementary video can be found at: http://bionics.seas.ucla.edu/research/surgeryproject17.html.


Title: A Novel Iterative Learning Model Predictive Control Method for Soft Bending Actuators
Key Words: actuators  bending  elasticity  iterative learning control  predictive control  robots  soft bending actuators  soft robots  pseudorigid-body model  bending behavior  learning curve  learning process  soft-elastic composite actuator  iterative learning model predictive control method  Mathematical model  Predictive models  Soft robotics  Actuators  Iterative methods  Predictive control  Computational modeling  Soft Material Robotics  Motion Control  Model Learning for Control 
Abstract: Soft robots attract research interests worldwide. However, its control remains challenging due to the difficulty in sensing and accurate modeling. In this paper, we propose a novel iterative learning model predictive control (ILMPC) method for soft bending actuators. The uniqueness of our approach is the ability to improve model accuracy gradually. In this method, a pseudo-rigid-body model is used to take an initial guess of the bending behavior of the actuator and the model accuracy is improved with iterative learning. Compared with conventional model free iterative learning control (ILC), the proposed method significantly reduces the learning curve. Compared with the model predictive control (MPC), the proposed method does not rely on an accurate model and it will output a satisfactory model after the learning process. A soft-elastic composite actuator (SECA) is used to validate the proposed method. Both simulation and experimental results show that the proposed method outperforms the conventional MPC and ILC.


Title: Mechanical Framework Design with Experimental Verification of a Wearable Exoskeleton Chair
Key Words: bending  biomechanics  electromyography  ergonomics  finite element analysis  medical signal processing  orthotics  solid modelling  HUST-EC  vastus lateralis  vastus medialis  biceps femoris  rectus femoris  muscle activation  chair height  bending angles  chair angles  MATLAB-based acquisition software  EMG sensors  electromyography test platform  finite element analysis program  solid models  prototype chair  wearable chair design  human-chair model  wearable exoskeleton chair  Conferences  Automation  exoskeleton  wearable chair  EMG  mechanism design 
Abstract: In this study, a human-chair model was developed as the basis for a wearable chair design. A prototype chair, HUST-EC, was fabricated and evaluated. Employing the optimization under an inner point penalty function, an optimized simulation of the operating mode with the lowest chair height was implemented. The solid models were established by using the finite element analysis program embedded in Solidworks, which revealed that the support from the designed chair was steady to the user. An electromyography (EMG) test platform has been developed, consisting of four EMG sensors, a MATLAB-based acquisition software, and a loaded vest. Four healthy subjects participated in the evaluation experiment, in which EMGs were collected from the muscle groups of rectus femoris, biceps femoris, vastus medialis, and vastus lateralis under different loads and chair angles. The experimental data demonstrate that (1) the HUST-EC can greatly reduce muscle activation at a variety of loads and bending angles; (2) under the same load, the muscle activation decreases slightly with an increased bending angle; and (3) at the same bending angle, muscle activation increases slightly with an increased load. The results show that the designed chair can effectively reduce the physical burden in workers and may improve work efficiency.


Title: Diffraction-Aware Sound Localization for a Non-Line-of-Sight Source
Key Words: acoustic signal processing  acoustic wave diffraction  acoustic wave propagation  particle filtering (numerical methods)  ray tracing  generated acoustic rays  estimated source position  static NLOS sound sources  dynamic NLOS sound sources  actual source locations  state-of-the-art localization method  nonline-of-sight source  sound localization algorithm  nonline-of-sight sound source  indoor environments  diffraction properties  sound waves  bending effects  virtual sound source  indoor scene  diffraction acoustic rays  ray tracing-based sound propagation  diffraction-aware sound localization  UTD  uniform theory of diffraction  wedge precomputing  reconstructed mesh  particle filter  size 7.0 m  size 3.0 m  Diffraction  Ray tracing  Three-dimensional displays  Computational modeling  Acoustic diffraction  Robots 
Abstract: We present a novel sound localization algorithm for a non-line-of-sight (NLOS) sound source in indoor environments. Our approach exploits the diffraction properties of sound waves as they bend around a barrier or an obstacle in the scene. We combine a ray tracing-based sound propagation algorithm with a Uniform Theory of Diffraction (UTD) model, which simulate bending effects by placing a virtual sound source on a wedge in the environment. We precompute the wedges of a reconstructed mesh of an indoor scene and use them to generate diffraction acoustic rays to localize the 3D position of the source. Our method identifies the convergence region of those generated acoustic rays as the estimated source position based on a particle filter. We have evaluated our algorithm in multiple scenarios consisting of static and dynamic NLOS sound sources. In our tested cases, our approach can localize a source position with an average accuracy error of 0.7m, measured by the L2 distance between estimated and actual source locations in a 7m×7m×3m room. Furthermore, we observe 37% to 130% improvement in accuracy over a state-of-the-art localization method that does not model diffraction effects, especially when a sound source is not visible to the robot.


Title: Modeling and Control of a Passively-Coupled Tilt-Rotor Vertical Takeoff and Landing Aircraft
Key Words: actuators  aerospace components  aircraft control  attitude control  autonomous aerial vehicles  cascade control  control system synthesis  helicopters  hinges  mobile robots  propellers  rotors (mechanical)  three-term control  velocity control  quadrotor frame  fixed-wing aircraft  hover  forward flight  tilting actuators  coupled dynamics  aircraft frame  cascaded control architecture  control design  forward velocity control  passively-coupled tilt-rotor vertical takeoff and landing aircraft  differential thrust  propellers  inner-loop attitude  height control  constrained Lagrangian approach  P-PID controllers  unactuated hinged mechanism  equations of motion  unmanned aerial vehicles  UAVs  Aircraft  Mathematical model  Atmospheric modeling  Aerodynamics  Aerospace control  Rotors  Angular velocity  Vertical takeoff and landing aircraft  passively-coupled tilt-rotor  dynamic modeling  cascade PID control  PX4 autopilot 
Abstract: This paper presents the modeling and control of a passively-coupled tilt-rotor vertical takeoff and landing aircraft. The aircraft consists of a quadrotor frame attached to a fixed-wing aircraft by an unactuated hinged mechanism. The platform is capable of smooth transitions from hover to forward flight without the use of tilting actuators. The transition from hover to forward flight is made possible by differential thrust between the fore and aft propellers of the quadrotor frame. In this paper, the coupled dynamics between the quadrotor frame and the aircraft frame are modeled as a constrained multi-body system. The equations of motion are established using a constrained Lagrangian approach and the model developed is used to build a realistic simulation environment for control design purpose. A cascaded control architecture based on P/PID controllers is proposed to achieve inner-loop attitude, height and forward velocity control. Simulated and experimental results are obtained with a close match for hover, transitions, forward flight, and banked turn maneuvers.


Title: Contact–based Navigation Path Planning for Aerial Robots
Key Words: autonomous aerial vehicles  mobile robots  path planning  remotely operated vehicles  robot dynamics  robot kinematics  aerial robots  in-contact operation  contact missions  flying robot  navigation mode  cartwheel mode  navigation modalities  in-contact navigation  specialized contact mechanism  contact-based navigation path planning  Navigation  Task analysis  Unmanned aerial vehicles  Inspection  Path planning  Mobile robots 
Abstract: In this paper the problem of contact-based navigation path planning for aerial robots is considered with the goal of enabling the autonomous in-contact operation on surfaces that can be highly anomalous. Such a capacity can prove critical in inspection through contact missions, as well as when a flying robot is tasked to operate in very narrow environments rendering safe free-flight impossible. To achieve this objective, beyond sliding in contact, a new locomotion primitive is introduced, namely that of azimuth rotations perpendicular to the surface under consideration. This new navigation mode, called flying cartwheel mode, offers navigation resourcefulness and resilience when the system is tasked to move in contact with surfaces that are otherwise non-traversable. The designed path planning method exploits both navigation modalities and a traversability metric to decide when to switch from sliding to flying cartwheel mode, and overall provides cost-optimal trajectories for in-contact navigation. The proposed approach is verified both in simulation, as well as experimentally using a surface presenting complex anomalies. It is highlighted that the proposed method does not assume any specialized contact mechanism or a control law tailored to physical interaction tasks, and hence is applicable to almost any micro aerial vehicle integrating protective shrouds around its propellers.


Title: Toward Lateral Aerial Grasping & Manipulation Using Scalable Suction
Key Words: grippers  mobile robots  self-adjusting systems  stability  scalable suction  aerial robot  lateral physical work  ground-based robots  functional work  lateral force  hovering vehicle  environmental forces  self-sealing suction cup  flight vehicle  physical grasping demonstrations  suction-based gripper  Grippers  Force  Spirals  Propulsion  Electron tubes  Robot sensing systems 
Abstract: This paper is an initial step toward the realization of an aerial robot that can perform lateral physical work, such as drilling a hole or fastening a screw in a wall. Aerial robots are capable of high maneuverability and can provide access to locations that would be difficult or impossible for ground-based robots to reach. However, to fully utilize this mobility, systems would ideally be able to perform functional work in those locations, requiring the ability to exert lateral forces. To substantially improve a hovering vehicle's ability to stably deliver large lateral forces, we propose the use of a versatile suction-based gripper that can establish pulling contact on featureless surfaces. Such contact enables access to environmental forces that can be used to further stabilize the vehicle and also increase the lateral force delivered to the surface through a possible secondary mechanism. This paper introduces the concept, describes the design of a new self-sealing suction cup based on a previous design, details the design of a gripper using those cups, and describes the arm and flight vehicle. It then evaluates the cup and gripper performance in several ways, culminating in physical grasping demonstrations using the arm and gripper, including one in the presence of simulated flight noise based on data from preliminary indoor flight experiments.


Title: Urban Swarms: A new approach for autonomous waste management
Key Words: geographic information systems  mobile robots  multi-robot systems  navigation  path planning  refuse disposal  service robots  garbage collection scenarios  urban swarms  ecosystems  bio-inspired foraging methods  multiplace foraging  real-world GIS data  robot swarms  urban waste management system  stigmergy-based navigation  urban environment  swarm robotics system  autonomous waste management  Robots  Urban areas  Roads  Waste management  RFID tags  Swarm robotics  Batteries 
Abstract: Modern cities are growing ecosystems that face new challenges due to the increasing population demands. One of the many problems they face nowadays is waste management, which has become a pressing issue requiring new solutions. Swarm robotics systems have been attracting an increasing amount of attention in the past years and they are expected to become one of the main driving factors for innovation in the field of robotics. The research presented in this paper explores the feasibility of a swarm robotics system in an urban environment. By using bio-inspired foraging methods such as multi-place foraging and stigmergy-based navigation, a swarm of robots is able to improve the efficiency and autonomy of the urban waste management system in a realistic scenario. To achieve this, a diverse set of simulation experiments was conducted using real-world GIS data and implementing different garbage collection scenarios driven by robot swarms. Results presented in this research show that the proposed system outperforms current approaches. Moreover, results not only show the efficiency of our solution, but also give insights about how to design and customize these systems.


Title: A Multi-Vehicle Trajectories Generator to Simulate Vehicle-to-Vehicle Encountering Scenarios
Key Words: mobile robots  path planning  position control  remotely operated vehicles  road traffic  road vehicles  vehicle-to-vehicle encountering scenarios  autonomous vehicle development  multivehicle trajectory generator  MTG  multivehicle interaction scenarios  driving encounter scenarios  multibranch decoder  vehicle-to-vehicle encounters  autonomous vehicles  Trajectory  Measurement  Decoding  Generators  Bidirectional control  Generative adversarial networks  Stability analysis 
Abstract: Generating multi-vehicle trajectories from existing limited data can provide rich resources for autonomous vehicle development and testing. This paper introduces a multi-vehicle trajectory generator (MTG) that can encode multi-vehicle interaction scenarios (called driving encounters) into an interpretable representation from which new driving encounter scenarios are generated by sampling. The MTG consists of a bi-directional encoder and a multi-branch decoder. A new disentanglement metric is then developed for model analyses and comparisons in terms of model robustness and the independence of the latent codes. Comparison of our proposed MTG with β-VAE and InfoGAN demonstrates that the MTG has stronger capability to purposely generate rational vehicle-to-vehicle encounters through operating the disentangled latent codes. Thus the MTG could provide more data for engineers and researchers to develop testing and evaluation scenarios for autonomous vehicles.


Title: SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud
Key Words: image segmentation  object detection  optical radar  rendering (computer graphics)  unsupervised learning  LiDAR point cloud  deep-learning-based approaches  point cloud segmentation  SqueezeSetV2  data collection  domain-adaptation training pipeline  domain adaptation pipeline  unsupervised domain adaptation  road-object segmentation  domain-adaptation methods  Three-dimensional displays  Laser radar  Training  Adaptation models  Data models  Pipelines  Sensors 
Abstract: Earlier work demonstrates the promise of deep-learning-based approaches for point cloud segmentation; however, these approaches need to be improved to be practically useful. To this end, we introduce a new model SqueezeSegV2. With an improved model structure, SqueezeSetV2 is more robust against dropout noises in LiDAR point cloud and therefore achieves significant accuracy improvement. Training models for point cloud segmentation requires large amounts of labeled data, which is expensive to obtain. To sidestep the cost of data collection and annotation, simulators such as GTA-V can be used to create unlimited amounts of labeled, synthetic data. However, due to domain shift, models trained on synthetic data often do not generalize well to the real world. Existing domain-adaptation methods mainly focus on images and most of them cannot be directly applied to point clouds. We address this problem with a domain-adaptation training pipeline consisting of three major components: 1) learned intensity rendering, 2) geodesic correlation alignment, and 3) progressive domain calibration. When trained on real data, our new model exhibits segmentation accuracy improvements of 6.0-8.6% over the original SqueezeSeg. When training our new model on synthetic data using the proposed domain adaptation pipeline, we nearly double test accuracy on real-world data, from 29.0% to 57.4%. Our source code and synthetic dataset are open sourced. https://github.com/xuanyuzhou98/SqueezeSegV2.


Title: A Framework for Self-Training Perceptual Agents in Simulated Photorealistic Environments
Key Words: computer games  learning (artificial intelligence)  mobile robots  object recognition  robot vision  virtual reality  self-training perceptual agents  simulated photorealistic environments  high-performance perception  mobile robotic agents  gaming industry  game engines  perceptual agent  virtual environment  task-specific object distribution  description language  learning environments  object recognition  sensory input  robotic system  Task analysis  Robots  Training data  Engines  Virtual environments  Games  Data models  Self-Training Perception  Robotic Simulation  Unreal Engine  Scenario Description 
Abstract: The development of high-performance perception for mobile robotic agents is still challenging. Learning appropriate perception models usually requires extensive amounts of labeled training data that ideally follows the same distribution as the data an agent will encounter in its target task. Recent developments in gaming industry led to game engines able to generate photorealistic environments in real-time, which can be used to realistically simulate the sensory input of an agent.We propose a novel framework which allows the definition of different learning scenarios and instantiates these scenarios in a high quality game engine where a perceptual agent can act and learn in. The scenarios are specified in a newly developed scenario description language that allows the parametrization of the virtual environment and the perceptual agent. New scenarios can be sampled from a task-specific object distribution that allows the automatic generation of extensive amounts of different learning environments for the perceptual agent.We will demonstrate the plausibility of the framework by conducting object recognition experiments on a real robotic system which has been trained within our framework.


Title: Vibration Control for Manipulators on a Translationally Flexible Base
Key Words: damping  flexible manipulators  Lyapunov methods  manipulator dynamics  numerical analysis  springs (mechanical)  stability  vibration control  vibration control  manipulators  translationally flexible base  fundamental oscillatory system  mass spring system  control strategy couples  n-link manipulator  linear translational stiffness  conditional stability argument  base vibrations  input transformation  coordinate transformation  semidefinite Lyapunov functions  Vibrations  Manipulator dynamics  Task analysis  Robot kinematics  Damping 
Abstract: In this contribution the problem of vibration control is studied on the basis of a fundamental oscillatory system consisting of a mass spring system and an additional mass. The proposed control strategy couples the orbits of the two masses such that both masses stop, while simultaneously stabilizing the second mass to a desired equilibrium. Using a coordinate and input transformation, the control strategy is directly transferred to an n-link manipulator mounted on a base with linear translational stiffness. Using semidefinite Lyapunov functions and a conditional stability argument, it is shown that the proposed control strategy damps out base vibrations, while additionally achieving a desired configuration in the task-space. Finally, the proposed method is compared to a state-of-the-art approach using numerical simulations.


Title: Salty-A Domain Specific Language for GR(1) Specifications and Designs
Key Words: autonomous aerial vehicles  control system synthesis  formal specification  mobile robots  path planning  program debugging  remotely operated vehicles  specification languages  sanity checking  high-level specifications  domain-specific language  specification optimization  robot controller design  specification patterns  Salty domain specific language  GR(1) specifications  correct-by-construction synthesis approach  generalized reactivity(1) specifications  Slugs synthesis tool  multiple unmanned air vehicles  UAV  Target tracking  Robot kinematics  Tools  Software  Unmanned aerial vehicles  Control systems 
Abstract: Designing robot controllers that correctly react to changes in the environment is a time-consuming and error-prone process. An alternative is to use “correct-by-construction” synthesis approaches to automatically generate controller designs from high-level specifications. In particular, Generalized Reactivity(l) or GR(1) specifications are well-suited to express specifications for robots that must act in dynamic environments, and approaches to generate controller designs from GR(1) specifications are highly computationally efficient. Toward that end, this paper presents Salty, a domain-specific language for GR(1) specifications. While tools exist to synthesize system designs from GR(1) specifications, Salty makes such specifications easier to write and debug by supporting features such as richer input and output types, user-defined macros, common specification patterns, and specification optimization and sanity checking. Salty interfaces with the separately developed synthesis tool Slugs to produce a system or controller design, and Salty translates this design to a software implementation in a variety of languages. We demonstrate Salty on an application involving coordination of multiple unmanned air vehicles (UAVs) and provide a workflow for connecting synthesized UAV controllers to freely available UAV planning and simulation software suites UxAS and AMASE.


Title: Persistent Multi-Robot Mapping in an Uncertain Environment
Key Words: mobile robots  multi-agent systems  multi-robot systems  path planning  probability  multiagent spatio-temporal states  world model  persistent multirobot mapping  uncertain environment  constrained energy capacities  typical occupancy map approaches  static world  occupancy probability  grid cells  promotes revisitation  unchanging areas  naive planning  tractable subproblems  tractable computation time  Robots  Clustering algorithms  Indexes  Planning  Computational modeling  Sensors  Heuristic algorithms 
Abstract: This paper proposes a method to deploy teams of robots with constrained energy capacities to persistently maintain a map of an uncertain environment. Typical occupancy map approaches assume a static world; however, we introduce a decay in confidence that degrades the occupancy probability of grid cells and promotes revisitation. Further, sections of the map whose occupancy differs between observations are visited more frequently, while unchanging areas are scheduled less frequently. While naive planning is intractable through the entire space of multi-agent spatio-temporal states, the proposed algorithm decouples planning such that constraints are resolved separately by solving tracTable subproblems. We evaluate this approach in simulation and show how the uncertainty of our world model is maintained below an acceptable threshold while the algorithm retains a tractable computation time.


Title: Streamlines for Motion Planning in Underwater Currents
Key Words: autonomous underwater vehicles  motion control  path planning  reachability analysis  sampling methods  stream functions  control space  complicated flows  underwater currents  underwater vehicles  ocean currents  reachability  sampling-based motion planning  Australia  Aerospace electronics  Planning  Underwater vehicles  Two dimensional displays  Oceans  Australia  Level set 
Abstract: Motion planning for underwater vehicles must consider the effect of ocean currents. We present an efficient method to compute reachability and cost between sample points in sampling-based motion planning that supports long-range planning over hundreds of kilometres in complicated flows. The idea is to search a reduced space of control inputs that consists of stream functions whose level sets, or streamlines, optimally connect two given points. Such stream functions are generated by superimposing a control input onto the underlying current flow. A streamline represents the resulting path that a vehicle would follow as it is carried along by the current given that control input. We provide rigorous analysis that shows how our method avoids exhaustive search of the control space, and demonstrate simulated examples in complicated flows including a traversal along the east coast of Australia, using actual current predictions, between Sydney and Brisbane.


Title: A Distributed Predictive Control Approach for Cooperative Manipulation of Multiple Underwater Vehicle Manipulator Systems
Key Words: autonomous underwater vehicles  collision avoidance  distributed control  feedback  manipulator dynamics  manipulators  mobile robots  motion control  multi-robot systems  nonlinear control systems  position control  predictive control  control input saturations  coupled dynamics  load sharing coefficients  distributed NMPC  object transportation  constrained workspace  static obstacles  kinematic representation singularities  joint limits  multiple underwater vehicle manipulator systems  nonlinear model predictive control approach  distributed predictive control approach  UVMS locally measurements  Task analysis  Kinematics  Robot sensing systems  Jacobian matrices  End effectors  Vehicle dynamics 
Abstract: This paper addresses the problem of cooperative object transportation for multiple Underwater Vehicle Manipulator Systems (UVMSs) in a constrained workspace involving static obstacles. We propose a Nonlinear Model Predictive Control (NMPC) approach for a team of UVMSs in order to transport an object while avoiding significant constraints and limitations such as: kinematic and representation singularities, obstacles within the workspace, joint limits and control input saturations. More precisely, by exploiting the coupled dynamics between the robots and the object, and using certain load sharing coefficients, we design a distributed NMPC for each UVMS in order to cooperatively transport the object within the workspace's feasible region. Moreover, the control scheme adopts load sharing among the UVMSs according to their specific payload capabilities. Additionally, the feedback relies on each UVMS's locally measurements and no explicit data is exchanged online among the robots, thus reducing the required communication bandwidth. Finally, real-time simulation results conducted in UwSim dynamic simulator running in ROS environment verify the efficiency of the theoretical finding.


Title: Ambient light based depth control of underwater robotic unit aMussel
Key Words: autonomous underwater vehicles  mobile robots  pressure sensors  underwater robotic unit  1DOF  ambient light sensor  aMussel holding depth  pressure sensor  one degree-of-freedom  weather conditions  acoustic communication  Robot sensing systems  Pressure sensors  Buoyancy  Pistons  Simulation  Force 
Abstract: In this paper, we present a method for depth control of one degree of freedom (1DOF) underwater robotic platform aMussel, based on the measurements from the ambient light sensor. Since ambient light values change during the day and depend on the weather conditions, references for the controller are acquired from other aMussel holding depth using pressure sensor based controller. Control inputs are transmitted using acoustic communication.


Title: A Unified Closed-Loop Motion Planning Approach For An I-AUV In Cluttered Environment With Localization Uncertainty
Key Words: autonomous underwater vehicles  closed loop systems  collision avoidance  cooperative systems  manipulators  mobile robots  motion control  optimisation  position control  remotely operated vehicles  cluttered environment  localization uncertainty  trajectory optimization problem  optimal trajectory  I-AUV trajectories  optimization solvers  quasiquadratic optimization problems  null space saturation controller  cluttered underwater environments  optimal collision-free  intervention autonomous underwater vehicle  linear-quadratic-Gaussian controller  base trajectories  unified closed-loop motion planning approach  Trajectory  Planning  Manipulators  Uncertainty  Optimization  Aerospace electronics  Task analysis  Intervention AUV  Motion planning  Uncertainty minimization 
Abstract: This paper presents a unified motion planning approach for an Intervention Autonomous Underwater Vehicle (I-AUV) in a cluttered environment with localization uncertainty. With the uncertainty being propagated by an information filter, a trajectory optimization problem closed by a Linear-Quadratic-Gaussian controller is formulated for a coupled design of optimal trajectory, localization, and control. Due to the presence of obstacles or complexity of the cluttered environment, a set of feasible initial I-AUV trajectories covering multiple homotopy classes are required by optimization solvers. Parameterized through polynomials, the initial base trajectories are from solving quasi-quadratic optimization problems that are linearly constrained by waypoints from RRTconnect, while the initial trajectories of the manipulator are generated by a null space saturation controller. Simulations on an I-AUV with a 3 DOF manipulator in cluttered underwater environments demonstrated that initial trajectories are generated efficiently and that optimal and collision-free I-AUV trajectories with low state uncertainty are obtained.


Title: Robot Communication Via Motion: Closing the Underwater Human-Robot Interaction Loop
Key Words: control engineering computing  human-robot interaction  mobile robots  robot communication  underwater human-robot interaction loop  colored lights  underwater robots  robot-to-human communication methods  body language gestures  communication vector  Robots  Solids  Task analysis  Unmanned underwater vehicles  Communication systems  Human-robot interaction  Hardware 
Abstract: In this paper, we propose a novel method for underwater robot-to-human communication using the motion of the robot as “body language”. To evaluate this system, we develop simulated examples of the system's body language gestures, called kinemes, and compare them to a baseline system using flashing colored lights through a user study. Our work shows evidence that motion can be used as a successful communication vector which is accurate, easy to learn, and quick enough to be used, all without requiring any additional hardware to be added to our platform. We thus contribute to “closing the loop” for human-robot interaction underwater by proposing and testing this system, suggesting a library of possible body language gestures for underwater robots, and offering insight on the design of nonverbal robot-to-human communication methods.


Title: A Multimodal Aerial Underwater Vehicle with Extended Endurance and Capabilities
Key Words: aerospace components  aircraft control  autonomous aerial vehicles  autonomous underwater vehicles  design engineering  motion control  pneumatic systems  three-term control  vehicle dynamics  multimodal hybrid aerial underwater vehicle  MHAUV  design concept  fixed-wing unmanned aerial vehicle  extended endurance  Newton-Euler formalism  multidomain simulation  underwater glide test  design principles  proportional-integral-derivative  multirotor  lightweight pneumatic buoyancy adjustment system  vehicle's physical parameters  gliding equilibrium points  vehicle's motion control  Buoyancy  Bladder  Underwater vehicles  Prototypes  Rotors  Unmanned aerial vehicles  Mathematical model 
Abstract: A new solution to improving the poor endurance of the existing hybrid aerial underwater vehicle (HAUV) is proposed in this paper. The proposed multimodal hybrid aerial underwater vehicle (MHAUV) merges the design concept of the fixed-wing unmanned aerial vehicle (UAV), the multirotor, and the underwater glider (UG) and has a novel lightweight pneumatic buoyancy adjustment system. MHAUV is well suited for moving in distinct medium and can achieve extended endurance for long distance travel in both air and water. The mathematical model is given based on Newton-Euler formalism. Necessary design principles of the vehicle's physical parameters are obtained through different gliding equilibrium points. Then, a control scheme composed of two separate proportional-integral-derivative (PID) is employed for the vehicle's motion control in multi-domain simulation. The simulation results are presented to verify the multi-domain mobility and the mode switch ability of the proposed vehicle intuitively. Finally, a prototype, NEZHA, is introduced to be the experimental platform. The success of the flight test, the hovering test, the underwater glide test, and the medium transition test all contribute to prove the feasibility of the proposed concept of the novel MHAUV.


Title: Improving the Robustness of Visual-Inertial Extended Kalman Filtering
Key Words: drag  image filtering  inertial navigation  Kalman filters  Monte Carlo methods  nonlinear filters  observability  state estimation  observability  consistency problems  three-fold improvement  linear drag term  velocity dynamics  estimation accuracy  partial-update formulation  linearization errors  partially-observable states  sensor biases  normally unobservable position  heading states  visual-inertial state estimation problem  Monte Carlo simulation experiment  visual-inertial Kalman filters  visual-inertial extended Kalman filtering  visual-inertial navigation methods  global measurements  Cameras  Quaternions  Estimation  Kalman filters  Mathematical model  Robustness  Navigation 
Abstract: Visual-inertial navigation methods have been shown to be an effective, low-cost way to operate autonomously without GPS or other global measurements, however most filtering approaches to VI suffer from observability and consistency problems. To increase robustness of the state-of-the-art methods, we propose a three-fold improvement. First, we propose the addition of a linear drag term in the velocity dynamics which improves estimation accuracy. Second, we propose the use of a partial-update formulation which limits the effect of linearization errors in partially-observable states, such as sensor biases. Finally, we propose the use of a keyframe reset step to enforce observability and consistency of the normally unobservable position and heading states. While all of these concepts have been used independently in the past, our experiments demonstrate additional strength when they are used simultaneously in a visual-inertial state estimation problem. In this paper, we derive the proposed filter and use a Monte Carlo simulation experiment to analyze the response of visual-inertial Kalman filters with the above described additions. The results of this study show that the combination of all of these features significantly improves estimation accuracy and consistency.


Title: Towards Fully Dense Direct Filter-Based Monocular Visual-Inertial Odometry
Key Words: covariance matrices  distance measurement  gradient methods  image filtering  image texture  matrix inversion  mobile robots  robot vision  smoothing methods  low-textured areas  smooth gradients  complexity reduction methods  direct filter-based monocular visual-inertial odometry  direct filter-based visual-inertial odometry method  Cameras  Integrated circuits  Uncertainty  Complexity theory  Estimation  Covariance matrices  Jacobian matrices 
Abstract: We propose a fully dense direct filter-based visual-inertial odometry method estimating both pixel depth for all pixels and robot state simultaneously, having all uncertainties in the same state vector. Due to the fully dense method, our approach works even in low-textured areas with very low, smooth gradients (i.e. scenes where feature based or semi-dense approaches fail). Our algorithm performs in real-time on a CPU with a time complexity linearly dependent on the amount of pixels in the provided image. To achieve this, we propose complexity reduction methods for fast matrix inversion, exploiting specific structures of the covariance matrix. We provide both simulated and real-world results in low-textured areas with a smooth gradient.


Title: Characterizing the Effects of Reduced Gravity on Rover Wheel-Soil Interactions using Computer Vision Techniques
Key Words: computer vision  Mars  mobile robots  planetary rovers  planetary surfaces  soil  wheels  lower gravity  soil resistance  weaker soil bonding  rover mobility  reduced-mass rover  full-mass rover  rover wheel-soil interactions  computer vision techniques  planetary rovers  Martian soil simulant  rover-soil visualization technique  reduced gravity wheel-terrain interaction  ExoMars wheel prototype  simulated Martian gravity  wheel normal load  ExoMars space mission  Wheels  Soil  Gravity  Moon  Aircraft  Space vehicles  Earth 
Abstract: Mitigating potential hazards for planetary rovers posed by soft soils requires testing in representative environments such as with Martian soil simulants in reduced gravity. This work describes the experimentation, methods, and results of a rover-soil visualization technique that produced rich datasets of reduced gravity wheel-terrain interaction. The activities are linked to the upcoming ExoMars space mission, through the use of ExoMars wheel prototype and Martian soil simulant in simulated Martian gravity produced in parabolic flights. The results indicate that, with wheel normal load held equal between experiments, the amount of soil mobilized by wheel-soil interaction increases as gravity decreases. Moreover, the amount of soil mobilized is more sensitive to slip in lower gravity. The results of the visualization analysis suggest a deterioration in the soil resistance and weaker soil bonding at lower gravities, which undermines the rover mobility by reducing the net traction. The results have important implications regarding the practice of using a reduced-mass rover on Earth to assess the performance of a full-mass rover in similar soil on an extraterrestrial surface.


Title: Adaptive H∞ Controller for Precise Manoeuvring of a Space Robot
Key Words: adaptive control  aerospace robotics  assembling  control system synthesis  H∞ control  manipulators  mirrors  motion control  nonlinear control systems  position control  robust control  space vehicles  space robot  precise manoeuvring  controlled-floating mode  in-orbit telescope assembly  robotic arm  slow manoeuvres  precise manoeuvres  orbital assembly missions  robustness  optical mirrors  nonlinear H∞ controller  adaptive H∞ controller  Space vehicles  Aerospace electronics  Robot kinematics  Manipulators  Uncertainty  Orbits 
Abstract: A space robot working in a controlled-floating mode can be used for performing in-orbit telescope assembly through simultaneously controlling the motion of the spacecraft base and its robotic arm. Handling and assembling optical mirrors requires the space robot to achieve slow and precise manoeuvres regardless of the disturbances and errors in the trajectory. The robustness offered by the nonlinear H∞ controller, in the presence of environmental disturbances and parametric uncertainties, makes it a viable solution. However, using fixed tuning parameters for this controller does not always result in the desired performance as the arm's trajectory is not known a priori for orbital assembly missions. In this paper, a complete study on the impact of the different tuning parameters is performed and a new adaptive H∞ controller is developed based on bounded functions. The simulation results presented show that the proposed adaptive H∞ controller guarantees robustness and precise tracking using a minimal amount of forces and torques for assembly operations using a small space robot.


Title: Teaching Robots To Draw
Key Words: handwritten character recognition  manipulators  natural language processing  teaching  just-drawn handwritten characters  writing utensil  target stroke  continuous drawing motion  handcrafted rules  predefined paths  stroke-based drawing  teaching robots  manipulator robots  line drawings  Automation  Machine-to-machine communications 
Abstract: In this paper, we introduce an approach which enables manipulator robots to write handwritten characters or line drawings. Given an image of just-drawn handwritten characters, the robot infers a plan to replicate the image with a writing utensil, and then reproduces the image. Our approach draws each target stroke in one continuous drawing motion and does not rely on handcrafted rules or on predefined paths of characters. Instead, it learns to write from a dataset of demonstrations. We evaluate our approach in both simulation and on two real robots. Our model can draw handwritten characters in a variety of languages which are disjoint from the training set, such as Greek, Tamil, or Hindi, and also reproduce any stroke-based drawing from an image of the drawing.


Title: Learning Probabilistic Multi-Modal Actor Models for Vision-Based Robotic Grasping
Key Words: Gaussian processes  learning (artificial intelligence)  manipulators  neural nets  robot vision  statistical distributions  inference time  probabilistic multimodal actor models  vision-based robotic grasping  neural density model  neural network  normalizing flows  complex probability distributions  Gaussian mixture  conditional distribution  4 dimensional action space  Training  Grasping  Robots  Neural networks  Computational modeling  Predictive models  Probability distribution 
Abstract: Many previous works approach vision-based robotic grasping by training a value network that evaluates grasp proposals. These approaches require an optimization process at run-time to infer the best action from the value network. As a result, the inference time grows exponentially as the dimension of action space increases. We propose an alternative method, by directly training a neural density model to approximate the conditional distribution of successful grasp poses from the input images. We construct a neural network that combines Gaussian mixture and normalizing flows, which is able to represent multi-modal, complex probability distributions. We demonstrate on both simulation and real robot that the proposed actor model achieves similar performance compared to the value network using the Cross-Entropy Method (CEM) for inference, on top-down grasping with a 4 dimensional action space. Our actor model reduces the inference time by 3 times compared to the state-of-the-art CEM method. We believe that actor models will play an important role when scaling up these approaches to higher dimensional action spaces.


Title: Learning to Drive from Simulation without Real World Labels
Key Words: cameras  closed loop systems  control engineering computing  learning (artificial intelligence)  learning systems  mobile robots  road vehicles  robot vision  traffic engineering computing  domain transfer  single-camera control policy  simulation control labels  driving performance  rural roads  urban roads  machine learning systems  simulated environment  vision-based lane  driving policy  rural road  image-to-image translation  autonomous vehicle  open-loop regression metric  Aerospace electronics  Image reconstruction  Task analysis  Semantics  Training  Roads  Measurement 
Abstract: Simulation can be a powerful tool for under-standing machine learning systems and designing methods to solve real-world problems. Training and evaluating methods purely in simulation is often “doomed to succeed” at the desired task in a simulated environment, but the resulting models are incapable of operation in the real world. Here we present and evaluate a method for transferring a vision-based lane following driving policy from simulation to operation on a rural road without any real-world labels. Our approach leverages recent advances in image-to-image translation to achieve domain transfer while jointly learning a single-camera control policy from simulation control labels. We assess the driving performance of this method using both open-loop regression metrics, and closed-loop performance operating an autonomous vehicle on rural and urban roads.


Title: Fabrication and Characterization of Muscle Rings Using Circular Mould and Rotary Electrical Stimulation for Bio-Syncretic Robots
Key Words: actuators  biological tissues  biomechanics  cardiology  cellular biophysics  electromechanical actuators  medical robotics  muscle  physiological models  tissue engineering  circular mould  rotary electrical stimulation  bio-syncretic robots  high-quality muscle rings  living biological systems  electromechanical systems  natural biological entities  3D skeletal muscles  contraction force  electrical pulses stimulation  control property  3D muscle tissues  muscle tissue engineering  Muscles  Electrical stimulation  Electrodes  Service robots  Skeleton 
Abstract: Bio-syncretic robots made up of living biological systems and electromechanical systems may have the potential excellent performance of natural biological entities. Therefore, the study of the bio-syncretic robots has got lots of attention in recent years. The 3D skeletal muscles have been used widely, due to the considerable contraction force and the controllability. However, the low differentiation quality of the C2C12 in the tissues hinders the broad application in the development of the skeleton muscle actuated bio-syncretic robots. In this work, an approach based on circular mould and rotary electrical stimulation to build high-quality muscle rings, which can be used to actuate various bio-syncretic robots, has been proposed. Firstly, the advantage of the proposed circular mould for the muscle rings culture has been shown by simulation. Then, the muscle rings have been fabricated with different moulds using the experiment-optimized compositions of the biological mixture. After that, the muscle rings in the circular moulds with different electrical stimulations have been cultured, to show the superiority of the proposed rotary electrical stimulation. Moreover, the contractility of the muscle rings have been measured under the different electrical pulses stimulation, for the study of the control property of the muscle rings. This work may be meaningful not only the development of bio-syncretic robots actuated by 3D muscle tissues but also the muscle tissue engineering.


Title: Orienting Oocytes using Vibrations for In-Vitro Fertilization Procedures
Key Words: biomedical equipment  bioMEMS  cellular biophysics  genetics  medical robotics  micromanipulators  patient diagnosis  vibrations  orienting oocytes  vibrations  assisted reproductive technologies  sperm injection  manual manipulation  error procedure  skilled embryologists  desired orientation  IVF clinics  extensive changes  standard equipment  surface transducer  pipette holder  pipette tip axis  vibration burst  polar body detection algorithm  system cause rotation  micropipettes  in-vitro fertilization procedures  2D motion  Vibrations  Transducers  Automation  Subspace constraints  Glass  Cameras  Resonant frequency 
Abstract: Accurate positioning of cells is a fundamental task for many procedures in assisted reproductive technologies (e.g. intracytoplasmic sperm injection or preimplantation genetic diagnosis) to extract or insert materials into and from the cell without causing damage to it. The current method of manual manipulation is based on a trial and error procedure performed by skilled embryologists, where they use two different micropipettes to rotate the cell and immobilize it in the desired orientation. This procedure is time consuming, inconsistent and has a low efficiency. Attempts to automate the process presented in the literature have not yet been implemented in IVF clinics because their high degree of automation requires extensive changes to the current systems used in the clinics. We designed a system that can easily be integrated into standard equipment of IVF clinics and allows automated as well as manual manipulation of cells. The system uses vibrations induced by a surface transducer at the pipette holder to rotate the cell around the pipette tip axis, resulting in 2D motion. To detect if the polar body is in the desired position after a vibration burst, we developed a polar body detection algorithm. We performed simulations and experiments to confirm that vibrations at the natural frequencies of the system cause rotation around the pipette tip axis. Experimental results show that the system is capable of positioning the polar body in plane in less than 5.41 seconds.


Title: Look No Deeper: Recognizing Places from Opposing Viewpoints under Varying Scene Appearance using Single-View Depth Estimation
Key Words: cameras  computer vision  feature extraction  image filtering  image matching  image representation  image sensors  image sequences  object detection  keypoint sequence  single query image  depth-filtered keypoint sequences  camera motion  varying scene appearance  single-view depth estimation  familiar visual place  extreme environmental appearance change  field-of-view vision  temporal-aware visual place recognition system  extreme appearance-change visual place recognition problem  sequence-to-single frame matching  depth-filtered keypoints  depth estimation pipeline  Visualization  Estimation  Feature extraction  Cameras  Indexes  Robots  Measurement 
Abstract: Visual place recognition (VPR) - the act of recognizing a familiar visual place - becomes difficult when there is extreme environmental appearance change or viewpoint change. Particularly challenging is the scenario where both phenomena occur simultaneously, such as when returning for the first time along a road at night that was previously traversed during the day in the opposite direction. While such problems can be solved with panoramic sensors, humans solve this problem regularly with limited field-of-view vision and without needing to constantly turn around. In this paper, we present a new depth- and temporal-aware visual place recognition system that solves the opposing viewpoint, extreme appearance-change visual place recognition problem. Our system performs sequence-to-single frame matching by extracting depth-filtered keypoints using a state-of-the-art depth estimation pipeline, constructing a keypoint sequence over multiple frames from the reference dataset, and comparing these keypoints to the keypoints extracted from a single query image. We evaluate the system on a challenging benchmark dataset and show that it consistently outperforms state-of-the-art techniques. We also develop a range of diagnostic simulation experiments that characterize the contribution of depth-filtered keypoint sequences with respect to key domain parameters including the degree of appearance change and camera motion.


Title: MetaGrasp: Data Efficient Grasping by Affordance Interpreter Network
Key Words: dexterous manipulators  grippers  image colour analysis  inference mechanisms  learning (artificial intelligence)  robot vision  data efficient grasping  data-driven approach  training data  data collection  grasp training system  model inference  antipodal grasp rule  affordance map  ungraspability  grasp affordances  pixel-level affordance interpreter network  quantitative experiments  real-world grasp experiments  qualitative experiments  Grasping  Training  Data collection  Data models  Grippers  Robots  Deep learning 
Abstract: Data-driven approach for grasping shows significant advance recently. But these approaches usually require much training data. To increase the efficiency of grasping data collection, this paper presents a novel grasp training system including the whole pipeline from data collection to model inference. The system can collect effective grasp sample with a corrective strategy assisted by antipodal grasp rule, and we design an affordance interpreter network to predict pixelwise grasp affordance map. We define graspability, ungraspability and background as grasp affordances. The key advantage of our system is that the pixel-level affordance interpreter network trained with only a small number of grasp samples under antipodal rule can achieve significant performance on totally unseen objects and backgrounds. The training sample is only collected in simulation. Extensive qualitative and quantitative experiments demonstrate the accuracy and robustness of our proposed approach. In the real-world grasp experiments, we achieve a grasp success rate of 93% on a set of household items and 91% on a set of adversarial items with only about 6,300 simulated samples. We also achieve 87% accuracy in clutter scenario. Although the model is trained using only RGB image, when changing the background textures, it also performs well and can achieve even 94% accuracy on the set of adversarial objects, which outperforms current state-of-the-art methods.


Title: SMT-Based Control and Feedback for Social Navigation
Key Words: collision avoidance  computability  feedback  human-robot interaction  motion control  SMT-based control  social navigation  HRI  socially acceptable distance  robot motion  high-level formal specifications  human behavior  formal methods  human-robot interaction  collision avoidance  satisfiability modulo theories  utility-based side-by-side navigation control  SMT formula  Navigation  Collision avoidance  Robot kinematics  Legged locomotion  Mathematical model  Safety 
Abstract: This paper combines techniques from Formal Methods and Human-Robot Interaction (HRI) to address the challenge of a robot walking with a human while maintaining a socially acceptable distance and avoiding collisions. We formulate a set of constraints on the robot motion using Satisfiability Modulo Theories (SMT) formulas, and synthesize robot control that is guaranteed to be safe and correct. Due to its use of high-level formal specifications, the controller is able to provide feedback to the user in situations where human behavior causes the robot to fail. This feedback allows the human to adjust their behavior and recover joint navigation. We demonstrate the behavior of the robot in a variety of simulated scenarios and compare it to utility-based side-by-side navigation control.


Title: Safe and Efficient High Dimensional Motion Planning in Space-Time with Time Parameterized Prediction
Key Words: collision avoidance  human-robot interaction  manipulators  mobile robots  probability  trajectory control  human-robot collaborative environments  pre-planned path  6-joint manipulator  human hand  robot trajectories  obstacle-avoidance strategies  motion planning  lazy safe interval probabilistic roadmap  Planning  Robots  Trajectory  Prediction algorithms  Heuristic algorithms  Collision avoidance  Real-time systems 
Abstract: In this work, we propose an algorithm that can plan safe and efficient robot trajectories in real time, given time-parameterized motion predictions, in order to avoid fast-moving obstacles in human-robot collaborative environments. Our algorithm is able to reduce the robot configuration space and the time domain significantly by constructing a Lazy Safe Interval Probabilistic Roadmap based on a pre-planned path. The algorithm then plans efficient obstacle-avoidance strategies within the space-time roadmap. We benchmarked our algorithm by evaluating the performance of a simulated 6-joint manipulator attempting to avoid a quickly moving human hand, using a dataset collected from human experiments. We compared our algorithm's performance with those of 8 variations of prior state-of-the-art planners. Results from this empirical evaluation indicate that our method generated safe plans in 97.5% of the evaluated situations, achieved a planning speed 30 times faster than the benchmarked methods that planned in the time domain without space reduction, and accomplished the minimal solution execution time among the benchmarked planners with a similar planning speed.


Title: OffsetNet: Deep Learning for Localization in the Lung using Rendered Images
Key Words: cameras  closed loop systems  image reconstruction  image registration  medical computing  medical image processing  phantoms  rendering (computer graphics)  surgery  bronchoscope  update rate  average position error  conserved regions  training dataset  simulated images  simulated domains  conservative thresholds  rendered images  surgical tools  dynamic anatomy  tortuous anatomy  real-time localization  preoperative scan  human operators  closed-loop control  autonomous agents  deep learning architecture  recorded camera images  lung phantom  OffsetNet  time 30.0 min  frequency 47.0 Hz  Lung  Computed tomography  Training  Robot sensing systems  Real-time systems  Cameras  Imaging phantoms 
Abstract: Navigating surgical tools in the dynamic and tortuous anatomy of the lung's airways requires accurate, real-time localization of the tools with respect to the preoperative scan of the anatomy. Such localization can inform human operators or enable closed-loop control by autonomous agents, which would require accuracy not yet reported in the literature. In this paper, we introduce a deep learning architecture, called OffsetNet, to accurately localize a bronchoscope in the lung in real-time. After training on only 30 minutes of recorded camera images in conserved regions of a lung phantom, OffsetNet tracks the bronchoscope's motion on a held-out recording through these same regions at an update rate of 47 Hz and an average position error of 1.4 mm. Because this model performs poorly in less conserved regions, we augment the training dataset with simulated images from these regions. To bridge the gap between camera and simulated domains, we implement domain randomization and a generative adversarial network (GAN). After training on simulated images, OffsetNet tracks the bronchoscope's motion in less conserved regions at an average position error of 2.4 mm, which meets conservative thresholds required for successful tracking.


Title: Adaptive Gait Planning for Walking Assistance Lower Limb Exoskeletons in Slope Scenarios
Key Words: adaptive control  gait analysis  humanoid robots  legged locomotion  medical robotics  motion control  pendulums  robot dynamics  adaptive gait planning approach  lower-limb walking assistance exoskeletons  human-exoskeleton system  reference foot locations  adaptive gait trajectories  level ground walking  paraplegic patients  slope terrains  stepping locations  dynamic movement primitives  2D linear inverted pendulum model  dynamic gait generator  conventional capture point theory  Legged locomotion  Exoskeletons  Foot  Trajectory  Adaptation models  Force  Planning  Adaptive Gait Planning  Lower-limb Exoskeleton  LIPM  Dynamic Movement Primitives  Slope 
Abstract: Lower-limb exoskeleton has gained considerable interests in walking assistance applications for paraplegic patients. In walking assistance of paraplegic patients, the exoskeleton should have the ability to help patients to walk over different terrains in the daily life, such as slope terrains. One critical issue is how to plan the stepping locations on slopes with different gradients, and generate stable and human-like gaits for patients. This paper proposed an adaptive gait planning approach which can generate gait trajectories adapt to slopes with different gradients for lower-limb walking assistance exoskeletons. We modeled the human-exoskeleton system as a 2D Linear Inverted Pendulum Model (2D-LIPM) with an external force in the two-dimensional sagittal plane, and proposed a Dynamic Gait Generator (DGG) based on an extension of the conventional Capture Point (CP) theory and Dynamic Movement Primitives (DMPs). The proposed approach can dynamically generate reference foot locations for each step on slopes, and human-like adaptive gait trajectories can be reproduced after the learning from demonstrated trajectories that sampled from level ground walking of normal healthy human. We demonstrated the efficiency of the proposed approach on both the Gazebo simulation platform and an exoskeleton named AIDER. Experimental results indicate that the proposed approach is able to provide the ability for exoskeletons to generate appropriate gaits adapt to slopes with different gradients.


Title: Open Loop Position Control of Soft Continuum Arm Using Deep Reinforcement Learning
Key Words: bending  control engineering computing  learning (artificial intelligence)  manipulator dynamics  neural nets  numerical analysis  pneumatic actuators  position control  torsion  open loop position control  deep reinforcement learning  soft robots  nonlinear spatial deformations  inherent actuation  numerical models  soft spatial continuum arm  unidirectional bending deformation  bidirectional torsional deformation  Deep-Q Learning  continuum arm prototype  external loading conditions  Manipulators  Load modeling  Mathematical model  Numerical models  Strain 
Abstract: Soft robots undergo large nonlinear spatial deformations due to both inherent actuation and external loading. The physics underlying these deformations is complex, and often requires intricate analytical and numerical models. The complexity of these models may render traditional model-based control difficult and unsuitable. Model-free methods offer an alternative for analyzing the behavior of such complex systems without the need for elaborate modeling techniques. In this paper, we present a model-free approach for open loop position control of a soft spatial continuum arm, based on deep reinforcement learning. The continuum arm is pneumatically actuated and attains a spatial work-space by a combination of unidirectional bending and bidirectional torsional deformation. We use Deep-Q Learning with experience replay to train the system in simulation. The efficacy and robustness of the control policy obtained from the system is validated both in simulation and on the continuum arm prototype for varying external loading conditions.


Title: Dynamic morphological computation through damping design of soft material robots: application to under-actuated grippers
Key Words: bending  damping  design engineering  dexterous manipulators  elasticity  granular materials  grippers  pneumatic actuators  pneumatic systems  granular material  bending actuators  dynamic morphological computation  damping design  soft material robots  under-actuated grippers  multichamber pneumatic systems  mechanical parameters  stiffness system  viscous oil  immersion  deformation pattern  Damping  Strain  Oils  Viscosity  Robots  Pneumatic systems  Actuators 
Abstract: This article presents the design of soft material robots with tunable damping properties. This study derives from the investigation of an under-actuated dynamic approach involving multi-chamber pneumatic systems. The co-design of the mechanical parameters (stiffness and damping) of the system along with the time profile of the input allows to obtain different behaviors using a reduced number of feeding line. In this work we analyze via simulations and experiments several approaches to tune the damping of soft robots. The most effective solution employs a layer of granular material immersed in viscous oil within the chamber wall. This method has been employed to realize bending actuators with a continuous deformation pattern. Finally, we show an application involving a two-fingered gripper fed by a single pneumatic line, which is able to perform pinch and power grasp.


Title: High-Fidelity Grasping in Virtual Reality using a Glove-based System
Key Words: computational geometry  computer simulation  data gloves  haptic interfaces  human computer interaction  manipulators  object tracking  virtual reality  physics-based simulation  haptic feedback  glove-based design  collision geometry  Vive Tracker  high-fidelity grasping  virtual objects  caging-based approach  virtual environments  virtual object manipulation  high-fidelity hand  VR  Virtual Reality  real-time stable grasps  hand localization  glove-based system  Haptic interfaces  Robot sensing systems  Vibrations  Real-time systems  Hardware  Geometry 
Abstract: This paper presents a design that jointly provides hand pose sensing, hand localization, and haptic feedback to facilitate real-time stable grasps in Virtual Reality (VR). The design is based on an easy-to-replicate glove-based system that can reliably perform (i) a high-fidelity hand pose sensing in real time through a network of 15 IMUs, and (ii) the hand localization using a Vive Tracker. The supported physics-based simulation in VR is capable of detecting collisions and contact points for virtual object manipulation, which drives the collision event to trigger the physical vibration motors on the glove to signal the user, providing a better realism inside virtual environments. A caging-based approach using collision geometry is integrated to determine whether a grasp is stable. In the experiment, we showcase successful grasps of virtual objects with large geometry variations. Comparing to the popular LeapMotion sensor, we demonstrate the proposed glove-based design yields a higher success rate in various tasks in VR. We hope such a glove-based system can simplify the data collection of human manipulations with VR.


Title: Balance Map Analysis as a Measure of Walking Balance Based on Pendulum-Like Leg Movements
Key Words: legged locomotion  linearisation techniques  motion control  nonlinear control systems  pendulums  state-space methods  balance map analysis  pendulum-like leg movements  swing legs  inverted pendulum  simple pendulum  linearization  nondimensionalization  compass gait model  energy ratio  phase difference  stance leg  swing leg  orbital energy conservation  step transition  balance loss  state space  reachability  walking balance  Legged locomotion  Trajectory  Orbits  Mathematical model  Compass  Computational modeling  Computer simulation 
Abstract: This paper proposes an analysis of walking balance in terms of movements of stance and swing legs based on an inverted pendulum and a simple pendulum. Linearization, decoupling, and non-dimensionalization of a compass gait model enable to characterize the relationship of the trajectories between the stance and swing legs by only two parameters (energy ratio and phase difference). The energy ratio is defined by the ratio of the orbital energy between the pendulums. The phase difference represents the position of the stance leg in relation to the swing leg. This study considers an orbital energy conservation of a step transition and analyzes reachability of a desirable touchdown condition. If the time evolution from a current state is not reachable to the desired touchdown region, the state is labeled as a state in balance loss. By analyzing the reachability limits of the energy ratio and phase difference, we illustrate the balance loss and safe regions on the state space of the inverted pendulum, which is termed as balance map. We examined the effects of the simplification and linearization of the compass gait model by using computer simulations. Through the simulations of walking with perturbations, we confirmed that the balance map analysis could predict a future fall in an early phase for even trajectories derived by the nonlinear model.


Title: Dynamic Stepping on Unknown Obstacles With Upper-Body Compliance and Angular Momentum Damping From the Reaction Null-Space
Key Words: acceleration control  angular momentum  damping  feedback  legged locomotion  motion control  robot dynamics  stability  short time interval  reaction null-space  stepping time  general whole-body controller  relative angular acceleration control component  angular momentum damping  dynamic stepping  unknown obstacles  upper-body compliance  robot steps  unknown height  RNS  iterative optimization  simulated dynamic stepping  Acceleration  Robots  Optimization  Damping  Dynamics  Task analysis  Collision avoidance 
Abstract: Contact destabilization after an impact that occurs at high-speed, e.g. when a robot steps on an obstacle of unknown height, can be tackled by injecting angular momentum damping for a short time interval immediately after the impact. This is done by making use of the motion from within the reaction null-space (RNS). The angular momentum damping results in an appropriate arm motion that stabilizes the contacts. An impact at high-speed occurs when the stepping time is very short. In this case, conventional controllers cannot handle the reaction stemming from the swing leg dynamics. A general whole-body controller is designed that makes use of the relative angular acceleration control component to inject the angular momentum damping. The proposed control method is robust; it can deal with obstacles of various height and inclination without altering the feedback gains. The controller is fast since iterative optimization is avoided. The performance is examined via a simulated dynamic stepping.


Title: Scalable Closed-Form Trajectories for Periodic and Non-Periodic Human-Like Walking
Key Words: gait analysis  medical control systems  optimal control  trajectory control  humanoid robots  linear simplified model  nonperiodic walking  lower-limb trajectories  closed-form trajectories  torso style  body mass  gait parameters  body properties  walking gaits  numerical optimization  geometric variables  kinematic conversion  stabilization  gait generation  footstep locations  optimal time-projecting controller  Legged locomotion  Trajectory  Pelvis  Foot  Kinematics  Torso  Knee 
Abstract: We present a new framework to generate human-like lower-limb trajectories in periodic and non-periodic walking. In our method, walking dynamics is encoded in 3LP, a linear simplified model composed of three pendulums to simulate falling, swing, and torso balancing dynamics. To stabilize the motion, we use an optimal time-projecting controller which suggests new footstep locations. On top of gait generation and stabilization in the simplified space, we introduce a kinematic conversion that synthesizes more humanlike trajectories by combining geometric variables of the 3LP model adaptively. Without any tuning, numerical optimization or off-line data, our walking gaits are scalable with respect to body properties and gait parameters. We can change body mass and height, walking direction, speed, frequency, double support time, torso style, ground clearance, and terrain inclinations. We can also simulate constant external dragging forces or momentary perturbations. The proposed framework offers closed-form solutions with simulation speeds orders of magnitude faster than real time. This can be used for video games and animations on portable electronic devices with limited power. It also gives insights for generation of more human-like walking gaits on humanoid robots.


Title: The Phoenix Drone: An Open-Source Dual-Rotor Tail-Sitter Platform for Research and Education
Key Words: aerodynamics  aerospace components  aerospace robotics  aircraft control  autonomous aerial vehicles  educational robots  helicopters  microrobots  mobile robots  rotors  educational purposes  design methodology  open-source Phoenix reference design  software design  Phoenix drone  open-source dual-rotor tail-sitter platform  open-source tail-sitter microaerial vehicle platform  dual-rotor design  open-source release  design documents  high-performance tail-sitter  testing  open-source materials  aerodynamics  flight control  state estimation  Open source software  Propellers  Aerodynamics  Vehicle dynamics  Attitude control  Drones  Atmospheric modeling 
Abstract: In this paper, we introduce the Phoenix drone: the first completely open-source tail-sitter micro aerial vehicle (MAV) platform. The vehicle has a highly versatile, dual-rotor design and is engineered to be low-cost and easily extensible/modifiable. Our open-source release includes all of the design documents, software resources, and simulation tools needed to build and fly a high-performance tail-sitter for research and educational purposes.The drone has been developed for precision flight with a high degree of control authority. Our design methodology included extensive testing and characterization of the aerodynamic properties of the vehicle. The platform incorporates many off-the-shelf components and 3D-printed parts, in order to keep the cost down. Nonetheless, the paper includes results from flight trials which demonstrate that the vehicle is capable of very stable hovering and accurate trajectory tracking.Our hope is that the open-source Phoenix reference design will be useful to both researchers and educators. In particular, the details in this paper and the available open-source materials should enable learners to gain an understanding of aerodynamics, flight control, state estimation, software design, and simulation, while experimenting with a unique aerial robot.


Title: 1-Actuator 3-DoF Manipulation Using an Underactuated Mechanism with Multiple Nonparallel and Viscoelastic Passive Joints
Key Words: actuators  end effectors  manipulator dynamics  manipulator kinematics  motion control  plates (structures)  position control  viscoelasticity  sinusoidal displacement input  orbital shape  orbital direction  input frequency  switching frequency  mechanical parameters  three-DoF manipulation  plate orbital motions  1-actuator 3-DoF manipulation  underactuated mechanism  multiple nonparallel  nonprehensile manipulation  planar part  manipulator  flat plate end effector  active joint joints  multiple passive viscoelastic joints  joint axes  viscoelastic passive joints  Orbits  Actuators  End effectors  Layout  Switches  Manipulator dynamics 
Abstract: This paper presents a nonprehensile manipulation based on the vibration of a plate, in which three degrees of freedom (DoF) of a planar part are controlled using only one actuator. First, the model of a manipulator with a flat plate end effector is proposed. The manipulator employs an underactuated mechanism including an active joint and multiple passive viscoelastic joints, in which the joint axes are arranged nonparallel to each other. Based on the model, the orbit of the plate for a sinusoidal displacement input to the active joint is theoretically derived. It is revealed that not only the orbital shape but also the orbital direction can be varied according to the input frequency. Based on the switching frequency of the orbital direction, a design index for the mechanical parameters is shown. Subsequently, the contribution of the switching of the orbital direction to the three-DoF manipulation of a part is explored via simulation. Eight primitives utilizing the plate orbital motions in both counter-clockwise and clockwise directions are provided. Finally, the proposed method is demonstrated by experiments.


Title: Spline Based Curve Path Following of Underactuated Snake Robots
Key Words: biomimetics  interpolation  mobile robots  motion control  path planning  splines (mathematics)  time-varying systems  underactuated snake robots  planar underactuated bio-inspired snake robots  time-varying line-of-sight guidance law  cubic spline interpolation path-planning method  snake robot motion control  8-link custom-built snake robot  spline based curve path following  integral controller  Snake robots  Friction  Turning  Splines (mathematics)  Interpolation  Mathematical model 
Abstract: This paper investigates the curve path following problem for a class of planar underactuated bio-inspired snake robots. The time-varying line-of-sight (LOS) guidance law and the cubic spline interpolation (CSI) path-planning method are employed. Existing studies focus on straight line path following which only gives a solution for snake robot motion control in relatively simple environments. Considering the snake robot's many degrees of freedom and excellent mobility in terrains, we propose a more applicable solution of curve path following for snake robots on the ground. The improved LOS helps the snake robot to steer aggressively at a sharp turning point. Furthermore, to avoid the sideslip of the snake robot caused by the ground friction change, an integral controller is introduced in the design of the heading reference. Simulations and experiments on an 8-link custom-built snake robot are conducted and the results demonstrate and validate the effectiveness of the proposed curve path following algorithm.


Title: TREE: A Variable Topology, Branching Continuum Robot
Key Words: adaptive systems  manipulators  TREE  variable topology  cleaning operations  hard-to-reach environments  hybrid concentric-tube  fully retractable continuum branches  branching continuum robot  inspection operations  tendon actuated continuum trunk core  Electron tubes  Tendons  Prototypes  Manipulators  Meters  Inspection 
Abstract: We describe the design and physical realization of a novel branching continuum robot, aimed at inspection and cleaning operations in hard-to-reach environments at depths greater than human arm lengths. The design, based on a hybrid concentric-tube/tendon actuated continuum trunk core, features two pairs of fully retractable continuum branches. The retractable nature of the branches allows the robot to actively change its topology, allowing it to penetrate narrow openings and expand to adaptively engage complex environmental geometries. We detail and discuss the realization of a physical prototype of the design, and its testing in a simulated glove box environment.


Title: Internal Array Electrodes Improve the Spatial Resolution of Soft Tactile Sensors Based on Electrical Resistance Tomography
Key Words: electrodes  tactile sensors  tomography  soft tactile sensors  electrical resistance tomography  unstructured environments  whole-body tactile sensors  complex electrical wiring  sensing elements  reconstruction method  sensing region  central region  ERT approach  optimal pairwise current injection patterns  ERT system  electrode pair  fabric-based soft tactile sensor  sensor-specific calibration  constructed sensor  internal array electrodes  frequency 200.0 Hz  Electrodes  Tactile sensors  Conductivity  Voltage measurement  Spatial resolution  Fabrics 
Abstract: Robots operating in unstructured environments would benefit from soft whole-body tactile sensors, but implementing such systems typically requires complex electrical wiring to a large number of sensing elements. The reconstruction method called electrical resistance tomography (ERT) has shown promising results (good coverage, manufacturability, and robustness) using electrodes located only along the boundary of the sensing region. However, relatively poor spatial resolution in the sensor's central region is a major drawback of the ERT approach. This paper introduces a new scheme of internal array electrodes to improve spatial resolution. We also systematically derive the optimal pairwise current injection patterns from a mathematical formulation of the ERT system. By highlighting the importance of each electrode pair, this approach enabled us to reduce the number of current injection patterns. Simulation of the standard and proposed sensor designs revealed that the internal array electrodes greatly improve distinguishability in the central region. For validation, a fabric-based soft tactile sensor made of multiple conductive fabrics was developed, including electronics that enable sampling at 200 Hz. During a 225-point localization test conducted without sensor-specific calibration, the constructed sensor showed average localization errors of 2.85 cm ± 1.02 cm. This result is notable because only 16 point electrodes were used to achieve this performance.


Title: Autonomous Exploration, Reconstruction, and Surveillance of 3D Environments Aided by Deep Learning
Key Words: collision avoidance  learning (artificial intelligence)  mobile robots  multi-robot systems  neural nets  autonomous exploration  surveillance  greedy learning approach  supervised learning approach  level set representation  convolutional neural network  visibility  on-line computational cost  topologically accurate maps  complex 3D environments  frontier-based strategies  potential vantage points  deep learning approaches  obstacle avoidance  local navigation  global exploration problem  3D urban environments  Training  Level set  Surveillance  Three-dimensional displays  Two dimensional displays  Sensors  Convolution 
Abstract: We propose a greedy and supervised learning approach for visibility-based exploration, reconstruction and surveillance. Using a level set representation, we train a convolutional neural network to determine vantage points that maximize visibility. We show that this method drastically reduces the on-line computational cost and determines a small set of vantage points that solve the problem. This enables us to efficiently produce highly-resolved and topologically accurate maps of complex 3D environments. Unlike traditional next-best-view and frontier-based strategies, the proposed method accounts for geometric priors while evaluating potential vantage points. While existing deep learning approaches focus on obstacle avoidance and local navigation, our method aims at finding near-optimal solutions to the more global exploration problem. We present realistic simulations on 2D and 3D urban environments.


Title: Recursive Bayesian Classification for Perception of Evolving Targets using a Gaussian Toroid Prediction Model
Key Words: Bayes methods  belief networks  feature extraction  Gaussian processes  image classification  real-time systems  recursive estimation  uncertainty handling  Gaussian toroid prediction model  probabilistic framework  recursive Bayesian estimation  perception-oriented context  recursive Bayesian classification scheme  high-dimensional belief spaces  evolving target classification  perception target evolution  RBC scheme  feature extraction  multiGaussian belief representation  real-time analysis  observational uncertainty  Predictive models  Bayes methods  Probabilistic logic  Probability density function  Estimation  Decision making  Mathematical model 
Abstract: This paper proposes a probabilistic framework for classification of evolving targets, leveraging the principles of recursive Bayesian estimation in a perception-oriented context. By implementing a Gaussian toroid prediction model of the perception target's evolution, the proposed recursive Bayesian classification (RBC) scheme provides probabilistically robust classification. Appropriate features are extracted from the target, which is then probabilistically represented in a belief space. This approach is capable of handling high-dimensional belief spaces, while simultaneously allowing for multi-Gaussian representation of belief without computational complexity that hinders real-time analysis. The proposed technique is validated over several parameter values by thousands of simulated experiments, where it is shown to outperform naıve classification when high observational uncertainty is present.


Title: The Robust Canadian Traveler Problem Applied to Robot Routing
Key Words: graph theory  mobile robots  stochastic processes  telecommunication network routing  worst-case cost  Robust Canadian Traveler Problem applied  stochastic Canadian Traveler Problem  CTP  robot route selection  traversal policy  policy cost  evaluation criteria  approximate algorithm  traversal cost  robot field trials  RCTP framework  sub-optimal policy alternatives  minimum expected cost  distance 5.0 km  Approximation algorithms  Robot sensing systems  Visualization  Search problems  Heuristic algorithms  Uncertainty 
Abstract: The stochastic Canadian Traveler Problem (CTP), which finds application in robot route selection under uncertainty, aims to find the traversal policy with the minimum expected cost. This paper extends the CTP to what we call the Robust Canadian Traveler Problem (RCTP), in which the variability of the policy cost is also part of the evaluation criteria. An optimal (offline) algorithm and an approximate (online) algorithm are then proposed to compute the policy that has a good balance of both mean and variation of the traversal cost. The benefit of the proposed framework versus traditional approaches is shown by doing simulations in randomly generated worlds as well as on a map of 5 km of paths built from robot field trials. Specifically, the RCTP framework is able to search for sub-optimal policy alternatives with significantly lower worst-case cost and less computational time compared to the optimal policy, but with little sacrifice on the expected cost.


Title: Analyzing Electromagnetic Actuator based on Force Analysis
Key Words: electric field effects  electromagnetic actuators  embossing  hot working  impact (mechanical)  magnetic field effects  impact hot embossing  force analysis  magnetic field  system equation  electromagnetic actuator  electrical field  mechanical system  Simulink analysis  Mathematical model  Actuators  Magnetic flux  Force  Magnetic forces  Magnetic circuits  Embossing  Hot Embossing  electromagnetic actuator  linear actuator  system modeling  equivalent magnetic circuit 
Abstract: By modeling the system with the mechanical, electrical, and magnetic field, we can derive the system equation for the actuator modeling. As it is not easy to conclude the output signal from the equations, we used Simulink to simulate and check the performance aspect of the system. After that, we did several experiments to verify whether experimental force meets with the needed condition for impact hot embossing and matches with simulation force. We tried to adjust the parameters of the system to match the force of experiment result and that of the simulation result. From the comparison, we can consider the analysis of the actuator as precise. A successful study can contribute to the better application of new type hot embossing techniques and better understanding and usage of the electromagnetic actuator when it is applied to another technology and research.


Title: Design and Formal Verification of a Safe Stop Supervisor for an Automated Vehicle*
Key Words: Global Positioning System  mobile robots  remotely operated vehicles  road safety  road vehicles  model-based approach  model checking  demonstration vehicle  formal verification  safe stop supervisor  automated vehicle  autonomous vehicles  pertinent planning  control algorithms  mode switch  nominal planners  safe fallback routine  safe position  nominal operational conditions  system failure  mode switching  safe stop trajectory planner  research concept vehicle  Trajectory  Planning  Automation  Global Positioning System  Software  Switches  Roads 
Abstract: Autonomous vehicles apply pertinent planning and control algorithms under different driving conditions. The mode switch between these algorithms should also be autonomous. On top of the nominal planners, a safe fallback routine is needed to stop the vehicle at a safe position if nominal operational conditions are violated, such as for a system failure. This paper describes the design and formal verification of a supervisor to manage all requirements for mode switching between nominal planners, and additional requirements for switching to a safe stop trajectory planner that acts as the fallback routine. The supervisor is designed via a model-based approach and its abstraction is formally verified by model checking. The supervisor is implemented and integrated with the Research Concept Vehicle, an experimental research and demonstration vehicle developed at the KTH Royal Institute of Technology. Simulations and experiments show that the vehicle is able to autonomously drive in a safe manner between two parking lots and can successfully come to a safe stop upon GPS sensor failure.


Title: Pedestrian Dominance Modeling for Socially-Aware Robot Navigation
Key Words: collision avoidance  human-robot interaction  mobile robots  socially-aware robot navigation  dominance characteristics  PDM models  perceived dominance levels  dominance-based collision-avoidance  pedestrian dominance model  robot navigation  autonomous vehicle navigation  Robots  Navigation  Trajectory  Psychology  Computational modeling  Prediction algorithms  Collision avoidance 
Abstract: We present a Pedestrian Dominance Model (PDM) to identify the dominance characteristics of pedestrians for robot navigation. Through a perception study on a simulated dataset of pedestrians, PDM models the perceived dominance levels of pedestrians with varying motion behaviors corresponding to trajectory, speed, and personal space. At runtime, we use PDM to identify the dominance levels of pedestrians to facilitate socially-aware navigation for the robots. PDM can predict dominance levels from trajectories with ~85% accuracy. Prior studies in psychology literature indicate that when interacting with humans, people are more comfortable around people that exhibit complementary movement behaviors. Our algorithm leverages this by enabling the robots to exhibit complementing responses to pedestrian dominance. We also present an application of PDM for generating dominance-based collision-avoidance behaviors in the navigation of autonomous vehicles among pedestrians. We demonstrate the benefits of our algorithm for robots navigating among tens of pedestrians in simulated environments.


Title: Multi-view Reconstruction of Wires using a Catenary Model
Key Words: autonomous aerial vehicles  cameras  extrapolation  image reconstruction  image segmentation  inspection  object detection  power cables  power engineering computing  robot vision  stereo image processing  multiview reconstruction  catenary model  UAV community  wire avoidance capabilities  powerline corridor inspection  multiview algorithm  catenary curve  partial wire detections  bundle-adjustment approaches  binarized wire segmentation images  approximate extrapolation  Wires  Image reconstruction  Three-dimensional displays  Cameras  Transforms  Computational modeling  Atmospheric modeling 
Abstract: Reliable detection and reconstruction of wires is one of the hardest problems in the UAV community, with a wide ranging impact in the industry in terms of wire avoidance capabilities and powerline corridor inspection. In this work, we introduce a real-time, model-based, multi-view algorithm to reconstruct wires from a set of images with known camera poses, while exploiting their natural shape - the catenary curve. Using a model-based approach helps us deal with partial wire detections in images, which may occur due to natural occlusion and false negatives. In addition, using a parsimonious model makes our algorithm efficient as we only need to optimize for 5 model parameters, as opposed to hundreds of 3D points in bundle-adjustment approaches. Our algorithm obviates the need for pixel correspondences by computing the reprojection error via the distance transform of binarized wire segmentation images. Further, we make our algorithm robust to arbitrary initializations by introducing an on-demand, approximate extrapolation of the distance transform based objective. We demonstrate the effectiveness of our algorithm against false negatives and random initializations in simulation, and show qualitative results with real data collected from a small UAV.


Title: Automatic Real-time Anomaly Detection for Autonomous Aerial Vehicles
Key Words: actuators  aerospace components  aerospace simulation  aircraft testing  autonomous aerial vehicles  fault diagnosis  fault tolerant control  least squares approximations  mobile robots  recursive least squares method  anomaly detection method  aircraft model  fault detection research  fixed-wing flights  ground truth  mid-flight actuator failures  fault detection open dataset  autonomous aircraft  correlated input-output pairs  autonomous aerial vehicles  Aircraft  Atmospheric modeling  Fault detection  Actuators  Reliability  Computational modeling  Safety 
Abstract: The recent increase in the use of aerial vehicles raises concerns about the safety and reliability of autonomous operations. There is a growing need for methods to monitor the status of these aircraft and report any faults and anomalies to the safety pilot or to the autopilot to deal with the emergency situation. In this paper, we present a real-time approach using the Recursive Least Squares method to detect anomalies in the behavior of an aircraft. The method models the relationship between correlated input-output pairs online and uses the model to detect the anomalies. The result is an easy-to-deploy anomaly detection method that does not assume a specific aircraft model and can detect many types of faults and anomalies in a wide range of autonomous aircraft. The experiments on this method show a precision of 88.23%, recall of 88.23% and 86.36% accuracy for over 22 flight tests. The other contribution is providing a new fault detection open dataset for autonomous aircraft, which contains complete data and the ground truth for 22 fixed-wing flights with eight different types of mid-flight actuator failures to help future fault detection research for aircraft.


Title: A Dual-Bladder Buoyancy Engine for a Cephalopod-Inspired AUV
Key Words: actuators  asymptotic stability  autonomous underwater vehicles  feedback  flow sensors  gears  Lyapunov methods  mobile robots  nonlinear control systems  pressure measurement  pressure sensors  pumps  remotely operated vehicles  robot dynamics  dual-bladder buoyancy engine  cephalopod-inspired AUV  nonlinear depth  backstepping depth  pitch controller  flow-rate feedback  custom flow sensor  differential pressure sensor  3D-printed attachment  depth control capability  single-bladder buoyancy engine  depth controller  autonomous underwater vehicle  Buoyancy  Engines  Bladder  Backstepping  Force  Vehicle dynamics  Pressure sensors 
Abstract: This paper presents a nonlinear, backstepping depth and pitch controller for a dual-bladder buoyancy engine actuated by gear pumps. Flow-rate feedback is obtained using a custom flow sensor comprised of a differential pressure sensor and a small, 3D-printed attachment. The controller is simulated using a model of the CephaloBot, our in-house developed autonomous underwater vehicle (AUV). Its depth control capability is also experimentally validated using a single-bladder buoyancy engine on-board a smaller-scale test cylinder. Lyapunov stability analysis shows global, asymptotic stability, which is exhibited in our simulation. Our experiments verify that this buoyancy engine is a feasible and effective depth controller for AUVs.


Title: Real-time Model Based Path Planning for Wheeled Vehicles
Key Words: electric vehicles  image colour analysis  image sensors  mobile robots  path planning  pose estimation  road safety  road vehicles  robot vision  search problems  wheels  model based traversability analysis method  complex environments  vehicles 3D pose  chassis collision  elevation map  reactive planning  safe paths  wheeled mobile robots  real world environment setups  real-time model  real-time path planning  simulated world environment setups  wheeled vehicles  vehicle model  scoring function  A*-like search strategy  RGB-D sensor  frequency 30.0 Hz  Wheels  Path planning  Robot sensing systems  Planning  Mobile robots  Real-time systems 
Abstract: This work presents a model based traversability analysis method which employs a detailed vehicle model to perform real-time path planning in complex environments. The vehicle model represents the vehicle's wheels and chassis, allowing it to accurately predict the vehicles 3D pose, detailed contact information for each wheel and the occurrence of a chassis collision given a 2D pose on an elevation map. These predictions are weighted, depending on the safety requirements of the vehicle, to provide a scoring function for an A*-like search strategy. The proposed method is designed to run at frame rates of 30Hz on data from a RGB-D sensor to provide reactive planning of safe paths. For evaluation, two wheeled mobile robots in different simulated and real world environment setups were tested to show the reliability and performance of the proposed method.


Title: Dynamic Risk Density for Autonomous Navigation in Cluttered Environments without Object Detection
Key Words: collision avoidance  handicapped aids  object detection  path planning  wheelchairs  dynamic risk density  congestion density  cost function  occupancy risk  velocity fields  object-based congestion cost  cluttered environments  autonomous navigation  object detection  object tracking  autonomous wheelchair  Navigation  Cost function  Wheelchairs  Dynamics  Vehicle dynamics  Planning  Level set 
Abstract: In this paper, we examine the problem of navigating cluttered environments without explicit object detection and tracking. We introduce the dynamic risk density to map the congestion density and spatial flow of the environment to a cost function for the agent to determine risk when navigating that environment. We build upon our prior work, wherein the agent maps the density and motion of objects to an occupancy risk, then navigate the environment over a specified risk level set. Here, the agent does not need to identify objects to compute the occupancy risk, and instead computes this cost function using the occupancy density and velocity fields around them. Simulations show how this dynamic risk density encodes movement information for the ego agent and closely models the object-based congestion cost. We implement our dynamic risk density on an autonomous wheelchair and show how it can be used for navigating unstructured, crowded and cluttered environments.


Title: Deep Local Trajectory Replanning and Control for Robot Navigation
Key Words: collision avoidance  control engineering computing  learning (artificial intelligence)  mobile robots  motion control  navigation  velocity control  robot navigation  hierarchical planning  machine learning  optimal paths  deep local trajectory planner  velocity controller  motion commands  attention mechanisms  nearby pedestrians  map global plan information  sensor data  velocity commands  hand-designed traditional navigation system  deep local trajectory replanning  global planner  Navigation  Robot kinematics  Trajectory  Planning  Robot sensing systems  Laser radar 
Abstract: We present a navigation system that combines ideas from hierarchical planning and machine learning. The system uses a traditional global planner to compute optimal paths towards a goal, and a deep local trajectory planner and velocity controller to compute motion commands. The latter components of the system adjust the behavior of the robot through attention mechanisms such that it moves towards the goal, avoids obstacles, and respects the space of nearby pedestrians. Both the structure of the proposed deep models and the use of attention mechanisms make the system's execution interpretable. Our simulation experiments suggest that the proposed architecture outperforms baselines that try to map global plan information and sensor data directly to velocity commands. In comparison to a hand-designed traditional navigation system, the proposed approach showed more consistent performance.


Title: Open-Loop Collective Assembly Using a Light Field to Power and Control a Phototaxic Mini-Robot Swarm
Key Words: artificial life  computational geometry  mobile robots  multi-robot systems  open loop systems  path planning  open-loop collective assembly  collective construction  dynamic light field design strategies  assembled shapes  mobile robots  polygonal shapes  phototaxic minirobot swarm  nonconvex polygons  global light field  Robot kinematics  Shape  Robot sensing systems  Mobile robots  Task analysis  Collision avoidance 
Abstract: We propose a novel scheme that jointly addresses the problems of powering and coordinating a population of mini-robots for collective construction. In our setting, a population of simple mobile robots must push blocks into desired polygonal shapes. Each robot performs only simple phototaxis. Coordination is purely open-loop: a global light field guides and powers the robots. We demonstrate this concept in simulation and explore a series of dynamic light field design strategies that robustly result in assembled shapes including nonconvex polygons.


Title: Simulated Annealing-optimized Trajectory Planning within Non-Collision Nominal Intervals for Highway Autonomous Driving
Key Words: acceleration control  collision avoidance  mobile robots  predictive control  road traffic control  simulated annealing  time-varying systems  trajectory control  sigmoid trajectory  collision-free intervals  nominal conditions  velocity-space representation  highway autonomous driving  near-optimal trajectory generation  autonomous vehicles  highways  predictive reference trajectory  free evolution space  pre-calculated set  candidate trajectories  decoupling path  velocity optimizations  multicriteria functions  decision evaluation function  trajectory generator  simulated annealing approach  noncollision nominal intervals  simulated annealing-optimized trajectory planning  Trajectory  Roads  Acceleration  Vehicle dynamics  Autonomous vehicles  Decision making 
Abstract: This article considers the problem of near-optimal trajectory generation for autonomous vehicles on highways. The goal is to select a predictive reference trajectory in the free evolution space, while avoiding both generating a pre-calculated set of candidate trajectories and decoupling path and velocity optimizations. Moreover, this trajectory aims at optimizing a decision process based on multi-criteria functions, which are not straightforward to design and can have a blackbox formulation. The main idea of this article is to use the decision evaluation function in the trajectory generator with a Simulated Annealing (SA) approach. The parameters of a sigmoid trajectory are optimized within Non-Collision Nominal Intervals (NCNI), which are defined as collision-free intervals under nominal conditions using a velocity-space representation.


Title: On the Impact of Uncertainty for Path Planning
Key Words: graph theory  learning (artificial intelligence)  mobile robots  navigation  path planning  probability  travelling salesman problems  path planning  planning paths  uncertain edge  learned classifier  mobile robots  partially-known environments  simulation campaign  real-world maps  planning strategy  traversability estimates  Canadian traveller problem  Robot sensing systems  Navigation  Uncertainty  Path planning  Estimation  Optimized production technology 
Abstract: We consider the problem of planning paths on graphs with some edges whose traversability is uncertain; for each uncertain edge, we are given a probability of being traversable (e.g., by a learned classifier). We categorize different interpretations of the problem that are meaningful for mobile robots navigating partially-known environments, each of which yields a different formalization; we then focus on the case in which the true traversability of an edge is revealed only when the agent visits one of its endpoints (Canadian Traveller Problem). In this context, we design a large simulation campaign on synthetic and real-world maps to study the impact of two different factors: the planning strategy, and the amount of uncertainty (which could depend on the quality of the classifier producing traversability estimates).


Title: Beyond Point Clouds: Fisher Information Field for Active Visual Localization
Key Words: mobile robots  path planning  robot vision  point clouds  Fisher information field  active visual localization  mobile robots  perception requirement  planning stage  localization information  perception-aware planning  3D landmarks  sensor visibility  Three-dimensional displays  Planning  Visualization  Cameras  Simultaneous localization and mapping 
Abstract: For mobile robots to localize robustly, actively considering the perception requirement at the planning stage is essential. In this paper, we propose a novel representation for active visual localization. By formulating the Fisher information and sensor visibility carefully, we are able to summarize the localization information into a discrete grid, namely the Fisher information field. The information for arbitrary poses can then be computed from the field in constant time, without the need of costly iterating all the 3D landmarks. Experimental results on simulated and real-world data show the great potential of our method in efficient active localization and perception-aware planning. To benefit related research, we release our implementation of the information field to the public.


Title: Sim-to-Real Transfer Learning using Robustified Controllers in Robotic Tasks involving Complex Dynamics
Key Words: learning (artificial intelligence)  robot dynamics  robust control  robustified controller  robotic tasks  complex dynamics  robot tasks  deep reinforcement learning  simulated environment  learned task  fine-tuning  simulation parameters  nontrivial task  nonrobustified controller  sim-to-real transfer learning  robustified controllers  Task analysis  Robots  Physics  Games  Reinforcement learning  Training  Computational modeling 
Abstract: Learning robot tasks or controllers using deep reinforcement learning has been proven effective in simulations. Learning in simulation has several advantages. For example, one can fully control the simulated environment, including halting motions while performing computations. Another advantage when robots are involved, is that the amount of time a robot is occupied learning a task-rather than being productive-can be reduced by transferring the learned task to the real robot. Transfer learning requires some amount of fine-tuning on the real robot. For tasks which involve complex (non-linear) dynamics, the fine-tuning itself may take a substantial amount of time. In order to reduce the amount of fine-tuning we propose to learn robustified controllers in simulation. Robustified controllers are learned by exploiting the ability to change simulation parameters (both appearance and dynamics) for successive training episodes. An additional benefit for this approach is that it alleviates the precise determination of physics parameters for the simulator, which is a non-trivial task. We demonstrate our proposed approach on a real setup in which a robot aims to solve a maze game, which involves complex dynamics due to static friction and potentially large accelerations. We show that the amount of fine-tuning in transfer learning for a robustified controller is substantially reduced compared to a non-robustified controller.


Title: Generalization through Simulation: Integrating Simulated and Real Data into Deep Reinforcement Learning for Vision-Based Autonomous Flight
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  data analysis  helicopters  learning (artificial intelligence)  mobile robots  robot vision  vision-based autonomous flight  fragile scale quadrotors  small-scale quadrotors  complex physics  air currents  hybrid deep reinforcement learning algorithm  generalizable perception system  nanoaerial vehicle collision avoidance task  real data  simulated data  Data models  Robots  Task analysis  Predictive models  Neural networks  Reinforcement learning  Collision avoidance 
Abstract: Deep reinforcement learning provides a promising approach for vision-based control of real-world robots. However, the generalization of such models depends critically on the quantity and variety of data available for training. This data can be difficult to obtain for some types of robotic systems, such as fragile, small-scale quadrotors. Simulated rendering and physics can provide for much larger datasets, but such data is inherently of lower quality: many of the phenomena that make the real-world autonomous flight problem challenging, such as complex physics and air currents, are modeled poorly or not at all, and the systematic differences between simulation and the real world are typically impossible to eliminate. In this work, we investigate how data from both simulation and the real world can be combined in a hybrid deep reinforcement learning algorithm. Our method uses real-world data to learn about the dynamics of the system, and simulated data to learn a generalizable perception system that can enable the robot to avoid collisions using only a monocular camera. We demonstrate our approach on a real-world nano aerial vehicle collision avoidance task, showing that with only an hour of real-world data, the quadrotor can avoid collisions in new environments with various lighting conditions and geometry. Code, instructions for building the aerial vehicles, and videos of the experiments can be found at github.com/gkahn13/GtS.


Title: A Reinforcement Learning Approach for Control of a Nature-Inspired Aerial Vehicle
Key Words: autonomous aerial vehicles  function approximation  gradient methods  learning (artificial intelligence)  neural nets  position control  three-term control  nature-inspired aerial vehicle  position controller  UAV  fixed-wing aircraft  neural network function approximators  reinforcement learning agent  learned controller  deep deterministic policy gradients  PID controller  Ape-X distributed prioritized experience replay  multi-rotors  underactuated nature-inspired unmanned aerial vehicle  body contrary  Training  Aerodynamics  Neural networks  Mathematical model  Reinforcement learning  Drag  Prototypes 
Abstract: In this work, reinforcement learning is used to develop a position controller for an underactuated nature-inspired Unmanned Aerial Vehicle (UAV). This particular configuration of UAVs achieves lift by spinning its entire body contrary to standard multi-rotors or fixed-wing aircraft. Deep Deterministic Policy Gradients (DDPG) with Ape-X Distributed Prioritized Experience Replay was used to train neural network function approximators that were implemented as the final control policy. The reinforcement learning agent was trained in simulations and directly ported over to real-life hardware. Position control tests were performed on the learned control policy and compared to a baseline PID controller. The learned controller was found to exhibit better control over the inherent oscillations that arise from the non-linear dynamics of the platform.


Title: Tightly-Coupled Aided Inertial Navigation with Point and Plane Features
Key Words: feature extraction  image fusion  image sensors  inertial navigation  mobile robots  Monte Carlo methods  object tracking  SLAM (robots)  planar point features  nonplanar point features  point-on-plane constraints  effective plane feature initialization algorithm  depth sensor  general sensor fusion framework  point feature tracking  plane extraction  geometrical structures  closest point  plane parameterization  Monte-Carlo simulations  visual sensor  tightly-coupled aided inertial navigation system  feature-based simultaneous localization and mapping  Feature extraction  Cameras  Calibration  Laser radar  Jacobian matrices  Simultaneous localization and mapping  Estimation 
Abstract: This paper presents a tightly-coupled aided inertial navigation system (INS) with point and plane features, a general sensor fusion framework applicable to any visual and depth sensor (e.g., RGBD, LiDAR) configuration, in which the camera is used for point feature tracking and depth sensor for plane extraction. The proposed system exploits geometrical structures (planes) of the environments and adopts the closest point (CP) for plane parameterization. Moreover, we distinguish planar point features from non-planar point features in order to enforce point-on-plane constraints which are used in our state estimator, thus further exploiting structural information from the environment. We also introduce a simple but effective plane feature initialization algorithm for feature-based simultaneous localization and mapping (SLAM). In addition, we perform online spatial calibration between the IMU and the depth sensor as it is difficult to obtain this critical calibration parameter in high precision. Both Monte-Carlo simulations and real-world experiments are performed to validate the proposed approach.


Title: Sliding Mode Momentum Observers for Estimation of External Torques and Joint Acceleration
Key Words: collision avoidance  end effectors  human-robot interaction  observers  torque control  variable structure systems  external torques  joint acceleration  external wrenches  robot structure  human-robot interaction  momentum dynamics  classic momentum observer  reaction strategies  sliding mode momentum observers  control loop  proprioceptive sensors  first-order filtered version  finite-time convergence  Observers  Robots  Collision avoidance  Torque  Convergence  Noise measurement 
Abstract: Interactions between robots and their environment give rise to external wrenches acting on the robot structure. The estimation of the resulting torques in the joints is fundamental in human-robot interaction to detect/identify collisions and perform suitable reaction strategies. Other applications may require to use the estimation for compensating the effects of the external torques within the control loop. The well-established momentum observer, which relies on proprioceptive sensors only, is usually used for these purposes. In this work, the momentum dynamics is used to derive new observers. While the classic momentum observer provides a first-order filtered version of the external torques, here a (theoretically) finite-time convergence is achieved. Simulations and experiments are used to validate the performance of the proposed methods.


Title: An Improved Control-Oriented Modeling of the Magnetic Field
Key Words: closed loop systems  coils  interpolation  magnetic fields  microrobots  mobile robots  motion control  control-oriented model  coil  untethered microscale mobile robotics  elliptic integral functions  magnetically actuated microrobots  map-based interpolation  computation time  closed-loop control  dipole approximation  Magnetic domains  Computational modeling  Magnetic hysteresis  Soft magnetic materials  Numerical models  Robots  Magnetic cores 
Abstract: This paper proposes a new control-oriented model to compute the magnetic field created by a coil. A major challenge for untethered microscale mobile robotics is the control of objects for precise and fast displacements. In this work, we propose to use an alternative implementation of a model based on elliptic integral functions to control magnetically actuated micro-robots. It allows to compute the magnetic field even in the area close to the coil quickly and accurately. This model is evaluated numerically and compared to classical approaches - dipole approximation, map-based interpolation and classical elliptic integral models - in terms of accuracy, computation time and memory requirement. Simulation results show that this works allows to have an accurate model in the whole workspace by avoiding numerical issues encountered in previous works. It can be computed in a few milliseconds, making it the right candidate for closed-loop control of magnetically actuated micro-robots.


Title: Efficient Micro Waveguide Coupling based on Microrobotic Positioning
Key Words: fuzzy control  integrated optics  micro-optics  microrobots  optical fibre couplers  optical microscopy  path planning  fuzzy controller  degrees of freedoms  microwaveguide coupling  path planning strategy  integrated optical component  optical fiber  micromanufacture field  traditional manual method  optical microscopy  microrobotic positioning system  light intensity feedback  commercial optoelectronic devices  optical devices  time 40.0 s  Couplings  Optical fibers  Optical fiber sensors  Optical distortion 
Abstract: Coupling the endface of an optical fiber to an integrated optical component is currently a low-throughput and costly manual process in the fabrication of the optical devices. In order to meet the high-volume demand for commercial optoelectronic devices, coupling must be automated. This paper presents a robotic positioning system and corresponding path planning strategy based on both the position and light intensity feedback. In this work, a micro-robotic positioning system with 3 degrees of freedoms (DOFs) is developed and integrated with an optical microscopy. Then the fuzzy controller is developed to design the trajectory. Lastly, simulation and experimental results demonstrate the accuracy and efficiency of the proposed system. Compared with the traditional manual method, the robotic positioning system can realize the coupling within 40 seconds. This method will have a significant impact on the automatic process of the micro manufacture field.


Title: Assembly of Multilayered Hepatic Lobule-like Vascular Network by using Heptapole Magnetic Tweezer
Key Words: biomedical materials  blood  blood vessels  cellular biophysics  hydrogels  liver  multilayers  steel  rat liver cells  fibrin gel  cell viability  cellular structure  3D channel network  magnetic tweezer  magnetic fields  central veins  portal veins  hepatic lobule tissue  magnetic hydrogel fibers  multilayered channel system  cell-laden hydrogels  heptapole magnetic tweezer  multilayered hepatic lobule-like vascular network  steel rods  Steel  Three-dimensional displays  Optical fiber networks  Veins  Magnetic flux  Magnetic fields  Magnetic multilayers 
Abstract: In this paper, we have fabricated a multilayered hepatic lobule-like vascular network in a 3D tissue using a heptapole magnetic tweezer. The tissue consists of cell-laden hydrogels with 3D channel networks. To fabricate multilayered channel system, magnetic hydrogel fibers were manipulated by a magnetic tweezer. The hepatic lobule tissue shows a hexagonal structure with different sizes of veins. Six portal veins transfer the blood including nutrients and oxygen to a central vein by sinusoids. The portal and central veins are made by steel rods, whereas the magnetic hydrogel fibers has a role of sinusoids. An important point of this research is to connect two veins - portal and central vein - by magnetic fibers. For this, we used magnetic tweezer with seven poles to magnetize the steel rods. In order to generate high magnetic fields, we design magnetic tweezer with a flat tip and additional lower tweezer based on simulation data. The manipulation was performed in fibrin gel inside rat liver cells. By applying high magnetic fields, we attracted magnetic fibers to the steel rods and constructed 3D channel network in cellular structure. To verify the efficiency of the channel, we supply culture medium to the channel and then analyze the cell viability according to the distance from the channel. As a result, the cells located at close to the channel show higher cell viability than others.


Title: ChainQueen: A Real-Time Differentiable Physical Simulator for Soft Robotics
Key Words: deformation  elasticity  gradient methods  inverse problems  least squares approximations  manipulator dynamics  mobile robots  multi-robot systems  optimal control  optimisation  path planning  ChainQueen  real-time differentiable physical simulator  robot planning  gradient-based optimization algorithms  inverse problems  optimal control  motion planning  rigid body simulators  deformable objects  rigid body dynamics  Lagrangian-Eulerian physical simulator  MLS-MPM  soft robotic systems  forward simulation  backward gradient computation  moving least squares material point method  Graphics processing units  Computational modeling  Soft robotics  Three-dimensional displays  Planning  Inverse problems 
Abstract: Physical simulators have been widely used in robot planning and control. Among them, differentiable simulators are particularly favored, as they can be incorporated into gradient-based optimization algorithms that are efficient in solving inverse problems such as optimal control and motion planning. Therefore, rigid body simulators and recently their differentiable variants are studied extensively. Simulating deformable objects is, however, more challenging compared to rigid body dynamics. The underlying physical laws of deformable objects are more complex, and the resulting systems have orders of magnitude more degrees of freedom and there-fore they are significantly more computationally expensive to simulate. Computing gradients with respect to physical design or controller parameters is typically even more computationally challenging. In this paper, we propose a real-time, differentiable hybrid Lagrangian-Eulerian physical simulator for deformable objects, ChainQueen, based on the Moving Least Squares Material Point Method (MLS-MPM). MLS-MPM can simulate deformable objects with collisions and can be seamlessly incorporated into soft robotic systems. We demonstrate that our simulator achieves high precision in both forward simulation and backward gradient computation. We have successfully employed it in a diverse set of inference, control and co-design tasks for soft robotics.


Title: A Validated Physical Model For Real-Time Simulation of Soft Robotic Snakes
Key Words: actuators  biomimetics  closed loop systems  deformation  legged locomotion  pneumatic actuators  robot dynamics  constraint-based dynamics model  multiphysics environment  soft robotic actuators  real-time simulation  validated physical model  real-time performance  dynamic locomotion open-loop control experiments  multiple 1D actuators  soft robotic snake  internal pressure forces  1-dimensional pneumatic soft actuator  Actuators  Deformable models  Soft robotics  Strain  Finite element analysis  Mathematical model 
Abstract: In this work we present a framework that is capable of accurately representing soft robotic actuators in a multiphysics environment in real-time. We propose a constraint-based dynamics model of a 1-dimensional pneumatic soft actuator that accounts for internal pressure forces, as well as the effect of actuator latency and damping under inflation and deflation and demonstrate its accuracy a full soft robotic snake with the composition of multiple 1D actuators. We verify our model's accuracy in static deformation and dynamic locomotion open-loop control experiments. To achieve real-time performance we leverage the parallel computation power of GPUs to allow interactive control and feedback.


Title: SpaceBok: A Dynamic Legged Robot for Space Exploration
Key Words: aerospace robotics  force control  legged locomotion  motion control  robot dynamics  SpaceBok  dynamic legged robot  space exploration  quadrupedal robot  dynamic legged locomotion  parallel elastic elements  high-torque brushless motors  force control  walking velocity  planetary gear transmissions  optimized parallel motion  jumping maneuvers  Legged locomotion  Hip  Actuators  Gravity  Torque  Foot 
Abstract: This paper introduces SpaceBok, a quadrupedal robot created to investigate dynamic legged locomotion for the exploration of low-gravity celestial bodies. With a hip height of 500 mm and a mass of 20 kg, its dimensions are comparable to a medium-sized dog. The robot's leg configuration is based on an optimized parallel motion mechanism that allows the integration of parallel elastic elements to store and release energy for powerful jumping maneuvers. High-torque brushless motors in combination with customized single-stage planetary gear transmissions enable force control at the foot contact points based on motor currents. We present successful walking, trotting, and pronking experiments. Thereby, Spacebok achieved maximal jump heights in single jump experiments of up to 1.05 m (more than twice the hip height) and a walking velocity of 1m/s. Moreover, simulation results for low gravity on the moon suggest that our robot can move with up to 1.1m/s at an approximate cost of transport of 1 in moon gravity when using the pronking gait.


Title: IN2LAMA: INertial Lidar Localisation And MApping
Key Words: mobile robots  motion estimation  optical radar  optimisation  probability  robot vision  IN2LAMA  spinning mechanisms  resulting point clouds  lidar mapping literature  constant velocity motion model  upsampled inertial data  motion distortion  explicit motion-model  temporally precise upsampled preintegrated measurement  frame-to-frame planar  edge features association  probabilistic framework  inertial lidar localisation and mapping  batch on-manifold optimisation formulation  state change estimation  front-end interaction  back-end interaction  Laser radar  Distortion measurement  Three-dimensional displays  Distortion  Optimization  Trajectory  Gyroscopes 
Abstract: In this paper, we introduce a probabilistic framework for INertial Lidar Localisation And MApping (IN2LAMA). Most of today's lidars are based on spinning mechanisms that do not capture snapshots of the environment. As a result, movement of the sensor can occur while scanning. Without a good estimation of this motion, the resulting point clouds might be distorted. In the lidar mapping literature, a constant velocity motion model is commonly assumed. This is an approximation that does not necessarily always hold. The key idea of the proposed framework is to exploit preintegrated measurements over upsampled inertial data to handle motion distortion without the need for any explicit motion-model. It tightly integrates inertial and lidar data in a batch on-manifold optimisation formulation. Using temporally precise upsampled preintegrated measurement allows frame-to-frame planar and edge features association. Moreover, features are re-computed when the estimate of the state changes, consolidating front-end and back-end interaction. We validate the effectiveness of the approach through simulated and real data.


Title: Energy Tank-Based Wrench/Impedance Control of a Fully-Actuated Hexarotor: A Geometric Port-Hamiltonian Approach
Key Words: autonomous aerial vehicles  control system synthesis  controllability  end effectors  feedback  force control  helicopters  mobile robots  nonlinear control systems  observers  stability  trajectory control  fully-actuated hexarotor  geometrically consistent manner  wrench observer  geometric port-Hamiltonian approach  aerial robot  port-Hamiltonian framework  special Euclidean group  UAV nonlinear geometric structure  energy tanks concept  contact stability  Unmanned aerial vehicles  Impedance  Robots  Springs  Propellers  Mathematical model  Observers 
Abstract: In this work, we show how the interactive behavior of an aerial robot can be modeled and controlled effectively and elegantly in the port-Hamiltonian framework. We present an observer-based wrench/impedance controller for a fully-actuated hexarotor. The analysis and control are performed in a geometrically consistent manner on the configuration manifold of the special Euclidean group SE (3) such that the UAV's nonlinear geometric structure is exploited. The controller uses a wrench observer to estimate the interaction wrench without the use of a force/torque sensor. Moreover, the concept of energy tanks is used to guarantee the system's overall contact stability to arbitrary passive environments. The reliability and robustness of the proposed approach is validated through simulation and experiment.


Title: Integral Backstepping Position Control for Quadrotors in Tunnel-Like Confined Environments
Key Words: aerodynamics  aerospace robotics  helicopters  Kalman filters  mechanical stability  mobile robots  pose estimation  position control  robot dynamics  robot vision  SLAM (robots)  tunnels  vision-based localisation  cross-sectional localisation system  integral backstepping controller  quadrotors  tunnel-like confined environments  integral backstepping position control  kinematic Kalman filter  semiautonomous system  flying robots  aerodynamic disturbances  Backstepping  Aerodynamics  Kinematics  Kalman filters  Navigation  Rail transportation  Sensors 
Abstract: There are many potential applications that require flying robots to navigate through tunnel-like environments, such as inspections of small railway culverts and mineral mappings of mining tunnels. Nevertheless, those environments present many challenges for quadrotors to navigate through. The aerodynamic disturbances created from the fluid interaction between the propellers' downwash and the surrounding surfaces of the environment, as well as longitudinal wind gusts, add hardship in stabilising the vehicle while the restricted narrow space increases the risk of collision. Furthermore, poor visibility and dust blown by the downwash make vision-based localisation extremely difficult. This paper presents a cross-sectional localisation system using Hough Scan Matching and a simple kinematic Kalman filter. Using the estimated state information, an integral backstepping controller is implemented which enables quadrotors to robustly fly in tunnel-like confined environments. A semi-autonomous system is proposed with self-stabilisation in the vertical and lateral axes while a pilot provides commands in the longitudinal direction. The results of a series of experiments in a simulated tunnel show that the proposed system successfully hovered itself and tracked various trajectories in a cross-sectional area without the aid of any external sensing or computing system.


Title: Fast Terminal Sliding Mode Super Twisting Controller For Position And Altitude Tracking of the Quadrotor
Key Words: attitude control  autonomous aerial vehicles  closed loop systems  control system synthesis  helicopters  Lyapunov methods  nonlinear control systems  position control  stability  variable structure systems  fast terminal sliding mode super twisting controller  altitude tracking  nonlinear fast terminal sliding manifold  super twisting reaching law  quadrotor position  FTSMSTC design  chattering phenomena  Lyapunov stability theory  MATLAB simulation  DJI Matrice M100  complete closed loop system stability  Convergence  Manifolds  Attitude control  Stability analysis  Sliding mode control  Trajectory  Backstepping 
Abstract: This paper proposes a fast terminal sliding mode super twisting controller (FTSMSTC) design for quadrotor position and altitude tracking in the presence of bounded disturbances. A nonlinear fast terminal sliding manifold has been proposed for fast convergence of the tracking error to zero in finite time unlike the conventional sliding mode control (CSMC) that guarantee only asymptotic convergence of the tracking error. The super twisting reaching law has been proposed to deal with the chattering phenomena, which is inherent in the CSMC. The finite time stability of the complete closed loop system is investigated using Lyapunov stability theory and an analytical expression for the convergence time has also been derived. The effectiveness of the designed controller is checked against the CSMC using MATLAB simulation. The controller has been experimentally validated using the DJI Matrice M100 as a proof of utility in real time applications.


Title: Exploiting a Human-Aware World Model for Dynamic Task Allocation in Flexible Human-Robot Teams
Key Words: cameras  human-robot interaction  mobile robots  motion control  multi-robot systems  robot vision  human participation  human models  human-robot teaming framework  human-aware world model  dynamic task allocation  human-robot teams  human-robot cooperation  eye-in-hand camera images  task operations  trust measure  action selection algorithm  Task analysis  Resource management  Cameras  Robot kinematics  Robot sensing systems  Dynamic scheduling 
Abstract: We propose a highly flexible approach to human-robot cooperation, where a robot dynamically selects operations contributing to a shared goal from a given task model. Therefore, knowledge on the task progress is extracted from a world model constructed from eye-in-hand camera images. Data generated from such partial workspace observations is not reliable over time, as humans may interact with resources. We therefore use a human-aware world model maintaining a measure for trust in stored objects regarding recent human presence and previous task progress. Our contribution is an action selection algorithm that uses this trust measure to interleave task operations with active vision to refresh the world model. Large-scale experiments cover various sorts of human participation in different benchmark tasks through simulation of simplified, partially randomized human models. Results illuminate system behaviour and performance for different parametrizations of our human-robot teaming framework.


Title: Group Surfing: A Pedestrian-Based Approach to Sidewalk Robot Navigation
Key Words: collision avoidance  edge detection  human-robot interaction  mobile robots  navigation  pedestrians  traffic engineering computing  pedestrian-based approach  sidewalk robot navigation  mobile robots  pedestrian-rich sidewalk environments  pedestrian-shared space  indoor spaces  pedestrian movement  linear flows  opposing directions  pedestrians  random movements  safe navigation  sidewalk space  natural human motion  socially-compliant manner  group surfing method  optimal pedestrian group  pedestrian-sparse environments  sidewalk edge detection  following method  integrated navigation stack  Navigation  Collision avoidance  Robot kinematics  Roads  Legged locomotion 
Abstract: In this paper, we propose a novel navigation system for mobile robots in pedestrian-rich sidewalk environments. Sidewalks are unique in that the pedestrian-shared space has characteristics of both roads and indoor spaces. Like vehicles on roads, pedestrian movement often manifests as linear flows in opposing directions. On the other hand, pedestrians also form crowds and can exhibit much more random movements than vehicles. Classical algorithms are insufficient for safe navigation around pedestrians and remaining on the sidewalk space. Thus, our approach takes advantage of natural human motion to allow a robot to adapt to sidewalk navigation in a safe and socially-compliant manner. We developed a group surfing method which aims to imitate the optimal pedestrian group for bringing the robot closer to its goal. For pedestrian-sparse environments, we propose a sidewalk edge detection and following method. Underlying these two navigation methods, the collision avoidance scheme is human-aware. The integrated navigation stack is evaluated and demonstrated in simulation. A hardware demonstration is also presented.


Title: Diagonally-Decoupled Direct Visual Servoing
Key Words: observers  robot vision  visual servoing  diagonally-decoupled direct visual servoing  vision-based robot control  reference image  intensity-based nonmetric solutions  fully coupled control error dynamics  translational part  lower triangular system  system dynamics  analysis complexity  system performance  nonlinear observer  rotational part  decoupling properties  robotic arm  control error dynamics  Visual servoing  Cameras  Convergence  Observers  Transmission line matrix methods  Voltage control 
Abstract: This paper addresses the problem of vision-based robot control where a reference image defines the equilibrium. Specifically, we consider the class of intensity-based nonmetric solutions, which provide for high accuracy, versatility, and robustness. Existing techniques within that class present either a fully coupled control error dynamics or at best only achieve decoupling of the translational part, i.e., they can only obtain a lower triangular system. These couplings in the system dynamics increase analysis complexity and may degrade system performance. This work proposes a new nonlinear observer for also decoupling the rotational part, i.e., for diagonally decoupling the entire control error dynamics. Theoretical proofs of stability and of those decoupling properties are provided. Improved performances are also experimentally confirmed using synthetic and real data, planar and nonplanar objects, simulating and applying a camera-mounted 6-DoF robotic arm.


Title: Model Predictive Control of Ride-sharing Autonomous Mobility-on-Demand Systems
Key Words: predictive control  road traffic control  model predictive control approach  self-driving vehicles  on-demand mobility  time-expanded network flow model  real-time MPC algorithm  customer-carrying vehicles  social welfare  RAMoD system  ride-sharing autonomous mobility-on-demand systems  empty vehicle  customer-carrying vehicle  San Francisco  CA  Roads  Automobiles  Prediction algorithms  Artificial neural networks  Analytical models  Optimization  Predictive models 
Abstract: This paper presents a model predictive control (MPC) approach to optimize routes for Ride-sharing Autonomous Mobility-on-Demand (RAMoD) systems, whereby self-driving vehicles provide coordinated on-demand mobility, possibly allowing multiple customers to share a ride. Specifically, we first devise a time-expanded network flow model for RAMoD. Second, leveraging this model, we design a real-time MPC algorithm to optimize the routes of both empty and customer-carrying vehicles, with the goal of optimizing social welfare, namely, a weighted combination of customers' travel time and vehicles' mileage. Finally, we present a real-world case study for the city of San Francisco, CA, by using the micro-scopic traffic simulator MATSim. The simulation results show that a RAMoD system can significantly improve social welfare with respect to a single-occupancy Autonomous Mobility-on-Demand (AMoD) system, and that the predictive structure of the proposed MPC controller allows it to outperform existing reactive ride-sharing coordination algorithms for RAMoD.


Title: A Hierarchical Framework for Coordinating Large-Scale Robot Networks
Key Words: collision avoidance  mobile robots  motion control  multi-robot systems  road traffic control  hierarchical framework  large-scale robot networks  motion coordination problems  multirobot system  robotic warehouses  automated transportation systems  life-long planning problem  coordination performance  robot motion uncertainties  hierarchical path planning  motion coordination structure  traffic heat-map  path planning level  sector-level path  path distance  motion coordination level  collision-free local path  rolling planning manner  traffic condition  robot uncertainty  Robot kinematics  Path planning  Task analysis  Collision avoidance  Planning  Topology 
Abstract: In this paper, we study the cooperative path planning and motion coordination problems of the multi-robot system with large number of robots, aiming for practical applications in robotic warehouses and automated transportation systems. Particularly, we solve the life-long planning problem and guarantee the coordination performance in the presence of robot motion uncertainties. A hierarchical path planning and motion coordination structure is presented. The environment is divided into several sectors and a traffic heat-map is presented to describe the current sector-level traffic condition. In path planning level, the sector-level path is calculated by considering the path distance, the current traffic condition and the current robot uncertainty. In motion coordination level, local cooperative A* algorithm and conflict-based searching strategy are utilized within each sector to generate the collision-free local path of each robot in a rolling planning manner. The effectiveness and practical applicability of the proposed approach are validated by simulations with more than one thousand robots and real experiments.


Title: Quantifying the Reality Gap in Robotic Manipulation Tasks
Key Words: image motion analysis  manipulators  mobile robots  robot vision  robotic manipulation tasks  Kinova robotic manipulator  motion capture system  manipulation-oriented robotic tasks  robotic reaching task  robotic interaction task  quantitative data  Physics  Engines  Task analysis  Hardware  Manipulators  Computational modeling 
Abstract: We quantify the accuracy of various simulators compared to a real world robotic reaching and interaction task. Simulators are used in robotics to design solutions for real world hardware without the need for physical access. The `reality gap' prevents solutions developed or learnt in simulation from performing well, or at all, when transferred to real-world hardware. Making use of a Kinova robotic manipulator and a motion capture system, we record a ground truth enabling comparisons with various simulators, and present quantitative data for various manipulation-oriented robotic tasks. We show the relative strengths and weaknesses of numerous contemporary simulators, highlighting areas of significant discrepancy, and assisting researchers in the field in their selection of appropriate simulators for their use cases.


Title: Learning Robust Manipulation Skills with Guided Policy Search via Generative Motor Reflexes
Key Words: learning (artificial intelligence)  manipulators  neural nets  search problems  trajectory control  robust manipulation skills  control policies  complex manipulation tasks  high-dimensional neural networks  robot actions  real-world trajectory samples  resulting neural networks  policy representation  robust actions  broader state space  state-dependent motor reflex  similar motor reflexes  real-world manipulation tasks  guided policy search  generative motor reflexes map states  state-action policies  Neural networks  Trajectory  Robots  Robustness  Reinforcement learning  Space exploration  Training 
Abstract: Guided Policy Search enables robots to learn control policies for complex manipulation tasks efficiently. Therein, the control policies are represented as high-dimensional neural networks which derive robot actions based on states. However, due to the small number of real-world trajectory samples in Guided Policy Search, the resulting neural networks are only robust in the neighbourhood of the trajectory distribution explored by real-world interactions. In this paper, we present a new policy representation called Generative Motor Reflexes, which is able to generate robust actions over a broader state space compared to previous methods. In contrast to prior state-action policies, Generative Motor Reflexes map states to parameters for a state-dependent motor reflex, which is then used to derive actions. Robustness is achieved by generating similar motor reflexes for many states. We evaluate the presented method in simulated and real-world manipulation tasks, including contact-rich peg-in-hole tasks. Using these evaluation tasks, we show that policies represented as Generative Motor Reflexes lead to robust manipulation skills also outside the explored trajectory distribution with less training needs compared to previous methods.


Title: Learning Quickly to Plan Quickly Using Modular Meta-Learning
Key Words: control engineering computing  learning (artificial intelligence)  manipulators  path planning  multiobject manipulation problems  continuous state  continuous operator parameters  state description  discrete parameters  single specializer  modular meta-learning approach  action spaces  3D pick-and-place tasks  Task analysis  Planning  Robots  Skeleton  Search problems  Companies  Neural networks 
Abstract: Multi-object manipulation problems in continuous state and action spaces can be solved by planners that search over sampled values for the continuous parameters of operators. The efficiency of these planners depends critically on the effectiveness of the samplers used, but effective sampling in turn depends on details of the robot, environment, and task. Our strategy is to learn functions called speciatizers that generate values for continuous operator parameters, given a state description and values for the discrete parameters. Rather than trying to learn a single specializer for each operator from large amounts of data on a single task, we take a modular meta-learning approach. We train on multiple tasks and learn a variety of specializers that, on a new task, can be quickly adapted using relatively little data - thus, our system learns quickly to plan quickly using these specializers. We validate our approach experimentally in simulated 3D pick-and-place tasks with continuous state and action spaces. Visit http://tinyurl.com/chitnis-icra-19 for a supplementary video.


Title: Streaming Scene Maps for Co-Robotic Exploration in Bandwidth Limited Environments
Key Words: autonomous underwater vehicles  geophysical image processing  image representation  object detection  oceanographic techniques  probability  robot vision  SLAM (robots)  unsupervised learning  co-robotic exploration  bandwidth tunable technique  real-time probabilistic scene modeling  communication constrained environments  deep sea  scene complexity  bandwidth requirements  underwater robot  high-level semantic scene constructs  artificially constructed tank environment  science interests  unsupervised scene model impact  resulting scene model  coral reef  bandwidth constraints  scene maps streaming  Robot sensing systems  Bandwidth  Oceans  Data models  Visualization  Bayes methods 
Abstract: This paper proposes a bandwidth tunable technique for real-time probabilistic scene modeling and mapping to enable co-robotic exploration in communication constrained environments such as the deep sea. The parameters of the system enable the user to characterize the scene complexity represented by the map, which in turn determines the bandwidth requirements. The approach is demonstrated using an underwater robot that learns an unsupervised scene model of the environment and then uses this scene model to communicate the spatial distribution of various high-level semantic scene constructs to a human operator. Preliminary experiments in an artificially constructed tank environment as well as simulated missions over a 10m×10m coral reef using real data show the tunability of the maps to different bandwidth constraints and science interests. To our knowledge this is the first paper to quantity how the free parameters of the unsupervised scene model impact both the scientific utility of and bandwidth required to communicate the resulting scene model.


Title: A Framework for On-line Learning of Underwater Vehicles Dynamic Models
Key Words: marine navigation  mobile robots  regression analysis  robot dynamics  support vector machines  tracking  underwater vehicles  vehicle dynamics  on-line learning  underwater vehicles dynamic models  accurate tracking controllers  navigation algorithms  high fidelity performance  robot dynamics  incremental support vector regression method  Robots  Vehicle dynamics  Adaptation models  Computational modeling  Heuristic algorithms  Support vector machines  Data models 
Abstract: Learning the dynamics of robots from data can help achieve more accurate tracking controllers, or aid their navigation algorithms. However, when the actual dynamics of the robots change due to external conditions, on-line adaptation of their models is required to maintain high fidelity performance. In this work, a framework for on-line learning of robot dynamics is developed to adapt to such changes. The proposed framework employs an incremental support vector regression method to learn the model sequentially from data streams. In combination with the incremental learning, strategies for including and forgetting data are developed to obtain better generalization over the whole state space. The framework is tested in simulation and real experimental scenarios demonstrating its adaptation capabilities to changes in the robot's dynamics.


Title: Underwater Communication Using Full-Body Gestures and Optimal Variable-Length Prefix Codes
Key Words: convolutional neural nets  decoding  encoding  gesture recognition  learning (artificial intelligence)  mobile robots  multi-robot systems  protocols  variable length codes  optimal variable-length prefix codes  interrobot communication  action sequences  swimming robot  communication protocol  whole-body gestures  radio-denied environments  passive communication  full-body gestures  underwater communication  robot gesture execution  classical decoding methods  observer robot  convolutional network  natural activity  Robots  Encoding  Decoding  Three-dimensional displays  Visualization  Heuristic algorithms  Target tracking 
Abstract: In this paper we consider inter-robot communication in the context of joint activities. In particular, we focus on convoying and passive communication for radio-denied environments by using whole-body gestures to provide cues regarding future actions. We develop a communication protocol whereby information described by codewords is transmitted by a series of actions executed by a swimming robot. These action sequences are chosen to optimize robustness and transmission duration given the observability, natural activity of the robot and the frequency of different messages. Our approach uses a convolutional network to make core observations of the pose of the robot being tracked, which is sending messages. The observer robot then uses an adaptation of classical decoding methods to infer a message that is being transmitted. The system is trained and validated using simulated data, tested in the pool and is targeted for deployment in the open ocean. Our decoder achieves.94 precision and.66 recall on real footage of robot gesture execution recorded in a swimming pool.


Title: Learning Recursive Bayesian Nonparametric Modeling of Moving Targets via Mobile Decentralized Sensors
Key Words: Bayes methods  Gaussian processes  learning (artificial intelligence)  recursive estimation  sensor fusion  mobile decentralized sensors  multisensor applications  GP recursive fusion law  recursive DPGP fusion approach  data fusion  Gaussian processes  recursive Bayesian nonparametric modeling  Dirichlet process  Sensor fusion  Computational modeling  Gaussian processes  Time measurement  Kinematics  Velocity measurement 
Abstract: Bayesian nonparametric models, such as the Dirichlet Process Gaussian Process (DPGP), have been shown very effective at learning models of dynamic targets exclusively from data. Previous work on batch DPGP learning and inference, however, ceases to be efficient in multi-sensor applications that require decentralized measurements to be obtained sequentially over time. Batch processing, in this case, leads to redundant computations that may hinder online applicability. This paper develops a recursive approach for DPGP learning and inference in which a novel Dirichlet Process prior based on Wasserstein metric is used for measuring the similarity between multiple Gaussian Processes (GPs). Combined with the GP recursive fusion law, the proposed recursive DPGP fusion approach enables efficient online data fusion. The problem of active sensing for recursive DPGP learning and inference is also investigated by uncertainty reduction via expected mutual information. Simulation and experimental results show that the proposed approach successfully learns the models of moving targets and outperforms existing benchmark methods.


Title: Distributed Motion Tomography for Reconstruction of Flow Fields*
Key Words: inverse problems  linear systems  multi-agent systems  nonlinear equations  nonlinear systems  optimisation  distributed nonlinear Kaczmarz method  constrained consensus problem  gyre flow field  distributed motion tomography  mobile sensing agents  inverse problem  distributed multiagent systems  flow field reconstruction  nonlinear system of equations  optimization approach  linear system of equations  Trajectory  Mathematical model  Robot sensing systems  Optimization  Tomography  Estimation  Inverse problems 
Abstract: This paper considers a group of mobile sensing agents in a flow field and presents a distributed method for motion tomography (MT) that estimates the underlying flow field. MT formulates an underdetermined nonlinear system of equations as an inverse problem. Inspired by the Kaczmarz method which is an optimization approach for solving a linear system of equations, our previous work developed a nonlinear Kaczmarz method that solves the system of equations associated with MT. Considering distributed multi-agent systems for MT, this paper extends the nonlinear Kaczmarz method into a distributed framework. The distributed nonlinear Kaczmarz method is developed by formulating a constrained consensus problem that belongs to a class of projected consensus algorithms. To study the convergence and consensus for the method, its linear case is analyzed first and then its nonlinear case is discussed. The nonlinear case of the method is further validated through simulations by estimating a gyre flow field using mobile sensor networks with different numbers of neighboring agents. Resulting estimated flow fields are compared with a flow field estimated by its centralized counterpart.


Title: HG-DAgger: Interactive Imitation Learning with Human Experts
Key Words: learning (artificial intelligence)  HG-DAgger  interactive imitation learning  behavioral cloning  data mismatch  DAgger algorithm  sampling schemes  action labels  autonomous driving task  corrective actions  Safety  Cloning  Training  Measurement  Trajectory  Task analysis 
Abstract: Imitation learning has proven to be useful for many real-world problems, but approaches such as behavioral cloning suffer from data mismatch and compounding error issues. One attempt to address these limitations is the DAgger algorithm, which uses the state distribution induced by the novice to sample corrective actions from the expert. Such sampling schemes, however, require the expert to provide action labels without being fully in control of the system. This can decrease safety and, when using humans as experts, is likely to degrade the quality of the collected labels due to perceived actuator lag. In this work, we propose HG-DAgger, a variant of DAgger that is more suitable for interactive imitation learning from human experts in real-world systems. In addition to training a novice policy, HG-DAgger also learns a safety threshold for a model-uncertainty-based risk metric that can be used to predict the performance of the fully trained novice in different regions of the state space. We evaluate our method on both a simulated and real-world autonomous driving task, and demonstrate improved performance over both DAgger and behavioral cloning.


Title: Compensation of measurement noise and bias in geometric attitude estimation*
Key Words: approximation theory  geometry  Kalman filters  nonlinear filters  measurement noise  geometric attitude estimation  geometry-based analytic attitude estimation  single reference vector  rigid body attitude estimation  residual error  geometric solution  rate measurements  methodical perturbation analysis  bias estimator  nonlinear problem  optimal Kalman gain  vector measurement  linearization approximations  sxtended Kalman filter  Angular velocity  Velocity measurement  Noise measurement  Measurement uncertainty  Q measurement  Estimation  Quaternions 
Abstract: A geometry-based analytic attitude estimation using a rate measurement and measurement of a single reference vector has been recently proposed. Because rigid body attitude estimation is a fundamentally nonlinear problem, the geometry-based method does not contain errors consequent to linearization approximations. A critical source of residual error in the geometric solution is on account of the noise and bias in the vector and rate measurements. A methodical perturbation analysis of the attitude estimate is performed in this paper that reveals the effects of measurement noise and bias, and provides means to compensate for, or filter out, such errors. Application of the filter and compensation provides better attitude estimation than a standard Extended Kalman filter using an optimal Kalman gain. The geometric method is first verified in experiments and then simulation results are provided that validate the better performance of the geometric attitude and bias estimator.


Title: Generating Adversarial Driving Scenarios in High-Fidelity Simulators
Key Words: automobile industry  Bayes methods  computer vision  control engineering computing  learning (artificial intelligence)  mobile robots  optimisation  program testing  road traffic  road vehicles  traffic engineering computing  transportation  self-driving policy  simulated pedestrians  self-driving behavior  high-fidelity simulators  public roads  software tests  self-driving software  adversarial self-driving scenarios  self-driving vehicles  transportation systems  simulated driving scenarios  driving scenario generation  self-driving car industry  Bayesian optimization  vision-based imitation learning  Optimization  Accidents  Rendering (computer graphics)  Bayes methods  Reinforcement learning  Roads  Trajectory 
Abstract: In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems. Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on high-fidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle. It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios. The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1]. In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using vision-based imitation learning we obtain safer self-driving behavior.


Title: Data-Driven Contact Clustering for Robot Simulation
Key Words: control engineering computing  force sensors  learning (artificial intelligence)  multilayer perceptrons  optimisation  pattern clustering  robots  data-driven contact clustering  rigid-body robot simulation  multilayer perceptron network  constraint-based optimization contact solver  contact simulation  data-driven learning-based contact clustering  force sensors  torque sensors  MLP network  Force  Numerical models  Robot sensing systems  Data models  Numerical stability  Optimization 
Abstract: We propose a novel data-driven learning-based contact clustering (i.e., of contact points and contact normals) framework for rigid-body robot simulation, with its accuracy established/verified by real experimental data. We first construct an experimental robotic setup with force/torque (F/T) sensors to collect real contact motion/force data. We then design a multilayer perceptron (MLP) network for the contact clustering based on the full motion and force/torque information of the contacts. We also adopt the constraint-based optimization contact solver to facilitate the learning of our MLP network during the training. Our proposed data-driven/learning-based contact clustering framework is then verified against the experimental setup, compared with other techniques/simulators and shown to significantly (or meaningfully) enhance the accuracy of contact simulation as compared to them.


Title: Pavilion: Bridging Photo-Realism and Robotics
Key Words: control engineering computing  image sequences  mobile robots  sensor fusion  virtual reality  Pavilion  bridging photo-realism  robotics  sensor fusion  robot control  novel open-source simulation system  robot perception  kinematic control  ROS  shader-based method  optical flow ground-truth data  Gazebo-compatible real-time simulation system  control algorithms  simulation environment  state-of-the-art simulators  simulation accuracy  simulation environments  unreal engine  simulation description format robot models  robot operating system  Engines  Robot sensing systems  Data models  Real-time systems  Pipelines  Optical sensors 
Abstract: Simulation environments play a centric role in the research of sensor fusion and robot control. This paper presents Pavilion, a novel open-source simulation system, for robot perception and kinematic control based on the Unreal Engine and the Robot Operating System (ROS). The novelty of this work includes threefold: (1) developing a shader-based method to generate optical flow ground-truth data with the Unreal Engine, (2) developing a toolset to remove binary incompatibility between ROS and the Unreal Engine to enable real-time interaction, and (3) developing a method to directly import Simulation Description Format (SDF) robot models into the Unreal Engine at runtime. Finally, a Gazebo-compatible real-time simulation system is developed to enable training and evaluation of a large number of sensor fusion, planning, decision and control algorithms. The system can be implemented on both Linux and macOS, with the latest version of ROS. Various experiments have been performed to validate the superior performance of the proposed simulation environment over other state-of-the-art simulators in terms of number of modalities, simulation accuracy, latency and degree of integration difficulty.


Title: A Real-Time Interactive Augmented Reality Depth Estimation Technique for Surgical Robotics
Key Words: augmented reality  kinematics  medical computing  medical robotics  surgery  Stereo-No CDE  CDE technique  forward kinematics joint encoder data  surgical field  virtual surgical instrument method  AR technique  blue-red color spectrum  tissue surface  tumor  medical abnormality  surgical robotics  color depth encoding  real-time interactive augmented reality depth estimation  Tools  Robots  Tumors  Image color analysis  Cameras  Instruments  Biomedical imaging 
Abstract: Augmented reality (AR) is a promising technology where the surgeon can see the medical abnormality in the context of the patient. It makes the anatomy of interest visible to the surgeon which otherwise is not visible. It can result in better surgical precision and therefore, potentially better surgical outcomes and faster recovery times. Despite these benefits, the current AR systems suffer from two major challenges; first, incorrect depth perception and, second, the lack of suitable evaluation systems. Therefore, in the current paper we addressed both of these problems. We proposed a color depth encoding (CDE) technique to estimate the distance between the tumor and the tissue surface using a surgical instrument. We mapped the distance between the tumor and the tissue surface to the blue-red color spectrum. For evaluation and interaction with our AR technique, we propose to use a virtual surgical instrument method using the CAD model of the instrument. The users were asked to reach the judged distance in the surgical field using the virtual tool. Realistic tool movement was simulated by collecting the forward kinematics joint encoder data. The results showed significant improvement in depth estimation, time for task completion and confidence, using our CDE technique with and without stereo versus other two cases, that are, Stereo-No CDE and No Stereo-No CDE.


Title: Force-based Heterogeneous Traffic Simulation for Autonomous Vehicle Testing
Key Words: computer simulation  control engineering computing  driver information systems  mobile robots  road safety  road traffic control  road vehicles  traffic engineering computing  self-driving tests  force-based concept  heterogenous traffic simulation  realistic urban environment  personal mobility devices  pedestrians  autonomous vehicles  traffic control  high-fidelity driving simulator  autonomous vehicle testing  force-based heterogeneous traffic simulation  Force  Autonomous vehicles  Roads  Acceleration  Bicycles  Testing  Urban areas 
Abstract: Recent failures in real-world self-driving tests have suggested a paradigm shift from directly learning in real-world roads to building a high-fidelity driving simulator as an alternative, effective, and safe tool to handle intricate traffic environments in urban areas. To date, traffic simulation can construct virtual urban environments with various weather conditions, day and night, and traffic control for autonomous vehicle testing. However, mutual interactions between autonomous vehicles and pedestrians are rarely modeled in existing simulators. Besides vehicles and pedestrians, the usage of personal mobility devices is increasing in congested cities as an alternative to the traditional transport system. A simulator that considers all potential road-users in a realistic urban environment is urgently desired. In this work, we propose a novel, extensible, and microscopic method to build heterogenous traffic simulation using the force-based concept. This force-based approach can accurately replicate the sophisticated behaviors of various road users and their interactions through a simple and unified way. Furthermore, we validate our approach through simulation experiments and comparisons to the popular simulators currently used for research and development of autonomous vehicles.


Title: Designing an Accurate and Customizable Epidural Anesthesia Haptic Simulator
Key Words: computer simulation  haptic interfaces  medical computing  pneumatic cylinder  electrical haptic interface  epidural anesthesia haptic simulator  medical procedure  Needles  Haptic interfaces  Force  Anesthesia  Prototypes  Bones  Training 
Abstract: Epidural anesthesia, despite being a relatively common medical procedure, remains quite demanding in terms of skills as it is mostly blind and thus heavily reliant on the haptic sensations. Although some training support solutions exist, anesthetists consider them mostly inefficient or impractical. A few attempts at creating a simulator for this particular procedure exist but each one lacks one of the important requirements of the procedure. This article introduces a haptic simulator featuring a more complete and realistic simulation of the procedure than we could observe in existing simulators. The simulator is composed of a generic electrical haptic interface coupled with a pneumatic cylinder.


Title: Real-time Model Predictive Control for Versatile Dynamic Motions in Quadrupedal Robots
Key Words: legged locomotion  motion control  predictive control  quadratic programming  robot dynamics  versatile dynamic motions  quadrupedal robot  single rigid body dynamics  rotation matrices  quaternions  unwinding phenomenon  MPC control law  periodic quadrupedal gaits  model predictive control framework  quadratic program  QP  Euler angles  acrobatic maneuvers  Legged locomotion  Dynamics  Robot kinematics  Three-dimensional displays  Trajectory  Real-time systems 
Abstract: This paper presents a new Model Predictive Control (MPC) framework for controlling various dynamic movements of a quadrupedal robot. System dynamics are represented by linearizing single rigid body dynamics in three-dimensional (3D) space. Our formulation linearizes rotation matrices without resorting to parameterizations like Euler angles and quaternions, avoiding issues of singularity and unwinding phenomenon, respectively. With a carefully chosen configuration error function, the MPC control law is transcribed into a Quadratic Program (QP) which can be solved efficiently in realtime. Our formulation can stabilize a wide range of periodic quadrupedal gaits and acrobatic maneuvers. We show various simulation as well as experimental results to validate our control strategy. Experiments prove the application of this framework with a custom QP solver could reach execution rates of 160 Hz on embedded platforms.


Title: Bounded Collision Force by the Sobolev Norm
Key Words: compliance control  control system synthesis  end effectors  feedback  force control  H2 control  manipulator dynamics  mechanical contact  springs (mechanical)  Sobolev norm  robot inertia  analytical models  maximum collision force  simplified mass-spring robot model  end-effector compliance  system norm  maximum force  general dynamic system  feedback control  control theory  controller synthesis  admittance-controlled robot  linear flexible-joint robot  bounded collision force  robot contact  safety risks  collision force minimisation  Force  Collision avoidance  Robot sensing systems  Measurement  End effectors  Admittance 
Abstract: A robot making contact with an environment or human presents potential safety risks, including excessive collision force. While experiments on the effect of robot inertia, relative velocity, and interface stiffness on collision are in literature, analytical models for maximum collision force are limited to a simplified mass-spring robot model. This simplified model limits the analysis of control (force/torque, impedance, or admittance) or compliant robots (joint and end-effector compliance). Here, the Sobolev norm is adapted to be a system norm, giving rigorous bounds on the maximum force on a stiffness element in a general dynamic system, allowing the study of collision with more accurate models and feedback control. The Sobolev norm can be found through the H2 norm of a transformed system, allowing efficient computation, connection with existing control theory, and controller synthesis to minimize collision force. The Sobolev norm is validated, first experimentally with an admittance-controlled robot, then in simulation with a linear flexible-joint robot. It is then used to investigate the impact of control, joint flexibility and end-effector compliance on collision, and a trade-off between collision performance and environmental estimation uncertainty is shown.


Title: Early Failure Detection of Deep End-to-End Control Policy by Reinforcement Learning
Key Words: belief networks  control engineering computing  convolutional neural nets  learning (artificial intelligence)  learning systems  observability  predictive control  learned control policies  reinforcement learning  end-to-end imitation  predictive uncertainty  model predictive controller  fully-observable vision-based partially-observable systems  deep convolutional Bayesian neural networks  deep end-to-end control policy  Bayesian networks  mean value  corrective action  partial state observability  Uncertainty  Bayes methods  Task analysis  Neural networks  Safety  Training  Autonomous vehicles 
Abstract: We propose the use of Bayesian networks, which provide both a mean value and an uncertainty estimate as output, to enhance the safety of learned control policies under circumstances in which a test-time input differs significantly from the training set. Our algorithm combines reinforcement learning and end-to-end imitation learning to simultaneously learn a control policy as well as a threshold over the predictive uncertainty of the learned model, with no hand-tuning required. Corrective action, such as a return of control to the model predictive controller or human expert, is taken before the failure of tasks, when the uncertainty threshold is exceeded. We validate our method on fully-observable and vision-based partially-observable systems using cart-pole and autonomous driving simulations using deep convolutional Bayesian neural networks. We demonstrate that our method is robust to uncertainty resulting from varying system dynamics as well as from partial state observability.


Title: Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning
Key Words: approximation theory  control engineering computing  dynamic programming  gradient methods  learning (artificial intelligence)  mobile robots  optimal control  partial differential equations  dynamic programming equation  contraction mapping  Hamilton-Jacobi safety analysis  control-theoretic safety analysis  optimal safety policy  quantitative safety analysis  reinforcement learning techniques  time-discounted modification  optimal control problems  robust optimal control theory  autonomous robotic systems  policy gradient techniques  value learning  Safety  Automation  Reinforcement learning  Robots  Optimal control  Jacobian matrices  Reachability analysis 
Abstract: Safety analysis is a necessary component in the design and deployment of autonomous robotic systems. Techniques from robust optimal control theory, such as Hamilton-Jacobi reachability analysis, allow a rigorous formalization of safety as guaranteed constraint satisfaction. Unfortunately, the computational complexity of these tools for general dynamical systems scales poorly with state dimension, making existing tools impractical beyond small problems. Modern reinforcement learning methods have shown promising ability to find approximate yet proficient solutions to optimal control problems in complex and high-dimensional systems, however their application has in practice been restricted to problems with an additive payoff over time, unsuitable for reasoning about safety. In recent work, we introduced a time-discounted modification of the problem of maximizing the minimum payoff over time, central to safety analysis, through a modified dynamic programming equation that induces a contraction mapping. Here, we show how a similar contraction mapping can render reinforcement learning techniques amenable to quantitative safety analysis as tools to approximate the safe set and optimal safety policy. This opens a new avenue of research connecting control-theoretic safety analysis and the reinforcement learning domain. We validate the correctness of our formulation by comparing safety results computed through Q-learning to analytic and numerical solutions, and demonstrate its scalability by learning safe sets and control policies for simulated systems of up to 18 state dimensions using value learning and policy gradient techniques.


Title: Orientation-Aware Motion Planning in Complex Workspaces using Adaptive Harmonic Potential Fields
Key Words: collision avoidance  mobile robots  motion control  orientation-aware motion planning  complex workspaces  adaptive harmonic potential fields  hybrid control scheme  navigation problem  planar robotic platform  approximate configuration space decomposition techniques  appropriate workspace transformations  adaptive potential field based control laws  configuration space representation  obstacle cluttered workspace  Aerospace electronics  Robot kinematics  Harmonic analysis  Navigation  Shape  Approximation algorithms 
Abstract: In this work, a hybrid control scheme is presented in order to address the navigation problem for a planar robotic platform of arbitrary shape that is moving inside an obstacle cluttered workspace. Given an initial and desired robot configuration, we propose a methodology based on approximate configuration space decomposition techniques that makes use of heuristics to adaptively refine a partition of the configuration space into non-overlapping, adjacent slices. Furthermore, we employ appropriate workspace transformations and adaptive potential field based control laws that integrate elegantly with the type of configuration space representation used, in order to safely navigate within a given cell and successfully cross over to the next, for almost all initial configurations, until the desired configuration is reached. Finally, we present simulation results that demonstrate the efficacy of the proposed control scheme.


Title: DMP Based Trajectory Tracking for a Nonholonomic Mobile Robot With Automatic Goal Adaptation and Obstacle Avoidance
Key Words: collision avoidance  fuzzy logic  gradient methods  learning (artificial intelligence)  Lyapunov methods  manipulator dynamics  mobile robots  motion control  position control  radial basis function networks  stability  steering systems  trajectory control  Dynamic Movement Primitive  motion planning  robot manipulator  nonholonomic mobile robot  Radial Basis Function Networks  robot goal position  Lyapunov stability theory-based analysis  dynamic obstacles  automatic goal adaptation  RBFN  DMP  gradient descent  static obstacles  trajectory tracking  damped spring model  steering angle dynamics  fuzzy logic  Mobile robots  Trajectory  Mathematical model  Robot kinematics  Collision avoidance  Dynamics 
Abstract: Dynamic Movement Primitive (DMP) which is popular for motion planning of a robot manipulator, has been adapted for a nonholonomic mobile robot to track the desired trajectory. DMP is a simple damped spring model with a forcing function, which learns the trajectory. The damped spring model attracts the robot towards the goal position, and the forcing function forces the robot to follow the given trajectory. Two Radial Basis Function Networks (RBFNs) have been used to learn the forcing function associated with the DMP model. Weight update laws are derived using the gradient descent approach to train the RBFNs. Fuzzy logic based steering angle dynamics is proposed to handle the asymmetric nature of an obstacle. The proposed scheme is capable enough to generate a smooth trajectory in the presence of an obstacle even when start and goal positions are altered, without losing the spatial information embedded while training. The convergence of the robot goal position has been shown using Lyapunov stability theory-based analysis. The approach has been extended to multiple static and dynamic obstacles for the successful convergence of the robot at the goal position. Both simulation and experimental results are provided to confirm the efficacy of the proposed scheme.


Title: Predictive Collision Avoidance for the Dynamic Window Approach
Key Words: collision avoidance  mobile robots  motion control  predictive collision avoidance  dynamic window approach  foresighted navigation  mobile robots  factory floor installations  dynamic collision model  nonholonomic vehicles  Trajectory  Vehicle dynamics  Dynamics  Acceleration  Collision avoidance  Robot sensing systems 
Abstract: Foresighted navigation is an essential skill for robots to rise from rigid factory floor installations to much more versatile mobile robots that partake in our everyday environment. The current state of the art that provides this mobility to some extent is the Dynamic Window Approach combined with a global start-to-target path planner. However, neither the Dynamic Window Approach nor the path planner are equipped to predict the motion of other objects in the environment. We propose a change in the Dynamic Window Approach-a dynamic collision model-that is capable of predicting future collisions with the environment by also taking into account the motion of other objects. We show in simulated experiments that our new way of computing the Dynamic Window Approach significantly reduces the number of collisions in a dynamic setting with nonholonomic vehicles while still being computationally efficient.


Title: OVPC Mesh: 3D Free-space Representation for Local Ground Vehicle Navigation
Key Words: computational geometry  mesh generation  mobile robots  navigation  path planning  remotely operated vehicles  robot vision  stereo image processing  OVPC Mesh  3D free-space representation  local ground vehicle navigation  autonomous unmanned ground vehicle  Visible Point Clouds Mesh  local point cloud data  UGV navigation  on visible point clouds mesh  watertight 3D mesh generation  trajectory planning  robot  Three-dimensional displays  Navigation  Robot sensing systems  Planning  Laser radar  Real-time systems 
Abstract: This paper presents a novel approach for local 3D environment representation for autonomous unmanned ground vehicle (UGV) navigation called On Visible Point Clouds Mesh (OVPC Mesh). Our approach represents the surrounding of the robot as a watertight 3D mesh generated from local point cloud data in order to represent the free space surrounding the robot. It is a conservative estimation of the free space and provides a desirable trade-off between representation precision and computational efficiency, without having to discretize the environment into a fixed grid size. Our experiments analyze the usability of the approach for UGV navigation in rough terrain, both in simulation and in a fully integrated real-world system. Additionally, we compare our approach to well-known state-of the-art solutions, such as Octomap and Elevation Mapping and show that OVPC Mesh can provide reliable 3D information for trajectory planning while fulfilling real-time constraints.


Title: Safe Reinforcement Learning With Model Uncertainty Estimates
Key Words: Bayes methods  collision avoidance  control engineering computing  learning (artificial intelligence)  neural nets  safety  model uncertainty estimates  current autonomous systems  strong reliance  black box predictions  deep neural networks  DNNs  unpredictable results  far-from-distribution test data  distributional shift  safety-critical applications  pedestrians  state-of-the-art extraction methods  Bayesian neural networks  MC-Dropout  computationally tractable uncertainty estimates  parallelizable uncertainty estimates  uncertainty-aware navigation  collision avoidance policy  unseen behavior  uncertainty-unaware baseline  safe reinforcement learning framework  Uncertainty  Collision avoidance  Neural networks  Computational modeling  Training  Data models  Reinforcement learning 
Abstract: Many current autonomous systems are being designed with a strong reliance on black box predictions from deep neural networks (DNNs). However, DNNs tend to be overconfident in predictions on unseen data and can give unpredictable results for far-from-distribution test data. The importance of predictions that are robust to this distributional shift is evident for safety-critical applications, such as collision avoidance around pedestrians. Measures of model uncertainty can be used to identify unseen data, but the state-of-the-art extraction methods such as Bayesian neural networks are mostly intractable to compute. This paper uses MC-Dropout and Bootstrapping to give computationally tractable and parallelizable uncertainty estimates. The methods are embedded in a Safe Reinforcement Learning framework to form uncertainty-aware navigation around pedestrians. The result is a collision avoidance policy that knows what it does not know and cautiously avoids pedestrians that exhibit unseen behavior. The policy is demonstrated in simulation to be more robust to novel observations and take safer actions than an uncertainty-unaware baseline.


Title: Generation of Synchronized Configuration Space Trajectories of Multi-Robot Systems
Key Words: multi-robot systems  optimisation  synchronized configuration space trajectories  multirobot systems  path-constrained trajectory generation  synchronous motion  nonlinear optimization problem  configuration variables  successive refinement techniques  parametric representation  Trajectory  Manipulators  Splines (mathematics)  Optimization  Robot kinematics  Tools 
Abstract: We pose the problem of path-constrained trajectory generation for the synchronous motion of multi-robot systems as a non-linear optimization problem. Our method determines appropriate parametric representation for the configuration variables, generates an approximate solution as a starting point for the optimization method, and uses successive refinement techniques to solve the problem in a computationally efficient manner. We have demonstrated the effectiveness of the proposed method on challenging simulation and physical experiments with high degrees of freedom robotic systems.


Title: Stable Bin Packing of Non-convex 3D Objects with a Robot Manipulator
Key Words: computational geometry  control engineering computing  industrial manipulators  production engineering computing  warehouse automation  nonconvex objects  bin packing  heightmap-minimization heuristic  constructive packing pipeline  placement plans  robot motion  automated warehousing domain  packing problem  fully automatic object packing  robot manipulator  nonconvex 3D objects  high-quality packing  robot packability constraints  Robots  Three-dimensional displays  Containers  Stability analysis  Collision avoidance  Pipelines  Geometry 
Abstract: Recent progress in the field of robotic manipulation has generated interest in fully automatic object packing in warehouses. This paper proposes a formulation of the packing problem that is tailored to the automated warehousing domain. Besides minimizing waste space inside a container, the problem requires stability of the object pile during packing and the feasibility of the robot motion executing the placement plans. To address this problem, a set of constraints are formulated, and a constructive packing pipeline is proposed to solve these constraints. The pipeline is able to pack geometrically complex, non-convex objects while satisfying stability and robot packability constraints. In particular, a new 3D positioning heuristic called Heightmap-Minimization heuristic is proposed, and heightmaps are used to speed up the search. Experimental evaluation of the method is conducted with a realistic physical simulator on a dataset of scanned real-world items, demonstrating stable and high-quality packing plans compared with other 3D packing methods.


Title: A Constraint Programming Approach to Simultaneous Task Allocation and Motion Scheduling for Industrial Dual-Arm Manipulation Tasks
Key Words: constraint handling  industrial manipulators  motion control  optimisation  robot programming  robotic assembly  scheduling  robotic platforms  constraint programming approach  simultaneous task allocation  motion scheduling  industrial dual-arm manipulation tasks  dual-arm robots  industrial manipulation  assembly tasks  robot motion models  constraint optimization problems  makespan-optimized robot programs  industrial workplaces  robot-independent task model  lightweight dual-arm robots  ordered visiting constraint  ordering constraints  Task analysis  Planning  Manipulators  Robot kinematics  Job shop scheduling  Service robots 
Abstract: Modern lightweight dual-arm robots bring the physical capabilities to quickly take over tasks at typical industrial workplaces designed for workers. Low setup times - including the instructing/specifying of new tasks - are crucial to stay competitive. We propose a constraint programming approach to simultaneous task allocation and motion scheduling for such industrial manipulation and assembly tasks. Our approach covers the robot as well as connected machines. The key concept are Ordered Visiting Constraints, a descriptive and extensible model to specify such tasks with their spatiotemporal requirements and combinatorial or ordering constraints. Our solver integrates such task models and robot motion models into constraint optimization problems and solves them efficiently using various heuristics to produce makespan-optimized robot programs. For large manipulation tasks with 200 objects, our solver implemented using Google's Operations Research tools requires less than a minute to compute usable plans. The proposed task model is robot-independent and can easily be deployed to other robotic platforms. This portability is validated through several simulation-based experiments.


Title: Towards 3D Path Planning from a Single 2D Fluoroscopic Image for Robot Assisted Fenestrated Endovascular Aortic Repair
Key Words: blood vessels  computerised tomography  diagnostic radiography  image registration  image segmentation  medical image processing  medical robotics  path planning  phantoms  CT scans  computed tomography  2D intra-operative AAA skeletons  graph matching method  3D preoperative AAA  3D distance error  skeleton length  skeleton deformation  real-time 3D robotic path planning  Abdominal Aortic Aneurysm  skeleton instantiation framework  2D fluoroscopic images  fenestrated endovascular aortic repair  single 2D fluoroscopic image  Three-dimensional displays  Two dimensional displays  Skeleton  Indexes  Robots  Arteries  Path planning 
Abstract: The current standard of intra-operative navigation during Fenestrated Endovascular Aortic Repair (FEVAR) calls for the need of 3D alignments between inserted devices and aortic branches. The navigation commonly via 2D fluoroscopic images, lacks anatomical information, resulting in longer operation hours and radiation exposure. In this paper, a skeleton instantiation framework of Abdominal Aortic Aneurysm (AAA) from a single 2D fluoroscopic image is introduced for real-time 3D robotic path planning. A graph matching method is proposed to establish the correspondences between the 3D preoperative and 2D intra-operative AAA skeletons, and then the two skeletons are registered by skeleton deformation and regularization in respect to skeleton length and smoothness. Furthermore, deep learning was used to segment 3D preoperative AAA from Computed Tomography (CT) scans to facilitate the framework automation. Simulation, phantom and patient AAA data sets have been used to validate the proposed framework. 3D distance error of 2mm was achieved in the phantom setup. Performance advantages were also achieved in terms of accuracy, robustness and time-efficiency.


Title: Tree Search Techniques for Minimizing Detectability and Maximizing Visibility
Key Words: game theory  minimax techniques  Monte Carlo methods  tree searching  trees (mathematics)  tree search techniques  reconnaissance mission  pursuit-evasion problem  finite-horizon path  zero-sum game  game tree search algorithms  minimax search tree  Monte-Carlo search tree  detectability minimization  visibility maximization  visibility-based target search  pruning techniques  Games  Search problems  Planning  Monte Carlo methods  Game theory  Task analysis  Reconnaissance 
Abstract: We introduce and study the problem of planning a trajectory for an agent to carry out a reconnaissance mission while avoiding being detected by an adversarial guard. This introduces a multi-objective version of classical visibility-based target search and pursuit-evasion problem. In our formulation, the agent receives a positive reward for increasing its visibility (by exploring new regions) and a negative penalty every time it is detected by the guard. The objective is to find a finite-horizon path for the agent that balances the trade off between maximizing visibility and minimizing detectability.We model this problem as a discrete, sequential, two-player, zero-sum game. We use two types of game tree search algorithms to solve this problem: minimax search tree and Monte-Carlo search tree. Both search trees can yield the optimal policy but may require possibly exponential computational time and space. We propose several pruning techniques to reduce the computational cost while still preserving optimality guarantees. Simulation results show that the proposed strategy prunes approximately three orders of magnitude nodes as compared to the brute-force strategy. We also find that the Monte-Carlo search tree saves approximately one order of computational time as compared to the minimax search tree.


Title: Complete and Near-Optimal Path Planning for Simultaneous Sensor-Based Inspection and Footprint Coverage in Robotic Crack Filling
Key Words: filling  inspection  mobile robots  optimal control  path planning  sensors  surface cracks  near-optimal path planning  robotic crack  simultaneous robotic footprint  range sensors  complete sensor coverage  planning strategy  crack-filling robotic prototype  online planning algorithm  sensor-based inspection  near-optimal footprint coverage  online sensor-based complete coverage planning  online SCC planning  Robot sensing systems  Planning  Inspection  Space exploration  Surface cracks 
Abstract: A simultaneous robotic footprint and sensor coverage planning scheme is proposed to efficiently detect all the unknown targets with range sensors and cover the targets with the robot's footprint in a structured environment. The proposed online Sensor-based Complete Coverage (online SCC) planning minimizes the total traveling distance of the robot, guarantees the complete sensor coverage of the whole free space, and achieves near-optimal footprint coverage of all the targets. The planning strategy is applied to a crack-filling robotic prototype to detect and fill all the unknown cracks on ground surfaces. Simulation and experimental results are presented that confirm the efficiency and effectiveness of the proposed online planning algorithm.


Title: Approximate Stability Analysis for Drystacked Structures
Key Words: building materials  geometry  linear programming  mechanical stability  planning  road building  shrinkage  construction materials  contact geometry  geometric safety factor  automated dry stacking procedure  building elements  structural stability analysis  kern  shrinkage  linear programming  fully simulated shaking test  heuristics-based planning  assembly process  Stability analysis  Force  Friction  Mathematical model  Stacking  Numerical stability  Buildings 
Abstract: We introduce a fast approximate stability analysis into an automated dry stacking procedure. Evaluating structural stability is essential for any type of construction, but especially challenging in techniques where building elements remain distinct and do not use fasteners or adhesives. Due to the irregular shape of construction materials, autonomous agents have restricted knowledge of contact geometry, which makes existing analysis tools difficult to deploy. In this paper, a geometric safety factor called kern is used to estimate how much the contact interface can shrink and the structure still be feasible, where feasibility can be checked efficiently using linear programming. We validate the stability measure by comparing the proposed methods with a fully simulated shaking test in 2D. We also improve existing heuristics-based planning by adding the proposed measure into the assembly process.


Title: Visual Robot Task Planning
Key Words: learning (artificial intelligence)  mobile robots  Monte Carlo methods  neural net architecture  planning (artificial intelligence)  robot vision  tree searching  visual robot task planning  visual information  planning algorithm  neural network architecture  Monte Carlo tree search  block-stacking simulation  Task analysis  Planning  Visualization  Predictive models  Robots  Transforms  Computer architecture 
Abstract: Prospection is key to solving challenging problems in new environments, but it has not been deeply explored as applied to task planning for perception-driven robotics. We propose visual robot task planning, where we take in an input image and must generate a sequence of high-level actions and associated observations that achieve some task. In this paper, we describe a neural network architecture and associated planning algorithm that (1) learns a representation of the world that can generate prospective futures, (2) uses this generative model to simulate the result of sequences of high-level actions in a variety of environments, and (3) evaluates these actions via a variant of Monte Carlo Tree Search to find a viable solution to a particular problem. Our approach allows us to visualize intermediate motion goals and learn to plan complex activity from visual information, and used this to generate and visualize task plans on held-out examples of a block-stacking simulation.


Title: Visual Representations for Semantic Target Driven Navigation
Key Words: image representation  image segmentation  learning (artificial intelligence)  mobile robots  navigation  path planning  robot vision  visual representations  semantic target driven navigation  semantic visual navigation  semantic segmentation  domain adaptation  computer vision algorithms  robot  deep network  navigation policy learning  Navigation  Visualization  Semantics  Training  Adaptation models  Robots  Task analysis 
Abstract: What is a good visual representation for navigation? We study this question in the context of semantic visual navigation, which is the problem of a robot finding its way through a previously unseen environment to a target object, e.g. go to the refrigerator. Instead of acquiring a metric semantic map of an environment and using planning for navigation, our approach learns navigation policies on top of representations that capture spatial layout and semantic contextual cues. We propose to use semantic segmentation and detection masks as observations obtained by state-of-the-art computer vision algorithms and use a deep network to learn the navigation policy. The availability of equitable representations in simulated environments enables joint training using real and simulated data and alleviates the need for domain adaptation or domain randomization commonly used to tackle the sim-to-real transfer of the learned policies. Both the representation and the navigation policy can be readily applied to real non-synthetic environments as demonstrated on the Active Vision Dataset [1]. Our approach successfully gets to the target in 54% of the cases in unexplored environments, compared to 46% for a non-learning based approach, and 28% for a learning-based baseline.


Title: Deep Object-Centric Policies for Autonomous Driving
Key Words: computer games  convolutional neural nets  data visualisation  learning (artificial intelligence)  traffic engineering computing  object-centric models  object instances  end-to-end learning  Grand Theft Auto V simulator  object-agnostic methods  object-centric policies  autonomous driving  visuomotor skills  deep neural networks  robotics tasks  intuitive visualization  Berkeley DeepDrive Video dataset  Task analysis  Training  Taxonomy  Automobiles  Autonomous vehicles  Feature extraction  Robots 
Abstract: While learning visuomotor skills in an end-to-end manner is appealing, deep neural networks are often uninterpretable and fail in surprising ways. For robotics tasks, such as autonomous driving, models that explicitly represent objects may be more robust to new scenes and provide intuitive visualizations. We describe a taxonomy of “object-centric” models which leverage both object instances and end-to-end learning. In the Grand Theft Auto V simulator, we show that object-centric models outperform object-agnostic methods in scenes with other vehicles and pedestrians, even with an imperfect detector. We also demonstrate that our architectures perform well on real-world environments by evaluating on the Berkeley DeepDrive Video dataset, where an object-centric model outperforms object-agnostic models in the low-data regimes.


Title: Online Multilayered Motion Planning with Dynamic Constraints for Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  collision avoidance  mobile robots  trajectory control  vehicle dynamics  underwater robot  online multilayered motion planning  autonomous underwater vehicles  loosely coupled multilayered planning design  motion planner  hydro-dynamic forces  trajectory planning  robots onboard computer  AUVs  inevitable collision states  Planning  Trajectory  Lead  Vehicle dynamics  Robots  Dynamics  Unmanned underwater vehicles 
Abstract: Underwater robots are subject to complex hydro-dynamic forces. These forces define how the vehicle moves, so it is important to consider them when planning trajectories. However, performing motion planning considering the dynamics on the robot's onboard computer is challenging due to the limited computational resources available. In this paper an efficient motion planning framework for autonomous underwater vehicles (AUVs) is presented. By introducing a loosely coupled multilayered planning design, our framework is able to generate dynamically feasible trajectories while keeping the planning time low enough for online planning. First, a fast path planner operating in a lower-dimensional projected space computes a lead path from the start to the goal configuration. Then, the lead path is used to bias the sampling of a second motion planner, which takes into account all the dynamic constraints. Furthermore, we propose a strategy for online planning that saves computational resources by generating the final trajectory only up to a finite horizon. By using the finite horizon strategy together with the multilayered approach, the sampling of the second planner focuses on regions where good quality solutions are more likely to be found, significantly reducing the planning time. To provide strong safety guarantees our framework also incorporates the conservative approximations of inevitable collision states (icss). finally, we present simulations and experiments using a real underwater robot to demonstrate the capabilities of our framework.


Title: Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks
Key Words: learning (artificial intelligence)  manipulators  haptic feedback  visual feedback  robot controller  deep reinforcement learning  high-dimensional inputs  sample complexity  multimodal representation  sensory inputs  policy learning  peg insertion task  self-supervised learning  multimodal representations  contact-rich manipulation tasks  Task analysis  Robot sensing systems  Haptic interfaces  Visualization  Geometry  Reinforcement learning 
Abstract: Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.


Title: Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience
Key Words: learning (artificial intelligence)  mobile robots  real world experience  simulation parameter distribution  policy training  policy transfer  policy behavior  sim-to-real loop  simulation randomization  swing-peg-in-hole  cabinet drawer opening  Adaptation models  Training  Data models  Robots  Computational modeling  Trajectory  Task analysis 
Abstract: We consider the problem of transferring policies to the real world by training on a distribution of simulated scenarios. Rather than manually tuning the randomization of simulations, we adapt the simulation parameter distribution using a few real world roll-outs interleaved with policy training. In doing so, we are able to change the distribution of simulations to improve the policy transfer by matching the policy behavior in simulation and the real world. We show that policies trained with our method are able to reliably transfer to different robots in two real world tasks: swing-peg-in-hole and opening a cabinet drawer. The video of our experiments can be found at https://sites.google.com/view/simopt.


Title: Distributed Multi-Robot Formation Splitting and Merging in Dynamic Environments
Key Words: collision avoidance  distributed control  graph theory  helicopters  mobile robots  multi-robot systems  distributed consensus  obstacle-free convex regions  distributed multirobot formation splitting  distributed multirobot formation merging  moving obstacles  static obstacles  intersection graph  quadrotors  Robot sensing systems  Collision avoidance  Merging  Navigation  Partitioning algorithms  Heuristic algorithms 
Abstract: This paper presents a distributed method for splitting and merging of multi-robot formations in dynamic environments with static and moving obstacles. Splitting and merging actions rely on distributed consensus and can be performed to avoid obstacles. Our method accounts for the limited communication range and visibility radius of the robots and relies on the communication of obstacle-free convex regions and the computation of an intersection graph. In addition, our method is able to detect and recover from (permanent and temporary) communication and motion faults. Finally, we demonstrate the applicability and scalability of the proposed method in simulations with up to sixteen quadrotors and real-world experiments with a team of four quadrotors.


Title: Multi-Robot Region-of-Interest Reconstruction with Dec-MCTS
Key Words: manipulators  Monte Carlo methods  multi-robot systems  navigation  path planning  tree searching  motion planning  high-dimensional configuration space  multirobot region-of-interest reconstruction  dec-MCTS  multiple robot arms  RGB-D sensors  precision agriculture  infrastructure inspection  viewpoint evaluation function  nonmyopic planning algorithm  decentralised Monte Carlo tree search  navigation graph  fruit detection  Robot kinematics  Robot sensing systems  Manipulators  Planning  Three-dimensional displays 
Abstract: We consider the problem of reconstructing regions of interest of a scene using multiple robot arms and RGB-D sensors. This problem is motivated by a variety of applications, such as precision agriculture and infrastructure inspection. A viewpoint evaluation function is presented that exploits predicted observations and the geometry of the scene. A recently proposed non-myopic planning algorithm, Decentralised Monte Carlo tree search, is used to coordinate the actions of the robot arms. Motion planning is performed over a navigation graph that considers the high-dimensional configuration space of the robot arms. Extensive simulated experiments are carried out using real sensor data and then validated on hardware with two robot arms. Our proposed targeted information gain planner is compared to state-of-the-art baselines and outperforms them in every measured metric. The robots quickly observe and accurately detect fruit in a trellis structure, demonstrating the viability of the approach for real-world applications.


Title: Search-based 3D Planning and Trajectory Optimization for Safe Micro Aerial Vehicle Flight Under Sensor Visibility Constraints
Key Words: aerospace safety  collision avoidance  graph theory  navigation  search problems  trajectory optimisation (aerospace)  trajectory optimization  sensor visibility constraints  obstacle-free flight paths  Velodyne Puck Lite 3D laser scanner  flight dynamics  navigation safety  allocentric complete planning  microaerial vehicle flight safety  search-based 3D planning  collision avoidance  graph search  Planning  Robot sensing systems  Three-dimensional displays  Trajectory optimization  Vehicle dynamics 
Abstract: Safe navigation of Micro Aerial Vehicles (MAVs) requires not only obstacle-free flight paths according to a static environment map, but also the perception of and reaction to previously unknown and dynamic objects. This implies that the onboard sensors cover the current flight direction. Due to the limited payload of MAVs, full sensor coverage of the environment has to be traded off with flight time. Thus, often only a part of the environment is covered. We present a combined allocentric complete planning and trajectory optimization approach taking these sensor visibility constraints into account. The optimized trajectories yield flight paths within the apex angle of a Velodyne Puck Lite 3D laser scanner enabling low-level collision avoidance to perceive obstacles in the flight direction. Furthermore, the optimized trajectories take the flight dynamics into account and contain the velocities and accelerations along the path. We evaluate our approach with a DJI Matrice 600 MAV and in simulation employing hardware-in-the-loop.


Title: Bayesian Optimization of Soft Exosuits Using a Metabolic Estimator Stopping Process
Key Words: Bayes methods  data acquisition  gradient methods  Kalman filters  legged locomotion  optimal control  parameter estimation  Kalman filter-based metabolic estimator  soft exosuits  metabolic estimator stopping process  human-in-the-loop optimization studies  wearable devices  improved average metabolic reduction  slow metabolic dynamics  Bayesian optimization  gradient descent optimization  Optimization  Bayes methods  Time measurement  Noise measurement  Estimation  Standards  Phase measurement 
Abstract: Recent human-in-the-loop (HIL) optimization studies using wearable devices have shown an improved average metabolic reduction by optimizing a small number of control parameters during short-duration walking experiments. However, the slow metabolic dynamics, high measurement noise, and experimental time constraints create challenges for increasing the number of control parameters to be optimized. Prior work applying gradient descent and Bayesian optimization to this problem have decoupled metabolic estimation and control parameter selection using fixed estimation intervals, which imposes a hard limit on the number of parameter evaluations possible in a given time budget. In this work, we take a different approach that couples estimation and parameter selection, allowing the algorithm to spend less time on refining the metabolic estimates for parameters that are unlikely to improve performance over the best observed values. Our approach uses a Kalman filter-based metabolic estimator to formulate an optimal stopping problem during the data acquisition step of standard Bayesian optimization. Performance was analyzed in numerical simulations and in pilot human subject testing with two subjects that involved optimizing six control parameters of a single-joint exosuit and four parameters of a multi-joint exosuit.


Title: Flappy Hummingbird: An Open Source Dynamic Simulation of Flapping Wing Robots and Animals
Key Words: aerodynamics  aerospace components  aerospace robotics  aircraft control  autonomous aerial vehicles  closed loop systems  control system synthesis  learning (artificial intelligence)  microrobots  mobile robots  motion control  nonlinear control systems  robot dynamics  robot kinematics  stability  vehicle dynamics  flappy hummingbird  open source dynamic simulation  flapping Wing robots  hummingbirds  extraordinary flight performance  stable hovering maneuvering  aggressive maneuvering  conventional small scale man-made vehicles  FWMAVs  performance gap  open source high fidelity dynamic simulation  optimization  flight control  at-scale hummingbird robot  system identification  dynamic response  open-loop  loop systems  simulated flights  experimental flights  highly nonlinear flight dynamics  control problems  control algorithms  linear controller  control policy  simulation-to-real transfer  physical robot  flapping wing microair vehicles  Aerodynamics  Robots  Vehicle dynamics  Force  Torque  Animals 
Abstract: Insects and hummingbirds exhibit extraordinary flight performance and can simultaneously master seemingly conflicting goals: stable hovering and aggressive maneuvering, which are unmatched by conventional small scale man-made vehicles. Flapping Wing Micro Air Vehicles (FWMAVs) hold great promise for closing this performance gap. However, design and control of such systems remain challenging. Here, we present an open source high fidelity dynamic simulation for FWMAVs. The simulator serves as a testbed for the design, optimization and flight control of FWMAVs. To validate the simulation, we recreated the at-scale hummingbird robot developed in our lab in the simulation. System identification was performed to obtain the model parameters. Force generation and dynamic response of open-loop and closed loop systems between simulated and experimental flights were compared. The unsteady aerodynamics and the highly nonlinear flight dynamics present challenging control problems for conventional and learning control algorithms such as Reinforcement Learning. The interface of the simulation is fully compatible with OpenAI Gym environment. As a benchmark study, we present a linear controller for hovering stabilization and a Deep Reinforcement Learning control policy for goal-directed maneuvering. Finally, we demonstrate direct simulation-to-real transfer of both control policies onto the physical robot, further demonstrating the fidelity of the simulation.


Title: Visual Repetition Sampling for Robot Manipulation Planning
Key Words: collision avoidance  Gaussian processes  image sampling  learning (artificial intelligence)  manipulators  mobile robots  robot vision  trees (mathematics)  Gaussian mixture models  rapidly-exploring random tree  biased sampling methods  real-time applications  longer planning times  optimization-based methods  complex environments  sampling-based motion planners  robot manipulation  visual repetition sampling  RRT motion planner  sampling efficiency  visual input  GMM  Planning  Databases  Task analysis  Visualization  Robots  Probability distribution  Feature extraction 
Abstract: One of the main challenges in sampling-based motion planners is to find an efficient sampling strategy. While methods such as Rapidly-exploring Random Tree (RRT) have shown to be more reliable in complex environments than optimization-based methods, they often require longer planning times, which reduces their usability for real-time applications. Recently, biased sampling methods have shown to remedy this issue. For example Gaussian Mixture Models (GMMs) have been used to sample more efficiently in feasible regions of the configuration space. Once the GMM is learned, however, this approach does not adapt its biases to individual planning scene during inference. Hence, we propose in this work a more efficient sampling strategy to further bias the GMM based on visual input upon query. We employ an autoencoder trained entirely in simulation to extract features from depth images and use the latent representation to adjust the weights of each mixture components in the GMM. We show empirically that this improves the sampling efficiency of an RRT motion planner in both real and simulated scenes.


Title: Contact-Driven Posture Behavior for Safe and Interactive Robot Operation
Key Words: collision avoidance  mobile robots  uncertain environments  unexpected contact  safe robot behavior  contact-driven approach  safe robot operation  interactive robot operation  unforeseen contact events  robot tasks  robot model  freedom robot arm  safe contact behavior  robot posture requirements  contact-driven posture behavior  Task analysis  Collision avoidance  Robot sensing systems  Aerospace electronics  Robot kinematics  Jacobian matrices 
Abstract: When performing tasks in uncertain environments and around humans, robots are likely to collide unexpectedly with people or objects. In order to ensure safety, most approaches rely on collision avoidance and try to prevent any contact from happening, which may result in unnecessary interruption of a task that would be feasible in spite of the obstacle. On the one hand, when an unexpected contact occurs, a safe robot behavior is required. On the other hand, it might be interesting to exploit the contact instead of moving away from it. In this paper, we present a contact-driven approach for safe and interactive robot operation to react to unforeseen contact events. This approach offers the possibility to control the contact while minimizing its effects on the robot tasks. It relies exclusively on the robot model and proprioceptive sensors. It is tested in simulation and hardware experiments on a 7 degrees of freedom robot arm and shows a safe contact behavior that does not interfere with the task, and as little as possible with the robot posture requirements.


Title: RCM-SLAM: Visual localisation and mapping under remote centre of motion constraints
Key Words: cameras  image motion analysis  image reconstruction  medical robotics  mobile robots  pose estimation  robot vision  SLAM (robots)  surgery  laparoscopic camera motion  RCM constraints  minimal solver  absolute camera  2D-3D point correspondences  bundle adjustment optimiser  RCM-constrained parameterisation  relative pose estimation  SLAM pipeline suitable  robotic surgery  RCM position  robotic prostatectomy show  RCM-SLAM  visual localisation  remote centre  motion constraints  insertion ports  Simultaneous Localisation and Mapping  mapping approach  RCM-PnP  Cameras  Robot vision systems  Simultaneous localization and mapping  Laparoscopes  Three-dimensional displays  Robot kinematics 
Abstract: In robotic surgery the motion of instruments and the laparoscopic camera is constrained by their insertion ports, i. e. a remote centre of motion (RCM). We propose a Simultaneous Localisation and Mapping (SLAM) approach that estimates laparoscopic camera motion under RCM constraints. To achieve this we derive a minimal solver for the absolute camera pose given two 2D-3D point correspondences (RCM-PnP) and also a bundle adjustment optimiser that refines camera poses within an RCM-constrained parameterisation. These two methods are used together with previous work on relative pose estimation under RCM [1] to assemble a SLAM pipeline suitable for robotic surgery. Our simulations show that RCM-PnP outperforms conventional PnP for a wide noise range in the RCM position. Results with video footage from a robotic prostatectomy show that RCM constraints significantly improve camera pose estimation.


Title: Comparing Physical and Simulated Performance of a Deterministic and a Bio-inspired Stochastic Foraging Strategy for Robot Swarms
Key Words: deterministic algorithms  multi-robot systems  stochastic processes  robot swarms  collective robot foraging  central-place foraging algorithm  CPFA  distributed deterministic spiral algorithm  DDSA  swarm robotic algorithms  bioinspired stochastic foraging strategy  resource-collection algorithms  Robot sensing systems  Collision avoidance  Spirals  Swarm robotics  Task analysis  Cameras 
Abstract: Designing resource-collection algorithms for relatively simple robots that are effective given the noise and uncertainty of the real world is a challenge in swarm robotics. This paper describes the performance of two algorithms for collective robot foraging: the stochastic central-place foraging algorithm (CPFA) and the distributed deterministic spiral algorithm (DDSA). With the CPFA, robots mimic the foraging behaviors of ants; they stochastically search for targets and share information to recruit other robots to locations where they detect multiple targets. With the DDSA, robots travel along pre-planned spiral paths; robots detect the nearest targets first and, in theory, guarantee eventual complete coverage of the arena with minimal overlap. We implemented both algorithms and compared their performance in a Gazebo simulation and in physical robots in a large outdoor arena. In a realistic Gazebo simulation, the DDSA outperforms the CPFA. However, in real-world experiments with obstacles, collisions, and errors, the movement patterns of robots implementing the DDSA become visually indistinguishable from the CPFA. The CPFA is less affected by noise and error, and it performs as well as, or better than, the DDSA. Physical experiments change our conclusion about which algorithm has the best performance, emphasizing the importance of systematically comparing the performance of swarm robotic algorithms in the real world.


Title: Trust Regions for Safe Sampling-Based Model Predictive Control
Key Words: nonlinear dynamical systems  predictive control  robust control  sampling methods  stochastic systems  trust regions  safe sampling-based model predictive control  nonlinear control systems  complex dynamics  nonlinear dynamics  sampling-based MPC scheme  sampling based estimation  safe constraint satisfaction  probabilistic information  Monte Carlo methods  Trajectory  Predictive control  Optimization  Safety  Optimal control 
Abstract: Guaranteeing safe constraint satisfaction in nonlinear control systems with uncertainty remains a major challenge for control. The most successful control method handling constraints under uncertainty has without doubt been model predictive control (MPC). In particular, recent sampling-based MPC methods have shown success in controlling stochastic systems with complex, nonlinear dynamics. The sampling-based schemes are appealing since they do not need strong assumptions on the underlying model, except that it can be forward simulated. At the same time, the lack of major assumptions on the models make the statement of safety or robustness guarantees difficult. However, the samples drawn during the control process inherently contain probabilistic information about these properties. In this paper, we formally describe the problem that results by adding chance constraints to a sampling-based MPC scheme. Furthermore, based on a variant of the Chernoff bound, we derive trust regions, in which the sampling based estimation of the safety constraint satisfies a specified quality. Finally, we present a case study in the navigation domain to demonstrate the applicability of the proposed approach.


Title: Improving the Performance of Auxiliary Null Space Tasks via Time Scaling-Based Relaxation of the Primary Task
Key Words: path planning  position control  redundant manipulators  auxiliary null space tasks  task achievement  null space task  multiple prioritized tasks  time scaling-based relaxation  primary task  kinematic redundancy  robot manipulators  safety criterion  optimization criterion  constraint relaxation  time scaling schemes  DLR lightweight robot  KUKA lightweight robot  Task analysis  Null space  Robot kinematics  Trajectory  Jacobian matrices  Optimization 
Abstract: Kinematic redundancy enhances the dexterity and flexibility of robot manipulators. By exploiting the redundant degrees of freedom, auxiliary null space tasks can be carried out in addition to the primary task. Such auxiliary tasks are often formulated in terms of a performance or safety criterion that shall be minimized. If the optimization criterion, however, is defined in global terms, then it is directly affected by the primary task. As a consequence, the task achievement of the auxiliary task may be unnecessarily detrimented by the main task. In addition to modifying the primary task via constraint relaxation, a possible solution for improving the performance of the auxiliary task is to relax the primary task temporarily via time scaling. This gives the null space task more time for achieving its objective. In this paper, we propose several such time scaling schemes and verify their performance for a DLR/KUKA Lightweight Robot with one redundant degree of freedom. Finally, we extend the concept to multiple prioritized tasks and provide a simulation example.


Title: Self-Modifying Morphology Experiments with DyRET: Dynamic Robot for Embodied Testing
Key Words: adaptive systems  legged locomotion  robot dynamics  self-reconfiguration  quadruped robots  DyRET  embodied testing  dynamic robot morphology  locomotion modes  self-reconfigurable morphology  servo supply voltage  four-legged robot  self-modifying morphology experiments  uncontrolled outdoor environments  Legged locomotion  Morphology  Servomotors  Computer architecture  Robot sensing systems  Switches 
Abstract: If robots are to become ubiquitous, they will need to be able to adapt to complex and dynamic environments. Robots that can adapt their bodies while deployed might be flexible and robust enough to meet this challenge. Previous work on dynamic robot morphology has focused on simulation, combining simple modules, or switching between locomotion modes. Here, we present an alternative approach: a self-reconfigurable morphology that allows a single four-legged robot to actively adapt the length of its legs to different environments. We report the design of our robot, as well as the results of a study that verifies the performance impact of self-reconfiguration. This study compares three different control and morphology pairs under different levels of servo supply voltage in the lab. We also performed preliminary tests in different uncontrolled outdoor environments to see if changes to the external environment supports our findings in the lab. Our results show better performance with an adaptable body, lending evidence to the value of self-reconfiguration for quadruped robots.


Title: Sensorless Force Control of Automated Grinding/Deburring Using an Adjustable force regulation mechanism
Key Words: deburring  end effectors  feedback  force control  force sensors  geometry  grinding  grinding machines  industrial robots  machine tool spindles  polishing  position control  prototypes  quality control  sensorless force control  controller feedback  constant contact force  force regulation mechanism  grinding spindle tool  industrial grinding-deburring operations  multiaxis force sensor  polishing quality  geometry  grinder prototype  compliant mechanism  end-effector  industrial robots  Frequency modulation  Force  Conferences  Automation  Indexes  Deburring  Force control  Automated deburring and polishing  force control  constant force  zero stiffness  compliant mechanism 
Abstract: Controlling the contact force on workpieces has been a challenging task for industrial grinding/deburring operations. Its realization often requires a grinding spindle with a multi-axis force sensor and controller feedback. The spindle needs to frequently vary its position in order to maintain a constant contact force. The use of sensors and control is costly and introduces extra complexity for grinding tools. To improve the polishing quality of handling workpieces of irregular contours, this paper presents a novel force regulation mechanism (FRM) to be installed on grinding tools. Without using additional sensors and control, the FRM can passively produce an adjusTable NORMAL Contact force between the tooltip and workpiece of various geometry. the spindle does not have to move to regulate the contact force. together with a simple grinder which is much less expensive, this approach offers a more attractive solution in terms of cost and complexity. in this paper, the design concept and simulation results are presented and discussed. a prototype of a grinder with the proposed FRM is illustrated to demonstrate the effectiveness and accuracy of force regulation. this novel mechanism is expected to serve as a reliable alternative for industrial grinding/deburring operation.


Title: Constrained Feedback Control by Prioritized Multi-objective Optimization
Key Words: closed loop systems  feedback  legged locomotion  motion control  optimisation  position control  control inputs  operational space inverse dynamics control  constrained prioritized multiobjective optimization-base control formulation  dynamic-model-free prioritized feedback control formulation  combined inverse dynamics impedance controller  planar anthropometric biped robot  stable locomotion  Task analysis  Dynamics  Impedance  Optimization  Feedback control  Robot kinematics 
Abstract: Prioritized multi-objective optimization has been widely used within the operational space inverse dynamics control framework. In this paper, we present a constrained prioritized multi-objective optimization-base control formulation that extends to impedance control, including the `simple' impedance controller, which does not require the dynamic model. The main contribution of this paper is the dynamic-model-free prioritized feedback control formulation which encompasses arbitrary number of priority levels and takes the saturation constraints on the control inputs rigorously into account. The utility of the proposed formulation is demonstrated by a combined inverse dynamics impedance controller used to simulate stable locomotion of a planar anthropometric biped robot.


Title: Exploitation of Environment Support Contacts for Manipulation Effort Reduction of a Robot Arm
Key Words: compliance control  control system synthesis  end effectors  force control  humanoid robots  manipulator dynamics  manipulator kinematics  mobile robots  motion control  optimal contact force control  support plane  contact control point  three-level hierarchical compliance controller  nonend-effector support contact  wrist level manipulation  upper arm  elbow joint  arm joints  loco-manipulation tasks  environment constraints  robot arm  manipulation effort reduction  environment support contacts  control scheme  interaction forces  impedance control  Task analysis  Robot kinematics  Manipulators  Optimization  Planning  Jacobian matrices 
Abstract: Humans commonly exploit interaction with the environment constraints to assist the execution of the loco-manipulation tasks they perform. One particular example is the exploration of contacts during manipulation to relax the loading of those arm joints that are not directly involved in the generation of the manipulation motions and forces, e.g. establishing a contact with the elbow joint to reduce the effort of the upper arm while executing wrist level manipulation. In this paper, we shall explore the possibility of actively (a) utilizing the environment for a non-end-effector support contact towards reducing the joints efforts during manipulation tasks. This is achieved by our proposed control scheme with a three-level hierarchical compliance controller. The highest priority task is assigned to an impedance control that regulates the interaction at the contact control point on the arm in the normal direction of the support plane prior to contact, and is switched to an optimal contact force control for minimizing the joint effort after the contact is built. The second priority task is an impedance control at the same point in the tangential directions of the plane to stabilize the contact. In the end, an impedance behavior at the end-effector is designed to deal with the interaction forces required by the manipulation tasks. The efficacy of the proposed control scheme was corroborated by simulations and experiments, where significant joint effort reduction was observed.


Title: Inferring Robot Morphology from Observation of Unscripted Movement
Key Words: image colour analysis  learning (artificial intelligence)  manipulator kinematics  mobile robots  motion control  multi-robot systems  recurrent neural nets  robot vision  low-cost RGB-D camera output  task sharing  shared communication protocol  centralized planner  shared action  kinematic model  large-scale data  RNN-based methods  unscripted movement observation  robots morphological structure  Robot sensing systems  Robot kinematics  Three-dimensional displays  Morphology  Task analysis  Manipulators 
Abstract: Task sharing between heterogeneous robots currently requires a priori capability knowledge, a shared communication protocol, or a centralized planner. However, in practice, when two robots are brought together, the effort required to construct shared action and structure models can be significant. In this paper, we describe our approach to determining the kinematic model of a robot based purely on observation of unscripted movement. We describe construction of large-scale data simulating low-cost RGB-D camera output, and application of two different RNN-based methods to the learning problem. Our results suggest that this is an efficient and effective way to determine a robot's morphological structure without requiring communication or pre-existing knowledge of its capabilities.


Title: Online Vehicle Trajectory Prediction using Policy Anticipation Network and optimization-based Context Reasoning
Key Words: inference mechanisms  optimisation  regression analysis  road traffic control  traffic engineering computing  ubiquitous computing  online vehicle trajectory prediction  two-level vehicle trajectory prediction framework  urban autonomous driving  complex contextual factors  traffic regulations  moving agents  high-level policy anticipation  low-level context reasoning  short-term memory network  sequential history observations  low-level optimization-based context reasoning process  optimization-based reasoning process  two-level reasoning process  continuous trajectory  regression-based trajectory prediction methods  vehicle motions  Trajectory  Cognition  Optimization  Hidden Markov models  Predictive models  Geometry  Adaptation models 
Abstract: In this paper, we present an online two-level vehicle trajectory prediction framework for urban autonomous driving where there are complex contextual factors, such as lane geometries, road constructions, traffic regulations and moving agents. Our method combines high-level policy anticipation with low-level context reasoning. We leverage a long short-term memory (LSTM) network to anticipate the vehicle's driving policy (e.g., forward, yield, turn left, turn right, etc.) using its sequential history observations. The policy is then used to guide a low-level optimization-based context reasoning process. We show that it is essential to incorporate the prior policy anticipation due to the multimodal nature of the future trajectory. Moreover, contrary to existing regression-based trajectory prediction methods, our optimization-based reasoning process can cope with complex contextual factors. The final output of the two-level reasoning process is a continuous trajectory that automatically adapts to different traffic configurations and accurately predicts future vehicle motions. The performance of the proposed framework is analyzed and validated in an emerging autonomous driving simulation platform (CARLA).


Title: Improving collective decision accuracy via time-varying cross-inhibition
Key Words: decision making  multi-robot systems  stochastic processes  time-varying cross-inhibition  decentralised decision-making  robot swarm  diffusive search  decentralised algorithm  house-hunting honeybees  single decentralised parameter  balance exploration  swarm robotics simulations  collective decision accuracy  Robot sensing systems  Robot kinematics  Noise measurement  Task analysis  Swarm robotics  Analytical models 
Abstract: We investigate decentralised decision-making, in which a robot swarm is tasked with selecting the best-quality option among a set of alternatives. Individual robots are simplistic as they only perform diffusive search, make local noisy estimates of the options' quality, and exchange information with near neighbours. We propose a decentralised algorithm, inspired by house-hunting honeybees, to efficiently aggregate noisy estimations. Individual robots, by varying over time a single decentralised parameter that modulates the interaction strength, balance exploration and agreement. In this way, the swarm first identifies the options under consideration, then rapidly converges on the best available option, even when outnumbered by lower quality options. We present stochastic analyses and swarm robotics simulations to compare the novel strategy with previous methods and to quantify the performance improvement. The proposed strategy limits the spreading of errors within the population and allows swarms of simple noisy units with minimal communication capabilities to make highly accurate collective decisions in predictable time.


Title: Spatial Coverage Without Computation
Key Words: mobile robots  multi-robot systems  navigation  path planning  random processes  robot redundancy  optimized random walk  performance improvements  sub-millimeter-sized robots  spatial coverage  anonymous robots  mobile robots  two-dimensional space  extremely simple robots  run-time computation  computer simulations  deterministic controller  off-line optimization  physical e-puck robots  Robot kinematics  Robot sensing systems  Mobile robots  Wheels  Area measurement 
Abstract: We study the problem of controlling a swarm of anonymous, mobile robots to cooperatively cover an unknown two-dimensional space. The novelty of our proposed solution is that it is applicable to extremely simple robots that lack run-time computation or storage. The solution requires only a single bit of information per robot-whether or not another robot is present in its line of sight. Computer simulations show that our deterministic controller, which was obtained through off-line optimization, achieves around 71-76% coverage in a test scenario with no robot redundancy, which corresponds to a 26-39% reduction of the area that is not covered, when compared to an optimized random walk. A moderately lower level of performance was observed in 20 experimental trials with 25 physical e-puck robots. Moreover, we demonstrate that the same controller can be used in environments of different dimensions and even to navigate a maze. The controller provides a baseline against which one can quantify the performance improvements that more advanced and expensive techniques may offer. Moreover, due to its simplicity, it could potentially be implemented on swarms of sub-millimeter-sized robots. This would pave the way for new applications in micro-medicine.


Title: RoboCSE: Robot Common Sense Embedding
Key Words: belief networks  embedded systems  home automation  mobile robots  service robots  statistical analysis  RoboCSE  robot common sense embedding  autonomous service robots  semantic knowledge  AI2Thor  statistical significant  home environment simulator  Word2Vec  Bayesian logic network  MatterPort3D  Semantics  Training  Robot sensing systems  Cognition  Computational modeling  Training data 
Abstract: Autonomous service robots require computational frameworks that allow them to generalize knowledge to new situations in a manner that models uncertainty while scaling to real-world problem sizes. The Robot Common Sense Embedding (RoboCSE) showcases a class of computational frameworks, multi-relational embeddings, that have not been leveraged in robotics to model semantic knowledge. We validate RoboCSE on a realistic home environment simulator (AI2Thor) to measure how well it generalizes learned knowledge about object affordances, locations, and materials. Our experiments show that RoboCSE can perform prediction better than a baseline that uses pre-trained embeddings, such as Word2Vec, achieving statistically significant improvements while using orders of magnitude less memory than our Bayesian Logic Network baseline. In addition, we show that predictions made by RoboCSE are robust to significant reductions in data available for training as well as domain transfer to MatterPort3D, achieving statistically significant improvements over a baseline that memorizes training data.


Title: Steering a Multi-armed Robotic Sheath Using Eccentric Precurved Tubes
Key Words: dexterous manipulators  elasticity  medical robotics  neurophysiology  pipes  robot kinematics  surgery  kinematic model  multiarmed robotic sheath  eccentric precurved tubes  single-port minimally invasive procedures  multiple robotic arms  precurved superelastic tubes  Cosserat rod theory  two-arm sheath  concentric tube balanced pair  neuroendoscopy  elastic backbone  push-pull tendons  continuum robot sheath  Electron tubes  Force  Kinematics  Shape  Endoscopes  Manipulators  Steerable sheath  Multiple arms  Concentric tube robots 
Abstract: This paper presents a novel continuum robot sheath for use in single-port minimally invasive procedures such as neuroendoscopy in which the sheath is designed to deliver multiple robotic arms. Articulation of the sheath is achieved by using precurved superelastic tubes lining the working channels used for arm delivery. These tubes perform a similar role to push/pull tendons, but can accomplish shape change of the sheath via rotation as well as translation. A kinematic model using Cosserat rod theory is derived which is based on modeling the system as a set of eccentrically aligned precurved tubes constrained along their length by an elastic backbone. The specific case of a two-arm sheath is considered in detail and its relationship to a concentric tube balanced pair is described. Simulation and experiment are used to investigate the concept, map its workspace and to evaluate the kinematic model.


Title: Dynamics Consensus between Centroidal and Whole-Body Models for Locomotion of Legged Robots
Key Words: humanoid robots  legged locomotion  manipulator dynamics  motion control  optimal control  optimisation  pendulums  whole-body level  whole-body optimal control problem  centroidal dynamics  manipulator dynamics  effective locomotion  HRP-2 robot  dynamics consensus  legged robots  large control problem  complex optimal control problem  numerical solver  inverted pendulum  capture points  whole-body constraints  reduced level  reduced solution  centroidal state dynamics  mathematical framework  Dynamics  Legged locomotion  Trajectory  Optimization  Convex functions  Optimal control 
Abstract: It is nowadays well-established that locomotion can be written as a large and complex optimal control problem. Yet, current knowledge in numerical solver fails to directly solve it. A common approach is to cut the dimensionality by relying on reduced models (inverted pendulum, capture points, centroidal). However it is difficult both to account for whole-body constraints at the reduced level and also to define what is an acceptable trade-off at the whole-body level between tracking the reduced solution or searching for a new one. The main contribution of this paper is to introduce a rigorous mathematical framework based on the Alternating Direction Method of Multipliers, to enforce the consensus between the centroidal state dynamics at reduced and whole-body level. We propose an exact splitting of the whole-body optimal control problem between the centroidal dynamics (under-actuation) and the manipulator dynamics (full actuation), corresponding to a re-arrangement of the equations already stated in previous works. We then describe with details how alternating descent is a good solution to implement an effective locomotion solver. We validate this approach in simulation with walking experiments on the HRP-2 robot.


Title: Mitigating energy loss in a robot hopping on a physically emulated dissipative substrate
Key Words: damping  energy conservation  legged locomotion  motion control  position control  sand  mitigating energy loss  physically emulated dissipative substrate  erosion  desertification  spatial resolution  temporal resolution  data collection  attractive scout robot candidate  heavily geared sensor-laden RHex  long-distance locomotion  virtual damping force  Minitaur foot  simulated granular media  bulk-behavior force law  ground emulator  single-legged hopper  physical hopping experiments  substrate emulator  linear stiffness  quadratic damping  Minitaur robot  ground properties  bulk-behavior model  energy savings  robot hopping  physical single-legged hopper jumping  Legged locomotion  Springs  Damping  Media  Foot  Force 
Abstract: We work with geoscientists studying erosion and desertification to improve the spatial and temporal resolution of their data collection over long transects in difficult realworld environments such as deserts [1]. The Minitaur [2] robot, which can run quickly over uneven terrain and use a single leg to measure relevant ground properties such as stiffness [3], is an attractive scout robot candidate for inclusion in a heterogeneous team in collaboration with a heavily geared, sensor-laden RHex [4]. However, Minitaur is challenged by long-distance locomotion on sand dunes. Previous simulation results [5] suggested that the energetic cost of transport can be mitigated by programming a virtual damping force to slow the intrusion of a Minitaur foot into simulated granular media following a bulk-behavior force law [6]. In this paper, we present a ground emulator that can be used to test such locomotion hypotheses with a physical single-legged hopper jumping on emulated ground programmed to exhibit any compliance and damping characteristics of interest. The new emulator allows us to corroborate the conclusions of our previous simulation with physical hopping experiments. Programming the substrate emulator to exhibit the mechanics of a simplified bulk-behavior model of granular media characterized by linear stiffness and quadratic damping, we achieve a consistent energy savings of 20% in comparison with a nominal controller, with savings of up to 50% under specific conditions.


Title: Energy Efficient Navigation for Running Legged Robots
Key Words: energy conservation  energy consumption  legged locomotion  motion control  optimisation  path planning  robot dynamics  sampling methods  search problems  trajectory control  mobile robots  energy savings  energy consumption  energy efficient navigation  running legged robots  sampling-based model predictive optimization  LLAMA quadrupedal platform  heuristic-based search  robot dynamics  robot motion plan  trajectory planning  Legged locomotion  Trajectory  Computational modeling  Predictive models  Planning  Heuristic algorithms 
Abstract: Energy-efficient navigation is an important technology for mobile robots because of its potential to increase the operation time of the robot. In particular, when coupled with a dynamic legged quadruped, the need for energy savings is made more apparent as payloads are limited. Due to the complexity in modeling motion and power models of these robots, a new approach is necessary to effectively motion plan for these complex robots. We accomplish this by using Sampling-Based Model Predictive optimization (SBMPO) which was extended for use on the LLAMA quadrupedal platform in simulation. SBMPO allows for direct generation of trajectories while using a heuristic-based search to speed up computations. This approach is shown to effectively motion plan while optimizing for energy consumption and maintaining the natural dynamics of the robot in a simulated environment.


Title: Online Continuous Mapping using Gaussian Process Implicit Surfaces
Key Words: approximation theory  Gaussian processes  mobile robots  path planning  regression analysis  implicit surface  SDF  regressor  gaussian process implicit surface  robotic tasks  signed-distance function  sparse measurements  grid-based methods  online continuous mapping  Surface treatment  Planning  Noise measurement  Training  Robot kinematics  Robot sensing systems 
Abstract: The representation of the environment strongly affects how robots can move and interact with it. This paper presents an online approach for continuous mapping using Gaussian Process Implicit Surfaces (GPISs). Compared with grid-based methods, GPIS better utilizes sparse measurements to represent the world seamlessly. It provides direct access to the signed-distance function (SDF) and its derivatives which are invaluable for other robotic tasks and it incorporates uncertainty in the sensor measurements. Our approach incrementally and efficiently updates GPIS by employing a regressor on observations and a spatial tree structure. The effectiveness of the suggested approach is demonstrated using simulations and real world 2D/3D data.


Title: Prospection: Interpretable plans from language by predicting the future
Key Words: control engineering computing  learning (artificial intelligence)  natural language processing  robot programming  high-level human instructions  natural-language command  crowd-sourcing  plan fidelity  representations learning  robot agent  Task analysis  Robots  Training  Natural languages  Visualization  Planning  Predictive models 
Abstract: High-level human instructions often correspond to behaviors with multiple implicit steps. In order for robots to be useful in the real world, they must be able to to reason over both motions and intermediate goals implied by human instructions. In this work, we propose a framework for learning representations that convert from a natural-language command to a sequence of intermediate goals for execution on a robot. A key feature of this framework is prospection, training an agent not just to correctly execute the prescribed command, but to predict a horizon of consequences of an action before taking it. We demonstrate the fidelity of plans generated by our framework when interpreting real, crowd-sourced natural language commands for a robot in simulated scenes.


Title: Efficient Generation of Motion Plans from Attribute-Based Natural Language Instructions Using Dynamic Constraint Mapping
Key Words: graph theory  human-robot interaction  learning (artificial intelligence)  mobile robots  motion control  natural language processing  optimisation  path planning  robot programming  dynamic constraint mapping  robot motion planning  dynamic grounding graph  7-DOF Fetch robot  factor graph  optimization-based motion planning  parametric constraints  attribute-based natural language instructions  motion plans  Robots  Grounding  Natural languages  Cost function  Planning  Dynamics  Heuristic algorithms 
Abstract: We present an algorithm for combining natural language processing (NLP) and fast robot motion planning to automatically generate robot movements. Our formulation uses a novel concept called Dynamic Constraint Mapping to transform complex, attribute-based natural language instructions into appropriate cost functions and parametric constraints for optimization-based motion planning. We generate a factor graph from natural language instructions called the Dynamic Grounding Graph (DGG), which takes latent parameters into account. The coefficients of this factor graph are learned based on conditional random fields (CRFs) and are used to dynamically generate the constraints for motion planning. We map the cost function directly to the motion parameters of the planner and compute smooth trajectories in dynamic scenes. We highlight the performance of our approach in a simulated environment and via a human interacting with a 7-DOF Fetch robot using intricate language commands including negation, orientation specification, and distance constraints.


Title: Safe and Fast Path Planning in Cluttered Environment using Contiguous Free-space Partitioning
Key Words: convex programming  graph theory  mobile robots  path planning  random processes  cluttered environment  contiguous free-space partitioning  convex optimization  convex navigable free-spaces  contiguous convex free-spaces  random-walk based seed generation method  contiguous navigable geometry  graph search problem  multiple query planning algorithm  fast path planning  undirected graph  safe path planning  Path planning  Planning  Ellipsoids  Robots  Data structures  Iris 
Abstract: The paper proposes a path planning algorithm for cluttered environment and maze. The proposed planning algorithm exploits the merit of convex optimization while forming the convex navigable free-spaces, ensuring safety of the vehicle. The contiguous convex free-spaces are iteratively computed from a random-walk based seed generation method to create a contiguous navigable geometry. Inside this contiguous navigable geometry an undirected graph is then created, whose each node and edge belong to at least one convex region which boils down the path planning problem into a graph search problem. In addition, the proposed multiple query planning algorithm can merge the user provided feasible initial and goal configuration with the existing undirected graph in each plan, without deteriorating the planning performance in terms of run-time and path length. Simulation and experimental results confirm the superiority of the proposed planning algorithm jointly in terms of both path length and run-time by a significant margin.


Title: Learning from Extrapolated Corrections
Key Words: control engineering computing  extrapolation  function approximation  learning (artificial intelligence)  robot programming  extrapolated corrections  cost functions  user guidance  extrapolation problem  online function approximation  function space  nonEuclidean norms  robot learning  Trajectory  Cost function  Robot kinematics  Function approximation  Kernel  Estimation 
Abstract: Our goal is to enable robots to learn cost functions from user guidance. Often it is difficult or impossible for users to provide full demonstrations, so corrections have emerged as an easier guidance channel. However, when robots learn cost functions from corrections rather than demonstrations, they have to extrapolate a small amount of information - the change of a waypoint along the way - to the rest of the trajectory. We cast this extrapolation problem as online function approximation, which exposes different ways in which the robot can interpret what trajectory the person intended, depending on the function space used for the approximation. Our simulation results and user study suggest that using function spaces with non-Euclidean norms can better capture what users intend, particularly if environments are uncluttered. This, in turn, can lead to the robot learning a more accurate cost function and improves the user's subjective perceptions of the robot.


Title: Continuous Value Iteration (CVI) Reinforcement Learning and Imaginary Experience Replay (IER) For Learning Multi-Goal, Continuous Action and State Space Controllers
Key Words: iterative methods  learning (artificial intelligence)  optimal control  state-space methods  continuous action  state space controllers  goal space  optimal value functions  nonparametric estimators  multiple arbitrary goals  real-world voltage controlled robot  nonobservable Cartesian task space  multigoal  model-free reinforcement learning algorithm  Aerospace electronics  Robot kinematics  Task analysis  Trajectory  Mathematical model  Voltage control 
Abstract: This paper presents a novel model-free Reinforcement Learning algorithm for learning behavior in continuous action, state, and goal spaces. The algorithm approximates optimal value functions using non-parametric estimators. It is able to efficiently learn to reach multiple arbitrary goals in deterministic and nondeterministic environments. To improve generalization in the goal space, we propose a novel sample augmentation technique. Using these methods, robots learn faster and overall better controllers. We benchmark the proposed algorithms using simulation and a real-world voltage controlled robot that learns to maneuver in a non-observable Cartesian task space.


Title: iX-BSP: Belief Space Planning through Incremental Expectation
Key Words: computational complexity  mobile robots  path planning  statistical analysis  robotics replanning  statistical simulation  incremental expectation calculations  planning session  computational complexity  belief space planning  iX-BSP  Planning  Current measurement  Robots  Uncertainty  History  Time measurement  Linear programming 
Abstract: Belief space planning (BSP) is a fundamental problem in robotics. Determining an optimal action quickly grows intractable as it involves calculating the expected accumulated cost (reward), where the expectation accounts for all future measurement realizations. State of the art approaches therefore resort to simplifying assumptions and approximations to reduce computational complexity. Importantly, while in robotics re-planning is essential, these approaches calculate each planning session from scratch. In this work we contribute a novel approach, iX-BSP, that is based on the key insight that calculations in consecutive planning sessions are similar in nature and can be thus re-used. Our approach performs incremental calculation of the expectation by appropriately re-using computations already performed in a precursory planing session while accounting for the information obtained in inference between the two planning sessions. The formulation of our approach considers general distributions and accounts for data association aspects. We evaluate iX-BSP in statistical simulation and show that incremental expectation calculations significantly reduce runtime without impacting performance.


Title: Multi-Object Search using Object-Oriented POMDPs
Key Words: Markov processes  mobile robots  Monte Carlo methods  path planning  object-oriented POMDPs  OO-POMDP  observable Markov decision process  object-oriented partially observable Monte-Carlo planning  multiobject search task  sequential decision making  mobile robot  Task analysis  Uncertainty  Search problems  Robot sensing systems  Planning  Object oriented modeling 
Abstract: A core capability of robots is to reason about multiple objects under uncertainty. Partially Observable Markov Decision Processes (POMDPs) provide a means of reasoning under uncertainty for sequential decision making, but are computationally intractable in large domains. In this paper, we propose Object-Oriented POMDPs (OO-POMDPs), which represent the state and observation spaces in terms of classes and objects. The structure afforded by OO-POMDPs support a factorization of the agent's belief into independent object distributions, which enables the size of the belief to scale linearly versus exponentially in the number of objects. We formulate a novel Multi-Object Search (MOS) task as an OO-POMDP for mobile robotics domains in which the agent must find the locations of multiple objects. Our solution exploits the structure of OO-POMDPs by featuring human language to selectively update the belief at task onset. Using this structure, we develop a new algorithm for efficiently solving OO-POMDPs: Object-Oriented Partially Observable Monte-Carlo Planning (OOPOMCP). We show that OO-POMCP with grounded language commands is sufficient for solving challenging MOS tasks both in simulation and on a physical mobile robot.


Title: Depth Generation Network: Estimating Real World Depth from Stereo and Depth Images*
Key Words: image colour analysis  learning (artificial intelligence)  stereo image processing  Depth Generation Network  real world Depth  dense depth estimation  deep-learning technique  stereo RGB images  stereo pairs  depth ground-truth  stereo setting parameters  image pairs  supervision learning  synthetic depth maps  relative dense depth  stereo geometric settings  optic settings  epipolar geometric cues  DGN  falling things dataset  variational method  Training  Estimation  Three-dimensional displays  Data models  Fats  Cameras  Robots 
Abstract: In this work, we propose the Depth Generation Network (DGN) to address the problem of dense depth estimation by exploiting the variational method and the deep-learning technique. In particular, we focus on improving the feasibility of depth estimation under complex scenarios given stereo RGB images, where the stereo pairs and/or depth ground-truth captured by real sensors may be deteriorated; the stereo setting parameters may be unavailable or unreliable, hence hamper efforts to establish the correspondence between image pairs via supervision learning or epipolar geometric cues. Instead of relying on real data, we supervise the training of our model using synthetic depth maps generated by the simulator, which deliver complex scenes and reliable data with ease. Two non-trivial challenges, i.e., (i) attaining reasonable amount yet realistic samples for training, and (ii) developing a model that adapts to both synthetic and real scenes arise, whereas in this work we mainly deal with the later one yet leveraging state-of-the-art Falling Things (FAT) dataset to overcome the first. Experiments on FAT and KITTI datasets demonstrate that our model estimates relative dense depth in fine details, potentially generalizable to real scenes without knowing the stereo geometric and optic settings.


Title: Domain Randomization for Active Pose Estimation
Key Words: image sequences  image texture  neural nets  pose estimation  domain randomization  active pose estimation  robotic control  robotic manipulation tasks  robot trains  domain-randomized simulation  Pose estimation  Cameras  Predictive models  Three-dimensional displays  Robot vision systems  Task analysis 
Abstract: Accurate state estimation is a fundamental component of robotic control. In robotic manipulation tasks, as is our focus in this work, state estimation is essential for identifying the positions of objects in the scene, forming the basis of the manipulation plan. However, pose estimation typically requires expensive 3D cameras or additional instrumentation such as fiducial markers to perform accurately. Recently, Tobin et al. introduced an approach to pose estimation based on domain randomization, where a neural network is trained to predict pose directly from a 2D image of the scene. The network is trained on computer generated images with a high variation in textures and lighting, thereby generalizing to real world images. In this work, we investigate how to improve the accuracy of domain randomization based pose estimation. Our main idea is that active perception - moving the robot to get a better estimate of pose- can be trained in simulation and transferred to real using domain randomization. In our approach, the robot trains in a domain-randomized simulation how to estimate pose from a sequence of images. We show that our approach can significantly improve the accuracy of standard pose estimation in several scenarios: when the robot holding an object moves, when reference objects are moved in the scene, or when the camera is moved around the object.


Title: Factored Contextual Policy Search with Bayesian optimization
Key Words: learning (artificial intelligence)  robots  search problems  truly complex tasks  locally learned policies  data-efficient learning  parametric context space  contextual policy representation  target contexts  task objectives  target position  environment contexts  contextual policy search algorithms  Bayesian optimization approach  active learning settings  faster learning  factored contextual policy search  scarce data  task contexts  Task analysis  Trajectory  Optimization  Bayes methods  Robot kinematics  Entropy 
Abstract: Scarce data is a major challenge to scaling robot learning to truly complex tasks, as we need to generalize locally learned policies over different task contexts. Contextual policy search offers data-efficient learning and generalization by explicitly conditioning the policy on a parametric context space. In this paper, we further structure the contextual policy representation. We propose to factor contexts into two components: target contexts that describe the task objectives, e.g. target position for throwing a ball; and environment contexts that characterize the environment, e.g. initial position or mass of the ball. Our key observation is that experience can be directly generalized over target contexts. We show that this can be easily exploited in contextual policy search algorithms. In particular, we apply factorization to a Bayesian optimization approach to contextual policy search both in sampling-based and active learning settings. Our simulation results show faster learning and better generalization in various robotic domains. See our supplementary video: https://youtu.be/IIJTbBAOufDY.


Title: Probabilistic Active Filtering for Object Search in Clutter
Key Words: Gaussian processes  graph theory  grippers  image filtering  learning (artificial intelligence)  probability  robot vision  search problems  complex state-action space  Gaussian process active filtering strategy  object search  state dynamics  object search problem  large-scale model  heavy occlusions  clutter  probabilistic active filtering  Search problems  Training  Robots  Task analysis  Probabilistic logic  Clutter  Uncertainty 
Abstract: This paper proposes a probabilistic approach for object search in clutter. Due to heavy occlusions, it is vital for an agent to be able to gradually reduce uncertainty in observations of the objects in its workspace by systematically rearranging them. Probabilistic methodologies present a promising sample-efficient alternative to handle the massively complex state-action space that inherently comes with this problem, avoiding the need for both exhaustive training samples and the accompanying heuristics for traversing a large-scale model during runtime. We approach the object search problem by extending a Gaussian Process active filtering strategy with an additional model for capturing state dynamics as the objects are moved over the course of the activity. This allows viable models to be built upon relatively scarce training data, while the complexity of the action space is also reduced by shifting objects over relatively short distances. Validation in both simulation and with a real Baxter robot with a limited number of training samples demonstrates the efficacy of the proposed approach.


Title: Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data
Key Words: CAD  convolutional neural nets  image coding  image colour analysis  image enhancement  image resolution  image segmentation  learning (artificial intelligence)  masks  object tracking  category-agnostic instance segmentation  hand-labeled data  object tracking  automated dataset generation  network training  computer vision research  RGB imaging  synthetic depth data sensors  unknown object segmentation  SD mask R-CNN  high-resolution synthetic depth imaging  synthetic depth mask R-CNN  unknown 3D object segmentation  3D CAD models  domain randomization  point cloud clustering baselines  COCO benchmarks  hand-labeled RGB datasets  instance-specific grasping pipeline  synthetic training dataset  Image segmentation  Training  Solid modeling  Three-dimensional displays  Robots  Cameras  Grasping 
Abstract: The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.


Title: Dynamic friction model with thermal and load dependency: modeling, compensation, and external force estimation
Key Words: drives  gears  sliding friction  slip  dynamic friction model  external force estimation  static friction model  gross sliding regime  Lund Grenoble  dynamic simulation  external torque estimation  generalized-Maxwell-slip  harmonic drive CSD 25 gear  test-bed  friction compensation  thermal-load dependency  nonlinear temperature dependency  nonlinear velocity dependency  Friction  Load modeling  Torque  Mathematical model  Temperature dependence  Estimation  Robots 
Abstract: A physically-motivated friction model with a parametric description of the nonlinear dependency of the temperature and velocity as well as the dependency on external load is presented. The fully parametric approach extends a static friction model in the gross sliding regime. We show how it can be seamlessly integrated in standard dynamic friction models such as Lund Grenoble (LuGre) and Generalized-Maxwell-Slip (GMS). Parameters of a Harmonic Drive CSD 25 gear are experimentally identified and the final model is evaluated on a dedicated test-bed. We show the integration and effectiveness in dynamic simulation, friction compensation, and external torque estimation.


Title: Azimuthal Shear Deformation of a Novel Soft Fiber-reinforced Rotary Pneumatic Actuator
Key Words: bending  displacement measurement  elasticity  electroactive polymer actuators  finite element analysis  force measurement  pneumatic actuators  shear deformation  torsion  fiber pattern lead  azimuthal deformation  anisotropically distributed fiber element  hyper elastic material  azimuthal shear deformation  soft materials  elastic inflatable actuators  soft fiber-reinforced rotary pneumatic actuator  structure design  fabrication process  FEM simulation  rotation angles  Actuators  Strain  Windings  Prototypes  Limiting  Fabrication  Shafts 
Abstract: The Elastic Inflatable Actuators (EIAs) has several advantages such as the inherent compliance due to the body comprised of a soft materials such as silicone. Among them, the soft fiber reinforced actuator is based on the principle that the expansion of enclosure and constraint of fiber pattern lead to a desired operation. While lots of researches on the actuator has been attributed to linear and bending motions, however, there are only few researches on rotary, or torsional, motions. In this paper, we propose a new actuator that causes azimuthal deformation due to restriction of anisotropically distributed fiber element along the radial direction and expansion of the hyper elastic material. Structure design of the actuator and a fabrication process of the actuator are presented. Subsequently, FEM simulation and experiment are executed to measure rotation angles of the actuators corresponding to the applied pressure.


Title: Realizing Learned Quadruped Locomotion Behaviors through Kinematic Motion Primitives
Key Words: control engineering computing  gradient methods  learning (artificial intelligence)  legged locomotion  motion control  principal component analysis  robot kinematics  robot programming  quadruped locomotion behavior learning  single gait learning  Stoch  policy gradient  PCA  quadrupedal walking  walking gaits  robust locomotion behaviors  D-RL  deep reinforcement learning  kMPs  kinematic motion primitives  Legged locomotion  Trajectory  Computational modeling  Kinematics  Optimization  Training 
Abstract: Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the “Stoch”. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then analyze the resulting walking by using principal component analysis. We observe that the kMPs extracted from PCA followed a similar pattern irrespective of the type of gaits generated. Leveraging on this underlying structure, we then realize walking in Stoch by a straightforward reconstruction of joint trajectories from kMPs. This type of methodology improves the transferability of these gaits to real hardware, lowers the computational overhead on-board, and also avoids multiple training iterations by generating a set of derived behaviors from a single learned gait.


Title: Single-shot Foothold Selection and Constraint Evaluation for Quadruped Locomotion
Key Words: control engineering computing  convolutional neural nets  geometry  legged locomotion  motion control  optimal control  robot dynamics  robot kinematics  single-shot foothold selection  constraint evaluation  quadruped locomotion  optimal footholds  legged systems  swing leg  local elevation map  kinematic constraints  convolutional neural network  geometrical characteristics  Legged locomotion  Foot  Kinematics  Robot kinematics  Collision avoidance  Neural networks 
Abstract: In this paper, we propose a method for selecting the optimal footholds for legged systems. The goal of the proposed method is to find the best foothold for the swing leg on a local elevation map. First, we evaluate the geometrical characteristics of each cell on the elevation map, checks kinematic constraints and collisions. Then, we apply the Convolutional Neural Network to learn the relationship between the local elevation map and the quality of potential footholds. During execution time, the controller obtains the qualitative measurement of each potential foothold from the neural model. This method evaluates hundreds of potential footholds and checks multiple constraints in a single step which takes 10 ms on a standard computer without GPU. The experiments were carried out on a quadruped robot walking over rough terrain in both simulation and real robotic platforms.


Title: Lift Your Leg: Mechanics of Running Through Fluids
Key Words: energy consumption  gait analysis  legged locomotion  robot dynamics  fluid interaction mechanics  energy consumption  center of mass  gait stability  mud  SLIP runner  viscous medium  snow  stream banks  beach-head  dense fluids  shallow fluids  outdoor environments  unstructured environments  legged robotic platforms  Legged locomotion  Hip  Foot  Drag  Mathematical model  Actuators 
Abstract: In order for legged robotic platforms to become adept enough to operate in unstructured, outdoor environments it is critical that they have the ability to adapt to a variety of terrains. One class of terrains to consider are regions of shallow, dense fluids, such as a beach-head, stream banks, snow or mud. This work examines the behavior of a simulated SLIP runner operating in such a viscous medium. Simulation results show that intelligently retracting the leg during flight can have a profound effect on the maximum achievable velocity of the runner, the stability of the resulting gait, and the cost of transport of the runner. Results also show that trudging gaits, in which the leg is positioned behind the center of mass, can be favorable in certain situations in terms of energy consumption and forward velocity.


Title: Safely Probabilistically Complete Real-Time Planning and Exploration in Unknown Environments
Key Words: approximation theory  collision avoidance  mobile robots  predictive control  probability  reachability analysis  robot dynamics  robust control  safe backward reachable set  real-time simulation  safely probabilistically complete real-time planning  motion planning  kinodynamic planners  a priori unknown  static environments  collision avoidance  robust controller  reachability analysis  motion plans  robot operating system software environment  Planning  Trajectory  Safety  Computational modeling  Real-time systems  Vehicle dynamics  Probabilistic logic 
Abstract: We present a new framework for motion planning that wraps around existing kinodynamic planners and guarantees recursive feasibility when operating in a priori unknown, static environments. Our approach makes strong guarantees about overall safety and collision avoidance by utilizing a robust controller derived from reachability analysis. We ensure that motion plans never exit the safe backward reachable set of the initial state, while safely exploring the space. This preserves the safety of the initial state, and guarantees that that we will eventually find the goal if it is possible to do so while exploring safely. We implement our framework in the Robot Operating System (ROS) software environment and demonstrate it in a real-time simulation.


Title: Compliant Limb Sensing and Control for Safe Human-Robot Interactions
Key Words: force control  friction  human-robot interaction  robot dynamics  robot kinematics  stability  transient response  controller parameters  maximum safe operating velocity  linear model  1 DoF robotic joint  traditional admittance control law  simple control structure  compliant limb sensing  safe human-robot interactions  control methodology  human-robot interaction  compliant sensor  robot links  existing robots  mechanical redesign  linear robot model  stability analysis  admittance control law  comparable transient response  control structure  Robot sensing systems  Collision avoidance  Impedance  Safety  Force  Analytical models 
Abstract: The current paper proposes a control methodology for ensuring safety during human-robot interaction based on a compliant sensor covering the robot links as a lightweight shell. The method can be used with existing robots without the need for mechanical redesign. To assess the behaviour of the proposed control law, the controller is analysed using a linear robot model. Stability analysis is performed and requirements on the controller parameters are derived. The effect of the controller parameters on the perceived impedance and the maximum safe operating velocity of the robot are determined via the linear model. The adverse impact of dry friction is analysed in simulation and methods are developed to mitigate the effects. The controller is implemented on a 1 DoF robotic joint and the results are compared to those of a traditional admittance control law, demonstrating comparable transient response while maintaining a simple control structure and decreased risk of instability.


Title: Path Following Controller for Differentially Driven Planar Robots with Limited Torques and Uncertain and Changing Dynamics
Key Words: Kalman filters  mobile robots  nonlinear filters  robot dynamics  torque control  wheel torque commands  motor torque limits  internal control elements  differentially driven planar robots  asymmetrical planar robots  limited motor torques  environmental forces  unscented Kalman filter  robot inertia  Acceleration  Mobile robots  Force  Wheels  Torque  Robot kinematics 
Abstract: This paper presents a path following controller that is suitable for asymmetrical planar robots with significant mass and limited motor torques. the controller is resistant against environmental forces, and inaccurate estimates of robot's inertia, by estimating their effects with unscented kalman filter. the controller outputs wheel torque commands which take in account the motor torque limits and given relative priority of internal control elements. the method presented is thoroughly explained and the simulation results demonstrate the performance of the controller.


Title: Nonlinear Tire Cornering Stiffness Observer for a Double Steering Off-Road Mobile Robot
Key Words: linear quadratic control  mobile robots  nonlinear control systems  observers  off-road vehicles  path planning  predictive control  steering systems  tyres  vehicle dynamics  open environments  rear contact cornering stiffnesses  soil proprieties  steering angles  LQR controller  nonlinear tire cornering stiffness observer  double steering off-road mobile robot  path tracking controllers  autonomous vehicle  dynamic model  wheel-ground contact  Kalman-Bucy observer  ground parameter estimation  Observers  Tires  Mobile robots  Vehicle dynamics  Wheels  Nonlinear optics 
Abstract: Path tracking controllers for an autonomous vehicle are often designed by using either a dynamic model or a kinematic one and some models are related to wheel-ground contact, that makes the efficiency of the controller highly dependent on the ground parameters estimation, especially for off-road mobile robots intended to navigate in open environments. This paper proposes a new nonlinear observer designed to estimate the front and rear contact cornering stiffnesses in real time, that are related both on tire and soil proprieties. The latter is estimated using steering angles as well as yaw rate and lateral velocity, which are provided by a preliminary Kalman-Bucy observer. The performance of the proposed nonlinear observer combined with the LQR controller is evaluated by both advanced simulations and experiments in real conditions at different speeds.


Title: Learning Primitive Skills for Mobile Robots
Key Words: intelligent robots  learning (artificial intelligence)  legged locomotion  multi-robot systems  robot vision  robot soccer small-size domain  tactical level team strategies  high-level team strategies  individual robot ball-based skills  robot primitive skills  continuous action space  hardware fidelity  learned skills  mobile robots  hand-coding algorithms  training parameters  mobile robot system  deep reinforcement learning algorithm  primitive skills  task performance  learning algorithms  Robot kinematics  Sports  Task analysis  Training  Legged locomotion 
Abstract: Achieving effective task performance on real mobile robots is a great challenge when hand-coding algorithms, both due to the amount of effort involved and manually tuned parameters required for each skill. Learning algorithms instead have the potential to lighten up this challenge by using one single set of training parameters for learning different skills, but the question of the feasibility of such learning in real robots remains a research pursuit. We focus on a kind of mobile robot system - the robot soccer “small-size” domain, in which tactical and high-level team strategies build upon individual robot ball-based skills. In this paper, we present our work using a Deep Reinforcement Learning algorithm to learn three real robot primitive skills in continuous action space: go-to-ball, turn-and-shoot and shoot-goalie, for which there is a clear success metric to reach a destination or score a goal. We introduce the state and action representation, as well as the reward and network architecture. We describe our training and testing using a simulator of high physical and hardware fidelity. Then we test the policies trained from simulation on real robots. Our results show that the learned skills achieve an overall better success rate at the expense of taking 0.29 seconds slower on average for all three skills. In the end, we show that our policies trained in simulation have good performance on real robots by directly transferring the policy.


Title: Continuous Control for High-Dimensional State Spaces: An Interactive Learning Approach
Key Words: interactive systems  learning (artificial intelligence)  interactive learning approach  deep reinforcement learning  corrective advice communicated by humans  DRL agent  human training effort  D-COACH framework  human corrective feedback  human knowledge  machine learning methods  reward function  simulated environments  robotics applications  complex decision-making problems  high-dimensional state spaces  continuous control  Training  Robots  Shape  Task analysis  Adaptation models  Decoding  Machine learning 
Abstract: Deep Reinforcement Learning (DRL) has become a powerful methodology to solve complex decision-making problems. However, DRL has several limitations when used in real-world problems (e.g., robotics applications). For instance, long training times are required and cannot be accelerated in contrast to simulated environments, and reward functions may be hard to specify/model and/or to compute. Moreover, the transfer of policies learned in a simulator to the real-world has limitations (reality gap). On the other hand, machine learning methods that rely on the transfer of human knowledge to an agent have shown to be time efficient for obtaining well performing policies and do not require a reward function. In this context, we analyze the use of human corrective feedback during task execution to learn policies with high-dimensional state spaces, by using the D-COACH framework, and we propose new variants of this framework. D-COACH is a Deep Learning based extension of COACH (COrrective Advice Communicated by Humans), where humans are able to shape policies through corrective advice. The enhanced version of DCOACH, which is proposed in this paper, largely reduces the time and effort of a human for training a policy. Experimental results validate the efficiency of the D-COACH framework in three different problems (simulated and with real robots), and show that its enhanced version reduces the human training effort considerably, and makes it feasible to learn policies within periods of time in which a DRL agent do not reach any improvement.


Title: A Predictive Reward Function for Human-Like Driving Based on a Transition Model of Surrounding Environment
Key Words: decision making  image processing  learning (artificial intelligence)  mobile robots  neural nets  road traffic  road vehicles  robot vision  traffic engineering computing  autonomous driving vehicles  deep predictive network  predictive reward function  human-like driving  decision making  vehicle control  traffic flow  occupancy grid image  prediction network training  real driving data  reinforcement learning agent training  deep neural networks  Autonomous vehicles  Roads  Predictive models  Reinforcement learning  Decision making  Object detection  Autonomous driving  Prediction  Reward  Deep Learning  Reinforcement Learning  naturalistic Driving Data 
Abstract: Driving is a complex task that requires the perception of the surrounding environment, decision making and control of the vehicle. Human drivers predict how surrounding objects move and decide an appropriate driving behavior. As with human drivers, autonomous driving vehicles should consider the condition of the surrounding environment and behave naturally so as not to disturb the traffic flow. We propose a reward function for learning how natural the driving is based on the hypothesis that the movement of surrounding vehicles becomes unpredictable when the ego vehicle takes an unnatural driving behavior. The reward function is based on the prediction error of a deep predictive network that models the transition of the surrounding environment. Occupancy grid image is used to perceive the surrounding environment and the predictions up to two seconds are used to calculate the reward function. We evaluated the reward function using both simulated and the real world data. We trained the prediction network using real driving data and trained a reinforcement learning agent based on the reward function. Then we compared the speed planned by the agent and a human driver, which showed a correlation of 0.52. We also confirmed the benefit of taking prediction into account by observing the behavior of the agent in a specific traffic scenario.


Title: ADAPS: Autonomous Driving Via Principled Simulations
Key Words: hierarchical systems  remotely operated vehicles  road traffic control  robust control  ADAPS  autonomous driving  robust control policy  autonomous vehicles  simulation platforms  learning mechanism  hierarchical control policy  DAGGER method  Task analysis  Training  Accidents  Autonomous vehicles  Training data  Trajectory  Learning systems 
Abstract: Autonomous driving has gained significant advancements in recent years. However, obtaining a robust control policy for driving remains challenging as it requires training data from a variety of scenarios, including rare situations (e.g., accidents), an effective policy architecture, and an efficient learning mechanism. We propose ADAPS for producing robust control policies for autonomous vehicles. ADAPS consists of two simulation platforms in generating and analyzing accidents to automatically produce labeled training data, and a memoryenabled hierarchical control policy. Additionally, ADAPS offers a more efficient online learning mechanism that reduces the number of iterations required in learning compared to existing methods such as DAGGER [1]. We present both theoretical and experimental results. The latter are produced in simulated environments, where qualitative and quantitative results are generated to demonstrate the benefits of ADAPS.


Title: Planning Coordinated Event Observation for Structured Narratives
Key Words: finite automata  mobile robots  multi-robot systems  sport  structured narratives  autonomous robots  robot teams  large-scale road race  marathon  legible form  weighted finite automaton  simulated race scenario  coordinated event observation planning  Videos  Robot kinematics  Cameras  Robot vision systems  Mobile robots  Observers 
Abstract: This paper addresses the problem of using autonomous robots to record events that obey narrative structure. The work is motivated by a vision of robot teams that can, for example, produce individualized highlight videos for each runner in a large-scale road race such as a marathon. We introduce a method for specifying the desired structure as a function that describes how well the captured events can be used to produce an output that meets the specification. This function is specified in a compact, legible form similar to a weighted finite automaton. Then we describe a planner that uses simple predictions of future events to coordinate the robots' efforts to capture the most important events, as determined by the specification. We describe an implementation of this approach, and demonstrate its effectiveness in a simulated race scenario both in simulation and in a hardware testbed.


Title: Algorithmic Resolution of Multiple Impacts in Nonsmooth Mechanical Systems with Switching Constraints
Key Words: complementarity  differential algebraic equations  impact (mechanical)  iterative methods  legged locomotion  plasticity  robot dynamics  algorithmic resolution  multiple impacts  nonsmooth mechanical systems  switching constraints  differential-algebraic formulation  nonsmooth dynamics  robotic systems  changing constraints  kinematic constraints  algorithmic impact resolution method  classical plastic impact law  multiple simultaneous impacts  prior linear-complementarity-based formulations  implicit impact resolution  Switches  Mathematical model  Mechanical systems  Robots  Dynamics  Heuristic algorithms  Plastics 
Abstract: We present a differential-algebraic formulation with switching constraints to model the nonsmooth dynamics of robotic systems subject to changing constraints and multiple impacts. The formulation combines a single structurally simple governing equation, a set of switching kinematic constraints, and the plastic impact law, to represent the dynamics of robots that interact with their environment. The main contribution of this formulation is a novel algorithmic impact resolution method which provides an explicit solution to the classical plastic impact law in the case of multiple simultaneous impacts. This method serves as an alternative to prior linear-complementarity-based formulations which offer an implicit impact resolution through iterative calculation. We demonstrate the utility of the proposed method by simulating the locomotion of a planar anthropometric biped.


Title: Rigid Body Motion Prediction with Planar Non-convex Contact Patch
Key Words: computational geometry  manipulator dynamics  mechanical contact  shear modulus  planar nonconvex contact patch  intermittent contact  rigid body dynamic simulation  convex contact patches  contact detection  contacting rigid bodies  multiple point contact  single point contact  rigid body motion prediction  convex hull  Mathematical model  Dynamics  Numerical models  Transmission line matrix methods  Robots  Bars  Symmetric matrices 
Abstract: We present a principled method for motion prediction via dynamic simulation for rigid bodies in intermittent contact with each other where the contact is assumed to be a planar non-convex contact patch. The planar non-convex contact patch can either be a topologically connected set or disconnected set. Such algorithms are useful in planning and control for robotic manipulation. Most work in rigid body dynamic simulation assume that the contact between objects is a point contact, which may not be valid in many applications. In this paper, by using the convex hull of the contact patch, we build on our recent work on simulating rigid bodies with convex contact patches, for simulating motion of objects with planar non-convex contact patches. We formulate a discrete-time mixed complementarity problem where we solve the contact detection and integration of the equations of motion simultaneously. Thus, our method is a geometrically-implicit method and we prove that in our formulation, there is no artificial penetration between the contacting rigid bodies. We solve for the equivalent contact point (ECP) and contact impulse of each contact patch simultaneously along with the state, i.e., configuration and velocity of the objects. We provide empirical evidence to show that our method can seamlessly capture transition between different contact modes like patch contact to multiple or single point contact during simulation.


Title: A Data-driven Approach for Fast Simulation of Robot Locomotion on Granular Media
Key Words: control engineering computing  data analysis  granular materials  legged locomotion  mechanical contact  optimisation  shear modulus  stick-slip  data-driven approach  robot locomotion  granular media  semiempirical approach  contact model  stick-slip behavior  rigid objects  granular grains  granular substrate  optimization-based contact force  contact solver  contact wrenches  fast simulation  convex volume  frictional dissipation  plausible interaction response  Substrates  Computational modeling  Force  Media  Legged locomotion  Foot 
Abstract: In this paper, we propose a semi-empirical approach for simulating robot locomotion on granular media. We first develop a contact model based on the stick-slip behavior between rigid objects and granular grains, which is then learned through running extensive experiments. The contact model represents all possible contact wrenches that the granular substrate can provide as a convex volume, which our method formulates as constraints in an optimization-based contact force solver. During simulation, granular substrates are treated as rigid objects that allow penetration and the contact solver solves for wrenches that maximize frictional dissipation. We show that our method is able to simulate plausible interaction response with several granular media at interactive rates.


Title: Experimental Assessment of Plume Mapping using Point Measurements from Unmanned Vehicles
Key Words: air pollution  air quality  autonomous aerial vehicles  environmental monitoring (geophysics)  Gaussian processes  interpolation  mobile robots  Monte Carlo methods  regression analysis  point measurements  autonomous robots  mapping algorithms  piecewise linear interpolation  steady state ground truth  unmanned aerial vehicle  Gaussian process regression  polynomial interpolation  plume mapping  neural networks  Robot sensing systems  Interpolation  Gaussian processes  Dispersion  Noise measurement  Neural networks 
Abstract: This paper presents experiments to assess the plume mapping performance of autonomous robots. The paper compares several mapping algorithms including Gaussian Process regression, Neural networks and polynomial and piecewise linear interpolation. The methods are compared in Monte Carlo simulations using a well known plume model and in indoor experiments using a ground robot. Unlike previous work on mapping using unmanned vehicles, the indoor experiments were performed in a controlled and repeatable manner where a steady state ground truth could be obtained in order to properly assess the various regression methods using data from a real dispersive source and sensor. The effect of sampling time during data collection was assessed with regards to the mapping accuracy, and the data collected during the experiments have been made available. Overall, the Gaussian Process method was found to perform the best among the regression algorithms, showing more robustness to the noisy measurements obtained from short sampling periods, enabling an accurate map to be produced in significantly less time. Finally, plume mapping results are presented in uncontrolled outdoor conditions, using an unmanned aerial vehicle, to demonstrate the system in a realistic uncontrolled environment.


