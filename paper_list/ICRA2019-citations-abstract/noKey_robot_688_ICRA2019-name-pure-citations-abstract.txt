total paper: 688
Title: Trajectory-based Probabilistic Policy Gradient for Learning Locomotion Behaviors
Abstract: In this paper, we propose a trajectory-based reinforcement learning method named deep latent policy gradient (DLPG) for learning locomotion skills. We define the policy function as a probability distribution over trajectories and train the policy using a deep latent variable model to achieve sample efficient skill learning. We first evaluate the sample efficiency of DLPG compared to the state-of-the-art reinforcement learning methods in simulated environments. Then, we apply the proposed method to a four-legged walking robot named Snapbot to learn three basic locomotion skills of turn left, go straight, and turn right. We demonstrate that, by properly designing two reward functions for curriculum learning, Snapbot successfully learns the desired locomotion skills with moderate sample complexity.


Title: Learning Motion Planning Policies in Uncertain Environments through Repeated Task Executions
Abstract: The ability to navigate uncertain environments from a start to a goal location is a necessity in many applications. While there are many reactive algorithms for online replanning, there has not been much investigation in leveraging past executions of the same navigation task to improve future executions. In this work, we first formalize this problem by introducing the Learned Reactive Planning Problem (LRPP). Second, we propose a method to capture these past executions and from that determine a motion policy to handle obstacles that the robot has seen before. Third, we show from our experiments that using this policy can significantly reduce the execution cost over just using reactive algorithms.


Title: BaRC: Backward Reachability Curriculum for Robotic Reinforcement Learning
Abstract: Model-free Reinforcement Learning (RL) offers an attractive approach to learn control policies for high dimensional systems, but its relatively poor sample complexity often necessitates training in simulated environments. Even in simulation, goal-directed tasks whose natural reward function is sparse remain intractable for state-of-the-art model-free algorithms for continuous control. The bottleneck in these tasks is the prohibitive amount of exploration required to obtain a learning signal from the initial state of the system. In this work, we leverage physical priors in the form of an approximate system dynamics model to design a curriculum for a model-free policy optimization algorithm. Our Backward Reachability Curriculum (BaRC) begins policy training from states that require a small number of actions to accomplish the task, and expands the initial state distribution backwards in a dynamically-consistent manner once the policy optimization algorithm demonstrates sufficient performance. BaRC is general, in that it can accelerate training of any model-free RL algorithm on a broad class of goal-directed continuous control MDPs. Its curriculum strategy is physically intuitive, easy-to-tune, and allows incorporating physical priors to accelerate training without hindering the performance, flexibility, and applicability of the model-free RL algorithm. We evaluate our approach on two representative dynamic robotic learning problems and find substantial performance improvement relative to previous curriculum generation techniques and naive exploration strategies.


Title: Active Sampling based Safe Identification of Dynamical Systems using Extreme Learning Machines and Barrier Certificates
Abstract: Learning the dynamical system (DS) model from data that preserves dynamical system properties is an important problem in many robot learning applications. Typically, the joint data coming from cyber-physical systems, such as robots have some underlying DS properties associated with it, e.g., convergence, invariance to a set, etc. In this paper, a model learning method is developed such that the trajectories of the DS are invariant in a given compact set. Such invariant DS models can be used to generate trajectories of the robot that will always remain in a prescribed set. In order to achieve invariance to a set, Barrier certificates are employed. The DS is approximated using Extreme Learning Machine (ELM), and a parameter learning problem subject to Barrier certificates enforced at all the points in the prescribed set is solved. To solve an infinite constraint problem for enforcing Barrier Certificates at every point in a given compact set, a modified constraint is developed that is sufficient to hold the Barrier certificates in the entire set. An active sampling strategy is formulated to minimize the number of constraints in learning. Simulation results of ELM learning with and without Barrier certificates are presented which show the invariance property being preserved in the ELM learning when learning procedure involves Barrier constraints. The method is validated using experiments conducted on a robot arm recreating invariant trajectories inside a prescribed set.


Title: Navigating Dynamically Unknown Environments Leveraging Past Experience
Abstract: To enable autonomous robot navigation among unknown dynamic obstacles, a real-time adaptive motion planner (RAMP) plans the robot motion online based on sensing the environment as the robot moves with sensors mounted on the robot. However, the sensed environmental data from the robot's local view is usually incomplete due to occlusions from obstacles and limited sensing range.This paper incorporates learning about the environment into the RAMP framework by leveraging the Hilbert Maps framework to generate a probabilistic model of occupancy of the unknown dynamic environment based on past observations. Utilizing this probabilistic model enables RAMP to reason about trajectory fitness when sensing information is partial and incomplete. This allows the RAMP robot to take advantage of what it has experienced from being in the dynamic environment before to inform its subsequent executions even though the dynamic environment changes in unknown ways. The effectiveness of incorporating such learned probabilistic data into RAMP is shown in both simulation and real experiments.


Title: VPE: Variational Policy Embedding for Transfer Reinforcement Learning
Abstract: Reinforcement Learning methods are capable of solving complex problems, but resulting policies might perform poorly in environments that are even slightly different. In robotics especially, training and deployment conditions often vary and data collection is expensive, making retraining undesirable. Simulation training allows for feasible training times, but on the other hand suffer from a reality-gap when applied in real-world settings. This raises the need of efficient adaptation of policies acting in new environments.We consider the problem of transferring knowledge within a family of similar Markov decision processes. We assume that Q-functions are generated by some low-dimensional latent variable. Given such a Q-function, we can find a master policy that can adapt given different values of this latent variable. Our method learns both the generative mapping and an approximate posterior of the latent variables, enabling identification of policies for new tasks by searching only in the latent space, rather than the space of all policies. The low-dimensional space, and master policy found by our method enables policies to quickly adapt to new environments. We demonstrate the method on both a pendulum swing-up task in simulation, and for simulation-to-real transfer on a pushing task.


Title: Video Object Segmentation using Teacher-Student Adaptation in a Human Robot Interaction (HRI) Setting
Abstract: Video object segmentation is an essential task in robot manipulation to facilitate grasping and learning affordances. Incremental learning is important for robotics in unstructured environments. Inspired by the children learning process, human robot interaction (HRI) can be utilized to teach robots about the world guided by humans similar to how children learn from a parent or a teacher. A human teacher can show potential objects of interest to the robot, which is able to self adapt to the teaching signal without providing manual segmentation labels. We propose a novel teacher-student learning paradigm to teach robots about their surrounding environment. A two-stream motion and appearance “teacher” network provides pseudo-labels to adapt an appearance “student” network. The student network is able to segment the newly learned objects in other scenes, whether they are static or in motion. We also introduce a carefully designed dataset that serves the proposed HRI setup, denoted as (I)nteractive (V)ideo (O)bject (S)egmentation. Our IVOS dataset contains teaching videos of different objects, and manipulation tasks. Our proposed adaptation method outperforms the state-of-theart on DAVIS and FBMS with 6.8% and 1.2% in F-measure respectively. It improves over the baseline on IVOS dataset with 46.1% and 25.9% in mIoU.


Title: A Maximum Likelihood Approach to Extract Finite Planes from 3-D Laser Scans
Abstract: Whether it is object detection, model reconstruction, laser odometry, or point cloud registration: Plane extraction is a vital component of many robotic systems. In this paper, we propose a strictly probabilistic method to detect finite planes in organized 3-D laser range scans. An agglomerative hierarchical clustering technique, our algorithm builds planes from bottom up, always extending a plane by the point that decreases the measurement likelihood of the scan the least. In contrast to most related methods, which rely on heuristics like orthogonal point-to-plane distance, we leverage the ray path information to compute the measurement likelihood. We evaluate our approach not only on the popular SegComp benchmark, but also provide a challenging synthetic dataset that overcomes SegComp's deficiencies. Both our implementation and the suggested dataset are available at [1].


Title: Designing Worm-inspired Neural Networks for Interpretable Robotic Control
Abstract: In this paper, we design novel liquid time-constant recurrent neural networks for robotic control, inspired by the brain of the nematode, C. elegans. In the worm's nervous system, neurons communicate through nonlinear time-varying synaptic links established amongst them by their particular wiring structure. This property enables neurons to express liquid time-constants dynamics and therefore allows the network to originate complex behaviors with a small number of neurons. We identify neuron-pair communication motifs as design operators and use them to configure compact neuronal network structures to govern sequential robotic tasks. The networks are systematically designed to map the environmental observations to motor actions, by their hierarchical topology from sensory neurons, through recurrently-wired interneurons, to motor neurons. The networks are then parametrized in a supervised-learning scheme by a search-based algorithm. We demonstrate that obtained networks realize interpretable dynamics. We evaluate their performance in controlling mobile and arm robots, and compare their attributes to other artificial neural network-based control agents. Finally, we experimentally show their superior resilience to environmental noise, compared to the existing machine learning-based methods.


Title: Acting Is Seeing: Navigating Tight Space Using Flapping Wings
Abstract: Wings of flying animals can not only generate lift and control torques but also can sense their surroundings. Such dual functions of sensing and actuation coupled in one element are particularly useful for small sized bio-inspired robotic flyers, whose weight, size, and power are under stringent constraint. In this work, we present the first flapping-wing robot using its flapping wings for environmental perception and navigation in tight space, without the need for any visual feedback. As the test platform, we introduce the Purdu Hummingbird, a flapping-wing robot with 17cm wingspan and 12 grams weight, with a pair of 30-40Hz flapping wings driven by only two actuators. By interpreting the wing loading feedback and its variations, the vehicle can detect the presence of environmental changes such as grounds, walls, stairs, obstacles and wind gust. The instantaneous wing loading can be obtained through the measurements and interpretation of the current feedback by the motors that actuate the wings. The effectiveness of the proposed approach is experimentally demonstrated on several challenging flight tasks without vision: terrain following, wall following and going through a narrow corridor. To ensure flight stability, a robust controller was designed for handling unforeseen disturbances during the flight. Sensing and navigating one's environment through actuator loading is a promising method for mobile robots, and it can serve as an alternative or complementary method to visual perception.


Title: Design and Characterization of a Novel Robotic Surface for Application to Compressed Physical Environments *
Abstract: Developments of robot arms are countless, but there has been little focus on robot surfaces for the reshaping of a habitable space - especially compliant surfaces. In this paper we introduce a novel, tendon-driven, robot surface comprised of aggregated, overlapping panels organized in a herringbone pattern. The individual 3D-printed panels and their behavior as an aggregation are inspired by the form and behavior of a pinecone. This paper presents our concept, design, and realization of this robot, and compares our prototype to simulations of four physical configurations that are formally distinct and suggestive of how the surface might be applied to habitable, physical space in response to human needs and wants. For the four configurations studied, we found a validating match between prototype and simulations. The paper concludes with a consideration of potential applications for robot surfaces like this one.


Title: Learning Extreme Hummingbird Maneuvers on Flapping Wing Robots
Abstract: Biological studies show that hummingbirds can perform extreme aerobatic maneuvers during fast escape. Given a sudden looming visual stimulus at hover, a hummingbird initiates a fast backward translation coupled with a 180-degree yaw turn, which is followed by instant posture stabilization in just under 10 wingbeats. Consider the wingbeat frequency of 40Hz, this aggressive maneuver is carried out in just 0.2 seconds. Inspired by the hummingbirds' near-maximal performance during such extreme maneuvers, we developed a flight control strategy and experimentally demonstrated that such maneuverability can be achieved by an at-scale 12-gram hummingbird robot equipped with just two actuators driving a pair of flapping wings up to 40Hz. The proposed hybrid control policy combines model-based nonlinear control with model-free reinforcement learning. We used the model-based nonlinear control for nominal flight conditions where dynamic models are relatively accurate. During extreme maneuvers when the modeling error becomes unmanageable, we use a model-free reinforcement learning policy trained and optimized in simulation to 'destabilize' the system for peak performance during maneuvering. The hybrid policy manifests a maneuver that is close to that observed in hummingbirds. Direct simulation-to-real transfer is achieved, demonstrating the hummingbird-like fast evasive maneuvers on the at-scale hummingbird robot.


Title: ScalableFusion: High-resolution Mesh-based Real-time 3D Reconstruction
Abstract: Dense 3D reconstructions generate globally consistent data of the environment suitable for many robot applications. Current RGB-D based reconstructions, however, only maintain the color resolution equal to the depth resolution of the used sensor. This firmly limits the precision and realism of the generated reconstructions. In this paper we present a real-time approach for creating and maintaining a surface reconstruction in as high as possible geometrical fidelity with full sensor resolution for its colorization (or surface texture). A multi-scale memory management process and a Level of Detail scheme enable equally detailed reconstructions to be generated at small scales, such as objects, as well as large scales, such as rooms or buildings. We showcase the benefit of this novel pipeline with a PrimeSense RGB-D camera as well as combining the depth channel of this camera with a high resolution global shutter camera. Further experiments show that our memory management approach allows us to scale up to larger domains that are not achievable with current state-of-the-art methods.


Title: GEN-SLAM: Generative Modeling for Monocular Simultaneous Localization and Mapping
Abstract: We present a Deep Learning based system for the twin tasks of localization and obstacle avoidance essential to any mobile robot. Our system learns from conventional geometric SLAM, and outputs, using a single camera, the topological pose of the camera in an environment, and the depth map of obstacles around it. We use a CNN to localize in a topological map, and a conditional VAE to output depth for a camera image, conditional on this topological location estimation. We demonstrate the effectiveness of our monocular localization and depth estimation system on simulated and real datasets.


Title: RESLAM: A real-time robust edge-based SLAM system
Abstract: Simultaneous Localization and Mapping is a key requirement for many practical applications in robotics. In this work, we present RESLAM, a novel edge-based SLAM system for RGBD sensors. Due to their sparse representation, larger convergence basin and stability under illumination changes, edges are a promising alternative to feature-based or other direct approaches. We build a complete SLAM pipeline with camera pose estimation, sliding window optimization, loop closure and relocalisation capabilities that utilizes edges throughout all steps. In our system, we additionally refine the initial depth from the sensor, the camera poses and the camera intrinsics in a sliding window to increase accuracy. Further, we introduce an edge-based verification for loop closures that can also be applied for relocalisation. We evaluate RESLAM on wide variety of benchmark datasets that include difficult scenes and camera motions and also present qualitative results. We show that this novel edge-based SLAM system performs comparable to state-of-the-art methods, while running in real-time on a CPU. RESLAM is available as open-source software1.


Title: On-line 3D active pose-graph SLAM based on key poses using graph topology and sub-maps
Abstract: In this paper, we present an on-line active pose-graph simultaneous localization and mapping (SLAM) frame-work for robots in three-dimensional (3D) environments using graph topology and sub-maps. This framework aims to find the best trajectory for loop-closure by re-visiting old poses based on the T-optimality and D-optimality metrics of the Fisher information matrix (FIM) in pose-graph SLAM. In order to reduce computational complexity, graph topologies are introduced, including weighted node degree (T-optimality metric) and weighted tree-connectivity (D-optimality metric), to choose a candidate trajectory and several key poses. With the help of the key poses, a sampling-based path planning method and a continuous-time trajectory optimization method are combined hierarchically and applied in the whole framework. So as to further improve the real-time capability of the method, the sub-map joining method is used in the estimation and planning process for large-scale active SLAM problems. In simulations and experiments, we validate our approach by comparing against existing methods, and we demonstrate the on-line planning part using a quad-rotor unmanned aerial vehicle (UAV).


Title: Modeling and Planning Manipulation in Dynamic Environments
Abstract: In this paper we propose a new model for sequential manipulation tasks that also considers robot dynamics and time-variant environments. From this model we automatically derive constraint-based controllers and use them as steering functions in a kinodynamic manipulation planner. The resulting plan is not a trajectory but a sequence of controllers that react online to disturbances. We validated our approach in simulation and on a real robot. In the experiments our approach plans and executes dual-robot manipulation tasks with online collision avoidance and reactions to estimates of object poses.


Title: Efficient Obstacle Rearrangement for Object Manipulation Tasks in Cluttered Environments
Abstract: We present an algorithm that produces a plan for relocating obstacles in order to grasp a target in clutter by a robotic manipulator without collisions. We consider configurations where objects are densely populated in a constrained and confined space. Thus, there exists no collision-free path for the manipulator without relocating obstacles. Since the problem of planning for object rearrangement has shown to be NP-hard, it is difficult to perform manipulation tasks efficiently which could frequently happen in service domains (e.g., taking out a target from a shelf or a fridge). Our proposed planner employs a collision avoidance scheme which has been widely used in mobile robot navigation. The planner determines an obstacle to be removed quickly in real time. It also can deal with dynamic changes in the configuration (e.g., changes in object poses). Our method is shown to be complete and runs in polynomial time. Experimental results in a realistic simulated environment show that our method improves up to 31% of the execution time compared to other competitors.


Title: MoveIt! Task Constructor for Task-Level Motion Planning
Abstract: A lot of motion planning research in robotics focuses on efficient means to find trajectories between individual start and goal regions, but it remains challenging to specify and plan robotic manipulation actions which consist of multiple interdependent subtasks. The Task Constructor framework we present in this work provides a flexible and transparent way to define and plan such actions, enhancing the capabilities of the popular robotic manipulation framework MoveIt!.11The Task Constructor framework is publicly available at https://github.com/ros-planning/moveit_task_constructor Subproblems are solved in isolation in black-box planning stages and a common interface is used to pass solution hypotheses between stages. The framework enables the hierarchical organization of basic stages using containers, allowing for sequential as well as parallel compositions. The flexibility of the framework is illustrated in multiple scenarios performed on various robot platforms, including bimanual ones.


Title: Exploiting Environment Contacts of Serial Manipulators
Abstract: We explore the characteristics of secondary contacts when applying forces with the end-effector of a robot and address the question when these secondary contacts can increase maximum applicable end-effector forces or reduce required actuator efforts. To this end, we formalize the effect of such secondary contacts in terms of required actuator efforts and derive efficiency bounds depending on the contact characteristics and robot configuration. Our findings are confirmed by experiments with a redundant serial manipulator.


Title: optimization-Based Human-in-the-Loop Manipulation Using Joint Space Polytopes
Abstract: This paper presents a new method of maximizing the free space for a robot operating in a constrained environment under operator supervision. The objective is to make the resulting trajectories more robust to operator commands and/or changes in the environment. To represent the volume of free space, the constrained manipulability polytopes are used. These polytopes embed the distance to obstacles, the distance to joint limits and the distance to singular configurations. The volume of the resulting Cartesian polyhedron is used in an optimization-based motion planner to create the trajectories. Additionally, we show how fast collision-free inverse kinematic solutions can be obtained by exploiting the pre-computed inequality constraints. The proposed algorithm is validated in simulation and experimentally.


Title: Large-Scale Multi-Object Rearrangement
Abstract: This paper describes a new robotic tabletop rearrangement system, and presents experimental results. The tasks involve rearranging as many as 30 to 100 blocks, sometimes packed with a density of up to 40%. The high packing factor forces the system to push several objects at a time, making accurate simulation difficult, if not impossible. Nonetheless, the system achieves goals specifying the pose of every object, with an average precision of ± 1 mm and ± 2°. The system searches through policy rollouts of simulated pushing actions, using an Iterated Local Search technique to escape local minima. In real world execution, the system executes just one action from a policy, then uses a vision system to update the estimated task state, and replans. The system accepts a fully general description of task goals, which means it can solve the singulation and separation problems addressed in prior work, but can also solve sorting problems and spell out words, among other things. The paper includes examples of several solved problems, statistical analysis of the system's behavior on different types of problems, and some discussion of limitations, insights, and future work.


Title: Manipulation Using Microrobot Driven by Optothermally Generated Surface Bubble
Abstract: A manipulation technique based on optothermally generated surface bubbles is proposed in this paper. The manipulation and assembly of microstructures are completed by using bubbles. In addition, the hydrogel microstructures are also used as microrobots driven by the bubble to operate and pattern the microspheres. Considering that many materials and lasers with different wavelength have been used for generating bubbles by optothermal effects, absorptivity and transmissivity are used as indicators of selections. Besides, the size of the bubble can be controlled by the frequency and time of the laser. This technique is supposed to be applied for manipulation of cells, microparticles and microstructures.


Title: Compound micromachines powered by acoustic streaming
Abstract: This paper presents the design, fabrication, and operation of compound micromachines powered by acoustic streaming. The machine components were directly incorporated around pillars serving as shafts without further assembly steps using a single-step in situ polymerization process controlled by a programmable projector. Two strategies were presented for harvesting acoustic energy using sharp-edged structures. The first method is based on on-board pumping of fluids and the second method involves engineering of rotors. The implementation of these strategies resulted in the construction of microscale turbines and engines that can be coupled to gear trains for adaptable transmission of mechanical power. We provide a number of further improvements that may together lead to development of compact yet powerful robotic manipulation systems inside microfluidic devices.


Title: ChevBot – An Untethered Microrobot Powered by Laser for Microfactory Applications
Abstract: In this paper, we introduce a new class of submillimeter robot (ChevBot) for microfactory applications in dry environments, powered by a 532 nm laser beam. ChevBot is an untethered microrobot propelled by a thermal Micro Electro Mechanical (MEMS) actuator upon exposure to the laser light. Novel models for opto-thermal-mechanical energy conversion are proposed to describe the microrobot's locomotion mechanism. First, an opto-thermal simulation model is presented which is experimentally validated with static displacement measurements with microrobots tethered to the substrate. Then, stick and slip motion of the microrobot was predicted using a dynamic extension of our simulation model, and experiments were conducted to validate this model in one dimension. Promising microrobot designs were fabricated on a silicon on insulator (SOI) wafer with 20 μm device layer and a dimple was assembled at the bottom to initiate directional locomotion on a silicon substrate. Validation experiments demonstrate that exposure to laser power below 2W and repetition frequencies below 60 kHz can generate actuator displacements of a few microns, and 46 μm/s locomotion velocity.


Title: Versatile Reactive Bipedal Locomotion Planning Through Hierarchical Optimization
Abstract: When experiencing disturbances during locomotion, human beings use several strategies to maintain balance, e.g. changing posture, modulating step frequency and location. However, when it comes to the gait generation for humanoid robots, modifying step time or body posture in real time introduces nonlinearities in the walking dynamics, thus increases the complexity of the planning. In this paper, we propose a two-layer hierarchical optimization framework to address this issue and provide the humanoids with the abilities of step time and step location adjustment, Center of Mass (CoM) height variation and angular momentum adaptation. In the first layer, times and locations of consecutive two steps are modulated online based on the current CoM state using the Linear Inverted Pendulum Model. By introducing new optimization variables to substitute the hyperbolic functions of step time, the derivatives of the objective function and feasibility constraints are analytically derived, thus reduces the computational cost. Then, taking the generated horizontal CoM trajectory, step times and step locations as inputs, CoM height and angular momentum changes are optimized by the second layer nonlinear model predictive control. This whole procedure will be repeated until the termination condition is met. The improved recovery capability under external disturbances is validated in simulation studies.


Title: Using Deep Reinforcement Learning to Learn High-Level Policies on the ATRIAS Biped
Abstract: Learning controllers for bipedal robots is a challenging problem, often requiring expert knowledge and extensive tuning of parameters that vary in different situations. Recently, deep reinforcement learning has shown promise at automatically learning controllers for complex systems in simulation. This has been followed by a push towards learning controllers that can be transferred between simulation and hardware, primarily with the use of domain randomization. However, domain randomization can make the problem of finding stable controllers even more challenging, especially for under actuated bipedal robots. In this work, we explore whether policies learned in simulation can be transferred to hardware with the use of high-fidelity simulators and structured controllers. We learn a neural network policy which is a part of a more structured controller. While the neural network is learned in simulation, the rest of the controller stays fixed, and can be tuned by the expert as needed. We show that using this approach can greatly speed up the rate of learning in simulation, as well as enable transfer of policies between simulation and hardware. We present our results on an ATRIAS robot and explore the effect of action spaces and cost functions on the rate of transfer between simulation and hardware. Our results show that structured policies can indeed be learned in simulation and implemented on hardware successfully. This has several advantages, as the structure preserves the intuitive nature of the policy, and the neural network improves the performance of the hand-designed policy. In this way, we propose a way of using neural networks to improve expert designed controllers, while maintaining ease of understanding.


Title: Unsupervised Gait Phase Estimation for Humanoid Robot Walking*
Abstract: Contact detection is an important topic in contemporary humanoid robotic research. Up to date control and state estimation schemes readily assume that feet contact status is known in advance. In this work, we elaborate on a broader question: in which gait phase is the robot currently in? We introduce an unsupervised learning framework for gait phase estimation based solely on proprioceptive sensing, namely joint encoder, inertial measurement unit and force/torque data. Initially, a meaningful physical explanation on data acquisition is presented. Subsequently, dimensionality reduction is performed to obtain a compact low-dimensional feature representation followed by clustering into three groups, one for each gait phase. The proposed framework is qualitatively and quantitatively assessed in simulation with ground-truth data of uneven/rough terrain walking gaits and insights about the latent gait phase dynamics are drawn. Additionally, its efficacy and robustness is demonstrated when incorporated in leg odometry computation. Since our implementation is based on sensing that is commonly available on humanoids today, we release an open-source ROS/Python package to reinforce further research endeavors.


Title: Stair Climbing Stabilization of the HRP-4 Humanoid Robot using Whole-body Admittance Control
Abstract: We consider dynamic stair climbing with the HRP-4 humanoid robot as part of an Airbus manufacturing use-case demonstrator. We share experimental knowledge gathered so as to achieve this task, which HRP-4 had never been challenged to before. In particular, we extend walking stabilization based on linear inverted pendulum tracking [1] by quadratic programming-based wrench distribution and a whole-body admittance controller that applies both end-effector and CoM strategies. While existing stabilizers tend to use either one or the other, our experience suggests that the combination of these two approaches improves tracking performance. We demonstrate this solution in an on-site experiment where HRP4 climbs an industrial staircase with 18.5 cm high steps, and release our walking controller as open source software.


Title: Reinforcement Learning Meets Hybrid Zero Dynamics: A Case Study for RABBIT
Abstract: The design of feedback controllers for bipedal robots is challenging due to the hybrid nature of its dynamics and the complexity imposed by high-dimensional bipedal models. In this paper, we present a novel approach for the design of feedback controllers using Reinforcement Learning (RL) and Hybrid Zero Dynamics (HZD). Existing RL approaches for bipedal walking are inefficient as they do not consider the underlying physics, often requires substantial training, and the resulting controller may not be applicable to real robots. HZD is a powerful tool for bipedal control with local stability guarantees of the walking limit cycles. In this paper, we propose a non traditional RL structure that embeds the HZD framework into the policy learning. More specifically, we propose to use RL to find a control policy that maps from the robot's reduced order states to a set of parameters that define the desired trajectories for the robot's joints through the virtual constraints. Then, these trajectories are tracked using an adaptive PD controller. The method results in a stable and robust control policy that is able to track variable speed within a continuous interval. Robustness of the policy is evaluated by applying external forces to the torso of the robot. The proposed RL framework is implemented and demonstrated in OpenAI Gym with the MuJoCo physics engine based on the well-known RABBIT robot model.


Title: Learning Wheel Odometry and IMU Errors for Localization
Abstract: Odometry techniques are key to autonomous robot navigation, since they enable self-localization in the environment. However, designing a robust odometry system is particularly challenging when camera and LiDAR are uninformative or unavailable. In this paper, we leverage recent advances in deep learning and variational inference to correct dynamical and observation models for state-space systems. The methodology trains Gaussian processes on the residual between the original model and the ground truth, and is applied on publicly available datasets for robot navigation based on two wheel encoders, a fiber optic gyro, and an Inertial Measurement Unit (IMU). We also propose to build an Extended Kalman Filter (EKF) on the learned model using wheel speed sensors and the fiber optic gyro for state propagation, and the IMU to update the estimated state. Experimental results clearly demonstrate that the (learned) corrected models and EKF are more accurate than their original counterparts.


Title: Recursive Integrity Monitoring for Mobile Robot Localization Safety
Abstract: This paper presents a new methodology to quantify robot localization safety by evaluating integrity risk, a performance metric widely used in open-sky aviation applications that has been recently extended to mobile ground robots. Here, a robot is localized by feeding relative measurements to mapped landmarks into an Extended Kalman Filter while a sequence of innovations is evaluated for fault detection. The main contribution is the derivation of a sequential chi-squared integrity monitoring methodology that maintains constant computation requirements by employing a preceding time window and, at the same time, is robust against faults occurring prior to the window. Additionally, no assumptions are made on either the nature or shape of the faults because safety is evaluated under the worst possible combination of sensor faults.


Title: A Multi-Domain Feature Learning Method for Visual Place Recognition
Abstract: Visual Place Recognition (VPR) is an important component in both computer vision and robotics applications, thanks to its ability to determine whether a place has been visited and where specifically. A major challenge in VPR is to handle changes of environmental conditions including weather, season and illumination. Most VPR methods try to improve the place recognition performance by ignoring the environmental factors, leading to decreased accuracy decreases when environmental conditions change significantly, such as day versus night. To this end, we propose an end-to-end conditional visual place recognition method. Specifically, we introduce the multi-domain feature learning method (MDFL) to capture multiple attribute-descriptions for a given place, and then use a feature detaching module to separate the environmental condition-related features from those that are not. The only label required within this feature learning pipeline is the environmental condition. Evaluation of the proposed method is conducted on the multi-season NORDLAND dataset, and the multi-weather GTAV dataset. Experimental results show that our method improves the feature robustness against variant environmental conditions.


Title: Event-based, Direct Camera Tracking from a Photometric 3D Map using Nonlinear Optimization
Abstract: Event cameras are novel bio-inspired vision sensors that output pixel-level intensity changes, called “events”, instead of traditional video images. These asynchronous sensors naturally respond to motion in the scene with very low latency (microseconds) and have a very high dynamic range. These features, along with a very low power consumption, make event cameras an ideal sensor for fast robot localization and wearable applications, such as AR/VR and gaming. Considering these applications, we present a method to track the 6-DOF pose of an event camera in a known environment, which we contemplate to be described by a photometric 3D map (i.e., intensity plus depth information) built via classic dense 3D reconstruction algorithms. Our approach uses the raw events, directly, without intermediate features, within a maximum-likelihood framework to estimate the camera motion that best explains the events via a generative model. We successfully evaluate the method using both simulated and real data, and show improved results over the state of the art. We release the datasets to the public to foster reproducibility and research in this topic.


Title: Linear Heterogeneous Reconfiguration of Cubic Modular Robots via Simultaneous Tunneling and Permutation
Abstract: Reconfiguring heterogeneous modular robots in which all modules are not identical is much more time consuming than reconfiguring homogeneous ones, because ordinary heterogeneous reconfiguration is a combination of homogeneous transformation and heterogeneous permutation. While linear homogeneous transformation has been accomplished in previous research, linear heterogeneous permutation has not. This paper studies a reconfiguration algorithm for heterogeneous lattice modular robots with linear operation time cost. The algorithm is based on simultaneous tunneling and permutation, where a robot transforms its configuration via tunneling motion while permutation of each module's position is performed simultaneously during the tunneling transformation. To achieve this, we introduce the idea of a transparent meta-module that allows modules belonging to a meta-module to pass through the spaces occupied by other meta-modules. We prove the correctness and completeness of the proposed algorithm for a 2×2×2 cubic meta-module-based connected robot structure. We also show examples of the reconfiguration simulations of heterogeneous modular robots by the proposed algorithm.


Title: Autonomous Sheet Pile Driving Robots for Soil Stabilization
Abstract: Soil stabilization is a fundamental component of nearly all construction projects, ranging from commercial construction to environmental restoration projects. Previous work in autonomous construction has generally not considered these essential stabilization and anchoring tasks. In this work we present Romu, an autonomous robot capable of building continuous linear structures by using a vibratory hammer to drive interlocking sheet piles into soil. We report on hardware parameters and their effects on pile driving performance, and demonstrate autonomous operation in both controlled and natural environments. Finally, we present simulations in which a small swarm of robots build with sheet piles in example terrains, or apply an alternate spray-based stabilizing agent, and quantify the ability of each intervention to mitigate hydraulic erosion.


Title: ModQuad-Vi: A Vision-Based Self-Assembling Modular Quadrotor
Abstract: Flying modular robots have the potential to rapidly form temporary structures. In the literature, docking actions rely on external systems and indoor infrastructures for relative pose estimation. In contrast to related work, we provide local estimation during the self-assembly process to avoid dependency on external systems. In this paper, we introduce ModQuad-Vi, a flying modular robot that is aimed to operate in outdoor environments. We propose a new robot design and vision-based docking method. Our design is based on a quadrotor platform with onboard computation and visual perception. Our control method is able to accurately align modules for docking actions. Additionally, we present the dynamics and a geometric controller for the aerial modular system. Experiments validate the vision-based docking method with successful results.


Title: Robotic endoscopy system (easyEndo) with a robotic arm mountable on a conventional endoscope
Abstract: The use of flexible endoscope has been rising inconveniences. Steering of the distal section is not intuitive and the weight of the endoscope burdens a physical pressure on physicians who use it continuously for a long time. Also, the limited dexterity of an instrument makes therapeutic procedures more difficult, and further the unintended communications often occur during cooperation with assistants. These degrade the efficiency and thus increase the procedure time. In this paper, we propose a robotic endoscopy system (easyEndo) that can be mounted on a conventional endoscope and facilitate solo-endoscopy with two intuitive hand-held controllers. Furthermore, a robotic arm is presented that can be attached to the endoscope to assist with tissue traction. To validate the robotic endoscopy system, experiments to simulate biopsy and lesion marking were conducted with novices. The results showed that the robotic manipulations improved efficiency and reduced workload than manual manipulation. Subsequently, a prototype of the robotic arm was attached at the distal end of the endoscope, and the feasibility of tissue traction was confirmed by a simulation of pulling a rubber band.


Title: A Rolling-Tip Flexible Instrument for Minimally Invasive Surgery
Abstract: Snake-like robots are commonly used in Minimally Invasive Surgery as they are able to reach areas deep inside the human body. These robots have instruments that are deployed out of the robot's head and controlled via tendons, which connect the instrument to motors at the proximal end. In most currently available systems the instruments are lacking a rolling motion of the end-effector.In this paper, we present a new instrument prototype for a snake-like robot that can perform a stable in-place rolling motion. The prototype has a diameter of 4mm, uses 13 tendons and has 6 degrees of freedom. The robot can bend and roll to high angles, and strongly improves the dexterity compared to an instrument without rolling capabilities. In the evaluation we show that the rolling-tip gripper can rotate about 165° and is capable of applying forces up to 6.5N.


Title: Intent-Uncertainty-Aware Grasp Planning for Robust Robot Assistance in Telemanipulation
Abstract: Promoting a robot agent's autonomy level, which allows it to understand the human operator's intent and provide motion assistance to achieve it, has demonstrated great advantages to the operator's intent in teleoperation. However, the research has been limited to the target approaching process. We advance the shared control technique one step further to deal with the more challenging object manipulation task. Appropriately manipulating an object is challenging as it requires fine motion constraints for a certain manipulation task. Although these motion constraints are critical for task success, they are subtle to observe from ambiguous human motion. The disembodiment problem and physical discrepancy between the human and robot hands bring additional uncertainty, make the object manipulation task more challenging. Moreover, there is a lack of modeling and planning techniques that can effectively combine the human motion input and robot agent's motion input while accounting for the ambiguity of the human intent. To overcome this challenge, we built a multi-task robot grasping model and developed an intent-uncertainty-aware grasp planner to generate robust grasp poses given the ambiguous human intent inference inputs. With this validated modeling and planning techniques, it is expected to extend teleoperated robots' functionality and adoption in practical telemanipulation scenarios.


Title: Vision-based Teleoperation of Shadow Dexterous Hand using End-to-End Deep Neural Network
Abstract: In this paper, we present TeachNet, a novel neural network architecture for intuitive and markerless vision-based teleoperation of dexterous robotic hands. Robot joint angles are directly generated from depth images of the human hand that produce visually similar robot hand poses in an end-to-end fashion. The special structure of TeachNet, combined with a consistency loss function, handles the differences in appearance and anatomy between human and robotic hands. A synchronized human-robot training set is generated from an existing dataset of labeled depth images of the human hand and simulated depth images of a robotic hand. The final training set includes 400K pairwise depth images and joint angles of a Shadow C6 robotic hand. The network evaluation results verify the superiority of TeachNet, especially regarding the high-precision condition. Imitation experiments and grasp tasks teleoperated by novice users demonstrate that TeachNet is more reliable and faster than the state-of-the-art vision-based teleoperation method.


Title: An energy-shared two-layer approach for multi-master-multi-slave bilateral teleoperation systems
Abstract: In this paper, a two-layer architecture for the bilateral teleoperation of multi-arms systems with communication delay is presented. We extend the single-master-single-slave two layer approach proposed in [1] by connecting multiple robots to a single energy tank. This allows to minimize the conservativeness due to passivity preservation and to increment the level of transparency that can be achieved. The proposed approach is implemented on a realistic surgical scenario developed within the EU-funded SARAS project.


Title: Passive Task-Prioritized Shared-Control Teleoperation with Haptic Guidance
Abstract: Robot teleoperation is widely used for several hazardous applications. To increase teleoperator capabilities shared-control methods can be employed. In this paper, we present a passive task-prioritized shared-control method for remote telemanipulation of redundant robots. The proposed method fuses the task-prioritized control architecture with haptic guidance techniques to realize a shared-control framework for teleoperation systems. To preserve the semi-autonomous telerobotic system safety, passivity is analyzed and an energy-tanks passivity-based controller is developed. The proposed theoretical results are validated through experiments involving a real haptic device and a simulated slave robot.


Title: Quasi-Direct Drive for Low-Cost Compliant Robotic Manipulation
Abstract: Robots must cost less and be force-controlled to enable widespread, safe deployment in unconstrained human environments. We propose Quasi-Direct Drive actuation as a capable paradigm for robotic force-controlled manipulation in human environments at low-cost. Our prototype - Blue - is a human scale 7 Degree of Freedom arm with 2kg payload. Blue can cost less than $5000. We show that Blue has dynamic properties that meet or exceed the needs of human operators: the robot has a nominal position-control bandwidth of 7.5Hz and repeatability within 4mm. We demonstrate a Virtual Reality based interface that can be used as a method for telepresence and collecting robot training demonstrations. Manufacturability, scaling, and potential use-cases for the Blue system are also addressed. Videos and additional information can be found online at berkeleyopenarms.github.io.


Title: Augmented Reality Predictive Displays to Help Mitigate the Effects of Delayed Telesurgery
Abstract: Surgical robots offer the exciting potential for remote telesurgery, but advances are needed to make this technology efficient and accurate to ensure patient safety. Achieving these goals is hindered by the deleterious effects of latency between the remote operator and the bedside robot. Predictive displays have found success in overcoming these effects by giving the operator immediate visual feedback. However, previously developed predictive displays can not be directly applied to telesurgery due to the unique challenges in tracking the 3D geometry of the surgical environment. In this paper, we present the first predictive display for teleoperated surgical robots. The predicted display is stereoscopic, utilizes Augmented Reality (AR) to show the predicted motions alongside the complex tissue found in-situ within surgical environments, and overcomes the challenges in accurately tracking slave-tools in real-time. We call this a Stereoscopic AR Predictive Display (SARPD). To test the SARPD's performance, we conducted a user study with ten participants on the da Vinci® Surgical System. The results showed with statistical significance that using SARPD decreased time to complete task while having no effect on error rates when operating under delay.


Title: Singularity of Cable-Driven Parallel Robot With Sagging Cables: Preliminary Investigation
Abstract: This paper addresses for the first time the singularity analysis of cable-driven parallel robot (CDPR) with sagging cables using the Irvine model. We present the mathematical framework of singularity analysis of CDPR using this cable model. We then show that, besides a cable model representation singularity, both the inverse and forward kinematics (IK and FK) have a singularity type, called parallel robot singularity, which correspond to the singularity of an equivalent parallel robot with rigid legs. We then show that both the IK and FK have also full singularities, that are not parallel robot singularity and are obtained when two of the IK or FK solution branches intersect. IK singularity will usually lie on the border of the CDPR workspace. We then exhibit an algorithm that allow one to prove that a singularity exist in the neighborhood of a given pose and to estimate its location with an arbitrary accuracy. Examples are provided for parallel robot, IK and FK singularities. However we have not been able to determine examples of combined singularity where both the IK and FK are singular (besides parallel robot singularity).


Title: Active Damping of Parallel Robots Driven by Flexible Cables Using Cold-Gas Thrusters
Abstract: This work is a preliminary study assessing the feasibility of using cold-gas thrusters for active damping of flexible cable-driven parallel robots. The concept is validated experimentally on a planar robot embedding custom-built supersonic air thrusters operating at an industry-standard pressure level.


Title: Exploiting Human and Robot Muscle Synergies for Human-in-the-loop Optimization of EMG-based Assistive Strategies
Abstract: In this study, we propose a novel human-in-the-loop optimization approach for exoskeleton robot control. We develop a method to optimize widely-used Electromyography (EMG)-based assistive strategies. If we use multiple EMG channels to control multi-DoF robots, optimization process becomes complex and requires a large amount of data. To make the optimization tractable, we exploit the synergies both of the human muscles and artificial muscles of the exoskeleton robots to reduce the number of parameters of the assistive strategies. We show that we can extract the synergies not only from the user's muscle activities but from pneumatic artificial muscle (PAMs) contractions of the exoskeleton robot. Then, we adopt a Bayesian optimization method to acquire the parameters for assisting human movements by iteratively identifying the user's preferences of the assistive strategies. We conducted experiments to evaluate our proposed method with a PAMs-driven upper-limb exoskeleton robot. Our method successfully learned assistive strategies from the human-in-theloop optimization with a practicable number of interactions.


Title: Development of a Low Inertia Parallel Actuated Shoulder Exoskeleton Robot for the Characterization of Neuromuscular Property during Static Posture and Dynamic Movement
Abstract: The purpose of this work is to introduce a newly developed exoskeleton robot designed to characterize the neuromuscular properties of the shoulder, including intrinsic and reflexive mechanisms, during static posture and dynamic movement in a 3-dimensional space. Quantitative characterization of these properties requires fast perturbation (>100°/s) to separate their contribution from that of voluntary mechanism. Understanding these properties of the shoulder control could assist in the rehabilitation or enhancement of upper limb performance during physical human-robot interaction. The device can be described as a new type of spherical parallel manipulator (SPM) that utilizes three 4-bar (4B) substructures to decouple and control roll, pitch and yaw of the shoulder. By utilizing a parallel architecture, the 4BSPM exoskeleton has the advantage of high acceleration, fast enough to satisfy the speed requirement for the characterization of distinct neuromuscular properties of the shoulder. In this work, the prototype is presented, along with an evaluation of its position accuracy and step response. The development and preliminary testing of the 4B-SPM exoskeleton presented in this work demonstrates its potential to be a useful tool for studying the neuromuscular mechanisms of the shoulder joint.


Title: Effort Estimation in Robot-aided Training with a Neural Network
Abstract: Robotic exoskeletons open up promising interventions during post-stroke rehabilitation by assisting individuals with sensorimotor impairments to complete therapy tasks. These devices have the ability to provide variable assistance tailored to individual-specific needs and, additionally, can measure several parameters associated with the movement execution. Metrics representative of movement quality are important to guide individualized treatment. While robots can provide data with high resolution, robustness, and consistency, the delineation of the human contribution in the presence of the kinematic guidance introduced by the robotic assistance is a significant challenge. In this paper, we propose a method for assessing voluntary effort from an individual fitted in an upper-body exoskeleton called Harmony. The method separates the active torques generated by the wearer from the effects caused by unmodeled dynamics and passive neuromuscular properties and involuntary forces. Preliminary results show that the effort estimated using the proposed method is consistent with the effort associated with muscle activity and is also sensitive to different levels, indicating that it can reliably evaluate user's contribution to movement. This method has the potential to serve as a high resolution assessment tool to monitor progress of movement quality throughout the treatment and evaluate motor recovery.


Title: Characterizing Architectures of Soft Pneumatic Actuators for a Cable-Driven Shoulder Exoskeleton
Abstract: Low weight and innate compliance make soft pneumatic actuators an attractive method for actuating wearable robots. Performance of soft pneumatic actuators can be tailored to an application by combining them in novel architectures. We modeled and constructed nested linear and pennate architectures using fiber-reinforced elastomeric enclosures (FREEs) with identical manufacturing parameters and total effective lengths to compare their suitability for a cable-driven exoskeleton for augmenting shoulder flexion. We determined actuator performance requirements using a static model for the transmission of actuator forces to the upper arm via Bowden cables. We experimentally characterized the architectures by measuring their force-displacement curves at a range of pressures, yielding greater force and displacement from the nested architecture in the domain required by our exoskeleton. Results also indicated a force threshold above which the pennate structure produced greater force at any given displacement. We validated the nested linear architecture using a prototype exoskeleton installed on a passive mannequin. Measured joint angles at varying pressures were close to predicted values, adjusted for measured losses due to cable anchor movement.


Title: Design and Implementation of a Two-DOF Robotic System with an Adjustable Force Limiting Mechanism for Ankle Rehabilitation
Abstract: This paper presents a novel light-weight back-drivable inherently-safe robotic mechanism for delivering ankle rehabilitation therapies. The robot is designed to be used as the ankle module of a multi-purpose lower-limb rehabilitation robot. A novel friction-based safety feature has been introduced that enables mechanical adjustment of the maximum amount of allowable transfer forces and torques to the patient's limb. The design procedure, mathematical modeling and experimental validations are provided to demonstrate the performance of the proposed system.


Title: Rorg: Service Robot Software Management with Linux Containers
Abstract: Scaling up the software system on service robots increases the maintenance burden of developers and the risk of resource contention of the computer embedded on robots. As a result, developers spend much time on configuring, deploying, and monitoring the robot software system; robots may utilize significant computer resources when all software processes are running. We present Rorg, a Linux container-based scheme to manage, schedule, and monitor software components on service robots. Although Linux containers are already widely-used in cloud environments, this technique is challenging to efficiently adopt in service robot systems due to multi-tasking, resource constraints and performance requirements. To pave the way of Linux containers on service robots in an efficient manner, we present a programmable container management interface and a resource time-sharing mechanism incorporated with the Robot Operating System (ROS). Rorg allows developers to pack software into self-contained images and runs them in isolated environments using Linux containers; it also allows the robot to turn on and off software components on demand to avoid resource contention. We evaluate Rorg with a long-term autonomous tour guide robot: It manages 41 software components on the robot and relieved our maintenance burden, and it also reduces CPU load by 45.5% and memory usage by 16.5% on average.


Title: CartesI/O: A ROS Based Real-Time Capable Cartesian Control Framework
Abstract: This work introduces a framework for the Cartesian control of multi-legged, highly redundant robots. The proposed framework allows the untrained user to perform complex motion tasks with robotics platforms by leveraging a simple, auto-generated ROS-based interface. Contrary to other motion control frameworks (e.g. ROS MoveIt!), we focus on the execution of Cartesian trajectories that are specified online, rather than planned in advance, as it is the case, for instance, in tele-operation and locomotion tasks. Moreover, we address the problem of generating such motions within a hard real-time (RT) control loop. Finally, we demonstrate the capabilities of our framework both on the COMAN + humanoid robot, and on the hybrid wheeled-legged quadruped CENTAURO.


Title: Synthesis of Real-Time Observers from Past-Time Linear Temporal Logic and Timed Specification
Abstract: Fault-tolerant architectures are mandatory to ensure the robustness of autonomous robots performing missions in complex and uncertain environments. The first step of a fault-tolerant mechanism is the detection of a faulty behavior of the system. It is then important to provide tools to help robot developers specify relevant observers. It is moreover crucial to guarantee a correct implementation of the observers, i.e. that the observers do not miss data and do not trigger unsuitable recovery actions in case of false detection. In this paper, we propose a specification language for observers that uses Past-Time LTL to express complex formulas on data produced by software components, and timed constraints on the evaluations of these formulas. We moreover provide an implementation of this specification that guarantees a real-time evaluation of the observers. We briefly describe the observers we have specified for a patrolling mission, and we evaluate the performance of our approach compared to state of the art on a benchmark in which we detect errors on a laser range sensor.


Title: Julia for robotics: simulation and real-time control in a high-level programming language
Abstract: Robotics applications often suffer from the `two-language problem', requiring a low-level language for performance-sensitive components and a high-level language for interactivity and experimentation, which tends to increase software complexity. We demonstrate the use of the Julia programming language to solve this problem by being fast enough for online control of a humanoid robot and flexible enough for prototyping. We present several Julia packages developed by the authors, which together enable roughly 2× realtime simulation of the Boston Dynamics Atlas humanoid robot balancing on flat ground using a quadratic-programming-based controller. Benchmarks show a sufficiently low variation in control frequency to make deployment on the physical robot feasible. We also show that Julia's naturally generic programming style results in versatile packages that are easy to compose and adapt to a wide variety of computational tasks in robotics.


Title: Motion Planning Templates: A Motion Planning Framework for Robots with Low-power CPUs
Abstract: Motion Planning Templates (MPT) is a C++ template-based library that uses compile-time polymorphism to generate robot-specific motion planning code and is geared towards eking out as much performance as possible when running on the low-power CPU of a battery-powered small robot. To use MPT, developers of robot software write or leverage code specific to their robot platform and motion planning problem, and then have MPT generate a robot-specific motion planner and its associated data-structures. The resulting motion planner implementation is faster and uses less memory than general motion planning implementations based upon runtime polymorphism. While MPT loses runtime flexibility, it gains advantages associated with compile-time polymorphism- including the ability to change scalar precision, generate tightly-packed data structures, and store robot-specific data in the motion planning graph. MPT also uses compile-time algorithms to resolve the algorithm implementation, and select the best nearest neighbor algorithm to integrate into it. We demonstrate MPT's performance, lower memory footprint, and ability to adapt to varying robots in motion planning scenarios on a small humanoid robot and on 3D rigid-body motions.


Title: Distortion-free Robotic Surface-drawing using Conformal Mapping
Abstract: We present a robotic pen-drawing system that is capable of faithfully reproducing pen art on an unknown surface. Our robotic system relies on an industrial, seven-degree-of freedom manipulator that can be both position- and impedance-controlled. In order to estimate a rough geometry of the target, continuous surface, we first generate a point cloud of the surface using an RGB-D camera, which is filtered to remove outliers and calibrated to the physical canvas surface. Then, our control algorithm physically reproduces digital drawing on the surface by impedance-controlling the manipulator. Our impedance-controlled drawing algorithm compensates for the uncertainty and incompleteness inherent to a point-cloud estimation of the drawing surface. Moreover, since drawing 2D vector pen art on a 3D surface requires surface parameterization that does not destroy the original 2D drawing, we rely on the least squares conformal mapping. Specifically, the conformal map reduces angle distortion during surface parameterization. As a result, our system can create distortion-free and complicated pen drawings on general surfaces with many unpredictable bumps robustly and faithfully.


Title: Mobile Robotic Painting of Texture
Abstract: Robotic painting is well-established in controlled factory environments, but there is now potential for mobile robots to do functional painting tasks around the everyday world. An obvious first target for such robots is painting a uniform single color. A step further is the painting of textured images. Texture involves a varying appearance, and requires that paint is delivered accurately onto the physical surface to produce the desired effect. Robotic painting of texture is relevant for architecture and in themed environments. A key challenge for robotic painting of texture is to take a desired image as input, and to generate the paint commands to as closely as possible create the desired appearance, according to the robotic capabilities. This paper describes a deep learning approach to take an input ink map of a desired texture, and infer robotic paint commands to produce that texture. We analyze the trade-offs between quality of reconstructed appearance and ease of execution. Our method is general for different kinds of robotic paint delivery systems, but the emphasis here is on spray painting. More generally, the framework can be viewed as an approach for solving a specific class of inverse imaging problems.


Title: A Practical Approach to Insertion with Variable Socket Position Using Deep Reinforcement Learning
Abstract: Insertion is a challenging haptic and visual control problem with significant practical value for manufacturing. Existing approaches in the model-based robotics community can be highly effective when task geometry is known, but are complex and cumbersome to implement, and must be tailored to each individual problem by a qualified engineer. Within the learning community there is a long history of insertion research, but existing approaches are either too sample-inefficient to run on real robots, or assume access to high-level object features, e.g. socket pose. In this paper we show that relatively minor modifications to an off-the-shelf Deep-RL algorithm (DDPG), combined with a small number of human demonstrations, allows the robot to quickly learn to solve these tasks efficiently and robustly. Our approach requires no modeling or simulation, no parameterized search or alignment behaviors, no vision system aside from raw images, and no reward shaping. We evaluate our approach on a narrow-clearance peg-insertion task and a deformable clip-insertion task, both of which include variability in the socket position. Our results show that these tasks can be solved reliably on the real robot in less than 10 minutes of interaction time, and that the resulting policies are robust to variance in the socket position and orientation.


Title: Uncertainty Aware Learning from Demonstrations in Multiple Contexts using Bayesian Neural Networks
Abstract: Diversity of environments is a key challenge that causes learned robotic controllers to fail due to the discrepancies between the training and evaluation conditions. Training from demonstrations in various conditions can mitigate - but not completely prevent - such failures. Learned controllers such as neural networks typically do not have a notion of uncertainty that allows to diagnose an offset between training and testing conditions, and potentially intervene. In this work, we propose to use Bayesian Neural Networks, which have such a notion of uncertainty. We show that uncertainty can be leveraged to consistently detect situations in high-dimensional simulated and real robotic domains in which the performance of the learned controller would be sub-par. Also, we show that such an uncertainty based solution allows making an informed decision about when to invoke a fallback strategy. One fallback strategy is to request more data. We empirically show that providing data only when requested results in increased data-efficiency.


Title: A Data-Efficient Framework for Training and Sim-to-Real Transfer of Navigation Policies
Abstract: Learning effective visuomotor policies for robots purely from data is challenging, but also appealing since a learning-based system should not require manual tuning or calibration. In the case of a robot operating in a real environment the training process can be costly, time-consuming, and even dangerous since failures are common at the start of training. For this reason, it is desirable to be able to leverage simulation and off-policy data to the extent possible to train the robot. In this work, we introduce a robust framework that plans in simulation and transfers well to the real environment. Our model incorporates a gradient-descent based planning module, which, given the initial image and goal image, encodes the images to a lower dimensional latent state and plans a trajectory to reach the goal. The model, consisting of the encoder and planner modules, is first trained through a meta-learning strategy in simulation. We subsequently perform adversarial domain transfer on the encoder by using a bank of unlabelled but random images from the simulation and real environments to enable the encoder to map images from the real and simulated environments to a similarly distributed latent representation. By fine tuning the entire model (encoder + planner) with only a few real world expert demonstrations, we show successful planning performances in different navigation tasks.


Title: A Supervised Approach to Predicting Noise in Depth Images
Abstract: Modern robotic systems are very complex and need to be tested in simulations with detailed sensor noise models to effectively verify robotic behavior. Depth imagery in particular comes with significant noise in the form of scene-dependent pixel-wise dropouts and distortions. Unfortunately, many depth camera simulations contain limited noise models, or can only support generating realistic depth images of simple scenes, which limits their usefulness in effectively testing perception algorithms. We propose a data driven approach to generate more realistic noise for complex simulated environments by using a convolutional neural network (CNN) to predict which pixels of a simulated noise-free depth image will not have returns (no-depth-return pixels, or NDP). We choose to focus on NDP here, as these dropouts are the most common and dramatic form of depth image noise. To train this network, we use reconstructed real-world scenes from the Label Fusion dataset to provide ground truth depth for each noisy depth image used to scan the scene. We use the resulting noise-free and noisy depth image pairs as labeled examples and train the network to predict which pixels of the noise-free image will be NDP. When used to post-process a simulation of a depth sensor, this system produces realistic depth images, even in cluttered scenes. To demonstrate that our approach successfully closes the reality gap for depth imagery, we show that the popular ICP algorithm for object pose estimation fails more realistically on our CNN-corrupted simulated depth images than on uncorrupted depth images and unsupervised domain adaptation baselines.


Title: Quantum Computation in Robotic Science and Applications
Abstract: Using the effects of quantum mechanics for computing challenges has been an often discussed topic for decades. The frequent successes and early products in this area, which we have seen in recent years, indicate that we are currently entering a new era of computing. This paradigm shift will also impact the work of robotic scientists and the applications of robotics. New possibilities as well as new approaches to known problems will enable the creation of even more powerful and intelligent robots that make use of quantum computing cloud services or co-processors. In this position paper, we discuss potential application areas and also point out open research topics in quantum computing for robotics. We go into detail on the impact of quantum computing in artificial intelligence and machine learning, sensing and perception, kinematics as well as system diagnosis. For each topic we point out where quantum computing could be applied based on results from current research.


Title: Manipulation by Feel: Touch-Based Control with Deep Predictive Models
Abstract: Touch sensing is widely acknowledged to be important for dexterous robotic manipulation, but exploiting tactile sensing for continuous, non-prehensile manipulation is challenging. General purpose control techniques that are able to effectively leverage tactile sensing as well as accurate physics models of contacts and forces remain largely elusive, and it is unclear how to even specify a desired behavior in terms of tactile percepts. In this paper, we take a step towards addressing these issues by combining high-resolution tactile sensing with data-driven modeling using deep neural network dynamics models. We propose deep tactile MPC, a framework for learning to perform tactile servoing from raw tactile sensor inputs, without manual supervision. We show that this method enables a robot equipped with a GelSight-style tactile sensor to manipulate a ball, analog stick, and 20-sided die, learning from unsupervised autonomous interaction and then using the learned tactile predictive model to reposition each object to user-specified configurations, indicated by a goal tactile reading. Videos, visualizations and the code are available here: https://sites.google.com/view/deeptactilempc.


Title: 3D Printed Soft Pneumatic Actuators with Intent Sensing for Hand Rehabilitative Exoskeletons*
Abstract: Loss of functional motor skills are common and often require patients to undergo rehabilitation so that they have a chance at motor recovery. Advancement in technology has seen to a rise in the use of robotic technology in conducting rehabilitative exercises that are traditionally carried out by physiotherapists. In recent years, soft robotic exoskeletons, using pneumatic-based actuation in particular, have gained much interest due to their compliant characteristics and safe operating conditions. In order to carry out complex task-based rehabilitative exercises, these soft pneumatic actuators must ideally be able to move with multiple degrees of freedom or minimally, in a bidirectional motion. Majority of the research covering soft actuators can only achieve finger flexion with some providing passive finger extension. Non-invasive intent detection in the control of these exoskeletons is also lacking in sensing both finger flexion and extension. In this paper we present our work on a fold-based bidirectional 3D printed intent-sensing soft pneumatic actuator (ISPA) that can achieve bidirectional motion and provide intent detection for finger flexion and extension for application in upper limb rehabilitative exoskeletons.


Title: Gaze-based, Context-aware Robotic System for Assisted Reaching and Grasping
Abstract: Assistive robotic systems endeavour to support those with movement disabilities, enabling them to move again and regain functionality. Main issue with these systems is the complexity of their low-level control, and how to translate this to simpler, higher level commands that are easy and intuitive for a human user to interact with. We have created a multi-modal system, consisting of different sensing, decision making and actuating modalities, leading to intuitive, human-in-the-loop assistive robotics. The system takes its cue from the user's gaze, to decode their intentions and implement low-level motion actions to achieve high-level tasks. This results in the user simply having to look at the objects of interest, for the robotic system to assist them in reaching for those objects, grasping them, and using them to interact with other objects. We present our method for 3D gaze estimation, and grammars-based implementation of sequences of action with the robotic system. The 3D gaze estimation is evaluated with 8 subjects, showing an overall accuracy of 4.68\pm 0.14cm. The full system is tested with 5 subjects, showing successful implementation of 100% of reach to gaze point actions and full implementation of pick and place tasks in 96%, and pick and pour tasks in 76% of cases. Finally we present a discussion on our results and what future work is needed to improve the system.


Title: Ways to Learn a Therapist’s Patient-specific Intervention: Robotics-vs Telerobotics-mediated Hands-on Teaching
Abstract: Due to the limitations of therapists time and healthcare resources to cover the increasing demand for rehabilitation services, robot-assisted rehabilitation is becoming an appealing, powerful and economical solution. In our previous research, a solution that combines Learning from Demonstration (LfD) and robotic rehabilitation to save the therapists time and reduce the therapy costs was proposed. In this paper we compare two modalities, Robot-and Telerobotic-Mediated Kinesthetic Teaching (RMKT and TMKT), for implementing LfD in robotic rehabilitation. Our results show that behaviors demonstrated in both modalities are able to be imitated accurately, but demonstrations in TMKT have less repeatability.


Title: A Four-magnet System for 2D Wireless Open-Loop Control of Microrobots
Abstract: This paper presents a novel permanent magnets based actuator capable of injecting and 2D wireless control the motion of an untethered microrobot. The actuator is obtained with a simple, but an effective arrangement of four permanent magnets. Its novelty is that it creates local maxima of the magnetic field magnitude in a planar workspace. This results in a convergence point for magnetic microrobots that are in its influence zone. Trapping microrobots in the local maxima makes their open-loop guidance possible, even in presence of reasonable perturbations. Actually, open-loop control is the only way to achieve some drug delivery when there are no sensors to provide us a feedback on the microrobot's positions. With the proposed actuator, the workspace is reduced, the movement is simplified and the actuator orientation is not needed anymore. Experimental results are provided in the paper to show the soundness of the proposed actuator design.


Title: Nitinol living hinges for millimeter-sized robots and medical devices
Abstract: A hybrid manufacturing process combining abrasive jet and laser micromaching enables the creation of living hinges in nitinol that retain the superelastic properties of the bulk material. The former selectively etches through the thickness of a workpiece and the latter defines the part's final geometry. Because the majority of the material removal is done with the room-temperature mechanical etching procedure, thermal damage to the part is minimized. Processing parameters to achieve desired geometries are described, a bending stiffness model for the living hinges is provided, and validation experiments are presented. Lastly, to demonstrate the usefulness of these components to millimeter-sized robotic systems and medical devices, we show their integration in two prototype devices: an endoscopic camera wrist and a simple laser beam steering system.


Title: Tetherless Mobile Micro-Surgical Scissors Using Magnetic Actuation
Abstract: Current minimally-invasive surgical tools suffer from lack of scalability and restricted access to some surgical sites using a laparoscopic probe. This paper introduces a proof-of-concept prototype of the first completely wireless surgical scissors capable of dexterous motion and cutting in a remote environment as a mobile microrobotic device. The 15 mm untethered surgical scissors are custom made from sharpened titanium sheets with a magnet on each blade for actuating force and control. A super-elastic nitinol wire acts as a restoring spring and results in a simple design with no pin joint which is difficult to fabricate at small sizes. To actuate and control the scissors, a 3D magnetic coil system is used here for testing and demonstration. An external magnetic flux density of 20 mT can be generated using the coils and is used for cutting as well as orienting, moving and closing the scissors. In this first prototype setup, the scissors can generate up to 75 mN of cutting force, and we demonstrate the cutting of agar. As a proof of concept demonstration of the potential use of the scissors as a completely untethered surgical tool, we robotically maneuver the scissors to a target location in a confined environment where they cut through agar and return to their initial position.


Title: A Large-Deflection FBG Bending Sensor for SMA Bending Modules for Steerable Surgical Robots
Abstract: This paper presents the development of a fiber Bragg grating (FBG) bending sensor for shape memory alloy (SMA) bending modules. Due to the small form factor, low cost, and large-deflection capability, SMA bending modules can be used to construct disposable surgical robots for a variety of minimally invasive procedures. To realize a closed-loop control of SMA bending modules, an intrinsic bending sensor is imperative. Due to the lack of bending sensors for SMA bending modules, we have developed an FBG bending sensor by integrating FBG fibers with a superelastic substrate using flexible adhesive. Since the substrate is ultra-thin and adhesive is flexible, the sensor has low stiffness and can measure large curvatures. Additionally, due to the orthogonal arrangement of the sensor/actuator assembly, the influence of temperature variation caused by SMA actuation can be compensated. The working principle of the developed sensor was modeled followed by simulations. After experimentally evaluating the developed model, the sensor was integrated with an SMA bending module and cyclically bi-directionally deflected. The experimental results proved the relatively high measurement accuracy, high repeatability, and large measurable curvatures of the sensor, although hysteresis was observed due to friction.


Title: Towards Learning Abstract Representations for Locomotion Planning in High-dimensional State Spaces
Abstract: Ground robots which are able to navigate a variety of terrains are needed in many domains. One of the key aspects is the capability to adapt to the ground structure, which can be realized through movable body parts coming along with additional degrees of freedom (DoF). However, planning respective locomotion is challenging since suitable representations result in large state spaces. Employing an additional abstract representation-which is coarser, lower-dimensional, and semantically enriched-can support the planning. While a desired robot representation and action set of such an abstract representation can be easily defined, the cost function requires large tuning efforts. We propose a method to represent the cost function as a CNN. Training of the network is done on generated artificial data, while it generalizes well to the abstraction of real world scenes. We further apply our method to the problem of search-based planning of hybrid driving-stepping locomotion. The abstract representation is used as a powerful informed heuristic which accelerates planning by multiple orders of magnitude.


Title: A Scalable Framework For Real-Time Multi-Robot, Multi-Human Collision Avoidance
Abstract: Robust motion planning is a well-studied problem in the robotics literature, yet current algorithms struggle to operate scalably and safely in the presence of other moving agents, such as humans. This paper introduces a novel framework for robot navigation that accounts for high-order system dynamics and maintains safety in the presence of external disturbances, other robots, and humans. Our approach precomputes a tracking error margin for each robot, generates confidence-aware human motion predictions, and coordinates multiple robots with a sequential priority ordering, effectively enabling scalable safe trajectory planning and execution. We demonstrate our approach in hardware with two robots and two humans, and showcase scalability in a larger simulation.


Title: Lazy Evaluation of Goal Specifications Guided by Motion Planning
Abstract: Nowadays robotic systems are expected to share workspaces and collaborate with humans. In such collaborative environments, an important challenge is to ground or establish the correct semantic interpretation of a human request. Once such an interpretation is available, the request must be translated into robot motion commands in order to complete the desired task. It is not unusual that a human request cannot be grounded to a unique interpretation, thus leading to an ambiguous request. A simple example is to ask a robot to “put a cup on the table,” when there are multiple cups available. In order to deal with this kind of ambiguous request, we propose a delayed or lazy variable grounding. The focus of this paper is a motion planning algorithm that, given goal regions that represent different valid groundings, lazily finds a feasible path to any one valid grounding. This algorithm includes a reward-penalty strategy, which attempts to prioritize those goal regions that seem more promising to provide a solution. We validate our approach by solving requests with multiple valid alternatives in both simulation and real-world experiments.


Title: Reconfigurable Motion Planning and Control in Obstacle Cluttered Environments under Timed Temporal Tasks
Abstract: This work addresses the problem of robot navigation under timed temporal specifications in workspaces cluttered with obstacles. We propose a hybrid control strategy that guarantees the accomplishment of a high-level specification expressed as a timed temporal logic formula, while preserving safety (i.e., obstacle avoidance) of the system. In particular, we utilize a motion controller that achieves safe navigation inside the workspace in predetermined time, thus allowing us to abstract the motion of the agent as a finite timed transition system among certain regions of interest. Next, we employ standard formal verification and convex optimization techniques to derive high-level timed plans that satisfy the agent's specifications. A simulation study illustrates and clarifies the proposed scheme.


Title: Door opening and traversal with an industrial cartesian impedance controlled mobile robot
Abstract: This paper presents a holistic approach for door opening with a cartesian impedance controlled mobile robot, a KUICA KMR iiwa. Based on a given map of the environment, the robot autonomously detects the door handle, opens doors and traverses doorways without knowledge of a door model or the door's geometry. The door handle detection uses a convolutional neural network (CNN)-based architecture to obtain the handle's bounding box in a RGB image that works robustly for various handle shapes and colors. We achieve a detection rate of 100% for an evaluation set of 38 different door handles, by always selecting for highest confidence score. Registered depth data segmentation defines the door plane to construct a handle coordinate frame. We introduce a control structure based on the task frame formalism that uses the handle frame for reference in an outer loop for the manipulator's impedance controller. It runs in soft real-time on an external computer with approximately 20 Hz since access to inner controller loops is not available for the KMR iiwa. With the approach proposed in this paper, the robot successfully opened and traversed for 22 out of 25 trials at five different doors.


Title: Neural Network Pile Loading Controller Trained by Demonstration
Abstract: This paper presents the development and testing of end-to-end Neural Network (NN) controllers for automated pile loading with a robotic wheel loader. NNs were trained using the Learning from Demonstration approach, i.e. by first recording sensor and control signals during manually-driven pile loading actions. Training made use of three input signals: boom angle, bucket angle and hydrostatic driving pressure; and three output signals: boom control, bucket control and the gas command. Most testing was conducted using NNs with 5 neurons in a single hidden layer, which were able to fill the bucket reasonably well. Qualitative comparisons were made to ascertain how the amount of training data and number of hidden neurons affects bucket filling performance, for NNs trained using both the Levenberg-Marquardt and Bayesian Regularization backpropagation algorithms. Different NNs trained with the same data were also compared. An additional pile transfer experiment compared the performance of an NN controller with a heuristic automated controller and manual human control. By estimating the total volume of material transferred using 3D laser scans, human control was found to have the highest performance, though the NN outperformed the heuristic controller. This indicated that end-to-end NN control trained by demonstration could offer improvement over current heuristic methods for automated pile loading.


Title: Dynamic Manipulation of Gear Ratio and Ride Height for a Novel Compliant Wheel using Pneumatic Actuators
Abstract: This paper proposes a novel configurable wheel that exhibits desired properties of varied radius wheels. Positional manipulation of the centre hub is proposed and tested to achieve these desired characteristics of `virtual' wheels in a physical system. The centre hub is manipulated via the use of pneumatic actuators mounted to and constricted by the outer rim of the wheel, which allows for fast and accurate control to enable the vehicle ride height and gear ratio to be adjusted continuously and be maintained during the wheels' full rotation. Experiments are presented, validating this ability of the system. We envision uses for this system to extend from off-road robotics to space exploration as these wheels exhibit novel characteristics not demonstrated by other platforms.


Title: Turn-minimizing multirobot coverage
Abstract: Multirobot coverage is the problem of planning paths for several identical robots such that the combined regions traced out by the robots completely cover their environment. We consider the problem of multirobot coverage with the objective of minimizing the mission time, which depends on the number of turns taken by the robots. To solve this problem, we first partition the environment into ranks which are long thin rectangles the width of the robot's coverage tool. Our novel partitioning heuristic produces a set of ranks which minimizes the number of turns. Next, we solve a variant of the multiple travelling salesperson problem (m-TSP) on the set of ranks to minimize the robots' mission time. The resulting coverage plan is guaranteed to cover the entire environment. We present coverage plans for a robotic vacuum using real maps of 25 indoor environments and compare the solutions to paths planned without the objective of minimizing turns. Turn minimization reduced the number of turns by 6.7% and coverage time by 3.8% on average for teams of 1-5 robots.


Title: Efficient Kinodynamic Multi-Robot Replanning in Known Workspaces
Abstract: In this work, we consider the problem of online centralized kinodynamic multi-robot replanning (from potentially non-stationary initial states) and coordination in known and cluttered workspaces. Offline state lattice reachability analysis is leveraged to decouple the planning problem into two sequential graph searches-one in the explicit geometric graph of the environment and the other in the graph of the higher-order derivatives of the robot's state-in a manner such that the intermediate vertices of a safe set of geometric paths are guaranteed to have a feasible assignment of higher-order derivatives. Without additional iterative refinement procedures, the resulting time parameterized polynomial trajectories are dynamically feasible and collision-free. Planning results with up to 20 robots in two and three dimensional workspaces suggest the suitability of the proposed approach for multi-robot replanning in known environments.


Title: Cannot avoid penalty? Let’s minimize
Abstract: Multi-robot systems are deployed in a warehouse to automate the process of storing and retrieving objects in and out of the warehouse. The efficiency of the system largely depends on how the tasks are allocated to the robots. Though there exists a number of techniques that can perform multi-robot task allocation quite efficiently, they hardly consider deadline for task completion while assigning tasks to the robots. A careful allocation is of paramount importance when there is an associated penalty with each of the tasks if it is not completed within a stipulated time. In this work, we develop an algorithm, called Minimum Penalty Scheduling (MPS) that allocates tasks among a group of robots with the goal that the overall penalty of executing all the tasks can be minimized. Our algorithm provides a robust, scalable, and near-optimal real-time task schedule. By comparing with the state-of-the-art algorithm, we show that MPS attracts up to 62.5% less penalty when a significant number of tasks are bound to miss the deadline. Additionally, MPS is also suitable for real-time multi-processor scheduling since it schedules a higher number of tasks within their deadline.


Title: Mixed-Granularity Human-Swarm Interaction
Abstract: We present an augmented reality human-swarm interface that combines two modalities of interaction: environment-oriented and robot-oriented. The environment-oriented modality allows the user to modify the environment (either virtual or physical) to indicate a goal to attain for the robot swarm. The robot-oriented modality makes it possible to select individual robots to reassign them to other tasks to increase performance or remedy failures. Previous research has concluded that environment-oriented interaction might prove more difficult to grasp for untrained users. In this paper, we report a user study which indicates that, at least in collective transport, environment-oriented interaction is more effective than purely robot-oriented interaction, and that the two combined achieve remarkable efficacy.


Title: Flexible collaborative transportation by a team of rotorcraft
Abstract: We propose a combined method for the collaborative transportation of a suspended payload by a team of rotorcraft. A recent distance-based formation-motion control algorithm based on assigning distance disagreements among robots generates the acceleration signals to be tracked by the vehicles. In particular, the proposed method does not need global positions nor tracking prescribed trajectories for the motion of the members of the team. The acceleration signals are followed accurately by an Incremental Nonlinear Dynamic Inversion controller designed for rotorcraft that measures and resists the tensions from the payload. Our approach allows us to analyze the involved accelerations and forces in the system so that we can calculate the worst case conditions explicitly to guarantee a nominal performance, provided that the payload starts at rest in the 2D centroid of the formation, and it is not under significant disturbances. For example, we can calculate the maximum safe deformation of the team with respect to its desired shape. We demonstrate our method with a team of four rotorcraft carrying a suspended object two times heavier than the maximum payload for an individual. Last but not least, our proposed algorithm is available for the community in the open-source autopilot Paparazzi.


Title: Dynamically-consistent Generalized Hierarchical Control
Abstract: Tracking multiple prioritized tasks simultaneously with redundant robots have been investigated extensively over the last decades. Recent research focuses on combining advantages from both classical soft and strict prioritization schemes which is non-trivial. Among the proposed methods to tackle this issue, Generalized Hierarchical Control (GHC) seems to have a reasonable performance, however, it does not include a weighting matrix in the computation of the nullspace projection operator and hence cannot construct dynamically-consistent stack-of-tasks hierarchies as a special case. We extend GHC by adding dynamic-consistency to the control scheme and refer to it as DynGHC. The extension is also advantageous when choosing non-strict priorities because inertia coupling between tasks is reduced. DynGHC allows to smoothly rearrange priorities which is important for robots acting in dynamically changing contexts. Comparative simulations with a 4 DOF planar manipulator and a KUKA LWR validate our approach. Matlab and C++ source code is made available.


Title: Robotic Joint Control System based on Analogue Spiking Neural Networks and SMA Actuators
Abstract: The control of human hands and fingers represents one of the most complex functions of the motor cortex. In order to implement anthropomorphic hands that mimic accurately the motion ability of the human hands, the basic biological mechanisms of the natural muscle control should be modelled. This paper presents the design of a significantly improved control system based on analogue neural networks that can be used to replicate the biological control mechanisms of the natural muscles. In order to demonstrate the proposed concept, experiments were performed using a single-joint robotic arm that can be flexed as the human elbow by an artificial muscle connected as the biceps. In order to bring more biological plausibility to the robotic arm, the artificial muscle is implemented using a shape memory alloy wire which actuates by contraction as the natural muscles. Moreover, the contraction force of the actuator wire is directly determined by the spiking frequency of the electronic neurons as the motor neurons determines the contraction strength of the natural muscles. The experimental results show that using excitatory neurons and several inhibitory neurons unevenly distributed on the inputs of the artificial motor neurons that drive the shape memory alloy actuator, the spiking neural network is able to control with high precision the rotation of the arm mobile lever to random target positions even if the arm is slightly loaded. These results validate the control method of the robotic arm junction showing that the analogue spiking neural networks represents a very good alternative to control the contraction of SMA actuators in a biological plausible manner.


Title: Model Reference Adaptive Control of a Two-Wheeled Mobile Robot
Abstract: The inverted pendulum is by nature a dynamically unstable system and may be subjected to severe disturbances due to its environmental or loading conditions. This paper formulates a design for a nonlinear controller to balance a two-wheeled mobile robot (TWMR) based on Model Reference Adaptive Control. The proposed solution overcomes the limitations of control systems that rely on fixed parameter controllers. Given the nonlinear single-input multi-output (SIMO) nature of the TWMR platform, the proposed adaptive controller can handle non-linearities without the need for linearization, and inherently dealing with SIMO systems. By studying the influence that hidden dynamic effects can cause, we show the preference of the proposed controller over other designs. Simulation results demonstrate the applicability and efficiency of our proposed design, and experimental results validate the effectiveness of the proposed scheme in guaranteeing asymptotic output tracking, even in the presence of unknown disturbances.


Title: A Robust Tracking Controller for Robot Manipulators: Embedding Internal Model of Disturbances
Abstract: This paper presents a robust controller for uncertain robot manipulators subject to disturbances which are composed of sinusoids. The controller employs the disturbance observer based controller which can effectively estimate and compensate the effect of plant uncertainties and the disturbances. Assuming that the frequencies of sinusoids are known, we embed the internal model of disturbances into the proposed controller so that the design parameters of the controller can be chosen without using the magnitude of disturbance or its time derivative. A rigorous stability analysis shows that the closed-loop system under the proposed controller behaves like the nominal closed-loop system free of disturbances. Simulation results for a 2-DOF manipulator show the effectiveness of the proposed controller.


Title: Receding horizon estimation and control with structured noise blocking for mobile robot slip compensation
Abstract: The control of field robots in varying and uncertain terrain conditions presents a challenge for autonomous navigation. Online estimation of the wheel-terrain slip characteristics is essential for generating the accurate control predictions necessary for tracking trajectories in off-road environments. Receding horizon estimation (RHE) provides a powerful framework for constrained estimation, and when combined with receding horizon control (RHC), yields an adaptive optimisation-based control method. Presently, such methods assume slip to be constant over the estimation horizon, while our proposed structured blocking approach relaxes this assumption, resulting in improved state and parameter estimation. We demonstrate and compare the performance of this method in simulation, and propose an overlapping-block strategy to ameliorate some of the limitations encountered in applying noise-blocking in a receding horizon estimation and control (RHEC) context.


Title: Decoupled Control of Position and / or Force of Tendon Driven Fingers
Abstract: In contrast to underactuated robotic hands the DLR AWIWI II hand of the David robot is fully controllable because each finger with 4 joints is actuated by 6 or 8 tendons respectively. For such fingers all joint angles (generalized positions) or joint torques (generalized forces) can be controlled independently. Usually, the specifications in joint space are converted to desired tendon forces or motor torques, which are regulated by an inner loop impedance controller. However, this conversion typically exhibits couplings between the components of the joint angle vector or the joint torque vector respectively, which arise when using the well known equations. Therefore the usual force control and position control schemes are reviewed and a generic computation of the desired tendon forces is presented. This is also done for the control of the Cartesian position and force at the finger endpoint. Thus the main contribution of the paper is the inhibition of couplings in joint space or at the Cartesian endpoint. This is demonstrated in simulations of the index finger of the DLR David hand.


Title: Learned Map Prediction for Enhanced Mobile Robot Exploration
Abstract: We demonstrate an autonomous ground robot capable of exploring unknown indoor environments for reconstructing their 2D maps. This problem has been traditionally tackled by geometric heuristics and information theory. More recently, deep learning and reinforcement learning based approaches have been proposed to learn exploration behavior in an end-to-end manner. We present a method that combines the strengths of these different approaches. Specifically, we employ a state-of-the-art generative neural network to predict unknown regions of a partially explored map, and use the prediction to enhance the exploration in an information-theoretic manner. We evaluate our system in simulation using floor plans of real buildings. We also present comparisons with traditional methods which demonstrate the advantage of our method in terms of exploration efficiency. We retain an advantage over end-to-end learned exploration methods in that the robot's behavior is easily explicable in terms of the predicted map.


Title: Exploiting Bistability for High Force Density Reflexive Gripping
Abstract: Robotic grasping can enable mobile vehicles to physically interact with the environment for delivery, repositioning, or landing. However, the requirements for grippers on mobile vehicles differ substantially from those used for conventional manipulation. Specifically, grippers for dynamic mobile robots should be capable of rapid activation, high force density, low power consumption, and minimal computation. In this work, we present a biologically-inspired robotic gripper designed specifically for mobile platforms. This design exploits a bistable shell to achieve “reflexive” activation based on contact with the environment. The mechanism can close its grasp within 0. 12s without any sensing or control. Electrical input power is not required for grasping or holding load. The reflexive gripper utilizes a novel pneumatic design to open its grasp with low power, and the gripper can carry slung loads up to 28 times its weight. This new mechanism, including the kinematics, static behavior, control structure, and fabrication, is described in detail. A proof of concept prototype is designed, built, and tested. Experimental results are used to characterize performance and demonstrate the potential of these methods.


Title: Compliant Bistable Gripper for Aerial Perching and Grasping
Abstract: Small aerial robots usually face a common challenge: they can only fly for a short time due to their limited onboard energy supply. To tackle this issue, one promising solution is to endow flying robots with perching capability so that they can perch or land on walls, trees, or power lines to rest or recharge. Such perching capability is especially useful for monitoring-related tasks since the robot can maintain a desired height for monitoring without flying. One of the major challenges for perching is to design a light-weight and energy-efficient perching mechanism. In this paper, we present a 3D-printed compliant bistable gripper which is easy to close, stable to hold, and easy to adjust for a palm-size quadcopter to perch on cylindrical objects. If installed on the bottom of aerial robots, it can also be used for aerial grasping. The gripper can be directly activated by the impact force during contact to switch from open state to closed state. It can also hold the quadcopter safely since the required force to open the gripper is larger than the robot weight. We analyze the required forces for closing and opening to provide design guidelines for the mechanism. Experimental results show that the designed gripper can successful make the quadcopter perch on cylinders as well as grasp objects.


Title: Learning Robust Manipulation Strategies with Multimodal State Transition Models and Recovery Heuristics
Abstract: Robots are prone to making mistakes when performing manipulation tasks in unstructured environments. Robust policies are thus needed to not only avoid mistakes but also to recover from them. We propose a framework for increasing the robustness of contact-based manipulations by modeling the task structure and optimizing a policy for selecting skills and recovery skills. A multimodal state transition model is acquired based on the contact dynamics of the task and the observed transitions. A policy is then learned from the model using reinforcement learning. The policy is incrementally improved by expanding the action space by generating recovery skills with a heuristic. Evaluations on three simulated manipulation tasks demonstrate the effectiveness of the framework. The robot was able to complete the tasks despite multiple contact state changes and errors encountered, increasing the success rate averaged across the tasks from 70.0% to 95.3%.


Title: Adaptive Critic Based Optimal Kinematic Control for a Robot Manipulator
Abstract: This paper is concerned with the optimal kinematic control of a robot manipulator where the robot end effector position follows a task space trajectory. The joints are actuated with the desired velocity profile to achieve this task. This problem has been solved using a single network adaptive critic (SNAC) by expressing the forward kinematics as input affine system. Usually in SNAC, the critic weights are updated using back propagation algorithm while little attention is given to convergence to the optimal cost. In this paper, we propose a critic weight update law that ensures convergence to the desired optimal cost while guaranteeing the stability of the closed loop kinematic control. In kinematic control, the robot is required to reach a specific target position. This has been solved as an optimal regulation problem in the context of SNAC based kinematic control. When the robot is required to follow a time varying task space trajectory, then the kinematic control has been framed as an optimal tracking problem. For tracking, an augmented system consisting of tracking error and reference trajectory is constructed and the optimal control policy is derived using SNAC framework. The stability and performance of the system under the proposed novel weight tuning law is guaranteed using Lyapunov approach. The proposed kinematic control scheme has been validated in simulations and experimentally executed using a real six degrees of freedom (DOF) Universal Robot (UR) 10 manipulator.


Title: Manipulability Optimization Control of a Serial Redundant Robot for Robot-assisted Minimally Invasive Surgery
Abstract: This paper proposes a manipulability optimization control of a 7-DoF robot manipulator for Robot-Assisted Minimally Invasive Surgery (RAMIS), which at the same time guarantees a Remote Center of Motion (RCM). The first degree of redundancy of the manipulator is used to achieve an RCM constraint, the second one is adopted for manipulability optimization. A hierarchical operational space formulation is introduced to integrate all the control components, including a Cartesian compliance control involving the main surgical task, a first null-space controller for the RCM constraint, and a second null-space controller for manipulability optimization. Experiments with virtual surgical tasks, in an augmented reality environment, were performed to validate the proposed control strategy using the KUKA LWR 4 +. The results demonstrate that end-effector accuracy and RCM constraint can be guaranteed, along with improving the manipulability of the surgical tip.


Title: Adapting Everyday Manipulation Skills to Varied Scenarios
Abstract: We address the problem of executing tool-using manipulation skills in scenarios where the objects to be used may vary. We assume that point clouds of the tool and target object can be obtained, but no interpretation or further knowledge about these objects is provided. The system must interpret the point clouds and decide how to use the tool to complete a manipulation task with a target object; this means it must adjust motion trajectories appropriately to complete the task. We tackle three everyday manipulations: scraping material from a tool into a container, cutting, and scooping from a container. Our solution encodes these manipulation skills in a generic way, with parameters that can be filled in at run-time via queries to a robot perception module; the perception module abstracts the functional parts of the tool and extracts key parameters that are needed for the task. The approach is evaluated in simulation and with selected examples on a PR2 robot.


Title: Closed-loop MPC with Dense Visual SLAM - Stability through Reactive Stepping
Abstract: Walking gaits generated using Model Predictive Control (MPC) is widely used due to its capability to handle several constraints that characterize humanoid locomotion. The use of simplified models such as the Linear Inverted Pendulum allows to perform computations in real-time, giving the robot the fundamental capacity to replan its motion to follow external inputs (e.g. reference velocity, footstep plans). However, usually the MPC does not take into account the current state of the robot when computing the reference motion, losing the ability to react to external disturbances. In this paper a closed-loop MPC scheme is proposed to estimate the robot's real state through Simultaneous Localization and Mapping (SLAM) and proprioceptive sensors (force/torque). With the proposed control scheme it is shown that the robot is able to react to external disturbances (push), by stepping to recover from the loss of balance. Moreover the localization allows the robot to navigate to target positions in the environment without being affected by the drift generated by imperfect open-loop control execution. We validate the proposed scheme through two different experiments with a HRP-4 humanoid robot.


Title: Feedback motion planning of legged robots by composing orbital Lyapunov functions using rapidly-exploring random trees
Abstract: We present a sampling-based framework for feedback motion planning of legged robots. Our framework is based on switching between limit cycles at a fixed instance of motion, the Poincaré section (e.g., apex or touchdown), by finding overlaps between the regions of attraction (ROA) of two limit cycles. First, we assume a candidate orbital Lyapunov function (OLF) and define a ROA at the Poincaré section. Next, we solve multiple trajectory optimization problems, one for each sampled initial condition on the ROA to minimize an energy metric and subject to the exponential convergence of the OLF between two steps. The result is a table of control actions and the corresponding initial conditions at the Poincaré section. Then we develop a control policy for each control action as a function of the initial condition using deep learning neural networks. The control policy is validated by testing on initial conditions sampled on ROA of randomly chosen limit cycles. Finally, the rapidly-exploring random tree algorithm is adopted to plan transitions between the limit cycles using the ROAs. The approach is demonstrated on a hopper model to achieve velocity and height transitions between steps.


Title: Online Walking Pattern Generation for Humanoid Robot with Compliant Motion Control
Abstract: The compliant motion of humanoid robots is one of their most important characteristics for interacting with humans and various environments in the real world. During walking, compliant motion ensures stable contact between the foot and ground, but walking stability is degraded by position tracking performance and unknown disturbances. To address the issue of instability of humanoid robot walking with compliant motion control, this paper proposes a model for real-time walking pattern generation considering the motion control performance of a robot. The dynamic model of a robot with a motion controller is described as a second-order system approximating position tracking performance with a linear inverted pendulum model to determine the relationship between the zero-moment point and center of mass (CoM). The CoM trajectory is calculated using preview control based on the dynamics model and current state of the robot. Therefore, even if the robot has the low tracking performance due to compliant motion control, the walking stability can be ensured. The proposed method was implemented on our humanoid robot, DYROS-JET, and its performance was demonstrated through improved stability during walking.


Title: A Kalman Filter-Based Algorithm for Simultaneous Time Synchronization and Localization in UWB Networks
Abstract: The ability to accurately measure signal time-of-flight between ultra-wideband (UWB) wireless communication transceivers, even in multipath environments, makes this technology ideally suited to develop ranging-based positioning systems, especially for indoor applications where GPS signals are not available. In recent years, low-cost commercial UWB transceivers have become more easily available and increasingly used to develop custom robot positioning systems. In this paper, we focus in particular on positioning techniques requiring the synchronization of base stations such as Time of Arrival (TOA) and Time Difference of Arrival (TDOA). We present a protocol based on Kalman filtering for simultaneous synchronization of multiple UWB base stations and positioning of an arbitrary number of passive UWB receivers. We illustrate experimentally using our protocol and an EKF-based navigation system design the level of accuracy achievable with small low-power UWB modules for mobile robot positioning. We discuss in details measurement errors and system tuning issues applicable to popular commercial UWB transceivers.


Title: eRTIS: A Fully Embedded Real Time 3D Imaging Sonar Sensor for Robotic Applications
Abstract: Many popular advanced sonar systems provide accurate and reliable measurements containing crucial info needed by robotic applications such as range, bearing and reflection strength of the objects in the field of view. While these sensor systems provide these crucial pieces of information accurately, they are often limited by a lack of processing power and/or size which leads to them needing an external computing device to process all the information generated by the microphone array on the sensor. In this paper we present two versions of a novel fully embedded 3D sonar sensor which have different sensing architectures which enable 3D perception for robotic application in harsh conditions using ultrasound at low cost. Experimental results taken from an office environment will show the 3D localization capabilities and performance of the sensor, showing the sensor has a large field-of-view (FoV) with accurate 3D localization combined with real-time capabilities.


Title: Analysis of Robust Functions for Registration Algorithms
Abstract: Registration accuracy is influenced by the presence of outliers and numerous robust solutions have been developed over the years to mitigate their effect. However, without a large scale comparison of solutions to filter outliers, it is becoming tedious to select an appropriate algorithm for a given application. This paper presents a comprehensive analysis of the effects of outlier filters on the Iterative Closest Point (ICP) algorithm aimed at a mobile robotic application. Fourteen of the most common outlier filters (such as M-estimators) have been tested in different types of environments, for a total of more than two million registrations. Furthermore, the influence of tuning parameters has been thoroughly explored. The experimental results show that most outlier filters have a similar performance if they are correctly tuned. Nonetheless, filters such as Var. Trim., Cauchy, and Cauchy MAD are more stable against different environment types. Interestingly, the simple norm L1 produces comparable accuracy, while being parameterless.


Title: CoLo: A Performance Evaluation System for Multi-robot Cooperative Localization Algorithms
Abstract: This paper describes CoLo - a performance evaluation system for two-dimensional cooperative localization algorithms. The system consists of a physical experiment (CoLo-PE) for data collection and a software analysis tool (CoLo-AT) using real-world datasets to evaluate the performances of users' cooperative localization algorithms. This paper details the design and operation of the physical experiment (CoLo-PE) and discusses the functionalities and uses of the software analysis tool (CoLo-AT) for algorithm evaluation. Specifically, CoLo allows researchers to conveniently add their cooperative localization algorithms and test them extensively on different real-world datasets with various settings. CoLo is available at https://git.uclalemur.com/billyskc/CoLo.


Title: A cane-based low cost sensor to implement attention mechanisms in telecare robots
Abstract: Telepresence robots have been recently used for Comprehensive Geriatric Assessment (CGA). Since the robot can not track a person continuously, there are several strategies to decide when to check them, from cyclic checks to simple requests from users and/or caregivers. In order to adapt to the user needs and condition, it is preferable to perform CGA as soon as regularities appear. However, this requires detection of potential issues in users to offer immediate service. In this work we propose a new low cost force sensor system to detect user's condition and attract attention of CGA robots, so they can perform a full examination on a need basis. The main advantages of this system are: i) it can be attached to any standard commercial cane; ii) its power consumption is very reduced; and iii) it provides continuous information as long as the user walks. It has been tested with several elderly volunteers in care facilities. Results have proven that the sensor readings are indeed correlated with the users' condition.


Title: A Deployable Soft Robotic Arm with Stiffness Modulation for Assistive Living Applications
Abstract: This paper presents a three-tendon actuated continuum robot with an origami backbone to assist the elderly and physically impaired individuals in performing activities of daily living. The proposed design solution is an inherently safe and cost-effective alternative to current assistive robots. The origami backbone based on a variation of the Yoshimura pattern provides controlled deployment of the robot and enables length variation (15 cm - 56 cm) in order to increase the reachable workspace. A pneumatic stiffness mechanism was implemented, increasing the weight bearing capabilities of the continuum robot to 500 g. This new stiffness modulation approach was assessed with the use of several testing rigs. Additionally, the robot is joypad controlled and is easily transportable due to its high packing efficiency of 73% and light weight of 1.3 kg for the main body (including the actuation system). For demonstration of usability studies, the robot was successfully tested at a simulated kitchen terminal and also performed pick and place tasks.


Title: Development of a Novel Gait Rehabilitation Device with Hip Interaction and a Single DOF Mechanism
Abstract: In this paper, a novel, low-cost lower extremity gait rehabilitation device using a single actuator is presented. The proposed device is based on a single DOF 8-bar Jansen mechanism, which was recently introduced as an efficient walking mechanism for legged robots. The mechanism is synthesized to generate the ankle trajectory during human gait relative to the hip, in terms of both position and time. Two mechanisms, one for each lower limb, are applied reciprocally and mechanically synchronized to guarantee symmetric gait. A custom designed seat-type weight support system is also introduced. It supports weight of the user and mechanisms, and also provides the required interaction while maintaining mobility at the hip. To accommodate different users, several parameters of the mechanism are adjustable. Ease of donning-doffing action, weight-bearing and possibility of unhindered arm swing have been considered to provide an effective and user-friendly training environment. A prototype is manufactured, and a pilot study with a healthy subject is conducted to demonstrate feasibility of the concept. Due to ease of control, cost-effectiveness and high intrinsic safety, the proposed system potentially offers a possible method of gait training.


Title: Differentially-Clutched Series Elastic Actuator for Robot-Aided Musculoskeletal Rehabilitation
Abstract: Series elastic actuators have proven to be an elegant response to the issue of safety around human-robot interaction. The compliant nature of series elastic actuators provides the potential to be applied in robot-aided rehabilitation for patients with upper and lower limb musculoskeletal injuries. This paper proposes a new series elastic actuator to be used in robot-aided musculoskeletal rehabilitation. The actuator is composed of a DC motor, a torsion spring, and a magnetic particle brake coupled to one common output shaft through a differential gear. The proposed topology focuses on three types of actuation modes most commonly used in rehabilitation, i.e., free motion, elastic, and assistive/resistive motion. A dynamic model of the actuator is presented and validated experimentally and the ability of the actuator to follow a reference torque is shown in different experimental scenarios.


Title: A Novel Robotic Suturing System for Flexible Endoscopic Surgery
Abstract: Perforations in flexible endoscopy are life-threatening. Defect closure or suturing in flexible endoscopy has long been a critical challenge due to the confined space of the access routes and surgical sites, high dexterity and force demands of suturing tasks, as well as critical size and strength requirements of wound closure. This paper introduces a novel robotic suturing system for flexible endoscopic surgery. This system features a flexible, through-the-scope, five-degree-of-freedom robotic suturing instrument. This instrument allows the surgeon to endoscopically manipulate a needle via a master console to create running stitches and knots in flexible endoscopy, which is not possible with existing devices. Successful ex-vivo trials were conducted inside porcine colons to show how surgical stitches and knots can be endoscopically created and secured in a completely new way. This new technology will change the way how surgeons close defects or perforations in flexible endoscopic surgery.


Title: A Noninvasive Approach to Recovering the Lost Force Feedback for a Robotic-Assisted Insertable Laparoscopic Surgical Camera
Abstract: Fully insertable laparoscopic cameras feature more locomotive flexibility in a larger workspace compared to conventional trocar-based laparoscopes and thus represent a promising future of minimally invasive surgery. These cameras are principally anchored and actuated by transabdominal magnetic coupling. Although several proof-of-concept prototypes have shown the technical feasibility in terms of camera actuation and laparoscopic imaging, none of them are getting close to clinical practice due to concerns about safety. One common problem lies in that the interaction force between the camera and the abdominal wall tissue is completely unknown and not controlled. The camera is being manipulated in an open loop which exposes the patient to a high risk of being injured. In this paper, a noninvasive real-time camera-tissue interaction force measurement approach for an insertable laparoscopic camera is proposed, implemented, and validated.Ex-vivo experiments using a simulated abdominal cavity have demonstrated the effectiveness of this approach during anchoring, translation, and rotation camera behaviors. Potential surgical impacts enabled by the force feedback have also been exemplified by a robotic-assisted camera control experiment using shared autonomy.


Title: Development of a Multi-level Stiffness Soft Robotic Module with Force Haptic Feedback for Endoscopic Applications*
Abstract: Despite the recent advances in soft endoscopes, they could not yet fully fulfill the requirements for minimally invasive and natural orifice transluminal endoscopic surgeries. Maneuverability, bendability, different structural stiffness required for different endoscopic surgical interventions, the space needed for surgical manipulators and patient's safety are amongst the main factors which can contribute to implementing the new soft robotics endoscope in practice. In this study, based on finite element analysis on an existing endoscopic segment, a new improved endoscopic module was developed. A novel approach for stiffening of the endoscopic module was proposed. The actuation and stiffening components were combined to introduce a multi-level stiffening mechanism to the endoscope, and also to provide a free lumen for manipulators. To increase patient's safety, a force sensing module was developed to estimate the magnitude and direction of the force from tissues to the endoscope. The developed endoscopic system was integrated to a haptic control system. The 3D kinematics control and haptic feedback control of the endoscopic module were validated.


Title: Feasibility Study of Robotic Needles with a Rotational Tip-Joint and Notch Patterns
Abstract: In this paper, we present the design of a steerable needle with proximal notch patterns for compliance and an embedded rotational tip joint for articulation. The device is fabricated by laser machining NiTi tube so that an inner working channel exists (to enable delivery of fluids, drugs or microtools) and no assembly is required for the joints. We formulate its model based on the classical Cosserat Rod theory. This is extended with incremental state prediction and a simple spring model for tissue reaction to integrate into a planning algorithm based on Dynamic Region RRT which efficiently explores the needle's state space. The planner was initialized with a target zone and arbitrary anatomical obstacles before running simulations which propagated incremental state changes at every step while adhering to constraints based on the physical system. Finally, we demonstrate the steering capability of the needle through insertion tests into a phantom.


Title: Autonomous Laparoscopic Robotic Suturing with a Novel Actuated Suturing Tool and 3D Endoscope
Abstract: Compared to open surgical techniques, laparoscopic surgical methods aim to reduce the collateral tissue damage and hence decrease the patient recovery time. However, constraints imposed by the laparoscopic surgery, i.e. the operation of surgical tools in limited spaces, turn simple surgical tasks such as suturing into time-consuming and inconsistent tasks for surgeons. In this paper, we develop an autonomous laparoscopic robotic suturing system. More specific, we expand our smart tissue anastomosis robot (STAR) by developing i) a new 3D imaging endoscope, ii) a novel actuated laparoscopic suturing tool, and iii) a suture planning strategy for the autonomous suturing. We experimentally test the accuracy and consistency of our developed system and compare it to sutures performed manually by surgeons. Our test results on suture pads indicate that STAR can reach 2.9 times better consistency in suture spacing compared to manual method and also eliminate suture repositioning and adjustments. Moreover, the consistency of suture bite sizes obtained by STAR matches with those obtained by manual suturing.


Title: Active Contraints for Tool-Shaft Collision Avoidance in Minimally Invasive Surgery
Abstract: Recent advances in teleoperation-based robotic-assisted Minimally Invasive Surgery (MIS) have made significant inroads in clinical adoption. However, such master-slave surgical systems create a physical separation between the surgeon and the patient. The concept of Active Constraints (ACs) provides guidance and sensory information to surgical robot operators in a form of haptic, visual or audible cues. This work proposes a novel ACs approach to avoid surgical tool-clashing and collision of the tool-shaft with delicate anatomy using elasto-plastic frictional force control. The presented framework is designed to reduce the occurence of direct coupling during electrocautery and to protect high-risk regions in Minimally Invasive Partial Nephrectomy (MIPN). Moreover, we combine aforementioned ACs methods and propose a solution when simultaneous penetration of both constraints occurs. The proposed methodology is implemented on the teleoperated da Vinci Surgical System using the da Vinci Research Kit (dVRK) and its performance is demonstrated through three types of user experiments. The experimental results show that the developed algorithms are of significant benefit in performing the tasks with ACs assistance.


Title: Energy Budget Transaction Protocol for Distributed Robotic Systems
Abstract: Passivity is a necessary condition for a system's stability, meaning that an energy generating system may readily become unstable. Energy-aware actuation can enforce passivity by monitoring the amount of energy that is exchanged with a system, while using an allocated energy budget to execute a task. Careful communication of the energy budgets is important to prevent accidental generation of energy. Therefore, this paper proposes an energy transaction protocol to communicate energy budgets in a distributed robotic system to guarantee that passivity is kept. Simulations are performed with a model of the protocol that is applied to a simulated unreliable communication channel. It is verified that the proposed protocol keeps passivity in the system, while a naive communication strategy either violates passivity or is unnecessarily dissipative.


Title: Tele-Echography using a Two-Layer Teleoperation Algorithm with Energy Scaling
Abstract: Performing ultrasound procedures from a remote site is a challenging task since both a stable behavior, for the safety of the patient, and a high-level of usability, to exploit the sonographer's expertise, need to be guaranteed. Furthermore, a teleoperation system that provides such requirements has to deal with communication delays as well. To address this issue, we use the two-layer algorithm: a passivity-based bilateral teleoperation architecture able to guarantee stability despite unknown and time-varying delay. Its flexibility allows to implement different kinds of control laws. In a Tele-Echography system, the slave manipulator has to apply significant forces needed by the procedure whereas the haptic device at the master side should be very light to avoid tiring the operator. Therefore, the energy needed by these two robots to perform their movements is very different and the energy injected into the system by the operator is often not sufficient to implement the desired action at the slave side. Methods to overcome this problem require to perfectly know the dynamical models of the robots. The solution proposed in this paper does not require such knowledge and is based on properly scaling the energy exchanged between the master and the slave side. We show the effectiveness of this approach in a real setup using a TOUCH haptic device and a WAM Barrett robot holding an ultrasound probe.


Title: EMG-Controlled Non-Anthropomorphic Hand Teleoperation Using a Continuous Teleoperation Subspace
Abstract: We present a method for EMG-driven teleoperation of non-anthropomorphic robot hands. EMG sensors are appealing as a wearable, inexpensive, and unobtrusive way to gather information about the teleoperator's hand pose. However, mapping from EMG signals to the pose space of a non-anthropomorphic hand presents multiple challenges. We present a method that first projects from forearm EMG into a subspace relevant to teleoperation. To increase robustness, we use a model which combines continuous and discrete predictors along different dimensions of this subspace. We then project from the teleoperation subspace into the pose space of the robot hand. Our method is effective and intuitive, as it enables novice users to teleoperate pick and place tasks faster and more robustly than state-of-the-art EMG teleoperation methods when applied to a non-anthropomorphic, multi-DOF robot hand.


Title: Motion Scaling Solutions for Improved Performance in High Delay Surgical Teleoperation
Abstract: Robotic teleoperation brings great potential for advances within the field of surgery. The ability of a surgeon to reach patient remotely opens exciting opportunities. Early experience with telerobotic surgery has been interesting, but the clinical feasibility remains out of reach, largely due to the deleterious effects of communication delays. Teleoperation tasks are significantly impacted by unavoidable signal latency, which directly results in slower operations, less precision in movements, and increased human errors. Introducing significant changes to the surgical workflow, for example by introducing semi-automation or self-correction, present too significant a technological and ethical burden for commercial surgical robotic systems to adopt. In this paper, we present three simple and intuitive motion scaling solutions to combat teleoperated robotic systems under delay and help improve operator accuracy. Motion scaling offers potentially improved user performance and reduction in errors with minimal change to the underlying teleoperation architecture. To validate the use of motion scaling as a performance enhancer in telesurgery, we conducted a user study with 17 participants, and our results show that the proposed solutions do indeed reduce the error rate when operating under high delay.


Title: Robust object grasping in clutter via singulation
Abstract: Grasping objects in a cluttered environment is challenging due to the lack of collision free grasp affordances. In such conditions, the target object touches or is covered by other objects in the scene, resulting in a failed grasp. To address this problem, we propose a strategy of singulating the object from its surrounding clutter, which consists of previously unseen objects, by means of lateral pushing movements. We employ reinforcement learning for obtaining optimal push policies given depth observations of the scene. The action-value function(Q-function) is approximated with a deep neural network. We train the robot in simulation and we demonstrate that the transfer of learned policies to the real environment is robust.


Title: Mechanical Search: Multi-Step Retrieval of a Target Object Occluded by Clutter
Abstract: When operating in unstructured environments such as warehouses, homes, and retail centers, robots are frequently required to interactively search for and retrieve specific objects from cluttered bins, shelves, or tables. Mechanical Search describes the class of tasks where the goal is to locate and extract a known target object. In this paper, we formalize Mechanical Search and study a version where distractor objects are heaped over the target object in a bin. The robot uses an RGBD perception system and control policies to iteratively select, parameterize, and perform one of 3 actions - push, suction, grasp - until the target object is extracted, or either a time limit is exceeded, or no high confidence push or grasp is available. We present a study of 5 algorithmic policies for mechanical search, with 15,000 simulated trials and 300 physical trials for heaps ranging from 10 to 20 objects. Results suggest that success can be achieved in this long-horizon task with algorithmic policies in over 95% of instances and that the number of actions required scales approximately linearly with the size of the heap. Code and supplementary material can be found at http://ai.stanford.edu/mech-search.


Title: Transferring Grasp Configurations using Active Learning and Local Replanning
Abstract: We present a new approach to transfer grasp configurations from prior example objects to novel objects. We assume the novel and example objects have the same topology and similar shapes. We perform 3D segmentation on these objects using geometric and semantic shape characteristics. We compute a grasp space for each part of the example object using active learning. We build bijective contact mapping between these model parts and compute the corresponding grasps for novel objects. Finally, we assemble the individual parts and use local replanning to adjust grasp configurations while maintaining its stability and physical constraints. Our approach is general, can handle all kind of objects represented using mesh or point cloud and a variety of robotic hands.


Title: Kinematically Redundant (6+3)-dof Hybrid Parallel Robot with Large orientational Workspace and Remotely Operated Gripper
Abstract: A novel 3-[R(RR-RRR)SR] kinematically redundant 6+3-degree-of-freedom (dof)spatial hybrid parallel robot with revolute actuators is proposed. The kinematic model is developed based on the constraint conditions of the robot. It is shown that the type II (parallel) singularities can be completely avoided, thereby greatly extending the orientational workspace. Mechanisms are then introduced to use the redundant degrees of freedom of the robot to operate a gripper with the robot actuators, which are mounted on or close to the base. A CAD model of the robot is shown and a computer animation is provided to demonstrate the resulting architecture, which has full 6-dof capabilities and a large orientational workspace.


Title: Modeling Variable Curvature Parallel Continuum Robots Using Euler Curves
Abstract: In this paper, we propose and investigate a new approach to modeling variable curvature continuum robot sections, based on Euler spirals. Euler spirals, also termed Clothoids, or Cornu spirals, are those curves in which the curvature increases linearly with their arc length. In this work, Euler spirals are applied to the kinematic modeling of continuum robots for the first time. The approach was evaluated using the sections of numerous continuum robots, including two novel parallel continuum robots. Each robot consists of three parallel sections, each with three thin, long McKibben actuators. These sections are poorly modeled by the widely used constant curvature kinematic model. The constant curvature and Euler spiral models were compared and the Euler spiral method was seen to be a significantly better match for a wide range of configurations of the robot hardware.


Title: Variable Damping Control of the Robotic Ankle Joint to Improve Trade-off between Performance and Stability
Abstract: This paper presents a variable damping control strategy to improve trade-off between agility/performance and stability in the control of the ankle exoskeleton robot. Depending on the user's intent of movement, the proposed variable damping controller determines the robotic ankle damping from negative to positive damping values. The range of damping values is determined by incorporating the knowledge of human ankle damping in order to always secure stability of the ankle joint of the coupled human-robot system. To evaluate the effectiveness of the proposed controller, we performed a set of human experiments with three different robotic damping conditions: fixed positive damping, fixed negative damping, and variable damping. Comparison of the two fixed damping conditions confirmed that there exists a clear trade-off between ankle agility and stability. Further, analysis of the variable damping condition demonstrated that humans could get benefits of not only positive damping to stabilize the ankle but also negative damping to enhance the agility of ankle movement as necessary during dynamic ankle movement. On average, the variable damping condition improved the agility of ankle movement by 76% and stability by 37% compared to the constant positive damping condition and the constant negative damping condition, respectively. Outcomes of this study would allow us to design a robotic controller that significantly improves agility/performance of the human-robot system without compromising its coupled stability.


Title: An Autonomous Exoskeleton for Ankle Plantarflexion Assistance
Abstract: Lower-limb exoskeletons are of great interest in the robotics community because of their various applications in enhancement and rehabilitation. In this paper we present an autonomous exoskeleton platform for ankle plantarflexion assistance. The untethered exoskeleton has a high efficiency transmission system with reduction ratio of 27.4:1. This allows relocating the actuator to the wearer's hip, which reduces device inertia. A feed-forward controller based on field oriented control was implemented to control the brushless DC motor on the exoskeleton. Through various performance tests, the exoskeleton was shown to provide a torque control bandwidth of 17.5Hz and can effectively track biological torque profiles. The augmentation factor (AF) of the exoskeleton is 64.7W, implying potential to reduce walking metabolic cost. This exoskeleton establishes an autonomous platform for experiments involving ankle assistance.


Title: Goal-Driven Navigation for Non-holonomic Multi-Robot System by Learning Collision
Abstract: In this paper, we propose the reinforcement learning based multi-robot collision avoidance approach by learning collision. Dynamical path re-planning, which is massively used in classical collision avoidance methods, needs overall information of the environment. Also, training agent robots to avoid the collision and pursue a goal point simultaneously is inefficient since the agent should learn two tasks. As the number of tasks that the agent should learn increases, it is difficult to make the performance of an algorithm consistent, which is known as reproducibility issue. To overcome these limitations, Collision Avoidance by Learning Collision (CALC), which learns collision instead of avoiding an obstacle robot is suggested. To solve the collision avoidance problem efficiently, the proposed method divides the problem into training and planning. In the training algorithm, an agent robot learns how to collide with a single obstacle robot and then generates a trained policy. With the trained policy, the agent can pursue a goal point since the policy leads the agent to `collide' with the goal. Furthermore, by taking action in a reverse way from the trained policy, the agent can avoid multiple obstacle robots in the planning algorithm at once. The proposed method is validated both in the robot simulation and real robot experiment, and compared with the existing collision avoidance method.


Title: Efficient Exact Collision Detection between Ellipsoids and Superquadrics via Closed-form Minkowski Sums
Abstract: Collision detection has attracted attention of researchers for decades in the field of computer graphics, robot motion planning, computer aided design, etc. A large number of successful algorithms have been proposed and applied, which make use of convex polytopes and bounding volumes as primitives. However, algorithms for those shapes rely significantly on the complexity of the meshes. This paper deals with collision detection for shapes with simple and exact mathematical descriptions, such as ellipsoids and superquadrics. These primitives have a wide range of applications in representing complex objects and have much fewer parameters than meshes. The foundation of the proposed collision detection scheme relies on the closed-form Minkowski sums between ellipsoids and superquadrics in n-dimensional Euclidean space. The basic idea here is to shrink the ellipsoid into a point and expand each superquadric into a new offset surface with closed-form parametric expression. The solutions for detecting relative positions between a point and a general convex differentiable parametric surface in both 2D and 3D are derived, leading to an algorithm for exact collision detection. To compare between exact and inexact algorithms, an accuracy metric is introduced based on the Principal Kinematic Formula (PKF). The proposed algorithm is then compared with existing wellknown algorithms: Gilbert-Johnson-Keerthi (GJK) and Algebraic Separation Conditions (ASC). The results show that the proposed algorithm performs competitively with these efficient checkers.


Title: Positioning Uncertainty Reduction of Magnetically Guided Actuation on Planar Surfaces
Abstract: Key design and operation parameters of the system for magnetically guided actuation of miniature robots on planar surfaces are analyzed and discussed. The study is carried out on the numerical analysis and also on the experimental measurement on the prototype of the system. Special attention is paid to robot actuation under uncertainty, which can be caused by both external and internal effects. A technique based on a superposition of actuation and lock-up field is proposed.


Title: Robot Localization Based on Aerial Images for Precision Agriculture Tasks in Crop Fields
Abstract: Localization is a pre-requisite for most autonomous robots. For example, to carry out precision agriculture tasks effectively, a robot must be able to localize itself accurately in crop fields. The crop field environment presents unique challenges such as the highly repetitive structure of the crops leading to visual aliasing as well as the continuously changing appearance of the field, which makes it difficult to localize over time. In this paper, we present a localization system, which uses an aerial map of the field and exploits the semantic information of the crops, weeds, and their stem positions to resolve the visual ambiguity problem and to enable robot localization over extended periods of time. We evaluate our approach on a real field over multiple sessions spanning several weeks. Experiments suggest that our approach provides the necessary accuracy required by precision agriculture applications and works in cases where current techniques using typical visual features tend to fail.


Title: Thermal Image Based Navigation System for Skid-Steering Mobile Robots in Sugarcane Crops*
Abstract: This work proposes a new strategy for autonomous navigation of mobile robots in sugarcane plantations based on thermal imaging. Unlike ordinary agricultural fields, sugarcane farms are generally vast and accommodates numerous arrangements of row crop tunnels, which are very tall, dense and hard-to-access. Moreover, sugarcane crops lie in harsh regions, which hinder the logistics for employing staff and heavy machinery for mapping, monitoring, and sampling. One solution for this problem is TIBA (Tankette for Intelligent BioEnergy Agriculture), a low-cost skid-steering mobile robot capable of infiltrating the crop tunnels with several sensing/sampling systems. The project concept is to reduce the product cost for making the deployment of a robot swarm feasible over a larger area. A prototype was built and tested in a bioenergy farm in order to improve the understanding of the environment and bring about the challenges for the next development steps. The major problem is the navigation through the crop tunnels, since most of the developed systems are suitable for open field operations and employ laser scanners and/or GPS/IMU, which in general are expensive technologies. In this context, we propose a low-cost solution based on infrared (IR) thermal imaging. IR cameras are simple and inexpensive devices, which do not pose risks to the user health, unlike laser-based sensors. This idea was highly motivated by the data collected in the field, which have shown a significant temperature difference between the ground and the crop. From the image analysis, it is possible to clearly visualize a distinguishable corridor and, consequently, generate a straight path for the robot to follow by using computationally efficient approaches. A rigorous analysis of the collected thermal data, numerical simulations and preliminary experiments in the real environment were included to illustrate the efficiency and feasibility of the proposed navigation methodology.


Title: Dynamic Obstacles Detection for Robotic Soil Explorations*
Abstract: Nowadays, robots can navigate complex and dynamic environments such as air, water, and different terrain. However, moving into the underground, and especially into the soil, is still a challenge. Soil is a complex environment, and its exploration and monitoring is a crucial aspect in different engineering fields. Although some robotic solutions for mapping the soil are available, none of them can navigate into it. In this work, we propose a new solution for dynamic obstacles detection by embedding a 6-axis force torque sensor into a plant-inspired robot for soil exploration. We measured the forces acting on the apical part of the robot while it penetrates the soil by growing. We tested the system in different configurations, and at different depths. Results show that it is possible to identify the relative position of the obstacle before touching it with the robot. By using the proposed method as control feedback it is possible to move toward the development of novel robotic systems for navigating in complex and dynamic environments, such as the soil.


Title: Non-Destructive Robotic Assessment of Mango Ripeness via Multi-Point Soft Haptics
Abstract: To match the ever increasing standards of fresh products, and the need to reduce waste, we devise an alternative to the destructive and highly variable fruit ripeness estimation by a penetrometer. We propose a fully automatic method to assess the ripeness of mango which is non-destructive, allows the user to test multiple surface areas with a single touch and is capable of dissociating between ripe and non-ripe fruits. A custom-made gripper equipped with a capacitive tactile sensor array is used to palpate the fruit. The ripeness is estimated as mango stiffness extracted through a simplified spring model. We test the framework on a set of 25 mangoes of the Keitt variety, and compare the results to penetrometer measurements. We show it is possible to correctly classify 88% of the mango without removing the skin of the fruit. The method can be a valuable substitute for non-destructive fruit ripeness testing. To the authors knowledge, this is the first robotics ripeness estimation system based on capacitive tactile sensing technology.


Title: The Open Vision Computer: An Integrated Sensing and Compute System for Mobile Robots
Abstract: In this paper we describe the Open Vision Computer (OVC) which was designed to support high speed, vision guided autonomous drone flight. In particular our aim was to develop a system that would be suitable for relatively small-scale flying platforms where size, weight, power consumption and computational performance were all important considerations. This manuscript describes the primary features of our OVC system and explains how they are used to support fully autonomous indoor and outdoor exploration and navigation operations on our Falcon 250 quadrotor platform.


Title: Online Estimation of Geometric and Inertia Parameters for Multirotor Aerial Vehicles
Abstract: Accurate knowledge of geometric and inertia parameters are a necessity for precise and robust control of aerial vehicles. We propose a novel filter that is able to fuse motor speed, inertia, and pose measurements to estimate the vehicle's key dynamic properties online. The presented framework is able to estimate the multirotor's moment of inertia, mass, center of mass and each sensor module's relative position. Obtaining these estimates in-flight allow the multirotor to be precisely controlled even during tasks such as load transportation or after configuration changes on scene. We provide a nonlinear observability analysis, proving that the presented model is locally weakly observable. Experimental results validate the proposed approach, showing the ability to estimate the dynamic properties accurately and demonstrate its capability to do so even while additional loads are added. The framework is flexible and can easily be adapted to a wide range of applications, including self-calibration, object grasping, and single robot or multi-robot payload transportation.


Title: External Wrench Estimation for Multilink Aerial Robot by Center of Mass Estimator Based on Distributed IMU System
Abstract: External wrench estimation is very helpful for aerial exploration and manipulation tasks. During the exploration, there might be unseen obstacles to cause dangerous collisions. The estimation of the external force and torque is also beneficial in aerial manipulation tasks. In this paper, we present a framework of estimating the external wrench for the aerial multilink robot based on the onboard inertial measurement unit (IMU) sensors, joints state and robot dynamic models. Compared to the conventional multirotor robot, the center of mass (CoM) is always changing when the robot transforms. The sensor could not be attached to CoM to observe the acceleration data. Consequently, we present a novel method by applying a distributed IMU system to estimate the CoM linear and angular accelerations for the external wrench estimation. With the help of the robot model, the position of the contact point could be estimated, which is useful in exploring tasks to safely interact with the physical world. We design the contact-aided navigation strategy and computationally efficient motion primitives library to help our robot react to the unexpected collision. We experimentally validate our framework with a two-dimensional multilink aerial robot to show the results of external wrench estimator and its further applications2.2Experiment video: https://youtu.be/R-WDReLnWWI


Title: A Novel Development of Robots with Cooperative Strategy for Long-term and Close-proximity Autonomous Transmission-line Inspection
Abstract: We develop two cooperative robots for power transmission lines (PTLs) inspection - a light climbing robot (CBR) which can stably move on the overhead ground wire (OGW) for sensor data collection and an unmanned aerial vehicle (UAV) with a grabbing mechanism, which can automatically put the CBR on the OGW and take it off. In order to guarantee the safety, the mechanical structures of the connectors are designed in the shape of a trumpet. Further, a self-locked structure of the CBR is developed to automatically seize and release the OGW. For autonomous navigation, the UAV is equipped with a movable sliding rail and a 2D Laser Range Finder (LRF). The LRF can not only detect the position and orientation of the OGW but also detect the top beam of the CBR and the grabbing position in it. Furthermore, the action of the grabbing mechanism is automatically triggered by a microswitch. Finally, by the developed UAV and CBR platforms, we test the whole loading and unloading strategy in an artificially constructed PTLs environment outdoors and achieve an encouraging result1. Combining the flexible motion of the UAV and the high inspection accuracy of the CBR, the CBR can negotiate any obstacle by flying and abandon the traditional heavy obstacle crossing mechanism to effectively realize close-proximity inspection. Due to the light weight and low power consumption, the CBRs can be deployed once in many power corridors to conduct a long-term inspection.


Title: Design and Testing of a New Cell Microinjector with Embedded Soft Force Sensor
Abstract: Cell microinjection plays an important role in genetics, transgenics, and other biomedical fields. As compared with manual cell microinjection and position-based robotic cell microinjection, force-assisted robotic cell microinjection can improve the success rate and survival rate of the injected cells. In this paper, a novel force-sensing cell injector is designed with piezoresistive force sensor embedded in soft materials. The soft sensors act as fixed-guided beams, which are introduced to achieve the force measurement with high sensitivity in pure one-degree-of-freedom (1-DOF) direction. The injector is developed by considering the installation and replacement issues of the micropipette as well as the connection convenience between the micropipette and tube of compressed air. A prototype of the cell injector with the force sensor is fabricated. Experimental study is conducted to verify its performance in practice.


Title: Energy optimization for a Robust and Flexible Interaction Control
Abstract: The possibility of adapting online the way a robot interacts with the environment is becoming more and more important. In this paper we introduce the tank based admittance controller. We show that all the admittance controllers can be modeled as an energy optimization problem and then we introduce a novel admittance control strategy that allows to change online the interactive behavior while preserving a stable interaction with the environment. The effectiveness of the proposed architecture is experimentally validated.


Title: Design of Versatile and Low-Cost Shaft Sensor for Health Monitoring
Abstract: Virtually every mechanized form of transportation, power generation system, industrial equipment, and robotic system has rotating shafts. As the shaft is often the main means of mechanical power transmission, measuring the torque, speed, vibration, and bending of the shaft can be used in many cases to access device performance and health and to implement controls. This paper proposes a shaft sensor that measures all of these phenomena with reasonable accuracy while having a low cost and simple installation process. This sensor transfers strain from the shaft and amplifies it to increase sensitivity. Furthermore, this sensor requires no components to be in the stationary reference frame, allowing the entire device to rotate with the shaft. A prototype is presented. Experimental results illustrate the effectiveness of the proposed system.


Title: Robust Execution of Contact-Rich Motion Plans by Hybrid Force-Velocity Control
Abstract: In hybrid force-velocity control, the robot can use velocity control in some directions to follow a trajectory, while performing force control in other directions to maintain contacts with the environment regardless of positional errors. We call this way of executing a trajectory hybrid servoing. We propose an algorithm to compute hybrid force-velocity control actions for hybrid servoing. We quantity the robustness of a control action and make trade-offs between different requirements by formulating the control synthesis as optimization problems. Our method can efficiently compute the dimensions, directions and magnitudes of force and velocity controls. We demonstrated by experiments the effectiveness of our method in several contact-rich manipulation tasks. Link to the video: https://youtu.be/KtSNmvwOenM.


Title: On The Combination of Gamification and Crowd Computation in Industrial Automation and Robotics Applications
Abstract: Autonomous intelligent systems outperform human workers in an expanding range of domains, typically those in which success is a function of speed, precision and repeatability. However, many cognitive tasks remain beyond the reach of automation. In this work, we propose the use of video games to crowdsource the cognitive versatility and creativity of human players to solve complex problems in industrial automation and robotics applications. To do so, we introduce a theoretical framework in which robotics problems are embedded into video game environments and gameplay from crowds of players is aggregated to inform robot actions. Such a framework could enable a future of synergistic human-machine collaboration for industrial automation, in which members of the public not only freely offer the fruits of their intelligent reasoning for productive use, but have fun whilst doing so. There is also potential for significant negative consequences surrounding safety, accountability and ethics if great care is not taken in the implementation. Further work is needed to explore these wider implications, as well as to develop the technical theory behind the framework and build prototype applications.


Title: A New Overloading Fatigue Model for Ergonomic Risk Assessment with Application to Human-Robot Collaboration
Abstract: Among the numerous risk factors associated to work-related musculoskeletal disorders (WMSD), repetitive and monotonous movements with light-weight tools are one of the most frequently cited. Such tasks may indeed result in the excessive accumulation of local muscle fatigue, causing severe injuries in human joints. Accordingly, this paper proposes a new whole-body fatigue model to evaluate the cumulative effect of the overloading torque induced on the joints over time by light payloads. The proposed model is then integrated into a human-robot collaboration (HRC) framework to set the timing of a body posture optimisation procedure guided by the robot assistance, by the time fatigue overcomes a threshold in any joint. Our overloading fatigue model is based on an estimation method we developed in a previous work, to monitor joint torque variations due to external forces in real-time. To account for individuals' different perception of fatigue, the fatigue ratio parameter in the model is computed experimentally for each subject. The proposed model is first studied on ten subjects by means of an electromyography analysis. Next, its performance is assessed in a painting task and finally evaluated within the HRC framework, which is proved to be able to reduce the risk of injuries caused by excessive fatigue accumulation.


Title: Human-inspired balance model to account for foot-beam interaction mechanics
Abstract: The locomotion and balance capabilities of bipedal robots have greatly improved in recent years. However, maintaining balance on difficult terrain still poses a significant challenge. In this paper, we examined how humans maintain mediolateral balance when standing on a narrow beam with bare feet and wearing rigid soles. Our results show that foot-beam interaction dynamics critically influence balancing behavior. Importantly, this suggests that differences in human balancing behavior across different support surfaces may not solely result from changes in their neural control strategy. They may also result from changes in foot-ground interaction. Thus, the altered foot-ground interaction dynamics must be considered to accurately capture changes in the human controller across different support surfaces. A simplified model of foot-beam interaction was added to a double inverted pendulum model for human balancing. This extended model could replicate the change in human behavior across different foot contact conditions (bare feet vs. rigid feet). A better understanding of how humans coordinate whole-body behavior across a range of conditions may inform the development of balance controllers for bipedal robots.


Title: Real-time Robot-assisted Ergonomics*
Abstract: This paper describes a novel approach in human-robot interaction driven by ergonomics. With a clear focus on optimising ergonomics, the approach proposed here continuously observes a human user's posture and by invoking appropriate cooperative robot movements, the user's posture is, whenever required, brought back to an ergonomic optimum. Effectively, the new protocol optimises the human-robot relative position and orientation as a function of human ergonomics. An RGB-D camera is used to calculate and monitor human joint angles in real-time and to determine the current ergonomics state. A total of 6 main causes of low ergonomic states are identified, leading to 6 universal robot responses to allow the human to return to an optimal ergonomics state. The algorithmic framework identifies these 6 causes and controls the cooperating robot to always adapt the environment (e.g. change the pose of the workpiece) in a way that is ergonomically most comfortable for the interacting user. Hence, human-robot interaction is continuously re-evaluated optimizing ergonomics states. The approach is validated through an experimental study, based on established ergonomic methods and their adaptation for real-time application. The study confirms improved ergonomics using the new approach.


Title: A Fog Robotic System for Dynamic Visual Servoing
Abstract: Cloud Robotics is a paradigm where multiple robots are connected to cloud services via Internet to access “unlimited” computation power, at the cost of network communication. However, due to limitations such as network latency and variability, it is difficult to control dynamic, human compliant service robots directly from the cloud. In this work, we combine cloud robotics with an agile edge device to build a Fog Robotic system by leveraging an asynchronous protocol with a “heartbeat” signal. We use the system to enable robust teleoperation of a dynamic self-balancing robot from the cloud. We use the system to pick up boxes from static locations, a task commonly performed in warehouse logistics. To make cloud teleoperation more intuitive and efficient, we program a cloud-based image based visual servoing (IBVS) module to automatically assist the cloud teleoperator during the object pickups. Visual feedbacks, including apriltag recognition and tracking, are performed in the cloud to emulate a Fog Robotic object recognition system for IBVS. We demonstrate the feasibility of a dynamic real-time automation system using this cloud-edge hybrid design, which opens up possibilities of deploying dynamic robotic control with deep-learning recognition systems in Fog Robotics. Finally, we show that Fog Robotics enables the self-balancing service robot to pick up a box automatically from a person under unstructured environments.


Title: Approximate Probabilistic Security for Networked Multi-Robot Systems
Abstract: In this paper, we formulate a combinatorial optimization problem that aims to maximize the accuracy of a lower bound estimate of the probability of security of a multi-robot system (MRS), while minimizing the computational complexity involved in its calculation. Security of an MRS is defined using the well-known control theoretic notion of left invertiblility, and the probability of security of an MRS can be calculated using binary decision diagrams (BDDs). The complexity of a BDD depends on the number of disjoint path sets considered during its construction. Taking into account all possible disjoint paths results in an exact probability of security, however, selecting an optimal subset of disjoint paths leads to a good estimate of the probability while significantly reducing computation. To deal with the dynamic nature of MRSs, we introduce two methods: (1) multi-point optimization, a technique that requires some a priori knowledge of the topology of the MRS over time, and (2) online optimization, a technique that does not require a priori knowledge, but must construct BDDs while the MRS is operating. Finally, our approach is validated on an MRS performing a rendezvous objective while exchanging information according to a noisy state agreement process.


Title: A Decentralized Heterogeneous Control Strategy for a Class of Infinitesimally Shape-Similar Formations
Abstract: The sensing modalities available to individual agents in a multi-robot team have a significant effect on what the team can accomplish. Previous work on infinitesimal shape-similarity has shown that maintaining relative angles between robots equipped with bearing-only sensors can render a formation of these robots invariant to translation, rotation, and uniform scaling; however, previous work has not proposed decentralized control strategies for exploiting this invariance. To address this deficiency, this paper proposes a decentralized formation control strategy for assembled triangulations, a class of infinitesimally shape-similar formations. Heterogeneous in terms of sensing and control, a decentralized formation control strategy is developed in which one robot sets the position of the formation, a robot capable of measuring bearings and distances controls the scale and heading, and the remaining robots maintain the assembled triangulation. The asymptotic controllers that compose the formation control strategy of this work are implemented on a team of differential-drive robots.


Title: Asynchronous Network Formation in Unknown Unbounded Environments*
Abstract: In this paper, we study the Online Network Formation Problem (ONFP) for a mobile multi-robot system. Consider a group of robots with a bounded communication range operating in a large open area. One of the robots has a piece of information which has to be propagated to all other robots. What strategy should the robots pursue to disseminate the information to the rest of the robots as quickly as possible? The initial locations of the robots are unknown to each other, therefore the problem must be solved in an online fashion. For this problem, we present an algorithm whose competitive ratio is O(H · max{M, √MH}) for arbitrary robot deployments, where M is the largest edge length in the Euclidean minimum spanning tree on the initial robot configuration and H is the height of the tree. We also study the case when the robot initial positions are chosen uniformly at random and improve the ratio to O(M). Finally, we present simulation results to validate the performance in larger scales and demonstrate our algorithm using three robots in a field experiment.


Title: Switching Topology for Resilient Consensus using Wi-Fi Signals
Abstract: Securing multi-robot teams against malicious activity is crucial as these systems accelerate towards widespread societal integration. This emerging class of “physical networks” requires research into new methods of security that exploit their physical nature. This paper derives a theoretical framework for securing multi-agent consensus against the Sybil attack by using the physical properties of wireless transmissions. Our frame-work uses information extracted from the wireless channels to design a switching signal that stochastically excludes potentially untrustworthy transmissions from the consensus. Intuitively, this amounts to selectively ignoring incoming communications from untrustworthy agents, allowing for consensus to the true average to be recovered with high probability if initiated after a certain observation time T0 that we derive. This work is different from previous work in that it allows for arbitrary malicious node values and is insensitive to the initial topology of the network so long as a connected topology over legitimate nodes in the network is feasible. We show that our algorithm will recover consensus and the true graph over the system of legitimate agents with an error rate that vanishes exponentially with time.


Title: Disturbance Compensation Based Control for an Indoor Blimp Robot
Abstract: This paper presents design of a robust controller with disturbance compensation for an indoor blimp robot and its realization. The movement of blimp in horizontal plane is modeled as a slider-like nonlinear system complemented with uncertain bounded disturbances. To design the output feedback controller, a homogeneous differentiator is used as an observer. Then the method for disturbance evaluation is designed, the perturbation estimate is next used in the controller for cancellation of the influence of exogenous disturbances. Control scheme is implemented on a concrete blimp, finally, the performance of blimp disturbance compensation based controller is verified in experiments.


Title: A Generic Optimization Based Cartesian Controller for Robotic Mobile Manipulation
Abstract: Typically, the problem of robotic manipulation is divided among two sequential phases: a planning one and an execution one. However, since the second one is executed in open loop, the robot is unable to react in real time to changes in the task (e.g. moving object). This paper addresses the mobile manipulation problem from a real-time, closed loop perspective. In particular, we propose a generic optimization-based Cartesian controller, that given a continuous monitoring of the goal, determines the best motion commands. We target our controller to a robotic system comprising an arm and a mobile platform. However, the approach can in principle be extended to more complex mechanisms. The approach is based on shifting the problem to velocity space, where end effector velocity is a linear function of joint and base platform velocities. Our approach was quantitatively evaluated both on simulation and on a real service robot. It was also integrated into a mobile service robot architecture targeting domestic tasks and evaluated on the RoboCup@Home scientific competition. Our results show that the controller is able to reach random arm configurations with a high probability of success.


Title: Task-Driven Estimation and Control via Information Bottlenecks
Abstract: Our goal is to develop a principled and general algorithmic framework for task-driven estimation and control for robotic systems. State-of-the-art approaches for controlling robotic systems typically rely heavily on accurately estimating the full state of the robot (e.g., a running robot might estimate joint angles and velocities, torso state, and position relative to a goal). However, full state representations are often excessively rich for the specific task at hand and can lead to significant computational inefficiency and brittleness to errors in state estimation. In contrast, we present an approach that eschews such rich representations and seeks to create task-driven representations. The key technical insight is to leverage the theory of information bottlenecks to formalize the notion of a “task-driven representation” in terms of information theoretic quantities that measure the minimality of a representation. We propose novel iterative algorithms for automatically synthesizing (offline) a task-driven representation (given in terms of a set of task-relevant variables (TRVs)) and a performant control policy that is a function of the TRVs. We present online algorithms for estimating the TRVs in order to apply the control policy. We demonstrate that our approach results in significant robustness to unmodeled measurement uncertainty both theoretically and via thorough simulation experiments including a spring-loaded inverted pendulum running to a goal location.


Title: Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty
Abstract: Deep learning provides a powerful tool for robotic perception in the open world. However, real-world robotic systems, especially mobile robots, must be able to react intelligently and safely even in unexpected circumstances. This requires a system that knows what it knows, and can estimate its own uncertainty for unfamiliar, out-of-distribution observations. Approximate Bayesian approaches are commonly used to estimate uncertainty for neural network predictions, but struggle with out-of-distribution observations. Generative models can in principle detect out-of-distribution observations as those with a low estimated density, but overly pessimistic as an uncertainty measure, since the mere presence of an out-of-distribution input does not by itself indicate an unsafe situation. Intuitively, we would like a perception system that can detect when task-salient parts of the image are unfamiliar or uncertain, while ignoring task-irrelevant features. In this paper, we present a method for uncertainty-aware robotic perception that combines generative modeling and model uncertainty. Our method estimates an uncertainty measure about the model's prediction, taking into account an explicit generative model of the observation distribution to handle out-of-distribution inputs. We evaluate our method on an action-conditioned collision prediction task with both simulated and real data, and demonstrate that our approach improves on a variety of Bayesian neural network techniques.


Title: Multimodal Trajectory Predictions for Autonomous Driving using Deep Convolutional Networks
Abstract: Autonomous driving presents one of the largest problems that the robotics and artificial intelligence communities are facing at the moment, both in terms of difficulty and potential societal impact. Self-driving vehicles (SDVs) are expected to prevent road accidents and save millions of lives while improving the livelihood and life quality of many more. However, despite large interest and a number of industry players working in the autonomous domain, there still remains more to be done in order to develop a system capable of operating at a level comparable to best human drivers. One reason for this is high uncertainty of traffic behavior and large number of situations that an SDV may encounter on the roads, making it very difficult to create a fully generalizable system. To ensure safe and efficient operations, an autonomous vehicle is required to account for this uncertainty and to anticipate a multitude of possible behaviors of traffic actors in its surrounding. We address this critical problem and present a method to predict multiple possible trajectories of actors while also estimating their probabilities. The method encodes each actor's surrounding context into a raster image, used as input by deep convolutional networks to automatically derive relevant features for the task. Following extensive offline evaluation and comparison to state-of-the-art baselines, the method was successfully tested on SDVs in closed-course tests.


Title: Lightweight Contrast Modeling for Attention-Aware Visual Localization
Abstract: Salient object detection, which aims at localizing the attention-aware visual objects, is the indispensable technology for intelligent robots to understand and interact with the complicated environments. Existing salient object detection approaches mainly focus on the optimization of detection performance, while ignoring the considerations for computational resource consumption and algorithm efficiency. Contrarily, we build a superior lightweight network architecture to simultaneously improve performance on both accuracy and efficiency for salient object detection. Specifically, our proposed approach adopts the lightweight bottleneck as its primary building block to significantly reduce the number of parameters and to speed up the process of training and inference. In practice, the visual contrast is insufficiently discovered with the limitation of the small empirical receptive field of CNN. To alleviate this issue, we design a multi-scale convolution module to rapidly discover high-level visual contrast. Moreover, a lightweight refinement module is utilized to restore object saliency details with negligible extra cost. Extensive experiments on efficiency and accuracy trade-offs show that our model is more competitive than the state-of-the-art works on salient object detection task and has prominent potentials for robots applications in real time.


Title: Learning to Write Anywhere with Spatial Transformer Image-to-Motion Encoder-Decoder Networks
Abstract: Learning to recognize and reproduce handwritten characters is already a challenging task both for humans and robots alike, but learning to do the same thing for characters that can be transformed arbitrarily in space, as humans do when writing on a blackboard for instance, significantly ups the ante from a robot vision and control perspective. In previous work we proposed various different forms of encoder-decoder networks that were capable of mapping raw images of digits to dynamic movement primitives (DMPs) such that a robot could learn to translate the digit images into motion trajectories in order to reproduce them in written form. However, even with the addition of convolutional layers in the image encoder, the extent to which these networks are spatially invariant or equivariant is rather limited. In this paper, we propose a new architecture that incorporates both an image-to-motion encoder-decoder and a spatial transformer in a fully differentiable overall network that learns to rectify affine transformed digits in input images into canonical forms, before converting them into DMPs with accompanying motion trajectories that are finally transformed back to match up with the original digit drawings such that a robot can write them in their original forms. We present experiments with various challenging datasets that demonstrate the superiority of the new architecture compared to our previous work and demonstrate its use with a humanoid robot in a real writing task.


Title: Motion Planning Networks
Abstract: Fast and efficient motion planning algorithms are crucial for many state-of-the-art robotics applications such as self-driving cars. Existing motion planning methods become ineffective as their computational complexity increases exponentially with the dimensionality of the motion planning problem. To address this issue, we present Motion Planning Networks (MPNet), a neural network-based novel planning algorithm. The proposed method encodes the given workspaces directly from a point cloud measurement and generates the end-to-end collision-free paths for the given start and goal configurations. We evaluate MPNet on various 2D and 3D environments including the planning of a 7 DOF Baxter robot manipulator. The results show that MPNet is not only consistently computationally efficient in all environments but also generalizes to completely unseen environments. The results also show that the computation time of MPNet consistently remains less than 1 second in all presented experiments, which is significantly lower than existing state-of-the-art motion planning algorithms.


Title: Improving Data Efficiency of Self-supervised Learning for Robotic Grasping
Abstract: Given the task of learning robotic grasping solely based on a depth camera input and gripper force feedback, we derive a learning algorithm from an applied point of view to significantly reduce the amount of required training data. Major improvements in time and data efficiency are achieved by: Firstly, we exploit the geometric consistency between the undistorted depth images and the task space. Using a relative small, fully-convolutional neural network, we predict grasp and gripper parameters with great advantages in training as well as inference performance. Secondly, motivated by the small random grasp success rate of around 3 %, the grasp space was explored in a systematic manner. The final system was learned with 23 000 grasp attempts in around 60 h, improving current solutions by an order of magnitude. For typical bin picking scenarios, we measured a grasp success rate of (96.6 ± 1.0) %. Further experiments showed that the system is able to generalize and transfer knowledge to novel objects and environments.


Title: Online Object and Task Learning via Human Robot Interaction
Abstract: This work describes the development of a robotic system that acquires knowledge incrementally through human interaction where new objects and motions are taught on the fly. The robotic system developed was one of the five finalists in the KUKA Innovation Award competition and demonstrated during the Hanover Messe 2018 in Germany. The main contributions of the system are i) a novel incremental object learning module - a deep learning based localization and recognition system - that allows a human to teach new objects to the robot, ii) an intuitive user interface for specifying 3D motion task associated with the new object, and iii) a hybrid force-vision control module for performing compliant motion on an unstructured surface. This paper describes the implementation and integration of the main modules of the system and summarizes the lessons learned from the competition.


Title: Color-Coded Fiber-Optic Tactile Sensor for an Elastomeric Robot Skin
Abstract: The sense of touch is essential for reliable mapping between the environment and a robot which interacts physically with objects. Presumably, an artificial tactile skin would facilitate safe interaction of the robots with the environment. In this work, we present our color-coded tactile sensor, incorporating plastic optical fibers (POF), transparent silicone rubber and an off-the-shelf color camera. Processing electronics are placed away from the sensing surface to make the sensor robust to harsh environments. Contact localization is possible thanks to the lower number of light sources compared to the number of camera POFs. Classical machine learning techniques and a hierarchical classification scheme were used for contact localization. Specifically, we generated the mapping from stimulation to sensation of a robotic perception system using our sensor. We achieved a force sensing range up to 18 N with the force resolution of around 3.6 N and the spatial resolution of 8 mm. The color-coded tactile sensor is suitable for tactile exploration and might enable further innovations in robust tactile sensing.


Title: Reinforcement Learning in Topology-based Representation for Human Body Movement with Whole Arm Manipulation
Abstract: Moving a human body or a large and bulky object may require the strength of whole arm manipulation (WAM). This type of manipulation places the load on the robot's arms and relies on global properties of the interaction to succeed- rather than local contacts such as grasping or non-prehensile pushing. In this paper, we learn to generate motions that enable WAM for holding and transporting of humans in certain rescue or patient care scenarios. We model the task as a reinforcement learning problem in order to provide a robot behavior that can directly respond to external perturbation and human motion. For this, we represent global properties of the robot-human interaction with topology-based coordinates that are computed from arm and torso positions. These coordinates also allow transferring the learned policy to other body shapes and sizes. For training and evaluation, we simulate a dynamic sea rescue scenario and show in quantitative experiments that the policy can solve unseen scenarios with differently-shaped humans, floating humans, or with perception noise. Our qualitative experiments show the subsequent transporting after holding is achieved and we demonstrate that the policy can be directly transferred to a real world setting.


Title: Demonstration-Guided Deep Reinforcement Learning of Control Policies for Dexterous Human-Robot Interaction
Abstract: In this paper, we propose a method for training control policies for human-robot interactions such as handshakes or hand claps via Deep Reinforcement Learning. The policy controls a humanoid Shadow Dexterous Hand, attached to a robot arm. We propose a parameterizable multi-objective reward function that allows learning of a variety of interactions without changing the reward structure. The parameters of the reward function are estimated directly from motion capture data of human-human interactions in order to produce policies that are perceived as being natural and human-like by observers. We evaluate our method on three significantly different hand interactions: handshake, hand clap and finger touch. We provide detailed analysis of the proposed reward function and the resulting policies and conduct a large-scale user study, indicating that our policy produces natural looking motions.


Title: Team-Based Robot Righting via Pushing and Shell Design
Abstract: The minimalist robot designs typically employed in swarms and teams can fall and get trapped when traversing irregular terrain. To protect against this contingency the design could add a specialized escape actuator, but each actuator drives up cost multiplicatively for the whole team. Instead, the emergency actuator can be found for free in the form of another teammate. Teammate pushing can be efficiently directed by careful shaping of the robot's exterior hull. This approach is illustrated by designing a shell for VelociRoACH robots that enables them to roll pronated comrades back onto their feet. The designed maneuver can be performed in open-loop with 87% success and an average time of 0.7 seconds.


Title: Deformation-based shape control with a multirobot system
Abstract: We present a novel method to control the relative positions of the members of a robotic team. The application scenario we consider is the cooperative manipulation of a deformable object in 2D space. A typical goal in this kind of scenario is to minimize the deformation of the object with respect to a desired state. Our contribution, then, is to use a global measure of deformation directly in the feedback loop. In particular, the robot motions are based on the descent along the gradient of a metric that expresses the difference between the team's current configuration and its desired shape. Crucially, the resulting multirobot controller has a simple expression and is inexpensive to compute, and the approach lends itself to analysis of both the transient and asymptotic dynamics of the system. This analysis reveals a number of properties that are interesting for a manipulation task: fundamental geometric parameters of the team (size, orientation, centroid, and distances between robots) can be suitably steered or bounded. We describe different policies within the proposed deformation-based control framework that produce useful team behaviors. We illustrate the methodology with computer simulations.


Title: One-to-many bipartite matching based coalition formation for multi-robot task allocation
Abstract: In this paper, we study the NP-Hard problem of multi-robot coalition formation for task allocation. To tackle this notoriously difficult problem, we model it as a variant of classical bipartite matching, which we call One-To-Many Bipartite Matching (OTMaM). Unlike the classical bipartite matching techniques used for matching a unique robot to a unique task, in the OTMaM problem, we let multiple robots to be matched to a single task while restricting the opposite. To this end, we propose a novel heuristic algorithm that allocates robots to tasks by finding mutually best robot-task pairs. Our algorithm provides a similar theoretical worst-case approximation ratio and guarantees a better worst-case time complexity than a comparable algorithm from the literature. The proposed approach in this paper is proved to be deterministic and the resultant matching is perfect. Simulation results also demonstrate the scalability of the presented algorithm (taking less than 1 millisecond with 100 robots and 10 tasks).


Title: Coordinated multi-robot planning while preserving individual privacy
Abstract: We consider the problem of multiple robots that must cooperate within a shared environment, but which wish to limit the information they disclose during their coordination efforts. Specifically, we examine the problems of privacy-preserving rendezvous and persistent monitoring. In the former, the robots construct a joint plan to have them meet, without either knowing beforehand where or when the meeting will occur. In the latter, multiple robots dynamically cover a region of space-they plan collective motions which are collision-free but with the assurance that agents remain ignorant of the paths of others. Accordingly, the tasks are sort of inverses in that the robots must collectively determine whether their joint paths collide or not, then, using this, achieve their collective task. Other than what is learned by the outcome of the joint-collision determination, the robots possess no details of the other paths. Our approach builds on garbled circuits and homomorphic encryption to realize basic secure path intersection primitives. We present algorithms, a software implementation, and a physical experiment on mobile robots to test the practical feasibility of our approach. We believe that these ideas provide a valuable direction for adoption in small Unmanned Systems belonging to different stakeholders.


Title: Robust Area Coverage with Connectivity Maintenance
Abstract: Robot swarms herald the ability to solve complex tasks using a large collection of simple devices. However, engineering a robotic swarm is far from trivial, with a major hurdle being the definition of the control laws leading to the desired globally coordinated behavior. Communication is a key element for coordination and it is considered one of the current most important challenges for swarm robotics. In this paper, we study the problem of maintaining robust swarm connectivity while performing a coverage task based on the Voronoi tessellation of an area of interest. We implement our methodology in a team of eight Khepera IV robots. With the assumptions that robots have a limited sensing and communication range-and cannot rely on centralized processing-we propose a tri-objective control law that outperforms other simpler strategies (e.g. a potential-based coverage) in terms of network connectivity, robustness to failure, and area coverage.


Title: Living with a Mobile Companion Robot in your Own Apartment - Final Implementation and Results of a 20-Weeks Field Study with 20 Seniors*
Abstract: This paper presents the results of the German research project SYMPARTNER (4/2015 - 6/2018), which aimed at developing a functional-emotional, mobile domestic robot companion for elderly people. The paper gives an overview of the developed robot, its system architecture, and essential skills and behaviors required for being a friendly home companion. Based on this, in a long-term field study running from January to June 2018 both technical aspects regarding the practical suitability and robustness of the robot under domestic operating conditions and social scientific questions on usability and acceptance of the robot and the users' familiarization with their new housemate were evaluated. In the field study, two of these autonomous companion robots were used in 20 senior households in Erfurt (Germany). All participants lived with their robot in their apartments for one week without the need for supervising or supporting persons being present on-site. The tests in 20 single-person households in the age group 62 to 94 years (average 74 years) provided important insights into the special challenges of domesticity from a technical, social scientific, and user-oriented point of view. The results of the study show how seniors can shape their everyday life with a companion robot and how quickly they get used to the new housemate.


Title: Enabling Identity-Aware Tracking via Fusion of Visual and Inertial Features
Abstract: Person identification and tracking (PIT) is an essential issue in computer vision and robotic applications. It has long been studied and achieved by technologies such as RFID or face/fingerprint/iris recognition. These approaches, however, have their limitations due to environmental constraints (such as lighting and obstacles) or require close contact to specific devices. Therefore, their recognition accuracy highly depends on use scenarios. In this work, we propose RCU (Robot Catch yoU), an accompanyist robot system that provides follow-me or guide-me services. Such robots are capable of distinguishing users' profiles in front of them and keep tracking a specific target person. We study a more challenging scenario where the target person may be under occlusion from time to time. To enable robust PIT, we develop a data fusion technique that integrates two types of sensors, an RGB-D camera and wearable inertial sensors. Since the data generated by these sensors share common features, we are able to fuse them to achieve identity-aware tracking. Practical issues, such as time synchronization and coordinate calibration, are also addressed. We implement our design on a robotic platform and show that it can track a target person even when no biological feature is captured by the RGB-D camera. Our experimental evaluation shows a recognition rate of 95% and a following rate of 88%.


Title: Inverse Reinforcement Learning of Interaction Dynamics from Demonstrations
Abstract: This paper presents a framework to learn the reward function underlying high-level sequential tasks from demonstrations. The purpose of reward learning, in the context of learning from demonstration (LfD), is to generate policies that mimic the demonstrator's policies, thereby enabling imitation learning. We focus on a human-robot interaction (HRI) domain where the goal is to learn and model structured interactions between a human and a robot. Such interactions can be modeled as a partially observable Markov decision process (POMDP) where the partial observability is caused by uncertainties associated with the ways humans respond to different stimuli. The key challenge in finding a good policy in such a POMDP is determining the reward function that was observed by the demonstrator. Existing inverse reinforcement learning (IRL) methods for POMDPs are computationally very expensive and the problem is not well understood. In comparison, IRL algorithms for Markov decision process (MDP) are well defined and computationally efficient. We propose an approach of reward function learning for high-level sequential tasks from human demonstrations where the core idea is to reduce the underlying POMDP to an MDP and apply any efficient MDPIRL algorithm. Our extensive experiments suggest that the reward function learned this way generates POMDP policies that mimic the policies of the demonstrator well.


Title: Investigating Design Elements of Companion Robots for Older Adults
Abstract: Older adults are vulnerable to symptoms of depression. The degree of depression is particularly high among older adults who live alone. To address this issue, various companion robots, which are capable of psychologically communicating with users, have been proposed. However, older adults' preferences on the appearance of these robots have not been systematically investigated; this forms the focus of the present study. We interviewed 191 older adults; investigated their preferences on the design elements of robots including type, weight, and material; and analyzed the data by age, gender, and living arrangement. Our primary goal was to determine how companion robots should be designed, paying special attention to older adults who live alone. Our findings indicated that those living alone prefer a bear-like robot and negative to the heavy robot. Our results suggest that companion robots need to be designed with careful consideration of older adults' physical and psychological preferences.


Title: Development of Informative Path Planning for Inspection of the Hanford Tank Farm
Abstract: Traditional environmental and structural monitoring often uses static sensor networks deployed at predetermined locations or mobile robots that use a rastering technique for area coverage. These methods rely on the operators making assumptions about the nature of the unknown field that is being measured and are often time-consuming for localizing an area of interest. Here, we aim to quickly localize possible leaks within high-level nuclear waste tanks at the Hanford facility. The structure of these tanks precludes most sensor network approaches and raises many issues with robotic inspection, such as navigation within highly constrained environments. This work uses a Bayesian Optimization approach for guiding a mobile robot's search strategy and implements a utility function that allows for prior knowledge of the structure to be incorporated when selecting future search locations. Compared to traditional exhaustive approaches, our method quickly reduces RMSE error and shortens the distance the robot must travel.


Title: A Fuzzy Based Accessibility Model for Disaster Environment
Abstract: Robots that perform autonomous maneuvering in a disaster environment usually dont have perfect understanding of the environment in advance. The robot is continuously evaluating the environment as it proceeds, deciding the optimal way to traverse the environment to get to the goal. A critical aspect of this decision is the robot estimate of the terrain accessibility index, which quantifies how easy it is to navigate through the immediate terrain. This paper represents a new method to calculate terrain accessibility index based on obstacle distance to the robots position. In addition, a Fuzzy Inference System Vector Field Histogram (FISVFH) method has been designed for automating the selection of the robots linear and angular velocities in the VFH (Vector Field Histogram) algorithm, based on the calculated sector accessibility index. The proposed method is a two-input and two-output Fuzzy Inference System, where the current robot heading, and sector accessibility index serve as the input, and the corresponding linear and angular velocities to the VFH algorithm are outputs. The VFH, VFH + and FISVFH are tested both in simulation and experimentation in 4 environments that are known to result in failures in VFH and VFH +, for comparison purposes. In addition, the algorithm was verified through experimental setup of a disaster prone environment. In both simulation and experimentation the results show that FISVFH outperforms VFH and VFH +. It is also shown that the FISVFH algorithm is capable of handling the disaster prone environment. Overall, the FISVFH algorithm enables the robot to get to the goal faster and also produces a smoother path while doing so.


Title: Visual recognition in the wild by sampling deep similarity functions
Abstract: Recognising relevant objects or object states in its environment is a basic capability for an autonomous robot. The dominant approach to object recognition in images and range images is classification by supervised machine learning, nowadays mostly with deep convolutional neural networks (CNNs). This works well for target classes whose variability can be completely covered with training examples. However, a robot moving in the wild, i.e., in an environment that is not known at the time the recognition system is trained, will often face domain shift: the training data cannot be assumed to exhaustively cover all the within-class variability that will be encountered in the test data. In that situation, learning is in principle possible, since the training set does capture the defining properties, respectively dissimilarities, of the target classes. But directly training a CNN to predict class probabilities is prone to overfitting to irrelevant correlations between the class labels and the specific subset of the target class that is represented in the training set. We explore the idea to instead learn a Siamese CNN that acts as similarity function between pairs of training examples. Class predictions are then obtained by measuring the similarities between a new test instance and the training samples. We show that the CNN embedding correctly recovers the relative similarities to arbitrary class exemplars in the training set. And that therefore few, randomly picked training exemplars are sufficient to achieve good predictions, making the procedure efficient.


Title: A Comparison of CNN-Based and Hand-Crafted Keypoint Descriptors
Abstract: Keypoint matching is an important operation in computer vision and its applications such as visual simultaneous localization and mapping (SLAM) in robotics. This matching operation heavily depends on the descriptors of the keypoints, and it must be performed reliably when images undergo condition changes such as those in illumination and viewpoint. Previous research in keypoint description has pursued three classes of descriptors: hand-crafted, those from trained convolutional neural networks (CNN), and those from pre-trained CNNs. This paper provides a comparative study of the three classes of keypoint descriptors, in terms of their ability to handle conditional changes. The study is conducted on the latest benchmark datasets in computer vision with challenging conditional changes. Our study finds that (a) in general CNN-based descriptors outperform hand-crafted descriptors, (b) the trained CNN descriptors perform better than pre-trained CNN descriptors with respect to viewpoint changes, and (c) pre-trained CNN descriptors perform better than trained CNN descriptors with respect to illumination changes. These findings can serve as a basis for selecting appropriate keypoint descriptors for various applications.


Title: Multimodal Semantic SLAM with Probabilistic Data Association
Abstract: The recent success of object detection systems motivates object-based representations for robot navigation; i.e. semantic simultaneous localization and mapping (SLAM). The semantic SLAM problem can be decomposed into a discrete inference problem: determining object class labels and measurement-landmark correspondences (the data association problem), and a continuous inference problem: obtaining the set of robot poses and object locations in the environment. A solution to the semantic SLAM problem necessarily addresses this joint inference, but under ambiguous data associations this is in general a non-Gaussian inference problem, while the majority of previous work focuses on Gaussian inference. Previous solutions to data association either produce solutions between potential hypotheses or maintain multiple explicit hypotheses for each association. We propose a solution that represents hypotheses as multiple modes of an equivalent non-Gaussian sensor model. We then solve the resulting non-Gaussian inference problem using nonparametric belief propagation. We validate our approach in a simulated hallway environment under a variety of sensor noise characteristics, as well as using real data from the KITTI dataset, demonstrating improved robustness to perceptual aliasing and odometry uncertainty.


Title: Multimodal Policy Search using Overlapping Mixtures of Sparse Gaussian Process Prior
Abstract: In this paper, we present a novel policy search reinforcement learning algorithm that can deal with multimodality in control policies based on Gaussian processes. Our approach employs Overlapping Mixtures of Gaussian Processes (OMGPs) for a control policy, in which all the GPs in the mixture are global and overlapped in the input space. We first extend the OMGPs by combing sparse pseudo-input GPs as OMSGPs to reduce its computational cost of learning and prediction suitable for policy search. Then, we derive a novel multimodal policy search algorithm based on variational Bayesian inference by placing the OMSGPs as the prior of the multimodal control policy. To validate the effectiveness of our algorithm, we applied it to two typical robotic tasks in simulation: 1) object grasping and 2) table-sweep tasks since they both require the multimodality in the optimal policies. Simulation results demonstrate that our algorithm can efficiently learn multimodal policies even with high dimensional observations.


Title: Online adaptation of uncertain models using neural network priors and partially observable planning
Abstract: One of the key challenges in realizing a robot that is capable of completing a variety of manipulation tasks in the real world is the need to utilize sufficiently compact and rich world models. If the assumed prediction model does not match real observations, planning systems are unable to perform properly. We propose a system that corrects the models based on information collected from the robot's sensors. We encode prior experiences in a neural network to generate possible parameters of the models for a physics engine from real observations. An online POMDP solver is used to plan actions to complete the task while progressively validating and improving the models. We perform experiments in simulations and on a real robot. The results show that this approach appropriately clarifies observed environments, can handle dynamics with discontinuities, and with increasing domain complexity achieves a better success rate than baseline methods.


Title: Contact-Implicit Trajectory Optimization Based on a Variable Smooth Contact Model and Successive Convexification
Abstract: In this paper, we propose a contact-implicit trajectory optimization (CITO) method based on a variable smooth contact model (VSCM) and successive convexification (SCvx). The VSCM facilitates the convergence of gradient-based optimization without compromising physical fidelity. On the other hand, the proposed SCvx-based approach combines the advantages of direct and shooting methods for CITO. For evaluations, we consider non-prehensile manipulation tasks. The proposed method is compared to a version based on iterative linear quadratic regulator (iLQR) on a planar example. The results demonstrate that both methods can find physically-consistent motions that complete the tasks without a meaningful initial guess owing to the VSCM. The proposed SCvx-based method outperforms the iLQR-based method in terms of convergence, computation time, and the quality of motions found. Finally, the proposed SCvx-based method is tested on a standard robot platform and shown to perform efficiently for a real-world application.


Title: A new robot skating on water surface intimating water striders based on flexible driving mechanism*
Abstract: The amazing ability of water striders on water surface has attracted many scholars. Especially the flexible driving mechanism enable the driving legs conform to the deformation of the water surface, which effectively improving water striders' floating ability and stability. However, the current research on water striders has never designed a flexible driven robot prototype like water striders. This paper proposes a new water strider robot that can walk on water surface based on flexible driving mechanism. The robot's driving legs are designed with flexible materials and possess ellipse-like spatial trajectories like water striders through a limit pin-linkage mechanism. Based on microelement cantilever method, the flexible driving effect was analyzed with different elastic modulus and diameter. It shows that the flexible legs can row at a higher frequency before puncturing the water surface and achieve bigger work in one period compared with the rigid one. At last, the skating experiment of the robot under different stiffness and rowing frequency was carried out. The results verified that the limit frequency of the flexible driving legs and maximum moving speed of the robot are about 41.3% and 36.2% higher than those with rigid legs, respectively. Moreover, a similarity analysis of hydrodynamic characteristic constants reveals that the locomotion of the flexible driving robot is more analogous to the biological water striders than the rigid one.


Title: Performance Metrics for a Robotic Actuation System using Static and Mobile Electromagnets
Abstract: Wireless magnetic microrobots can perform complex tasks for small-scale minimally invasive surgery (MIS) that requires high precision and dexterity. The choice of the configuration of the electromagnetic actuation (EMA) system is a key issue for reliable medical applications. This paper addresses the study of a robotic EMA platform firstly devoted to ophthalmic MIS, aiming at improving the manipulability and dexterity of the procedure. To this end, a robotic EMA system comprising four static and four mobile electromagnets is investigated. Evaluation of the magnetic force and torque, the manipulability and the dexterity indexes of EMA platforms are studied. The results demonstrate that a robotic EMA platform increases the versatility of the EMA system, and becomes resourceful to perform various tasks.


Title: Data-efficient Learning of Morphology and Controller for a Microrobot
Abstract: Robot design is often a slow and difficult process requiring the iterative construction and testing of prototypes, with the goal of sequentially optimizing the design. For most robots, this process is further complicated by the need, when validating the capabilities of the hardware to solve the desired task, to already have an appropriate controller, which is in turn designed and tuned for the specific hardware. In this paper, we propose a novel approach, HPC-BBO, to efficiently and automatically design hardware configurations, and evaluate them by also automatically tuning the corresponding controller. HPC-BBO is based on a hierarchical Bayesian optimization process which iteratively optimizes morphology configurations (based on the performance of the previous designs during the controller learning process) and subsequently learns the corresponding controllers (exploiting the knowledge collected from optimizing for previous morphologies). Moreover, HPC-BBO can select a “batch” of multiple morphology designs at once, thus parallelizing hardware validation and reducing the number of time-consuming production cycles. We validate HPC-BBO on the design of the morphology and controller for a simulated 6-legged microrobot. Experimental results show that HPC-BBO outperforms multiple competitive baselines, and yields a 360% reduction in production cycles over standard Bayesian optimization, thus reducing the hypothetical manufacturing time of our microrobot from 21 to 4 months.


Title: Retrieval of magnetic medical microrobots from the bloodstream
Abstract: Untethered magnetic microrobots hold the potential to penetrate hard-to-reach areas of the human body and to perform therapy in a controlled way. In the past decade, impressive advancements have been made in this field but the clinical adoption of magnetoresponsive microrobots is still hampered by safety issues. A tool appointed for magnetic microrobots retrieval within body fluids could enable a real paradigm change, fostering their clinical translation.By starting from the general problem to retrieve magnetic microrobots injected into the bloodstream, the authors introduce a magnetic capture model that allows to design retrieval tools for magnetic cores of different diameters (down to 10 nm) and in different environmental conditions (fluid speed up to 7 cms-1). The model robustness is demonstrated by the design and testing of a retrieval catheter. In its optimal configuration, the catheter includes 27 magnets and fits a 12 F catheter. The model provides a good prediction of capture efficiency for 250 nm magnetic particles (experimental data: 77.6%, model prediction: 65%) and a very good prediction for 500 nm particles (experimental data: 93.6%, model prediction: 94%). The results support the proposed model-based design approach, which can be extended to retrieve other magnetoresponsive agents from body compartments.


Title: Experiments with Human-inspired Behaviors in a Humanoid Robot: Quasi-static Balancing using Toe-off Motion and Stretched Knees
Abstract: Humanoid robots typically display locomotion patterns that include walking with flat foot-ground contact, and knees slightly bent. However, analysis of human gait indicate that several physiological mechanisms like stretched knees, heel-strike and toe push-off increase the step length and energetic efficiency of locomotion. This paper presents an implementation of two of those mechanisms, namely stretched knees and push-off, on a quasi-static whole-body balancing controller. The influence of such mechanisms on the kinematic capabilities of the DLR humanoid robot TORO is analyzed in different experiments, and their benefits are thoroughly discussed. As a result, the energetic savings of balancing with stretched knees are shown to be of reduced magnitude with respect to the overall power consumption of the robot, and the ability of TORO for negotiating stairs is greatly enhanced.


Title: Prediction Maps for Real-Time 3D Footstep Planning in Dynamic Environments
Abstract: Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments. Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions. For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information. Considering dynamic obstacles introduces another level of complexity, since they can lead to necessary replanning or collisions at later stages. In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be efficiently planned in real time at low CPU cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.


Title: See and Be Seen – Rapid and Likeable High-Definition Camera-Eye for Anthropomorphic Robots
Abstract: While many social robots already include carefully designed robotic faces, functional robot eyes that meet human expectations are still an open challenge. As a consequence, many robots either have cameras separated from their robot eyes or active camera heads missing an anthropomorphic face. In this paper, we propose a new robot eye that is integrated in the anthropomorphic robot head Floka and fulfills a similar technical specification as a human eye including zero backlash, an increased range of motion, high velocities and accelerations, an integrated high resolution camera, and fast actuated eyelids. The robot eye is built using state-of-the-art off-the-shelf components and the CAD model of our prototype is available free of charge on request for non-commercial applications. We evaluate the technical properties of the robot eye and show that it meets and partially outperforms human eye movements and saccades.


Title: Generalized Orientation Learning in Robot Task Space
Abstract: In the context of imitation learning, several approaches have been developed so as to transfer human skills to robots, with demonstrations often represented in Cartesian or joint space. While learning Cartesian positions suffices for many applications, the end-effector orientation is required in many others. However, several crucial issues arising from learning orientations have not been adequately addressed yet. For instance, how can demonstrated orientations be adapted to pass through arbitrary desired points that comprise orientations and angular velocities? In this paper, we propose an approach that is capable of learning multiple orientation trajectories and adapting learned orientation skills to new situations (e.g., via-point and end-point), where both orientation and angular velocity are addressed. Specifically, we introduce a kernelized treatment to alleviate explicit basis functions when learning orientations. Several examples including comparison with the state-of-the-art dynamic movement primitives are provided to verify the effectiveness of our method.


Title: ATLAS FaST: Fast and Simple Scheduled TDOA for Reliable Ultra-Wideband Localization
Abstract: The ever increasing need for precise location estimation in robotics is challenging a significant amount of research. Hence, new applications such as wireless localization based aerial robot control or high precision personal safety tracking are developed. However, most of the current developments and research solely focus on the accuracy of the required localization systems. Multi-user scalability, energy efficiency and real-time capabilities are often neglected. This work aims to overcome the technology barrier by providing scalable, high accuracy, real-time localization through energy-efficient, scheduled time-difference of arrival channel access. We could show that simultaneous processing and provisioning of more than a thousand localization results per second with high reliability is possible using the proposed approach. To enable wide-spread adoption, we provide an open source implementation of our system for the robot operating system (ROS). Furthermore, we provide open source access to the raw data created during our evaluation.


Title: Self-Supervised Incremental Learning for Sound Source Localization in Complex Indoor Environment
Abstract: This paper presents an incremental learning framework for mobile robots localizing the human sound source using a microphone array in a complex indoor environment consisting of multiple rooms. In contrast to conventional approaches that leverage direction-of-arrival (DOA) estimation, the framework allows a robot to accumulate training data and improve the performance of the prediction model over time using an incremental learning scheme. Specifically, we use implicit acoustic features obtained from an auto-encoder together with the geometry features from the map for training. A self-supervision process is developed such that the model ranks the priority of rooms to explore and assigns the ground truth label to the collected data, updating the learned model on-the-fly. The framework does not require pre-collected data and can be directly applied to real-world scenarios without any human supervisions or interventions. In experiments, we demonstrate that the prediction accuracy reaches 67% using about 20 training samples and eventually achieves 90% accuracy within 120 samples, surpassing prior classification-based methods with explicit GCC-PHAT features.


Title: Development of a strain gauge based disturbance estimation and compensation technique for a wheeled inverted pendulum robot
Abstract: The ongoing development of the Inverted PENdulum Type Assistant Robot (I-PENTAR) is being undertaken by the authors. The I-PENTAR has many tasks like lifting objects with unknown mass, pushing and pulling a carts and many more. During execution of these tasks unknown disturbances enter the system and cause dynamic responses and errors. Most notably, the wheels of the robot move with excessively transients. To alleviate this problem, a strain gauge based sensor is attached to the existing structure of the robot to gain information regarding the disturbances. This allows minimal change to the system design while improving robustness to disturbances. In this paper the development of the sensor, the corresponding model and a method of updating the existing purely estimation based control is presented together with tests.


Title: Spatio-temporal representation for long-term anticipation of human presence in service robotics
Abstract: We propose an efficient spatio-temporal model for mobile autonomous robots operating in human populated environments. Our method aims to model periodic temporal patterns of people presence, which are based on peoples' routines and habits. The core idea is to project the time onto a set of wrapped dimensions that represent the periodicities of people presence. Extending a 2D spatial model with this multidimensional representation of time results in a memory efficient spatio-temporal model. This model is capable of long-term predictions of human presence, allowing mobile robots to schedule their services better and to plan their paths. The experimental evaluation, performed over datasets gathered by a robot over a period of several weeks, indicates that the proposed method achieves more accurate predictions than the previous state of the art used in robotics.


Title: Object Transfer Point Estimation for Fluent Human-Robot Handovers
Abstract: Handing over objects is the foundation of many human-robot interaction and collaboration tasks. In the scenario where a human is handing over an object to a robot, the human chooses where the object needs to be transferred. The robot needs to accurately predict this point of transfer to reach out proactively, instead of waiting for the final position to be presented. This work presents an efficient method for predicting the Object Transfer Point (OTP), which synthesizes (1) an offline OTP calculated based on human preferences observed in a human-robot motion study with (2) a dynamic OTP predicted based on the observed human motion. Our proposed OTP predictor is implemented on a humanoid nursing robot and experimentally validated in human-robot handover tasks. Compared to only using static or dynamic OTP estimators, it has better accuracy at the earlier phase of handover (up to 45% of the handover motion) and can render fluent handovers with a reach-to-grasp response time (about 3.1 secs) close to natural human receiver's response. In addition, the OTP prediction accuracy is maintained across the robot's visible workspace by utilizing a user-adaptive reference frame.


Title: Controlling AeroBot: Development of a Motion Planner for an Actively Articulated Wheeled Humanoid Robot
Abstract: There is value in exploring new robot morphologies that combine the benefits of legged robots (i.e. high terrain adaptability, humanlike form factor) with those of wheeled systems (i.e. high stability, low energy consumption). Once the basic design concept has been demonstrated, there is a further requirement to validate the controllability of the system through adaptation and implementation of advanced control techniques. This research presents a motion planner that enables the Aerobot robot, an actively articulated wheeled humanoid robot capable of performing step climbing and gap crossing, to plan dynamically stable motion in response to a range of task conditions. Using a model of the robots kinematics, a motion planner is developed. The sequential quadratic program algorithm is used to solve quadratic objectives and non-linear constraints pertaining to stability and postural configuration adjustment requirements. The results showed good tracking of the robot's Zero Moment Point while transitioning between postural configurations and traversing obstacles. During these phase transitions, robustness in maintaining balance and position is also demonstrated via velocity control of the drive wheels.


Title: User Centric Device Registration for Streamlined Workflows in Surgical Navigation Systems
Abstract: Alongside sweeping transformations in healthcare, a timeless drive to make surgical interventions less invasive and more effective has led to the integration of disparate technologies into surgical navigation systems. Fusions of device tracking and medical imaging modalities have been comprehensively investigated for opportunities to improve care. Such composite systems provide more and better information, enabling clinicians to operate less invasively and more effectively. Because of these merits, the preoperative ritual of harmonizing multiple information sources has been tacitly adopted. In this paper, we challenge the paradigm of preoperative registration. Proposed herein is a technique in which a clinician registers an interventional device to a navigation system simply by gesturing the device through a strategically designed fixture. In the background, the system continuously monitors the device path for this registration gesture. We demonstrate generality by applying the method to both robotic and electromagnetically tracked devices, and exhibit versatility by repeating the registration at multiple device base locations. Experiments indicate sub-millimeter accuracy versus conventional approaches on the same setup. Consequently, clinicians can register devices on the fly, increasing flexibility in setup and redefining workflow possibilities in surgery.


Title: Compliant four degree-of-freedom manipulator with locally deformable elastic elements for minimally invasive surgery
Abstract: Minimally Invasive Surgery (MIS) is one of the most successful applications of surgical robots. Although the introduction of robotic technology has brought a number of benefits, further advancements in MIS are limited by the size and bending radius of instruments. In this paper, we present a compliant four degree-of-freedom manipulator that consists of elastic elements with partly thinner structures. The proposed mechanism allows the elastic element to deform locally, thus minimizing its bending radius while the low number of mechanical parts greatly contributes to its compactness. This paper describes the design strategy, optimization method using FEA, prototype implementation, and evaluations. The evaluations reveal high accuracy and repeat accuracy, which are key elements for robotic instruments in MIS. Further, the prototype is able to exert sufficient force and it is possible to perform a simulated needle insertion task using the manipulator, demonstrating the feasibility of the proposed mechanism.


Title: Safe teleoperation of a laparoscope holder with dynamic precision but low stiffness.
Abstract: A laparoscope is a key element in Minimally Invasive Surgery (MIS) as it provides visual feedback to the surgeon. To overcome the drawbacks induced by its manual operation by a human assistant, it can be fixed on the end-effector of a robotic assistant teleoperated by the surgeon: laparoscope displacements are commanded through a master input interface (e.g., joysticks, voice control, etc.) and replicated accordingly at the slave level. In this approach, precision is of high importance to ensure a good operability by the surgeon. This is why the state-of-the-art relies on rigid laparoscope holders with high-gain PID position control, ensuring high static and dynamic precision. However, in the event of undetected obstacles, such stiff systems generate high forces that may cause harm to the patient. Rather, a compliant behaviour is desirable but it leads to a lack of precision when disturbances occur, such as the unknown friction between the trocar and the laparoscope. In this paper we present a “compliant-and-precise” laparo-scope holder with 4 active Degrees of Freedom (DoFs). Its design is based on cable transmission used for haptic interfaces, thus it exhibits very high backdrivability. The paper shows how an intelligent PID position controller can be used to compensate for unknown friction at the trocar while keeping very low PID gains and a satisfactory tracking precision.


Title: Real-time Teleoperation of Flexible Beveled-tip Needle Insertion using Haptic Force Feedback and 3D Ultrasound Guidance
Abstract: Needle insertion procedures can greatly benefit from robotic systems to improve their accuracy and success rate. However, a fully automated system is usually not desirable and the clinicians need to be included in the control loop. In this paper we present a teleoperation framework for beveledtip flexible needle steering that enables the user to directly and intuitively control the trajectory of the needle tip via a haptic interface. The 6 degrees of freedom of the needle base are used to perform several automatic safety and targeting tasks in addition to the one controlled by the user. Real-time visual feedback is provided by a 3D ultrasound probe and used to track the 3D location of the needle and of a spherical target. Several haptic force feedback are compared as well as two different levels of mix between automated and user-controlled tasks. A validation of the framework is conducted in gelatin phantom and a mean targeting accuracy of 2.5 mm is achieved. The results show that providing an adequate haptic guidance to the user can reduce the risks of damage to the tissues while still letting the surgeon in control of the tip trajectory.


Title: End-User Robot Programming Using Mixed Reality
Abstract: Mixed Reality (MR) is a promising interface for robot programming because it can project an immersive 3D visualization of a robot's intended movement onto the real world. MR can also support hand gestures, which provide an intuitive way for users to construct and modify robot motions. We present a Mixed Reality Head-Mounted Display (MRHMD) interface that enables end-users to easily create and edit robot motions using waypoints. We describe a user study where 20 participants were asked to program a robot arm using 2D and MR interfaces to perform two pick-and-place tasks. In the primitive task, participants created typical pickand-place programs. In the adapted task, participants adapted their primitive programs to address a more complex pickand-place scenario, which included obstacles and conditional reasoning. Compared to the 2D interface, a higher number of users were able to complete both tasks in significantly less time, and reported experiencing lower cognitive workload, higher usability, and higher naturalness with the MR-HMD interface.


Title: Control of Delayed Bilateral Teleoperation System for Robotic Tele-Echography
Abstract: This paper describes development of a controllerfor bilateral robotic system for tele-echography with delayed communications. The system comprises two identical 6DOF robotic devices based on Stewart-Gough mechanisms, which were developed especially for the sake of the considered application. Controller design is facilitated by a symmetry of the teleoperation setup, in which the master and slave devices have identical geometry, actuation and measurement arrays. To further simplify the analysis, we treat coupling between degrees of freedom as exogenous disturbances and this allows us to split the control problem into six independent IDOF settings. The IDOF problems are addressed then using a novel approach to bilateral teleoperation control, based on a complete parameterization of feasible teleoperators. It allows to intuitively shape teleoperator performance while guaranteeing passivity and thus coupled stability of the system. The potential of the proposed control method is demonstrated with experimental results.


Title: A Unified Framework for the Teleoperation of Surgical Robots in Constrained Workspaces
Abstract: In adult laparoscopy, robot-aided surgery is a reality in thousands of operating rooms worldwide, owing to the increased dexterity provided by the robotic tools. Many robots and robot control techniques have been developed to aid in more challenging scenarios, such as pediatric surgery and microsurgery. However, the prevalence of case-specific solutions, particularly those focused on non-redundant robots, reduces the reproducibility of the initial results in more challenging scenarios. In this paper, we propose a general framework for the control of surgical robotics in constrained workspaces under teleoperation, regardless of the robot geometry. Our technique is divided into a slave-side constrained optimization algorithm, which provides virtual fixtures, and with Cartesian impedance on the master side to provide force feedback. Experiments with two robotic systems, one redundant and one non-redundant, show that smooth teleoperation can be achieved in adult laparoscopy and infant surgery.


Title: High-Speed Ring Insertion by Dynamic Observable Contact Hand
Abstract: This study proposes a dynamic observable contact (DOC) hand as a new multifingered hand to ensure high- speed insertion in an assembly process with a small clearance between objects. To achieve insertion with a small clearance at high speed, a robot hand must realize both impact reduction and position-error compensation when the two objects contact each other. The DOC hand, with its features of 6-degrees-of- freedom dynamic passivity and object-pose observability, can realize both impact reduction and position-error compensation. To evaluate the effectiveness of the DOC hand, we construct a robot system using the DOC hand. We evaluate the performance of the system in the task of ring insertion with a small clearance (0-36um). The results indicate that the robot system performs with a higher speed than a human. In fact, the average cycle time is 2.42 s for the robot, whereas it is 2.58 s for a human. The DOC hand has opened up the possibility for achieving high-speed precision assembly using robots.


Title: Learning To Grasp Under Uncertainty Using POMDPs
Abstract: Robust object grasping under uncertainty is an essential capability of service robots. Many existing approaches rely on far-field sensors, such as cameras, to compute a grasp pose and perform open-loop grasp after placing gripper under the pose. This often fails as a result of sensing or environment uncertainty. This paper presents a principled, general and efficient approach to adaptive grasping, using both tactile and visual sensing as feedback. We first model adaptive grasping as a partially observable Markov decision process (POMDP), which handles uncertainty naturally. We solve the POMDP for sampled objects from a set, in order to generate data for learning. Finally, we train a grasp policy, represented as a deep recurrent neural network (RNN), in simulation through imitation learning. By combining model-based POMDP planning and imitation learning, the proposed approach achieves robustness under uncertainty, generalization over many objects, and fast execution. In particular, we show that modeling only a small sample of objects enables us to learn a robust strategy to grasp previously unseen objects of varying shapes and recover from failure over multiple steps. Experiments on the G3DB object dataset in simulation and a smaller object set with a real robot indicate promising results.


Title: Soft Hands with Embodied Constraints: The Soft ScoopGripper
Abstract: The design of robotic grippers requires the accomplishment of several contrasting requirements. Research in under actuated soft hands is a lively topic, with several potentialities and challenges. Soft hands are simple, robust and able of adapting to uncertain environment and operative conditions, however their intrinsic compliance and underactuation reduce control capabilities and precision. Recent studies attempted to compensate this limitation by wisely exploiting environmental constraints and considering them as supports to accomplish the task rather than obstacle to avoid. The development of grasp primitives taking into account environment features leaded to interesting and encouraging results. In this paper, we propose to embed on the hand the positive aspects of studies on environmental constraints exploitation. We present a modular under actuated soft hand in which we added a scoop as a feature of the palm, which simplify object grasping. The scoop allows to grasp objects in narrow spaces, augments the possible contact areas, allows to obtain more robust grasps, with lower forces. The paper illustrates the main design principles, a prototype and experimental results.


Title: A Simple Electric Soft Robotic Gripper with High-Deformation Haptic Feedback
Abstract: Compliant robotic grippers are more robust to uncertainties in grasping and manipulation tasks, especially when paired with tactile and proprioceptive feedback. Although considerable progress has been made towards achieving proprioceptive soft robotic grippers, current efforts require complex driving hardware or fabrication techniques. In this paper, we present a simple scalable soft robotic gripper integrated with high-deformation strain and pressure sensors. The gripper is composed of structurally-compliant handed shearing auxetic structures actuated by electric motors. Coupling deformable sensors with the compliant grippers enables gripper proprioception and object classification. With this sensorized system, we are able to identify objects' size to within 33% of actual radius and sort objects as hard/soft with 78% accuracy.


Title: Using Geometric Features to Represent Near-Contact Behavior in Robotic Grasping
Abstract: In this paper we define two feature representations for grasping. These representations capture hand-object geometric relationships at the near-contact stage - before the fingers close around the object. Their benefits are: 1) They are stable under noise in both joint and pose variation. 2) They are largely hand and object agnostic, enabling direct comparison across different hand morphologies. 3) Their format makes them suitable for direct application of machine learning techniques developed for images. We validate the representations by: 1) Demonstrating that they can accurately predict the distribution of ε-metric values generated by kinematic noise. I.e., they capture much of the information inherent in contact points and force vectors without the corresponding instabilities. 2) Training a binary grasp success classifier on a real-world data set consisting of 588 grasps.


Title: A Robotic Cell for Multi-Resolution Additive Manufacturing
Abstract: Extrusion-based additive manufacturing (AM), also known as fused deposition modeling (FDM) extrudes filaments through a heated nozzle and builds a part layer-by-layer. Using a smaller diameter nozzle can achieve better surface finish. However, there is a trade-off between surface finish and build times as using a small diameter nozzle leads to smaller layer thickness and long build times. Traditional FDM printers create a part with planar layers, and this restricts control over fiber orientations. This paper presents a robotic cell for multi-resolution AM. The cell consists of two 6 degrees of freedom (DOF) robot manipulators capable of printing non-planar and/or planar layers. We describe algorithms for decomposing parts into multi-resolution layers and generating collision-free trajectories for the robot manipulators. We validate our approach by printing five parts with multi-resolution.


Title: Multimodal Bin Picking System with Compliant Tactile Sensor Arrays for Flexible Part Handling*
Abstract: This paper presents a robot control architecture comprised of tactile and vision sensors incorporated into an off-the-shelf bin picking system. The proposed architecture facilitates flexible and reliable handling of objects and materials by employing a tactile grasp validation system and in-hand object monitoring. Two industrial grippers, specifically a magnetic gripper and a flexible vacuum gripper, are equipped with a compliant custom tactile sensor array. The algorithms used are for each specific gripper and respective sensor, however are transferrable to other grippers as well. The tactile sensing augments vision-based picking approaches, thus supporting in-hand object recognition [1] that is particularly useful for hard-to-recognize objects such as objects with transparent or shiny surfaces. Algorithms for tactile-based object pose estimation in the gripper and for grasp monitoring, including grasp validation, complete the approach.


Title: Offline Policy Iteration Based Reinforcement Learning Controller for Online Robotic Knee Prosthesis Parameter Tuning
Abstract: This paper aims to develop an optimal controller that can automatically provide personalized control of robotic knee prosthesis in order to best support gait of individual prosthesis wearers. We introduced a new reinforcement learning (RL) controller for this purpose based on the promising ability of RL controllers to solve optimal control problems through interactions with the environment without requiring an explicit system model. However, collecting data from a human-prosthesis system is expensive and thus the design of a RL controller has to take into account data and time efficiency. We therefore propose an offline policy iteration based reinforcement learning approach. Our solution is built on the finite state machine (FSM) impedance control framework, which is the most used prosthesis control method in commercial and prototypic robotic prosthesis. Under such a framework, we designed an approximate policy iteration algorithm to devise impedance parameter update rules for 12 prosthesis control parameters in order to meet individual users' needs. The goal of the reinforcement learning-based control was to reproduce near-normal knee kinematics during gait. We tested the RL controller obtained from offline learning in real time experiment involving the same able-bodied human subject wearing a robotic lower limb prosthesis. Our results showed that the RL control resulted in good convergent behavior in kinematic states, and the offline learning control policy successfully adjusted the prosthesis control parameters to produce near-normal knee kinematics in 10 updates of the impedance control parameters.


Title: Estimating Loads Along Elastic Rods
Abstract: Mechanics-based models of thin elastic structures are prevalent in robotics research, both in soft/continuum robot modeling, and in robotic manipulation of strings, sutures, needles, and endoscopes. In all these applications, distributed loads along the device's length can affect its shape in space. Estimation of the distributed loading based on observation of the object's shape constitutes a classical mechanics inverse problem that would be useful in many applications, but this problem has received relatively little attention to date. In this paper, we propose methods to estimate distributed loads on an elastic rod using a large-deflection Cosserat-rod model and constrained nonlinear optimization. We perform experiments that illustrate the feasibility of using these methods to locate regions of high contact force along the rod, and to estimate magnitudes of the forces that are applied. Results show that overall force magnitudes and locations can be estimated with average error of 0.29 N (6.7% of average resultant magnitude) and 4 mm (2% of rod length) for complex double-bend shapes, and the shape approximation has near-zero error.


Title: The Importance of Metric Learning for Robotic Vision: Open Set Recognition and Active Learning
Abstract: State-of-the-art deep neural network recognition systems are designed for a static and closed world. It is usually assumed that the distribution at test time will be the same as the distribution during training. As a result, classifiers are forced to categorise observations into one out of a set of predefined semantic classes. Robotic problems are dynamic and open world; a robot will likely observe objects that are from outside of the training set distribution. Classifier outputs in robotic applications can lead to real-world robotic action and as such, a practical recognition system should not silently fail by confidently misclassifying novel observations. We show how a deep metric learning classification system can be applied to such open set recognition problems, allowing the classifier to label novel observations as unknown. Further to detecting novel examples, we propose an open set active learning approach that allows a robot to efficiently query a user about unknown observations. Our approach enables a robot to improve its understanding of the true distribution of data in the environment, from a small number of label queries. Experimental results show that our approach significantly outperforms comparable methods in both the open set recognition and active learning problems.


Title: Learning Discriminative Embeddings for Object Recognition on-the-fly
Abstract: We address the problem of learning to recognize new objects on-the-fly efficiently. When using CNNs, a typical approach for learning new objects is by fine-tuning the model. However, this approach relies on the assumption that the original training set is available and requires high-end computational resources for training the ever-growing dataset efficiently, which can be unfeasible for robots with limited hardware. To overcome these limitations, we propose a new architecture that: 1) Instead of predicting labels, it learns to generate discriminative and separable embeddings of an object's viewpoints by using a Supervised Triplet Loss, which is easier to implement than current smart mining techniques and the trained model can be applied to unseen objects. 2) Infers an object's identity efficiently by utilizing a lightweight classifier in the features embedding space, this keeps the inference time in the order of milliseconds and can be retrained efficiently when new objects are learned. We evaluate our approach on four real-world images datasets used for Robotics and Computer Vision applications: Amazon Robotics Challenge 2017 by MIT-Princeton, T-LESS, ToyBoX, and CORe50 datasets. Code available at [1].


Title: Spatial change detection using voxel classification by normal distributions transform
Abstract: Detection of spatial change around a robot is indispensable in several robotic applications, such as search and rescue, security, and surveillance. The present paper proposes a fast spatial change detection technique for a mobile robot using an on-board RGB-D/stereo camera and a highly precise 3D map created by a 3D laser scanner. This technique first converts point clouds in a map and measured data to grid data (ND voxels) using normal distributions transform and classifies the ND voxels into three categories. The voxels in the map and the measured data are then compared according to the category and features of the ND voxels. Overlapping and voting techniques are also introduced in order to detect the spatial changes more robustly. We conducted experiments using a mobile robot equipped with real-time range sensors to confirm the performance of the proposed real-time localization and spatial change detection techniques in indoor and outdoor environments.


Title: Unsupervised Learning of Assistive Camera Views by an Aerial Co-robot in Augmented Reality Multitasking Environments
Abstract: This paper presents a novel method by which an assistive aerial robot can learn the relevant camera views within a task domain through tracking the head motions of a human collaborator. The human's visual field is modeled as an anisotropic spherical sensor, which decays in acuity towards the periphery, and is integrated in time throughout the domain. This data is resampled and fed into an expectation maximization solver in order to estimate the environment's visual interest as a mixture of Gaussians. A dynamic coverage control law directs the robot to capture camera views of the peaks of these Gaussians which is broadcast to an augmented reality display worn by the human operator. An experimental study is presented that assesses the influence of the assistive robot on reflex time, head motion, and task completion time.


Title: Visual Coverage Control for Teams of Quadcopters via Control Barrier Functions
Abstract: This paper presents a coverage control strategy for teams of quadcopters that ensures that no area is left unsurveyed in between the fields of view of the visual sensors mounted on the quadcopters. We present a locational cost that quantifies the team's coverage performance according to the sensors' performance function. Moreover, the cost function penalizes overlaps between the fields of view of the different sensors, with the objective of increasing the area covered by the team. A distributed control law is derived for the quadcopters so that they adjust their position and zoom according to the direction of ascent of the cost. Control barrier functions are implemented to ensure that, while executing the gradient ascent control law, no holes appear in between the fields of view of neighboring robots. The performance of the algorithm is evaluated in simulated experiments.


Title: Robot Co-design: Beyond the Monotone Case
Abstract: Recent advances in 3D printing and manufacturing of miniaturized robotic hardware and computing are paving the way to build inexpensive and disposable robots. This will have a large impact on several applications including scientific discovery (e.g., hurricane monitoring), search-and-rescue (e.g., operation in confined spaces), and entertainment (e.g., nano drones). The need for inexpensive and task-specific robots clashes with the current practice, where human experts are in charge of designing hardware and software aspects of the robotic platform. This makes the robot design process expensive and time consuming, and ultimately unsuitable for small-volumes low-cost applications. This paper considers the computational robot co-design problem, which aims to create an automatic algorithm that selects the best robotic modules (sensing, actuation, computing) in order to maximize the performance on a task, while satisfying given specifications (e.g., maximum cost of the resulting design). We propose a binary optimization formulation of the co-design problem and show that such formulation generalizes previous work based on strong modeling assumptions. We show that the proposed formulation can solve relatively large co-design problems in seconds and with minimal human intervention. We demonstrate the proposed approach in two applications: the co-design of an autonomous drone racing platform and the co-design of a multi-robot system.


Title: Critically fast pick-and-place with suction cups
Abstract: Fast robotics pick-and-place with suction cups is a crucial component in the current development of automation in logistics (factory lines, e-commerce, etc.). By “critically fast” we mean the fastest possible movement for transporting an object such that it does not slip or fall from the suction cup. The main difficulties are: (i) handling the contact between the suction cup and the object, which fundamentally involves kinodynamic constraints; and (ii) doing so at a low computational cost, typically a few hundreds of milliseconds. To address these difficulties, we propose (a) a model for suction cup contacts, (b) a procedure to identify the contact stability constraint based on that model, and (c) a pipeline to parameterize, in a time-optimal manner, arbitrary geometric paths under the identified contact stability constraint. We experimentally validate the proposed pipeline on a physical robot system: the cycle time for a typical pick-and-place task was less than 5 seconds, planning and execution times included. The full pipeline is released as opensource for the robotics community.


Title: Robust Link Position Tracking Control for Robot Manipulators with Series Elastic Actuators Using Time-delay Estimation
Abstract: This paper aims to develop a controller for a robot manipulator equipped with series elastic actuators (SEAs) to precisely track the desired link position coping with deflections from the intrinsic compliance. The well-known time-delay estimation (TDE) technique is modified for devising the new controller. In this paper, we first report that the conventional use of a constant gain matrix for the TDE framework is insufficient for high accuracy tracking because the tracking accuracy is significantly deteriorated and the closed-loop stability may be threatened. Accordingly, the new controller employs link inertia information with dynamic coupling terms to define the gain for TDE and then employs terminal sliding mode (TSM) control to enhance robustness and convergence speed. Particularly, the modified TDE is applied in the two-staged manner which enables to compensate the complicated nonlinear dynamics terms in SEA dynamics. The TSM synergistically amalgamates the accuracy, robustness, and convergence in tracking. The proposed controller is numerically validated by comparative experiments with a SEA-driven manipulator.


Title: Robotic Cutting: Mechanics and Control of Knife Motion
Abstract: Effectiveness of cutting is measured by the ability to achieve material fracture with smooth knife movements. The work performed by a knife overcomes the material toughness, acts against the blade-material friction, and generates shape deformation. This paper studies how to control a 2-DOF robotic arm equipped with a force/torque sensor to cut through an object in a sequence of three moves: press, push, and slice. For each move, a separate control strategy in the Cartesian space is designed to incorporate contact and/or force constraints while following some prescribed trajectory. Experiments conducted over several types of natural foods have demonstrated smooth motions like would be commanded by a human hand.


Title: A constrained control-planning strategy for redundant manipulators
Abstract: This paper presents an interconnected control-planning strategy for redundant manipulators, subject to system and environmental constraints. The method incorporates low-level control characteristics and high-level planning components into a robust strategy for manipulators acting in complex environments, subject to joint limits. This strategy is formulated using an adaptive control rule, a computational efficient estimation of the robot's mathematical model and the nullspace of the constraints. A path is generated that takes into account the capabilities of the platform. The proposed method is computationally efficient, enabling its implementation on a real multi-body robotic system. Through experimental results with a 7 degree-of-freedom (DOF) manipulator, we demonstrate the performance of the method in real-world scenarios.


Title: Reinforcement Learning on Variable Impedance Controller for High-Precision Robotic Assembly
Abstract: Precise robotic manipulation skills are desirable in many industrial settings, reinforcement learning (RL) methods hold the promise of acquiring these skills autonomously. In this paper, we explicitly consider incorporating operational space force/torque information into reinforcement learning; this is motivated by humans heuristically mapping perceived forces to control actions, which results in completing high-precision tasks in a fairly easy manner. Our approach combines RL with force/torque information by incorporating a proper operational space force controller; where we also exploit different ablations on processing this information. Moreover, we propose a neural network architecture that generalizes to reasonable variations of the environment. We evaluate our method on the open-source Siemens Robot Learning Challenge, which requires precise and delicate force-controlled behavior to assemble a tight-fit gear wheel set.


Title: A Compliant and Precise Pneumatic Rotary Drive Using Pneumatic Artificial Muscles in a Swash Plate Design
Abstract: Compliant and precise rotary drive units are essential for the design of articulated robots that are capable of safe human-robot collaboration. In this paper, we present a new pneumatic rotary drive unit that combines the compliance of pneumatic systems with the ability to perform high precision positioning. We use pneumatic artificial muscles (PAMs) pulling on a swash plate to avoid the stick-slip phenomenon and to realize adjustable stiffness. Furthermore, the presented drive unit can operate in 360° continuous rotation. These properties make the drive particularly suitable for the later use in human-robot collaboration. We explain the mechanic design as well as the pneumatic and electric control system that we use to operate the drive unit. We derive the equations to calculate the static torque distribution and compare the theoretical results to the data measured on the realized laboratory test stand, depicted in figure 1. The accuracy of the used 16-bit encoder is achieved and adjustable stiffness is realized and measured on the laboratory test stand. The measurements of the reaction to a step response are discussed based on a first and basic control strategy.


Title: Exact Modal Characterization of the Non Conservative Non Linear Radial Mass Spring System
Abstract: Since the spread of robotic systems embedding in their mechanics purposefully designed elastic elements, the interest in characterizing and exploiting non-linear oscillatory behaviors has progressively grown. However, few works so far looked at the problem from the point of view of modal analysis. This is particularly surprising if considered the central role that modal theory had in the development of classic results in analysis and control of linear mechanical systems. With the aim of making a step toward translating and extending this powerful tool to the robotic field, we present the complete modal characterization of a simple yet representative non-linear elastic robot: the 2D planar mass-spring-damper system. Generic non-linear elastic forces and dissipative effects are considered. We provide here exact descriptions of the two non-linear normal modes of the system. We then extend the analysis to generic combinations of the modes in conservative case and for small damping. Simulations are provided to illustrate the theoretical results. This is one of the very firsts applications of normal mode theory to dynamically coupled non-linear systems, and the first exact result in the field.


Title: Body Lift and Drag for a Legged Millirobot in Compliant Beam Environment
Abstract: Much current study of legged locomotion has rightly focused on foot traction forces, including on granular media. Future legged millirobots will need to go through terrain, such as brush or other vegetation, where the body contact forces significantly affect locomotion. In this work, a (previously developed) low-cost 6-axis force/torque sensing shell is used to measure the interaction forces between a hexapedal millirobot and a set of compliant beams, which act as a surrogate for a densely cluttered environment. Experiments with a VelociRoACH robotic platform are used to measure lift and drag forces on the tactile shell, where negative lift forces can increase traction, even while drag forces increase. The drag energy and specific resistance required to pass through dense terrains can be measured. Furthermore, some contact between the robot and the compliant beams can lower specific resistance of locomotion. For small, light-weight legged robots in the beam environment, the body motion depends on both legground and body-beam forces. A shell-shape which reduces drag but increases negative lift, such as the half-ellipsoid used, is suggested to be advantageous for robot locomotion in this type of environment.


Title: Tightly Coupled 3D Lidar Inertial Odometry and Mapping
Abstract: Ego-motion estimation is a fundamental requirement for most mobile robotic applications. By sensor fusion, we can compensate the deficiencies of stand-alone sensors and provide more reliable estimations. We introduce a tightly coupled lidar-IMU fusion method in this paper. By jointly minimizing the cost derived from lidar and IMU measurements, the lidarIMU odometry (LIO) can perform well with considerable drifts after long-term experiment, even in challenging cases where the lidar measurement can be degraded. Besides, to obtain more reliable estimations of the lidar poses, a rotation-constrained refinement algorithm (LIO-mapping) is proposed to further align the lidar poses with the global map. The experiment results demonstrate that the proposed method can estimate the poses of the sensor pair at the IMU update rate with high precision, even under fast motion conditions or with insufficient features.


Title: Joint Inference of Kinematic and Force Trajectories with Visuo-Tactile Sensing
Abstract: To perform complex tasks, robots must be able to interact with and manipulate their surroundings. One of the key challenges in accomplishing this is robust state estimation during physical interactions, where the state involves not only the robot and the object being manipulated, but also the state of the contact itself. In this work, within the context of planar pushing, we extend previous inference-based approaches to state estimation in several ways. We estimate the robot, object, and the contact state on multiple manipulation platforms configured with a vision-based articulated model tracker, and either a biomimetic tactile sensor or a force-torque sensor. We show how to fuse raw measurements from the tracker and tactile sensors to jointly estimate the trajectory of the kinematic states and the forces in the system via probabilistic inference on factor graphs, in both batch and incremental settings. We perform several benchmarks with our framework and show how performance is affected by incorporating various geometric and physics based constraints, occluding vision sensors, or injecting noise in tactile sensors. We also compare with prior work on multiple datasets and demonstrate that our approach can effectively optimize over multi-modal sensor data and reduce uncertainty to find better state estimates.


Title: Every Hop is an Opportunity: Quickly Classifying and Adapting to Terrain During Targeted Hopping
Abstract: Practical use of robots in diverse domains requires programming for, or adapting to, each domain and its unique characteristics. Failure to do so compromises the ability of the robot to achieve task-relevant objectives. Here we describe how the learned terrain reaction force profiles of a hopping robot serve the additional objectives of classifying terrain and quickly learning control strategies to accomplish a jumping task on novel terrain. We show that the reaction forces experienced during closed-loop jumping are sufficient to discriminate between three different terrain types (granular, trampoline, and rigid) when using the learned models as discriminators. Building on this, we show that applying the classification to unknown terrain types leads to faster task completion, where the task objective is to meet a specific jump height. The classification experiments, utilizing real-world jumping data, achieve 95% prediction accuracy. The online learning experiments leverage simulation as there is more control over the terrain properties. Terrain-informed learning achieves the target hop heights more than 2x faster than without terrain knowledge when the prediction is correct, and 1.5x faster when the prediction is incorrect. Thus, applying the closest approximately known terrain knowledge facilitates low shot learning when hopping on unknown terrain.


Title: Semiparametrical Gaussian Processes Learning of Forward Dynamical Models for Navigating in a Circular Maze
Abstract: This paper presents a problem of model learning for the purpose of learning how to navigate a ball to a goal state in a circular maze environment with two degrees of freedom. The motion of the ball in the maze environment is influenced by several non-linear effects such as dry friction and contacts, which are difficult to model physically. We propose a semiparametric model to estimate the motion dynamics of the ball based on Gaussian Process Regression equipped with basis functions obtained from physics first principles. The accuracy of this semiparametric model is shown not only in estimation but also in prediction at n-steps ahead and its compared with standard algorithms for model learning. The learned model is then used in a trajectory optimization algorithm to compute ball trajectories. We propose the system presented in the paper as a benchmark problem for reinforcement and robot learning, for its interesting and challenging dynamics and its relative ease of reproducibility.


Title: Adaptive Variance for Changing Sparse-Reward Environments
Abstract: Robots that are trained to perform a task in a fixed environment often fail when facing unexpected changes to the environment due to a lack of exploration. We propose a principled way to adapt the policy for better exploration in changing sparse-reward environments. Unlike previous works which explicitly model environmental changes, we analyze the relationship between the value function and the optimal exploration for a Gaussian-parameterized policy and show that our theory leads to an effective strategy for adjusting the variance of the policy, enabling fast adapt to changes in a variety of sparse-reward environments.


Title: Combining Physical Simulators and Object-Based Networks for Control
Abstract: Physics engines play an important role in robot planning and control; however, many real-world control problems involve complex contact dynamics that cannot be characterized analytically. Most physics engines therefore employ approximations that lead to a loss in precision. In this paper, we propose a hybrid dynamics model, simulator-augmented interaction networks (SAIN), combining a physics engine with an object-based neural network for dynamics modeling. Compared with existing models that are purely analytical or purely data-driven, our hybrid model captures the dynamics of interacting objects in a more accurate and data-efficient manner. Experiments both in simulation and on a real robot suggest that it also leads to better performance when used in complex control tasks. Finally, we show that our model generalizes to novel environments with varying object shapes and materials.


Title: Using Data-Driven Domain Randomization to Transfer Robust Control Policies to Mobile Robots
Abstract: This work develops a technique for using robot motion trajectories to create a high quality stochastic dynamics model that is then leveraged in simulation to train control policies with associated performance guarantees. We demonstrate the idea by collecting dynamics data from a 1/5 scale agile ground vehicle, fitting a stochastic dynamics model, and training a policy in simulation to drive around an oval track at up to 6.5 m/s while avoiding obstacles. We show that the control policy can be transferred back to the real vehicle with little loss in predicted performance. We compare this to an approach that uses a simple analytic car model to train a policy in simulation and show that using a model with stochasticity learned from data leads to higher performance in terms of trajectory tracking accuracy and collision probability. Furthermore, we show empirically that simulation-derived performance guarantees transfer to the actual vehicle when executing a policy optimized using a deep stochastic dynamics model fit to vehicle data.


Title: Coordinating multi-robot systems through environment partitioning for adaptive informative sampling
Abstract: As robotic platforms have become more capable and autonomous, they have increasingly been utilized in time sensitive applications such as search and rescue. To that end, we have developed a system for teams of robots to efficiently explore an environment while taking sensor measurements. The system utilizes an information seeking algorithm that generates high priority points of interest based on the highest expected information gained per distance travelled. In order to coordinate multiple robots, the system partitions the area into different regions according to the effort needed to explore each region. Robots are assigned different regions to measure in order to minimize repetition of work and reduce interference between each robot.We present an information rate adaptive sampling approach for tasking robots within an environment to gather sensor measurements. We evaluated our approach within a simulation environment with one to four robots. Multiple robots are coordinated through our region segmentation approach. The data shows efficiency gains through the use of adaptive information gain rate tasking above a naïve closest point approach. We also see positive results from using the region segmentation technique. We further the experimentation by testing the algorithm on real world robots and verify the results in real world experimentation.


Title: A Fleet of Miniature Cars for Experiments in Cooperative Driving
Abstract: We introduce a unique experimental testbed that consists of a fleet of 16 miniature Ackermann-steering vehicles. We are motivated by a lack of available low-cost platforms to support research and education in multi-car navigation and trajectory planning. This article elaborates the design of our miniature robotic car, the Cambridge Minicar, as well as the fleet's control architecture. Our experimental testbed allows us to implement state-of-the-art driver models as well as autonomous control strategies, and test their validity in a real, physical multi-lane setup. Through experiments on our miniature highway, we are able to tangibly demonstrate the benefits of cooperative driving on multi-lane road topographies. Our setup paves the way for indoor large-fleet experimental research.


Title: Multi-robot Informative Path Planning with Continuous Connectivity Constraints
Abstract: We consider the problem of information collection from a polygonal environment using a multi-robot system, subject to continuous connectivity constraints. In particular, the robots, having a common radius of communication range, must remain connected throughout the exploration maximizing the information collection. The information gained through the exploration of the terrain is wirelessly transmitted to a base station. The base station performs the centralized planning of informative paths for the robots based on the information collected by them and thereafter, the robots follow these paths. This paper formulates the problem of multi-robot informative path planning under continuous connectivity constraints as an integer program leveraging the ideas of bipartite graph matching and minimal node separators. Theoretical analysis of the proposed solution proves that the informative paths will be collision-free and will be free of both livelock and deadlock. Experimental results demonstrate the low computational requirements of our algorithm for planning the informative paths, taking only about 0.75 sec. for planning a joint set of collision-free informative locations for 10 robots.


Title: Sensor Coverage Control Using Robots Constrained to a Curve
Abstract: In this paper we consider a constrained coverage control problem for a team of mobile robots. The robots are asked to provide sensor coverage over a two-dimensional domain, while being constrained to only move on a curve. The unconstrained coverage problem can be effectively solved by defining a locational cost to be minimized by the robots, in a decentralized fashion, using gradient descent. However, a direct projection of the solution to the unconstrained problem onto the curve may result in a very poor spatial allocation of the team within the two-dimensional domain. Therefore, we propose a modification to the locational cost, which incorporates the constraints, and a convex relaxation that allows us to efficiently minimize a convex approximation of the cost using a decentralized strategy. The resulting algorithm is implemented on a team of mobile robots.


Title: Point Cloud Compression for 3D LiDAR Sensor using Recurrent Neural Network with Residual Blocks
Abstract: The use of 3D LiDAR, which has proven its capabilities in autonomous driving systems, is now expanding into many other fields. The sharing and transmission of point cloud data from 3D LiDAR sensors has broad application prospects in robotics. However, due to the sparseness and disorderly nature of this data, it is difficult to compress it directly into a very low volume. A potential solution is utilizing raw LiDAR data. We can rearrange the raw data from each frame losslessly in a 2D matrix, making the data compact and orderly. Due to the special structure of 3D LiDAR data, the texture of the 2D matrix is irregular, in contrast to 2D matrices of camera images. In order to compress this raw, 2D formatted LiDAR data efficiently, in this paper we propose a method which uses a recurrent neural network and residual blocks to progressively compress one frame's information from 3D LiDAR. Compared to our previous image compression based method and generic octree point cloud compression method, the proposed approach needs much less volume while giving the same decompression accuracy. Potential application scenarios for point cloud compression are also considered in this paper. We describe how decompressed point cloud data can be used with SLAM (simultaneous localization and mapping) as well as for localization using a given map, illustrating potential uses of the proposed method in real robotics applications.


Title: Self-Supervised Sparse-to-Dense: Self-Supervised Depth Completion from LiDAR and Monocular Camera
Abstract: Depth completion, the technique of estimating a dense depth image from sparse depth measurements, has a variety of applications in robotics and autonomous driving. However, depth completion faces 3 main challenges: the irregularly spaced pattern in the sparse depth input, the difficulty in handling multiple sensor modalities (when color images are available), as well as the lack of dense, pixel-level ground truth depth labels for training. In this work, we address all these challenges. Specifically, we develop a deep regression model to learn a direct mapping from sparse depth (and color images) input to dense depth prediction. We also propose a self-supervised training framework that requires only sequences of color and sparse depth images, without the need for dense depth labels. Our experiments demonstrate that the self-supervised framework outperforms a number of existing solutions trained with semi-dense annotations. Furthermore, when trained with semi-dense annotations, our network attains state-of-the-art accuracy and is the winning approach on the KITTI depth completion benchmark at the time of submission.


Title: Online Plan Repair in Multi-robot Coordination with Disturbances
Abstract: This paper addresses the problem of multi-robot coordination in scenarios where the robots may experience unexpected delays in their movements. Prior work by Čáp, Gregoire, and Frazzołi introduced a control law, called RMTRACK, which enables robots in such scenarios to execute preplanned paths in spite of disturbances in the execution speed of each robot, while guaranteeing that each robot can reach its goal without collisions and without deadlocks. We extend that approach to handle scenarios in which the disturbance probabilities are unknown at the start and non-uniform across the environment. The key idea is to `repair' a plan on-the-fly, by swapping the order in which a pair of robots passes through a mutual collision region (i.e. a coordination space obstacle), when making such a change can be estimated to improve the overall performance of the system. We introduce a technique based on Gaussian Processes to estimate future disturbances, and propose two algorithms for testing, at appropriate times, whether a swap of a given obstacle would be beneficial. Tests in simulation demonstrate that our algorithm achieves significantly smaller average travel time than RMTRACK at only a modest computational expense.


Title: Integrated Mapping and Path Planning for Very Large-Scale Robotic (VLSR) Systems
Abstract: This paper develops a decentralized approach for mapping and information-driven path planning for Very Large Scale Robotic (VLSR) systems. In this approach, obstacle mapping is performed using a continuous probabilistic representation known as a Hilbert map, which formulates the mapping problem as a binary classification task and uses kernel logistic regression to train a discriminative classifier online. A novel Hilbert map fusion method is presented that quickly and efficiently combines the information from individual robot maps. An integrated mapping and path planning algorithm is presented to determine paths of maximum information value, while simultaneously performing obstacle avoidance. Furthermore, the effect of how percentage communication failure effects the overall performance of the system is investigated. The approach is demonstrated on a VLSR system with hundreds of robots that must map obstacles collaboratively over a large region of interest using onboard range sensors and no prior obstacle information. The results show that, through fusion and decentralized processing, the entropy of the map decreases over time and robot paths remain collision-free.


Title: Methodology of Designing Multi-agent Robot Control Systems Utilising Hierarchical Petri Nets
Abstract: A robot system is designed as a set of embodied agents. An embodied agent is decomposed into cooperating subsystems. In our previous work activities of subsystems were defined by hierarchical finite state machines. With their states activities were associated. In that approach communication between subsystems was treated as an implementation issue. This paper represents activities of a robot system using hierarchical Petri nets with conditions. Such net is created by specifying consecutive layers: multi-agent robot system layer, agent layer, subsystem layer, behaviour layer and communication layer. This decomposition not only organizes in a systematic manner the development of a robot system, but also introduces a comprehensive description of concurrently acting subsystems. Based on those theoretical considerations, a tool was created for producing hierarchical Petri nets defining the model of a robotic system and enabling automatic generation of the robot controller code, resulting in a significant acceleration of the implementation phase. The capabilities of the tool are presented by the development of a robot controller performing a rudimentary task.


Title: Interaction-Aware Multi-Agent Reinforcement Learning for Mobile Agents with Individual Goals
Abstract: In a multi-agent setting, the optimal policy of a single agent is largely dependent on the behavior of other agents. We investigate the problem of multi-agent reinforcement learning, focusing on decentralized learning in non-stationary domains for mobile robot navigation. We identify a cause for the difficulty in training non-stationary policies: mutual adaptation to sub-optimal behaviors, and we use this to motivate a curriculum-based strategy for learning interactive policies. The curriculum has two stages. First, the agent leverages policy gradient algorithms to learn a policy that is capable of achieving multiple goals. Second, the agent learns a modifier policy to learn how to interact with other agents in a multi-agent setting. We evaluated our approach on both an autonomous driving lane-change domain and a robot navigation domain.


Title: Coverage Control for Multiple Event Types with Heterogeneous Robots
Abstract: This paper focuses on the problem of deploying a set of autonomous robots to efficiently monitor multiple types of events in an environment. There is a density function over the environment for each event type representing the weighted likelihood of the event at each location. The robots are heterogeneous in that each robot is equipped with a set of sensors and it is capable of sensing a subset of event types. The objective is to deploy the robots in the environment to minimize a linear combination of the total sensing quality of the events. We propose a new formulation for the problem which is a natural extension of the homogeneous problem. We propose distributed algorithms that drive the robots to locally optimal positions in both continuous environments that are obstacle-free, and in discrete environments that may contain obstacles. In both cases we prove convergence to locally optimal positions. We provide extension to the case where the density functions are unknown prior to the deployment in continuous environments. Finally, we present benchmarking results and physical experiments to characterize the solution quality.


Title: A Competitive Algorithm for Online Multi-Robot Exploration of a Translating Plume
Abstract: In this paper, we study the problem of exploring a translating plume with a team of aerial robots. The shape and the size of the plume are unknown to the robots. The objective is to find a tour for each robot such that they collectively explore the plume. Specifically, the tours must be such that each point in the plume must be visible from the field-of-view of some robot along its tour. We propose a recursive Depth-First Search (DFS)-based algorithm that yields a constant competitive ratio for the exploration problem. The competitive ratio is 2(Sr + Sp)(R+⌊log R⌋)/(Sr + Sp)(R+⌊log R⌋) where R is the number of robots, and Sr and Sp are the robot speed and the plume speed, respectively. We also consider a more realistic scenario where the plume shape is not restricted to grid cells but an arbitrary shape. We show our algorithm has 2(Sr + Sp)(18 R+⌊log R⌋)/(Sr + Sp)(1+⌊log R⌋) competitive ratio under the fat condition. We empirically verify our algorithm using simulations.


Title: Online Estimation of Ocean Current from Sparse GPS Data for Underwater Vehicles
Abstract: Underwater robots are subject to position drift due to the effect of ocean currents and the lack of accurate localisation while submerged. We are interested in exploiting such position drift to estimate the ocean current in the surrounding area, thereby assisting navigation and planning. We present a Gaussian process (GP)-based expectation-maximisation (EM) algorithm that estimates the underlying ocean current using sparse GPS data obtained on the surface and dead-reckoned position estimates. We first develop a specialised GP regression scheme that exploits the incompressibility of ocean currents to counteract the underdetermined nature of the problem. We then use the proposed regression scheme in an EM algorithm that estimates the best-fitting ocean current in between each GPS fix. The proposed algorithm is validated in simulation and on a real dataset, and is shown to be capable of reconstructing the underlying ocean current field. We expect to use this algorithm to close the loop between planning and estimation for underwater navigation in unknown ocean currents.


Title: Easily Deployable Underwater Acoustic Navigation System for Multi-Vehicle Environmental Sampling Applications
Abstract: Water as a medium poses a number of challenges for robots, limiting the progress of research in underwater robotics vis-á-vis ground or aerial robotics. The primary challenges are satellite based positioning and radio communication being unusable due to high attenuation of electromagnetic waves in water. We have developed miniature, agile, easy to carry and deploy Autonomous Underwater Vehicles (AUVs) equipped with a suite of sensors for underwater environmental sensing. We previously demonstrated adaptive sampling and feature tracking, and gathered data from a lake for limnological research, with the AUV performing inertial navigation. In this paper, we demonstrate a new underwater acoustic positioning system, which allows on-board estimation of AUV position. Our system uses absolute time information from GNSS for initial clock synchronization and uses one-way-travel-time for range measurements, which makes it scalable in the number of robots. It is easily deployable and does not rely on any installed infrastructure in the environment. We describe various hardware and software components of our system, and present results from experiments in Lake Geneva.


Title: Detect in RGB, Optimize in Edge: Accurate 6D Pose Estimation for Texture-less Industrial Parts
Abstract: In order to solve robotic bin-picking problem in many industrial applications, accurate 6D object pose estimation is one of fundamental technologies. This paper presents a method for accurate 6D pose estimation from a single RGB image for texture-less industrial parts. These objects are common but still challenging to deal with, due to the fact that poor surface texture and brightness makes difficult to compute discriminative local appearance descriptors. The proposed method mainly consists of two stages, which ranges from the detection stage to the optimization stage. Firstly, all known objects in the RGB image are detected with 2D bounding box via a tiny convolutional neural network. Then, the second stage will optimize the 6D pose in the Edge image given several coarse initializations. These coarse initializations are generated from the Edge image via a hypothesis-evaluation scheme. Furthermore, the proposed method is validated by achieving state-of-the-art results of texture-less industrial parts for RGB input. According to practical experiments, the proposed method is accurate and robust enough to be applied on the robotic manipulation platform to complete a simple assembly task.


Title: Learning Object Localization and 6D Pose Estimation from Simulation and Weakly Labeled Real Images
Abstract: Accurate pose estimation is often a requirement for robust robotic grasping and manipulation of objects placed in cluttered, tight environments, such as a shelf with multiple objects. When deep learning approaches are employed to perform this task, they typically require a large amount of training data. However, obtaining precise 6 degrees of freedom for ground-truth can be prohibitively expensive. This work therefore proposes an architecture and a training process to solve this issue. More precisely, we present a weak object detector that enables localizing objects and estimating their 6D poses in cluttered and occluded scenes. To minimize the human labor required for annotations, the proposed detector is trained with a combination of synthetic and a few weakly annotated real images (as little as 10 images per object), for which a human provides only a list of objects present in each image (no time-consuming annotations, such as bounding boxes, segmentation masks and object poses). To close the gap between real and synthetic images, we use multiple domain classifiers trained adversarially. During the inference phase, the resulting class-specific heatmaps of the weak detector are used to guide the search of 6D poses of objects. Our proposed approach is evaluated on several publicly available datasets for pose estimation. We also evaluated our model on classification and localization in unsupervised and semi-supervised settings. The results clearly indicate that this approach could provide an efficient way toward fully automating the training process of computer vision models used in robotics.


Title: STAMPEDE: A Discrete-Optimization Method for Solving Pathwise-Inverse Kinematics
Abstract: We present a discrete-optimization technique for finding feasible robot arm trajectories that pass through provided 6-DOF Cartesian-space end-effector paths with high accuracy, a problem called pathwise-inverse kinematics. The output from our method consists of a path function of joint-angles that best follows the provided end-effector path function, given some definition of “best”. Our method, called Stampede, casts the robot motion translation problem as a discrete-space graph-search problem where the nodes in the graph are individually solved for using non-linear optimization; framing the problem in such a way gives rise to a well-structured graph that affords an effective best path calculation using an efficient dynamic-programming algorithm. We present techniques for sampling configuration space, such as diversity sampling and adaptive sampling, to construct the search-space in the graph. Through an evaluation, we show that our approach performs well in finding smooth, feasible, collision-free robot motions that match the input end-effector trace with very high accuracy, while alternative approaches, such as a state-of-the-art per-frame inverse kinematics solver and a global non-linear trajectory-optimization approach, performed unfavorably.


Title: Learning Pose Estimation for High-Precision Robotic Assembly Using Simulated Depth Images
Abstract: Most of industrial robotic assembly tasks today require fixed initial conditions for successful assembly. These constraints induce high production costs and low adaptability to new tasks. In this work we aim towards flexible and adaptable robotic assembly by using 3D CAD models for all parts to be assembled. We focus on a generic assembly task - the Siemens Innovation Challenge - in which a robot needs to assemble a gear-like mechanism with high precision into an operating system. To obtain the millimeter-accuracy required for this task and industrial settings alike, we use a depth camera mounted near the robot's end-effector. We present a high-accuracy two-stage pose estimation procedure based on deep convolutional neural networks, which includes detection, pose estimation, refinement, and handling of near- and full symmetries of parts. The networks are trained on simulated depth images with means to ensure successful transfer to the real robot. We obtain an average pose estimation error of 2.16 millimeters and 0.64 degree leading to 91% success rate for robotic assembly of randomly distributed parts. To the best of our knowledge, this is the first time that the Siemens Innovation Challenge is fully addressed, with all the parts assembled with high success rates.


Title: A Linear-Complexity EKF for Visual-Inertial Navigation with Loop Closures
Abstract: Enabling real-time visual-inertial navigation in unknown environments while achieving bounded-error performance holds great potentials in robotic applications. To this end, in this paper, we propose a novel linear-complexity EKF for visual-inertial localization, which can efficiently utilize loop closure constraints, thus allowing for long-term persistent navigation. The key idea is to adapt the Schmidt-Kalman formulation within the multi-state constraint Kalman filter (MSCKF) framework, in which we selectively include keyframes as nuisance parameters in the state vector for loop closures but do not update their estimates and covariance in order to save computations while still tracking their cross-correlations with the current navigation states. As a result, the proposed Schmidt-MSCKF has only O(n) computational complexity while still incorporating loop closures into the system. The proposed approach is validated extensively on large-scale real-world experiments, showing significant performance improvements when compared to the standard MSCKF, while only incurring marginal computational overhead.


Title: Keyframe-based Direct Thermal–Inertial Odometry
Abstract: This paper proposes an approach for fusing direct radiometric data from a thermal camera with inertial measurements to extend the robotic capabilities of aerial robots for navigation in GPS-denied and visually degraded environments in the conditions of darkness and in the presence of airborne obscurants such as dust, fog and smoke. An optimization based approach is developed that jointly minimizes the re-projection error of 3D landmarks and inertial measurement errors. The developed solution is extensively verified against both ground-truth in an indoor laboratory setting, as well as inside an underground mine under severely visually degraded conditions.


Title: Contact-Event-Triggered Mode Estimation for Dynamic Rigid Body Impedance-Controlled Capture
Abstract: This paper presents a contact-event-triggered filter using only a force-torque sensor with impedance control for non-cooperative, rotating, heavy object capture. Contact events are modeled for prediction, and detected to trigger the particle filter's updating process. By combining these features, a computationally efficient, contact-event-triggered filter is proposed. For our purpose of capture using impedance control, expected contact events, collisions and sliding are defined for prediction and detection. This novel method is implemented in an air bearing robotic system, and has demonstrated its superiority with the highest success rate (100%) for sliding contact mode cases, whereas the previous method could only yield a success rate of 87.9%. The computation resource is demonstrated to be limited, with a computation time of 4.2 milliseconds on average and 8.3 milliseconds at worst.


Title: Leveraging Contact Forces for Learning to Grasp
Abstract: Grasping objects under uncertainty remains an open problem in robotics research. This uncertainty is often due to noisy or partial observations of the object pose or shape. To enable a robot to react appropriately to unforeseen effects, it is crucial that it continuously takes sensor feedback into account. While visual feedback is important for inferring a grasp pose and reaching for an object, contact feedback offers valuable information during manipulation and grasp acquisition. In this paper, we use model-free deep reinforcement learning to synthesize control policies that exploit contact sensing to generate robust grasping under uncertainty. We demonstrate our approach on a multi-fingered hand that exhibits more complex finger coordination than the commonly used two-fingered grippers. We conduct extensive experiments in order to assess the performance of the learned policies, with and without contact sensing. While it is possible to learn grasping policies without contact sensing, our results suggest that contact feedback allows for a significant improvement of grasping robustness under object pose uncertainty and for objects with a complex shape.


Title: Learning Latent Space Dynamics for Tactile Servoing
Abstract: To achieve a dexterous robotic manipulation, we need to endow our robot with tactile feedback capability, i.e. the ability to drive action based on tactile sensing. In this paper, we specifically address the challenge of tactile servoing, i.e. given the current tactile sensing and a target/goal tactile sensing - memorized from a successful task execution in the past - what is the action that will bring the current tactile sensing to move closer towards the target tactile sensing at the next time step. We develop a data-driven approach to acquire a dynamics model for tactile servoing by learning from demonstration. Moreover, our method represents the tactile sensing information as to lie on a surface - or a 2D manifold - and perform a manifold learning, making it applicable to any tactile skin geometry. We evaluate our method on a contact point tracking task using a robot equipped with a tactile finger.


Title: PointNetGPD: Detecting Grasp Configurations from Point Sets
Abstract: In this paper, we propose an end-to-end grasp evaluation model to address the challenging problem of localizing robot grasp configurations directly from the point cloud. Compared to recent grasp evaluation metrics that are based on handcrafted depth features and a convolutional neural network (CNN), our proposed PointNetGPD is lightweight and can directly process the 3D point cloud that locates within the gripper for grasp evaluation. Taking the raw point cloud as input, our proposed grasp evaluation network can capture the complex geometric structure of the contact area between the gripper and the object even if the point cloud is very sparse. To further improve our proposed model, we generate a large-scale grasp dataset with 350k real point cloud and grasps with the YCB object set for training. The performance of the proposed model is quantitatively measured both in simulation and on robotic hardware. Experiments on object grasping and clutter removal show that our proposed model generalizes well to novel objects and outperforms state-of-the-art methods. Code and video are available at https://lianghongzhuo.github.io/PointNetGPD.


Title: Learning Deep Visuomotor Policies for Dexterous Hand Manipulation
Abstract: Multi-fingered dexterous hands are versatile and capable of acquiring a diverse set of skills such as grasping, in-hand manipulation, and tool use. To fully utilize their versatility in real-world scenarios, we require algorithms and policies that can control them using on-board sensing capabilities, without relying on external tracking or motion capture systems. Cameras and tactile sensors are the most widely used on-board sensors that do not require instrumentation of the world. In this work, we demonstrate an imitation learning based approach to train deep visuomotor policies for a variety of manipulation tasks with a simulated five fingered dexterous hand. These policies directly control the hand using high dimensional visual observations of the world and propreoceptive observations from the robot, and can be trained efficiently with a few hundred expert demonstration trajectories. We also find that using touch sensing information enables faster learning and better asymptotic performance for tasks with high degree of occlusions. Video demonstration of our results are available at: https://sites.google.com/view/hand-vil/.


Title: Learning to Identify Object Instances by Touch: Tactile Recognition via Multimodal Matching
Abstract: Much of the literature on robotic perception focuses on the visual modality. Vision provides a global observation of a scene, making it broadly useful. However, in the domain of robotic manipulation, vision alone can sometimes prove inadequate: in the presence of occlusions or poor lighting, visual object identification might be difficult. The sense of touch can provide robots with an alternative mechanism for recognizing objects. In this paper, we study the problem of touch-based instance recognition. We propose a novel framing of the problem as multi-modal recognition: the goal of our system is to recognize, given a visual and tactile observation, whether or not these observations correspond to the same object. To our knowledge, our work is the first to address this type of multi-modal instance recognition problem on such a large-scale with our analysis spanning 98 different objects. We employ a robot equipped with two GelSight touch sensors, one on each finger, and a self-supervised, autonomous data collection procedure to collect a dataset of tactile observations and images. Our experimental results show that it is possible to accurately recognize object instances by touch alone, including instances of novel objects that were never seen during training. Our learned model outperforms other methods on this complex task, including that of human volunteers.


Title: Dexterous Manipulation with Deep Reinforcement Learning: Efficient, General, and Low-Cost
Abstract: Dexterous multi-fingered robotic hands can perform a wide range of manipulation skills, making them an appealing component for general-purpose robotic manipulators. However, such hands pose a major challenge for autonomous control, due to the high dimensionality of their configuration space and complex intermittent contact interactions. In this work, we propose deep reinforcement learning (deep RL) as a scalable solution for learning complex, contact rich behaviors with multi-fingered hands. Deep RL provides an end-to-end approach to directly map sensor readings to actions, without the need for task specific models or policy classes. We show that contact-rich manipulation behavior with multi-fingered hands can be learned by directly training with model-free deep RL algorithms in the real world, with minimal additional assumption and without the aid of simulation. We learn to perform a variety of tasks on two different low-cost hardware platforms entirely from scratch, and further study how the learning can be accelerated by using a small number of human demonstrations. Our experiments demonstrate that complex multi-fingered manipulation skills can be learned in the real world in about 4-7 hours for most tasks, and that demonstrations can decrease this to 2-3 hours, indicating that direct deep RL training in the real world is a viable and practical alternative to simulation and model-based control. https:// sites.google.com/view/deeprl-handmanipulation.


Title: Inkjet Printable Actuators and Sensors for Soft-bodied Crawling Robots
Abstract: Soft-bodied robots are getting attention from researchers as their potential in designing compliant and adaptive robots. However, soft-bodied robots also pose many challenges not only in non-linear controlling but also in design and fabrication. Especially, the non-compatibility between soft materials and rigid sensors/actuators makes it more difficult to design a fully compliant soft-bodied robot. In this paper, we propose an all-printed sensor and actuator for designing soft-bodied robots by printing silver nano-particle ink on top of a flexible plastic film. We can print bending sensors and thermal based actuators instantly with home-commodity inkjet printers without any pre/post-processing. We exemplify the application of this fabrication method with an all-printed paper caterpillar robots which can inch forward and sense its body bending angle.


Title: Design and Evaluation of an Energy-Saving Drive for a Versatile Robotic Gripper
Abstract: The main task of robotic grippers, holding an object, does not require work theoretically. Yet grippers consume significant amounts of energy in practice. This paper presents an approach for designing an energy-saving drive for robotic grippers employing a Statically Balanced Force Amplifier (SBFA) and a Non-backdrivable mechanism (NBDM). A novel metric (Grip Performance Metric) to systematically evaluate drives regarding their energy consumption, is used in the design phase; afterwards, the realization and testing of a prototype (REED, Robotic Energy-Efficient Drive) are presented. Results show that the actuation force can be reduced by 92%, resulting in energy-savings of 86% for an example task. This shows the potential of drives based on SBFAs and NBDMs to achieve energy-neutral grippers.


Title: Robotics Education and Research at Scale: A Remotely Accessible Robotics Development Platform
Abstract: This paper introduces the KUKA Robot Learning Lab at KIT - a remotely accessible robotics testbed. The motivation behind the laboratory is to make state-of-the-art industrial lightweight robots more accessible for education and research. Such expensive hardware is usually not available to students or less privileged researchers to conduct experiments. This paper describes the design and operation of the Robot Learning Lab and discusses the challenges that one faces when making experimental robot cells remotely accessible. Especially safety and security must be ensured, while giving users as much freedom as possible when developing programs to control the robots. A fully automated and efficient processing pipeline for experiments makes the lab suitable for a large amount of users and allows a high usage rate of the robots.


Title: Adsorption Pad using Capillary Force for Uneven Surface
Abstract: We propose a novel adsorption pad for wall climbing robot and irregular surface object using capillary force and water sealing. We call this adsorption pad as Super Wet Adsorption pad. The SWA pad has a porous part and a capillary part. The porous part is made by salt reaching method. When the SWA pad adsorbs to the wall which some sand and dust are attached, water comes from the porous part to avoid vacuum breaking. The capillary part is connected to the porous part to supply and stock the water. In this paper, we show the design of the porous part and the capillary part, fabrication process of each parts, and perform the evaluation experiment of the capillary force and adsorption of uneven surfaces, demonstration of wall climbing robot and adsorption of irregular surface foods.


Title: Effects of Foot Stiffness and Damping on Walking Robot Performance
Abstract: In this paper, we investigated how the stiffness and damping properties of soft robotic feet affect the stability and energetic economy of bipedal robotic walking. To this end, we manufactured four different spherical feet from the following materials: hollow rubber, Sorbothane, Norsorex, and Neoprene. The materials were specifically chosen to cover a wide range of stiffness and damping values. The impact response of each design was first characterized in a drop test rig. We then evaluated the performance of each foot in an extensive series of walking experiments on the planar bipedal robot RAM one. Our results showed that, at low speeds, the feet with lower damping had a smaller energy cost of walking, possibly due to greater return of mechanical energy at lift-off. However, at speeds above 0.5m\s, the feet with lower damping started to exhibit a bouncing behaviour which led to higher walking instability and increased the energy cost of walking. Additionally, we found the feet with lower stiffness to be more economical across all walking speeds. Our results provide insight into the role of foot properties in bipedal walking and may help with the design of walking robots.


Title: Dynamic Walking on Slippery Surfaces : Demonstrating Stable Bipedal Gaits with Planned Ground Slippage*
Abstract: Dynamic bipedal robot locomotion has achieved remarkable success due in part to recent advances in trajectory generation and nonlinear control for stabilization. A key assumption utilized in both theory and experiments is that the robot's stance foot always makes no-slip contact with the ground, including at impacts. This assumption breaks down on slippery low-friction surfaces, as commonly encountered in outdoor terrains, leading to failure and loss of stability. In this work, we extend the theoretical analysis and trajectory optimization to account for stick-slip transitions at point foot contact using Coulomb's friction law. Using AMBER-3M planar biped robot as an experimental platform, we demonstrate for the first time a slippery walking gait which can be stabilized successfully both on a lubricated surface and on a rough no-slip surface. We also study the influence of foot slippage on reducing the mechanical cost of transport, and compare energy efficiency in both numerical simulation and experimental measurement.


Title: Torque and velocity controllers to perform jumps with a humanoid robot: theory and implementation on the iCub robot
Abstract: Jumping can be an effective way of locomotion to overcome small terrain gaps or obstacles. In this paper we propose two different approaches to perform jumps with a humanoid robot. Specifically, starting from a pre-defined CoM trajectory we develop the theory for a velocity controller and for a torque controller based on an optimization technique for the evaluation of the joints input. The controllers have been tested both in simulation and on the humanoid robot iCub. In simulation the robot was able to jump using both controllers, while the real system jumped with the velocity controller only. The results highlight the importance of controlling the centroidal angular momentum and they suggest that the joint performances, namely maximum power, of the legs and torso joints, and the low level control performances are fundamental to achieve acceptable results.


Title: Safe Adaptive Switching among Dynamical Movement Primitives: Application to 3D Limit-Cycle Walkers
Abstract: Complex robot motions are frequently generated by composing simpler primitive movements. We use this approach to formulate robot motion plans as sequences of primitives to be executed one after the other. When dealing with dynamical movement primitives, besides accomplishing the high-level objective, planners must also reason about the effect of the plan's execution on the safety of the platform. This task is exacerbated by the presence of disturbances, such as non-vanishing external forces. To address this issue, we present a framework that builds on rigorous control-theoretic tools to generate safely executable motion plans for externally excited robotic systems. We illustrate the proposed framework on adapting the motion of a 3D bipedal robot model to persistent external forcing by switching among dynamic movement primitives, each corresponding to a limit-cycle walking gait.


Title: Interactive Open-Ended Object, Affordance and Grasp Learning for Robotic Manipulation
Abstract: Service robots are expected to autonomously and efficiently work in human-centric environments. For this type of robots, object perception and manipulation are challenging tasks due to need for accurate and real-time response. This paper presents an interactive open-ended learning approach to recognize multiple objects and their grasp affordances concurrently. This is an important contribution in the field of service robots since no matter how extensive the training data used for batch learning, a robot might always be confronted with an unknown object when operating in human-centric environments. The paper describes the system architecture and the learning and recognition capabilities. Grasp learning associates grasp configurations (i.e., end-effector positions and orientations) to grasp affordance categories. The grasp affordance category and the grasp configuration are taught through verbal and kinesthetic teaching, respectively. A Bayesian approach is adopted for learning and recognition of object categories and an instance-based approach is used for learning and recognition of affordance categories. An extensive set of experiments has been performed to assess the performance of the proposed approach regarding recognition accuracy, scalability and grasp success rate on challenging datasets and real-world scenarios.


Title: A parallel low-impedance sensing approach for highly responsive physical human-robot interaction
Abstract: This paper presents a novel sensing approach for the physical interaction between a human user and a serial robotic arm. The approach is inspired from the concept of macro-mini robot architecture. The framework is developed for a general multi-degree-of-freedom serial robot and a corresponding impedance control scheme is proposed. In order to illustrate the concept, a five-degree-of-freedom robotic arm was built as well as a six-degree-of-freedom low-impedance sensing device that is used to control the robot. Experimental results are provided.


Title: Safe Human Robot Cooperation in Task Performed on the Shared Load
Abstract: Human-robot collaboration in industrial settings calls for implementing safety measures to ensure there is no risk to humans working in such an environment. In human-robot physical collaboration, an object or a load is handled by both human and the robot. Developing a safety framework for the robot is a requirement for preventing collisions during performing a task. In this paper, force myography (FMG) data are used to develop a control scheme for the robot such that it can work with the human worker while avoiding collisions. Force myography quantifies the activities of human muscles when applying forces to handle an object. A neural network-based approach is then used to select the most informative features of the FMG signal. The developed control scheme incorporates the FMG data and the robot dynamics to obtain a prediction about the next step of the cooperation task and to plan the robot motion accordingly. The proposed approach is evaluated experimentally in real time in a moving objects task which requires appropriate complementary actions from the robot and the human user. The results of this study show that the proposed scheme can successfully plan the robot motion based on the actions of the human user.


Title: A Multi-modal Sensor Array for Safe Human-Robot Interaction and Mapping
Abstract: In the future, human-robot interaction will include collaboration in close-quarters where the environment geometry is partially unknown. As a means for enabling such interaction, this paper presents a multi-modal sensor array capable of contact detection and localization, force sensing, proximity sensing, and mapping. The sensor array integrates Hall effect and time-of-flight (ToF) sensors in an I2C communication network. The design, fabrication, and characterization of the sensor array for a future in-situ collaborative continuum robot are presented. Possible perception benefits of the sensor array are demonstrated for accidental contact detection, mapping of the environment, selection of admissible zones for bracing, and constrained motion control of the end effector while maintaining a bracing constraint with an admissible rolling motion.


Title: Dynamic Primitives in Human Manipulation of Non-Rigid Objects
Abstract: This study examined strategies humans chose to manipulate an object with complex (nonlinear, underactuated) dynamics, such as liquid sloshing in a cup of coffee. The problem was simplified to the well-known cart-and-pendulum system moving on a horizontal line. This model was implemented in a virtual environment and human subjects manipulated the object via a robotic manipulandum. The task was to maneuver the system from rest to arrive at a target position such that no residual oscillations of the pendulum bob remained. Our goal was to test whether humans simplified control by employing dynamic primitives, specifically submovements. Experimental velocity profiles of the human movements were compared to those predicted by three different control models. Two models used continuous optimization-based control, the third control model was based on Input Shaping. Input Shaping is a method for controlling flexible objects by convolving a motion profile with impulses of appropriate amplitude and timing. To evaluate whether humans used Input Shaping, we decomposed the velocity profiles recorded from humans into submovements, as proxies for the convolved impulses. Comparing the motion profiles from the 3 models with the experimentally measured human profiles showed superior performance of the Input Shaping model. These initial results are consistent with our hypothesis that combining dynamic primitives, submovements, is a competent description of human performance and may provide a simpler alternative to computationally complex optimization-based methods of robot control.


Title: State Estimation in Contact-Rich Manipulation
Abstract: This paper introduces a Bayesian state estimator for contact-rich manipulation tasks with application in non-prehensile manipulation, industrial assembly or in-hand localization. The core idea of our approach is to explicitly model both the contact dynamics and a torque-based robot controller as part of the underlying system model. Our approach is capable of estimating the state of movable objects for various robot kinematics and geometries of robots and objects. This includes complex scenarios with multiple robots, multiple objects and articulated objects. We have validated our approach in simulation and on a physical robot. The experiments show that multimodal distributions of six degrees of freedom object poses can be accurately tracked in real-time in a complex manipulation scenario.


Title: Improved Proximity, Contact, and Force Sensing via Optimization of Elastomer-Air Interface Geometry
Abstract: We describe a single fingertip-mounted sensing system for robot manipulation that provides proximity (pre-touch), contact detection (touch), and force sensing (post-touch). The sensor system consists of optical time-of-flight range measurement modules covered in a clear elastomer. Because the elastomer is clear, the sensor can detect and range nearby objects, as well as measure deformations caused by objects that are in contact with the sensor and thereby estimate the applied force. We examine how this sensor design can be improved with respect to invariance to object reflectivity, signal-to-noise ratio, and continuous operation when switching between the distance and force measurement regimes. By harnessing time-of-flight technology and optimizing the elastomer-air boundary to control the emitted light's path, we develop a sensor that is able to seamlessly transition between measuring distances of up to 50 mm and contact forces of up to 10 newtons. We demonstrate that our sensor improves manipulation accuracy in a block unstacking task. Thorough instructions for manufacturing the sensor from inexpensive, commercially available components are provided, as well as all relevant hardware design files and software sources.


Title: Improving Haptic Adjective Recognition with Unsupervised Feature Learning
Abstract: Humans can form an impression of how a new object feels simply by touching its surfaces with the densely innervated skin of the fingertips. Many haptics researchers have recently been working to endow robots with similar levels of haptic intelligence, but these efforts almost always employ hand-crafted features, which are brittle, and concrete tasks, such as object recognition. We applied unsupervised feature learning methods, specifically K-SVD and Spatio-Temporal Hierarchical Matching Pursuit (ST-HMP), to rich multi-modal haptic data from a diverse dataset. We then tested the learned features on 19 more abstract binary classification tasks that center on haptic adjectives such as smooth and squishy. The learned features proved superior to traditional hand-crafted features by a large margin, almost doubling the average F1 score across all adjectives. Additionally, particular exploratory procedures (EPs) and sensor channels were found to support perception of certain haptic adjectives, underlining the need for diverse interactions and multi-modal haptic data.


Title: Semantic mapping extension for OpenStreetMap applied to indoor robot navigation
Abstract: In this work a graph-based, semantic mapping approach for indoor robotics applications is presented, which is extending OpenStreetMap (OSM) with robotic-specific, semantic, topological, and geometrical information. Models are introduced for basic indoor structures such as walls, doors, corridors, elevators, etc. The architectural principles support composition with additional domain and application-specific knowledge. As an example, a model for an area is introduced, and it is explained how this can be used in navigation. A key advantage of the proposed graph-based map representation is that it allows exploiting the hierarchical structure of the graphs. Finally, the compatibility of the approach with existing, grid-based motion planning algorithms is shown.


Title: Autonomous Tissue Manipulation via Surgical Robot Using Learning Based Model Predictive Control
Abstract: Tissue manipulation is a frequently used fundamental subtask of any surgical procedures, and in some cases it may require the involvement of a surgeon's assistant. The complex dynamics of soft tissue as an unstructured environment is one of the main challenges in any attempt to automate the manipulation of it via a surgical robotic system. Two AI learning based model predictive control algorithms using vision strategies are proposed and studied: (1) reinforcement learning and (2) learning from demonstration. Comparison of the performance of these AI algorithms in a simulation setting indicated that the learning from demonstration algorithm can boost the learning policy by initializing the predicted dynamics with given demonstrations. Furthermore, the learning from demonstration algorithm is implemented on a Raven IV surgical robotic system and successfully demonstrated feasibility of the proposed algorithm using an experimental approach. This study is part of a profound vision in which the role of a surgeon will be redefined as a pure decision maker whereas the vast majority of the manipulation will be conducted autonomously by a surgical robotic system. A supplementary video can be found at: http://bionics.seas.ucla.edu/research/surgeryproject17.html.


Title: Robotic Control of a Multi-Modal Rigid Endoscope Combining Optical Imaging with All-Optical Ultrasound
Abstract: Fetoscopy is a technically challenging surgery, due to the dynamic environment and low diameter endoscopes often resulting in a limited field of view. In this paper, we report on the design and operation of a robotic multimodal endoscope with optical ultrasound and white light stereo camera. The manufacture and control of the endoscope is presented, along with large area (80 mm ×80 mm) surface visualisations of a placenta phantom using the optical ultrasound sensor. The repeatability of the surface visualisations was found to be 0. 446 ± 0.139 mm and 0. 267 ± 0.017 mm for a raster and spiral scan, respectively.


Title: Enabling Technology for Safe Robot-Assisted Retinal Surgery: Early Warning for Unsafe Scleral Force
Abstract: Retinal microsurgery is technically demanding and requires high surgical skill with very little room for manipulation error. During surgery the tool needs to be inserted into the eyeball while maintaining constant contact with the sclera. Any unexpected manipulation could cause extreme tool-sclera contact force (scleral force) thus damage the sclera. The introduction of robotic assistance could enhance and expand the surgeon's manipulation capabilities during surgery. However, the potential intra-operative danger from surgeon's mis-operations remains difficult to detect and prevent by existing robotic systems. Therefore, we propose a method to predict imminent unsafe manipulation in robot-assisted retinal surgery and generate feedback to the surgeon via auditory substitution. The surgeon could then react to the possible unsafe events in advance. This work specifically focuses on minimizing sclera damage using a force-sensing tool calibrated to measure small scleral forces. A recurrent neural network is designed and trained to predict the force safety status up to 500 milliseconds in the future. The system is implemented using an existing “steady hand” eye robot. A vessel following manipulation task is designed and performed on a dry eye phantom to emulate the retinal surgery and to analyze the proposed method. Finally, preliminary validation experiments are performed by five users, the results of which indicate that the proposed early warning system could help to reduce the number of unsafe manipulation events.


Title: Robotic bronchoscopy drive mode of the Auris Monarch platform*
Abstract: Robotic bronchoscopy has the potential to improve the early detection of lung cancer. For the technology to be broadly adopted, the physician needs to be able to control the robotic bronchoscope in an instinctive and effective manner. In this paper, we describe the algorithms used to manipulate/drive the Auris Monarch Platform, a 10 degree-of-freedom bronchoscope and sheath, using a 3 degree-of-freedom user input. We introduce the concept of paired driving where the devices co-insert and co-articulate depending on their relative insertion. The paper presents safety algorithms such as auto-relax on retract and tension monitoring. The drive modes were developed, optimized, and clinically tested in lung models, human cadavers and live porcine models prior to their commercial release. Clinical studies show that the physician is able to reach significantly deeper in the lung than with classic bronchoscopes.


Title: Using comanipulation with active force feedback to undistort stiffness perception in laparoscopy
Abstract: Surgeons performing laparoscopic surgery experience distortion when perceiving the stiffness of a patient's tissues. This is due to the lever effect induced by the introduction of instruments in their patient's body through a fulcrum. To address this problem, we propose to use the comanipulation paradigm. A robotic device is connected to the handle of the instrument while simultaneously being held by the surgeon. This device applies a force on the handle that reflects the force measured at the tool tip, with a gain that depends on the lever ratio. The implementation of this method is presented on an experimental setup and a preliminary assessment experiment is presented.


Title: Stiffness-Tuneable Limb Segment with Flexible Spine for Malleable Robots
Abstract: Robotic arms built from stiffness-adjustable, continuously bending segments serially connected with revolute joints have the ability to change their mechanical architecture and workspace, thus allowing high flexibility and adaptation to different tasks with less than six degrees of freedom, a concept that we call malleable robots. Known stiffening mechanisms may be used to implement suitable links for these novel robotic manipulators; however, these solutions usually show a reduced performance when bending due to structural deformation. By including an inner support structure this deformation can be minimised, resulting in an increased stiffening performance. This paper presents a new multi-material spine-inspired flexible structure for providing support in stiffness-controllable layer-jamming-based robotic links of large diameter. The proposed spine mechanism is highly movable with type and range of motions that match those of a robotic link using solely layer jamming, whilst maintaining a hollow and light structure. The mechanics and design of the flexible spine are explored, and a prototype of a link utilising it is developed and compared with limb segments based on granular jamming and layer jamming without support structure. Results of experiments verify the advantages of the proposed design, demonstrating that it maintains a constant central diameter across bending angles and presents an improvement of more than 203% of resisting force at 180°.


Title: A Reconfigurable Variable Stiffness Manipulator by a Sliding Layer Mechanism
Abstract: Inherent compliance plays an enabling role in soft robots, which rely on it to mechanically conform to the environment. However, it also limits the payload of the robots. Various variable stiffness approaches have been adopted to limit compliance and provide structural stability, but most of them can only achieve stiffening of discrete fixed regions which means compliance cannot be precisely adjusted for different needs. This paper offers an approach to enhance the payload with finely adjusted compliance for different needs. We have developed a manipulator that incorporates a novel variable stiffness mechanism and a sliding layer mechanism. The variable stiffness mechanism can achieve a 6.4 stiffness changing ratio with a miniaturized size (10 mm diameter for the testing prototype) through interlocking jamming layers with a honeycomb core. The sliding layer mechanism can actively shift the position of the stiffening regions through sliding of jamming layers. A model to predict the robot shape is derived with verifications via an experiment. The stiffening capacity of the variable stiffness mechanism is also empirically evaluated. A case study of a potential application in laparoscopic surgeries is showcased. The payload of the manipulator is investigated, and the prototype shows up to 57.8 percentage decrease of the vertical deflection due to an external load after reconfigurations.


Title: A Novel Variable Stiffness Actuator Based on Pneumatic Actuation and Supercoiled Polymer Artificial Muscles
Abstract: This article describes an innovative design of variable stiffness soft actuator, which can potentially be utilized for manipulation and locomotion of soft robots. The new actuator is a combination of two types of actuations: soft pneumatic actuation and muscle-like supercoiled polymer (SCP) actuation. Soft pneumatic actuator has two roles: first is to generate bending motions and second is to increase the stiffness of the whole actuator together with SCP artificial muscles. SCP artificial muscles are exploited to generate pre-load to resist the whole actuator from (excessive) deformation when external load is applied. These two types of actuations are arranged antagonistically to realize stiffness tuning of the whole actuator. At a given bending position, stiffness of the actuator could be tuned by controlling the pressure inside the air chamber and the tension on the SCP artificial muscles. In experimental section, tests are conducted to characterize the applied SCP artificial muscles before they are applied to the proposed actuator. Afterwards, tests of proposed actuator are performed to examine its variable stiffness capability. From experimental results, the proposed actuator can achieve 3.47 times stiffness variation ratio from 0.0312 N/mm(40kPa air pressure and no SCP actuation) to 0.1083 N/mm(82kPa air pressure and SCP actuation at 0.143 W/cm) at the same position (bending angle of 56 degree). This study exhibits the potential of applying SCP artificial muscles to promote the performance of soft robots.


Title: A Novel Iterative Learning Model Predictive Control Method for Soft Bending Actuators
Abstract: Soft robots attract research interests worldwide. However, its control remains challenging due to the difficulty in sensing and accurate modeling. In this paper, we propose a novel iterative learning model predictive control (ILMPC) method for soft bending actuators. The uniqueness of our approach is the ability to improve model accuracy gradually. In this method, a pseudo-rigid-body model is used to take an initial guess of the bending behavior of the actuator and the model accuracy is improved with iterative learning. Compared with conventional model free iterative learning control (ILC), the proposed method significantly reduces the learning curve. Compared with the model predictive control (MPC), the proposed method does not rely on an accurate model and it will output a satisfactory model after the learning process. A soft-elastic composite actuator (SECA) is used to validate the proposed method. Both simulation and experimental results show that the proposed method outperforms the conventional MPC and ILC.


Title: Design and Experimental Validation of a 2DOF Sidestick Powered by Hyper-Redundant Magnetorheological Actuators Providing Active Feedback
Abstract: Haptic joysticks for man-machine interaction used in aerospace flight control have highly demanding requirements of reliability, force density, and high dynamics that can hardly be met with conventional electromagnetic actuators. This work explores the potential of using an alternative actuation strategy based on hyper-redundant MR clutches that modulate the force of a tendon-driven 2-degree-of-freedom spherical gimbal. A system design and its closed-loop force control scheme are proposed. Experimental results for an open-loop characterization, static force control and dynamic force control are set out and compared with typical requirements for such devices from the literature. Results show that the proposed architecture leads to one of the lightest systems reported in the literature that has the potential to meet reliability requirements by providing a jam-free design with duplex fault tolerance, and yet, can generate high force levels while providing enough force resolution. The approach is promising and can extend to high-performance collaborative robot applications.


Title: A Lightweight Force-Controllable Wearable Arm Based on Magnetorheological-Hydrostatic Actuators
Abstract: Supernumerary Robotic Limbs (SRLs) are wearable robots augmenting human capabilities by acting as a co-worker, reaching objects, support human arms, etc. However, existing SRLs lack the mechanical backdrivability and bandwidth required for tasks where the interaction forces must be controlled such as painting, drilling, manipulating fragile objects, etc. Being highly backdrivable with a high bandwidth while minimizing weight presents a major technological challenge imposed by the limited performances of conventional electromagnetic actuators. This paper studies the feasibility of using magnetorheological (MR) clutches coupled-to a low-friction hydrostatic transmission to provide a highly capable, but yet lightweight, force-controllable SRL. A 2.7 kg 2-DOFs wearable robotic arm is designed and built. Shoulder and elbow joints are designed to deliver 39 and 25 Nm, with 115 and 180° of range of motion. Experimental studies conducted on a one-DOF test bench and validated analytically demonstrate a high force bandwidth (>25 Hz) and a good ability to control interaction forces even when interacting with an external impedance. Furthermore, three force-control approaches are studied and demonstrated experimentally: open-loop, closed-loop on force, and closed-loop on pressure. All three methods are shown to be effective. Overall, the proposed MR-Hydrostatic actuation system is well-suited for a lightweight SRL interacting with both human and environment that add unpredictable disturbances.


Title: Optical Force Sensing In Minimally Invasive Robotic Surgery
Abstract: This paper evaluates the feasibility of a novel optical sensing concept to measure forces applied at the tip of daVinci EndoWrist instruments. An optical slit is clamped onto the instrument shaft, in-line with an infrared LED-bicell pair. Deflection of the shaft moves the slit with respect to the LED-bicell pair and modulates the light incident on each active element of the bicell. The differential photocurrent is conditioned and monitored to estimate the tip forces. The feasibility evaluation consists of a flexible beam model to quantify the required sensor performance, experimental results with a 3D printed prototype and estimation of the sensor limitations including the measurement bandwidth due to the structural dynamics. The proposed approach requires no modifications to the instrument, is adaptable to different instruments and robot platforms, and leads to high-resolution, high-dynamic range sensing without hysteresis.


Title: KO-Fusion: Dense Visual SLAM with Tightly-Coupled Kinematic and Odometric Tracking
Abstract: Dense visual SLAM methods are able to estimate the 3D structure of an environment and locate the observer within them. They estimate the motion of a camera by matching visual information between consecutive frames, and are thus prone to failure under extreme motion conditions or when observing texture-poor regions. The integration of additional sensor modalities has shown great promise in improving the robustness and accuracy of such SLAM systems. In contrast to the popular use of inertial measurements we propose to tightly-couple a dense RGB-D SLAM system with kinematic and odometry measurements from a wheeled robot equipped with a manipulator. The system has real-time capability while running on GPU. It optimizes the camera pose by considering the geometric alignment of the map as well as kinematic and odometric data from the robot. Through experimentation in the real-world, we show that the system is more robust to challenging trajectories featuring fast and loopy motion than the equivalent system without the additional kinematic and odometric knowledge, whilst retaining comparable performance to the equivalent RGB-D only system on easy trajectories.


Title: Diffraction-Aware Sound Localization for a Non-Line-of-Sight Source
Abstract: We present a novel sound localization algorithm for a non-line-of-sight (NLOS) sound source in indoor environments. Our approach exploits the diffraction properties of sound waves as they bend around a barrier or an obstacle in the scene. We combine a ray tracing-based sound propagation algorithm with a Uniform Theory of Diffraction (UTD) model, which simulate bending effects by placing a virtual sound source on a wedge in the environment. We precompute the wedges of a reconstructed mesh of an indoor scene and use them to generate diffraction acoustic rays to localize the 3D position of the source. Our method identifies the convergence region of those generated acoustic rays as the estimated source position based on a particle filter. We have evaluated our algorithm in multiple scenarios consisting of static and dynamic NLOS sound sources. In our tested cases, our approach can localize a source position with an average accuracy error of 0.7m, measured by the L2 distance between estimated and actual source locations in a 7m×7m×3m room. Furthermore, we observe 37% to 130% improvement in accuracy over a state-of-the-art localization method that does not model diffraction effects, especially when a sound source is not visible to the robot.


Title: DeepFusion: Real-Time Dense 3D Reconstruction for Monocular SLAM using Single-View Depth and Gradient Predictions
Abstract: While the keypoint-based maps created by sparse monocular Simultaneous Localisation and Mapping (SLAM) systems are useful for camera tracking, dense 3D reconstructions may be desired for many robotic tasks. Solutions involving depth cameras are limited in range and to indoor spaces, and dense reconstruction systems based on minimising the photometric error between frames are typically poorly constrained and suffer from scale ambiguity. To address these issues, we propose a 3D reconstruction system that leverages the output of a Convolutional Neural Network (CNN) to produce fully dense depth maps for keyframes that include metric scale. Our system, DeepFusion, is capable of producing real-time dense reconstructions on a GPU. It fuses the output of a semi-dense multiview stereo algorithm with the depth and gradient predictions of a CNN in a probabilistic fashion, using learned uncertainties produced by the network. While the network only needs to be run once per keyframe, we are able to optimise for the depth map with each new frame so as to constantly make use of new geometric constraints. Based on its performance on synthetic and real world datasets, we demonstrate that DeepFusion is capable of performing at least as well as other comparable systems.


Title: Evaluating the Effectiveness of Perspective Aware Planning with Panoramas
Abstract: In this work, we present an information based exploration strategy tailored for the generation of high resolution 3D maps. We employ RGBD panoramas because they have been shown to provide memory efficient high quality representations of space. Robots explore the environment by selecting locations with maximal Cauchy-Schwarz Quadratic Mutual Information (CSQMI) computed on an angle enhanced occupancy grid to collect these RGBD panoramas. By employing the angle enhanced occupancy grid, the resulting exploration strategy emphasizes perspective in addition to binary coverage. Furthermore, the goal selection strategy is improved by using image morphology to reduce the search space over which CSQMI is computed. We present experimental results demonstrating the improved performance in perception related tasks by capturing panoramas using this approach, near frontier exploration, and a control of logging images at regular intervals while teleoperating the robot through the workspace. Collect imagery was passed through an object detection library with our perspective aware approach yielding a greater number of successful detections compared to near frontier exploration.


Title: Actively Improving Robot Navigation On Different Terrains Using Gaussian Process Mixture Models
Abstract: Robot navigation in outdoor environments is exposed to detrimental factors such as vibrations or power consumption due to the different terrains on which the robot navigates. In this paper, we address the problem of actively improving navigation by planning paths that aim at reducing over time phenomena such as vibrations during traversal. Our approach uses a Gaussian Process (GP) mixture model and an aerial image of the environment to learn and improve continuously a place-dependent model of such phenomena from the experiences of the robot. We use this model to plan paths that trade-off the exploration of unknown promising regions and the exploitation of known areas where the impact of the detrimental factors on navigation is low, leading to an improved navigation over time. We implemented our approach and thoroughly tested it using real-world data. Our experiments suggest that our approach with no initial information leads the robot, after few runs, to follow paths along which it experiences similar vibrations or energy consumption as if it was following the optimal path computed given the ground truth information.


Title: Continuous Occupancy Map Fusion with Fast Bayesian Hilbert Maps
Abstract: Mapping the occupancy of an environment is central for robot autonomy. Traditional occupancy grid maps discretise the environment into independent cells, neglecting important spatial correlations, and are unable to capture the continuous nature of the real world. With these drawbacks of grid maps in mind, Hilbert Maps (HM) and more recently Bayesian Hilbert Maps (BHMs), were introduced as a continuous representation of the environment. In this paper we propose a method to merge Bayesian Hilbert Maps built by a team of robots in a decentralised manner. The training of BHMs requires the inversion of a large covariance matrix, incurring cubic complexity. We introduce an approximation, Fast Bayesian Hilbert Maps (Fast-BHM), which reduces the time complexity to below quadratic. Such speed-ups allow the building and merging of Bayesian Hilbert Map models to be practical, opening the door for multi-robot Hilbert Map systems which can be much faster and more robust than an individual robot. By merging several individual Fast-BHMs in a decentralised manner we obtain a unified model of the environment which is itself a Fast-BHM. We conduct experiments to show that global Fast-BHM models do not deteriorate after repeated merging and training. We then empirically demonstrate, due to its the compact representation, fused Fast-BHMs outperform fusion methods involving discretising continuous representations, when the amount of information communicated is limited.


Title: Rapid Inertial Reorientation of an Aerial Insect-sized Robot Using a Piezo-actuated Tail
Abstract: We present the design, fabrication, and feedforward control of a insect-sized (142 mg) aerial robot that is equipped with a bio-inspired inertial tail. A tail allows the robot to perform rapid inertial reorientation as well as to shift weight to modulate aerodynamic torques on its body. Here we present the first analysis of inertial reorientation using a piezo actuator, departing from previous work to date that has focused exclusively on actuation by DC electric motor. The primary difference is that unlike a geared motor system, the piezo-tail system operates as a resonant system, exhibiting slowly-decaying oscillations. We present a dynamic model of piezo-driven inertial reorientation, along with an open-loop feedforward controller that reduces excitation of the resonant mode. We validate our approach on a tethered testbed as well as a flight-capable prototype. Our results indicate that incorporating a tail can allow for more rapid dynamic maneuvers and could stabilize the robot during flight.


Title: Contact–based Navigation Path Planning for Aerial Robots
Abstract: In this paper the problem of contact-based navigation path planning for aerial robots is considered with the goal of enabling the autonomous in-contact operation on surfaces that can be highly anomalous. Such a capacity can prove critical in inspection through contact missions, as well as when a flying robot is tasked to operate in very narrow environments rendering safe free-flight impossible. To achieve this objective, beyond sliding in contact, a new locomotion primitive is introduced, namely that of azimuth rotations perpendicular to the surface under consideration. This new navigation mode, called flying cartwheel mode, offers navigation resourcefulness and resilience when the system is tasked to move in contact with surfaces that are otherwise non-traversable. The designed path planning method exploits both navigation modalities and a traversability metric to decide when to switch from sliding to flying cartwheel mode, and overall provides cost-optimal trajectories for in-contact navigation. The proposed approach is verified both in simulation, as well as experimentally using a surface presenting complex anomalies. It is highlighted that the proposed method does not assume any specialized contact mechanism or a control law tailored to physical interaction tasks, and hence is applicable to almost any micro aerial vehicle integrating protective shrouds around its propellers.


Title: Experimental Learning of a Lift-Maximizing Central Pattern Generator for a Flapping Robotic Wing
Abstract: In this work, we present an application of a policy gradient algorithm to a real-time robotic learning problem, where the goal is to maximize the average lift generation of a dynamically scaled robotic wing at a constant Reynolds number (Re). Compared to our previous work, the merit of this work is two-fold. First, a central pattern generator (CPG) model was used as the motion controller, which provided a smooth generation and transition of rhythmic wing motion patterns while the CPG was being updated by the policy gradient, thereby accelerating the sample generation and reducing the total learning time. Second, the kinematics included three degrees of freedom (stroke, deviation, pitching) and were also free of half-stroke symmetry constraint, together they yielded a larger kinematic space which later explored by the policy gradient to maximize the lift generation. The learned wing kinematics used the full range of stroke and deviation to maximize the lift generation, implying that the wing trajectories with larger disk area and lower frequencies were preferred for high lift generation at constant Re. Furthermore, the wing pitching amplitude converged to values between 45°-49° regardless of what the other parameters were. Notably, the learning agent was able to find two locally optimal wing motion patterns, which had distinct shapes of wing trajectory but generated similar cycle-averaged lift.


Title: Toward Lateral Aerial Grasping & Manipulation Using Scalable Suction
Abstract: This paper is an initial step toward the realization of an aerial robot that can perform lateral physical work, such as drilling a hole or fastening a screw in a wall. Aerial robots are capable of high maneuverability and can provide access to locations that would be difficult or impossible for ground-based robots to reach. However, to fully utilize this mobility, systems would ideally be able to perform functional work in those locations, requiring the ability to exert lateral forces. To substantially improve a hovering vehicle's ability to stably deliver large lateral forces, we propose the use of a versatile suction-based gripper that can establish pulling contact on featureless surfaces. Such contact enables access to environmental forces that can be used to further stabilize the vehicle and also increase the lateral force delivered to the surface through a possible secondary mechanism. This paper introduces the concept, describes the design of a new self-sealing suction cup based on a previous design, details the design of a gripper using those cups, and describes the arm and flight vehicle. It then evaluates the cup and gripper performance in several ways, culminating in physical grasping demonstrations using the arm and gripper, including one in the presence of simulated flight noise based on data from preliminary indoor flight experiments.


Title: Design and Implementation of Computer Vision based In-Row Weeding System
Abstract: Autonomous robotic weeding systems in precision farming have demonstrated their full potential to alleviate the current dependency on herbicides or pesticides by introducing selective spraying or mechanical weed removal modules, thus reducing the environmental pollution and improving the sustainability. However, most previous works require fast weed detection system to achieve real-time treatment. In this paper, a novel computer vision based weeding control system is presented, where a non-overlapping multi-camera system is introduced to compensate the indeterminate classification delays, thus allowing for more complicated and advanced detection algorithms, e.g. deep learning based methods. The suitable tracking and control strategies are developed to achieve accurate and robust in-row weed treatment, and the performance of the proposed system is evaluated in different terrain conditions in the presence of various delays.


Title: LSTM-based Network for Human Gait Stability Prediction in an Intelligent Robotic Rollator
Abstract: In this work, we present a novel framework for on-line human gait stability prediction of the elderly users of an intelligent robotic rollator using Long Short Term Memory (LSTM) networks, fusing multimodal RGB-D and Laser Range Finder (LRF) data from non-wearable sensors. A Deep Learning (DL) based approach is used for the upper body pose estimation. The detected pose is used for estimating the body Center of Mass (CoM) using Unscented Kalman Filter (UKF). An Augmented Gait State Estimation framework exploits the LRF data to estimate the legs' positions and the respective gait phase. These estimates are the inputs of an encoder-decoder sequence to sequence model which predicts the gait stability state as Safe or Fall Risk walking. It is validated with data from real patients, by exploring different network architectures, hyperparameter settings and by comparing the proposed method with other baselines. The presented LSTM-based human gait stability predictor is shown to provide robust predictions of the human stability state, and thus has the potential to be integrated into a general user-adaptive control architecture as a fall-risk alarm.


Title: Urban Swarms: A new approach for autonomous waste management
Abstract: Modern cities are growing ecosystems that face new challenges due to the increasing population demands. One of the many problems they face nowadays is waste management, which has become a pressing issue requiring new solutions. Swarm robotics systems have been attracting an increasing amount of attention in the past years and they are expected to become one of the main driving factors for innovation in the field of robotics. The research presented in this paper explores the feasibility of a swarm robotics system in an urban environment. By using bio-inspired foraging methods such as multi-place foraging and stigmergy-based navigation, a swarm of robots is able to improve the efficiency and autonomy of the urban waste management system in a realistic scenario. To achieve this, a diverse set of simulation experiments was conducted using real-world GIS data and implementing different garbage collection scenarios driven by robot swarms. Results presented in this research show that the proposed system outperforms current approaches. Moreover, results not only show the efficiency of our solution, but also give insights about how to design and customize these systems.


Title: Towards Effective Tactile Identification of Textures using a Hybrid Touch Approach
Abstract: The sense of touch is arguably the first human sense to develop. Empowering robots with the sense of touch may augment their understanding of interacted objects and the environment beyond standard sensory modalities (e.g., vision). This paper investigates the effect of hybridizing touch and sliding movements for tactile-based texture classification. We develop three machine-learning methods within a framework to discriminate between surface textures; the first two methods use hand-engineered features, whilst the third leverages convolutional and recurrent neural network layers to learn feature representations from raw data. To compare these methods, we constructed a dataset comprising tactile data from 23 textures gathered using the iCub platform under a loosely constrained setup, i.e., with nonlinear motion. In line with findings from neuroscience, our experiments show that a good initial estimate can be obtained via touch data, which can be further refined via sliding; combining both touch and sliding data results in 98% classification accuracy over unseen test data.


Title: “Touching to See” and “Seeing to Feel”: Robotic Cross-modal Sensory Data Generation for Visual-Tactile Perception
Abstract: The integration of visual-tactile stimulus is common while humans performing daily tasks. In contrast, using unimodal visual or tactile perception limits the perceivable dimensionality of a subject. However, it remains a challenge to integrate the visual and tactile perception to facilitate robotic tasks. In this paper, we propose a novel framework for the cross-modal sensory data generation for visual and tactile perception. Taking texture perception as an example, we apply conditional generative adversarial networks to generate pseudo visual images or tactile outputs from data of the other modality. Extensive experiments on the ViTac dataset of cloth textures show that the proposed method can produce realistic outputs from other sensory inputs. We adopt the structural similarity index to evaluate similarity of the generated output and real data and results show that realistic data have been generated. Classification evaluation has also been performed to show that the inclusion of generated data can improve the perception performance. The proposed framework has potential to expand datasets for classification tasks, generate sensory outputs that are not easy to access, and also advance integrated visual-tactile perception.


Title: Shear-invariant Sliding Contact Perception with a Soft Tactile Sensor
Abstract: Manipulation tasks often require robots to be continuously in contact with an object. Therefore tactile perception systems need to handle continuous contact data. Shear deformation causes the tactile sensor to output path-dependent readings in contrast to discrete contact readings. As such, in some continuous-contact tasks, sliding can be regarded as a disturbance over the sensor signal. Here we present a shear-invariant perception method based on principal component analysis (PCA) which outputs the required information about the environment despite sliding motion. A compliant tactile sensor (the TacTip) is used to investigate continuous tactile contact. First, we evaluate the method offline using test data collected whilst the sensor slides over an edge. Then, the method is used within a contour-following task applied to 6 objects with varying curvatures; all contours are successfully traced. The method demonstrates generalisation capabilities and could underlie a more sophisticated controller for challenging manipulation or exploration tasks in unstructured environments.


Title: Miniaturization of multistage high dynamic range six-axis force sensor composed of resin material
Abstract: The following topics are dealt with: mobile robots; learning (artificial intelligence); robot vision; path planning; motion control; medical robotics; optimisation; object detection; position control; collision avoidance.


Title: Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots
Abstract: Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.


Title: The Doctor will See You Now: Could a Robot Be a medical Receptionist?
Abstract: A robot cannot be warm and friendly - or can it? To explore whether a robot can be a medical receptionist, we developed a robotic system for interacting with patients at a doctor's clinic, including acting friendly. We designed the robot to interact naturally with patients at the start and finish of a clinic visit. We investigated people's perceptions to the robot in a wizard-of-Oz study, where the participants interacted with the robot over four interactions. 40 participants evaluated the robot. The results indicate the participants thought the robot could be a friendly receptionist, especially after repeated interactions with the robot. However, the participants mainly thought the robot was friendly in a “professional” way, rather than a personal friend.


Title: Designing a Personality-Driven Robot for a Human-Robot Interaction Scenario
Abstract: In this paper, we present an autonomous AI system designed for a Human-Robot Interaction (HRI) study, set around a dice game scenario. We conduct a case study to answer our research question: Does a robot with a socially engaged personality lead to a higher acceptance than a competitive personality? The flexibility of our proposed system allows us to construct and attribute two different personalities to a humanoid robot: a socially engaged personality that maximizes its user interaction and a competitive personality that is focused on playing and winning the game. We evaluate both personalities in a user study, in which the participants play a turn-taking dice game with the robot. Each personality is assessed with four different evaluation tools: 1) the Godspeed Questionnaire, 2) the Mind Perception Questionnaire, 3) a custom questionnaire concerning the overall HRI experience, and 4) a Convolutional Neural Network analyzing the emotions on the participants' facial feedback throughout the game. Our results show that the socially engaged personality evokes stronger emotions among the participants and is rated higher in likability and animacy than the competitive one. We conclude that designing the robot with a socially engaged personality contributes to a higher acceptance within an HRI scenario.


Title: Customized Object Recognition and Segmentation by One Shot Learning with Human Robot Interaction
Abstract: There are two difficulties to utilize state-of-the-art object recognition/detection/segmentation methods to robotic applications. First, most of the deep learning models heavily depend on large amounts of labeled training data, which are expensive to obtain for each individual application. Second, the object categories must be pre-defined in the dataset, thus not practical to scenarios with varying object categories. To alleviate the reliance on pre-defined big data, this paper proposes a customized object recognition and segmentation method. It aims to recognize and segment any object defined by the user, given only one annotation. There are three steps in the proposed method. First, the user takes an exemplar video of the target object with the robot, defines its name, and mask its boundary on only one frame. Then the robot automatically propagates the annotation through the exemplar video based on a proposed data generation method. In the meantime, a segmentation model continuously updates itself on the generated data. Finally, only a lightweight segmentation net is required at testing stage, to recognize and segment the user-defined object in any scenes.


Title: RoPose-Real: Real World Dataset Acquisition for Data-Driven Industrial Robot Arm Pose Estimation
Abstract: It is necessary to employ smart sensory systems in dynamic and mobile workspaces where industrial robots are mounted on mobile platforms. Such systems should be aware of flexible and non-stationary workspaces and able to react autonomously to changing situations. Building upon our previously presented RoPose-system [1], which employs a convolutional neural network architecture that has been trained on pure synthetic data to estimate the kinematic chain of an industrial robot arm system, we now present RoPose-Real. RoPose-Real extends the prior system with a comfortable and targetless extrinsic calibration tool, to allow for the production of automatically annotated datasets for real robot systems. Furthermore, we use the novel datasets to train the estimation network with real world data. The extracted pose information is used to automatically estimate the observing sensor pose relative to the robot system. Finally we evaluate the performance of the presented subsystems in a real world robotic scenario.


Title: A Framework for Self-Training Perceptual Agents in Simulated Photorealistic Environments
Abstract: The development of high-performance perception for mobile robotic agents is still challenging. Learning appropriate perception models usually requires extensive amounts of labeled training data that ideally follows the same distribution as the data an agent will encounter in its target task. Recent developments in gaming industry led to game engines able to generate photorealistic environments in real-time, which can be used to realistically simulate the sensory input of an agent.We propose a novel framework which allows the definition of different learning scenarios and instantiates these scenarios in a high quality game engine where a perceptual agent can act and learn in. The scenarios are specified in a newly developed scenario description language that allows the parametrization of the virtual environment and the perceptual agent. New scenarios can be sampled from a task-specific object distribution that allows the automatic generation of extensive amounts of different learning environments for the perceptual agent.We will demonstrate the plausibility of the framework by conducting object recognition experiments on a real robotic system which has been trained within our framework.


Title: Fast and Precise Detection of Object Grasping Positions with Eigenvalue Templates
Abstract: Fast Graspability Evaluation (FGE) has been proposed as a method for detecting grasping positions on objects and is now being used for industrial robots. FGE uses convolution of hand templates with regions on the target object to estimate the optimum grasping posture. However, the hand opening width and rotation angles must be set with high resolution to achieve highly accurate results and the computational load is high. To address that issue, we propose a method in which hand templates are represented in compact form for faster processing by using singular value decomposition. Applying singular value decomposition enables hand templates to be represented as linear combinations of a small number of eigenvalue templates and eigenfunctions. Eigenfunctions take discrete values, but response values can be calculated with arbitrary parameters by fitting a continuous function. Experimental results show that the proposed method reduces computation time by two thirds while maintaining the same detection accuracy as conventional FGE for both parallel hands and three-finger hands.


Title: Improved Coverage Path Planning Using a Virtual Sensor Footprint: a Case Study on Demining
Abstract: Coverage performance in a coverage path planning problem depends both on the path created and on the footprint of the sensor used. The footprint can be increased either by increasing the size of the sensor, or by mounting the sensor on a robotic arm to allow scanning over larger areas as the platform moves, effectively creating a virtual sensor with a larger footprint than the physical sensor's. However, the virtual footprint comes at a cost requiring formulating an optimization problem for the area of interest. In this work, three common strategies to use a metal detector on a platform are discussed, their time and energy performances are formulated and the corresponding optima are found.


Title: Model-Based Estimation of the Gravity-Loaded Shape and Scene Depth for a Slim 3-Actuator Continuum Robot with Monocular Visual Feedback
Abstract: Fruitful developments on continuum robots have been witnessed in recent years due to their movements and manipulation capabilities in confined spaces. Due to the nature that a continuum robot has an infinite number of DoFs (Degrees of Freedom), majority of the existing systems deployed abundant actuators such that the robot can be controlled in separately modeled and actuated segments with constant or variable curvature. As the shape of a continuum robot is always jointly determined by its actuation and the interactions from the environment, it is hence worth exploring the opposite approach that how a task can be accomplished with a minimal number of actuators. This paper presents the first step of such an investigation where a slim 3-actuator continuum robot is actuated to reach different spatial locations under gravity. As the gravity greatly affects the robot's shape, a monocular camera, together with two UKFs (Unscented Kalman Filters), was used to concurrently estimate the robot's shape and the feature depth. Then the estimated shape can be used in updating the kinematics model of the robot to achieve motion control. Experiments were conducted to validate the effectiveness of the proposed shape estimation, which promises the motion control implementation in the near future work.


Title: Design of a Modular Continuum Robot Segment for use in a General Purpose Manipulator*
Abstract: This paper presents the development of a tendon-driven continuum robot segment with a modular design, simple construction and significant lifting capabilities. The segment features a continuous flexible core combined with rigid interlocking vertebrae evenly distributed along its length. This design allows bending in two degrees of freedom while minimising torsional movement. The segment is actuated by two antagonistic tendon pairs, each of which is driven by a single geared DC motor. Modularity is achieved by embedding these motors in one end of the segment, avoiding the need for a bulky actuation unit and allowing variable numbers of segments to be connected. The design features a large hollow central bore which could be used as a vacuum channel for suction-assisted gripping or to allow ingress and egress of fluids. The design process goes through four iterations, the final two of which are subjected to quantitative experiments to evaluate workspace, lifting capabilities and torsional rigidity. All iterations are fabricated using multi-material 3D printing, which allows the entire structure to be printed as a pre-assembled unit with the rigid vertebrae fused to the flexible core. Assembly is then a simple case of inserting the motors and connecting the tendons. This unconventional manufacturing approach is found to be efficient, effective and relatively cheap.


Title: Velocity Constrained Trajectory Generation for a Collinear Mecanum Wheeled Robot
Abstract: While much research has been conducted into the generation of smooth trajectories for underactuated unstable aerial vehicles such as quadrotors, less attention has been paid to the application of the same techniques to ground based omnidirectional dynamically balancing robots. These systems have more control authority over their linear accelerations than aerial vehicles, meaning trajectory smoothness is less of a critical design parameter. However, when operating in indoor environments these systems must often adhere to relatively low velocity constraints, resulting in very conservative trajectories when enforced using existing trajectory optimisation methods. This paper makes two contributions; this gap is bridged by the extension of these existing methods to create a fast velocity constrained trajectory planner, with trajectory timing characteristics derived from the optimal minimum-time solution of a simplified acceleration and velocity constrained model. Next, a differentially flat model of an omnidirectional balancing robot utilizing a collinear Mecanum drive is derived, which is used to allow an experimental prototype of this configuration to smoothly follow these velocity constrained trajectories.


Title: Gaussian Processes Model-Based Control of Underactuated Balance Robots
Abstract: Control of underactuated balance robot requires external subsystem trajectory tracking and internal unstable subsystem balancing with limited control authority. We present a learning-based control approach for underactuated balance robots. The tracking and balancing control is designed the controller in fast- and slow-time scales. In the slow-time scale, model predictive control is adopted to plan desired internal state profile to achieve external trajectory tracking task. The internal state is then stabilized around the planned profile in the fast-time scale. The control design is based on a learned Gaussian process (GP) regression model without need of a priori knowledge about the robot dynamics. The controller also incorporates the GP model predicted variance to enhance robustness to modeling errors. Experiments are presented using a Furuta pendulum system.


Title: A Heuristic for Task Allocation and Routing of Heterogeneous Robots while Minimizing Maximum Travel Cost
Abstract: The article proposes a new heuristic for task allocation and routing of heterogeneous robots. Specifically, we consider a path planning problem where there are two (structurally) heterogeneous robots that start from distinctive depots and a set of targets to visit. The objective is to find a tour for each robot in a manner that enables each target location to be visited at least once by one of the robots while minimizing the maximum travel cost. A solution for Multiple Depot Heterogeneous Traveling Salesman Problem (MDHTSP) with min-max objective is in great demand with many potential applications, because it can significantly reduce the job completion duration. However, there are still no reliable algorithms that can run in short amount of time. As an initial idea of solving min-max MDHTSP, we present a heuristic based on a primal-dual technique that solves for a case involving two robots while focusing on task allocation. Based on computational results of the implementation, we show that the proposed algorithm produces a good quality of feasible solution within a relatively short computation time.


Title: Solving Methods for Multi-Robot Missions Planning with Energy Capacity Consideration
Abstract: We consider a problem minimizing the total duration of accomplishing missions performed by heterogeneous vehicles. The problem respects constraints related to vehicles' capabilities and energy capacities. The goal is to determine the best routes of each vehicle deployed by choosing which waypoints to pass and which observations to perform. Each vehicle has a particular distance matrix and a limited energy. In order to provide high quality solutions within reasonable computational time, two decomposition-based approximate methods were implemented: (i) the Multiphase heuristic, and (ii) the Two-Phase iterative heuristic. The performance of the methods is evaluated against the Branch-and-Cut algorithm using generated instances.


Title: Salty-A Domain Specific Language for GR(1) Specifications and Designs
Abstract: Designing robot controllers that correctly react to changes in the environment is a time-consuming and error-prone process. An alternative is to use “correct-by-construction” synthesis approaches to automatically generate controller designs from high-level specifications. In particular, Generalized Reactivity(l) or GR(1) specifications are well-suited to express specifications for robots that must act in dynamic environments, and approaches to generate controller designs from GR(1) specifications are highly computationally efficient. Toward that end, this paper presents Salty, a domain-specific language for GR(1) specifications. While tools exist to synthesize system designs from GR(1) specifications, Salty makes such specifications easier to write and debug by supporting features such as richer input and output types, user-defined macros, common specification patterns, and specification optimization and sanity checking. Salty interfaces with the separately developed synthesis tool Slugs to produce a system or controller design, and Salty translates this design to a software implementation in a variety of languages. We demonstrate Salty on an application involving coordination of multiple unmanned air vehicles (UAVs) and provide a workflow for connecting synthesized UAV controllers to freely available UAV planning and simulation software suites UxAS and AMASE.


Title: Persistent Multi-Robot Mapping in an Uncertain Environment
Abstract: This paper proposes a method to deploy teams of robots with constrained energy capacities to persistently maintain a map of an uncertain environment. Typical occupancy map approaches assume a static world; however, we introduce a decay in confidence that degrades the occupancy probability of grid cells and promotes revisitation. Further, sections of the map whose occupancy differs between observations are visited more frequently, while unchanging areas are scheduled less frequently. While naive planning is intractable through the entire space of multi-agent spatio-temporal states, the proposed algorithm decouples planning such that constraints are resolved separately by solving tracTable subproblems. We evaluate this approach in simulation and show how the uncertainty of our world model is maintained below an acceptable threshold while the algorithm retains a tractable computation time.


Title: A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering
Abstract: The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.


Title: A Distributed Predictive Control Approach for Cooperative Manipulation of Multiple Underwater Vehicle Manipulator Systems
Abstract: This paper addresses the problem of cooperative object transportation for multiple Underwater Vehicle Manipulator Systems (UVMSs) in a constrained workspace involving static obstacles. We propose a Nonlinear Model Predictive Control (NMPC) approach for a team of UVMSs in order to transport an object while avoiding significant constraints and limitations such as: kinematic and representation singularities, obstacles within the workspace, joint limits and control input saturations. More precisely, by exploiting the coupled dynamics between the robots and the object, and using certain load sharing coefficients, we design a distributed NMPC for each UVMS in order to cooperatively transport the object within the workspace's feasible region. Moreover, the control scheme adopts load sharing among the UVMSs according to their specific payload capabilities. Additionally, the feedback relies on each UVMS's locally measurements and no explicit data is exchanged online among the robots, thus reducing the required communication bandwidth. Finally, real-time simulation results conducted in UwSim dynamic simulator running in ROS environment verify the efficiency of the theoretical finding.


Title: Ambient light based depth control of underwater robotic unit aMussel
Abstract: In this paper, we present a method for depth control of one degree of freedom (1DOF) underwater robotic platform aMussel, based on the measurements from the ambient light sensor. Since ambient light values change during the day and depend on the weather conditions, references for the controller are acquired from other aMussel holding depth using pressure sensor based controller. Control inputs are transmitted using acoustic communication.


Title: A bio-robotic remora disc with attachment and detachment capabilities for reversible underwater hitchhiking
Abstract: Remoras employ their adhesive discs to rapidly attach to and detach from a wide range of marine surfaces. By analyzing high-speed images of remoras' (Echeneis naucrates) hitchhiking behavior, we describe the fish's detachment mechanism as a lip curling up to break the seal between the disc and substrate. By mimicking the kinematic and morphological properties of the biological disc, we fabricated a multi-material biomimetic disc (whose stiffness spans four orders of magnitude) that is capable of both attachment and detachment. Detachment is realized by a flexible cable-driven mechanism that curls the anterior region of the silicone soft lip, allows leakage under the disc, and equalizes the internal pressure to the external pressure. The disc lamellae with attached carbon fiber spinules can be rotated by hydraulic soft actuators whose internal pressure is precisely tuned to the ambient underwater pressure. During attachment, increasing the rotational angle of the lamellae and the preload of the disc significantly enhanced the adhesive forces. We found that curling up the soft lip and folding down the lamellae rapidly reduced the pulling force of the disc by a factor of 254 compared to that under the attached state, which lead to detachment. Based on these mechanisms, underwater maneuvers involving repeated attachment and detachment were demonstrated with an integrated ROV unit that had a self-contained actuation and control system for the disc. This study lays a foundation for the development of fully untethered robotic systems for underwater hitchhiking in real-world marine environments.


Title: Robot Communication Via Motion: Closing the Underwater Human-Robot Interaction Loop
Abstract: In this paper, we propose a novel method for underwater robot-to-human communication using the motion of the robot as “body language”. To evaluate this system, we develop simulated examples of the system's body language gestures, called kinemes, and compare them to a baseline system using flashing colored lights through a user study. Our work shows evidence that motion can be used as a successful communication vector which is accurate, easy to learn, and quick enough to be used, all without requiring any additional hardware to be added to our platform. We thus contribute to “closing the loop” for human-robot interaction underwater by proposing and testing this system, suggesting a library of possible body language gestures for underwater robots, and offering insight on the design of nonverbal robot-to-human communication methods.


Title: Three-Dimensionally Maneuverable Robotic Fish Enabled by Servo Motor and Water Electrolyser
Abstract: Three-dimensionally (3D) maneuverable robotic fish are highly desirable due to their abilities to explore and survey the underwater environment. Existing depth control mechanism is focused on using compressed air or piston to generate volume change, which makes the system bulky and impractical in a small size underwater robot. In this paper, a small and compact 3D maneuverable robotic fish is developed. Instead of using a compressed air tank, the robot is equipped with an on-board water electrolyzer to generate the gases for depth change. The fabricated robotic fish shows fast diving and rising performance. A servo motor is used to generate asymmetric flapping motion on the caudal fin, which leads to a two-dimensionally (2D) planar motion. A 3D dynamic model is then derived for the fabricated robotic fish. Several open-loop control experiments have been conducted to validate the model as well as the design. It has been demonstrated in the experimental results that the robot is capable of generating 3D motion. The robot can achieve 0.13 m/s forward velocity, 30.6 degree/s turning rate, and it takes about 5.5 s to dive to 0.55 m and 10 s to rise.


Title: Nonlinear Orientation Controller for a Compliant Robotic Fish Based on Asymmetric Actuation
Abstract: Compliant fish-like robots are being developed as efficient and dependable underwater observation platforms with low impact on the observed environment. Orientation control is an essential building block to achieve autonomy for those vehicles. So far, the major focus has been on rigid tails or on flexible tails with a high degree of actuation. We present a novel control strategy for an underactuated robotic fish with a flexible tail optimized for cruising. The basis for our approach is the generation of asymmetric velocity profiles of the robot's tail beats. To achieve such velocity profiles, the usual sinusoidal tail actuation is replaced with skewed triangle waves. We provide a simple formulation for such waves, where their skew is dependent on only one variable which we define as skew factor. Furthermore, a nonlinear control law is derived to achieve the desired turning motions. We implement the controller on a compliant fish-like robot with a simple actuation mechanism. The control scheme is experimentally validated, and its robustness is tested in field trials.


Title: Towards Fully Dense Direct Filter-Based Monocular Visual-Inertial Odometry
Abstract: We propose a fully dense direct filter-based visual-inertial odometry method estimating both pixel depth for all pixels and robot state simultaneously, having all uncertainties in the same state vector. Due to the fully dense method, our approach works even in low-textured areas with very low, smooth gradients (i.e. scenes where feature based or semi-dense approaches fail). Our algorithm performs in real-time on a CPU with a time complexity linearly dependent on the amount of pixels in the provided image. To achieve this, we propose complexity reduction methods for fast matrix inversion, exploiting specific structures of the covariance matrix. We provide both simulated and real-world results in low-textured areas with a smooth gradient.


Title: Enhancing V-SLAM Keyframe Selection with an Efficient ConvNet for Semantic Analysis
Abstract: Selecting relevant visual information from a video is a challenging task on its own and even more in robotics, due to strong computational restrictions. This work proposes a novel keyframe selection strategy based on image quality and semantic information, which boosts strategies currently used in Visual-SLAM (V-SLAM). Commonly used V-SLAM methods select keyframes based only on relative displacements and amount of tracked feature points. Our strategy to select more carefully these keyframes allows the robotic systems to make better use of them. With minimal computational cost, we show that our selection includes more relevant keyframes, which are useful for additional posterior recognition tasks, without penalizing the existing ones, mainly place recognition. A key ingredient is our novel CNN architecture to run a quick semantic image analysis at the onboard CPU of the robot. It provides sufficient accuracy significantly faster than related works. We demonstrate our hypothesis with several public datasets with challenging robotic data.


Title: Adaptive H∞ Controller for Precise Manoeuvring of a Space Robot
Abstract: A space robot working in a controlled-floating mode can be used for performing in-orbit telescope assembly through simultaneously controlling the motion of the spacecraft base and its robotic arm. Handling and assembling optical mirrors requires the space robot to achieve slow and precise manoeuvres regardless of the disturbances and errors in the trajectory. The robustness offered by the nonlinear H∞ controller, in the presence of environmental disturbances and parametric uncertainties, makes it a viable solution. However, using fixed tuning parameters for this controller does not always result in the desired performance as the arm's trajectory is not known a priori for orbital assembly missions. In this paper, a complete study on the impact of the different tuning parameters is performed and a new adaptive H∞ controller is developed based on bounded functions. The simulation results presented show that the proposed adaptive H∞ controller guarantees robustness and precise tracking using a minimal amount of forces and torques for assembly operations using a small space robot.


Title: Experimental Evaluation of Teleoperation Interfaces for Cutting of Satellite Insulation
Abstract: On-orbit servicing of satellites is complicated by the fact that almost all existing satellites were not designed to be serviced. This creates a number of challenges, one of which is to cut and partially remove the protective thermal blanketing that encases a satellite prior to performing the servicing operation. A human operator on Earth can perform this task telerobotically, but must overcome difficulties presented by the multi-second round-trip telemetry delay between the satellite and the operator and the limited, or even obstructed, views from the available cameras. This paper reports the results of ground-based experiments with trained NASA robot teleoperators to compare our recently-reported augmented virtuality visualization to the conventional camera-based visualization. We also compare the master console of a da Vinci surgical robot to the conventional teleoperation interface. The results show that, for the cutting task, the augmented virtuality visualization can improve operator performance compared to the conventional visualization, but that operators are more proficient with the conventional control interface than with the da Vinci master console.


Title: OmniDRL: Robust Pedestrian Detection using Deep Reinforcement Learning on Omnidirectional Cameras*
Abstract: Pedestrian detection is one of the most explored topics in computer vision and robotics. The use of deep learning methods allowed the development of new and highly competitive algorithms. Deep Reinforcement Learning has proved to be within the state-of-the-art in terms of both detection in perspective cameras and robotics applications. However, for detection in omnidirectional cameras, the literature is still scarce, mostly because of their high levels of distortion. This paper presents a novel and efficient technique for robust pedestrian detection in omnidirectional images. The proposed method uses deep Reinforcement Learning that takes advantage of the distortion in the image. By considering the 3D bounding boxes and their distorted projections into the image, our method is able to provide the pedestrian's position in the world, in contrast to the image positions provided by most state-of-the-art methods for perspective cameras. Our method avoids the need of pre-processing steps to remove the distortion, which is computationally expensive. Beyond the novel solution, our method compares favorably with the state-of-the-art methodologies that do not consider the underlying distortion for the detection task.


Title: 2D3D-Matchnet: Learning To Match Keypoints Across 2D Image And 3D Point Cloud
Abstract: Large-scale point cloud generated from 3D sensors is more accurate than its image-based counterpart. However, it is seldom used in visual pose estimation due to the difficulty in obtaining 2D-3D image to point cloud correspondences. In this paper, we propose the 2D3D-MatchNet - an end-to-end deep network architecture to jointly learn the descriptors for 2D and 3D keypoint from image and point cloud, respectively. As a result, we are able to directly match and establish 2D-3D correspondences from the query image and 3D point cloud reference map for visual pose estimation. We create our Oxford 2D-3D Patches dataset from the Oxford Robotcar dataset with the ground truth camera poses and 2D-3D image to point cloud correspondences for training and testing the deep network. Experimental results verify the feasibility of our approach.


Title: Teaching Robots To Draw
Abstract: In this paper, we introduce an approach which enables manipulator robots to write handwritten characters or line drawings. Given an image of just-drawn handwritten characters, the robot infers a plan to replicate the image with a writing utensil, and then reproduces the image. Our approach draws each target stroke in one continuous drawing motion and does not rely on handcrafted rules or on predefined paths of characters. Instead, it learns to write from a dataset of demonstrations. We evaluate our approach in both simulation and on two real robots. Our model can draw handwritten characters in a variety of languages which are disjoint from the training set, such as Greek, Tamil, or Hindi, and also reproduce any stroke-based drawing from an image of the drawing.


Title: Learning Probabilistic Multi-Modal Actor Models for Vision-Based Robotic Grasping
Abstract: Many previous works approach vision-based robotic grasping by training a value network that evaluates grasp proposals. These approaches require an optimization process at run-time to infer the best action from the value network. As a result, the inference time grows exponentially as the dimension of action space increases. We propose an alternative method, by directly training a neural density model to approximate the conditional distribution of successful grasp poses from the input images. We construct a neural network that combines Gaussian mixture and normalizing flows, which is able to represent multi-modal, complex probability distributions. We demonstrate on both simulation and real robot that the proposed actor model achieves similar performance compared to the value network using the Cross-Entropy Method (CEM) for inference, on top-down grasping with a 4 dimensional action space. Our actor model reduces the inference time by 3 times compared to the state-of-the-art CEM method. We believe that actor models will play an important role when scaling up these approaches to higher dimensional action spaces.


Title: Fabrication and Characterization of Muscle Rings Using Circular Mould and Rotary Electrical Stimulation for Bio-Syncretic Robots
Abstract: Bio-syncretic robots made up of living biological systems and electromechanical systems may have the potential excellent performance of natural biological entities. Therefore, the study of the bio-syncretic robots has got lots of attention in recent years. The 3D skeletal muscles have been used widely, due to the considerable contraction force and the controllability. However, the low differentiation quality of the C2C12 in the tissues hinders the broad application in the development of the skeleton muscle actuated bio-syncretic robots. In this work, an approach based on circular mould and rotary electrical stimulation to build high-quality muscle rings, which can be used to actuate various bio-syncretic robots, has been proposed. Firstly, the advantage of the proposed circular mould for the muscle rings culture has been shown by simulation. Then, the muscle rings have been fabricated with different moulds using the experiment-optimized compositions of the biological mixture. After that, the muscle rings in the circular moulds with different electrical stimulations have been cultured, to show the superiority of the proposed rotary electrical stimulation. Moreover, the contractility of the muscle rings have been measured under the different electrical pulses stimulation, for the study of the control property of the muscle rings. This work may be meaningful not only the development of bio-syncretic robots actuated by 3D muscle tissues but also the muscle tissue engineering.


Title: Cell Injection Microrobot Development and Evaluation in Microfluidic Chip
Abstract: We propose an innovative design of microrobot, which can achieve donor cell suction, delivery and injection in a mammalian oocyte on microfluidic chip. The microrobot body contains a hollow space that produces suction and ejection forces for injection of cell nuclei using a nozzle at the tip of the robot. Specifically, a controller changes the hollow volume by balancing the magnetic and elastic forces of the membrane, and along with motion of stages in the XY plane. A glass capillary attached at the tip of the robot contains the nozzle is able to absorb and inject cell nuclei. The microrobot provides three degrees of freedom and generates micronewton forces. We demonstrate the effectiveness of the proposed microrobot through an experiment of absorption and ejection of 20 μm particles from the nozzle using magnetic control in a microfluidic chip.


Title: Fast and Robust 3D Person Detector and Posture Estimator for Mobile Robotic Applications
Abstract: Due to recent deep learning techniques, person detection seems to be solved in the computer vision domain, however, it is still an issue in mobile robotics. On a robot only limited computing capacities are available. The challenge gets even more difficult when operating in an environment, with people in poses different from the standard upright ones. In this work the environment of a supermarket is considered. Unlike most scenarios targeted by the community, persons not only occur in standing postures, but also grasping into the shelves or squatting in front of them. Furthermore, people are heavily occluded, e.g. by shopping carts. In such a challenging environment, it is important to perceive people early enough and in real-time in order to enable a socially aware navigation. Classical person detectors often suffer from a high posture variance or do not achieve acceptable real-time detection rates. For this reason, different components from the 3D object detection domain have been used to create a new robust person detector for mobile application. Operating on 3D point clouds allows fast detections in real-time up to our goal distance of ten meters and above using the Kinect2 depth sensor. The detector can even differentiate between typical postures of customers who stand or squat in front of shelves.


Title: Spatiotemporal and Kinetic Gait Analysis System Based on Multisensor Fusion of Laser Range Sensor and Instrumented Insoles
Abstract: Tracking of human legs during walking are key technologies for gait analysis evaluating the movement function of the elderly and patients with gait disorders. Although the motion capture cameras are the gold standard method for gait analysis because of their high accuracy, they are not always accessible in clinical sites because of their cost, scale, and usability. In response, a laser range sensor (LRS), which is used for obstacle avoidance and human detection of mobile robots, has recently been employed for tracking of leg motions. Some previous studies set LRS at shin height and tracked leg motions during walking using three or five observation patterns and the Kalman filtering and data association methods. However, these systems had difficulty in tracking during walking along a circular trajectory including frequent overlaps and occlusions of legs. Therefore, this paper presents a spatiotemporal and kinetic gait analysis system using a single LRS and instrumented insoles and proposes a multisensor fusion algorithm for tracking leg motions. The instrumented insoles are in-shoe devices embedded force sensors and can detect accurate timings of gait events via force sensing. The system identifies gait phases by the fusion algorithm and switches acceleration input added to motion models of tracked legs for the Kalman filter and data association. The tracking performance of the proposed system was evaluated by measuring walking on a circular trajectory in experiments.


Title: Part Segmentation for Highly Accurate Deformable Tracking in Occlusions via Fully Convolutional Neural Networks
Abstract: Successfully tracking the human body is an important perceptual challenge for robots that must work around people. Existing methods fall into two broad categories: geometric tracking and direct pose estimation using machine learning. While recent work has shown direct estimation techniques can be quite powerful, geometric tracking methods using point clouds can provide a very high level of 3D accuracy which is necessary for many robotic applications. However these approaches can have difficulty in clutter when large portions of the subject are occluded. To overcome this limitation, we propose a solution based on fully convolutional neural networks (FCN). We develop an optimized Fast-FCN network architecture for our application which allows us to filter observed point clouds and improve tracking accuracy while maintaining interactive frame rates. We also show that this model can be trained with a limited number of examples and almost no manual labelling by using an existing geometric tracker and data augmentation to automatically generate segmentation maps. We demonstrate the accuracy of our full system by comparing it against an existing geometric tracker, and show significant improvement in these challenging scenarios.


Title: Using Variable Natural Environment Brain-Computer Interface Stimuli for Real-time Humanoid Robot Navigation
Abstract: This paper addresses the challenge of humanoid robot teleoperation in a natural indoor environment via a Brain-Computer Interface (BCI). We leverage deep Convolutional Neural Network (CNN) based image and signal understanding to facilitate both real-time object detection and dry-Electroencephalography (EEG) based human cortical brain bio-signals decoding. We employ recent advances in dry-EEG technology to stream and collect the cortical waveforms from subjects while they fixate on variable Steady State Visual Evoked Potential (SSVEP) stimuli generated directly from the environment the robot is navigating. To these ends, we propose the use of novel variable BCI stimuli by utilising the real-time video streamed via the on-board robot camera as visual input for SSVEP, where the CNN detected natural scene objects are altered and flickered with differing frequencies (10Hz, 12Hz and 15Hz). These stimuli are not akin to traditional stimuli - as both the dimensions of the flicker regions and their on-screen position changes depending on the scene objects detected. Onscreen object selection via such a dry-EEG enabled SSVEP methodology, facilitates the on-line decoding of human cortical brain signals, via a specialised secondary CNN, directly into teleoperation robot commands (approach object, move in a specific direction: right, left or back). This SSVEP decoding model is trained via a priori offline experimental data in which very similar visual input is present for all subjects. The resulting classification demonstrates high performance with mean accuracy of 85% for the real-time robot navigation experiment across multiple test subjects.


Title: Estimating the Localizability in Tunnel-like Environments using LiDAR and UWB
Abstract: The application of robots in inspection tasks has been growing quickly thanks to the advancements in autonomous navigation technology, especially the robot localization techniques in GPS-denied environments. Although many methods have been proposed to localize a robot using onboard sensors such as cameras and LiDARs, achieving robust localization in geometrically degenerated environments, e.g. tunnels, remains a challenging problem. In this work, we focus on the robust localization problem in such situations. A novel degeneration characterization model is presented to estimate the localizability at a given location in the prior map. And the localizability of a LiDAR and an Ultra-Wideband (UWB) ranging radio is analyzed. Additionally, a probabilistic sensor fusion method is developed to combine IMU, LiDAR and the UWB. Experiment results show that this method allows for robust localization inside a long straight tunnel.


Title: Exploiting Trademark Databases for Robotic Object Fetching
Abstract: Service robots require the ability to recognize various household objects in order to carry out certain tasks, such as fetching an object for a person. Manually collecting information on all the objects a robot may encounter in a household is tedious and time-consuming; therefore this paper proposes the use of large-scale data from existing trademark databases. These databases contain logo images and a description of the goods and services the logo was registered under. For example, Pepsi is registered under soft drinks. We extend domain randomization in order to generate synthetic data to train a convolutional neural network logo detector, which outperformed previous logo detectors trained on synthetic data. We also provide a practical implementation for object fetching on a robot, which uses a Kinect and the logo detector to identify the object the human user requested. Tests on this robot indicate promising results, despite not using any real world photos for training.


Title: Object Detection Approach for Robot Grasp Detection
Abstract: In this paper, we focus on the robot grasping problem with parallel grippers using image data. For this task, we propose and implement an end-to-end approach. In order to detect the good grasping poses for a parallel gripper from RGB images, we have employed transfer learning for a Convolutional Neural Network (CNN) based object detection architecture. Our obtained results show that, the adapted network either outperforms or is on-par with the state-of-the art methods on a benchmark dataset. We also performed grasping experiments on a real robot platform to evaluate our method's real world performance.


Title: Toward Fingertip Non-Contact Material Recognition and Near-Distance Ranging for Robotic Grasping
Abstract: We report the feasibility study of a new acoustic and optical bi-modal distance & material sensor for robotic grasping. The new sensor is designed to be mounted on the robot fingertip to provide last-moment perception before contact happens. It is based on both pulse-echo ultrasound and optoacoustic effects enabled by single-element air-coupled transducers. In contrast to conventional contact-based and recent pre-touch approaches, this new method overcomes their disadvantages and provides robotic fingers with the capability to detect the distance and material type of the target at a near distance before contact occurs, which is crucial for robust and nimble grasping. The proposed sensor has been tested with different materials, shapes, and porous properties. The experimental results show that this sensor design is functional and practical.


Title: Reactive Walking Based on Upper-Body Manipulability: An application to Intention Detection and Reaction
Abstract: In this paper, we look at the challenge of human robot interaction in locomotion. We consider a hand-in-hand interaction scenario where a human compliantly interacts with the upper-body of an impedance controlled humanoid. By exploring the velocity transmission of the robot arms, and the interaction in terms of robot arms manipulation quality evaluated through the monitoring of their manipulability the proposed method derives suitable reactive steps in appropriate directions to ensure that the robot manipulation ability is maintained with the robot arms providing high capacity of motion along the different directions. The proposed approach can be combined with different walking pattern generators and is not tailored to a specific one used in this work. The results of the proposed method are experimentally validated on the COMAN + humanoid robot showing the efficacy of the method to generate reactive stepping driven by the interaction and manipulation motion of the human operator. Besides, the work also provides a real-time software architecture to control humanoid COMAN+, but it is also flexible to be used for the control of other robot platforms.


Title: A Self-Modulated Impedance Multimodal Interaction Framework for Human-Robot Collaboration
Abstract: Human Robot interaction is a fundamental perquisite for any robot performing a physical task in collaboration with a human. The presence of disturbances arising from the partially known tasks payloads, the unexpected interaction forces in general, and the uncertainty in the interpretation of the human intention in terms of motions and forces can pose significant challenges and eventually compromise the execution of the collaborative task. This work presents a novel, intrinsically adaptable multimodal (force, motion and verbal) interaction framework for human-robot collaboration (HRC) that leverages on an online self-tuning stiffness regulation principle to provide adaptation to interaction/payload forces and reject disturbances arising by unexpected interaction loads. Besides the presented method, it enables the rejection of unnecessary motion commands (e.g. oscillations generated by the human operator) to reach the robot co-worker through the filtering of the human generated motions, that are outside the range (in terms of speed and acceleration) of the envisioned manipulation manoeuvres. Finally, a verbal interaction channel allows the operator to convey securely his high level intentions and to control the states of the task execution. We evaluated and demonstrated the effectiveness of the proposed multimodal interaction framework in a high weight carrying human-robot collaboration task using the humanoid robot COMAN +.


Title: SMT-Based Control and Feedback for Social Navigation
Abstract: This paper combines techniques from Formal Methods and Human-Robot Interaction (HRI) to address the challenge of a robot walking with a human while maintaining a socially acceptable distance and avoiding collisions. We formulate a set of constraints on the robot motion using Satisfiability Modulo Theories (SMT) formulas, and synthesize robot control that is guaranteed to be safe and correct. Due to its use of high-level formal specifications, the controller is able to provide feedback to the user in situations where human behavior causes the robot to fail. This feedback allows the human to adjust their behavior and recover joint navigation. We demonstrate the behavior of the robot in a variety of simulated scenarios and compare it to utility-based side-by-side navigation control.


Title: Safe and Efficient High Dimensional Motion Planning in Space-Time with Time Parameterized Prediction
Abstract: In this work, we propose an algorithm that can plan safe and efficient robot trajectories in real time, given time-parameterized motion predictions, in order to avoid fast-moving obstacles in human-robot collaborative environments. Our algorithm is able to reduce the robot configuration space and the time domain significantly by constructing a Lazy Safe Interval Probabilistic Roadmap based on a pre-planned path. The algorithm then plans efficient obstacle-avoidance strategies within the space-time roadmap. We benchmarked our algorithm by evaluating the performance of a simulated 6-joint manipulator attempting to avoid a quickly moving human hand, using a dataset collected from human experiments. We compared our algorithm's performance with those of 8 variations of prior state-of-the-art planners. Results from this empirical evaluation indicate that our method generated safe plans in 97.5% of the evaluated situations, achieved a planning speed 30 times faster than the benchmarked methods that planned in the time domain without space reduction, and accomplished the minimal solution execution time among the benchmarked planners with a similar planning speed.


Title: Fast Online Segmentation of Activities from Partial Trajectories
Abstract: Augmenting a robot with the capacity to understand the activities of the people it collaborates with in order to then label and segment those activities allows the robot to generate an efficient and safe plan for performing its own actions. In this work, we introduce an online activity segmentation algorithm that can detect activity segments by processing a partial trajectory. We model the transitions through activities as a hidden Markov model, which runs online by implementing an efficient particle-filtering approach to infer the maximum a posteriori estimate of the activity sequence. This process is complemented by an online search process to refine activity segments using task model information about the partial order of activities. We evaluated our algorithm by comparing its performance to two state-of-the-art activity segmentation algorithms on three human activity datasets. The proposed algorithm improved activity segmentation accuracy across all three datasets compared with the other two approaches, with a range from 11.3% to 65.5%, and could accurately recognize an activity through observation alone for 31.6% of the initial trajectory of that activity, on average. We also implemented the algorithm onto an industrial mobile robot during an automotive assembly task in which the robot tracked a human worker's progress and provided the worker with the correct materials at the appropriate time.


Title: Using Augmentation to Improve the Robustness to Rotation of Deep Learning Segmentation in Robotic-Assisted Surgical Data
Abstract: Robotic-Assisted Minimally Invasive Surgery allows for easy recording of kinematic data, and presents excellent opportunities for data-intensive approaches to assessment of surgical skill, system design, and automation of procedures. However, typical surgical cases result in long data streams, and therefore, automated segmentation into gestures is important. The public release of the JIGSAWS dataset allowed for developing and benchmarking data-intensive segmentation algorithms. However, this dataset is small and the gestures are similar in their structure and directions. This may limit the generalization of the algorithms to real surgical data that are characterized by movements in arbitrary directions. In this paper, we use a recurrent neural network to segment a suturing task, and demonstrate one such generalization problem-limited generalization to rotation. We propose a simple augmentation that can solve this problem without collecting new data, and demonstrate its benefit using: (1) the JIGSAWS dataset, and (2) a new dataset that we recorded with a da Vinci Research Kit. Our study highlights the prospect of using data augmentation in the analysis of kinematic data in surgical data science.


Title: Deep Learning based Motion Prediction for Exoskeleton Robot Control in Upper Limb Rehabilitation
Abstract: The synchronization of the movement between exoskeleton robot and human arm is crucial for Robot-assisted training (RAT) in upper limb rehabilitation. In this paper, we propose a deep learning based motion prediction model which is applied to our recently developed 8 degrees-of-freedom (DoFs) upper limb rehabilitation exoskeleton, named NTUH-II. The human arm dynamics and surface electromyography (sEMG) can be first measured by two wireless sensors and used as input of deep learning model to predict user's motion. Then, the prediction can be used as desired motion trajectory of the exoskeleton. As a result, the robot arm can follow the movement on either side of the user's arm in real-time. Various experiments have been conducted to verify the performance of the proposed motion prediction model, and the results show that the proposed motion prediction implementation can reduce the mean absolute error and the average delay time of movement between human arm and robot arm.


Title: A Data-Driven Predictive Model of Individual-Specific Effects of FES on Human Gait Dynamics
Abstract: Modeling individual-specific gait dynamics based on kinematic data could aid development of gait rehabilitation robotics by enabling robots to predict the user's gait kinematics with and without external inputs, such as mechanical or electrical perturbations. Here we address a current limitation of data-driven gait models, which do not yet predict human gait dynamics nor responses to perturbations. We used Switched Linear Dynamical Systems (SLDS) to model joint angle kinematic data from healthy individuals walking on a treadmill during normal gait and during gait perturbed by functional electrical stimulation (FES) to the ankle muscles. Our SLDS models were able to generate joint angle trajectories in each of four gait phases, as well as across an entire gait cycle, given initial conditions and gait phase information. Because the SLDS dynamics matrices encoded significant coupling across joints that differed across indivdiuals, we compared the SLDS predictions to that of a kinematic model, where the joint angles were independent. Joint angle trajectories generated by SLDS and kinematic models were similar over time horizons of a few milliseconds, but SLDS models provided better predictions of gait kinematics over time horizons of up to a second. We also demonstrated that SLDS models can infer and predict individual-specific responses to FES during swing phase. As such, SLDS models may be a promising approach for online estimation and control of and human gait dynamics, allowing robotic control strategies to be tailored to an individual's specific gait coordination patterns.


Title: A new soft fingertip based on electroactive hydrogels
Abstract: In this work we present the design and application of an active soft fingertip for robotic hands. This fingertip is based on a new type of hydrogel which has been designed with the purpose of overcoming some of the major drawbacks of previous hydrogels such as the dependency of aqueous solutions. Fingertip applications benefit from the changes of stiffness and volume which take place in our hydrogel when electric fields are applied. Theoretical modeling and experimental verification of the fingertip properties are presented in this work, showing its potential usability in grasping and manipulation tasks.


Title: Open Loop Position Control of Soft Continuum Arm Using Deep Reinforcement Learning
Abstract: Soft robots undergo large nonlinear spatial deformations due to both inherent actuation and external loading. The physics underlying these deformations is complex, and often requires intricate analytical and numerical models. The complexity of these models may render traditional model-based control difficult and unsuitable. Model-free methods offer an alternative for analyzing the behavior of such complex systems without the need for elaborate modeling techniques. In this paper, we present a model-free approach for open loop position control of a soft spatial continuum arm, based on deep reinforcement learning. The continuum arm is pneumatically actuated and attains a spatial work-space by a combination of unidirectional bending and bidirectional torsional deformation. We use Deep-Q Learning with experience replay to train the system in simulation. The efficacy and robustness of the control policy obtained from the system is validated both in simulation and on the continuum arm prototype for varying external loading conditions.


Title: Fast Motion Planning for High-DOF Robot Systems Using Hierarchical System Identification
Abstract: We present an efficient algorithm for motion planning and controlling a robot system with a high number of degrees-of-freedom (DOF). These systems include high-DOF soft robots and articulated robots interacting with a deformable environment. We present a novel technique to accelerate the evaluations of the forward dynamics function by storing the results of costly computations in a hierarchical adaptive grid. Furthermore, we exploit the underactuated properties of the robot systems and build the grid in a low-dimensional space. Our approach approximates the forward dynamics function with guaranteed error bounds and can be used in optimization-based motion planning and reinforcement-learning-based feed-back control. We highlight the performance on two high-DOF robot systems: a line-actuated elastic robot arm and an underwater swimming robot in water. Compared to prior techniques based on exact dynamics evaluation, we observe one to two orders of magnitude improvement in the performance.


Title: Resilient Task Planning and Execution for Reactive Soft Robots
Abstract: Soft robots utilize compliant materials to perform motions and behaviors not typically achievable by rigid bodied systems. These materials and soft actuator fabrication methods have been leveraged to create multigait walking soft robots. However, soft materials are prone to failure, restricting the ability of soft robots to accomplish tasks. In this work we address the problem of generating reactive controllers for multigait walking soft robots that are resilient to actuator failure by applying methods of formal synthesis. We present a sensing-based abstraction for actuator performance, provide a framework for encoding multigait behavior and actuator failure in Linear Temporal Logic (LTL), and demonstrate synthesized controllers on a physical soft robot.


Title: Dynamic morphological computation through damping design of soft material robots: application to under-actuated grippers
Abstract: This article presents the design of soft material robots with tunable damping properties. This study derives from the investigation of an under-actuated dynamic approach involving multi-chamber pneumatic systems. The co-design of the mechanical parameters (stiffness and damping) of the system along with the time profile of the input allows to obtain different behaviors using a reduced number of feeding line. In this work we analyze via simulations and experiments several approaches to tune the damping of soft robots. The most effective solution employs a layer of granular material immersed in viscous oil within the chamber wall. This method has been employed to realize bending actuators with a continuous deformation pattern. Finally, we show an application involving a two-fingered gripper fed by a single pneumatic line, which is able to perform pinch and power grasp.


Title: Augmented Reality Assisted Instrument Insertion and Tool Manipulation for the First Assistant in Robotic Surgery
Abstract: In robotic-assisted laparoscopic surgery, the first assistant (FA) stands at the bedside assisting the intervention, while the surgeon sits at the console teleoperating the robot. Tasks for the FA include navigating new instruments into the surgeon's field-of-view and passing in or retracting materials from the body using hand-held tools. We previously developed ARssist, an augmented reality application based on an optical see-through head-mounted display, to aid the FA. In this paper, we refine the system and first perform a pilot study with three experienced surgeons for two specific tasks: instrument insertion and tool manipulation. The results suggest that ARssist would be especially useful for less experienced assistants and for difficult hand-eye configurations. We then perform a multi-user study with inexperienced subjects. The results show that ARssist can reduce navigation time by 34.57%, enhance insertion path consistency by 41.74%, reduce root-mean-square path deviation by 40.04%, and reduce tool manipulation time by 72.25%. Thus, ARssist has the potential to improve efficiency, safety and hand-eye coordination, especially for novice assistants.


Title: On the role of wearable haptics for force feedback in teleimpedance control for dual-arm robotic teleoperation
Abstract: Robotic teleoperation enables humans to safely complete exploratory procedures in remote locations for applications such as deep sea exploration or building assessments following natural disasters. Successful task completion requires meaningful dual arm robotic coordination and proper understanding of the environment. While these capabilities are inherent to humans via impedance regulation and haptic interactions, they can be challenging to achieve in telerobotic systems. Teleimpedance control has allowed impedance regulation in such applications, and bilateral teleoperation systems aim to restore haptic sensation to the operator, though often at the expense of stability or workspace size. Wearable haptic devices have the potential to apprise the operator of key forces during task completion while maintaining stability and transparency. In this paper, we evaluate the impact of wearable haptics for force feedback in teleimpedance control for dual-arm robotic teleoperation. Participants completed a peg-in-hole, box placement task, aiming to seat as many boxes as possible within the trial period. Experiments were conducted both transparent and opaque boxes. With the opaque box, participants achieved a higher number of successful placements with haptic feedback, and we saw higher mean interaction forces. Results suggest that the provision of wearable haptic feedback may increase confidence when visual cues are obscured.


Title: CNN-SVO: Improving the Mapping in Semi-Direct Visual Odometry Using Single-Image Depth Prediction
Abstract: Reliable feature correspondence between frames is a critical step in visual odometry (VO) and visual simultaneous localization and mapping (V-SLAM) algorithms. In comparison with existing VO and V-SLAM algorithms, semi-direct visual odometry (SVO) has two main advantages that lead to state-of-the-art frame rate camera motion estimation: direct pixel correspondence and efficient implementation of probabilistic mapping method. This paper improves the SVO mapping by initializing the mean and the variance of the depth at a feature location according to the depth prediction from a single-image depth prediction network. By significantly reducing the depth uncertainty of the initialized map point (i.e., small variance centred about the depth prediction), the benefits are twofold: reliable feature correspondence between views and fast convergence to the true depth in order to create new map points. We evaluate our method with two outdoor datasets: KITTI dataset and Oxford Robotcar dataset. The experimental results indicate that improved SVO mapping results in increased robustness and camera tracking accuracy. The implementation of this work is available at https: //github.com/yan99033/CNN-SVO.


Title: A Unified Framework for Mutual Improvement of SLAM and Semantic Segmentation
Abstract: This paper presents a novel framework for simultaneously implementing localization and segmentation, which are two of the most important vision-based tasks for robotics. While the goals and techniques used for them were considered to be different previously, we show that by making use of the intermediate results of the two modules, their performance can be enhanced at the same time. Our framework is able to handle both the instantaneous motion and long-term changes of instances in localization with the help of the segmentation result, which also benefits from the refined 3D pose information. We conduct experiments on various datasets, and prove that our framework works effectively on improving the precision and robustness of the two tasks and outperforms existing localization and segmentation algorithms.


Title: MID-Fusion: Octree-based Object-Level Multi-Instance Dynamic SLAM
Abstract: We propose a new multi-instance dynamic RGB-D SLAM system using an object-level octree-based volumetric representation. It can provide robust camera tracking in dynamic environments and at the same time, continuously estimate geometric, semantic, and motion properties for arbitrary objects in the scene. For each incoming frame, we perform instance segmentation to detect objects and refine mask boundaries using geometric and motion information. Meanwhile, we estimate the pose of each existing moving object using an object-oriented tracking method and robustly track the camera pose against the static scene. Based on the estimated camera pose and object poses, we associate segmented masks with existing models and incrementally fuse corresponding colour, depth, semantic, and foreground object probabilities into each object model. In contrast to existing approaches, our system is the first system to generate an object-level dynamic volumetric map from a single RGB-D camera, which can be used directly for robotic tasks. Our method can run at 2-3 Hz on a CPU, excluding the instance segmentation part. We demonstrate its effectiveness by quantitatively and qualitatively testing it on both synthetic and real-world sequences.


Title: Surfel-Based Dense RGB-D Reconstruction With Global And Local Consistency
Abstract: Achieving high surface reconstruction accuracy in dense mapping has been a desirable target for both robotics and vision communities. In the robotics literature, simultaneous localization and mapping (SLAM) systems use RGB-D cameras to reconstruct a dense map of the environment. They leverage the depth input to provide accurate local pose estimation and a locally consistent model. However, drift in the pose tracking over time leads to misalignments and artifacts. On the other hand, offline computer vision methods, such as the pipeline that combines structure-from-motion (SfM) and multi-view stereo (MVS), estimate the camera poses by performing batch optimization. These methods achieve global consistency, but suffer from heavy computation loads. We propose a novel approach that integrates both methods to achieve locally and globally consistent reconstruction. First, we estimate poses of keyframes in the offline SfM pipeline to provide strong global constraints at relatively low cost. Afterwards, we compute odometry between frames driven by off-the-shelf SLAM systems with high local accuracy. We fuse the two pose estimations using factor graph optimization to generate accurate camera poses for dense reconstruction. Experiments on real-world and synthetic datasets demonstrate that our approach produces more accurate models comparing to existing dense SLAM systems, while achieving significant speedup with respect to state-of-the-art SfM-MVS pipelines.


Title: A-SLAM: Human in-the-loop Augmented SLAM
Abstract: In this work, we are proposing an intuitive Augmented SLAM method (A-SLAM) that allows the user to interact, in real-time, with a robot running SLAM to correct for pose and map errors. We built an AR application that works on HoloLens and allows the operator to view the robot's map superposed on the physical environment and edit it. Through map editing, the operator can account for errors affecting real environment's representation by adding navigation-forbidden areas to the map in addition to the ability to correct errors affecting the localization. The proposed system allows the operator to edit the robot's pose (based on SLAM request) and can be extended to sending navigation goals to the robot, viewing the planned path to evaluate it before execution, and teleoperating the robot. The proposed solution could be applied on any 2D-based SLAM algorithm and can easily be extended to 3D SLAM techniques. We validated our system through experimentation on pose correction and map editing. Experiments demonstrated that through A-SLAM, SLAM runtime is cut to half, post-processing of maps is totally eliminated, and high quality occupancy grid maps could be achieved with minimal added computational and hardware costs.


Title: Non-parametric Imitation Learning of Robot Motor Skills
Abstract: Unstructured environments impose several challenges when robots are required to perform different tasks and adapt to unseen situations. In this context, a relevant problem arises: how can robots learn to perform various tasks and adapt to different conditions? A potential solution is to endow robots with learning capabilities. In this line, imitation learning emerges as an intuitive way to teach robots different motor skills. This learning approach typically mimics human demonstrations by extracting invariant motion patterns and subsequently applies these patterns to new situations. In this paper, we propose a novel kernel treatment of imitation learning, which endows the robot with imitative and adaptive capabilities. In particular, due to the kernel treatment, the proposed approach is capable of learning human skills associated with high-dimensional inputs. Furthermore, we study a new concept of correlation-adaptive imitation learning, which allows for the adaptation of correlations exhibited in high-dimensional demonstrated skills. Several toy examples and a collaborative task with a real robot are provided to verify the effectiveness of our approach.


Title: Dynamic Stepping on Unknown Obstacles With Upper-Body Compliance and Angular Momentum Damping From the Reaction Null-Space
Abstract: Contact destabilization after an impact that occurs at high-speed, e.g. when a robot steps on an obstacle of unknown height, can be tackled by injecting angular momentum damping for a short time interval immediately after the impact. This is done by making use of the motion from within the reaction null-space (RNS). The angular momentum damping results in an appropriate arm motion that stabilizes the contacts. An impact at high-speed occurs when the stepping time is very short. In this case, conventional controllers cannot handle the reaction stemming from the swing leg dynamics. A general whole-body controller is designed that makes use of the relative angular acceleration control component to inject the angular momentum damping. The proposed control method is robust; it can deal with obstacles of various height and inclination without altering the feedback gains. The controller is fast since iterative optimization is avoided. The performance is examined via a simulated dynamic stepping.


Title: Efficient Humanoid Contact Planning using Learned Centroidal Dynamics Prediction
Abstract: Humanoid robots dynamically navigate an environment by interacting with it via contact wrenches exerted at intermittent contact poses. Therefore, it is important to consider dynamics when planning a contact sequence. Traditional contact planning approaches assume a quasi-static balance criterion to reduce the computational challenges of selecting a contact sequence over a rough terrain. This however limits the applicability of the approach when dynamic motions are required, such as when walking down a steep slope or crossing a wide gap. Recent methods overcome this limitation with the help of efficient mixed integer convex programming solvers capable of synthesizing dynamic contact sequences. Nevertheless, its exponential-time complexity limits its applicability to short time horizon contact sequences within small environments. In this paper, we go beyond current approaches by learning a prediction of the dynamic evolution of the robot centroidal momenta, which can then be used for quickly generating dynamically robust contact sequences for robots with arms and legs using a search-based contact planner. We demonstrate the efficiency and quality of the results of the proposed approach in a set of dynamically challenging scenarios.


Title: Scalable Closed-Form Trajectories for Periodic and Non-Periodic Human-Like Walking
Abstract: We present a new framework to generate human-like lower-limb trajectories in periodic and non-periodic walking. In our method, walking dynamics is encoded in 3LP, a linear simplified model composed of three pendulums to simulate falling, swing, and torso balancing dynamics. To stabilize the motion, we use an optimal time-projecting controller which suggests new footstep locations. On top of gait generation and stabilization in the simplified space, we introduce a kinematic conversion that synthesizes more humanlike trajectories by combining geometric variables of the 3LP model adaptively. Without any tuning, numerical optimization or off-line data, our walking gaits are scalable with respect to body properties and gait parameters. We can change body mass and height, walking direction, speed, frequency, double support time, torso style, ground clearance, and terrain inclinations. We can also simulate constant external dragging forces or momentary perturbations. The proposed framework offers closed-form solutions with simulation speeds orders of magnitude faster than real time. This can be used for video games and animations on portable electronic devices with limited power. It also gives insights for generation of more human-like walking gaits on humanoid robots.


Title: Flying STAR, a Hybrid Crawling and Flying Sprawl Tuned Robot
Abstract: This paper presents Flying STAR (FSTAR) a reconfigurable hybrid flying quadcopter robot. FSTAR is the latest in the family of the STAR robots fitted with a sprawling mechanism and propellers allowing it to both run and fly using the same motors. The combined capabilities of running and flying allows FSTAR to fly over obstacles or run underneath them and move inside pipes. The robot can reduce its width to crawl in confined spaces or underneath obstacles while touching the ground. We first describe the design of the robot and the configuration of the wheels and propellers in the flying and running modes. Then we present the 3D printed prototype of the FSTAR robot which we used for our experiments. We evaluate the energy requirements of the robot and the forces it can generate. The experimental robot can fly like an ordinary quadcopter but can also run on the ground at a speed of up to 2.6 m/s to save energy (see video).


Title: Development of SAM: cable-Suspended Aerial Manipulator*
Abstract: High risk of a collision between rotor blades and the obstacles in a complex environment imposes restrictions on the aerial manipulators. To solve this issue, a novel system cable-Suspended Aerial Manipulator (SAM) is presented in this paper. Instead of attaching a robotic manipulator directly to an aerial carrier, it is mounted on an active platform which is suspended on the carrier by means of a cable. As a result, higher safety can be achieved because the aerial carrier can keep a distance from the obstacles. For self-stabilization, the SAM is equipped with two actuation systems: winches and propulsion units. This paper presents an overview of the SAM including the concept behind, hardware realization, control strategy, and the first experimental results.


Title: The Phoenix Drone: An Open-Source Dual-Rotor Tail-Sitter Platform for Research and Education
Abstract: In this paper, we introduce the Phoenix drone: the first completely open-source tail-sitter micro aerial vehicle (MAV) platform. The vehicle has a highly versatile, dual-rotor design and is engineered to be low-cost and easily extensible/modifiable. Our open-source release includes all of the design documents, software resources, and simulation tools needed to build and fly a high-performance tail-sitter for research and educational purposes.The drone has been developed for precision flight with a high degree of control authority. Our design methodology included extensive testing and characterization of the aerodynamic properties of the vehicle. The platform incorporates many off-the-shelf components and 3D-printed parts, in order to keep the cost down. Nonetheless, the paper includes results from flight trials which demonstrate that the vehicle is capable of very stable hovering and accurate trajectory tracking.Our hope is that the open-source Phoenix reference design will be useful to both researchers and educators. In particular, the details in this paper and the available open-source materials should enable learners to gain an understanding of aerodynamics, flight control, state estimation, software design, and simulation, while experimenting with a unique aerial robot.


Title: Spline Based Curve Path Following of Underactuated Snake Robots
Abstract: This paper investigates the curve path following problem for a class of planar underactuated bio-inspired snake robots. The time-varying line-of-sight (LOS) guidance law and the cubic spline interpolation (CSI) path-planning method are employed. Existing studies focus on straight line path following which only gives a solution for snake robot motion control in relatively simple environments. Considering the snake robot's many degrees of freedom and excellent mobility in terrains, we propose a more applicable solution of curve path following for snake robots on the ground. The improved LOS helps the snake robot to steer aggressively at a sharp turning point. Furthermore, to avoid the sideslip of the snake robot caused by the ground friction change, an integral controller is introduced in the design of the heading reference. Simulations and experiments on an 8-link custom-built snake robot are conducted and the results demonstrate and validate the effectiveness of the proposed curve path following algorithm.


Title: High-Bandwidth Control of Twisted String Actuators
Abstract: Twisted string actuators are an emerging type of transmission systems that may benefit various applications of robotics and mechatronics. However, control of TSAs in applications that require high bandwidth has attracted comparatively little interest from research community, mainly due to complexity of twisted string behavior. This paper proposes a new adaptive control methodology that allows to sufficiently increase bandwidth of TSA-based systems. We reformulate mathematical model of the TSA into a suitable form for online parameter estimation, outline adaptive estimation methods and propose a method to design variable controller gain that rectifies nonlinearities in the system. we present experimental comparison of proposed adaptive control strategies with two conventional tsa control techniques. experimental results demonstrated that the proposed adaptive control architecture with feedforward speed term was nearly insensitive to increase in input signal frequency while reducing position tracking error by 80%. proposed algorithm can be applied in any tsa control system that has input and output signal measurements.


Title: TREE: A Variable Topology, Branching Continuum Robot
Abstract: We describe the design and physical realization of a novel branching continuum robot, aimed at inspection and cleaning operations in hard-to-reach environments at depths greater than human arm lengths. The design, based on a hybrid concentric-tube/tendon actuated continuum trunk core, features two pairs of fully retractable continuum branches. The retractable nature of the branches allows the robot to actively change its topology, allowing it to penetrate narrow openings and expand to adaptively engage complex environmental geometries. We detail and discuss the realization of a physical prototype of the design, and its testing in a simulated glove box environment.


Title: Model Based In Situ Calibration with Temperature compensation of 6 axis Force Torque Sensors
Abstract: It is well known that sensors using strain gauges have a potential dependency on temperature. This creates temperature drift in the measurements of six axis force torque sensors (F/T). The temperature drift can be considerable if an experiment is long or the environmental conditions are different from when the calibration of the sensor was performed. Other in situ methods disregard the effect of temperature on the sensor measurements. Experiments performed using the humanoid robot platform iCub show that the effect of temperature is relevant. The model based in situ calibration of six axis force torque sensors method is extended to perform temperature compensation.


Title: Whole-Body Active Compliance Control for Humanoid Robots with Robot Skin
Abstract: Humanoid robots are expected to interact in human environments, where physical interactions are unavoidable. Therefore, whole-body control methods that include multi-contact interactions are required. The new emerging technologies in touch sensing are fundamental to acquire online and rich information about these physical interactions with the environment. These technologies lead to the design of novel control systems that can profit from the tactile sensor information in an efficient form, thus producing reactive and compliant robots capable of interacting with their environment. In this paper, we present a novel control framework to integrate the multi-modal tactile information of a robot skin with different control strategies, producing dynamic behaviours suitable for Human-Robot Interactions (HRI). The control framework was experimentally evaluated on a full-size humanoid robot covered with more than 1260 skin cells distributed in the whole robot body. The results show that multi-modal tactile information can be fused hierarchically with multiple control strategies, producing active compliance in a position-controlled stiff humanoid robot.


Title: Internal Array Electrodes Improve the Spatial Resolution of Soft Tactile Sensors Based on Electrical Resistance Tomography
Abstract: Robots operating in unstructured environments would benefit from soft whole-body tactile sensors, but implementing such systems typically requires complex electrical wiring to a large number of sensing elements. The reconstruction method called electrical resistance tomography (ERT) has shown promising results (good coverage, manufacturability, and robustness) using electrodes located only along the boundary of the sensing region. However, relatively poor spatial resolution in the sensor's central region is a major drawback of the ERT approach. This paper introduces a new scheme of internal array electrodes to improve spatial resolution. We also systematically derive the optimal pairwise current injection patterns from a mathematical formulation of the ERT system. By highlighting the importance of each electrode pair, this approach enabled us to reduce the number of current injection patterns. Simulation of the standard and proposed sensor designs revealed that the internal array electrodes greatly improve distinguishability in the central region. For validation, a fabric-based soft tactile sensor made of multiple conductive fabrics was developed, including electronics that enable sampling at 200 Hz. During a 225-point localization test conducted without sensor-specific calibration, the constructed sensor showed average localization errors of 2.85 cm ± 1.02 cm. This result is notable because only 16 point electrodes were used to achieve this performance.


Title: Probably Unknown: Deep Inverse Sensor Modelling Radar
Abstract: Radar presents a promising alternative to lidar and vision in autonomous vehicle applications, able to detect objects at long range under a variety of weather conditions. However, distinguishing between occupied and free space from raw radar power returns is challenging due to complex interactions between sensor noise and occlusion. To counter this we propose to learn an Inverse Sensor Model (ISM) converting a raw radar scan to a grid map of occupancy probabilities using a deep neural network. Our network is selfsupervised using partial occupancy labels generated by lidar, allowing a robot to learn about world occupancy from past experience without human supervision. We evaluate our approach on five hours of data recorded in a dynamic urban environment. By accounting for the scene context of each grid cell our model is able to successfully segment the world into occupied and free space, outperforming standard CFAR filtering approaches. Additionally by incorporating heteroscedastic uncertainty into our model formulation, we are able to quantify the variance in the uncertainty throughout the sensor observation. Through this mechanism we are able to successfully identify regions of space that are likely to be occluded.


Title: Uncertainty-Aware Occupancy Map Prediction Using Generative Networks for Robot Navigation
Abstract: Efficient exploration through unknown environments remains a challenging problem for robotic systems. In these situations, the robot's ability to reason about its future motion is often severely limited by sensor field of view (FOV). By contrast, biological systems routinely make decisions by taking into consideration what might exist beyond their FOV based on prior experience. We present an approach for predicting occupancy map representations of sensor data for future robot motions using deep neural networks. We develop a custom loss function used to make accurate prediction while emphasizing physical boundaries. We further study extensions to our neural network architecture to account for uncertainty and ambiguity inherent in mapping and exploration. Finally, we demonstrate a combined map prediction and information-theoretic exploration strategy using the variance of the generated hypotheses as the heuristic for efficient exploration of unknown environments.


Title: Empty Cities: Image Inpainting for a Dynamic-Object-Invariant Space
Abstract: In this paper we present an end-to-end deep learning framework to turn images that show dynamic content, such as vehicles or pedestrians, into realistic static frames. This objective encounters two main challenges: detecting all the dynamic objects, and inpainting the static occluded background with plausible imagery. The former challenge is addressed by the use of a convolutional network that learns a multiclass semantic segmentation of the image. The second problem is approached with a conditional generative adversarial model that, taking as input the original dynamic image and its dynamic/static binary mask, is capable of generating the final static image. These generated images can be used for applications such as augmented reality or vision-based robot localization purposes. To validate our approach, we show both qualitative and quantitative comparisons against other state-of-the-art inpainting methods by removing the dynamic objects and hallucinating the static structure behind them. Furthermore, to demonstrate the potential of our results, we carry out pilot experiments that show the benefits of our proposal for visual place recognition.


Title: Fast Instance and Semantic Segmentation Exploiting Local Connectivity, Metric Learning, and One-Shot Detection for Robotics
Abstract: Semantic scene understanding is important for autonomous robots that aim to navigate dynamic environments, manipulate objects, or interact with humans in a natural way. In this paper, we address the problem of jointly performing semantic segmentation as well as instance segmentation in an online fashion, so that autonomous robots can use this information on-the-go and without sacrificing accuracy. We achieve this by exploiting a local connectivity prior of objects in the real world and a multi-task convolutional neural network architecture. The network identifies the individual object instances and their classes without region proposals or pre-segmentation of the images into individual classes. We implemented and thoroughly evaluated our approach, and our experiments suggest that our method can be used to accurately segment instance masks of objects and identify their class in an online fashion.


Title: The Robust Canadian Traveler Problem Applied to Robot Routing
Abstract: The stochastic Canadian Traveler Problem (CTP), which finds application in robot route selection under uncertainty, aims to find the traversal policy with the minimum expected cost. This paper extends the CTP to what we call the Robust Canadian Traveler Problem (RCTP), in which the variability of the policy cost is also part of the evaluation criteria. An optimal (offline) algorithm and an approximate (online) algorithm are then proposed to compute the policy that has a good balance of both mean and variation of the traversal cost. The benefit of the proposed framework versus traditional approaches is shown by doing simulations in randomly generated worlds as well as on a map of 5 km of paths built from robot field trials. Specifically, the RCTP framework is able to search for sub-optimal policy alternatives with significantly lower worst-case cost and less computational time compared to the optimal policy, but with little sacrifice on the expected cost.


Title: Dynamic Channel: A Planning Framework for Crowd Navigation
Abstract: Real-time navigation in dense human environments is a challenging problem in robotics. Most existing path planners fail to account for the dynamics of pedestrians because introducing time as an additional dimension in search space is computationally prohibitive. Alternatively, most local motion planners only address imminent collision avoidance and fail to offer long-term optimality. In this work, we present an approach, called Dynamic Channels, to solve this global to local quandary. Our method combines the high-level topological path planning with low-level motion planning into a complete pipeline. By formulating the path planning problem as graph-searching in the triangulation space, our planner is able to explicitly reason about the obstacle dynamics and capture the environmental change efficiently. We evaluate efficiency and performance of our approach on public pedestrian datasets and compare it to a state-of-the-art planning algorithm for dynamic obstacle avoidance. Completeness proofs are provided in the supplement at http://caochao.me/files/proof.pdf. An extended version of the paper is available on arXiv.


Title: Composition of Local Potential Functions with Reflection
Abstract: This paper suggests reflections can be practically useful if they are included in planning for collision capable robot platforms. By modifying a proven strategy for navigation with reflections we maintain global convergence results and reach the goal in less time. An algorithm for identifying reflection surfaces for a given cell decomposition is reported. Baseline and reflected scenarios are compared for two different cell decompositions. Omnipuck, a reflection capable omnidirectional robot meant to store and release impact energy, is used to obtain experimental results and draw conclusions for future work.


Title: A Novel Robotic System for Finishing of Freeform Surfaces
Abstract: Surface finishing of freeform surfaces is predominately a manual operation that requires a considerable amount of operator skill; automation of this process has many benefits, including consistent surface quality, preventing hazardous exposure to particulate, etc. A novel robotic surface finishing system, consisting of a robot and an end-effector that includes a force sensor, finishing tool, and proximity laser sensor, is developed in this paper to automate the surface finishing process. The laser sensor is treated as an additional link, and based on it a novel perception system is developed for real-time scanning of the surface that provides the surface profile mesh and the corresponding normal vectors which can be used directly by the robot closed-loop control system for pose tracking. A unique feature of the perception system is that the geometry of the surface profile and normal vectors are all obtained in real-time in the robot base coordinate system, thus eliminating issues such as precise registration of the work piece in the fixture and its location with respect to the robot base coordinates. An impedance-type closed-loop control algorithm is developed for pose tracking. The proposed system and control algorithm are employed to conduct surface finishing experiments on wooden surfaces. A representative sample of the results and measurement images of surface finish are provided to illustrate the capabilities of the robotic surface finishing system. A video of the system in operation is also provided.


Title: Context-Dependent Compensation Scheme to Reduce Trajectory Execution Errors for Industrial Manipulators
Abstract: Currently, automatically generated trajectories cannot be directly used on tasks that require high execution accuracies due to errors accused by inaccuracies in the robot model, actuator errors, and controller limitations. These trajectories often need manual refinement. This is not economically viable on low production volume applications. Unfortunately, execution errors are dependent on the nature of the trajectory and end-effector loads, and therefore devising a general purpose automated compensation scheme for reducing trajectory errors is not possible. This paper presents a method for analyzing the given trajectory, executing an exploratory physical run for a small portion of the given trajectory, and learning a compensation scheme based on the measured data. The learned compensation scheme is context-dependent and can be used to reduce the execution error. We have demonstrated the feasibility of this approach by conducting physical experiments.


Title: Identifying Feasible Workpiece Placement with Respect to Redundant Manipulator for Complex Manufacturing Tasks
Abstract: Successfully completing a complex manufacturing task requires finding a feasible placement of the workpiece in the robot workspace. The workpiece placement should be such that the task surfaces on the workpiece are reachable by the robot, the robot can apply the required forces, and the end-effector/tool can move with the desired velocity. This paper formulates the problem of identifying a feasible placement as a non-linear optimization problem over the constraint violation functions. This is a computationally challenging problem. We show that this problem can be solved by successively searching for the solution by incrementally applying different constraints. We demonstrate the feasibility of our approach using several complex workpieces.


Title: Geometric Search-Based Inverse Kinematics of 7-DoF Redundant Manipulator with Multiple Joint Offsets
Abstract: We propose a geometric method to solve inverse kinematics (IK) problems of 7-DoF manipulators with joint offsets at shoulder, elbow, and wrist. Traditionally, inverse position kinematics for redundant manipulators are solved by using an iterative method based on the pseudo-inverse of the manipulator Jacobian. This provides a single solution among the infinitely many possible solutions for the IK problem of redundant manipulators. There are no closed-form IK solutions for redundant manipulators with multiple joint offsets. Using our method we can compute multiple IK solutions using two-parameter search by exploiting geometry of the structure of a redundant manipulator. Our proposed IK algorithm can handle multiple joint offsets and is mathematically simple to implement in a few lines of code. We apply our algorithm to compute IK solutions for 7-DoF redundant Baxter robot (that has joint offsets at shoulder, wrist, and elbow joints) for end-effector configurations where existing geometry-based IK solvers fail to find solutions. We also demonstrate the use of our algorithm in an application where we want to compute an IK solution (among the infinitely many possible solutions) that has minimum error bound in end-effector position, in the presence of random joint actuation and sensing uncertainties.


Title: Pedestrian Dominance Modeling for Socially-Aware Robot Navigation
Abstract: We present a Pedestrian Dominance Model (PDM) to identify the dominance characteristics of pedestrians for robot navigation. Through a perception study on a simulated dataset of pedestrians, PDM models the perceived dominance levels of pedestrians with varying motion behaviors corresponding to trajectory, speed, and personal space. At runtime, we use PDM to identify the dominance levels of pedestrians to facilitate socially-aware navigation for the robots. PDM can predict dominance levels from trajectories with ~85% accuracy. Prior studies in psychology literature indicate that when interacting with humans, people are more comfortable around people that exhibit complementary movement behaviors. Our algorithm leverages this by enabling the robots to exhibit complementing responses to pedestrian dominance. We also present an application of PDM for generating dominance-based collision-avoidance behaviors in the navigation of autonomous vehicles among pedestrians. We demonstrate the benefits of our algorithm for robots navigating among tens of pedestrians in simulated environments.


Title: Towards the Design of Robotic Drivers for Full-Scale Self-Driving Racing Cars
Abstract: Autonomous vehicles are undergoing a rapid development thanks to advances in perception, planning and control methods and technologies achieved in the last two decades. Moreover, the lowering costs of sensors and computing platforms are attracting industrial entities, empowering the integration and development of innovative solutions for civilian use. Still, the development of autonomous racing cars has been confined mainly to laboratory studies and small to middle scale vehicles. This paper tackles the development of a planning and control framework for an electric full scale autonomous racing car, which is an absolute novelty in the literature, upon which we report our preliminary experiments and perspectives on future work. Our system leverages real time Nonlinear Model Predictive Control to track a pre-planned racing line. We describe the whole control system architecture including the mapping and localization methods employed.


Title: Learning ad-hoc Compact Representations from Salient Landmarks for Visual Place Recognition in Underwater Environments
Abstract: In this paper, we propose an approach to learn compact representations from salient landmarks detected by a visual attention algorithm to recognize previously visited places in underwater environments. Instead of using hand-crafted local descriptors as it has been typically done in visual place recognition, we use a convolutional autoencoder to obtain an ad hoc descriptor generator from salient landmarks. The main advantage of using an autoencoder is that it can learn in an unsupervised manner directly from the salient landmarks. In addition, we show that it is possible to do the training with less than 100,000 examples instead of several hundreds of thousands or even millions of labeled examples as in other convolutional architectures. The trained convolutional autoencoder is used to obtain descriptors for salient landmarks that are later utilized in a voting scheme to calculate similarity between images with the objective of finding if a place has already been visited. The proposed method has obtained good results compared to SeqSLAM and FAB-MAP in different datasets obtained from robotic explorations of coral reefs in real life conditions. Moreover, when the visual attention algorithm is used, fewer features are required to get a good performance in terms of precision and recall compared when using the SURF method to extract visual features.


Title: Finding divers with SCUBANet
Abstract: Robot-diver communication underwater is complicated by the attenuation of RF signals, the complexities of the environment in terms of deploying interaction devices, and issues related to the cognitive loading of human operators. Humans operating underwater have developed a simple yet effective strategy for diver-diver communication based on the visual recognition of gestures. Can a similar approach be effective for diver-robot communication? Here we present experiments with SCUBANet, an underwater detection dataset of body parts associated with diver-robot communication. Given the nature of standard diver gestures, here we concentrate on diver recognition and in particular on diver body-head-hand localization and examine the feasibility of using a CNN-based approach to address this problem. Such data-driven approaches typically require an appropriately annotated dataset. The SCUBANet dataset contains images of object classes commonly encountered during human-robot communication underwater. Object classes are labeled using per-instance bounding boxes. Annotations were created through crowd sourcing via a web-based interface to ease deployment. We provide baseline performance on diver and diver component recognition and localization using transfer learning on three widely available pre-trained models.


Title: Robotic Detection of Marine Litter Using Deep Visual Detection Models
Abstract: Trash deposits in aquatic environments have a destructive effect on marine ecosystems and pose a long-term economic and environmental threat. Autonomous underwater vehicles (AUVs) could very well contribute to the solution of this problem by finding and eventually removing trash. This paper evaluates a number of deep-learning algorithms performing the task of visually detecting trash in realistic underwater environments, with the eventual goal of exploration, mapping, and extraction of such debris by using AUVs. A large and publicly-available dataset of actual debris in open-water locations is annotated for training a number of convolutional neural network architectures for object detection. The trained networks are then evaluated on a set of images from other portions of that dataset, providing insight into approaches for developing the detection capabilities of an AUV for underwater trash removal. In addition, the evaluation is performed on three different platforms of varying processing power, which serves to assess these algorithms' fitness for real-time applications.


Title: Uncertainty-Aware Path Planning for Navigation on Road Networks Using Augmented MDPs
Abstract: Although most robots use probabilistic algorithms to solve state estimation problems, path planning is often performed without considering the uncertainty about the robot's position. Uncertainty, however, matters in planning, but considering it often leads to computationally expensive algorithms. In this paper, we investigate the problem of path planning considering the uncertainty in the robot's belief about the world, in its perceptions and in its action execution. We propose the use of an uncertainty-augmented Markov Decision Process to approximate the underlying Partially Observable Markov Decision Process, and we employ a localization prior to estimate how the belief about the robot's position propagates through the environment. This yields to a planning approach that generates navigation policies able to make decisions according to the degree of uncertainty while being computationally tractable. We implemented our approach and thoroughly evaluated it on different navigation problems. Our experiments suggest that we are able to compute policies that are more effective than approaches that ignore the uncertainty, and that also outperform policies that always take the safest actions.


Title: Real-time Model Based Path Planning for Wheeled Vehicles
Abstract: This work presents a model based traversability analysis method which employs a detailed vehicle model to perform real-time path planning in complex environments. The vehicle model represents the vehicle's wheels and chassis, allowing it to accurately predict the vehicles 3D pose, detailed contact information for each wheel and the occurrence of a chassis collision given a 2D pose on an elevation map. These predictions are weighted, depending on the safety requirements of the vehicle, to provide a scoring function for an A*-like search strategy. The proposed method is designed to run at frame rates of 30Hz on data from a RGB-D sensor to provide reactive planning of safe paths. For evaluation, two wheeled mobile robots in different simulated and real world environment setups were tested to show the reliability and performance of the proposed method.


Title: Integrity Risk-Based Model Predictive Control for Mobile Robots
Abstract: This paper presents a Model Predictive Controller (MPC) that uses navigation integrity risk as a constraint. Navigation integrity risk accounts for the presence of faults in localization sensors and algorithms, an increasingly important consideration as the number of robots operating in life and mission-critical situations is expected to increase dramatically in near future (e.g. a potential influx of self-driving cars). Specifically, the work uses a local nearest neighbor integrity risk evaluation methodology that accounts for data association faults as a constraint in order to guarantee localization safety over a receding horizon. Moreover, state and control-input constraints have also been enforced in this work. The proposed MPC design is tested using real-world mapped environments, showing that a robot is capable of maintaining a predefined minimum level of localization safety while operating in an urban environment.


Title: Deep Local Trajectory Replanning and Control for Robot Navigation
Abstract: We present a navigation system that combines ideas from hierarchical planning and machine learning. The system uses a traditional global planner to compute optimal paths towards a goal, and a deep local trajectory planner and velocity controller to compute motion commands. The latter components of the system adjust the behavior of the robot through attention mechanisms such that it moves towards the goal, avoids obstacles, and respects the space of nearby pedestrians. Both the structure of the proposed deep models and the use of attention mechanisms make the system's execution interpretable. Our simulation experiments suggest that the proposed architecture outperforms baselines that try to map global plan information and sensor data directly to velocity commands. In comparison to a hand-designed traditional navigation system, the proposed approach showed more consistent performance.


Title: Learning from Transferable Mechanics Models: Generalizable Online Mode Detection in Underactuated Dexterous Manipulation
Abstract: In this work, we investigate a mechanics-inspired framework for describing fingertip-based planar within-hand manipulation with an underactuated robotic gripper. In particular, this framework leverages fundamental mechanics properties of the hand-object system, including basic terms such as local contact curvature as well as more complex features including the grasp matrix and manipulability metrics. These are extracted using a simple visual approach and then in real-time used for predicting planar manipulation modes: namely rolling, dropped, stuck, and sliding. Given a desired cartesian motion for the object, a supervised learning model predicts these four manipulation modes before they occur, allowing us to either avoid or trigger these different behaviors. Since we utilize strictly fundamental properties of the grasp matrix, finger Jacobians, and contact curvatures, we are able to demonstrate prediction transferability between different grippers using our original classifier. In particular, a Random Forests classifier trained on one gripper successfully predicts manipulation modes for grippers with different fingers with 84% accuracy, compared to just 56% from an approach in previous work. Overall, we find that the features designed in our approach better describes fingertip manipulation when precise gripper models are not available.


Title: CARA system Architecture - A Click and Assemble Robotic Assembly System
Abstract: Future robotic assembly systems will allow product designers to upload their assembled product models remotely such that they can be assembled autonomously. In this work we present the architecture for a Click and Assemble Robotic Assembly (CARA) system. This architecture takes an assembly file uploaded by the user through a web interface as the only input. It then performs all the necessary planning before executing the assembly. To the authors' knowledge, this is the first time that all of the required components from previous advances in robotic assembly have been brought together, with all interconnecting challenges solved, into a complete working system for physical, real world assembly tasks. To demonstrate the implemented architecture capabilities, a real industrial product with tight tolerances was assembled from its CAD file only, illustrating the end to end robotic assembly premise in a real world setting.


Title: Tool Macgyvering: Tool Construction Using Geometric Reasoning
Abstract: MacGyvering is defined as creating or repairing something in an inventive or improvised way by utilizing objects that are available at hand. In this paper, we explore a subset of Macgyvering problems involving tool construction, i.e., creating tools from parts available in the environment. We formalize the overall problem domain of tool Macgyvering, introducing three levels of complexity for tool construction and substitution problems, and presenting a novel computational framework aimed at solving one level of the tool Macgyvering problem, specifically contributing a novel algorithm for tool construction based on geometric reasoning. We validate our approach by constructing three tools using a 7-DOF robot arm.


Title: A Framework for Robot Manipulation: Skill Formalism, Meta Learning and Adaptive Control
Abstract: In this paper we introduce a novel framework for expressing and learning force-sensitive robot manipulation skills. It is based on a formalism that extends our previous work on adaptive impedance control with meta parameter learning and compatible skill specifications. This way the system is also able to make use of abstract expert knowledge by incorporating process descriptions and quality evaluation metrics. We evaluate various state-of-the-art schemes for meta parameter learning and experimentally compare selected ones. Our results clearly indicate that the combination of our adaptive impedance controller with a carefully defined skill formalism significantly reduces the complexity of manipulation tasks even for learning peg-in-hole with submillimeter industrial tolerances. Overall, the considered system is able to learn variations of this skill in under 20 minutes. In fact, experimentally the system was able to perform the learned tasks without visual feedback faster than humans, leading to the first learning-based solution of complex assembly at such real-world performance.


Title: Open-Loop Collective Assembly Using a Light Field to Power and Control a Phototaxic Mini-Robot Swarm
Abstract: We propose a novel scheme that jointly addresses the problems of powering and coordinating a population of mini-robots for collective construction. In our setting, a population of simple mobile robots must push blocks into desired polygonal shapes. Each robot performs only simple phototaxis. Coordination is purely open-loop: a global light field guides and powers the robots. We demonstrate this concept in simulation and explore a series of dynamic light field design strategies that robustly result in assembled shapes including nonconvex polygons.


Title: A Variational Observation Model of 3D Object for Probabilistic Semantic SLAM
Abstract: We present a Bayesian object observation model for complete probabilistic semantic SLAM. Recent studies on object detection and feature extraction have become important for scene understanding and 3D mapping. However, 3D shape of the object is too complex to formulate the probabilistic observation model; therefore, performing the Bayesian inference of the object-oriented features as well as their pose is less considered. Besides, when the robot equipped with an RGB mono camera only observes the projected single view of an object, a significant amount of the 3D shape information is abandoned. Due to these limitations, semantic SLAM and viewpoint-independent loop closure using volumetric 3D object shape is challenging. In order to enable the complete formulation of probabilistic semantic SLAM, we approximate the observation model of a 3D object with a tractable distribution. We also estimate the variational likelihood from the 2D image of the object to exploit its observed single view. In order to evaluate the proposed method, we perform pose and feature estimation, and demonstrate that the automatic loop closure works seamlessly without additional loop detector in various environments.


Title: Anytime Stereo Image Depth Estimation on Mobile Devices
Abstract: Many applications of stereo depth estimation in robotics require the generation of accurate disparity maps in real time under significant computational constraints. Current state-of-the-art algorithms force a choice between either generating accurate mappings at a slow pace, or quickly generating inaccurate ones, and additionally these methods typically require far too many parameters to be usable on power- or memory-constrained devices. Motivated by these shortcomings, we propose a novel approach for disparity prediction in the anytime setting. In contrast to prior work, our end-to-end learned approach can trade off computation and accuracy at inference time. Depth estimation is performed in stages, during which the model can be queried at any time to output its current best estimate. Our final model can process 1242×375 resolution images within a range of 10-35 FPS on an NVIDIA Jetson TX2 module with only marginal increases in error - using two orders of magnitude fewer parameters than the most competitive baseline. The source code is available at https://github.com/mileyan/AnyNet.


Title: Improved Generalization of Heading Direction Estimation for Aerial Filming Using Semi-Supervised Regression
Abstract: In the task of Autonomous aerial filming of a moving actor (e.g. a person or a vehicle), it is crucial to have a good heading direction estimation for the actor from the visual input. However, the models obtained in other similar tasks, such as pedestrian collision risk analysis and human-robot interaction, are very difficult to generalize to the aerial filming task, because of the difference in data distributions. Towards improving generalization with less amount of labeled data, this paper presents a semi-supervised algorithm for heading direction estimation problem. We utilize temporal continuity as the unsupervised signal to regularize the model and achieve better generalization ability. This semi-supervised algorithm is applied to both training and testing phases, which increases the testing performance by a large margin. We show that by leveraging unlabeled sequences, the amount of labeled data required can be significantly reduced. We also discuss several important details on improving the performance by balancing labeled and unlabeled loss, and making good combinations. Experimental results show that our approach robustly outputs the heading direction for different types of actor. The aesthetic value of the video is also improved in the aerial filming task.


Title: Graduated Fidelity Lattices for Motion Planning under Uncertainty
Abstract: In this work we present a state lattice based approach for motion planning in mobile robotics. Sensing and motion uncertainty are managed at planning time to obtain safe and optimal paths. To do this reliably, our approach estimates the probability of collision taking into account the robot shape and the uncertainty in heading. We also introduce a novel graduated fidelity approach and a multi-resolution heuristic which adapt to the obstacles in the map, improving the planning efficiency while maintaining its performance. Results for different environments, shapes and motion models are reported, including experiments with real robots.


Title: On the Impact of Uncertainty for Path Planning
Abstract: We consider the problem of planning paths on graphs with some edges whose traversability is uncertain; for each uncertain edge, we are given a probability of being traversable (e.g., by a learned classifier). We categorize different interpretations of the problem that are meaningful for mobile robots navigating partially-known environments, each of which yields a different formalization; we then focus on the case in which the true traversability of an edge is revealed only when the agent visits one of its endpoints (Canadian Traveller Problem). In this context, we design a large simulation campaign on synthetic and real-world maps to study the impact of two different factors: the planning strategy, and the amount of uncertainty (which could depend on the quality of the classifier producing traversability estimates).


Title: Localization with Sliding Window Factor Graphs on Third-Party Maps for Automated Driving
Abstract: Localizing a vehicle in a map is essential for automated driving and various other robotic applications. This paper addresses the problem of vehicle localization in urban environments. Our approach performs a graph-based sliding window optimization over a set of recent landmark and odometry measurements for fast and accurate vehicle localization on third-party maps. Our work incorporates landmark priors from third-party maps into the estimation problem and shows how to exploit the sliding window formulation for revising data associations. We describe how to construct our factor graph and derive its necessary factors to model the information from the map as a prior over the landmark detections. We implemented our approach on an automated car and thoroughly tested it on real-world data. The experiments suggest that the approach provides highly accurate pose estimates, is fast enough for automated driving applications, and outperforms localization using particle filters.


Title: Night-to-Day Image Translation for Retrieval-based Localization
Abstract: Visual localization is a key step in many robotics pipelines, allowing the robot to (approximately) determine its position and orientation in the world. An efficient and scalable approach to visual localization is to use image retrieval techniques. These approaches identify the image most similar to a query photo in a database of geo-tagged images and approximate the query's pose via the pose of the retrieved database image. However, image retrieval across drastically different illumination conditions, e.g. day and night, is still a problem with unsatisfactory results, even in this age of powerful neural models. This is due to a lack of a suitably diverse dataset with true correspondences to perform end-to-end learning. A recent class of neural models allows for realistic translation of images among visual domains with relatively little training data and, most importantly, without ground-truth pairings.In this paper, we explore the task of accurately localizing images captured from two traversals of the same area in both day and night. We propose ToDayGAN - a modified image-translation model to alter nighttime driving images to a more useful daytime representation. We then compare the daytime and translated night images to obtain a pose estimate for the night image using the known 6-DOF position of the closest day image. Our approach improves localization performance by over 250% compared the current state-of-the-art, in the context of standard metrics in multiple categories.


Title: Beyond Point Clouds: Fisher Information Field for Active Visual Localization
Abstract: For mobile robots to localize robustly, actively considering the perception requirement at the planning stage is essential. In this paper, we propose a novel representation for active visual localization. By formulating the Fisher information and sensor visibility carefully, we are able to summarize the localization information into a discrete grid, namely the Fisher information field. The information for arbitrary poses can then be computed from the field in constant time, without the need of costly iterating all the 3D landmarks. Experimental results on simulated and real-world data show the great potential of our method in efficient active localization and perception-aware planning. To benefit related research, we release our implementation of the information field to the public.


Title: Deep Reinforcement Learning of Navigation in a Complex and Crowded Environment with a Limited Field of View
Abstract: Mobile robots are required to navigate freely in a complex and crowded environment in order to provide services to humans. For this navigation ability, deep reinforcement learning (DRL)-based methods are gaining increasing attentions. However, existing DRL methods require a wide field of view (FOV), which imposes the usage of high-cost lidar devices. In this paper, we explore the possibility of replacing expensive lidar devices with affordable depth cameras which have a limited FOV. First, we analyze the effect of a limited field of view in the DRL agents. Second, we propose a LSTM agent with Local-Map Critic (LSTM-LMC), which is a novel DRL method to learn efficient navigation in a complex environment with a limited FOV. Lastly, we introduce the dynamics randomization technique to improve the robustness of the DRL agents in the real world. We found that our method with a limited FOV can outperform the methods having a wide FOV but limited memory. We provide the empirical evidence that our method learns to implicitly model the surrounding environment and dynamics of other agents. We also show that a robot with a single depth camera can navigate through a complex real-world environment using our method.


Title: Sim-to-Real Transfer Learning using Robustified Controllers in Robotic Tasks involving Complex Dynamics
Abstract: Learning robot tasks or controllers using deep reinforcement learning has been proven effective in simulations. Learning in simulation has several advantages. For example, one can fully control the simulated environment, including halting motions while performing computations. Another advantage when robots are involved, is that the amount of time a robot is occupied learning a task-rather than being productive-can be reduced by transferring the learned task to the real robot. Transfer learning requires some amount of fine-tuning on the real robot. For tasks which involve complex (non-linear) dynamics, the fine-tuning itself may take a substantial amount of time. In order to reduce the amount of fine-tuning we propose to learn robustified controllers in simulation. Robustified controllers are learned by exploiting the ability to change simulation parameters (both appearance and dynamics) for successive training episodes. An additional benefit for this approach is that it alleviates the precise determination of physics parameters for the simulator, which is a non-trivial task. We demonstrate our proposed approach on a real setup in which a robot aims to solve a maze game, which involves complex dynamics due to static friction and potentially large accelerations. We show that the amount of fine-tuning in transfer learning for a robustified controller is substantially reduced compared to a non-robustified controller.


Title: Generalization through Simulation: Integrating Simulated and Real Data into Deep Reinforcement Learning for Vision-Based Autonomous Flight
Abstract: Deep reinforcement learning provides a promising approach for vision-based control of real-world robots. However, the generalization of such models depends critically on the quantity and variety of data available for training. This data can be difficult to obtain for some types of robotic systems, such as fragile, small-scale quadrotors. Simulated rendering and physics can provide for much larger datasets, but such data is inherently of lower quality: many of the phenomena that make the real-world autonomous flight problem challenging, such as complex physics and air currents, are modeled poorly or not at all, and the systematic differences between simulation and the real world are typically impossible to eliminate. In this work, we investigate how data from both simulation and the real world can be combined in a hybrid deep reinforcement learning algorithm. Our method uses real-world data to learn about the dynamics of the system, and simulated data to learn a generalizable perception system that can enable the robot to avoid collisions using only a monocular camera. We demonstrate our approach on a real-world nano aerial vehicle collision avoidance task, showing that with only an hour of real-world data, the quadrotor can avoid collisions in new environments with various lighting conditions and geometry. Code, instructions for building the aerial vehicles, and videos of the experiments can be found at github.com/gkahn13/GtS.


Title: Crowd-Robot Interaction: Crowd-Aware Robot Navigation With Attention-Based Deep Reinforcement Learning
Abstract: Mobility in an effective and socially-compliant manner is an essential yet challenging task for robots operating in crowded spaces. Recent works have shown the power of deep reinforcement learning techniques to learn socially cooperative policies. However, their cooperation ability deteriorates as the crowd grows since they typically relax the problem as a one-way Human-Robot interaction problem. In this work, we want to go beyond first-order Human-Robot interaction and more explicitly model Crowd-Robot Interaction (CRI). We propose to (i) rethink pairwise interactions with a self-attention mechanism, and (ii) jointly model Human-Robot as well as Human-Human interactions in the deep reinforcement learning framework. Our model captures the Human-Human interactions occurring in dense crowds that indirectly affects the robot's anticipation capability. Our proposed attentive pooling mechanism learns the collective importance of neighboring humans with respect to their future states. Various experiments demonstrate that our model can anticipate human dynamics and navigate in crowds with time efficiency, outperforming state-of-the-art methods.


Title: Residual Reinforcement Learning for Robot Control
Abstract: Conventional feedback control methods can solve various types of robot control problems very efficiently by capturing the structure with explicit models, such as rigid body equations of motion. However, many control problems in modern manufacturing deal with contacts and friction, which are difficult to capture with first-order physical modeling. Hence, applying control design methodologies to these kinds of problems often results in brittle and inaccurate controllers, which have to be manually tuned for deployment. Reinforcement learning (RL) methods have been demonstrated to be capable of learning continuous robot controllers from interactions with the environment, even for problems that include friction and contacts. In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals. We demonstrate our approach by training an agent to successfully perform a real-world block assembly task involving contacts and unstable objects.


Title: Formal Policy Learning from Demonstrations for Reachability Properties
Abstract: We consider the problem of learning structured, closed-loop policies (feedback laws) from demonstrations in order to control under-actuated robotic systems, so that formal behavioral specifications such as reaching a target set of states are satisfied. Our approach uses a “counterexample-guided” iterative loop that involves the interaction between a policy learner, a demonstrator and a verifier. The learner is responsible for querying the demonstrator in order to obtain the training data to guide the construction of a policy candidate. This candidate is analyzed by the verifier and either accepted as correct, or rejected with a counterexample. In the latter case, the counterexample is used to update the training data and further refine the policy.The approach is instantiated using receding horizon model-predictive controllers (MPCs) as demonstrators. Rather than using regression to fit a policy to the demonstrator actions, we extend the MPC formulation with the gradient of the cost-to-go function evaluated at sample states in order to constrain the set of policies compatible with the behavior of the demonstrator. We demonstrate the successful application of the resulting policy learning schemes on two case studies and we show how simple, formally-verified policies can be inferred starting from a complex and unverified nonlinear MPC implementations. As a further benefit, the policies are many orders of magnitude faster to implement when compared to the original MPCs.


Title: Formalized Task Characterization for Human-Robot Autonomy Allocation
Abstract: Humans and robots team together to perform tasks in various domains. Some tasks are easier to perform than others, but little work focuses on discovering the underlying mechanisms that affect perceived difficulty and task performance. To fill this gap, we propose a formalized approach to task characterization for human-robot teams using Taguchi design of experiments and conjoint analysis. With this, we conduct a 20 person study where participants operate a 6 degree of freedom robotic arm to perform manipulations defined by 6 kinematic features. We find that rotational features of a task contribute significantly more to decreased performance and increased difficulty than translational features. The participants also perform the activities with autonomy assistance. The data shows a reduction in the effect of these features on performance and difficulty when assistance is active. Furthermore, we examine when to trigger assistance based on thresholds set from outlier detection. The analysis indicates that rotational features and features leading to kinematic singularities are useful for triggering assistance.


Title: DoS-Resilient Multi-Robot Temporal Logic Motion Planning
Abstract: We propose an efficient multi-robot motion planning algorithm for missions captured by linear temporal logic (LTL) specifications, in the presence of bounded disturbances and denial-of-service (DoS) attacks against the communication between robots and base stations. Given an LTL formula Ψ, our goal is to construct robot trajectories, and associated control strategies, to satisfy Ψ and continuously establish communication paths between robots and base stations despite the DoS attacks and the disturbances on the robot states. Our approach combines and extends results from robust control and efficient motion planning via satisfiability modulo convex programming (SMC). We first compute a feedback controller that rejects the disturbance together with a perturbation of the DoS-free workspace that accounts for the worst-case disturbance scenario. On the perturbed workspace, we formulate the planning problem as a feasibility problem over Boolean and convex constraints, respectively capturing the DoS-resilient mission constraints and the constraints on the nominal, disturbance-free, robot dynamics. Numerical results show the effectiveness of our algorithm in providing DoS-resilient plans that are robust to disturbances and support the execution of complex missions.


Title: Task-Based Design of Ad-hoc Modular Manipulators
Abstract: The great promise of modular robots is the ability to create on demand robots; however, choosing the “right” design based on a task is still a challenging problem. In this paper, we present an approach to automatically synthesize both the design and control for modular robots from a task description. In particular, we focus on manipulators composed of one degree-of-freedom (DoF) modules. Our approach is able to handle partially infeasible tasks by either identifying the infeasible part and finding a design that satisfies the feasible part or searching for multiple designs that together satisfy the entire task. We compare our approach to a baseline genetic algorithm in a series of increasingly complex environments.


Title: 3D Surface Reconstruction Using A Two-Step Stereo Matching Method Assisted with Five Projected Patterns
Abstract: Three-dimensional vision plays an important role in robotics. In this paper, we present a 3D surface reconstruction scheme based on combination of stereo matching and pattern projection. A two-step matching scheme is proposed to establish reliable correspondence between stereo images with high computation efficiency and accuracy. The first step (coarse matching) can quickly find the correlation candidates, and the second step (precise matching) is responsible for determining the most precise correspondence within the candidates. Two phase maps serve as codewords and are utilized in the two-step stereo matching, respectively. The phase maps are derived from phase-shifting patterns to provide robustness to the background noises. Only five patterns are required, which reduces the image acquisition time. Moreover, the precision is further enhanced by applying a correspondence refinement algorithm. The precision and accuracy are validated by experiments on standard objects. Furthermore, various experiments are conducted to verify the capability of the proposed method, which includes the complex object reconstruction, the high-resolution reconstruction, and the occlusion avoidance. The real-time experimental results are also provided.


Title: FastDepth: Fast Monocular Depth Estimation on Embedded Systems
Abstract: Depth sensing is a critical function for robotic tasks such as localization, mapping and obstacle detection. There has been a significant and growing interest in depth estimation from a single RGB image, due to the relatively low cost and size of monocular cameras. However, state-of-the-art single-view depth estimation algorithms are based on fairly complex deep neural networks that are too slow for real-time inference on an embedded platform, for instance, mounted on a micro aerial vehicle. In this paper, we address the problem of fast depth estimation on embedded systems. We propose an efficient and lightweight encoder-decoder network architecture and apply network pruning to further reduce computational complexity and latency. In particular, we focus on the design of a low-latency decoder. Our methodology demonstrates that it is possible to achieve similar accuracy as prior work on depth estimation, but at inference speeds that are an order of magnitude faster. Our proposed network, FastDepth, runs at 178 fps on an NVIDIA Jetson TX2 GPU and at 27 fps when using only the TX2 CPU, with active power consumption under 10 W. FastDepth achieves close to state-of-the-art accuracy on the NYU Depth v2 dataset. To the best of the authors' knowledge, this paper demonstrates real-time monocular depth estimation using a deep neural network with the lowest latency and highest throughput on an embedded platform that can be carried by a micro aerial vehicle.


Title: Sliding Mode Momentum Observers for Estimation of External Torques and Joint Acceleration
Abstract: Interactions between robots and their environment give rise to external wrenches acting on the robot structure. The estimation of the resulting torques in the joints is fundamental in human-robot interaction to detect/identify collisions and perform suitable reaction strategies. Other applications may require to use the estimation for compensating the effects of the external torques within the control loop. The well-established momentum observer, which relies on proprioceptive sensors only, is usually used for these purposes. In this work, the momentum dynamics is used to derive new observers. While the classic momentum observer provides a first-order filtered version of the external torques, here a (theoretically) finite-time convergence is achieved. Simulations and experiments are used to validate the performance of the proposed methods.


Title: Discrete Layer Jamming for Safe Co-Robots
Abstract: High injury severity occurs when a stiff robot arm hits an operator. Introducing compliance into robot systems reduces the impact and enables safe interaction, but at the expense of positioning performance and payload capacity. This paper presents a tunable stiffness mechanism for safe human-robot interaction based on discrete layer jamming. The proposed design of a discrete layer jamming mechanism is a robot link made of multiple thin layers of ABS and multiple clamps. By applying high clamping pressure to the laminates, the link behaves like a rigid link; reducing the clamping pressure softens the link which yields safer human-robot interaction. Compared to conventional pneumatic layer jamming, discrete layer jamming allows for simplicity of installation with dynamic actuators, faster control, greater portability since no air supply is needed, and no sealing issues. To validate the concept, this paper investigates a discrete layer jamming beam made of ten ABS laminates and two aluminum clamps that cover 10% of the surface of the beam. Stiffness tests have been performed, showing that around 17 times bending stiffness change is achieved by increasing the clamping pressure of two clamps from 0 to 1 MPa.


Title: Admittance Control for Human-Robot Interaction Using an Industrial Robot Equipped with a F/T Sensor
Abstract: We present an approach to safe physical Human-Robot Interaction (pHRI) for industrial robots, including collision detection, distinguishing accidental from intentional contacts, and achieving collaborative tasks. Typical industrial robots have a closed control architecture that accepts only velocity/position reference inputs, there are no joint torque sensors, and little or no information is available to the user on robot dynamics and on low-level joint controllers. Nonetheless, taking also advantage of the presence of a Force/Torque (F/T) sensor at the end-effector, a safe pHRI strategy based on kinematic information, on measurements from joint encoders and motor currents, and on end-effector forces/torques can be realized. An admittance control law has been implemented for collaboration in manual guidance mode, with whole-body collision detection in place both when the robot is in autonomous operation and when is simultaneously collaborating with a human. Several pHRI experiments validate the approach on a KUKA KR5 Sixx R650 robot equipped with an ATI F/T sensor.


Title: Effect of Mechanical Resistance on Cognitive Conflict in Physical Human-Robot Collaboration
Abstract: Physical Human-Robot Collaboration (pHRC) is about the interaction between one or more human operator(s) and one or more robot(s) in direct contact and voluntarily exchanging forces to accomplish a common task. In any pHRC, the intuitiveness of the interaction has always been a priority, so that the operator can comfortably and safely interact with the robot. So far, the intuitiveness has always been described in a qualitative way. In this paper, we suggest an objective way to evaluate intuitiveness, known as prediction error negativity (PEN) using electroencephalogram (EEG). PEN is defined as a negative deflection in event related potential (ERP) due to cognitive conflict, as a consequence of a mismatch between perception and reality. Experimental results showed that the forces exchanged between robot and human during pHRC modulate the amplitude of PEN, representing different levels of cognitive conflict. We also found that PEN amplitude significantly decreases (p <; 0.05) when a mechanical resistance is being applied smoothly and more time in advance before an invisible obstacle, when compared to a scenario in which the resistance is applied abruptly before the obstacle. These results indicate that an earlier and smoother resistance reduces the conflict level. Consequently, this suggests that smoother changes in resistance make the interaction more intuitive.


Title: Magnetic-Field-Inspired Navigation for Quadcopter Robot in Unknown Environments
Abstract: In this paper, a magnetic-field-inspired robot navigation is used to navigate an under-actuated quad-copter towards the desired position amidst previously-unknown arbitrary-shaped convex obstacles. Taking inspiration from the phenomena of magnetic field interaction with charged particles observed in nature, the algorithm outperforms previous reactive navigation algorithms for flying robots found in the literature as it is able to reactively generate motion commands relying only on a local sensory information without prior knowledge of the obstacles' shape or location and without getting trapped in local minima configurations. The application of the algorithm in a dynamic model of quadcopter system and in the realistic model of the commercial AscTec Pelican micro-aerial vehicle confirm the superior performance of the algorithm.


Title: Human-Care Rounds Robot with Contactless Breathing Measurement
Abstract: This paper describes a human measurement system for autonomous rounds robot aiming in physical support of care staffs working in nursing and medical facilities. We propose a novel scheme of vision-based contactless breathing measurement system that integrates three-dimensional shape and thermal information of the target person. We developed the human-care rounds robot Lucia and implemented the measurement system on the robot. We then evaluated the human detection and breathing measurement based on the conditions of real incident cases that occurred in the nursing facility for the physically handicapped. In the experiments, we examined that the breathing measurement system successfully measured volume variation of human subjects with different configurations of body postures. The robot is also capable of discrimination between the breathing and non-breathing states of targets based on the difference in the power spectrum patterns in the frequency domain. The experimental results showed that the proposed system detected the presence of breathing within the accuracy of about 90% or more, and moreover, the ability of anomaly detection in breathing was suggested.


Title: An Improved Control-Oriented Modeling of the Magnetic Field
Abstract: This paper proposes a new control-oriented model to compute the magnetic field created by a coil. A major challenge for untethered microscale mobile robotics is the control of objects for precise and fast displacements. In this work, we propose to use an alternative implementation of a model based on elliptic integral functions to control magnetically actuated micro-robots. It allows to compute the magnetic field even in the area close to the coil quickly and accurately. This model is evaluated numerically and compared to classical approaches - dipole approximation, map-based interpolation and classical elliptic integral models - in terms of accuracy, computation time and memory requirement. Simulation results show that this works allows to have an accurate model in the whole workspace by avoiding numerical issues encountered in previous works. It can be computed in a few milliseconds, making it the right candidate for closed-loop control of magnetically actuated micro-robots.


Title: Efficient Micro Waveguide Coupling based on Microrobotic Positioning
Abstract: Coupling the endface of an optical fiber to an integrated optical component is currently a low-throughput and costly manual process in the fabrication of the optical devices. In order to meet the high-volume demand for commercial optoelectronic devices, coupling must be automated. This paper presents a robotic positioning system and corresponding path planning strategy based on both the position and light intensity feedback. In this work, a micro-robotic positioning system with 3 degrees of freedoms (DOFs) is developed and integrated with an optical microscopy. Then the fuzzy controller is developed to design the trajectory. Lastly, simulation and experimental results demonstrate the accuracy and efficiency of the proposed system. Compared with the traditional manual method, the robotic positioning system can realize the coupling within 40 seconds. This method will have a significant impact on the automatic process of the micro manufacture field.


Title: Sizing the aortic annulus with a robotised, commercially available soft balloon catheter: in vitro study on idealised phantoms
Abstract: Transcatheter aortic valve implantation (TAVI) is a minimally invasive surgical technique to treat aortic heart valve diseases. According to current clinical guidelines, the implanted prosthetic valve replacing the native one is selected based on pre-operative size assessment of the aortic annulus through different imaging techniques. That very often leads to suboptimal device selection resulting in major complications, such as prosthetic valve leakage or interruption of the cardiac electrical signal. In this paper, we propose a new, intra-operative approach to determine the diameter of theaortic annulus exploiting intra-balloon pressure and volume data, acquired from a robotised valvuloplasty balloon catheter. An inflation device, capable of collecting real-time intra-balloon pressure and volume data, was designed and interfaced with a commercially available valvuloplasty balloon catheter. A sizing algorithm allowing to precisely estimate the annular diameter was integrated. The algorithm relies on a characterised analytical model of the balloon free inflation and an iterative method based on linear regression. In vitro tests were performed on idealised aortic phantoms. Experimental results show that pressure-volume data can be used to determine annular diameters bigger than the unstretched diameter of the balloon catheter. For these cases, the proposed approach exhibited good precision (maximum average error 0.93%) and good repeatability (maximum standard deviation ±0.11 mm).


Title: Miniature Robotic Tubes with Rotational Tip-Joints as a Medical Delivery Platform
Abstract: We present a medical-needle-sized robotic tube with multi-degrees of freedom (M-DOF) rotational hinge joints at the instrument tip, fabricated by two-axis laser micro-machining. Due to the presence of an ample working channel and direct tip controllability, this tube is a potential candidate for the precise delivery of radioactive seeds, probes and micro-forceps to regions of interest within the human body. In this paper, the advantages of the proposed hinged instrument are studied in contrast with that of flexure joints, which include-fine angle control (posability), and a shorter joint length that enables compact articulation. In addition, the joint strength both in the axial and lateral directions was experimentally investigated to demonstrate its feasibility as a robust delivery platform. Further, the intuitive nature of hinge rotation permits the use of a simple kinematic model for accurate tip motion control, under fewer simplifying assumptions than flexure joints which are impeded by material non-linearity and geometric discontinuities. An instrumented prototype was used to test this model by delivering a laser beam along a prescribed path (synonymous to simple ablation tasks). The observed RMS position error for the projected beam was ~0.364 mm.


Title: Nonlinear System Identification of Soft Robot Dynamics Using Koopman Operator Theory
Abstract: Soft robots are challenging to model due in large part to the nonlinear properties of soft materials. Fortunately, this softness makes it possible to safely observe their behavior under random control inputs, making them amenable to large-scale data collection and system identification. This paper implements and evaluates a system identification method based on Koopman operator theory in which models of nonlinear dynamical systems are constructed via linear regression of observed data by exploiting the fact that every nonlinear system has a linear representation in the infinite-dimensional space of real-valued functions called observables. The approach does not suffer from some of the shortcomings of other nonlinear system identification methods, which typically require the manual tuning of training parameters and have limited convergence guarantees. A dynamic model of a pneumatic soft robot arm is constructed via this method, and used to predict the behavior of the real system. The total normalized-root-mean-square error (NRMSE) of its predictions is lower than that of several other identified models including a neural network, NLARX, nonlinear Hammerstein-Wiener, and linear state space model.


Title: Data Driven Inverse Kinematics of Soft Robots using Local Models
Abstract: Soft robots are advantageous in terms of flexibility, safety and adaptability. It is challenging to find efficient computational approaches for planning and controlling their motion. This work takes a direct data-driven approach to learn the kinematics of the three-dimensional shape of a soft robot, by using visual markers. No prior information about the robot at hand is required. The model is oblivious to the design of the robot and type of actuation system. This allows adaptation to erroneous manufacturing. We present a highly versatile and inexpensive learning cube environment for collecting and analysing data. We prove that using multiple, lower order models of data opposed to one global, higher order model, will reduce the required data quantity, time complexity and memory complexity significantly without compromising accuracy. Further, our approach allows for embarrassingly parallelism. Yielding an overall much more simple and efficient approach.


Title: ChainQueen: A Real-Time Differentiable Physical Simulator for Soft Robotics
Abstract: Physical simulators have been widely used in robot planning and control. Among them, differentiable simulators are particularly favored, as they can be incorporated into gradient-based optimization algorithms that are efficient in solving inverse problems such as optimal control and motion planning. Therefore, rigid body simulators and recently their differentiable variants are studied extensively. Simulating deformable objects is, however, more challenging compared to rigid body dynamics. The underlying physical laws of deformable objects are more complex, and the resulting systems have orders of magnitude more degrees of freedom and there-fore they are significantly more computationally expensive to simulate. Computing gradients with respect to physical design or controller parameters is typically even more computationally challenging. In this paper, we propose a real-time, differentiable hybrid Lagrangian-Eulerian physical simulator for deformable objects, ChainQueen, based on the Moving Least Squares Material Point Method (MLS-MPM). MLS-MPM can simulate deformable objects with collisions and can be seamlessly incorporated into soft robotic systems. We demonstrate that our simulator achieves high precision in both forward simulation and backward gradient computation. We have successfully employed it in a diverse set of inference, control and co-design tasks for soft robotics.


Title: A Validated Physical Model For Real-Time Simulation of Soft Robotic Snakes
Abstract: In this work we present a framework that is capable of accurately representing soft robotic actuators in a multiphysics environment in real-time. We propose a constraint-based dynamics model of a 1-dimensional pneumatic soft actuator that accounts for internal pressure forces, as well as the effect of actuator latency and damping under inflation and deflation and demonstrate its accuracy a full soft robotic snake with the composition of multiple 1D actuators. We verify our model's accuracy in static deformation and dynamic locomotion open-loop control experiments. To achieve real-time performance we leverage the parallel computation power of GPUs to allow interactive control and feedback.


Title: SpaceBok: A Dynamic Legged Robot for Space Exploration
Abstract: This paper introduces SpaceBok, a quadrupedal robot created to investigate dynamic legged locomotion for the exploration of low-gravity celestial bodies. With a hip height of 500 mm and a mass of 20 kg, its dimensions are comparable to a medium-sized dog. The robot's leg configuration is based on an optimized parallel motion mechanism that allows the integration of parallel elastic elements to store and release energy for powerful jumping maneuvers. High-torque brushless motors in combination with customized single-stage planetary gear transmissions enable force control at the foot contact points based on motor currents. We present successful walking, trotting, and pronking experiments. Thereby, Spacebok achieved maximal jump heights in single jump experiments of up to 1.05 m (more than twice the hip height) and a walking velocity of 1m/s. Moreover, simulation results for low gravity on the moon suggest that our robot can move with up to 1.1m/s at an approximate cost of transport of 1 in moon gravity when using the pronking gait.


Title: Mini Cheetah: A Platform for Pushing the Limits of Dynamic Quadruped Control
Abstract: Mini Cheetah is a small and inexpensive, yet powerful and mechanically robust quadruped robot, intended to enable rapid development of control systems for legged robots. The robot uses custom backdriveable modular actuators, which enable high-bandwidth force control, high force density, and robustness to impacts. Standing around 0.3 m tall and weighing 9 kg, Mini Cheetah can easily be handled by a single operator. We have demonstrated dynamic trot, trot-run, bounding, and pronking gaits on the robot to speeds of up to 2.45 meters per second using Convex Model-Predictive Control (cMPC). In addition to locomotion, we have used the robot to execute 360° backflips, with trajectories generated using offline nonlinear optimization.


Title: Optimal Leg Sequencing for a Hexapod Subject to External Forces and Slopes
Abstract: An optimal leg sequence selection method is developed, which maximizes hexapod robot stability, considering feasible gaits, motion modes, and terrain slope. A novel and fast search method is employed to find the most stable leg sequence for a given gait; if no such sequence exists, the next fastest stable gait is chosen and the most stable leg sequence for this gait is selected. The method can be based on any stability measure; here the Force-Angle Stability Margin criterion is employed that is sensitive to top-heaviness, and inertial and external forces. Results show that the developed method senses instabilities accurately and selects the best leg sequence for maximum stability far faster than exhaustive searches, offering distinct advantages when varied external forces are applied.


Title: Stanford Doggo: An Open-Source, Quasi-Direct-Drive Quadruped
Abstract: This paper presents Stanford Doggo, a quasi-direct-drive quadruped capable of dynamic locomotion. This robot matches or exceeds common performance metrics of state-of-the-art legged robots. In terms of vertical jumping agility, a measure of average vertical speed, Stanford Doggo matches the best performing animal and surpasses the previous best robot by 22%. An overall design architecture is presented with focus on our quasi-direct-drive design methodology. The hardware and software to replicate this robot is open-source, requires only hand tools for manufacturing and assembly, and costs less than $3000.


Title: Workspace CPG with Body Pose Control for Stable, Directed Vision during Omnidirectional Locomotion
Abstract: In this paper, we focus on the problem of directing the gaze of a vision system mounted to the body of a high-degree-of-freedom (DOF) legged robot for active perception deployments. In particular, we consider the case where the vision system is rigidly attached to the robot's body (i.e., without any additional DOF between the vision system and robot body) and show how the supernumerary DOFs of the robot can be leveraged to allow independent locomotion and gaze control. Specifically, we augment a workspace central pattern generator (CPG) with omnidirectional capabilities by coupling it with a body pose control mechanism. We leverage the smoothing nature of the CPG framework to allow online adaptation of relevant locomotion parameters, and obtain a stable mid-level controller that translates desired gaze orientation and body velocity directly into joint angles. We validate our approach on an 18-DOF hexapod robot, in a series of indoor and outdoor trials, where the robot inspects an environmental feature or follows a pre-planned path relative to a visually-tracked landmark, demonstrating simultaneous locomotion and directed vision.


Title: Robotic Forceps without Position Sensors using Visual SLAM
Abstract: In this study, a robotic forceps with a wrist joint using visual SLAM for joint angle sensing was developed. The forceps has a flexible joint connected to the wrist joint at its rear end and the motion of the rear joint is driven by a parallel linkage. A monocular camera attached on the rear of the parallel linkage is in charge of position sensing, and the joint angles are estimated from the pose of the camera. The pose of the camera is obtained by a visual SLAM. The visual servo system realizes a simple attaching mechanism. The static and dynamic positioning experiments are conducted. We confirmed that the visual servoing system controls the forceps tip within the error of 3 deg in the motion range of 50 deg.


Title: 3D Keypoint Repeatability for Heterogeneous Multi-Robot SLAM
Abstract: For robots with different types of sensors, loop closure in a multi-robot SLAM scenario requires keypoints that can be matched between sensor measurement point clouds with different properties such as point density and noise. In this paper, we evaluate the performance of several 3D keypoint detectors (Harris3D, ISS, KPQ, KPQ-SI, and NARF) for repeatability between scans from different sensors towards building a heterogeneous multi-robot SLAM system. We find that KPQ-SI and NARF have the best relative repeatability, with KPQ-SI finding more keypoints overall and a higher number of repeatable keypoints, at the cost of significantly worse computational performance. In scans of the same area from different poses, both detectors find enough keypoints for point cloud registration and loop closure. For heterogenous multirobot SLAM applications with computational or bandwidth restrictions, the NARF detector consistently finds repeatable keypoints while also allowing for real-time performance.


Title: SLAMBench 3.0: Systematic Automated Reproducible Evaluation of SLAM Systems for Robot Vision Challenges and Scene Understanding
Abstract: As the SLAM research area matures and the number of SLAM systems available increases, the need for frameworks that can objectively evaluate them against prior work grows. This new version of SLAMBench moves beyond traditional visual SLAM, and provides new support for scene understanding and non-rigid environments (dynamic SLAM). More concretely for dynamic SLAM, SLAMBench 3.0 includes the first publicly available implementation of DynamicFusion, along with an evaluation infrastructure. In addition, we include two SLAM systems (one dense, one sparse) augmented with convolutional neural networks for scene understanding, together with datasets and appropriate metrics. Through a series of use-cases, we demonstrate the newly incorporated algorithms, visulation aids and metrics (6 new metrics, 4 new datasets and 5 new algorithms).


Title: Efficient Integrity Monitoring for KF-based Localization
Abstract: This paper presents a new method to efficiently monitor localization safety in mobile robots. Localization safety is quantified by measuring the system's integrity risk, which is a well-known aviation performance metric. However, aviation integrity monitoring solutions almost exclusively rely on the Global Navigation Satellite System (GNSS) while robot navigation usually needs the additional information provided by a state evolution model and/or relative positioning sensors, which makes previously established approaches impractical. In response, this paper develops an efficient integrity monitoring methodology applicable to Kalman Filter-based localization. The work is intended for life-or mission-critical operations such as co-robot applications where ignoring the impact of faults can jeopardize human safety.


Title: Speeding Up Iterative Closest Point Using Stochastic Gradient Descent
Abstract: Sensors producing 3D point clouds such as 3D laser scanners and RGB-D cameras are widely used in robotics, be it for autonomous driving or manipulation. Aligning point clouds produced by these sensors is a vital component in such applications to perform tasks such as model registration, pose estimation, and SLAM. Iterative closest point (ICP) is the most widely used method for this task, due to its simplicity and efficiency. In this paper we propose a novel method which solves the optimisation problem posed by ICP using stochastic gradient descent (SGD). Using SGD allows us to improve the convergence speed of ICP without sacrificing solution quality. Experiments using Kinect as well as Velodyne data show that, our proposed method is faster than existing methods, while obtaining solutions comparable to standard ICP. An additional benefit is robustness to parameters when processing data from different sensors.


Title: Energy Tank-Based Wrench/Impedance Control of a Fully-Actuated Hexarotor: A Geometric Port-Hamiltonian Approach
Abstract: In this work, we show how the interactive behavior of an aerial robot can be modeled and controlled effectively and elegantly in the port-Hamiltonian framework. We present an observer-based wrench/impedance controller for a fully-actuated hexarotor. The analysis and control are performed in a geometrically consistent manner on the configuration manifold of the special Euclidean group SE (3) such that the UAV's nonlinear geometric structure is exploited. The controller uses a wrench observer to estimate the interaction wrench without the use of a force/torque sensor. Moreover, the concept of energy tanks is used to guarantee the system's overall contact stability to arbitrary passive environments. The reliability and robustness of the proposed approach is validated through simulation and experiment.


Title: Integral Backstepping Position Control for Quadrotors in Tunnel-Like Confined Environments
Abstract: There are many potential applications that require flying robots to navigate through tunnel-like environments, such as inspections of small railway culverts and mineral mappings of mining tunnels. Nevertheless, those environments present many challenges for quadrotors to navigate through. The aerodynamic disturbances created from the fluid interaction between the propellers' downwash and the surrounding surfaces of the environment, as well as longitudinal wind gusts, add hardship in stabilising the vehicle while the restricted narrow space increases the risk of collision. Furthermore, poor visibility and dust blown by the downwash make vision-based localisation extremely difficult. This paper presents a cross-sectional localisation system using Hough Scan Matching and a simple kinematic Kalman filter. Using the estimated state information, an integral backstepping controller is implemented which enables quadrotors to robustly fly in tunnel-like confined environments. A semi-autonomous system is proposed with self-stabilisation in the vertical and lateral axes while a pilot provides commands in the longitudinal direction. The results of a series of experiments in a simulated tunnel show that the proposed system successfully hovered itself and tracked various trajectories in a cross-sectional area without the aid of any external sensing or computing system.


Title: Control and Configuration Planning of an Aerial Cable Towed System
Abstract: This paper investigates the effect of the robot configuration on the performance of an aerial cable towed system (ACTS) composed of three quadrotors manipulating a point mass payload. The kinematic and dynamic models of the ACTS are derived in a minimal set of geometric coordinates, and a centralized feedback linearization controller is developed. Independent to the payload trajectory, the configuration of the ACTS is controlled and is evaluated using a robustness index named the capacity margin. Experiments are performed with optimal, suboptimal, and wrench infeasible configurations. It is shown that configurations near the point of zero capacity margin allow the ACTS to hover but not to follow dynamic trajectories, and that the ACTS cannot fly with a negative capacity margin. Dynamic tests of the ACTS show the effects of the configuration on the achievable accelerations.


Title: Adaptive Control of Aerobatic Quadrotor Maneuvers in the Presence of Propeller-Aerodynamic-Coefficient and Torque-Latency Time-Variations
Abstract: We present a study of the dynamics and control of a 28-gram quadrotor during the execution of aerobatic maneuvers in the presence of propeller-aerodynamic-coefficient and torque-latency time-variations. First, through a momentum-theory-based analysis of the flow field surrounding the robot during aerobatic flight, we develop a dynamic linear time-varying (LTV) description of the torque acting on the flyer in which both considered effects explicitly appear as distinct mathematical terms. Then, an adaptive control scheme, composed of a backstepping controller and a modified recursive least-squares (RLS) estimator, is designed to counteract the negative effects produced by the time-varying dynamics of the torque that drives the flyer. The suitability and efficacy of the proposed methods are demonstrated through real-time flight experiments in which the quadrotor autonomously performs three different types of aerobatic maneuvers: triple flips, Pugachev's Cobras and mixed flips. Furthermore, analyses of the experimental data compellingly show that the proposed control scheme consistently improves the performance of the aerial vehicle during aerobatic flight, compared to those achieved by using a high-performance linear time-invariant (LTI) controller that does not account for time-varying torque generation.


Title: Exploiting a Human-Aware World Model for Dynamic Task Allocation in Flexible Human-Robot Teams
Abstract: We propose a highly flexible approach to human-robot cooperation, where a robot dynamically selects operations contributing to a shared goal from a given task model. Therefore, knowledge on the task progress is extracted from a world model constructed from eye-in-hand camera images. Data generated from such partial workspace observations is not reliable over time, as humans may interact with resources. We therefore use a human-aware world model maintaining a measure for trust in stored objects regarding recent human presence and previous task progress. Our contribution is an action selection algorithm that uses this trust measure to interleave task operations with active vision to refresh the world model. Large-scale experiments cover various sorts of human participation in different benchmark tasks through simulation of simplified, partially randomized human models. Results illuminate system behaviour and performance for different parametrizations of our human-robot teaming framework.


Title: Group Surfing: A Pedestrian-Based Approach to Sidewalk Robot Navigation
Abstract: In this paper, we propose a novel navigation system for mobile robots in pedestrian-rich sidewalk environments. Sidewalks are unique in that the pedestrian-shared space has characteristics of both roads and indoor spaces. Like vehicles on roads, pedestrian movement often manifests as linear flows in opposing directions. On the other hand, pedestrians also form crowds and can exhibit much more random movements than vehicles. Classical algorithms are insufficient for safe navigation around pedestrians and remaining on the sidewalk space. Thus, our approach takes advantage of natural human motion to allow a robot to adapt to sidewalk navigation in a safe and socially-compliant manner. We developed a group surfing method which aims to imitate the optimal pedestrian group for bringing the robot closer to its goal. For pedestrian-sparse environments, we propose a sidewalk edge detection and following method. Underlying these two navigation methods, the collision avoidance scheme is human-aware. The integrated navigation stack is evaluated and demonstrated in simulation. A hardware demonstration is also presented.


Title: Dentronics: Review, First Concepts and Pilot Study of a New Application Domain for Collaborative Robots in Dental Assistance
Abstract: In this paper we introduce dentronics as a new emerging application domain for collaborative lightweight robots in the dental context backed up by a user survey supporting the clear need. Specifically, we developed a multi-modal interaction framework, applied this framework to a specific dental use-case, and conducted a preliminary user-study for evaluation. Our results demonstrate usability and feasibility beyond a controlled experimental setup. We conclude that dentronics is indeed within reach given today's technology and deserves further investigation towards clinical use.


Title: Activity recognition in manufacturing: The roles of motion capture and sEMG+inertial wearables in detecting fine vs. gross motion
Abstract: In safety-critical environments, robots need to reliably recognize human activity to be effective and trust-worthy partners. Since most human activity recognition (HAR) approaches rely on unimodal sensor data (e.g. motion capture or wearable sensors), it is unclear how the relationship between the sensor modality and motion granularity (e.g. gross or fine) of the activities impacts classification accuracy. To our knowledge, we are the first to investigate the efficacy of using motion capture as compared to wearable sensor data for recognizing human motion in manufacturing settings. We introduce the UCSD-MIT Human Motion dataset, composed of two assembly tasks that entail either gross or fine-grained motion. For both tasks, we compared the accuracy of a Vicon motion capture system to a Myo armband using three widely used HAR algorithms. We found that motion capture yielded higher accuracy than the wearable sensor for gross motion recognition (up to 36.95%), while the wearable sensor yielded higher accuracy for fine-grained motion (up to 28.06%). These results suggest that these sensor modalities are complementary, and that robots may benefit from systems that utilize multiple modalities to simultaneously, but independently, detect gross and fine-grained motion. Our findings will help guide researchers in numerous fields of robotics including learning from demonstration and grasping to effectively choose sensor modalities that are most suitable for their applications.


Title: Optimal Proactive Path Planning for Collaborative Robots in Industrial Contexts
Abstract: The coexistence of humans and robots in the future production plants is one of the pillars of Industry 4.0. Humans and robots will collaborate to accomplish common tasks in order to mutually compensate their deficiencies. In recent years, many efforts have been spent to develop safe motion planning strategies, designed to prevent robots from injuring humans. Most of the previous techniques are classifiable as reactive, since the considered motion controllers impose some local corrective actions in order to dodge the space occupied by the human. In this paper, a proactive approach is adopted, optimizing robotic paths according to a prediction of the volume occupied by the human when collaborating with the robot. The validity of the approach is shown in a realistic use-case involving the collaboration of a human operator with a 7 degrees robotic arm, the ABB YuMi.


Title: UWB/LiDAR Fusion For Cooperative Range-Only SLAM
Abstract: We equip an ultra-wideband (UWB) node and a 2D LiDAR sensor a.k.a. 2D laser rangefinder on a mobile robot, and place UWB beacon nodes at unknown locations in an unknown environment. All UWB nodes can do ranging with each other thus forming a cooperative sensor network. We propose to fuse the peer-to-peer ranges measured between UWB nodes and laser scanning information, i.e., range measured between robot and nearby objects/obstacles, for simultaneous localization of the robot, all UWB beacons and LiDAR mapping. The fusion is inspired by two facts: 1) LiDAR may improve UWB-only localization accuracy as it gives a more precise and comprehensive picture of the surrounding environment; 2) on the other hand, UWB ranging measurements may remove the error accumulated in the LiDAR-based SLAM algorithm. Our experiments demonstrate that UWB/LiDAR fusion enables drift-free SLAM in real-time based on ranging measurements only.


Title: Learning-driven Coarse-to-Fine Articulated Robot Tracking
Abstract: In this work we present an articulated tracking approach for robotic manipulators, which relies only on visual cues from colour and depth images to estimate the robot's state when interacting with or being occluded by its environment. We hypothesise that articulated model fitting approaches can only achieve accurate tracking if subpixel-level accurate correspondences between observed and estimated state can be established. Previous work in this area has exclusively relied on either discriminative depth information or colour edge correspondences as tracking objective and required initialisation from joint encoders. In this paper we propose a coarse-to-fine articulated state estimator, which relies only on visual cues from colour edges and learned depth keypoints, and which is initialised from a robot state distribution predicted from a depth image. We evaluate our approach on four RGB-D sequences showing a KUICA LWR arm with a Schunk SDH2 hand interacting with its environment and demonstrate that this combined keypoint and edge tracking objective can estimate the palm position with an average error of 2. 5cm without using any joint encoder sensing.


Title: Diagonally-Decoupled Direct Visual Servoing
Abstract: This paper addresses the problem of vision-based robot control where a reference image defines the equilibrium. Specifically, we consider the class of intensity-based nonmetric solutions, which provide for high accuracy, versatility, and robustness. Existing techniques within that class present either a fully coupled control error dynamics or at best only achieve decoupling of the translational part, i.e., they can only obtain a lower triangular system. These couplings in the system dynamics increase analysis complexity and may degrade system performance. This work proposes a new nonlinear observer for also decoupling the rotational part, i.e., for diagonally decoupling the entire control error dynamics. Theoretical proofs of stability and of those decoupling properties are provided. Improved performances are also experimentally confirmed using synthetic and real data, planar and nonplanar objects, simulating and applying a camera-mounted 6-DoF robotic arm.


Title: 2D LiDAR Map Prediction via Estimating Motion Flow with GRU
Abstract: It is a significant problem to predict the 2D LiDAR map at next moment for robotics navigation and path-planning. To tackle this problem, we resort to the motion flow between adjacent maps, as motion flow is a powerful tool to process and analyze the dynamic data, which is named optical flow in video processing. However, unlike video, which contains abundant visual features in each frame, a 2D LiDAR map lacks distinctive local features. To alleviate this challenge, we propose to estimate the motion flow based on deep neural networks inspired by its powerful representation learning ability in estimating the optical flow of the video. To this end, we design a recurrent neural network based on gated recurrent unit, which is named LiDAR-FlowNet. As a recurrent neural network can encode the temporal dynamic information, our LiDAR-FlowNet can estimate motion flow between the current map and the unknown next map only from the current frame and previous frames. A self-supervised strategy is further designed to train the LiDAR-FlowNet model effectively, while no training data need to be manually annotated. With the estimated motion flow, it is straightforward to predict the 2D LiDAR map at the next moment. Experimental results verify the effectiveness of our LiDAR-FlowNet as well as the proposed training strategy. The results of the predicted LiDAR map also show the advantages of our motion flow based method.


Title: Robot eye-hand coordination learning by watching human demonstrations: a task function approximation approach
Abstract: We present a robot eye-hand coordination learning method that can directly learn visual task specification by watching human demonstrations. Task specification is represented as a task function, which is learned using inverse reinforcement learning(IRL [1]) by inferring a reward model from state transitions. The learned reward model is then used as continuous feedbacks in an uncalibrated visual servoing(UVS [2]) controller designed for the execution phase. Our proposed method can directly learn from raw videos, which removes the need for hand-engineered task specification. Benefiting from the use of a traditional UVS controller, the training on real robot only happens at initial Jacobian estimation which takes an average of 4-7 seconds for a new task. Besides, the learned policy is independent from a particular robot, thus has the potential of fast adapting to other robot platforms. Various experiments were designed to show that, for a task with certain DOFs, our method can adapt to task/environment changes in target positions, backgrounds, illuminations, and occlusions.


Title: Vision-Based Dynamic Control of Car-Like Mobile Robots
Abstract: Most existing controllers for Car-Like Mobile Robots (CLMR) are designed to handle dynamic effects by decoupling speed and steering controls, also assume that full states are accessible, which are unrealistic for real-world applications. This paper presents a combined speed and steering control system for CLMR. To provide the essential state for the controller, a newly developed visual algorithm is adopted for estimating the high-update rate longitudinal and lateral velocities of the robot which cannot be accurately measured by wheel encoders due to the skidding and slipping effects. The stability of the proposed system can be guaranteed by Lyapunov method since the velocity estimation error, the speed tracking error and the lateral deviation converging to zero simultaneously. Real-world experiments are conducted on an electric autonomous tractor with online estimation to demonstrate the feasibility of the approach.


Title: Interaction-aware Multi-agent Tracking and Probabilistic Behavior Prediction via Adversarial Learning
Abstract: In order to enable high-quality decision making and motion planning of intelligent systems such as robotics and autonomous vehicles, accurate probabilistic predictions for surrounding interactive objects is a crucial prerequisite. Although many research studies have been devoted to making predictions on a single entity, it remains an open challenge to forecast future behaviors for multiple interactive agents simultaneously. In this work, we take advantage of the Generative Adversarial Network (GAN) due to its capability of distribution learning and propose a generic multi-agent probabilistic prediction and tracking framework which takes the interactions among multiple entities into account, in which all the entities are treated as a whole. However, since GAN is very hard to train, we make an empirical research and present the relationship between training performance and hyperparameter values with a numerical case study. The results imply that the proposed model can capture both the mean, variance and multi-modalities of the groundtruth distribution. Moreover, we apply the proposed approach to a real-world task of vehicle behavior prediction to demonstrate its effectiveness and accuracy. The results illustrate that the proposed model trained by adversarial learning can achieve a better prediction performance than other state-of-the-art models trained by traditional supervised learning which maximizes the data likelihood. The well-trained model can also be utilized as an implicit proposal distribution for particle filtered based Bayesian state estimation.


Title: A Hierarchical Framework for Coordinating Large-Scale Robot Networks
Abstract: In this paper, we study the cooperative path planning and motion coordination problems of the multi-robot system with large number of robots, aiming for practical applications in robotic warehouses and automated transportation systems. Particularly, we solve the life-long planning problem and guarantee the coordination performance in the presence of robot motion uncertainties. A hierarchical path planning and motion coordination structure is presented. The environment is divided into several sectors and a traffic heat-map is presented to describe the current sector-level traffic condition. In path planning level, the sector-level path is calculated by considering the path distance, the current traffic condition and the current robot uncertainty. In motion coordination level, local cooperative A* algorithm and conflict-based searching strategy are utilized within each sector to generate the collision-free local path of each robot in a rolling planning manner. The effectiveness and practical applicability of the proposed approach are validated by simulations with more than one thousand robots and real experiments.


Title: EasyLabel: A Semi-Automatic Pixel-wise Object Annotation Tool for Creating Robotic RGB-D Datasets
Abstract: Developing robot perception systems for recognizing objects in the real world requires computer vision algorithms to be carefully scrutinized with respect to the expected operating domain. This demands large quantities of ground truth data to rigorously evaluate the performance of algorithms. This paper presents the EasyLabel tool for easily acquiring high-quality ground truth annotation of objects at pixel-level in densely cluttered scenes. In a semi-automatic process, complex scenes are incrementally built and EasyLabel exploits depth changes to extract precise object masks at each step. We use this tool to generate the Object Cluttered Indoor Dataset (OCID) that captures diverse settings of objects, background, context, sensor to scene distance, viewpoint angle and lighting conditions. OCID is used to perform a systematic comparison of existing object segmentation methods. The baseline comparison supports the need for pixel- and object-wise annotation to progress robot vision towards realistic applications. This insight reveals the usefulness of EasyLabel and OCID to better understand the challenges that robots face in the real world.


Title: A Benchmarking Framework for Systematic Evaluation of Robotic Pick-and-Place Systems in an Industrial Grocery Setting
Abstract: Robotic manipulation is a very active field of research nowadays; however, pick-and-place operations constitute the majority of today's industrial robotic applications. In order to adopt a robotic solution for an industrial setting, proper evaluation processes should be defined to assess the system's performance. A number of benchmarks have been proposed in the literature focusing mainly on individual components needed to perform the task, like grasping, perception and motion planning; thus, they do not provide enough information on the performance of the entire robotic system. To address this, we propose a benchmarking framework for a pick-and-place task inspired by a use case for picking fruits and vegetables in an industrial setting. To foster reproducible research and comparison of different robotic systems, the benchmarking framework uses surrogate objects with instructions on how to build them, an easy-to-reproduce environment, and guidelines for object placement. The proposed benchmark is applied to evaluate the performance of two variants of a robotic system with different end-effectors.


Title: Characterizing Visual Localization and Mapping Datasets
Abstract: Benchmarking mapping and motion estimation algorithms is established practice in robotics and computer vision. As the diversity of datasets increases, in terms of the trajectories, models, and scenes, it becomes a challenge to select datasets for a given benchmarking purpose. Inspired by the Wasserstein distance, this paper addresses this concern by developing novel metrics to evaluate trajectories and the environments without relying on any SLAM or motion estimation algorithm. The metrics, which so far have been missing in the research community, can be applied to the plethora of datasets that exist. Additionally, to improve the robotics SLAM benchmarking, the paper presents a new dataset for visual localization and mapping algorithms. A broad range of real-world trajectories is used in very high-quality scenes and a rendering framework to create a set of synthetic datasets with ground-truth trajectory and dense map which are representative of key SLAM applications such as virtual reality (VR), micro aerial vehicle (MAV) flight, and ground robotics.


Title: Quantifying the Reality Gap in Robotic Manipulation Tasks
Abstract: We quantify the accuracy of various simulators compared to a real world robotic reaching and interaction task. Simulators are used in robotics to design solutions for real world hardware without the need for physical access. The `reality gap' prevents solutions developed or learnt in simulation from performing well, or at all, when transferred to real-world hardware. Making use of a Kinova robotic manipulator and a motion capture system, we record a ground truth enabling comparisons with various simulators, and present quantitative data for various manipulation-oriented robotic tasks. We show the relative strengths and weaknesses of numerous contemporary simulators, highlighting areas of significant discrepancy, and assisting researchers in the field in their selection of appropriate simulators for their use cases.


Title: Practical guide to solve the minimum-effort problem with geometric algorithms and B-Splines
Abstract: This paper focuses on important implementation issues of numerical optimal control that are often overlooked. In particular, transcription methods should be carefully implemented for obtaining a discrete representation of the problem. For this purpose, we explain the algorithms to solve the minimum-effort problem by applying a direct collocation method based on B-Splines. In addition, we describe how to compute the gradient of the objective function as well as the Jacobian of the constraints without the use of finite differences and automatic differentiation. Geometric algorithms based on Lie groups and Lie algebra are examined to efficiently compute the analytical derivatives of the equations of motion of articulated robots. These ingredients allow the fast computation of dynamically feasible robot motions. We provide numerical comparisons with a biped robot to validate our recipe against classical direct collocation methods.


Title: Augmenting Action Model Learning by Non-Geometric Features
Abstract: Learning from demonstration is a powerful tool for teaching manipulation actions to a robot. It is, however, an unsolved problem how to consider knowledge about the world and action-induced reactions such as forces imposed onto the gripper or measured liquid levels during pouring without explicit and case dependent programming. In this paper, we present a novel approach to include such knowledge directly in form of measured features. To this end, we use action demonstrations together with external features to learn a motion encoded by a dynamic system in a Gaussian Mixture Model (GMM) representation. Accordingly, during action imitation, the system is able to couple the geometric trajectory of the motion to measured features in the scene. We demonstrate the feasibility of our approach with a broad range of external features in real-world robot experiments including a drinking, a handover and a pouring task.


Title: Real-time Multisensory Affordance-based Control for Adaptive Object Manipulation
Abstract: We address the challenge of how a robot can adapt its actions to successfully manipulate objects it has not previously encountered. We introduce Real-time Multisensory Affordance-based Control (RMAC), which enables a robot to adapt existing affordance models using multisensory inputs. We show that using the combination of haptic, audio, and visual information with RMAC allows the robot to learn afforance models and adaptively manipulate two very different objects (drawer, lamp), in multiple novel configurations. Offline evaluations and real-time online evaluations show that RMAC allows the robot to accurately open different drawer configurations and turn-on novel lamps with an average accuracy of 75%.


Title: Learning Behavior Trees From Demonstration
Abstract: Robotic Learning from Demonstration (LfD) allows anyone, not just experts, to program a robot for an arbitrary task. Many LfD methods focus on low level primitive actions such as manipulator trajectories. Complex multistep task with many primitive actions must be learned from demonstration if LfD is to encompass the full range of task a user may desire. Existing methods represent the high level task in various forms including, finite state machines, decision trees, formal logic, among others. Behavior trees are proposed as an alternative representation of high level task. Behavior trees are an execution model for the control of a robot designed for real time execution, modularity, and, consequently, transparency. Real time execution allows the robot to reactively perform the task. Modularity allows the reuse of learned primitive actions and high level task in new situations, speeding up the process of learning in new scenarios. Transparency allows users to understand and interactively modify the learned model. Behavior trees are used to represent high level tasks by building on the relationship it has with decision trees. We demonstrate a human teaching our Fetch robot a household cleaning task.


Title: Leveraging Temporal Reasoning for Policy Selection in Learning from Demonstration
Abstract: High-level human activities often have rich temporal structures that determine the order in which atomic actions are executed. We propose the Temporal Context Graph (TCG), a temporal reasoning model that integrates probabilistic inference with Allen's interval algebra, to capture these temporal structures. TCGs are capable of modeling tasks with cyclical atomic actions and consisting of sequential and parallel temporal relations. We present Learning from Demonstration as the application domain where the use of TCGs can improve policy selection and address the problem of perceptual aliasing. Experiments validating the model are presented for learning two tasks from demonstration that involve structured human-robot interactions. The source code for this implementation is available at https://github.com/AssistiveRoboticsUNH/TCG.


Title: Imitating Human Search Strategies for Assembly
Abstract: We present a Learning from Demonstration method for teaching robots to perform search strategies imitated from humans in scenarios where alignment tasks fail due to position uncertainty. The method utilizes human demonstrations to learn both a state invariant dynamics model and an exploration distribution that captures the search area covered by the demonstrator. We present two alternative algorithms for computing a search trajectory from the exploration distribution, one based on sampling and another based on deterministic ergodic control. We augment the search trajectory with forces learnt through the dynamics model to enable searching both in force and position domains. An impedance controller with superposed forces is used for reproducing the learnt strategy. We experimentally evaluate the method on a KUKA LWR4+ performing a 2D peg-in-hole and a 3D electricity socket task. Results show that the proposed method can, with only few human demonstrations, learn to complete the search task.


Title: Active Multi-Contact Continuous Tactile Exploration with Gaussian Process Differential Entropy
Abstract: In the present work, we propose an active tactile exploration framework to obtain a surface model of an unknown object utilizing multiple contacts simultaneously. To incorporate these multiple contacts, the exploration strategy is based on the differential entropy of the underlying Gaussian process implicit surface model, which formalizes the exploration with multiple contacts within an information theoretic context and additionally allows for nonmyopic multi-step planning. In contrast to many previous approaches, the robot continuously slides along the surface with its end-effectors to gather the tactile stimuli, instead of touching it at discrete locations. This is realized by closely integrating the surface model into the compliant controller framework. Furthermore, we extend our recently proposed sliding based tactile exploration approach to handle non-convex objects. In the experiments, it is shown that multiple contacts simultaneously leads to a more efficient exploration of complex, non-convex objects, not only in terms of time, but also with respect to the total moved distance of all end-effectors. Finally, we demonstrate our methodology with a real PR2 robot that explores an object with both of its arms.


Title: Learning Robust Manipulation Skills with Guided Policy Search via Generative Motor Reflexes
Abstract: Guided Policy Search enables robots to learn control policies for complex manipulation tasks efficiently. Therein, the control policies are represented as high-dimensional neural networks which derive robot actions based on states. However, due to the small number of real-world trajectory samples in Guided Policy Search, the resulting neural networks are only robust in the neighbourhood of the trajectory distribution explored by real-world interactions. In this paper, we present a new policy representation called Generative Motor Reflexes, which is able to generate robust actions over a broader state space compared to previous methods. In contrast to prior state-action policies, Generative Motor Reflexes map states to parameters for a state-dependent motor reflex, which is then used to derive actions. Robustness is achieved by generating similar motor reflexes for many states. We evaluate the presented method in simulated and real-world manipulation tasks, including contact-rich peg-in-hole tasks. Using these evaluation tasks, we show that policies represented as Generative Motor Reflexes lead to robust manipulation skills also outside the explored trajectory distribution with less training needs compared to previous methods.


Title: Incremental Learning of Spatial-Temporal Features in Human Motion Patterns with Mixture Model for Planning Motion of a Collaborative Robot in Assembly Lines
Abstract: Collaborative robots are expected to work in cooperation with humans to improve productivity and maintain the quality of products. In the previous study, we have proposed an incremental learning system for adaptively scheduling a motion of the collaborative robot based on a worker's behavior. Although this system could model the worker's motion pattern precisely and robustly without collecting the worker's data in advance, it required two different models for modeling the worker's spatial and temporal features respectively and was not well considered for generalization. In this paper, we extend the previous incremental learning system by integrating the spatial and temporal models using a mixture model. In addition, we install a new incremental learning algorithm which improves a generalization capability of the mixture model and avoids overfitting in the situation where the prior information is limited. Implementing the proposed algorithm, we evaluate the effectiveness of the proposed system by experiments for several workers and for several assembly processes.


Title: Learning Quickly to Plan Quickly Using Modular Meta-Learning
Abstract: Multi-object manipulation problems in continuous state and action spaces can be solved by planners that search over sampled values for the continuous parameters of operators. The efficiency of these planners depends critically on the effectiveness of the samplers used, but effective sampling in turn depends on details of the robot, environment, and task. Our strategy is to learn functions called speciatizers that generate values for continuous operator parameters, given a state description and values for the discrete parameters. Rather than trying to learn a single specializer for each operator from large amounts of data on a single task, we take a modular meta-learning approach. We train on multiple tasks and learn a variety of specializers that, on a new task, can be quickly adapted using relatively little data - thus, our system learns quickly to plan quickly using these specializers. We validate our approach experimentally in simulated 3D pick-and-place tasks with continuous state and action spaces. Visit http://tinyurl.com/chitnis-icra-19 for a supplementary video.


Title: Deep Multi-Sensory Object Category Recognition Using Interactive Behavioral Exploration
Abstract: When identifying an object and its properties, humans use features from multiple sensory modalities produced when manipulating the object. Motivated by this cognitive process, we propose a deep learning methodology for object category recognition which uses visual, auditory, and haptic sensory data coupled with exploratory behaviors (e.g., grasping, lifting, pushing, etc.). In our method, as the robot performs an action on an object, it uses a Tensor-Train Gated Recurrent Unit network to process its visual data, and Convolutional Neural Networks to process haptic and auditory data. We propose a novel strategy to train a single neural network that inputs video, audio and haptic data, and demonstrate that its performance is better than separate neural networks for each sensory modality. The proposed method was evaluated on a dataset in which the robot explored 100 different objects, each belonging to one of 20 categories. While the visual information was the dominant modality for most categories, adding the additional haptic and auditory networks further improves the robot's category recognition accuracy. For some of the behaviors, our approach outperforms the previous published baseline for the dataset which used handcrafted features for each modality. We also show that a robot does not need the sensory data from the entire interaction, but instead can make a good prediction early on during behavior execution.


Title: Sharing the Load: Human-Robot Team Lifting Using Muscle Activity
Abstract: Seamless communication of desired motions and goals is essential for enabling effective physical human-robot collaboration. In such cases, muscle activity measured via surface electromyography (EMG) can provide insight into a person's intentions while minimally distracting from the task. The presented system uses two muscle signals to create a control framework for team lifting tasks in which a human and robot lift an object together. A continuous setpoint algorithm uses biceps activity to estimate changes in the user's hand height, and also allows the user to explicitly adjust the robot by stiffening or relaxing their arm. In addition to this pipeline, a neural network trained only on previous users classifies biceps and triceps activity to detect up or down gestures on a rolling basis; this enables finer control over the robot and expands the feasible workspace. The resulting system is evaluated by 10 untrained subjects performing a variety of team lifting and assembly tasks with rigid and flexible objects.


Title: Position control of medical cable-driven flexible instruments by combining machine learning and kinematic analysis
Abstract: Non-linearities in cable transmissions are important limitations for the accurate control of flexible instruments used in medical endoscopic systems. Hysteresis effects greatly impact the accuracy of conventional kinematic models. This is especially critical for implementing automatic motions in flexible medical robotic systems. In this paper, we propose a method for improving open-loop accuracy of flexible instruments by implementing a Position Inverse Kinematic Model which is able to take into account hysteresis effects. In order to avoid complex physical modeling, the method relies on the off-line learning of the behavior of the instruments. Basic knowledge of the kinematic is also incorporated in the learning process in order to make it fast. The validity of the approach is demonstrated by the execution of 2D and 3D trajectories with the instruments of the STRAS medical robot. The accuracy is shown to be significantly improved with respect to other learning-based methods.


Title: Passive Dynamic Object Locomotion by Rocking and Walking Manipulation
Abstract: This paper presents a novel robotic manipulation technique for transporting objects on the ground in a passive dynamic, nonprehensile manner. The object is manipulated to rock from side to side repeatedly; in the meantime, the force of gravity enables the object to roll along a zigzag path that is eventually heading forward. We call it rock-and-walk object locomotion. First, we examine the kinematics and dynamics of the rocking motion to understand how the states of the object evolve. We then discuss how to control the robot to connect individual rocking motions into a stable gait of the object. Our rock-and-walk object transportation technique is implemented using a conventional manipulator arm and a simple end-effector, interacting with the object in a nonprehensile manner in favor of the passive dynamics of the object. A set of experiments demonstrates successful object locomotion.


Title: Autonomous Latching System for Robotic Boats
Abstract: Autonomous robotic boats are devised to transport people and goods similar to self-driving cars. One of the attractive features specially applied in water environment is to dynamically link and join multiple boats into one unit in order to form floating infrastructure such as bridges, markets or concert stages, as well as autonomously self-detach to perform individual tasks.In this paper we present a novel latching system that enables robotic boats to create dynamic united floating infrastructure while overcoming water disturbances. The proposed latching mechanism is based on the spherical joint (ball and socket) that allows rotation and free movements in two planes at the same time. In this configuration, the latching system is capable to securely and efficiently assemble/disassemble floating structures. The vision-based robot controller guides the self-driving robotic boats to latch with high accuracy in the millimeter range. Moreover, in case the robotic boat fails to latch due to harsh weather, the autonomous latching system is capable to recompute and reposition to latch successfully. We present experimental results from latching and docking in indoor environments. Also, we present results in outdoor environments from latching a couple of robotic boats in open water with calm and turbulent currents.


Title: Streaming Scene Maps for Co-Robotic Exploration in Bandwidth Limited Environments
Abstract: This paper proposes a bandwidth tunable technique for real-time probabilistic scene modeling and mapping to enable co-robotic exploration in communication constrained environments such as the deep sea. The parameters of the system enable the user to characterize the scene complexity represented by the map, which in turn determines the bandwidth requirements. The approach is demonstrated using an underwater robot that learns an unsupervised scene model of the environment and then uses this scene model to communicate the spatial distribution of various high-level semantic scene constructs to a human operator. Preliminary experiments in an artificially constructed tank environment as well as simulated missions over a 10m×10m coral reef using real data show the tunability of the maps to different bandwidth constraints and science interests. To our knowledge this is the first paper to quantity how the free parameters of the unsupervised scene model impact both the scientific utility of and bandwidth required to communicate the resulting scene model.


Title: UWStereoNet: Unsupervised Learning for Depth Estimation and Color Correction of Underwater Stereo Imagery
Abstract: Stereo cameras are widely used for sensing and navigation of underwater robotic systems. They can provide high resolution color views of a scene; the constrained camera geometry enables metrically accurate depth estimation; they are also relatively cost-effective. Traditional stereo vision algorithms rely on feature detection and matching to enable triangulation of points for estimating disparity. However, for underwater applications, the effects of underwater light propagation lead to image degradation, reducing image quality and contrast. This makes it especially challenging to detect and match features, especially from varying viewpoints. Recently, deep learning has shown success in end-to-end learning of dense disparity maps from stereo images. Still, many state-of-the-art methods are supervised and require ground truth depth or disparity, which is challenging to gather in subsea environments. Simultaneously, deep learning has also been applied to the problem of underwater image restoration. Again, it is difficult or impossible to gather real ground truth data for this problem. In this work, we present an unsupervised deep neural network (DNN) that takes input raw color underwater stereo imagery and outputs dense depth maps and color corrected imagery of underwater scenes. We leverage a model of the process of underwater image formation, image processing techniques, as well as the geometric constraints inherent to the stereo vision problem to develop a modular network that outperforms existing methods.


Title: A Framework for On-line Learning of Underwater Vehicles Dynamic Models
Abstract: Learning the dynamics of robots from data can help achieve more accurate tracking controllers, or aid their navigation algorithms. However, when the actual dynamics of the robots change due to external conditions, on-line adaptation of their models is required to maintain high fidelity performance. In this work, a framework for on-line learning of robot dynamics is developed to adapt to such changes. The proposed framework employs an incremental support vector regression method to learn the model sequentially from data streams. In combination with the incremental learning, strategies for including and forgetting data are developed to obtain better generalization over the whole state space. The framework is tested in simulation and real experimental scenarios demonstrating its adaptation capabilities to changes in the robot's dynamics.


Title: Incorporating End-to-End Speech Recognition Models for Sentiment Analysis
Abstract: Previous work on emotion recognition demonstrated a synergistic effect of combining several modalities such as auditory, visual, and transcribed text to estimate the affective state of a speaker. Among these, the linguistic modality is crucial for the evaluation of an expressed emotion. However, manually transcribed spoken text cannot be given as input to a system practically. We argue that using ground-truth transcriptions during training and evaluation phases leads to a significant discrepancy in performance compared to real-world conditions, as the spoken text has to be recognized on the fly and can contain speech recognition mistakes. In this paper, we propose a method of integrating an automatic speech recognition (ASR) output with a character-level recurrent neural network for sentiment recognition. In addition, we conduct several experiments investigating sentiment recognition for human-robot interaction in a noise-realistic scenario which is challenging for the ASR systems. We quantify the improvement compared to using only the acoustic modality in sentiment recognition. We demonstrate the effectiveness of this approach on the Multimodal Corpus of Sentiment Intensity (MOSI) by achieving 73,6% accuracy in a binary sentiment classification task, exceeding previously reported results that use only acoustic input. In addition, we set a new state-of-the-art performance on the MOSI dataset (80.4% accuracy, 2% absolute improvement).


Title: Improved Optical Flow for Gesture-based Human-robot Interaction
Abstract: Gesture interaction is a natural way of communicating with a robot as an alternative to speech. Gesture recognition methods leverage optical flow in order to understand human motion. However, while accurate optical flow estimation (i.e., traditional) methods are costly in terms of runtime, fast estimation (i.e., deep learning) methods' accuracy can be improved. In this paper, we present a pipeline for gesture-based human-robot interaction that uses a novel optical flow estimation method in order to achieve an improved speed-accuracy trade-off. Our optical flow estimation method introduces four improvements to previous deep learning-based methods: strong feature extractors, attention to contours, midway features, and a combination of these three. This results in a better understanding of motion, and a finer representation of silhouettes. In order to evaluate our pipeline, we generated our own dataset, MIBURI, which contains gestures to command a house service robot. In our experiments, we show how our method improves not only optical flow estimation, but also gesture recognition, offering a speed-accuracy trade-off more realistic for practical robot applications.


Title: Decentralization of Multiagent Policies by Learning What to Communicate
Abstract: Effective communication is required for teams of robots to solve sophisticated collaborative tasks. In practice it is typical for both the encoding and semantics of communication to be manually defined by an expert; this is true regardless of whether the behaviors themselves are bespoke, optimization based, or learned. We present an agent architecture and training methodology using neural networks to learn task-oriented communication semantics based on the example of a communication-unaware expert policy. A perimeter defense game illustrates the system's ability to handle dynamically changing numbers of agents and its graceful degradation in performance as communication constraints are tightened or the expert's observability assumptions are broken.


Title: Acquisition of Word-Object Associations from Human-Robot and Human-Human Dialogues
Abstract: Past work on acquisition of word-object associations in robots has focused on either fast instruction-based methods which accept highly constrained input or gradual cross-situational learning methods, but not a mixture of both. In this paper, we present an integrated robotic system which allows for a combination of these methods to contribute to the task of learning the labels of objects in AI agents. We demonstrate the expanded word learning capabilities in the outcome system and how learning from both human-human and human-robot dialogues can be achieved in one integrated system.


Title: Robot Object Referencing through Legible Situated Projections
Abstract: The ability to reference objects in the environment is a key communication skill that robots need for complex, task-oriented human-robot collaborations. In this paper we explore the use of projections, which are a powerful communication channel for robot-to-human information transfer as they allow for situated, instantaneous, and parallelized visual referencing. We focus on the question of what makes a good projection for referencing a target object. To that end, we mathematically formulatelegibility of projections intended to reference an object, and propose alternative arrow-object match functions for optimally computing the placement of an arrow to indicate a target object in a cluttered scene. We implement our approach on a PR2 robot with a head-mounted projector. Through an online (48 participants) and an in-person (12 participants) user study we validate the effectiveness of our approach, identify the types of scenes where projections may fail, and characterize the differences between alternative match functions.


Title: Underwater Communication Using Full-Body Gestures and Optimal Variable-Length Prefix Codes
Abstract: In this paper we consider inter-robot communication in the context of joint activities. In particular, we focus on convoying and passive communication for radio-denied environments by using whole-body gestures to provide cues regarding future actions. We develop a communication protocol whereby information described by codewords is transmitted by a series of actions executed by a swimming robot. These action sequences are chosen to optimize robustness and transmission duration given the observability, natural activity of the robot and the frequency of different messages. Our approach uses a convolutional network to make core observations of the pose of the robot being tracked, which is sending messages. The observer robot then uses an adaptation of classical decoding methods to infer a message that is being transmitted. The system is trained and validated using simulated data, tested in the pool and is targeted for deployment in the open ocean. Our decoder achieves.94 precision and.66 recall on real footage of robot gesture execution recorded in a swimming pool.


Title: WISDOM: WIreless Sensing-assisted Distributed Online Mapping
Abstract: Spatial sensing is a fundamental requirement for applications in robotics and augmented reality. In urban spaces such as malls, airports, apartments, and others, it is quite challenging for a single robot to map the whole environment. So, we employ a swarm of robots to perform the mapping. One challenge with this approach is merging sub-maps built by each robot. In this work, we use wireless access points, which are ubiquitous in most urban spaces, to provide us with coarse orientation between sub-maps, and use a custom ICP algorithm to refine this orientation to merge them. We demonstrate our approach with maps from a building on campus and evaluate it using two metrics. Our results show that, in the building we studied, we can achieve an average Absolute Trajectory error of 0.2m in comparison to a map created by a single robot and average Root Mean Square mapping error of 1.3m from ground truth landmark locations.


Title: UAV/UGV Autonomous Cooperation: UAV assists UGV to climb a cliff by attaching a tether
Abstract: This paper proposes a novel cooperative system for an Unmanned Aerial Vehicle (UAV) and an Unmanned Ground Vehicle (UGV) which utilizes the UAV not only as a flying sensor but also as a tether attachment device. Two robots are connected with a tether, allowing the UAV to anchor the tether to a structure located at the top of a steep terrain, impossible to reach for UGVs. Thus, enhancing the poor traversability of the UGV by not only providing a wider range of scanning and mapping from the air, but also by allowing the UGV to climb steep terrains with the winding of the tether. In addition, we present an autonomous framework for the collaborative navigation and tether attachment in an unknown environment. The UAV employs visual inertial navigation with 3D voxel mapping and obstacle avoidance planning. The UGV makes use of the voxel map and generates an elevation map to execute path planning based on a traversability analysis. Furthermore, we compared the pros and cons of possible methods for the tether anchoring from multiple points of view. To increase the probability of successful anchoring, we evaluated the anchoring strategy with an experiment. Finally, the feasibility and capability of our proposed system were demonstrated by an autonomous mission experiment in the field with an obstacle and a cliff.


Title: Sound-Indicated Visual Object Detection for Robotic Exploration
Abstract: Robots are usually equipped with microphones and cameras to perceive and understand the physical world. Though visual object detection technology has achieved great success, the detection in other modalities remains unsolved. In this paper, we establish a novel robotic sound-indicated visual object detection framework, and develop a two-stream weakly-supervised deep learning architecture to connect the visual and audio modalities for localizing the sounding object. A dataset is constructed from the AudioSet to validate the proposed method and some promising applications are demonstrated on robotic platforms.


Title: Proximity Human-Robot Interaction Using Pointing Gestures and a Wrist-mounted IMU
Abstract: We present a system for interaction between co-located humans and mobile robots, which uses pointing gestures sensed by a wrist-mounted IMU. The operator begins by pointing, for a short time, at a moving robot. The system thus simultaneously determines: that the operator wants to interact; the robot they want to interact with; and the relative pose among the two. Then, the system can reconstruct pointed locations in the robot's own reference frame, and provide real-time feedback about them so that the user can adapt to misalignments. We discuss the challenges to be solved to implement such a system and propose practical solutions, including variants for fast flying robots and slow ground robots. We report different experiments with real robots and untrained users, validating the individual components and the system as a whole.


Title: Air-to-Ground Surveillance Using Predictive Pursuit
Abstract: This paper introduces a probabilistic prediction model with a novel variant of the Markov decision process to improve tracking time and location detection accuracy in an air-to-ground robot surveillance scenario. While most surveillance algorithms focus mainly on controls of an unmanned aerial vehicle (UAV) and camera for faster tracking of an unmanned ground vehicle (UGV), this paper proposes a way of minimizing detection and tracking time by applying a prediction model to the first observed path taken by the UGV. We present a pursuit algorithm that addresses the problem of target (UGV) localization by combining prediction of used planning algorithm by the target, and application of the same planning algorithm to predict future trajectories. Our results show a high predictive accuracy based on a final position attained by the target and the location predicted by our model.


Title: Online Planning for Target Object Search in Clutter under Partial Observability
Abstract: The problem of finding and grasping a target object in a cluttered, uncertain environment, target object search, is a common and important problem in robotics. One key challenge is the uncertainty of locating and recognizing each object in a cluttered environment due to noisy perception and occlusions. Furthermore, the uncertainty in localization makes manipulation difficult and uncertain. To cope with these challenges, we formulate the target object search task as a partially observable Markov decision process (POMDP), enabling the robot to reason about perceptual and manipulation uncertainty while searching. To further address the manipulation difficulty, we propose Parameterized Action Partially Observable Monte-Carlo Planning (PA-POMCP), an algorithm that evaluates manipulation actions by taking into account the effect of the robot's current belief on the success of the action execution. In addition, a novel run-time initial belief generator and a state value estimator are introduced in this paper to facilitate the PA-POMCP algorithm. Our experiments show that our methods solve the target object search task in settings where simpler methods either take more object movements or fail.


Title: Data-Driven Contact Clustering for Robot Simulation
Abstract: We propose a novel data-driven learning-based contact clustering (i.e., of contact points and contact normals) framework for rigid-body robot simulation, with its accuracy established/verified by real experimental data. We first construct an experimental robotic setup with force/torque (F/T) sensors to collect real contact motion/force data. We then design a multilayer perceptron (MLP) network for the contact clustering based on the full motion and force/torque information of the contacts. We also adopt the constraint-based optimization contact solver to facilitate the learning of our MLP network during the training. Our proposed data-driven/learning-based contact clustering framework is then verified against the experimental setup, compared with other techniques/simulators and shown to significantly (or meaningfully) enhance the accuracy of contact simulation as compared to them.


Title: Pavilion: Bridging Photo-Realism and Robotics
Abstract: Simulation environments play a centric role in the research of sensor fusion and robot control. This paper presents Pavilion, a novel open-source simulation system, for robot perception and kinematic control based on the Unreal Engine and the Robot Operating System (ROS). The novelty of this work includes threefold: (1) developing a shader-based method to generate optical flow ground-truth data with the Unreal Engine, (2) developing a toolset to remove binary incompatibility between ROS and the Unreal Engine to enable real-time interaction, and (3) developing a method to directly import Simulation Description Format (SDF) robot models into the Unreal Engine at runtime. Finally, a Gazebo-compatible real-time simulation system is developed to enable training and evaluation of a large number of sensor fusion, planning, decision and control algorithms. The system can be implemented on both Linux and macOS, with the latest version of ROS. Various experiments have been performed to validate the superior performance of the proposed simulation environment over other state-of-the-art simulators in terms of number of modalities, simulation accuracy, latency and degree of integration difficulty.


Title: A Real-Time Interactive Augmented Reality Depth Estimation Technique for Surgical Robotics
Abstract: Augmented reality (AR) is a promising technology where the surgeon can see the medical abnormality in the context of the patient. It makes the anatomy of interest visible to the surgeon which otherwise is not visible. It can result in better surgical precision and therefore, potentially better surgical outcomes and faster recovery times. Despite these benefits, the current AR systems suffer from two major challenges; first, incorrect depth perception and, second, the lack of suitable evaluation systems. Therefore, in the current paper we addressed both of these problems. We proposed a color depth encoding (CDE) technique to estimate the distance between the tumor and the tissue surface using a surgical instrument. We mapped the distance between the tumor and the tissue surface to the blue-red color spectrum. For evaluation and interaction with our AR technique, we propose to use a virtual surgical instrument method using the CAD model of the instrument. The users were asked to reach the judged distance in the surgical field using the virtual tool. Realistic tool movement was simulated by collecting the forward kinematics joint encoder data. The results showed significant improvement in depth estimation, time for task completion and confidence, using our CDE technique with and without stereo versus other two cases, that are, Stereo-No CDE and No Stereo-No CDE.


Title: Customizing Object Detectors for Indoor Robots
Abstract: Object detection models based on convolutional neural networks (CNNs) demonstrate impressive performance when trained on large-scale labeled datasets. While a generic object detector trained on such a dataset performs adequately in applications where the input data is similar to user photographs, the detector performs poorly on small objects, particularly ones with limited training data or imaged from uncommon viewpoints. Also, a specific room will have many objects that are missed by standard object detectors, frustrating a robot that continually operates in the same indoor environment.This paper describes a system for rapidly creating customized object detectors. Data is collected from a quadcopter that is teleoperated with an interactive interface. Once an object is selected, the quadcopter autonomously photographs the object from multiple viewpoints to collect data to train DUNet (Dense Upscaled Network), our proposed model for learning customized object detectors from scratch given limited data. Our experiments compare the performance of learning models from scratch with DUNet vs. fine tuning existing state of the art object detectors, both on our indoor robotics domain and on standard datasets.


Title: Semi Supervised Deep Quick Instance Detection and Segmentation
Abstract: In this paper, we present a semi supervised deep quick learning framework for instance detection and pixelwise semantic segmentation of images in a dense clutter of items. The framework can quickly and incrementally learn novel items in an online manner by real-time data acquisition and generating corresponding ground truths on its own. To learn various combinations of items, it can synthesize cluttered scenes, in real time. The overall approach is based on the tutor-child analogy in which a deep network (tutor) is pretrained for class-agnostic object detection which generates labeled data for another deep network (child). The child utilizes a customized convolutional neural network head for the purpose of quick learning. There are broadly four key components of the proposed framework: semi supervised labeling, occlusion aware clutter synthesis, a customized convolutional neural network head, and instance detection. The initial version of this framework was implemented during our participation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked 3rd rd, 4th and 5 th worldwide in pick, stow-pick and stow task respectively. The proposed framework is an improved version over ARC'17 where novel features such as instance detection and online learning has been added.


Title: Guaranteed Active Constraints Enforcement on Point Cloud-approximated Regions for Surgical Applications
Abstract: In this work, a passive physical human-robot interaction (pHRI) controller is proposed to intraoperatively ensure that sensitive tissues will not be damaged by the robot's tool. The proposed scheme uses the point cloud of the restricted region's surface as constraint definition and Artificial Potential fields for constraint enforcement. The controller is proven to be passive with respect to the interaction force and to guarantee constraint satisfaction in all cases. The proposed methodology is experimentally validated by the kinesthetic guidance of a KUKA LWR4+ robot's end-effector driving a virtual slave KUKA in the vicinity of a 3D point-cloud of a kidney and its adjacent vessels.


Title: Sleeve Pneumatic Artificial Muscles for Antagonistically Actuated Joints
Abstract: Pneumatic artificial muscles (PAMs) have been researched for applications in powered exoskeletons, orthosis and robotics. Their high force to mass ratio, low cost and inherent compliance are particularly advantageous for systems requiring physical interaction with humans.Sleeve PAMs, which introduce an internal structure to the actuator, offer improved force capacity, contraction ratio, efficiency and operating bandwidth. In this paper sleeve PAMs are applied to a popular muscle configuration; that of a joint operated antagonistically by two muscles. It is shown that the sleeve PAM can increases the range of joint rotation by 14% or load capacity by over 50% of that of a comparable joint actuated with traditional PAMs, depending on the joint configuration. The stiffness of joints actuated with both PAM types is also studied, particularly the case of closed system operation (mass of air in the PAMs is constant), where the reduced volume of the sleeve PAM significantly increases the observed stiffness. Finally energy consumption is considered, showing substantial savings in the case of joints actuated with sleeve PAMs.


Title: Sensing Shear Forces During Food Manipulation: Resolving the Trade-Off Between Range and Sensitivity
Abstract: Autonomous assistive feeding systems need to acquire deformable food items of varying physical characteristics to be able to feed users. However, bite acquisition of these deformable food items is challenging without force feedback of appropriate range and sensitivity. We developed custom solutions using two widely-used shear sensing fingertip tactile sensors and calibrated them to the range of forces needed for manipulating food items. We compared their performance with traditional force/torque sensors and showed the trade-off between the range and the sensitivity of the fingertip tactile sensors in detecting potential bite acquisition successes for food items with widely varying weights and compliance. We then developed a control policy, using which a robotic gripper equipped with the fingertip tactile sensors can autonomously regulate the sensing range and the sensitivity to be able to skewer food items of different compliance and detect their bite acquisition success attempts.


Title: Benchmarking Resilience of Artificial Hands
Abstract: The deployment of robotics in real-world scenarios, which may involve harsh and irregular physical interactions with the environment, such as those when robots operating in a disaster scenario, or the interactions that prosthetic devices may experience, demands hardware, which is physically resilient. The end-effectors, as the main media of interaction, are probably the parts at the highest risk. The capability of robotic hands to survive severe impacts is thus a necessity for the effective deployment of reliable robotic solutions in real-world tasks. Although, this robustness capability has been noted and discussed in the robotics community for long time, the literature does not provide a systematic study nor there is any proposal of standardized test or metric to evaluate hand resilience. In this work, inspired by the works of Charpy and Izod for the systematic definition of resilience and toughness of materials through impact tests, we consider extending the standard test to robot hands. We introduce a resilience evaluation framework, including a precisely defined experimental set-up and test procedure. As an example of application of the procedure, we apply it to experimentally characterize two robot hands, with a similar conceptual architecture but different size and material. From these tests we obtain several insights, including the observation that the dominant factor in hand resilience is their compliance and actuation principle, and that the use, under certain design conditions, of lightweight materials, such as plastic instead of aluminum, may not necessarily reduce the mechanical strength of the overall system.


Title: CHiMP: A Contact based Hilbert Map Planner
Abstract: This work presents a new contact-based 3D path planning approach for manipulators using robot skin. We make use of the Stochastic Functional Gradient Path Planner, extending it to the 3D case, and assess its usefulness in combination with multi-modal robot skin. Our proposed algorithm is verified on a 6 DOF robot arm that has been covered with multi-modal robot skin. The experimental platform is combined with a skin based compliant controller, making the robot inherently reactive. We implement different state-of-the-art planners within our contact-based robot system to compare their performance under the same conditions. In this way, all the planners use the same skin compliant control during evaluation. Furthermore, we extend the stochastic planner with tactile-based explorative behavior to improve its performance, especially for unknown environments. We show that CHiMP is able to outperform state of the art algorithms when working with skin-based sparse contact data.


Title: A Novel Reconfigurable Revolute Joint with Adjustable Stiffness
Abstract: In this paper, a novel revolute joint of adjustable stiffness with reconfigurability (JASR) is presented. The JASR is designed with zero-length base link four-bar linkage, and allows adjusting its stiffness to achieve soft- and hard-spring behaviour. The new joint has a compact and light-weight structure and can be integrated in robot and transmissions for different applications. In the paper, mathematical models are developed for the JASR, with which influences of design parameters on stiffness performance are analyzed. A prototype of JASR is constructed and preliminary test results demonstrate the compliance properties of the new joint.


Title: A novel force sensor with zero stiffness at contact transition based on optical line generation
Abstract: Robotization of medical acts often requires the evaluation of contacts between a robotic system and a patient, for safety or efficiency reasons. When contact occurs with a stiff environment, instabilities and vibrations can appear and a passive compliance is therefore needed. In this paper, we propose to embed compliance in a force sensor and to develop a novel force sensor with large compliance, i.e. a zero stiffness at contact transition to ease robot control. To get at the same time a satisfying measurement range and low off-axis sensitivity, an optical measurement process based on an optical line generated thanks to additive manufacturing is exploited. A compliant sensor body allowing the desired stiffness profile is presented and the specific optical measurement technique is developed. Finally, a prototype of the proposed force sensor is evaluated experimentally.


Title: Hydraulically-actuated compliant revolute joint for medical robotic systems based on multimaterial additive manufacturing
Abstract: In this paper, an active compliant revolute joint actuated by hydraulic energy is developed. The joint is made of polymer for integration in medical robotic systems, even in a challenging environment such as Magnetic Resonance Imaging (MRI). The use of multimaterial additive manufacturing allows us to develop two original aspects. First, a new seal design is proposed to build miniature hydraulic cylinders embedded in the active joint, with low level of friction. Second, a rack-and-pinion mechanism is being integrated to a compliant revolute joint to obtain a high level of compactness. Design and experimental assessment of the hydraulic cylinder and the compliant joint with embedded rack-and-pinion are presented, as well as an illustration in the context of needle manipulation with passive teleoperation.


Title: Model-Based On-line Estimation of Time-Varying Nonlinear Joint Stiffness on an e-Series Universal Robots Manipulator
Abstract: Flexibility commonly exists in the joints of many industrial robots due to the elasticity of the lightweight strain-wave type transmissions being used. This leads to a dynamic time-varying displacement between the position of the drive actuator and that of the driven link. Furthermore, the joint flexibility changes with time due to the material slowly being worn off at the gear meshing. Knowing the stiffness of the robot joints is of great value, e.g. in the design of new model-based feedforward and feedback controllers, and for predictive maintenance in the case of gearing unit failure. In this paper, we address on-line estimation of robot joint stiffness using a recursive least squares strategy based on a parametric model taking into account the elastic torques' nonlinear dependency on transmission deformation. Robustness is achieved in the presence of measurement noise and in poor excitation conditions. The method can be easily extended to general classes of serial-link multi-degree-of-freedom robots. The estimation technique uses only feedback signals that are readily available on Universal Robots' e-Series manipulators. Experiments on the new UR5e manipulator demonstrate the effectiveness of the proposed method.


Title: A Rolling Flexure Mechanism for Progressive Stiffness Actuators
Abstract: Linear Series Elastic Actuators exhibit a restricted design space. This inevitably leads to design trade-offs translating into robot performance limitations. These prevent robots from eventually reaching human comparable soft but also powerful physical interaction performance.This work presents a novel fixed passive rolling flexure design principle enabling the realization of a wide range of progressive torque-deflection characteristics. The proposed principle displays low hysteresis and can be manufactured in single 2D components. The paper derives the analytic foundation for the rolling flexure principle and is supported by numerical finite element analysis. The theory is validated by experimental results obtained on two laboratory prototypes.


Title: Locomotion Dynamics of a Miniature Wave-Like Robot, Modeling and Experiments
Abstract: In a recent study, we developed a minimally actuated wave-like robot and analyzed its kinematics. In this paper, we present the dynamic locomotion analysis of a miniature version of this wave robot. We examine different crawling environments, determine under which conditions it can advance, and evaluate its propulsion force. We first developed two locomotion models to characterize the cases where the robot is crawling between two straight surfaces or over a single flat surface. We specified the conditions in which the robot will advance and the advance time ratio as a function of the friction forces and weight of the robot. Next, we developed highly flexible tube-like shapes that we molded from silicone rubber to experimentally test the forces acting on the robot inside these tubes. Finally, we designed a miniature model of the robot and experimentally validated its crawling conditions (see video).


Title: Fabric Soft Poly-Limbs for Physical Assistance of Daily Living Tasks
Abstract: This paper presents the design and development of a highly articulated, continuum, wearable, fabric-based Soft Poly-Limb (fSPL). This fabric soft arm acts as an additional limb that provides the wearer with mobile manipulation assistance through the use of soft actuators made with high-strength inflatable fabrics. In this work, a set of systematic design rules is presented for the creation of highly compliant soft robotic limbs through an understanding of the fabric based components behavior as a function of input pressure. These design rules are generated by investigating a range of parameters through computational finite-element method (FEM) models focusing on the fSPL's articulation capabilities and payload capacity in 3D space. The theoretical motion and payload outputs of the fSPL and its components are experimentally validated as well as additional evaluations verify its capability to safely carry loads 10.1x its body weight, by wrapping around the object. Finally, we demonstrate how the fully collapsible fSPL can comfortably be stored in a soft-waist belt and interact with the wearer through spatial mobility and preliminary pick-and-place control experiments.


Title: A Depth Camera-Based Soft Fingertip Device for Contact Region Estimation and Perception-Action Coupling
Abstract: As the demand for robotic applications in unconstrained and dynamic environments rises, so does the benefit of advancing the state of the art in soft robotic technologies. However, the complex capabilities of soft robots elicited by their high-dimensional, non-linear characteristics simultaneously yield difficult challenges in control and sensing. Moreover, embedding tactile sensing capabilities in soft materials is often expensive and difficult to fabricate. In recent years, however, the invention of small-scale depth-sensing cameras introduced a promising channel for soft tactile sensor design. In this work, we propose a novel soft device inspired by the human fingertip that not only utilizes a small depth camera as the perception mechanism, but also possesses compliance-modulating capabilities. We demonstrate its ability to accurately estimate contact regions upon interaction with an external obstacle, and show that the estimation sensitivity can be modulated via internal fluid states. In addition, we determine an empirical model of the device's force-deformation characteristics under simplifying assumptions, and validate its performance with real-time force matching control experiments.


Title: A Pipe-Climbing Soft Robot
Abstract: This paper presents the design and testing of a bio-inspired soft pneumatic robot that can achieve locomotion along the outside of a cylinder. The robot uses soft pneumatic actuators called FREEs (Fiber Reinforced Elastomeric Enclosure), which can have a wide range of deformation behavior upon pressurization. The robot being soft and compliant can grasp and move along cylinders of varying dimensions. Two different types of FREEs are used in the robot namely (a) extending FREEs and (b) bending FREEs. These actuators are arranged in such a way that the bending actuators are used to grip the pipe while the extending actuators generate forward motion as well as bending for direction control. The modular design of the robot provides simplicity and ease of maintenance. The entire robot is made of flexible actuators and can withstand external impact with minimal to no damage. The maximum speed achieved for horizontal motion is 4.2 mm/s and for vertical motion is 2.1 mm/s.


Title: Support Surface Estimation for Legged Robots
Abstract: The high agility of legged systems allows them to operate in rugged outdoor environments. In these situations, knowledge about the terrain geometry is key for foothold planning to enable safe locomotion. However, on penetrable or highly compliant terrain (e.g. grass) the visibility of the supporting ground surface is obstructed, i.e. it cannot directly be perceived by depth sensors. We present a method to estimate the underlying terrain topography by fusing haptic information about foot contact closure locations with exteroceptive sensing. To obtain a dense support surface estimate from sparsely sampled footholds we apply Gaussian process regression. Exteroceptive information is integrated into the support surface estimation procedure by estimating the height of the penetrable surface layer from discrete penetration depth measurements at the footholds. The method is designed such that it provides a continuous support surface estimate even if there is only partial exteroceptive information available due to shadowing effects. Field experiments with the quadrupedal robot ANYmal show how the robot can smoothly and safely navigate in dense vegetation.


Title: ALMA - Articulated Locomotion and Manipulation for a Torque-Controllable Robot
Abstract: The task of robotic mobile manipulation poses several scientific challenges that need to be addressed to execute complex manipulation tasks in unstructured environments, in which collaboration with humans might be required. Therefore, we present ALMA, a motion planning and control framework for a torque-controlled quadrupedal robot equipped with a six degrees of freedom robotic arm capable of performing dynamic locomotion while executing manipulation tasks. The online motion planning framework, together with a whole-body controller based on a hierarchical optimization algorithm, enables the system to walk, trot and pace while executing operational space end-effector control, reactive human-robot collaboration and torso posture optimization to increase the arm's workspace. The torque control of the whole system enables the implementation of compliant behavior, allowing a user to safely interact with the robot. We verify our framework on the real robot by performing tasks such as opening a door and carrying a payload together with a human.


Title: Real-time Model Predictive Control for Versatile Dynamic Motions in Quadrupedal Robots
Abstract: This paper presents a new Model Predictive Control (MPC) framework for controlling various dynamic movements of a quadrupedal robot. System dynamics are represented by linearizing single rigid body dynamics in three-dimensional (3D) space. Our formulation linearizes rotation matrices without resorting to parameterizations like Euler angles and quaternions, avoiding issues of singularity and unwinding phenomenon, respectively. With a carefully chosen configuration error function, the MPC control law is transcribed into a Quadratic Program (QP) which can be solved efficiently in realtime. Our formulation can stabilize a wide range of periodic quadrupedal gaits and acrobatic maneuvers. We show various simulation as well as experimental results to validate our control strategy. Experiments prove the application of this framework with a custom QP solver could reach execution rates of 160 Hz on embedded platforms.


Title: Scanning the Internet for ROS: A View of Security in Robotics Research
Abstract: Security is particularly important in robotics, as robots can directly perceive and affect the physical world. We describe the results of a scan of the entire IPv4 address space of the Internet for instances of the Robot Operating System (ROS), a widely used robotics software platform. We identified a number of hosts supporting ROS that are exposed to the public Internet, thereby allowing anyone to access robotic sensors and actuators. As a proof of concept, and with the consent of the relevant researchers, we were able to read image sensor information from and actuate a physical robot present in a research lab in an American university. This paper gives an overview of our findings, including our methodology, the geographic distribution of publicly-accessible platforms, the sorts of sensor and actuator data that is available, and the different kinds of robots and sensors that our scan uncovered. Additionally, we offer recommendations on best practices to mitigate these security issues in the future.


Title: Risk Averse Robust Adversarial Reinforcement Learning
Abstract: Deep reinforcement learning has recently made significant progress in solving computer games and robotic control tasks. A known problem, though, is that policies overfit to the training environment and may not avoid rare, catastrophic events such as automotive accidents. A classical technique for improving the robustness of reinforcement learning algorithms is to train on a set of randomized environments, but this approach only guards against common situations. Recently, robust adversarial reinforcement learning (RARL) was developed, which allows efficient applications of random and systematic perturbations by a trained adversary. A limitation of RARL is that only the expected control objective is optimized; there is no explicit modeling or optimization of risk. Thus the agents do not consider the probability of catastrophic events (i.e., those inducing abnormally large negative reward), except through their effect on the expected objective. In this paper we introduce risk-averse robust adversarial reinforcement learning (RARARL), using a risk-averse protagonist and a risk-seeking adversary. We test our approach on a self-driving vehicle controller. We use an ensemble of policy networks to model risk as the variance of value functions. We show through experiments that a risk-averse agent is better equipped to handle a risk-seeking adversary, and experiences substantially fewer crashes compared to agents trained without an adversary. Supplementary materials are available at https://sites.google.com/view/rararl.


Title: Bounded Collision Force by the Sobolev Norm
Abstract: A robot making contact with an environment or human presents potential safety risks, including excessive collision force. While experiments on the effect of robot inertia, relative velocity, and interface stiffness on collision are in literature, analytical models for maximum collision force are limited to a simplified mass-spring robot model. This simplified model limits the analysis of control (force/torque, impedance, or admittance) or compliant robots (joint and end-effector compliance). Here, the Sobolev norm is adapted to be a system norm, giving rigorous bounds on the maximum force on a stiffness element in a general dynamic system, allowing the study of collision with more accurate models and feedback control. The Sobolev norm can be found through the H2 norm of a transformed system, allowing efficient computation, connection with existing control theory, and controller synthesis to minimize collision force. The Sobolev norm is validated, first experimentally with an admittance-controlled robot, then in simulation with a linear flexible-joint robot. It is then used to investigate the impact of control, joint flexibility and end-effector compliance on collision, and a trade-off between collision performance and environmental estimation uncertainty is shown.


Title: Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning
Abstract: Safety analysis is a necessary component in the design and deployment of autonomous robotic systems. Techniques from robust optimal control theory, such as Hamilton-Jacobi reachability analysis, allow a rigorous formalization of safety as guaranteed constraint satisfaction. Unfortunately, the computational complexity of these tools for general dynamical systems scales poorly with state dimension, making existing tools impractical beyond small problems. Modern reinforcement learning methods have shown promising ability to find approximate yet proficient solutions to optimal control problems in complex and high-dimensional systems, however their application has in practice been restricted to problems with an additive payoff over time, unsuitable for reasoning about safety. In recent work, we introduced a time-discounted modification of the problem of maximizing the minimum payoff over time, central to safety analysis, through a modified dynamic programming equation that induces a contraction mapping. Here, we show how a similar contraction mapping can render reinforcement learning techniques amenable to quantitative safety analysis as tools to approximate the safe set and optimal safety policy. This opens a new avenue of research connecting control-theoretic safety analysis and the reinforcement learning domain. We validate the correctness of our formulation by comparing safety results computed through Q-learning to analytic and numerical solutions, and demonstrate its scalability by learning safe sets and control policies for simulated systems of up to 18 state dimensions using value learning and policy gradient techniques.


Title: A Friction-Based Kinematic Model for Skid-Steer Wheeled Mobile Robots
Abstract: Skid-steer drive systems are widely used in mobile robot platforms. Such systems are subject to significant slippage and skidding during normal operation due to their nature. The ability to predict and compensate for such slippages in the forward kinematics of these types of robots is of great importance and provides the means for accurate control and safe navigation. In this work, we propose a new kinematic model capable of slip prediction for skid-steer wheeled mobile robots (SSWMRs). The proposed model outperforms the state-of-the-art in terms of both translational and rotational prediction error on a dataset composed of more than 6 km worth of trajectories traversed by a skid-steer robot. We also publicly release our dataset to serve as a benchmark for system identification and model learning research for SSWMRs.


Title: Modeling and state estimation of a Micro Ball-balancing Robot using a high yaw-rate dynamic model and an Extended Kalman Filter
Abstract: The state estimation and control of a ball-balancing robot under high yaw rate is a challenging problem due to its highly nonlinear 3D dynamic. The small size and low-cost components in our Micro Ball-Balancing Robot makes the system inherently very noisy which further increases the complexity of the problem. In order to drive the robot more aggressively such as translating and spinning at the same time, a good state estimator which works well under high yaw rates is required. This paper presents the derivation of a high yaw-rate Ball-Balancing Robot dynamic model and the implementation of said model in an Extended Kalman Filter (EKF) using raw on-board sensor measurements. The EKF using the new model is then compared to a Kalman Filter which uses a linearized dynamic model. The accuracy of the attitude estimates and the controller performance under high yaw rates were verified using a motion capture system.


Title: Orientation-Aware Motion Planning in Complex Workspaces using Adaptive Harmonic Potential Fields
Abstract: In this work, a hybrid control scheme is presented in order to address the navigation problem for a planar robotic platform of arbitrary shape that is moving inside an obstacle cluttered workspace. Given an initial and desired robot configuration, we propose a methodology based on approximate configuration space decomposition techniques that makes use of heuristics to adaptively refine a partition of the configuration space into non-overlapping, adjacent slices. Furthermore, we employ appropriate workspace transformations and adaptive potential field based control laws that integrate elegantly with the type of configuration space representation used, in order to safely navigate within a given cell and successfully cross over to the next, for almost all initial configurations, until the desired configuration is reached. Finally, we present simulation results that demonstrate the efficacy of the proposed control scheme.


Title: Energy-Aware Temporal Logic Motion Planning for Mobile Robots
Abstract: This paper presents a methodology for synthesizing a motion plan for a mobile robot to ensure that the robot never gets depleted with battery charge while carrying out its mission successfully. The specification of the robot is provided in the form of an LTL (Linear Temporal Logic) formula. A trajectory satisfying an LTL formula may contain a loop whose repetitive execution causes the depletion of battery charge in the robot. The motion plan generated by our methodology ensures that the robot visits the charging station periodically in such a way that it never gets depleted with battery charge while carrying out its mission optimally. Given a set of potential charging station locations and an LTL specification, our algorithm also finds the best location for the charging station along with the optimal trajectory for the robot. We encode the motion planning problem as an SMT (Satisfiability Modulo Theory) solving problem and use the off-the-shelf SMT solver Z3 to solve the constraints to find the location of the charging station and generate an optimal trajectory for the robot. We apply our methodology to synthesize energy-aware trajectories for robots with different dynamics in various workspaces and for various LTL specifications.


Title: Using Local Experiences for Global Motion Planning
Abstract: Sampling-based planners are effective in many real-world applications such as robotics manipulation, navigation, and even protein modeling. However, it is often challenging to generate a collision-free path in environments where key areas are hard to sample. In the absence of any prior information, sampling-based planners are forced to explore uniformly or heuristically, which can lead to degraded performance. One way to improve performance is to use prior knowledge of environments to adapt the sampling strategy to the problem at hand. In this work, we decompose the workspace into local primitives, memorizing local experiences by these primitives in the form of local samplers, and store them in a database. We synthesize an efficient global sampler by retrieving local experiences relevant to the given situation. Our method transfers knowledge effectively between diverse environments that share local primitives and speeds up the performance dramatically. Our results show, in terms of solution time, an improvement of multiple orders of magnitude in two traditionally challenging high-dimensional problems compared to state-of-the-art approaches.


Title: DMP Based Trajectory Tracking for a Nonholonomic Mobile Robot With Automatic Goal Adaptation and Obstacle Avoidance
Abstract: Dynamic Movement Primitive (DMP) which is popular for motion planning of a robot manipulator, has been adapted for a nonholonomic mobile robot to track the desired trajectory. DMP is a simple damped spring model with a forcing function, which learns the trajectory. The damped spring model attracts the robot towards the goal position, and the forcing function forces the robot to follow the given trajectory. Two Radial Basis Function Networks (RBFNs) have been used to learn the forcing function associated with the DMP model. Weight update laws are derived using the gradient descent approach to train the RBFNs. Fuzzy logic based steering angle dynamics is proposed to handle the asymmetric nature of an obstacle. The proposed scheme is capable enough to generate a smooth trajectory in the presence of an obstacle even when start and goal positions are altered, without losing the spatial information embedded while training. The convergence of the robot goal position has been shown using Lyapunov stability theory-based analysis. The approach has been extended to multiple static and dynamic obstacles for the successful convergence of the robot at the goal position. Both simulation and experimental results are provided to confirm the efficacy of the proposed scheme.


Title: Predictive Collision Avoidance for the Dynamic Window Approach
Abstract: Foresighted navigation is an essential skill for robots to rise from rigid factory floor installations to much more versatile mobile robots that partake in our everyday environment. The current state of the art that provides this mobility to some extent is the Dynamic Window Approach combined with a global start-to-target path planner. However, neither the Dynamic Window Approach nor the path planner are equipped to predict the motion of other objects in the environment. We propose a change in the Dynamic Window Approach-a dynamic collision model-that is capable of predicting future collisions with the environment by also taking into account the motion of other objects. We show in simulated experiments that our new way of computing the Dynamic Window Approach significantly reduces the number of collisions in a dynamic setting with nonholonomic vehicles while still being computationally efficient.


Title: Kinematic Constraints Based Bi-directional RRT (KB-RRT) with Parameterized Trajectories for Robot Path Planning in Cluttered Environment
Abstract: Optimal path planning and smooth trajectory planning are critical for effective navigation of mobile robots working towards accomplishing complex missions. For autonomous, real time and extended operations of mobile robots, the navigation capability needs to be executed at the edge. Thus, efficient compute, minimum memory utilization and smooth trajectory are the key parameters that drive the successful operation of autonomous mobile robots. Traditionally, navigation solutions focus on developing robust path planning algorithms which are complex and compute/memory intensive. Bidirectional-RRT(Bi-RRT) based path planning algorithms have gained increased attention due to their effectiveness and computational efficiency in generating feasible paths. However, these algorithms neither optimize memory nor guarantee smooth trajectories. To this end, we propose a kinematically constrained Bi-RRT (KB-RRT) algorithm, which restricts the number of nodes generated without compromising on the accuracy and incorporates kinodynamic constraints for generating smooth trajectories, together resulting in efficient navigation of autonomous mobile robots. The proposed algorithm is tested in a highly cluttered environment on an Ackermannsteering vehicle model with severe kinematic constraints. The experimental results demonstrate that KB-RRT achieves three times (3 X) better performance in terms of convergence rate and memory utilization compared to a standard Bi-RRT algorithm.


Title: OVPC Mesh: 3D Free-space Representation for Local Ground Vehicle Navigation
Abstract: This paper presents a novel approach for local 3D environment representation for autonomous unmanned ground vehicle (UGV) navigation called On Visible Point Clouds Mesh (OVPC Mesh). Our approach represents the surrounding of the robot as a watertight 3D mesh generated from local point cloud data in order to represent the free space surrounding the robot. It is a conservative estimation of the free space and provides a desirable trade-off between representation precision and computational efficiency, without having to discretize the environment into a fixed grid size. Our experiments analyze the usability of the approach for UGV navigation in rough terrain, both in simulation and in a fully integrated real-world system. Additionally, we compare our approach to well-known state-of the-art solutions, such as Octomap and Elevation Mapping and show that OVPC Mesh can provide reliable 3D information for trajectory planning while fulfilling real-time constraints.


Title: Generation of Synchronized Configuration Space Trajectories of Multi-Robot Systems
Abstract: We pose the problem of path-constrained trajectory generation for the synchronous motion of multi-robot systems as a non-linear optimization problem. Our method determines appropriate parametric representation for the configuration variables, generates an approximate solution as a starting point for the optimization method, and uses successive refinement techniques to solve the problem in a computationally efficient manner. We have demonstrated the effectiveness of the proposed method on challenging simulation and physical experiments with high degrees of freedom robotic systems.


Title: REPLAB: A Reproducible Low-Cost Arm Benchmark for Robotic Learning
Abstract: Standardized evaluation measures have aided in the progress of machine learning approaches in disciplines such as computer vision and machine translation. In this paper, we make the case that robotic learning would also benefit from benchmarking, and present a template for a vision-based manipulation benchmark. Our benchmark is built on “REPLAB,” a reproducible and self-contained hardware stack (robot arm, camera, and workspace) that costs about 2000 USD and occupies a cuboid of size 70x40x60 cm. Each REPLAB cell may be assembled within a few hours. Through this low-cost, compact design, REPLAB aims to drive wide participation by lowering the barrier to entry into robotics and to enable easy scaling to many robots. We envision REPLAB as a framework for reproducible research across manipulation tasks, and as a step in this direction, we define a grasping benchmark consisting of a task definition, evaluation protocol, performance measures, and a dataset of over 50,000 grasp attempts. We implement, evaluate, and analyze several previously proposed grasping approaches to establish baselines for this benchmark. Project page with assembly instructions, additional details, and videos: https://goo.gl/5F9dP4.


Title: Stable Bin Packing of Non-convex 3D Objects with a Robot Manipulator
Abstract: Recent progress in the field of robotic manipulation has generated interest in fully automatic object packing in warehouses. This paper proposes a formulation of the packing problem that is tailored to the automated warehousing domain. Besides minimizing waste space inside a container, the problem requires stability of the object pile during packing and the feasibility of the robot motion executing the placement plans. To address this problem, a set of constraints are formulated, and a constructive packing pipeline is proposed to solve these constraints. The pipeline is able to pack geometrically complex, non-convex objects while satisfying stability and robot packability constraints. In particular, a new 3D positioning heuristic called Heightmap-Minimization heuristic is proposed, and heightmaps are used to speed up the search. Experimental evaluation of the method is conducted with a realistic physical simulator on a dataset of scanned real-world items, demonstrating stable and high-quality packing plans compared with other 3D packing methods.


Title: A Constraint Programming Approach to Simultaneous Task Allocation and Motion Scheduling for Industrial Dual-Arm Manipulation Tasks
Abstract: Modern lightweight dual-arm robots bring the physical capabilities to quickly take over tasks at typical industrial workplaces designed for workers. Low setup times - including the instructing/specifying of new tasks - are crucial to stay competitive. We propose a constraint programming approach to simultaneous task allocation and motion scheduling for such industrial manipulation and assembly tasks. Our approach covers the robot as well as connected machines. The key concept are Ordered Visiting Constraints, a descriptive and extensible model to specify such tasks with their spatiotemporal requirements and combinatorial or ordering constraints. Our solver integrates such task models and robot motion models into constraint optimization problems and solves them efficiently using various heuristics to produce makespan-optimized robot programs. For large manipulation tasks with 200 objects, our solver implemented using Google's Operations Research tools requires less than a minute to compute usable plans. The proposed task model is robot-independent and can easily be deployed to other robotic platforms. This portability is validated through several simulation-based experiments.


Title: Self-Supervised Surgical Tool Segmentation using Kinematic Information
Abstract: Surgical tool segmentation in endoscopic images is the first step towards pose estimation and (sub-)task automation in challenging minimally invasive surgical operations. While many approaches in the literature have shown great results using modern machine learning methods such as convolutional neural networks, the main bottleneck lies in the acquisition of a large number of manually-annotated images for efficient learning. This is especially true in surgical context, where patient-to-patient differences impede the overall generalizability. In order to cope with this lack of annotated data, we propose a self-supervised approach in a robot-assisted context. To our knowledge, the proposed approach is the first to make use of the kinematic model of the robot in order to generate training labels. The core contribution of the paper is to propose an optimization method to obtain good labels for training despite an unknown hand-eye calibration and an imprecise kinematic model. The labels can subsequently be used for fine-tuning a fully-convolutional neural network for pixel-wise classification. As a result, the tool can be segmented in the endoscopic images without needing a single manually-annotated image. Experimental results on phantom and in vivo datasets obtained using a flexible robotized endoscopy system are very promising.


Title: Needle Localization for Robot-assisted Subretinal Injection based on Deep Learning
Abstract: Subretinal injection is known to be a complicated task for ophthalmologists to perform, the main sources of difficulties are the fine anatomy of the retina, insufficient visual feedback, and high surgical precision. Image guided robot-assisted surgery is one of the promising solutions that bring significant surgical enhancement in treatment outcome and reduces the physical limitations of human surgeons. In this paper, we demonstrate a robust framework for needle detection and localization in subretinal injection using microscope-integrated Optical Coherence Tomography (MI-OCT) based on deep learning. The proposed method consists of two main steps: a) the preprocessing of OCT volumetric images; b) needle localization in the processed images. The first step is to coarsely localize the needle position based on the needle information above the retinal surface and crop the original image into a small region of interest (ROI). Afterward, the cropped small image is fed into a well trained network for detection and localization of the needle segment. The entire framework is extensively validated in ex-vivo pig eye experiments with robotic subretinal injection. The results show that the proposed method can localize the needle accurately with a confidence of 99.2%.


Title: Robust Generalized Point Set Registration using Inhomogeneous Hybrid Mixture Models via Expectation Maximization
Abstract: Point set registration (PSR) is an important problem in computer vision, robotics and biomedical engineering communities. Usually, only positional information at each point is adopted in a registration. In this paper, the orientational vector (or normal vector) associated with each point is also utilized. Generalized point set registration is formulated and solved under the Expectation-Maximization (EM) framework. In the E-step, the posterior probabilities representing the correspondence probabilities are computed. In the Mstep, rigid transformation parameters including the rotation matrix, the translation vector are updated. The proposed algorithm stops when it converges to the optimal solution or a maximum number of iterations is achieved. The observed position set and normal vector set are assumed to follow Gaussian Mixture Models (GMMs) and Fisher distribution Mixture Models (FMMs), respectively. To further improve our algorithm's robustness, the hybrid mixture models (HMMs) are assumed to be inhomogeneous. Experimental results on the surface points extracted from a human femur' CT model show that our algorithm can achieve lower registration error, is more robust to noise and outliers than the state-of-the-art registration methods.


Title: Visual Guidance and Automatic Control for Robotic Personalized Stent Graft Manufacturing
Abstract: Personalized stent graft is designed to treat Abdominal Aortic Aneurysms (AAA). Due to the individual difference in arterial structures, stent graft has to be custom made for each AAA patient. Robotic platforms for autonomous personalized stent graft manufacturing have been proposed in recently which rely upon stereo vision systems for coordinating multiple robots for fabricating customized stent grafts. This paper proposes a novel hybrid vision system for real-time visual-sevoing for personalized stent-graft manufacturing. To coordinate the robotic arms, this system is based on projecting a dynamic stereo microscope coordinate system onto a static wide angle view stereo webcam coordinate system. The multiple stereo camera configuration enables accurate localization of the needle in 3D during the sewing process. The scale-invariant feature transform (SIFT) method and color filtering are implemented for stereo matching and feature identifications for object localization. To maintain the clear view of the sewing process, a visual-servoing system is developed for guiding the stereo microscopes for tracking the needle movements. The deep deterministic policy gradient (DDPG) reinforcement learning algorithm is developed for real-time intelligent robotic control. Experimental results have shown that the robotic arm can learn to reach the desired targets autonomously.


Title: Towards 3D Path Planning from a Single 2D Fluoroscopic Image for Robot Assisted Fenestrated Endovascular Aortic Repair
Abstract: The current standard of intra-operative navigation during Fenestrated Endovascular Aortic Repair (FEVAR) calls for the need of 3D alignments between inserted devices and aortic branches. The navigation commonly via 2D fluoroscopic images, lacks anatomical information, resulting in longer operation hours and radiation exposure. In this paper, a skeleton instantiation framework of Abdominal Aortic Aneurysm (AAA) from a single 2D fluoroscopic image is introduced for real-time 3D robotic path planning. A graph matching method is proposed to establish the correspondences between the 3D preoperative and 2D intra-operative AAA skeletons, and then the two skeletons are registered by skeleton deformation and regularization in respect to skeleton length and smoothness. Furthermore, deep learning was used to segment 3D preoperative AAA from Computed Tomography (CT) scans to facilitate the framework automation. Simulation, phantom and patient AAA data sets have been used to validate the proposed framework. 3D distance error of 2mm was achieved in the phantom setup. Performance advantages were also achieved in terms of accuracy, robustness and time-efficiency.


Title: A Multi-Sensor Next-Best-View Framework for Geometric Model-Based Robotics Applications
Abstract: Geometric models are crucial for many robotics applications. Current robotic 3D reconstruction systems only focus on specific reconstruction goals which make them hard to adapt to different tasks. In this paper we present a next-best-view framework which allows robots to construct a geometric model incrementally through consecutive sensing actions. Instead of limiting the type and total number of sensors, in each sensing step we evaluate actions from all available sensors and pick the best to execute. Our framework is more comprehensive since the model building process can be designed to best accomplish different tasks. The system has been demonstrated in two experiments on 3D reconstruction and weld seam inspection, yielding promising results.


Title: Chance Constrained Motion Planning for High-Dimensional Robots
Abstract: This paper introduces Probabilistic Chekov (p-Chekov), a chance-constrained motion planning system that can be applied to high degree-of-freedom (DOF) robots under motion uncertainty and imperfect state information. Given process and observation noise models, it can find feasible trajectories which satisfy a user-specified bound over the probability of collision. Leveraging our previous work in deterministic motion planning which integrated trajectory optimization into a sparse roadmap framework, p-Chekov shows superiority in its planning speed for high-dimensional tasks. P-Chekov incorporates a linear-quadratic Gaussian motion planning approach into the estimation of the robot state probability distribution, applies quadrature theories to waypoint collision risk estimation, and adapts risk allocation approaches to assign allowable probabilities of failure among waypoints. Unlike other existing risk-aware planners, p-Chekov can be applied to high-DOF robotic planning tasks without the convexification of the environment. The experiment results in this paper show that this p-Chekov system can effectively reduce collision risk and satisfy user-specified chance constraints in typical real-world planning scenarios for high-DOF robots.


Title: Complete and Near-Optimal Path Planning for Simultaneous Sensor-Based Inspection and Footprint Coverage in Robotic Crack Filling
Abstract: A simultaneous robotic footprint and sensor coverage planning scheme is proposed to efficiently detect all the unknown targets with range sensors and cover the targets with the robot's footprint in a structured environment. The proposed online Sensor-based Complete Coverage (online SCC) planning minimizes the total traveling distance of the robot, guarantees the complete sensor coverage of the whole free space, and achieves near-optimal footprint coverage of all the targets. The planning strategy is applied to a crack-filling robotic prototype to detect and fill all the unknown cracks on ground surfaces. Simulation and experimental results are presented that confirm the efficiency and effectiveness of the proposed online planning algorithm.


Title: User-Guided Offline Synthesis of Robot Arm Motion from 6-DoF Paths
Abstract: We present an offline method to generate smooth, feasible motion for robot arms such that end-effector pose goals of a 6-DoF path are matched within acceptable limits specified by the user. Our approach aims to accurately match the position and orientation goals of the given path, and allows deviation from these goals if there is danger of self-collisions, joint-space discontinuities or kinematic singularities. Our method generates multiple candidate trajectories, and selects the best by incorporating sparse user input that specifies what kinds of deviations are acceptable. We apply our method to a range of challenging paths and show that our method generates solutions that achieve smooth, feasible motions while closely approximating the given pose goals and adhering to user specifications.


Title: Visual Robot Task Planning
Abstract: Prospection is key to solving challenging problems in new environments, but it has not been deeply explored as applied to task planning for perception-driven robotics. We propose visual robot task planning, where we take in an input image and must generate a sequence of high-level actions and associated observations that achieve some task. In this paper, we describe a neural network architecture and associated planning algorithm that (1) learns a representation of the world that can generate prospective futures, (2) uses this generative model to simulate the result of sequences of high-level actions in a variety of environments, and (3) evaluates these actions via a variant of Monte Carlo Tree Search to find a viable solution to a particular problem. Our approach allows us to visualize intermediate motion goals and learn to plan complex activity from visual information, and used this to generate and visualize task plans on held-out examples of a block-stacking simulation.


Title: Towards Blended Reactive Planning and Acting using Behavior Trees
Abstract: In this paper, we show how a planning algorithm can be used to automatically create and update a Behavior Tree (BT), controlling a robot in a dynamic environment. The planning part of the algorithm is based on the idea of back chaining. Starting from a goal condition we iteratively select actions to achieve that goal, and if those actions have unmet preconditions, they are extended with actions to achieve them in the same way. The fact that BTs are inherently modular and reactive makes the proposed solution blend acting and planning in a way that enables the robot to effectively react to external disturbances. If an external agent undoes an action the robot reexecutes it without re-planning, and if an external agent helps the robot, it skips the corresponding actions, again without replanning. We illustrate our approach in two different robotics scenarios.


Title: Visual Representations for Semantic Target Driven Navigation
Abstract: What is a good visual representation for navigation? We study this question in the context of semantic visual navigation, which is the problem of a robot finding its way through a previously unseen environment to a target object, e.g. go to the refrigerator. Instead of acquiring a metric semantic map of an environment and using planning for navigation, our approach learns navigation policies on top of representations that capture spatial layout and semantic contextual cues. We propose to use semantic segmentation and detection masks as observations obtained by state-of-the-art computer vision algorithms and use a deep network to learn the navigation policy. The availability of equitable representations in simulated environments enables joint training using real and simulated data and alleviates the need for domain adaptation or domain randomization commonly used to tackle the sim-to-real transfer of the learned policies. Both the representation and the navigation policy can be readily applied to real non-synthetic environments as demonstrated on the Active Vision Dataset [1]. Our approach successfully gets to the target in 54% of the cases in unexplored environments, compared to 46% for a non-learning based approach, and 28% for a learning-based baseline.


Title: Deep Object-Centric Policies for Autonomous Driving
Abstract: While learning visuomotor skills in an end-to-end manner is appealing, deep neural networks are often uninterpretable and fail in surprising ways. For robotics tasks, such as autonomous driving, models that explicitly represent objects may be more robust to new scenes and provide intuitive visualizations. We describe a taxonomy of “object-centric” models which leverage both object instances and end-to-end learning. In the Grand Theft Auto V simulator, we show that object-centric models outperform object-agnostic methods in scenes with other vehicles and pedestrians, even with an imperfect detector. We also demonstrate that our architectures perform well on real-world environments by evaluating on the Berkeley DeepDrive Video dataset, where an object-centric model outperforms object-agnostic models in the low-data regimes.


Title: Two-Stage Transfer Learning for Heterogeneous Robot Detection and 3D Joint Position Estimation in a 2D Camera Image Using CNN
Abstract: Collaborative robots are becoming more common on factory floors as well as regular environments, however, their safety still is not a fully solved issue. Collision detection does not always perform as expected and collision avoidance is still an active research area. Collision avoidance works well for fixed robot-camera setups, however, if they are shifted around, Eye-to-Hand calibration becomes invalid making it difficult to accurately run many of the existing collision avoidance algorithms. We approach the problem by presenting a stand-alone system capable of detecting the robot and estimating its position, including individual joints, by using a simple 2D colour image as an input, where no Eye-to-Hand calibration is needed. As an extension of previous work, a two-stage transfer learning approach is used to re-train a multi-objective convolutional neural network (CNN) to allow it to be used with heterogeneous robot arms. Our method is capable of detecting the robot in real-time and new robot types can be added by having significantly smaller training datasets compared to the requirements of a fully trained network. We present data collection approach, the structure of the multi-objective CNN, the two-stage transfer learning training and test results by using real robots from Universal Robots, Kuka, and Franka Emika. Eventually, we analyse possible application areas of our method together with the possible improvements.


Title: Automatic Optical Coherence Tomography Imaging of Stationary and Moving Eyes with a Robotically-Aligned Scanner
Abstract: Optical coherence tomography (OCT) has found great success in ophthalmology where it plays a key role in screening and diagnostics. Clinical ophthalmic OCT systems are typically deployed as tabletop instruments that require chinrest stabilization and trained ophthalmic photographers to operate. These requirements preclude OCT diagnostics in bedbound or unconscious patients who cannot use a chinrest, and restrict OCT screening to ophthalmology offices. We present a robotically-aligned OCT scanner capable of automatic eye imaging without chinrests. The scanner features eye tracking from fixed-base RGB-D cameras for coarse and stereo pupil cameras for fine alignment, as well as galvanometer aiming for fast lateral tracking, reference arm adjustment for fast axial tracking, and a commercial robot arm for slow lateral and axial tracking. We demonstrate the system's performance autonomously aligning with stationary eyes, pursuing moving eyes, and tracking eyes undergoing physiologic motion. The system demonstrates sub-millimeter eye tracking accuracy, 12 μm lateral pupil tracking accuracy, 83.2 ms stabilization time following step disturbance, and 9.7 Hz tracking bandwidth.


Title: Online Multilayered Motion Planning with Dynamic Constraints for Autonomous Underwater Vehicles
Abstract: Underwater robots are subject to complex hydro-dynamic forces. These forces define how the vehicle moves, so it is important to consider them when planning trajectories. However, performing motion planning considering the dynamics on the robot's onboard computer is challenging due to the limited computational resources available. In this paper an efficient motion planning framework for autonomous underwater vehicles (AUVs) is presented. By introducing a loosely coupled multilayered planning design, our framework is able to generate dynamically feasible trajectories while keeping the planning time low enough for online planning. First, a fast path planner operating in a lower-dimensional projected space computes a lead path from the start to the goal configuration. Then, the lead path is used to bias the sampling of a second motion planner, which takes into account all the dynamic constraints. Furthermore, we propose a strategy for online planning that saves computational resources by generating the final trajectory only up to a finite horizon. By using the finite horizon strategy together with the multilayered approach, the sampling of the second planner focuses on regions where good quality solutions are more likely to be found, significantly reducing the planning time. To provide strong safety guarantees our framework also incorporates the conservative approximations of inevitable collision states (icss). finally, we present simulations and experiments using a real underwater robot to demonstrate the capabilities of our framework.


Title: Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks
Abstract: Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.


Title: Deep Visuo-Tactile Learning: Estimation of Tactile Properties from Images
Abstract: Estimation of tactile properties from vision, such as slipperiness or roughness, is important to effectively interact with the environment. These tactile properties help us decide which actions we should choose and how to perform them. E.g., we can drive slower if we see that we have bad traction or grasp tighter if an item looks slippery. We believe that this ability also helps robots to enhance their understanding of the environment, and thus enables them to tailor their actions to the situation at hand. We therefore propose a model to estimate the degree of tactile properties from visual perception alone (e.g., the level of slipperiness or roughness). Our method extends a encoder-decoder network, in which the latent variables are visual and tactile features. In contrast to previous works, our method does not require manual labeling, but only RGB images and the corresponding tactile sensor data. All our data is collected with a webcam and uSkin tactile sensor mounted on the end-effector of a Sawyer robot, which strokes the surfaces of 25 different materials. We show that our model generalizes to materials not included in the training data by evaluating the feature space, indicating that it has learned to associate important tactile properties with images.


Title: Variational End-to-End Navigation and Localization
Abstract: Deep learning has revolutionized the ability to learn “end-to-end” autonomous vehicle control directly from raw sensory data. While there have been recent extensions to handle forms of navigation instruction, these works are unable to capture the full distribution of possible actions that could be taken and to reason about localization of the robot within the environment. In this paper, we extend end-to-end driving networks with the ability to perform point-to-point navigation as well as probabilistic localization using only noisy GPS data. We define a novel variational network capable of learning from raw camera data of the environment as well as higher level roadmaps to predict (1) a full probability distribution over the possible control commands; and (2) a deterministic control command capable of navigating on the route specified within the map. Additionally, we formulate how our model can be used to localize the robot according to correspondences between the map and the observed visual road topology, inspired by the rough localization that human drivers can perform. We test our algorithms on real-world driving data that the vehicle has never driven through before, and integrate our point-topoint navigation algorithms onboard a full-scale autonomous vehicle for real-time performance. Our localization algorithm is also evaluated over a new set of roads and intersections to demonstrates rough pose localization even in situations without any GPS prior.


Title: Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience
Abstract: We consider the problem of transferring policies to the real world by training on a distribution of simulated scenarios. Rather than manually tuning the randomization of simulations, we adapt the simulation parameter distribution using a few real world roll-outs interleaved with policy training. In doing so, we are able to change the distribution of simulations to improve the policy transfer by matching the policy behavior in simulation and the real world. We show that policies trained with our method are able to reliably transfer to different robots in two real world tasks: swing-peg-in-hole and opening a cabinet drawer. The video of our experiments can be found at https://sites.google.com/view/simopt.


Title: Robotic Orientation Control of Deformable Cells
Abstract: Robotic manipulation of deformable objects (vs. rigid objects) has been a classic topic in robotics. Compared to deformable synthetic objects such as rubber balls and clothes, biological cells are highly deformable and more prone to damage. This paper presents robotic manipulation of deformable cells for orientation control (both out-of-plane and in-plane), which is required in both clinical (e.g., in vitro fertilization) and biomedical (e.g., clone) applications. Compared to manual cell rotation control based on empirical experience, the robotic approach, based on mathematical modeling and path planning, effectively rotates a cell while consistently maintaining minimal cell deformation to avoid cell damage. A force model is established to determine the minimal force applied by the micropipette to rotate a spherical or more generally, an ellipsoidal mouse oocyte. The force information is translated into indentation through a contact mechanics model, and the manipulation path of the micropipette is formed by connecting the indentation positions on the oocyte. A compensation controller is designed to compensate for the variations of mechanical properties across cells. The polar body of an oocyte is detected by deep neural networks with robustness to shape and size differences. Experimental results demonstrate that the system achieved an accuracy of 97.6% in polar body detection and an accuracy of 0.7° in oocyte orientation control with maximum oocyte deformation of 2.69 μm.


Title: Drift-free Roll and Pitch Estimation for High-acceleration Hopping
Abstract: We develop a drift-free roll and pitch attitude estimation scheme for monopedal jumping robots. The estimator uses only onboard rate gyroscopes and encoders and does not rely on external sensing or processing. It is capable of recovering from attitude estimate disturbances and, together with onboard velocity estimation, enables fully autonomous stable hopping control. The estimator performs well on a small untethered robot capable of large jumps and extreme stance accelerations. We demonstrate that the robot can follow a rectangular path using onboard dead-reckoning with less than 2 meters of drift over 200 seconds and 300 jumps covering 60 m. We also demonstrate that the robot can operate untethered outdoors under human wireless joystick direction.


Title: Efficient Symbolic Reactive Synthesis for Finite-Horizon Tasks
Abstract: When humans and robots perform complex tasks together, the robot must have a strategy to choose its actions based on observed human behavior. One well-studied approach for finding such strategies is reactive synthesis. Existing approaches for finite-horizon tasks have used an explicit state approach, which incurs high runtime. In this work, we present a compositional approach to perform synthesis for finite-horizon tasks based on binary decision diagrams. We show that for pick-and-place tasks, the compositional approach achieves orders-of-magnitude speed-ups compared to previous approaches. We demonstrate the synthesized strategy on a UR5 robot.


Title: Towards Robust Product Packing with a Minimalistic End-Effector
Abstract: Advances in sensor technologies, object detection algorithms, planning frameworks and hardware designs have motivated the deployment of robots in warehouse automation. A variety of such applications, like order fulfillment or packing tasks, require picking objects from unstructured piles and carefully arranging them in bins or containers. Desirable solutions need to be low-cost, easily deployable and controllable, making minimalistic hardware choices desirable. The challenge in designing an effective solution to this problem relates to appropriately integrating multiple components, so as to achieve a robust pipeline that minimizes failure conditions. The current work proposes a complete pipeline for solving such packing tasks, given access only to RGB-D data and a single robot arm with a vacuum-based end-effector, which is also used as a pushing finger. To achieve the desired level of robustness, three key manipulation primitives are identified, which take advantage of the environment and simple operations to successfully pack multiple cubic objects. The overall approach is demonstrated to be robust to execution and perception errors. The impact of each manipulation primitive is evaluated by considering different versions of the proposed pipeline, which incrementally introduce reasoning about object poses and corrective manipulation actions.


Title: Robust Learning of Tactile Force Estimation through Robot Interaction
Abstract: Current methods for estimating force from tactile sensor signals are either inaccurate analytic models or task-specific learned models. In this paper, we explore learning a robust model that maps tactile sensor signals to force. We specifically explore learning a mapping for the SynTouch BioTac sensor via neural networks. We propose a voxelized input feature layer for spatial signals and leverage information about the sensor surface to regularize the loss function. To learn a robust tactile force model that transfers across tasks, we generate ground truth data from three different sources: (1) the BioTac rigidly mounted to a force torque (FT) sensor, (2) a robot interacting with a ball rigidly attached to the same FT sensor, and (3) through force inference on a planar pushing task by formalizing the mechanics as a system of particles and optimizing over the object motion. A total of 140k samples were collected from the three sources. We achieve a median angular accuracy of 3.5 degrees in predicting force direction (66% improvement over the current state of the art) and a median magnitude accuracy of 0.06 N (93% improvement) on a test dataset. Additionally, we evaluate the learned force model in a force feedback grasp controller performing object lifting and gentle placement. Our results can be found on https: //sites.google.com/view/tactile-force.


Title: Soft Robotic Glove with Integrated Sensing for Intuitive Grasping Assistance Post Spinal Cord Injury
Abstract: This paper presents a fully-integrated soft robotic glove with multi-articular textile actuators, custom soft sensors, and an intuitive state machine intent detection controller. We demonstrate that the pressurized actuators can generate motion and force comparable to natural human fingers through bench-top testing. We apply textile-elastomer capacitive sensors to the glove to track finger flexion via strain and detect contact with objects via force. Intuitive user control is achieved via a state machine controller based on signals from the integrated sensors to detect relative changes in hand-object interactions. Results from an initial evaluation with 3 participants with spinal cord injury (SCI), of varied injury levels and years since injury, wearing and controlling the glove show an average of 87% improvement in grasping force, and improvements in functional assessments for participants with recent injuries. A significant variation in response suggests further investigation is required to understand the adaptation needed across different injury levels and durations since injury. Additionally, we evaluate the controller and find an average of 3 seconds from user initiations to completed grasps, and 10% inadvertent grasp triggers and no false releases when objects are held.


Title: Shape Sensing of Variable Stiffness Soft Robots using Electrical Impedance Tomography
Abstract: Soft robotic systems offer benefits over traditional rigid systems through reduced contact trauma with soft tissues and by enabling access through tortuous paths in minimally invasive surgery. However, the inherent deformability of soft robots places both a greater onus on accurate modelling of their shape, and greater challenges in realising intraoperative shape sensing. Herein we present a proprioceptive (self-sensing) soft actuator, with an electrically conductive working fluid. Electrical impedance measurements from up to six electrodes enabled tomographic reconstructions using Electrical Impedance Tomography (EIT). A new Frequency Division Multiplexed (FDM) EIT system was developed capable of measurements of 66 dB SNR with 20 ms temporal resolution. The concept was examined in two two-degree-of-freedom designs: a hydraulic hinged actuator and a pneumatic finger actuator with hydraulic beams. Both cases demonstrated that impedance measurements could be used to infer shape changes, and EIT images reconstructed during actuation showed distinct patterns with respect to each degree of freedom (DOF). Whilst there was some mechanical hysteresis observed, the repeatability of the measurements and resultant images was high. The results show the potential of FDM-EIT as a low-cost, low profile shape sensor in soft robots.


Title: Adaptive Control of Sclera Force and Insertion Depth for Safe Robot-Assisted Retinal Surgery
Abstract: One of the significant challenges of moving from manual to robot-assisted retinal surgery is the loss of perception of forces applied to the sclera (sclera forces) by the surgical tools. This damping of force feedback is primarily due to the stiffness and inertia of the robot. The diminished perception of tool-to-eye interactions might put the eye tissue at high risk of injury due to excessive sclera forces or extreme insertion of the tool into the eye. In the present study therefore a 1-dimensional adaptive control method is customized for 3-dimensional control of sclera force components and tool insertion depth and then implemented on the velocity-controlled Johns Hopkins Steady-Hand Eye Robot. The control method enables the robot to perform autonomous motions to make the sclera force and/or insertion depth of the tool tip to follow pre-defined desired and safe trajectories when they exceed safe bounds. A robotic light pipe holding application in retinal surgery is also investigated using the adaptive control method. The implementation results indicate that the adaptive control is able to achieve the imposed safety margins and prevent sclera forces and insertion depth from exceeding safe boundaries.


Title: Distributed Multi-Robot Formation Splitting and Merging in Dynamic Environments
Abstract: This paper presents a distributed method for splitting and merging of multi-robot formations in dynamic environments with static and moving obstacles. Splitting and merging actions rely on distributed consensus and can be performed to avoid obstacles. Our method accounts for the limited communication range and visibility radius of the robots and relies on the communication of obstacle-free convex regions and the computation of an intersection graph. In addition, our method is able to detect and recover from (permanent and temporary) communication and motion faults. Finally, we demonstrate the applicability and scalability of the proposed method in simulations with up to sixteen quadrotors and real-world experiments with a team of four quadrotors.


Title: Eagle Shoal: A new designed modular tactile sensing dexterous hand for domestic service robots
Abstract: This paper introduces a new designed modular tactile sensing dexterous hand for domestic service robots. This fully-actuated hand consists of 1 palm and 3 fingers, with embedded tactile sensors, motors and control boards. The palm and each finger have 2 degrees of freedom (DOFs). The modular design makes it easy to attach and detach the hand, even by inexperienced users. The tactile sensor unit with new structure can help to decrease sensor number and keep a good sensing ability. A series of experiments to test the sensor unit and evaluated the hand performance with an object set was performed in this paper. The results show that the sensor unit can provide precise sensing result and perceive continuous vibration data, and the hand has excellent grasp ability. In addition to its good performance, the hand features a cost of $500 USD with a scale of one hundred sets. This hand is affordable for researchers and for domestic service robots in the consumer market. In future research, this hand will be used to promote the robotic manipulation research based on visual and tactile data.


Title: Multi-Robot Region-of-Interest Reconstruction with Dec-MCTS
Abstract: We consider the problem of reconstructing regions of interest of a scene using multiple robot arms and RGB-D sensors. This problem is motivated by a variety of applications, such as precision agriculture and infrastructure inspection. A viewpoint evaluation function is presented that exploits predicted observations and the geometry of the scene. A recently proposed non-myopic planning algorithm, Decentralised Monte Carlo tree search, is used to coordinate the actions of the robot arms. Motion planning is performed over a navigation graph that considers the high-dimensional configuration space of the robot arms. Extensive simulated experiments are carried out using real sensor data and then validated on hardware with two robot arms. Our proposed targeted information gain planner is compared to state-of-the-art baselines and outperforms them in every measured metric. The robots quickly observe and accurately detect fruit in a trellis structure, demonstrating the viability of the approach for real-world applications.


Title: LineRanger: Analysis and Field Testing of an Innovative Robot for Efficient Assessment of Bundled High-Voltage Powerlines
Abstract: Robotic platforms dedicated to powerline inspection are often complex to operate, take several minutes to cross any obstacle, and must be operated by highly trained specialists. To further its goal of massive inspection of its power grid, Hydro-Québec developed an innovative robot that is simple to operate and can be used directly by line maintenance technicians. LineRanger was developed following the field deployment of LineROVer and LineScout but aims at surpassing them in terms of inspection efficiency. With an ingenious and passive obstacle-crossing system, this new robot allows large-scale inspection of bundled-type powerlines, since the obstacle crossing time is considerably reduced. In this paper, details on the robot's key features are presented along with its mathematical analysis, which guarantees its stability on flexible bundles and directly influenced the design. Finally, the LineRanger prototype is presented, with insights about its first field deployments.


Title: Adjustable Power Modulation For A Leg Mechanism Suitable For Running
Abstract: Recent work in the design of mechanical systems for terrestrial locomotion has indicated successful strategies for increasing the energetic performance of a robotic locomotor without upgrading its actuator system. We apply one such strategy, termed power modulation, in a new way: for the design of a leg mechanism useful for running. Power modulation geometrically defines force/torque ratios between robot components to mechanically achieve certain energy transmission characteristics during fast stance dynamics that increase the kinetic power output of the overall system. Furthermore, we investigate the design of a leg mechanism that can adjust to exhibit power modulation. In this way, a leg mechanism would exhibit a low power mode for flat terrain, and can adjust to a high power mode for rough terrain. The latter makes jumping possible and extends the range of available footholds that can be accessed in a single step. To find a suitable leg mechanism, we leverage the Finite Root Generation method to compute a design. The design is advanced to a prototype and basic experiments are conducted to investigate its behavior as adjusted between high-and low-power modes.


Title: Towards Semi-Autonomous and Soft-Robotics Enabled Upper-Limb Exoprosthetics: First Concepts and Robot-Based Emulation Prototype
Abstract: In this paper the first robot-based prototype of a semi-autonomous upper-limb exoprosthesis is introduced, unifying exoskeletons and prostheses [1]. A central goal of this work is to minimize unnecessary interaction forces on the residual limb by compensating gravity effects via a upper body grounded exoskeleton. Furthermore, the exoskeleton provides the residual limb's kinematic data that allows to design more intelligent coordinated control concepts. The soft-robotics design of a prototype consisting of a transhumeral prosthesis and a robot-based exoskeleton substitute is outlined. For this class of hybrid systems a human embodied dynamics model and semi-autonomous coordinated motion strategies are derived. Here, in contrast to established standard sequential strategies all joints are moved simultaneously according to a desired task. In combination with an app-based programming framework the strategy goals are set either user-based via kinesthetic teaching or autonomously via 3D visual perception. This enables the user to execute tasks faster and more intuitive. First experimental evaluations show promising performance with a healthy subject.


Title: A Miniature Suction-Gripper With Passive and Active Microneedle Arrays to Manipulate Peripheral Nerves
Abstract: We develop a miniature suction-gripper with the goal to realize the novel robotic surgical instrument that can grip slippery and flexible peripheral nerves. In developing the instrument, we place a priority on devising the method that can robustly grip the nerve bundles during the surgical operation for the peripheral nerve. Also, we concentrate to investigate the working principle being able to minimize nerve damages that might be caused when manipulating the nerve. In this study, as the most suitable method to achieve the goal, we scheme to utilize the suction mechanism. Because it can non-invasively grip the nerve based on negative pressure, no external force is applied to the nervous tissues. Therefore the peripheral nerve can be manipulated without serious nerve damage (e.g. crush injury and stretch injury). To improve the gripping ability of the proposed suction gripper, two different types of microneedle arrays are applied to the suction-tips: passive-microneedle (PMN) arrays and active-microneedle (AMN) arrays. Since the most outer membrane of the nerve can be anchored by the penetrated PMN and AMN, the gripper can grip the nerve more robustly. The designed suction-gripper is fabricated as a functional prototype, and its working performances are assessed with in-vitro and in-vivo animal experiments. The experimental results well demonstrate the practical effectiveness of the proposed method and its applicability to the neurosurgical robot for the peripheral nerve.


Title: Flappy Hummingbird: An Open Source Dynamic Simulation of Flapping Wing Robots and Animals
Abstract: Insects and hummingbirds exhibit extraordinary flight performance and can simultaneously master seemingly conflicting goals: stable hovering and aggressive maneuvering, which are unmatched by conventional small scale man-made vehicles. Flapping Wing Micro Air Vehicles (FWMAVs) hold great promise for closing this performance gap. However, design and control of such systems remain challenging. Here, we present an open source high fidelity dynamic simulation for FWMAVs. The simulator serves as a testbed for the design, optimization and flight control of FWMAVs. To validate the simulation, we recreated the at-scale hummingbird robot developed in our lab in the simulation. System identification was performed to obtain the model parameters. Force generation and dynamic response of open-loop and closed loop systems between simulated and experimental flights were compared. The unsteady aerodynamics and the highly nonlinear flight dynamics present challenging control problems for conventional and learning control algorithms such as Reinforcement Learning. The interface of the simulation is fully compatible with OpenAI Gym environment. As a benchmark study, we present a linear controller for hovering stabilization and a Deep Reinforcement Learning control policy for goal-directed maneuvering. Finally, we demonstrate direct simulation-to-real transfer of both control policies onto the physical robot, further demonstrating the fidelity of the simulation.


Title: Visual Repetition Sampling for Robot Manipulation Planning
Abstract: One of the main challenges in sampling-based motion planners is to find an efficient sampling strategy. While methods such as Rapidly-exploring Random Tree (RRT) have shown to be more reliable in complex environments than optimization-based methods, they often require longer planning times, which reduces their usability for real-time applications. Recently, biased sampling methods have shown to remedy this issue. For example Gaussian Mixture Models (GMMs) have been used to sample more efficiently in feasible regions of the configuration space. Once the GMM is learned, however, this approach does not adapt its biases to individual planning scene during inference. Hence, we propose in this work a more efficient sampling strategy to further bias the GMM based on visual input upon query. We employ an autoencoder trained entirely in simulation to extract features from depth images and use the latent representation to adjust the weights of each mixture components in the GMM. We show empirically that this improves the sampling efficiency of an RRT motion planner in both real and simulated scenes.


Title: Contact-Driven Posture Behavior for Safe and Interactive Robot Operation
Abstract: When performing tasks in uncertain environments and around humans, robots are likely to collide unexpectedly with people or objects. In order to ensure safety, most approaches rely on collision avoidance and try to prevent any contact from happening, which may result in unnecessary interruption of a task that would be feasible in spite of the obstacle. On the one hand, when an unexpected contact occurs, a safe robot behavior is required. On the other hand, it might be interesting to exploit the contact instead of moving away from it. In this paper, we present a contact-driven approach for safe and interactive robot operation to react to unforeseen contact events. This approach offers the possibility to control the contact while minimizing its effects on the robot tasks. It relies exclusively on the robot model and proprioceptive sensors. It is tested in simulation and hardware experiments on a 7 degrees of freedom robot arm and shows a safe contact behavior that does not interfere with the task, and as little as possible with the robot posture requirements.


Title: The Mechanics and Control of Leaning to Lift Heavy Objects with a Dynamically Stable Mobile Robot
Abstract: A control algorithm is developed to enable dynamically stable spherical-wheel robots (ballbots) with arms to detect a heavy object of unknown mass, navigate to it, lift it, transport it, and place it in a desired location semi-autonomously. Previous work has successfully demonstrated two-wheeled dynamically stable mobile manipulator robots transporting heavy objects. We report here the first ballbot to reliably achieve such a task. A successful semi-autonomous lift and transport of a 15 kg heavy box whose actual mass was unknown was achieved using a combination of feedforward and feedback control laws based on a quasi-static center of mass computation. The ballbot's pan and tilt sensor turret tracked fiducial markers on the box. Ballbot-to-human and human-to-ballbot exchanges of a 10 kg heavy object was achieved while dynamically balancing.


Title: Improving Underwater Obstacle Detection using Semantic Image Segmentation
Abstract: This paper presents two novel approaches for improving image-based underwater obstacle detection by combining sparse stereo point clouds with monocular semantic image segmentation. Generating accurate image-based obstacle maps in cluttered underwater environments, such as coral reefs, are essential for robust robotic path planning and navigation. However, these maps can be challenged by factors including visibility, lighting and dynamic objects (e.g. fish) that may lead to falsely identified free space or dynamic objects which trajectory planners may react to undesirably. We propose combining feature-based stereo matching with learning-based segmentation to produce a more robust obstacle map. This approach considers direct binary learning of the presence or absence of underwater obstacles, as well as a multiclass learning approach to classify their distance (near, mid and far) in the scene. An enhancement to the binary map is also shown by including depth information from sparse stereo matching to produce 3D obstacle maps of the scene. The performance is evaluated using field data collected in cluttered, and at times, visually degraded coral reef environments. The results show improved image-wide obstacle detection, rejection of transient objects (such as fish), and range estimation compared to feature-based sparse and dense stereo point clouds alone.


Title: RCM-SLAM: Visual localisation and mapping under remote centre of motion constraints
Abstract: In robotic surgery the motion of instruments and the laparoscopic camera is constrained by their insertion ports, i. e. a remote centre of motion (RCM). We propose a Simultaneous Localisation and Mapping (SLAM) approach that estimates laparoscopic camera motion under RCM constraints. To achieve this we derive a minimal solver for the absolute camera pose given two 2D-3D point correspondences (RCM-PnP) and also a bundle adjustment optimiser that refines camera poses within an RCM-constrained parameterisation. These two methods are used together with previous work on relative pose estimation under RCM [1] to assemble a SLAM pipeline suitable for robotic surgery. Our simulations show that RCM-PnP outperforms conventional PnP for a wide noise range in the RCM position. Results with video footage from a robotic prostatectomy show that RCM constraints significantly improve camera pose estimation.


Title: Comparing Physical and Simulated Performance of a Deterministic and a Bio-inspired Stochastic Foraging Strategy for Robot Swarms
Abstract: Designing resource-collection algorithms for relatively simple robots that are effective given the noise and uncertainty of the real world is a challenge in swarm robotics. This paper describes the performance of two algorithms for collective robot foraging: the stochastic central-place foraging algorithm (CPFA) and the distributed deterministic spiral algorithm (DDSA). With the CPFA, robots mimic the foraging behaviors of ants; they stochastically search for targets and share information to recruit other robots to locations where they detect multiple targets. With the DDSA, robots travel along pre-planned spiral paths; robots detect the nearest targets first and, in theory, guarantee eventual complete coverage of the arena with minimal overlap. We implemented both algorithms and compared their performance in a Gazebo simulation and in physical robots in a large outdoor arena. In a realistic Gazebo simulation, the DDSA outperforms the CPFA. However, in real-world experiments with obstacles, collisions, and errors, the movement patterns of robots implementing the DDSA become visually indistinguishable from the CPFA. The CPFA is less affected by noise and error, and it performs as well as, or better than, the DDSA. Physical experiments change our conclusion about which algorithm has the best performance, emphasizing the importance of systematically comparing the performance of swarm robotic algorithms in the real world.


Title: WheeLeR: Wheel-Leg Reconfigurable Mechanism with Passive Gears for Mobile Robot Applications
Abstract: This paper presents a new passive wheel-leg transformation mechanism and its embodiment in a small mobile robot. The mechanism is based on a unique geared structure, allowing the wheel to transform between two modes, i.e., wheel or leg, potentially adapting to varying ground conditions. It consists of a central gear and legs with partial gears that rotate around the central gear to open or close the legs. When fully closed, the mechanism forms a seamless circular wheel; when opened, it operates in the leg mode. The central gear actuated by the driving motor generates opening and closing motions of the legs without using an additional actuator. The number of legs, their physical size, and the gear ratio between the central gear and the partial gears on the legs are adjustable. This design is mechanically simple, customizable, and easy to fabricate. For physical demonstration and experiments, a mobile robotic platform was built and its terrainability was tested using five different sets of the transformable wheels with varying sizes and gear ratios. For each design, the performance with successful wheel-leg transformation, obstacle climbing, and locomotion capabilities was tested in different ground conditions.


Title: Guaranteed Globally Optimal Planar Pose Graph and Landmark SLAM via Sparse-Bounded Sums-of-Squares Programming
Abstract: Autonomous navigation requires an accurate model or map of the environment. While dramatic progress in the prior two decades has enabled large-scale simultaneous localization and mapping (SLAM), the majority of existing methods rely on non-linear optimization techniques to find the maximum likelihood estimate (MLE) of the robot trajectory and surrounding environment. These methods are prone to local minima and are thus sensitive to initialization. Several recent papers have developed optimization algorithms for the Pose-Graph SLAM problem that can certify the optimality of a computed solution. Though this does not guarantee a priori that this approach generates an optimal solution, a recent extension has shown that when the noise lies within a critical threshold that the solution to the optimization algorithm is guaranteed to be optimal. To address the limitations of existing approaches, this paper illustrates that the Pose-Graph SLAM and Landmark SLAM can be formulated as polynomial optimization programs that are sum-of-squares (SOS) convex. This paper then describes how the Pose-Graph and Landmark SLAM problems can be solved to a global minimum without initialization regardless of noise level using the sparse bounded degree sum-of-squares (Sparse-BSOS) optimization method. Finally, the superior performance of the proposed approach when compared to existing SLAM methods is illustrated on graphs with several hundred nodes.


Title: Removing Leaking Corners to Reduce Dimensionality in Hamilton-Jacobi Reachability
Abstract: Hamilton-Jacobi (HJ) reachability provides a flexible framework for the verification of safety in robotic systems: it accounts for nonlinear system dynamics and provides safety-preserving controllers. However, computational scalability limits its direct application to systems of less than five continuous state dimensions. To alleviate this computational burden, system decomposition methods have been proposed; however, safety guarantees are lost in situations involving “leaking corners which arise when there are conflicting controls between subsystems. In this paper, a coupled HJ formulation is presented, which addresses leaking corners and guarantees safety, while incorporating dimensionality reduction. We demonstrate our method in two examples, one of which is a vehicle obstacle avoidance problem with a 5D car model, whose HJ computation was previously considered to be intractable.


Title: Improving the Performance of Auxiliary Null Space Tasks via Time Scaling-Based Relaxation of the Primary Task
Abstract: Kinematic redundancy enhances the dexterity and flexibility of robot manipulators. By exploiting the redundant degrees of freedom, auxiliary null space tasks can be carried out in addition to the primary task. Such auxiliary tasks are often formulated in terms of a performance or safety criterion that shall be minimized. If the optimization criterion, however, is defined in global terms, then it is directly affected by the primary task. As a consequence, the task achievement of the auxiliary task may be unnecessarily detrimented by the main task. In addition to modifying the primary task via constraint relaxation, a possible solution for improving the performance of the auxiliary task is to relax the primary task temporarily via time scaling. This gives the null space task more time for achieving its objective. In this paper, we propose several such time scaling schemes and verify their performance for a DLR/KUKA Lightweight Robot with one redundant degree of freedom. Finally, we extend the concept to multiple prioritized tasks and provide a simulation example.


Title: Shape Memory Structures-Automated Design of Monolithic Soft Robot Structures with Pre-defined End Poses
Abstract: The particularly compliant and adaptable properties of soft robotic systems and structures offer enormous potential for use in unpredictable environments as well as for safe and interactive work in human environments. Therefore, new approaches for the design of soft robotic systems are constantly being introduced in this still emerging field of research. Through the use of additive manufacturing methods, it is possible to design systems specifically for an individual task. In this paper we present an approach for an automated design process for monolithic soft robotic structures that can assume pre-defined end poses. The idea thereby is to design simple individualizable systems that are 3D-printable and require a minimum number of actuators. Using the automated design process, we could already generate soft robotic systems for different applications which show promising properties.


Title: A Novel Rotating Beam Link for Variable Stiffness Robotic Arms
Abstract: In this paper, we present a novel design concept for a robot arm link with variable stiffness. Variable stiffness links are intended to grant a robot the safety benefits of compliance and the performance benefits of stiffness. Our compact design actively modulates stiffness via parallel, rotating beams actuated by simple servomotors. It achieves a lateral stiffness ratio greater than ten with a minimum stiffness under 0.2 N/mm. Our novel design offers many benefits over existing variable stiffness link solutions in its compactness, simplicity, and speed of actuation. One challenge of this research lies in the mechanics modeling of variable stiffness. Here we propose a comprehensive mechanics model that considers mechanical compliances due to deflections of parallel guided beams, column buckling, and bearing at the beam roots. By comparing with experimental testing data, we show that our analytical model accurately predicts the lateral stiffness of the robotic link. This model can be used as a design tool in future iterations, including for scaling the design.


Title: Multi-Task Sensorization of Soft Actuators Using Prior Knowledge
Abstract: The space of all possible deformations of soft robotic actuators is extremely large. It is impossible to explicitly measure each internal degree of freedom, regardless of the number and types of sensors. It is, however, possible to measure a smaller subset of task-relevant deformations using only a few well-placed sensors. But for a different task, the soft actuator's deformation behavior might differ significantly. Instead of finding a new sensor placement for the new task, which would result in a separate hand for every task, we propose a method that maintains the original sensors and uses prior knowledge about each task to extend the applicability of the existing sensorized actuators to new tasks. We demonstrate our approach by the example of a PneuFlex actuator of the RBO Hand 2. When sensorizing the actuator for a single task, the sensor model does not transfer well to other tasks. Using our multi-task method, we train new sensor models that use prior knowledge about the tasks. The new models improve measurement accuracy for the new tasks without having to change the sensor hardware.


Title: Self-Modifying Morphology Experiments with DyRET: Dynamic Robot for Embodied Testing
Abstract: If robots are to become ubiquitous, they will need to be able to adapt to complex and dynamic environments. Robots that can adapt their bodies while deployed might be flexible and robust enough to meet this challenge. Previous work on dynamic robot morphology has focused on simulation, combining simple modules, or switching between locomotion modes. Here, we present an alternative approach: a self-reconfigurable morphology that allows a single four-legged robot to actively adapt the length of its legs to different environments. We report the design of our robot, as well as the results of a study that verifies the performance impact of self-reconfiguration. This study compares three different control and morphology pairs under different levels of servo supply voltage in the lab. We also performed preliminary tests in different uncontrolled outdoor environments to see if changes to the external environment supports our findings in the lab. Our results show better performance with an adaptable body, lending evidence to the value of self-reconfiguration for quadruped robots.


Title: Experimental Validation of High-Efficiency Hydraulic Direct-Drive System for a Biped Humanoid Robot—Comparison with Valve-Based Control System
Abstract: Biped robots require substantial amounts of power alternately on each leg while walking, hopping, and running. However, it is difficult to mount high-power large electrical motors in conventional mechanical transmission systems owing to spatial limitations. A hydraulic direct-drive system is proposed in which the size of the motor in each leg can be reduced by sharing the motor outputs between the legs. In this paper, the hydraulic direct-drive system is evaluated in an actual hydraulic system. Velocity followability, excellent energy saving, and virtually perfect position tracking are achieved with the proposed system. The results of performance comparison with a valve-based control system show that energy consumption is controlled and good position-following capability is achieved using the proposed system.


Title: Experimental Demonstration of High-Performance Robotic Balancing
Abstract: This paper presents the first practical demonstration of a recently developed theory of balance control that aims to achieve high performance in the sense of allowing a robot to make large, fast movements while maintaining its balance on a narrow support. This theory includes a simple method of leaning in anticipation of future motion commands, which is largely responsible for the high performance. The experiments reported here use a robot acting as a reaction wheel pendulum, and they test only the 2-D version of the theory. The results show that the balance controller's performance in practice closely resembles its theoretical performance. This paper also presents a simple yet accurate balance offset observer that measures the difference between true and estimated balanced configurations.


Title: OpenRoACH: A Durable Open-Source Hexapedal Platform with Onboard Robot Operating System (ROS)
Abstract: OpenRoACH is a 15-cm 200-gram self-contained hexapedal robot with an onboard single-board computer. To our knowledge, it is the smallest legged robot with the capability of running the Robot Operating System (ROS) onboard. The robot is fully open sourced, uses accessible materials and off-the-shelf electronic components, can be fabricated with benchtop fast-prototyping machines such as a laser cutter and a 3D printer, and can be assembled by one person within two hours. Its sensory capacity has been tested with gyroscopes, accelerometers, Beacon sensors, color vision sensors, linescan sensors and cameras. It is low-cost within $150 including structure materials, motors, electronics, and a battery. The capabilities of OpenRoACH are demonstrated with multi-surface walking and running, 24-hour continuous walking burn-ins, carrying 200-gram dynamic payloads and 800-gram static payloads, and ROS control of steering based on camera feedback. Information and files related to mechanical design, fabrication, assembly, electronics, and control algorithms are all publicly available on https://wiki.eecs.berkeley.edu/biomimetics/Main/OpenRoACH.


Title: Constrained Feedback Control by Prioritized Multi-objective Optimization
Abstract: Prioritized multi-objective optimization has been widely used within the operational space inverse dynamics control framework. In this paper, we present a constrained prioritized multi-objective optimization-base control formulation that extends to impedance control, including the `simple' impedance controller, which does not require the dynamic model. The main contribution of this paper is the dynamic-model-free prioritized feedback control formulation which encompasses arbitrary number of priority levels and takes the saturation constraints on the control inputs rigorously into account. The utility of the proposed formulation is demonstrated by a combined inverse dynamics impedance controller used to simulate stable locomotion of a planar anthropometric biped robot.


Title: Exploitation of Environment Support Contacts for Manipulation Effort Reduction of a Robot Arm
Abstract: Humans commonly exploit interaction with the environment constraints to assist the execution of the loco-manipulation tasks they perform. One particular example is the exploration of contacts during manipulation to relax the loading of those arm joints that are not directly involved in the generation of the manipulation motions and forces, e.g. establishing a contact with the elbow joint to reduce the effort of the upper arm while executing wrist level manipulation. In this paper, we shall explore the possibility of actively (a) utilizing the environment for a non-end-effector support contact towards reducing the joints efforts during manipulation tasks. This is achieved by our proposed control scheme with a three-level hierarchical compliance controller. The highest priority task is assigned to an impedance control that regulates the interaction at the contact control point on the arm in the normal direction of the support plane prior to contact, and is switched to an optimal contact force control for minimizing the joint effort after the contact is built. The second priority task is an impedance control at the same point in the tangential directions of the plane to stabilize the contact. In the end, an impedance behavior at the end-effector is designed to deal with the interaction forces required by the manipulation tasks. The efficacy of the proposed control scheme was corroborated by simulations and experiments, where significant joint effort reduction was observed.


Title: A Coordinate-based Approach for Static Balancing and Walking Control of Compliantly Actuated Legged Robots
Abstract: The paper addresses the static balancing and walking of elastically actuated legged robots. The control is realized by commanding the motor positions only and exploiting the bijective relation between motor and link positions at equilibrium under static external forces. The approach is formulated in a quite general framework first. The main implementation contribution is the definition of a body coordinate system and of an appropriate set of constraints, which leads to a fully determined system of equations. In addition to the desired COM and the vertical foot positions, which are defined by the walking task and the terrain, the imposed constraints are related to distances between individual legs. The controller is experimentally validated on a compliantly actuated quadruped.


Title: Joint kinematic configuration influence on the passivity of an impedance-controlled robotic leg
Abstract: Although the design of legged robots may be dependent on the application, all of them share the need to safely deal with physical interaction with the environment in every step they take. Impedance controllers have been applied with success to handle contact, and some authors applied the concept of passivity to guarantee stability during the interaction. Whereas previous studies on the passivity of legged robots considered aspects such as inner force loop gains and actuation bandwidth influence on the Z-width (i.e. the range of renderable passive impedances), they did not take into account the role of the kinematic configuration of the leg on the stability of the interaction. Thus, in this work we present a systematic analysis of the effects of joint positions on the passivity conditions of a robotic leg and show that this is a very relevant aspect that may seriously affect the stability and passivity of an impedance controller. By analyzing a linearized model of the leg via its Nyquist plots and the respective Z-width diagrams, we were able to determine what joint configurations within the leg workspace are more suitable to physically interact with the environment or people.


Title: Towards Robot Interaction Autonomy: Explore, Identify, and Interact
Abstract: Nowadays, robots are expected to enter in various application scenarios and interact with unknown and dynamically changing environments. This highlights the need for creating autonomous robot behaviours to explore such environments, identify their characteristics and adapt, and build knowledge for future interactions. To respond to this need, in this paper we present a novel framework that integrates multiple components to achieve a context-aware and adaptive interaction between the robot and uncertain environments. The core of this framework is a novel self-tuning impedance controller that regulates robot quasi-static parameters, i.e., stiffness and damping, based on the robot sensory data and vision. The tuning of the parameters is achieved only in the direction(s) of interaction or movement, by distinguishing expected interactions from external disturbances. A vision module is developed to recognize the environmental characteristics and to associate them to the previously/newly identified interaction parameters, with the robot always being able to adapt to the new changes or unexpected situations. This enables a faster robot adaptability, starting from better initial interaction parameters. The framework is evaluated experimentally in an agricultural task, where the robot effectively interacts with various deformable environments.


Title: Knowledge is Never Enough: Towards Web Aided Deep Open World Recognition
Abstract: While today's robots are able to perform sophisticated tasks, they can only act on objects they have been trained to recognize. This is a severe limitation: any robot will inevitably see new objects in unconstrained settings, and thus will always have visual knowledge gaps. However, standard visual modules are usually built on a limited set of classes and are based on the strong prior that an object must belong to one of those classes. Identifying whether an instance does not belong to the set of known categories (i.e. open set recognition), only partially tackles this problem, as a truly autonomous agent should be able not only to detect what it does not know, but also to extend dynamically its knowledge about the world. We contribute to this challenge with a deep learning architecture that can dynamically update its known classes in an end-to-end fashion. The proposed deep network, based on a deep extension of a non-parametric model, detects whether a perceived object belongs to the set of categories known by the system and learns it without the need to retrain the whole system from scratch. Annotated images about the new category can be provided by an `oracle' (i.e. human supervision), or by autonomous mining of the Web. Experiments on two different databases and on a robot platform demonstrate the promise of our approach.


Title: Inferring Robot Morphology from Observation of Unscripted Movement
Abstract: Task sharing between heterogeneous robots currently requires a priori capability knowledge, a shared communication protocol, or a centralized planner. However, in practice, when two robots are brought together, the effort required to construct shared action and structure models can be significant. In this paper, we describe our approach to determining the kinematic model of a robot based purely on observation of unscripted movement. We describe construction of large-scale data simulating low-cost RGB-D camera output, and application of two different RNN-based methods to the learning problem. Our results suggest that this is an efficient and effective way to determine a robot's morphological structure without requiring communication or pre-existing knowledge of its capabilities.


Title: Joint Learning of Instance and Semantic Segmentation for Robotic Pick-and-Place with Heavy Occlusions in Clutter
Abstract: We present joint learning of instance and semantic segmentation for visible and occluded region masks. Sharing the feature extractor with instance occlusion segmentation, we introduce semantic occlusion segmentation into the instance segmentation model. This joint learning fuses the instance-and image-level reasoning of the mask prediction on the different segmentation tasks, which was missing in the previous work of learning instance segmentation only (instance-only). In the experiments, we evaluated the proposed joint learning comparing the instance-only learning on the test dataset. We also applied the joint learning model to 2 different types of robotic pick-and-place tasks (random and target picking) and evaluated its effectiveness to achieve real-world robotic tasks.


Title: Weakly Supervised Recognition of Surgical Gestures
Abstract: Kinematic trajectories recorded from surgical robots contain information about surgical gestures and potentially encode cues about surgeon's skill levels. Automatic segmentation of these trajectories into meaningful action units could help to develop new metrics for surgical skill assessment as well as to simplify surgical automation. State-of-the-art methods for action recognition relied on manual labelling of large datasets, which is time consuming and error prone. Unsupervised methods have been developed to overcome these limitations. However, they often rely on tedious parameter tuning and perform less well than supervised approaches, especially on data with high variability such as surgical trajectories. Hence, the potential of weak supervision could be to improve unsupervised learning while avoiding manual annotation of large datasets. In this paper, we used at a minimum one expert demonstration and its ground truth annotations to generate an appropriate initialization for a GMM-based algorithm for gesture recognition. We showed on real surgical demonstrations that the latter significantly outperforms standard task-agnostic initialization methods. We also demonstrated how to improve the recognition accuracy further by redefining the actions and optimising the inputs.


Title: A Flexible Low-Cost Biologically Inspired Sonar Sensor Platform for Robotic Applications
Abstract: In this paper we present a flexible low-cost sonar sensor platform that can be used for a wide range of biomimetic sonar experiments and autonomous sonar navigation targeted at robotics applications. The navigation abilities of bats using ultrasound (sonar) in unknown cluttered environments are very effective and can be distilled into a sensor architecture and accompanying control methodology that lends itself to be implemented on cost efficient hardware. The sensor architecture and processing methodology of this sensing platform mimics that of bats. In this paper we specifically focused on the common big-eared bat (Micronycteris microtis) although this could be transferred to other bat species or even other echolocating animals since the experimental platform was designed for flexibility. Using this platform we were able to implement a control system using a subsumption architecture that features different behavior patterns based solely on the sonar sensor as a source of exteroceptive information. In order to validate the combination of our autonomous navigation control system and our developed sonar sensor platform, the hardware was mounted on the P3DX robotics platform that was introduced in an unknown testing environment and have it drive autonomously. These experiments were used to validate our assumption of the efficacy of these relatively simple biomimetic control mechanisms and thus alleviating the need for expensive sensing platforms for certain robotics applications.


Title: ClusterNav: Learning-Based Robust Navigation Operating in Cluttered Environments
Abstract: Robust autonomous navigation is one of the most important aspects in the acceptance of social robots by elderly users. Traditional model-based navigation techniques provide a stable theoretical and practical foundation for autonomous operation in domestic environments, but fall short in achieving human-like, acceptable behaviour while still being able to robustly navigate cluttered environments. In this work, we propose ClusterNav, a novel learning-based technique for navigation. Our technique consists of teaching the robot how it should move in the environment in a human-like manner, capturing key features of this demonstration in a geometric representation of the environment. This representation is then used to generate new trajectories for execution, allowing the robot move in an acceptable manner. We have tested our technique in a real environment in an elderly care facility, comparing it with the traditional model-based approach. Tests involved both expert and non-expert users teleoperating the robot. Results show that ClusterNav is capable of navigating the environment, achieving better similarity with the reference trajectories and higher execution speed when compared to the model-based approach.


Title: Adaptive motor control and learning in a spiking neural network realised on a mixed-signal neuromorphic processor
Abstract: Neuromorphic computing is a new paradigm for design of both the computing hardware and algorithms inspired by biological neural networks. The event-based nature and the inherent parallelism make neuromorphic computing a promising paradigm for building efficient neural network based architectures for control of fast and agile robots. In this paper, we present a spiking neural network architecture that uses sensory feedback to control rotational velocity of a robotic vehicle. When the velocity reaches the target value, the mapping from the target velocity of the vehicle to the correct motor command, both represented in the spiking neural network on the neuromorphic device, is autonomously stored on the device using on-chip plastic synaptic weights. We validate the controller using a wheel motor of a miniature mobile vehicle and inertia measurement unit as the sensory feedback and demonstrate online learning of a simple “inverse model” in a two-layer spiking neural network on the neuromorphic chip. The prototype neuromorphic device that features 256 spiking neurons allows us to realise a simple proof of concept architecture for the purely neuromorphic motor control and learning. The architecture can be easily scaled-up if a larger neuromorphic device is available.


Title: End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot
Abstract: This paper introduces an end-to-end learning approach based on Reward-modulated Spike-Timing-Dependent Plasticity (R-STDP) for a multi-layered spiking neural network (SNN). As a case study, a snake-like robot is used as an agent to perform target tracking tasks on the basis of our proposed approach. Since the key of R-STDP is to use rewards to modulate synapse strengthens, we first propose a general way to propagate the reward back through a multi-layered SNN. Upon the proposed approach, we build up an SNN controller that drives a snake-like robot for performing target tracking tasks. We demonstrate the practicability and advantage of our approach in terms of lateral tracking accuracy by comparing it to other state-of-the-art learning algorithms for SNNs based on R-STDP.


Title: Improving collective decision accuracy via time-varying cross-inhibition
Abstract: We investigate decentralised decision-making, in which a robot swarm is tasked with selecting the best-quality option among a set of alternatives. Individual robots are simplistic as they only perform diffusive search, make local noisy estimates of the options' quality, and exchange information with near neighbours. We propose a decentralised algorithm, inspired by house-hunting honeybees, to efficiently aggregate noisy estimations. Individual robots, by varying over time a single decentralised parameter that modulates the interaction strength, balance exploration and agreement. In this way, the swarm first identifies the options under consideration, then rapidly converges on the best available option, even when outnumbered by lower quality options. We present stochastic analyses and swarm robotics simulations to compare the novel strategy with previous methods and to quantify the performance improvement. The proposed strategy limits the spreading of errors within the population and allows swarms of simple noisy units with minimal communication capabilities to make highly accurate collective decisions in predictable time.


Title: A Motion Planning Scheme for Cooperative Loading Using Heterogeneous Robotic Agents
Abstract: In this work, we present a decentralized motion planning and control architecture for the cooperative loading task using heterogeneous robotic agents operating in a cluttered workspace with static obstacles. Initially, we tackle the problem of calculating a set of feasible loading configurations via a Probabilistic Road Maps technique. Next, an optimal loading configuration is selected considering the connectivity of the space and the Euclidean distance between the robotic agents. A motion control scheme for each agent is designed and implemented in order to autonomously guide each robot to the desired loading configuration with guaranteed obstacle avoidance and convergence properties. The performance and the applicability of the proposed strategy is experimentally verified in a variety of loading scenarios using a redundant static manipulator and a mobile platform.


Title: Voluntary Retreat for Decentralized Interference Reduction in Robot Swarms
Abstract: In densely-packed robot swarms operating in confined regions, spatial interference-which manifests itself as a competition for physical space-forces robots to spend more time navigating around each other rather than performing the primary task. This paper develops a decentralized algorithm that enables individual robots to decide whether to stay in the region and contribute to the overall mission, or vacate the region so as to reduce the negative effects that interference has on the overall efficiency of the swarm. We develop this algorithm in the context of a distributed collection task, where a team of robots collect and deposit objects from one set of locations to another in a given region. Robots do not communicate and use only binary information regarding the presence of other robots around them to make the decision to stay or retreat. We illustrate the efficacy of the algorithm with experiments on a team of real robots.


Title: Spatial Coverage Without Computation
Abstract: We study the problem of controlling a swarm of anonymous, mobile robots to cooperatively cover an unknown two-dimensional space. The novelty of our proposed solution is that it is applicable to extremely simple robots that lack run-time computation or storage. The solution requires only a single bit of information per robot-whether or not another robot is present in its line of sight. Computer simulations show that our deterministic controller, which was obtained through off-line optimization, achieves around 71-76% coverage in a test scenario with no robot redundancy, which corresponds to a 26-39% reduction of the area that is not covered, when compared to an optimized random walk. A moderately lower level of performance was observed in 20 experimental trials with 25 physical e-puck robots. Moreover, we demonstrate that the same controller can be used in environments of different dimensions and even to navigate a maze. The controller provides a baseline against which one can quantify the performance improvements that more advanced and expensive techniques may offer. Moreover, due to its simplicity, it could potentially be implemented on swarms of sub-millimeter-sized robots. This would pave the way for new applications in micro-medicine.


Title: Go with the Flow: Exploration and Mapping of Pedestrian Flow Patterns from Partial Observations
Abstract: Understanding how people are likely to behave in an environment is a key requirement for efficient and safe robot navigation. However, mobile platforms are subject to spatial and temporal constraints, meaning that only partial observations of human activities are typically available to a robot, while the activity patterns of people in a given environment may also change at different times. To address these issues we present as the main contribution an exploration strategy for acquiring models of pedestrian flows, which decides not only the locations to explore but also the times when to explore them. The approach is driven by the uncertainty from multiple Poisson processes built from past observations. The approach is evaluated using two long-term pedestrian datasets, comparing its performance against uninformed exploration strategies. The results show that when using the uncertainty in the exploration policy, model accuracy increases, enabling faster learning of human motion patterns.


Title: Design and Analysis of A Miniature Two-Wheg Climbing Robot with Robust Internal and External Transitioning Capabilities
Abstract: Plane-to-plane transitioning has been a significant challenge for climbing robots. To accomplish this, additional actuator or robot module is usually required which significantly increases both size and weight of the robot. This paper presents a two-wheg miniature climbing robot with a novel passive vertical tail component which results in robust transitioning capabilities. The design decision was derived from an indepth force analysis of the climbing robot while performing the transition. The theoretical analysis is verified through a working prototype with robust transitioning capabilities whose performance follows closely the analytical prediction. The climbing robot is able to climb any slope angles, 4-way internal transitions, and 4-way external transitions. This work contributes to the understanding and advancement of the transitioning capabilities and the design of a simple climbing robot, which expands the possibilities of scaling down miniature climbing robot further.


Title: Design and Implementation of CCRobot-II: a Palm-based Cable Climbing Robot for Cable-stayed Bridge Inspection
Abstract: This project aims at developing a bio-inspired climbing robotic technology for cable inspection on the cable-stayed bridge. The design and implementation of a palm-based cable climbing robot: CCRobot-II with mass 25 kg, maximal payload 30kg and maximal length 1.1 m are described. CCRobot-II consists of several novel design features, including the palm-based gripping module, the alternating-sliding frame specialized for high-speed climbing, and the following wheels. With its carefully designed mechanism, climbing gait and trajectory algorithm, CCRobot-II is able to crawl along a bridge cable with a maximal speed 5.2 m/min. This speed has been hardly achieved by a existing climbing robot with such a large scale, and it is nearly the twice as the climbing speed of CCRobot-I which is designed previously. CCRobot-II also works effectively even if the bridge cable surface is attached with small obstacles. Experiments have been conducted, the results show that CCRobot-II has potential engineering applications on the cable-stayed bridge for fieldwork.


Title: Dynamic Modeling and Gait Analysis for Miniature Robots in the Absence of Foot Placement Control
Abstract: The study of animals and insects have led to realization that animals select their gaits, patterns of leg movement, according to speed. For proper gait planning, the legs must be controlled for proper foot placement with respect to the body motion and ground interactions. However, in small scale robotic platforms gait planning through foot placement control is neither cost effective nor easily attainable due to a lack of available sensors. Thus, even though a desired gait is envisioned at the design phase, it is not known whether the gait is optimum. In this work, we present the comprehensive dynamic model of the miniature foldable robot, MinIAQ-II, which has four independently actuated legs. Dynamic model is used to perform gait analysis, to investigate the difference between the intended gait and the achieved gait in the absence of foot placement control. The model is verified through slow speed walking experiments on flat terrain. The work presented can be modified for different miniature robots with passive legs to predict their locomotion under no foot placement control.


Title: Memory Efficient Experience Replay for Streaming Learning
Abstract: In supervised machine learning, an agent is typically trained once and then deployed. While this works well for static settings, robots often operate in changing environments and must quickly learn new things from data streams. In this paradigm, known as streaming learning, a learner is trained online, in a single pass, from a data stream that cannot be assumed to be independent and identically distributed (iid). Streaming learning will cause conventional deep neural networks (DNNs) to fail for two reasons: 1) they need multiple passes through the entire dataset; and 2) non-iid data will cause catastrophic forgetting. An old fix to both of these issues is rehearsal. To learn a new example, rehearsal mixes it with previous examples, and then this mixture is used to update the DNN. Full rehearsal is slow and memory intensive because it stores all previously observed examples, and its effectiveness for preventing catastrophic forgetting has not been studied in modern DNNs. Here, we describe the ExStream algorithm for memory efficient rehearsal and compare it to alternatives. We find that full rehearsal can eliminate catastrophic forgetting in a variety of streaming learning settings, with ExStream performing well using far less memory and computation.


Title: RoboCSE: Robot Common Sense Embedding
Abstract: Autonomous service robots require computational frameworks that allow them to generalize knowledge to new situations in a manner that models uncertainty while scaling to real-world problem sizes. The Robot Common Sense Embedding (RoboCSE) showcases a class of computational frameworks, multi-relational embeddings, that have not been leveraged in robotics to model semantic knowledge. We validate RoboCSE on a realistic home environment simulator (AI2Thor) to measure how well it generalizes learned knowledge about object affordances, locations, and materials. Our experiments show that RoboCSE can perform prediction better than a baseline that uses pre-trained embeddings, such as Word2Vec, achieving statistically significant improvements while using orders of magnitude less memory than our Bayesian Logic Network baseline. In addition, we show that predictions made by RoboCSE are robust to significant reductions in data available for training as well as domain transfer to MatterPort3D, achieving statistically significant improvements over a baseline that memorizes training data.


Title: Jointly Learning to Construct and Control Agents using Deep Reinforcement Learning
Abstract: The physical design of a robot and the policy that controls its motion are inherently coupled, and should be determined according to the task and environment. In an increasing number of applications, data-driven and learning-based approaches, such as deep reinforcement learning, have proven effective at designing control policies. For most tasks, the only way to evaluate a physical design with respect to such control policies is empirical-i.e., by picking a design and training a control policy for it. Since training these policies is time-consuming, it is computationally infeasible to train separate policies for all possible designs as a means to identify the best one. In this work, we address this limitation by introducing a method that jointly optimizes over the physical design and control network. Our approach maintains a distribution over designs and uses reinforcement learning to optimize a control policy to maximize expected reward over the design distribution. We give the controller access to design parameters to allow it to tailor its policy to each design in the distribution. Throughout training, we shift the distribution towards higher-performing designs, eventually converging to a design and control policy that are jointly optimal. We evaluate our approach in the context of legged locomotion, and demonstrate that it discovers novel designs and walking gaits, outperforming baselines across different settings.


Title: Steering a Multi-armed Robotic Sheath Using Eccentric Precurved Tubes
Abstract: This paper presents a novel continuum robot sheath for use in single-port minimally invasive procedures such as neuroendoscopy in which the sheath is designed to deliver multiple robotic arms. Articulation of the sheath is achieved by using precurved superelastic tubes lining the working channels used for arm delivery. These tubes perform a similar role to push/pull tendons, but can accomplish shape change of the sheath via rotation as well as translation. A kinematic model using Cosserat rod theory is derived which is based on modeling the system as a set of eccentrically aligned precurved tubes constrained along their length by an elastic backbone. The specific case of a two-arm sheath is considered in detail and its relationship to a concentric tube balanced pair is described. Simulation and experiment are used to investigate the concept, map its workspace and to evaluate the kinematic model.


Title: Continuous signed distance computation for polygonal robots in 3D
Abstract: We propose a novel method adaptive subdivision (AS) to evaluate the distance function for moving general polygonal models. The distance function can have a positive and a negative value, each of which corresponds to the Euclidean distance and penetration depth, respectively. In our approach, the distance between a pair of objects can be evaluated along any time interval of the object's trajectory; therefore it is called “continuous”, and a minimum of the continuous distance (MCD) is determined for collision avoidance. In order to compute a MCD for general polygonal models, we calculate the upper and lower bounds of the distance in the time interval and abandons the time intervals that cannot realize the MCD. We have implemented our distance evaluation method, and have experimentally validated the proposed methods to effectively and accurately find the MCDs to generate a collision-free motion for the HRP-2 humanoid robot.


Title: Dynamics Consensus between Centroidal and Whole-Body Models for Locomotion of Legged Robots
Abstract: It is nowadays well-established that locomotion can be written as a large and complex optimal control problem. Yet, current knowledge in numerical solver fails to directly solve it. A common approach is to cut the dimensionality by relying on reduced models (inverted pendulum, capture points, centroidal). However it is difficult both to account for whole-body constraints at the reduced level and also to define what is an acceptable trade-off at the whole-body level between tracking the reduced solution or searching for a new one. The main contribution of this paper is to introduce a rigorous mathematical framework based on the Alternating Direction Method of Multipliers, to enforce the consensus between the centroidal state dynamics at reduced and whole-body level. We propose an exact splitting of the whole-body optimal control problem between the centroidal dynamics (under-actuation) and the manipulator dynamics (full actuation), corresponding to a re-arrangement of the equations already stated in previous works. We then describe with details how alternating descent is a good solution to implement an effective locomotion solver. We validate this approach in simulation with walking experiments on the HRP-2 robot.


Title: Efficient Computation of Feedback Control for Equality-Constrained LQR
Abstract: A method is presented for solving the discrete-time finite-horizon Linear Quadratic Regulator (LQR) problem subject to auxiliary linear equality constraints, such as fixed end-point constraints. The method explicitly determines an affine relationship between the control and state variables, as in standard Riccati recursion, giving rise to feedback control policies that account for constraints. Since the linearly-constrained LQR problem arises commonly in robotic trajectory optimization, having a method that can efficiently compute these solutions is important. We demonstrate some of the useful properties and interpretations of said control policies, and we compare the computation time and complexity of our method against existing methods.


Title: Mitigating energy loss in a robot hopping on a physically emulated dissipative substrate
Abstract: We work with geoscientists studying erosion and desertification to improve the spatial and temporal resolution of their data collection over long transects in difficult realworld environments such as deserts [1]. The Minitaur [2] robot, which can run quickly over uneven terrain and use a single leg to measure relevant ground properties such as stiffness [3], is an attractive scout robot candidate for inclusion in a heterogeneous team in collaboration with a heavily geared, sensor-laden RHex [4]. However, Minitaur is challenged by long-distance locomotion on sand dunes. Previous simulation results [5] suggested that the energetic cost of transport can be mitigated by programming a virtual damping force to slow the intrusion of a Minitaur foot into simulated granular media following a bulk-behavior force law [6]. In this paper, we present a ground emulator that can be used to test such locomotion hypotheses with a physical single-legged hopper jumping on emulated ground programmed to exhibit any compliance and damping characteristics of interest. The new emulator allows us to corroborate the conclusions of our previous simulation with physical hopping experiments. Programming the substrate emulator to exhibit the mechanics of a simplified bulk-behavior model of granular media characterized by linear stiffness and quadratic damping, we achieve a consistent energy savings of 20% in comparison with a nominal controller, with savings of up to 50% under specific conditions.


Title: Energy Efficient Navigation for Running Legged Robots
Abstract: Energy-efficient navigation is an important technology for mobile robots because of its potential to increase the operation time of the robot. In particular, when coupled with a dynamic legged quadruped, the need for energy savings is made more apparent as payloads are limited. Due to the complexity in modeling motion and power models of these robots, a new approach is necessary to effectively motion plan for these complex robots. We accomplish this by using Sampling-Based Model Predictive optimization (SBMPO) which was extended for use on the LLAMA quadrupedal platform in simulation. SBMPO allows for direct generation of trajectories while using a heuristic-based search to speed up computations. This approach is shown to effectively motion plan while optimizing for energy consumption and maintaining the natural dynamics of the robot in a simulated environment.


Title: Force-controllable Quadruped Robot System with Capacitive-type Joint Torque Sensor
Abstract: This paper introduces a force-controllable quadruped robot system consists of twelve Actuator Modules embedded a novel Capacitive-type Joint Torque Sensor (CJTS) which is accurate (0.05 Nm), robust to impact, and easy to manufacture at low cost. The Actuator Module with CJTS shows accurate joint torque controllability in range of ±70 Nm (90 % settling time 0.04 s). The leg made by the three Actuator Modules is capable of generating forces in the z-axis up to 350 N and shows force control performances with zero-force control and lifting weights in three-dimensional space. To reduce the reflected limb inertia, all the Actuator Modules are located on the body frame and light-weight limbs made of the carbon pipe (3.6 % of total body weight). The introduced robot performed the motion on various terrains with walking/trot gaits.


Title: Visual Diver Recognition for Underwater Human-Robot Collaboration
Abstract: This paper presents an approach for autonomous underwater robots to visually detect and identify divers. The proposed approach enables an autonomous underwater robot to detect multiple divers in a visual scene and distinguish between them. Such methods are useful for robots to identify a human leader, for example, in multi-human/robot teams where only designated individuals are allowed to command or lead a team of robots. Initial diver identification is performed using the Faster R-CNN algorithm with a region proposal network which produces bounding boxes around the divers' locations. Subsequently, a suite of spatial and frequency domain descriptors are extracted from the bounding boxes to create a feature vector. A K-Means clustering algorithm, with k set to the number of detected bounding boxes, thereafter identifies the detected divers based on these feature vectors. We evaluate the performance of the proposed approach on video footage of divers swimming in front of a mobile robot and demonstrate its accuracy.


Title: An Integrated Approach to Navigation and Control in Micro Underwater Robotics using Radio-Frequency Localization
Abstract: Navigation and control are a largely unsolved problems for micro autonomous underwater vehicles (μAUVs). The main challenges are due to the lack of accurate underwater localization systems, which fit on-board of μAUVs. In this work, we present an integrated navigation and control architecture consisting of a low-cost embedded localization module and an underwater way-point tracking controller, which fulfills the requirements of μAUVs. The performance of the navigation and control system is benchmarked in two different experimental scenarios.


Title: Online Continuous Mapping using Gaussian Process Implicit Surfaces
Abstract: The representation of the environment strongly affects how robots can move and interact with it. This paper presents an online approach for continuous mapping using Gaussian Process Implicit Surfaces (GPISs). Compared with grid-based methods, GPIS better utilizes sparse measurements to represent the world seamlessly. It provides direct access to the signed-distance function (SDF) and its derivatives which are invaluable for other robotic tasks and it incorporates uncertainty in the sensor measurements. Our approach incrementally and efficiently updates GPIS by employing a regressor on observations and a spatial tree structure. The effectiveness of the suggested approach is demonstrated using simulations and real world 2D/3D data.


Title: Predicting the Layout of Partially Observed Rooms from Grid Maps
Abstract: In several applications, autonomous mobile robots benefit from knowing the structure of the indoor environments where they operate. This knowledge can be extracted from the metric maps built (e.g., using SLAM algorithms) from the data perceived by the robots' sensors. The layout is a way to represent the structure of an indoor environment with geometrical primitives. Most of the current methods for reconstructing the layout from a metric map represent the parts of the environment that have been fully observed. In this paper, we propose an approach that predicts the layout of rooms which are only partially known in a 2D metric grid map. The prediction is made according to the global structure of the environment, as identified from its known parts. Experiments show that our approach is able to effectively predict the layout of several indoor environments that have been observed to different degrees.


Title: FSMI: Fast Computation of Shannon Mutual Information for Information-Theoretic Mapping
Abstract: Information-based mapping algorithms are critical to robot exploration tasks in several applications ranging from disaster response to space exploration. Unfortunately, most existing information-based mapping algorithms are plagued by the computational difficulty of evaluating the Shannon mutual information between potential future sensor measurements and the map. This has lead researchers to develop approximate methods, such as Cauchy-Schwarz Quadratic Mutual Information (CSQMI). In this paper, we propose a new algorithm, called Fast Shannon Mutual Information (FSMI), which is significantly faster than existing methods at computing the exact Shannon mutual information. The key insight behind FSMI is recognizing that the integral over the sensor beam can be evaluated analytically, removing an expensive numerical integration. In addition, we provide a number of approximation techniques for FSMI, which significantly improve computation time. Equipped with these approximation techniques, the FSMI algorithm is more than three orders of magnitude faster than the existing computation for Shannon mutual information; it also outperforms the CSQMI algorithm significantly, being roughly twice as fast, in our experiments.


Title: Inferring Compact Representations for Efficient Natural Language Understanding of Robot Instructions
Abstract: The speed and accuracy with which robots are able to interpret natural language is fundamental to realizing effective human-robot interaction. A great deal of attention has been paid to developing models and approximate inference algorithms that improve the efficiency of language understanding. However, existing methods still attempt to reason over a representation of the environment that is flat and unnecessarily detailed, which limits scalability. An open problem is then to develop methods capable of producing the most compact environment model sufficient for accurate and efficient natural language understanding. We propose a model that leverages environment-related information encoded within instructions to identify the subset of observations and perceptual classifiers necessary to perceive a succinct, instruction-specific environment representation. The framework uses three probabilistic graphical models trained from a corpus of annotated instructions to infer salient scene semantics, perceptual classifiers, and grounded symbols. Experimental results on two robots operating in different environments demonstrate that by exploiting the content and the structure of the instructions, our method learns compact environment representations that significantly improve the efficiency of natural language symbol grounding.


Title: Improving Grounded Natural Language Understanding through Human-Robot Dialog
Abstract: Natural language understanding for robotics can require substantial domain- and platform-specific engineering. For example, for mobile robots to pick-and-place objects in an environment to satisfy human commands, we can specify the language humans use to issue such commands, and connect concept words like red can to physical object properties. One way to alleviate this engineering for a new domain is to enable robots in human environments to adapt dynamically-continually learning new language constructions and perceptual concepts. In this work, we present an end-to-end pipeline for translating natural language commands to discrete robot actions, and use clarification dialogs to jointly improve language parsing and concept grounding. We train and evaluate this agent in a virtual setting on Amazon Mechanical Turk, and we transfer the learned agent to a physical robot platform to demonstrate it in the real world.


Title: Prospection: Interpretable plans from language by predicting the future
Abstract: High-level human instructions often correspond to behaviors with multiple implicit steps. In order for robots to be useful in the real world, they must be able to to reason over both motions and intermediate goals implied by human instructions. In this work, we propose a framework for learning representations that convert from a natural-language command to a sequence of intermediate goals for execution on a robot. A key feature of this framework is prospection, training an agent not just to correctly execute the prescribed command, but to predict a horizon of consequences of an action before taking it. We demonstrate the fidelity of plans generated by our framework when interpreting real, crowd-sourced natural language commands for a robot in simulated scenes.


Title: Flight, Camera, Action! Using Natural Language and Mixed Reality to Control a Drone
Abstract: With increasing autonomy, robots like drones are increasingly accessible to untrained users. Most users control drones using a low-level interface, such as a radio-controlled (RC) controller. For a wider adoption of these technologies by the public, a much higher-level interface, such as natural language or mixed reality (MR), allows the automation of the control of the agent in a goal-oriented setting. We present an interface that uses natural language grounding within an MR environment to solve high-level task and navigational instructions given to an autonomous drone. To the best of our knowledge, this is the first work to perform fully autonomous language grounding in an MR setting for a robot. Given a map, our interface first grounds natural language commands to reward specifications within a Markov Decision Process (MDP) framework. Then, it passes the reward specification to an MDP solver. Finally, the drone performs the desired operations in the real world while planning and localizing itself. Our approach uses MR to provide a set of known virtual landmarks, enabling the drone to understand commands referring to objects without being equipped with object detectors for multiple novel objects or a predefined environment model. We conducted an exploratory user study to assess users' experience of our MR interface with and without natural language, as compared to a web interface. We found that users were able to command the drone more quickly via both MR interfaces as compared to the web interface, with roughly equal system usability scores across all three interfaces.


Title: An Interactive Scene Generation Using Natural Language
Abstract: Scene generation is an important step of robotic drawing. Recent works have shown success in scene generation conditioned on text using a variety of approaches, with which the generated scenes cannot be revised after its generation. To allow modification on generated scenes, we model the scene generation process as a discrete event system. Instead of training text-to-pixel mappings using large datasets, the proposed approach uses object instances retrieved from the Internet to synthesize scenes. Evaluated on 128 experiments using MSCOCO evaluation dataset, the result shows the scene generation performance has been increased by 197%, 22.3%, and 55.7% compared with the state of the art approach on three standard metrics (CIDEr, ROUGH-L, METEOR), respectively. Human evaluation conducted on Amazon Mechanical Turk shows over 80% of generated scenes are considered to have higher recognizability and better alignment with natural language descriptions than baseline works.


Title: Efficient Generation of Motion Plans from Attribute-Based Natural Language Instructions Using Dynamic Constraint Mapping
Abstract: We present an algorithm for combining natural language processing (NLP) and fast robot motion planning to automatically generate robot movements. Our formulation uses a novel concept called Dynamic Constraint Mapping to transform complex, attribute-based natural language instructions into appropriate cost functions and parametric constraints for optimization-based motion planning. We generate a factor graph from natural language instructions called the Dynamic Grounding Graph (DGG), which takes latent parameters into account. The coefficients of this factor graph are learned based on conditional random fields (CRFs) and are used to dynamically generate the constraints for motion planning. We map the cost function directly to the motion parameters of the planner and compute smooth trajectories in dynamic scenes. We highlight the performance of our approach in a simulated environment and via a human interacting with a 7-DOF Fetch robot using intricate language commands including negation, orientation specification, and distance constraints.


Title: Learning from Extrapolated Corrections
Abstract: Our goal is to enable robots to learn cost functions from user guidance. Often it is difficult or impossible for users to provide full demonstrations, so corrections have emerged as an easier guidance channel. However, when robots learn cost functions from corrections rather than demonstrations, they have to extrapolate a small amount of information - the change of a waypoint along the way - to the rest of the trajectory. We cast this extrapolation problem as online function approximation, which exposes different ways in which the robot can interpret what trajectory the person intended, depending on the function space used for the approximation. Our simulation results and user study suggest that using function spaces with non-Euclidean norms can better capture what users intend, particularly if environments are uncluttered. This, in turn, can lead to the robot learning a more accurate cost function and improves the user's subjective perceptions of the robot.


Title: Merging Position and orientation Motion Primitives
Abstract: In this paper, we focus on generating complex robotic trajectories by merging sequential motion primitives. A robotic trajectory is a time series of positions and orientations ending at a desired target. Hence, we first discuss the generation of converging pose trajectories via dynamical systems, providing a rigorous stability analysis. Then, we present approaches to merge motion primitives which represent both the position and the orientation part of the motion. Developed approaches preserve the shape of each learned movement and allow for continuous transitions among succeeding motion primitives. Presented methodologies are theoretically described and experimentally evaluated, showing that it is possible to generate a smooth pose trajectory out of multiple motion primitives.


Title: Learning Haptic Exploration Schemes for Adaptive Task Execution
Abstract: The recent generation of compliant robots enables kinesthetic teaching of novel skills by human demonstration. This enables strategies to transfer tasks to the robot in a more intuitive way than conventional programming interfaces. Programming physical interactions can be achieved by manually guiding the robot to learn the behavior from the motion and force data. To let the robot react to changes in the environment, force sensing can be used to identify constraints and act accordingly. While autonomous exploration strategies in the whole workspace are time consuming, we propose a way to learn these schemes from human demonstrations in an object targeted manner. The presented teaching strategy and the learning framework allow to generate adaptive robot behaviors relying on the robot's sense of touch in a systematically changing environment. A generated behavior consists of a hierarchical representation of skills, where haptic exploration skills are used to touch the environment with the end effector, and relative manipulation skills, which are parameterized according to previous exploration events. The effectiveness of the approach has been proven in a manipulation task, where the adaptive task structure is able to generalize to unseen object locations. The robot autonomously manipulates objects without relying on visual feedback.


Title: Learning Motion Trajectories from Phase Space Analysis of the Demonstration
Abstract: A major goal of learning from demonstration is task generalization via observation of a teacher. In this paper, we propose a novel framework for learning motion from a single demonstration. Our approach reconstructs the demonstrated trajectory's phase space curve via a linear piece-wise regression method. We approximate dynamics of trajectory segments with linear time invariant equations, each yielding closed form solutions. We show convergence to desired phase space states via an energy-based analysis. The robustness of the model is evaluated on a robot for a sequential trajectory task. Additionally, we show the advantages that the phase space model has over the dynamic motion primitive for a kinematic based task.


Title: Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs
Abstract: The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.


Title: Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations
Abstract: Deployment of deep learning models in robotics as sensory information extractors can be a daunting task to handle, even using generic GPU cards. Here, we address three of its most prominent hurdles, namely, i) the adaptation of a single model to perform multiple tasks at once (in this work, we consider depth estimation and semantic segmentation crucial for acquiring geometric and semantic understanding of the scene), while ii) doing it in real-time, and iii) using asymmetric datasets with uneven numbers of annotations per each modality. To overcome the first two issues, we adapt a recently proposed real-time semantic segmentation network, making changes to further reduce the number of floating point operations. To approach the third issue, we embrace a simple solution based on hard knowledge distillation under the assumption of having access to a powerful `teacher' network. We showcase how our system can be easily extended to handle more tasks, and more datasets, all at once, performing depth estimation and segmentation both indoors and outdoors with a single model. Quantitatively, we achieve results equivalent to (or better than) current state-of-the-art approaches with one forward pass costing just 13ms and 6.5 GFLOPs on 640×480 inputs. This efficiency allows us to directly incorporate the raw predictions of our network into the SemanticFusion framework [1] for dense 3D semantic reconstruction of the scene.


Title: Real-Time Monocular Object-Model Aware Sparse SLAM
Abstract: Simultaneous Localization And Mapping (SLAM) is a fundamental problem in mobile robotics. While sparse point-based SLAM methods provide accurate camera localization, the generated maps lack semantic information. On the other hand, state of the art object detection methods provide rich information about entities present in the scene from a single image. This work incorporates a real-time deep-learned object detector to the monocular SLAM framework for representing generic objects as quadrics that permit detections to be seamlessly integrated while allowing the real-time performance. Finer reconstruction of an object, learned by a CNN network, is also incorporated and provides a shape prior for the quadric leading further refinement. To capture the structure of the scene, additional planar landmarks are detected by a CNN-based plane detector and modelled as independent landmarks in the map. Extensive experiments support our proposed inclusion of semantic objects and planar structures directly in the bundle-adjustment of SLAM - Semantic SLAM- that enriches the reconstructed map semantically, while significantly improving the camera localization.


Title: Generalized Controllers in POMDP Decision-Making
Abstract: We present a general policy formulation for partially observable Markov decision processes (POMDPs) called controller family policies that may be used as a framework to facilitate the design of new policy forms. We prove how modern approximate policy forms: point-based, finite state controller (FSC), and belief compression, are instances of this family of generalized controller policies. Our analysis provides a deeper understanding of the POMDP model and suggests novel ways to design POMDP solutions that can combine the benefits of different state-of-the-art methods. We illustrate this capability by creating a new customized POMDP policy form called the belief-integrated FSC (BI-FSC) tailored to overcome the shortcomings of a state-of-the-art algorithm that uses non-linear programming (NLP). Specifically, experiments show that for NLP the BI-FSC offers improved performance over a vanilla FSC-based policy form on benchmark domains. Furthermore, we demonstrate the BI-FSC's execution on a real robot navigating in a maze environment. Results confirm the value of using the controller family policy as a framework to design customized policies in POMDP robotic solutions.


Title: Continuous Value Iteration (CVI) Reinforcement Learning and Imaginary Experience Replay (IER) For Learning Multi-Goal, Continuous Action and State Space Controllers
Abstract: This paper presents a novel model-free Reinforcement Learning algorithm for learning behavior in continuous action, state, and goal spaces. The algorithm approximates optimal value functions using non-parametric estimators. It is able to efficiently learn to reach multiple arbitrary goals in deterministic and nondeterministic environments. To improve generalization in the goal space, we propose a novel sample augmentation technique. Using these methods, robots learn faster and overall better controllers. We benchmark the proposed algorithms using simulation and a real-world voltage controlled robot that learns to maneuver in a non-observable Cartesian task space.


Title: iX-BSP: Belief Space Planning through Incremental Expectation
Abstract: Belief space planning (BSP) is a fundamental problem in robotics. Determining an optimal action quickly grows intractable as it involves calculating the expected accumulated cost (reward), where the expectation accounts for all future measurement realizations. State of the art approaches therefore resort to simplifying assumptions and approximations to reduce computational complexity. Importantly, while in robotics re-planning is essential, these approaches calculate each planning session from scratch. In this work we contribute a novel approach, iX-BSP, that is based on the key insight that calculations in consecutive planning sessions are similar in nature and can be thus re-used. Our approach performs incremental calculation of the expectation by appropriately re-using computations already performed in a precursory planing session while accounting for the information obtained in inference between the two planning sessions. The formulation of our approach considers general distributions and accounts for data association aspects. We evaluate iX-BSP in statistical simulation and show that incremental expectation calculations significantly reduce runtime without impacting performance.


Title: What am I touching? Learning to classify terrain via haptic sensing
Abstract: Mobile robots are becoming very popular in real-world outdoors applications, where there are many challenges in robot control and perception. One of the most critical problems is to characterise the terrain traversed by the robot. This knowledge is indispensable for optimal terrain negotiation. Currently, most approaches are performing terrain classification from vision, but there is not enough research on terrain identification from a direct interaction of the robot with the environment. In our work, we proposed new methods for classification of force/torque data from an interaction of the legged robot foot with the ground, gathered during the walking process. We provided machine learning methods for terrain classification from raw force/torque signals for which we achieved 93% accuracy on a challenging dataset with 160 minutes of recorded fixed-length steps. We also worked on a dataset where the assumption of a fixed-length step is not valid. In this case, the final result is around 80% of accuracy. The most important fact is that the data in both cases was recorded while the robot was walking, no particular movements or controlled environment were needed. Additionally, we also proposed a clustering method which allows us to learn about the class membership based on the recorded data only, without any human supervision.


Title: Multi-Object Search using Object-Oriented POMDPs
Abstract: A core capability of robots is to reason about multiple objects under uncertainty. Partially Observable Markov Decision Processes (POMDPs) provide a means of reasoning under uncertainty for sequential decision making, but are computationally intractable in large domains. In this paper, we propose Object-Oriented POMDPs (OO-POMDPs), which represent the state and observation spaces in terms of classes and objects. The structure afforded by OO-POMDPs support a factorization of the agent's belief into independent object distributions, which enables the size of the belief to scale linearly versus exponentially in the number of objects. We formulate a novel Multi-Object Search (MOS) task as an OO-POMDP for mobile robotics domains in which the agent must find the locations of multiple objects. Our solution exploits the structure of OO-POMDPs by featuring human language to selectively update the belief at task onset. Using this structure, we develop a new algorithm for efficiently solving OO-POMDPs: Object-Oriented Partially Observable Monte-Carlo Planning (OOPOMCP). We show that OO-POMCP with grounded language commands is sufficient for solving challenging MOS tasks both in simulation and on a physical mobile robot.


Title: Multi-Task Template Matching for Object Detection, Segmentation and Pose Estimation Using Depth Images
Abstract: Template matching has been shown to accurately estimate the pose of a new object given a limited number of samples. However, pose estimation of occluded objects is still challenging. Furthermore, many robot application domains encounter texture-less objects for which depth images are more suitable than color images. In this paper, we propose a novel framework, Multi-Task Template Matching (MTTM), that finds the nearest template of a target object from a depth image while predicting segmentation masks and a pose transformation between the template and a detected object in the scene using the same feature map of the object region. The proposed feature comparison network computes segmentation masks and pose predictions by comparing feature maps of templates and cropped features of a scene. The segmentation result from this network improves the robustness of the pose estimation by excluding points that do not belong to the object. Experimental results show that MTTM outperforms baseline methods for segmentation and pose estimation of occluded objects despite using only depth images.


Title: A Clustering Approach to Categorizing 7 Degree-of-Freedom Arm Motions during Activities of Daily Living
Abstract: In this paper we present a novel method of categorizing naturalistic human arm motions during activities of daily living using clustering techniques. While many current approaches attempt to define all arm motions using heuristic interpretation, or a combination of several abstract motion primitives, our unsupervised approach generates a hierarchical description of natural human motion with well recognized groups. Reliable recommendation of a subset of motions for task achievement is beneficial to various fields, such as robotic and semi-autonomous prosthetic device applications. The proposed method makes use of well-known techniques such as dynamic time warping (DTW) to obtain a divergence measure between motion segments, DTW barycenter averaging (DBA) to get a motion average, and Ward's distance criterion to build the hierarchical tree. The clusters that emerge summarize the variety of recorded motions into the following general tasks: reach-to-front, transfer-box, drinking from vessel, on-table motion, turning a key or door knob, and reach-to-back pocket. The clustering methodology is justified by comparing against an alternative measure of divergence using Bezier coefficients and K-medoids clustering.


Title: Factored Pose Estimation of Articulated Objects using Efficient Nonparametric Belief Propagation
Abstract: Robots working in human environments often encounter a wide range of articulated objects, such as tools, cabinets, and other jointed objects. Such articulated objects can take an infinite number of possible poses, as a point in a potentially high-dimensional continuous space. A robot must perceive this continuous pose in order to manipulate the object to a desired pose. This problem of perception and manipulation of articulated objects remains a challenge due to its high dimensionality and multi-modal uncertainty. In this paper, we propose a factored approach to estimate the poses of articulated objects using an efficient non-parametric belief propagation algorithm. We consider inputs as geometrical models with articulation constraints, and observed 3D sensor data. The proposed framework produces object-part pose beliefs iteratively. The problem is formulated as a pairwise Markov Random Field (MRF) where each hidden node (continuous pose variable) models an observed object-part's pose and each edge denotes an articulation constraint between a pair of parts. We propose articulated pose estimation by a Pull Message Passing algorithm for Nonparametric Belief Propagation (PMPNBP) and evaluate its convergence properties over scenes with articulated objects.


Title: Domain Randomization for Active Pose Estimation
Abstract: Accurate state estimation is a fundamental component of robotic control. In robotic manipulation tasks, as is our focus in this work, state estimation is essential for identifying the positions of objects in the scene, forming the basis of the manipulation plan. However, pose estimation typically requires expensive 3D cameras or additional instrumentation such as fiducial markers to perform accurately. Recently, Tobin et al. introduced an approach to pose estimation based on domain randomization, where a neural network is trained to predict pose directly from a 2D image of the scene. The network is trained on computer generated images with a high variation in textures and lighting, thereby generalizing to real world images. In this work, we investigate how to improve the accuracy of domain randomization based pose estimation. Our main idea is that active perception - moving the robot to get a better estimate of pose- can be trained in simulation and transferred to real using domain randomization. In our approach, the robot trains in a domain-randomized simulation how to estimate pose from a sequence of images. We show that our approach can significantly improve the accuracy of standard pose estimation in several scenarios: when the robot holding an object moves, when reference objects are moved in the scene, or when the camera is moved around the object.


Title: GraspFusion: Realizing Complex Motion by Learning and Fusing Grasp Modalities with Instance Segmentation
Abstract: Recent progress of deep learning improved the capability of a robot to find a proper grasp of a novel object for different grasp modalities (e.g., pinch and suction). While these previous studies consider multiple modalities separately, several studies develop multi-modal grippers that can achieve simultaneous pinch and suction grasp (multi-modal grasp fusion) for more capable and stable object manipulation. However, the previous studies with these grippers restrict the situations: simple object geometry and uncluttered environments. To overcome these difficulties, we propose a system that consists of: 1) object-class-agnostic grasp modality detection; 2) object-class-agnostic instance segmentation; and 3) grasp template matching for different modalities. The key idea of our work is the introduction of instance segmentation to fuse multiple modalities regarding each instance eluding a grasp of multiple objects at once. In the experiments, we evaluated the proposed system on the real-world picking task in clutter. The experimental results show that the effectiveness of modality detection, instance segmentation, and the integrated system as a whole.


Title: Factored Contextual Policy Search with Bayesian optimization
Abstract: Scarce data is a major challenge to scaling robot learning to truly complex tasks, as we need to generalize locally learned policies over different task contexts. Contextual policy search offers data-efficient learning and generalization by explicitly conditioning the policy on a parametric context space. In this paper, we further structure the contextual policy representation. We propose to factor contexts into two components: target contexts that describe the task objectives, e.g. target position for throwing a ball; and environment contexts that characterize the environment, e.g. initial position or mass of the ball. Our key observation is that experience can be directly generalized over target contexts. We show that this can be easily exploited in contextual policy search algorithms. In particular, we apply factorization to a Bayesian optimization approach to contextual policy search both in sampling-based and active learning settings. Our simulation results show faster learning and better generalization in various robotic domains. See our supplementary video: https://youtu.be/IIJTbBAOufDY.


Title: Probabilistic Active Filtering for Object Search in Clutter
Abstract: This paper proposes a probabilistic approach for object search in clutter. Due to heavy occlusions, it is vital for an agent to be able to gradually reduce uncertainty in observations of the objects in its workspace by systematically rearranging them. Probabilistic methodologies present a promising sample-efficient alternative to handle the massively complex state-action space that inherently comes with this problem, avoiding the need for both exhaustive training samples and the accompanying heuristics for traversing a large-scale model during runtime. We approach the object search problem by extending a Gaussian Process active filtering strategy with an additional model for capturing state dynamics as the objects are moved over the course of the activity. This allows viable models to be built upon relatively scarce training data, while the complexity of the action space is also reduced by shifting objects over relatively short distances. Validation in both simulation and with a real Baxter robot with a limited number of training samples demonstrates the efficacy of the proposed approach.


Title: Robust 3D Object Classification by Combining Point Pair Features and Graph Convolution
Abstract: Object classification is an important capability for robots as it provides vital semantic information that underpin most practical high-level tasks. Classic handcrafted features, such as point pair features, have demonstrated their robustness for this task. Combining these features with modern deep learning methods provide discriminative features that are rotation invariant and robust to various sources of noise. In this work, we aim to improve the descriptiveness of point pair features while retaining their robustness. We propose a method to achieve more structured sampling of pairs and combine this information through the use of graph convolutional networks. We introduce a novel attention model based on a repeatable local reference frame. Experiments show that our approach significantly improves the state of the art for object classification on large scale reconstruction such as the Stanford 3D indoor dataset and ScanNet and obtains competitive accuracy on the artificial dataset ModelNet.


Title: Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data
Abstract: The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.


Title: Multi-Modal Geometric Learning for Grasping and Manipulation
Abstract: This work provides an architecture that incorporates depth and tactile information to create rich and accurate 3D models useful for robotic manipulation tasks. This is accomplished through the use of a 3D convolutional neural network (CNN). Offline, the network is provided with both depth and tactile information and trained to predict the object's geometry, thus filling in regions of occlusion. At runtime, the network is provided a partial view of an object. Tactile information is acquired to augment the captured depth information. The network can then reason about the object's geometry by utilizing both the collected tactile and depth information. We demonstrate that even small amounts of additional tactile information can be incredibly helpful in reasoning about object geometry. This is particularly true when information from depth alone fails to produce an accurate geometric prediction. Our method is benchmarked against and outperforms other visual-tactile approaches to general geometric reasoning. We also provide experimental results comparing grasping success with our method.


Title: Panthera: Design of a Reconfigurable Pavement Sweeping Robot
Abstract: The pavement cleaning is essential to maintain urban hygiene and keep the long stretch of pavements spick and span. This paper reports on the development of novel reconfigurable pavement cleaning robot named Panthera. Reconfiguration in Panthera is gained by the expansion and contraction of the body frame using a single lead screw shaft and linkages mechanism. It gives the capability to reshape itself based on factors like pavement width and pedestrian density. The independent steering action is derived using two in-wheels motors for each steering axis. This imparts the flexibility in motion and make system omnidirectional and allows the convenient movement of the robot in any direction along the pavement. It is powered using onboard batteries that generate lesser noise compared to the existing solution powered with gasoline. The modeling and steering kinematics is presented along with experimental results of the path followed and discussion supporting the robot's capability.


Title: Automatic Leg Regeneration for Robot Mobility Recovery
Abstract: Automatic repair of mechanical structures would enable a robot to recover or improve functions after physical damage. Little work exists on real-world execution of automatic repair in robotic systems. State-of-the-art takes a modular approach where the robotic system is modular and a replacement module is available. However, the modular approach suffers from low granularity in repair even with tens of motors. In addition, there is a lack of quantitative evaluation of the effect of automatic repair on robot functionality. Here we propose a cooperative method for automatic repair in a robotic system. Our method is regeneration-based rather than module-based and does not assume availability of a replacement part. It integrates a fabrication process on the fly for robot structure regeneration. With a system that consists of a regenerating robot, a legged robot and a pre-engineered ribbon, we demonstrate end-to-end execution of automated repair of the legged robot's leg by the regenerating robot in 335 seconds. Experiments on repeatability show a 100% success rate for sub-processes such as positioning, leg fabrication, and legged robot disengagement and a 90% success rate for leg detachment. We quantify the effect of leg regeneration on mobility recovery and found a 90% recovery of forward speed, a 19.7% increase of peak power and a 9.3% reduction of cost of transport with a regenerated leg.


Title: Geometric interpretation of the general POE model for a serial-link robot via conversion into D-H parameterization
Abstract: While Product of Exponentials (POE) formula has been gaining maturity in modeling the kinematics of a serial-link robot, the Denavit-Hartenberg (D-H) notation is still the most widely used due to its intuitive and concise geometric interpretation of the robot. This paper has developed an analytical solution to automatically convert a POE model into a D-H model for a robot with revolute, prismatic, and helical joints, which are the complete set of three basic one degree of freedom lower pair joints for constructing a serial-link robot. The conversion algorithm developed can be used in applications such as calibration where it is necessary to convert the D-H model to the POE model for identification and then back to the D-H model for compensation. The equivalence of the two models proved in this paper also benefits the analysis of the identifiability of the kinematic parameters. It is found that the maximum number of identifiable parameters in a general POE model is 5h+4r+2t+n+6 where h, r, t, and n stand for the number of helical, revolute, prismatic, and general joints, respectively. It is also suggested that the identifiability of the base frame and the tool frame in the D-H model is restricted rather than the arbitrary six parameters as assumed previously.


Title: Echinoderm Inspired Variable Stiffness Soft Actuator with Connected Ossicle Structure
Abstract: An echinoderm can actively modulate the structural stiffness of its body wall by as much as 10 times, using the material and structural features that make up its body, including calcite ossicles, connective tissue and interossicular muscle. This capacity for variable stiffness makes it possible to adapt to the kinematics and dynamics required to perform a given task and the surrounding environment. This characteristic can improve the ability of soft material robots, which currently have limited application because of their low load-bearing capability. This paper presents a stiffness modulation method inspired by the connected ossicle structures of echinoderms. We introduce the mechanism, structure, and stiffness variation of the proposed design with respect to different ossicle shape, interval, and elastomer. Then we built a finger-shaped stiffening structure using the proposed design, measured its stiffness according to vacuum level, and showed its load-bearing capacity under control. The proposed design was then applied to a robotic gripper, a typical device that interacts with unpredictable environments and needs variable stiffening ability.


Title: Controllability pre-verification of silicone soft robots based on finite-element method
Abstract: Soft robot is an emergent research field which has variant promising applications. However, the design of soft robots nowadays still follows the trial-and-error process, which is not at all efficient. This paper proposes to design soft robots by pre-checking controllability during the numerical design phase. Finite-element method is used to model the dynamics of silicone soft robots, based on which the differential geometric method is applied to analyze the controllability of the points of interest. Such a verification is also investigated via model order reduction technique and Galerkin projection. The proposed methodology is finally validated by numerically designing a controllable parallel soft robot.


Title: A Vacuum-driven Origami “Magic-ball” Soft Gripper
Abstract: Soft robotics has yielded numerous examples of soft grippers that utilize compliance to achieve impressive grasping performances with great simplicity, adaptability, and robustness. Designing soft grippers with substantial grasping strength while remaining compliant and gentle is one of the most important challenges in this field. In this paper, we present a light-weight, vacuum-driven soft robotic gripper made of an origami “magic-ball” and a flexible thin membrane. We also describe the design and fabrication method to rapidly manufacture the gripper with different combinations of low-cost materials for diverse applications. Grasping experiments demonstrate that our gripper can lift a large variety of objects, including delicate foods, heavy bottles, and other miscellaneous items. The grasp force on 3D-printed objects is also characterized through mechanical load tests. The results reveal that our soft gripper can produce significant grasp force on various shapes using negative pneumatic pressure (vacuum). This new gripper holds the potential for many practical applications that require safe, strong, and simple grasping.


Title: INFORA: A Novel Inflatable Origami-based Actuator
Abstract: Pneumatic actuators have gained huge popularity in the field of soft robotics. A class of this kind of devices exploits inflatable thin membranes which generate a desired displacement upon inflation, but often without providing sufficient force/torque to perform their task. In this paper, we propose a novel actuator combining a membrane and a rigid foldable structure. Experimental tests show that such INFlatable ORigami Actuator (INFORA) is characterized by relatively high stiffness compared to other actuators of the same class. We provide a mathematical model to be used for design purposes and we describe the fabrication process. In addition, we show how the INFORA can be used to build a tendril-like structure capable of performing grasping tasks.


Title: Dynamic Period-two Gait Generation in a Hexapod Robot based on the Fixed-point Motion of a Reduced-order Model
Abstract: This research explored the generation of period-two dynamic running motion in a robot, based on the passive dynamic period-two motion of the reduced order, rolling spring-loaded inverted pendulum (R-SLIP) model. Each cycle of period-two motion consists of two stance phases separated by two flight phases. The distribution of the period-two fixed points of the model was analyzed using a return map. Models with the same or different landing angles per motion cycle were studied, and two sets of period-two motion trajectories were implemented in a robot for experimental evaluation. Without sensory feedback or control, this evaluation relied on the open loop trajectory of the model. Based on the experiments, the robot was capable of performing dynamic period-two motion.


Title: Realizing Learned Quadruped Locomotion Behaviors through Kinematic Motion Primitives
Abstract: Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the “Stoch”. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then analyze the resulting walking by using principal component analysis. We observe that the kMPs extracted from PCA followed a similar pattern irrespective of the type of gaits generated. Leveraging on this underlying structure, we then realize walking in Stoch by a straightforward reconstruction of joint trajectories from kMPs. This type of methodology improves the transferability of these gaits to real hardware, lowers the computational overhead on-board, and also avoids multiple training iterations by generating a set of derived behaviors from a single learned gait.


Title: Single-shot Foothold Selection and Constraint Evaluation for Quadruped Locomotion
Abstract: In this paper, we propose a method for selecting the optimal footholds for legged systems. The goal of the proposed method is to find the best foothold for the swing leg on a local elevation map. First, we evaluate the geometrical characteristics of each cell on the elevation map, checks kinematic constraints and collisions. Then, we apply the Convolutional Neural Network to learn the relationship between the local elevation map and the quality of potential footholds. During execution time, the controller obtains the qualitative measurement of each potential foothold from the neural model. This method evaluates hundreds of potential footholds and checks multiple constraints in a single step which takes 10 ms on a standard computer without GPU. The experiments were carried out on a quadruped robot walking over rough terrain in both simulation and real robotic platforms.


Title: Optimized Jumping on the MIT Cheetah 3 Robot
Abstract: This paper presents a novel methodology for implementing optimized jumping behavior on quadruped robots. Our method includes efficient trajectory optimization, precise high-frequency tracking controller and robust landing controller for stabilizing the robot body position and orientation after impact. Experimental validation was successfully conducted on the MIT Cheetah 3, enabling the robot to repeatably jump onto and jump down from a desk with the height of 30" (0.76 m). The result demonstrates the advantages of the approach as well as the capability of the robot hardware itself.


Title: Lift Your Leg: Mechanics of Running Through Fluids
Abstract: In order for legged robotic platforms to become adept enough to operate in unstructured, outdoor environments it is critical that they have the ability to adapt to a variety of terrains. One class of terrains to consider are regions of shallow, dense fluids, such as a beach-head, stream banks, snow or mud. This work examines the behavior of a simulated SLIP runner operating in such a viscous medium. Simulation results show that intelligently retracting the leg during flight can have a profound effect on the maximum achievable velocity of the runner, the stability of the resulting gait, and the cost of transport of the runner. Results also show that trudging gaits, in which the leg is positioned behind the center of mass, can be favorable in certain situations in terms of energy consumption and forward velocity.


Title: Safely Probabilistically Complete Real-Time Planning and Exploration in Unknown Environments
Abstract: We present a new framework for motion planning that wraps around existing kinodynamic planners and guarantees recursive feasibility when operating in a priori unknown, static environments. Our approach makes strong guarantees about overall safety and collision avoidance by utilizing a robust controller derived from reachability analysis. We ensure that motion plans never exit the safe backward reachable set of the initial state, while safely exploring the space. This preserves the safety of the initial state, and guarantees that that we will eventually find the goal if it is possible to do so while exploring safely. We implement our framework in the Robot Operating System (ROS) software environment and demonstrate it in a real-time simulation.


Title: Handling robot constraints within a Set-Based Multi-Task Priority Inverse Kinematics Framework
Abstract: Set-Based Multi-Task Priority is a recent framework to handle inverse kinematics for redundant structures. Both equality tasks, i.e., control objectives to be driven to a desired value, and set-bases tasks, i.e., control objectives to be satisfied with a set/range of values can be addressed in a rigorous manner within a priority framework. In addition, optimization tasks, driven by the gradient of a proper function, may be considered as well, usually as lower priority tasks. In this paper the proper design of the tasks, their priority and the use of a Set-Based Multi-Task Priority framework is proposed in order to handle several constraints simultaneously in real-time. It is shown that safety related tasks such as, e.g., joint limits or kinematic singularity, may be properly handled by consider them both at an higher priority as set-based task and at a lower within a proper optimization functional. Experimental results on a 7DOF Jaco2 arm with and without the proposed approach show the effectiveness of the proposed method.


Title: Compliant Limb Sensing and Control for Safe Human-Robot Interactions
Abstract: The current paper proposes a control methodology for ensuring safety during human-robot interaction based on a compliant sensor covering the robot links as a lightweight shell. The method can be used with existing robots without the need for mechanical redesign. To assess the behaviour of the proposed control law, the controller is analysed using a linear robot model. Stability analysis is performed and requirements on the controller parameters are derived. The effect of the controller parameters on the perceived impedance and the maximum safe operating velocity of the robot are determined via the linear model. The adverse impact of dry friction is analysed in simulation and methods are developed to mitigate the effects. The controller is implemented on a 1 DoF robotic joint and the results are compared to those of a traditional admittance control law, demonstrating comparable transient response while maintaining a simple control structure and decreased risk of instability.


Title: Ascento: A Two-Wheeled Jumping Robot
Abstract: Applications of mobile ground robots demand high speed and agility while navigating in complex indoor environments. These present an ongoing challenge in mobile robotics. A system with these specifications would be of great use for a wide range of indoor inspection tasks. This paper introduces Ascento, a compact wheeled bipedal robot that is able to move quickly on flat terrain, and to overcome obstacles by jumping. The mechanical design and overall architecture of the system is presented, as well as the development of various controllers for different scenarios. A series of experiments1 with the final prototype system validate these behaviors in realistic scenarios.


Title: Path Following Controller for Differentially Driven Planar Robots with Limited Torques and Uncertain and Changing Dynamics
Abstract: This paper presents a path following controller that is suitable for asymmetrical planar robots with significant mass and limited motor torques. the controller is resistant against environmental forces, and inaccurate estimates of robot's inertia, by estimating their effects with unscented kalman filter. the controller outputs wheel torque commands which take in account the motor torque limits and given relative priority of internal control elements. the method presented is thoroughly explained and the simulation results demonstrate the performance of the controller.


Title: Nonlinear Tire Cornering Stiffness Observer for a Double Steering Off-Road Mobile Robot
Abstract: Path tracking controllers for an autonomous vehicle are often designed by using either a dynamic model or a kinematic one and some models are related to wheel-ground contact, that makes the efficiency of the controller highly dependent on the ground parameters estimation, especially for off-road mobile robots intended to navigate in open environments. This paper proposes a new nonlinear observer designed to estimate the front and rear contact cornering stiffnesses in real time, that are related both on tire and soil proprieties. The latter is estimated using steering angles as well as yaw rate and lateral velocity, which are provided by a preliminary Kalman-Bucy observer. The performance of the proposed nonlinear observer combined with the LQR controller is evaluated by both advanced simulations and experiments in real conditions at different speeds.


Title: Hierarchical optimization for Whole-Body Control of Wheeled Inverted Pendulum Humanoids
Abstract: In this paper, we present a whole-body control framework for Wheeled Inverted Pendulum (WIP) Humanoids. WIP Humanoids are redundant manipulators dynamically balancing themselves on wheels. Characterized by several degrees of freedom, they have the ability to perform several tasks simultaneously, such as balancing, maintaining a body pose, controlling the gaze, lifting a load or maintaining end-effector configuration in operation space. The problem of whole-body control is to enable simultaneous performance of these tasks with optimal participation of all degrees of freedom at specified priorities for each objective. The control also has to obey constraint of angle and torque limits on each joint. The proposed approach is hierarchical with a low level controller for body joints manipulation and a high-level controller that defines center of mass (CoM) targets for the low-level controller to control zero dynamics of the system driving the wheels. The low-level controller plans for shorter horizons while considering more complete dynamics of the system, while the high-level controller plans for longer horizon based on an approximate model of the robot for computational efficiency.


Title: An Actively Controlled Variable Stiffness Structure via Layer Jamming and Pneumatic Actuation
Abstract: Current robotics industry trends show an increased interest in the interaction between humans and robots in a variety of fields, ranging from collaborative robots in manufacturing to assisted medical devices in the medical field. One limiting factor in present applications is the ability to actively morph these robotic structures and control their stiffness using the same type of actuation system. This paper focuses on developing an actively controlled, variable stiffness structure that uses a pneumatic system for both morphing and locking the structure shape. The structure design integrates Pneumatic Artificial Muscles (PAMs) that are pressurized to control shape morphing. The pressurization of the PAM provides a radial force that allows bi-directional morphing based on the pressurization scheme. Layer Jamming, which utilizes varied friction between thin sheets based on pressure, is used to control the variable stiffness of the structure. In this paper, a control model is developed to predict the morphed curvature of the structure based on the input actuator pressure. This experimental control model is also validated using a theoretical pseudo-rigid-body model. The repeatability and accuracy of morphing is also discussed. Through experimental testing, a measure of the stiffness variation range of the structure is also developed. This novel research would positively impact the robotics field by creating lightweight morphing structures that are flexible and easily deformed, but also stiff with high load-carrying capability for increased human-robot interaction.


Title: A Floating-Piston Hydrostatic Linear Actuator and Remote-Direct-Drive 2-DOF Gripper
Abstract: Dexterous, serial-chain motor-driven robotic arms have high moving mass, since most of the actuators must be located in the arm itself. This necessitates high gear ratios, sacrificing passive compliance, backdrivability, and the capacity for delicate motion. We introduce the concept of a remote direct-drive (RDD) manipulator, in which every motor is located in the base, connected to remote joints via a low-friction hydrostatic transmission. We have designed a new hydrostatic linear actuator with a fully-floating piston; the piston floats within the cylinder using a pair of soft fiber-elastomer rolling-diaphragm seals. This eliminates static friction from seal rubbing and piston/rod misalignment. Actuators were developed with a 20mm bore, weighing 55 grams each with a 400:1 bidirectional strength-to-weight ratio $( + /-230\mathrm {N}$), which drive a 2-DOF manipulator (wrist pitch/finger pinch; 120-degree range-of-motion; 6.6 Nm max grip strength). The gripper is hydrostatically coupled to remotely-located direct-drive/backdrivable brushless electric motors. System hysteresis and friction are 1 percent of full-range force. This low-mass low-friction configuration is of great interest for powered prosthetic hand design, and passively-safe high dynamic range robot arms.


Title: Learning Primitive Skills for Mobile Robots
Abstract: Achieving effective task performance on real mobile robots is a great challenge when hand-coding algorithms, both due to the amount of effort involved and manually tuned parameters required for each skill. Learning algorithms instead have the potential to lighten up this challenge by using one single set of training parameters for learning different skills, but the question of the feasibility of such learning in real robots remains a research pursuit. We focus on a kind of mobile robot system - the robot soccer “small-size” domain, in which tactical and high-level team strategies build upon individual robot ball-based skills. In this paper, we present our work using a Deep Reinforcement Learning algorithm to learn three real robot primitive skills in continuous action space: go-to-ball, turn-and-shoot and shoot-goalie, for which there is a clear success metric to reach a destination or score a goal. We introduce the state and action representation, as well as the reward and network architecture. We describe our training and testing using a simulator of high physical and hardware fidelity. Then we test the policies trained from simulation on real robots. Our results show that the learned skills achieve an overall better success rate at the expense of taking 0.29 seconds slower on average for all three skills. In the end, we show that our policies trained in simulation have good performance on real robots by directly transferring the policy.


Title: Coverage Path Planning in Belief Space
Abstract: For safety reasons, robotic lawn mowers and similar devices are required to stay within a predefined working area. Keeping the robot within its workspace is typically achieved by special safeguards such as a wire installed in the ground. In the case of robotic lawn mowers, this causes a certain customer reluctance. It is more desirable to fulfill those safety-critical tasks by safe navigation and path planning. In this paper, we tackle the problem of planning a coverage path composed of parallel lanes that maximizes robot safety under the constraints of cheap, low range sensors and thus substantial uncertainty in the robot's belief and ability to execute actions. Our approach uses a map of the environment to estimate localizability at all locations, and it uses these estimates to search for an uncertainty-aware coverage path while avoiding collisions. We implemented our approach using C++ and ROS and thoroughly tested it on real garden data. The experiment shows that our approach leads to safer meander patterns for the lawn mower and takes expected localizability information into account.


Title: Continuous Control for High-Dimensional State Spaces: An Interactive Learning Approach
Abstract: Deep Reinforcement Learning (DRL) has become a powerful methodology to solve complex decision-making problems. However, DRL has several limitations when used in real-world problems (e.g., robotics applications). For instance, long training times are required and cannot be accelerated in contrast to simulated environments, and reward functions may be hard to specify/model and/or to compute. Moreover, the transfer of policies learned in a simulator to the real-world has limitations (reality gap). On the other hand, machine learning methods that rely on the transfer of human knowledge to an agent have shown to be time efficient for obtaining well performing policies and do not require a reward function. In this context, we analyze the use of human corrective feedback during task execution to learn policies with high-dimensional state spaces, by using the D-COACH framework, and we propose new variants of this framework. D-COACH is a Deep Learning based extension of COACH (COrrective Advice Communicated by Humans), where humans are able to shape policies through corrective advice. The enhanced version of DCOACH, which is proposed in this paper, largely reduces the time and effort of a human for training a policy. Experimental results validate the efficiency of the D-COACH framework in three different problems (simulated and with real robots), and show that its enhanced version reduces the human training effort considerably, and makes it feasible to learn policies within periods of time in which a DRL agent do not reach any improvement.


Title: Planning Coordinated Event Observation for Structured Narratives
Abstract: This paper addresses the problem of using autonomous robots to record events that obey narrative structure. The work is motivated by a vision of robot teams that can, for example, produce individualized highlight videos for each runner in a large-scale road race such as a marathon. We introduce a method for specifying the desired structure as a function that describes how well the captured events can be used to produce an output that meets the specification. This function is specified in a compact, legible form similar to a weighted finite automaton. Then we describe a planner that uses simple predictions of future events to coordinate the robots' efforts to capture the most important events, as determined by the specification. We describe an implementation of this approach, and demonstrate its effectiveness in a simulated race scenario both in simulation and in a hardware testbed.


Title: Algorithmic Resolution of Multiple Impacts in Nonsmooth Mechanical Systems with Switching Constraints
Abstract: We present a differential-algebraic formulation with switching constraints to model the nonsmooth dynamics of robotic systems subject to changing constraints and multiple impacts. The formulation combines a single structurally simple governing equation, a set of switching kinematic constraints, and the plastic impact law, to represent the dynamics of robots that interact with their environment. The main contribution of this formulation is a novel algorithmic impact resolution method which provides an explicit solution to the classical plastic impact law in the case of multiple simultaneous impacts. This method serves as an alternative to prior linear-complementarity-based formulations which offer an implicit impact resolution through iterative calculation. We demonstrate the utility of the proposed method by simulating the locomotion of a planar anthropometric biped.


Title: Rigid Body Motion Prediction with Planar Non-convex Contact Patch
Abstract: We present a principled method for motion prediction via dynamic simulation for rigid bodies in intermittent contact with each other where the contact is assumed to be a planar non-convex contact patch. The planar non-convex contact patch can either be a topologically connected set or disconnected set. Such algorithms are useful in planning and control for robotic manipulation. Most work in rigid body dynamic simulation assume that the contact between objects is a point contact, which may not be valid in many applications. In this paper, by using the convex hull of the contact patch, we build on our recent work on simulating rigid bodies with convex contact patches, for simulating motion of objects with planar non-convex contact patches. We formulate a discrete-time mixed complementarity problem where we solve the contact detection and integration of the equations of motion simultaneously. Thus, our method is a geometrically-implicit method and we prove that in our formulation, there is no artificial penetration between the contacting rigid bodies. We solve for the equivalent contact point (ECP) and contact impulse of each contact patch simultaneously along with the state, i.e., configuration and velocity of the objects. We provide empirical evidence to show that our method can seamlessly capture transition between different contact modes like patch contact to multiple or single point contact during simulation.


Title: A Data-driven Approach for Fast Simulation of Robot Locomotion on Granular Media
Abstract: In this paper, we propose a semi-empirical approach for simulating robot locomotion on granular media. We first develop a contact model based on the stick-slip behavior between rigid objects and granular grains, which is then learned through running extensive experiments. The contact model represents all possible contact wrenches that the granular substrate can provide as a convex volume, which our method formulates as constraints in an optimization-based contact force solver. During simulation, granular substrates are treated as rigid objects that allow penetration and the contact solver solves for wrenches that maximize frictional dissipation. We show that our method is able to simulate plausible interaction response with several granular media at interactive rates.


Title: Controller Synthesis for Discrete-time Hybrid Polynomial Systems via Occupation Measures
Abstract: We consider the feedback design for stabilizing a rigid body system by making and breaking multiple contacts with the environment without prespecifying the timing or the number of occurrence of the contacts. We model such a system as a discrete-time hybrid polynomial system, where the state-input space is partitioned into several polytopic regions with each region associated with a different polynomial dynamics equation. Based on the notion of occupation measures, we present a novel controller synthesis approach that solves finite-dimensional semidefinite programs as approximations to an infinite-dimensional linear program to stabilize the system. The optimization formulation is simple and convex, and for any fixed degree of approximations the computational complexity is polynomial in the state and control input dimensions. We illustrate our approach on some robotics examples.


Title: Optimal Path Planning for ω-regular Objectives with Abstraction-Refinement
Abstract: This paper presents an abstraction-refinement based framework for optimal controller synthesis of discrete-time systems with respect to ω-regular objectives. It first abstracts the discrete-time “concrete” system into a finite weighted transition system using a finite partition of the state-space. Then, a two-player mean payoff parity game is solved on the product of the abstract system and the Büchi automaton corresponding to the ω-regular objective, to obtain an optimal “abstract” controller that satisfies the ω-regular objective. The abstract controller is guaranteed to be implementable in the concrete discrete-time system, with a sub-optimal cost. The abstraction is refined with finer partitions to reduce the suboptimality. In contrast to existing formal controller synthesis algorithms based on abstractions, this technique provides an upper bound on the trajectory cost when implementing the suboptimal controller. A robot surveillance scenario is presented to illustrate the feasibility of the approach.


Title: Sampling-Based Polytopic Trees for Approximate Optimal Control of Piecewise Affine Systems
Abstract: Piecewise affine (PWA) systems are widely used to model highly nonlinear behaviors such as contact dynamics in robot locomotion and manipulation. Existing control techniques for PWA systems have computational drawbacks, both in offline design and online implementation. In this paper, we introduce a method to obtain feedback control policies and a corresponding set of admissible initial conditions for discrete-time PWA systems such that all the closed-loop trajectories reach a goal polytope, while a cost function is optimized. The idea is conceptually similar to LQR-trees [1], which consists of 3 steps: (1) open-loop trajectory optimization, (2) feedback control for computation of “funnels” of states around trajectories, and (3) repeating (1) and (2) in a way that the funnels are grown backward from the goal in a tree fashion and fill the state-space as much as possible. We show PWA dynamics can be exploited to combine step (1) and (2) into a single step that is tackled using mixed-integer convex programming, which makes the method suitable for dealing with hard constraints. Illustrative examples on contact-based dynamics are presented.


Title: Experimental Assessment of Plume Mapping using Point Measurements from Unmanned Vehicles
Abstract: This paper presents experiments to assess the plume mapping performance of autonomous robots. The paper compares several mapping algorithms including Gaussian Process regression, Neural networks and polynomial and piecewise linear interpolation. The methods are compared in Monte Carlo simulations using a well known plume model and in indoor experiments using a ground robot. Unlike previous work on mapping using unmanned vehicles, the indoor experiments were performed in a controlled and repeatable manner where a steady state ground truth could be obtained in order to properly assess the various regression methods using data from a real dispersive source and sensor. The effect of sampling time during data collection was assessed with regards to the mapping accuracy, and the data collected during the experiments have been made available. Overall, the Gaussian Process method was found to perform the best among the regression algorithms, showing more robustness to the noisy measurements obtained from short sampling periods, enabling an accurate map to be produced in significantly less time. Finally, plume mapping results are presented in uncontrolled outdoor conditions, using an unmanned aerial vehicle, to demonstrate the system in a realistic uncontrolled environment.


Title: Precision Stationary Flight of a Robotic Hummingbird*
Abstract: This paper describes recent developments of a robotic hummingbird project, aimed at achieving precision stationary hovering. To this end, the early version of our flapping mechanism is modified which, besides being more efficient, reduces significantly the asymmetry of the wing trajectory of the previous version. A cascade control strategy is used to compensate for the residual parasitic torques and the misalignment of the lift vector and the autopilot.


Title: Robust attitude estimation using an adaptive unscented Kalman filter
Abstract: This paper presents the robust Adaptive unscented Kalman filter (RAUKF) for attitude estimation. Since the proposed algorithm represents attitude as a unit quaternion, all basic tools used, including the standard UKF, are adapted to the unit quaternion algebra. Additionally, the algorithm adopts an outlier detector algorithm to identify abrupt changes in the UKF innovation and an adaptive strategy based on covariance matching to tune the measurement covariance matrix online. Adaptation and outlier detection make the proposed algorithm robust to fast and slow perturbations such as magnetic field interference and linear accelerations. Experimental results with a manipulator robot suggest that our method overcomes other algorithms found in the literature.


Title: One-Shot Learning of Multi-Step Tasks from Observation via Activity Localization in Auxiliary Video
Abstract: Due to burdensome data requirements, learning from demonstration often falls short of its promise to allow users to quickly and naturally program robots. Demonstrations are inherently ambiguous and incomplete, making correct generalization to unseen situations difficult without a large number of demonstrations in varying conditions. By contrast, humans are often able to learn complex tasks from a single demonstration (typically observations without action labels) by leveraging context learned over a lifetime. Inspired by this capability, our goal is to enable robots to perform one-shot learning of multi-step tasks from observation by leveraging auxiliary video data as context. Our primary contribution is a novel system that achieves this goal by: (1) using a single user-segmented demonstration to define the primitive actions that comprise a task, (2) localizing additional examples of these actions in unsegmented auxiliary videos via a metalearning-based approach, (3) using these additional examples to learn a reward function for each action, and (4) performing reinforcement learning on top of the inferred reward functions to learn action policies that can be combined to accomplish the task. We empirically demonstrate that a robot can learn multi-step tasks more effectively when provided auxiliary video, and that performance greatly improves when localizing individual actions, compared to learning from unsegmented videos.


Title: LVIS: Learning from Value Function Intervals for Contact-Aware Robot Controllers
Abstract: Guided policy search is a popular approach for training controllers for high-dimensional systems, but it has a number of pitfalls. Non-convex trajectory optimization has local minima, and non-uniqueness in the optimal policy itself can mean that independently-optimized samples do not describe a coherent policy from which to train. We introduce LVIS, which circumvents the issue of local minima through global mixed-integer optimization and the issue of non-uniqueness through learning the optimal value function rather than the optimal policy. To avoid the expense of solving the mixed-integer programs to full global optimality, we instead solve them only partially, extracting intervals containing the true cost-to-go from early termination of the branch-and-bound algorithm. These interval samples are used to weakly supervise the training of a neural net which approximates the true cost-to-go. Online, we use that learned cost-to-go as the terminal cost of a one-step model-predictive controller, which we solve via a small mixed-integer optimization. We demonstrate LVIS on piecewise affine models of a cart-pole system with walls and a planar humanoid robot and show that it can be applied to a fundamentally hard problem in feedback control-control through contact.


