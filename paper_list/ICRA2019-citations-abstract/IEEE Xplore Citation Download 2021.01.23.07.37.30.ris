TY  - CONF
TI  - Energy optimization for a Robust and Flexible Interaction Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1919
EP  - 1925
AU  - C. Secchi
AU  - F. Ferraguti
PY  - 2019
KW  - humanoid robots
KW  - human-robot interaction
KW  - optimisation
KW  - stability
KW  - tanks (containers)
KW  - admittance controllers
KW  - energy optimization problem
KW  - interactive behavior
KW  - stable interaction
KW  - robot interaction
KW  - admittance control strategy
KW  - Admittance
KW  - Optimization
KW  - Dynamics
KW  - Manipulators
KW  - Collaboration
KW  - Buildings
DO  - 10.1109/ICRA.2019.8794055
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The possibility of adapting online the way a robot interacts with the environment is becoming more and more important. In this paper we introduce the tank based admittance controller. We show that all the admittance controllers can be modeled as an energy optimization problem and then we introduce a novel admittance control strategy that allows to change online the interactive behavior while preserving a stable interaction with the environment. The effectiveness of the proposed architecture is experimentally validated.
ER  - 

TY  - CONF
TI  - Design of Versatile and Low-Cost Shaft Sensor for Health Monitoring
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1926
EP  - 1932
AU  - E. Gest
AU  - M. Furokawa
AU  - T. Hirano
AU  - K. Youcef-Toumi
PY  - 2019
KW  - bending
KW  - condition monitoring
KW  - power transmission (mechanical)
KW  - prototypes
KW  - shafts
KW  - strain sensors
KW  - torque measurement
KW  - velocity measurement
KW  - vibration measurement
KW  - design engineering
KW  - transportation
KW  - torque measurement
KW  - speed measurement
KW  - vibration measurement
KW  - bending measurement
KW  - strain sensor
KW  - prototype
KW  - mechanical power transmission
KW  - rotating shafts
KW  - robotic system
KW  - industrial equipment
KW  - power generation system
KW  - health monitoring
KW  - low-cost shaft sensor
KW  - Shafts
KW  - Torque
KW  - Strain
KW  - Bridges
KW  - Strain measurement
KW  - Robot sensing systems
KW  - Torque measurement
DO  - 10.1109/ICRA.2019.8794408
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Virtually every mechanized form of transportation, power generation system, industrial equipment, and robotic system has rotating shafts. As the shaft is often the main means of mechanical power transmission, measuring the torque, speed, vibration, and bending of the shaft can be used in many cases to access device performance and health and to implement controls. This paper proposes a shaft sensor that measures all of these phenomena with reasonable accuracy while having a low cost and simple installation process. This sensor transfers strain from the shaft and amplifies it to increase sensitivity. Furthermore, this sensor requires no components to be in the stationary reference frame, allowing the entire device to rotate with the shaft. A prototype is presented. Experimental results illustrate the effectiveness of the proposed system.
ER  - 

TY  - CONF
TI  - Robust Execution of Contact-Rich Motion Plans by Hybrid Force-Velocity Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1933
EP  - 1939
AU  - Y. Hou
AU  - M. T. Mason
PY  - 2019
KW  - control system synthesis
KW  - force control
KW  - industrial manipulators
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - trajectory control
KW  - velocity control
KW  - robust execution
KW  - contact-rich motion plans
KW  - trajectory hybrid servoing
KW  - hybrid force-velocity control actions
KW  - control synthesis
KW  - positional errors
KW  - optimization problems
KW  - contact-rich manipulation tasks
KW  - Robots
KW  - Force
KW  - Force control
KW  - Aerospace electronics
KW  - Collision avoidance
KW  - Planning
KW  - Velocity control
DO  - 10.1109/ICRA.2019.8794366
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In hybrid force-velocity control, the robot can use velocity control in some directions to follow a trajectory, while performing force control in other directions to maintain contacts with the environment regardless of positional errors. We call this way of executing a trajectory hybrid servoing. We propose an algorithm to compute hybrid force-velocity control actions for hybrid servoing. We quantity the robustness of a control action and make trade-offs between different requirements by formulating the control synthesis as optimization problems. Our method can efficiently compute the dimensions, directions and magnitudes of force and velocity controls. We demonstrated by experiments the effectiveness of our method in several contact-rich manipulation tasks. Link to the video: https://youtu.be/KtSNmvwOenM.
ER  - 

TY  - CONF
TI  - Endoscope Force Generation and Intrinsic Sensing with Environmental Scaffolding
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1940
EP  - 1946
AU  - J. E. Bernth
AU  - J. Back
AU  - G. Abrahams
AU  - L. Lindenroth
AU  - B. Hayee
AU  - H. Liu
PY  - 2019
KW  - actuators
KW  - cantilevers
KW  - endoscopes
KW  - force control
KW  - manipulator dynamics
KW  - medical robotics
KW  - skin
KW  - surgery
KW  - cantilevered configuration
KW  - environmental scaffolding
KW  - contact forces
KW  - tip force estimation
KW  - actuation forces
KW  - skin wounds
KW  - laparoscopic techniques
KW  - endoscopic surgery
KW  - intrinsic sensing
KW  - endoscope force generation
KW  - Endoscopes
KW  - Tendons
KW  - Force
KW  - Shape
KW  - Robot sensing systems
KW  - Endoscopes
KW  - Finite element analysis
KW  - Intrinsic force measurement
KW  - Minimally invasive surgery
DO  - 10.1109/ICRA.2019.8793726
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Endoscopic surgery is an increasingly popular alternative to laparoscopic techniques for many conditions, as the operation site can be reached without skin wounds. In many tasks, sufficient force generation is desired. As endoscopes must be highly flexible and slim, however, the force generation and sensing capabilities associated with these tools is limited due their compliance, significantly hindering the adoption rate of endoscopic surgeries. This paper proposes a technique, termed `environmental scaffolding', to stabilize an actuated, flexible segment in the intestine such that larger forces can be applied. Through the measurement of actuation forces, a method for intrinsically sensing multiple contact forces when in this configuration is presented. Experimental results show that with the environmental scaffolding technique, the tip force generated can be increased by over 50% on average compared to using the device in a purely cantilevered configuration, and the tip force estimation is accurate to within 2.97%.
ER  - 

TY  - CONF
TI  - On The Combination of Gamification and Crowd Computation in Industrial Automation and Robotics Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1955
EP  - 1961
AU  - T. Bewley
AU  - M. Liarokapis
PY  - 2019
KW  - cognition
KW  - computer games
KW  - human computer interaction
KW  - mobile robots
KW  - cognitive versatility
KW  - industrial automation
KW  - robotics applications
KW  - human-machine collaboration
KW  - gamification
KW  - video games
KW  - human workers
KW  - autonomous intelligent systems
KW  - crowd computation
KW  - Crowdsourcing
KW  - Games
KW  - Task analysis
KW  - Service robots
KW  - Automation
KW  - Collaboration
DO  - 10.1109/ICRA.2019.8794040
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous intelligent systems outperform human workers in an expanding range of domains, typically those in which success is a function of speed, precision and repeatability. However, many cognitive tasks remain beyond the reach of automation. In this work, we propose the use of video games to crowdsource the cognitive versatility and creativity of human players to solve complex problems in industrial automation and robotics applications. To do so, we introduce a theoretical framework in which robotics problems are embedded into video game environments and gameplay from crowds of players is aggregated to inform robot actions. Such a framework could enable a future of synergistic human-machine collaboration for industrial automation, in which members of the public not only freely offer the fruits of their intelligent reasoning for productive use, but have fun whilst doing so. There is also potential for significant negative consequences surrounding safety, accountability and ethics if great care is not taken in the implementation. Further work is needed to explore these wider implications, as well as to develop the technical theory behind the framework and build prototype applications.
ER  - 

TY  - CONF
TI  - A New Overloading Fatigue Model for Ergonomic Risk Assessment with Application to Human-Robot Collaboration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1962
EP  - 1968
AU  - M. Lorenzini
AU  - W. Kim
AU  - E. D. Momi
AU  - A. Ajoudani
PY  - 2019
KW  - biomechanics
KW  - electromyography
KW  - ergonomics
KW  - fatigue
KW  - human-robot interaction
KW  - injuries
KW  - medical disorders
KW  - medical robotics
KW  - occupational health
KW  - occupational safety
KW  - patient monitoring
KW  - risk analysis
KW  - work-related musculoskeletal disorders
KW  - electromyography analysis
KW  - overloading fatigue model
KW  - risk factors
KW  - excessive fatigue accumulation
KW  - HRC framework
KW  - painting task
KW  - fatigue ratio parameter
KW  - joint torque variations
KW  - robot assistance
KW  - body posture optimisation procedure
KW  - human-robot collaboration framework
KW  - light payloads
KW  - overloading torque
KW  - cumulative effect
KW  - whole-body fatigue model
KW  - human joints
KW  - severe injuries
KW  - local muscle fatigue
KW  - light-weight tools
KW  - monotonous movements
KW  - WMSD
KW  - ergonomic risk assessment
KW  - Fatigue
KW  - Torque
KW  - Task analysis
KW  - Muscles
KW  - Load modeling
KW  - Tools
KW  - Robots
DO  - 10.1109/ICRA.2019.8794044
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Among the numerous risk factors associated to work-related musculoskeletal disorders (WMSD), repetitive and monotonous movements with light-weight tools are one of the most frequently cited. Such tasks may indeed result in the excessive accumulation of local muscle fatigue, causing severe injuries in human joints. Accordingly, this paper proposes a new whole-body fatigue model to evaluate the cumulative effect of the overloading torque induced on the joints over time by light payloads. The proposed model is then integrated into a human-robot collaboration (HRC) framework to set the timing of a body posture optimisation procedure guided by the robot assistance, by the time fatigue overcomes a threshold in any joint. Our overloading fatigue model is based on an estimation method we developed in a previous work, to monitor joint torque variations due to external forces in real-time. To account for individuals' different perception of fatigue, the fatigue ratio parameter in the model is computed experimentally for each subject. The proposed model is first studied on ten subjects by means of an electromyography analysis. Next, its performance is assessed in a painting task and finally evaluated within the HRC framework, which is proved to be able to reduce the risk of injuries caused by excessive fatigue accumulation.
ER  - 

TY  - CONF
TI  - Human-inspired balance model to account for foot-beam interaction mechanics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1969
EP  - 1974
AU  - J. Lee
AU  - M. E. Huber
AU  - E. Chiovetto
AU  - M. Giese
AU  - D. Sternad
AU  - N. Hogan
PY  - 2019
KW  - legged locomotion
KW  - nonlinear control systems
KW  - pendulums
KW  - stability
KW  - human-inspired balance model
KW  - foot-beam interaction mechanics
KW  - bipedal robots
KW  - mediolateral balance
KW  - foot-beam interaction dynamics
KW  - human balancing behavior
KW  - human controller
KW  - whole-body behavior
KW  - balance controllers
KW  - foot contact conditions
KW  - foot-ground interaction dynamics
KW  - double inverted pendulum model
KW  - Foot
KW  - Torque
KW  - Robot kinematics
KW  - Mathematical model
KW  - Task analysis
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8793981
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The locomotion and balance capabilities of bipedal robots have greatly improved in recent years. However, maintaining balance on difficult terrain still poses a significant challenge. In this paper, we examined how humans maintain mediolateral balance when standing on a narrow beam with bare feet and wearing rigid soles. Our results show that foot-beam interaction dynamics critically influence balancing behavior. Importantly, this suggests that differences in human balancing behavior across different support surfaces may not solely result from changes in their neural control strategy. They may also result from changes in foot-ground interaction. Thus, the altered foot-ground interaction dynamics must be considered to accurately capture changes in the human controller across different support surfaces. A simplified model of foot-beam interaction was added to a double inverted pendulum model for human balancing. This extended model could replicate the change in human behavior across different foot contact conditions (bare feet vs. rigid feet). A better understanding of how humans coordinate whole-body behavior across a range of conditions may inform the development of balance controllers for bipedal robots.
ER  - 

TY  - CONF
TI  - Real-time Robot-assisted Ergonomics*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1975
EP  - 1981
AU  - A. Shafti
AU  - A. Ataka
AU  - B. U. Lazpita
AU  - A. Shiva
AU  - H. A. Wurdemann
AU  - K. Althoefer
PY  - 2019
KW  - ergonomics
KW  - human-robot interaction
KW  - image colour analysis
KW  - pose estimation
KW  - real-time systems
KW  - human-robot relative position
KW  - human ergonomics
KW  - human-robot interaction
KW  - cooperative robot movements
KW  - real-time robot-assisted ergonomics
KW  - human user posture
KW  - RGB-D camera
KW  - Ergonomics
KW  - Service robots
KW  - Robot sensing systems
KW  - Wrist
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793739
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes a novel approach in human-robot interaction driven by ergonomics. With a clear focus on optimising ergonomics, the approach proposed here continuously observes a human user's posture and by invoking appropriate cooperative robot movements, the user's posture is, whenever required, brought back to an ergonomic optimum. Effectively, the new protocol optimises the human-robot relative position and orientation as a function of human ergonomics. An RGB-D camera is used to calculate and monitor human joint angles in real-time and to determine the current ergonomics state. A total of 6 main causes of low ergonomic states are identified, leading to 6 universal robot responses to allow the human to return to an optimal ergonomics state. The algorithmic framework identifies these 6 causes and controls the cooperating robot to always adapt the environment (e.g. change the pose of the workpiece) in a way that is ergonomically most comfortable for the interacting user. Hence, human-robot interaction is continuously re-evaluated optimizing ergonomics states. The approach is validated through an experimental study, based on established ergonomic methods and their adaptation for real-time application. The study confirms improved ergonomics using the new approach.
ER  - 

TY  - CONF
TI  - A Fog Robotic System for Dynamic Visual Servoing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1982
EP  - 1988
AU  - N. Tian
AU  - A. K. Tanwani
AU  - J. Chen
AU  - M. Ma
AU  - R. Zhang
AU  - B. Huang
AU  - K. Goldberg
AU  - S. Sojoudi
PY  - 2019
KW  - cloud computing
KW  - control engineering computing
KW  - Internet
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - object recognition
KW  - position control
KW  - robot vision
KW  - service robots
KW  - telerobotics
KW  - visual servoing
KW  - dynamic visual
KW  - cloud robotics
KW  - multiple robots
KW  - cloud services
KW  - unlimited computation power
KW  - network communication
KW  - dynamic compliant service robots
KW  - human compliant service robots
KW  - dynamic self-balancing robot
KW  - cloud teleoperation
KW  - cloud-based image based visual servoing module
KW  - cloud teleoperator
KW  - real-time automation system
KW  - cloud-edge hybrid design
KW  - dynamic robotic control
KW  - deep-learning recognition systems
KW  - self-balancing service robot
KW  - fog robotic object recognition system
KW  - Cloud computing
KW  - Service robots
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793600
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Cloud Robotics is a paradigm where multiple robots are connected to cloud services via Internet to access “unlimited” computation power, at the cost of network communication. However, due to limitations such as network latency and variability, it is difficult to control dynamic, human compliant service robots directly from the cloud. In this work, we combine cloud robotics with an agile edge device to build a Fog Robotic system by leveraging an asynchronous protocol with a “heartbeat” signal. We use the system to enable robust teleoperation of a dynamic self-balancing robot from the cloud. We use the system to pick up boxes from static locations, a task commonly performed in warehouse logistics. To make cloud teleoperation more intuitive and efficient, we program a cloud-based image based visual servoing (IBVS) module to automatically assist the cloud teleoperator during the object pickups. Visual feedbacks, including apriltag recognition and tracking, are performed in the cloud to emulate a Fog Robotic object recognition system for IBVS. We demonstrate the feasibility of a dynamic real-time automation system using this cloud-edge hybrid design, which opens up possibilities of deploying dynamic robotic control with deep-learning recognition systems in Fog Robotics. Finally, we show that Fog Robotics enables the self-balancing service robot to pick up a box automatically from a person under unstructured environments.
ER  - 

TY  - CONF
TI  - Approximate Probabilistic Security for Networked Multi-Robot Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1997
EP  - 2003
AU  - R. Wehbe
AU  - R. K. Williams
PY  - 2019
KW  - binary decision diagrams
KW  - computational complexity
KW  - control system security
KW  - graph theory
KW  - multi-robot systems
KW  - networked control systems
KW  - optimisation
KW  - probability
KW  - MRS
KW  - approximate probabilistic security
KW  - networked multirobot systems
KW  - combinatorial optimization problem
KW  - lower bound estimate
KW  - computational complexity
KW  - binary decision diagrams
KW  - exact probability
KW  - optimal subset
KW  - multipoint optimization
KW  - left invertiblility
KW  - disjoint path sets
KW  - online optimization
KW  - Security
KW  - Observers
KW  - Robot sensing systems
KW  - Probabilistic logic
KW  - Boolean functions
KW  - Probability
DO  - 10.1109/ICRA.2019.8794232
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we formulate a combinatorial optimization problem that aims to maximize the accuracy of a lower bound estimate of the probability of security of a multi-robot system (MRS), while minimizing the computational complexity involved in its calculation. Security of an MRS is defined using the well-known control theoretic notion of left invertiblility, and the probability of security of an MRS can be calculated using binary decision diagrams (BDDs). The complexity of a BDD depends on the number of disjoint path sets considered during its construction. Taking into account all possible disjoint paths results in an exact probability of security, however, selecting an optimal subset of disjoint paths leads to a good estimate of the probability while significantly reducing computation. To deal with the dynamic nature of MRSs, we introduce two methods: (1) multi-point optimization, a technique that requires some a priori knowledge of the topology of the MRS over time, and (2) online optimization, a technique that does not require a priori knowledge, but must construct BDDs while the MRS is operating. Finally, our approach is validated on an MRS performing a rendezvous objective while exchanging information according to a noisy state agreement process.
ER  - 

TY  - CONF
TI  - A Decentralized Heterogeneous Control Strategy for a Class of Infinitesimally Shape-Similar Formations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2004
EP  - 2010
AU  - I. Buckley
AU  - M. Egerstedt
PY  - 2019
KW  - decentralised control
KW  - geometry
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - decentralized formation control strategy
KW  - assembled triangulation
KW  - infinitesimally shape-similar formations
KW  - asymptotic controllers
KW  - differential-drive robots
KW  - decentralized heterogeneous control strategy
KW  - sensing modalities
KW  - multirobot team
KW  - infinitesimal shape-similarity
KW  - Robot sensing systems
KW  - Shape
KW  - Robot kinematics
KW  - Self-assembly
KW  - Maintenance engineering
KW  - Multi-Robot Systems
DO  - 10.1109/ICRA.2019.8793514
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The sensing modalities available to individual agents in a multi-robot team have a significant effect on what the team can accomplish. Previous work on infinitesimal shape-similarity has shown that maintaining relative angles between robots equipped with bearing-only sensors can render a formation of these robots invariant to translation, rotation, and uniform scaling; however, previous work has not proposed decentralized control strategies for exploiting this invariance. To address this deficiency, this paper proposes a decentralized formation control strategy for assembled triangulations, a class of infinitesimally shape-similar formations. Heterogeneous in terms of sensing and control, a decentralized formation control strategy is developed in which one robot sets the position of the formation, a robot capable of measuring bearings and distances controls the scale and heading, and the remaining robots maintain the assembled triangulation. The asymptotic controllers that compose the formation control strategy of this work are implemented on a team of differential-drive robots.
ER  - 

TY  - CONF
TI  - Asynchronous Network Formation in Unknown Unbounded Environments*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2011
EP  - 2017
AU  - S. Engin
AU  - V. Isler
PY  - 2019
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - trees (mathematics)
KW  - mobile multirobot system
KW  - arbitrary robot deployments
KW  - robot initial positions
KW  - robot configuration
KW  - online network formation problem
KW  - asynchronous network formation
KW  - unknown unbounded environments
KW  - ONFP
KW  - bounded communication range
KW  - competitive ratio
KW  - Euclidean minimum spanning tree
KW  - Robot kinematics
KW  - Task analysis
KW  - Partitioning algorithms
KW  - Vegetation
KW  - Protocols
KW  - Peer-to-peer computing
DO  - 10.1109/ICRA.2019.8794031
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we study the Online Network Formation Problem (ONFP) for a mobile multi-robot system. Consider a group of robots with a bounded communication range operating in a large open area. One of the robots has a piece of information which has to be propagated to all other robots. What strategy should the robots pursue to disseminate the information to the rest of the robots as quickly as possible? The initial locations of the robots are unknown to each other, therefore the problem must be solved in an online fashion. For this problem, we present an algorithm whose competitive ratio is O(H · max{M, √MH}) for arbitrary robot deployments, where M is the largest edge length in the Euclidean minimum spanning tree on the initial robot configuration and H is the height of the tree. We also study the case when the robot initial positions are chosen uniformly at random and improve the ratio to O(M). Finally, we present simulation results to validate the performance in larger scales and demonstrate our algorithm using three robots in a field experiment.
ER  - 

TY  - CONF
TI  - Switching Topology for Resilient Consensus using Wi-Fi Signals
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2018
EP  - 2024
AU  - T. Wheeler
AU  - E. Bharathi
AU  - S. Gil
PY  - 2019
KW  - graph theory
KW  - multi-robot systems
KW  - probability
KW  - telecommunication network topology
KW  - telecommunication security
KW  - telecommunication switching
KW  - wireless channels
KW  - wireless LAN
KW  - resilient consensus
KW  - physical networks
KW  - multiagent consensus
KW  - Sybil attack
KW  - physical properties
KW  - wireless transmissions
KW  - wireless channels
KW  - switching signal
KW  - untrustworthy agents
KW  - arbitrary malicious node values
KW  - initial topology
KW  - connected topology
KW  - legitimate agents
KW  - Wi-Fi signals
KW  - societal integration
KW  - multirobot team security
KW  - untrustworthy transmissions
KW  - switching topology
KW  - true graph
KW  - Wireless communication
KW  - Switches
KW  - Communication system security
KW  - Wireless sensor networks
KW  - Network topology
KW  - Security
KW  - Topology
DO  - 10.1109/ICRA.2019.8793788
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Securing multi-robot teams against malicious activity is crucial as these systems accelerate towards widespread societal integration. This emerging class of “physical networks” requires research into new methods of security that exploit their physical nature. This paper derives a theoretical framework for securing multi-agent consensus against the Sybil attack by using the physical properties of wireless transmissions. Our frame-work uses information extracted from the wireless channels to design a switching signal that stochastically excludes potentially untrustworthy transmissions from the consensus. Intuitively, this amounts to selectively ignoring incoming communications from untrustworthy agents, allowing for consensus to the true average to be recovered with high probability if initiated after a certain observation time T0 that we derive. This work is different from previous work in that it allows for arbitrary malicious node values and is insensitive to the initial topology of the network so long as a connected topology over legitimate nodes in the network is feasible. We show that our algorithm will recover consensus and the true graph over the system of legitimate agents with an error rate that vanishes exponentially with time.
ER  - 

TY  - CONF
TI  - Multi-Vehicle Trajectory optimisation On Road Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2025
EP  - 2031
AU  - P. Gun
AU  - A. Hill
AU  - R. Vujanic
PY  - 2019
KW  - integer programming
KW  - linear programming
KW  - path planning
KW  - multivehicle trajectory optimisation
KW  - road networks
KW  - planning time-optimal trajectories
KW  - multiple cooperative agents
KW  - static road network
KW  - vehicle interactions
KW  - nontrivial decisions
KW  - complex flow-on effects
KW  - globally optimal time trajectory
KW  - minimum time trajectory
KW  - MILP
KW  - computational performance
KW  - binary variables
KW  - collision constraints
KW  - open-pit mining scenario
KW  - mixed integer linear programming
KW  - goal constraints
KW  - heuristic method
KW  - Roads
KW  - Trajectory
KW  - Planning
KW  - Automation
KW  - Optimization
KW  - Iterative methods
KW  - Mixed integer linear programming
DO  - 10.1109/ICRA.2019.8793831
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of planning time-optimal trajectories for multiple cooperative agents along specified paths through a static road network. Vehicle interactions at intersections create non-trivial decisions, with complex flow-on effects for subsequent interactions. A globally optimal, minimum time trajectory is found for all vehicles using Mixed Integer Linear Programming (MILP). Computational performance is improved by minimising binary variables using iteratively applied targeted collision constraints, and efficient goal constraints. Simulation results in an open-pit mining scenario compare the proposed method against a fast heuristic method and a reactive approach based on site practices. The heuristic is found to scale better with problem size while the MILP is able to avoid local minima.
ER  - 

TY  - CONF
TI  - Disturbance Compensation Based Control for an Indoor Blimp Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2040
EP  - 2046
AU  - Y. Wang
AU  - G. Zheng
AU  - D. Efimov
AU  - W. Perruquetti
PY  - 2019
KW  - autonomous aerial vehicles
KW  - compensation
KW  - control system synthesis
KW  - feedback
KW  - mobile robots
KW  - nonlinear control systems
KW  - observers
KW  - robust control
KW  - uncertain systems
KW  - blimp disturbance compensation based controller
KW  - indoor blimp robot
KW  - robust controller
KW  - horizontal plane
KW  - slider-like nonlinear system
KW  - uncertain bounded disturbances
KW  - output feedback controller
KW  - disturbance evaluation
KW  - exogenous disturbances
KW  - control scheme
KW  - concrete blimp
KW  - homogeneous differentiator
KW  - observer
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Biological system modeling
KW  - Output feedback
KW  - Robot sensing systems
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793535
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents design of a robust controller with disturbance compensation for an indoor blimp robot and its realization. The movement of blimp in horizontal plane is modeled as a slider-like nonlinear system complemented with uncertain bounded disturbances. To design the output feedback controller, a homogeneous differentiator is used as an observer. Then the method for disturbance evaluation is designed, the perturbation estimate is next used in the controller for cancellation of the influence of exogenous disturbances. Control scheme is implemented on a concrete blimp, finally, the performance of blimp disturbance compensation based controller is verified in experiments.
ER  - 

TY  - CONF
TI  - Informed Information Theoretic Model Predictive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2047
EP  - 2053
AU  - R. Kusumoto
AU  - L. Palmieri
AU  - M. Spies
AU  - A. Csiszar
AU  - K. O. Arras
PY  - 2019
KW  - nonlinear control systems
KW  - nonlinear dynamical systems
KW  - optimal control
KW  - optimisation
KW  - predictive control
KW  - robust control
KW  - sampling methods
KW  - informed sampling distribution
KW  - optimized controls
KW  - informed information theoretic model predictive control
KW  - nonlinear control systems
KW  - uncertainties
KW  - highly nonlinear dynamics
KW  - contextual information
KW  - generative models
KW  - trajectory control
KW  - sampling-based MPC methods
KW  - robustness properties
KW  - conditional variational autoencoders
KW  - autonomous navigation domain
KW  - Task analysis
KW  - Optimal control
KW  - Trajectory
KW  - Decoding
KW  - Robots
KW  - Planning
KW  - Cost function
DO  - 10.1109/ICRA.2019.8793945
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The problem of minimizing cost in nonlinear control systems with uncertainties or disturbances remains a major challenge. Model predictive control (MPC), and in particular sampling-based MPC has recently shown great success in complex domains such as aggressive driving with highly nonlinear dynamics. Sampling-based methods rely on a prior distribution to generate samples in the first place. Obviously, the choice of this distribution highly influences efficiency of the controller. Existing approaches such as sampling around the control trajectory of the previous time step perform suboptimally, especially in multi-modal or highly dynamic settings. In this work, we therefore propose to learn models that generate samples in low-cost areas of the state-space, conditioned on the environment and on contextual information of the task to solve. By using generative models as an informed sampling distribution, our approach exploits guidance from the learned models and at the same time maintains robustness properties of the MPC methods. We use Conditional Variational Autoencoders (CVAE) to learn distributions that imitate samples from a training dataset containing optimized controls. An extensive evaluation in the autonomous navigation domain suggests that replacing previous sampling schemes with our learned models considerably improves performance in terms of path quality and planning efficiency.
ER  - 

TY  - CONF
TI  - A Generic Optimization Based Cartesian Controller for Robotic Mobile Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2054
EP  - 2060
AU  - E. Brzozowska
AU  - O. Lima
AU  - R. Ventura
PY  - 2019
KW  - angular velocity control
KW  - closed loop systems
KW  - end effectors
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - probability
KW  - robot vision
KW  - service robots
KW  - sequential phases
KW  - closed loop perspective
KW  - generic optimization-based Cartesian controller
KW  - motion commands
KW  - robotic system
KW  - mobile platform
KW  - velocity space
KW  - end effector velocity
KW  - joint platform velocities
KW  - base platform velocities
KW  - mobile service robot architecture
KW  - domestic tasks
KW  - robotic mobile manipulation
KW  - random arm configurations
KW  - Optimization
KW  - Kinematics
KW  - Manipulators
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Planning
DO  - 10.1109/ICRA.2019.8793635
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Typically, the problem of robotic manipulation is divided among two sequential phases: a planning one and an execution one. However, since the second one is executed in open loop, the robot is unable to react in real time to changes in the task (e.g. moving object). This paper addresses the mobile manipulation problem from a real-time, closed loop perspective. In particular, we propose a generic optimization-based Cartesian controller, that given a continuous monitoring of the goal, determines the best motion commands. We target our controller to a robotic system comprising an arm and a mobile platform. However, the approach can in principle be extended to more complex mechanisms. The approach is based on shifting the problem to velocity space, where end effector velocity is a linear function of joint and base platform velocities. Our approach was quantitatively evaluated both on simulation and on a real service robot. It was also integrated into a mobile service robot architecture targeting domestic tasks and evaluated on the RoboCup@Home scientific competition. Our results show that the controller is able to reach random arm configurations with a high probability of success.
ER  - 

TY  - CONF
TI  - Task-Driven Estimation and Control via Information Bottlenecks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2061
EP  - 2067
AU  - V. Pacelli
AU  - A. Majumdar
PY  - 2019
KW  - information theory
KW  - iterative methods
KW  - robots
KW  - state estimation
KW  - general algorithmic framework
KW  - task-driven estimation
KW  - state representations
KW  - state estimation
KW  - task-driven representation
KW  - task-relevant variables
KW  - performant control policy
KW  - robotic system control
KW  - principled algorithmic framework
KW  - iterative algorithms
KW  - information bottleneck optimization problem
KW  - Task analysis
KW  - Robot sensing systems
KW  - Robustness
KW  - Optimized production technology
KW  - Estimation
DO  - 10.1109/ICRA.2019.8794213
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Our goal is to develop a principled and general algorithmic framework for task-driven estimation and control for robotic systems. State-of-the-art approaches for controlling robotic systems typically rely heavily on accurately estimating the full state of the robot (e.g., a running robot might estimate joint angles and velocities, torso state, and position relative to a goal). However, full state representations are often excessively rich for the specific task at hand and can lead to significant computational inefficiency and brittleness to errors in state estimation. In contrast, we present an approach that eschews such rich representations and seeks to create task-driven representations. The key technical insight is to leverage the theory of information bottlenecks to formalize the notion of a “task-driven representation” in terms of information theoretic quantities that measure the minimality of a representation. We propose novel iterative algorithms for automatically synthesizing (offline) a task-driven representation (given in terms of a set of task-relevant variables (TRVs)) and a performant control policy that is a function of the TRVs. We present online algorithms for estimating the TRVs in order to apply the control policy. We demonstrate that our approach results in significant robustness to unmodeled measurement uncertainty both theoretically and via thorough simulation experiments including a spring-loaded inverted pendulum running to a goal location.
ER  - 

TY  - CONF
TI  - Feasibility Analysis For Constrained Model Predictive Control Based Motion Cueing Algorithm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2076
EP  - 2082
AU  - C. Rengifo
AU  - J. Chardonnet
AU  - H. Mohellebi
AU  - D. Paillot
AU  - A. Kemeny
PY  - 2019
KW  - closed loop systems
KW  - motion control
KW  - optimal control
KW  - predictive control
KW  - road traffic control
KW  - stability
KW  - feasibility issues
KW  - implicit model predictive control-based motion cueing algorithms
KW  - prediction horizons
KW  - control inputs
KW  - feasibility analysis
KW  - constrained model predictive control based motion cueing algorithm
KW  - motion control
KW  - constrained optimal control
KW  - high performance driving simulator
KW  - Acceleration
KW  - Force
KW  - Stability criteria
KW  - Cost function
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794129
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper deals with motion control for an 8-degree-of-freedom (DOF) high performance driving simulator. We formulate a constrained optimal control that defines the dynamical behavior of the system. Furthermore, the paper brings together various methodologies for addressing feasibility issues arising in implicit model predictive control-based motion cueing algorithms. The implementation of different techniques is described and discussed subsequently. Several simulations are carried out in the simulator platform. It is observed that the only technique that can provide ensured closed-loop stability by assuring feasibility over all prediction horizons is a braking law that basically saturates the control inputs in the constrained form.
ER  - 

TY  - CONF
TI  - Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2083
EP  - 2089
AU  - R. McAllister
AU  - G. Kahn
AU  - J. Clune
AU  - S. Levine
PY  - 2019
KW  - Bayes methods
KW  - belief networks
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - robust control
KW  - uncertainty-aware robotic perception
KW  - explicit generative model
KW  - observation distribution
KW  - action-conditioned collision prediction task
KW  - Bayesian neural network techniques
KW  - task-aware generative uncertainty
KW  - deep learning
KW  - open world
KW  - real-world robotic systems
KW  - mobile robots
KW  - out-of-distribution observations
KW  - neural network predictions
KW  - robotic perception
KW  - approximate Bayesian approach
KW  - Uncertainty
KW  - Robots
KW  - Predictive models
KW  - Bayes methods
KW  - Neural networks
KW  - Training
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793552
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deep learning provides a powerful tool for robotic perception in the open world. However, real-world robotic systems, especially mobile robots, must be able to react intelligently and safely even in unexpected circumstances. This requires a system that knows what it knows, and can estimate its own uncertainty for unfamiliar, out-of-distribution observations. Approximate Bayesian approaches are commonly used to estimate uncertainty for neural network predictions, but struggle with out-of-distribution observations. Generative models can in principle detect out-of-distribution observations as those with a low estimated density, but overly pessimistic as an uncertainty measure, since the mere presence of an out-of-distribution input does not by itself indicate an unsafe situation. Intuitively, we would like a perception system that can detect when task-salient parts of the image are unfamiliar or uncertain, while ignoring task-irrelevant features. In this paper, we present a method for uncertainty-aware robotic perception that combines generative modeling and model uncertainty. Our method estimates an uncertainty measure about the model's prediction, taking into account an explicit generative model of the observation distribution to handle out-of-distribution inputs. We evaluate our method on an action-conditioned collision prediction task with both simulated and real data, and demonstrate that our approach improves on a variety of Bayesian neural network techniques.
ER  - 

TY  - CONF
TI  - Multimodal Trajectory Predictions for Autonomous Driving using Deep Convolutional Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2090
EP  - 2096
AU  - H. Cui
AU  - V. Radosavljevic
AU  - F. Chou
AU  - T. Lin
AU  - T. Nguyen
AU  - T. Huang
AU  - J. Schneider
AU  - N. Djuric
PY  - 2019
KW  - convolutional neural nets
KW  - driver information systems
KW  - feature extraction
KW  - image processing
KW  - mobile robots
KW  - probability
KW  - road accidents
KW  - road safety
KW  - road traffic
KW  - road vehicles
KW  - multimodal trajectory predictions
KW  - autonomous driving
KW  - deep convolutional networks
KW  - robotics
KW  - artificial intelligence communities
KW  - self-driving vehicles
KW  - SDVs
KW  - road accidents
KW  - human drivers
KW  - traffic behavior
KW  - safe operations
KW  - autonomous vehicle
KW  - raster image
KW  - probabilities
KW  - Trajectory
KW  - Predictive models
KW  - Roads
KW  - Hidden Markov models
KW  - Task analysis
KW  - Radar tracking
DO  - 10.1109/ICRA.2019.8793868
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous driving presents one of the largest problems that the robotics and artificial intelligence communities are facing at the moment, both in terms of difficulty and potential societal impact. Self-driving vehicles (SDVs) are expected to prevent road accidents and save millions of lives while improving the livelihood and life quality of many more. However, despite large interest and a number of industry players working in the autonomous domain, there still remains more to be done in order to develop a system capable of operating at a level comparable to best human drivers. One reason for this is high uncertainty of traffic behavior and large number of situations that an SDV may encounter on the roads, making it very difficult to create a fully generalizable system. To ensure safe and efficient operations, an autonomous vehicle is required to account for this uncertainty and to anticipate a multitude of possible behaviors of traffic actors in its surrounding. We address this critical problem and present a method to predict multiple possible trajectories of actors while also estimating their probabilities. The method encodes each actor's surrounding context into a raster image, used as input by deep convolutional networks to automatically derive relevant features for the task. Following extensive offline evaluation and comparison to state-of-the-art baselines, the method was successfully tested on SDVs in closed-course tests.
ER  - 

TY  - CONF
TI  - Classifying Pedestrian Actions In Advance Using Predicted Video Of Urban Driving Scenes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2097
EP  - 2103
AU  - P. Gujjar
AU  - R. Vaughan
PY  - 2019
KW  - feature extraction
KW  - graphics processing units
KW  - image classification
KW  - image representation
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - pedestrians
KW  - traffic engineering computing
KW  - video signal processing
KW  - encoder-decoder network models
KW  - predicted video
KW  - urban driving scenes
KW  - traffic scene
KW  - pedestrian behaviour
KW  - urban pedestrian
KW  - binary action classifier
KW  - iterative transform
KW  - image sequence
KW  - GPU
KW  - Hidden Markov models
KW  - Decoding
KW  - Predictive models
KW  - Kernel
KW  - Training
KW  - Automobiles
KW  - Iterative decoding
DO  - 10.1109/ICRA.2019.8794278
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fig. 1.Generating predictions of a future for a pedestrian attempting to cross the street. We pick out two key frames from the (a) input sequence and the (b) ground truth sequence, 16 frames apart. Image (c) shows our prediction at the same time instant as the ground truth.We explore prediction of urban pedestrian actions by generating a video future of the traffic scene, and show promising results in classifying pedestrian behaviour before it is observed. We compare several encoder-decoder network models that predict 16 frames (400-600 milliseconds of video) from the preceding 16 frames. Our main contribution is a method for learning a sequence of representations to iteratively transform features learnt from the input to the future. Then we use a binary action classifier network for determining a pedestrian's crossing intent from predicted video. Our results show an average precision of 81%, significantly higher than previous methods. The model with the best classification performance runs for 117 ms on commodity GPU, giving an effective look-ahead of 416 ms.
ER  - 

TY  - CONF
TI  - Lightweight Contrast Modeling for Attention-Aware Visual Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2104
EP  - 2110
AU  - L. Huang
AU  - G. Li
AU  - Y. Li
AU  - L. Lin
PY  - 2019
KW  - intelligent robots
KW  - object detection
KW  - salient object detection task
KW  - object saliency details
KW  - lightweight refinement module
KW  - high-level visual contrast
KW  - superior lightweight network architecture
KW  - computational resource consumption
KW  - detection performance
KW  - attention-aware visual objects
KW  - attention-aware visual localization
KW  - lightweight contrast modeling
KW  - Convolution
KW  - Visualization
KW  - Object detection
KW  - Feature extraction
KW  - Robots
KW  - Training
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794442
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Salient object detection, which aims at localizing the attention-aware visual objects, is the indispensable technology for intelligent robots to understand and interact with the complicated environments. Existing salient object detection approaches mainly focus on the optimization of detection performance, while ignoring the considerations for computational resource consumption and algorithm efficiency. Contrarily, we build a superior lightweight network architecture to simultaneously improve performance on both accuracy and efficiency for salient object detection. Specifically, our proposed approach adopts the lightweight bottleneck as its primary building block to significantly reduce the number of parameters and to speed up the process of training and inference. In practice, the visual contrast is insufficiently discovered with the limitation of the small empirical receptive field of CNN. To alleviate this issue, we design a multi-scale convolution module to rapidly discover high-level visual contrast. Moreover, a lightweight refinement module is utilized to restore object saliency details with negligible extra cost. Extensive experiments on efficiency and accuracy trade-offs show that our model is more competitive than the state-of-the-art works on salient object detection task and has prominent potentials for robots applications in real time.
ER  - 

TY  - CONF
TI  - Learning to Write Anywhere with Spatial Transformer Image-to-Motion Encoder-Decoder Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2111
EP  - 2117
AU  - B. Ridge
AU  - R. Pahič
AU  - A. Ude
AU  - J. Morimoto
PY  - 2019
KW  - affine transforms
KW  - handwritten character recognition
KW  - humanoid robots
KW  - image coding
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - DMP
KW  - digit drawings
KW  - image-to-motion encoder-decoder networks
KW  - convolutional layers
KW  - humanoid robot
KW  - affine transformed digits
KW  - fully differentiable overall network
KW  - spatial transformer
KW  - motion trajectories
KW  - digit images
KW  - robot vision
KW  - handwritten characters
KW  - Trajectory
KW  - Robots
KW  - Transforms
KW  - Task analysis
KW  - Writing
KW  - Neural networks
KW  - Decoding
DO  - 10.1109/ICRA.2019.8794253
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning to recognize and reproduce handwritten characters is already a challenging task both for humans and robots alike, but learning to do the same thing for characters that can be transformed arbitrarily in space, as humans do when writing on a blackboard for instance, significantly ups the ante from a robot vision and control perspective. In previous work we proposed various different forms of encoder-decoder networks that were capable of mapping raw images of digits to dynamic movement primitives (DMPs) such that a robot could learn to translate the digit images into motion trajectories in order to reproduce them in written form. However, even with the addition of convolutional layers in the image encoder, the extent to which these networks are spatially invariant or equivariant is rather limited. In this paper, we propose a new architecture that incorporates both an image-to-motion encoder-decoder and a spatial transformer in a fully differentiable overall network that learns to rectify affine transformed digits in input images into canonical forms, before converting them into DMPs with accompanying motion trajectories that are finally transformed back to match up with the original digit drawings such that a robot can write them in their original forms. We present experiments with various challenging datasets that demonstrate the superiority of the new architecture compared to our previous work and demonstrate its use with a humanoid robot in a real writing task.
ER  - 

TY  - CONF
TI  - Motion Planning Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2118
EP  - 2124
AU  - A. H. Qureshi
AU  - A. Simeonov
AU  - M. J. Bency
AU  - M. C. Yip
PY  - 2019
KW  - collision avoidance
KW  - computational complexity
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - neurocontrollers
KW  - computational complexity
KW  - neural network
KW  - collision-free paths
KW  - motion planning networks
KW  - robotics applications
KW  - self-driving cars
KW  - 7 DOF Baxter robot manipulator
KW  - MPNet
KW  - Planning
KW  - Three-dimensional displays
KW  - Neural networks
KW  - Training
KW  - Manipulators
KW  - Encoding
DO  - 10.1109/ICRA.2019.8793889
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fast and efficient motion planning algorithms are crucial for many state-of-the-art robotics applications such as self-driving cars. Existing motion planning methods become ineffective as their computational complexity increases exponentially with the dimensionality of the motion planning problem. To address this issue, we present Motion Planning Networks (MPNet), a neural network-based novel planning algorithm. The proposed method encodes the given workspaces directly from a point cloud measurement and generates the end-to-end collision-free paths for the given start and goal configurations. We evaluate MPNet on various 2D and 3D environments including the planning of a 7 DOF Baxter robot manipulator. The results show that MPNet is not only consistently computationally efficient in all environments but also generalizes to completely unseen environments. The results also show that the computation time of MPNet consistently remains less than 1 second in all presented experiments, which is significantly lower than existing state-of-the-art motion planning algorithms.
ER  - 

TY  - CONF
TI  - Improving Data Efficiency of Self-supervised Learning for Robotic Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2125
EP  - 2131
AU  - L. Berscheid
AU  - T. Rühr
AU  - T. Kröger
PY  - 2019
KW  - convolutional neural nets
KW  - force feedback
KW  - grippers
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - fully-convolutional neural network
KW  - gripper parameters
KW  - inference performance
KW  - random grasp success rate
KW  - grasp space
KW  - systematic manner
KW  - typical bin picking scenarios
KW  - self-supervised learning
KW  - robotic grasping
KW  - depth camera input
KW  - gripper force feedback
KW  - learning algorithm
KW  - geometric consistency
KW  - undistorted depth images
KW  - task space
KW  - grasp attempts
KW  - data efficiency
KW  - training data
KW  - Grasping
KW  - Grippers
KW  - Robot kinematics
KW  - Artificial neural networks
KW  - Task analysis
KW  - Training
DO  - 10.1109/ICRA.2019.8793952
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Given the task of learning robotic grasping solely based on a depth camera input and gripper force feedback, we derive a learning algorithm from an applied point of view to significantly reduce the amount of required training data. Major improvements in time and data efficiency are achieved by: Firstly, we exploit the geometric consistency between the undistorted depth images and the task space. Using a relative small, fully-convolutional neural network, we predict grasp and gripper parameters with great advantages in training as well as inference performance. Secondly, motivated by the small random grasp success rate of around 3 %, the grasp space was explored in a systematic manner. The final system was learned with 23 000 grasp attempts in around 60 h, improving current solutions by an order of magnitude. For typical bin picking scenarios, we measured a grasp success rate of (96.6 ± 1.0) %. Further experiments showed that the system is able to generalize and transfer knowledge to novel objects and environments.
ER  - 

TY  - CONF
TI  - Online Object and Task Learning via Human Robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2132
EP  - 2138
AU  - M. Dehghan
AU  - Z. Zhang
AU  - M. Siam
AU  - J. Jin
AU  - L. Petrich
AU  - M. Jagersand
PY  - 2019
KW  - force control
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - motion control
KW  - neural nets
KW  - deep learning based localization
KW  - recognition system
KW  - intuitive user interface
KW  - 3D motion task
KW  - hybrid force-vision control module
KW  - compliant motion
KW  - task learning
KW  - human robot interaction
KW  - KUKA Innovation Award competition
KW  - Hanover Messe 2018
KW  - online object learning
KW  - incremental object learning module
KW  - Robots
KW  - Education
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Feature extraction
KW  - Human-robot interaction
DO  - 10.1109/ICRA.2019.8794036
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work describes the development of a robotic system that acquires knowledge incrementally through human interaction where new objects and motions are taught on the fly. The robotic system developed was one of the five finalists in the KUKA Innovation Award competition and demonstrated during the Hanover Messe 2018 in Germany. The main contributions of the system are i) a novel incremental object learning module - a deep learning based localization and recognition system - that allows a human to teach new objects to the robot, ii) an intuitive user interface for specifying 3D motion task associated with the new object, and iii) a hybrid force-vision control module for performing compliant motion on an unstructured surface. This paper describes the implementation and integration of the main modules of the system and summarizes the lessons learned from the competition.
ER  - 

TY  - CONF
TI  - Dynamic Manipulation of Flexible Objects with Torque Sequence Using a Deep Neural Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2139
EP  - 2145
AU  - K. Kawaharazuka
AU  - T. Ogawa
AU  - J. Tamura
AU  - C. Nabeshima
PY  - 2019
KW  - control engineering computing
KW  - flexible manipulators
KW  - manipulator dynamics
KW  - motion control
KW  - neural nets
KW  - time series
KW  - torque control
KW  - dynamic manipulation
KW  - torque sequence
KW  - deep neural network
KW  - acquisition method
KW  - flexible object motion equation model
KW  - time-series joint torque command
KW  - Torque
KW  - Mathematical model
KW  - Dynamics
KW  - Optical imaging
KW  - Manipulator dynamics
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793513
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For dynamic manipulation of flexible objects, we propose an acquisition method of a flexible object motion equation model using a deep neural network and a control method to realize a target state by calculating an optimized time-series joint torque command. By using the proposed method, any physics model of a target object is not needed, and the object can be controlled as intended. We applied this method to manipulations of a rigid object, a flexible object with and without environmental contact, and a cloth, and verified its effectiveness.
ER  - 

TY  - CONF
TI  - Color-Coded Fiber-Optic Tactile Sensor for an Elastomeric Robot Skin
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2146
EP  - 2152
AU  - Z. Kappassov
AU  - D. Baimukashev
AU  - Z. Kuanyshuly
AU  - Y. Massalin
AU  - A. Urazbayev
AU  - H. A. Varol
PY  - 2019
KW  - cameras
KW  - robots
KW  - tactile sensors
KW  - contact localization
KW  - robotic perception system
KW  - force sensing range
KW  - color-coded tactile sensor
KW  - tactile exploration
KW  - robust tactile sensing
KW  - color-coded fiber-optic tactile sensor
KW  - elastomeric robot skin
KW  - artificial tactile skin
KW  - transparent silicone rubber
KW  - off-the-shelf color camera
KW  - camera POFs
KW  - Optical sensors
KW  - Tactile sensors
KW  - Image color analysis
KW  - Cameras
DO  - 10.1109/ICRA.2019.8793262
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The sense of touch is essential for reliable mapping between the environment and a robot which interacts physically with objects. Presumably, an artificial tactile skin would facilitate safe interaction of the robots with the environment. In this work, we present our color-coded tactile sensor, incorporating plastic optical fibers (POF), transparent silicone rubber and an off-the-shelf color camera. Processing electronics are placed away from the sensing surface to make the sensor robust to harsh environments. Contact localization is possible thanks to the lower number of light sources compared to the number of camera POFs. Classical machine learning techniques and a hierarchical classification scheme were used for contact localization. Specifically, we generated the mapping from stimulation to sensation of a robotic perception system using our sensor. We achieved a force sensing range up to 18 N with the force resolution of around 3.6 N and the spatial resolution of 8 mm. The color-coded tactile sensor is suitable for tactile exploration and might enable further innovations in robust tactile sensing.
ER  - 

TY  - CONF
TI  - Reinforcement Learning in Topology-based Representation for Human Body Movement with Whole Arm Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2153
EP  - 2160
AU  - W. Yuan
AU  - K. Hang
AU  - H. Song
AU  - D. Kragic
AU  - M. Y. Wang
AU  - J. A. Stork
PY  - 2019
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - medical robotics
KW  - path planning
KW  - patient care
KW  - position control
KW  - topology-based representation
KW  - human body movement
KW  - bulky object
KW  - WAM
KW  - manipulation places
KW  - global properties
KW  - local contacts
KW  - grasping
KW  - reinforcement learning problem
KW  - robot behavior
KW  - human motion
KW  - robot-human interaction
KW  - topology-based coordinates
KW  - torso positions
KW  - learned policy
KW  - body shapes
KW  - dynamic sea rescue scenario
KW  - unseen scenarios
KW  - differently-shaped humans
KW  - whole arm manipulation
KW  - Robot kinematics
KW  - Humanoid robots
KW  - Manipulators
KW  - Laplace equations
KW  - Torso
KW  - Shape
DO  - 10.1109/ICRA.2019.8794160
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Moving a human body or a large and bulky object may require the strength of whole arm manipulation (WAM). This type of manipulation places the load on the robot's arms and relies on global properties of the interaction to succeed- rather than local contacts such as grasping or non-prehensile pushing. In this paper, we learn to generate motions that enable WAM for holding and transporting of humans in certain rescue or patient care scenarios. We model the task as a reinforcement learning problem in order to provide a robot behavior that can directly respond to external perturbation and human motion. For this, we represent global properties of the robot-human interaction with topology-based coordinates that are computed from arm and torso positions. These coordinates also allow transferring the learned policy to other body shapes and sizes. For training and evaluation, we simulate a dynamic sea rescue scenario and show in quantitative experiments that the policy can solve unseen scenarios with differently-shaped humans, floating humans, or with perception noise. Our qualitative experiments show the subsequent transporting after holding is achieved and we demonstrate that the policy can be directly transferred to a real world setting.
ER  - 

TY  - CONF
TI  - Demonstration-Guided Deep Reinforcement Learning of Control Policies for Dexterous Human-Robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2161
EP  - 2167
AU  - S. Christen
AU  - S. Stevšić
AU  - O. Hilliges
PY  - 2019
KW  - dexterous manipulators
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - motion control
KW  - neural nets
KW  - handshake
KW  - hand clap
KW  - finger touch
KW  - training control policies
KW  - human-robot interactions
KW  - hand claps
KW  - humanoid Shadow Dexterous Hand
KW  - robot arm
KW  - multiobjective reward function
KW  - reward structure
KW  - motion capture data
KW  - human-human interactions
KW  - hand interactions
KW  - dexterous human-robot interaction
KW  - demonstration-guided deep reinforcement learning
KW  - Training
KW  - Humanoid robots
KW  - Task analysis
KW  - Robot kinematics
KW  - Reinforcement learning
KW  - Convergence
DO  - 10.1109/ICRA.2019.8794065
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a method for training control policies for human-robot interactions such as handshakes or hand claps via Deep Reinforcement Learning. The policy controls a humanoid Shadow Dexterous Hand, attached to a robot arm. We propose a parameterizable multi-objective reward function that allows learning of a variety of interactions without changing the reward structure. The parameters of the reward function are estimated directly from motion capture data of human-human interactions in order to produce policies that are perceived as being natural and human-like by observers. We evaluate our method on three significantly different hand interactions: handshake, hand clap and finger touch. We provide detailed analysis of the proposed reward function and the resulting policies and conduct a large-scale user study, indicating that our policy produces natural looking motions.
ER  - 

TY  - CONF
TI  - Team-Based Robot Righting via Pushing and Shell Design
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2168
EP  - 2173
AU  - D. L. McPherson
AU  - R. S. Fearing
PY  - 2019
KW  - control system synthesis
KW  - mobile robots
KW  - multi-robot systems
KW  - shells (structures)
KW  - team-based robot righting
KW  - minimalist robot designs
KW  - specialized escape actuator
KW  - emergency actuator
KW  - teammate pushing
KW  - VelociRoACH robots
KW  - robot exterior hull
KW  - shell design
KW  - Force
KW  - Friction
KW  - Shape
KW  - Actuators
KW  - Robot kinematics
KW  - Potential energy
DO  - 10.1109/ICRA.2019.8793958
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The minimalist robot designs typically employed in swarms and teams can fall and get trapped when traversing irregular terrain. To protect against this contingency the design could add a specialized escape actuator, but each actuator drives up cost multiplicatively for the whole team. Instead, the emergency actuator can be found for free in the form of another teammate. Teammate pushing can be efficiently directed by careful shaping of the robot's exterior hull. This approach is illustrated by designing a shell for VelociRoACH robots that enables them to roll pronated comrades back onto their feet. The designed maneuver can be performed in open-loop with 87% success and an average time of 0.7 seconds.
ER  - 

TY  - CONF
TI  - Deformation-based shape control with a multirobot system
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2174
EP  - 2180
AU  - M. Aranda
AU  - J. A. Corrales
AU  - Y. Mezouar
PY  - 2019
KW  - feedback
KW  - gradient methods
KW  - manipulators
KW  - mobile robots
KW  - multi-robot systems
KW  - 2D space
KW  - useful team behaviors
KW  - deformation-based control framework
KW  - manipulation task
KW  - resulting multirobot controller
KW  - robot motions
KW  - feedback loop
KW  - global measure
KW  - typical goal
KW  - deformable object
KW  - application scenario
KW  - robotic team
KW  - multirobot system
KW  - deformation-based shape control
KW  - Robot kinematics
KW  - Shape
KW  - Strain
KW  - Task analysis
KW  - Geometry
KW  - Shape control
DO  - 10.1109/ICRA.2019.8793811
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel method to control the relative positions of the members of a robotic team. The application scenario we consider is the cooperative manipulation of a deformable object in 2D space. A typical goal in this kind of scenario is to minimize the deformation of the object with respect to a desired state. Our contribution, then, is to use a global measure of deformation directly in the feedback loop. In particular, the robot motions are based on the descent along the gradient of a metric that expresses the difference between the team's current configuration and its desired shape. Crucially, the resulting multirobot controller has a simple expression and is inexpensive to compute, and the approach lends itself to analysis of both the transient and asymptotic dynamics of the system. This analysis reveals a number of properties that are interesting for a manipulation task: fundamental geometric parameters of the team (size, orientation, centroid, and distances between robots) can be suitably steered or bounded. We describe different policies within the proposed deformation-based control framework that produce useful team behaviors. We illustrate the methodology with computer simulations.
ER  - 

TY  - CONF
TI  - One-to-many bipartite matching based coalition formation for multi-robot task allocation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2181
EP  - 2187
AU  - A. Dutta
AU  - A. Asaithambi
PY  - 2019
KW  - approximation theory
KW  - computational complexity
KW  - graph theory
KW  - multi-robot systems
KW  - multirobot task allocation
KW  - multirobot coalition formation
KW  - OTMaM problem
KW  - multiple robots
KW  - robot-task pairs
KW  - worst-case approximation ratio
KW  - worst-case time complexity
KW  - NP-hard problem
KW  - one-to-many bipartite matching based coalition formation
KW  - Task analysis
KW  - Robot kinematics
KW  - Resource management
KW  - Bipartite graph
KW  - Approximation algorithms
KW  - Time complexity
DO  - 10.1109/ICRA.2019.8793855
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we study the NP-Hard problem of multi-robot coalition formation for task allocation. To tackle this notoriously difficult problem, we model it as a variant of classical bipartite matching, which we call One-To-Many Bipartite Matching (OTMaM). Unlike the classical bipartite matching techniques used for matching a unique robot to a unique task, in the OTMaM problem, we let multiple robots to be matched to a single task while restricting the opposite. To this end, we propose a novel heuristic algorithm that allocates robots to tasks by finding mutually best robot-task pairs. Our algorithm provides a similar theoretical worst-case approximation ratio and guarantees a better worst-case time complexity than a comparable algorithm from the literature. The proposed approach in this paper is proved to be deterministic and the resultant matching is perfect. Simulation results also demonstrate the scalability of the presented algorithm (taking less than 1 millisecond with 100 robots and 10 tasks).
ER  - 

TY  - CONF
TI  - Coordinated multi-robot planning while preserving individual privacy
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2188
EP  - 2194
AU  - L. Li
AU  - A. Bayuelo
AU  - L. Bobadilla
AU  - T. Alam
AU  - D. A. Shell
PY  - 2019
KW  - collision avoidance
KW  - cryptography
KW  - data privacy
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - coordinated multirobot planning
KW  - individual privacy
KW  - multiple robots
KW  - privacy-preserving rendezvous
KW  - persistent monitoring
KW  - joint plan
KW  - collective motions
KW  - collective task
KW  - joint-collision determination
KW  - mobile robots
KW  - secure path intersection primitives
KW  - homomorphic encryption
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Protocols
KW  - Task analysis
KW  - Privacy
KW  - Encryption
DO  - 10.1109/ICRA.2019.8794460
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of multiple robots that must cooperate within a shared environment, but which wish to limit the information they disclose during their coordination efforts. Specifically, we examine the problems of privacy-preserving rendezvous and persistent monitoring. In the former, the robots construct a joint plan to have them meet, without either knowing beforehand where or when the meeting will occur. In the latter, multiple robots dynamically cover a region of space-they plan collective motions which are collision-free but with the assurance that agents remain ignorant of the paths of others. Accordingly, the tasks are sort of inverses in that the robots must collectively determine whether their joint paths collide or not, then, using this, achieve their collective task. Other than what is learned by the outcome of the joint-collision determination, the robots possess no details of the other paths. Our approach builds on garbled circuits and homomorphic encryption to realize basic secure path intersection primitives. We present algorithms, a software implementation, and a physical experiment on mobile robots to test the practical feasibility of our approach. We believe that these ideas provide a valuable direction for adoption in small Unmanned Systems belonging to different stakeholders.
ER  - 

TY  - CONF
TI  - Multi-Agent Synchronization Using Online Model-Free Action Dependent Dual Heuristic Dynamic Programming Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2195
EP  - 2201
AU  - M. Abouheaf
AU  - W. Gueaieb
PY  - 2019
KW  - adaptive control
KW  - approximation theory
KW  - discrete time systems
KW  - dynamic programming
KW  - iterative methods
KW  - learning systems
KW  - multi-agent systems
KW  - neurocontrollers
KW  - nonlinear control systems
KW  - optimal control
KW  - action dependent dual heuristic dynamic programming schemes
KW  - fast solution platforms
KW  - unknown models
KW  - uncertain dynamical models
KW  - online model-free adaptive
KW  - dynamic graphical games
KW  - approximate the optimal value function
KW  - associated model-free control strategy
KW  - model-free coupled Bellman optimality equation
KW  - multiagent synchronization
KW  - online model-free action dependent dual heuristic dynamic programming approach
KW  - approximate dynamic programming platforms
KW  - agents interaction
KW  - communication graphs
KW  - policy iteration process
KW  - Mathematical model
KW  - Adaptation models
KW  - Optimal control
KW  - Dynamic programming
KW  - Synchronization
KW  - Games
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8794438
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Approximate dynamic programming platforms are employed to solve dynamic graphical games, where the agents interact among each other using communication graphs in order to achieve synchronization. Although the action dependent dual heuristic dynamic programming schemes provide fast solution platforms for several control problems, their capabilities degrade for systems with unknown or uncertain dynamical models. An online model-free adaptive learning solution based on action dependent dual heuristic dynamic programming is proposed to solve the dynamic graphical games. It employs distributed actor-critic neural networks to approximate the optimal value function and the associated model-free control strategy for each agent. This is done using a policy iteration process where it does not employ any extensive computational effort, as traditionally observed. The duality between the model-free coupled Bellman optimality equation and the underlying coupled Riccati equation is highlighted. This is followed by a graph simulation scenario to test the usefulness of the proposed policy iteration process.
ER  - 

TY  - CONF
TI  - Robust Area Coverage with Connectivity Maintenance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2202
EP  - 2208
AU  - L. Siligardi
AU  - J. Panerati
AU  - M. Kaufmann
AU  - M. Minelli
AU  - C. Ghedini
AU  - G. Beltrame
AU  - L. Sabattini
PY  - 2019
KW  - computational geometry
KW  - multi-robot systems
KW  - robust swarm connectivity
KW  - coverage task
KW  - Khepera IV robots
KW  - tri-objective control law
KW  - potential-based coverage
KW  - network connectivity
KW  - robust area coverage
KW  - connectivity maintenance
KW  - robotic swarm
KW  - control laws
KW  - swarm robotics
KW  - globally coordinated behavior
KW  - Voronoi tessellation
KW  - Robot kinematics
KW  - Robustness
KW  - Multi-robot systems
KW  - Maintenance engineering
KW  - Robot sensing systems
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793555
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot swarms herald the ability to solve complex tasks using a large collection of simple devices. However, engineering a robotic swarm is far from trivial, with a major hurdle being the definition of the control laws leading to the desired globally coordinated behavior. Communication is a key element for coordination and it is considered one of the current most important challenges for swarm robotics. In this paper, we study the problem of maintaining robust swarm connectivity while performing a coverage task based on the Voronoi tessellation of an area of interest. We implement our methodology in a team of eight Khepera IV robots. With the assumptions that robots have a limited sensing and communication range-and cannot rely on centralized processing-we propose a tri-objective control law that outperforms other simpler strategies (e.g. a potential-based coverage) in terms of network connectivity, robustness to failure, and area coverage.
ER  - 

TY  - CONF
TI  - Living with a Mobile Companion Robot in your Own Apartment - Final Implementation and Results of a 20-Weeks Field Study with 20 Seniors*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2253
EP  - 2259
AU  - H. Gross
AU  - A. Scheidig
AU  - S. Müller
AU  - B. Schütz
AU  - C. Fricke
AU  - S. Meyer
PY  - 2019
KW  - geriatrics
KW  - home automation
KW  - mobile robots
KW  - service robots
KW  - mobile companion robot
KW  - apartment
KW  - German research project SYMPARTNER
KW  - functional-emotional robot companion
KW  - mobile domestic robot companion
KW  - elderly people
KW  - developed robot
KW  - system architecture
KW  - essential skills
KW  - friendly home companion
KW  - long-term field study
KW  - robustness
KW  - domestic operating conditions
KW  - social scientific questions
KW  - autonomous companion robots
KW  - single-person households
KW  - senior households
KW  - time 20 week
KW  - Tactile sensors
KW  - Three-dimensional displays
KW  - Legged locomotion
KW  - Navigation
DO  - 10.1109/ICRA.2019.8793693
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the results of the German research project SYMPARTNER (4/2015 - 6/2018), which aimed at developing a functional-emotional, mobile domestic robot companion for elderly people. The paper gives an overview of the developed robot, its system architecture, and essential skills and behaviors required for being a friendly home companion. Based on this, in a long-term field study running from January to June 2018 both technical aspects regarding the practical suitability and robustness of the robot under domestic operating conditions and social scientific questions on usability and acceptance of the robot and the users' familiarization with their new housemate were evaluated. In the field study, two of these autonomous companion robots were used in 20 senior households in Erfurt (Germany). All participants lived with their robot in their apartments for one week without the need for supervising or supporting persons being present on-site. The tests in 20 single-person households in the age group 62 to 94 years (average 74 years) provided important insights into the special challenges of domesticity from a technical, social scientific, and user-oriented point of view. The results of the study show how seniors can shape their everyday life with a companion robot and how quickly they get used to the new housemate.
ER  - 

TY  - CONF
TI  - Enabling Identity-Aware Tracking via Fusion of Visual and Inertial Features
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2260
EP  - 2266
AU  - R. Y. Tsai
AU  - H. T. Ke
AU  - K. C. Lin
AU  - Y. Tseng
PY  - 2019
KW  - calibration
KW  - robot vision
KW  - sensor fusion
KW  - synchronisation
KW  - target tracking
KW  - robust PIT
KW  - data fusion technique
KW  - RGB-D camera
KW  - wearable inertial sensors
KW  - time synchronization
KW  - robotic platform
KW  - biological feature
KW  - recognition rate
KW  - visual features
KW  - inertial features
KW  - computer vision
KW  - robotic applications
KW  - RFID
KW  - environmental constraints
KW  - recognition accuracy
KW  - identity-aware tracking
KW  - Skeleton
KW  - Cameras
KW  - Robot sensing systems
KW  - Target tracking
KW  - Robot kinematics
KW  - Computer Vision
KW  - Data Fusion
KW  - IoT
KW  - Person Identification
KW  - Tracking
KW  - Robotics
KW  - Wearable Computing
DO  - 10.1109/ICRA.2019.8793839
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Person identification and tracking (PIT) is an essential issue in computer vision and robotic applications. It has long been studied and achieved by technologies such as RFID or face/fingerprint/iris recognition. These approaches, however, have their limitations due to environmental constraints (such as lighting and obstacles) or require close contact to specific devices. Therefore, their recognition accuracy highly depends on use scenarios. In this work, we propose RCU (Robot Catch yoU), an accompanyist robot system that provides follow-me or guide-me services. Such robots are capable of distinguishing users' profiles in front of them and keep tracking a specific target person. We study a more challenging scenario where the target person may be under occlusion from time to time. To enable robust PIT, we develop a data fusion technique that integrates two types of sensors, an RGB-D camera and wearable inertial sensors. Since the data generated by these sensors share common features, we are able to fuse them to achieve identity-aware tracking. Practical issues, such as time synchronization and coordinate calibration, are also addressed. We implement our design on a robotic platform and show that it can track a target person even when no biological feature is captured by the RGB-D camera. Our experimental evaluation shows a recognition rate of 95% and a following rate of 88%.
ER  - 

TY  - CONF
TI  - Inverse Reinforcement Learning of Interaction Dynamics from Demonstrations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2267
EP  - 2274
AU  - M. Hussein
AU  - M. Begum
AU  - M. Petrik
PY  - 2019
KW  - decision theory
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - inverse reinforcement learning methods
KW  - high-level sequential tasks
KW  - human demonstrations
KW  - POMDP policies
KW  - interaction dynamics
KW  - human-robot interaction domain
KW  - structured interactions
KW  - partially observable Markov decision process
KW  - learning from demonstration
KW  - IRL algorithms
KW  - reward function learning
KW  - MDPIRL algorithm
KW  - Robots
KW  - Task analysis
KW  - Education
KW  - Reinforcement learning
KW  - Uncertainty
KW  - Aircraft navigation
KW  - Human-robot interaction
DO  - 10.1109/ICRA.2019.8793867
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a framework to learn the reward function underlying high-level sequential tasks from demonstrations. The purpose of reward learning, in the context of learning from demonstration (LfD), is to generate policies that mimic the demonstrator's policies, thereby enabling imitation learning. We focus on a human-robot interaction (HRI) domain where the goal is to learn and model structured interactions between a human and a robot. Such interactions can be modeled as a partially observable Markov decision process (POMDP) where the partial observability is caused by uncertainties associated with the ways humans respond to different stimuli. The key challenge in finding a good policy in such a POMDP is determining the reward function that was observed by the demonstrator. Existing inverse reinforcement learning (IRL) methods for POMDPs are computationally very expensive and the problem is not well understood. In comparison, IRL algorithms for Markov decision process (MDP) are well defined and computationally efficient. We propose an approach of reward function learning for high-level sequential tasks from human demonstrations where the core idea is to reduce the underlying POMDP to an MDP and apply any efficient MDPIRL algorithm. Our extensive experiments suggest that the reward function learned this way generates POMDP policies that mimic the policies of the demonstrator well.
ER  - 

TY  - CONF
TI  - Investigating Design Elements of Companion Robots for Older Adults
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2275
EP  - 2281
AU  - Y. H. Oh
AU  - J. Kim
AU  - S. Jeong
AU  - a. Y. Ju
PY  - 2019
KW  - age issues
KW  - design engineering
KW  - health care
KW  - human-robot interaction
KW  - medical robotics
KW  - psychology
KW  - service robots
KW  - older adults
KW  - robot design elements
KW  - depression
KW  - physical preferences
KW  - psychological health
KW  - depressive symptoms
KW  - companion robots
KW  - Robots
KW  - Dogs
KW  - Analysis of variance
KW  - Pediatrics
KW  - Psychology
KW  - Synthetic fibers
KW  - Aging
DO  - 10.1109/ICRA.2019.8793583
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Older adults are vulnerable to symptoms of depression. The degree of depression is particularly high among older adults who live alone. To address this issue, various companion robots, which are capable of psychologically communicating with users, have been proposed. However, older adults' preferences on the appearance of these robots have not been systematically investigated; this forms the focus of the present study. We interviewed 191 older adults; investigated their preferences on the design elements of robots including type, weight, and material; and analyzed the data by age, gender, and living arrangement. Our primary goal was to determine how companion robots should be designed, paying special attention to older adults who live alone. Our findings indicated that those living alone prefer a bear-like robot and negative to the heavy robot. Our results suggest that companion robots need to be designed with careful consideration of older adults' physical and psychological preferences.
ER  - 

TY  - CONF
TI  - Development of Informative Path Planning for Inspection of the Hanford Tank Farm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2297
EP  - 2303
AU  - S. A. Zanlongo
AU  - L. Bobadilla
AU  - D. McDaniel
AU  - Y. T. Tan
PY  - 2019
KW  - inspection
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - rastering technique
KW  - high-level nuclear waste tanks
KW  - Hanford facility
KW  - robotic inspection
KW  - utility function
KW  - informative path planning
KW  - Hanford tank farm
KW  - structural monitoring
KW  - static sensor networks
KW  - predetermined locations
KW  - mobile robots
KW  - Bayesian optimization approach
KW  - Robot sensing systems
KW  - Kernel
KW  - Inspection
KW  - Temperature measurement
KW  - Gaussian processes
KW  - Welding
DO  - 10.1109/ICRA.2019.8794138
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Traditional environmental and structural monitoring often uses static sensor networks deployed at predetermined locations or mobile robots that use a rastering technique for area coverage. These methods rely on the operators making assumptions about the nature of the unknown field that is being measured and are often time-consuming for localizing an area of interest. Here, we aim to quickly localize possible leaks within high-level nuclear waste tanks at the Hanford facility. The structure of these tanks precludes most sensor network approaches and raises many issues with robotic inspection, such as navigation within highly constrained environments. This work uses a Bayesian Optimization approach for guiding a mobile robot's search strategy and implements a utility function that allows for prior knowledge of the structure to be incorporated when selecting future search locations. Compared to traditional exhaustive approaches, our method quickly reduces RMSE error and shortens the distance the robot must travel.
ER  - 

TY  - CONF
TI  - A Fuzzy Based Accessibility Model for Disaster Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2304
EP  - 2310
AU  - K. Balan
AU  - M. P. Manuel
AU  - M. Faied
AU  - M. Krishnan
AU  - M. Santora
PY  - 2019
KW  - angular velocity control
KW  - collision avoidance
KW  - disasters
KW  - fuzzy control
KW  - fuzzy reasoning
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - terrain accessibility index
KW  - robots position
KW  - angular velocities
KW  - VFH algorithm
KW  - disaster prone environment
KW  - FISVFH algorithm
KW  - fuzzy based accessibility model
KW  - disaster environment
KW  - autonomous maneuvering
KW  - robot estimate
KW  - two-output fuzzy inference system
KW  - sector accessibility index
KW  - fuzzy inference system vector field histogram method
KW  - obstacle distance
KW  - linear velocities
KW  - two-input fuzzy inference system
KW  - Indexes
KW  - Angular velocity
KW  - Fuzzy logic
KW  - Robot sensing systems
KW  - Histograms
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8793602
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots that perform autonomous maneuvering in a disaster environment usually dont have perfect understanding of the environment in advance. The robot is continuously evaluating the environment as it proceeds, deciding the optimal way to traverse the environment to get to the goal. A critical aspect of this decision is the robot estimate of the terrain accessibility index, which quantifies how easy it is to navigate through the immediate terrain. This paper represents a new method to calculate terrain accessibility index based on obstacle distance to the robots position. In addition, a Fuzzy Inference System Vector Field Histogram (FISVFH) method has been designed for automating the selection of the robots linear and angular velocities in the VFH (Vector Field Histogram) algorithm, based on the calculated sector accessibility index. The proposed method is a two-input and two-output Fuzzy Inference System, where the current robot heading, and sector accessibility index serve as the input, and the corresponding linear and angular velocities to the VFH algorithm are outputs. The VFH, VFH + and FISVFH are tested both in simulation and experimentation in 4 environments that are known to result in failures in VFH and VFH +, for comparison purposes. In addition, the algorithm was verified through experimental setup of a disaster prone environment. In both simulation and experimentation the results show that FISVFH outperforms VFH and VFH +. It is also shown that the FISVFH algorithm is capable of handling the disaster prone environment. Overall, the FISVFH algorithm enables the robot to get to the goal faster and also produces a smoother path while doing so.
ER  - 

TY  - CONF
TI  - Learning to Predict the Wind for Safe Aerial Vehicle Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2311
EP  - 2317
AU  - F. Achermann
AU  - N. R. J. Lawrance
AU  - R. Ranftl
AU  - A. Dosovitskiy
AU  - J. J. Chung
AU  - R. Siegwart
PY  - 2019
KW  - autonomous aerial vehicles
KW  - convolutional neural nets
KW  - mobile robots
KW  - path planning
KW  - sampling methods
KW  - wind
KW  - safe aerial vehicle planning
KW  - local wind
KW  - unmanned aerial vehicles
KW  - wind environment
KW  - relatively low mass
KW  - high-resolution wind fields
KW  - terrain elevation model
KW  - deep convolutional neural network
KW  - sampling-based planner
KW  - strong wind scenarios
KW  - UAV
KW  - inflow conditions
KW  - prediction error
KW  - wind estimation techniques
KW  - Wind forecasting
KW  - Planning
KW  - Computational modeling
KW  - Wind speed
KW  - Predictive models
KW  - Data models
DO  - 10.1109/ICRA.2019.8793547
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Obtaining an accurate estimate of the local wind remains a significant challenge for small unmanned aerial vehicles (UAVs). Small UAVs often operate at low altitudes near terrain, where the wind environment can be more complex than at higher altitudes. Combined with their relatively low mass, this makes small UAVs particularly susceptible to wind. In this paper we present an approach for predicting high-resolution wind fields based on a terrain elevation model and known inflow conditions. Our approach uses a deep convolutional neural network (CNN) to generate 3D wind estimates. We show that our approach produces wind estimates with lower prediction error than existing methods, and that inference can be performed on an on-board computer in less than two seconds. By providing the wind estimate to a sampling-based planner we show that the improved estimates allow the planner to generate safer paths in strong wind scenarios than with alternative wind estimation techniques.
ER  - 

TY  - CONF
TI  - Distributed Radiation Field Estimation and Informative Path Planning for Nuclear Environment Characterization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2318
EP  - 2324
AU  - F. Mascarich
AU  - C. Papachristos
AU  - T. Wilson
AU  - K. Alexis
PY  - 2019
KW  - Global Positioning System
KW  - mobile robots
KW  - optical radar
KW  - path planning
KW  - photomultipliers
KW  - scintillation counters
KW  - solid scintillation detectors
KW  - thallium
KW  - distributed radiation field estimation
KW  - informative path planning
KW  - nuclear environment characterization
KW  - autonomous estimation
KW  - distributed nuclear radiation fields
KW  - GPS-denied environments
KW  - sensing apparatus
KW  - radially placed Thallium-doped Cesium Iodide
KW  - Silicon Photomultipliers
KW  - pulse counting circuitry
KW  - provided readings
KW  - LiDAR-based localization
KW  - radiation intensity readings
KW  - immediate field gradient
KW  - believed field intensity
KW  - local measurement
KW  - field gradient co-estimation
KW  - informative data gathering
KW  - path planning strategy
KW  - uncertainty
KW  - admissible paths
KW  - autonomous exploration
KW  - SiPm
KW  - Estimation
KW  - Detectors
KW  - Robot sensing systems
KW  - Path planning
KW  - Uncertainty
KW  - Area measurement
DO  - 10.1109/ICRA.2019.8794402
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper details the system and methods designed to enable the autonomous estimation of distributed nuclear radiation fields within complex and possibly GPS-denied environments. A sensing apparatus consisting of three radially placed Thallium-doped Cesium Iodide (CsI(Tl)) scintillators and Silicon Photomultipliers (SiPm) combined with custom- built pulse counting circuitry is designed and the provided readings are pose-annotated using LiDAR-based localization. Given this capacity, a method that utilizes the radiation intensity readings to first calculate the immediate field gradient and then combine this information to update and co-estimate the believed field intensity and gradient across the whole environment is developed. The strategy propagates the effect of each local measurement through field gradient co-estimation and simultaneously derives a model of the underlying uncertainty. To further support the need for informative data gathering, especially in the framework of emergency and rapid reconnaissance missions, a path planning strategy is also developed that first utilizes the field intensity and uncertainty estimates to select its new waypoint and then performs terrain traversability analysis to derive admissible paths. The complete system is evaluated both in simulation and experimentally. The experimental results refer to the autonomous exploration and field estimation inside an indoor facility within which actual radioactive uranium and thorium ore sources have been distributed.
ER  - 

TY  - CONF
TI  - Visual recognition in the wild by sampling deep similarity functions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2341
EP  - 2347
AU  - M. Usvyatsov
AU  - K. Schindler
PY  - 2019
KW  - convolutional neural nets
KW  - image representation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - pattern classification
KW  - probability
KW  - probabilities
KW  - class variability
KW  - images range
KW  - training exemplars
KW  - relative similarities
KW  - class predictions
KW  - class labels
KW  - CNN
KW  - test data
KW  - training data
KW  - recognition system
KW  - target class
KW  - deep convolutional neural networks
KW  - supervised machine learning
KW  - autonomous robot
KW  - deep similarity functions
KW  - visual recognition
KW  - Training
KW  - Computer aided instruction
KW  - Visualization
KW  - Robots
KW  - Neural networks
KW  - Labeling
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794162
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recognising relevant objects or object states in its environment is a basic capability for an autonomous robot. The dominant approach to object recognition in images and range images is classification by supervised machine learning, nowadays mostly with deep convolutional neural networks (CNNs). This works well for target classes whose variability can be completely covered with training examples. However, a robot moving in the wild, i.e., in an environment that is not known at the time the recognition system is trained, will often face domain shift: the training data cannot be assumed to exhaustively cover all the within-class variability that will be encountered in the test data. In that situation, learning is in principle possible, since the training set does capture the defining properties, respectively dissimilarities, of the target classes. But directly training a CNN to predict class probabilities is prone to overfitting to irrelevant correlations between the class labels and the specific subset of the target class that is represented in the training set. We explore the idea to instead learn a Siamese CNN that acts as similarity function between pairs of training examples. Class predictions are then obtained by measuring the similarities between a new test instance and the training samples. We show that the CNN embedding correctly recovers the relative similarities to arbitrary class exemplars in the training set. And that therefore few, randomly picked training exemplars are sufficient to achieve good predictions, making the procedure efficient.
ER  - 

TY  - CONF
TI  - Evaluating Merging Strategies for Sampling-based Uncertainty Techniques in Object Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2348
EP  - 2354
AU  - D. Miller
AU  - F. Dayoub
AU  - M. Milford
AU  - N. Sünderhauf
PY  - 2019
KW  - merging
KW  - neural nets
KW  - object detection
KW  - pattern clustering
KW  - sampling methods
KW  - statistical analysis
KW  - merging strategies
KW  - sampling-based uncertainty techniques
KW  - epistemic uncertainty
KW  - deep neural networks
KW  - affinity-clustering combination
KW  - spatial uncertainty estimation
KW  - object detection
KW  - Uncertainty
KW  - Object detection
KW  - Detectors
KW  - Clustering methods
KW  - Semantics
KW  - Measurement uncertainty
KW  - Robots
DO  - 10.1109/ICRA.2019.8793821
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There has been a recent emergence of sampling-based techniques for estimating epistemic uncertainty in deep neural networks. While these methods can be applied to classification or semantic segmentation tasks by simply averaging samples, this is not the case for object detection, where detection sample bounding boxes must be accurately associated and merged. A weak merging strategy can significantly degrade the performance of the detector and yield an unreliable uncertainty measure. This paper provides the first in-depth investigation of the effect of different association and merging strategies. We compare different combinations of three spatial and two semantic affinity measures with four clustering methods for MC Dropout with a Single Shot Multi-Box Detector. Our results show that the correct choice of affinity-clustering combination can greatly improve the effectiveness of the classification and spatial uncertainty estimation and the resulting object detection performance. We base our evaluation on a new mix of datasets that emulate near open-set conditions (semantically similar unknown classes), distant open-set conditions (semantically dissimilar unknown classes) and the common closed-set conditions (only known classes).
ER  - 

TY  - CONF
TI  - Training a Binary Weight Object Detector by Knowledge Transfer for Autonomous Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2379
EP  - 2384
AU  - J. Xu
AU  - Y. Nie
AU  - P. Wang
AU  - A. M. López
PY  - 2019
KW  - computer vision
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - object detection
KW  - road traffic
KW  - traffic engineering computing
KW  - binary weight object detector
KW  - autonomous driving
KW  - energy efficiency
KW  - on-board object detection
KW  - object detectors
KW  - low-precision neural networks
KW  - computation requirements
KW  - memory footprint
KW  - binary weight neural networks
KW  - BWNs
KW  - knowledge transfer method
KW  - full-precision teacher network
KW  - MobileNet-based binary weight YOLOv2 detectors
KW  - pedestrian
KW  - cyclist detection
KW  - KITTI benchmark
KW  - MobileNet-YOLO
KW  - DarkNet-YOLO
KW  - deep convolutional neural network
KW  - word length 1.0 bit
KW  - memory size 8.8 MByte to 257.0 MByte
KW  - memory size 7.9 MByte to 193.0 MByte
KW  - Training
KW  - Detectors
KW  - Neural networks
KW  - Quantization (signal)
KW  - Knowledge transfer
KW  - Task analysis
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2019.8793743
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous driving has harsh requirements of small model size and energy efficiency, in order to enable the embedded system to achieve real-time on-board object detection. Recent deep convolutional neural network based object detectors have achieved state-of-the-art accuracy. However, such models are trained with numerous parameters and their high computational costs and large storage prohibit the deployment to memory and computation resource limited systems. Low-precision neural networks are popular techniques for reducing the computation requirements and memory footprint. Among them, binary weight neural networks (BWNs) are the extreme case which quantizes the float-point into just 1 bit. BWNs are difficult to train and suffer from accuracy deprecation due to the extreme low-bit representation. To address this problem, we propose a knowledge transfer (KT) method to aid the training of BWN using a full-precision teacher network. We built DarkNet- and MobileNet-based binary weight YOLOv2 detectors and conduct experiments on KITTI benchmark for car, pedestrian and cyclist detection. The experimental results show that the proposed method maintains high detection accuracy while reducing the model size of DarkNet-YOLO from 257 MB to 8.8 MB and MobileNet-YOLO from 193 MB to 7.9 MB.
ER  - 

TY  - CONF
TI  - Visual SLAM: Why Bundle Adjust?
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2385
EP  - 2391
AU  - Á. P. Bustos
AU  - T. Chin
AU  - A. Eriksson
AU  - I. Reid
PY  - 2019
KW  - cameras
KW  - feature extraction
KW  - image sequences
KW  - motion estimation
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - video signal processing
KW  - bundle adjustment
KW  - feature-based monocular SLAM
KW  - camera orientation optimisation
KW  - camera position estimation
KW  - quasiconvex formulation
KW  - keyframe rate
KW  - SLAM optimisation
KW  - rotational motion
KW  - slow motion
KW  - SLAM algorithm
KW  - 3D structure estimation
KW  - input feature tracks
KW  - 3D point cloud
KW  - 3D map estimation
KW  - 6DOF camera trajectory estimation
KW  - visual SLAM
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Estimation
KW  - Bundle adjustment
KW  - Optimization
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793749
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Bundle adjustment plays a vital role in feature-based monocular SLAM. In many modern SLAM pipelines, bundle adjustment is performed to estimate the 6DOF camera trajectory and 3D map (3D point cloud) from the input feature tracks. However, two fundamental weaknesses plague SLAM systems based on bundle adjustment. First, the need to carefully initialise bundle adjustment means that all variables, in particular the map, must be estimated as accurately as possible and maintained over time, which makes the overall algorithm cumbersome. Second, since estimating the 3D structure (which requires sufficient baseline) is inherent in bundle adjustment, the SLAM algorithm will encounter difficulties during periods of slow motion or pure rotational motion. We propose a different SLAM optimisation core: instead of bundle adjustment, we conduct rotation averaging to incrementally optimise only camera orientations. Given the orientations, we estimate the camera positions and 3D points via a quasi-convex formulation that can be solved efficiently and globally optimally. Our approach not only obviates the need to estimate and maintain the positions and 3D map at keyframe rate (which enables simpler SLAM systems), it is also more capable of handling slow motions or pure rotational motions.
ER  - 

TY  - CONF
TI  - Illumination Robust Monocular Direct Visual Odometry for Outdoor Environment Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2392
EP  - 2398
AU  - X. Wu
AU  - C. Pradalier
PY  - 2019
KW  - distance measurement
KW  - image colour analysis
KW  - lighting
KW  - mobile robots
KW  - motion estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - illumination-robust direct monocular SLAM system
KW  - global lighting changes
KW  - local lighting changes
KW  - stereo SLAM systems
KW  - camera motion
KW  - scene structure
KW  - high-precision motion estimation
KW  - illumination robust monocular direct visual odometry
KW  - outdoor environment
KW  - illumination invariant photometric costs
KW  - vision-based localization and mapping
KW  - RGB-D
KW  - DSO system
KW  - ORBSLAM2 system
KW  - Lighting
KW  - Optimization
KW  - Robustness
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Motion estimation
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793607
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Vision-based localization and mapping in outdoor environments is still a challenging issue, which requests significant robustness against various unpredictable illumination changes. In this paper, an illumination-robust direct monocular SLAM system that focuses on modeling outdoor scenery is presented. To deal with global and local lighting changes, such as solar flares, the state-of-art illumination invariant photometric costs for RGB-D and stereo SLAM systems are revisited in the context of their monocular counterpart, where the camera motion and scene structure are jointly optimized with a reasonably poor initialization. Based on our analysis, a combined cost is proposed to achieve a high-precision motion estimation with an improved convergence radius. The proposed system is extensively evaluated on the synthetic and real-world datasets regarding accuracy, robustness, and processing time, where our approach outperforms systems with other costs and state-of-art DSO and ORBSLAM2 systems.
ER  - 

TY  - CONF
TI  - A Comparison of CNN-Based and Hand-Crafted Keypoint Descriptors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2399
EP  - 2404
AU  - Z. Dai
AU  - X. Huang
AU  - W. Chen
AU  - L. He
AU  - H. Zhang
PY  - 2019
KW  - convolutional neural nets
KW  - image matching
KW  - neurocontrollers
KW  - robot vision
KW  - SLAM (robots)
KW  - pre-trained CNN descriptors
KW  - viewpoint changes
KW  - illumination changes
KW  - hand-crafted keypoint descriptors
KW  - keypoint matching
KW  - computer vision
KW  - keypoint description
KW  - trained convolutional neural networks
KW  - pre-trained CNNs
KW  - hand-crafted descriptors
KW  - visual simultaneous localization and mapping
KW  - CNN-based descriptors
KW  - SLAM
KW  - Lighting
KW  - Computational modeling
KW  - Detectors
KW  - Dogs
KW  - Simultaneous localization and mapping
KW  - Measurement
DO  - 10.1109/ICRA.2019.8793701
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Keypoint matching is an important operation in computer vision and its applications such as visual simultaneous localization and mapping (SLAM) in robotics. This matching operation heavily depends on the descriptors of the keypoints, and it must be performed reliably when images undergo condition changes such as those in illumination and viewpoint. Previous research in keypoint description has pursued three classes of descriptors: hand-crafted, those from trained convolutional neural networks (CNN), and those from pre-trained CNNs. This paper provides a comparative study of the three classes of keypoint descriptors, in terms of their ability to handle conditional changes. The study is conducted on the latest benchmark datasets in computer vision with challenging conditional changes. Our study finds that (a) in general CNN-based descriptors outperform hand-crafted descriptors, (b) the trained CNN descriptors perform better than pre-trained CNN descriptors with respect to viewpoint changes, and (c) pre-trained CNN descriptors perform better than trained CNN descriptors with respect to illumination changes. These findings can serve as a basis for selecting appropriate keypoint descriptors for various applications.
ER  - 

TY  - CONF
TI  - Environment Driven Underwater Camera-IMU Calibration for Monocular Visual-Inertial SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2405
EP  - 2411
AU  - C. Gu
AU  - Y. Cong
AU  - G. Sun
PY  - 2019
KW  - autonomous underwater vehicles
KW  - calibration
KW  - cameras
KW  - inertial navigation
KW  - mobile robots
KW  - SLAM (robots)
KW  - visual-inertial SLAM
KW  - shallow water
KW  - calibration errors
KW  - environmental indexes
KW  - underwater camera-inertial measurement unit
KW  - simultaneous localization and mapping
KW  - intrinsic parameters
KW  - extrinsic parameters
KW  - underwater monocular vision systems
KW  - environment driven underwater camera-IMU calibration
KW  - Cameras
KW  - Calibration
KW  - Atmospheric modeling
KW  - Simultaneous localization and mapping
KW  - Geometry
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793577
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Most state-of-the-art underwater vision systems are calibrated manually in shallow water and used in open seas without changing. However, the refractivity of the water is adaptively changed depending on the salinity, temperature, depth or other underwater environmental indexes, which inevitably generate the calibration errors and induces incorrectness e.g., for underwater Simultaneously Localization and Mapping (SLAM). To address this issue, in this paper, we propose a new underwater Camera-Inertial Measurement Unit (IMU) calibration model, which just needs to be calibrated once in the air, and then both the intrinsic parameters and extrinsic parameters between the camera and IMU could be automatically calculated depending on the environment indexes. To our best knowledge, this is the first work to consider the underwater Camera-IMU calibration via environmental indexes. We also build a verification platform to validate the effectiveness of our proposed method on real experiments, and use it for underwater monocular Visual-Inertial SLAM.
ER  - 

TY  - CONF
TI  - Leveraging Structural Regularity of Atlanta World for Monocular SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2412
EP  - 2418
AU  - H. Li
AU  - Y. Xing
AU  - J. Zhao
AU  - J. Bazin
AU  - Z. Liu
AU  - Y. Liu
PY  - 2019
KW  - Kalman filters
KW  - maximum likelihood estimation
KW  - polynomials
KW  - SLAM (robots)
KW  - multiple local Atlanta frames
KW  - global Atlanta frames
KW  - world frame
KW  - structural regularity
KW  - monocular SLAM
KW  - common vertical axis
KW  - multiple horizontal axes
KW  - camera frame
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Cameras
KW  - Estimation
KW  - Optimization
KW  - Reliability
DO  - 10.1109/ICRA.2019.8793716
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A wide range of man-made environments can be abstracted as the Atlanta world. It consists of a set of Atlanta frames with a common vertical (gravitational) axis and multiple horizontal axes orthogonal to this vertical axis. This paper focuses on leveraging the regularity of Atlanta world for monocular SLAM. First, we robustly cluster image lines. Based on these clusters, we compute the local Atlanta frames in the camera frame by solving polynomial equations. Our method provides the global optimum and satisfies inherent geometric constraints. Second, we define the posterior probabilities to refine the initial clusters and Atlanta frames alternately by the maximum a posteriori estimation. Third, based on multiple local Atlanta frames, we compute the global Atlanta frames in the world frame using Kalman filtering. We optimize rotations by the global alignment and then refine translations and 3D line-based map under the directional constraints. Experiments on both synthesized and real data have demonstrated that our approach outperforms state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Multimodal Semantic SLAM with Probabilistic Data Association
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2419
EP  - 2425
AU  - K. Doherty
AU  - D. Fourie
AU  - J. Leonard
PY  - 2019
KW  - image fusion
KW  - image representation
KW  - inference mechanisms
KW  - mobile robots
KW  - object detection
KW  - path planning
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - nonGaussian sensor model
KW  - multimodal semantic SLAM
KW  - probabilistic data association
KW  - robot navigation
KW  - semantic SLAM problem
KW  - discrete inference problem
KW  - object class labels
KW  - measurement-landmark correspondences
KW  - continuous inference problem
KW  - robot poses
KW  - object detection systems
KW  - simultaneous localization and mapping
KW  - object-based representations
KW  - object locations
KW  - nonGaussian inference problem
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Belief propagation
KW  - Maximum likelihood estimation
KW  - Maximum likelihood detection
DO  - 10.1109/ICRA.2019.8794244
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The recent success of object detection systems motivates object-based representations for robot navigation; i.e. semantic simultaneous localization and mapping (SLAM). The semantic SLAM problem can be decomposed into a discrete inference problem: determining object class labels and measurement-landmark correspondences (the data association problem), and a continuous inference problem: obtaining the set of robot poses and object locations in the environment. A solution to the semantic SLAM problem necessarily addresses this joint inference, but under ambiguous data associations this is in general a non-Gaussian inference problem, while the majority of previous work focuses on Gaussian inference. Previous solutions to data association either produce solutions between potential hypotheses or maintain multiple explicit hypotheses for each association. We propose a solution that represents hypotheses as multiple modes of an equivalent non-Gaussian sensor model. We then solve the resulting non-Gaussian inference problem using nonparametric belief propagation. We validate our approach in a simulated hallway environment under a variety of sensor noise characteristics, as well as using real data from the KITTI dataset, demonstrating improved robustness to perceptual aliasing and odometry uncertainty.
ER  - 

TY  - CONF
TI  - Improving Incremental Planning Performance through Overlapping Replanning and Execution
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2426
EP  - 2432
AU  - M. Orton
AU  - S. Dai
AU  - S. Schaffert
AU  - A. Hofmann
AU  - B. Williams
PY  - 2019
KW  - path planning
KW  - robots
KW  - trajectory control
KW  - integrated motion planning
KW  - Chekov
KW  - trajectory optimization problems
KW  - roadmap seed trajectories
KW  - motion planning algorithms
KW  - control information
KW  - incremental planning
KW  - Planning
KW  - Dynamics
KW  - Mobile robots
KW  - Trajectory optimization
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793642
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deployment of motion planning algorithms in practical applications has lagged due to their slow speed in reacting to disturbances. We believe that the best way to address this is to reuse learned planning and control information across queries. In previous work, we introduced Chekov, a reactive, integrated motion planning and execution system that reuses learned information in the form of an enhanced roadmap. We have previously shown how we can use Chekov to formulate trajectory optimization problems that result in superior performance in static environments. In this work, we show how incremental planning can be incorporated into the formulation of optimized trajectories from roadmap seed trajectories. Further, we show how an incremental planner can be adapted to reduce the overhead incurred for replanning when trajectories become invalid during execution.
ER  - 

TY  - CONF
TI  - Multimodal Policy Search using Overlapping Mixtures of Sparse Gaussian Process Prior
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2433
EP  - 2439
AU  - H. Sasaki
AU  - T. Matsubara
PY  - 2019
KW  - Bayes methods
KW  - Gaussian processes
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - search problems
KW  - OMSGPs
KW  - optimal policies
KW  - reinforcement learning
KW  - multimodal policy search algorithm
KW  - overlapping mixtures of sparse Gaussian process
KW  - Bayesian inference
KW  - object grasping
KW  - table-sweep tasks
KW  - Task analysis
KW  - Grasping
KW  - Kernel
KW  - Gaussian processes
KW  - Robots
KW  - Inference algorithms
KW  - Prediction algorithms
DO  - 10.1109/ICRA.2019.8794131
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a novel policy search reinforcement learning algorithm that can deal with multimodality in control policies based on Gaussian processes. Our approach employs Overlapping Mixtures of Gaussian Processes (OMGPs) for a control policy, in which all the GPs in the mixture are global and overlapped in the input space. We first extend the OMGPs by combing sparse pseudo-input GPs as OMSGPs to reduce its computational cost of learning and prediction suitable for policy search. Then, we derive a novel multimodal policy search algorithm based on variational Bayesian inference by placing the OMSGPs as the prior of the multimodal control policy. To validate the effectiveness of our algorithm, we applied it to two typical robotic tasks in simulation: 1) object grasping and 2) table-sweep tasks since they both require the multimodality in the optimal policies. Simulation results demonstrate that our algorithm can efficiently learn multimodal policies even with high dimensional observations.
ER  - 

TY  - CONF
TI  - Online adaptation of uncertain models using neural network priors and partially observable planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2440
EP  - 2446
AU  - A. Hayashi
AU  - D. Ruiken
AU  - C. Goerick
AU  - T. Hasegawa
PY  - 2019
KW  - Markov processes
KW  - mobile robots
KW  - neural nets
KW  - planning (artificial intelligence)
KW  - uncertain systems
KW  - online adaptation
KW  - uncertain models
KW  - neural network priors
KW  - partially observable planning
KW  - manipulation tasks
KW  - encode prior experiences
KW  - physics engine
KW  - online POMDP solver
KW  - observed environments
KW  - prediction model
KW  - domain complexity
KW  - Adaptation models
KW  - Task analysis
KW  - Physics
KW  - Planning
KW  - Robots
KW  - Engines
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793630
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - One of the key challenges in realizing a robot that is capable of completing a variety of manipulation tasks in the real world is the need to utilize sufficiently compact and rich world models. If the assumed prediction model does not match real observations, planning systems are unable to perform properly. We propose a system that corrects the models based on information collected from the robot's sensors. We encode prior experiences in a neural network to generate possible parameters of the models for a physics engine from real observations. An online POMDP solver is used to plan actions to complete the task while progressively validating and improving the models. We perform experiments in simulations and on a real robot. The results show that this approach appropriately clarifies observed environments, can handle dynamics with discontinuities, and with increasing domain complexity achieves a better success rate than baseline methods.
ER  - 

TY  - CONF
TI  - Contact-Implicit Trajectory Optimization Based on a Variable Smooth Contact Model and Successive Convexification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2447
EP  - 2453
AU  - A. Ö. Önol
AU  - P. Long
AU  - T. Padır
PY  - 2019
KW  - gradient methods
KW  - linear quadratic control
KW  - manipulators
KW  - mobile robots
KW  - optimisation
KW  - trajectory control
KW  - CITO
KW  - variable smooth contact model
KW  - VSCM
KW  - successive convexification
KW  - gradient-based optimization
KW  - nonprehensile manipulation tasks
KW  - iterative linear quadratic regulator
KW  - physically-consistent motions
KW  - SCvx-based method
KW  - iLQR-based method
KW  - contact-implicit trajectory optimization method
KW  - robot platform
KW  - Robots
KW  - Convergence
KW  - Trajectory optimization
KW  - Task analysis
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794250
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a contact-implicit trajectory optimization (CITO) method based on a variable smooth contact model (VSCM) and successive convexification (SCvx). The VSCM facilitates the convergence of gradient-based optimization without compromising physical fidelity. On the other hand, the proposed SCvx-based approach combines the advantages of direct and shooting methods for CITO. For evaluations, we consider non-prehensile manipulation tasks. The proposed method is compared to a version based on iterative linear quadratic regulator (iLQR) on a planar example. The results demonstrate that both methods can find physically-consistent motions that complete the tasks without a meaningful initial guess owing to the VSCM. The proposed SCvx-based method outperforms the iLQR-based method in terms of convergence, computation time, and the quality of motions found. Finally, the proposed SCvx-based method is tested on a standard robot platform and shown to perform efficiently for a real-world application.
ER  - 

TY  - CONF
TI  - Energy Gradient-Based Graphs for Planning Within-Hand Caging Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2462
EP  - 2467
AU  - W. G. Bircher
AU  - A. S. Morgan
AU  - K. Hang
AU  - A. M. Dollar
PY  - 2019
KW  - dexterous manipulators
KW  - gradient methods
KW  - graph theory
KW  - grippers
KW  - mobile robots
KW  - path planning
KW  - hand-object configurations
KW  - Yale T42 hand
KW  - stored energy profile
KW  - energy gradient-based graph
KW  - energy map
KW  - low energy states
KW  - actuation input
KW  - underactuated hands
KW  - caging grasps
KW  - within-hand caging manipulation
KW  - Actuators
KW  - Computational modeling
KW  - Grippers
KW  - Force
KW  - Planning
KW  - Energy states
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8794411
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we present a within-hand manipulation approach that leverages a simple energy model based on caging grasps made by underactuated hands. Instead of explicitly modeling the contacts and dynamics in manipulation, we can calculate a map to describe the energy states of different hand-object configurations under an actuation input. Since the system intrinsically steers towards low energy states, the object's movement is uniquely described by the gradient of the energy map if the corresponding actuation is applied. Such maps are pre-calculated for a range of actuation inputs to represent the system's energy profile. We discretize the workspace into a grid and construct an energy gradient-based graph by locally exploring the gradients of the stored energy profile. Given a goal configuration of a simple cylindrical object, a sequence of actuation inputs can be calculated to manipulate it towards the goal by exploiting the connectivity in the graph. The proposed approach is experimentally implemented on a Yale T42 hand. Our evaluation results show that parts of the graph are well connected, explaining our ability to successfully plan and execute trajectories within the gripper's workspace.
ER  - 

TY  - CONF
TI  - A new robot skating on water surface intimating water striders based on flexible driving mechanism*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2468
EP  - 2473
AU  - J. Yan
AU  - K. Yang
AU  - Y. Yang
AU  - J. Zhao
AU  - G. Liu
AU  - S. Tang
PY  - 2019
KW  - cantilevers
KW  - elasticity
KW  - hydrodynamics
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - water surface
KW  - flexible driven robot prototype
KW  - water strider robot
KW  - flexible driving legs
KW  - flexible driving robot
KW  - biological water striders
KW  - robot skating
KW  - flexible materials
KW  - ellipse-like spatial trajectories
KW  - pin-linkage mechanism
KW  - microelement cantilever method
KW  - similarity analysis
KW  - hydrodynamic characteristic constants
KW  - Legged locomotion
KW  - Strain
KW  - Force
KW  - Surface treatment
KW  - Trajectory
KW  - Ganglia
DO  - 10.1109/ICRA.2019.8793996
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The amazing ability of water striders on water surface has attracted many scholars. Especially the flexible driving mechanism enable the driving legs conform to the deformation of the water surface, which effectively improving water striders' floating ability and stability. However, the current research on water striders has never designed a flexible driven robot prototype like water striders. This paper proposes a new water strider robot that can walk on water surface based on flexible driving mechanism. The robot's driving legs are designed with flexible materials and possess ellipse-like spatial trajectories like water striders through a limit pin-linkage mechanism. Based on microelement cantilever method, the flexible driving effect was analyzed with different elastic modulus and diameter. It shows that the flexible legs can row at a higher frequency before puncturing the water surface and achieve bigger work in one period compared with the rigid one. At last, the skating experiment of the robot under different stiffness and rowing frequency was carried out. The results verified that the limit frequency of the flexible driving legs and maximum moving speed of the robot are about 41.3% and 36.2% higher than those with rigid legs, respectively. Moreover, a similarity analysis of hydrodynamic characteristic constants reveals that the locomotion of the flexible driving robot is more analogous to the biological water striders than the rigid one.
ER  - 

TY  - CONF
TI  - Performance Metrics for a Robotic Actuation System using Static and Mobile Electromagnets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2474
EP  - 2480
AU  - R. Chen
AU  - D. Folio
AU  - A. Ferreira
PY  - 2019
KW  - electromagnetic actuators
KW  - medical robotics
KW  - microrobots
KW  - surgery
KW  - telerobotics
KW  - robotic EMA platform
KW  - ophthalmic MIS
KW  - magnetic force
KW  - dexterity indexes
KW  - performance metrics
KW  - robotic actuation system
KW  - wireless magnetic microrobots
KW  - small-scale minimally invasive surgery
KW  - electromagnetic actuation system
KW  - reliable medical applications
KW  - Magnetic resonance imaging
KW  - Electromagnets
KW  - Robots
KW  - Micromagnetics
KW  - Electromagnetics
KW  - Coils
KW  - Torque
DO  - 10.1109/ICRA.2019.8794092
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Wireless magnetic microrobots can perform complex tasks for small-scale minimally invasive surgery (MIS) that requires high precision and dexterity. The choice of the configuration of the electromagnetic actuation (EMA) system is a key issue for reliable medical applications. This paper addresses the study of a robotic EMA platform firstly devoted to ophthalmic MIS, aiming at improving the manipulability and dexterity of the procedure. To this end, a robotic EMA system comprising four static and four mobile electromagnets is investigated. Evaluation of the magnetic force and torque, the manipulability and the dexterity indexes of EMA platforms are studied. The results demonstrate that a robotic EMA platform increases the versatility of the EMA system, and becomes resourceful to perform various tasks.
ER  - 

TY  - CONF
TI  - Yaw Torque Authority for a Flapping-Wing Micro-Aerial Vehicle
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2481
EP  - 2487
AU  - R. Steinmeyer
AU  - N. P. Hyun
AU  - E. F. Helbling
AU  - R. J. Wood
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - control nonlinearities
KW  - microrobots
KW  - mobile robots
KW  - piezoelectric actuators
KW  - torque
KW  - reliable torque
KW  - controllable yaw torque
KW  - yaw torque authority
KW  - flapping-wing microaerial vehicle
KW  - high-frequency wing
KW  - reliable yaw control authority
KW  - split-cycle flapping
KW  - flapping frequency
KW  - flapping signal
KW  - Torque
KW  - Actuators
KW  - Harmonic analysis
KW  - Force
KW  - Power harmonic filters
KW  - Shape
KW  - Resonant frequency
DO  - 10.1109/ICRA.2019.8793873
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Flapping-wing micro-aerial vehicles rely on subtle changes in the kinematics of high-frequency wing flapping to produce roll, pitch, and yaw torques. To generate yaw torque, the Harvard RoboBee changes the ratio of upstroke to downstroke speed (“split-cycling”) by applying a second harmonic to the fundamental flapping signal for each wing. However, since flapping typically occurs near resonance (for efficiency), these higher harmonics are filtered out by the transmission and actuator dynamics. Therefore, reliable yaw control authority has proven elusive. We propose a method to generate yaw torque sufficient for in-flight control by using split-cycle flapping in an “iso-lift” regime, to mitigate resonant filtering by decreasing the flapping frequency and increasing the drive voltage, which produces lift identical to typical flight conditions. We model the expected torque at iso-lift conditions and apply this method to the physical RoboBee, achieving reliable, controllable yaw torque. Finally, we demonstrate yaw control with a simple heading controller, achieving a step response with a time constant an order of magnitude faster than previous attempts.
ER  - 

TY  - CONF
TI  - Data-efficient Learning of Morphology and Controller for a Microrobot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2488
EP  - 2494
AU  - T. Liao
AU  - G. Wang
AU  - B. Yang
AU  - R. Lee
AU  - K. Pister
AU  - S. Levine
AU  - R. Calandra
PY  - 2019
KW  - Bayes methods
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - microrobots
KW  - optimisation
KW  - data-efficient learning
KW  - robot design
KW  - HPC-BBO
KW  - hierarchical Bayesian optimization process
KW  - morphology configurations
KW  - controller learning process
KW  - hardware validation
KW  - hardware configurations design
KW  - 6-legged microrobot
KW  - Morphology
KW  - Optimization
KW  - Robots
KW  - Bayes methods
KW  - Hardware
KW  - Process control
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793802
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot design is often a slow and difficult process requiring the iterative construction and testing of prototypes, with the goal of sequentially optimizing the design. For most robots, this process is further complicated by the need, when validating the capabilities of the hardware to solve the desired task, to already have an appropriate controller, which is in turn designed and tuned for the specific hardware. In this paper, we propose a novel approach, HPC-BBO, to efficiently and automatically design hardware configurations, and evaluate them by also automatically tuning the corresponding controller. HPC-BBO is based on a hierarchical Bayesian optimization process which iteratively optimizes morphology configurations (based on the performance of the previous designs during the controller learning process) and subsequently learns the corresponding controllers (exploiting the knowledge collected from optimizing for previous morphologies). Moreover, HPC-BBO can select a “batch” of multiple morphology designs at once, thus parallelizing hardware validation and reducing the number of time-consuming production cycles. We validate HPC-BBO on the design of the morphology and controller for a simulated 6-legged microrobot. Experimental results show that HPC-BBO outperforms multiple competitive baselines, and yields a 360% reduction in production cycles over standard Bayesian optimization, thus reducing the hypothetical manufacturing time of our microrobot from 21 to 4 months.
ER  - 

TY  - CONF
TI  - Retrieval of magnetic medical microrobots from the bloodstream
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2495
EP  - 2501
AU  - V. Iacovacci
AU  - L. Ricotti
AU  - G. Signore
AU  - F. Vistoli
AU  - E. Sinibaldi
AU  - A. Menciassi
PY  - 2019
KW  - catheters
KW  - magnetic particles
KW  - medical robotics
KW  - microrobots
KW  - patient treatment
KW  - magnetoresponsive agents
KW  - capture efficiency
KW  - magnetic particles
KW  - human body
KW  - untethered magnetic microrobots
KW  - magnetic medical microrobots
KW  - body compartments
KW  - retrieval catheter
KW  - magnetic cores
KW  - retrieval tools
KW  - magnetic capture model
KW  - bloodstream
KW  - clinical translation
KW  - body fluids
KW  - magnetic microrobots retrieval
KW  - magnetoresponsive microrobots
KW  - Magnetic separation
KW  - Magnetic confinement
KW  - Saturation magnetization
KW  - Catheters
KW  - Magnetic cores
KW  - Micromagnetics
DO  - 10.1109/ICRA.2019.8794322
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Untethered magnetic microrobots hold the potential to penetrate hard-to-reach areas of the human body and to perform therapy in a controlled way. In the past decade, impressive advancements have been made in this field but the clinical adoption of magnetoresponsive microrobots is still hampered by safety issues. A tool appointed for magnetic microrobots retrieval within body fluids could enable a real paradigm change, fostering their clinical translation.By starting from the general problem to retrieve magnetic microrobots injected into the bloodstream, the authors introduce a magnetic capture model that allows to design retrieval tools for magnetic cores of different diameters (down to 10 nm) and in different environmental conditions (fluid speed up to 7 cms-1). The model robustness is demonstrated by the design and testing of a retrieval catheter. In its optimal configuration, the catheter includes 27 magnets and fits a 12 F catheter. The model provides a good prediction of capture efficiency for 250 nm magnetic particles (experimental data: 77.6%, model prediction: 65%) and a very good prediction for 500 nm particles (experimental data: 93.6%, model prediction: 94%). The results support the proposed model-based design approach, which can be extended to retrieve other magnetoresponsive agents from body compartments.
ER  - 

TY  - CONF
TI  - Experiments with Human-inspired Behaviors in a Humanoid Robot: Quasi-static Balancing using Toe-off Motion and Stretched Knees
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2510
EP  - 2516
AU  - B. Henze
AU  - M. A. Roa
AU  - A. Werner
AU  - A. Dietrich
AU  - C. Ott
AU  - A. Albu-Schäffer
PY  - 2019
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - human-inspired behaviors
KW  - toe-off motion
KW  - stretched knees
KW  - locomotion patterns
KW  - flat foot-ground contact
KW  - human gait
KW  - physiological mechanisms
KW  - TORO DLR humanoid robot
KW  - quasistatic whole-body balancing
KW  - kinematic capabilities
KW  - quasistatic whole-body balancing controller
KW  - Task analysis
KW  - Knee
KW  - Humanoid robots
KW  - Legged locomotion
KW  - Null space
KW  - End effectors
DO  - 10.1109/ICRA.2019.8794096
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humanoid robots typically display locomotion patterns that include walking with flat foot-ground contact, and knees slightly bent. However, analysis of human gait indicate that several physiological mechanisms like stretched knees, heel-strike and toe push-off increase the step length and energetic efficiency of locomotion. This paper presents an implementation of two of those mechanisms, namely stretched knees and push-off, on a quasi-static whole-body balancing controller. The influence of such mechanisms on the kinematic capabilities of the DLR humanoid robot TORO is analyzed in different experiments, and their benefits are thoroughly discussed. As a result, the energetic savings of balancing with stretched knees are shown to be of reduced magnitude with respect to the overall power consumption of the robot, and the ability of TORO for negotiating stairs is greatly enhanced.
ER  - 

TY  - CONF
TI  - Prediction Maps for Real-Time 3D Footstep Planning in Dynamic Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2517
EP  - 2523
AU  - P. Karkowski
AU  - M. Bennewitz
PY  - 2019
KW  - collision avoidance
KW  - humanoid robots
KW  - mobile robots
KW  - robot vision
KW  - humanoids
KW  - smaller wheeled robots
KW  - planar regions
KW  - simple 2D occupancy map
KW  - environment representation
KW  - height information
KW  - prediction maps
KW  - real-time 3D footstep planning
KW  - mobile robots
KW  - dynamic obstacle detection
KW  - time 10.0 ms
KW  - Three-dimensional displays
KW  - Tracking
KW  - Real-time systems
KW  - Mobile robots
KW  - Task analysis
KW  - Humanoid robots
DO  - 10.1109/ICRA.2019.8793999
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments. Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions. For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information. Considering dynamic obstacles introduces another level of complexity, since they can lead to necessary replanning or collisions at later stages. In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be efficiently planned in real time at low CPU cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.
ER  - 

TY  - CONF
TI  - See and Be Seen – Rapid and Likeable High-Definition Camera-Eye for Anthropomorphic Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2524
EP  - 2530
AU  - S. Schulz
AU  - S. M. z. Borgsen
AU  - S. Wachsmuth
PY  - 2019
KW  - cameras
KW  - eye
KW  - humanoid robots
KW  - human-robot interaction
KW  - interactive systems
KW  - mobile robots
KW  - robot vision
KW  - integrated high resolution camera
KW  - robot eye
KW  - human eye movements
KW  - high-definition camera-eye
KW  - anthropomorphic robots
KW  - social robots
KW  - robotic faces
KW  - anthropomorphic face
KW  - anthropomorphic robot head Floka
KW  - Cameras
KW  - Robot vision systems
KW  - Eyelids
KW  - Prototypes
KW  - Acceleration
KW  - Humanoid robots
DO  - 10.1109/ICRA.2019.8794319
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While many social robots already include carefully designed robotic faces, functional robot eyes that meet human expectations are still an open challenge. As a consequence, many robots either have cameras separated from their robot eyes or active camera heads missing an anthropomorphic face. In this paper, we propose a new robot eye that is integrated in the anthropomorphic robot head Floka and fulfills a similar technical specification as a human eye including zero backlash, an increased range of motion, high velocities and accelerations, an integrated high resolution camera, and fast actuated eyelids. The robot eye is built using state-of-the-art off-the-shelf components and the CAD model of our prototype is available free of charge on request for non-commercial applications. We evaluate the technical properties of the robot eye and show that it meets and partially outperforms human eye movements and saccades.
ER  - 

TY  - CONF
TI  - Generalized Orientation Learning in Robot Task Space
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2531
EP  - 2537
AU  - Y. Huang
AU  - F. J. Abu-Dakka
AU  - J. Silvério
AU  - D. G. Caldwell
PY  - 2019
KW  - control engineering computing
KW  - end effectors
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - generalized orientation learning
KW  - robot task space
KW  - imitation learning
KW  - human skills
KW  - joint space
KW  - end-effector orientation
KW  - arbitrary desired points
KW  - adapting learned orientation skills
KW  - angular velocity
KW  - learning Cartesian positions suffices
KW  - learning multiple orientation trajectories
KW  - kernelized treatment
KW  - dynamic movement primitives
KW  - Quaternions
KW  - Trajectory
KW  - Probabilistic logic
KW  - Task analysis
KW  - Robots
KW  - Angular velocity
KW  - Transforms
DO  - 10.1109/ICRA.2019.8793540
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In the context of imitation learning, several approaches have been developed so as to transfer human skills to robots, with demonstrations often represented in Cartesian or joint space. While learning Cartesian positions suffices for many applications, the end-effector orientation is required in many others. However, several crucial issues arising from learning orientations have not been adequately addressed yet. For instance, how can demonstrated orientations be adapted to pass through arbitrary desired points that comprise orientations and angular velocities? In this paper, we propose an approach that is capable of learning multiple orientation trajectories and adapting learned orientation skills to new situations (e.g., via-point and end-point), where both orientation and angular velocity are addressed. Specifically, we introduce a kernelized treatment to alleviate explicit basis functions when learning orientations. Several examples including comparison with the state-of-the-art dynamic movement primitives are provided to verify the effectiveness of our method.
ER  - 

TY  - CONF
TI  - ATLAS FaST: Fast and Simple Scheduled TDOA for Reliable Ultra-Wideband Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2554
EP  - 2560
AU  - J. Tiemann
AU  - Y. Elmasry
AU  - L. Koring
AU  - C. Wietfeld
PY  - 2019
KW  - direction-of-arrival estimation
KW  - mobile robots
KW  - operating systems (computers)
KW  - public domain software
KW  - time-of-arrival estimation
KW  - ATLAS FaST
KW  - fast scheduled TDOA
KW  - simple scheduled TDOA
KW  - ultra-wideband localization
KW  - wireless localization
KW  - aerial robot control
KW  - high precision personal safety tracking
KW  - required localization systems
KW  - multiuser scalability
KW  - energy efficiency
KW  - real-time capabilities
KW  - real-time localization
KW  - robot operating system
KW  - open source access
KW  - precise robotic location estimation
KW  - scheduled time-difference of arrival channel access
KW  - Synchronization
KW  - Clocks
KW  - Mobile nodes
KW  - Reliability
KW  - Wireless communication
KW  - Batteries
DO  - 10.1109/ICRA.2019.8793737
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ever increasing need for precise location estimation in robotics is challenging a significant amount of research. Hence, new applications such as wireless localization based aerial robot control or high precision personal safety tracking are developed. However, most of the current developments and research solely focus on the accuracy of the required localization systems. Multi-user scalability, energy efficiency and real-time capabilities are often neglected. This work aims to overcome the technology barrier by providing scalable, high accuracy, real-time localization through energy-efficient, scheduled time-difference of arrival channel access. We could show that simultaneous processing and provisioning of more than a thousand localization results per second with high reliability is possible using the proposed approach. To enable wide-spread adoption, we provide an open source implementation of our system for the robot operating system (ROS). Furthermore, we provide open source access to the raw data created during our evaluation.
ER  - 

TY  - CONF
TI  - HD Map Change Detection with a Boosted Particle Filter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2561
EP  - 2567
AU  - D. Pannen
AU  - M. Liebner
AU  - W. Burgard
PY  - 2019
KW  - image classification
KW  - learning (artificial intelligence)
KW  - object detection
KW  - particle filtering (numerical methods)
KW  - probability
KW  - road vehicles
KW  - traffic engineering computing
KW  - automated driving
KW  - landmark readings
KW  - probability distribution
KW  - HD map change detection
KW  - boosted particle filter
KW  - change detection algorithm
KW  - backend-based stream processing pipeline
KW  - floating car data
KW  - series-production vehicles
KW  - automotive high definition digital map
KW  - crowd-based approach
KW  - Roads
KW  - Global navigation satellite system
KW  - Measurement
KW  - Visualization
KW  - Automobiles
KW  - Robot sensing systems
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8794329
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a change detection algorithm that can run in real time as part of a backend-based stream processing pipeline. It can process the floating car data collected by series-production vehicles to detect changes in an automotive high definition digital (HD) map used for automated driving. The algorithm uses a particle filter approach with odometry, GNSS and landmark readings to localize the vehicle within the digital map. While all particles together represent the probability distribution for the vehicle's position at a given time, each individual particle also serves as a hypothesis about the vehicle's position. This is used to compute various metrics for how well the current sensor readings match the world model encoded in the HD map. The different metrics are evaluated by a number of weak classifiers that are used as input for a trained Adaboost classifier. The achievable detection rate of a single vehicle is then compared to that of a simple crowd-based approach, where each vehicle votes on whether or not the current section of the road has changed.
ER  - 

TY  - CONF
TI  - Non-parametric Error Modeling for Ultra-wideband Localization Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2568
EP  - 2574
AU  - A. Haggenmiller
AU  - M. Krogius
AU  - E. Olson
PY  - 2019
KW  - optimisation
KW  - probability
KW  - ultra wideband antennas
KW  - wireless sensor networks
KW  - antenna delays
KW  - line-of-sight conditions
KW  - nonline-of-sight conditions
KW  - nonparametric error modeling
KW  - ultra-wideband localization networks
KW  - nonparametric estimation
KW  - measurement probability densities
KW  - explicit modeling
KW  - multimodal errors
KW  - linear estimation methods
KW  - size 3.0 cm
KW  - size 30.0 cm
KW  - Antenna measurements
KW  - Delays
KW  - Probability density function
KW  - Antennas
KW  - Optimization
KW  - Density measurement
KW  - Hardware
DO  - 10.1109/ICRA.2019.8794291
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose an ultra-wideband-based (UWB) localization system that achieves high accuracy through nonparametric estimation of measurement probability densities and explicit modeling of antenna delays. This problem is difficult because non-line-of-sight conditions give rise to multimodal errors, which make linear estimation methods ineffective. The primary contribution in this paper is an approach for both characterizing these errors in situ and an optimization framework that recovers both positions and antenna delays. We evaluate our system with a network of 8 nodes based on the DecaWave DWM1000 and achieve accuracies from 3 cm RMSE in line-of-sight conditions to 30 cm RMSE in non-line-of-sight conditions. Collecting measurements and localizing the network in this manner requires less than a minute, after which the realized network may be used for dynamic real-time tracking.
ER  - 

TY  - CONF
TI  - Self-Supervised Incremental Learning for Sound Source Localization in Complex Indoor Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2599
EP  - 2605
AU  - H. Liu
AU  - Z. Zhang
AU  - Y. Zhu
AU  - S. Zhu
PY  - 2019
KW  - direction-of-arrival estimation
KW  - geometry
KW  - indoor environment
KW  - learning (artificial intelligence)
KW  - microphone arrays
KW  - mobile robots
KW  - geometry features
KW  - self-supervision process
KW  - ground truth label
KW  - pre-collected data
KW  - human supervisions
KW  - explicit GCC-PHAT features
KW  - supervised incremental learning
KW  - sound source localization
KW  - complex indoor environment
KW  - incremental learning framework
KW  - mobile robots
KW  - human sound source
KW  - microphone array
KW  - multiple rooms
KW  - training data
KW  - prediction model
KW  - incremental learning scheme
KW  - implicit acoustic features
KW  - training samples
KW  - direction-of-arrival estimation
KW  - Feature extraction
KW  - Robots
KW  - Acoustics
KW  - Predictive models
KW  - Indoor environment
KW  - Microphones
KW  - Data models
DO  - 10.1109/ICRA.2019.8794231
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents an incremental learning framework for mobile robots localizing the human sound source using a microphone array in a complex indoor environment consisting of multiple rooms. In contrast to conventional approaches that leverage direction-of-arrival (DOA) estimation, the framework allows a robot to accumulate training data and improve the performance of the prediction model over time using an incremental learning scheme. Specifically, we use implicit acoustic features obtained from an auto-encoder together with the geometry features from the map for training. A self-supervision process is developed such that the model ranks the priority of rooms to explore and assigns the ground truth label to the collected data, updating the learned model on-the-fly. The framework does not require pre-collected data and can be directly applied to real-world scenarios without any human supervisions or interventions. In experiments, we demonstrate that the prediction accuracy reaches 67% using about 20 training samples and eventually achieves 90% accuracy within 120 samples, surpassing prior classification-based methods with explicit GCC-PHAT features.
ER  - 

TY  - CONF
TI  - Automated Models of Human Everyday Activity based on Game and Virtual Reality Technology
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2606
EP  - 2612
AU  - A. Haidu
AU  - M. Beetz
PY  - 2019
KW  - computer games
KW  - knowledge acquisition
KW  - virtual reality
KW  - virtual reality technology
KW  - human everyday manipulation activity
KW  - virtual human living
KW  - working environments
KW  - recorded activity data
KW  - knowledge acquisition
KW  - human manipulation activities
KW  - AMEvA
KW  - automated models of everyday activities
KW  - knowledge interpretation
KW  - knowledge processing system
KW  - KNOWROB
KW  - Solid modeling
KW  - Task analysis
KW  - Robots
KW  - Force
KW  - Games
KW  - Virtual reality
DO  - 10.1109/ICRA.2019.8793859
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we will describe AMEvA (Automated Models of Everyday Activities), a special-purpose knowledge acquisition, interpretation, and processing system for human everyday manipulation activity that can automatically: (1) create and simulate virtual human living and working environments (such as kitchens and apartments) with a scope, extent, level of detail, physics, and close to photorealism that facilitates and promotes the natural and realistic execution of human everyday manipulation activities; (2) record human manipulation activities performed in the respective virtual reality environment as well as their effects on the environment and detect force-dynamic states and events; (3) decompose and segment the recorded activity data into meaningful motions and categorize the motions according to action models used in cognitive science; and (4) represent the interpreted activities symbolically in KNOWROB [1] using a first-order time interval logic representation.
ER  - 

TY  - CONF
TI  - Development of a strain gauge based disturbance estimation and compensation technique for a wheeled inverted pendulum robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2613
EP  - 2619
AU  - L. Canete
AU  - T. Takahashi
PY  - 2019
KW  - compensation
KW  - force control
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - position control
KW  - robot dynamics
KW  - service robots
KW  - strain gauges
KW  - wheels
KW  - strain gauge based disturbance estimation
KW  - compensation technique
KW  - wheeled inverted pendulum robot
KW  - I-PENTAR
KW  - strain gauge based sensor
KW  - purely estimation based control
KW  - inverted pendulum type assistant robot
KW  - Wheels
KW  - Robot sensing systems
KW  - Strain measurement
KW  - Task analysis
KW  - Mobile robots
KW  - Axles
DO  - 10.1109/ICRA.2019.8793995
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ongoing development of the Inverted PENdulum Type Assistant Robot (I-PENTAR) is being undertaken by the authors. The I-PENTAR has many tasks like lifting objects with unknown mass, pushing and pulling a carts and many more. During execution of these tasks unknown disturbances enter the system and cause dynamic responses and errors. Most notably, the wheels of the robot move with excessively transients. To alleviate this problem, a strain gauge based sensor is attached to the existing structure of the robot to gain information regarding the disturbances. This allows minimal change to the system design while improving robustness to disturbances. In this paper the development of the sensor, the corresponding model and a method of updating the existing purely estimation based control is presented together with tests.
ER  - 

TY  - CONF
TI  - Spatio-temporal representation for long-term anticipation of human presence in service robotics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2620
EP  - 2626
AU  - T. Vintr
AU  - Z. Yan
AU  - T. Duckett
AU  - T. Krajník
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - service robots
KW  - spatiotemporal phenomena
KW  - spatio-temporal representation
KW  - long-term anticipation
KW  - service robotics
KW  - mobile autonomous robots
KW  - human populated environments
KW  - wrapped dimensions
KW  - periodicities
KW  - 2D spatial model
KW  - multidimensional representation
KW  - memory efficient spatio-temporal model
KW  - long-term predictions
KW  - mobile robots
KW  - periodic temporal patterns
KW  - Hidden Markov models
KW  - Predictive models
KW  - Market research
KW  - Mobile robots
KW  - Spectral analysis
KW  - Time series analysis
DO  - 10.1109/ICRA.2019.8793534
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose an efficient spatio-temporal model for mobile autonomous robots operating in human populated environments. Our method aims to model periodic temporal patterns of people presence, which are based on peoples' routines and habits. The core idea is to project the time onto a set of wrapped dimensions that represent the periodicities of people presence. Extending a 2D spatial model with this multidimensional representation of time results in a memory efficient spatio-temporal model. This model is capable of long-term predictions of human presence, allowing mobile robots to schedule their services better and to plan their paths. The experimental evaluation, performed over datasets gathered by a robot over a period of several weeks, indicates that the proposed method achieves more accurate predictions than the previous state of the art used in robotics.
ER  - 

TY  - CONF
TI  - Object Transfer Point Estimation for Fluent Human-Robot Handovers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2627
EP  - 2633
AU  - H. Nemlekar
AU  - D. Dutia
AU  - Z. Li
PY  - 2019
KW  - estimation theory
KW  - humanoid robots
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - robot vision
KW  - human-robot interaction
KW  - collaboration tasks
KW  - offline OTP
KW  - human preferences
KW  - dynamic OTP
KW  - OTP predictor
KW  - humanoid nursing robot
KW  - handover motion
KW  - reach-to-grasp response time
KW  - natural human receiver
KW  - human-robot handovers
KW  - human-robot motion
KW  - object transfer point estimation
KW  - robot visible workspace
KW  - user-adaptive reference frame
KW  - time 3.1 s
KW  - Handover
KW  - Receivers
KW  - Robot kinematics
KW  - Estimation
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794008
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Handing over objects is the foundation of many human-robot interaction and collaboration tasks. In the scenario where a human is handing over an object to a robot, the human chooses where the object needs to be transferred. The robot needs to accurately predict this point of transfer to reach out proactively, instead of waiting for the final position to be presented. This work presents an efficient method for predicting the Object Transfer Point (OTP), which synthesizes (1) an offline OTP calculated based on human preferences observed in a human-robot motion study with (2) a dynamic OTP predicted based on the observed human motion. Our proposed OTP predictor is implemented on a humanoid nursing robot and experimentally validated in human-robot handover tasks. Compared to only using static or dynamic OTP estimators, it has better accuracy at the earlier phase of handover (up to 45% of the handover motion) and can render fluent handovers with a reach-to-grasp response time (about 3.1 secs) close to natural human receiver's response. In addition, the OTP prediction accuracy is maintained across the robot's visible workspace by utilizing a user-adaptive reference frame.
ER  - 

TY  - CONF
TI  - Controlling AeroBot: Development of a Motion Planner for an Actively Articulated Wheeled Humanoid Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2634
EP  - 2640
AU  - M. V. Otubela
AU  - M. F. Cullinan
AU  - C. McGinn
PY  - 2019
KW  - controllability
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - position control
KW  - quadratic programming
KW  - robot kinematics
KW  - stability
KW  - velocity control
KW  - wheels
KW  - robot morphologies
KW  - legged robots
KW  - humanlike form factor
KW  - wheeled systems
KW  - controllability
KW  - motion planner
KW  - actively articulated wheeled humanoid robot
KW  - gap crossing
KW  - dynamically stable motion
KW  - robots kinematics
KW  - sequential quadratic program algorithm
KW  - postural configuration adjustment requirements
KW  - velocity control
KW  - drive wheels
KW  - terrain adaptability
KW  - energy consumption
KW  - aerobot robot
KW  - step climbing
KW  - nonlinear constraints
KW  - stability
KW  - zero moment point
KW  - Trajectory
KW  - Robot kinematics
KW  - Kinematics
KW  - Stability analysis
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8794217
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There is value in exploring new robot morphologies that combine the benefits of legged robots (i.e. high terrain adaptability, humanlike form factor) with those of wheeled systems (i.e. high stability, low energy consumption). Once the basic design concept has been demonstrated, there is a further requirement to validate the controllability of the system through adaptation and implementation of advanced control techniques. This research presents a motion planner that enables the Aerobot robot, an actively articulated wheeled humanoid robot capable of performing step climbing and gap crossing, to plan dynamically stable motion in response to a range of task conditions. Using a model of the robots kinematics, a motion planner is developed. The sequential quadratic program algorithm is used to solve quadratic objectives and non-linear constraints pertaining to stability and postural configuration adjustment requirements. The results showed good tracking of the robot's Zero Moment Point while transitioning between postural configurations and traversing obstacles. During these phase transitions, robustness in maintaining balance and position is also demonstrated via velocity control of the drive wheels.
ER  - 

TY  - CONF
TI  - User Centric Device Registration for Streamlined Workflows in Surgical Navigation Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2641
EP  - 2647
AU  - P. Thienphrapa
AU  - P. Vagdargi
AU  - A. Chen
AU  - D. Stanton
PY  - 2019
KW  - computerised tomography
KW  - health care
KW  - image registration
KW  - medical image processing
KW  - medical robotics
KW  - surgery
KW  - surgery
KW  - health care
KW  - user centric device registration
KW  - registration gesture
KW  - preoperative registration
KW  - medical imaging modalities
KW  - device tracking
KW  - surgical navigation systems
KW  - Navigation
KW  - Robots
KW  - Tracking
KW  - Fixtures
KW  - Monitoring
KW  - Market research
KW  - Medical services
DO  - 10.1109/ICRA.2019.8793822
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Alongside sweeping transformations in healthcare, a timeless drive to make surgical interventions less invasive and more effective has led to the integration of disparate technologies into surgical navigation systems. Fusions of device tracking and medical imaging modalities have been comprehensively investigated for opportunities to improve care. Such composite systems provide more and better information, enabling clinicians to operate less invasively and more effectively. Because of these merits, the preoperative ritual of harmonizing multiple information sources has been tacitly adopted. In this paper, we challenge the paradigm of preoperative registration. Proposed herein is a technique in which a clinician registers an interventional device to a navigation system simply by gesturing the device through a strategically designed fixture. In the background, the system continuously monitors the device path for this registration gesture. We demonstrate generality by applying the method to both robotic and electromagnetically tracked devices, and exhibit versatility by repeating the registration at multiple device base locations. Experiments indicate sub-millimeter accuracy versus conventional approaches on the same setup. Consequently, clinicians can register devices on the fly, increasing flexibility in setup and redefining workflow possibilities in surgery.
ER  - 

TY  - CONF
TI  - Compliant four degree-of-freedom manipulator with locally deformable elastic elements for minimally invasive surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2663
EP  - 2669
AU  - J. Arata
AU  - Y. Fujisawa
AU  - R. Nakadate
AU  - K. Kiguchi
AU  - K. Harada
AU  - M. Mitsuishi
AU  - M. Hashizume
PY  - 2019
KW  - bending
KW  - finite element analysis
KW  - manipulators
KW  - medical robotics
KW  - needles
KW  - optimisation
KW  - surgery
KW  - locally deformable elastic elements
KW  - minimally invasive surgery
KW  - MIS
KW  - surgical robots
KW  - robotic technology
KW  - compliant four degree-of-freedom manipulator
KW  - mechanical parts
KW  - robotic instruments
KW  - optimization method
KW  - FEA
KW  - prototype implementation
KW  - Springs
KW  - Instruments
KW  - Strain
KW  - Surgery
KW  - Manipulators
KW  - Medical robotics
DO  - 10.1109/ICRA.2019.8793798
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Minimally Invasive Surgery (MIS) is one of the most successful applications of surgical robots. Although the introduction of robotic technology has brought a number of benefits, further advancements in MIS are limited by the size and bending radius of instruments. In this paper, we present a compliant four degree-of-freedom manipulator that consists of elastic elements with partly thinner structures. The proposed mechanism allows the elastic element to deform locally, thus minimizing its bending radius while the low number of mechanical parts greatly contributes to its compactness. This paper describes the design strategy, optimization method using FEA, prototype implementation, and evaluations. The evaluations reveal high accuracy and repeat accuracy, which are key elements for robotic instruments in MIS. Further, the prototype is able to exert sufficient force and it is possible to perform a simulated needle insertion task using the manipulator, demonstrating the feasibility of the proposed mechanism.
ER  - 

TY  - CONF
TI  - Safe teleoperation of a laparoscope holder with dynamic precision but low stiffness.
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2693
EP  - 2699
AU  - J. Mago
AU  - M. Aricò
AU  - J. D. Silva
AU  - G. Morel
PY  - 2019
KW  - haptic interfaces
KW  - interactive devices
KW  - medical robotics
KW  - position control
KW  - surgery
KW  - telerobotics
KW  - three-term control
KW  - rigid laparoscope holders
KW  - high-gain PID position control
KW  - dynamic precision
KW  - undetected obstacles
KW  - stiff systems
KW  - compliant behaviour
KW  - unknown friction
KW  - compliant- scope holder
KW  - -precise laparo-scope holder
KW  - haptic interfaces
KW  - high backdrivability
KW  - intelligent PID position controller
KW  - low PID gains
KW  - satisfactory tracking precision
KW  - safe teleoperation
KW  - laparoscope holder
KW  - low stiffness
KW  - Minimally Invasive Surgery
KW  - MIS
KW  - visual feedback
KW  - human assistant
KW  - end-effector
KW  - robotic assistant
KW  - laparoscope displacements
KW  - master input interface
KW  - voice control
KW  - slave level
KW  - Laparoscopes
KW  - Friction
KW  - Surgery
KW  - Robots
KW  - Optimized production technology
KW  - Force
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794076
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A laparoscope is a key element in Minimally Invasive Surgery (MIS) as it provides visual feedback to the surgeon. To overcome the drawbacks induced by its manual operation by a human assistant, it can be fixed on the end-effector of a robotic assistant teleoperated by the surgeon: laparoscope displacements are commanded through a master input interface (e.g., joysticks, voice control, etc.) and replicated accordingly at the slave level. In this approach, precision is of high importance to ensure a good operability by the surgeon. This is why the state-of-the-art relies on rigid laparoscope holders with high-gain PID position control, ensuring high static and dynamic precision. However, in the event of undetected obstacles, such stiff systems generate high forces that may cause harm to the patient. Rather, a compliant behaviour is desirable but it leads to a lack of precision when disturbances occur, such as the unknown friction between the trocar and the laparoscope. In this paper we present a “compliant-and-precise” laparo-scope holder with 4 active Degrees of Freedom (DoFs). Its design is based on cable transmission used for haptic interfaces, thus it exhibits very high backdrivability. The paper shows how an intelligent PID position controller can be used to compensate for unknown friction at the trocar while keeping very low PID gains and a satisfactory tracking precision.
ER  - 

TY  - CONF
TI  - Real-time Teleoperation of Flexible Beveled-tip Needle Insertion using Haptic Force Feedback and 3D Ultrasound Guidance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2700
EP  - 2706
AU  - J. Chevrie
AU  - A. Krupa
AU  - M. Babel
PY  - 2019
KW  - biological tissues
KW  - biomedical ultrasonics
KW  - force feedback
KW  - haptic interfaces
KW  - medical image processing
KW  - medical robotics
KW  - needles
KW  - phantoms
KW  - telemedicine
KW  - telerobotics
KW  - gelatin phantom
KW  - real-time teleoperation
KW  - 3D ultrasound guidance
KW  - flexible beveled-tip needle
KW  - tip trajectory
KW  - user-controlled tasks
KW  - haptic force feedback
KW  - 3D ultrasound probe
KW  - real-time visual feedback
KW  - haptic interface
KW  - needle tip
KW  - beveledtip flexible needle steering
KW  - teleoperation framework
KW  - control loop
KW  - robotic systems
KW  - needle insertion procedures
KW  - Needles
KW  - Task analysis
KW  - Haptic interfaces
KW  - Robots
KW  - Surgery
KW  - Trajectory
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8794012
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Needle insertion procedures can greatly benefit from robotic systems to improve their accuracy and success rate. However, a fully automated system is usually not desirable and the clinicians need to be included in the control loop. In this paper we present a teleoperation framework for beveledtip flexible needle steering that enables the user to directly and intuitively control the trajectory of the needle tip via a haptic interface. The 6 degrees of freedom of the needle base are used to perform several automatic safety and targeting tasks in addition to the one controlled by the user. Real-time visual feedback is provided by a 3D ultrasound probe and used to track the 3D location of the needle and of a spherical target. Several haptic force feedback are compared as well as two different levels of mix between automated and user-controlled tasks. A validation of the framework is conducted in gelatin phantom and a mean targeting accuracy of 2.5 mm is achieved. The results show that providing an adequate haptic guidance to the user can reduce the risks of damage to the tissues while still letting the surgeon in control of the tip trajectory.
ER  - 

TY  - CONF
TI  - End-User Robot Programming Using Mixed Reality
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2707
EP  - 2713
AU  - S. Y. Gadre
AU  - E. Rosen
AU  - G. Chien
AU  - E. Phillips
AU  - S. Tellex
AU  - G. Konidaris
PY  - 2019
KW  - augmented reality
KW  - dexterous manipulators
KW  - helmet mounted displays
KW  - robot programming
KW  - MR-HMD interface
KW  - end-user robot programming
KW  - immersive 3D visualization
KW  - hand gestures
KW  - robot motions
KW  - robot arm
KW  - mixed reality head-mounted display
KW  - pick-and-place programs
KW  - Task analysis
KW  - Visualization
KW  - Two dimensional displays
KW  - Virtual reality
KW  - Programming
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793988
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mixed Reality (MR) is a promising interface for robot programming because it can project an immersive 3D visualization of a robot's intended movement onto the real world. MR can also support hand gestures, which provide an intuitive way for users to construct and modify robot motions. We present a Mixed Reality Head-Mounted Display (MRHMD) interface that enables end-users to easily create and edit robot motions using waypoints. We describe a user study where 20 participants were asked to program a robot arm using 2D and MR interfaces to perform two pick-and-place tasks. In the primitive task, participants created typical pickand-place programs. In the adapted task, participants adapted their primitive programs to address a more complex pickand-place scenario, which included obstacles and conditional reasoning. Compared to the 2D interface, a higher number of users were able to complete both tasks in significantly less time, and reported experiencing lower cognitive workload, higher usability, and higher naturalness with the MR-HMD interface.
ER  - 

TY  - CONF
TI  - Control of Delayed Bilateral Teleoperation System for Robotic Tele-Echography
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2714
EP  - 2720
AU  - J. H. Cho
AU  - M. Kristalny
AU  - J. Seo
AU  - H. J. Lee
AU  - K. Kim
AU  - H. S. Woo
PY  - 2019
KW  - control system synthesis
KW  - delays
KW  - medical robotics
KW  - mobile robots
KW  - stability
KW  - telerobotics
KW  - robotic tele-echography
KW  - controllerfor bilateral robotic system
KW  - delayed communications
KW  - identical 6DOF robotic devices
KW  - Stewart-Gough mechanisms
KW  - controller design
KW  - teleoperation setup
KW  - slave devices
KW  - identical geometry
KW  - measurement arrays
KW  - independent IDOF settings
KW  - intuitively shape teleoperator performance
KW  - control method
KW  - Teleoperators
KW  - Stability analysis
KW  - Service robots
KW  - Internet
KW  - Real-time systems
KW  - Haptic interfaces
DO  - 10.1109/ICRA.2019.8794196
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes development of a controllerfor bilateral robotic system for tele-echography with delayed communications. The system comprises two identical 6DOF robotic devices based on Stewart-Gough mechanisms, which were developed especially for the sake of the considered application. Controller design is facilitated by a symmetry of the teleoperation setup, in which the master and slave devices have identical geometry, actuation and measurement arrays. To further simplify the analysis, we treat coupling between degrees of freedom as exogenous disturbances and this allows us to split the control problem into six independent IDOF settings. The IDOF problems are addressed then using a novel approach to bilateral teleoperation control, based on a complete parameterization of feasible teleoperators. It allows to intuitively shape teleoperator performance while guaranteeing passivity and thus coupled stability of the system. The potential of the proposed control method is demonstrated with experimental results.
ER  - 

TY  - CONF
TI  - A Unified Framework for the Teleoperation of Surgical Robots in Constrained Workspaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2721
EP  - 2727
AU  - M. M. Marinho
AU  - B. V. Adorno
AU  - K. Harada
AU  - K. Deie
AU  - A. Deguet
AU  - P. Kazanzides
AU  - R. H. Taylor
AU  - M. Mitsuishi
PY  - 2019
KW  - dexterous manipulators
KW  - force feedback
KW  - medical robotics
KW  - optimisation
KW  - surgery
KW  - telerobotics
KW  - constrained workspaces
KW  - robot geometry
KW  - slave-side constrained optimization algorithm
KW  - robotic systems
KW  - adult laparoscopy
KW  - infant surgery
KW  - surgical robots
KW  - robot-aided surgery
KW  - operating rooms
KW  - robotic tools
KW  - robot control techniques
KW  - pediatric surgery
KW  - microsurgery
KW  - nonredundant robots
KW  - teleoperation
KW  - dexterity
KW  - Robots
KW  - Surgery
KW  - Optimization
KW  - Jacobian matrices
KW  - Quaternions
KW  - Kinematics
KW  - Laparoscopes
DO  - 10.1109/ICRA.2019.8794363
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In adult laparoscopy, robot-aided surgery is a reality in thousands of operating rooms worldwide, owing to the increased dexterity provided by the robotic tools. Many robots and robot control techniques have been developed to aid in more challenging scenarios, such as pediatric surgery and microsurgery. However, the prevalence of case-specific solutions, particularly those focused on non-redundant robots, reduces the reproducibility of the initial results in more challenging scenarios. In this paper, we propose a general framework for the control of surgical robotics in constrained workspaces under teleoperation, regardless of the robot geometry. Our technique is divided into a slave-side constrained optimization algorithm, which provides virtual fixtures, and with Cartesian impedance on the master side to provide force feedback. Experiments with two robotic systems, one redundant and one non-redundant, show that smooth teleoperation can be achieved in adult laparoscopy and infant surgery.
ER  - 

TY  - CONF
TI  - High-Speed Ring Insertion by Dynamic Observable Contact Hand
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2744
EP  - 2750
AU  - Y. Karako
AU  - S. Kawakami
AU  - K. Koyama
AU  - M. Shimojo
AU  - T. Senoo
AU  - M. Ishikawa
PY  - 2019
KW  - assembling
KW  - design of experiments
KW  - dexterous manipulators
KW  - error compensation
KW  - masks
KW  - position control
KW  - robot hand
KW  - impact reduction
KW  - position-error compensation
KW  - objects contact
KW  - DOC hand
KW  - 6-degrees-of- freedom dynamic passivity
KW  - robot system
KW  - high-speed precision assembly
KW  - dynamic observable contact hand
KW  - multifingered hand
KW  - high speed ring insertion
KW  - time 2.42 s
KW  - time 2.58 s
KW  - Robots
KW  - Shafts
KW  - Task analysis
KW  - Shape
KW  - Force
KW  - Grippers
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794120
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study proposes a dynamic observable contact (DOC) hand as a new multifingered hand to ensure high- speed insertion in an assembly process with a small clearance between objects. To achieve insertion with a small clearance at high speed, a robot hand must realize both impact reduction and position-error compensation when the two objects contact each other. The DOC hand, with its features of 6-degrees-of- freedom dynamic passivity and object-pose observability, can realize both impact reduction and position-error compensation. To evaluate the effectiveness of the DOC hand, we construct a robot system using the DOC hand. We evaluate the performance of the system in the task of ring insertion with a small clearance (0-36um). The results indicate that the robot system performs with a higher speed than a human. In fact, the average cycle time is 2.42 s for the robot, whereas it is 2.58 s for a human. The DOC hand has opened up the possibility for achieving high-speed precision assembly using robots.
ER  - 

TY  - CONF
TI  - Learning To Grasp Under Uncertainty Using POMDPs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2751
EP  - 2757
AU  - N. P. Garg
AU  - D. Hsu
AU  - W. S. Lee
PY  - 2019
KW  - grippers
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - object detection
KW  - recurrent neural nets
KW  - robust control
KW  - service robots
KW  - uncertainty handling
KW  - visual sensing
KW  - partially observable Markov decision process
KW  - grasp policy
KW  - deep recurrent neural network
KW  - imitation learning
KW  - model-based POMDP planning
KW  - G3DB object dataset
KW  - service robots
KW  - far-field sensors
KW  - open-loop grasp
KW  - tactile sensing
KW  - adaptive grasping
KW  - robust object grasping strategy
KW  - uncertainty handling
KW  - Uncertainty
KW  - Grippers
KW  - Grasping
KW  - Planning
KW  - Sensors
KW  - Shape
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793818
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robust object grasping under uncertainty is an essential capability of service robots. Many existing approaches rely on far-field sensors, such as cameras, to compute a grasp pose and perform open-loop grasp after placing gripper under the pose. This often fails as a result of sensing or environment uncertainty. This paper presents a principled, general and efficient approach to adaptive grasping, using both tactile and visual sensing as feedback. We first model adaptive grasping as a partially observable Markov decision process (POMDP), which handles uncertainty naturally. We solve the POMDP for sampled objects from a set, in order to generate data for learning. Finally, we train a grasp policy, represented as a deep recurrent neural network (RNN), in simulation through imitation learning. By combining model-based POMDP planning and imitation learning, the proposed approach achieves robustness under uncertainty, generalization over many objects, and fast execution. In particular, we show that modeling only a small sample of objects enables us to learn a robust strategy to grasp previously unseen objects of varying shapes and recover from failure over multiple steps. Experiments on the G3DB object dataset in simulation and a smaller object set with a real robot indicate promising results.
ER  - 

TY  - CONF
TI  - Soft Hands with Embodied Constraints: The Soft ScoopGripper
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2758
EP  - 2764
AU  - G. Salvietti
AU  - Z. Iqbal
AU  - M. Malvezzi
AU  - T. Eslami
AU  - D. Prattichizzo
PY  - 2019
KW  - control system synthesis
KW  - grippers
KW  - uncertain systems
KW  - soft ScoopGripper
KW  - underactuation
KW  - robust grasps
KW  - robotic gripper design
KW  - modular under actuated soft hand
KW  - object grasping
KW  - Robots
KW  - Grippers
KW  - Tendons
KW  - Actuators
KW  - Grasping
KW  - Force
KW  - Fasteners
DO  - 10.1109/ICRA.2019.8793563
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The design of robotic grippers requires the accomplishment of several contrasting requirements. Research in under actuated soft hands is a lively topic, with several potentialities and challenges. Soft hands are simple, robust and able of adapting to uncertain environment and operative conditions, however their intrinsic compliance and underactuation reduce control capabilities and precision. Recent studies attempted to compensate this limitation by wisely exploiting environmental constraints and considering them as supports to accomplish the task rather than obstacle to avoid. The development of grasp primitives taking into account environment features leaded to interesting and encouraging results. In this paper, we propose to embed on the hand the positive aspects of studies on environmental constraints exploitation. We present a modular under actuated soft hand in which we added a scoop as a feature of the palm, which simplify object grasping. The scoop allows to grasp objects in narrow spaces, augments the possible contact areas, allows to obtain more robust grasps, with lower forces. The paper illustrates the main design principles, a prototype and experimental results.
ER  - 

TY  - CONF
TI  - A Simple Electric Soft Robotic Gripper with High-Deformation Haptic Feedback
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2765
EP  - 2771
AU  - L. Chin
AU  - M. C. Yuen
AU  - J. Lipton
AU  - L. H. Trueba
AU  - R. Kramer-Bottiglio
AU  - D. Rus
PY  - 2019
KW  - auxetics
KW  - deformation
KW  - feedback
KW  - grippers
KW  - haptic interfaces
KW  - pressure sensors
KW  - grasping tasks
KW  - electric soft robotic gripper
KW  - fabrication techniques
KW  - sensorized system
KW  - object classification
KW  - gripper proprioception
KW  - coupling deformable sensors
KW  - electric motors
KW  - structurally-compliant handed shearing auxetic structures
KW  - pressure sensors
KW  - high-deformation strain
KW  - complex driving hardware
KW  - proprioceptive soft robotic grippers
KW  - proprioceptive feedback
KW  - tactile feedback
KW  - manipulation tasks
KW  - compliant robotic grippers
KW  - high-deformation haptic feedback
KW  - Grippers
KW  - Strain
KW  - Capacitive sensors
KW  - Robot sensing systems
KW  - Servomotors
KW  - Pressure sensors
DO  - 10.1109/ICRA.2019.8794098
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Compliant robotic grippers are more robust to uncertainties in grasping and manipulation tasks, especially when paired with tactile and proprioceptive feedback. Although considerable progress has been made towards achieving proprioceptive soft robotic grippers, current efforts require complex driving hardware or fabrication techniques. In this paper, we present a simple scalable soft robotic gripper integrated with high-deformation strain and pressure sensors. The gripper is composed of structurally-compliant handed shearing auxetic structures actuated by electric motors. Coupling deformable sensors with the compliant grippers enables gripper proprioception and object classification. With this sensorized system, we are able to identify objects' size to within 33% of actual radius and sort objects as hard/soft with 78% accuracy.
ER  - 

TY  - CONF
TI  - Using Geometric Features to Represent Near-Contact Behavior in Robotic Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2772
EP  - 2777
AU  - E. Dessalene
AU  - Y. H. Ong
AU  - J. Morrow
AU  - R. Balasubramanian
AU  - C. Grimm
PY  - 2019
KW  - geometry
KW  - grippers
KW  - learning (artificial intelligence)
KW  - kinematic noise
KW  - contact points
KW  - binary grasp success classifier
KW  - hand morphologies
KW  - hand-object geometric relationships
KW  - near-contact behavior
KW  - near-contact stage
KW  - feature representations
KW  - robotic grasping
KW  - geometric features
KW  - Measurement
KW  - Robots
KW  - Grasping
KW  - Surface morphology
KW  - Geometry
KW  - Morphology
KW  - Machine learning algorithms
DO  - 10.1109/ICRA.2019.8793779
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we define two feature representations for grasping. These representations capture hand-object geometric relationships at the near-contact stage - before the fingers close around the object. Their benefits are: 1) They are stable under noise in both joint and pose variation. 2) They are largely hand and object agnostic, enabling direct comparison across different hand morphologies. 3) Their format makes them suitable for direct application of machine learning techniques developed for images. We validate the representations by: 1) Demonstrating that they can accurately predict the distribution of ε-metric values generated by kinematic noise. I.e., they capture much of the information inherent in contact points and force vectors without the corresponding instabilities. 2) Training a binary grasp success classifier on a real-world data set consisting of 588 grasps.
ER  - 

TY  - CONF
TI  - A GPU Based Parallel Genetic Algorithm for the Orientation Optimization Problem in 3D Printing*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2786
EP  - 2792
AU  - Z. Li
AU  - G. Xiong
AU  - X. Zhang
AU  - Z. Shen
AU  - C. Luo
AU  - X. Shang
AU  - X. Dong
AU  - G. Bian
AU  - X. Wang
AU  - F. Wang
PY  - 2019
KW  - genetic algorithms
KW  - graphics processing units
KW  - parallel algorithms
KW  - production engineering computing
KW  - three-dimensional printing
KW  - parallel genetic algorithm
KW  - 3D printing
KW  - additive manufacturing
KW  - GA
KW  - single-objective optimization
KW  - building time
KW  - multiobjective optimization problem
KW  - model orientation problem
KW  - orientation optimization problem
KW  - GPU
KW  - Optimization
KW  - Silicon
KW  - Solid modeling
KW  - Graphics processing units
KW  - Genetic algorithms
KW  - Three-dimensional printing
KW  - Orientation Optimization
KW  - GPU
KW  - parallel computing
KW  - genetic algorithm
KW  - Additive Manufacturing
DO  - 10.1109/ICRA.2019.8793989
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The choice of model orientation is a very important issue in Additive Manufacturing (AM). In this paper, the model orientation problem is formulated as a multi-objective optimization problem, aiming at minimizing the building time, the surface quality, and the supporting area. Then we convert the problem into a single-objective optimization in the linear-weighted way. After that, the Genetic Algorithm (GA) is used to solve the optimization problem and the process of GA is parallelized and implemented on GPU. Experimental results show that when dealing with complex models in AM, compared with CPU only implementation, the GPU based GA can speed up the process by about 50 times, which helps to significantly reduce the optimization time and ensure the quality of solutions. The GPU based parallel methods we proposed can help to reduce the execution time and improve the efficiency greatly, making the processes more efficient.
ER  - 

TY  - CONF
TI  - Where Should We Place LiDARs on the Autonomous Vehicle? - An Optimal Design Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2793
EP  - 2799
AU  - Z. Liu
AU  - M. Arief
AU  - D. Zhao
PY  - 2019
KW  - ant colony optimisation
KW  - evolutionary computation
KW  - minimax techniques
KW  - object detection
KW  - optical radar
KW  - nondetectable subspace
KW  - min-max optimization problem
KW  - cuboid-based approach
KW  - VSR-based measure
KW  - object detection rate
KW  - tractable cost function computation
KW  - VSR measure
KW  - cost-effectiveness configuration
KW  - optimal design approach
KW  - autonomous vehicle manufacturers
KW  - accurate 3D views
KW  - precise distance measures
KW  - optimal LiDAR configuration problem
KW  - utility maximization
KW  - artificial bee colony evolutionary algorithm
KW  - uncertain driving conditions
KW  - bio-inspired measure
KW  - Laser radar
KW  - Laser beams
KW  - Cost function
KW  - Shape
KW  - Three-dimensional displays
KW  - Cameras
DO  - 10.1109/ICRA.2019.8793619
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous vehicle manufacturers recognize that LiDAR provides accurate 3D views and precise distance measures under highly uncertain driving conditions. Its practical implementation, however, remains costly. This paper investigates the optimal LiDAR configuration problem to achieve utility maximization. We use the perception area and non-detectable subspace to construct the design procedure as solving a min-max optimization problem and propose a bio-inspired measure - volume to surface area ratio (VSR) - as an easy-to-evaluate cost function representing the notion of the size of the non-detectable subspaces of a given configuration. We then adopt a cuboid-based approach to show that the proposed VSR-based measure is a well-suited proxy for object detection rate. It is found that the Artificial Bee Colony evolutionary algorithm yields a tractable cost function computation. Our experiments highlight the effectiveness of our proposed VSR measure in terms of cost-effectiveness configuration as well as providing insightful analyses that can improve the design of AV systems.
ER  - 

TY  - CONF
TI  - A Robotic Cell for Multi-Resolution Additive Manufacturing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2800
EP  - 2807
AU  - P. M. Bhatt
AU  - A. M. Kabir
AU  - R. K. Malhan
AU  - B. Shah
AU  - A. V. Shembekar
AU  - Y. J. Yoon
AU  - S. K. Gupta
PY  - 2019
KW  - extrusion
KW  - industrial robots
KW  - manipulators
KW  - nozzles
KW  - rapid prototyping (industrial)
KW  - surface finishing
KW  - three-dimensional printing
KW  - trajectory control
KW  - planar layers
KW  - robot manipulators
KW  - robotic cell
KW  - multiresolution additive manufacturing
KW  - heated nozzle
KW  - surface finish
KW  - fiber orientations
KW  - extrusion
KW  - layer-by-layer deposition
KW  - fused deposition model
KW  - nonplanar layers
KW  - degrees of freedom
KW  - collision-free trajectories
KW  - Tools
KW  - Printing
KW  - Surface treatment
KW  - Manipulators
KW  - Collision avoidance
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793730
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Extrusion-based additive manufacturing (AM), also known as fused deposition modeling (FDM) extrudes filaments through a heated nozzle and builds a part layer-by-layer. Using a smaller diameter nozzle can achieve better surface finish. However, there is a trade-off between surface finish and build times as using a small diameter nozzle leads to smaller layer thickness and long build times. Traditional FDM printers create a part with planar layers, and this restricts control over fiber orientations. This paper presents a robotic cell for multi-resolution AM. The cell consists of two 6 degrees of freedom (DOF) robot manipulators capable of printing non-planar and/or planar layers. We describe algorithms for decomposing parts into multi-resolution layers and generating collision-free trajectories for the robot manipulators. We validate our approach by printing five parts with multi-resolution.
ER  - 

TY  - CONF
TI  - Multimodal Bin Picking System with Compliant Tactile Sensor Arrays for Flexible Part Handling*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2824
EP  - 2830
AU  - V. Müller
AU  - N. Elkmann
PY  - 2019
KW  - control engineering computing
KW  - grippers
KW  - manipulators
KW  - object recognition
KW  - pose estimation
KW  - robot vision
KW  - sensor arrays
KW  - tactile sensors
KW  - compliant tactile sensor arrays
KW  - flexible part handling
KW  - robot control architecture
KW  - vision sensors
KW  - reliable handling
KW  - tactile grasp validation system
KW  - in-hand object monitoring
KW  - industrial grippers
KW  - magnetic gripper
KW  - flexible vacuum gripper
KW  - compliant custom tactile sensor array
KW  - specific gripper
KW  - in-hand object recognition
KW  - tactile-based object
KW  - grasp monitoring
KW  - tactile sensing
KW  - multimodal bin picking system
KW  - off-the-shelf bin picking system
KW  - vision-based picking approaches
KW  - Grippers
KW  - Grasping
KW  - Tactile sensors
KW  - Pose estimation
KW  - Monitoring
KW  - Sensor arrays
DO  - 10.1109/ICRA.2019.8793950
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a robot control architecture comprised of tactile and vision sensors incorporated into an off-the-shelf bin picking system. The proposed architecture facilitates flexible and reliable handling of objects and materials by employing a tactile grasp validation system and in-hand object monitoring. Two industrial grippers, specifically a magnetic gripper and a flexible vacuum gripper, are equipped with a compliant custom tactile sensor array. The algorithms used are for each specific gripper and respective sensor, however are transferrable to other grippers as well. The tactile sensing augments vision-based picking approaches, thus supporting in-hand object recognition [1] that is particularly useful for hard-to-recognize objects such as objects with transparent or shiny surfaces. Algorithms for tactile-based object pose estimation in the gripper and for grasp monitoring, including grasp validation, complete the approach.
ER  - 

TY  - CONF
TI  - Offline Policy Iteration Based Reinforcement Learning Controller for Online Robotic Knee Prosthesis Parameter Tuning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2831
EP  - 2837
AU  - M. Li
AU  - X. Gao
AU  - Y. Wen
AU  - J. Si
AU  - H. H. Huang
PY  - 2019
KW  - biomechanics
KW  - finite state machines
KW  - iterative methods
KW  - learning systems
KW  - medical robotics
KW  - optimal control
KW  - prosthetics
KW  - offline policy iteration
KW  - online robotic knee prosthesis parameter
KW  - optimal controller
KW  - personalized control
KW  - optimal control problems
KW  - human-prosthesis system
KW  - prototypic robotic prosthesis
KW  - approximate policy iteration algorithm
KW  - reinforcement learning-based control
KW  - near-normal knee kinematics
KW  - offline learning
KW  - robotic lower limb prosthesis
KW  - RL control
KW  - control policy
KW  - impedance control parameters
KW  - prosthesis control parameters
KW  - Prosthetics
KW  - Knee
KW  - Impedance
KW  - Kinematics
KW  - Reinforcement learning
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8794212
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper aims to develop an optimal controller that can automatically provide personalized control of robotic knee prosthesis in order to best support gait of individual prosthesis wearers. We introduced a new reinforcement learning (RL) controller for this purpose based on the promising ability of RL controllers to solve optimal control problems through interactions with the environment without requiring an explicit system model. However, collecting data from a human-prosthesis system is expensive and thus the design of a RL controller has to take into account data and time efficiency. We therefore propose an offline policy iteration based reinforcement learning approach. Our solution is built on the finite state machine (FSM) impedance control framework, which is the most used prosthesis control method in commercial and prototypic robotic prosthesis. Under such a framework, we designed an approximate policy iteration algorithm to devise impedance parameter update rules for 12 prosthesis control parameters in order to meet individual users' needs. The goal of the reinforcement learning-based control was to reproduce near-normal knee kinematics during gait. We tested the RL controller obtained from offline learning in real time experiment involving the same able-bodied human subject wearing a robotic lower limb prosthesis. Our results showed that the RL control resulted in good convergent behavior in kinematic states, and the offline learning control policy successfully adjusted the prosthesis control parameters to produce near-normal knee kinematics in 10 updates of the impedance control parameters.
ER  - 

TY  - CONF
TI  - Consolidated control framework to control a powered transfemoral prosthesis over inclined terrain conditions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2838
EP  - 2844
AU  - W. Hong
AU  - V. Paredes
AU  - K. Chao
AU  - S. Patrick
AU  - P. Hur
PY  - 2019
KW  - legged locomotion
KW  - medical control systems
KW  - optimisation
KW  - PD control
KW  - prosthetics
KW  - PD controller
KW  - AMPRO II
KW  - cubic Bezier polynomials
KW  - proportional-derivative controller
KW  - impedance parameters
KW  - impedance control scheme
KW  - trajectory tracking
KW  - sloped terrains
KW  - inclined terrain conditions
KW  - consolidated control framework
KW  - terrain inclinations
KW  - powered transfemoral prosthesis
KW  - terminal swing phase
KW  - slope walking trajectories
KW  - human slope walking data
KW  - offline optimization problem
KW  - Proportional-Derivative controller
KW  - compliant stance phase
KW  - Legged locomotion
KW  - Prosthetics
KW  - Trajectory
KW  - Impedance
KW  - Knee
KW  - Thigh
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794140
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For amputees, walking on sloped surfaces is one of the most challenging tasks in their daily lives. Unfortunately, designing a prosthesis that can effectively adapt to varying terrain is an ongoing problem. In this paper, we propose a unified control scheme that enables a powered transfemoral prosthesis to perform human-like walking on sloped terrains regardless of the slope and without any knowledge of the upcoming slope. The control scheme implements impedance control and trajectory tracking during the stance and swing phase, respectively. In the impedance control scheme, properly tuned impedance parameters are used to provide a stable and compliant stance phase that adapts to the slope of the ground. During the swing phase, the system is controlled by a Proportional-Derivative (PD) controller to track the desired trajectories based on cubic Bezier polynomials. These trajectories were obtained by solving an offline optimization problem compared to human slope walking data. Any slope walking trajectories can be generated online by using the optimized Bezier coefficients. At the terminal swing phase, a low gain PD controller is utilized to adapt to the unexpected terrains and smoothly track the generated trajectories. The proposed control framework is implemented on a powered transfemoral prosthesis, AMPRO II, on various slopes. The results validate the controller's ability to adapt to terrain inclinations within the range of ± 10°.
ER  - 

TY  - CONF
TI  - Estimating Loads Along Elastic Rods
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2867
EP  - 2873
AU  - V. A. Aloi
AU  - D. C. Rucker
PY  - 2019
KW  - bending
KW  - elasticity
KW  - inverse problems
KW  - manipulators
KW  - nonlinear programming
KW  - rods (structures)
KW  - elastic structures
KW  - distributed loads
KW  - elastic rod
KW  - large-deflection Cosserat-rod model
KW  - rod length
KW  - double-bend shapes
KW  - shape approximation
KW  - mechanics-based models
KW  - mechanics inverse problem
KW  - constrained nonlinear optimization
KW  - Force
KW  - Robot sensing systems
KW  - Shape
KW  - Load modeling
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794301
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mechanics-based models of thin elastic structures are prevalent in robotics research, both in soft/continuum robot modeling, and in robotic manipulation of strings, sutures, needles, and endoscopes. In all these applications, distributed loads along the device's length can affect its shape in space. Estimation of the distributed loading based on observation of the object's shape constitutes a classical mechanics inverse problem that would be useful in many applications, but this problem has received relatively little attention to date. In this paper, we propose methods to estimate distributed loads on an elastic rod using a large-deflection Cosserat-rod model and constrained nonlinear optimization. We perform experiments that illustrate the feasibility of using these methods to locate regions of high contact force along the rod, and to estimate magnitudes of the forces that are applied. Results show that overall force magnitudes and locations can be estimated with average error of 0.29 N (6.7% of average resultant magnitude) and 4 mm (2% of rod length) for complex double-bend shapes, and the shape approximation has near-zero error.
ER  - 

TY  - CONF
TI  - Oriented Point Sampling for Plane Detection in Unorganized Point Clouds
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2917
EP  - 2923
AU  - B. Sun
AU  - P. Mordohai
PY  - 2019
KW  - image reconstruction
KW  - image segmentation
KW  - image sensors
KW  - object detection
KW  - octrees
KW  - robot vision
KW  - SLAM (robots)
KW  - solid modelling
KW  - unorganized point clouds
KW  - crucial pre-processing step
KW  - point cloud segmentation
KW  - organized point clouds
KW  - plane hypotheses
KW  - unoriented points
KW  - efficient plane detection method
KW  - semantic mapping
KW  - SLAM
KW  - plane detection methods
KW  - OPS
KW  - oriented point sampling
KW  - Three-dimensional displays
KW  - Sun
KW  - Surface treatment
KW  - Clustering algorithms
KW  - Octrees
KW  - Estimation
KW  - Image segmentation
DO  - 10.1109/ICRA.2019.8793487
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Plane detection in 3D point clouds is a crucial pre-processing step for applications such as point cloud segmentation, semantic mapping and SLAM. In contrast to many recent plane detection methods that are only applicable on organized point clouds, our work is targeted to unorganized point clouds that do not permit a 2D parametrization. We compare three methods for detecting planes in point clouds efficiently. One is a novel method proposed in this paper that generates plane hypotheses by sampling from a set of points with estimated normals. We named this method Oriented Point Sampling (OPS) to contrast with more conventional techniques that require the sampling of three unoriented points to generate plane hypotheses. We also implemented an efficient plane detection method based on local sampling of three unoriented points and compared it with OPS and the 3D-KHT algorithm, which is based on octrees, on the detection of planes on 10,000 point clouds from the SUN RGB-D dataset.
ER  - 

TY  - CONF
TI  - The Importance of Metric Learning for Robotic Vision: Open Set Recognition and Active Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2924
EP  - 2931
AU  - B. J. Meyer
AU  - T. Drummond
PY  - 2019
KW  - convolutional neural nets
KW  - image classification
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - robotic vision
KW  - robotic problems
KW  - training set distribution
KW  - robotic applications
KW  - real-world robotic action
KW  - deep metric learning classification system
KW  - open set recognition problems
KW  - open set active learning approach
KW  - active learning problems
KW  - deep neural network recognition systems
KW  - Training
KW  - Robots
KW  - Labeling
KW  - Semantics
KW  - Task analysis
KW  - Extraterrestrial measurements
DO  - 10.1109/ICRA.2019.8794188
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - State-of-the-art deep neural network recognition systems are designed for a static and closed world. It is usually assumed that the distribution at test time will be the same as the distribution during training. As a result, classifiers are forced to categorise observations into one out of a set of predefined semantic classes. Robotic problems are dynamic and open world; a robot will likely observe objects that are from outside of the training set distribution. Classifier outputs in robotic applications can lead to real-world robotic action and as such, a practical recognition system should not silently fail by confidently misclassifying novel observations. We show how a deep metric learning classification system can be applied to such open set recognition problems, allowing the classifier to label novel observations as unknown. Further to detecting novel examples, we propose an open set active learning approach that allows a robot to efficiently query a user about unknown observations. Our approach enables a robot to improve its understanding of the true distribution of data in the environment, from a small number of label queries. Experimental results show that our approach significantly outperforms comparable methods in both the open set recognition and active learning problems.
ER  - 

TY  - CONF
TI  - Learning Discriminative Embeddings for Object Recognition on-the-fly
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2932
EP  - 2938
AU  - M. Lagunes-Fortiz
AU  - D. Damen
AU  - W. Mayol-Cuevas
PY  - 2019
KW  - image classification
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - lightweight classifier
KW  - Computer Vision applications
KW  - real-world images datasets
KW  - inference time
KW  - unseen objects
KW  - trained model
KW  - Supervised Triplet Loss
KW  - separable embeddings
KW  - high-end computational resources
KW  - CNNs
KW  - object recognition on-the-fly
KW  - discriminative embeddings
KW  - Training
KW  - Measurement
KW  - Computational modeling
KW  - Robots
KW  - Computer architecture
KW  - Object recognition
KW  - Support vector machines
DO  - 10.1109/ICRA.2019.8793715
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We address the problem of learning to recognize new objects on-the-fly efficiently. When using CNNs, a typical approach for learning new objects is by fine-tuning the model. However, this approach relies on the assumption that the original training set is available and requires high-end computational resources for training the ever-growing dataset efficiently, which can be unfeasible for robots with limited hardware. To overcome these limitations, we propose a new architecture that: 1) Instead of predicting labels, it learns to generate discriminative and separable embeddings of an object's viewpoints by using a Supervised Triplet Loss, which is easier to implement than current smart mining techniques and the trained model can be applied to unseen objects. 2) Infers an object's identity efficiently by utilizing a lightweight classifier in the features embedding space, this keeps the inference time in the order of milliseconds and can be retrained efficiently when new objects are learned. We evaluate our approach on four real-world images datasets used for Robotics and Computer Vision applications: Amazon Robotics Challenge 2017 by MIT-Princeton, T-LESS, ToyBoX, and CORe50 datasets. Code available at [1].
ER  - 

TY  - CONF
TI  - A Novel Multi-layer Framework for Tiny Obstacle Discovery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2939
EP  - 2945
AU  - F. Xue
AU  - A. Ming
AU  - M. Zhou
AU  - Y. Zhou
PY  - 2019
KW  - collision avoidance
KW  - edge detection
KW  - feature extraction
KW  - mobile robots
KW  - probability
KW  - regression analysis
KW  - robot vision
KW  - tiny obstacle discovery
KW  - monocular image
KW  - obstacle-aware discovery method
KW  - multilayer regions
KW  - tiny obstacle proposals
KW  - multilayer framework
KW  - edge detection
KW  - missing contour recovery
KW  - visual cues
KW  - obstacle-aware occlusion edge maps
KW  - proposals extraction
KW  - obstacle occupied probability map
KW  - obstacle-aware regressor
KW  - Lost and Found dataset
KW  - Image edge detection
KW  - Proposals
KW  - Visualization
KW  - Roads
KW  - Cameras
KW  - Three-dimensional displays
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8794279
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For tiny obstacle discovery in a monocular image, edge is a fundamental visual element. Nevertheless, because of various reasons, e.g., noise and similar color distribution with background, it is still difficult to detect the edges of tiny (b) obstacles at long distance. In this paper, we propose an obstacle-aware discovery method to recover the missing contours of these obstacles, which helps to obtain obstacle proposals as much as possible. First, by using visual cues in monocular images, several multi-layer regions are elaborately inferred to reveal the distances from the camera. Second, several novel obstacle-aware occlusion edge maps are constructed to well capture the contours of tiny obstacles, which combines cues from each layer. Third, to ensure the existence of the tiny obstacle proposals, the maps from all layers are used for proposals extraction. Finally, based on these proposals containing tiny obstacles, a novel obstacle-aware regressor is proposed to generate an obstacle occupied probability map with high confidence. The convincing experimental results with comparisons on the Lost and Found dataset demonstrate the effectiveness of our approach, achieving around 9.5% improvement on the accuracy than FPHT and PHT, it even gets comparable performance to MergeNet. Moreover, our method outperforms the state-of-the-art algorithms and significantly improves the discovery ability for tiny obstacles at long distance.
ER  - 


