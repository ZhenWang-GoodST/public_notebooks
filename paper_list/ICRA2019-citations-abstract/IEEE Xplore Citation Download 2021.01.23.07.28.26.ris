TY  - CONF
TI  - ICRA 2019 Digest Final
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - i
EP  - lvii
PY  - 2019
DO  - 10.1109/ICRA.2019.8793894
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Presents abstracts for the articles comprising the conference proceedings.
ER  - 

TY  - CONF
TI  - Table of contents
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 46
PY  - 2019
DO  - 10.1109/ICRA.2019.8793964
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Presents the table of contents/splash page of the proceedings record.
ER  - 

TY  - CONF
TI  - Trajectory-based Probabilistic Policy Gradient for Learning Locomotion Behaviors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 7
AU  - S. Choi
AU  - J. Kim
PY  - 2019
KW  - control engineering computing
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - probability
KW  - robot programming
KW  - moderate sample complexity
KW  - trajectory-based probabilistic policy gradient
KW  - trajectory-based reinforcement learning method
KW  - deep latent policy gradient
KW  - DLPG
KW  - policy function
KW  - probability distribution
KW  - deep latent variable model
KW  - curriculum learning
KW  - locomotion skills
KW  - Snapbot
KW  - four-legged walking robot
KW  - Trajectory
KW  - Legged locomotion
KW  - Task analysis
KW  - Gradient methods
KW  - Stochastic processes
KW  - Training
DO  - 10.1109/ICRA.2019.8794207
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a trajectory-based reinforcement learning method named deep latent policy gradient (DLPG) for learning locomotion skills. We define the policy function as a probability distribution over trajectories and train the policy using a deep latent variable model to achieve sample efficient skill learning. We first evaluate the sample efficiency of DLPG compared to the state-of-the-art reinforcement learning methods in simulated environments. Then, we apply the proposed method to a four-legged walking robot named Snapbot to learn three basic locomotion skills of turn left, go straight, and turn right. We demonstrate that, by properly designing two reward functions for curriculum learning, Snapbot successfully learns the desired locomotion skills with moderate sample complexity.
ER  - 

TY  - CONF
TI  - Learning Motion Planning Policies in Uncertain Environments through Repeated Task Executions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8
EP  - 14
AU  - F. Tsang
AU  - R. A. Macdonald
AU  - S. L. Smith
PY  - 2019
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - learned reactive planning problem
KW  - motion planning policy learning
KW  - execution cost
KW  - motion policy
KW  - navigation task
KW  - online replanning
KW  - reactive algorithms
KW  - goal location
KW  - repeated task executions
KW  - uncertain environments
KW  - Task analysis
KW  - Robot sensing systems
KW  - Planning
KW  - Navigation
KW  - Reinforcement learning
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8793961
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to navigate uncertain environments from a start to a goal location is a necessity in many applications. While there are many reactive algorithms for online replanning, there has not been much investigation in leveraging past executions of the same navigation task to improve future executions. In this work, we first formalize this problem by introducing the Learned Reactive Planning Problem (LRPP). Second, we propose a method to capture these past executions and from that determine a motion policy to handle obstacles that the robot has seen before. Third, we show from our experiments that using this policy can significantly reduce the execution cost over just using reactive algorithms.
ER  - 

TY  - CONF
TI  - BaRC: Backward Reachability Curriculum for Robotic Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 15
EP  - 21
AU  - B. Ivanovic
AU  - J. Harrison
AU  - A. Sharma
AU  - M. Chen
AU  - M. Pavone
PY  - 2019
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - optimisation
KW  - path planning
KW  - robots
KW  - BaRC
KW  - initial state distribution backwards
KW  - model-free RL algorithm
KW  - goal-directed continuous control MDPs
KW  - curriculum strategy
KW  - representative dynamic robotic learning problems
KW  - goal-directed tasks
KW  - learning signal
KW  - model-free policy optimization algorithm
KW  - backward reachability curriculum
KW  - curriculum generation techniques
KW  - robotic reinforcement learning
KW  - model-free reinforcement learning
KW  - model-free algorithms
KW  - reward function
KW  - exploration strategies
KW  - Robots
KW  - Task analysis
KW  - Training
KW  - Computational modeling
KW  - Heuristic algorithms
KW  - Complexity theory
KW  - Approximation algorithms
DO  - 10.1109/ICRA.2019.8794206
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Model-free Reinforcement Learning (RL) offers an attractive approach to learn control policies for high dimensional systems, but its relatively poor sample complexity often necessitates training in simulated environments. Even in simulation, goal-directed tasks whose natural reward function is sparse remain intractable for state-of-the-art model-free algorithms for continuous control. The bottleneck in these tasks is the prohibitive amount of exploration required to obtain a learning signal from the initial state of the system. In this work, we leverage physical priors in the form of an approximate system dynamics model to design a curriculum for a model-free policy optimization algorithm. Our Backward Reachability Curriculum (BaRC) begins policy training from states that require a small number of actions to accomplish the task, and expands the initial state distribution backwards in a dynamically-consistent manner once the policy optimization algorithm demonstrates sufficient performance. BaRC is general, in that it can accelerate training of any model-free RL algorithm on a broad class of goal-directed continuous control MDPs. Its curriculum strategy is physically intuitive, easy-to-tune, and allows incorporating physical priors to accelerate training without hindering the performance, flexibility, and applicability of the model-free RL algorithm. We evaluate our approach on two representative dynamic robotic learning problems and find substantial performance improvement relative to previous curriculum generation techniques and naive exploration strategies.
ER  - 

TY  - CONF
TI  - Active Sampling based Safe Identification of Dynamical Systems using Extreme Learning Machines and Barrier Certificates
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 22
EP  - 28
AU  - I. Salehi
AU  - G. Yao
AU  - A. P. Dani
PY  - 2019
KW  - cyber-physical systems
KW  - feedforward neural nets
KW  - function approximation
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - nonlinear dynamical systems
KW  - optimisation
KW  - robot programming
KW  - dynamical system model
KW  - robot learning applications
KW  - cyber-physical systems
KW  - model learning method
KW  - ELM learning
KW  - invariance property
KW  - invariant trajectories
KW  - barrier certificates
KW  - parameter learning problem
KW  - active sampling based safe identification
KW  - extreme learning machines
KW  - infinite constraint problem
KW  - robot arm
KW  - barrier constraints
KW  - Robots
KW  - Trajectory
KW  - Safety
KW  - Stability analysis
KW  - Heuristic algorithms
KW  - Neurons
KW  - Convergence
DO  - 10.1109/ICRA.2019.8793891
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning the dynamical system (DS) model from data that preserves dynamical system properties is an important problem in many robot learning applications. Typically, the joint data coming from cyber-physical systems, such as robots have some underlying DS properties associated with it, e.g., convergence, invariance to a set, etc. In this paper, a model learning method is developed such that the trajectories of the DS are invariant in a given compact set. Such invariant DS models can be used to generate trajectories of the robot that will always remain in a prescribed set. In order to achieve invariance to a set, Barrier certificates are employed. The DS is approximated using Extreme Learning Machine (ELM), and a parameter learning problem subject to Barrier certificates enforced at all the points in the prescribed set is solved. To solve an infinite constraint problem for enforcing Barrier Certificates at every point in a given compact set, a modified constraint is developed that is sufficient to hold the Barrier certificates in the entire set. An active sampling strategy is formulated to minimize the number of constraints in learning. Simulation results of ELM learning with and without Barrier certificates are presented which show the invariance property being preserved in the ELM learning when learning procedure involves Barrier constraints. The method is validated using experiments conducted on a robot arm recreating invariant trajectories inside a prescribed set.
ER  - 

TY  - CONF
TI  - Navigating Dynamically Unknown Environments Leveraging Past Experience
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 29
EP  - 35
AU  - S. McLeod
AU  - J. Xiao
PY  - 2019
KW  - adaptive control
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - autonomous robot navigation
KW  - unknown dynamic obstacles
KW  - real-time adaptive motion planner
KW  - robot motion online
KW  - sensed environmental data
KW  - limited sensing range
KW  - RAMP framework
KW  - probabilistic model
KW  - unknown dynamic environment
KW  - sensing information
KW  - RAMP robot
KW  - dynamic environment changes
KW  - unknown ways
KW  - learned probabilistic data
KW  - Hilbert maps framework
KW  - dynamically unknown environment navigation
KW  - Robot sensing systems
KW  - Trajectory
KW  - Sociology
KW  - Statistics
KW  - Planning
DO  - 10.1109/ICRA.2019.8793565
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To enable autonomous robot navigation among unknown dynamic obstacles, a real-time adaptive motion planner (RAMP) plans the robot motion online based on sensing the environment as the robot moves with sensors mounted on the robot. However, the sensed environmental data from the robot's local view is usually incomplete due to occlusions from obstacles and limited sensing range.This paper incorporates learning about the environment into the RAMP framework by leveraging the Hilbert Maps framework to generate a probabilistic model of occupancy of the unknown dynamic environment based on past observations. Utilizing this probabilistic model enables RAMP to reason about trajectory fitness when sensing information is partial and incomplete. This allows the RAMP robot to take advantage of what it has experienced from being in the dynamic environment before to inform its subsequent executions even though the dynamic environment changes in unknown ways. The effectiveness of incorporating such learned probabilistic data into RAMP is shown in both simulation and real experiments.
ER  - 

TY  - CONF
TI  - VPE: Variational Policy Embedding for Transfer Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 36
EP  - 42
AU  - I. Arnekvist
AU  - D. Kragic
AU  - J. A. Stork
PY  - 2019
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - pendulums
KW  - variational techniques
KW  - variational policy embedding
KW  - transfer reinforcement Learning
KW  - complex problems
KW  - deployment conditions
KW  - data collection
KW  - simulation training
KW  - Q-function
KW  - master policy
KW  - latent variables
KW  - latent space
KW  - low-dimensional space
KW  - simulation-to-real transfer
KW  - reinforcement learning methods
KW  - Markov decision processes
KW  - Optimization
KW  - Training
KW  - Task analysis
KW  - Robots
KW  - Adaptation models
KW  - Reinforcement learning
KW  - Supervised learning
DO  - 10.1109/ICRA.2019.8793556
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Reinforcement Learning methods are capable of solving complex problems, but resulting policies might perform poorly in environments that are even slightly different. In robotics especially, training and deployment conditions often vary and data collection is expensive, making retraining undesirable. Simulation training allows for feasible training times, but on the other hand suffer from a reality-gap when applied in real-world settings. This raises the need of efficient adaptation of policies acting in new environments.We consider the problem of transferring knowledge within a family of similar Markov decision processes. We assume that Q-functions are generated by some low-dimensional latent variable. Given such a Q-function, we can find a master policy that can adapt given different values of this latent variable. Our method learns both the generative mapping and an approximate posterior of the latent variables, enabling identification of policies for new tasks by searching only in the latent space, rather than the space of all policies. The low-dimensional space, and master policy found by our method enables policies to quickly adapt to new environments. We demonstrate the method on both a pendulum swing-up task in simulation, and for simulation-to-real transfer on a pushing task.
ER  - 

TY  - CONF
TI  - Automatic Labeled LiDAR Data Generation based on Precise Human Model
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 43
EP  - 49
AU  - W. Kim
AU  - M. Tanaka
AU  - M. Okutomi
AU  - Y. Sasaki
PY  - 2019
KW  - data analysis
KW  - image motion analysis
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - optical radar
KW  - human recognition
KW  - point clouds
KW  - ground truth label
KW  - automatic labeled data generation pipeline
KW  - data generation environments
KW  - realistic artificial data
KW  - automatic labeled LiDAR data generation
KW  - precise human model
KW  - deep neural networks
KW  - Laser radar
KW  - Data models
KW  - Three-dimensional displays
KW  - Pipelines
KW  - Labeling
KW  - Legged locomotion
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8793916
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Following improvements in deep neural networks, state-of-the-art networks have been proposed for human recognition using point clouds captured by LiDAR. However, the performance of these networks strongly depends on the training data. An issue with collecting training data is labeling. Labeling by humans is necessary to obtain the ground truth label; however, labeling requires huge costs. Therefore, we propose an automatic labeled data generation pipeline, for which we can change any parameters or data generation environments. Our approach uses a human model named Dhaiba and a background of Miraikan and consequently generated realistic artificial data. We present 500k + data generated by the proposed pipeline. This paper also describes the specification of the pipeline and data details with evaluations of various approaches.
ER  - 

TY  - CONF
TI  - Video Object Segmentation using Teacher-Student Adaptation in a Human Robot Interaction (HRI) Setting
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 50
EP  - 56
AU  - M. Siam
AU  - C. Jiang
AU  - S. Lu
AU  - L. Petrich
AU  - M. Gamal
AU  - M. Elhoseiny
AU  - M. Jagersand
PY  - 2019
KW  - computer aided instruction
KW  - human-robot interaction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - teaching
KW  - video signal processing
KW  - teacher-student learning paradigm
KW  - interactive video object segmentation
KW  - grasping affordances
KW  - children learning process
KW  - IVOS dataset
KW  - teaching signal
KW  - human teacher
KW  - unstructured environments
KW  - robotics
KW  - incremental learning
KW  - learning affordances
KW  - robot manipulation
KW  - human robot interaction setting
KW  - teacher-student adaptation
KW  - adaptation method
KW  - manipulation tasks
KW  - HRI setup
KW  - appearance student network
KW  - appearance teacher network
KW  - Task analysis
KW  - Adaptation models
KW  - Motion segmentation
KW  - Education
KW  - Object segmentation
KW  - Benchmark testing
DO  - 10.1109/ICRA.2019.8794254
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Video object segmentation is an essential task in robot manipulation to facilitate grasping and learning affordances. Incremental learning is important for robotics in unstructured environments. Inspired by the children learning process, human robot interaction (HRI) can be utilized to teach robots about the world guided by humans similar to how children learn from a parent or a teacher. A human teacher can show potential objects of interest to the robot, which is able to self adapt to the teaching signal without providing manual segmentation labels. We propose a novel teacher-student learning paradigm to teach robots about their surrounding environment. A two-stream motion and appearance “teacher” network provides pseudo-labels to adapt an appearance “student” network. The student network is able to segment the newly learned objects in other scenes, whether they are static or in motion. We also introduce a carefully designed dataset that serves the proposed HRI setup, denoted as (I)nteractive (V)ideo (O)bject (S)egmentation. Our IVOS dataset contains teaching videos of different objects, and manipulation tasks. Our proposed adaptation method outperforms the state-of-theart on DAVIS and FBMS with 6.8% and 1.2% in F-measure respectively. It improves over the baseline on IVOS dataset with 46.1% and 25.9% in mIoU.
ER  - 

TY  - CONF
TI  - Morphology-Specific Convolutional Neural Networks for Tactile Object Recognition with a Multi-Fingered Hand
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 57
EP  - 63
AU  - S. Funabashi
AU  - G. Yan
AU  - A. Geier
AU  - A. Schmitz
AU  - T. Ogata
AU  - S. Sugano
PY  - 2019
KW  - convolutional neural nets
KW  - dexterous manipulators
KW  - force measurement
KW  - force sensors
KW  - object recognition
KW  - tactile sensors
KW  - morphology-specific convolutional neural network
KW  - distributed tactile sensors
KW  - multifingered hands
KW  - high-dimensional information
KW  - grasping objects
KW  - abundant tactile information
KW  - MS-CNN
KW  - Allegro Hand
KW  - uSkin modules
KW  - consecutive layers
KW  - finger segment
KW  - tactile map
KW  - force measurements
KW  - joint angle measurements
KW  - object recognition rate
KW  - triaxial force sensors
KW  - Tactile sensors
KW  - Convolution
KW  - Task analysis
KW  - Object recognition
DO  - 10.1109/ICRA.2019.8793901
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Distributed tactile sensors on multi-fingered hands can provide high-dimensional information for grasping objects, but it is not clear how to optimally process such abundant tactile information. The current paper explores the possibility of using a morphology-specific convolutional neural network (MS-CNN). uSkin tactile sensors are mounted on an Allegro Hand, which provides 720 force measurements (15 patches of uSkin modules with 16 triaxial force sensors each) in addition to 16 joint angle measurements. Consecutive layers in the CNN get input from parts of one finger segment, one finger, and the whole hand. Since the sensors give 3D (x, y, z) vector tactile information, inputs with 3 channels (x, y and z) are used in the first layer, based on the idea of such inputs for RGB images from cameras. Overall, the layers are combined, resulting in the building of a tactile map based on the relative position of the tactile sensors on the hand. Seven different combination variations were evaluated, and an over-95% object recognition rate with 20 objects was achieved, even though only one random time instance from a repeated squeezing motion of an object in an unknown pose within the hand was used as input.
ER  - 

TY  - CONF
TI  - A Maximum Likelihood Approach to Extract Finite Planes from 3-D Laser Scans
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 72
EP  - 78
AU  - A. Schaefer
AU  - J. Vertens
AU  - D. Büscher
AU  - W. Burgard
PY  - 2019
KW  - feature extraction
KW  - image registration
KW  - image segmentation
KW  - laser ranging
KW  - maximum likelihood estimation
KW  - pattern clustering
KW  - ray tracing
KW  - stereo image processing
KW  - measurement likelihood
KW  - point-to-plane distance
KW  - ray path information
KW  - maximum likelihood approach
KW  - object detection
KW  - model reconstruction
KW  - laser odometry
KW  - point cloud registration
KW  - robotic systems
KW  - strictly probabilistic method
KW  - agglomerative hierarchical clustering
KW  - 3-D laser range scans
KW  - finite plane extraction
KW  - image segmentation
KW  - Laser modes
KW  - Three-dimensional displays
KW  - Measurement by laser beam
KW  - Clustering algorithms
KW  - Probabilistic logic
KW  - Computational modeling
KW  - Maximum likelihood estimation
DO  - 10.1109/ICRA.2019.8794318
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Whether it is object detection, model reconstruction, laser odometry, or point cloud registration: Plane extraction is a vital component of many robotic systems. In this paper, we propose a strictly probabilistic method to detect finite planes in organized 3-D laser range scans. An agglomerative hierarchical clustering technique, our algorithm builds planes from bottom up, always extending a plane by the point that decreases the measurement likelihood of the scan the least. In contrast to most related methods, which rely on heuristics like orthogonal point-to-plane distance, we leverage the ray path information to compute the measurement likelihood. We evaluate our approach not only on the popular SegComp benchmark, but also provide a challenging synthetic dataset that overcomes SegComp's deficiencies. Both our implementation and the suggested dataset are available at [1].
ER  - 

TY  - CONF
TI  - Designing Worm-inspired Neural Networks for Interpretable Robotic Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 87
EP  - 94
AU  - M. Lechner
AU  - R. Hasani
AU  - M. Zimmer
AU  - T. A. Henzinger
AU  - R. Grosu
PY  - 2019
KW  - brain
KW  - manipulator dynamics
KW  - mobile robots
KW  - neurocontrollers
KW  - neurophysiology
KW  - nonlinear control systems
KW  - recurrent neural nets
KW  - search problems
KW  - supervised learning
KW  - time-varying systems
KW  - interpretable robotic control
KW  - nonlinear time-varying synaptic links
KW  - liquid time-constants dynamics
KW  - neuron-pair communication motifs
KW  - compact neuronal network structures
KW  - sequential robotic tasks
KW  - sensory neurons
KW  - recurrently-wired interneurons
KW  - motor neurons
KW  - interpretable dynamics
KW  - mobile arm robots
KW  - artificial neural network-based control agents
KW  - wiring structure
KW  - worm-inspired neural networks
KW  - liquid time-constant recurrent neural networks
KW  - nematode
KW  - C. elegans
KW  - supervised-learning scheme
KW  - search-based algorithm
KW  - Neurons
KW  - Biological neural networks
KW  - Robot sensing systems
KW  - Synapses
KW  - Correlation
KW  - Couplings
DO  - 10.1109/ICRA.2019.8793840
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we design novel liquid time-constant recurrent neural networks for robotic control, inspired by the brain of the nematode, C. elegans. In the worm's nervous system, neurons communicate through nonlinear time-varying synaptic links established amongst them by their particular wiring structure. This property enables neurons to express liquid time-constants dynamics and therefore allows the network to originate complex behaviors with a small number of neurons. We identify neuron-pair communication motifs as design operators and use them to configure compact neuronal network structures to govern sequential robotic tasks. The networks are systematically designed to map the environmental observations to motor actions, by their hierarchical topology from sensory neurons, through recurrently-wired interneurons, to motor neurons. The networks are then parametrized in a supervised-learning scheme by a search-based algorithm. We demonstrate that obtained networks realize interpretable dynamics. We evaluate their performance in controlling mobile and arm robots, and compare their attributes to other artificial neural network-based control agents. Finally, we experimentally show their superior resilience to environmental noise, compared to the existing machine learning-based methods.
ER  - 

TY  - CONF
TI  - Acting Is Seeing: Navigating Tight Space Using Flapping Wings
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 95
EP  - 101
AU  - Z. Tu
AU  - F. Fei
AU  - J. Zhang
AU  - X. Deng
PY  - 2019
KW  - aerospace robotics
KW  - biomimetics
KW  - control system synthesis
KW  - feedback
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robust control
KW  - torque control
KW  - flapping-wing robot
KW  - wing loading feedback
KW  - instantaneous wing loading
KW  - bio-inspired robotic flyers
KW  - torque control
KW  - tight space navigation
KW  - Purdu Hummingbird
KW  - flight stability
KW  - robust controller design
KW  - Robot sensing systems
KW  - DC motors
KW  - Navigation
KW  - Loading
KW  - Aerodynamics
DO  - 10.1109/ICRA.2019.8794084
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Wings of flying animals can not only generate lift and control torques but also can sense their surroundings. Such dual functions of sensing and actuation coupled in one element are particularly useful for small sized bio-inspired robotic flyers, whose weight, size, and power are under stringent constraint. In this work, we present the first flapping-wing robot using its flapping wings for environmental perception and navigation in tight space, without the need for any visual feedback. As the test platform, we introduce the Purdu Hummingbird, a flapping-wing robot with 17cm wingspan and 12 grams weight, with a pair of 30-40Hz flapping wings driven by only two actuators. By interpreting the wing loading feedback and its variations, the vehicle can detect the presence of environmental changes such as grounds, walls, stairs, obstacles and wind gust. The instantaneous wing loading can be obtained through the measurements and interpretation of the current feedback by the motors that actuate the wings. The effectiveness of the proposed approach is experimentally demonstrated on several challenging flight tasks without vision: terrain following, wall following and going through a narrow corridor. To ensure flight stability, a robust controller was designed for handling unforeseen disturbances during the flight. Sensing and navigating one's environment through actuator loading is a promising method for mobile robots, and it can serve as an alternative or complementary method to visual perception.
ER  - 

TY  - CONF
TI  - Design and Characterization of a Novel Robotic Surface for Application to Compressed Physical Environments *
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 102
EP  - 108
AU  - Y. Wang
AU  - C. Frazelle
AU  - R. Sirohi
AU  - L. Li
AU  - I. D. Walker
AU  - K. E. Green
PY  - 2019
KW  - biomechanics
KW  - design engineering
KW  - mobile robots
KW  - compressed physical environments
KW  - robot arms
KW  - robot surface
KW  - compliant surfaces
KW  - habitable space
KW  - physical space
KW  - tendon-driven robotic surface
KW  - herringbone pattern
KW  - 3D-printed panels
KW  - Prototypes
KW  - Service robots
KW  - Springs
KW  - Surface treatment
KW  - Robot kinematics
KW  - Surface waves
DO  - 10.1109/ICRA.2019.8794043
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Developments of robot arms are countless, but there has been little focus on robot surfaces for the reshaping of a habitable space - especially compliant surfaces. In this paper we introduce a novel, tendon-driven, robot surface comprised of aggregated, overlapping panels organized in a herringbone pattern. The individual 3D-printed panels and their behavior as an aggregation are inspired by the form and behavior of a pinecone. This paper presents our concept, design, and realization of this robot, and compares our prototype to simulations of four physical configurations that are formally distinct and suggestive of how the surface might be applied to habitable, physical space in response to human needs and wants. For the four configurations studied, we found a validating match between prototype and simulations. The paper concludes with a consideration of potential applications for robot surfaces like this one.
ER  - 

TY  - CONF
TI  - Learning Extreme Hummingbird Maneuvers on Flapping Wing Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 109
EP  - 115
AU  - F. Fei
AU  - Z. Tu
AU  - J. Zhang
AU  - X. Deng
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - aircraft control
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - nonlinear control systems
KW  - position control
KW  - robot dynamics
KW  - robot kinematics
KW  - stability
KW  - extreme aerobatic maneuvers
KW  - visual stimulus
KW  - 180-degree yaw turn
KW  - wingbeat frequency
KW  - flight control strategy
KW  - hybrid control policy
KW  - model-based nonlinear control
KW  - model-free reinforcement learning policy
KW  - hummingbird-like fast evasive maneuvers
KW  - extreme hummingbird maneuvers
KW  - flapping wing robots
KW  - backward translation
KW  - posture stabilization
KW  - hummingbird robot
KW  - frequency 40.0 Hz
KW  - time 0.2 s
KW  - Aerodynamics
KW  - Vehicle dynamics
KW  - Uncertainty
KW  - Robots
KW  - Adaptation models
KW  - Torque
KW  - Actuators
DO  - 10.1109/ICRA.2019.8794100
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Biological studies show that hummingbirds can perform extreme aerobatic maneuvers during fast escape. Given a sudden looming visual stimulus at hover, a hummingbird initiates a fast backward translation coupled with a 180-degree yaw turn, which is followed by instant posture stabilization in just under 10 wingbeats. Consider the wingbeat frequency of 40Hz, this aggressive maneuver is carried out in just 0.2 seconds. Inspired by the hummingbirds' near-maximal performance during such extreme maneuvers, we developed a flight control strategy and experimentally demonstrated that such maneuverability can be achieved by an at-scale 12-gram hummingbird robot equipped with just two actuators driving a pair of flapping wings up to 40Hz. The proposed hybrid control policy combines model-based nonlinear control with model-free reinforcement learning. We used the model-based nonlinear control for nominal flight conditions where dynamic models are relatively accurate. During extreme maneuvers when the modeling error becomes unmanageable, we use a model-free reinforcement learning policy trained and optimized in simulation to 'destabilize' the system for peak performance during maneuvering. The hybrid policy manifests a maneuver that is close to that observed in hummingbirds. Direct simulation-to-real transfer is achieved, demonstrating the hummingbird-like fast evasive maneuvers on the at-scale hummingbird robot.
ER  - 

TY  - CONF
TI  - FMD Stereo SLAM: Fusing MVG and Direct Formulation Towards Accurate and Fast Stereo SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 133
EP  - 139
AU  - F. Tang
AU  - H. Li
AU  - Y. Wu
PY  - 2019
KW  - feature extraction
KW  - motion estimation
KW  - pose estimation
KW  - SLAM (robots)
KW  - stereo image processing
KW  - key-feature-based multiple view geometry
KW  - global map
KW  - 3D structure
KW  - bundle adjustment
KW  - fast stereo SLAM
KW  - direct formulation
KW  - local map
KW  - constant motion model
KW  - direct-based formulation
KW  - novel stereo visual SLAM framework
KW  - FMD stereo SLAM
KW  - back-end process
KW  - stereo constraint
KW  - reprojection error minimization
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Visualization
KW  - Robot vision systems
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8793664
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel stereo visual SLAM framework considering both accuracy and speed at the same time. The framework makes full use of the advantages of key-feature-based multiple view geometry (MVG) and direct-based formulation. At the front-end, our system performs direct formulation and constant motion model to predict a robust initial pose, reprojects local map to find 3D-2D correspondence and finally refines pose by the reprojection error minimization. This frontend process makes our system faster. At the back-end, MVG is used to estimate 3D structure. When a new keyframe is inserted, new mappoints are generated by triangulating. In order to improve the accuracy of the proposed system, bad mappoints are removed and a global map is kept by bundle adjustment. Especially, the stereo constraint is performed to optimize the map. This back-end process makes our system more accurate. Experimental evaluation on EuRoC dataset shows that the proposed algorithm can run at more than 100 frames per second on a consumer computer while achieving highly competitive accuracy.
ER  - 

TY  - CONF
TI  - ScalableFusion: High-resolution Mesh-based Real-time 3D Reconstruction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 140
EP  - 146
AU  - S. Schreiberhuber
AU  - J. Prankl
AU  - T. Patten
AU  - M. Vincze
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image reconstruction
KW  - image resolution
KW  - image sensors
KW  - SLAM (robots)
KW  - sensor resolution
KW  - colorization
KW  - multiscale memory management process
KW  - high resolution global shutter camera
KW  - memory management approach
KW  - high-resolution mesh-based real-time 3D reconstruction
KW  - dense 3D reconstructions
KW  - robot applications
KW  - color resolution
KW  - depth resolution
KW  - surface reconstruction
KW  - surface texture
KW  - geometrical fidelity
KW  - RGB-D based reconstructions
KW  - PrimeSense RGB-D camera
KW  - Surface reconstruction
KW  - Image color analysis
KW  - Robot sensing systems
KW  - Geometry
KW  - Three-dimensional displays
KW  - Surface texture
KW  - Image reconstruction
DO  - 10.1109/ICRA.2019.8793654
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dense 3D reconstructions generate globally consistent data of the environment suitable for many robot applications. Current RGB-D based reconstructions, however, only maintain the color resolution equal to the depth resolution of the used sensor. This firmly limits the precision and realism of the generated reconstructions. In this paper we present a real-time approach for creating and maintaining a surface reconstruction in as high as possible geometrical fidelity with full sensor resolution for its colorization (or surface texture). A multi-scale memory management process and a Level of Detail scheme enable equally detailed reconstructions to be generated at small scales, such as objects, as well as large scales, such as rooms or buildings. We showcase the benefit of this novel pipeline with a PrimeSense RGB-D camera as well as combining the depth channel of this camera with a high resolution global shutter camera. Further experiments show that our memory management approach allows us to scale up to larger domains that are not achievable with current state-of-the-art methods.
ER  - 

TY  - CONF
TI  - GEN-SLAM: Generative Modeling for Monocular Simultaneous Localization and Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 147
EP  - 153
AU  - P. Chakravarty
AU  - P. Narayanan
AU  - T. Roussel
PY  - 2019
KW  - cameras
KW  - collision avoidance
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - depth estimation system
KW  - GEN-SLAM
KW  - generative modeling
KW  - Deep Learning based system
KW  - obstacle avoidance
KW  - mobile robot
KW  - conventional geometric SLAM
KW  - single camera
KW  - topological map
KW  - camera image
KW  - topological location estimation
KW  - monocular localization
KW  - monocular simultaneous localization and mapping
KW  - Cameras
KW  - Image reconstruction
KW  - Simultaneous localization and mapping
KW  - Decoding
KW  - Training
DO  - 10.1109/ICRA.2019.8793530
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a Deep Learning based system for the twin tasks of localization and obstacle avoidance essential to any mobile robot. Our system learns from conventional geometric SLAM, and outputs, using a single camera, the topological pose of the camera in an environment, and the depth map of obstacles around it. We use a CNN to localize in a topological map, and a conditional VAE to output depth for a camera image, conditional on this topological location estimation. We demonstrate the effectiveness of our monocular localization and depth estimation system on simulated and real datasets.
ER  - 

TY  - CONF
TI  - RESLAM: A real-time robust edge-based SLAM system
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 154
EP  - 160
AU  - F. Schenk
AU  - F. Fraundorfer
PY  - 2019
KW  - cameras
KW  - edge detection
KW  - image colour analysis
KW  - image representation
KW  - image sensors
KW  - motion estimation
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - camera intrinsics
KW  - sliding window
KW  - edge-based verification
KW  - RESLAM
KW  - camera motions
KW  - RGBD sensors
KW  - sparse representation
KW  - SLAM pipeline
KW  - robust edge-based SLAM system
KW  - simultaneous localization and mapping
KW  - Image edge detection
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Optimization
KW  - Real-time systems
KW  - Microsoft Windows
DO  - 10.1109/ICRA.2019.8794462
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Simultaneous Localization and Mapping is a key requirement for many practical applications in robotics. In this work, we present RESLAM, a novel edge-based SLAM system for RGBD sensors. Due to their sparse representation, larger convergence basin and stability under illumination changes, edges are a promising alternative to feature-based or other direct approaches. We build a complete SLAM pipeline with camera pose estimation, sliding window optimization, loop closure and relocalisation capabilities that utilizes edges throughout all steps. In our system, we additionally refine the initial depth from the sensor, the camera poses and the camera intrinsics in a sliding window to increase accuracy. Further, we introduce an edge-based verification for loop closures that can also be applied for relocalisation. We evaluate RESLAM on wide variety of benchmark datasets that include difficult scenes and camera motions and also present qualitative results. We show that this novel edge-based SLAM system performs comparable to state-of-the-art methods, while running in real-time on a CPU. RESLAM is available as open-source software1.
ER  - 

TY  - CONF
TI  - On-line 3D active pose-graph SLAM based on key poses using graph topology and sub-maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 169
EP  - 175
AU  - Y. Chen
AU  - S. Huang
AU  - R. Fitch
AU  - L. Zhao
AU  - H. Yu
AU  - D. Yang
PY  - 2019
KW  - autonomous aerial vehicles
KW  - computational complexity
KW  - graph theory
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - remotely operated vehicles
KW  - robot vision
KW  - SLAM (robots)
KW  - graph topology
KW  - pose-graph simultaneous localization
KW  - three-dimensional environments
KW  - D-optimality metrics
KW  - weighted node degree
KW  - T-optimality metric
KW  - sampling-based path
KW  - continuous-time trajectory optimization method
KW  - large-scale active SLAM problems
KW  - submap joining method
KW  - online 3D active pose-graph SLAM
KW  - Simultaneous localization and mapping
KW  - Measurement
KW  - Trajectory
KW  - Planning
KW  - Three-dimensional displays
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793632
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present an on-line active pose-graph simultaneous localization and mapping (SLAM) frame-work for robots in three-dimensional (3D) environments using graph topology and sub-maps. This framework aims to find the best trajectory for loop-closure by re-visiting old poses based on the T-optimality and D-optimality metrics of the Fisher information matrix (FIM) in pose-graph SLAM. In order to reduce computational complexity, graph topologies are introduced, including weighted node degree (T-optimality metric) and weighted tree-connectivity (D-optimality metric), to choose a candidate trajectory and several key poses. With the help of the key poses, a sampling-based path planning method and a continuous-time trajectory optimization method are combined hierarchically and applied in the whole framework. So as to further improve the real-time capability of the method, the sub-map joining method is used in the estimation and planning process for large-scale active SLAM problems. In simulations and experiments, we validate our approach by comparing against existing methods, and we demonstrate the on-line planning part using a quad-rotor unmanned aerial vehicle (UAV).
ER  - 

TY  - CONF
TI  - Modeling and Planning Manipulation in Dynamic Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 176
EP  - 182
AU  - P. S. Schmitt
AU  - F. Wirnshofer
AU  - K. M. Wurm
AU  - G. v. Wichert
AU  - W. Burgard
PY  - 2019
KW  - collision avoidance
KW  - manipulator dynamics
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - steering systems
KW  - kinodynamic manipulation planner
KW  - dynamic environments
KW  - robot dynamics
KW  - time-variant environments
KW  - manipulation modeling
KW  - manipulation planning
KW  - online collision avoidance
KW  - object pose estimation
KW  - steering functions
KW  - Planning
KW  - Task analysis
KW  - Collision avoidance
KW  - Manipulator dynamics
KW  - Grippers
DO  - 10.1109/ICRA.2019.8793824
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we propose a new model for sequential manipulation tasks that also considers robot dynamics and time-variant environments. From this model we automatically derive constraint-based controllers and use them as steering functions in a kinodynamic manipulation planner. The resulting plan is not a trajectory but a sequence of controllers that react online to disturbances. We validated our approach in simulation and on a real robot. In the experiments our approach plans and executes dual-robot manipulation tasks with online collision avoidance and reactions to estimates of object poses.
ER  - 

TY  - CONF
TI  - Efficient Obstacle Rearrangement for Object Manipulation Tasks in Cluttered Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 183
EP  - 189
AU  - J. Lee
AU  - Y. Cho
AU  - C. Nam
AU  - J. Park
AU  - C. Kim
PY  - 2019
KW  - collision avoidance
KW  - computational complexity
KW  - manipulators
KW  - mobile robots
KW  - navigation
KW  - object manipulation tasks
KW  - cluttered environments
KW  - robotic manipulator
KW  - constrained confined space
KW  - collision-free path
KW  - object rearrangement
KW  - NP-hard
KW  - service domains
KW  - collision avoidance scheme
KW  - mobile robot navigation
KW  - object poses
KW  - obstacle rearrangement
KW  - polynomial time
KW  - Histograms
KW  - Planning
KW  - Task analysis
KW  - Grasping
KW  - End effectors
DO  - 10.1109/ICRA.2019.8793616
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an algorithm that produces a plan for relocating obstacles in order to grasp a target in clutter by a robotic manipulator without collisions. We consider configurations where objects are densely populated in a constrained and confined space. Thus, there exists no collision-free path for the manipulator without relocating obstacles. Since the problem of planning for object rearrangement has shown to be NP-hard, it is difficult to perform manipulation tasks efficiently which could frequently happen in service domains (e.g., taking out a target from a shelf or a fridge). Our proposed planner employs a collision avoidance scheme which has been widely used in mobile robot navigation. The planner determines an obstacle to be removed quickly in real time. It also can deal with dynamic changes in the configuration (e.g., changes in object poses). Our method is shown to be complete and runs in polynomial time. Experimental results in a realistic simulated environment show that our method improves up to 31% of the execution time compared to other competitors.
ER  - 

TY  - CONF
TI  - MoveIt! Task Constructor for Task-Level Motion Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 190
EP  - 196
AU  - M. Görner
AU  - R. Haschke
AU  - H. Ritter
AU  - J. Zhang
PY  - 2019
KW  - manipulators
KW  - path planning
KW  - robotic manipulation actions
KW  - Task Constructor framework
KW  - black-box planning stages
KW  - task-level motion planning
KW  - robotic manipulation framework
KW  - MoveIt!
KW  - Planning
KW  - Task analysis
KW  - Robots
KW  - Trajectory
KW  - Containers
KW  - Generators
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793898
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A lot of motion planning research in robotics focuses on efficient means to find trajectories between individual start and goal regions, but it remains challenging to specify and plan robotic manipulation actions which consist of multiple interdependent subtasks. The Task Constructor framework we present in this work provides a flexible and transparent way to define and plan such actions, enhancing the capabilities of the popular robotic manipulation framework MoveIt!.11The Task Constructor framework is publicly available at https://github.com/ros-planning/moveit_task_constructor Subproblems are solved in isolation in black-box planning stages and a common interface is used to pass solution hypotheses between stages. The framework enables the hierarchical organization of basic stages using containers, allowing for sequential as well as parallel compositions. The flexibility of the framework is illustrated in multiple scenarios performed on various robot platforms, including bimanual ones.
ER  - 

TY  - CONF
TI  - Exploiting Environment Contacts of Serial Manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 197
EP  - 203
AU  - P. Mohammadi
AU  - D. Kubus
AU  - J. J. Steil
PY  - 2019
KW  - actuators
KW  - end effectors
KW  - force control
KW  - manipulators
KW  - environment contacts
KW  - serial manipulators
KW  - redundant serial manipulator
KW  - robot configuration
KW  - end-effector forces
KW  - actuator
KW  - Actuators
KW  - Force
KW  - Friction
KW  - Kinematics
KW  - End effectors
DO  - 10.1109/ICRA.2019.8794027
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We explore the characteristics of secondary contacts when applying forces with the end-effector of a robot and address the question when these secondary contacts can increase maximum applicable end-effector forces or reduce required actuator efforts. To this end, we formalize the effect of such secondary contacts in terms of required actuator efforts and derive efficiency bounds depending on the contact characteristics and robot configuration. Our findings are confirmed by experiments with a redundant serial manipulator.
ER  - 

TY  - CONF
TI  - optimization-Based Human-in-the-Loop Manipulation Using Joint Space Polytopes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 204
EP  - 210
AU  - P. Long
AU  - T. Keleştemur
AU  - A. Ö. Önol
AU  - T. Padir
PY  - 2019
KW  - collision avoidance
KW  - geometry
KW  - manipulator kinematics
KW  - mobile robots
KW  - optimisation
KW  - motion planner
KW  - human-in-the-loop manipulation
KW  - optimization
KW  - robot operation
KW  - Cartesian polyhedron
KW  - fast collision-free inverse kinematic
KW  - joint space polytopes
KW  - singular configurations
KW  - constrained manipulability polytopes
KW  - operator commands
KW  - End effectors
KW  - Trajectory
KW  - Kinematics
KW  - Task analysis
KW  - Collision avoidance
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2019.8794071
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a new method of maximizing the free space for a robot operating in a constrained environment under operator supervision. The objective is to make the resulting trajectories more robust to operator commands and/or changes in the environment. To represent the volume of free space, the constrained manipulability polytopes are used. These polytopes embed the distance to obstacles, the distance to joint limits and the distance to singular configurations. The volume of the resulting Cartesian polyhedron is used in an optimization-based motion planner to create the trajectories. Additionally, we show how fast collision-free inverse kinematic solutions can be obtained by exploiting the pre-computed inequality constraints. The proposed algorithm is validated in simulation and experimentally.
ER  - 

TY  - CONF
TI  - Large-Scale Multi-Object Rearrangement
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 211
EP  - 218
AU  - E. Huang
AU  - Z. Jia
AU  - M. T. Mason
PY  - 2019
KW  - iterative methods
KW  - optimisation
KW  - robot vision
KW  - search problems
KW  - robotic tabletop rearrangement system
KW  - high packing factor forces
KW  - simulated pushing actions
KW  - vision system
KW  - iterated local search technique
KW  - large-scale multiobject rearrangement
KW  - Planning
KW  - Task analysis
KW  - Grasping
KW  - Robots
KW  - Annealing
KW  - Trajectory
KW  - Markov processes
DO  - 10.1109/ICRA.2019.8793946
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes a new robotic tabletop rearrangement system, and presents experimental results. The tasks involve rearranging as many as 30 to 100 blocks, sometimes packed with a density of up to 40%. The high packing factor forces the system to push several objects at a time, making accurate simulation difficult, if not impossible. Nonetheless, the system achieves goals specifying the pose of every object, with an average precision of ± 1 mm and ± 2°. The system searches through policy rollouts of simulated pushing actions, using an Iterated Local Search technique to escape local minima. In real world execution, the system executes just one action from a policy, then uses a vision system to update the estimated task state, and replans. The system accepts a fully general description of task goals, which means it can solve the singulation and separation problems addressed in prior work, but can also solve sorting problems and spell out words, among other things. The paper includes examples of several solved problems, statistical analysis of the system's behavior on different types of problems, and some discussion of limitations, insights, and future work.
ER  - 

TY  - CONF
TI  - Manipulation Using Microrobot Driven by Optothermally Generated Surface Bubble
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 219
EP  - 224
AU  - L. Dai
AU  - Z. Ge
AU  - N. Jiao
AU  - J. Shi
AU  - L. Liu
PY  - 2019
KW  - bioMEMS
KW  - bubbles
KW  - hydrogels
KW  - microrobots
KW  - photothermal effects
KW  - optothermal effects
KW  - microparticles
KW  - optothermally generated surface bubble
KW  - manipulation technique
KW  - hydrogel microstructures
KW  - microrobots
KW  - absorptivity
KW  - transmissivity
KW  - Microstructure
KW  - Silicon
KW  - Gold
KW  - Surface waves
KW  - Laser theory
KW  - Photothermal effects
DO  - 10.1109/ICRA.2019.8794242
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A manipulation technique based on optothermally generated surface bubbles is proposed in this paper. The manipulation and assembly of microstructures are completed by using bubbles. In addition, the hydrogel microstructures are also used as microrobots driven by the bubble to operate and pattern the microspheres. Considering that many materials and lasers with different wavelength have been used for generating bubbles by optothermal effects, absorptivity and transmissivity are used as indicators of selections. Besides, the size of the bubble can be controlled by the frequency and time of the laser. This technique is supposed to be applied for manipulation of cells, microparticles and microstructures.
ER  - 

TY  - CONF
TI  - Compound micromachines powered by acoustic streaming
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 225
EP  - 230
AU  - M. Kaynak
AU  - F. Ayhan
AU  - M. S. Sakar
PY  - 2019
KW  - acoustic streaming
KW  - energy harvesting
KW  - gears
KW  - machine tools
KW  - manipulators
KW  - microfabrication
KW  - microfluidics
KW  - micromachining
KW  - polymerisation
KW  - pumps
KW  - in-situ polymerization process
KW  - acoustic energy harvesting
KW  - robotic manipulation systems
KW  - microfluidic devices
KW  - microfluidic devices
KW  - mechanical power
KW  - microscale turbines
KW  - programmable projector
KW  - assembly steps
KW  - machine components
KW  - acoustic streaming
KW  - compound micromachines
KW  - Acoustics
KW  - Rotors
KW  - Bars
KW  - Oscillators
KW  - Turbines
KW  - Microchannels
DO  - 10.1109/ICRA.2019.8793481
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the design, fabrication, and operation of compound micromachines powered by acoustic streaming. The machine components were directly incorporated around pillars serving as shafts without further assembly steps using a single-step in situ polymerization process controlled by a programmable projector. Two strategies were presented for harvesting acoustic energy using sharp-edged structures. The first method is based on on-board pumping of fluids and the second method involves engineering of rotors. The implementation of these strategies resulted in the construction of microscale turbines and engines that can be coupled to gear trains for adaptable transmission of mechanical power. We provide a number of further improvements that may together lead to development of compact yet powerful robotic manipulation systems inside microfluidic devices.
ER  - 

TY  - CONF
TI  - ChevBot – An Untethered Microrobot Powered by Laser for Microfactory Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 231
EP  - 236
AU  - R. Zhang
AU  - A. Sherehiy
AU  - Z. Yang
AU  - D. Wei
AU  - C. K. Harnett
AU  - D. O. Popa
PY  - 2019
KW  - displacement measurement
KW  - industrial robots
KW  - integrated circuit manufacture
KW  - laser beam applications
KW  - microactuators
KW  - micromechanical devices
KW  - microrobots
KW  - semiconductor technology
KW  - silicon-on-insulator
KW  - ChevBot
KW  - microfactory applications
KW  - dry environments
KW  - thermal MicroElectro Mechanical actuator
KW  - laser light
KW  - opto-thermal-mechanical energy conversion
KW  - opto-thermal simulation model
KW  - static displacement measurements
KW  - dynamic extension
KW  - directional locomotion
KW  - laser power
KW  - actuator displacements
KW  - locomotion velocity
KW  - submillimeter robot
KW  - laser beam
KW  - untethered microrobot
KW  - microrobot designs
KW  - silicon on insulator wafer
KW  - Laser modes
KW  - Actuators
KW  - Laser beams
KW  - Measurement by laser beam
KW  - Power lasers
KW  - Silicon
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8793856
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we introduce a new class of submillimeter robot (ChevBot) for microfactory applications in dry environments, powered by a 532 nm laser beam. ChevBot is an untethered microrobot propelled by a thermal Micro Electro Mechanical (MEMS) actuator upon exposure to the laser light. Novel models for opto-thermal-mechanical energy conversion are proposed to describe the microrobot's locomotion mechanism. First, an opto-thermal simulation model is presented which is experimentally validated with static displacement measurements with microrobots tethered to the substrate. Then, stick and slip motion of the microrobot was predicted using a dynamic extension of our simulation model, and experiments were conducted to validate this model in one dimension. Promising microrobot designs were fabricated on a silicon on insulator (SOI) wafer with 20 μm device layer and a dimple was assembled at the bottom to initiate directional locomotion on a silicon substrate. Validation experiments demonstrate that exposure to laser power below 2W and repetition frequencies below 60 kHz can generate actuator displacements of a few microns, and 46 μm/s locomotion velocity.
ER  - 

TY  - CONF
TI  - Capillary Ionic Transistor and Precise Transport Control for Nano Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 237
EP  - 242
AU  - Y. Lin
AU  - X. Liu
AU  - T. Arai
PY  - 2019
KW  - capillarity
KW  - electrodes
KW  - elemental semiconductors
KW  - nanoparticles
KW  - silicon
KW  - size measurement
KW  - surface charging
KW  - transistors
KW  - velocity measurement
KW  - negative gate voltage
KW  - positive gate
KW  - nanodevice
KW  - surface charge
KW  - capillary interface
KW  - solution interface
KW  - electrical double layer
KW  - nanoparticle delivery
KW  - resistive pulse method
KW  - velocity measurement
KW  - size measurement
KW  - CIT device
KW  - gate control ability
KW  - gate electrode
KW  - nanochannel
KW  - ionic transport
KW  - CIT
KW  - Capillary Ionic Transistor
KW  - precise transport control
KW  - Si
KW  - Logic gates
KW  - Electrodes
KW  - Transistors
KW  - Nanobioscience
KW  - Electric potential
KW  - Ions
KW  - Nanoscale devices
KW  - nanofluidic
KW  - gate voltage control
KW  - sub 100nm
KW  - micromanipulator
DO  - 10.1109/ICRA.2019.8793755
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Capillary Ionic Transistor (CIT) is introduced as a nanodevice which provides control of ionic transport through nanochannel by gate voltage. CIT is Ionic transistor which employs pulled capillary as nanochannel with tip diameter smaller than 100 nm. We observed that gate voltage applied to gate electrode, deposited on the outer wall of capillary, affect a conductance of nanochannel, due to change of surface charge at the solution/capillary interface. Negative gate voltage corresponds to lower conductivity and positive gate increase conductance of the channel. This effect strongly depends on the size of the channel. In general, at least one dimension of the channel has to be small enough for electrical double layer to overlap. As a demonstration of the gate control ability, we performed Si nanoparticle delivery via CIT and recorded the deliverance through resistive pulse method. Size and velocity measurement are also conducted, to showcase the versatility of CIT device.
ER  - 

TY  - CONF
TI  - Resolved Viscoelasticity Control Considering Singularity for Knee-stretched Walking of a Humanoid
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 250
EP  - 255
AU  - K. Murotani
AU  - K. Yamamoto
AU  - T. Ko
AU  - Y. Nakamura
PY  - 2019
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - viscoelasticity
KW  - task-space
KW  - mass viscoelasticity
KW  - joint-space viscoelasticity
KW  - robust motion
KW  - compliant motion
KW  - RVC method
KW  - kinematic singularity
KW  - knee joint torque
KW  - RVC capable
KW  - humanoid
KW  - stable knee-stretched walking
KW  - knee-bent posture
KW  - resolved viscoelasticity control
KW  - Task analysis
KW  - Knee
KW  - Legged locomotion
KW  - Kinematics
KW  - Trajectory
KW  - Foot
KW  - Humanoid robots
DO  - 10.1109/ICRA.2019.8793605
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes a stable knee-stretched walking of a humanoid by the resolved viscoelasticity control (RVC). The RVC method resolves multiple viscoelasticities in task-space, including the center of mass viscoelasticity for balancing, into joint-space viscoelasticity. Although a robust and compliant motion was achieved by the RVC method in previous studies, the conventional knee-bent posture to avoid the kinematic singularity suffered large knee joint torque. In this study, we propose an extension of the RVC capable of the kinematic singularity. We demonstrate through simulations and experiments that the RVC method considering the singularity achieves a stable and human-like walking, reducing the knee joint torque and improving the energy efficiency.
ER  - 

TY  - CONF
TI  - Versatile Reactive Bipedal Locomotion Planning Through Hierarchical Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 256
EP  - 262
AU  - J. Ding
AU  - C. Zhou
AU  - Z. Guo
AU  - X. Xiao
AU  - N. Tsagarakis
PY  - 2019
KW  - control nonlinearities
KW  - humanoid robots
KW  - legged locomotion
KW  - linear systems
KW  - motion control
KW  - nonlinear control systems
KW  - optimisation
KW  - path planning
KW  - pendulums
KW  - predictive control
KW  - robot dynamics
KW  - step frequency
KW  - humanoid robots
KW  - hierarchical optimization
KW  - angular momentum
KW  - nonlinear model predictive control
KW  - reactive bipedal locomotion planning
KW  - nonlinearities
KW  - walking dynamics
KW  - step time abilities
KW  - step location adjustment
KW  - Center of Mass height variation
KW  - linear inverted pendulum model
KW  - robot gait generation
KW  - Legged locomotion
KW  - Optimization
KW  - Trajectory
KW  - Humanoid robots
KW  - Linear programming
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794072
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When experiencing disturbances during locomotion, human beings use several strategies to maintain balance, e.g. changing posture, modulating step frequency and location. However, when it comes to the gait generation for humanoid robots, modifying step time or body posture in real time introduces nonlinearities in the walking dynamics, thus increases the complexity of the planning. In this paper, we propose a two-layer hierarchical optimization framework to address this issue and provide the humanoids with the abilities of step time and step location adjustment, Center of Mass (CoM) height variation and angular momentum adaptation. In the first layer, times and locations of consecutive two steps are modulated online based on the current CoM state using the Linear Inverted Pendulum Model. By introducing new optimization variables to substitute the hyperbolic functions of step time, the derivatives of the objective function and feasibility constraints are analytically derived, thus reduces the computational cost. Then, taking the generated horizontal CoM trajectory, step times and step locations as inputs, CoM height and angular momentum changes are optimized by the second layer nonlinear model predictive control. This whole procedure will be repeated until the termination condition is met. The improved recovery capability under external disturbances is validated in simulation studies.
ER  - 

TY  - CONF
TI  - Using Deep Reinforcement Learning to Learn High-Level Policies on the ATRIAS Biped
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 263
EP  - 269
AU  - T. Li
AU  - H. Geyer
AU  - C. G. Atkeson
AU  - A. Rai
PY  - 2019
KW  - control system synthesis
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - neurocontrollers
KW  - deep reinforcement learning
KW  - expert knowledge
KW  - domain randomization
KW  - stable controllers
KW  - high-fidelity simulators
KW  - neural network policy
KW  - ATRIAS robot
KW  - bipedal robots
KW  - Neural networks
KW  - Hardware
KW  - Legged locomotion
KW  - Reinforcement learning
KW  - Torso
KW  - Foot
DO  - 10.1109/ICRA.2019.8793864
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning controllers for bipedal robots is a challenging problem, often requiring expert knowledge and extensive tuning of parameters that vary in different situations. Recently, deep reinforcement learning has shown promise at automatically learning controllers for complex systems in simulation. This has been followed by a push towards learning controllers that can be transferred between simulation and hardware, primarily with the use of domain randomization. However, domain randomization can make the problem of finding stable controllers even more challenging, especially for under actuated bipedal robots. In this work, we explore whether policies learned in simulation can be transferred to hardware with the use of high-fidelity simulators and structured controllers. We learn a neural network policy which is a part of a more structured controller. While the neural network is learned in simulation, the rest of the controller stays fixed, and can be tuned by the expert as needed. We show that using this approach can greatly speed up the rate of learning in simulation, as well as enable transfer of policies between simulation and hardware. We present our results on an ATRIAS robot and explore the effect of action spaces and cost functions on the rate of transfer between simulation and hardware. Our results show that structured policies can indeed be learned in simulation and implemented on hardware successfully. This has several advantages, as the structure preserves the intuitive nature of the policy, and the neural network improves the performance of the hand-designed policy. In this way, we propose a way of using neural networks to improve expert designed controllers, while maintaining ease of understanding.
ER  - 

TY  - CONF
TI  - Unsupervised Gait Phase Estimation for Humanoid Robot Walking*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 270
EP  - 276
AU  - S. Piperakis
AU  - S. Timotheatos
AU  - P. Trahanias
PY  - 2019
KW  - data acquisition
KW  - data reduction
KW  - humanoid robots
KW  - legged locomotion
KW  - pattern clustering
KW  - phase estimation
KW  - robot dynamics
KW  - robust control
KW  - state estimation
KW  - unsupervised learning
KW  - unsupervised gait phase estimation
KW  - humanoid robot walking
KW  - contact detection
KW  - feet contact status
KW  - proprioceptive sensing
KW  - inertial measurement unit
KW  - data acquisition
KW  - dimensionality reduction
KW  - state estimation
KW  - unsupervised learning
KW  - feature representation
KW  - gait phase dynamics
KW  - joint encoder
KW  - force data
KW  - torque data
KW  - clustering
KW  - robustness
KW  - legged robots
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Robot sensing systems
KW  - Kinematics
KW  - Unsupervised learning
DO  - 10.1109/ICRA.2019.8793598
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Contact detection is an important topic in contemporary humanoid robotic research. Up to date control and state estimation schemes readily assume that feet contact status is known in advance. In this work, we elaborate on a broader question: in which gait phase is the robot currently in? We introduce an unsupervised learning framework for gait phase estimation based solely on proprioceptive sensing, namely joint encoder, inertial measurement unit and force/torque data. Initially, a meaningful physical explanation on data acquisition is presented. Subsequently, dimensionality reduction is performed to obtain a compact low-dimensional feature representation followed by clustering into three groups, one for each gait phase. The proposed framework is qualitatively and quantitatively assessed in simulation with ground-truth data of uneven/rough terrain walking gaits and insights about the latent gait phase dynamics are drawn. Additionally, its efficacy and robustness is demonstrated when incorporated in leg odometry computation. Since our implementation is based on sensing that is commonly available on humanoids today, we release an open-source ROS/Python package to reinforce further research endeavors.
ER  - 

TY  - CONF
TI  - Stair Climbing Stabilization of the HRP-4 Humanoid Robot using Whole-body Admittance Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 277
EP  - 283
AU  - S. Caron
AU  - A. Kheddar
AU  - O. Tempier
PY  - 2019
KW  - end effectors
KW  - humanoid robots
KW  - legged locomotion
KW  - linear systems
KW  - nonlinear control systems
KW  - pendulums
KW  - quadratic programming
KW  - robot dynamics
KW  - stability
KW  - stair climbing stabilization
KW  - HRP-4 humanoid robot
KW  - whole-body admittance control
KW  - Airbus manufacturing use-case demonstrator
KW  - quadratic programming-based wrench distribution
KW  - whole-body admittance controller
KW  - walking controller
KW  - dynamic stair climbing
KW  - walking stabilization
KW  - linear inverted pendulum tracking
KW  - end-effector
KW  - CoM strategy
KW  - tracking performance
KW  - industrial staircase
KW  - open source software
KW  - size 18.5 cm
KW  - Admittance
KW  - Legged locomotion
KW  - Foot
KW  - Humanoid robots
KW  - Force
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794348
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider dynamic stair climbing with the HRP-4 humanoid robot as part of an Airbus manufacturing use-case demonstrator. We share experimental knowledge gathered so as to achieve this task, which HRP-4 had never been challenged to before. In particular, we extend walking stabilization based on linear inverted pendulum tracking [1] by quadratic programming-based wrench distribution and a whole-body admittance controller that applies both end-effector and CoM strategies. While existing stabilizers tend to use either one or the other, our experience suggests that the combination of these two approaches improves tracking performance. We demonstrate this solution in an on-site experiment where HRP4 climbs an industrial staircase with 18.5 cm high steps, and release our walking controller as open source software.
ER  - 

TY  - CONF
TI  - Reinforcement Learning Meets Hybrid Zero Dynamics: A Case Study for RABBIT
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 284
EP  - 290
AU  - G. A. Castillo
AU  - B. Weng
AU  - A. Hereid
AU  - Z. Wang
AU  - W. Zhang
PY  - 2019
KW  - adaptive control
KW  - control engineering computing
KW  - control system synthesis
KW  - feedback
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - mobile robots
KW  - PD control
KW  - robust control
KW  - stability
KW  - feedback controllers
KW  - bipedal robots
KW  - high-dimensional bipedal models
KW  - bipedal walking
KW  - bipedal control
KW  - walking limit cycles
KW  - HZD framework
KW  - policy learning
KW  - adaptive PD controller
KW  - stable control policy
KW  - robust control policy
KW  - RL framework
KW  - RABBIT robot model
KW  - reinforcement learning
KW  - local stability
KW  - hybrid zero dynamics
KW  - OpenAI gym
KW  - MuJoCo physics engine
KW  - Legged locomotion
KW  - Hip
KW  - Rabbits
KW  - Robot kinematics
KW  - Training
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793627
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The design of feedback controllers for bipedal robots is challenging due to the hybrid nature of its dynamics and the complexity imposed by high-dimensional bipedal models. In this paper, we present a novel approach for the design of feedback controllers using Reinforcement Learning (RL) and Hybrid Zero Dynamics (HZD). Existing RL approaches for bipedal walking are inefficient as they do not consider the underlying physics, often requires substantial training, and the resulting controller may not be applicable to real robots. HZD is a powerful tool for bipedal control with local stability guarantees of the walking limit cycles. In this paper, we propose a non traditional RL structure that embeds the HZD framework into the policy learning. More specifically, we propose to use RL to find a control policy that maps from the robot's reduced order states to a set of parameters that define the desired trajectories for the robot's joints through the virtual constraints. Then, these trajectories are tracked using an adaptive PD controller. The method results in a stable and robust control policy that is able to track variable speed within a continuous interval. Robustness of the policy is evaluated by applying external forces to the torso of the robot. The proposed RL framework is implemented and demonstrated in OpenAI Gym with the MuJoCo physics engine based on the well-known RABBIT robot model.
ER  - 

TY  - CONF
TI  - Learning Wheel Odometry and IMU Errors for Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 291
EP  - 297
AU  - M. BROSSARD
AU  - S. BONNABEL
PY  - 2019
KW  - cameras
KW  - distance measurement
KW  - Gaussian processes
KW  - image filtering
KW  - Kalman filters
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - nonlinear filters
KW  - path planning
KW  - robot vision
KW  - wheel odometry
KW  - IMU errors
KW  - odometry techniques
KW  - autonomous robot navigation
KW  - robust odometry system
KW  - camera
KW  - deep learning
KW  - variational inference
KW  - observation models
KW  - state-space systems
KW  - Gaussian processes
KW  - ground truth
KW  - wheel encoders
KW  - fiber optic gyro
KW  - EKF
KW  - wheel speed sensors
KW  - inertial measurement unit
KW  - extended Kalman filter
KW  - Wheels
KW  - Kernel
KW  - Mobile robots
KW  - Sensors
KW  - Gaussian processes
KW  - Training
KW  - Gaussian process
KW  - odometry estimation
KW  - variational inference
KW  - Kalman filter
DO  - 10.1109/ICRA.2019.8794237
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Odometry techniques are key to autonomous robot navigation, since they enable self-localization in the environment. However, designing a robust odometry system is particularly challenging when camera and LiDAR are uninformative or unavailable. In this paper, we leverage recent advances in deep learning and variational inference to correct dynamical and observation models for state-space systems. The methodology trains Gaussian processes on the residual between the original model and the ground truth, and is applied on publicly available datasets for robot navigation based on two wheel encoders, a fiber optic gyro, and an Inertial Measurement Unit (IMU). We also propose to build an Extended Kalman Filter (EKF) on the learned model using wheel speed sensors and the fiber optic gyro for state propagation, and the IMU to update the estimated state. Experimental results clearly demonstrate that the (learned) corrected models and EKF are more accurate than their original counterparts.
ER  - 

TY  - CONF
TI  - Radar-only ego-motion estimation in difficult settings via graph matching
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 298
EP  - 304
AU  - S. H. Cen
AU  - P. Newman
PY  - 2019
KW  - distance measurement
KW  - feature extraction
KW  - Global Positioning System
KW  - graph theory
KW  - image matching
KW  - motion estimation
KW  - object detection
KW  - radar detection
KW  - sensor fusion
KW  - speckle noise
KW  - scan matching accuracy
KW  - visual odometry
KW  - ego-motion estimation
KW  - stable range objects
KW  - long-range objects
KW  - variable weather
KW  - lighting conditions
KW  - radar-only odometry pipeline
KW  - radar artifacts
KW  - key point extraction
KW  - data association
KW  - graph matching optimization problem
KW  - Robot sensing systems
KW  - Azimuth
KW  - Radar measurements
KW  - Radar detection
KW  - Feature extraction
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793990
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Radar detects stable, long-range objects under variable weather and lighting conditions, making it a reliable and versatile sensor well suited for ego-motion estimation. In this work, we propose a radar-only odometry pipeline that is highly robust to radar artifacts (e.g., speckle noise and false positives) and requires only one input parameter. We demonstrate its ability to adapt across diverse settings, from urban UK to off-road Iceland, achieving a scan matching accuracy of approximately 5.20 cm and 0.0929 deg when using GPS as ground truth (compared to visual odometry's 5.77 cm and 0.1032 deg). We present algorithms for key point extraction and data association, framing the latter as a graph matching optimization problem, and provide an in-depth system analysis.
ER  - 

TY  - CONF
TI  - Recursive Integrity Monitoring for Mobile Robot Localization Safety
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 305
EP  - 311
AU  - G. D. Arana
AU  - O. A. Hafez
AU  - M. Joerger
AU  - M. Spenko
PY  - 2019
KW  - fault diagnosis
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - constant computation requirements
KW  - sequential chi-squared integrity monitoring methodology
KW  - fault detection
KW  - Extended Kalman Filter
KW  - mobile ground robots
KW  - open-sky aviation applications
KW  - integrity risk
KW  - mobile robot localization safety
KW  - recursive integrity monitoring
KW  - preceding time window
KW  - Monitoring
KW  - Feature extraction
KW  - Safety
KW  - Fault detection
KW  - Robot sensing systems
KW  - Kalman filters
DO  - 10.1109/ICRA.2019.8794115
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a new methodology to quantify robot localization safety by evaluating integrity risk, a performance metric widely used in open-sky aviation applications that has been recently extended to mobile ground robots. Here, a robot is localized by feeding relative measurements to mapped landmarks into an Extended Kalman Filter while a sequence of innovations is evaluated for fault detection. The main contribution is the derivation of a sequential chi-squared integrity monitoring methodology that maintains constant computation requirements by employing a preceding time window and, at the same time, is robust against faults occurring prior to the window. Additionally, no assumptions are made on either the nature or shape of the faults because safety is evaluated under the worst possible combination of sensor faults.
ER  - 

TY  - CONF
TI  - Four-Wheeled Dead-Reckoning Model Calibration using RTS Smoothing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 312
EP  - 318
AU  - A. Welte
AU  - P. Xu
AU  - P. Bonnifait
PY  - 2019
KW  - automobiles
KW  - calibration
KW  - inertial navigation
KW  - Kalman filters
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - remotely operated vehicles
KW  - sensor fusion
KW  - smoothing methods
KW  - state estimation
KW  - RTS smoothing
KW  - autonomous vehicles
KW  - accurate dead-reckoning system
KW  - car-like vehicles
KW  - complementary sensors
KW  - redundant sensors
KW  - wheel encoders
KW  - yaw rate gyro
KW  - steering wheel measurements
KW  - ground truth
KW  - smoothing scheme
KW  - smoothed estimates
KW  - model parameters
KW  - experimental vehicle
KW  - public roads
KW  - dead-reckoning drift
KW  - commonly used calibration method
KW  - dead reckoning system
KW  - four-wheeled dead-reckoning model calibration
KW  - complex maneuvers
KW  - public traffic
KW  - Wheels
KW  - Sensors
KW  - Smoothing methods
KW  - Global navigation satellite system
KW  - Calibration
KW  - Dead reckoning
KW  - Radio frequency
DO  - 10.1109/ICRA.2019.8794270
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Localization is one of the main challenges to be addressed to develop autonomous vehicles able to perform complex maneuvers on roads opened to public traffic. Having an accurate dead-reckoning system is an essential step to reach this objective. This paper presents a dead-reckoning model for car-like vehicles that performs the data fusion of complementary and redundant sensors: wheel encoders, yaw rate gyro and steering wheel measurements. In order to get an accurate dead-reckoning system with a drift reduced to the minimum, the parameters have to be well calibrated and the procedure has to be simple and efficient. We present a method able to accurately calibrate the parameters without knowing the ground truth by using a Rauch-Tung-Striebel smoothing scheme which enables to obtain state estimates as close to the ground truth as possible. The smoothed estimates are then used within a optimization process to calibrate the model parameters. The method has been tested using data recorded from an experimental vehicle on public roads. The results show a significant diminution of the dead-reckoning drift compared to a commonly used calibration method. We evaluate finally the average distance a vehicle can navigate without exteroceptive sensors by using the proposed four-wheeled dead reckoning system.
ER  - 

TY  - CONF
TI  - A Multi-Domain Feature Learning Method for Visual Place Recognition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 319
EP  - 324
AU  - P. Yin
AU  - L. Xu
AU  - X. Li
AU  - C. Yin
AU  - Y. Li
AU  - R. A. Srivatsan
AU  - L. Li
AU  - J. Ji
AU  - Y. He
PY  - 2019
KW  - feature extraction
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - computer vision
KW  - robotics applications
KW  - VPR methods
KW  - place recognition performance
KW  - environmental factors
KW  - end-to-end conditional visual place recognition method
KW  - multidomain feature learning method
KW  - feature detaching module
KW  - environmental condition-related features
KW  - feature learning pipeline
KW  - multiseason NORDLAND dataset
KW  - multiweather GTAV dataset
KW  - feature robustness
KW  - variant environmental conditions
KW  - Feature extraction
KW  - Entropy
KW  - Visualization
KW  - Task analysis
KW  - Decoding
KW  - Robots
KW  - Upper bound
DO  - 10.1109/ICRA.2019.8793752
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual Place Recognition (VPR) is an important component in both computer vision and robotics applications, thanks to its ability to determine whether a place has been visited and where specifically. A major challenge in VPR is to handle changes of environmental conditions including weather, season and illumination. Most VPR methods try to improve the place recognition performance by ignoring the environmental factors, leading to decreased accuracy decreases when environmental conditions change significantly, such as day versus night. To this end, we propose an end-to-end conditional visual place recognition method. Specifically, we introduce the multi-domain feature learning method (MDFL) to capture multiple attribute-descriptions for a given place, and then use a feature detaching module to separate the environmental condition-related features from those that are not. The only label required within this feature learning pipeline is the environmental condition. Evaluation of the proposed method is conducted on the multi-season NORDLAND dataset, and the multi-weather GTAV dataset. Experimental results show that our method improves the feature robustness against variant environmental conditions.
ER  - 

TY  - CONF
TI  - Event-based, Direct Camera Tracking from a Photometric 3D Map using Nonlinear Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 325
EP  - 331
AU  - S. Bryner
AU  - G. Gallego
AU  - H. Rebecq
AU  - D. Scaramuzza
PY  - 2019
KW  - cameras
KW  - image reconstruction
KW  - image sensors
KW  - maximum likelihood estimation
KW  - motion estimation
KW  - motion measurement
KW  - nonlinear programming
KW  - photometry
KW  - pose estimation
KW  - asynchronous sensors
KW  - low power consumption
KW  - photometric 3D map
KW  - classic dense 3D reconstruction algorithms
KW  - bioinspired vision sensors
KW  - video imaging
KW  - output pixel-level intensity
KW  - event-based direct camera tracking
KW  - nonlinear optimization
KW  - robot localization
KW  - AR-VR
KW  - 6-DOF pose tracking
KW  - maximum-likelihood framework
KW  - event camera motion estimation
KW  - Cameras
KW  - Robot vision systems
KW  - Three-dimensional displays
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794255
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Event cameras are novel bio-inspired vision sensors that output pixel-level intensity changes, called “events”, instead of traditional video images. These asynchronous sensors naturally respond to motion in the scene with very low latency (microseconds) and have a very high dynamic range. These features, along with a very low power consumption, make event cameras an ideal sensor for fast robot localization and wearable applications, such as AR/VR and gaming. Considering these applications, we present a method to track the 6-DOF pose of an event camera in a known environment, which we contemplate to be described by a photometric 3D map (i.e., intensity plus depth information) built via classic dense 3D reconstruction algorithms. Our approach uses the raw events, directly, without intermediate features, within a maximum-likelihood framework to estimate the camera motion that best explains the events via a generative model. We successfully evaluate the method using both simulated and real data, and show improved results over the state of the art. We release the datasets to the public to foster reproducibility and research in this topic.
ER  - 

TY  - CONF
TI  - Linear Heterogeneous Reconfiguration of Cubic Modular Robots via Simultaneous Tunneling and Permutation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 332
EP  - 338
AU  - H. Kawano
PY  - 2019
KW  - computational complexity
KW  - control engineering computing
KW  - distributed control
KW  - evolutionary computation
KW  - mobile robots
KW  - multi-robot systems
KW  - reconfigurable architectures
KW  - heterogeneous lattice modular robots
KW  - linear operation time cost
KW  - 2×2×2 cubic meta-module-based connected robot structure
KW  - heterogeneous modular robots
KW  - linear heterogeneous reconfiguration
KW  - cubic modular robots
KW  - ordinary heterogeneous reconfiguration
KW  - linear homogeneous transformation
KW  - linear heterogeneous permutation
KW  - simultaneous tunneling and permutation
KW  - Tunneling
KW  - Computer aided software engineering
KW  - Cameras
KW  - Robot vision systems
KW  - Robot kinematics
KW  - Lattices
DO  - 10.1109/ICRA.2019.8793594
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Reconfiguring heterogeneous modular robots in which all modules are not identical is much more time consuming than reconfiguring homogeneous ones, because ordinary heterogeneous reconfiguration is a combination of homogeneous transformation and heterogeneous permutation. While linear homogeneous transformation has been accomplished in previous research, linear heterogeneous permutation has not. This paper studies a reconfiguration algorithm for heterogeneous lattice modular robots with linear operation time cost. The algorithm is based on simultaneous tunneling and permutation, where a robot transforms its configuration via tunneling motion while permutation of each module's position is performed simultaneously during the tunneling transformation. To achieve this, we introduce the idea of a transparent meta-module that allows modules belonging to a meta-module to pass through the spaces occupied by other meta-modules. We prove the correctness and completeness of the proposed algorithm for a 2×2×2 cubic meta-module-based connected robot structure. We also show examples of the reconfiguration simulations of heterogeneous modular robots by the proposed algorithm.
ER  - 

TY  - CONF
TI  - Autonomous Sheet Pile Driving Robots for Soil Stabilization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 339
EP  - 345
AU  - N. Melenbrink
AU  - J. Werfel
PY  - 2019
KW  - construction equipment
KW  - construction industry
KW  - erosion
KW  - foundations
KW  - geotechnical engineering
KW  - hammers (machines)
KW  - mobile robots
KW  - soil
KW  - stability
KW  - autonomous sheet pile
KW  - soil stabilization
KW  - construction projects
KW  - environmental restoration projects
KW  - autonomous robot
KW  - continuous linear structures
KW  - vibratory hammer
KW  - hardware parameters
KW  - spray-based stabilizing agent
KW  - hydraulic erosion
KW  - Robots
KW  - Soil
KW  - Task analysis
KW  - Dams
KW  - Force
KW  - Actuators
KW  - Automation
DO  - 10.1109/ICRA.2019.8793546
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soil stabilization is a fundamental component of nearly all construction projects, ranging from commercial construction to environmental restoration projects. Previous work in autonomous construction has generally not considered these essential stabilization and anchoring tasks. In this work we present Romu, an autonomous robot capable of building continuous linear structures by using a vibratory hammer to drive interlocking sheet piles into soil. We report on hardware parameters and their effects on pile driving performance, and demonstrate autonomous operation in both controlled and natural environments. Finally, we present simulations in which a small swarm of robots build with sheet piles in example terrains, or apply an alternate spray-based stabilizing agent, and quantify the ability of each intervention to mitigate hydraulic erosion.
ER  - 

TY  - CONF
TI  - ModQuad-Vi: A Vision-Based Self-Assembling Modular Quadrotor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 346
EP  - 352
AU  - G. Li
AU  - B. Gabrich
AU  - D. Saldaña
AU  - J. Das
AU  - V. Kumar
AU  - M. Yim
PY  - 2019
KW  - autonomous aerial vehicles
KW  - indoor radio
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - self-assembly
KW  - relative pose estimation
KW  - local estimation
KW  - self-assembly process
KW  - external systems
KW  - ModQuad-Vi
KW  - flying modular robot
KW  - robot design
KW  - vision-based docking method
KW  - docking actions
KW  - aerial modular system
KW  - vision-based self-assembling modular quadrotor
KW  - temporary structures
KW  - indoor infrastructures
KW  - Robot kinematics
KW  - Acceleration
KW  - Rotors
KW  - Force
KW  - Trajectory
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794056
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Flying modular robots have the potential to rapidly form temporary structures. In the literature, docking actions rely on external systems and indoor infrastructures for relative pose estimation. In contrast to related work, we provide local estimation during the self-assembly process to avoid dependency on external systems. In this paper, we introduce ModQuad-Vi, a flying modular robot that is aimed to operate in outdoor environments. We propose a new robot design and vision-based docking method. Our design is based on a quadrotor platform with onboard computation and visual perception. Our control method is able to accurately align modules for docking actions. Additionally, we present the dynamics and a geometric controller for the aerial modular system. Experiments validate the vision-based docking method with successful results.
ER  - 

TY  - CONF
TI  - Robotic endoscopy system (easyEndo) with a robotic arm mountable on a conventional endoscope
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 367
EP  - 372
AU  - D. Lee
AU  - M. Hwang
AU  - D. Kwon
PY  - 2019
KW  - biological tissues
KW  - biomechanics
KW  - endoscopes
KW  - manipulators
KW  - medical robotics
KW  - tissue traction
KW  - lesion
KW  - rubber band
KW  - robotic arm
KW  - flexible endoscope
KW  - robotic manipulations
KW  - intuitive hand-held controllers
KW  - solo-endoscopy
KW  - conventional endoscope
KW  - robotic endoscopy system
KW  - Endoscopes
KW  - Manipulators
KW  - Instruments
KW  - Medical services
KW  - Cameras
KW  - Gears
DO  - 10.1109/ICRA.2019.8793626
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The use of flexible endoscope has been rising inconveniences. Steering of the distal section is not intuitive and the weight of the endoscope burdens a physical pressure on physicians who use it continuously for a long time. Also, the limited dexterity of an instrument makes therapeutic procedures more difficult, and further the unintended communications often occur during cooperation with assistants. These degrade the efficiency and thus increase the procedure time. In this paper, we propose a robotic endoscopy system (easyEndo) that can be mounted on a conventional endoscope and facilitate solo-endoscopy with two intuitive hand-held controllers. Furthermore, a robotic arm is presented that can be attached to the endoscope to assist with tissue traction. To validate the robotic endoscopy system, experiments to simulate biopsy and lesion marking were conducted with novices. The results showed that the robotic manipulations improved efficiency and reduced workload than manual manipulation. Subsequently, a prototype of the robotic arm was attached at the distal end of the endoscope, and the feasibility of tissue traction was confirmed by a simulation of pulling a rubber band.
ER  - 

TY  - CONF
TI  - Design and Fabrication of Transformable Head Structures for Endoscopic Catheters*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 373
EP  - 378
AU  - S. Kwon
AU  - S. V. Kalker
AU  - S. H. Choi
AU  - K. Kim
AU  - K. S. Park
AU  - S. Kang
AU  - C. Kim
AU  - S. C. Ryu
PY  - 2019
KW  - biomedical optical imaging
KW  - cameras
KW  - catheters
KW  - endoscopes
KW  - medical image processing
KW  - medical robotics
KW  - polymers
KW  - camera module
KW  - transformable catheter head structure
KW  - endoscopic catheter
KW  - laser micromachining
KW  - polymer catheter
KW  - Catheters
KW  - Head
KW  - Magnetic heads
KW  - Tools
KW  - Electron tubes
KW  - Polymers
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794256
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a transformable catheter head structure for endoscopic catheter allowing the simultaneous use of a camera module and a large tool channel introduced through a small incision. At the site of interest, the head with a camera can be expanded from the initial straight configuration, which opens a window for advancing a tool that is located behind the camera. Two different designs were proposed and prototyped. One option has flexure joints directly fabricated at the distal end of a polymer catheter by laser micro-machining, while another design employs a hinged metal head assembled at the tip of the same type of catheter. The kinematic behavior of each head was evaluated during the head-up and tip steering motions, and compared with each other to draw a selection guideline between them. Experimental results prove the feasibility of the proposed head structure for smarter endoscopic catheters.
ER  - 

TY  - CONF
TI  - A Rolling-Tip Flexible Instrument for Minimally Invasive Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 379
EP  - 385
AU  - A. Schmitz
AU  - S. Treratanakulchai
AU  - P. Berthet-Rayne
AU  - G. Yang
PY  - 2019
KW  - dexterous manipulators
KW  - end effectors
KW  - flexible manipulators
KW  - grippers
KW  - medical robotics
KW  - mobile robots
KW  - prototypes
KW  - surgery
KW  - rolling-tip flexible instrument
KW  - human body
KW  - end-effector
KW  - instrument prototype
KW  - in-place rolling motion
KW  - rolling-tip gripper
KW  - minimally invasive surgery
KW  - snake-like robots
KW  - tendons
KW  - 6 degrees-of-freedom
KW  - dexterity
KW  - Tendons
KW  - Instruments
KW  - Grippers
KW  - Fasteners
KW  - Surgery
KW  - End effectors
DO  - 10.1109/ICRA.2019.8793480
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Snake-like robots are commonly used in Minimally Invasive Surgery as they are able to reach areas deep inside the human body. These robots have instruments that are deployed out of the robot's head and controlled via tendons, which connect the instrument to motors at the proximal end. In most currently available systems the instruments are lacking a rolling motion of the end-effector.In this paper, we present a new instrument prototype for a snake-like robot that can perform a stable in-place rolling motion. The prototype has a diameter of 4mm, uses 13 tendons and has 6 degrees of freedom. The robot can bend and roll to high angles, and strongly improves the dexterity compared to an instrument without rolling capabilities. In the evaluation we show that the rolling-tip gripper can rotate about 165° and is capable of applying forces up to 6.5N.
ER  - 

TY  - CONF
TI  - A Novel Laser Scalpel System for Computer-assisted Laser Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 386
EP  - 392
AU  - G. Ma
AU  - W. A. Ross
AU  - I. Hill
AU  - N. Narasimhan
AU  - P. J. Codd
PY  - 2019
KW  - biomedical optical imaging
KW  - cameras
KW  - laser applications in medicine
KW  - medical computing
KW  - phantoms
KW  - radiation therapy
KW  - skin
KW  - surgery
KW  - planar phantoms
KW  - cylindrical phantoms
KW  - root-mean-square
KW  - carbon dioxide laser scalpel
KW  - laser scalpel system
KW  - 3D extrinsic calibration method
KW  - 3D triangulation sensor
KW  - superficial laser therapy applications
KW  - dermatological procedures
KW  - surgical procedures
KW  - computer-assisted laser surgery
KW  - sensor system
KW  - automated laser therapy
KW  - laser coordinate system
KW  - RGB-D camera frame
KW  - Three-dimensional displays
KW  - Lasers
KW  - Cameras
KW  - Calibration
KW  - Surgery
KW  - Measurement by laser beam
KW  - Color
DO  - 10.1109/ICRA.2019.8794066
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Laser scalpels are utilized across a variety of surgical and dermatological procedures due to their precision and non-contact nature. This paper presents a novel laser scalpel system for superficial laser therapy applications. The system integrates a RGB-D camera, a 3D triangulation sensor and a carbon dioxide (CO2) laser scalpel for computer-assisted laser surgery. To accurately ablate targets chosen from the color image, a 3D extrinsic calibration method between the RGB-D camera frame and the laser coordinate system is implemented. The accuracy of the calibration method is tested on phantoms with planar and cylindrical surfaces. Positive error and negative error, as defined as undershooting and overshooting over the target area, are reported for each test. For 60 total test cases, the root-mean-square of the positive and negative error in both planar and cylindrical phantoms is less than 1.0 mm, with a maximum absolute error less than 2.0 mm. This work demonstrates the feasibility of automated laser therapy with surgeon oversight via our sensor system.
ER  - 

TY  - CONF
TI  - Intent-Uncertainty-Aware Grasp Planning for Robust Robot Assistance in Telemanipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 409
EP  - 415
AU  - M. Bowman
AU  - S. Li
AU  - X. Zhang
PY  - 2019
KW  - dexterous manipulators
KW  - grippers
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - telerobotics
KW  - intent-uncertainty-aware grasp planning
KW  - robust robot assistance
KW  - robot agent
KW  - motion assistance
KW  - target approaching process
KW  - fine motion constraints
KW  - ambiguous human motion
KW  - robot hands
KW  - planning techniques
KW  - human motion input
KW  - multitask robot
KW  - intent-uncertainty-aware grasp planner
KW  - robust grasp
KW  - ambiguous human intent inference inputs
KW  - teleoperated robots
KW  - object manipulation task
KW  - Task analysis
KW  - Robots
KW  - Planning
KW  - Uncertainty
KW  - Handover
KW  - Grasping
DO  - 10.1109/ICRA.2019.8793819
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Promoting a robot agent's autonomy level, which allows it to understand the human operator's intent and provide motion assistance to achieve it, has demonstrated great advantages to the operator's intent in teleoperation. However, the research has been limited to the target approaching process. We advance the shared control technique one step further to deal with the more challenging object manipulation task. Appropriately manipulating an object is challenging as it requires fine motion constraints for a certain manipulation task. Although these motion constraints are critical for task success, they are subtle to observe from ambiguous human motion. The disembodiment problem and physical discrepancy between the human and robot hands bring additional uncertainty, make the object manipulation task more challenging. Moreover, there is a lack of modeling and planning techniques that can effectively combine the human motion input and robot agent's motion input while accounting for the ambiguity of the human intent. To overcome this challenge, we built a multi-task robot grasping model and developed an intent-uncertainty-aware grasp planner to generate robust grasp poses given the ambiguous human intent inference inputs. With this validated modeling and planning techniques, it is expected to extend teleoperated robots' functionality and adoption in practical telemanipulation scenarios.
ER  - 

TY  - CONF
TI  - Vision-based Teleoperation of Shadow Dexterous Hand using End-to-End Deep Neural Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 416
EP  - 422
AU  - S. Li
AU  - X. Ma
AU  - H. Liang
AU  - M. Görner
AU  - P. Ruppel
AU  - B. Fang
AU  - F. Sun
AU  - J. Zhang
PY  - 2019
KW  - dexterous manipulators
KW  - human-robot interaction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - pose estimation
KW  - robot vision
KW  - telerobotics
KW  - TeachNet
KW  - Shadow dexterous hand
KW  - end-to-end deep neural network
KW  - intuitive vision-based teleoperation
KW  - markerless vision-based teleoperation
KW  - dexterous robotic hands
KW  - robot joint angles
KW  - human hand
KW  - visually similar robot hand
KW  - consistency loss function
KW  - human hands
KW  - human-robot training set
KW  - labeled depth images
KW  - simulated depth images
KW  - Shadow C6 robotic hand
KW  - pairwise depth images
KW  - vision-based teleoperation method
KW  - Training
KW  - Pose estimation
KW  - Three-dimensional displays
KW  - Neural networks
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794277
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present TeachNet, a novel neural network architecture for intuitive and markerless vision-based teleoperation of dexterous robotic hands. Robot joint angles are directly generated from depth images of the human hand that produce visually similar robot hand poses in an end-to-end fashion. The special structure of TeachNet, combined with a consistency loss function, handles the differences in appearance and anatomy between human and robotic hands. A synchronized human-robot training set is generated from an existing dataset of labeled depth images of the human hand and simulated depth images of a robotic hand. The final training set includes 400K pairwise depth images and joint angles of a Shadow C6 robotic hand. The network evaluation results verify the superiority of TeachNet, especially regarding the high-precision condition. Imitation experiments and grasp tasks teleoperated by novice users demonstrate that TeachNet is more reliable and faster than the state-of-the-art vision-based teleoperation method.
ER  - 

TY  - CONF
TI  - An energy-shared two-layer approach for multi-master-multi-slave bilateral teleoperation systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 423
EP  - 429
AU  - M. Minelli
AU  - F. Ferraguti
AU  - N. Piccinelli
AU  - R. Muradore
AU  - C. Secchi
PY  - 2019
KW  - delay systems
KW  - medical robotics
KW  - surgery
KW  - telerobotics
KW  - energy-shared two-layer approach
KW  - multimaster-multislave bilateral teleoperation systems
KW  - two-layer architecture
KW  - multiarms systems
KW  - communication delay
KW  - energy tank
KW  - single-master-single-slave two layer approach
KW  - passivity preservation
KW  - surgical scenario
KW  - Computer architecture
KW  - Surgery
KW  - Robot kinematics
KW  - Force
KW  - Delays
KW  - Communication channels
DO  - 10.1109/ICRA.2019.8794335
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, a two-layer architecture for the bilateral teleoperation of multi-arms systems with communication delay is presented. We extend the single-master-single-slave two layer approach proposed in [1] by connecting multiple robots to a single energy tank. This allows to minimize the conservativeness due to passivity preservation and to increment the level of transparency that can be achieved. The proposed approach is implemented on a realistic surgical scenario developed within the EU-funded SARAS project.
ER  - 

TY  - CONF
TI  - Passive Task-Prioritized Shared-Control Teleoperation with Haptic Guidance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 430
EP  - 436
AU  - M. Selvaggio
AU  - P. Robuffo Giordano
AU  - F. Ficuciellol
AU  - B. Siciliano
PY  - 2019
KW  - control engineering computing
KW  - haptic interfaces
KW  - telerobotics
KW  - passive task-prioritized shared-control teleoperation
KW  - robot teleoperation
KW  - teleoperator capabilities shared-control methods
KW  - passive task-prioritized shared-control method
KW  - redundant robots
KW  - task-prioritized control architecture
KW  - haptic guidance techniques
KW  - shared-control framework
KW  - semiautonomous telerobotic system safety
KW  - energy-tanks passivity-based controller
KW  - simulated slave robot
KW  - Task analysis
KW  - Haptic interfaces
KW  - Jacobian matrices
KW  - Manipulators
KW  - Robot kinematics
KW  - Couplings
DO  - 10.1109/ICRA.2019.8794197
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot teleoperation is widely used for several hazardous applications. To increase teleoperator capabilities shared-control methods can be employed. In this paper, we present a passive task-prioritized shared-control method for remote telemanipulation of redundant robots. The proposed method fuses the task-prioritized control architecture with haptic guidance techniques to realize a shared-control framework for teleoperation systems. To preserve the semi-autonomous telerobotic system safety, passivity is analyzed and an energy-tanks passivity-based controller is developed. The proposed theoretical results are validated through experiments involving a real haptic device and a simulated slave robot.
ER  - 

TY  - CONF
TI  - Quasi-Direct Drive for Low-Cost Compliant Robotic Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 437
EP  - 443
AU  - D. V. Gealy
AU  - S. McKinley
AU  - B. Yi
AU  - P. Wu
AU  - P. R. Downey
AU  - G. Balke
AU  - A. Zhao
AU  - M. Guo
AU  - R. Thomasson
AU  - A. Sinclair
AU  - P. Cuellar
AU  - Z. McCarthy
AU  - P. Abbeel
PY  - 2019
KW  - control engineering computing
KW  - force control
KW  - manipulators
KW  - position control
KW  - telerobotics
KW  - user interfaces
KW  - virtual reality
KW  - QuasiDirect Drive actuation
KW  - robotic force-controlled manipulation
KW  - telepresence
KW  - Blue system
KW  - human environments
KW  - robot training demonstrations
KW  - 7 degree of freedom arm
KW  - position-control bandwidth
KW  - virtual reality based interface
KW  - compliant robotic manipulation
KW  - mass 2.0 kg
KW  - frequency 7.5 Hz
KW  - size 4.0 mm
KW  - Manipulators
KW  - Payloads
KW  - Bandwidth
KW  - Robot sensing systems
KW  - Task analysis
KW  - Belts
DO  - 10.1109/ICRA.2019.8794236
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots must cost less and be force-controlled to enable widespread, safe deployment in unconstrained human environments. We propose Quasi-Direct Drive actuation as a capable paradigm for robotic force-controlled manipulation in human environments at low-cost. Our prototype - Blue - is a human scale 7 Degree of Freedom arm with 2kg payload. Blue can cost less than $5000. We show that Blue has dynamic properties that meet or exceed the needs of human operators: the robot has a nominal position-control bandwidth of 7.5Hz and repeatability within 4mm. We demonstrate a Virtual Reality based interface that can be used as a method for telepresence and collecting robot training demonstrations. Manufacturability, scaling, and potential use-cases for the Blue system are also addressed. Videos and additional information can be found online at berkeleyopenarms.github.io.
ER  - 

TY  - CONF
TI  - Augmented Reality Predictive Displays to Help Mitigate the Effects of Delayed Telesurgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 444
EP  - 450
AU  - F. Richter
AU  - Y. Zhang
AU  - Y. Zhi
AU  - R. K. Orosco
AU  - M. C. Yip
PY  - 2019
KW  - augmented reality
KW  - medical computing
KW  - medical robotics
KW  - surgery
KW  - telemedicine
KW  - telerobotics
KW  - da Vinci surgical system
KW  - SARPD
KW  - augmented reality predictive displays
KW  - stereoscopic AR predictive display
KW  - predictive displays
KW  - visual feedback
KW  - teleoperated surgical robots
KW  - surgical environment
KW  - remote operator
KW  - remote telesurgery
KW  - Delays
KW  - Rendering (computer graphics)
KW  - Cameras
KW  - Stereo image processing
KW  - Real-time systems
KW  - Transforms
KW  - Robots
DO  - 10.1109/ICRA.2019.8794051
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Surgical robots offer the exciting potential for remote telesurgery, but advances are needed to make this technology efficient and accurate to ensure patient safety. Achieving these goals is hindered by the deleterious effects of latency between the remote operator and the bedside robot. Predictive displays have found success in overcoming these effects by giving the operator immediate visual feedback. However, previously developed predictive displays can not be directly applied to telesurgery due to the unique challenges in tracking the 3D geometry of the surgical environment. In this paper, we present the first predictive display for teleoperated surgical robots. The predicted display is stereoscopic, utilizes Augmented Reality (AR) to show the predicted motions alongside the complex tissue found in-situ within surgical environments, and overcomes the challenges in accurately tracking slave-tools in real-time. We call this a Stereoscopic AR Predictive Display (SARPD). To test the SARPD's performance, we conducted a user study with ten participants on the da Vinci® Surgical System. The results showed with statistical significance that using SARPD decreased time to complete task while having no effect on error rates when operating under delay.
ER  - 

TY  - CONF
TI  - Stability Optimization of Two-Fingered Anthropomorphic Hands for Precision Grasping with a Single Actuator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 451
EP  - 457
AU  - M. T. Leddy
AU  - A. M. Dollar
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - dexterous manipulators
KW  - grippers
KW  - prosthetics
KW  - link length ratios
KW  - anthropomorphic design parameters
KW  - grasp planning applications
KW  - optimal configuration
KW  - heuristically evaluated optimal solutions
KW  - post-contact system work
KW  - upper limb prosthetic design
KW  - palm width
KW  - joint stiffness ratios
KW  - transmission ratios
KW  - post-contact stability
KW  - constrained optimization framework
KW  - single actuator
KW  - precision grasping
KW  - two-fingered anthropomorphic hands
KW  - stability optimization
KW  - Force
KW  - Grasping
KW  - Actuators
KW  - Tendons
KW  - Optimization
KW  - Stability criteria
DO  - 10.1109/ICRA.2019.8793812
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a constrained optimization framework for evaluating the post-contact stability of underactuated precision grasping configurations with a single degree of actuation. Relationships between key anthropomorphic design parameters including link length ratios, transmission ratios, joint stiffness ratios and palm width are developed with applications in upper limb prosthetic design. In addition to grasp stability, we examine post-contact system work, to reduce reconfiguration, and consider the range of objects that can be stably grasped. External wrenches were simulated on a subset of the heuristically evaluated optimal solutions and an optimal configuration was experimentally tested to determine favorable wrench resistible gripper orientations for grasp planning applications.
ER  - 

TY  - CONF
TI  - A new Approach for an Adaptive Linear Quadratic Regulated Motion Cueing Algorithm for an 8 DoF Full Motion Driving Simulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 497
EP  - 503
AU  - T. Miunske
AU  - C. Holzapfel
AU  - E. Baumgartner
AU  - H. Reuss
PY  - 2019
KW  - linear quadratic control
KW  - minimisation
KW  - motion control
KW  - road vehicles
KW  - vehicle dynamics
KW  - 8 DoF full motion driving simulator
KW  - Stuttgart Driving Simulator
KW  - state-flow chart
KW  - kinematic vehicle movements
KW  - motion driving simulator
KW  - adaptive motion cueing algorithm
KW  - adaptive linear quadratic regulated motion cueing algorithm
KW  - linear quadratic error minimization
KW  - Acceleration
KW  - Switches
KW  - Vehicles
KW  - Heuristic algorithms
KW  - Vehicle dynamics
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794109
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this contribution, a new adaptive motion cueing algorithm for a full motion driving simulator at the University of Stuttgart is presented, which allows kinematic vehicle movements to be taken into account. These are adequately processed via a state-flow chart and transferred to the motion cueing algorithm in such a way that the dynamic of the Stuttgart Driving Simulator can be used much more efficiently. Furthermore, a linear quadratic error minimization of the mentioned algorithm is presented. The primary objective is to provide a more realistic driving experience to the driver.
ER  - 

TY  - CONF
TI  - Singularity of Cable-Driven Parallel Robot With Sagging Cables: Preliminary Investigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 504
EP  - 509
AU  - J. Merlet
PY  - 2019
KW  - cables (mechanical)
KW  - manipulator kinematics
KW  - cable-driven parallel robot
KW  - sagging cables
KW  - singularity analysis
KW  - CDPR
KW  - Irvine model
KW  - cable model representation singularity
KW  - singularity type
KW  - IK singularity
KW  - parallel robot singularity
KW  - inverse kinematics
KW  - forward kinematics
KW  - rigid legs
KW  - Parallel robots
KW  - Mathematical model
KW  - Kinematics
KW  - Zirconium
KW  - Legged locomotion
KW  - End effectors
KW  - parallel robot cable-driven parallel robot
KW  - singularity
DO  - 10.1109/ICRA.2019.8794218
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses for the first time the singularity analysis of cable-driven parallel robot (CDPR) with sagging cables using the Irvine model. We present the mathematical framework of singularity analysis of CDPR using this cable model. We then show that, besides a cable model representation singularity, both the inverse and forward kinematics (IK and FK) have a singularity type, called parallel robot singularity, which correspond to the singularity of an equivalent parallel robot with rigid legs. We then show that both the IK and FK have also full singularities, that are not parallel robot singularity and are obtained when two of the IK or FK solution branches intersect. IK singularity will usually lie on the border of the CDPR workspace. We then exhibit an algorithm that allow one to prove that a singularity exist in the neighborhood of a given pose and to estimate its location with an arbitrary accuracy. Examples are provided for parallel robot, IK and FK singularities. However we have not been able to determine examples of combined singularity where both the IK and FK are singular (besides parallel robot singularity).
ER  - 

TY  - CONF
TI  - A defect identification approach of operations for the driving element of multi-duty parallel manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 510
EP  - 516
AU  - S. Fan
AU  - S. Fan
AU  - W. Lan
AU  - G. Song
PY  - 2019
KW  - end effectors
KW  - fasteners
KW  - force control
KW  - industrial manipulators
KW  - machining
KW  - defect identification approach
KW  - driving element
KW  - multiduty parallel manipulators
KW  - heavy-load
KW  - 1PU+3UPS parallel manipulator
KW  - machining efficiency improvement
KW  - Force
KW  - Indexes
KW  - Machining
KW  - Fasteners
KW  - Manipulator dynamics
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794326
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In order to improve the machining efficiency and the flexibility of manufacturing system, the study of multi-duty parallel manipulators has attracted the interest of some researchers. In this paper, according to the effects of different operations on the driving element, a demarcation diagram for distinguishing different duties, such as statics, low-speed but heavy-load, high-speed but low-load and high-speed but heavy-load, is proposed, and a defect identification approach to prevent the occurrence of defects for multi-duty parallel manipulators is presented. Taking the 1PU+3UPS parallel manipulator as an instance, an analysis method to the statics and dynamics is investigated by means of the screw theory and the proposed virtual screw. Based on the numerical example, the results show that the classification and practicability of operations can be accurately identified by the proposed demarcation diagram and defect identification approach, respectively.
ER  - 

TY  - CONF
TI  - Active Damping of Parallel Robots Driven by Flexible Cables Using Cold-Gas Thrusters
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 530
EP  - 536
AU  - H. Sellet
AU  - I. Khayour
AU  - L. Cuvillon
AU  - S. Durand
AU  - J. Gangloff
PY  - 2019
KW  - cables (mechanical)
KW  - damping
KW  - flexible manipulators
KW  - manipulator dynamics
KW  - supersonic flow
KW  - planar robot
KW  - custom-built supersonic air thrusters
KW  - active damping
KW  - cold-gas thrusters
KW  - flexible cable-driven parallel robots
KW  - industry-standard pressure level
KW  - Attitude control
KW  - Vibrations
KW  - End effectors
KW  - Valves
KW  - Damping
KW  - Bars
DO  - 10.1109/ICRA.2019.8794061
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work is a preliminary study assessing the feasibility of using cold-gas thrusters for active damping of flexible cable-driven parallel robots. The concept is validated experimentally on a planar robot embedding custom-built supersonic air thrusters operating at an industry-standard pressure level.
ER  - 

TY  - CONF
TI  - Exploiting Human and Robot Muscle Synergies for Human-in-the-loop Optimization of EMG-based Assistive Strategies
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 549
EP  - 555
AU  - M. Hamaya
AU  - T. Matsubara
AU  - J. Furukawa
AU  - Y. Sun
AU  - S. Yagi
AU  - T. Teramae
AU  - T. Noda
AU  - J. Morimoto
PY  - 2019
KW  - artificial limbs
KW  - biomechanics
KW  - electromyography
KW  - medical robotics
KW  - motion control
KW  - optimisation
KW  - robot muscle synergies
KW  - EMG-based assistive strategies
KW  - exoskeleton robot control
KW  - Electromyography-based assistive strategies
KW  - multiple EMG channels
KW  - multiDoF robots
KW  - optimization process
KW  - human muscles
KW  - pneumatic artificial muscle contractions
KW  - Bayesian optimization method
KW  - human movements
KW  - PAMs-driven upper-limb exoskeleton robot
KW  - human-in-theloop optimization
KW  - human-in-the-loop optimization approach
KW  - Muscles
KW  - Robots
KW  - Optimization
KW  - Exoskeletons
KW  - Electromyography
KW  - Bayes methods
KW  - Pneumatic systems
DO  - 10.1109/ICRA.2019.8794082
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this study, we propose a novel human-in-the-loop optimization approach for exoskeleton robot control. We develop a method to optimize widely-used Electromyography (EMG)-based assistive strategies. If we use multiple EMG channels to control multi-DoF robots, optimization process becomes complex and requires a large amount of data. To make the optimization tractable, we exploit the synergies both of the human muscles and artificial muscles of the exoskeleton robots to reduce the number of parameters of the assistive strategies. We show that we can extract the synergies not only from the user's muscle activities but from pneumatic artificial muscle (PAMs) contractions of the exoskeleton robot. Then, we adopt a Bayesian optimization method to acquire the parameters for assisting human movements by iteratively identifying the user's preferences of the assistive strategies. We conducted experiments to evaluate our proposed method with a PAMs-driven upper-limb exoskeleton robot. Our method successfully learned assistive strategies from the human-in-theloop optimization with a practicable number of interactions.
ER  - 

TY  - CONF
TI  - Development of a Low Inertia Parallel Actuated Shoulder Exoskeleton Robot for the Characterization of Neuromuscular Property during Static Posture and Dynamic Movement
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 556
EP  - 562
AU  - J. Hunt
AU  - H. Lee
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - human-robot interaction
KW  - manipulator kinematics
KW  - medical robotics
KW  - patient rehabilitation
KW  - low inertia parallel actuated shoulder exoskeleton robot
KW  - neuromuscular property
KW  - dynamic movement
KW  - intrinsic mechanisms
KW  - reflexive mechanisms
KW  - voluntary mechanism
KW  - shoulder control
KW  - upper limb performance
KW  - physical human-robot interaction
KW  - spherical parallel manipulator
KW  - control roll
KW  - parallel architecture
KW  - speed requirement
KW  - 4B-SPM exoskeleton
KW  - neuromuscular mechanisms
KW  - shoulder joint
KW  - neuromuscular properties
KW  - Shoulder
KW  - Exoskeletons
KW  - Servomotors
KW  - Robots
KW  - Neuromuscular
KW  - Prototypes
KW  - Impedance
DO  - 10.1109/ICRA.2019.8794181
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The purpose of this work is to introduce a newly developed exoskeleton robot designed to characterize the neuromuscular properties of the shoulder, including intrinsic and reflexive mechanisms, during static posture and dynamic movement in a 3-dimensional space. Quantitative characterization of these properties requires fast perturbation (>100°/s) to separate their contribution from that of voluntary mechanism. Understanding these properties of the shoulder control could assist in the rehabilitation or enhancement of upper limb performance during physical human-robot interaction. The device can be described as a new type of spherical parallel manipulator (SPM) that utilizes three 4-bar (4B) substructures to decouple and control roll, pitch and yaw of the shoulder. By utilizing a parallel architecture, the 4BSPM exoskeleton has the advantage of high acceleration, fast enough to satisfy the speed requirement for the characterization of distinct neuromuscular properties of the shoulder. In this work, the prototype is presented, along with an evaluation of its position accuracy and step response. The development and preliminary testing of the 4B-SPM exoskeleton presented in this work demonstrates its potential to be a useful tool for studying the neuromuscular mechanisms of the shoulder joint.
ER  - 

TY  - CONF
TI  - Effort Estimation in Robot-aided Training with a Neural Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 563
EP  - 569
AU  - A. C. d. Oliveira
AU  - K. Warburton
AU  - J. S. Sulzer
AU  - A. D. Deshpande
PY  - 2019
KW  - biomechanics
KW  - medical robotics
KW  - motion control
KW  - muscle
KW  - neurocontrollers
KW  - patient rehabilitation
KW  - patient treatment
KW  - robot dynamics
KW  - robot kinematics
KW  - robust control
KW  - torque control
KW  - wearable robots
KW  - effort estimation
KW  - robot-aided training
KW  - neural network
KW  - robotic exoskeletons
KW  - post-stroke rehabilitation
KW  - sensorimotor impairments
KW  - variable assistance
KW  - movement execution
KW  - movement quality
KW  - individualized treatment
KW  - kinematic guidance
KW  - robotic assistance
KW  - voluntary effort
KW  - active torques
KW  - unmodeled dynamics
KW  - passive neuromuscular properties
KW  - involuntary forces
KW  - muscle activity
KW  - high resolution assessment tool
KW  - therapy tasks
KW  - robustness
KW  - Harmony upper-body exoskeleton
KW  - motor recovery evaluation
KW  - Robot sensing systems
KW  - Torque
KW  - Shoulder
KW  - Muscles
KW  - Exoskeletons
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794281
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic exoskeletons open up promising interventions during post-stroke rehabilitation by assisting individuals with sensorimotor impairments to complete therapy tasks. These devices have the ability to provide variable assistance tailored to individual-specific needs and, additionally, can measure several parameters associated with the movement execution. Metrics representative of movement quality are important to guide individualized treatment. While robots can provide data with high resolution, robustness, and consistency, the delineation of the human contribution in the presence of the kinematic guidance introduced by the robotic assistance is a significant challenge. In this paper, we propose a method for assessing voluntary effort from an individual fitted in an upper-body exoskeleton called Harmony. The method separates the active torques generated by the wearer from the effects caused by unmodeled dynamics and passive neuromuscular properties and involuntary forces. Preliminary results show that the effort estimated using the proposed method is consistent with the effort associated with muscle activity and is also sensitive to different levels, indicating that it can reliably evaluate user's contribution to movement. This method has the potential to serve as a high resolution assessment tool to monitor progress of movement quality throughout the treatment and evaluate motor recovery.
ER  - 

TY  - CONF
TI  - Characterizing Architectures of Soft Pneumatic Actuators for a Cable-Driven Shoulder Exoskeleton
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 570
EP  - 576
AU  - N. Thompson
AU  - A. Sinha
AU  - G. Krishnan
PY  - 2019
KW  - biomechanics
KW  - cables (mechanical)
KW  - elastomers
KW  - medical robotics
KW  - patient rehabilitation
KW  - pneumatic actuators
KW  - wearable robots
KW  - architectures characterization
KW  - wearable robots
KW  - fiber-reinforced elastomeric enclosures
KW  - FREEs
KW  - shoulder flexion
KW  - force-displacement curves
KW  - cable anchor movement
KW  - Bowden cables
KW  - nested linear architecture
KW  - pennate architectures
KW  - cable-driven shoulder exoskeleton
KW  - soft pneumatic actuators
KW  - Shoulder
KW  - Actuators
KW  - Force
KW  - Exoskeletons
KW  - Cable shielding
KW  - Torque
KW  - Prototypes
DO  - 10.1109/ICRA.2019.8793707
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Low weight and innate compliance make soft pneumatic actuators an attractive method for actuating wearable robots. Performance of soft pneumatic actuators can be tailored to an application by combining them in novel architectures. We modeled and constructed nested linear and pennate architectures using fiber-reinforced elastomeric enclosures (FREEs) with identical manufacturing parameters and total effective lengths to compare their suitability for a cable-driven exoskeleton for augmenting shoulder flexion. We determined actuator performance requirements using a static model for the transmission of actuator forces to the upper arm via Bowden cables. We experimentally characterized the architectures by measuring their force-displacement curves at a range of pressures, yielding greater force and displacement from the nested architecture in the domain required by our exoskeleton. Results also indicated a force threshold above which the pennate structure produced greater force at any given displacement. We validated the nested linear architecture using a prototype exoskeleton installed on a passive mannequin. Measured joint angles at varying pressures were close to predicted values, adjusted for measured losses due to cable anchor movement.
ER  - 

TY  - CONF
TI  - Design and Implementation of a Two-DOF Robotic System with an Adjustable Force Limiting Mechanism for Ankle Rehabilitation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 577
EP  - 583
AU  - V. Mehrabi
AU  - S. F. Atashzar
AU  - H. A. Talebi
AU  - R. V. Patel
PY  - 2019
KW  - end effectors
KW  - friction
KW  - manipulator dynamics
KW  - medical robotics
KW  - mobile robots
KW  - patient rehabilitation
KW  - patient treatment
KW  - lower-limb rehabilitation robot
KW  - mechanical adjustment
KW  - design procedure
KW  - adjustable force limiting mechanism
KW  - light-weight back-drivable inherently-safe robotic mechanism
KW  - ankle rehabilitation therapies
KW  - ankle module
KW  - mathematical modeling
KW  - experimental validations
KW  - two-DOF robotic system
KW  - friction-based safety feature
KW  - Robots
KW  - Wheels
KW  - Force
KW  - Torque
KW  - Medical treatment
KW  - Safety
KW  - Training
DO  - 10.1109/ICRA.2019.8794028
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel light-weight back-drivable inherently-safe robotic mechanism for delivering ankle rehabilitation therapies. The robot is designed to be used as the ankle module of a multi-purpose lower-limb rehabilitation robot. A novel friction-based safety feature has been introduced that enables mechanical adjustment of the maximum amount of allowable transfer forces and torques to the patient's limb. The design procedure, mathematical modeling and experimental validations are provided to demonstrate the performance of the proposed system.
ER  - 

TY  - CONF
TI  - Rorg: Service Robot Software Management with Linux Containers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 584
EP  - 590
AU  - S. Wang
AU  - X. Liu
AU  - J. Zhao
AU  - H. I. Christensen
PY  - 2019
KW  - cloud computing
KW  - control engineering computing
KW  - Linux
KW  - mobile robots
KW  - object-oriented programming
KW  - scheduling
KW  - service robots
KW  - Linux container-based scheme
KW  - monitor software components
KW  - service robots
KW  - Linux containers
KW  - service robot systems
KW  - resource constraints
KW  - programmable container management interface
KW  - resource time-sharing mechanism
KW  - Rorg
KW  - resource contention
KW  - long-term autonomous tour guide robot
KW  - robot software system
KW  - software processes
KW  - software components
KW  - computer resources
KW  - service robot software management
KW  - robot operating system
KW  - Containers
KW  - Software
KW  - Linux
KW  - Service robots
KW  - Data centers
KW  - Monitoring
DO  - 10.1109/ICRA.2019.8793764
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Scaling up the software system on service robots increases the maintenance burden of developers and the risk of resource contention of the computer embedded on robots. As a result, developers spend much time on configuring, deploying, and monitoring the robot software system; robots may utilize significant computer resources when all software processes are running. We present Rorg, a Linux container-based scheme to manage, schedule, and monitor software components on service robots. Although Linux containers are already widely-used in cloud environments, this technique is challenging to efficiently adopt in service robot systems due to multi-tasking, resource constraints and performance requirements. To pave the way of Linux containers on service robots in an efficient manner, we present a programmable container management interface and a resource time-sharing mechanism incorporated with the Robot Operating System (ROS). Rorg allows developers to pack software into self-contained images and runs them in isolated environments using Linux containers; it also allows the robot to turn on and off software components on demand to avoid resource contention. We evaluate Rorg with a long-term autonomous tour guide robot: It manages 41 software components on the robot and relieved our maintenance burden, and it also reduces CPU load by 45.5% and memory usage by 16.5% on average.
ER  - 

TY  - CONF
TI  - CartesI/O: A ROS Based Real-Time Capable Cartesian Control Framework
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 591
EP  - 596
AU  - A. Laurenzi
AU  - E. M. Hoffman
AU  - L. Muratore
AU  - N. G. Tsagarakis
PY  - 2019
KW  - control engineering computing
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - robot kinematics
KW  - telerobotics
KW  - robotics platforms
KW  - simple auto-generated ROS-based interface
KW  - motion control frameworks
KW  - ROS MoveIt
KW  - Cartesian trajectories
KW  - locomotion tasks
KW  - COMAN + humanoid robot
KW  - redundant robots
KW  - motion tasks
KW  - multilegged highly redundant robots
KW  - Cartesian control framework
KW  - Task analysis
KW  - Robot kinematics
KW  - Real-time systems
KW  - Libraries
KW  - C++ languages
KW  - Planning
DO  - 10.1109/ICRA.2019.8794464
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work introduces a framework for the Cartesian control of multi-legged, highly redundant robots. The proposed framework allows the untrained user to perform complex motion tasks with robotics platforms by leveraging a simple, auto-generated ROS-based interface. Contrary to other motion control frameworks (e.g. ROS MoveIt!), we focus on the execution of Cartesian trajectories that are specified online, rather than planned in advance, as it is the case, for instance, in tele-operation and locomotion tasks. Moreover, we address the problem of generating such motions within a hard real-time (RT) control loop. Finally, we demonstrate the capabilities of our framework both on the COMAN + humanoid robot, and on the hybrid wheeled-legged quadruped CENTAURO.
ER  - 

TY  - CONF
TI  - Synthesis of Real-Time Observers from Past-Time Linear Temporal Logic and Timed Specification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 597
EP  - 603
AU  - C. Lesire
AU  - S. Roussel
AU  - D. Doose
AU  - C. Grand
PY  - 2019
KW  - fault tolerant control
KW  - mobile robots
KW  - observers
KW  - specification languages
KW  - temporal logic
KW  - timed specification
KW  - fault-tolerant architectures
KW  - autonomous robots
KW  - robot developers
KW  - specification language
KW  - real-time evaluation
KW  - real-time observers
KW  - past-time linear temporal logic
KW  - past-time LTL
KW  - software components
KW  - mission patrolling
KW  - Observers
KW  - Monitoring
KW  - Real-time systems
KW  - Robot sensing systems
KW  - Timing
KW  - Safety
DO  - 10.1109/ICRA.2019.8793754
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fault-tolerant architectures are mandatory to ensure the robustness of autonomous robots performing missions in complex and uncertain environments. The first step of a fault-tolerant mechanism is the detection of a faulty behavior of the system. It is then important to provide tools to help robot developers specify relevant observers. It is moreover crucial to guarantee a correct implementation of the observers, i.e. that the observers do not miss data and do not trigger unsuitable recovery actions in case of false detection. In this paper, we propose a specification language for observers that uses Past-Time LTL to express complex formulas on data produced by software components, and timed constraints on the evaluations of these formulas. We moreover provide an implementation of this specification that guarantees a real-time evaluation of the observers. We briefly describe the observers we have specified for a patrolling mission, and we evaluate the performance of our approach compared to state of the art on a benchmark in which we detect errors on a laser range sensor.
ER  - 

TY  - CONF
TI  - Julia for robotics: simulation and real-time control in a high-level programming language
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 604
EP  - 611
AU  - T. Koolen
AU  - R. Deits
PY  - 2019
KW  - computer simulation
KW  - control engineering computing
KW  - high level languages
KW  - humanoid robots
KW  - programming languages
KW  - quadratic programming
KW  - robot dynamics
KW  - robot programming
KW  - real-time control
KW  - high-level programming language
KW  - robotics applications
KW  - two-language problem
KW  - performance-sensitive components
KW  - high-level language
KW  - software complexity
KW  - Julia programming language
KW  - online control
KW  - Julia packages
KW  - Boston Dynamics Atlas humanoid robot
KW  - quadratic-programming-based controller
KW  - Robots
KW  - Libraries
KW  - Software packages
KW  - C++ languages
KW  - Productivity
KW  - Resource management
DO  - 10.1109/ICRA.2019.8793875
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotics applications often suffer from the `two-language problem', requiring a low-level language for performance-sensitive components and a high-level language for interactivity and experimentation, which tends to increase software complexity. We demonstrate the use of the Julia programming language to solve this problem by being fast enough for online control of a humanoid robot and flexible enough for prototyping. We present several Julia packages developed by the authors, which together enable roughly 2× realtime simulation of the Boston Dynamics Atlas humanoid robot balancing on flat ground using a quadratic-programming-based controller. Benchmarks show a sufficiently low variation in control frequency to make deployment on the physical robot feasible. We also show that Julia's naturally generic programming style results in versatile packages that are easy to compose and adapt to a wide variety of computational tasks in robotics.
ER  - 

TY  - CONF
TI  - Motion Planning Templates: A Motion Planning Framework for Robots with Low-power CPUs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 612
EP  - 618
AU  - J. Ichnowski
AU  - R. Alterovitz
PY  - 2019
KW  - control engineering computing
KW  - data structures
KW  - graph theory
KW  - humanoid robots
KW  - mobile robots
KW  - path planning
KW  - low-power CPU
KW  - template-based library
KW  - compile-time polymorphism
KW  - robot-specific motion planning code
KW  - robot software
KW  - motion planning problem
KW  - general motion planning implementations
KW  - motion planning graph
KW  - compile-time algorithms
KW  - motion planning scenarios
KW  - humanoid robot
KW  - 3D rigid-body motions
KW  - motion planning framework
KW  - MPT
KW  - motion planning templates
KW  - Planning
KW  - Runtime
KW  - C++ languages
KW  - Libraries
KW  - Data structures
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8794099
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Motion Planning Templates (MPT) is a C++ template-based library that uses compile-time polymorphism to generate robot-specific motion planning code and is geared towards eking out as much performance as possible when running on the low-power CPU of a battery-powered small robot. To use MPT, developers of robot software write or leverage code specific to their robot platform and motion planning problem, and then have MPT generate a robot-specific motion planner and its associated data-structures. The resulting motion planner implementation is faster and uses less memory than general motion planning implementations based upon runtime polymorphism. While MPT loses runtime flexibility, it gains advantages associated with compile-time polymorphism- including the ability to change scalar precision, generate tightly-packed data structures, and store robot-specific data in the motion planning graph. MPT also uses compile-time algorithms to resolve the algorithm implementation, and select the best nearest neighbor algorithm to integrate into it. We demonstrate MPT's performance, lower memory footprint, and ability to adapt to varying robots in motion planning scenarios on a small humanoid robot and on 3D rigid-body motions.
ER  - 

TY  - CONF
TI  - Distortion-free Robotic Surface-drawing using Conformal Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 627
EP  - 633
AU  - D. Song
AU  - Y. J. Kim
PY  - 2019
KW  - computational geometry
KW  - computer graphics
KW  - conformal mapping
KW  - distance measurement
KW  - image reconstruction
KW  - least squares approximations
KW  - manipulators
KW  - mobile robots
KW  - solid modelling
KW  - distortion-free robotic surface-drawing
KW  - robotic pen-drawing system
KW  - unknown surface
KW  - robotic system
KW  - seven-degree-of freedom manipulator
KW  - continuous surface
KW  - physical canvas surface
KW  - point-cloud estimation
KW  - drawing surface
KW  - 2D vector pen art
KW  - surface parameterization
KW  - squares conformal mapping
KW  - complicated pen drawings
KW  - general surfaces
KW  - impedance-control
KW  - digital drawing
KW  - 2D drawing
KW  - Surface impedance
KW  - Three-dimensional displays
KW  - Robot kinematics
KW  - Two dimensional displays
KW  - Service robots
KW  - Surface reconstruction
DO  - 10.1109/ICRA.2019.8794034
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a robotic pen-drawing system that is capable of faithfully reproducing pen art on an unknown surface. Our robotic system relies on an industrial, seven-degree-of freedom manipulator that can be both position- and impedance-controlled. In order to estimate a rough geometry of the target, continuous surface, we first generate a point cloud of the surface using an RGB-D camera, which is filtered to remove outliers and calibrated to the physical canvas surface. Then, our control algorithm physically reproduces digital drawing on the surface by impedance-controlling the manipulator. Our impedance-controlled drawing algorithm compensates for the uncertainty and incompleteness inherent to a point-cloud estimation of the drawing surface. Moreover, since drawing 2D vector pen art on a 3D surface requires surface parameterization that does not destroy the original 2D drawing, we rely on the least squares conformal mapping. Specifically, the conformal map reduces angle distortion during surface parameterization. As a result, our system can create distortion-free and complicated pen drawings on general surfaces with many unpredictable bumps robustly and faithfully.
ER  - 

TY  - CONF
TI  - Automated Cell Patterning System with a Microchip using Dielectrophoresis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 634
EP  - 639
AU  - K. Huang
AU  - H. K. Chu
AU  - B. Lu
AU  - J. Lai
AU  - L. Cheng
PY  - 2019
KW  - bioelectric phenomena
KW  - biological techniques
KW  - cellular biophysics
KW  - electrophoresis
KW  - lab-on-a-chip
KW  - microorganisms
KW  - dielectrophoresis
KW  - automatic method
KW  - 6-aminohexanoic acid
KW  - yeast cells
KW  - cell-printing microchip
KW  - large-scale cell patterns
KW  - cell-based assay
KW  - patterning cells
KW  - automated cell patterning system
KW  - Integrated circuits
KW  - Substrates
KW  - Electrodes
KW  - Microscopy
KW  - Force
KW  - Lenses
KW  - Glass
DO  - 10.1109/ICRA.2019.8794177
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to patterning cells is an important technique to facilitate cell-based assay and characterization. In this paper, an automated cell patterning system was developed for the fabrication of large-scale cell patterns. To resolve the challenge of the limited printable area, the cell-printing microchip and the substrate were mounted on the movable stages of the system, and large-scale cell patterns were realized through coordination between the stages. An autofocusing technique was integrated in the system to evaluate the gap between the microchip and the substrate. In order to enhance the performance of the patterning system, different experimental parameters, including the velocity of the moving stage, were examined. Yeast cells suspending in 6-aminohexanoic acid (AHA) solution were considered in this study, and a sequence of characters was successfully printed using the proposed system. The results confirm that this system offers an automatic method with high flexibility to construct large-scale cell patterns for various applications.
ER  - 

TY  - CONF
TI  - Mobile Robotic Painting of Texture
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 640
EP  - 647
AU  - M. E. Helou
AU  - S. Mandt
AU  - A. Krause
AU  - P. Beardsley
PY  - 2019
KW  - image colour analysis
KW  - image reconstruction
KW  - image texture
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - painting
KW  - spraying
KW  - mobile robotic painting
KW  - mobile robots
KW  - robotic paint delivery systems
KW  - spray painting
KW  - painting tasks
KW  - image texture
KW  - robotic paint commands
KW  - deep learning approach
KW  - appearance reconstruction
KW  - Painting
KW  - Robots
KW  - Paints
KW  - Ink
KW  - Atmospheric modeling
KW  - Spraying
DO  - 10.1109/ICRA.2019.8793947
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic painting is well-established in controlled factory environments, but there is now potential for mobile robots to do functional painting tasks around the everyday world. An obvious first target for such robots is painting a uniform single color. A step further is the painting of textured images. Texture involves a varying appearance, and requires that paint is delivered accurately onto the physical surface to produce the desired effect. Robotic painting of texture is relevant for architecture and in themed environments. A key challenge for robotic painting of texture is to take a desired image as input, and to generate the paint commands to as closely as possible create the desired appearance, according to the robotic capabilities. This paper describes a deep learning approach to take an input ink map of a desired texture, and infer robotic paint commands to produce that texture. We analyze the trade-offs between quality of reconstructed appearance and ease of execution. Our method is general for different kinds of robotic paint delivery systems, but the emphasis here is on spray painting. More generally, the framework can be viewed as an approach for solving a specific class of inverse imaging problems.
ER  - 

TY  - CONF
TI  - Detecting Invasive Insects with Unmanned Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 648
EP  - 654
AU  - B. Stumph
AU  - M. H. Virto
AU  - H. Medeiros
AU  - A. Tabb
AU  - S. Wolford
AU  - K. Rice
AU  - T. Leskey
PY  - 2019
KW  - agriculture
KW  - autonomous aerial vehicles
KW  - cameras
KW  - computer vision
KW  - mobile robots
KW  - pest control
KW  - robot vision
KW  - mark-release-recapture technique
KW  - invasive insect species migration patterns
KW  - unmanned aerial vehicles
KW  - computer vision algorithms
KW  - invasive insects detection
KW  - agriculture
KW  - Insects
KW  - Cameras
KW  - Unmanned aerial vehicles
KW  - Image color analysis
KW  - Data acquisition
KW  - Pipelines
KW  - Agriculture
DO  - 10.1109/ICRA.2019.8794116
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A key aspect to controlling and reducing the effects invasive insect species have on agriculture is to obtain knowledge about the migration patterns of these species. Current state-of-the-art methods of studying these migration patterns involve a mark-release-recapture technique, in which insects are released after being marked and researchers attempt to recapture them later. However, this approach involves a human researcher manually searching for these insects in large fields and results in very low recapture rates. In this paper, we propose an automated system for detecting released insects using an unmanned aerial vehicle. This system utilizes ultraviolet lighting technology, digital cameras, and lightweight computer vision algorithms to more quickly and accurately detect insects compared to the current state of the art. The efficiency and accuracy that this system provides will allow for a more comprehensive understanding of invasive insect species migration patterns. Our experimental results demonstrate that our system can detect real target insects in field conditions with high precision and recall rates.
ER  - 

TY  - CONF
TI  - Robust Object-based SLAM for High-speed Autonomous Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 669
EP  - 675
AU  - K. Ok
AU  - K. Liu
AU  - K. Frey
AU  - J. P. How
AU  - N. Roy
PY  - 2019
KW  - cameras
KW  - helicopters
KW  - image sequences
KW  - image texture
KW  - mobile robots
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - ROSHAN
KW  - object-level mapping
KW  - ellipsoid-based SLAM
KW  - object surface
KW  - autonomous quadrotor
KW  - bounding box detections
KW  - median shape error
KW  - forward-moving camera sequence
KW  - planar constraint
KW  - vehicle motions
KW  - semantic knowledge
KW  - robust object-based SLAM for high-speed autonomous navigation
KW  - Ellipsoids
KW  - Image edge detection
KW  - Semantics
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Shape
KW  - Shape measurement
DO  - 10.1109/ICRA.2019.8794344
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present Robust Object-based SLAM for High-speed Autonomous Navigation (ROSHAN), a novel approach to object-level mapping suitable for autonomous navigation. In ROSHAN, we represent objects as ellipsoids and infer their parameters using three sources of information - bounding box detections, image texture, and semantic knowledge - to overcome the observability problem in ellipsoid-based SLAM under common forward-translating vehicle motions. Each bounding box provides four planar constraints on an object surface and we add a fifth planar constraint using the texture on the objects along with a semantic prior on the shape of ellipsoids. We demonstrate ROSHAN in simulation where we outperform the baseline, reducing the median shape error by 83% and the median position error by 72% in a forward-moving camera sequence. We demonstrate similar qualitative result on data collected on a fast-moving autonomous quadrotor.
ER  - 

TY  - CONF
TI  - A Fault Diagnosis Framework for MAVLink-Enabled UAVs Using Structural Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 676
EP  - 682
AU  - G. Zogopoulos-Papaliakos
AU  - M. Logothetis
AU  - K. J. Kyriakopoulos
PY  - 2019
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - fault diagnosis
KW  - telemetry
KW  - MAVLink-enabled UAVs
KW  - fixed-wing UAVs
KW  - MAVLink telemetry streams
KW  - residual generators
KW  - observable faults
KW  - FDI system
KW  - isolability analyses
KW  - real-life telemetry log
KW  - UAV crash
KW  - fault diagnosis framework
KW  - structural analysis
KW  - message protocol
KW  - unmanned aerial vehicles
KW  - fault detection and isolation framework
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Generators
KW  - Fault diagnosis
KW  - Telemetry
KW  - Batteries
KW  - Unmanned aerial vehicles
DO  - 10.1109/ICRA.2019.8793760
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - MAVLink is a popular message protocol for small Unmanned Aerial Vehicles (UAVs). In this work, we present a Fault Detection and Isolation (FDI) framework for fixed-wing UAVs which takes advantage of the information conveyed in MAVLink telemetry streams and produces a bank of residual generators. Structural Analysis is employed to systematically handle the varying set of available measurements, identify the observable faults and adjust the FDI system accordingly. Structural detectability and isolability analyses are carried out. A case-study on a real-life telemetry log of a UAV crash demonstrates the efficacy of the proposed approach.
ER  - 

TY  - CONF
TI  - Real-Time Minimum Snap Trajectory Generation for Quadcopters: Algorithm Speed-up Through Machine Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 683
EP  - 689
AU  - M. M. d. Almeida
AU  - R. Moghe
AU  - M. Akella
PY  - 2019
KW  - computational complexity
KW  - control engineering computing
KW  - gradient methods
KW  - helicopters
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - trajectory control
KW  - human-machine interface
KW  - gradient descent method
KW  - supervised neural network
KW  - computational time
KW  - machine learning
KW  - quadcopter
KW  - iterative methods
KW  - real-time minimum snap trajectory generation
KW  - smart-tablet interface
KW  - Trajectory
KW  - Resource management
KW  - Real-time systems
KW  - Neural networks
KW  - Acceleration
KW  - Quadratic programming
KW  - Nonlinear optics
DO  - 10.1109/ICRA.2019.8793569
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of generating quadcopter minimum snap trajectories for real time applications. Previous efforts addressed this problem by either employing a gradient descent method, or by greatly sacrificing optimality for faster solutions that are amenable for onboard implementation. In this work, outputs of the gradient descent method are used offline to train a supervised neural network. We show that the use of neural networks results typically in two orders of magnitude reduction in computational time. Our proposed approach can be used for warm-starting onboard implementable iterative methods with an “educated ” initial guess. This work is motivated by the application for human-machine interface in which a human provides desired trajectory through a smart-tablet interface, which has to be translated into a dynamically feasible trajectory for a quadcopter. The proposed solution is tested in thousands of different examples, demonstrating its effectiveness as a booster for minimum snap trajectory generation for quadcopters.
ER  - 

TY  - CONF
TI  - Beauty and the Beast: Optimal Methods Meet Learning for Drone Racing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 690
EP  - 696
AU  - E. Kaufmann
AU  - M. Gehrig
AU  - P. Foehn
AU  - R. Ranftl
AU  - A. Dosovitskiy
AU  - V. Koltun
AU  - D. Scaramuzza
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - Kalman filters
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - optimisation
KW  - predictive control
KW  - state estimation
KW  - robust flight
KW  - previously-unseen race tracks
KW  - optimal methods
KW  - fast maneuvers
KW  - agile maneuvers
KW  - dynamic environments
KW  - imperfect sensing
KW  - state estimation drift
KW  - human pilots
KW  - unseen track
KW  - practice runs
KW  - state-of-the-art autonomous navigation algorithms
KW  - precise metric map
KW  - training data
KW  - unseen environment
KW  - precise map
KW  - expensive data collection
KW  - global track layout
KW  - coarse gate locations
KW  - single demonstration flight
KW  - convolutional network
KW  - closest gates
KW  - extended Kalman filter
KW  - maximum-a-posteriori estimates
KW  - high-variance estimates
KW  - poor observability
KW  - visible gates
KW  - estimated gate poses
KW  - model predictive control
KW  - agile flight
KW  - autonomous microaerial vehicles
KW  - autonomous drone racing
KW  - IROS 2018 autonomous drone race competition
KW  - Logic gates
KW  - Drones
KW  - Navigation
KW  - Training data
KW  - Current measurement
KW  - Layout
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793631
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous micro aerial vehicles still struggle with fast and agile maneuvers, dynamic environments, imperfect sensing, and state estimation drift. Autonomous drone racing brings these challenges to the fore. Human pilots can fly a previously unseen track after a handful of practice runs. In contrast, state-of-the-art autonomous navigation algorithms require either a precise metric map of the environment or a large amount of training data collected in the track of interest. To bridge this gap, we propose an approach that can fly a new track in a previously unseen environment without a precise map or expensive data collection. Our approach represents the global track layout with coarse gate locations, which can be easily estimated from a single demonstration flight. At test time, a convolutional network predicts the poses of the closest gates along with their uncertainty. These predictions are incorporated by an extended Kalman filter to maintain optimal maximum-a-posteriori estimates of gate locations. This allows the framework to cope with misleading high-variance estimates that could stem from poor observability or lack of visible gates. Given the estimated gate poses, we use model predictive control to quickly and accurately navigate through the track. We conduct extensive experiments in the physical world, demonstrating agile and robust flight through complex and diverse previously-unseen race tracks. The presented approach was used to win the IROS 2018 Autonomous Drone Race Competition, outracing the second-placing team by a factor of two.
ER  - 

TY  - CONF
TI  - Detection and Reconstruction of Wires Using Cameras for Aircraft Safety Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 697
EP  - 703
AU  - A. Stambler
AU  - G. Sherwin
AU  - P. Rowe
PY  - 2019
KW  - aerospace computing
KW  - aerospace safety
KW  - aircraft
KW  - convolutional neural nets
KW  - feature extraction
KW  - hazards
KW  - image reconstruction
KW  - image segmentation
KW  - neural net architecture
KW  - object detection
KW  - real-time systems
KW  - cameras
KW  - aircraft safety systems
KW  - free hanging wires
KW  - wire obstacles
KW  - neural network architecture
KW  - Deep Wire CNN
KW  - wire line segments
KW  - wire reconstruction
KW  - real-time detections
KW  - wire hazards
KW  - wire detection
KW  - Wires
KW  - Image reconstruction
KW  - Cameras
KW  - Detectors
KW  - Image resolution
KW  - Agriculture
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793526
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We extend the ability of cameras to perceive obstacles for aircraft safety systems by enabling 3d sensing of free hanging wires. Our algorithm exploits the specialized 2d and 3d structure of wires to exceed state of the art performance in 2d sensing and 3d location estimation of wire obstacles. In 2d, a new neural network architecture, Deep Wire CNN, directly predicts the location of wire line segments in the image. In 3d, the detections are tracked and triangulated as the aircraft flies in order to estimate the wire's location. Our triangulation uses a new formulation of wire reconstruction as the estimation of the wire's vertical plane. Together these advancements enable real-time detections of wire hazards at ranges of over 1km. The system performance is evaluated on prior image level wire detection datasets and we introduce a new public dataset in order to evaluate full system results on over 40 approaches to power lines from a manned helicopter.
ER  - 

TY  - CONF
TI  - Pose and Posture Estimation of Aerial Skeleton Systems for Outdoor Flying
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 704
EP  - 710
AU  - S. Park
AU  - Y. Lee
AU  - J. Heo
AU  - D. Lee
PY  - 2019
KW  - Kalman filters
KW  - pose estimation
KW  - satellite navigation
KW  - outdoor flying
KW  - posture estimation framework
KW  - system modular
KW  - GNSS module
KW  - global navigation satellite system
KW  - EKF estimates
KW  - three-link aerial skeleton system
KW  - inertial measurement unit
KW  - extended Kalman filtering
KW  - Skeleton
KW  - Estimation
KW  - Kinematics
KW  - Global navigation satellite system
KW  - Rotors
KW  - Kalman filters
KW  - Force
DO  - 10.1109/ICRA.2019.8794080
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel pose and posture estimation framework of aerial skeleton system for outdoor flying. To exploit redundant/independent sensing while rendering the system “modular”, we attach an IMU (inertial measurement unit) sensor and a GNSS (global navigation satellite system) module on each link and perform SE(3)-motion EKF (extended Kalman filtering). We then apply the kinematic constraints of the aerial skeleton system to these EKF estimates of all the links through SCKF (smoothly constrained Kalman filtering), thereby, enforcing the kinematic coherency of the skeleton system and, consequently, significantly enhancing the estimation accuracy and the control performance/stability of the aerial skeleton system. A semi-distributed version of the obtained estimation framework is also presented to address the issue of scalability. The theory is then verified/demonstrated with real outdoor flying experiments and simulation studies of a three-link aerial skeleton system.
ER  - 

TY  - CONF
TI  - Flight Testing Boustrophedon Coverage Path Planning for Fixed Wing UAVs in Wind
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 711
EP  - 717
AU  - M. Coombes
AU  - W. Chen
AU  - C. Liu
PY  - 2019
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - wind
KW  - flight test results
KW  - model prediction
KW  - multirotor UAV
KW  - boustrophedon coverage path planning
KW  - flight path
KW  - aerial surveys
KW  - complex concave agricultural fields
KW  - flight time
KW  - wind prediction model
KW  - cost function
KW  - wind field measurements
KW  - fixed wing UAV
KW  - Wind
KW  - Aircraft
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Path planning
KW  - Predictive models
KW  - Aerial Surveying
KW  - Coverage Path Planning
KW  - Remote Sensing
KW  - Boustrophedon paths
KW  - Wind
KW  - Trochoids
DO  - 10.1109/ICRA.2019.8793943
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A method was previously developed by this author to optimise the flight path of a fixed wing UAV performing aerial surveys of complex concave agricultural fields. This relies heavily on a flight time in wind prediction model as its cost function. This paper aims to validate this model by comparing flight test results with the model prediction. There are a number of assumptions that this model relies on. The major assumption is that wind is steady and uniform over the small area and time scales involved in a survey. To show that this is reasonable, wind fields measurements will be taken from a multi rotor UAV with an ultrasonic windspeed sensor.
ER  - 

TY  - CONF
TI  - Obstacle-aware Adaptive Informative Path Planning for UAV-based Target Search
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 718
EP  - 724
AU  - A. A. Meera
AU  - M. Popović
AU  - A. Millane
AU  - R. Siegwart
PY  - 2019
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - Gaussian processes
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - target occupancy
KW  - UAV-based target search
KW  - Gaussian process based model
KW  - flight time constraints
KW  - planning strategy
KW  - obstacle-aware adaptive informative path planning algorithm
KW  - target detection
KW  - unmanned aerial vehicles
KW  - collision avoidance
KW  - Planning
KW  - Search problems
KW  - Three-dimensional displays
KW  - Optimization
KW  - Trajectory
KW  - Unmanned aerial vehicles
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794345
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Target search with unmanned aerial vehicles (UAVs) is relevant problem to many scenarios, e.g., search and rescue (SaR). However, a key challenge is planning paths for maximal search efficiency given flight time constraints. To address this, we propose the Obstacle-aware Adaptive Informative Path Planning (OA-IPP) algorithm for target search in cluttered environments using UAVs. Our approach leverages a layered planning strategy using a Gaussian Process (GP)based model of target occupancy to generate informative paths in continuous 3D space. Within this framework, we introduce an adaptive replanning scheme which allows us to trade off between information gain, field coverage, sensor performance, and collision avoidance for efficient target detection. Extensive simulations show that our OA-IPP method performs better than state-of-the-art planners, and we demonstrate its application in a realistic urban SaR scenario.
ER  - 

TY  - CONF
TI  - Real-Time Planning with Multi-Fidelity Models for Agile Flights in Unknown Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 725
EP  - 731
AU  - J. Tordesillas
AU  - B. T. Lopez
AU  - J. Carter
AU  - J. Ware
AU  - J. P. How
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - sensors
KW  - low-fidelity models
KW  - fast planner
KW  - planning framework
KW  - agile flights
KW  - replanning times
KW  - cluttered environments
KW  - multifidelity models
KW  - autonomous navigation
KW  - real-time localization
KW  - lightweight sensing
KW  - planning methodologies
KW  - hierarchical planning architecture
KW  - low-fidelity global planner
KW  - high-fidelity local planner
KW  - erratic behavior
KW  - unstable behavior
KW  - global plan
KW  - higher-order dynamics
KW  - real-time planning
KW  - sensor data
KW  - collision check
KW  - UAV
KW  - time 5.0 ms to 40.0 ms
KW  - Planning
KW  - Trajectory
KW  - Computational modeling
KW  - Vehicle dynamics
KW  - Robot sensing systems
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794248
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous navigation through unknown environments is a challenging task that entails real-time localization, perception, planning, and control. UAVs with this capability have begun to emerge in the literature with advances in lightweight sensing and computing. Although the planning methodologies vary from platform to platform, many algorithms adopt a hierarchical planning architecture where a slow, low-fidelity global planner guides a fast, high-fidelity local planner. However, in unknown environments, this approach can lead to erratic or unstable behavior due to the interaction between the global planner, whose solution is changing constantly, and the local planner; a consequence of not capturing higher-order dynamics in the global plan. This work proposes a planning framework in which multi-fidelity models are used to reduce the discrepancy between the local and global planner. Our approach uses high-, medium-, and low-fidelity models to compose a path that captures higher-order dynamics while remaining computationally tractable. In addition, we address the interaction between a fast planner and a slower mapper by considering the sensor data not yet fused into the map during the collision check. This novel mapping and planning framework for agile flights is validated in simulation and hardware experiments, showing replanning times of 5-40 ms in cluttered environments.
ER  - 

TY  - CONF
TI  - Efficient Trajectory Planning for High Speed Flight in Unknown Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 732
EP  - 738
AU  - M. Ryll
AU  - J. Ware
AU  - J. Carter
AU  - N. Roy
PY  - 2019
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - closed loop systems
KW  - collision avoidance
KW  - inertial navigation
KW  - mobile robots
KW  - motion control
KW  - optimal control
KW  - predictive control
KW  - sampling methods
KW  - trajectory control
KW  - motion planning
KW  - motion capture systems
KW  - receding horizon planning architecture
KW  - reactive obstacle avoidance
KW  - closed-form trajectory generation method
KW  - spatial partitioning data structures
KW  - obstacle density
KW  - sampling-based motion planner
KW  - minimum-jerk trajectories
KW  - closed-loop tracking
KW  - high-speed flight
KW  - autonomous quadrotor flights
KW  - urban environment
KW  - trajectory planning
KW  - visual-inertial navigation
KW  - distance 22.0 km
KW  - Trajectory
KW  - Planning
KW  - Sensors
KW  - Three-dimensional displays
KW  - Cameras
KW  - Vehicle dynamics
KW  - Tracking
DO  - 10.1109/ICRA.2019.8793930
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There has been considerable recent work in motion planning for UAVs to enable aggressive, highly dynamic flight in known environments with motion capture systems. However, these existing planners have not been shown to enable the same kind of flight in unknown, outdoor environments. In this paper we present a receding horizon planning architecture that enables the fast replanning necessary for reactive obstacle avoidance by combining three techniques. First, we show how previous work in computationally efficient, closed-form trajectory generation method can be coupled with spatial partitioning data structures to reason about the geometry of the environment in real-time. Second, we show how to maintain safety margins during fast flight in unknown environments by planning velocities according to obstacle density. Third, our receding-horizon, sampling-based motion planner uses minimum-jerk trajectories and closed-loop tracking to enable smooth, robust, high-speed flight with the low angular rates necessary for accurate visual-inertial navigation. We compare against two state-of-the-art, reactive motion planners in simulation and benchmark solution quality against an offline global planner. Finally, we demonstrate our planner over 80 flights with a combined distance of 22km of autonomous quadrotor flights in an urban environment at speeds up to 9.4ms $^{-1}$.
ER  - 

TY  - CONF
TI  - Priority Maps for Surveillance and Intervention of Wildfires and other Spreading Processes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 739
EP  - 745
AU  - V. L. J. Somers
AU  - I. R. Manchester
PY  - 2019
KW  - autonomous aerial vehicles
KW  - optimisation
KW  - path planning
KW  - wildfires
KW  - priority maps
KW  - wildfires
KW  - knowledge reward function
KW  - dynamic spreading processes
KW  - surveillance
KW  - bushfire spreading dynamics
KW  - wildfire intervention
KW  - unmanned aerial vehicle
KW  - optimization framework
KW  - UAV path planning
KW  - Mathematical model
KW  - Surveillance
KW  - Stochastic processes
KW  - Unmanned aerial vehicles
KW  - Path planning
KW  - Vehicle dynamics
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793874
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Unmanned Aerial Vehicle (UAV) path planning algorithms often assume a knowledge reward function or priority map, indicating the most important areas to visit. In this paper we propose a method to create priority maps for monitoring or intervention of dynamic spreading processes such as wildfires. The presented optimization framework utilizes the properties of positive systems, in particular the separable structure of value (cost-to-go) functions, to provide scalable algorithms for surveillance and intervention. We present results obtained for a 16 and 1000 node example and convey how the priority map responds to changes in the dynamics of the system. The larger example of 1000 nodes, representing a fictional landscape, shows how the method can integrate bushfire spreading dynamics, landscape and wind conditions. Finally, we give an example of combining the proposed method with a travelling salesman problem for UAV path planning for wildfire intervention.
ER  - 

TY  - CONF
TI  - A Practical Approach to Insertion with Variable Socket Position Using Deep Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 754
EP  - 760
AU  - M. Vecerik
AU  - O. Sushkov
AU  - D. Barker
AU  - T. Rothörl
AU  - T. Hester
AU  - J. Scholz
PY  - 2019
KW  - control engineering computing
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - production engineering computing
KW  - variable socket position
KW  - visual control problem
KW  - model-based robotics community
KW  - task geometry
KW  - off-the-shelf Deep-RL algorithm
KW  - narrow-clearance peg-insertion task
KW  - deformable clip-insertion task
KW  - deep reinforcement learning
KW  - haptic control problem
KW  - Task analysis
KW  - Robots
KW  - Sockets
KW  - Visualization
KW  - Training
KW  - Plugs
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8794074
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Insertion is a challenging haptic and visual control problem with significant practical value for manufacturing. Existing approaches in the model-based robotics community can be highly effective when task geometry is known, but are complex and cumbersome to implement, and must be tailored to each individual problem by a qualified engineer. Within the learning community there is a long history of insertion research, but existing approaches are either too sample-inefficient to run on real robots, or assume access to high-level object features, e.g. socket pose. In this paper we show that relatively minor modifications to an off-the-shelf Deep-RL algorithm (DDPG), combined with a small number of human demonstrations, allows the robot to quickly learn to solve these tasks efficiently and robustly. Our approach requires no modeling or simulation, no parameterized search or alignment behaviors, no vision system aside from raw images, and no reward shaping. We evaluate our approach on a narrow-clearance peg-insertion task and a deformable clip-insertion task, both of which include variability in the socket position. Our results show that these tasks can be solved reliably on the real robot in less than 10 minutes of interaction time, and that the resulting policies are robust to variance in the socket position and orientation.
ER  - 

TY  - CONF
TI  - Uncertainty-Aware Data Aggregation for Deep Imitation Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 761
EP  - 767
AU  - Y. Cui
AU  - D. Isele
AU  - S. Niekum
AU  - K. Fujimura
PY  - 2019
KW  - data aggregation
KW  - learning (artificial intelligence)
KW  - Monte Carlo methods
KW  - uncertain systems
KW  - uncertainty estimation method
KW  - UAIL
KW  - uncertainty-aware data aggregation
KW  - deep imitation learning
KW  - statistical uncertainties
KW  - autonomous agents
KW  - task execution
KW  - safety-critical domains
KW  - autonomous driving
KW  - uncertainty-aware imitation learning algorithm
KW  - end-to-end control systems
KW  - Monte Carlo Dropout
KW  - control output
KW  - end-to-end systems
KW  - training data
KW  - prior data aggregation algorithms
KW  - sub-optimal states
KW  - simulated driving tasks
KW  - Uncertainty
KW  - Data aggregation
KW  - Task analysis
KW  - Switches
KW  - Estimation
KW  - Data models
DO  - 10.1109/ICRA.2019.8794025
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Estimating statistical uncertainties allows autonomous agents to communicate their confidence during task execution and is important for applications in safety-critical domains such as autonomous driving. In this work, we present the uncertainty-aware imitation learning (UAIL) algorithm for improving end-to-end control systems via data aggregation. UAIL applies Monte Carlo Dropout to estimate uncertainty in the control output of end-to-end systems, using states where it is uncertain to selectively acquire new training data. In contrast to prior data aggregation algorithms that force human experts to visit sub-optimal states at random, UAIL can anticipate its own mistakes and switch control to the expert in order to prevent visiting a series of sub-optimal states. Our experimental results from simulated driving tasks demonstrate that our proposed uncertainty estimation method can be leveraged to reliably predict infractions. Our analysis shows that UAIL outperforms existing data aggregation algorithms on a series of benchmark tasks.
ER  - 

TY  - CONF
TI  - Uncertainty Aware Learning from Demonstrations in Multiple Contexts using Bayesian Neural Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 768
EP  - 774
AU  - S. Thakur
AU  - H. van Hoof
AU  - J. C. G. Higuera
AU  - D. Precup
AU  - D. Meger
PY  - 2019
KW  - Bayes methods
KW  - belief networks
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - neurocontrollers
KW  - Bayesian neural networks
KW  - robotic controllers
KW  - evaluation conditions
KW  - learned controller
KW  - testing conditions
KW  - high-dimensional simulated domains
KW  - real robotic domains
KW  - uncertainty based solution
KW  - uncertainty aware learning
KW  - Uncertainty
KW  - Task analysis
KW  - Neural networks
KW  - Training
KW  - Robots
KW  - Bayes methods
KW  - Measurement uncertainty
DO  - 10.1109/ICRA.2019.8794328
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Diversity of environments is a key challenge that causes learned robotic controllers to fail due to the discrepancies between the training and evaluation conditions. Training from demonstrations in various conditions can mitigate - but not completely prevent - such failures. Learned controllers such as neural networks typically do not have a notion of uncertainty that allows to diagnose an offset between training and testing conditions, and potentially intervene. In this work, we propose to use Bayesian Neural Networks, which have such a notion of uncertainty. We show that uncertainty can be leveraged to consistently detect situations in high-dimensional simulated and real robotic domains in which the performance of the learned controller would be sub-par. Also, we show that such an uncertainty based solution allows making an informed decision about when to invoke a fallback strategy. One fallback strategy is to request more data. We empirically show that providing data only when requested results in increased data-efficiency.
ER  - 

TY  - CONF
TI  - Learning From Demonstration in the Wild
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 775
EP  - 781
AU  - F. Behbahani
AU  - K. Shiarlis
AU  - X. Chen
AU  - V. Kurin
AU  - S. Kasewa
AU  - C. Stirbu
AU  - J. Gomes
AU  - S. Paul
AU  - F. A. Oliehoek
AU  - J. Messias
AU  - S. Whiteson
PY  - 2019
KW  - cameras
KW  - learning (artificial intelligence)
KW  - object detection
KW  - traffic engineering computing
KW  - video signal processing
KW  - uncalibrated camera
KW  - learning from demonstration
KW  - ViBe
KW  - traffic intersection
KW  - knowledge expert
KW  - video to behaviour
KW  - natural behaviour
KW  - reward function
KW  - hand-coding behaviour
KW  - wild
KW  - raw videos
KW  - naturalistic behaviour
KW  - LfD
KW  - monocular camera
KW  - single camera
KW  - traffic scene
KW  - Cameras
KW  - Trajectory
KW  - Roads
KW  - Three-dimensional displays
KW  - Sensors
KW  - Training
KW  - Tracking
DO  - 10.1109/ICRA.2019.8794412
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning from demonstration (LfD) is useful in settings where hand-coding behaviour or a reward function is impractical. It has succeeded in a wide range of problems but typically relies on manually generated demonstrations or specially deployed sensors and has not generally been able to leverage the copious demonstrations available in the wild: those that capture behaviours that were occurring anyway using sensors that were already deployed for another purpose, e.g., traffic camera footage capturing demonstrations of natural behaviour of vehicles, cyclists, and pedestrians. We propose video to behaviour (ViBe), a new approach to learn models of behaviour from unlabelled raw video data of a traffic scene collected from a single, monocular, initially uncalibrated camera with ordinary resolution. Our approach calibrates the camera, detects relevant objects, tracks them through time, and uses the resulting trajectories to perform LfD, yielding models of naturalistic behaviour. We apply ViBe to raw videos of a traffic intersection and show that it can learn purely from videos, without additional expert knowledge.
ER  - 

TY  - CONF
TI  - A Data-Efficient Framework for Training and Sim-to-Real Transfer of Navigation Policies
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 782
EP  - 788
AU  - H. Bharadhwaj
AU  - Z. Wang
AU  - Y. Bengio
AU  - L. Paull
PY  - 2019
KW  - gradient methods
KW  - image coding
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - data-efficient framework
KW  - sim-to-real transfer
KW  - navigation policies
KW  - effective visuomotor policies
KW  - learning-based system
KW  - manual tuning
KW  - robot operating
KW  - training process
KW  - leverage simulation
KW  - off-policy data
KW  - initial image
KW  - lower dimensional latent state
KW  - planner modules
KW  - meta-learning strategy
KW  - adversarial domain transfer
KW  - simulated environments
KW  - similarly distributed latent representation
KW  - fine tuning
KW  - encoder + planner
KW  - planning performances
KW  - navigation tasks
KW  - unlabelled random images
KW  - Robots
KW  - Data models
KW  - Planning
KW  - Task analysis
KW  - Trajectory
KW  - Training
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794310
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning effective visuomotor policies for robots purely from data is challenging, but also appealing since a learning-based system should not require manual tuning or calibration. In the case of a robot operating in a real environment the training process can be costly, time-consuming, and even dangerous since failures are common at the start of training. For this reason, it is desirable to be able to leverage simulation and off-policy data to the extent possible to train the robot. In this work, we introduce a robust framework that plans in simulation and transfers well to the real environment. Our model incorporates a gradient-descent based planning module, which, given the initial image and goal image, encodes the images to a lower dimensional latent state and plans a trajectory to reach the goal. The model, consisting of the encoder and planner modules, is first trained through a meta-learning strategy in simulation. We subsequently perform adversarial domain transfer on the encoder by using a bank of unlabelled but random images from the simulation and real environments to enable the encoder to map images from the real and simulated environments to a similarly distributed latent representation. By fine tuning the entire model (encoder + planner) with only a few real world expert demonstrations, we show successful planning performances in different navigation tasks.
ER  - 

TY  - CONF
TI  - Simulating Emergent Properties of Human Driving Behavior Using Multi-Agent Reward Augmented Imitation Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 789
EP  - 795
AU  - R. P. Bhattacharyya
AU  - D. J. Phillips
AU  - C. Liu
AU  - J. K. Gupta
AU  - K. Driggs-Campbell
AU  - M. J. Kochenderfer
PY  - 2019
KW  - behavioural sciences computing
KW  - convergence
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - traffic engineering computing
KW  - multiagent settings
KW  - multiagent imitation learning
KW  - human drivers
KW  - reward augmentation
KW  - imitation learning process
KW  - multiagent reward augmented imitation learning
KW  - traffic behaviors
KW  - imitation learning algorithms
KW  - human driving behavior modeling
KW  - prior knowledge specification
KW  - convergence guarantees
KW  - driving policies
KW  - Rails
KW  - Convergence
KW  - Biological system modeling
KW  - Trajectory
KW  - Computational modeling
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2019.8793750
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent developments in multi-agent imitation learning have shown promising results for modeling the behavior of human drivers. However, it is challenging to capture emergent traffic behaviors that are observed in real-world datasets. Such behaviors arise due to the many local interactions between agents that are not commonly accounted for in imitation learning. This paper proposes Reward Augmented Imitation Learning (RAIL), which integrates reward augmentation into the multi-agent imitation learning framework and allows the designer to specify prior knowledge in a principled fashion. We prove that convergence guarantees for the imitation learning process are preserved under the application of reward augmentation. This method is validated in a driving scenario, where an entire traffic scene is controlled by driving policies learned using our proposed algorithm. Further, we demonstrate improved performance in comparison to traditional imitation learning algorithms both in terms of the local actions of a single agent and the behavior of emergent properties in complex, multi-agent settings.
ER  - 

TY  - CONF
TI  - A Supervised Approach to Predicting Noise in Depth Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 796
EP  - 802
AU  - C. Sweeney
AU  - G. Izatt
AU  - R. Tedrake
PY  - 2019
KW  - cameras
KW  - convolutional neural nets
KW  - image denoising
KW  - image fusion
KW  - image reconstruction
KW  - image sensors
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - supervised learning
KW  - supervised approach
KW  - modern robotic systems
KW  - detailed sensor noise models
KW  - robotic behavior
KW  - scene-dependent pixel-wise dropouts
KW  - depth camera simulations
KW  - data driven approach
KW  - convolutional neural network
KW  - no-depth-return pixels
KW  - NDP
KW  - ground truth depth
KW  - noisy depth image
KW  - resulting noise-free
KW  - noise-free image
KW  - depth sensor
KW  - cluttered scenes
KW  - uncorrupted depth images
KW  - noise prediction
KW  - scenes reconstruction
KW  - CNN
KW  - unsupervised domain adaptation baselines
KW  - object pose estimation
KW  - noise-free depth image
KW  - label fusion dataset
KW  - Cameras
KW  - Image reconstruction
KW  - Data models
KW  - Noise measurement
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793820
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Modern robotic systems are very complex and need to be tested in simulations with detailed sensor noise models to effectively verify robotic behavior. Depth imagery in particular comes with significant noise in the form of scene-dependent pixel-wise dropouts and distortions. Unfortunately, many depth camera simulations contain limited noise models, or can only support generating realistic depth images of simple scenes, which limits their usefulness in effectively testing perception algorithms. We propose a data driven approach to generate more realistic noise for complex simulated environments by using a convolutional neural network (CNN) to predict which pixels of a simulated noise-free depth image will not have returns (no-depth-return pixels, or NDP). We choose to focus on NDP here, as these dropouts are the most common and dramatic form of depth image noise. To train this network, we use reconstructed real-world scenes from the Label Fusion dataset to provide ground truth depth for each noisy depth image used to scan the scene. We use the resulting noise-free and noisy depth image pairs as labeled examples and train the network to predict which pixels of the noise-free image will be NDP. When used to post-process a simulation of a depth sensor, this system produces realistic depth images, even in cluttered scenes. To demonstrate that our approach successfully closes the reality gap for depth imagery, we show that the popular ICP algorithm for object pose estimation fails more realistically on our CNN-corrupted simulated depth images than on uncorrupted depth images and unsupervised domain adaptation baselines.
ER  - 

TY  - CONF
TI  - Quantum Computation in Robotic Science and Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 803
EP  - 810
AU  - C. Petschnigg
AU  - M. Brandstötter
AU  - H. Pichler
AU  - M. Hofbaur
AU  - B. Dieber
PY  - 2019
KW  - cloud computing
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - quantum computing
KW  - robot programming
KW  - quantum computing
KW  - cloud services
KW  - artificial intelligence
KW  - machine learning
KW  - robotic scientists
KW  - quantum mechanics
KW  - quantum computation
KW  - intelligent robots
KW  - powerful robots
KW  - Robot sensing systems
KW  - Computers
KW  - Optimization
KW  - Qubit
KW  - Acceleration
DO  - 10.1109/ICRA.2019.8793768
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Using the effects of quantum mechanics for computing challenges has been an often discussed topic for decades. The frequent successes and early products in this area, which we have seen in recent years, indicate that we are currently entering a new era of computing. This paradigm shift will also impact the work of robotic scientists and the applications of robotics. New possibilities as well as new approaches to known problems will enable the creation of even more powerful and intelligent robots that make use of quantum computing cloud services or co-processors. In this position paper, we discuss potential application areas and also point out open research topics in quantum computing for robotics. We go into detail on the impact of quantum computing in artificial intelligence and machine learning, sensing and perception, kinematics as well as system diagnosis. For each topic we point out where quantum computing could be applied based on results from current research.
ER  - 

TY  - CONF
TI  - A Learning Framework for High Precision Industrial Assembly
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 811
EP  - 817
AU  - Y. Fan
AU  - J. Luo
AU  - M. Tomizuka
PY  - 2019
KW  - assembling
KW  - optimisation
KW  - production engineering computing
KW  - supervised learning
KW  - learning framework
KW  - high precision industrial assembly
KW  - reinforcement learning
KW  - automatic assembly
KW  - supervised learning
KW  - assembly tasks
KW  - trajectory optimization
KW  - actor-critic algorithm
KW  - Task analysis
KW  - Trajectory
KW  - Optimization
KW  - Dynamics
KW  - Supervised learning
KW  - Computational modeling
KW  - Space exploration
DO  - 10.1109/ICRA.2019.8793659
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Automatic assembly has broad applications in industries. Traditional assembly tasks utilize predefined trajectories or tuned force control parameters, which make the automatic assembly time-consuming, difficult to generalize, and not robust to uncertainties. In this paper, we propose a learning framework for high precision industrial assembly. The framework combines both the supervised learning and the reinforcement learning. The supervised learning utilizes trajectory optimization to provide the initial guidance to the policy, while the reinforcement learning utilizes actor-critic algorithm to establish the evaluation system even the supervisor is not accurate. The proposed learning framework is more efficient compared with the reinforcement learning and achieves better stability performance than the supervised learning. The effectiveness of the method is verified by both the simulation and experiment. Experimental videos are available at [1].
ER  - 

TY  - CONF
TI  - Manipulation by Feel: Touch-Based Control with Deep Predictive Models
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 818
EP  - 824
AU  - S. Tian
AU  - F. Ebert
AU  - D. Jayaraman
AU  - M. Mudigonda
AU  - C. Finn
AU  - R. Calandra
AU  - S. Levine
PY  - 2019
KW  - dexterous manipulators
KW  - neurocontrollers
KW  - predictive control
KW  - tactile sensors
KW  - unsupervised learning
KW  - feel
KW  - touch-based control
KW  - deep predictive models
KW  - touch sensing
KW  - dexterous robotic manipulation
KW  - tactile sensing
KW  - nonprehensile manipulation
KW  - general purpose control techniques
KW  - accurate physics models
KW  - tactile percepts
KW  - high-resolution tactile
KW  - deep neural network dynamics models
KW  - deep tactile MPC
KW  - tactile servoing
KW  - raw tactile sensor inputs
KW  - GelSight-style tactile sensor
KW  - learned tactile predictive model
KW  - user-specified configurations
KW  - goal tactile reading
KW  - Task analysis
KW  - Predictive models
KW  - Tactile sensors
KW  - Videos
DO  - 10.1109/ICRA.2019.8794219
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Touch sensing is widely acknowledged to be important for dexterous robotic manipulation, but exploiting tactile sensing for continuous, non-prehensile manipulation is challenging. General purpose control techniques that are able to effectively leverage tactile sensing as well as accurate physics models of contacts and forces remain largely elusive, and it is unclear how to even specify a desired behavior in terms of tactile percepts. In this paper, we take a step towards addressing these issues by combining high-resolution tactile sensing with data-driven modeling using deep neural network dynamics models. We propose deep tactile MPC, a framework for learning to perform tactile servoing from raw tactile sensor inputs, without manual supervision. We show that this method enables a robot equipped with a GelSight-style tactile sensor to manipulate a ball, analog stick, and 20-sided die, learning from unsupervised autonomous interaction and then using the learned tactile predictive model to reposition each object to user-specified configurations, indicated by a goal tactile reading. Videos, visualizations and the code are available here: https://sites.google.com/view/deeptactilempc.
ER  - 

TY  - CONF
TI  - 3D Printed Soft Pneumatic Actuators with Intent Sensing for Hand Rehabilitative Exoskeletons*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 841
EP  - 846
AU  - B. W. K. Ang
AU  - C. Yeow
PY  - 2019
KW  - biomechanics
KW  - medical robotics
KW  - patient rehabilitation
KW  - pneumatic actuators
KW  - intent sensing
KW  - hand rehabilitative exoskeletons
KW  - functional motor skills
KW  - motor recovery
KW  - soft robotic exoskeletons
KW  - complex task-based rehabilitative exercises
KW  - bidirectional motion
KW  - soft actuators
KW  - finger flexion
KW  - noninvasive intent detection
KW  - upper limb rehabilitative exoskeletons
KW  - passive finger extension
KW  - fold-based bidirectional 3D printed intent-sensing soft pneumatic actuator
KW  - Fingers
KW  - Exoskeletons
KW  - Actuators
KW  - Robots
KW  - Three-dimensional displays
KW  - Optical sensors
DO  - 10.1109/ICRA.2019.8793785
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Loss of functional motor skills are common and often require patients to undergo rehabilitation so that they have a chance at motor recovery. Advancement in technology has seen to a rise in the use of robotic technology in conducting rehabilitative exercises that are traditionally carried out by physiotherapists. In recent years, soft robotic exoskeletons, using pneumatic-based actuation in particular, have gained much interest due to their compliant characteristics and safe operating conditions. In order to carry out complex task-based rehabilitative exercises, these soft pneumatic actuators must ideally be able to move with multiple degrees of freedom or minimally, in a bidirectional motion. Majority of the research covering soft actuators can only achieve finger flexion with some providing passive finger extension. Non-invasive intent detection in the control of these exoskeletons is also lacking in sensing both finger flexion and extension. In this paper we present our work on a fold-based bidirectional 3D printed intent-sensing soft pneumatic actuator (ISPA) that can achieve bidirectional motion and provide intent detection for finger flexion and extension for application in upper limb rehabilitative exoskeletons.
ER  - 

TY  - CONF
TI  - Gaze-based, Context-aware Robotic System for Assisted Reaching and Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 863
EP  - 869
AU  - A. Shafti
AU  - P. Orlov
AU  - A. A. Faisal
PY  - 2019
KW  - gaze tracking
KW  - grammars
KW  - handicapped aids
KW  - human-robot interaction
KW  - medical robotics
KW  - mobile robots
KW  - patient rehabilitation
KW  - human-in-the-loop assistive robotics
KW  - low-level motion actions
KW  - 3D gaze estimation
KW  - grammars-based implementation
KW  - gaze-based
KW  - context-aware robotic system
KW  - assistive robotic systems
KW  - movement disabilities
KW  - human user
KW  - multimodal system
KW  - assisted reaching
KW  - assisted grasping
KW  - Three-dimensional displays
KW  - Cameras
KW  - Robot kinematics
KW  - Robot vision systems
KW  - Grasping
DO  - 10.1109/ICRA.2019.8793804
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Assistive robotic systems endeavour to support those with movement disabilities, enabling them to move again and regain functionality. Main issue with these systems is the complexity of their low-level control, and how to translate this to simpler, higher level commands that are easy and intuitive for a human user to interact with. We have created a multi-modal system, consisting of different sensing, decision making and actuating modalities, leading to intuitive, human-in-the-loop assistive robotics. The system takes its cue from the user's gaze, to decode their intentions and implement low-level motion actions to achieve high-level tasks. This results in the user simply having to look at the objects of interest, for the robotic system to assist them in reaching for those objects, grasping them, and using them to interact with other objects. We present our method for 3D gaze estimation, and grammars-based implementation of sequences of action with the robotic system. The 3D gaze estimation is evaluated with 8 subjects, showing an overall accuracy of 4.68\pm 0.14cm. The full system is tested with 5 subjects, showing successful implementation of 100% of reach to gaze point actions and full implementation of pick and place tasks in 96%, and pick and pour tasks in 76% of cases. Finally we present a discussion on our results and what future work is needed to improve the system.
ER  - 

TY  - CONF
TI  - Ways to Learn a Therapist’s Patient-specific Intervention: Robotics-vs Telerobotics-mediated Hands-on Teaching
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 870
EP  - 876
AU  - J. Fong
AU  - C. Martinez
AU  - M. Tavakoli
PY  - 2019
KW  - medical robotics
KW  - patient rehabilitation
KW  - patient treatment
KW  - telerobotics
KW  - therapists time
KW  - healthcare resources
KW  - rehabilitation services
KW  - robot-assisted rehabilitation
KW  - economical solution
KW  - LfD
KW  - robotic rehabilitation
KW  - learning from demonstration
KW  - telerobotic-mediated hands-on teaching
KW  - telerobotic-mediated kinesthetic teaching
KW  - TMKT
KW  - RMKT
KW  - Task analysis
KW  - Impedance
KW  - Medical treatment
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Service robots
DO  - 10.1109/ICRA.2019.8793907
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Due to the limitations of therapists time and healthcare resources to cover the increasing demand for rehabilitation services, robot-assisted rehabilitation is becoming an appealing, powerful and economical solution. In our previous research, a solution that combines Learning from Demonstration (LfD) and robotic rehabilitation to save the therapists time and reduce the therapy costs was proposed. In this paper we compare two modalities, Robot-and Telerobotic-Mediated Kinesthetic Teaching (RMKT and TMKT), for implementing LfD in robotic rehabilitation. Our results show that behaviors demonstrated in both modalities are able to be imitated accurately, but demonstrations in TMKT have less repeatability.
ER  - 

TY  - CONF
TI  - Development of a Novel Force Sensing System to Measure the Ground Reaction Force of Rats with Complete Spinal Cord Injury
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 877
EP  - 882
AU  - D. Anopas
AU  - L. Junquan
AU  - S. E. Kiat
AU  - S. K. Wee
AU  - P. E. Tow
AU  - S. Y. Chew
AU  - A. W. Tech
PY  - 2019
KW  - biomechanics
KW  - biomedical measurement
KW  - force sensors
KW  - injuries
KW  - medical disorders
KW  - molecular biophysics
KW  - nanofibres
KW  - nanomedicine
KW  - neurophysiology
KW  - patient rehabilitation
KW  - patient treatment
KW  - proteins
KW  - tissue engineering
KW  - T9-T10 level
KW  - human observance
KW  - nanofiber scaffold
KW  - neurotrophin-3
KW  - right limb
KW  - force sensing system
KW  - spinalized rats
KW  - force detection
KW  - effective treatment method
KW  - spinal cord injury
KW  - complete spinal cord
KW  - spinal cord transection injury model
KW  - motor function
KW  - rehabilitation enhanced recovery
KW  - rehabilitated rats
KW  - left limb
KW  - ground reaction force
KW  - Rats
KW  - Force
KW  - Force measurement
KW  - Spinal cord
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794368
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To date, the aim of spinal cord injury (SCI) researches in animals is to find the most effective treatment method which can lead to faster recovery. In order to evaluate if the method is effective, robust functional assessments are crucial. From the past to present, indicators to observe the recovery of the motor function in rodent SCI models are using human observance or the Basso, Beattie, and Bresnahan score (BBB score), force detection, and imaging approaches. Nevertheless, these indicators do not meet some requirements for a severe full transection injury case. The goal of this project is to develop a novel force sensing system for measuring the ground reaction force of rats with severe SCI. In total, this system was tested with 12 spinalized rats. Following a full transection at the T9-T10 level of the spinal cord in rats with a 2mm gap, a nanofiber scaffold containing Neurotrophin-3 (NT-3), as previously described, was implanted [1]. After 12 weeks of rehabilitative training, results showed that rats that underwent rehabilitation were able to gradually exert more force as compared to rats that did not undergo rehabilitation. At Week 6, the ground reaction force recorded in rats with rehabilitation was 0.8 ± 0.1 N in left limb and 0.75 ± 0.14 N in right limb. On the other hand, rats without rehabilitation exerted 0.52 ± 0.06 N in left limb and 0.47 ± 0.09 N in right limb. At Week 12, the force recorded in rehabilitated rats increased to 1.43 ± 0.13 N in left limb and 1.28 ± 0.17 N in right limb whereas in rats without rehabilitation, the force recorded was only 0.74 ± 0.12 N in left limb and 0.54 ± 0.11 N in right limb. These results not only showed that rehabilitation enhanced recovery of motor function, but also demonstrated the viability of measuring the ground reaction force applied by the rats as an assessment for a full spinal cord transection injury model.
ER  - 


