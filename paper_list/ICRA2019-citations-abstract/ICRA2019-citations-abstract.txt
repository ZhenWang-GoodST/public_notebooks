TY  - CONF
TI  - ICRA 2019 Digest Final
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - i
EP  - lvii
PY  - 2019
DO  - 10.1109/ICRA.2019.8793894
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Presents abstracts for the articles comprising the conference proceedings.
ER  - 

TY  - CONF
TI  - Table of contents
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 46
PY  - 2019
DO  - 10.1109/ICRA.2019.8793964
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Presents the table of contents/splash page of the proceedings record.
ER  - 

TY  - CONF
TI  - Trajectory-based Probabilistic Policy Gradient for Learning Locomotion Behaviors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 7
AU  - S. Choi
AU  - J. Kim
PY  - 2019
KW  - control engineering computing
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - probability
KW  - robot programming
KW  - moderate sample complexity
KW  - trajectory-based probabilistic policy gradient
KW  - trajectory-based reinforcement learning method
KW  - deep latent policy gradient
KW  - DLPG
KW  - policy function
KW  - probability distribution
KW  - deep latent variable model
KW  - curriculum learning
KW  - locomotion skills
KW  - Snapbot
KW  - four-legged walking robot
KW  - Trajectory
KW  - Legged locomotion
KW  - Task analysis
KW  - Gradient methods
KW  - Stochastic processes
KW  - Training
DO  - 10.1109/ICRA.2019.8794207
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a trajectory-based reinforcement learning method named deep latent policy gradient (DLPG) for learning locomotion skills. We define the policy function as a probability distribution over trajectories and train the policy using a deep latent variable model to achieve sample efficient skill learning. We first evaluate the sample efficiency of DLPG compared to the state-of-the-art reinforcement learning methods in simulated environments. Then, we apply the proposed method to a four-legged walking robot named Snapbot to learn three basic locomotion skills of turn left, go straight, and turn right. We demonstrate that, by properly designing two reward functions for curriculum learning, Snapbot successfully learns the desired locomotion skills with moderate sample complexity.
ER  - 

TY  - CONF
TI  - Learning Motion Planning Policies in Uncertain Environments through Repeated Task Executions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8
EP  - 14
AU  - F. Tsang
AU  - R. A. Macdonald
AU  - S. L. Smith
PY  - 2019
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - learned reactive planning problem
KW  - motion planning policy learning
KW  - execution cost
KW  - motion policy
KW  - navigation task
KW  - online replanning
KW  - reactive algorithms
KW  - goal location
KW  - repeated task executions
KW  - uncertain environments
KW  - Task analysis
KW  - Robot sensing systems
KW  - Planning
KW  - Navigation
KW  - Reinforcement learning
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8793961
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to navigate uncertain environments from a start to a goal location is a necessity in many applications. While there are many reactive algorithms for online replanning, there has not been much investigation in leveraging past executions of the same navigation task to improve future executions. In this work, we first formalize this problem by introducing the Learned Reactive Planning Problem (LRPP). Second, we propose a method to capture these past executions and from that determine a motion policy to handle obstacles that the robot has seen before. Third, we show from our experiments that using this policy can significantly reduce the execution cost over just using reactive algorithms.
ER  - 

TY  - CONF
TI  - BaRC: Backward Reachability Curriculum for Robotic Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 15
EP  - 21
AU  - B. Ivanovic
AU  - J. Harrison
AU  - A. Sharma
AU  - M. Chen
AU  - M. Pavone
PY  - 2019
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - optimisation
KW  - path planning
KW  - robots
KW  - BaRC
KW  - initial state distribution backwards
KW  - model-free RL algorithm
KW  - goal-directed continuous control MDPs
KW  - curriculum strategy
KW  - representative dynamic robotic learning problems
KW  - goal-directed tasks
KW  - learning signal
KW  - model-free policy optimization algorithm
KW  - backward reachability curriculum
KW  - curriculum generation techniques
KW  - robotic reinforcement learning
KW  - model-free reinforcement learning
KW  - model-free algorithms
KW  - reward function
KW  - exploration strategies
KW  - Robots
KW  - Task analysis
KW  - Training
KW  - Computational modeling
KW  - Heuristic algorithms
KW  - Complexity theory
KW  - Approximation algorithms
DO  - 10.1109/ICRA.2019.8794206
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Model-free Reinforcement Learning (RL) offers an attractive approach to learn control policies for high dimensional systems, but its relatively poor sample complexity often necessitates training in simulated environments. Even in simulation, goal-directed tasks whose natural reward function is sparse remain intractable for state-of-the-art model-free algorithms for continuous control. The bottleneck in these tasks is the prohibitive amount of exploration required to obtain a learning signal from the initial state of the system. In this work, we leverage physical priors in the form of an approximate system dynamics model to design a curriculum for a model-free policy optimization algorithm. Our Backward Reachability Curriculum (BaRC) begins policy training from states that require a small number of actions to accomplish the task, and expands the initial state distribution backwards in a dynamically-consistent manner once the policy optimization algorithm demonstrates sufficient performance. BaRC is general, in that it can accelerate training of any model-free RL algorithm on a broad class of goal-directed continuous control MDPs. Its curriculum strategy is physically intuitive, easy-to-tune, and allows incorporating physical priors to accelerate training without hindering the performance, flexibility, and applicability of the model-free RL algorithm. We evaluate our approach on two representative dynamic robotic learning problems and find substantial performance improvement relative to previous curriculum generation techniques and naive exploration strategies.
ER  - 

TY  - CONF
TI  - Active Sampling based Safe Identification of Dynamical Systems using Extreme Learning Machines and Barrier Certificates
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 22
EP  - 28
AU  - I. Salehi
AU  - G. Yao
AU  - A. P. Dani
PY  - 2019
KW  - cyber-physical systems
KW  - feedforward neural nets
KW  - function approximation
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - nonlinear dynamical systems
KW  - optimisation
KW  - robot programming
KW  - dynamical system model
KW  - robot learning applications
KW  - cyber-physical systems
KW  - model learning method
KW  - ELM learning
KW  - invariance property
KW  - invariant trajectories
KW  - barrier certificates
KW  - parameter learning problem
KW  - active sampling based safe identification
KW  - extreme learning machines
KW  - infinite constraint problem
KW  - robot arm
KW  - barrier constraints
KW  - Robots
KW  - Trajectory
KW  - Safety
KW  - Stability analysis
KW  - Heuristic algorithms
KW  - Neurons
KW  - Convergence
DO  - 10.1109/ICRA.2019.8793891
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning the dynamical system (DS) model from data that preserves dynamical system properties is an important problem in many robot learning applications. Typically, the joint data coming from cyber-physical systems, such as robots have some underlying DS properties associated with it, e.g., convergence, invariance to a set, etc. In this paper, a model learning method is developed such that the trajectories of the DS are invariant in a given compact set. Such invariant DS models can be used to generate trajectories of the robot that will always remain in a prescribed set. In order to achieve invariance to a set, Barrier certificates are employed. The DS is approximated using Extreme Learning Machine (ELM), and a parameter learning problem subject to Barrier certificates enforced at all the points in the prescribed set is solved. To solve an infinite constraint problem for enforcing Barrier Certificates at every point in a given compact set, a modified constraint is developed that is sufficient to hold the Barrier certificates in the entire set. An active sampling strategy is formulated to minimize the number of constraints in learning. Simulation results of ELM learning with and without Barrier certificates are presented which show the invariance property being preserved in the ELM learning when learning procedure involves Barrier constraints. The method is validated using experiments conducted on a robot arm recreating invariant trajectories inside a prescribed set.
ER  - 

TY  - CONF
TI  - Navigating Dynamically Unknown Environments Leveraging Past Experience
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 29
EP  - 35
AU  - S. McLeod
AU  - J. Xiao
PY  - 2019
KW  - adaptive control
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - autonomous robot navigation
KW  - unknown dynamic obstacles
KW  - real-time adaptive motion planner
KW  - robot motion online
KW  - sensed environmental data
KW  - limited sensing range
KW  - RAMP framework
KW  - probabilistic model
KW  - unknown dynamic environment
KW  - sensing information
KW  - RAMP robot
KW  - dynamic environment changes
KW  - unknown ways
KW  - learned probabilistic data
KW  - Hilbert maps framework
KW  - dynamically unknown environment navigation
KW  - Robot sensing systems
KW  - Trajectory
KW  - Sociology
KW  - Statistics
KW  - Planning
DO  - 10.1109/ICRA.2019.8793565
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To enable autonomous robot navigation among unknown dynamic obstacles, a real-time adaptive motion planner (RAMP) plans the robot motion online based on sensing the environment as the robot moves with sensors mounted on the robot. However, the sensed environmental data from the robot's local view is usually incomplete due to occlusions from obstacles and limited sensing range.This paper incorporates learning about the environment into the RAMP framework by leveraging the Hilbert Maps framework to generate a probabilistic model of occupancy of the unknown dynamic environment based on past observations. Utilizing this probabilistic model enables RAMP to reason about trajectory fitness when sensing information is partial and incomplete. This allows the RAMP robot to take advantage of what it has experienced from being in the dynamic environment before to inform its subsequent executions even though the dynamic environment changes in unknown ways. The effectiveness of incorporating such learned probabilistic data into RAMP is shown in both simulation and real experiments.
ER  - 

TY  - CONF
TI  - VPE: Variational Policy Embedding for Transfer Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 36
EP  - 42
AU  - I. Arnekvist
AU  - D. Kragic
AU  - J. A. Stork
PY  - 2019
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - pendulums
KW  - variational techniques
KW  - variational policy embedding
KW  - transfer reinforcement Learning
KW  - complex problems
KW  - deployment conditions
KW  - data collection
KW  - simulation training
KW  - Q-function
KW  - master policy
KW  - latent variables
KW  - latent space
KW  - low-dimensional space
KW  - simulation-to-real transfer
KW  - reinforcement learning methods
KW  - Markov decision processes
KW  - Optimization
KW  - Training
KW  - Task analysis
KW  - Robots
KW  - Adaptation models
KW  - Reinforcement learning
KW  - Supervised learning
DO  - 10.1109/ICRA.2019.8793556
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Reinforcement Learning methods are capable of solving complex problems, but resulting policies might perform poorly in environments that are even slightly different. In robotics especially, training and deployment conditions often vary and data collection is expensive, making retraining undesirable. Simulation training allows for feasible training times, but on the other hand suffer from a reality-gap when applied in real-world settings. This raises the need of efficient adaptation of policies acting in new environments.We consider the problem of transferring knowledge within a family of similar Markov decision processes. We assume that Q-functions are generated by some low-dimensional latent variable. Given such a Q-function, we can find a master policy that can adapt given different values of this latent variable. Our method learns both the generative mapping and an approximate posterior of the latent variables, enabling identification of policies for new tasks by searching only in the latent space, rather than the space of all policies. The low-dimensional space, and master policy found by our method enables policies to quickly adapt to new environments. We demonstrate the method on both a pendulum swing-up task in simulation, and for simulation-to-real transfer on a pushing task.
ER  - 

TY  - CONF
TI  - Automatic Labeled LiDAR Data Generation based on Precise Human Model
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 43
EP  - 49
AU  - W. Kim
AU  - M. Tanaka
AU  - M. Okutomi
AU  - Y. Sasaki
PY  - 2019
KW  - data analysis
KW  - image motion analysis
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - optical radar
KW  - human recognition
KW  - point clouds
KW  - ground truth label
KW  - automatic labeled data generation pipeline
KW  - data generation environments
KW  - realistic artificial data
KW  - automatic labeled LiDAR data generation
KW  - precise human model
KW  - deep neural networks
KW  - Laser radar
KW  - Data models
KW  - Three-dimensional displays
KW  - Pipelines
KW  - Labeling
KW  - Legged locomotion
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8793916
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Following improvements in deep neural networks, state-of-the-art networks have been proposed for human recognition using point clouds captured by LiDAR. However, the performance of these networks strongly depends on the training data. An issue with collecting training data is labeling. Labeling by humans is necessary to obtain the ground truth label; however, labeling requires huge costs. Therefore, we propose an automatic labeled data generation pipeline, for which we can change any parameters or data generation environments. Our approach uses a human model named Dhaiba and a background of Miraikan and consequently generated realistic artificial data. We present 500k + data generated by the proposed pipeline. This paper also describes the specification of the pipeline and data details with evaluations of various approaches.
ER  - 

TY  - CONF
TI  - Video Object Segmentation using Teacher-Student Adaptation in a Human Robot Interaction (HRI) Setting
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 50
EP  - 56
AU  - M. Siam
AU  - C. Jiang
AU  - S. Lu
AU  - L. Petrich
AU  - M. Gamal
AU  - M. Elhoseiny
AU  - M. Jagersand
PY  - 2019
KW  - computer aided instruction
KW  - human-robot interaction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - teaching
KW  - video signal processing
KW  - teacher-student learning paradigm
KW  - interactive video object segmentation
KW  - grasping affordances
KW  - children learning process
KW  - IVOS dataset
KW  - teaching signal
KW  - human teacher
KW  - unstructured environments
KW  - robotics
KW  - incremental learning
KW  - learning affordances
KW  - robot manipulation
KW  - human robot interaction setting
KW  - teacher-student adaptation
KW  - adaptation method
KW  - manipulation tasks
KW  - HRI setup
KW  - appearance student network
KW  - appearance teacher network
KW  - Task analysis
KW  - Adaptation models
KW  - Motion segmentation
KW  - Education
KW  - Object segmentation
KW  - Benchmark testing
DO  - 10.1109/ICRA.2019.8794254
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Video object segmentation is an essential task in robot manipulation to facilitate grasping and learning affordances. Incremental learning is important for robotics in unstructured environments. Inspired by the children learning process, human robot interaction (HRI) can be utilized to teach robots about the world guided by humans similar to how children learn from a parent or a teacher. A human teacher can show potential objects of interest to the robot, which is able to self adapt to the teaching signal without providing manual segmentation labels. We propose a novel teacher-student learning paradigm to teach robots about their surrounding environment. A two-stream motion and appearance “teacher” network provides pseudo-labels to adapt an appearance “student” network. The student network is able to segment the newly learned objects in other scenes, whether they are static or in motion. We also introduce a carefully designed dataset that serves the proposed HRI setup, denoted as (I)nteractive (V)ideo (O)bject (S)egmentation. Our IVOS dataset contains teaching videos of different objects, and manipulation tasks. Our proposed adaptation method outperforms the state-of-theart on DAVIS and FBMS with 6.8% and 1.2% in F-measure respectively. It improves over the baseline on IVOS dataset with 46.1% and 25.9% in mIoU.
ER  - 

TY  - CONF
TI  - Morphology-Specific Convolutional Neural Networks for Tactile Object Recognition with a Multi-Fingered Hand
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 57
EP  - 63
AU  - S. Funabashi
AU  - G. Yan
AU  - A. Geier
AU  - A. Schmitz
AU  - T. Ogata
AU  - S. Sugano
PY  - 2019
KW  - convolutional neural nets
KW  - dexterous manipulators
KW  - force measurement
KW  - force sensors
KW  - object recognition
KW  - tactile sensors
KW  - morphology-specific convolutional neural network
KW  - distributed tactile sensors
KW  - multifingered hands
KW  - high-dimensional information
KW  - grasping objects
KW  - abundant tactile information
KW  - MS-CNN
KW  - Allegro Hand
KW  - uSkin modules
KW  - consecutive layers
KW  - finger segment
KW  - tactile map
KW  - force measurements
KW  - joint angle measurements
KW  - object recognition rate
KW  - triaxial force sensors
KW  - Tactile sensors
KW  - Convolution
KW  - Task analysis
KW  - Object recognition
DO  - 10.1109/ICRA.2019.8793901
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Distributed tactile sensors on multi-fingered hands can provide high-dimensional information for grasping objects, but it is not clear how to optimally process such abundant tactile information. The current paper explores the possibility of using a morphology-specific convolutional neural network (MS-CNN). uSkin tactile sensors are mounted on an Allegro Hand, which provides 720 force measurements (15 patches of uSkin modules with 16 triaxial force sensors each) in addition to 16 joint angle measurements. Consecutive layers in the CNN get input from parts of one finger segment, one finger, and the whole hand. Since the sensors give 3D (x, y, z) vector tactile information, inputs with 3 channels (x, y and z) are used in the first layer, based on the idea of such inputs for RGB images from cameras. Overall, the layers are combined, resulting in the building of a tactile map based on the relative position of the tactile sensors on the hand. Seven different combination variations were evaluated, and an over-95% object recognition rate with 20 objects was achieved, even though only one random time instance from a repeated squeezing motion of an object in an unknown pose within the hand was used as input.
ER  - 

TY  - CONF
TI  - A Maximum Likelihood Approach to Extract Finite Planes from 3-D Laser Scans
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 72
EP  - 78
AU  - A. Schaefer
AU  - J. Vertens
AU  - D. Büscher
AU  - W. Burgard
PY  - 2019
KW  - feature extraction
KW  - image registration
KW  - image segmentation
KW  - laser ranging
KW  - maximum likelihood estimation
KW  - pattern clustering
KW  - ray tracing
KW  - stereo image processing
KW  - measurement likelihood
KW  - point-to-plane distance
KW  - ray path information
KW  - maximum likelihood approach
KW  - object detection
KW  - model reconstruction
KW  - laser odometry
KW  - point cloud registration
KW  - robotic systems
KW  - strictly probabilistic method
KW  - agglomerative hierarchical clustering
KW  - 3-D laser range scans
KW  - finite plane extraction
KW  - image segmentation
KW  - Laser modes
KW  - Three-dimensional displays
KW  - Measurement by laser beam
KW  - Clustering algorithms
KW  - Probabilistic logic
KW  - Computational modeling
KW  - Maximum likelihood estimation
DO  - 10.1109/ICRA.2019.8794318
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Whether it is object detection, model reconstruction, laser odometry, or point cloud registration: Plane extraction is a vital component of many robotic systems. In this paper, we propose a strictly probabilistic method to detect finite planes in organized 3-D laser range scans. An agglomerative hierarchical clustering technique, our algorithm builds planes from bottom up, always extending a plane by the point that decreases the measurement likelihood of the scan the least. In contrast to most related methods, which rely on heuristics like orthogonal point-to-plane distance, we leverage the ray path information to compute the measurement likelihood. We evaluate our approach not only on the popular SegComp benchmark, but also provide a challenging synthetic dataset that overcomes SegComp's deficiencies. Both our implementation and the suggested dataset are available at [1].
ER  - 

TY  - CONF
TI  - Designing Worm-inspired Neural Networks for Interpretable Robotic Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 87
EP  - 94
AU  - M. Lechner
AU  - R. Hasani
AU  - M. Zimmer
AU  - T. A. Henzinger
AU  - R. Grosu
PY  - 2019
KW  - brain
KW  - manipulator dynamics
KW  - mobile robots
KW  - neurocontrollers
KW  - neurophysiology
KW  - nonlinear control systems
KW  - recurrent neural nets
KW  - search problems
KW  - supervised learning
KW  - time-varying systems
KW  - interpretable robotic control
KW  - nonlinear time-varying synaptic links
KW  - liquid time-constants dynamics
KW  - neuron-pair communication motifs
KW  - compact neuronal network structures
KW  - sequential robotic tasks
KW  - sensory neurons
KW  - recurrently-wired interneurons
KW  - motor neurons
KW  - interpretable dynamics
KW  - mobile arm robots
KW  - artificial neural network-based control agents
KW  - wiring structure
KW  - worm-inspired neural networks
KW  - liquid time-constant recurrent neural networks
KW  - nematode
KW  - C. elegans
KW  - supervised-learning scheme
KW  - search-based algorithm
KW  - Neurons
KW  - Biological neural networks
KW  - Robot sensing systems
KW  - Synapses
KW  - Correlation
KW  - Couplings
DO  - 10.1109/ICRA.2019.8793840
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we design novel liquid time-constant recurrent neural networks for robotic control, inspired by the brain of the nematode, C. elegans. In the worm's nervous system, neurons communicate through nonlinear time-varying synaptic links established amongst them by their particular wiring structure. This property enables neurons to express liquid time-constants dynamics and therefore allows the network to originate complex behaviors with a small number of neurons. We identify neuron-pair communication motifs as design operators and use them to configure compact neuronal network structures to govern sequential robotic tasks. The networks are systematically designed to map the environmental observations to motor actions, by their hierarchical topology from sensory neurons, through recurrently-wired interneurons, to motor neurons. The networks are then parametrized in a supervised-learning scheme by a search-based algorithm. We demonstrate that obtained networks realize interpretable dynamics. We evaluate their performance in controlling mobile and arm robots, and compare their attributes to other artificial neural network-based control agents. Finally, we experimentally show their superior resilience to environmental noise, compared to the existing machine learning-based methods.
ER  - 

TY  - CONF
TI  - Acting Is Seeing: Navigating Tight Space Using Flapping Wings
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 95
EP  - 101
AU  - Z. Tu
AU  - F. Fei
AU  - J. Zhang
AU  - X. Deng
PY  - 2019
KW  - aerospace robotics
KW  - biomimetics
KW  - control system synthesis
KW  - feedback
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robust control
KW  - torque control
KW  - flapping-wing robot
KW  - wing loading feedback
KW  - instantaneous wing loading
KW  - bio-inspired robotic flyers
KW  - torque control
KW  - tight space navigation
KW  - Purdu Hummingbird
KW  - flight stability
KW  - robust controller design
KW  - Robot sensing systems
KW  - DC motors
KW  - Navigation
KW  - Loading
KW  - Aerodynamics
DO  - 10.1109/ICRA.2019.8794084
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Wings of flying animals can not only generate lift and control torques but also can sense their surroundings. Such dual functions of sensing and actuation coupled in one element are particularly useful for small sized bio-inspired robotic flyers, whose weight, size, and power are under stringent constraint. In this work, we present the first flapping-wing robot using its flapping wings for environmental perception and navigation in tight space, without the need for any visual feedback. As the test platform, we introduce the Purdu Hummingbird, a flapping-wing robot with 17cm wingspan and 12 grams weight, with a pair of 30-40Hz flapping wings driven by only two actuators. By interpreting the wing loading feedback and its variations, the vehicle can detect the presence of environmental changes such as grounds, walls, stairs, obstacles and wind gust. The instantaneous wing loading can be obtained through the measurements and interpretation of the current feedback by the motors that actuate the wings. The effectiveness of the proposed approach is experimentally demonstrated on several challenging flight tasks without vision: terrain following, wall following and going through a narrow corridor. To ensure flight stability, a robust controller was designed for handling unforeseen disturbances during the flight. Sensing and navigating one's environment through actuator loading is a promising method for mobile robots, and it can serve as an alternative or complementary method to visual perception.
ER  - 

TY  - CONF
TI  - Design and Characterization of a Novel Robotic Surface for Application to Compressed Physical Environments *
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 102
EP  - 108
AU  - Y. Wang
AU  - C. Frazelle
AU  - R. Sirohi
AU  - L. Li
AU  - I. D. Walker
AU  - K. E. Green
PY  - 2019
KW  - biomechanics
KW  - design engineering
KW  - mobile robots
KW  - compressed physical environments
KW  - robot arms
KW  - robot surface
KW  - compliant surfaces
KW  - habitable space
KW  - physical space
KW  - tendon-driven robotic surface
KW  - herringbone pattern
KW  - 3D-printed panels
KW  - Prototypes
KW  - Service robots
KW  - Springs
KW  - Surface treatment
KW  - Robot kinematics
KW  - Surface waves
DO  - 10.1109/ICRA.2019.8794043
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Developments of robot arms are countless, but there has been little focus on robot surfaces for the reshaping of a habitable space - especially compliant surfaces. In this paper we introduce a novel, tendon-driven, robot surface comprised of aggregated, overlapping panels organized in a herringbone pattern. The individual 3D-printed panels and their behavior as an aggregation are inspired by the form and behavior of a pinecone. This paper presents our concept, design, and realization of this robot, and compares our prototype to simulations of four physical configurations that are formally distinct and suggestive of how the surface might be applied to habitable, physical space in response to human needs and wants. For the four configurations studied, we found a validating match between prototype and simulations. The paper concludes with a consideration of potential applications for robot surfaces like this one.
ER  - 

TY  - CONF
TI  - Learning Extreme Hummingbird Maneuvers on Flapping Wing Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 109
EP  - 115
AU  - F. Fei
AU  - Z. Tu
AU  - J. Zhang
AU  - X. Deng
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - aircraft control
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - nonlinear control systems
KW  - position control
KW  - robot dynamics
KW  - robot kinematics
KW  - stability
KW  - extreme aerobatic maneuvers
KW  - visual stimulus
KW  - 180-degree yaw turn
KW  - wingbeat frequency
KW  - flight control strategy
KW  - hybrid control policy
KW  - model-based nonlinear control
KW  - model-free reinforcement learning policy
KW  - hummingbird-like fast evasive maneuvers
KW  - extreme hummingbird maneuvers
KW  - flapping wing robots
KW  - backward translation
KW  - posture stabilization
KW  - hummingbird robot
KW  - frequency 40.0 Hz
KW  - time 0.2 s
KW  - Aerodynamics
KW  - Vehicle dynamics
KW  - Uncertainty
KW  - Robots
KW  - Adaptation models
KW  - Torque
KW  - Actuators
DO  - 10.1109/ICRA.2019.8794100
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Biological studies show that hummingbirds can perform extreme aerobatic maneuvers during fast escape. Given a sudden looming visual stimulus at hover, a hummingbird initiates a fast backward translation coupled with a 180-degree yaw turn, which is followed by instant posture stabilization in just under 10 wingbeats. Consider the wingbeat frequency of 40Hz, this aggressive maneuver is carried out in just 0.2 seconds. Inspired by the hummingbirds' near-maximal performance during such extreme maneuvers, we developed a flight control strategy and experimentally demonstrated that such maneuverability can be achieved by an at-scale 12-gram hummingbird robot equipped with just two actuators driving a pair of flapping wings up to 40Hz. The proposed hybrid control policy combines model-based nonlinear control with model-free reinforcement learning. We used the model-based nonlinear control for nominal flight conditions where dynamic models are relatively accurate. During extreme maneuvers when the modeling error becomes unmanageable, we use a model-free reinforcement learning policy trained and optimized in simulation to 'destabilize' the system for peak performance during maneuvering. The hybrid policy manifests a maneuver that is close to that observed in hummingbirds. Direct simulation-to-real transfer is achieved, demonstrating the hummingbird-like fast evasive maneuvers on the at-scale hummingbird robot.
ER  - 

TY  - CONF
TI  - FMD Stereo SLAM: Fusing MVG and Direct Formulation Towards Accurate and Fast Stereo SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 133
EP  - 139
AU  - F. Tang
AU  - H. Li
AU  - Y. Wu
PY  - 2019
KW  - feature extraction
KW  - motion estimation
KW  - pose estimation
KW  - SLAM (robots)
KW  - stereo image processing
KW  - key-feature-based multiple view geometry
KW  - global map
KW  - 3D structure
KW  - bundle adjustment
KW  - fast stereo SLAM
KW  - direct formulation
KW  - local map
KW  - constant motion model
KW  - direct-based formulation
KW  - novel stereo visual SLAM framework
KW  - FMD stereo SLAM
KW  - back-end process
KW  - stereo constraint
KW  - reprojection error minimization
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Visualization
KW  - Robot vision systems
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8793664
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel stereo visual SLAM framework considering both accuracy and speed at the same time. The framework makes full use of the advantages of key-feature-based multiple view geometry (MVG) and direct-based formulation. At the front-end, our system performs direct formulation and constant motion model to predict a robust initial pose, reprojects local map to find 3D-2D correspondence and finally refines pose by the reprojection error minimization. This frontend process makes our system faster. At the back-end, MVG is used to estimate 3D structure. When a new keyframe is inserted, new mappoints are generated by triangulating. In order to improve the accuracy of the proposed system, bad mappoints are removed and a global map is kept by bundle adjustment. Especially, the stereo constraint is performed to optimize the map. This back-end process makes our system more accurate. Experimental evaluation on EuRoC dataset shows that the proposed algorithm can run at more than 100 frames per second on a consumer computer while achieving highly competitive accuracy.
ER  - 

TY  - CONF
TI  - ScalableFusion: High-resolution Mesh-based Real-time 3D Reconstruction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 140
EP  - 146
AU  - S. Schreiberhuber
AU  - J. Prankl
AU  - T. Patten
AU  - M. Vincze
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image reconstruction
KW  - image resolution
KW  - image sensors
KW  - SLAM (robots)
KW  - sensor resolution
KW  - colorization
KW  - multiscale memory management process
KW  - high resolution global shutter camera
KW  - memory management approach
KW  - high-resolution mesh-based real-time 3D reconstruction
KW  - dense 3D reconstructions
KW  - robot applications
KW  - color resolution
KW  - depth resolution
KW  - surface reconstruction
KW  - surface texture
KW  - geometrical fidelity
KW  - RGB-D based reconstructions
KW  - PrimeSense RGB-D camera
KW  - Surface reconstruction
KW  - Image color analysis
KW  - Robot sensing systems
KW  - Geometry
KW  - Three-dimensional displays
KW  - Surface texture
KW  - Image reconstruction
DO  - 10.1109/ICRA.2019.8793654
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dense 3D reconstructions generate globally consistent data of the environment suitable for many robot applications. Current RGB-D based reconstructions, however, only maintain the color resolution equal to the depth resolution of the used sensor. This firmly limits the precision and realism of the generated reconstructions. In this paper we present a real-time approach for creating and maintaining a surface reconstruction in as high as possible geometrical fidelity with full sensor resolution for its colorization (or surface texture). A multi-scale memory management process and a Level of Detail scheme enable equally detailed reconstructions to be generated at small scales, such as objects, as well as large scales, such as rooms or buildings. We showcase the benefit of this novel pipeline with a PrimeSense RGB-D camera as well as combining the depth channel of this camera with a high resolution global shutter camera. Further experiments show that our memory management approach allows us to scale up to larger domains that are not achievable with current state-of-the-art methods.
ER  - 

TY  - CONF
TI  - GEN-SLAM: Generative Modeling for Monocular Simultaneous Localization and Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 147
EP  - 153
AU  - P. Chakravarty
AU  - P. Narayanan
AU  - T. Roussel
PY  - 2019
KW  - cameras
KW  - collision avoidance
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - depth estimation system
KW  - GEN-SLAM
KW  - generative modeling
KW  - Deep Learning based system
KW  - obstacle avoidance
KW  - mobile robot
KW  - conventional geometric SLAM
KW  - single camera
KW  - topological map
KW  - camera image
KW  - topological location estimation
KW  - monocular localization
KW  - monocular simultaneous localization and mapping
KW  - Cameras
KW  - Image reconstruction
KW  - Simultaneous localization and mapping
KW  - Decoding
KW  - Training
DO  - 10.1109/ICRA.2019.8793530
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a Deep Learning based system for the twin tasks of localization and obstacle avoidance essential to any mobile robot. Our system learns from conventional geometric SLAM, and outputs, using a single camera, the topological pose of the camera in an environment, and the depth map of obstacles around it. We use a CNN to localize in a topological map, and a conditional VAE to output depth for a camera image, conditional on this topological location estimation. We demonstrate the effectiveness of our monocular localization and depth estimation system on simulated and real datasets.
ER  - 

TY  - CONF
TI  - RESLAM: A real-time robust edge-based SLAM system
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 154
EP  - 160
AU  - F. Schenk
AU  - F. Fraundorfer
PY  - 2019
KW  - cameras
KW  - edge detection
KW  - image colour analysis
KW  - image representation
KW  - image sensors
KW  - motion estimation
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - camera intrinsics
KW  - sliding window
KW  - edge-based verification
KW  - RESLAM
KW  - camera motions
KW  - RGBD sensors
KW  - sparse representation
KW  - SLAM pipeline
KW  - robust edge-based SLAM system
KW  - simultaneous localization and mapping
KW  - Image edge detection
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Optimization
KW  - Real-time systems
KW  - Microsoft Windows
DO  - 10.1109/ICRA.2019.8794462
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Simultaneous Localization and Mapping is a key requirement for many practical applications in robotics. In this work, we present RESLAM, a novel edge-based SLAM system for RGBD sensors. Due to their sparse representation, larger convergence basin and stability under illumination changes, edges are a promising alternative to feature-based or other direct approaches. We build a complete SLAM pipeline with camera pose estimation, sliding window optimization, loop closure and relocalisation capabilities that utilizes edges throughout all steps. In our system, we additionally refine the initial depth from the sensor, the camera poses and the camera intrinsics in a sliding window to increase accuracy. Further, we introduce an edge-based verification for loop closures that can also be applied for relocalisation. We evaluate RESLAM on wide variety of benchmark datasets that include difficult scenes and camera motions and also present qualitative results. We show that this novel edge-based SLAM system performs comparable to state-of-the-art methods, while running in real-time on a CPU. RESLAM is available as open-source software1.
ER  - 

TY  - CONF
TI  - On-line 3D active pose-graph SLAM based on key poses using graph topology and sub-maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 169
EP  - 175
AU  - Y. Chen
AU  - S. Huang
AU  - R. Fitch
AU  - L. Zhao
AU  - H. Yu
AU  - D. Yang
PY  - 2019
KW  - autonomous aerial vehicles
KW  - computational complexity
KW  - graph theory
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - remotely operated vehicles
KW  - robot vision
KW  - SLAM (robots)
KW  - graph topology
KW  - pose-graph simultaneous localization
KW  - three-dimensional environments
KW  - D-optimality metrics
KW  - weighted node degree
KW  - T-optimality metric
KW  - sampling-based path
KW  - continuous-time trajectory optimization method
KW  - large-scale active SLAM problems
KW  - submap joining method
KW  - online 3D active pose-graph SLAM
KW  - Simultaneous localization and mapping
KW  - Measurement
KW  - Trajectory
KW  - Planning
KW  - Three-dimensional displays
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793632
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present an on-line active pose-graph simultaneous localization and mapping (SLAM) frame-work for robots in three-dimensional (3D) environments using graph topology and sub-maps. This framework aims to find the best trajectory for loop-closure by re-visiting old poses based on the T-optimality and D-optimality metrics of the Fisher information matrix (FIM) in pose-graph SLAM. In order to reduce computational complexity, graph topologies are introduced, including weighted node degree (T-optimality metric) and weighted tree-connectivity (D-optimality metric), to choose a candidate trajectory and several key poses. With the help of the key poses, a sampling-based path planning method and a continuous-time trajectory optimization method are combined hierarchically and applied in the whole framework. So as to further improve the real-time capability of the method, the sub-map joining method is used in the estimation and planning process for large-scale active SLAM problems. In simulations and experiments, we validate our approach by comparing against existing methods, and we demonstrate the on-line planning part using a quad-rotor unmanned aerial vehicle (UAV).
ER  - 

TY  - CONF
TI  - Modeling and Planning Manipulation in Dynamic Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 176
EP  - 182
AU  - P. S. Schmitt
AU  - F. Wirnshofer
AU  - K. M. Wurm
AU  - G. v. Wichert
AU  - W. Burgard
PY  - 2019
KW  - collision avoidance
KW  - manipulator dynamics
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - steering systems
KW  - kinodynamic manipulation planner
KW  - dynamic environments
KW  - robot dynamics
KW  - time-variant environments
KW  - manipulation modeling
KW  - manipulation planning
KW  - online collision avoidance
KW  - object pose estimation
KW  - steering functions
KW  - Planning
KW  - Task analysis
KW  - Collision avoidance
KW  - Manipulator dynamics
KW  - Grippers
DO  - 10.1109/ICRA.2019.8793824
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we propose a new model for sequential manipulation tasks that also considers robot dynamics and time-variant environments. From this model we automatically derive constraint-based controllers and use them as steering functions in a kinodynamic manipulation planner. The resulting plan is not a trajectory but a sequence of controllers that react online to disturbances. We validated our approach in simulation and on a real robot. In the experiments our approach plans and executes dual-robot manipulation tasks with online collision avoidance and reactions to estimates of object poses.
ER  - 

TY  - CONF
TI  - Efficient Obstacle Rearrangement for Object Manipulation Tasks in Cluttered Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 183
EP  - 189
AU  - J. Lee
AU  - Y. Cho
AU  - C. Nam
AU  - J. Park
AU  - C. Kim
PY  - 2019
KW  - collision avoidance
KW  - computational complexity
KW  - manipulators
KW  - mobile robots
KW  - navigation
KW  - object manipulation tasks
KW  - cluttered environments
KW  - robotic manipulator
KW  - constrained confined space
KW  - collision-free path
KW  - object rearrangement
KW  - NP-hard
KW  - service domains
KW  - collision avoidance scheme
KW  - mobile robot navigation
KW  - object poses
KW  - obstacle rearrangement
KW  - polynomial time
KW  - Histograms
KW  - Planning
KW  - Task analysis
KW  - Grasping
KW  - End effectors
DO  - 10.1109/ICRA.2019.8793616
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an algorithm that produces a plan for relocating obstacles in order to grasp a target in clutter by a robotic manipulator without collisions. We consider configurations where objects are densely populated in a constrained and confined space. Thus, there exists no collision-free path for the manipulator without relocating obstacles. Since the problem of planning for object rearrangement has shown to be NP-hard, it is difficult to perform manipulation tasks efficiently which could frequently happen in service domains (e.g., taking out a target from a shelf or a fridge). Our proposed planner employs a collision avoidance scheme which has been widely used in mobile robot navigation. The planner determines an obstacle to be removed quickly in real time. It also can deal with dynamic changes in the configuration (e.g., changes in object poses). Our method is shown to be complete and runs in polynomial time. Experimental results in a realistic simulated environment show that our method improves up to 31% of the execution time compared to other competitors.
ER  - 

TY  - CONF
TI  - MoveIt! Task Constructor for Task-Level Motion Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 190
EP  - 196
AU  - M. Görner
AU  - R. Haschke
AU  - H. Ritter
AU  - J. Zhang
PY  - 2019
KW  - manipulators
KW  - path planning
KW  - robotic manipulation actions
KW  - Task Constructor framework
KW  - black-box planning stages
KW  - task-level motion planning
KW  - robotic manipulation framework
KW  - MoveIt!
KW  - Planning
KW  - Task analysis
KW  - Robots
KW  - Trajectory
KW  - Containers
KW  - Generators
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793898
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A lot of motion planning research in robotics focuses on efficient means to find trajectories between individual start and goal regions, but it remains challenging to specify and plan robotic manipulation actions which consist of multiple interdependent subtasks. The Task Constructor framework we present in this work provides a flexible and transparent way to define and plan such actions, enhancing the capabilities of the popular robotic manipulation framework MoveIt!.11The Task Constructor framework is publicly available at https://github.com/ros-planning/moveit_task_constructor Subproblems are solved in isolation in black-box planning stages and a common interface is used to pass solution hypotheses between stages. The framework enables the hierarchical organization of basic stages using containers, allowing for sequential as well as parallel compositions. The flexibility of the framework is illustrated in multiple scenarios performed on various robot platforms, including bimanual ones.
ER  - 

TY  - CONF
TI  - Exploiting Environment Contacts of Serial Manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 197
EP  - 203
AU  - P. Mohammadi
AU  - D. Kubus
AU  - J. J. Steil
PY  - 2019
KW  - actuators
KW  - end effectors
KW  - force control
KW  - manipulators
KW  - environment contacts
KW  - serial manipulators
KW  - redundant serial manipulator
KW  - robot configuration
KW  - end-effector forces
KW  - actuator
KW  - Actuators
KW  - Force
KW  - Friction
KW  - Kinematics
KW  - End effectors
DO  - 10.1109/ICRA.2019.8794027
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We explore the characteristics of secondary contacts when applying forces with the end-effector of a robot and address the question when these secondary contacts can increase maximum applicable end-effector forces or reduce required actuator efforts. To this end, we formalize the effect of such secondary contacts in terms of required actuator efforts and derive efficiency bounds depending on the contact characteristics and robot configuration. Our findings are confirmed by experiments with a redundant serial manipulator.
ER  - 

TY  - CONF
TI  - optimization-Based Human-in-the-Loop Manipulation Using Joint Space Polytopes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 204
EP  - 210
AU  - P. Long
AU  - T. Keleştemur
AU  - A. Ö. Önol
AU  - T. Padir
PY  - 2019
KW  - collision avoidance
KW  - geometry
KW  - manipulator kinematics
KW  - mobile robots
KW  - optimisation
KW  - motion planner
KW  - human-in-the-loop manipulation
KW  - optimization
KW  - robot operation
KW  - Cartesian polyhedron
KW  - fast collision-free inverse kinematic
KW  - joint space polytopes
KW  - singular configurations
KW  - constrained manipulability polytopes
KW  - operator commands
KW  - End effectors
KW  - Trajectory
KW  - Kinematics
KW  - Task analysis
KW  - Collision avoidance
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2019.8794071
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a new method of maximizing the free space for a robot operating in a constrained environment under operator supervision. The objective is to make the resulting trajectories more robust to operator commands and/or changes in the environment. To represent the volume of free space, the constrained manipulability polytopes are used. These polytopes embed the distance to obstacles, the distance to joint limits and the distance to singular configurations. The volume of the resulting Cartesian polyhedron is used in an optimization-based motion planner to create the trajectories. Additionally, we show how fast collision-free inverse kinematic solutions can be obtained by exploiting the pre-computed inequality constraints. The proposed algorithm is validated in simulation and experimentally.
ER  - 

TY  - CONF
TI  - Large-Scale Multi-Object Rearrangement
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 211
EP  - 218
AU  - E. Huang
AU  - Z. Jia
AU  - M. T. Mason
PY  - 2019
KW  - iterative methods
KW  - optimisation
KW  - robot vision
KW  - search problems
KW  - robotic tabletop rearrangement system
KW  - high packing factor forces
KW  - simulated pushing actions
KW  - vision system
KW  - iterated local search technique
KW  - large-scale multiobject rearrangement
KW  - Planning
KW  - Task analysis
KW  - Grasping
KW  - Robots
KW  - Annealing
KW  - Trajectory
KW  - Markov processes
DO  - 10.1109/ICRA.2019.8793946
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes a new robotic tabletop rearrangement system, and presents experimental results. The tasks involve rearranging as many as 30 to 100 blocks, sometimes packed with a density of up to 40%. The high packing factor forces the system to push several objects at a time, making accurate simulation difficult, if not impossible. Nonetheless, the system achieves goals specifying the pose of every object, with an average precision of ± 1 mm and ± 2°. The system searches through policy rollouts of simulated pushing actions, using an Iterated Local Search technique to escape local minima. In real world execution, the system executes just one action from a policy, then uses a vision system to update the estimated task state, and replans. The system accepts a fully general description of task goals, which means it can solve the singulation and separation problems addressed in prior work, but can also solve sorting problems and spell out words, among other things. The paper includes examples of several solved problems, statistical analysis of the system's behavior on different types of problems, and some discussion of limitations, insights, and future work.
ER  - 

TY  - CONF
TI  - Manipulation Using Microrobot Driven by Optothermally Generated Surface Bubble
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 219
EP  - 224
AU  - L. Dai
AU  - Z. Ge
AU  - N. Jiao
AU  - J. Shi
AU  - L. Liu
PY  - 2019
KW  - bioMEMS
KW  - bubbles
KW  - hydrogels
KW  - microrobots
KW  - photothermal effects
KW  - optothermal effects
KW  - microparticles
KW  - optothermally generated surface bubble
KW  - manipulation technique
KW  - hydrogel microstructures
KW  - microrobots
KW  - absorptivity
KW  - transmissivity
KW  - Microstructure
KW  - Silicon
KW  - Gold
KW  - Surface waves
KW  - Laser theory
KW  - Photothermal effects
DO  - 10.1109/ICRA.2019.8794242
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A manipulation technique based on optothermally generated surface bubbles is proposed in this paper. The manipulation and assembly of microstructures are completed by using bubbles. In addition, the hydrogel microstructures are also used as microrobots driven by the bubble to operate and pattern the microspheres. Considering that many materials and lasers with different wavelength have been used for generating bubbles by optothermal effects, absorptivity and transmissivity are used as indicators of selections. Besides, the size of the bubble can be controlled by the frequency and time of the laser. This technique is supposed to be applied for manipulation of cells, microparticles and microstructures.
ER  - 

TY  - CONF
TI  - Compound micromachines powered by acoustic streaming
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 225
EP  - 230
AU  - M. Kaynak
AU  - F. Ayhan
AU  - M. S. Sakar
PY  - 2019
KW  - acoustic streaming
KW  - energy harvesting
KW  - gears
KW  - machine tools
KW  - manipulators
KW  - microfabrication
KW  - microfluidics
KW  - micromachining
KW  - polymerisation
KW  - pumps
KW  - in-situ polymerization process
KW  - acoustic energy harvesting
KW  - robotic manipulation systems
KW  - microfluidic devices
KW  - microfluidic devices
KW  - mechanical power
KW  - microscale turbines
KW  - programmable projector
KW  - assembly steps
KW  - machine components
KW  - acoustic streaming
KW  - compound micromachines
KW  - Acoustics
KW  - Rotors
KW  - Bars
KW  - Oscillators
KW  - Turbines
KW  - Microchannels
DO  - 10.1109/ICRA.2019.8793481
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the design, fabrication, and operation of compound micromachines powered by acoustic streaming. The machine components were directly incorporated around pillars serving as shafts without further assembly steps using a single-step in situ polymerization process controlled by a programmable projector. Two strategies were presented for harvesting acoustic energy using sharp-edged structures. The first method is based on on-board pumping of fluids and the second method involves engineering of rotors. The implementation of these strategies resulted in the construction of microscale turbines and engines that can be coupled to gear trains for adaptable transmission of mechanical power. We provide a number of further improvements that may together lead to development of compact yet powerful robotic manipulation systems inside microfluidic devices.
ER  - 

TY  - CONF
TI  - ChevBot – An Untethered Microrobot Powered by Laser for Microfactory Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 231
EP  - 236
AU  - R. Zhang
AU  - A. Sherehiy
AU  - Z. Yang
AU  - D. Wei
AU  - C. K. Harnett
AU  - D. O. Popa
PY  - 2019
KW  - displacement measurement
KW  - industrial robots
KW  - integrated circuit manufacture
KW  - laser beam applications
KW  - microactuators
KW  - micromechanical devices
KW  - microrobots
KW  - semiconductor technology
KW  - silicon-on-insulator
KW  - ChevBot
KW  - microfactory applications
KW  - dry environments
KW  - thermal MicroElectro Mechanical actuator
KW  - laser light
KW  - opto-thermal-mechanical energy conversion
KW  - opto-thermal simulation model
KW  - static displacement measurements
KW  - dynamic extension
KW  - directional locomotion
KW  - laser power
KW  - actuator displacements
KW  - locomotion velocity
KW  - submillimeter robot
KW  - laser beam
KW  - untethered microrobot
KW  - microrobot designs
KW  - silicon on insulator wafer
KW  - Laser modes
KW  - Actuators
KW  - Laser beams
KW  - Measurement by laser beam
KW  - Power lasers
KW  - Silicon
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8793856
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we introduce a new class of submillimeter robot (ChevBot) for microfactory applications in dry environments, powered by a 532 nm laser beam. ChevBot is an untethered microrobot propelled by a thermal Micro Electro Mechanical (MEMS) actuator upon exposure to the laser light. Novel models for opto-thermal-mechanical energy conversion are proposed to describe the microrobot's locomotion mechanism. First, an opto-thermal simulation model is presented which is experimentally validated with static displacement measurements with microrobots tethered to the substrate. Then, stick and slip motion of the microrobot was predicted using a dynamic extension of our simulation model, and experiments were conducted to validate this model in one dimension. Promising microrobot designs were fabricated on a silicon on insulator (SOI) wafer with 20 μm device layer and a dimple was assembled at the bottom to initiate directional locomotion on a silicon substrate. Validation experiments demonstrate that exposure to laser power below 2W and repetition frequencies below 60 kHz can generate actuator displacements of a few microns, and 46 μm/s locomotion velocity.
ER  - 

TY  - CONF
TI  - Capillary Ionic Transistor and Precise Transport Control for Nano Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 237
EP  - 242
AU  - Y. Lin
AU  - X. Liu
AU  - T. Arai
PY  - 2019
KW  - capillarity
KW  - electrodes
KW  - elemental semiconductors
KW  - nanoparticles
KW  - silicon
KW  - size measurement
KW  - surface charging
KW  - transistors
KW  - velocity measurement
KW  - negative gate voltage
KW  - positive gate
KW  - nanodevice
KW  - surface charge
KW  - capillary interface
KW  - solution interface
KW  - electrical double layer
KW  - nanoparticle delivery
KW  - resistive pulse method
KW  - velocity measurement
KW  - size measurement
KW  - CIT device
KW  - gate control ability
KW  - gate electrode
KW  - nanochannel
KW  - ionic transport
KW  - CIT
KW  - Capillary Ionic Transistor
KW  - precise transport control
KW  - Si
KW  - Logic gates
KW  - Electrodes
KW  - Transistors
KW  - Nanobioscience
KW  - Electric potential
KW  - Ions
KW  - Nanoscale devices
KW  - nanofluidic
KW  - gate voltage control
KW  - sub 100nm
KW  - micromanipulator
DO  - 10.1109/ICRA.2019.8793755
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Capillary Ionic Transistor (CIT) is introduced as a nanodevice which provides control of ionic transport through nanochannel by gate voltage. CIT is Ionic transistor which employs pulled capillary as nanochannel with tip diameter smaller than 100 nm. We observed that gate voltage applied to gate electrode, deposited on the outer wall of capillary, affect a conductance of nanochannel, due to change of surface charge at the solution/capillary interface. Negative gate voltage corresponds to lower conductivity and positive gate increase conductance of the channel. This effect strongly depends on the size of the channel. In general, at least one dimension of the channel has to be small enough for electrical double layer to overlap. As a demonstration of the gate control ability, we performed Si nanoparticle delivery via CIT and recorded the deliverance through resistive pulse method. Size and velocity measurement are also conducted, to showcase the versatility of CIT device.
ER  - 

TY  - CONF
TI  - Resolved Viscoelasticity Control Considering Singularity for Knee-stretched Walking of a Humanoid
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 250
EP  - 255
AU  - K. Murotani
AU  - K. Yamamoto
AU  - T. Ko
AU  - Y. Nakamura
PY  - 2019
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - viscoelasticity
KW  - task-space
KW  - mass viscoelasticity
KW  - joint-space viscoelasticity
KW  - robust motion
KW  - compliant motion
KW  - RVC method
KW  - kinematic singularity
KW  - knee joint torque
KW  - RVC capable
KW  - humanoid
KW  - stable knee-stretched walking
KW  - knee-bent posture
KW  - resolved viscoelasticity control
KW  - Task analysis
KW  - Knee
KW  - Legged locomotion
KW  - Kinematics
KW  - Trajectory
KW  - Foot
KW  - Humanoid robots
DO  - 10.1109/ICRA.2019.8793605
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes a stable knee-stretched walking of a humanoid by the resolved viscoelasticity control (RVC). The RVC method resolves multiple viscoelasticities in task-space, including the center of mass viscoelasticity for balancing, into joint-space viscoelasticity. Although a robust and compliant motion was achieved by the RVC method in previous studies, the conventional knee-bent posture to avoid the kinematic singularity suffered large knee joint torque. In this study, we propose an extension of the RVC capable of the kinematic singularity. We demonstrate through simulations and experiments that the RVC method considering the singularity achieves a stable and human-like walking, reducing the knee joint torque and improving the energy efficiency.
ER  - 

TY  - CONF
TI  - Versatile Reactive Bipedal Locomotion Planning Through Hierarchical Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 256
EP  - 262
AU  - J. Ding
AU  - C. Zhou
AU  - Z. Guo
AU  - X. Xiao
AU  - N. Tsagarakis
PY  - 2019
KW  - control nonlinearities
KW  - humanoid robots
KW  - legged locomotion
KW  - linear systems
KW  - motion control
KW  - nonlinear control systems
KW  - optimisation
KW  - path planning
KW  - pendulums
KW  - predictive control
KW  - robot dynamics
KW  - step frequency
KW  - humanoid robots
KW  - hierarchical optimization
KW  - angular momentum
KW  - nonlinear model predictive control
KW  - reactive bipedal locomotion planning
KW  - nonlinearities
KW  - walking dynamics
KW  - step time abilities
KW  - step location adjustment
KW  - Center of Mass height variation
KW  - linear inverted pendulum model
KW  - robot gait generation
KW  - Legged locomotion
KW  - Optimization
KW  - Trajectory
KW  - Humanoid robots
KW  - Linear programming
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794072
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When experiencing disturbances during locomotion, human beings use several strategies to maintain balance, e.g. changing posture, modulating step frequency and location. However, when it comes to the gait generation for humanoid robots, modifying step time or body posture in real time introduces nonlinearities in the walking dynamics, thus increases the complexity of the planning. In this paper, we propose a two-layer hierarchical optimization framework to address this issue and provide the humanoids with the abilities of step time and step location adjustment, Center of Mass (CoM) height variation and angular momentum adaptation. In the first layer, times and locations of consecutive two steps are modulated online based on the current CoM state using the Linear Inverted Pendulum Model. By introducing new optimization variables to substitute the hyperbolic functions of step time, the derivatives of the objective function and feasibility constraints are analytically derived, thus reduces the computational cost. Then, taking the generated horizontal CoM trajectory, step times and step locations as inputs, CoM height and angular momentum changes are optimized by the second layer nonlinear model predictive control. This whole procedure will be repeated until the termination condition is met. The improved recovery capability under external disturbances is validated in simulation studies.
ER  - 

TY  - CONF
TI  - Using Deep Reinforcement Learning to Learn High-Level Policies on the ATRIAS Biped
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 263
EP  - 269
AU  - T. Li
AU  - H. Geyer
AU  - C. G. Atkeson
AU  - A. Rai
PY  - 2019
KW  - control system synthesis
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - neurocontrollers
KW  - deep reinforcement learning
KW  - expert knowledge
KW  - domain randomization
KW  - stable controllers
KW  - high-fidelity simulators
KW  - neural network policy
KW  - ATRIAS robot
KW  - bipedal robots
KW  - Neural networks
KW  - Hardware
KW  - Legged locomotion
KW  - Reinforcement learning
KW  - Torso
KW  - Foot
DO  - 10.1109/ICRA.2019.8793864
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning controllers for bipedal robots is a challenging problem, often requiring expert knowledge and extensive tuning of parameters that vary in different situations. Recently, deep reinforcement learning has shown promise at automatically learning controllers for complex systems in simulation. This has been followed by a push towards learning controllers that can be transferred between simulation and hardware, primarily with the use of domain randomization. However, domain randomization can make the problem of finding stable controllers even more challenging, especially for under actuated bipedal robots. In this work, we explore whether policies learned in simulation can be transferred to hardware with the use of high-fidelity simulators and structured controllers. We learn a neural network policy which is a part of a more structured controller. While the neural network is learned in simulation, the rest of the controller stays fixed, and can be tuned by the expert as needed. We show that using this approach can greatly speed up the rate of learning in simulation, as well as enable transfer of policies between simulation and hardware. We present our results on an ATRIAS robot and explore the effect of action spaces and cost functions on the rate of transfer between simulation and hardware. Our results show that structured policies can indeed be learned in simulation and implemented on hardware successfully. This has several advantages, as the structure preserves the intuitive nature of the policy, and the neural network improves the performance of the hand-designed policy. In this way, we propose a way of using neural networks to improve expert designed controllers, while maintaining ease of understanding.
ER  - 

TY  - CONF
TI  - Unsupervised Gait Phase Estimation for Humanoid Robot Walking*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 270
EP  - 276
AU  - S. Piperakis
AU  - S. Timotheatos
AU  - P. Trahanias
PY  - 2019
KW  - data acquisition
KW  - data reduction
KW  - humanoid robots
KW  - legged locomotion
KW  - pattern clustering
KW  - phase estimation
KW  - robot dynamics
KW  - robust control
KW  - state estimation
KW  - unsupervised learning
KW  - unsupervised gait phase estimation
KW  - humanoid robot walking
KW  - contact detection
KW  - feet contact status
KW  - proprioceptive sensing
KW  - inertial measurement unit
KW  - data acquisition
KW  - dimensionality reduction
KW  - state estimation
KW  - unsupervised learning
KW  - feature representation
KW  - gait phase dynamics
KW  - joint encoder
KW  - force data
KW  - torque data
KW  - clustering
KW  - robustness
KW  - legged robots
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Robot sensing systems
KW  - Kinematics
KW  - Unsupervised learning
DO  - 10.1109/ICRA.2019.8793598
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Contact detection is an important topic in contemporary humanoid robotic research. Up to date control and state estimation schemes readily assume that feet contact status is known in advance. In this work, we elaborate on a broader question: in which gait phase is the robot currently in? We introduce an unsupervised learning framework for gait phase estimation based solely on proprioceptive sensing, namely joint encoder, inertial measurement unit and force/torque data. Initially, a meaningful physical explanation on data acquisition is presented. Subsequently, dimensionality reduction is performed to obtain a compact low-dimensional feature representation followed by clustering into three groups, one for each gait phase. The proposed framework is qualitatively and quantitatively assessed in simulation with ground-truth data of uneven/rough terrain walking gaits and insights about the latent gait phase dynamics are drawn. Additionally, its efficacy and robustness is demonstrated when incorporated in leg odometry computation. Since our implementation is based on sensing that is commonly available on humanoids today, we release an open-source ROS/Python package to reinforce further research endeavors.
ER  - 

TY  - CONF
TI  - Stair Climbing Stabilization of the HRP-4 Humanoid Robot using Whole-body Admittance Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 277
EP  - 283
AU  - S. Caron
AU  - A. Kheddar
AU  - O. Tempier
PY  - 2019
KW  - end effectors
KW  - humanoid robots
KW  - legged locomotion
KW  - linear systems
KW  - nonlinear control systems
KW  - pendulums
KW  - quadratic programming
KW  - robot dynamics
KW  - stability
KW  - stair climbing stabilization
KW  - HRP-4 humanoid robot
KW  - whole-body admittance control
KW  - Airbus manufacturing use-case demonstrator
KW  - quadratic programming-based wrench distribution
KW  - whole-body admittance controller
KW  - walking controller
KW  - dynamic stair climbing
KW  - walking stabilization
KW  - linear inverted pendulum tracking
KW  - end-effector
KW  - CoM strategy
KW  - tracking performance
KW  - industrial staircase
KW  - open source software
KW  - size 18.5 cm
KW  - Admittance
KW  - Legged locomotion
KW  - Foot
KW  - Humanoid robots
KW  - Force
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794348
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider dynamic stair climbing with the HRP-4 humanoid robot as part of an Airbus manufacturing use-case demonstrator. We share experimental knowledge gathered so as to achieve this task, which HRP-4 had never been challenged to before. In particular, we extend walking stabilization based on linear inverted pendulum tracking [1] by quadratic programming-based wrench distribution and a whole-body admittance controller that applies both end-effector and CoM strategies. While existing stabilizers tend to use either one or the other, our experience suggests that the combination of these two approaches improves tracking performance. We demonstrate this solution in an on-site experiment where HRP4 climbs an industrial staircase with 18.5 cm high steps, and release our walking controller as open source software.
ER  - 

TY  - CONF
TI  - Reinforcement Learning Meets Hybrid Zero Dynamics: A Case Study for RABBIT
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 284
EP  - 290
AU  - G. A. Castillo
AU  - B. Weng
AU  - A. Hereid
AU  - Z. Wang
AU  - W. Zhang
PY  - 2019
KW  - adaptive control
KW  - control engineering computing
KW  - control system synthesis
KW  - feedback
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - mobile robots
KW  - PD control
KW  - robust control
KW  - stability
KW  - feedback controllers
KW  - bipedal robots
KW  - high-dimensional bipedal models
KW  - bipedal walking
KW  - bipedal control
KW  - walking limit cycles
KW  - HZD framework
KW  - policy learning
KW  - adaptive PD controller
KW  - stable control policy
KW  - robust control policy
KW  - RL framework
KW  - RABBIT robot model
KW  - reinforcement learning
KW  - local stability
KW  - hybrid zero dynamics
KW  - OpenAI gym
KW  - MuJoCo physics engine
KW  - Legged locomotion
KW  - Hip
KW  - Rabbits
KW  - Robot kinematics
KW  - Training
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793627
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The design of feedback controllers for bipedal robots is challenging due to the hybrid nature of its dynamics and the complexity imposed by high-dimensional bipedal models. In this paper, we present a novel approach for the design of feedback controllers using Reinforcement Learning (RL) and Hybrid Zero Dynamics (HZD). Existing RL approaches for bipedal walking are inefficient as they do not consider the underlying physics, often requires substantial training, and the resulting controller may not be applicable to real robots. HZD is a powerful tool for bipedal control with local stability guarantees of the walking limit cycles. In this paper, we propose a non traditional RL structure that embeds the HZD framework into the policy learning. More specifically, we propose to use RL to find a control policy that maps from the robot's reduced order states to a set of parameters that define the desired trajectories for the robot's joints through the virtual constraints. Then, these trajectories are tracked using an adaptive PD controller. The method results in a stable and robust control policy that is able to track variable speed within a continuous interval. Robustness of the policy is evaluated by applying external forces to the torso of the robot. The proposed RL framework is implemented and demonstrated in OpenAI Gym with the MuJoCo physics engine based on the well-known RABBIT robot model.
ER  - 

TY  - CONF
TI  - Learning Wheel Odometry and IMU Errors for Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 291
EP  - 297
AU  - M. BROSSARD
AU  - S. BONNABEL
PY  - 2019
KW  - cameras
KW  - distance measurement
KW  - Gaussian processes
KW  - image filtering
KW  - Kalman filters
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - nonlinear filters
KW  - path planning
KW  - robot vision
KW  - wheel odometry
KW  - IMU errors
KW  - odometry techniques
KW  - autonomous robot navigation
KW  - robust odometry system
KW  - camera
KW  - deep learning
KW  - variational inference
KW  - observation models
KW  - state-space systems
KW  - Gaussian processes
KW  - ground truth
KW  - wheel encoders
KW  - fiber optic gyro
KW  - EKF
KW  - wheel speed sensors
KW  - inertial measurement unit
KW  - extended Kalman filter
KW  - Wheels
KW  - Kernel
KW  - Mobile robots
KW  - Sensors
KW  - Gaussian processes
KW  - Training
KW  - Gaussian process
KW  - odometry estimation
KW  - variational inference
KW  - Kalman filter
DO  - 10.1109/ICRA.2019.8794237
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Odometry techniques are key to autonomous robot navigation, since they enable self-localization in the environment. However, designing a robust odometry system is particularly challenging when camera and LiDAR are uninformative or unavailable. In this paper, we leverage recent advances in deep learning and variational inference to correct dynamical and observation models for state-space systems. The methodology trains Gaussian processes on the residual between the original model and the ground truth, and is applied on publicly available datasets for robot navigation based on two wheel encoders, a fiber optic gyro, and an Inertial Measurement Unit (IMU). We also propose to build an Extended Kalman Filter (EKF) on the learned model using wheel speed sensors and the fiber optic gyro for state propagation, and the IMU to update the estimated state. Experimental results clearly demonstrate that the (learned) corrected models and EKF are more accurate than their original counterparts.
ER  - 

TY  - CONF
TI  - Radar-only ego-motion estimation in difficult settings via graph matching
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 298
EP  - 304
AU  - S. H. Cen
AU  - P. Newman
PY  - 2019
KW  - distance measurement
KW  - feature extraction
KW  - Global Positioning System
KW  - graph theory
KW  - image matching
KW  - motion estimation
KW  - object detection
KW  - radar detection
KW  - sensor fusion
KW  - speckle noise
KW  - scan matching accuracy
KW  - visual odometry
KW  - ego-motion estimation
KW  - stable range objects
KW  - long-range objects
KW  - variable weather
KW  - lighting conditions
KW  - radar-only odometry pipeline
KW  - radar artifacts
KW  - key point extraction
KW  - data association
KW  - graph matching optimization problem
KW  - Robot sensing systems
KW  - Azimuth
KW  - Radar measurements
KW  - Radar detection
KW  - Feature extraction
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793990
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Radar detects stable, long-range objects under variable weather and lighting conditions, making it a reliable and versatile sensor well suited for ego-motion estimation. In this work, we propose a radar-only odometry pipeline that is highly robust to radar artifacts (e.g., speckle noise and false positives) and requires only one input parameter. We demonstrate its ability to adapt across diverse settings, from urban UK to off-road Iceland, achieving a scan matching accuracy of approximately 5.20 cm and 0.0929 deg when using GPS as ground truth (compared to visual odometry's 5.77 cm and 0.1032 deg). We present algorithms for key point extraction and data association, framing the latter as a graph matching optimization problem, and provide an in-depth system analysis.
ER  - 

TY  - CONF
TI  - Recursive Integrity Monitoring for Mobile Robot Localization Safety
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 305
EP  - 311
AU  - G. D. Arana
AU  - O. A. Hafez
AU  - M. Joerger
AU  - M. Spenko
PY  - 2019
KW  - fault diagnosis
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - constant computation requirements
KW  - sequential chi-squared integrity monitoring methodology
KW  - fault detection
KW  - Extended Kalman Filter
KW  - mobile ground robots
KW  - open-sky aviation applications
KW  - integrity risk
KW  - mobile robot localization safety
KW  - recursive integrity monitoring
KW  - preceding time window
KW  - Monitoring
KW  - Feature extraction
KW  - Safety
KW  - Fault detection
KW  - Robot sensing systems
KW  - Kalman filters
DO  - 10.1109/ICRA.2019.8794115
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a new methodology to quantify robot localization safety by evaluating integrity risk, a performance metric widely used in open-sky aviation applications that has been recently extended to mobile ground robots. Here, a robot is localized by feeding relative measurements to mapped landmarks into an Extended Kalman Filter while a sequence of innovations is evaluated for fault detection. The main contribution is the derivation of a sequential chi-squared integrity monitoring methodology that maintains constant computation requirements by employing a preceding time window and, at the same time, is robust against faults occurring prior to the window. Additionally, no assumptions are made on either the nature or shape of the faults because safety is evaluated under the worst possible combination of sensor faults.
ER  - 

TY  - CONF
TI  - Four-Wheeled Dead-Reckoning Model Calibration using RTS Smoothing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 312
EP  - 318
AU  - A. Welte
AU  - P. Xu
AU  - P. Bonnifait
PY  - 2019
KW  - automobiles
KW  - calibration
KW  - inertial navigation
KW  - Kalman filters
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - remotely operated vehicles
KW  - sensor fusion
KW  - smoothing methods
KW  - state estimation
KW  - RTS smoothing
KW  - autonomous vehicles
KW  - accurate dead-reckoning system
KW  - car-like vehicles
KW  - complementary sensors
KW  - redundant sensors
KW  - wheel encoders
KW  - yaw rate gyro
KW  - steering wheel measurements
KW  - ground truth
KW  - smoothing scheme
KW  - smoothed estimates
KW  - model parameters
KW  - experimental vehicle
KW  - public roads
KW  - dead-reckoning drift
KW  - commonly used calibration method
KW  - dead reckoning system
KW  - four-wheeled dead-reckoning model calibration
KW  - complex maneuvers
KW  - public traffic
KW  - Wheels
KW  - Sensors
KW  - Smoothing methods
KW  - Global navigation satellite system
KW  - Calibration
KW  - Dead reckoning
KW  - Radio frequency
DO  - 10.1109/ICRA.2019.8794270
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Localization is one of the main challenges to be addressed to develop autonomous vehicles able to perform complex maneuvers on roads opened to public traffic. Having an accurate dead-reckoning system is an essential step to reach this objective. This paper presents a dead-reckoning model for car-like vehicles that performs the data fusion of complementary and redundant sensors: wheel encoders, yaw rate gyro and steering wheel measurements. In order to get an accurate dead-reckoning system with a drift reduced to the minimum, the parameters have to be well calibrated and the procedure has to be simple and efficient. We present a method able to accurately calibrate the parameters without knowing the ground truth by using a Rauch-Tung-Striebel smoothing scheme which enables to obtain state estimates as close to the ground truth as possible. The smoothed estimates are then used within a optimization process to calibrate the model parameters. The method has been tested using data recorded from an experimental vehicle on public roads. The results show a significant diminution of the dead-reckoning drift compared to a commonly used calibration method. We evaluate finally the average distance a vehicle can navigate without exteroceptive sensors by using the proposed four-wheeled dead reckoning system.
ER  - 

TY  - CONF
TI  - A Multi-Domain Feature Learning Method for Visual Place Recognition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 319
EP  - 324
AU  - P. Yin
AU  - L. Xu
AU  - X. Li
AU  - C. Yin
AU  - Y. Li
AU  - R. A. Srivatsan
AU  - L. Li
AU  - J. Ji
AU  - Y. He
PY  - 2019
KW  - feature extraction
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - computer vision
KW  - robotics applications
KW  - VPR methods
KW  - place recognition performance
KW  - environmental factors
KW  - end-to-end conditional visual place recognition method
KW  - multidomain feature learning method
KW  - feature detaching module
KW  - environmental condition-related features
KW  - feature learning pipeline
KW  - multiseason NORDLAND dataset
KW  - multiweather GTAV dataset
KW  - feature robustness
KW  - variant environmental conditions
KW  - Feature extraction
KW  - Entropy
KW  - Visualization
KW  - Task analysis
KW  - Decoding
KW  - Robots
KW  - Upper bound
DO  - 10.1109/ICRA.2019.8793752
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual Place Recognition (VPR) is an important component in both computer vision and robotics applications, thanks to its ability to determine whether a place has been visited and where specifically. A major challenge in VPR is to handle changes of environmental conditions including weather, season and illumination. Most VPR methods try to improve the place recognition performance by ignoring the environmental factors, leading to decreased accuracy decreases when environmental conditions change significantly, such as day versus night. To this end, we propose an end-to-end conditional visual place recognition method. Specifically, we introduce the multi-domain feature learning method (MDFL) to capture multiple attribute-descriptions for a given place, and then use a feature detaching module to separate the environmental condition-related features from those that are not. The only label required within this feature learning pipeline is the environmental condition. Evaluation of the proposed method is conducted on the multi-season NORDLAND dataset, and the multi-weather GTAV dataset. Experimental results show that our method improves the feature robustness against variant environmental conditions.
ER  - 

TY  - CONF
TI  - Event-based, Direct Camera Tracking from a Photometric 3D Map using Nonlinear Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 325
EP  - 331
AU  - S. Bryner
AU  - G. Gallego
AU  - H. Rebecq
AU  - D. Scaramuzza
PY  - 2019
KW  - cameras
KW  - image reconstruction
KW  - image sensors
KW  - maximum likelihood estimation
KW  - motion estimation
KW  - motion measurement
KW  - nonlinear programming
KW  - photometry
KW  - pose estimation
KW  - asynchronous sensors
KW  - low power consumption
KW  - photometric 3D map
KW  - classic dense 3D reconstruction algorithms
KW  - bioinspired vision sensors
KW  - video imaging
KW  - output pixel-level intensity
KW  - event-based direct camera tracking
KW  - nonlinear optimization
KW  - robot localization
KW  - AR-VR
KW  - 6-DOF pose tracking
KW  - maximum-likelihood framework
KW  - event camera motion estimation
KW  - Cameras
KW  - Robot vision systems
KW  - Three-dimensional displays
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794255
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Event cameras are novel bio-inspired vision sensors that output pixel-level intensity changes, called “events”, instead of traditional video images. These asynchronous sensors naturally respond to motion in the scene with very low latency (microseconds) and have a very high dynamic range. These features, along with a very low power consumption, make event cameras an ideal sensor for fast robot localization and wearable applications, such as AR/VR and gaming. Considering these applications, we present a method to track the 6-DOF pose of an event camera in a known environment, which we contemplate to be described by a photometric 3D map (i.e., intensity plus depth information) built via classic dense 3D reconstruction algorithms. Our approach uses the raw events, directly, without intermediate features, within a maximum-likelihood framework to estimate the camera motion that best explains the events via a generative model. We successfully evaluate the method using both simulated and real data, and show improved results over the state of the art. We release the datasets to the public to foster reproducibility and research in this topic.
ER  - 

TY  - CONF
TI  - Linear Heterogeneous Reconfiguration of Cubic Modular Robots via Simultaneous Tunneling and Permutation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 332
EP  - 338
AU  - H. Kawano
PY  - 2019
KW  - computational complexity
KW  - control engineering computing
KW  - distributed control
KW  - evolutionary computation
KW  - mobile robots
KW  - multi-robot systems
KW  - reconfigurable architectures
KW  - heterogeneous lattice modular robots
KW  - linear operation time cost
KW  - 2×2×2 cubic meta-module-based connected robot structure
KW  - heterogeneous modular robots
KW  - linear heterogeneous reconfiguration
KW  - cubic modular robots
KW  - ordinary heterogeneous reconfiguration
KW  - linear homogeneous transformation
KW  - linear heterogeneous permutation
KW  - simultaneous tunneling and permutation
KW  - Tunneling
KW  - Computer aided software engineering
KW  - Cameras
KW  - Robot vision systems
KW  - Robot kinematics
KW  - Lattices
DO  - 10.1109/ICRA.2019.8793594
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Reconfiguring heterogeneous modular robots in which all modules are not identical is much more time consuming than reconfiguring homogeneous ones, because ordinary heterogeneous reconfiguration is a combination of homogeneous transformation and heterogeneous permutation. While linear homogeneous transformation has been accomplished in previous research, linear heterogeneous permutation has not. This paper studies a reconfiguration algorithm for heterogeneous lattice modular robots with linear operation time cost. The algorithm is based on simultaneous tunneling and permutation, where a robot transforms its configuration via tunneling motion while permutation of each module's position is performed simultaneously during the tunneling transformation. To achieve this, we introduce the idea of a transparent meta-module that allows modules belonging to a meta-module to pass through the spaces occupied by other meta-modules. We prove the correctness and completeness of the proposed algorithm for a 2×2×2 cubic meta-module-based connected robot structure. We also show examples of the reconfiguration simulations of heterogeneous modular robots by the proposed algorithm.
ER  - 

TY  - CONF
TI  - Autonomous Sheet Pile Driving Robots for Soil Stabilization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 339
EP  - 345
AU  - N. Melenbrink
AU  - J. Werfel
PY  - 2019
KW  - construction equipment
KW  - construction industry
KW  - erosion
KW  - foundations
KW  - geotechnical engineering
KW  - hammers (machines)
KW  - mobile robots
KW  - soil
KW  - stability
KW  - autonomous sheet pile
KW  - soil stabilization
KW  - construction projects
KW  - environmental restoration projects
KW  - autonomous robot
KW  - continuous linear structures
KW  - vibratory hammer
KW  - hardware parameters
KW  - spray-based stabilizing agent
KW  - hydraulic erosion
KW  - Robots
KW  - Soil
KW  - Task analysis
KW  - Dams
KW  - Force
KW  - Actuators
KW  - Automation
DO  - 10.1109/ICRA.2019.8793546
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soil stabilization is a fundamental component of nearly all construction projects, ranging from commercial construction to environmental restoration projects. Previous work in autonomous construction has generally not considered these essential stabilization and anchoring tasks. In this work we present Romu, an autonomous robot capable of building continuous linear structures by using a vibratory hammer to drive interlocking sheet piles into soil. We report on hardware parameters and their effects on pile driving performance, and demonstrate autonomous operation in both controlled and natural environments. Finally, we present simulations in which a small swarm of robots build with sheet piles in example terrains, or apply an alternate spray-based stabilizing agent, and quantify the ability of each intervention to mitigate hydraulic erosion.
ER  - 

TY  - CONF
TI  - ModQuad-Vi: A Vision-Based Self-Assembling Modular Quadrotor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 346
EP  - 352
AU  - G. Li
AU  - B. Gabrich
AU  - D. Saldaña
AU  - J. Das
AU  - V. Kumar
AU  - M. Yim
PY  - 2019
KW  - autonomous aerial vehicles
KW  - indoor radio
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - self-assembly
KW  - relative pose estimation
KW  - local estimation
KW  - self-assembly process
KW  - external systems
KW  - ModQuad-Vi
KW  - flying modular robot
KW  - robot design
KW  - vision-based docking method
KW  - docking actions
KW  - aerial modular system
KW  - vision-based self-assembling modular quadrotor
KW  - temporary structures
KW  - indoor infrastructures
KW  - Robot kinematics
KW  - Acceleration
KW  - Rotors
KW  - Force
KW  - Trajectory
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794056
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Flying modular robots have the potential to rapidly form temporary structures. In the literature, docking actions rely on external systems and indoor infrastructures for relative pose estimation. In contrast to related work, we provide local estimation during the self-assembly process to avoid dependency on external systems. In this paper, we introduce ModQuad-Vi, a flying modular robot that is aimed to operate in outdoor environments. We propose a new robot design and vision-based docking method. Our design is based on a quadrotor platform with onboard computation and visual perception. Our control method is able to accurately align modules for docking actions. Additionally, we present the dynamics and a geometric controller for the aerial modular system. Experiments validate the vision-based docking method with successful results.
ER  - 

TY  - CONF
TI  - Robotic endoscopy system (easyEndo) with a robotic arm mountable on a conventional endoscope
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 367
EP  - 372
AU  - D. Lee
AU  - M. Hwang
AU  - D. Kwon
PY  - 2019
KW  - biological tissues
KW  - biomechanics
KW  - endoscopes
KW  - manipulators
KW  - medical robotics
KW  - tissue traction
KW  - lesion
KW  - rubber band
KW  - robotic arm
KW  - flexible endoscope
KW  - robotic manipulations
KW  - intuitive hand-held controllers
KW  - solo-endoscopy
KW  - conventional endoscope
KW  - robotic endoscopy system
KW  - Endoscopes
KW  - Manipulators
KW  - Instruments
KW  - Medical services
KW  - Cameras
KW  - Gears
DO  - 10.1109/ICRA.2019.8793626
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The use of flexible endoscope has been rising inconveniences. Steering of the distal section is not intuitive and the weight of the endoscope burdens a physical pressure on physicians who use it continuously for a long time. Also, the limited dexterity of an instrument makes therapeutic procedures more difficult, and further the unintended communications often occur during cooperation with assistants. These degrade the efficiency and thus increase the procedure time. In this paper, we propose a robotic endoscopy system (easyEndo) that can be mounted on a conventional endoscope and facilitate solo-endoscopy with two intuitive hand-held controllers. Furthermore, a robotic arm is presented that can be attached to the endoscope to assist with tissue traction. To validate the robotic endoscopy system, experiments to simulate biopsy and lesion marking were conducted with novices. The results showed that the robotic manipulations improved efficiency and reduced workload than manual manipulation. Subsequently, a prototype of the robotic arm was attached at the distal end of the endoscope, and the feasibility of tissue traction was confirmed by a simulation of pulling a rubber band.
ER  - 

TY  - CONF
TI  - Design and Fabrication of Transformable Head Structures for Endoscopic Catheters*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 373
EP  - 378
AU  - S. Kwon
AU  - S. V. Kalker
AU  - S. H. Choi
AU  - K. Kim
AU  - K. S. Park
AU  - S. Kang
AU  - C. Kim
AU  - S. C. Ryu
PY  - 2019
KW  - biomedical optical imaging
KW  - cameras
KW  - catheters
KW  - endoscopes
KW  - medical image processing
KW  - medical robotics
KW  - polymers
KW  - camera module
KW  - transformable catheter head structure
KW  - endoscopic catheter
KW  - laser micromachining
KW  - polymer catheter
KW  - Catheters
KW  - Head
KW  - Magnetic heads
KW  - Tools
KW  - Electron tubes
KW  - Polymers
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794256
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a transformable catheter head structure for endoscopic catheter allowing the simultaneous use of a camera module and a large tool channel introduced through a small incision. At the site of interest, the head with a camera can be expanded from the initial straight configuration, which opens a window for advancing a tool that is located behind the camera. Two different designs were proposed and prototyped. One option has flexure joints directly fabricated at the distal end of a polymer catheter by laser micro-machining, while another design employs a hinged metal head assembled at the tip of the same type of catheter. The kinematic behavior of each head was evaluated during the head-up and tip steering motions, and compared with each other to draw a selection guideline between them. Experimental results prove the feasibility of the proposed head structure for smarter endoscopic catheters.
ER  - 

TY  - CONF
TI  - A Rolling-Tip Flexible Instrument for Minimally Invasive Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 379
EP  - 385
AU  - A. Schmitz
AU  - S. Treratanakulchai
AU  - P. Berthet-Rayne
AU  - G. Yang
PY  - 2019
KW  - dexterous manipulators
KW  - end effectors
KW  - flexible manipulators
KW  - grippers
KW  - medical robotics
KW  - mobile robots
KW  - prototypes
KW  - surgery
KW  - rolling-tip flexible instrument
KW  - human body
KW  - end-effector
KW  - instrument prototype
KW  - in-place rolling motion
KW  - rolling-tip gripper
KW  - minimally invasive surgery
KW  - snake-like robots
KW  - tendons
KW  - 6 degrees-of-freedom
KW  - dexterity
KW  - Tendons
KW  - Instruments
KW  - Grippers
KW  - Fasteners
KW  - Surgery
KW  - End effectors
DO  - 10.1109/ICRA.2019.8793480
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Snake-like robots are commonly used in Minimally Invasive Surgery as they are able to reach areas deep inside the human body. These robots have instruments that are deployed out of the robot's head and controlled via tendons, which connect the instrument to motors at the proximal end. In most currently available systems the instruments are lacking a rolling motion of the end-effector.In this paper, we present a new instrument prototype for a snake-like robot that can perform a stable in-place rolling motion. The prototype has a diameter of 4mm, uses 13 tendons and has 6 degrees of freedom. The robot can bend and roll to high angles, and strongly improves the dexterity compared to an instrument without rolling capabilities. In the evaluation we show that the rolling-tip gripper can rotate about 165° and is capable of applying forces up to 6.5N.
ER  - 

TY  - CONF
TI  - A Novel Laser Scalpel System for Computer-assisted Laser Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 386
EP  - 392
AU  - G. Ma
AU  - W. A. Ross
AU  - I. Hill
AU  - N. Narasimhan
AU  - P. J. Codd
PY  - 2019
KW  - biomedical optical imaging
KW  - cameras
KW  - laser applications in medicine
KW  - medical computing
KW  - phantoms
KW  - radiation therapy
KW  - skin
KW  - surgery
KW  - planar phantoms
KW  - cylindrical phantoms
KW  - root-mean-square
KW  - carbon dioxide laser scalpel
KW  - laser scalpel system
KW  - 3D extrinsic calibration method
KW  - 3D triangulation sensor
KW  - superficial laser therapy applications
KW  - dermatological procedures
KW  - surgical procedures
KW  - computer-assisted laser surgery
KW  - sensor system
KW  - automated laser therapy
KW  - laser coordinate system
KW  - RGB-D camera frame
KW  - Three-dimensional displays
KW  - Lasers
KW  - Cameras
KW  - Calibration
KW  - Surgery
KW  - Measurement by laser beam
KW  - Color
DO  - 10.1109/ICRA.2019.8794066
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Laser scalpels are utilized across a variety of surgical and dermatological procedures due to their precision and non-contact nature. This paper presents a novel laser scalpel system for superficial laser therapy applications. The system integrates a RGB-D camera, a 3D triangulation sensor and a carbon dioxide (CO2) laser scalpel for computer-assisted laser surgery. To accurately ablate targets chosen from the color image, a 3D extrinsic calibration method between the RGB-D camera frame and the laser coordinate system is implemented. The accuracy of the calibration method is tested on phantoms with planar and cylindrical surfaces. Positive error and negative error, as defined as undershooting and overshooting over the target area, are reported for each test. For 60 total test cases, the root-mean-square of the positive and negative error in both planar and cylindrical phantoms is less than 1.0 mm, with a maximum absolute error less than 2.0 mm. This work demonstrates the feasibility of automated laser therapy with surgeon oversight via our sensor system.
ER  - 

TY  - CONF
TI  - Intent-Uncertainty-Aware Grasp Planning for Robust Robot Assistance in Telemanipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 409
EP  - 415
AU  - M. Bowman
AU  - S. Li
AU  - X. Zhang
PY  - 2019
KW  - dexterous manipulators
KW  - grippers
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - telerobotics
KW  - intent-uncertainty-aware grasp planning
KW  - robust robot assistance
KW  - robot agent
KW  - motion assistance
KW  - target approaching process
KW  - fine motion constraints
KW  - ambiguous human motion
KW  - robot hands
KW  - planning techniques
KW  - human motion input
KW  - multitask robot
KW  - intent-uncertainty-aware grasp planner
KW  - robust grasp
KW  - ambiguous human intent inference inputs
KW  - teleoperated robots
KW  - object manipulation task
KW  - Task analysis
KW  - Robots
KW  - Planning
KW  - Uncertainty
KW  - Handover
KW  - Grasping
DO  - 10.1109/ICRA.2019.8793819
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Promoting a robot agent's autonomy level, which allows it to understand the human operator's intent and provide motion assistance to achieve it, has demonstrated great advantages to the operator's intent in teleoperation. However, the research has been limited to the target approaching process. We advance the shared control technique one step further to deal with the more challenging object manipulation task. Appropriately manipulating an object is challenging as it requires fine motion constraints for a certain manipulation task. Although these motion constraints are critical for task success, they are subtle to observe from ambiguous human motion. The disembodiment problem and physical discrepancy between the human and robot hands bring additional uncertainty, make the object manipulation task more challenging. Moreover, there is a lack of modeling and planning techniques that can effectively combine the human motion input and robot agent's motion input while accounting for the ambiguity of the human intent. To overcome this challenge, we built a multi-task robot grasping model and developed an intent-uncertainty-aware grasp planner to generate robust grasp poses given the ambiguous human intent inference inputs. With this validated modeling and planning techniques, it is expected to extend teleoperated robots' functionality and adoption in practical telemanipulation scenarios.
ER  - 

TY  - CONF
TI  - Vision-based Teleoperation of Shadow Dexterous Hand using End-to-End Deep Neural Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 416
EP  - 422
AU  - S. Li
AU  - X. Ma
AU  - H. Liang
AU  - M. Görner
AU  - P. Ruppel
AU  - B. Fang
AU  - F. Sun
AU  - J. Zhang
PY  - 2019
KW  - dexterous manipulators
KW  - human-robot interaction
KW  - image classification
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - pose estimation
KW  - robot vision
KW  - telerobotics
KW  - TeachNet
KW  - Shadow dexterous hand
KW  - end-to-end deep neural network
KW  - intuitive vision-based teleoperation
KW  - markerless vision-based teleoperation
KW  - dexterous robotic hands
KW  - robot joint angles
KW  - human hand
KW  - visually similar robot hand
KW  - consistency loss function
KW  - human hands
KW  - human-robot training set
KW  - labeled depth images
KW  - simulated depth images
KW  - Shadow C6 robotic hand
KW  - pairwise depth images
KW  - vision-based teleoperation method
KW  - Training
KW  - Pose estimation
KW  - Three-dimensional displays
KW  - Neural networks
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794277
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present TeachNet, a novel neural network architecture for intuitive and markerless vision-based teleoperation of dexterous robotic hands. Robot joint angles are directly generated from depth images of the human hand that produce visually similar robot hand poses in an end-to-end fashion. The special structure of TeachNet, combined with a consistency loss function, handles the differences in appearance and anatomy between human and robotic hands. A synchronized human-robot training set is generated from an existing dataset of labeled depth images of the human hand and simulated depth images of a robotic hand. The final training set includes 400K pairwise depth images and joint angles of a Shadow C6 robotic hand. The network evaluation results verify the superiority of TeachNet, especially regarding the high-precision condition. Imitation experiments and grasp tasks teleoperated by novice users demonstrate that TeachNet is more reliable and faster than the state-of-the-art vision-based teleoperation method.
ER  - 

TY  - CONF
TI  - An energy-shared two-layer approach for multi-master-multi-slave bilateral teleoperation systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 423
EP  - 429
AU  - M. Minelli
AU  - F. Ferraguti
AU  - N. Piccinelli
AU  - R. Muradore
AU  - C. Secchi
PY  - 2019
KW  - delay systems
KW  - medical robotics
KW  - surgery
KW  - telerobotics
KW  - energy-shared two-layer approach
KW  - multimaster-multislave bilateral teleoperation systems
KW  - two-layer architecture
KW  - multiarms systems
KW  - communication delay
KW  - energy tank
KW  - single-master-single-slave two layer approach
KW  - passivity preservation
KW  - surgical scenario
KW  - Computer architecture
KW  - Surgery
KW  - Robot kinematics
KW  - Force
KW  - Delays
KW  - Communication channels
DO  - 10.1109/ICRA.2019.8794335
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, a two-layer architecture for the bilateral teleoperation of multi-arms systems with communication delay is presented. We extend the single-master-single-slave two layer approach proposed in [1] by connecting multiple robots to a single energy tank. This allows to minimize the conservativeness due to passivity preservation and to increment the level of transparency that can be achieved. The proposed approach is implemented on a realistic surgical scenario developed within the EU-funded SARAS project.
ER  - 

TY  - CONF
TI  - Passive Task-Prioritized Shared-Control Teleoperation with Haptic Guidance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 430
EP  - 436
AU  - M. Selvaggio
AU  - P. Robuffo Giordano
AU  - F. Ficuciellol
AU  - B. Siciliano
PY  - 2019
KW  - control engineering computing
KW  - haptic interfaces
KW  - telerobotics
KW  - passive task-prioritized shared-control teleoperation
KW  - robot teleoperation
KW  - teleoperator capabilities shared-control methods
KW  - passive task-prioritized shared-control method
KW  - redundant robots
KW  - task-prioritized control architecture
KW  - haptic guidance techniques
KW  - shared-control framework
KW  - semiautonomous telerobotic system safety
KW  - energy-tanks passivity-based controller
KW  - simulated slave robot
KW  - Task analysis
KW  - Haptic interfaces
KW  - Jacobian matrices
KW  - Manipulators
KW  - Robot kinematics
KW  - Couplings
DO  - 10.1109/ICRA.2019.8794197
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot teleoperation is widely used for several hazardous applications. To increase teleoperator capabilities shared-control methods can be employed. In this paper, we present a passive task-prioritized shared-control method for remote telemanipulation of redundant robots. The proposed method fuses the task-prioritized control architecture with haptic guidance techniques to realize a shared-control framework for teleoperation systems. To preserve the semi-autonomous telerobotic system safety, passivity is analyzed and an energy-tanks passivity-based controller is developed. The proposed theoretical results are validated through experiments involving a real haptic device and a simulated slave robot.
ER  - 

TY  - CONF
TI  - Quasi-Direct Drive for Low-Cost Compliant Robotic Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 437
EP  - 443
AU  - D. V. Gealy
AU  - S. McKinley
AU  - B. Yi
AU  - P. Wu
AU  - P. R. Downey
AU  - G. Balke
AU  - A. Zhao
AU  - M. Guo
AU  - R. Thomasson
AU  - A. Sinclair
AU  - P. Cuellar
AU  - Z. McCarthy
AU  - P. Abbeel
PY  - 2019
KW  - control engineering computing
KW  - force control
KW  - manipulators
KW  - position control
KW  - telerobotics
KW  - user interfaces
KW  - virtual reality
KW  - QuasiDirect Drive actuation
KW  - robotic force-controlled manipulation
KW  - telepresence
KW  - Blue system
KW  - human environments
KW  - robot training demonstrations
KW  - 7 degree of freedom arm
KW  - position-control bandwidth
KW  - virtual reality based interface
KW  - compliant robotic manipulation
KW  - mass 2.0 kg
KW  - frequency 7.5 Hz
KW  - size 4.0 mm
KW  - Manipulators
KW  - Payloads
KW  - Bandwidth
KW  - Robot sensing systems
KW  - Task analysis
KW  - Belts
DO  - 10.1109/ICRA.2019.8794236
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots must cost less and be force-controlled to enable widespread, safe deployment in unconstrained human environments. We propose Quasi-Direct Drive actuation as a capable paradigm for robotic force-controlled manipulation in human environments at low-cost. Our prototype - Blue - is a human scale 7 Degree of Freedom arm with 2kg payload. Blue can cost less than $5000. We show that Blue has dynamic properties that meet or exceed the needs of human operators: the robot has a nominal position-control bandwidth of 7.5Hz and repeatability within 4mm. We demonstrate a Virtual Reality based interface that can be used as a method for telepresence and collecting robot training demonstrations. Manufacturability, scaling, and potential use-cases for the Blue system are also addressed. Videos and additional information can be found online at berkeleyopenarms.github.io.
ER  - 

TY  - CONF
TI  - Augmented Reality Predictive Displays to Help Mitigate the Effects of Delayed Telesurgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 444
EP  - 450
AU  - F. Richter
AU  - Y. Zhang
AU  - Y. Zhi
AU  - R. K. Orosco
AU  - M. C. Yip
PY  - 2019
KW  - augmented reality
KW  - medical computing
KW  - medical robotics
KW  - surgery
KW  - telemedicine
KW  - telerobotics
KW  - da Vinci surgical system
KW  - SARPD
KW  - augmented reality predictive displays
KW  - stereoscopic AR predictive display
KW  - predictive displays
KW  - visual feedback
KW  - teleoperated surgical robots
KW  - surgical environment
KW  - remote operator
KW  - remote telesurgery
KW  - Delays
KW  - Rendering (computer graphics)
KW  - Cameras
KW  - Stereo image processing
KW  - Real-time systems
KW  - Transforms
KW  - Robots
DO  - 10.1109/ICRA.2019.8794051
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Surgical robots offer the exciting potential for remote telesurgery, but advances are needed to make this technology efficient and accurate to ensure patient safety. Achieving these goals is hindered by the deleterious effects of latency between the remote operator and the bedside robot. Predictive displays have found success in overcoming these effects by giving the operator immediate visual feedback. However, previously developed predictive displays can not be directly applied to telesurgery due to the unique challenges in tracking the 3D geometry of the surgical environment. In this paper, we present the first predictive display for teleoperated surgical robots. The predicted display is stereoscopic, utilizes Augmented Reality (AR) to show the predicted motions alongside the complex tissue found in-situ within surgical environments, and overcomes the challenges in accurately tracking slave-tools in real-time. We call this a Stereoscopic AR Predictive Display (SARPD). To test the SARPD's performance, we conducted a user study with ten participants on the da Vinci® Surgical System. The results showed with statistical significance that using SARPD decreased time to complete task while having no effect on error rates when operating under delay.
ER  - 

TY  - CONF
TI  - Stability Optimization of Two-Fingered Anthropomorphic Hands for Precision Grasping with a Single Actuator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 451
EP  - 457
AU  - M. T. Leddy
AU  - A. M. Dollar
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - dexterous manipulators
KW  - grippers
KW  - prosthetics
KW  - link length ratios
KW  - anthropomorphic design parameters
KW  - grasp planning applications
KW  - optimal configuration
KW  - heuristically evaluated optimal solutions
KW  - post-contact system work
KW  - upper limb prosthetic design
KW  - palm width
KW  - joint stiffness ratios
KW  - transmission ratios
KW  - post-contact stability
KW  - constrained optimization framework
KW  - single actuator
KW  - precision grasping
KW  - two-fingered anthropomorphic hands
KW  - stability optimization
KW  - Force
KW  - Grasping
KW  - Actuators
KW  - Tendons
KW  - Optimization
KW  - Stability criteria
DO  - 10.1109/ICRA.2019.8793812
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a constrained optimization framework for evaluating the post-contact stability of underactuated precision grasping configurations with a single degree of actuation. Relationships between key anthropomorphic design parameters including link length ratios, transmission ratios, joint stiffness ratios and palm width are developed with applications in upper limb prosthetic design. In addition to grasp stability, we examine post-contact system work, to reduce reconfiguration, and consider the range of objects that can be stably grasped. External wrenches were simulated on a subset of the heuristically evaluated optimal solutions and an optimal configuration was experimentally tested to determine favorable wrench resistible gripper orientations for grasp planning applications.
ER  - 

TY  - CONF
TI  - A new Approach for an Adaptive Linear Quadratic Regulated Motion Cueing Algorithm for an 8 DoF Full Motion Driving Simulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 497
EP  - 503
AU  - T. Miunske
AU  - C. Holzapfel
AU  - E. Baumgartner
AU  - H. Reuss
PY  - 2019
KW  - linear quadratic control
KW  - minimisation
KW  - motion control
KW  - road vehicles
KW  - vehicle dynamics
KW  - 8 DoF full motion driving simulator
KW  - Stuttgart Driving Simulator
KW  - state-flow chart
KW  - kinematic vehicle movements
KW  - motion driving simulator
KW  - adaptive motion cueing algorithm
KW  - adaptive linear quadratic regulated motion cueing algorithm
KW  - linear quadratic error minimization
KW  - Acceleration
KW  - Switches
KW  - Vehicles
KW  - Heuristic algorithms
KW  - Vehicle dynamics
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794109
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this contribution, a new adaptive motion cueing algorithm for a full motion driving simulator at the University of Stuttgart is presented, which allows kinematic vehicle movements to be taken into account. These are adequately processed via a state-flow chart and transferred to the motion cueing algorithm in such a way that the dynamic of the Stuttgart Driving Simulator can be used much more efficiently. Furthermore, a linear quadratic error minimization of the mentioned algorithm is presented. The primary objective is to provide a more realistic driving experience to the driver.
ER  - 

TY  - CONF
TI  - Singularity of Cable-Driven Parallel Robot With Sagging Cables: Preliminary Investigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 504
EP  - 509
AU  - J. Merlet
PY  - 2019
KW  - cables (mechanical)
KW  - manipulator kinematics
KW  - cable-driven parallel robot
KW  - sagging cables
KW  - singularity analysis
KW  - CDPR
KW  - Irvine model
KW  - cable model representation singularity
KW  - singularity type
KW  - IK singularity
KW  - parallel robot singularity
KW  - inverse kinematics
KW  - forward kinematics
KW  - rigid legs
KW  - Parallel robots
KW  - Mathematical model
KW  - Kinematics
KW  - Zirconium
KW  - Legged locomotion
KW  - End effectors
KW  - parallel robot cable-driven parallel robot
KW  - singularity
DO  - 10.1109/ICRA.2019.8794218
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses for the first time the singularity analysis of cable-driven parallel robot (CDPR) with sagging cables using the Irvine model. We present the mathematical framework of singularity analysis of CDPR using this cable model. We then show that, besides a cable model representation singularity, both the inverse and forward kinematics (IK and FK) have a singularity type, called parallel robot singularity, which correspond to the singularity of an equivalent parallel robot with rigid legs. We then show that both the IK and FK have also full singularities, that are not parallel robot singularity and are obtained when two of the IK or FK solution branches intersect. IK singularity will usually lie on the border of the CDPR workspace. We then exhibit an algorithm that allow one to prove that a singularity exist in the neighborhood of a given pose and to estimate its location with an arbitrary accuracy. Examples are provided for parallel robot, IK and FK singularities. However we have not been able to determine examples of combined singularity where both the IK and FK are singular (besides parallel robot singularity).
ER  - 

TY  - CONF
TI  - A defect identification approach of operations for the driving element of multi-duty parallel manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 510
EP  - 516
AU  - S. Fan
AU  - S. Fan
AU  - W. Lan
AU  - G. Song
PY  - 2019
KW  - end effectors
KW  - fasteners
KW  - force control
KW  - industrial manipulators
KW  - machining
KW  - defect identification approach
KW  - driving element
KW  - multiduty parallel manipulators
KW  - heavy-load
KW  - 1PU+3UPS parallel manipulator
KW  - machining efficiency improvement
KW  - Force
KW  - Indexes
KW  - Machining
KW  - Fasteners
KW  - Manipulator dynamics
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794326
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In order to improve the machining efficiency and the flexibility of manufacturing system, the study of multi-duty parallel manipulators has attracted the interest of some researchers. In this paper, according to the effects of different operations on the driving element, a demarcation diagram for distinguishing different duties, such as statics, low-speed but heavy-load, high-speed but low-load and high-speed but heavy-load, is proposed, and a defect identification approach to prevent the occurrence of defects for multi-duty parallel manipulators is presented. Taking the 1PU+3UPS parallel manipulator as an instance, an analysis method to the statics and dynamics is investigated by means of the screw theory and the proposed virtual screw. Based on the numerical example, the results show that the classification and practicability of operations can be accurately identified by the proposed demarcation diagram and defect identification approach, respectively.
ER  - 

TY  - CONF
TI  - Active Damping of Parallel Robots Driven by Flexible Cables Using Cold-Gas Thrusters
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 530
EP  - 536
AU  - H. Sellet
AU  - I. Khayour
AU  - L. Cuvillon
AU  - S. Durand
AU  - J. Gangloff
PY  - 2019
KW  - cables (mechanical)
KW  - damping
KW  - flexible manipulators
KW  - manipulator dynamics
KW  - supersonic flow
KW  - planar robot
KW  - custom-built supersonic air thrusters
KW  - active damping
KW  - cold-gas thrusters
KW  - flexible cable-driven parallel robots
KW  - industry-standard pressure level
KW  - Attitude control
KW  - Vibrations
KW  - End effectors
KW  - Valves
KW  - Damping
KW  - Bars
DO  - 10.1109/ICRA.2019.8794061
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work is a preliminary study assessing the feasibility of using cold-gas thrusters for active damping of flexible cable-driven parallel robots. The concept is validated experimentally on a planar robot embedding custom-built supersonic air thrusters operating at an industry-standard pressure level.
ER  - 

TY  - CONF
TI  - Exploiting Human and Robot Muscle Synergies for Human-in-the-loop Optimization of EMG-based Assistive Strategies
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 549
EP  - 555
AU  - M. Hamaya
AU  - T. Matsubara
AU  - J. Furukawa
AU  - Y. Sun
AU  - S. Yagi
AU  - T. Teramae
AU  - T. Noda
AU  - J. Morimoto
PY  - 2019
KW  - artificial limbs
KW  - biomechanics
KW  - electromyography
KW  - medical robotics
KW  - motion control
KW  - optimisation
KW  - robot muscle synergies
KW  - EMG-based assistive strategies
KW  - exoskeleton robot control
KW  - Electromyography-based assistive strategies
KW  - multiple EMG channels
KW  - multiDoF robots
KW  - optimization process
KW  - human muscles
KW  - pneumatic artificial muscle contractions
KW  - Bayesian optimization method
KW  - human movements
KW  - PAMs-driven upper-limb exoskeleton robot
KW  - human-in-theloop optimization
KW  - human-in-the-loop optimization approach
KW  - Muscles
KW  - Robots
KW  - Optimization
KW  - Exoskeletons
KW  - Electromyography
KW  - Bayes methods
KW  - Pneumatic systems
DO  - 10.1109/ICRA.2019.8794082
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this study, we propose a novel human-in-the-loop optimization approach for exoskeleton robot control. We develop a method to optimize widely-used Electromyography (EMG)-based assistive strategies. If we use multiple EMG channels to control multi-DoF robots, optimization process becomes complex and requires a large amount of data. To make the optimization tractable, we exploit the synergies both of the human muscles and artificial muscles of the exoskeleton robots to reduce the number of parameters of the assistive strategies. We show that we can extract the synergies not only from the user's muscle activities but from pneumatic artificial muscle (PAMs) contractions of the exoskeleton robot. Then, we adopt a Bayesian optimization method to acquire the parameters for assisting human movements by iteratively identifying the user's preferences of the assistive strategies. We conducted experiments to evaluate our proposed method with a PAMs-driven upper-limb exoskeleton robot. Our method successfully learned assistive strategies from the human-in-theloop optimization with a practicable number of interactions.
ER  - 

TY  - CONF
TI  - Development of a Low Inertia Parallel Actuated Shoulder Exoskeleton Robot for the Characterization of Neuromuscular Property during Static Posture and Dynamic Movement
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 556
EP  - 562
AU  - J. Hunt
AU  - H. Lee
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - human-robot interaction
KW  - manipulator kinematics
KW  - medical robotics
KW  - patient rehabilitation
KW  - low inertia parallel actuated shoulder exoskeleton robot
KW  - neuromuscular property
KW  - dynamic movement
KW  - intrinsic mechanisms
KW  - reflexive mechanisms
KW  - voluntary mechanism
KW  - shoulder control
KW  - upper limb performance
KW  - physical human-robot interaction
KW  - spherical parallel manipulator
KW  - control roll
KW  - parallel architecture
KW  - speed requirement
KW  - 4B-SPM exoskeleton
KW  - neuromuscular mechanisms
KW  - shoulder joint
KW  - neuromuscular properties
KW  - Shoulder
KW  - Exoskeletons
KW  - Servomotors
KW  - Robots
KW  - Neuromuscular
KW  - Prototypes
KW  - Impedance
DO  - 10.1109/ICRA.2019.8794181
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The purpose of this work is to introduce a newly developed exoskeleton robot designed to characterize the neuromuscular properties of the shoulder, including intrinsic and reflexive mechanisms, during static posture and dynamic movement in a 3-dimensional space. Quantitative characterization of these properties requires fast perturbation (>100°/s) to separate their contribution from that of voluntary mechanism. Understanding these properties of the shoulder control could assist in the rehabilitation or enhancement of upper limb performance during physical human-robot interaction. The device can be described as a new type of spherical parallel manipulator (SPM) that utilizes three 4-bar (4B) substructures to decouple and control roll, pitch and yaw of the shoulder. By utilizing a parallel architecture, the 4BSPM exoskeleton has the advantage of high acceleration, fast enough to satisfy the speed requirement for the characterization of distinct neuromuscular properties of the shoulder. In this work, the prototype is presented, along with an evaluation of its position accuracy and step response. The development and preliminary testing of the 4B-SPM exoskeleton presented in this work demonstrates its potential to be a useful tool for studying the neuromuscular mechanisms of the shoulder joint.
ER  - 

TY  - CONF
TI  - Effort Estimation in Robot-aided Training with a Neural Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 563
EP  - 569
AU  - A. C. d. Oliveira
AU  - K. Warburton
AU  - J. S. Sulzer
AU  - A. D. Deshpande
PY  - 2019
KW  - biomechanics
KW  - medical robotics
KW  - motion control
KW  - muscle
KW  - neurocontrollers
KW  - patient rehabilitation
KW  - patient treatment
KW  - robot dynamics
KW  - robot kinematics
KW  - robust control
KW  - torque control
KW  - wearable robots
KW  - effort estimation
KW  - robot-aided training
KW  - neural network
KW  - robotic exoskeletons
KW  - post-stroke rehabilitation
KW  - sensorimotor impairments
KW  - variable assistance
KW  - movement execution
KW  - movement quality
KW  - individualized treatment
KW  - kinematic guidance
KW  - robotic assistance
KW  - voluntary effort
KW  - active torques
KW  - unmodeled dynamics
KW  - passive neuromuscular properties
KW  - involuntary forces
KW  - muscle activity
KW  - high resolution assessment tool
KW  - therapy tasks
KW  - robustness
KW  - Harmony upper-body exoskeleton
KW  - motor recovery evaluation
KW  - Robot sensing systems
KW  - Torque
KW  - Shoulder
KW  - Muscles
KW  - Exoskeletons
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794281
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic exoskeletons open up promising interventions during post-stroke rehabilitation by assisting individuals with sensorimotor impairments to complete therapy tasks. These devices have the ability to provide variable assistance tailored to individual-specific needs and, additionally, can measure several parameters associated with the movement execution. Metrics representative of movement quality are important to guide individualized treatment. While robots can provide data with high resolution, robustness, and consistency, the delineation of the human contribution in the presence of the kinematic guidance introduced by the robotic assistance is a significant challenge. In this paper, we propose a method for assessing voluntary effort from an individual fitted in an upper-body exoskeleton called Harmony. The method separates the active torques generated by the wearer from the effects caused by unmodeled dynamics and passive neuromuscular properties and involuntary forces. Preliminary results show that the effort estimated using the proposed method is consistent with the effort associated with muscle activity and is also sensitive to different levels, indicating that it can reliably evaluate user's contribution to movement. This method has the potential to serve as a high resolution assessment tool to monitor progress of movement quality throughout the treatment and evaluate motor recovery.
ER  - 

TY  - CONF
TI  - Characterizing Architectures of Soft Pneumatic Actuators for a Cable-Driven Shoulder Exoskeleton
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 570
EP  - 576
AU  - N. Thompson
AU  - A. Sinha
AU  - G. Krishnan
PY  - 2019
KW  - biomechanics
KW  - cables (mechanical)
KW  - elastomers
KW  - medical robotics
KW  - patient rehabilitation
KW  - pneumatic actuators
KW  - wearable robots
KW  - architectures characterization
KW  - wearable robots
KW  - fiber-reinforced elastomeric enclosures
KW  - FREEs
KW  - shoulder flexion
KW  - force-displacement curves
KW  - cable anchor movement
KW  - Bowden cables
KW  - nested linear architecture
KW  - pennate architectures
KW  - cable-driven shoulder exoskeleton
KW  - soft pneumatic actuators
KW  - Shoulder
KW  - Actuators
KW  - Force
KW  - Exoskeletons
KW  - Cable shielding
KW  - Torque
KW  - Prototypes
DO  - 10.1109/ICRA.2019.8793707
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Low weight and innate compliance make soft pneumatic actuators an attractive method for actuating wearable robots. Performance of soft pneumatic actuators can be tailored to an application by combining them in novel architectures. We modeled and constructed nested linear and pennate architectures using fiber-reinforced elastomeric enclosures (FREEs) with identical manufacturing parameters and total effective lengths to compare their suitability for a cable-driven exoskeleton for augmenting shoulder flexion. We determined actuator performance requirements using a static model for the transmission of actuator forces to the upper arm via Bowden cables. We experimentally characterized the architectures by measuring their force-displacement curves at a range of pressures, yielding greater force and displacement from the nested architecture in the domain required by our exoskeleton. Results also indicated a force threshold above which the pennate structure produced greater force at any given displacement. We validated the nested linear architecture using a prototype exoskeleton installed on a passive mannequin. Measured joint angles at varying pressures were close to predicted values, adjusted for measured losses due to cable anchor movement.
ER  - 

TY  - CONF
TI  - Design and Implementation of a Two-DOF Robotic System with an Adjustable Force Limiting Mechanism for Ankle Rehabilitation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 577
EP  - 583
AU  - V. Mehrabi
AU  - S. F. Atashzar
AU  - H. A. Talebi
AU  - R. V. Patel
PY  - 2019
KW  - end effectors
KW  - friction
KW  - manipulator dynamics
KW  - medical robotics
KW  - mobile robots
KW  - patient rehabilitation
KW  - patient treatment
KW  - lower-limb rehabilitation robot
KW  - mechanical adjustment
KW  - design procedure
KW  - adjustable force limiting mechanism
KW  - light-weight back-drivable inherently-safe robotic mechanism
KW  - ankle rehabilitation therapies
KW  - ankle module
KW  - mathematical modeling
KW  - experimental validations
KW  - two-DOF robotic system
KW  - friction-based safety feature
KW  - Robots
KW  - Wheels
KW  - Force
KW  - Torque
KW  - Medical treatment
KW  - Safety
KW  - Training
DO  - 10.1109/ICRA.2019.8794028
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel light-weight back-drivable inherently-safe robotic mechanism for delivering ankle rehabilitation therapies. The robot is designed to be used as the ankle module of a multi-purpose lower-limb rehabilitation robot. A novel friction-based safety feature has been introduced that enables mechanical adjustment of the maximum amount of allowable transfer forces and torques to the patient's limb. The design procedure, mathematical modeling and experimental validations are provided to demonstrate the performance of the proposed system.
ER  - 

TY  - CONF
TI  - Rorg: Service Robot Software Management with Linux Containers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 584
EP  - 590
AU  - S. Wang
AU  - X. Liu
AU  - J. Zhao
AU  - H. I. Christensen
PY  - 2019
KW  - cloud computing
KW  - control engineering computing
KW  - Linux
KW  - mobile robots
KW  - object-oriented programming
KW  - scheduling
KW  - service robots
KW  - Linux container-based scheme
KW  - monitor software components
KW  - service robots
KW  - Linux containers
KW  - service robot systems
KW  - resource constraints
KW  - programmable container management interface
KW  - resource time-sharing mechanism
KW  - Rorg
KW  - resource contention
KW  - long-term autonomous tour guide robot
KW  - robot software system
KW  - software processes
KW  - software components
KW  - computer resources
KW  - service robot software management
KW  - robot operating system
KW  - Containers
KW  - Software
KW  - Linux
KW  - Service robots
KW  - Data centers
KW  - Monitoring
DO  - 10.1109/ICRA.2019.8793764
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Scaling up the software system on service robots increases the maintenance burden of developers and the risk of resource contention of the computer embedded on robots. As a result, developers spend much time on configuring, deploying, and monitoring the robot software system; robots may utilize significant computer resources when all software processes are running. We present Rorg, a Linux container-based scheme to manage, schedule, and monitor software components on service robots. Although Linux containers are already widely-used in cloud environments, this technique is challenging to efficiently adopt in service robot systems due to multi-tasking, resource constraints and performance requirements. To pave the way of Linux containers on service robots in an efficient manner, we present a programmable container management interface and a resource time-sharing mechanism incorporated with the Robot Operating System (ROS). Rorg allows developers to pack software into self-contained images and runs them in isolated environments using Linux containers; it also allows the robot to turn on and off software components on demand to avoid resource contention. We evaluate Rorg with a long-term autonomous tour guide robot: It manages 41 software components on the robot and relieved our maintenance burden, and it also reduces CPU load by 45.5% and memory usage by 16.5% on average.
ER  - 

TY  - CONF
TI  - CartesI/O: A ROS Based Real-Time Capable Cartesian Control Framework
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 591
EP  - 596
AU  - A. Laurenzi
AU  - E. M. Hoffman
AU  - L. Muratore
AU  - N. G. Tsagarakis
PY  - 2019
KW  - control engineering computing
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - robot kinematics
KW  - telerobotics
KW  - robotics platforms
KW  - simple auto-generated ROS-based interface
KW  - motion control frameworks
KW  - ROS MoveIt
KW  - Cartesian trajectories
KW  - locomotion tasks
KW  - COMAN + humanoid robot
KW  - redundant robots
KW  - motion tasks
KW  - multilegged highly redundant robots
KW  - Cartesian control framework
KW  - Task analysis
KW  - Robot kinematics
KW  - Real-time systems
KW  - Libraries
KW  - C++ languages
KW  - Planning
DO  - 10.1109/ICRA.2019.8794464
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work introduces a framework for the Cartesian control of multi-legged, highly redundant robots. The proposed framework allows the untrained user to perform complex motion tasks with robotics platforms by leveraging a simple, auto-generated ROS-based interface. Contrary to other motion control frameworks (e.g. ROS MoveIt!), we focus on the execution of Cartesian trajectories that are specified online, rather than planned in advance, as it is the case, for instance, in tele-operation and locomotion tasks. Moreover, we address the problem of generating such motions within a hard real-time (RT) control loop. Finally, we demonstrate the capabilities of our framework both on the COMAN + humanoid robot, and on the hybrid wheeled-legged quadruped CENTAURO.
ER  - 

TY  - CONF
TI  - Synthesis of Real-Time Observers from Past-Time Linear Temporal Logic and Timed Specification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 597
EP  - 603
AU  - C. Lesire
AU  - S. Roussel
AU  - D. Doose
AU  - C. Grand
PY  - 2019
KW  - fault tolerant control
KW  - mobile robots
KW  - observers
KW  - specification languages
KW  - temporal logic
KW  - timed specification
KW  - fault-tolerant architectures
KW  - autonomous robots
KW  - robot developers
KW  - specification language
KW  - real-time evaluation
KW  - real-time observers
KW  - past-time linear temporal logic
KW  - past-time LTL
KW  - software components
KW  - mission patrolling
KW  - Observers
KW  - Monitoring
KW  - Real-time systems
KW  - Robot sensing systems
KW  - Timing
KW  - Safety
DO  - 10.1109/ICRA.2019.8793754
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fault-tolerant architectures are mandatory to ensure the robustness of autonomous robots performing missions in complex and uncertain environments. The first step of a fault-tolerant mechanism is the detection of a faulty behavior of the system. It is then important to provide tools to help robot developers specify relevant observers. It is moreover crucial to guarantee a correct implementation of the observers, i.e. that the observers do not miss data and do not trigger unsuitable recovery actions in case of false detection. In this paper, we propose a specification language for observers that uses Past-Time LTL to express complex formulas on data produced by software components, and timed constraints on the evaluations of these formulas. We moreover provide an implementation of this specification that guarantees a real-time evaluation of the observers. We briefly describe the observers we have specified for a patrolling mission, and we evaluate the performance of our approach compared to state of the art on a benchmark in which we detect errors on a laser range sensor.
ER  - 

TY  - CONF
TI  - Julia for robotics: simulation and real-time control in a high-level programming language
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 604
EP  - 611
AU  - T. Koolen
AU  - R. Deits
PY  - 2019
KW  - computer simulation
KW  - control engineering computing
KW  - high level languages
KW  - humanoid robots
KW  - programming languages
KW  - quadratic programming
KW  - robot dynamics
KW  - robot programming
KW  - real-time control
KW  - high-level programming language
KW  - robotics applications
KW  - two-language problem
KW  - performance-sensitive components
KW  - high-level language
KW  - software complexity
KW  - Julia programming language
KW  - online control
KW  - Julia packages
KW  - Boston Dynamics Atlas humanoid robot
KW  - quadratic-programming-based controller
KW  - Robots
KW  - Libraries
KW  - Software packages
KW  - C++ languages
KW  - Productivity
KW  - Resource management
DO  - 10.1109/ICRA.2019.8793875
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotics applications often suffer from the `two-language problem', requiring a low-level language for performance-sensitive components and a high-level language for interactivity and experimentation, which tends to increase software complexity. We demonstrate the use of the Julia programming language to solve this problem by being fast enough for online control of a humanoid robot and flexible enough for prototyping. We present several Julia packages developed by the authors, which together enable roughly 2× realtime simulation of the Boston Dynamics Atlas humanoid robot balancing on flat ground using a quadratic-programming-based controller. Benchmarks show a sufficiently low variation in control frequency to make deployment on the physical robot feasible. We also show that Julia's naturally generic programming style results in versatile packages that are easy to compose and adapt to a wide variety of computational tasks in robotics.
ER  - 

TY  - CONF
TI  - Motion Planning Templates: A Motion Planning Framework for Robots with Low-power CPUs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 612
EP  - 618
AU  - J. Ichnowski
AU  - R. Alterovitz
PY  - 2019
KW  - control engineering computing
KW  - data structures
KW  - graph theory
KW  - humanoid robots
KW  - mobile robots
KW  - path planning
KW  - low-power CPU
KW  - template-based library
KW  - compile-time polymorphism
KW  - robot-specific motion planning code
KW  - robot software
KW  - motion planning problem
KW  - general motion planning implementations
KW  - motion planning graph
KW  - compile-time algorithms
KW  - motion planning scenarios
KW  - humanoid robot
KW  - 3D rigid-body motions
KW  - motion planning framework
KW  - MPT
KW  - motion planning templates
KW  - Planning
KW  - Runtime
KW  - C++ languages
KW  - Libraries
KW  - Data structures
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8794099
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Motion Planning Templates (MPT) is a C++ template-based library that uses compile-time polymorphism to generate robot-specific motion planning code and is geared towards eking out as much performance as possible when running on the low-power CPU of a battery-powered small robot. To use MPT, developers of robot software write or leverage code specific to their robot platform and motion planning problem, and then have MPT generate a robot-specific motion planner and its associated data-structures. The resulting motion planner implementation is faster and uses less memory than general motion planning implementations based upon runtime polymorphism. While MPT loses runtime flexibility, it gains advantages associated with compile-time polymorphism- including the ability to change scalar precision, generate tightly-packed data structures, and store robot-specific data in the motion planning graph. MPT also uses compile-time algorithms to resolve the algorithm implementation, and select the best nearest neighbor algorithm to integrate into it. We demonstrate MPT's performance, lower memory footprint, and ability to adapt to varying robots in motion planning scenarios on a small humanoid robot and on 3D rigid-body motions.
ER  - 

TY  - CONF
TI  - Distortion-free Robotic Surface-drawing using Conformal Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 627
EP  - 633
AU  - D. Song
AU  - Y. J. Kim
PY  - 2019
KW  - computational geometry
KW  - computer graphics
KW  - conformal mapping
KW  - distance measurement
KW  - image reconstruction
KW  - least squares approximations
KW  - manipulators
KW  - mobile robots
KW  - solid modelling
KW  - distortion-free robotic surface-drawing
KW  - robotic pen-drawing system
KW  - unknown surface
KW  - robotic system
KW  - seven-degree-of freedom manipulator
KW  - continuous surface
KW  - physical canvas surface
KW  - point-cloud estimation
KW  - drawing surface
KW  - 2D vector pen art
KW  - surface parameterization
KW  - squares conformal mapping
KW  - complicated pen drawings
KW  - general surfaces
KW  - impedance-control
KW  - digital drawing
KW  - 2D drawing
KW  - Surface impedance
KW  - Three-dimensional displays
KW  - Robot kinematics
KW  - Two dimensional displays
KW  - Service robots
KW  - Surface reconstruction
DO  - 10.1109/ICRA.2019.8794034
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a robotic pen-drawing system that is capable of faithfully reproducing pen art on an unknown surface. Our robotic system relies on an industrial, seven-degree-of freedom manipulator that can be both position- and impedance-controlled. In order to estimate a rough geometry of the target, continuous surface, we first generate a point cloud of the surface using an RGB-D camera, which is filtered to remove outliers and calibrated to the physical canvas surface. Then, our control algorithm physically reproduces digital drawing on the surface by impedance-controlling the manipulator. Our impedance-controlled drawing algorithm compensates for the uncertainty and incompleteness inherent to a point-cloud estimation of the drawing surface. Moreover, since drawing 2D vector pen art on a 3D surface requires surface parameterization that does not destroy the original 2D drawing, we rely on the least squares conformal mapping. Specifically, the conformal map reduces angle distortion during surface parameterization. As a result, our system can create distortion-free and complicated pen drawings on general surfaces with many unpredictable bumps robustly and faithfully.
ER  - 

TY  - CONF
TI  - Automated Cell Patterning System with a Microchip using Dielectrophoresis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 634
EP  - 639
AU  - K. Huang
AU  - H. K. Chu
AU  - B. Lu
AU  - J. Lai
AU  - L. Cheng
PY  - 2019
KW  - bioelectric phenomena
KW  - biological techniques
KW  - cellular biophysics
KW  - electrophoresis
KW  - lab-on-a-chip
KW  - microorganisms
KW  - dielectrophoresis
KW  - automatic method
KW  - 6-aminohexanoic acid
KW  - yeast cells
KW  - cell-printing microchip
KW  - large-scale cell patterns
KW  - cell-based assay
KW  - patterning cells
KW  - automated cell patterning system
KW  - Integrated circuits
KW  - Substrates
KW  - Electrodes
KW  - Microscopy
KW  - Force
KW  - Lenses
KW  - Glass
DO  - 10.1109/ICRA.2019.8794177
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to patterning cells is an important technique to facilitate cell-based assay and characterization. In this paper, an automated cell patterning system was developed for the fabrication of large-scale cell patterns. To resolve the challenge of the limited printable area, the cell-printing microchip and the substrate were mounted on the movable stages of the system, and large-scale cell patterns were realized through coordination between the stages. An autofocusing technique was integrated in the system to evaluate the gap between the microchip and the substrate. In order to enhance the performance of the patterning system, different experimental parameters, including the velocity of the moving stage, were examined. Yeast cells suspending in 6-aminohexanoic acid (AHA) solution were considered in this study, and a sequence of characters was successfully printed using the proposed system. The results confirm that this system offers an automatic method with high flexibility to construct large-scale cell patterns for various applications.
ER  - 

TY  - CONF
TI  - Mobile Robotic Painting of Texture
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 640
EP  - 647
AU  - M. E. Helou
AU  - S. Mandt
AU  - A. Krause
AU  - P. Beardsley
PY  - 2019
KW  - image colour analysis
KW  - image reconstruction
KW  - image texture
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - painting
KW  - spraying
KW  - mobile robotic painting
KW  - mobile robots
KW  - robotic paint delivery systems
KW  - spray painting
KW  - painting tasks
KW  - image texture
KW  - robotic paint commands
KW  - deep learning approach
KW  - appearance reconstruction
KW  - Painting
KW  - Robots
KW  - Paints
KW  - Ink
KW  - Atmospheric modeling
KW  - Spraying
DO  - 10.1109/ICRA.2019.8793947
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic painting is well-established in controlled factory environments, but there is now potential for mobile robots to do functional painting tasks around the everyday world. An obvious first target for such robots is painting a uniform single color. A step further is the painting of textured images. Texture involves a varying appearance, and requires that paint is delivered accurately onto the physical surface to produce the desired effect. Robotic painting of texture is relevant for architecture and in themed environments. A key challenge for robotic painting of texture is to take a desired image as input, and to generate the paint commands to as closely as possible create the desired appearance, according to the robotic capabilities. This paper describes a deep learning approach to take an input ink map of a desired texture, and infer robotic paint commands to produce that texture. We analyze the trade-offs between quality of reconstructed appearance and ease of execution. Our method is general for different kinds of robotic paint delivery systems, but the emphasis here is on spray painting. More generally, the framework can be viewed as an approach for solving a specific class of inverse imaging problems.
ER  - 

TY  - CONF
TI  - Detecting Invasive Insects with Unmanned Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 648
EP  - 654
AU  - B. Stumph
AU  - M. H. Virto
AU  - H. Medeiros
AU  - A. Tabb
AU  - S. Wolford
AU  - K. Rice
AU  - T. Leskey
PY  - 2019
KW  - agriculture
KW  - autonomous aerial vehicles
KW  - cameras
KW  - computer vision
KW  - mobile robots
KW  - pest control
KW  - robot vision
KW  - mark-release-recapture technique
KW  - invasive insect species migration patterns
KW  - unmanned aerial vehicles
KW  - computer vision algorithms
KW  - invasive insects detection
KW  - agriculture
KW  - Insects
KW  - Cameras
KW  - Unmanned aerial vehicles
KW  - Image color analysis
KW  - Data acquisition
KW  - Pipelines
KW  - Agriculture
DO  - 10.1109/ICRA.2019.8794116
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A key aspect to controlling and reducing the effects invasive insect species have on agriculture is to obtain knowledge about the migration patterns of these species. Current state-of-the-art methods of studying these migration patterns involve a mark-release-recapture technique, in which insects are released after being marked and researchers attempt to recapture them later. However, this approach involves a human researcher manually searching for these insects in large fields and results in very low recapture rates. In this paper, we propose an automated system for detecting released insects using an unmanned aerial vehicle. This system utilizes ultraviolet lighting technology, digital cameras, and lightweight computer vision algorithms to more quickly and accurately detect insects compared to the current state of the art. The efficiency and accuracy that this system provides will allow for a more comprehensive understanding of invasive insect species migration patterns. Our experimental results demonstrate that our system can detect real target insects in field conditions with high precision and recall rates.
ER  - 

TY  - CONF
TI  - Robust Object-based SLAM for High-speed Autonomous Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 669
EP  - 675
AU  - K. Ok
AU  - K. Liu
AU  - K. Frey
AU  - J. P. How
AU  - N. Roy
PY  - 2019
KW  - cameras
KW  - helicopters
KW  - image sequences
KW  - image texture
KW  - mobile robots
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - ROSHAN
KW  - object-level mapping
KW  - ellipsoid-based SLAM
KW  - object surface
KW  - autonomous quadrotor
KW  - bounding box detections
KW  - median shape error
KW  - forward-moving camera sequence
KW  - planar constraint
KW  - vehicle motions
KW  - semantic knowledge
KW  - robust object-based SLAM for high-speed autonomous navigation
KW  - Ellipsoids
KW  - Image edge detection
KW  - Semantics
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Shape
KW  - Shape measurement
DO  - 10.1109/ICRA.2019.8794344
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present Robust Object-based SLAM for High-speed Autonomous Navigation (ROSHAN), a novel approach to object-level mapping suitable for autonomous navigation. In ROSHAN, we represent objects as ellipsoids and infer their parameters using three sources of information - bounding box detections, image texture, and semantic knowledge - to overcome the observability problem in ellipsoid-based SLAM under common forward-translating vehicle motions. Each bounding box provides four planar constraints on an object surface and we add a fifth planar constraint using the texture on the objects along with a semantic prior on the shape of ellipsoids. We demonstrate ROSHAN in simulation where we outperform the baseline, reducing the median shape error by 83% and the median position error by 72% in a forward-moving camera sequence. We demonstrate similar qualitative result on data collected on a fast-moving autonomous quadrotor.
ER  - 

TY  - CONF
TI  - A Fault Diagnosis Framework for MAVLink-Enabled UAVs Using Structural Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 676
EP  - 682
AU  - G. Zogopoulos-Papaliakos
AU  - M. Logothetis
AU  - K. J. Kyriakopoulos
PY  - 2019
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - fault diagnosis
KW  - telemetry
KW  - MAVLink-enabled UAVs
KW  - fixed-wing UAVs
KW  - MAVLink telemetry streams
KW  - residual generators
KW  - observable faults
KW  - FDI system
KW  - isolability analyses
KW  - real-life telemetry log
KW  - UAV crash
KW  - fault diagnosis framework
KW  - structural analysis
KW  - message protocol
KW  - unmanned aerial vehicles
KW  - fault detection and isolation framework
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Generators
KW  - Fault diagnosis
KW  - Telemetry
KW  - Batteries
KW  - Unmanned aerial vehicles
DO  - 10.1109/ICRA.2019.8793760
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - MAVLink is a popular message protocol for small Unmanned Aerial Vehicles (UAVs). In this work, we present a Fault Detection and Isolation (FDI) framework for fixed-wing UAVs which takes advantage of the information conveyed in MAVLink telemetry streams and produces a bank of residual generators. Structural Analysis is employed to systematically handle the varying set of available measurements, identify the observable faults and adjust the FDI system accordingly. Structural detectability and isolability analyses are carried out. A case-study on a real-life telemetry log of a UAV crash demonstrates the efficacy of the proposed approach.
ER  - 

TY  - CONF
TI  - Real-Time Minimum Snap Trajectory Generation for Quadcopters: Algorithm Speed-up Through Machine Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 683
EP  - 689
AU  - M. M. d. Almeida
AU  - R. Moghe
AU  - M. Akella
PY  - 2019
KW  - computational complexity
KW  - control engineering computing
KW  - gradient methods
KW  - helicopters
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - trajectory control
KW  - human-machine interface
KW  - gradient descent method
KW  - supervised neural network
KW  - computational time
KW  - machine learning
KW  - quadcopter
KW  - iterative methods
KW  - real-time minimum snap trajectory generation
KW  - smart-tablet interface
KW  - Trajectory
KW  - Resource management
KW  - Real-time systems
KW  - Neural networks
KW  - Acceleration
KW  - Quadratic programming
KW  - Nonlinear optics
DO  - 10.1109/ICRA.2019.8793569
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of generating quadcopter minimum snap trajectories for real time applications. Previous efforts addressed this problem by either employing a gradient descent method, or by greatly sacrificing optimality for faster solutions that are amenable for onboard implementation. In this work, outputs of the gradient descent method are used offline to train a supervised neural network. We show that the use of neural networks results typically in two orders of magnitude reduction in computational time. Our proposed approach can be used for warm-starting onboard implementable iterative methods with an “educated ” initial guess. This work is motivated by the application for human-machine interface in which a human provides desired trajectory through a smart-tablet interface, which has to be translated into a dynamically feasible trajectory for a quadcopter. The proposed solution is tested in thousands of different examples, demonstrating its effectiveness as a booster for minimum snap trajectory generation for quadcopters.
ER  - 

TY  - CONF
TI  - Beauty and the Beast: Optimal Methods Meet Learning for Drone Racing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 690
EP  - 696
AU  - E. Kaufmann
AU  - M. Gehrig
AU  - P. Foehn
AU  - R. Ranftl
AU  - A. Dosovitskiy
AU  - V. Koltun
AU  - D. Scaramuzza
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - Kalman filters
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - optimisation
KW  - predictive control
KW  - state estimation
KW  - robust flight
KW  - previously-unseen race tracks
KW  - optimal methods
KW  - fast maneuvers
KW  - agile maneuvers
KW  - dynamic environments
KW  - imperfect sensing
KW  - state estimation drift
KW  - human pilots
KW  - unseen track
KW  - practice runs
KW  - state-of-the-art autonomous navigation algorithms
KW  - precise metric map
KW  - training data
KW  - unseen environment
KW  - precise map
KW  - expensive data collection
KW  - global track layout
KW  - coarse gate locations
KW  - single demonstration flight
KW  - convolutional network
KW  - closest gates
KW  - extended Kalman filter
KW  - maximum-a-posteriori estimates
KW  - high-variance estimates
KW  - poor observability
KW  - visible gates
KW  - estimated gate poses
KW  - model predictive control
KW  - agile flight
KW  - autonomous microaerial vehicles
KW  - autonomous drone racing
KW  - IROS 2018 autonomous drone race competition
KW  - Logic gates
KW  - Drones
KW  - Navigation
KW  - Training data
KW  - Current measurement
KW  - Layout
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793631
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous micro aerial vehicles still struggle with fast and agile maneuvers, dynamic environments, imperfect sensing, and state estimation drift. Autonomous drone racing brings these challenges to the fore. Human pilots can fly a previously unseen track after a handful of practice runs. In contrast, state-of-the-art autonomous navigation algorithms require either a precise metric map of the environment or a large amount of training data collected in the track of interest. To bridge this gap, we propose an approach that can fly a new track in a previously unseen environment without a precise map or expensive data collection. Our approach represents the global track layout with coarse gate locations, which can be easily estimated from a single demonstration flight. At test time, a convolutional network predicts the poses of the closest gates along with their uncertainty. These predictions are incorporated by an extended Kalman filter to maintain optimal maximum-a-posteriori estimates of gate locations. This allows the framework to cope with misleading high-variance estimates that could stem from poor observability or lack of visible gates. Given the estimated gate poses, we use model predictive control to quickly and accurately navigate through the track. We conduct extensive experiments in the physical world, demonstrating agile and robust flight through complex and diverse previously-unseen race tracks. The presented approach was used to win the IROS 2018 Autonomous Drone Race Competition, outracing the second-placing team by a factor of two.
ER  - 

TY  - CONF
TI  - Detection and Reconstruction of Wires Using Cameras for Aircraft Safety Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 697
EP  - 703
AU  - A. Stambler
AU  - G. Sherwin
AU  - P. Rowe
PY  - 2019
KW  - aerospace computing
KW  - aerospace safety
KW  - aircraft
KW  - convolutional neural nets
KW  - feature extraction
KW  - hazards
KW  - image reconstruction
KW  - image segmentation
KW  - neural net architecture
KW  - object detection
KW  - real-time systems
KW  - cameras
KW  - aircraft safety systems
KW  - free hanging wires
KW  - wire obstacles
KW  - neural network architecture
KW  - Deep Wire CNN
KW  - wire line segments
KW  - wire reconstruction
KW  - real-time detections
KW  - wire hazards
KW  - wire detection
KW  - Wires
KW  - Image reconstruction
KW  - Cameras
KW  - Detectors
KW  - Image resolution
KW  - Agriculture
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793526
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We extend the ability of cameras to perceive obstacles for aircraft safety systems by enabling 3d sensing of free hanging wires. Our algorithm exploits the specialized 2d and 3d structure of wires to exceed state of the art performance in 2d sensing and 3d location estimation of wire obstacles. In 2d, a new neural network architecture, Deep Wire CNN, directly predicts the location of wire line segments in the image. In 3d, the detections are tracked and triangulated as the aircraft flies in order to estimate the wire's location. Our triangulation uses a new formulation of wire reconstruction as the estimation of the wire's vertical plane. Together these advancements enable real-time detections of wire hazards at ranges of over 1km. The system performance is evaluated on prior image level wire detection datasets and we introduce a new public dataset in order to evaluate full system results on over 40 approaches to power lines from a manned helicopter.
ER  - 

TY  - CONF
TI  - Pose and Posture Estimation of Aerial Skeleton Systems for Outdoor Flying
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 704
EP  - 710
AU  - S. Park
AU  - Y. Lee
AU  - J. Heo
AU  - D. Lee
PY  - 2019
KW  - Kalman filters
KW  - pose estimation
KW  - satellite navigation
KW  - outdoor flying
KW  - posture estimation framework
KW  - system modular
KW  - GNSS module
KW  - global navigation satellite system
KW  - EKF estimates
KW  - three-link aerial skeleton system
KW  - inertial measurement unit
KW  - extended Kalman filtering
KW  - Skeleton
KW  - Estimation
KW  - Kinematics
KW  - Global navigation satellite system
KW  - Rotors
KW  - Kalman filters
KW  - Force
DO  - 10.1109/ICRA.2019.8794080
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel pose and posture estimation framework of aerial skeleton system for outdoor flying. To exploit redundant/independent sensing while rendering the system “modular”, we attach an IMU (inertial measurement unit) sensor and a GNSS (global navigation satellite system) module on each link and perform SE(3)-motion EKF (extended Kalman filtering). We then apply the kinematic constraints of the aerial skeleton system to these EKF estimates of all the links through SCKF (smoothly constrained Kalman filtering), thereby, enforcing the kinematic coherency of the skeleton system and, consequently, significantly enhancing the estimation accuracy and the control performance/stability of the aerial skeleton system. A semi-distributed version of the obtained estimation framework is also presented to address the issue of scalability. The theory is then verified/demonstrated with real outdoor flying experiments and simulation studies of a three-link aerial skeleton system.
ER  - 

TY  - CONF
TI  - Flight Testing Boustrophedon Coverage Path Planning for Fixed Wing UAVs in Wind
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 711
EP  - 717
AU  - M. Coombes
AU  - W. Chen
AU  - C. Liu
PY  - 2019
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - wind
KW  - flight test results
KW  - model prediction
KW  - multirotor UAV
KW  - boustrophedon coverage path planning
KW  - flight path
KW  - aerial surveys
KW  - complex concave agricultural fields
KW  - flight time
KW  - wind prediction model
KW  - cost function
KW  - wind field measurements
KW  - fixed wing UAV
KW  - Wind
KW  - Aircraft
KW  - Robot sensing systems
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Path planning
KW  - Predictive models
KW  - Aerial Surveying
KW  - Coverage Path Planning
KW  - Remote Sensing
KW  - Boustrophedon paths
KW  - Wind
KW  - Trochoids
DO  - 10.1109/ICRA.2019.8793943
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A method was previously developed by this author to optimise the flight path of a fixed wing UAV performing aerial surveys of complex concave agricultural fields. This relies heavily on a flight time in wind prediction model as its cost function. This paper aims to validate this model by comparing flight test results with the model prediction. There are a number of assumptions that this model relies on. The major assumption is that wind is steady and uniform over the small area and time scales involved in a survey. To show that this is reasonable, wind fields measurements will be taken from a multi rotor UAV with an ultrasonic windspeed sensor.
ER  - 

TY  - CONF
TI  - Obstacle-aware Adaptive Informative Path Planning for UAV-based Target Search
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 718
EP  - 724
AU  - A. A. Meera
AU  - M. Popović
AU  - A. Millane
AU  - R. Siegwart
PY  - 2019
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - Gaussian processes
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - target occupancy
KW  - UAV-based target search
KW  - Gaussian process based model
KW  - flight time constraints
KW  - planning strategy
KW  - obstacle-aware adaptive informative path planning algorithm
KW  - target detection
KW  - unmanned aerial vehicles
KW  - collision avoidance
KW  - Planning
KW  - Search problems
KW  - Three-dimensional displays
KW  - Optimization
KW  - Trajectory
KW  - Unmanned aerial vehicles
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794345
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Target search with unmanned aerial vehicles (UAVs) is relevant problem to many scenarios, e.g., search and rescue (SaR). However, a key challenge is planning paths for maximal search efficiency given flight time constraints. To address this, we propose the Obstacle-aware Adaptive Informative Path Planning (OA-IPP) algorithm for target search in cluttered environments using UAVs. Our approach leverages a layered planning strategy using a Gaussian Process (GP)based model of target occupancy to generate informative paths in continuous 3D space. Within this framework, we introduce an adaptive replanning scheme which allows us to trade off between information gain, field coverage, sensor performance, and collision avoidance for efficient target detection. Extensive simulations show that our OA-IPP method performs better than state-of-the-art planners, and we demonstrate its application in a realistic urban SaR scenario.
ER  - 

TY  - CONF
TI  - Real-Time Planning with Multi-Fidelity Models for Agile Flights in Unknown Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 725
EP  - 731
AU  - J. Tordesillas
AU  - B. T. Lopez
AU  - J. Carter
AU  - J. Ware
AU  - J. P. How
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - sensors
KW  - low-fidelity models
KW  - fast planner
KW  - planning framework
KW  - agile flights
KW  - replanning times
KW  - cluttered environments
KW  - multifidelity models
KW  - autonomous navigation
KW  - real-time localization
KW  - lightweight sensing
KW  - planning methodologies
KW  - hierarchical planning architecture
KW  - low-fidelity global planner
KW  - high-fidelity local planner
KW  - erratic behavior
KW  - unstable behavior
KW  - global plan
KW  - higher-order dynamics
KW  - real-time planning
KW  - sensor data
KW  - collision check
KW  - UAV
KW  - time 5.0 ms to 40.0 ms
KW  - Planning
KW  - Trajectory
KW  - Computational modeling
KW  - Vehicle dynamics
KW  - Robot sensing systems
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794248
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous navigation through unknown environments is a challenging task that entails real-time localization, perception, planning, and control. UAVs with this capability have begun to emerge in the literature with advances in lightweight sensing and computing. Although the planning methodologies vary from platform to platform, many algorithms adopt a hierarchical planning architecture where a slow, low-fidelity global planner guides a fast, high-fidelity local planner. However, in unknown environments, this approach can lead to erratic or unstable behavior due to the interaction between the global planner, whose solution is changing constantly, and the local planner; a consequence of not capturing higher-order dynamics in the global plan. This work proposes a planning framework in which multi-fidelity models are used to reduce the discrepancy between the local and global planner. Our approach uses high-, medium-, and low-fidelity models to compose a path that captures higher-order dynamics while remaining computationally tractable. In addition, we address the interaction between a fast planner and a slower mapper by considering the sensor data not yet fused into the map during the collision check. This novel mapping and planning framework for agile flights is validated in simulation and hardware experiments, showing replanning times of 5-40 ms in cluttered environments.
ER  - 

TY  - CONF
TI  - Efficient Trajectory Planning for High Speed Flight in Unknown Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 732
EP  - 738
AU  - M. Ryll
AU  - J. Ware
AU  - J. Carter
AU  - N. Roy
PY  - 2019
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - closed loop systems
KW  - collision avoidance
KW  - inertial navigation
KW  - mobile robots
KW  - motion control
KW  - optimal control
KW  - predictive control
KW  - sampling methods
KW  - trajectory control
KW  - motion planning
KW  - motion capture systems
KW  - receding horizon planning architecture
KW  - reactive obstacle avoidance
KW  - closed-form trajectory generation method
KW  - spatial partitioning data structures
KW  - obstacle density
KW  - sampling-based motion planner
KW  - minimum-jerk trajectories
KW  - closed-loop tracking
KW  - high-speed flight
KW  - autonomous quadrotor flights
KW  - urban environment
KW  - trajectory planning
KW  - visual-inertial navigation
KW  - distance 22.0 km
KW  - Trajectory
KW  - Planning
KW  - Sensors
KW  - Three-dimensional displays
KW  - Cameras
KW  - Vehicle dynamics
KW  - Tracking
DO  - 10.1109/ICRA.2019.8793930
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There has been considerable recent work in motion planning for UAVs to enable aggressive, highly dynamic flight in known environments with motion capture systems. However, these existing planners have not been shown to enable the same kind of flight in unknown, outdoor environments. In this paper we present a receding horizon planning architecture that enables the fast replanning necessary for reactive obstacle avoidance by combining three techniques. First, we show how previous work in computationally efficient, closed-form trajectory generation method can be coupled with spatial partitioning data structures to reason about the geometry of the environment in real-time. Second, we show how to maintain safety margins during fast flight in unknown environments by planning velocities according to obstacle density. Third, our receding-horizon, sampling-based motion planner uses minimum-jerk trajectories and closed-loop tracking to enable smooth, robust, high-speed flight with the low angular rates necessary for accurate visual-inertial navigation. We compare against two state-of-the-art, reactive motion planners in simulation and benchmark solution quality against an offline global planner. Finally, we demonstrate our planner over 80 flights with a combined distance of 22km of autonomous quadrotor flights in an urban environment at speeds up to 9.4ms $^{-1}$.
ER  - 

TY  - CONF
TI  - Priority Maps for Surveillance and Intervention of Wildfires and other Spreading Processes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 739
EP  - 745
AU  - V. L. J. Somers
AU  - I. R. Manchester
PY  - 2019
KW  - autonomous aerial vehicles
KW  - optimisation
KW  - path planning
KW  - wildfires
KW  - priority maps
KW  - wildfires
KW  - knowledge reward function
KW  - dynamic spreading processes
KW  - surveillance
KW  - bushfire spreading dynamics
KW  - wildfire intervention
KW  - unmanned aerial vehicle
KW  - optimization framework
KW  - UAV path planning
KW  - Mathematical model
KW  - Surveillance
KW  - Stochastic processes
KW  - Unmanned aerial vehicles
KW  - Path planning
KW  - Vehicle dynamics
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793874
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Unmanned Aerial Vehicle (UAV) path planning algorithms often assume a knowledge reward function or priority map, indicating the most important areas to visit. In this paper we propose a method to create priority maps for monitoring or intervention of dynamic spreading processes such as wildfires. The presented optimization framework utilizes the properties of positive systems, in particular the separable structure of value (cost-to-go) functions, to provide scalable algorithms for surveillance and intervention. We present results obtained for a 16 and 1000 node example and convey how the priority map responds to changes in the dynamics of the system. The larger example of 1000 nodes, representing a fictional landscape, shows how the method can integrate bushfire spreading dynamics, landscape and wind conditions. Finally, we give an example of combining the proposed method with a travelling salesman problem for UAV path planning for wildfire intervention.
ER  - 

TY  - CONF
TI  - A Practical Approach to Insertion with Variable Socket Position Using Deep Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 754
EP  - 760
AU  - M. Vecerik
AU  - O. Sushkov
AU  - D. Barker
AU  - T. Rothörl
AU  - T. Hester
AU  - J. Scholz
PY  - 2019
KW  - control engineering computing
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - production engineering computing
KW  - variable socket position
KW  - visual control problem
KW  - model-based robotics community
KW  - task geometry
KW  - off-the-shelf Deep-RL algorithm
KW  - narrow-clearance peg-insertion task
KW  - deformable clip-insertion task
KW  - deep reinforcement learning
KW  - haptic control problem
KW  - Task analysis
KW  - Robots
KW  - Sockets
KW  - Visualization
KW  - Training
KW  - Plugs
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8794074
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Insertion is a challenging haptic and visual control problem with significant practical value for manufacturing. Existing approaches in the model-based robotics community can be highly effective when task geometry is known, but are complex and cumbersome to implement, and must be tailored to each individual problem by a qualified engineer. Within the learning community there is a long history of insertion research, but existing approaches are either too sample-inefficient to run on real robots, or assume access to high-level object features, e.g. socket pose. In this paper we show that relatively minor modifications to an off-the-shelf Deep-RL algorithm (DDPG), combined with a small number of human demonstrations, allows the robot to quickly learn to solve these tasks efficiently and robustly. Our approach requires no modeling or simulation, no parameterized search or alignment behaviors, no vision system aside from raw images, and no reward shaping. We evaluate our approach on a narrow-clearance peg-insertion task and a deformable clip-insertion task, both of which include variability in the socket position. Our results show that these tasks can be solved reliably on the real robot in less than 10 minutes of interaction time, and that the resulting policies are robust to variance in the socket position and orientation.
ER  - 

TY  - CONF
TI  - Uncertainty-Aware Data Aggregation for Deep Imitation Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 761
EP  - 767
AU  - Y. Cui
AU  - D. Isele
AU  - S. Niekum
AU  - K. Fujimura
PY  - 2019
KW  - data aggregation
KW  - learning (artificial intelligence)
KW  - Monte Carlo methods
KW  - uncertain systems
KW  - uncertainty estimation method
KW  - UAIL
KW  - uncertainty-aware data aggregation
KW  - deep imitation learning
KW  - statistical uncertainties
KW  - autonomous agents
KW  - task execution
KW  - safety-critical domains
KW  - autonomous driving
KW  - uncertainty-aware imitation learning algorithm
KW  - end-to-end control systems
KW  - Monte Carlo Dropout
KW  - control output
KW  - end-to-end systems
KW  - training data
KW  - prior data aggregation algorithms
KW  - sub-optimal states
KW  - simulated driving tasks
KW  - Uncertainty
KW  - Data aggregation
KW  - Task analysis
KW  - Switches
KW  - Estimation
KW  - Data models
DO  - 10.1109/ICRA.2019.8794025
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Estimating statistical uncertainties allows autonomous agents to communicate their confidence during task execution and is important for applications in safety-critical domains such as autonomous driving. In this work, we present the uncertainty-aware imitation learning (UAIL) algorithm for improving end-to-end control systems via data aggregation. UAIL applies Monte Carlo Dropout to estimate uncertainty in the control output of end-to-end systems, using states where it is uncertain to selectively acquire new training data. In contrast to prior data aggregation algorithms that force human experts to visit sub-optimal states at random, UAIL can anticipate its own mistakes and switch control to the expert in order to prevent visiting a series of sub-optimal states. Our experimental results from simulated driving tasks demonstrate that our proposed uncertainty estimation method can be leveraged to reliably predict infractions. Our analysis shows that UAIL outperforms existing data aggregation algorithms on a series of benchmark tasks.
ER  - 

TY  - CONF
TI  - Uncertainty Aware Learning from Demonstrations in Multiple Contexts using Bayesian Neural Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 768
EP  - 774
AU  - S. Thakur
AU  - H. van Hoof
AU  - J. C. G. Higuera
AU  - D. Precup
AU  - D. Meger
PY  - 2019
KW  - Bayes methods
KW  - belief networks
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - neurocontrollers
KW  - Bayesian neural networks
KW  - robotic controllers
KW  - evaluation conditions
KW  - learned controller
KW  - testing conditions
KW  - high-dimensional simulated domains
KW  - real robotic domains
KW  - uncertainty based solution
KW  - uncertainty aware learning
KW  - Uncertainty
KW  - Task analysis
KW  - Neural networks
KW  - Training
KW  - Robots
KW  - Bayes methods
KW  - Measurement uncertainty
DO  - 10.1109/ICRA.2019.8794328
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Diversity of environments is a key challenge that causes learned robotic controllers to fail due to the discrepancies between the training and evaluation conditions. Training from demonstrations in various conditions can mitigate - but not completely prevent - such failures. Learned controllers such as neural networks typically do not have a notion of uncertainty that allows to diagnose an offset between training and testing conditions, and potentially intervene. In this work, we propose to use Bayesian Neural Networks, which have such a notion of uncertainty. We show that uncertainty can be leveraged to consistently detect situations in high-dimensional simulated and real robotic domains in which the performance of the learned controller would be sub-par. Also, we show that such an uncertainty based solution allows making an informed decision about when to invoke a fallback strategy. One fallback strategy is to request more data. We empirically show that providing data only when requested results in increased data-efficiency.
ER  - 

TY  - CONF
TI  - Learning From Demonstration in the Wild
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 775
EP  - 781
AU  - F. Behbahani
AU  - K. Shiarlis
AU  - X. Chen
AU  - V. Kurin
AU  - S. Kasewa
AU  - C. Stirbu
AU  - J. Gomes
AU  - S. Paul
AU  - F. A. Oliehoek
AU  - J. Messias
AU  - S. Whiteson
PY  - 2019
KW  - cameras
KW  - learning (artificial intelligence)
KW  - object detection
KW  - traffic engineering computing
KW  - video signal processing
KW  - uncalibrated camera
KW  - learning from demonstration
KW  - ViBe
KW  - traffic intersection
KW  - knowledge expert
KW  - video to behaviour
KW  - natural behaviour
KW  - reward function
KW  - hand-coding behaviour
KW  - wild
KW  - raw videos
KW  - naturalistic behaviour
KW  - LfD
KW  - monocular camera
KW  - single camera
KW  - traffic scene
KW  - Cameras
KW  - Trajectory
KW  - Roads
KW  - Three-dimensional displays
KW  - Sensors
KW  - Training
KW  - Tracking
DO  - 10.1109/ICRA.2019.8794412
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning from demonstration (LfD) is useful in settings where hand-coding behaviour or a reward function is impractical. It has succeeded in a wide range of problems but typically relies on manually generated demonstrations or specially deployed sensors and has not generally been able to leverage the copious demonstrations available in the wild: those that capture behaviours that were occurring anyway using sensors that were already deployed for another purpose, e.g., traffic camera footage capturing demonstrations of natural behaviour of vehicles, cyclists, and pedestrians. We propose video to behaviour (ViBe), a new approach to learn models of behaviour from unlabelled raw video data of a traffic scene collected from a single, monocular, initially uncalibrated camera with ordinary resolution. Our approach calibrates the camera, detects relevant objects, tracks them through time, and uses the resulting trajectories to perform LfD, yielding models of naturalistic behaviour. We apply ViBe to raw videos of a traffic intersection and show that it can learn purely from videos, without additional expert knowledge.
ER  - 

TY  - CONF
TI  - A Data-Efficient Framework for Training and Sim-to-Real Transfer of Navigation Policies
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 782
EP  - 788
AU  - H. Bharadhwaj
AU  - Z. Wang
AU  - Y. Bengio
AU  - L. Paull
PY  - 2019
KW  - gradient methods
KW  - image coding
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - data-efficient framework
KW  - sim-to-real transfer
KW  - navigation policies
KW  - effective visuomotor policies
KW  - learning-based system
KW  - manual tuning
KW  - robot operating
KW  - training process
KW  - leverage simulation
KW  - off-policy data
KW  - initial image
KW  - lower dimensional latent state
KW  - planner modules
KW  - meta-learning strategy
KW  - adversarial domain transfer
KW  - simulated environments
KW  - similarly distributed latent representation
KW  - fine tuning
KW  - encoder + planner
KW  - planning performances
KW  - navigation tasks
KW  - unlabelled random images
KW  - Robots
KW  - Data models
KW  - Planning
KW  - Task analysis
KW  - Trajectory
KW  - Training
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794310
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning effective visuomotor policies for robots purely from data is challenging, but also appealing since a learning-based system should not require manual tuning or calibration. In the case of a robot operating in a real environment the training process can be costly, time-consuming, and even dangerous since failures are common at the start of training. For this reason, it is desirable to be able to leverage simulation and off-policy data to the extent possible to train the robot. In this work, we introduce a robust framework that plans in simulation and transfers well to the real environment. Our model incorporates a gradient-descent based planning module, which, given the initial image and goal image, encodes the images to a lower dimensional latent state and plans a trajectory to reach the goal. The model, consisting of the encoder and planner modules, is first trained through a meta-learning strategy in simulation. We subsequently perform adversarial domain transfer on the encoder by using a bank of unlabelled but random images from the simulation and real environments to enable the encoder to map images from the real and simulated environments to a similarly distributed latent representation. By fine tuning the entire model (encoder + planner) with only a few real world expert demonstrations, we show successful planning performances in different navigation tasks.
ER  - 

TY  - CONF
TI  - Simulating Emergent Properties of Human Driving Behavior Using Multi-Agent Reward Augmented Imitation Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 789
EP  - 795
AU  - R. P. Bhattacharyya
AU  - D. J. Phillips
AU  - C. Liu
AU  - J. K. Gupta
AU  - K. Driggs-Campbell
AU  - M. J. Kochenderfer
PY  - 2019
KW  - behavioural sciences computing
KW  - convergence
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - traffic engineering computing
KW  - multiagent settings
KW  - multiagent imitation learning
KW  - human drivers
KW  - reward augmentation
KW  - imitation learning process
KW  - multiagent reward augmented imitation learning
KW  - traffic behaviors
KW  - imitation learning algorithms
KW  - human driving behavior modeling
KW  - prior knowledge specification
KW  - convergence guarantees
KW  - driving policies
KW  - Rails
KW  - Convergence
KW  - Biological system modeling
KW  - Trajectory
KW  - Computational modeling
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2019.8793750
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent developments in multi-agent imitation learning have shown promising results for modeling the behavior of human drivers. However, it is challenging to capture emergent traffic behaviors that are observed in real-world datasets. Such behaviors arise due to the many local interactions between agents that are not commonly accounted for in imitation learning. This paper proposes Reward Augmented Imitation Learning (RAIL), which integrates reward augmentation into the multi-agent imitation learning framework and allows the designer to specify prior knowledge in a principled fashion. We prove that convergence guarantees for the imitation learning process are preserved under the application of reward augmentation. This method is validated in a driving scenario, where an entire traffic scene is controlled by driving policies learned using our proposed algorithm. Further, we demonstrate improved performance in comparison to traditional imitation learning algorithms both in terms of the local actions of a single agent and the behavior of emergent properties in complex, multi-agent settings.
ER  - 

TY  - CONF
TI  - A Supervised Approach to Predicting Noise in Depth Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 796
EP  - 802
AU  - C. Sweeney
AU  - G. Izatt
AU  - R. Tedrake
PY  - 2019
KW  - cameras
KW  - convolutional neural nets
KW  - image denoising
KW  - image fusion
KW  - image reconstruction
KW  - image sensors
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - supervised learning
KW  - supervised approach
KW  - modern robotic systems
KW  - detailed sensor noise models
KW  - robotic behavior
KW  - scene-dependent pixel-wise dropouts
KW  - depth camera simulations
KW  - data driven approach
KW  - convolutional neural network
KW  - no-depth-return pixels
KW  - NDP
KW  - ground truth depth
KW  - noisy depth image
KW  - resulting noise-free
KW  - noise-free image
KW  - depth sensor
KW  - cluttered scenes
KW  - uncorrupted depth images
KW  - noise prediction
KW  - scenes reconstruction
KW  - CNN
KW  - unsupervised domain adaptation baselines
KW  - object pose estimation
KW  - noise-free depth image
KW  - label fusion dataset
KW  - Cameras
KW  - Image reconstruction
KW  - Data models
KW  - Noise measurement
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793820
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Modern robotic systems are very complex and need to be tested in simulations with detailed sensor noise models to effectively verify robotic behavior. Depth imagery in particular comes with significant noise in the form of scene-dependent pixel-wise dropouts and distortions. Unfortunately, many depth camera simulations contain limited noise models, or can only support generating realistic depth images of simple scenes, which limits their usefulness in effectively testing perception algorithms. We propose a data driven approach to generate more realistic noise for complex simulated environments by using a convolutional neural network (CNN) to predict which pixels of a simulated noise-free depth image will not have returns (no-depth-return pixels, or NDP). We choose to focus on NDP here, as these dropouts are the most common and dramatic form of depth image noise. To train this network, we use reconstructed real-world scenes from the Label Fusion dataset to provide ground truth depth for each noisy depth image used to scan the scene. We use the resulting noise-free and noisy depth image pairs as labeled examples and train the network to predict which pixels of the noise-free image will be NDP. When used to post-process a simulation of a depth sensor, this system produces realistic depth images, even in cluttered scenes. To demonstrate that our approach successfully closes the reality gap for depth imagery, we show that the popular ICP algorithm for object pose estimation fails more realistically on our CNN-corrupted simulated depth images than on uncorrupted depth images and unsupervised domain adaptation baselines.
ER  - 

TY  - CONF
TI  - Quantum Computation in Robotic Science and Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 803
EP  - 810
AU  - C. Petschnigg
AU  - M. Brandstötter
AU  - H. Pichler
AU  - M. Hofbaur
AU  - B. Dieber
PY  - 2019
KW  - cloud computing
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - quantum computing
KW  - robot programming
KW  - quantum computing
KW  - cloud services
KW  - artificial intelligence
KW  - machine learning
KW  - robotic scientists
KW  - quantum mechanics
KW  - quantum computation
KW  - intelligent robots
KW  - powerful robots
KW  - Robot sensing systems
KW  - Computers
KW  - Optimization
KW  - Qubit
KW  - Acceleration
DO  - 10.1109/ICRA.2019.8793768
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Using the effects of quantum mechanics for computing challenges has been an often discussed topic for decades. The frequent successes and early products in this area, which we have seen in recent years, indicate that we are currently entering a new era of computing. This paradigm shift will also impact the work of robotic scientists and the applications of robotics. New possibilities as well as new approaches to known problems will enable the creation of even more powerful and intelligent robots that make use of quantum computing cloud services or co-processors. In this position paper, we discuss potential application areas and also point out open research topics in quantum computing for robotics. We go into detail on the impact of quantum computing in artificial intelligence and machine learning, sensing and perception, kinematics as well as system diagnosis. For each topic we point out where quantum computing could be applied based on results from current research.
ER  - 

TY  - CONF
TI  - A Learning Framework for High Precision Industrial Assembly
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 811
EP  - 817
AU  - Y. Fan
AU  - J. Luo
AU  - M. Tomizuka
PY  - 2019
KW  - assembling
KW  - optimisation
KW  - production engineering computing
KW  - supervised learning
KW  - learning framework
KW  - high precision industrial assembly
KW  - reinforcement learning
KW  - automatic assembly
KW  - supervised learning
KW  - assembly tasks
KW  - trajectory optimization
KW  - actor-critic algorithm
KW  - Task analysis
KW  - Trajectory
KW  - Optimization
KW  - Dynamics
KW  - Supervised learning
KW  - Computational modeling
KW  - Space exploration
DO  - 10.1109/ICRA.2019.8793659
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Automatic assembly has broad applications in industries. Traditional assembly tasks utilize predefined trajectories or tuned force control parameters, which make the automatic assembly time-consuming, difficult to generalize, and not robust to uncertainties. In this paper, we propose a learning framework for high precision industrial assembly. The framework combines both the supervised learning and the reinforcement learning. The supervised learning utilizes trajectory optimization to provide the initial guidance to the policy, while the reinforcement learning utilizes actor-critic algorithm to establish the evaluation system even the supervisor is not accurate. The proposed learning framework is more efficient compared with the reinforcement learning and achieves better stability performance than the supervised learning. The effectiveness of the method is verified by both the simulation and experiment. Experimental videos are available at [1].
ER  - 

TY  - CONF
TI  - Manipulation by Feel: Touch-Based Control with Deep Predictive Models
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 818
EP  - 824
AU  - S. Tian
AU  - F. Ebert
AU  - D. Jayaraman
AU  - M. Mudigonda
AU  - C. Finn
AU  - R. Calandra
AU  - S. Levine
PY  - 2019
KW  - dexterous manipulators
KW  - neurocontrollers
KW  - predictive control
KW  - tactile sensors
KW  - unsupervised learning
KW  - feel
KW  - touch-based control
KW  - deep predictive models
KW  - touch sensing
KW  - dexterous robotic manipulation
KW  - tactile sensing
KW  - nonprehensile manipulation
KW  - general purpose control techniques
KW  - accurate physics models
KW  - tactile percepts
KW  - high-resolution tactile
KW  - deep neural network dynamics models
KW  - deep tactile MPC
KW  - tactile servoing
KW  - raw tactile sensor inputs
KW  - GelSight-style tactile sensor
KW  - learned tactile predictive model
KW  - user-specified configurations
KW  - goal tactile reading
KW  - Task analysis
KW  - Predictive models
KW  - Tactile sensors
KW  - Videos
DO  - 10.1109/ICRA.2019.8794219
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Touch sensing is widely acknowledged to be important for dexterous robotic manipulation, but exploiting tactile sensing for continuous, non-prehensile manipulation is challenging. General purpose control techniques that are able to effectively leverage tactile sensing as well as accurate physics models of contacts and forces remain largely elusive, and it is unclear how to even specify a desired behavior in terms of tactile percepts. In this paper, we take a step towards addressing these issues by combining high-resolution tactile sensing with data-driven modeling using deep neural network dynamics models. We propose deep tactile MPC, a framework for learning to perform tactile servoing from raw tactile sensor inputs, without manual supervision. We show that this method enables a robot equipped with a GelSight-style tactile sensor to manipulate a ball, analog stick, and 20-sided die, learning from unsupervised autonomous interaction and then using the learned tactile predictive model to reposition each object to user-specified configurations, indicated by a goal tactile reading. Videos, visualizations and the code are available here: https://sites.google.com/view/deeptactilempc.
ER  - 

TY  - CONF
TI  - 3D Printed Soft Pneumatic Actuators with Intent Sensing for Hand Rehabilitative Exoskeletons*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 841
EP  - 846
AU  - B. W. K. Ang
AU  - C. Yeow
PY  - 2019
KW  - biomechanics
KW  - medical robotics
KW  - patient rehabilitation
KW  - pneumatic actuators
KW  - intent sensing
KW  - hand rehabilitative exoskeletons
KW  - functional motor skills
KW  - motor recovery
KW  - soft robotic exoskeletons
KW  - complex task-based rehabilitative exercises
KW  - bidirectional motion
KW  - soft actuators
KW  - finger flexion
KW  - noninvasive intent detection
KW  - upper limb rehabilitative exoskeletons
KW  - passive finger extension
KW  - fold-based bidirectional 3D printed intent-sensing soft pneumatic actuator
KW  - Fingers
KW  - Exoskeletons
KW  - Actuators
KW  - Robots
KW  - Three-dimensional displays
KW  - Optical sensors
DO  - 10.1109/ICRA.2019.8793785
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Loss of functional motor skills are common and often require patients to undergo rehabilitation so that they have a chance at motor recovery. Advancement in technology has seen to a rise in the use of robotic technology in conducting rehabilitative exercises that are traditionally carried out by physiotherapists. In recent years, soft robotic exoskeletons, using pneumatic-based actuation in particular, have gained much interest due to their compliant characteristics and safe operating conditions. In order to carry out complex task-based rehabilitative exercises, these soft pneumatic actuators must ideally be able to move with multiple degrees of freedom or minimally, in a bidirectional motion. Majority of the research covering soft actuators can only achieve finger flexion with some providing passive finger extension. Non-invasive intent detection in the control of these exoskeletons is also lacking in sensing both finger flexion and extension. In this paper we present our work on a fold-based bidirectional 3D printed intent-sensing soft pneumatic actuator (ISPA) that can achieve bidirectional motion and provide intent detection for finger flexion and extension for application in upper limb rehabilitative exoskeletons.
ER  - 

TY  - CONF
TI  - Gaze-based, Context-aware Robotic System for Assisted Reaching and Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 863
EP  - 869
AU  - A. Shafti
AU  - P. Orlov
AU  - A. A. Faisal
PY  - 2019
KW  - gaze tracking
KW  - grammars
KW  - handicapped aids
KW  - human-robot interaction
KW  - medical robotics
KW  - mobile robots
KW  - patient rehabilitation
KW  - human-in-the-loop assistive robotics
KW  - low-level motion actions
KW  - 3D gaze estimation
KW  - grammars-based implementation
KW  - gaze-based
KW  - context-aware robotic system
KW  - assistive robotic systems
KW  - movement disabilities
KW  - human user
KW  - multimodal system
KW  - assisted reaching
KW  - assisted grasping
KW  - Three-dimensional displays
KW  - Cameras
KW  - Robot kinematics
KW  - Robot vision systems
KW  - Grasping
DO  - 10.1109/ICRA.2019.8793804
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Assistive robotic systems endeavour to support those with movement disabilities, enabling them to move again and regain functionality. Main issue with these systems is the complexity of their low-level control, and how to translate this to simpler, higher level commands that are easy and intuitive for a human user to interact with. We have created a multi-modal system, consisting of different sensing, decision making and actuating modalities, leading to intuitive, human-in-the-loop assistive robotics. The system takes its cue from the user's gaze, to decode their intentions and implement low-level motion actions to achieve high-level tasks. This results in the user simply having to look at the objects of interest, for the robotic system to assist them in reaching for those objects, grasping them, and using them to interact with other objects. We present our method for 3D gaze estimation, and grammars-based implementation of sequences of action with the robotic system. The 3D gaze estimation is evaluated with 8 subjects, showing an overall accuracy of 4.68\pm 0.14cm. The full system is tested with 5 subjects, showing successful implementation of 100% of reach to gaze point actions and full implementation of pick and place tasks in 96%, and pick and pour tasks in 76% of cases. Finally we present a discussion on our results and what future work is needed to improve the system.
ER  - 

TY  - CONF
TI  - Ways to Learn a Therapist’s Patient-specific Intervention: Robotics-vs Telerobotics-mediated Hands-on Teaching
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 870
EP  - 876
AU  - J. Fong
AU  - C. Martinez
AU  - M. Tavakoli
PY  - 2019
KW  - medical robotics
KW  - patient rehabilitation
KW  - patient treatment
KW  - telerobotics
KW  - therapists time
KW  - healthcare resources
KW  - rehabilitation services
KW  - robot-assisted rehabilitation
KW  - economical solution
KW  - LfD
KW  - robotic rehabilitation
KW  - learning from demonstration
KW  - telerobotic-mediated hands-on teaching
KW  - telerobotic-mediated kinesthetic teaching
KW  - TMKT
KW  - RMKT
KW  - Task analysis
KW  - Impedance
KW  - Medical treatment
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Service robots
DO  - 10.1109/ICRA.2019.8793907
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Due to the limitations of therapists time and healthcare resources to cover the increasing demand for rehabilitation services, robot-assisted rehabilitation is becoming an appealing, powerful and economical solution. In our previous research, a solution that combines Learning from Demonstration (LfD) and robotic rehabilitation to save the therapists time and reduce the therapy costs was proposed. In this paper we compare two modalities, Robot-and Telerobotic-Mediated Kinesthetic Teaching (RMKT and TMKT), for implementing LfD in robotic rehabilitation. Our results show that behaviors demonstrated in both modalities are able to be imitated accurately, but demonstrations in TMKT have less repeatability.
ER  - 

TY  - CONF
TI  - Development of a Novel Force Sensing System to Measure the Ground Reaction Force of Rats with Complete Spinal Cord Injury
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 877
EP  - 882
AU  - D. Anopas
AU  - L. Junquan
AU  - S. E. Kiat
AU  - S. K. Wee
AU  - P. E. Tow
AU  - S. Y. Chew
AU  - A. W. Tech
PY  - 2019
KW  - biomechanics
KW  - biomedical measurement
KW  - force sensors
KW  - injuries
KW  - medical disorders
KW  - molecular biophysics
KW  - nanofibres
KW  - nanomedicine
KW  - neurophysiology
KW  - patient rehabilitation
KW  - patient treatment
KW  - proteins
KW  - tissue engineering
KW  - T9-T10 level
KW  - human observance
KW  - nanofiber scaffold
KW  - neurotrophin-3
KW  - right limb
KW  - force sensing system
KW  - spinalized rats
KW  - force detection
KW  - effective treatment method
KW  - spinal cord injury
KW  - complete spinal cord
KW  - spinal cord transection injury model
KW  - motor function
KW  - rehabilitation enhanced recovery
KW  - rehabilitated rats
KW  - left limb
KW  - ground reaction force
KW  - Rats
KW  - Force
KW  - Force measurement
KW  - Spinal cord
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794368
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To date, the aim of spinal cord injury (SCI) researches in animals is to find the most effective treatment method which can lead to faster recovery. In order to evaluate if the method is effective, robust functional assessments are crucial. From the past to present, indicators to observe the recovery of the motor function in rodent SCI models are using human observance or the Basso, Beattie, and Bresnahan score (BBB score), force detection, and imaging approaches. Nevertheless, these indicators do not meet some requirements for a severe full transection injury case. The goal of this project is to develop a novel force sensing system for measuring the ground reaction force of rats with severe SCI. In total, this system was tested with 12 spinalized rats. Following a full transection at the T9-T10 level of the spinal cord in rats with a 2mm gap, a nanofiber scaffold containing Neurotrophin-3 (NT-3), as previously described, was implanted [1]. After 12 weeks of rehabilitative training, results showed that rats that underwent rehabilitation were able to gradually exert more force as compared to rats that did not undergo rehabilitation. At Week 6, the ground reaction force recorded in rats with rehabilitation was 0.8 ± 0.1 N in left limb and 0.75 ± 0.14 N in right limb. On the other hand, rats without rehabilitation exerted 0.52 ± 0.06 N in left limb and 0.47 ± 0.09 N in right limb. At Week 12, the force recorded in rehabilitated rats increased to 1.43 ± 0.13 N in left limb and 1.28 ± 0.17 N in right limb whereas in rats without rehabilitation, the force recorded was only 0.74 ± 0.12 N in left limb and 0.54 ± 0.11 N in right limb. These results not only showed that rehabilitation enhanced recovery of motor function, but also demonstrated the viability of measuring the ground reaction force applied by the rats as an assessment for a full spinal cord transection injury model.
ER  - 


TY  - CONF
TI  - A Four-magnet System for 2D Wireless Open-Loop Control of Microrobots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 883
EP  - 888
AU  - A. Zarrouk
AU  - K. Belharet
AU  - O. Tahri
AU  - A. Ferreira
PY  - 2019
KW  - electric actuators
KW  - microrobots
KW  - permanent magnets
KW  - four-magnet system
KW  - 2D wireless open-loop control
KW  - untethered microrobot
KW  - local maxima
KW  - magnetic field magnitude
KW  - planar workspace
KW  - convergence point
KW  - magnetic microrobots
KW  - influence zone
KW  - actuator orientation
KW  - actuator design
KW  - permanent magnets
KW  - open-loop guidance
KW  - Actuators
KW  - Permanent magnets
KW  - Magnetization
KW  - Magnetic forces
KW  - Convergence
KW  - Force
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8794241
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel permanent magnets based actuator capable of injecting and 2D wireless control the motion of an untethered microrobot. The actuator is obtained with a simple, but an effective arrangement of four permanent magnets. Its novelty is that it creates local maxima of the magnetic field magnitude in a planar workspace. This results in a convergence point for magnetic microrobots that are in its influence zone. Trapping microrobots in the local maxima makes their open-loop guidance possible, even in presence of reasonable perturbations. Actually, open-loop control is the only way to achieve some drug delivery when there are no sensors to provide us a feedback on the microrobot's positions. With the proposed actuator, the workspace is reduced, the movement is simplified and the actuator orientation is not needed anymore. Experimental results are provided in the paper to show the soundness of the proposed actuator design.
ER  - 

TY  - CONF
TI  - Nitinol living hinges for millimeter-sized robots and medical devices
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 889
EP  - 893
AU  - P. A. York
AU  - R. J. Wood
PY  - 2019
KW  - beam steering
KW  - bending
KW  - biomedical materials
KW  - cameras
KW  - elasticity
KW  - endoscopes
KW  - etching
KW  - hinges
KW  - laser beam machining
KW  - micromachining
KW  - microrobots
KW  - nickel alloys
KW  - prototypes
KW  - titanium alloys
KW  - water jet cutting
KW  - millimeter-sized robots
KW  - medical devices
KW  - hybrid manufacturing process
KW  - laser micromaching
KW  - superelastic properties
KW  - room-temperature mechanical etching procedure
KW  - thermal damage
KW  - bending stiffness model
KW  - prototype devices
KW  - simple laser beam steering system
KW  - nitinol living hinges
KW  - abrasive jet micromaching
KW  - endoscopic camera wrist
KW  - Fasteners
KW  - Fabrication
KW  - Robots
KW  - Laser beam cutting
KW  - Micromachining
KW  - Strain
KW  - Geometry
DO  - 10.1109/ICRA.2019.8794091
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A hybrid manufacturing process combining abrasive jet and laser micromaching enables the creation of living hinges in nitinol that retain the superelastic properties of the bulk material. The former selectively etches through the thickness of a workpiece and the latter defines the part's final geometry. Because the majority of the material removal is done with the room-temperature mechanical etching procedure, thermal damage to the part is minimized. Processing parameters to achieve desired geometries are described, a bending stiffness model for the living hinges is provided, and validation experiments are presented. Lastly, to demonstrate the usefulness of these components to millimeter-sized robotic systems and medical devices, we show their integration in two prototype devices: an endoscopic camera wrist and a simple laser beam steering system.
ER  - 

TY  - CONF
TI  - Tetherless Mobile Micro-Surgical Scissors Using Magnetic Actuation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 894
EP  - 899
AU  - O. Onaizah
AU  - E. Diller
PY  - 2019
KW  - elasticity
KW  - magnetic flux
KW  - medical robotics
KW  - microrobots
KW  - surgery
KW  - laparoscopic probe
KW  - current minimally-invasive surgical tools
KW  - wireless surgical scissors
KW  - untethered surgical scissors
KW  - untethered surgical tool
KW  - superelastic nitinol wire
KW  - external magnetic flux density
KW  - 3D magnetic coil system
KW  - sharpened titanium sheets
KW  - mobile microrobotic device
KW  - proof-of-concept prototype
KW  - magnetic actuation
KW  - tetherless mobile microsurgical scissors
KW  - size 15.0 mm
KW  - Blades
KW  - Magnetic flux
KW  - Tools
KW  - Force
KW  - Torque
KW  - Springs
KW  - Robots
DO  - 10.1109/ICRA.2019.8793564
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Current minimally-invasive surgical tools suffer from lack of scalability and restricted access to some surgical sites using a laparoscopic probe. This paper introduces a proof-of-concept prototype of the first completely wireless surgical scissors capable of dexterous motion and cutting in a remote environment as a mobile microrobotic device. The 15 mm untethered surgical scissors are custom made from sharpened titanium sheets with a magnet on each blade for actuating force and control. A super-elastic nitinol wire acts as a restoring spring and results in a simple design with no pin joint which is difficult to fabricate at small sizes. To actuate and control the scissors, a 3D magnetic coil system is used here for testing and demonstration. An external magnetic flux density of 20 mT can be generated using the coils and is used for cutting as well as orienting, moving and closing the scissors. In this first prototype setup, the scissors can generate up to 75 mN of cutting force, and we demonstrate the cutting of agar. As a proof of concept demonstration of the potential use of the scissors as a completely untethered surgical tool, we robotically maneuver the scissors to a target location in a confined environment where they cut through agar and return to their initial position.
ER  - 

TY  - CONF
TI  - A Large-Deflection FBG Bending Sensor for SMA Bending Modules for Steerable Surgical Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 900
EP  - 906
AU  - J. Sheng
AU  - N. J. Deaton
AU  - J. P. Desai
PY  - 2019
KW  - bending
KW  - biomedical measurement
KW  - Bragg gratings
KW  - closed loop systems
KW  - fibre optic sensors
KW  - manipulators
KW  - medical robotics
KW  - shape memory effects
KW  - surgery
KW  - steerable surgical robots
KW  - disposable surgical robots
KW  - minimally invasive procedures
KW  - closed-loop control
KW  - superelastic substrate
KW  - flexible adhesive
KW  - sensor-actuator assembly
KW  - SMA actuation
KW  - intrinsic bending sensor
KW  - shape memory alloy bending modules
KW  - fiber Bragg grating bending sensor
KW  - SMA bending module
KW  - large-deflection FBG bending sensor
KW  - Robot sensing systems
KW  - Fiber gratings
KW  - Substrates
KW  - Wires
KW  - Strain
KW  - Gratings
DO  - 10.1109/ICRA.2019.8794302
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the development of a fiber Bragg grating (FBG) bending sensor for shape memory alloy (SMA) bending modules. Due to the small form factor, low cost, and large-deflection capability, SMA bending modules can be used to construct disposable surgical robots for a variety of minimally invasive procedures. To realize a closed-loop control of SMA bending modules, an intrinsic bending sensor is imperative. Due to the lack of bending sensors for SMA bending modules, we have developed an FBG bending sensor by integrating FBG fibers with a superelastic substrate using flexible adhesive. Since the substrate is ultra-thin and adhesive is flexible, the sensor has low stiffness and can measure large curvatures. Additionally, due to the orthogonal arrangement of the sensor/actuator assembly, the influence of temperature variation caused by SMA actuation can be compensated. The working principle of the developed sensor was modeled followed by simulations. After experimentally evaluating the developed model, the sensor was integrated with an SMA bending module and cyclically bi-directionally deflected. The experimental results proved the relatively high measurement accuracy, high repeatability, and large measurable curvatures of the sensor, although hysteresis was observed due to friction.
ER  - 

TY  - CONF
TI  - Towards Learning Abstract Representations for Locomotion Planning in High-dimensional State Spaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 922
EP  - 928
AU  - T. Klamt
AU  - S. Behnke
PY  - 2019
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - path planning
KW  - cost function
KW  - search-based planning
KW  - hybrid driving-stepping locomotion
KW  - locomotion planning
KW  - high-dimensional state spaces
KW  - ground robots
KW  - ground structure
KW  - movable body parts
KW  - robot representation
KW  - Planning
KW  - Robots
KW  - Cost function
KW  - Task analysis
KW  - Search problems
KW  - Acceleration
KW  - Tuning
DO  - 10.1109/ICRA.2019.8794144
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Ground robots which are able to navigate a variety of terrains are needed in many domains. One of the key aspects is the capability to adapt to the ground structure, which can be realized through movable body parts coming along with additional degrees of freedom (DoF). However, planning respective locomotion is challenging since suitable representations result in large state spaces. Employing an additional abstract representation-which is coarser, lower-dimensional, and semantically enriched-can support the planning. While a desired robot representation and action set of such an abstract representation can be easily defined, the cost function requires large tuning efforts. We propose a method to represent the cost function as a CNN. Training of the network is done on generated artificial data, while it generalizes well to the abstraction of real world scenes. We further apply our method to the problem of search-based planning of hybrid driving-stepping locomotion. The abstract representation is used as a powerful informed heuristic which accelerates planning by multiple orders of magnitude.
ER  - 

TY  - CONF
TI  - Fast Stochastic Functional Path Planning in Occupancy Maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 929
EP  - 935
AU  - G. Francis
AU  - L. Ott
AU  - F. Ramos
PY  - 2019
KW  - computational complexity
KW  - Gaussian processes
KW  - optimisation
KW  - path planning
KW  - robots
KW  - sampling methods
KW  - trajectory control
KW  - occupancy map
KW  - stochastic trajectory optimiser
KW  - Gaussian process path representation
KW  - trajectory optimisation
KW  - fast stochastic functional path planning
KW  - path planners
KW  - highly expressive path representation
KW  - sampling-based planners
KW  - fully defined artificial potential field
KW  - partially observed model
KW  - cubic complexity
KW  - kernel approximation
KW  - computational complexity
KW  - stochastic sampling
KW  - sampling-based methods
KW  - Planning
KW  - Optimization
KW  - Trajectory
KW  - Kernel
KW  - Robots
KW  - Stochastic processes
DO  - 10.1109/ICRA.2019.8794118
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Path planners are generally categorised as either trajectory optimisers or sampling-based planners. The latter is the predominant planning paradigm for occupancy maps. Most trajectory optimisers require a fully defined artificial potential field for planning and cannot incorporate updates from a partially observed model such as an occupancy map. A stochastic trajectory optimiser capable of planning over occupancy map was presented in [1]. However, its scalability is limited by the cubic complexity of the Gaussian process path representation. In this work, we introduce a novel highly expressive path representation based on kernel approximation to perform trajectory optimisation over occupancy maps. This approach reduces the computational complexity to a fixed cost that only depends on the number of features. We show that stochastic sampling is crucial for planning in occupancy maps and present comparisons to other state-of-the-art planning methods, using simulated and real occupancy data. These experiments demonstrate the significant reduction in runtime, resulting in performance comparable to or better than sampling-based methods.
ER  - 

TY  - CONF
TI  - A Scalable Framework For Real-Time Multi-Robot, Multi-Human Collision Avoidance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 936
EP  - 943
AU  - A. Bajcsy
AU  - S. L. Herbert
AU  - D. Fridovich-Keil
AU  - J. F. Fisac
AU  - S. Deglurkar
AU  - A. D. Dragan
AU  - C. J. Tomlin
PY  - 2019
KW  - collision avoidance
KW  - human-robot interaction
KW  - multi-robot systems
KW  - robust control
KW  - trajectory control
KW  - robust motion planning
KW  - robotics literature
KW  - robot navigation
KW  - high-order system dynamics
KW  - confidence-aware human motion predictions
KW  - sequential priority ordering
KW  - trajectory planning
KW  - multirobot multihuman collision avoidance
KW  - Planning
KW  - Trajectory
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Predictive models
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8794457
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robust motion planning is a well-studied problem in the robotics literature, yet current algorithms struggle to operate scalably and safely in the presence of other moving agents, such as humans. This paper introduces a novel framework for robot navigation that accounts for high-order system dynamics and maintains safety in the presence of external disturbances, other robots, and humans. Our approach precomputes a tracking error margin for each robot, generates confidence-aware human motion predictions, and coordinates multiple robots with a sequential priority ordering, effectively enabling scalable safe trajectory planning and execution. We demonstrate our approach in hardware with two robots and two humans, and showcase scalability in a larger simulation.
ER  - 

TY  - CONF
TI  - Lazy Evaluation of Goal Specifications Guided by Motion Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 944
EP  - 950
AU  - J. D. Hernández
AU  - M. Moll
AU  - L. E. Kavraki
PY  - 2019
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - lazy evaluation
KW  - collaborative environments
KW  - robot motion commands
KW  - delayed grounding
KW  - lazy variable grounding
KW  - motion planning algorithm
KW  - semantic interpretation
KW  - goal specifications
KW  - reward-penalty strategy
KW  - Semantics
KW  - Planning
KW  - Robot kinematics
KW  - Grounding
KW  - Automobiles
KW  - Collaboration
DO  - 10.1109/ICRA.2019.8793570
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Nowadays robotic systems are expected to share workspaces and collaborate with humans. In such collaborative environments, an important challenge is to ground or establish the correct semantic interpretation of a human request. Once such an interpretation is available, the request must be translated into robot motion commands in order to complete the desired task. It is not unusual that a human request cannot be grounded to a unique interpretation, thus leading to an ambiguous request. A simple example is to ask a robot to “put a cup on the table,” when there are multiple cups available. In order to deal with this kind of ambiguous request, we propose a delayed or lazy variable grounding. The focus of this paper is a motion planning algorithm that, given goal regions that represent different valid groundings, lazily finds a feasible path to any one valid grounding. This algorithm includes a reward-penalty strategy, which attempts to prioritize those goal regions that seem more promising to provide a solution. We validate our approach by solving requests with multiple valid alternatives in both simulation and real-world experiments.
ER  - 

TY  - CONF
TI  - Reconfigurable Motion Planning and Control in Obstacle Cluttered Environments under Timed Temporal Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 951
EP  - 957
AU  - C. K. Verginis
AU  - C. Vrohidis
AU  - C. P. Bechlioulis
AU  - K. J. Kyriakopoulos
AU  - D. V. Dimarogonas
PY  - 2019
KW  - collision avoidance
KW  - convex programming
KW  - formal verification
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - temporal logic
KW  - high-level specification
KW  - timed temporal logic formula
KW  - obstacle avoidance
KW  - motion controller
KW  - safe navigation
KW  - transition system
KW  - standard formal verification
KW  - convex optimization techniques
KW  - reconfigurable motion planning
KW  - obstacle cluttered environments
KW  - timed temporal tasks
KW  - robot navigation
KW  - hybrid control strategy
KW  - temporal specifications
KW  - agent motion abstraction
KW  - Clocks
KW  - Task analysis
KW  - Planning
KW  - Navigation
KW  - Automata
DO  - 10.1109/ICRA.2019.8794000
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work addresses the problem of robot navigation under timed temporal specifications in workspaces cluttered with obstacles. We propose a hybrid control strategy that guarantees the accomplishment of a high-level specification expressed as a timed temporal logic formula, while preserving safety (i.e., obstacle avoidance) of the system. In particular, we utilize a motion controller that achieves safe navigation inside the workspace in predetermined time, thus allowing us to abstract the motion of the agent as a finite timed transition system among certain regions of interest. Next, we employ standard formal verification and convex optimization techniques to derive high-level timed plans that satisfy the agent's specifications. A simulation study illustrates and clarifies the proposed scheme.
ER  - 

TY  - CONF
TI  - Door opening and traversal with an industrial cartesian impedance controlled mobile robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 966
EP  - 972
AU  - M. Stuede
AU  - K. Nuelle
AU  - S. Tappe
AU  - T. Ortmaier
PY  - 2019
KW  - convolutional neural nets
KW  - image colour analysis
KW  - image segmentation
KW  - manipulator dynamics
KW  - mobile robots
KW  - robot vision
KW  - handle frame
KW  - manipulator
KW  - inner controller loops
KW  - door opening
KW  - industrial cartesian impedance
KW  - mobile robot
KW  - holistic approach
KW  - door model
KW  - door handle detection
KW  - convolutional neural network-based architecture
KW  - handle shapes
KW  - detection rate
KW  - door plane
KW  - control structure
KW  - Robot kinematics
KW  - Impedance
KW  - Task analysis
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - End effectors
DO  - 10.1109/ICRA.2019.8793866
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a holistic approach for door opening with a cartesian impedance controlled mobile robot, a KUICA KMR iiwa. Based on a given map of the environment, the robot autonomously detects the door handle, opens doors and traverses doorways without knowledge of a door model or the door's geometry. The door handle detection uses a convolutional neural network (CNN)-based architecture to obtain the handle's bounding box in a RGB image that works robustly for various handle shapes and colors. We achieve a detection rate of 100% for an evaluation set of 38 different door handles, by always selecting for highest confidence score. Registered depth data segmentation defines the door plane to construct a handle coordinate frame. We introduce a control structure based on the task frame formalism that uses the handle frame for reference in an outer loop for the manipulator's impedance controller. It runs in soft real-time on an external computer with approximately 20 Hz since access to inner controller loops is not available for the KMR iiwa. With the approach proposed in this paper, the robot successfully opened and traversed for 22 out of 25 trials at five different doors.
ER  - 

TY  - CONF
TI  - An Algorithm for Odor Source Localization based on Source Term Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 973
EP  - 979
AU  - F. Rahbar
AU  - A. Marjovi
AU  - A. Martinoli
PY  - 2019
KW  - estimation theory
KW  - Markov processes
KW  - mobile robots
KW  - path planning
KW  - wind tunnels
KW  - odor source localization
KW  - source term estimation
KW  - airborne chemicals
KW  - mobile sensing systems
KW  - navigation method
KW  - partially observable Markov decision processes
KW  - wind tunnel
KW  - Robot sensing systems
KW  - Estimation
KW  - Navigation
KW  - Probabilistic logic
KW  - Heuristic algorithms
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8793784
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Finding sources of airborne chemicals with mobile sensing systems finds applications across the security, safety, domestic, medical, and environmental domains. In this paper, we present an algorithm based on source term estimation for odor source localization that is coupled with a navigation method based on partially observable Markov decision processes. We propose an innovative strategy to balance exploration and exploitation in navigation. The method has been evaluated systematically through high-fidelity simulations and in a wind tunnel emulating realistic and repeatable conditions. The impact of multiple algorithmic and environmental parameters has been studied in the experiments.
ER  - 

TY  - CONF
TI  - Neural Network Pile Loading Controller Trained by Demonstration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 980
EP  - 986
AU  - E. Halbach
AU  - J. Kämäräinen
AU  - R. Ghabcheloo
PY  - 2019
KW  - backpropagation
KW  - Bayes methods
KW  - construction equipment
KW  - feedforward neural nets
KW  - industrial robots
KW  - mobile robots
KW  - neurocontrollers
KW  - sensors
KW  - automated pile loading
KW  - robotic wheel loader
KW  - control signals
KW  - hydrostatic driving pressure
KW  - boom control
KW  - single hidden layer
KW  - training data
KW  - bucket filling performance
KW  - heuristic automated controller
KW  - manual human control
KW  - demonstration approach
KW  - Bayesian regularization backpropagation algorithm
KW  - end-to-end neural network controllers
KW  - 3D laser scan
KW  - Levenberg-Marquardt algorithm
KW  - Artificial neural networks
KW  - Loading
KW  - Robot sensing systems
KW  - Wheels
KW  - Training
KW  - Neurons
DO  - 10.1109/ICRA.2019.8793468
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the development and testing of end-to-end Neural Network (NN) controllers for automated pile loading with a robotic wheel loader. NNs were trained using the Learning from Demonstration approach, i.e. by first recording sensor and control signals during manually-driven pile loading actions. Training made use of three input signals: boom angle, bucket angle and hydrostatic driving pressure; and three output signals: boom control, bucket control and the gas command. Most testing was conducted using NNs with 5 neurons in a single hidden layer, which were able to fill the bucket reasonably well. Qualitative comparisons were made to ascertain how the amount of training data and number of hidden neurons affects bucket filling performance, for NNs trained using both the Levenberg-Marquardt and Bayesian Regularization backpropagation algorithms. Different NNs trained with the same data were also compared. An additional pile transfer experiment compared the performance of an NN controller with a heuristic automated controller and manual human control. By estimating the total volume of material transferred using 3D laser scans, human control was found to have the highest performance, though the NN outperformed the heuristic controller. This indicated that end-to-end NN control trained by demonstration could offer improvement over current heuristic methods for automated pile loading.
ER  - 

TY  - CONF
TI  - Dynamic Manipulation of Gear Ratio and Ride Height for a Novel Compliant Wheel using Pneumatic Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 987
EP  - 992
AU  - T. Hojnik
AU  - P. Flick
AU  - T. Bandyopadhyay
AU  - J. Roberts
PY  - 2019
KW  - gears
KW  - mobile robots
KW  - pneumatic actuators
KW  - road vehicles
KW  - vehicle dynamics
KW  - wheels
KW  - dynamic manipulation
KW  - gear ratio
KW  - pneumatic actuators
KW  - configurable wheel
KW  - varied radius wheels
KW  - positional manipulation
KW  - centre hub
KW  - virtual wheels
KW  - physical system
KW  - outer rim
KW  - fast control
KW  - vehicle ride height
KW  - compliant wheel
KW  - off-road robotics
KW  - space exploration
KW  - Wheels
KW  - Mathematical model
KW  - Mobile robots
KW  - Two dimensional displays
KW  - Gears
KW  - Acceleration
DO  - 10.1109/ICRA.2019.8793681
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a novel configurable wheel that exhibits desired properties of varied radius wheels. Positional manipulation of the centre hub is proposed and tested to achieve these desired characteristics of `virtual' wheels in a physical system. The centre hub is manipulated via the use of pneumatic actuators mounted to and constricted by the outer rim of the wheel, which allows for fast and accurate control to enable the vehicle ride height and gear ratio to be adjusted continuously and be maintained during the wheels' full rotation. Experiments are presented, validating this ability of the system. We envision uses for this system to extend from off-road robotics to space exploration as these wheels exhibit novel characteristics not demonstrated by other platforms.
ER  - 

TY  - CONF
TI  - Feasible coordination of multiple homogeneous or heterogeneous mobile vehicles with various constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1008
EP  - 1013
AU  - Z. Sun
AU  - M. Greiff
AU  - A. Robertsson
AU  - R. Johansson
PY  - 2019
KW  - algebra
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - path planning
KW  - nonholonomic motion constraints
KW  - holonomic coordination constraints
KW  - differential-algebraic equations
KW  - viability theory
KW  - coordinated motion control
KW  - heterogeneous vehicle dynamics
KW  - multivehicle coordination
KW  - control schemes
KW  - coordination control
KW  - heterogeneous mobile vehicles
KW  - Task analysis
KW  - Kinematics
KW  - Mathematical model
KW  - Vehicle dynamics
KW  - Trajectory
KW  - Tools
DO  - 10.1109/ICRA.2019.8793834
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of feasible coordination control for multiple homogeneous or heterogeneous mobile vehicles subject to various constraints (nonholonomic motion constraints, holonomic coordination constraints, equality/inequality constraints etc). We develop a general framework involving differential-algebraic equations and viability theory to describe and determine coordination feasibility for a coordinated motion control under heterogeneous vehicle dynamics and various constraints. A heuristic algorithm is proposed for generating feasible trajectories for each individual vehicle. We show several application examples and simulation experiments on multi-vehicle coordination under various constraints to validate the theory and the effectiveness of the proposed algorithm and control schemes.
ER  - 

TY  - CONF
TI  - Turn-minimizing multirobot coverage
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1014
EP  - 1020
AU  - I. Vandermeulen
AU  - R. Groß
AU  - A. Kolling
PY  - 2019
KW  - minimisation
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - travelling salesman problems
KW  - turn-minimizing multirobot coverage
KW  - identical robots
KW  - mission time
KW  - robot
KW  - multiple travelling salesperson problem
KW  - coverage plans
KW  - robotic vacuum
KW  - turn minimization
KW  - coverage time
KW  - path planning
KW  - partitioning heuristic
KW  - coverage plan
KW  - multirobot coverage
KW  - Robots
KW  - Tools
KW  - Turning
KW  - Minimization
KW  - Shape
KW  - Merging
KW  - Planning
DO  - 10.1109/ICRA.2019.8794002
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Multirobot coverage is the problem of planning paths for several identical robots such that the combined regions traced out by the robots completely cover their environment. We consider the problem of multirobot coverage with the objective of minimizing the mission time, which depends on the number of turns taken by the robots. To solve this problem, we first partition the environment into ranks which are long thin rectangles the width of the robot's coverage tool. Our novel partitioning heuristic produces a set of ranks which minimizes the number of turns. Next, we solve a variant of the multiple travelling salesperson problem (m-TSP) on the set of ranks to minimize the robots' mission time. The resulting coverage plan is guaranteed to cover the entire environment. We present coverage plans for a robotic vacuum using real maps of 25 indoor environments and compare the solutions to paths planned without the objective of minimizing turns. Turn minimization reduced the number of turns by 6.7% and coverage time by 3.8% on average for teams of 1-5 robots.
ER  - 

TY  - CONF
TI  - Efficient Kinodynamic Multi-Robot Replanning in Known Workspaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1021
EP  - 1027
AU  - A. Desai
AU  - M. Collins
AU  - N. Michael
PY  - 2019
KW  - collision avoidance
KW  - graph theory
KW  - iterative methods
KW  - mobile robots
KW  - multi-robot systems
KW  - reachability analysis
KW  - robot dynamics
KW  - trajectory control
KW  - known workspaces
KW  - online centralized kinodynamic multirobot replanning
KW  - offline state lattice reachability analysis
KW  - explicit geometric graph
KW  - higher-order derivatives
KW  - geometric paths
KW  - kinodynamic multirobot replanning
KW  - sequential graph searches
KW  - iterative refinement procedures
KW  - Planning
KW  - Trajectory
KW  - Libraries
KW  - Lattices
KW  - Collision avoidance
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793647
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we consider the problem of online centralized kinodynamic multi-robot replanning (from potentially non-stationary initial states) and coordination in known and cluttered workspaces. Offline state lattice reachability analysis is leveraged to decouple the planning problem into two sequential graph searches-one in the explicit geometric graph of the environment and the other in the graph of the higher-order derivatives of the robot's state-in a manner such that the intermediate vertices of a safe set of geometric paths are guaranteed to have a feasible assignment of higher-order derivatives. Without additional iterative refinement procedures, the resulting time parameterized polynomial trajectories are dynamically feasible and collision-free. Planning results with up to 20 robots in two and three dimensional workspaces suggest the suitability of the proposed approach for multi-robot replanning in known environments.
ER  - 

TY  - CONF
TI  - Cannot avoid penalty? Let’s minimize
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1052
EP  - 1058
AU  - C. Sarkar
AU  - M. Agarwal
PY  - 2019
KW  - multi-robot systems
KW  - optimisation
KW  - processor scheduling
KW  - warehousing
KW  - multirobot systems
KW  - multirobot task allocation
KW  - task completion
KW  - multiprocessor scheduling
KW  - minimum penalty scheduling
KW  - near-optimal real-time task schedule
KW  - Task analysis
KW  - Robots
KW  - Resource management
KW  - Schedules
KW  - Real-time systems
KW  - Scheduling
KW  - Multi-robot systems
DO  - 10.1109/ICRA.2019.8794338
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Multi-robot systems are deployed in a warehouse to automate the process of storing and retrieving objects in and out of the warehouse. The efficiency of the system largely depends on how the tasks are allocated to the robots. Though there exists a number of techniques that can perform multi-robot task allocation quite efficiently, they hardly consider deadline for task completion while assigning tasks to the robots. A careful allocation is of paramount importance when there is an associated penalty with each of the tasks if it is not completed within a stipulated time. In this work, we develop an algorithm, called Minimum Penalty Scheduling (MPS) that allocates tasks among a group of robots with the goal that the overall penalty of executing all the tasks can be minimized. Our algorithm provides a robust, scalable, and near-optimal real-time task schedule. By comparing with the state-of-the-art algorithm, we show that MPS attracts up to 62.5% less penalty when a significant number of tasks are bound to miss the deadline. Additionally, MPS is also suitable for real-time multi-processor scheduling since it schedules a higher number of tasks within their deadline.
ER  - 

TY  - CONF
TI  - Mixed-Granularity Human-Swarm Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1059
EP  - 1065
AU  - J. Patel
AU  - Y. Xu
AU  - C. Pinciroli
PY  - 2019
KW  - augmented reality
KW  - control engineering computing
KW  - human-robot interaction
KW  - mobile robots
KW  - multi-robot systems
KW  - mixed-granularity human-swarm interaction
KW  - augmented reality human-swarm interface
KW  - environment-oriented modality
KW  - robot swarm
KW  - robot-oriented modality
KW  - environment-oriented interaction
KW  - robot-oriented interaction
KW  - Task analysis
KW  - Robot kinematics
KW  - Augmented reality
KW  - Cognitive science
KW  - Navigation
KW  - Engines
DO  - 10.1109/ICRA.2019.8793261
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an augmented reality human-swarm interface that combines two modalities of interaction: environment-oriented and robot-oriented. The environment-oriented modality allows the user to modify the environment (either virtual or physical) to indicate a goal to attain for the robot swarm. The robot-oriented modality makes it possible to select individual robots to reassign them to other tasks to increase performance or remedy failures. Previous research has concluded that environment-oriented interaction might prove more difficult to grasp for untrained users. In this paper, we report a user study which indicates that, at least in collective transport, environment-oriented interaction is more effective than purely robot-oriented interaction, and that the two combined achieve remarkable efficacy.
ER  - 

TY  - CONF
TI  - Flexible collaborative transportation by a team of rotorcraft
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1074
EP  - 1080
AU  - H. G. d. Marina
AU  - E. Smeur
PY  - 2019
KW  - aerospace control
KW  - control system synthesis
KW  - helicopters
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - nonlinear control systems
KW  - position control
KW  - robot dynamics
KW  - suspensions (mechanical components)
KW  - flexible collaborative transportation
KW  - suspended payload
KW  - acceleration signals
KW  - maximum payload
KW  - incremental nonlinear dynamic inversion controller
KW  - distance-based formation-motion control algorithm
KW  - worst case conditions
KW  - open-source autopilot
KW  - rotorcraft team
KW  - Acceleration
KW  - Shape
KW  - Robot kinematics
KW  - Tracking
KW  - Payloads
KW  - Transportation
DO  - 10.1109/ICRA.2019.8794316
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a combined method for the collaborative transportation of a suspended payload by a team of rotorcraft. A recent distance-based formation-motion control algorithm based on assigning distance disagreements among robots generates the acceleration signals to be tracked by the vehicles. In particular, the proposed method does not need global positions nor tracking prescribed trajectories for the motion of the members of the team. The acceleration signals are followed accurately by an Incremental Nonlinear Dynamic Inversion controller designed for rotorcraft that measures and resists the tensions from the payload. Our approach allows us to analyze the involved accelerations and forces in the system so that we can calculate the worst case conditions explicitly to guarantee a nominal performance, provided that the payload starts at rest in the 2D centroid of the formation, and it is not under significant disturbances. For example, we can calculate the maximum safe deformation of the team with respect to its desired shape. We demonstrate our method with a team of four rotorcraft carrying a suspended object two times heavier than the maximum payload for an individual. Last but not least, our proposed algorithm is available for the community in the open-source autopilot Paparazzi.
ER  - 

TY  - CONF
TI  - Dynamically-consistent Generalized Hierarchical Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1141
EP  - 1147
AU  - N. Dehio
AU  - J. J. Steil
PY  - 2019
KW  - C++ language
KW  - control engineering computing
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - Matlab
KW  - redundant manipulators
KW  - robot programming
KW  - source code (software)
KW  - dynamically-consistent generalized hierarchical control
KW  - redundant robots
KW  - strict prioritization schemes
KW  - GHC
KW  - nullspace projection operator
KW  - dynamically-consistent stack-of-tasks hierarchies
KW  - DynGHC
KW  - soft prioritization schemes
KW  - Matlab
KW  - C++ source code
KW  - Task analysis
KW  - Jacobian matrices
KW  - Robots
KW  - Couplings
KW  - Matrix decomposition
KW  - Transmission line matrix methods
KW  - Matlab
DO  - 10.1109/ICRA.2019.8793553
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Tracking multiple prioritized tasks simultaneously with redundant robots have been investigated extensively over the last decades. Recent research focuses on combining advantages from both classical soft and strict prioritization schemes which is non-trivial. Among the proposed methods to tackle this issue, Generalized Hierarchical Control (GHC) seems to have a reasonable performance, however, it does not include a weighting matrix in the computation of the nullspace projection operator and hence cannot construct dynamically-consistent stack-of-tasks hierarchies as a special case. We extend GHC by adding dynamic-consistency to the control scheme and refer to it as DynGHC. The extension is also advantageous when choosing non-strict priorities because inertia coupling between tasks is reduced. DynGHC allows to smoothly rearrange priorities which is important for robots acting in dynamically changing contexts. Comparative simulations with a 4 DOF planar manipulator and a KUKA LWR validate our approach. Matlab and C++ source code is made available.
ER  - 

TY  - CONF
TI  - Robotic Joint Control System based on Analogue Spiking Neural Networks and SMA Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1148
EP  - 1154
AU  - M. Hulea
AU  - A. Burlacu
AU  - C. Caruntu
PY  - 2019
KW  - biocontrol
KW  - biomechanics
KW  - dexterous manipulators
KW  - humanoid robots
KW  - medical robotics
KW  - mobile robots
KW  - muscle
KW  - neurocontrollers
KW  - position control
KW  - shape memory effects
KW  - robotic joint control system
KW  - analogue spiking neural networks
KW  - SMA actuators
KW  - human hands
KW  - complex functions
KW  - motor cortex
KW  - anthropomorphic hands
KW  - natural muscle control
KW  - improved control system
KW  - analogue neural networks
KW  - biological control mechanisms
KW  - natural muscles
KW  - single-joint robotic arm
KW  - human elbow
KW  - artificial muscle
KW  - biological plausibility
KW  - shape memory alloy wire
KW  - contraction force
KW  - actuator wire
KW  - spiking frequency
KW  - electronic neurons
KW  - excitatory neurons
KW  - inhibitory neurons
KW  - artificial motor neurons
KW  - shape memory alloy actuator
KW  - spiking neural network
KW  - arm mobile lever
KW  - control method
KW  - robotic arm junction
KW  - Conferences
KW  - Automation
KW  - single-joint robotic arm
KW  - analogue neural networks
KW  - shape memory alloy actuators
KW  - joint rotation accuracy and precision
KW  - disturbances
DO  - 10.1109/ICRA.2019.8794215
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The control of human hands and fingers represents one of the most complex functions of the motor cortex. In order to implement anthropomorphic hands that mimic accurately the motion ability of the human hands, the basic biological mechanisms of the natural muscle control should be modelled. This paper presents the design of a significantly improved control system based on analogue neural networks that can be used to replicate the biological control mechanisms of the natural muscles. In order to demonstrate the proposed concept, experiments were performed using a single-joint robotic arm that can be flexed as the human elbow by an artificial muscle connected as the biceps. In order to bring more biological plausibility to the robotic arm, the artificial muscle is implemented using a shape memory alloy wire which actuates by contraction as the natural muscles. Moreover, the contraction force of the actuator wire is directly determined by the spiking frequency of the electronic neurons as the motor neurons determines the contraction strength of the natural muscles. The experimental results show that using excitatory neurons and several inhibitory neurons unevenly distributed on the inputs of the artificial motor neurons that drive the shape memory alloy actuator, the spiking neural network is able to control with high precision the rotation of the arm mobile lever to random target positions even if the arm is slightly loaded. These results validate the control method of the robotic arm junction showing that the analogue spiking neural networks represents a very good alternative to control the contraction of SMA actuators in a biological plausible manner.
ER  - 

TY  - CONF
TI  - Model Reference Adaptive Control of a Two-Wheeled Mobile Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1155
EP  - 1161
AU  - H. A. Jleilaty
AU  - D. Asmar
AU  - N. Daher
PY  - 2019
KW  - adaptive control
KW  - control system synthesis
KW  - mobile robots
KW  - model reference adaptive control systems
KW  - nonlinear control systems
KW  - pendulums
KW  - two-wheeled mobile robot
KW  - dynamically unstable system
KW  - environmental conditions
KW  - loading conditions
KW  - nonlinear controller
KW  - control systems
KW  - fixed parameter controllers
KW  - single-input multioutput nature
KW  - adaptive controller
KW  - SIMO systems
KW  - hidden dynamic effects
KW  - model reference adaptive control
KW  - Vehicle dynamics
KW  - Adaptation models
KW  - Mathematical model
KW  - Control systems
KW  - Adaptive control
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8793633
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The inverted pendulum is by nature a dynamically unstable system and may be subjected to severe disturbances due to its environmental or loading conditions. This paper formulates a design for a nonlinear controller to balance a two-wheeled mobile robot (TWMR) based on Model Reference Adaptive Control. The proposed solution overcomes the limitations of control systems that rely on fixed parameter controllers. Given the nonlinear single-input multi-output (SIMO) nature of the TWMR platform, the proposed adaptive controller can handle non-linearities without the need for linearization, and inherently dealing with SIMO systems. By studying the influence that hidden dynamic effects can cause, we show the preference of the proposed controller over other designs. Simulation results demonstrate the applicability and efficiency of our proposed design, and experimental results validate the effectiveness of the proposed scheme in guaranteeing asymptotic output tracking, even in the presence of unknown disturbances.
ER  - 

TY  - CONF
TI  - A Robust Tracking Controller for Robot Manipulators: Embedding Internal Model of Disturbances
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1162
EP  - 1168
AU  - W. Ha
AU  - J. Back
PY  - 2019
KW  - closed loop systems
KW  - control system synthesis
KW  - manipulators
KW  - nonlinear control systems
KW  - observers
KW  - robust control
KW  - trajectory control
KW  - uncertain systems
KW  - robust tracking controller
KW  - uncertain robot manipulators
KW  - disturbance observer based controller
KW  - internal model embedding
KW  - sinusoids frequencies
KW  - stability analysis
KW  - 2-DOF manipulator
KW  - closed-loop system
KW  - Disturbance observers
KW  - Manipulators
KW  - Uncertainty
KW  - Stability analysis
KW  - Closed loop systems
KW  - Torque
DO  - 10.1109/ICRA.2019.8793478
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a robust controller for uncertain robot manipulators subject to disturbances which are composed of sinusoids. The controller employs the disturbance observer based controller which can effectively estimate and compensate the effect of plant uncertainties and the disturbances. Assuming that the frequencies of sinusoids are known, we embed the internal model of disturbances into the proposed controller so that the design parameters of the controller can be chosen without using the magnitude of disturbance or its time derivative. A rigorous stability analysis shows that the closed-loop system under the proposed controller behaves like the nominal closed-loop system free of disturbances. Simulation results for a 2-DOF manipulator show the effectiveness of the proposed controller.
ER  - 

TY  - CONF
TI  - Receding horizon estimation and control with structured noise blocking for mobile robot slip compensation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1169
EP  - 1175
AU  - N. D. Wallace
AU  - H. Kong
AU  - A. J. Hill
AU  - S. Sukkarieh
PY  - 2019
KW  - adaptive control
KW  - compensation
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - parameter estimation
KW  - predictive control
KW  - statistical analysis
KW  - wheels
KW  - parameter estimation
KW  - overlapping-block strategy
KW  - receding horizon estimation
KW  - mobile robot slip compensation
KW  - field robots
KW  - uncertain terrain conditions
KW  - autonomous navigation
KW  - online estimation
KW  - wheel-terrain slip characteristics
KW  - off-road environments
KW  - constrained estimation
KW  - receding horizon control
KW  - adaptive optimisation-based control method
KW  - estimation horizon
KW  - structured noise blocking
KW  - control predictions
KW  - tracking trajectories
KW  - RHE
KW  - RHC
KW  - structured blocking approach
KW  - state estimation
KW  - Estimation
KW  - Adaptation models
KW  - Optimization
KW  - Wheels
KW  - Mobile robots
KW  - Parameter estimation
DO  - 10.1109/ICRA.2019.8793941
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The control of field robots in varying and uncertain terrain conditions presents a challenge for autonomous navigation. Online estimation of the wheel-terrain slip characteristics is essential for generating the accurate control predictions necessary for tracking trajectories in off-road environments. Receding horizon estimation (RHE) provides a powerful framework for constrained estimation, and when combined with receding horizon control (RHC), yields an adaptive optimisation-based control method. Presently, such methods assume slip to be constant over the estimation horizon, while our proposed structured blocking approach relaxes this assumption, resulting in improved state and parameter estimation. We demonstrate and compare the performance of this method in simulation, and propose an overlapping-block strategy to ameliorate some of the limitations encountered in applying noise-blocking in a receding horizon estimation and control (RHEC) context.
ER  - 

TY  - CONF
TI  - Decoupled Control of Position and / or Force of Tendon Driven Fingers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1176
EP  - 1182
AU  - F. Lange
AU  - G. Quere
AU  - A. Raffin
PY  - 2019
KW  - actuators
KW  - dexterous manipulators
KW  - force control
KW  - humanoid robots
KW  - motion control
KW  - position control
KW  - torque control
KW  - vectors
KW  - inner loop impedance controller
KW  - joint angle vector
KW  - joint torque vector
KW  - Cartesian position
KW  - finger endpoint
KW  - DLR David hand
KW  - decoupled control
KW  - tendon driven fingers
KW  - underactuated robotic hands
KW  - DLR AWIWI II hand
KW  - David robot
KW  - joint torques
KW  - generalized forces
KW  - motor torques
KW  - force control
KW  - position control
KW  - Tendons
KW  - Force
KW  - Torque
KW  - Robots
KW  - Couplings
KW  - Position control
KW  - Routing
DO  - 10.1109/ICRA.2019.8794297
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In contrast to underactuated robotic hands the DLR AWIWI II hand of the David robot is fully controllable because each finger with 4 joints is actuated by 6 or 8 tendons respectively. For such fingers all joint angles (generalized positions) or joint torques (generalized forces) can be controlled independently. Usually, the specifications in joint space are converted to desired tendon forces or motor torques, which are regulated by an inner loop impedance controller. However, this conversion typically exhibits couplings between the components of the joint angle vector or the joint torque vector respectively, which arise when using the well known equations. Therefore the usual force control and position control schemes are reviewed and a generic computation of the desired tendon forces is presented. This is also done for the control of the Cartesian position and force at the finger endpoint. Thus the main contribution of the paper is the inhibition of couplings in joint space or at the Cartesian endpoint. This is demonstrated in simulations of the index finger of the DLR David hand.
ER  - 

TY  - CONF
TI  - Reconfigurable Network for Efficient Inferencing in Autonomous Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1183
EP  - 1189
AU  - S. Fang
AU  - A. Choromanska
PY  - 2019
KW  - feature extraction
KW  - mobile robots
KW  - remotely operated vehicles
KW  - road vehicles
KW  - robot vision
KW  - sensors
KW  - reconfigurable network
KW  - autonomous vehicles
KW  - multiple perception sensors
KW  - steering autonomous platforms
KW  - gating network
KW  - unmanned ground vehicle
KW  - UGV
KW  - feature extractors
KW  - experts
KW  - Feature extraction
KW  - Sensors
KW  - Training
KW  - Autonomous vehicles
KW  - Task analysis
KW  - Computational modeling
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794064
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a reconfigurable network for efficient inference dedicated to autonomous platforms equipped with multiple perception sensors. The size of the network for steering autonomous platforms grows proportionally to the number of installed sensors eventually preventing the usage of multiple sensors in real-time applications due to an inefficient inference. Our approach hinges on the observation that multiple sensors provide a large stream of data, where only a fraction of the data is relevant for the performed task at any given moment in time. The architecture of the reconfigurable network that we propose contains separate feature extractors, called experts, for each sensor. The decisive block of our model is the gating network, which online decides which sensor provides the data that is most relevant for driving. It then reconfigures the network by activating only the relevant expert corresponding to that sensor and deactivating the remaining ones. As a consequence, the model never extracts features from data that are irrelevant for driving. The gating network takes the data from all inputs and thus to avoid explosion of computation time and memory space it has to be realized as a small and shallow network. We verify our model on the unmanned ground vehicle (UGV) comprising of the 1/6 scale remote control truck equipped with three cameras. We demonstrate that the reconfigurable network correctly chooses experts in real-time allowing the reduction of computations cost for the whole model without deteriorating its performance.
ER  - 

TY  - CONF
TI  - Fast Radar Motion Estimation with a Learnt Focus of Attention using Weak Supervision
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1190
EP  - 1196
AU  - R. Aldera
AU  - D. D. Martini
AU  - M. Gadd
AU  - P. Newman
PY  - 2019
KW  - distance measurement
KW  - image filtering
KW  - image fusion
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion estimation
KW  - pose estimation
KW  - radar imaging
KW  - robot vision
KW  - fast radar motion estimation
KW  - data association
KW  - radar odometry
KW  - weak supervision
KW  - focus of attention policy
KW  - learning algorithm
KW  - raw data prefiltering
KW  - image segmentation network
KW  - radar processing time reduction
KW  - field robots
KW  - consistent motion estimation
KW  - copious annotated measurements
KW  - wheel odometry
KW  - external ego-motion estimator
KW  - short-term sensor coherence
KW  - measurement stream
KW  - scanning radar
KW  - Azimuth
KW  - Robot sensing systems
KW  - Task analysis
KW  - Laser radar
KW  - Training
KW  - Labeling
KW  - radar
KW  - sensing
KW  - ego-motion estimation
KW  - field robotics
DO  - 10.1109/ICRA.2019.8794014
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper is about fast motion estimation with scanning radar. We use weak supervision to train a focus of attention policy which actively down-samples the measurement stream before data association steps are undertaken. At training, we avoid laborious manual labelling by exploiting short-term sensor coherence from multiple poses in the presence of an external ego-motion estimator (for example, wheel odometry). In this way, we generate copious annotated measurements which can be used for training a learning algorithm in a weakly-supervised fashion. We demonstrate the validity of the approach in the context of a Radar Odometry (RO) task, pre-filtering raw data with a popular image segmentation network trained as presented. We evaluate our system against 26 km of data collected in Central Oxford and show consistent motion estimation with greatly reduced radar processing times (by a factor of 2.36).
ER  - 

TY  - CONF
TI  - Learned Map Prediction for Enhanced Mobile Robot Exploration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1197
EP  - 1204
AU  - R. Shrestha
AU  - F. Tian
AU  - W. Feng
AU  - P. Tan
AU  - R. Vaughan
PY  - 2019
KW  - information theory
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - autonomous ground robot
KW  - geometric heuristics
KW  - information theory
KW  - deep learning
KW  - mobile robot exploration
KW  - generative neural network
KW  - 2D maps
KW  - reinforcement learning
KW  - robots behavior
KW  - Deep learning
KW  - Robot sensing systems
KW  - Decoding
KW  - Gain measurement
KW  - Navigation
KW  - Training
DO  - 10.1109/ICRA.2019.8793769
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We demonstrate an autonomous ground robot capable of exploring unknown indoor environments for reconstructing their 2D maps. This problem has been traditionally tackled by geometric heuristics and information theory. More recently, deep learning and reinforcement learning based approaches have been proposed to learn exploration behavior in an end-to-end manner. We present a method that combines the strengths of these different approaches. Specifically, we employ a state-of-the-art generative neural network to predict unknown regions of a partially explored map, and use the prediction to enhance the exploration in an information-theoretic manner. We evaluate our system in simulation using floor plans of real buildings. We also present comparisons with traditional methods which demonstrate the advantage of our method in terms of exploration efficiency. We retain an advantage over end-to-end learned exploration methods in that the robot's behavior is easily explicable in terms of the predicted map.
ER  - 

TY  - CONF
TI  - Propagation Networks for Model-Based Control Under Partial Observation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1205
EP  - 1211
AU  - Y. Li
AU  - J. Wu
AU  - J. Zhu
AU  - J. B. Tenenbaum
AU  - A. Torralba
AU  - R. Tedrake
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - off-the-shelf physics engines
KW  - interaction networks
KW  - pairwise interactions
KW  - propagation networks
KW  - differentiable dynamics model
KW  - learnable dynamics model
KW  - partially observable scenarios
KW  - model-based control
KW  - deep reinforcement learning algorithms
KW  - robot planning
KW  - PropNet
KW  - Engines
KW  - Task analysis
KW  - Force
KW  - Robots
KW  - Computational modeling
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8793509
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There has been an increasing interest in learning dynamics simulators for model-based control. Compared with off-the-shelf physics engines, a learnable simulator can quickly adapt to unseen objects, scenes, and tasks. However, existing models like interaction networks only work for fully observable systems; they also only consider pairwise interactions within a single time step, both restricting their use in practical systems. We introduce Propagation Networks (PropNet), a differentiable, learnable dynamics model that handles partially observable scenarios and enables instantaneous propagation of signals beyond pairwise interactions. With these innovations, our propagation networks not only outperform current learnable physics engines in forward simulation, but also achieves superior performance on various control tasks. Compared with existing deep reinforcement learning algorithms, model-based control with propagation networks is more accurate, efficient, and generalizable to novel, partially observable scenes and tasks.
ER  - 

TY  - CONF
TI  - Interactive Trajectory Prediction for Autonomous Driving via Recurrent Meta Induction Neural Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1212
EP  - 1217
AU  - C. Dong
AU  - Y. Chen
AU  - J. M. Dolan
PY  - 2019
KW  - automobiles
KW  - estimation theory
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - recurrent neural nets
KW  - road safety
KW  - road traffic control
KW  - stochastic processes
KW  - traffic engineering computing
KW  - lane change trajectory
KW  - meta-learning framework
KW  - autonomous driving data collection
KW  - interactive trajectory prediction
KW  - interactive driving
KW  - autonomous cars
KW  - stochastic processes
KW  - driving behavior estimation
KW  - recurrent neural cell
KW  - recurrent meta induction neural network
KW  - human-driven cars behaviors
KW  - conditional neural process
KW  - Trajectory
KW  - Automobiles
KW  - Autonomous vehicles
KW  - Estimation
KW  - Generators
KW  - Task analysis
KW  - Stochastic processes
DO  - 10.1109/ICRA.2019.8794392
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Interactive driving is challenging but essential for autonomous cars in dense traffic or urban areas. Proper interaction requires understanding and prediction of future trajectories of all neighboring cars around a target vehicle. Current solutions typically assume a certain distribution or stochastic process to approximate human-driven cars' behaviors. To relax this assumption, a Recurrent Meta Induction Network (RMIN) framework is developed. The original Conditional Neural Process (CNP) on which this is based does not consider the sequence of the conditions, due to the permutation invariance requirements for stochastic processes. However, the sequential information is important for the driving behavior estimation. Therefore, in the proposed method, a recurrent neural cell replaces the original demonstration sub-net. The behavior estimation is conditioned on the historical observations for all related cars, including the target car and its surrounding cars. The method is applied to predict the lane change trajectory of a target car in dense traffic areas. The proposed method achieves better results than previous methods and thanks to the meta-learning framework, it can use a smaller dataset, putting fewer demands on autonomous driving data collection.
ER  - 

TY  - CONF
TI  - Studies on Positioning Manipulators Actuated by Solid Media Transmissions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1226
EP  - 1232
AU  - H. Zhao
AU  - X. Liu
AU  - R. Korpu
AU  - M. J. Heffernan
AU  - A. T. Becker
AU  - N. V. Tsekos
PY  - 2019
KW  - actuators
KW  - closed loop systems
KW  - manipulators
KW  - PI control
KW  - position control
KW  - telerobotics
KW  - transmission lines
KW  - PI controller
KW  - master-slave control
KW  - positioning manipulators
KW  - PTFE tubing
KW  - closed-loop position control
KW  - push-only bidirectional transmission
KW  - SMT
KW  - solid-media transmission
KW  - fluidic transmission mechanisms
KW  - Manipulators
KW  - Kinematics
KW  - Robot kinematics
KW  - Needles
KW  - Strips
KW  - Fasteners
DO  - 10.1109/ICRA.2019.8794356
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fluidic transmission mechanisms use fluids to transmit force through conduits. We previously presented a transmission mechanism called solid-media transmission (SMT), which uses conduits filled with spheres and spacers for push-only bidirectional transmission. In this paper, we present new designs of SMT-actuated one-degree-of-freedom (DoF) and two-degree-of-freedom positioning manipulators, and report experiment studies to assess their performance. In these studies, closed-loop position control was performed with a PI controller and/or master-slave control. With braided PTFE tubing, SMT exhibited sub-millimeter accuracy, with a tolerance of ±0.05 mm for the tested transmission lines with lengths up to 4m.
ER  - 

TY  - CONF
TI  - Exploiting Bistability for High Force Density Reflexive Gripping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1241
EP  - 1247
AU  - R. Jitosho
AU  - K. Choi
AU  - A. Foris
AU  - A. Mazumdar
PY  - 2019
KW  - control system synthesis
KW  - force control
KW  - grippers
KW  - mobile robots
KW  - pneumatic control equipment
KW  - vehicles
KW  - robotic grasping
KW  - mobile vehicles
KW  - conventional manipulation
KW  - dynamic mobile robots
KW  - robotic gripper
KW  - mobile platforms
KW  - reflexive activation
KW  - reflexive gripper
KW  - high force density reflexive gripping
KW  - pneumatic design
KW  - Grippers
KW  - Robot sensing systems
KW  - Steel
KW  - Strain
KW  - Grasping
DO  - 10.1109/ICRA.2019.8794393
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic grasping can enable mobile vehicles to physically interact with the environment for delivery, repositioning, or landing. However, the requirements for grippers on mobile vehicles differ substantially from those used for conventional manipulation. Specifically, grippers for dynamic mobile robots should be capable of rapid activation, high force density, low power consumption, and minimal computation. In this work, we present a biologically-inspired robotic gripper designed specifically for mobile platforms. This design exploits a bistable shell to achieve “reflexive” activation based on contact with the environment. The mechanism can close its grasp within 0. 12s without any sensing or control. Electrical input power is not required for grasping or holding load. The reflexive gripper utilizes a novel pneumatic design to open its grasp with low power, and the gripper can carry slung loads up to 28 times its weight. This new mechanism, including the kinematics, static behavior, control structure, and fabrication, is described in detail. A proof of concept prototype is designed, built, and tested. Experimental results are used to characterize performance and demonstrate the potential of these methods.
ER  - 

TY  - CONF
TI  - Compliant Bistable Gripper for Aerial Perching and Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1248
EP  - 1253
AU  - H. Zhang
AU  - J. Sun
AU  - J. Zhao
PY  - 2019
KW  - aerospace control
KW  - aerospace robotics
KW  - autonomous aerial vehicles
KW  - grippers
KW  - helicopters
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - compliant bistable gripper
KW  - aerial perching
KW  - aerial robots
KW  - onboard energy supply
KW  - flying robots
KW  - perching capability
KW  - power lines
KW  - monitoring-related tasks
KW  - energy-efficient perching mechanism
KW  - palm-size quadcopter
KW  - aerial grasping
KW  - robot weight
KW  - quadcopter perch
KW  - grasp objects
KW  - force
KW  - Grippers
KW  - Electron tubes
KW  - Force
KW  - Unmanned aerial vehicles
KW  - Springs
KW  - Mathematical model
KW  - Grasping
DO  - 10.1109/ICRA.2019.8793936
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Small aerial robots usually face a common challenge: they can only fly for a short time due to their limited onboard energy supply. To tackle this issue, one promising solution is to endow flying robots with perching capability so that they can perch or land on walls, trees, or power lines to rest or recharge. Such perching capability is especially useful for monitoring-related tasks since the robot can maintain a desired height for monitoring without flying. One of the major challenges for perching is to design a light-weight and energy-efficient perching mechanism. In this paper, we present a 3D-printed compliant bistable gripper which is easy to close, stable to hold, and easy to adjust for a palm-size quadcopter to perch on cylindrical objects. If installed on the bottom of aerial robots, it can also be used for aerial grasping. The gripper can be directly activated by the impact force during contact to switch from open state to closed state. It can also hold the quadcopter safely since the required force to open the gripper is larger than the robot weight. We analyze the required forces for closing and opening to provide design guidelines for the mechanism. Experimental results show that the designed gripper can successful make the quadcopter perch on cylinders as well as grasp objects.
ER  - 

TY  - CONF
TI  - MH-iSAM2: Multi-hypothesis iSAM using Bayes Tree and Hypo-tree
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1274
EP  - 1280
AU  - M. Hsiao
AU  - M. Kaess
PY  - 2019
KW  - Bayes methods
KW  - data structures
KW  - mobile robots
KW  - optimisation
KW  - SLAM (robots)
KW  - original Bayes tree
KW  - hypothesis pruning strategy
KW  - multihypothesis iSAM
KW  - nonlinear incremental optimization algorithm
KW  - MH-iSAM2
KW  - simultaneous localization and mapping problems
KW  - SLAM problems
KW  - hypo-tree
KW  - multihypothesis inference
KW  - data structures
KW  - Simultaneous localization and mapping
KW  - Zirconium
KW  - Maximum likelihood estimation
KW  - Optimization
KW  - Inference algorithms
KW  - Robustness
DO  - 10.1109/ICRA.2019.8793854
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A novel nonlinear incremental optimization algorithm MH-iSAM2 is developed to handle ambiguity in simultaneous localization and mapping (SLAM) problems in a multi-hypothesis fashion. It can output multiple possible solutions for each variable according to the ambiguous inputs, which is expected to greatly enhance the robustness of autonomous systems as a whole. The algorithm consists of two data structures: an extension of the original Bayes tree that allows efficient multi-hypothesis inference, and a Hypo-tree that is designed to explicitly track and associate the hypotheses of each variable as well as all the inference processes for optimization. With our proposed hypothesis pruning strategy, MH-iSAM2 enables fast optimization and avoids the exponential growth of hypotheses. We evaluate MH-iSAM2 using both simulated datasets and real-world experiments, demonstrating its improvements on the robustness and accuracy of SLAM systems.
ER  - 

TY  - CONF
TI  - Improving Keypoint Matching Using a Landmark-Based Image Representation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1281
EP  - 1287
AU  - X. Huang
AU  - Z. Dai
AU  - W. Chen
AU  - L. He
AU  - H. Zhang
PY  - 2019
KW  - convolutional neural nets
KW  - image matching
KW  - image representation
KW  - learning (artificial intelligence)
KW  - landmark-based image representation
KW  - visual loop closure verification
KW  - multiview geometry
KW  - MVG
KW  - deep learning
KW  - convolutional neural network features
KW  - matched landmark pairs
KW  - image representation
KW  - verification method
KW  - keypoint matching method
KW  - ConvNet features
KW  - Lighting
KW  - Proposals
KW  - Visualization
KW  - Standards
KW  - Feature extraction
KW  - Simultaneous localization and mapping
KW  - Image representation
DO  - 10.1109/ICRA.2019.8794420
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Motivated by the need to improve the performance of visual loop closure verification via multi-view geometry (MVG) under significant illumination and viewpoint changes, we propose a keypoint matching method that uses landmarks as an intermediate image representation in order to leverage the power of deep learning. In environments with various changes, the traditional verification method via MVG may encounter difficulty because of their inability to generate a sufficient number of correctly matched keypoints. Our method exploits the excellent invariance properties of convolutional neural network (ConvNet) features, which have shown outstanding performance for matching landmarks between images. By generating and matching landmarks first in the images and then matching the keypoints within the matched landmark pairs, we can significantly improve the quality of matched keypoints in terms of precision and recall measures. The proposed method is validated on challenging datasets that involve significant illumination and viewpoint changes, to establish its superior performance to the standard keypoint matching method.
ER  - 

TY  - CONF
TI  - Fast and Robust Initialization for Visual-Inertial SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1288
EP  - 1294
AU  - C. Campos
AU  - J. M. M. Montiel
AU  - J. D. Tardós
PY  - 2019
KW  - accelerometers
KW  - gyroscopes
KW  - inertial navigation
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - visual-inertial SLAM
KW  - VI-SLAM
KW  - gyroscope
KW  - initialization method
KW  - visual-inertial bundle adjustment
KW  - Cameras
KW  - Gravity
KW  - Simultaneous localization and mapping
KW  - Observability
KW  - Feature extraction
KW  - Jacobian matrices
KW  - Accelerometers
DO  - 10.1109/ICRA.2019.8793718
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual-inertial SLAM (VI-SLAM) requires a good initial estimation of the initial velocity, orientation with respect to gravity and gyroscope and accelerometer biases. In this paper we build on the initialization method proposed by Martinelli [1] and extended by Kaiser et al. [2], modifying it to be more general and efficient. We improve accuracy with several rounds of visual-inertial bundle adjustment, and robustify the method with novel observability and consensus tests, that discard erroneous solutions. Our results on the EuRoC dataset show that, while the original method produces scale errors up to 156%, our method is able to consistently initialize in less than two seconds with scale errors around 5%, which can be further reduced to less than 1% performing visual-inertial bundle adjustment after ten seconds.
ER  - 

TY  - CONF
TI  - Accurate Direct Visual-Laser Odometry with Explicit Occlusion Handling and Plane Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1295
EP  - 1301
AU  - K. Huang
AU  - J. Xiao
AU  - C. Stachniss
PY  - 2019
KW  - distance measurement
KW  - motion estimation
KW  - camera information
KW  - mobile platform
KW  - direct laser-visual odometry approach building
KW  - photometric image alignment
KW  - information usage
KW  - laser scan
KW  - frame-to-frame motion estimate
KW  - planar point
KW  - individual point clouds
KW  - corresponding pixel patches
KW  - camera image
KW  - extracted planar image patches
KW  - nonplanar pixels
KW  - pixel alignments
KW  - high estimation accuracy
KW  - Clearpath Husky platform
KW  - competitive estimation accuracy
KW  - colored point clouds
KW  - accurate direct visual-laser odometry
KW  - explicit occlusion handling
KW  - plane detection
KW  - Three-dimensional displays
KW  - Cameras
KW  - Measurement by laser beam
KW  - Lasers
KW  - Estimation
KW  - Visual odometry
KW  - Motion estimation
DO  - 10.1109/ICRA.2019.8793629
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we address the problem of combining 3D laser scanner and camera information to estimate the motion of a mobile platform. We propose a direct laser-visual odometry approach building upon photometric image alignment. Our approach is designed to maximize the information usage of both, the image and the laser scan, to compute an accurate frame-to-frame motion estimate. To deal with the sparsity of the range measurements, our approach identifies planar point sets within individual point clouds and subsequently extract their corresponding pixel patches from the camera image. The extracted planar image patches are used together with the non-planar pixels to estimate the frame-to-frame motion using a homography formulation capable of incorporating both types of pixel alignments. To achieve high estimation accuracy, we explicitly predict possible occlusions caused by observations taken from different locations. We evaluate our proposed approach using the KITTI dataset as well as data recorded with a Clearpath Husky platform. The experiments suggest that our approach can achieve competitive estimation accuracy and produce consistently registered, colored point clouds.
ER  - 

TY  - CONF
TI  - Efficient Constellation-Based Map-Merging for Semantic SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1302
EP  - 1308
AU  - K. M. Frey
AU  - T. J. Steiner
AU  - J. P. How
PY  - 2019
KW  - covariance matrices
KW  - SLAM (robots)
KW  - tree searching
KW  - local information
KW  - SLAM graph
KW  - expensive recovery
KW  - system covariance matrix
KW  - joint compatibility
KW  - search space
KW  - clique-based pairwise compatibility
KW  - robust object-based loop-closure
KW  - SLAM problems
KW  - semantic SLAM
KW  - data association
KW  - high-confidence loop-closure mechanism
KW  - object-level SLAM
KW  - landmark uncertainty
KW  - constellation-based map-merging
KW  - branch-and-bound max-cardinality search
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Covariance matrices
KW  - Uncertainty
KW  - Detectors
KW  - Search problems
KW  - Current measurement
DO  - 10.1109/ICRA.2019.8794452
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Data association in SLAM is fundamentally challenging, and handling ambiguity well is crucial to achieve robust operation in real-world environments. When ambiguous measurements arise, conservatism often mandates that the measurement is discarded or a new landmark is initialized rather than risking an incorrect association. To address the inevitable “duplicate” landmarks that arise, we present an efficient map-merging framework to detect duplicate constellations of landmarks, providing a high-confidence loop-closure mechanism well-suited for object-level SLAM. This approach uses an incrementally-computable approximation of landmark uncertainty that only depends on local information in the SLAM graph, avoiding expensive recovery of the full system covariance matrix. This enables a search based on geometric consistency (GC) (rather than full joint compatibility (JC)) that inexpensively reduces the search space to a handful of “best” hypotheses. Furthermore, we reformulate the commonly-used interpretation tree to allow for more efficient integration of clique-based pairwise compatibility, accelerating the branch-and-bound max-cardinality search. Our method is demonstrated to match the performance of full JC methods at significantly-reduced computational cost, facilitating robust object-based loop-closure over large SLAM problems.
ER  - 

TY  - CONF
TI  - Learning Robust Manipulation Strategies with Multimodal State Transition Models and Recovery Heuristics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1309
EP  - 1315
AU  - A. S. Wang
AU  - O. Kroemer
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - mobile robots
KW  - optimisation
KW  - robot programming
KW  - contact dynamics
KW  - reinforcement learning
KW  - recovery skills
KW  - multiple contact state changes
KW  - multimodal state transition model
KW  - recovery heuristics
KW  - contact-based manipulations
KW  - robust manipulation strategies learning
KW  - skill selections
KW  - Task analysis
KW  - End effectors
KW  - Robustness
KW  - Data models
KW  - Planning
KW  - Clustering algorithms
DO  - 10.1109/ICRA.2019.8793623
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots are prone to making mistakes when performing manipulation tasks in unstructured environments. Robust policies are thus needed to not only avoid mistakes but also to recover from them. We propose a framework for increasing the robustness of contact-based manipulations by modeling the task structure and optimizing a policy for selecting skills and recovery skills. A multimodal state transition model is acquired based on the contact dynamics of the task and the observed transitions. A policy is then learned from the model using reinforcement learning. The policy is incrementally improved by expanding the action space by generating recovery skills with a heuristic. Evaluations on three simulated manipulation tasks demonstrate the effectiveness of the framework. The robot was able to complete the tasks despite multiple contact state changes and errors encountered, increasing the success rate averaged across the tasks from 70.0% to 95.3%.
ER  - 

TY  - CONF
TI  - Adaptive Critic Based Optimal Kinematic Control for a Robot Manipulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1316
EP  - 1322
AU  - A. Menon
AU  - R. Prakash
AU  - L. Behera
PY  - 2019
KW  - adaptive control
KW  - closed loop systems
KW  - control system synthesis
KW  - end effectors
KW  - Lyapunov methods
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - motion control
KW  - optimal control
KW  - position control
KW  - stability
KW  - time-varying systems
KW  - tracking
KW  - robot manipulator
KW  - robot end effector position
KW  - task space trajectory
KW  - desired velocity profile
KW  - single network adaptive critic
KW  - forward kinematics
KW  - input affine system
KW  - critic weight update law
KW  - desired optimal cost
KW  - closed loop kinematic control
KW  - optimal regulation problem
KW  - SNAC based kinematic control
KW  - optimal tracking problem
KW  - tracking error
KW  - reference trajectory
KW  - optimal control policy
KW  - kinematic control scheme
KW  - Universal Robot 10 manipulator
KW  - adaptive critic based optimal kinematic control
KW  - Kinematics
KW  - Manipulators
KW  - Trajectory
KW  - Optimal control
KW  - Cost function
KW  - Stability analysis
DO  - 10.1109/ICRA.2019.8793684
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper is concerned with the optimal kinematic control of a robot manipulator where the robot end effector position follows a task space trajectory. The joints are actuated with the desired velocity profile to achieve this task. This problem has been solved using a single network adaptive critic (SNAC) by expressing the forward kinematics as input affine system. Usually in SNAC, the critic weights are updated using back propagation algorithm while little attention is given to convergence to the optimal cost. In this paper, we propose a critic weight update law that ensures convergence to the desired optimal cost while guaranteeing the stability of the closed loop kinematic control. In kinematic control, the robot is required to reach a specific target position. This has been solved as an optimal regulation problem in the context of SNAC based kinematic control. When the robot is required to follow a time varying task space trajectory, then the kinematic control has been framed as an optimal tracking problem. For tracking, an augmented system consisting of tracking error and reference trajectory is constructed and the optimal control policy is derived using SNAC framework. The stability and performance of the system under the proposed novel weight tuning law is guaranteed using Lyapunov approach. The proposed kinematic control scheme has been validated in simulations and experimentally executed using a real six degrees of freedom (DOF) Universal Robot (UR) 10 manipulator.
ER  - 

TY  - CONF
TI  - Manipulability Optimization Control of a Serial Redundant Robot for Robot-assisted Minimally Invasive Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1323
EP  - 1328
AU  - H. Su
AU  - S. Li
AU  - J. Manivannan
AU  - L. Bascetta
AU  - G. Ferrigno
AU  - E. D. Momi
PY  - 2019
KW  - compliance control
KW  - end effectors
KW  - manipulator dynamics
KW  - medical robotics
KW  - motion control
KW  - optimisation
KW  - redundant manipulators
KW  - surgery
KW  - manipulability optimization control
KW  - serial redundant robot
KW  - robot-assisted minimally invasive surgery
KW  - 7-DoF robot manipulator
KW  - RCM constraint
KW  - hierarchical operational space formulation
KW  - Cartesian compliance control
KW  - null-space controller
KW  - control components integration
KW  - remote center of motion
KW  - end-effector accuracy
KW  - Robots
KW  - Task analysis
KW  - Optimization
KW  - Surgery
KW  - Aerospace electronics
KW  - Redundancy
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793676
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a manipulability optimization control of a 7-DoF robot manipulator for Robot-Assisted Minimally Invasive Surgery (RAMIS), which at the same time guarantees a Remote Center of Motion (RCM). The first degree of redundancy of the manipulator is used to achieve an RCM constraint, the second one is adopted for manipulability optimization. A hierarchical operational space formulation is introduced to integrate all the control components, including a Cartesian compliance control involving the main surgical task, a first null-space controller for the RCM constraint, and a second null-space controller for manipulability optimization. Experiments with virtual surgical tasks, in an augmented reality environment, were performed to validate the proposed control strategy using the KUKA LWR 4 +. The results demonstrate that end-effector accuracy and RCM constraint can be guaranteed, along with improving the manipulability of the surgical tip.
ER  - 

TY  - CONF
TI  - Accounting for Part Pose Estimation Uncertainties during Trajectory Generation for Part Pick-Up Using Mobile Manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1329
EP  - 1336
AU  - S. Thakar
AU  - P. Rajendran
AU  - V. Annem
AU  - A. Kabir
AU  - S. Gupta
PY  - 2019
KW  - grippers
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - pose estimation
KW  - position control
KW  - probability
KW  - mobile base trajectory
KW  - active learning based approach
KW  - optimization-based framework
KW  - time-optimal trajectories
KW  - part pose estimation uncertainties
KW  - trajectory generation
KW  - part pick-up
KW  - mobile manipulators
KW  - operation time
KW  - gripper
KW  - Grippers
KW  - Grasping
KW  - Trajectory
KW  - Uncertainty
KW  - Physics
KW  - End effectors
DO  - 10.1109/ICRA.2019.8793501
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To minimize the operation time, mobile manipulators need to pick-up parts while the mobile base and the gripper are moving. The gripper speed needs to be selected to ensure that the pick-up operation does not fail due to uncertainties in part pose estimation. This, in turn, affects the mobile base trajectory. This paper presents an active learning based approach to construct a meta-model to estimate the probability of successful part pick-up for a given level of uncertainty in the part pose estimate. Using this model, we present an optimization-based framework to generate time-optimal trajectories that satisfy the given level of success probability threshold for picking-up the part.
ER  - 

TY  - CONF
TI  - Adapting Everyday Manipulation Skills to Varied Scenarios
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1345
EP  - 1351
AU  - P. Gajewski
AU  - P. Ferreira
AU  - G. Bartels
AU  - C. Wang
AU  - F. Guerin
AU  - B. Indurkhya
AU  - M. Beetz
AU  - B. Śniezyński
PY  - 2019
KW  - control engineering computing
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - robot vision
KW  - service robots
KW  - point clouds
KW  - target object
KW  - tool-using manipulation skills
KW  - motion trajectories
KW  - scraping material
KW  - robot perception module
KW  - PR2 robot
KW  - Tools
KW  - Task analysis
KW  - Robots
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Containers
KW  - Dairy products
DO  - 10.1109/ICRA.2019.8793590
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We address the problem of executing tool-using manipulation skills in scenarios where the objects to be used may vary. We assume that point clouds of the tool and target object can be obtained, but no interpretation or further knowledge about these objects is provided. The system must interpret the point clouds and decide how to use the tool to complete a manipulation task with a target object; this means it must adjust motion trajectories appropriately to complete the task. We tackle three everyday manipulations: scraping material from a tool into a container, cutting, and scooping from a container. Our solution encodes these manipulation skills in a generic way, with parameters that can be filled in at run-time via queries to a robot perception module; the perception module abstracts the functional parts of the tool and extracts key parameters that are needed for the task. The approach is evaluated in simulation and with selected examples on a PR2 robot.
ER  - 

TY  - CONF
TI  - Feedback Control and 3D Motion of Heterogeneous Janus Particles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1352
EP  - 1357
AU  - L. W. Rogowski
AU  - X. Zhang
AU  - L. Huang
AU  - A. Bhattacharjee
AU  - J. S. Lee
AU  - A. T. Becker
AU  - M. J. Kim
PY  - 2019
KW  - chemical engineering
KW  - closed loop systems
KW  - feedback
KW  - open loop systems
KW  - position control
KW  - propulsion
KW  - vectors
KW  - 3D closed loop control system
KW  - 3D motion
KW  - self-actuated particles
KW  - open loop 3D control
KW  - 2D feedback control
KW  - triaxial approximate Helmholtz coil system
KW  - propulsion vectors
KW  - heterogeneous chemically catalyzing Janus particles
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA.2019.8793678
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents 2D feedback control and open loop 3D trajectories of heterogeneous chemically catalyzing Janus particles. Self-actuated particles have enormous implications for both in vivo and in vitro environments, which make them a diverse resource for a variety of medical and assembly applications. Janus particles, consisting of cobalt and platinum hemispheres, can self-propel in hydrogen peroxide solutions due to platinum's catalyzation properties. These particles are directionally controlled using static magnetic fields produced from a triaxial approximate Helmholtz coil system. Since the magnetization direction of Janus particles is often heterogeneous, and thereby not consistent with the propulsion direction, this creates a unique opportunity to explore the motion effects of these particles under 2D feedback control and open loop 3D control. Using a modified closed loop controller, Janus particles with magnetization both closely aligned and greatly misaligned to the propulsion vectors, were instructed to perform complex trajectories. These trajectories were then compared between trials to measure both consistency and accuracy. The effects of increasing offset between the magnetization and propulsion vectors were also analyzed. The effects this heterogeneity had on 3D motion is also briefly discussed. It is our hope going forward to develop a 3D closed loop control system that can retroactively account for variations in the magnetization vector.
ER  - 

TY  - CONF
TI  - Data-Driven Gait Segmentation for Walking Assistance in a Lower-Limb Assistive Device
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1390
EP  - 1396
AU  - A. Kalinowska
AU  - T. A. Berrueta
AU  - A. Zoss
AU  - T. Murphey
PY  - 2019
KW  - biomechanics
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - nonlinear control systems
KW  - patient rehabilitation
KW  - predictive control
KW  - robot dynamics
KW  - robot kinematics
KW  - data-driven gait segmentation
KW  - walking assistance
KW  - lower-limb assistive device
KW  - hybrid systems
KW  - bipedal walker
KW  - nonlinear dynamics
KW  - hybrid mode
KW  - reliable state sensing
KW  - data-driven analysis
KW  - data-driven dynamics identification
KW  - model predictive control
KW  - hybrid SLIP model
KW  - gait partitioning
KW  - human walking data
KW  - kinematics data
KW  - online assistance
KW  - predefined gait structure
KW  - healthy gaits
KW  - pathological gaits
KW  - impairment-specific rehabilitation strategies
KW  - Heuristic algorithms
KW  - Mathematical model
KW  - Data models
KW  - Predictive models
KW  - Prediction algorithms
KW  - System dynamics
KW  - Switches
DO  - 10.1109/ICRA.2019.8794416
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Hybrid systems, such as bipedal walkers, are challenging to control because of discontinuities in their nonlinear dynamics. Little can be predicted about the systems' evolution without modeling the guard conditions that govern transitions between hybrid modes, so even systems with reliable state sensing can be difficult to control. We propose an algorithm that allows for determining the hybrid mode of a system in real-time using data-driven analysis. The algorithm is used with data-driven dynamics identification to enable model predictive control based entirely on data. Two examples-a simulated hopper and experimental data from a bipedal walker-are used. In the context of the first example, we are able to closely approximate the dynamics of a hybrid SLIP model and then successfully use them for control in simulation. In the second example, we demonstrate gait partitioning of human walking data, accurately differentiating between stance and swing, as well as selected subphases of swing. We identify contact events, such as heel strike and toe-off, without a contact sensor using only kinematics data from the knee and hip joints, which could be particularly useful in providing online assistance during walking. Our algorithm does not assume a predefined gait structure or gait phase transitions, lending itself to segmentation of both healthy and pathological gaits. With this flexibility, impairment-specific rehabilitation strategies or assistance could be designed.
ER  - 

TY  - CONF
TI  - Closed-loop MPC with Dense Visual SLAM - Stability through Reactive Stepping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1397
EP  - 1403
AU  - A. Tanguy
AU  - D. De Simone
AU  - A. I. Comport
AU  - G. Oriolo
AU  - A. Kheddar
PY  - 2019
KW  - approximation theory
KW  - closed loop systems
KW  - humanoid robots
KW  - legged locomotion
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - path planning
KW  - pendulums
KW  - position control
KW  - predictive control
KW  - SLAM (robots)
KW  - stability
KW  - fundamental capacity
KW  - external inputs
KW  - reference velocity
KW  - footstep plans
KW  - reference motion
KW  - external disturbances
KW  - closed-loop MPC scheme
KW  - proprioceptive sensors
KW  - imperfect open-loop control execution
KW  - HRP-4 humanoid robot
KW  - reactive stepping
KW  - walking gaits
KW  - humanoid locomotion
KW  - model predictive control
KW  - pendulum
KW  - dense visual SLAM stability
KW  - Simultaneous localization and mapping
KW  - Foot
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Lips
DO  - 10.1109/ICRA.2019.8794006
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Walking gaits generated using Model Predictive Control (MPC) is widely used due to its capability to handle several constraints that characterize humanoid locomotion. The use of simplified models such as the Linear Inverted Pendulum allows to perform computations in real-time, giving the robot the fundamental capacity to replan its motion to follow external inputs (e.g. reference velocity, footstep plans). However, usually the MPC does not take into account the current state of the robot when computing the reference motion, losing the ability to react to external disturbances. In this paper a closed-loop MPC scheme is proposed to estimate the robot's real state through Simultaneous Localization and Mapping (SLAM) and proprioceptive sensors (force/torque). With the proposed control scheme it is shown that the robot is able to react to external disturbances (push), by stepping to recover from the loss of balance. Moreover the localization allows the robot to navigate to target positions in the environment without being affected by the drift generated by imperfect open-loop control execution. We validate the proposed scheme through two different experiments with a HRP-4 humanoid robot.
ER  - 

TY  - CONF
TI  - Safe 3D Bipedal Walking through Linear MPC with 3D Capturability
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1404
EP  - 1409
AU  - A. Pajon
AU  - P. Wiebe
PY  - 2019
KW  - collision avoidance
KW  - gait analysis
KW  - legged locomotion
KW  - manipulator dynamics
KW  - nonlinear control systems
KW  - predictive control
KW  - trajectory control
KW  - complete kinematic feasibility guarantees
KW  - dynamic feasibility guarantees
KW  - piecewise horizontal ground
KW  - vertical motion
KW  - linear constraints
KW  - nonlinear constraint
KW  - linear MPC scheme
KW  - online computation
KW  - reactive walking motions
KW  - physical collaboration
KW  - collision avoidance
KW  - fully adaptable height
KW  - adaptable step placement
KW  - safe 3D bipedal walking
KW  - 3D capturability constraint
KW  - Legged locomotion
KW  - Trajectory
KW  - Collision avoidance
KW  - Kinematics
KW  - Three-dimensional displays
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794117
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a linear MPC scheme for online computation of reactive walking motions, necessary for fast interactions such as physical collaboration with humans or collision avoidance in crowds. Unlike other existing schemes, it provides fully adaptable height, adaptable step placement and complete kinematic and dynamic feasibility guarantees, making it possible to walk perfectly safely on a piecewise horizontal ground such as stairs. A linear formulation is proposed, based on efficiently bounding the nonlinear term introduced by vertical motion, considering two linear constraints instead of one nonlinear constraint. Balance and Passive Safety guarantees are secured by enforcing a 3D capturability constraint. Based on a comparison between CoM and CoP trajectories involving exponentials instead of polynomials, this capturability constraint involves a CoM motion stopping along a segment of line, always maintaining complete kinematic and dynamic feasibility.
ER  - 

TY  - CONF
TI  - Feedback motion planning of legged robots by composing orbital Lyapunov functions using rapidly-exploring random trees
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1410
EP  - 1416
AU  - A. Zamani
AU  - J. D. Galloway
AU  - P. A. Bhounsule
PY  - 2019
KW  - feedback
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - Lyapunov methods
KW  - neurocontrollers
KW  - path planning
KW  - random processes
KW  - sampling methods
KW  - trajectory control
KW  - trees (mathematics)
KW  - feedback motion planning
KW  - legged robots
KW  - orbital Lyapunov functions
KW  - sampling-based framework
KW  - Poincaré section
KW  - multiple trajectory optimization problems
KW  - rapidly-exploring random tree algorithm
KW  - regions of attraction
KW  - deep learning neural networks
KW  - Limit-cycles
KW  - Planning
KW  - Legged locomotion
KW  - Lyapunov methods
KW  - Force
KW  - Trajectory optimization
DO  - 10.1109/ICRA.2019.8793578
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a sampling-based framework for feedback motion planning of legged robots. Our framework is based on switching between limit cycles at a fixed instance of motion, the Poincaré section (e.g., apex or touchdown), by finding overlaps between the regions of attraction (ROA) of two limit cycles. First, we assume a candidate orbital Lyapunov function (OLF) and define a ROA at the Poincaré section. Next, we solve multiple trajectory optimization problems, one for each sampled initial condition on the ROA to minimize an energy metric and subject to the exponential convergence of the OLF between two steps. The result is a table of control actions and the corresponding initial conditions at the Poincaré section. Then we develop a control policy for each control action as a function of the initial condition using deep learning neural networks. The control policy is validated by testing on initial conditions sampled on ROA of randomly chosen limit cycles. Finally, the rapidly-exploring random tree algorithm is adopted to plan transitions between the limit cycles using the ROAs. The approach is demonstrated on a hopper model to achieve velocity and height transitions between steps.
ER  - 

TY  - CONF
TI  - Online Walking Pattern Generation for Humanoid Robot with Compliant Motion Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1417
EP  - 1422
AU  - M. Kim
AU  - D. Lim
AU  - J. Park
PY  - 2019
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - pendulums
KW  - position control
KW  - predictive control
KW  - robot dynamics
KW  - stability
KW  - DYROS-JET
KW  - CoM trajectory
KW  - center-of-mass
KW  - zero-moment point
KW  - linear inverted pendulum model
KW  - second-order system
KW  - preview control
KW  - dynamics model
KW  - motion controller
KW  - real-time walking pattern generation
KW  - humanoid robot walking
KW  - position tracking performance
KW  - walking stability
KW  - compliant motion control
KW  - online walking pattern generation
KW  - Legged locomotion
KW  - Trajectory
KW  - Humanoid robots
KW  - Foot
KW  - Stability analysis
DO  - 10.1109/ICRA.2019.8794174
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The compliant motion of humanoid robots is one of their most important characteristics for interacting with humans and various environments in the real world. During walking, compliant motion ensures stable contact between the foot and ground, but walking stability is degraded by position tracking performance and unknown disturbances. To address the issue of instability of humanoid robot walking with compliant motion control, this paper proposes a model for real-time walking pattern generation considering the motion control performance of a robot. The dynamic model of a robot with a motion controller is described as a second-order system approximating position tracking performance with a linear inverted pendulum model to determine the relationship between the zero-moment point and center of mass (CoM). The CoM trajectory is calculated using preview control based on the dynamics model and current state of the robot. Therefore, even if the robot has the low tracking performance due to compliant motion control, the walking stability can be ensured. The proposed method was implemented on our humanoid robot, DYROS-JET, and its performance was demonstrated through improved stability during walking.
ER  - 

TY  - CONF
TI  - A Kalman Filter-Based Algorithm for Simultaneous Time Synchronization and Localization in UWB Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1431
EP  - 1437
AU  - J. Cano
AU  - S. Chidami
AU  - J. L. Ny
PY  - 2019
KW  - indoor radio
KW  - Kalman filters
KW  - mobile robots
KW  - path planning
KW  - position control
KW  - radionavigation
KW  - synchronisation
KW  - time-of-arrival estimation
KW  - transceivers
KW  - ultra wideband communication
KW  - EKF-based navigation system design
KW  - mobile robot positioning
KW  - Kalman filter-based algorithm
KW  - UWB transceivers
KW  - ultra-wideband wireless communication transceivers
KW  - time difference of arrival
KW  - TDOA
KW  - passive UWB receivers
KW  - UWB networks
KW  - ranging-based positioning systems
KW  - simultaneous time synchronization-localization
KW  - signal time-of-flight measurement
KW  - time of arrival
KW  - TOA
KW  - multiple UWB base station synchronization
KW  - Clocks
KW  - Synchronization
KW  - Protocols
KW  - Distance measurement
KW  - Thermodynamics
KW  - Transceivers
DO  - 10.1109/ICRA.2019.8794180
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to accurately measure signal time-of-flight between ultra-wideband (UWB) wireless communication transceivers, even in multipath environments, makes this technology ideally suited to develop ranging-based positioning systems, especially for indoor applications where GPS signals are not available. In recent years, low-cost commercial UWB transceivers have become more easily available and increasingly used to develop custom robot positioning systems. In this paper, we focus in particular on positioning techniques requiring the synchronization of base stations such as Time of Arrival (TOA) and Time Difference of Arrival (TDOA). We present a protocol based on Kalman filtering for simultaneous synchronization of multiple UWB base stations and positioning of an arbitrary number of passive UWB receivers. We illustrate experimentally using our protocol and an EKF-based navigation system design the level of accuracy achievable with small low-power UWB modules for mobile robot positioning. We discuss in details measurement errors and system tuning issues applicable to popular commercial UWB transceivers.
ER  - 

TY  - CONF
TI  - eRTIS: A Fully Embedded Real Time 3D Imaging Sonar Sensor for Robotic Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1438
EP  - 1443
AU  - R. Kerstens
AU  - D. Laurijssen
AU  - J. Steckel
PY  - 2019
KW  - image sensors
KW  - microphone arrays
KW  - mobile robots
KW  - robot vision
KW  - sonar imaging
KW  - fully embedded real time 3D imaging sonar sensor
KW  - robotic application
KW  - reflection strength
KW  - sensor systems
KW  - crucial pieces
KW  - processing power
KW  - external computing device
KW  - 3D sonar sensor
KW  - 3D localization capabilities
KW  - field-of-view
KW  - 3D perception
KW  - harsh conditions
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Microphone arrays
KW  - Computer architecture
KW  - Field programmable gate arrays
DO  - 10.1109/ICRA.2019.8794419
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Many popular advanced sonar systems provide accurate and reliable measurements containing crucial info needed by robotic applications such as range, bearing and reflection strength of the objects in the field of view. While these sensor systems provide these crucial pieces of information accurately, they are often limited by a lack of processing power and/or size which leads to them needing an external computing device to process all the information generated by the microphone array on the sensor. In this paper we present two versions of a novel fully embedded 3D sonar sensor which have different sensing architectures which enable 3D perception for robotic application in harsh conditions using ultrasound at low cost. Experimental results taken from an office environment will show the 3D localization capabilities and performance of the sensor, showing the sensor has a large field-of-view (FoV) with accurate 3D localization combined with real-time capabilities.
ER  - 

TY  - CONF
TI  - LookUP: Vision-Only Real-Time Precise Underground Localisation for Autonomous Mining Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1444
EP  - 1450
AU  - F. Zeng
AU  - A. Jacobson
AU  - D. Smith
AU  - N. Boswell
AU  - T. Peynot
AU  - M. Milford
PY  - 2019
KW  - cameras
KW  - image sensors
KW  - mining
KW  - mining industry
KW  - mobile robots
KW  - neural nets
KW  - robot vision
KW  - autonomous underground mining vehicles
KW  - neural-network-based pixel sampling strategy
KW  - visual based technique
KW  - real-time accurate localisation system
KW  - range sensor-based system
KW  - ceiling-facing cameras
KW  - Optical imaging
KW  - Cameras
KW  - Optical sensors
KW  - Adaptive optics
KW  - Heating systems
KW  - Optical network units
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8794453
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A key capability for autonomous underground mining vehicles is real-time accurate localisation. While significant progress has been made, currently deployed systems have several limitations ranging from dependence on costly additional infrastructure to failure of both visual and range-sensor-based techniques in highly aliased or visually challenging environments. In our previous work, we presented a lightweight coarse vision-based localisation system that could map and then localise to within a few metres in an underground mining environment. However, this level of precision is insufficient for providing a cheaper, more reliable vision-based automation alternative to current range sensor-based systems. Here we present a new precision localisation system dubbed “LookUP”, which learns a neural-network-based pixel sampling strategy for estimating homographies based on ceiling-facing cameras without requiring any manual labelling. This new system runs in real time on limited computation resource and is demonstrated on two different underground mine sites, achieving real time performance at ~5 frames per second and a much improved average localisation error of ~1.2 metre.
ER  - 

TY  - CONF
TI  - Analysis of Robust Functions for Registration Algorithms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1451
EP  - 1457
AU  - P. Babin
AU  - P. Giguère
AU  - F. Pomerleau
PY  - 2019
KW  - image registration
KW  - iterative methods
KW  - mobile robots
KW  - robust functions
KW  - registration algorithms
KW  - registration accuracy
KW  - mobile robotic application
KW  - iterative closest point algorithm
KW  - environment types
KW  - outlier filters
KW  - ICP algorithm
KW  - M-estimators
KW  - tuning parameters
KW  - Three-dimensional displays
KW  - Cost function
KW  - Minimization
KW  - Tuning
KW  - Robot sensing systems
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8793791
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Registration accuracy is influenced by the presence of outliers and numerous robust solutions have been developed over the years to mitigate their effect. However, without a large scale comparison of solutions to filter outliers, it is becoming tedious to select an appropriate algorithm for a given application. This paper presents a comprehensive analysis of the effects of outlier filters on the Iterative Closest Point (ICP) algorithm aimed at a mobile robotic application. Fourteen of the most common outlier filters (such as M-estimators) have been tested in different types of environments, for a total of more than two million registrations. Furthermore, the influence of tuning parameters has been thoroughly explored. The experimental results show that most outlier filters have a similar performance if they are correctly tuned. Nonetheless, filters such as Var. Trim., Cauchy, and Cauchy MAD are more stable against different environment types. Interestingly, the simple norm L1 produces comparable accuracy, while being parameterless.
ER  - 

TY  - CONF
TI  - CoLo: A Performance Evaluation System for Multi-robot Cooperative Localization Algorithms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1458
EP  - 1464
AU  - S. Chen
AU  - A. Mehta
PY  - 2019
KW  - cooperative systems
KW  - data analysis
KW  - location based services
KW  - multi-robot systems
KW  - performance evaluation
KW  - performance evaluation system
KW  - physical experiment
KW  - CoLo-PE
KW  - software analysis tool
KW  - algorithm evaluation
KW  - CoLo-AT
KW  - multirobot cooperative localization algorithms
KW  - multirobot localization data collection
KW  - robot location
KW  - Robots
KW  - Automation
KW  - Read only memory
DO  - 10.1109/ICRA.2019.8794311
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes CoLo - a performance evaluation system for two-dimensional cooperative localization algorithms. The system consists of a physical experiment (CoLo-PE) for data collection and a software analysis tool (CoLo-AT) using real-world datasets to evaluate the performances of users' cooperative localization algorithms. This paper details the design and operation of the physical experiment (CoLo-PE) and discusses the functionalities and uses of the software analysis tool (CoLo-AT) for algorithm evaluation. Specifically, CoLo allows researchers to conveniently add their cooperative localization algorithms and test them extensively on different real-world datasets with various settings. CoLo is available at https://git.uclalemur.com/billyskc/CoLo.
ER  - 

TY  - CONF
TI  - A cane-based low cost sensor to implement attention mechanisms in telecare robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1473
EP  - 1478
AU  - J. Ballesteros
AU  - A. Tudela
AU  - J. R. Caro-Romero
AU  - C. Urdiales
PY  - 2019
KW  - force sensors
KW  - geriatrics
KW  - health care
KW  - medical robotics
KW  - telemedicine
KW  - telerobotics
KW  - attention mechanisms
KW  - telecare robots
KW  - telepresence robots
KW  - cyclic checks
KW  - caregivers
KW  - CGA robots
KW  - comprehensive geriatric assessment
KW  - cane-based low cost force sensor system
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Shafts
KW  - Force sensors
KW  - Monitoring
KW  - Standards
DO  - 10.1109/ICRA.2019.8794283
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Telepresence robots have been recently used for Comprehensive Geriatric Assessment (CGA). Since the robot can not track a person continuously, there are several strategies to decide when to check them, from cyclic checks to simple requests from users and/or caregivers. In order to adapt to the user needs and condition, it is preferable to perform CGA as soon as regularities appear. However, this requires detection of potential issues in users to offer immediate service. In this work we propose a new low cost force sensor system to detect user's condition and attract attention of CGA robots, so they can perform a full examination on a need basis. The main advantages of this system are: i) it can be attached to any standard commercial cane; ii) its power consumption is very reduced; and iii) it provides continuous information as long as the user walks. It has been tested with several elderly volunteers in care facilities. Results have proven that the sensor readings are indeed correlated with the users' condition.
ER  - 

TY  - CONF
TI  - A Deployable Soft Robotic Arm with Stiffness Modulation for Assistive Living Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1479
EP  - 1485
AU  - J. Fathi
AU  - T. J. C. Oude Vrielink
AU  - M. S. Runciman
AU  - G. P. Mylonas
PY  - 2019
KW  - actuators
KW  - assisted living
KW  - biomechanics
KW  - handicapped aids
KW  - human-robot interaction
KW  - manipulator kinematics
KW  - medical robotics
KW  - mobile robots
KW  - motion control
KW  - pneumatic actuators
KW  - service robots
KW  - deployable soft robotic arm
KW  - assistive living applications
KW  - three-tendon actuated continuum robot
KW  - elderly impaired individuals
KW  - physically impaired individuals
KW  - daily living
KW  - Yoshimura pattern
KW  - controlled deployment
KW  - length variation
KW  - pneumatic stiffness mechanism
KW  - stiffness modulation approach
KW  - actuation system
KW  - assistive robots
KW  - Manipulators
KW  - Modulation
KW  - Pneumatic systems
KW  - Tendons
KW  - Soft robotics
DO  - 10.1109/ICRA.2019.8793670
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a three-tendon actuated continuum robot with an origami backbone to assist the elderly and physically impaired individuals in performing activities of daily living. The proposed design solution is an inherently safe and cost-effective alternative to current assistive robots. The origami backbone based on a variation of the Yoshimura pattern provides controlled deployment of the robot and enables length variation (15 cm - 56 cm) in order to increase the reachable workspace. A pneumatic stiffness mechanism was implemented, increasing the weight bearing capabilities of the continuum robot to 500 g. This new stiffness modulation approach was assessed with the use of several testing rigs. Additionally, the robot is joypad controlled and is easily transportable due to its high packing efficiency of 73% and light weight of 1.3 kg for the main body (including the actuation system). For demonstration of usability studies, the robot was successfully tested at a simulated kitchen terminal and also performed pick and place tasks.
ER  - 

TY  - CONF
TI  - Development of a Novel Gait Rehabilitation Device with Hip Interaction and a Single DOF Mechanism
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1492
EP  - 1498
AU  - M. R. Sabaapour
AU  - H. Lee
AU  - M. R. Afzal
AU  - A. Eizad
AU  - J. Yoon
PY  - 2019
KW  - actuators
KW  - gait analysis
KW  - legged locomotion
KW  - medical robotics
KW  - patient rehabilitation
KW  - trajectory control
KW  - hip interaction
KW  - single DOF mechanism
KW  - low-cost lower extremity gait rehabilitation device
KW  - single actuator
KW  - single DOF 8-bar Jansen mechanism
KW  - efficient walking mechanism
KW  - legged robots
KW  - ankle trajectory
KW  - human gait
KW  - lower limb
KW  - custom designed seat-type weight support system
KW  - donning-doffing action
KW  - weight-bearing
KW  - effective user-friendly training environment
KW  - gait training
KW  - Trajectory
KW  - Hip
KW  - Legged locomotion
KW  - Training
KW  - Couplings
KW  - Timing
KW  - Actuators
DO  - 10.1109/ICRA.2019.8794269
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, a novel, low-cost lower extremity gait rehabilitation device using a single actuator is presented. The proposed device is based on a single DOF 8-bar Jansen mechanism, which was recently introduced as an efficient walking mechanism for legged robots. The mechanism is synthesized to generate the ankle trajectory during human gait relative to the hip, in terms of both position and time. Two mechanisms, one for each lower limb, are applied reciprocally and mechanically synchronized to guarantee symmetric gait. A custom designed seat-type weight support system is also introduced. It supports weight of the user and mechanisms, and also provides the required interaction while maintaining mobility at the hip. To accommodate different users, several parameters of the mechanism are adjustable. Ease of donning-doffing action, weight-bearing and possibility of unhindered arm swing have been considered to provide an effective and user-friendly training environment. A prototype is manufactured, and a pilot study with a healthy subject is conducted to demonstrate feasibility of the concept. Due to ease of control, cost-effectiveness and high intrinsic safety, the proposed system potentially offers a possible method of gait training.
ER  - 

TY  - CONF
TI  - Differentially-Clutched Series Elastic Actuator for Robot-Aided Musculoskeletal Rehabilitation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1507
EP  - 1513
AU  - B. DeBoon
AU  - S. Nokleby
AU  - N. La Delfa
AU  - C. Rossa
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - brakes
KW  - clutches
KW  - human-robot interaction
KW  - medical robotics
KW  - motion control
KW  - patient rehabilitation
KW  - robot dynamics
KW  - safety
KW  - shafts
KW  - springs (mechanical)
KW  - torque control
KW  - human-robot interaction
KW  - robot-aided rehabilitation
KW  - upper limb musculoskeletal injuries
KW  - lower limb musculoskeletal injuries
KW  - robot-aided musculoskeletal rehabilitation
KW  - actuation modes
KW  - differentially-clutched series elastic actuator
KW  - safety
KW  - compliant nature
KW  - DC motor
KW  - torsion spring
KW  - magnetic particle brake
KW  - differential gear
KW  - topology
KW  - free motion
KW  - elastic motion
KW  - assistive motion
KW  - resistive motion
KW  - actuator dynamic model
KW  - reference torque
KW  - Actuators
KW  - Brakes
KW  - DC motors
KW  - Springs
KW  - Gears
KW  - Robots
KW  - Safety
DO  - 10.1109/ICRA.2019.8793586
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Series elastic actuators have proven to be an elegant response to the issue of safety around human-robot interaction. The compliant nature of series elastic actuators provides the potential to be applied in robot-aided rehabilitation for patients with upper and lower limb musculoskeletal injuries. This paper proposes a new series elastic actuator to be used in robot-aided musculoskeletal rehabilitation. The actuator is composed of a DC motor, a torsion spring, and a magnetic particle brake coupled to one common output shaft through a differential gear. The proposed topology focuses on three types of actuation modes most commonly used in rehabilitation, i.e., free motion, elastic, and assistive/resistive motion. A dynamic model of the actuator is presented and validated experimentally and the ability of the actuator to follow a reference torque is shown in different experimental scenarios.
ER  - 

TY  - CONF
TI  - A Novel Robotic Suturing System for Flexible Endoscopic Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1514
EP  - 1520
AU  - L. Cao
AU  - X. Li
AU  - P. T. Phan
AU  - A. M. H. Tiong
AU  - J. Liu
AU  - S. J. Phee
PY  - 2019
KW  - biomedical optical imaging
KW  - endoscopes
KW  - medical robotics
KW  - surgery
KW  - wound closure
KW  - robotic suturing system
KW  - five-degree-of-freedom robotic suturing instrument
KW  - suturing tasks
KW  - flexible endoscopic surgery
KW  - Surgery
KW  - Endoscopes
KW  - Needles
KW  - Instruments
KW  - Manipulators
KW  - Tools
DO  - 10.1109/ICRA.2019.8794247
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Perforations in flexible endoscopy are life-threatening. Defect closure or suturing in flexible endoscopy has long been a critical challenge due to the confined space of the access routes and surgical sites, high dexterity and force demands of suturing tasks, as well as critical size and strength requirements of wound closure. This paper introduces a novel robotic suturing system for flexible endoscopic surgery. This system features a flexible, through-the-scope, five-degree-of-freedom robotic suturing instrument. This instrument allows the surgeon to endoscopically manipulate a needle via a master console to create running stitches and knots in flexible endoscopy, which is not possible with existing devices. Successful ex-vivo trials were conducted inside porcine colons to show how surgical stitches and knots can be endoscopically created and secured in a completely new way. This new technology will change the way how surgeons close defects or perforations in flexible endoscopic surgery.
ER  - 

TY  - CONF
TI  - A Noninvasive Approach to Recovering the Lost Force Feedback for a Robotic-Assisted Insertable Laparoscopic Surgical Camera
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1521
EP  - 1526
AU  - N. Li
AU  - G. J. Mancini
AU  - J. Tan
PY  - 2019
KW  - biological tissues
KW  - biomedical optical imaging
KW  - cameras
KW  - force measurement
KW  - medical robotics
KW  - surgery
KW  - camera actuation
KW  - rotation camera behaviors
KW  - simulated abdominal cavity
KW  - noninvasive real-time camera-tissue interaction force measurement approach
KW  - abdominal wall tissue
KW  - robotic-assisted camera control experiment
KW  - laparoscopic imaging
KW  - transabdominal magnetic coupling
KW  - minimally invasive surgery
KW  - conventional trocar-based laparoscopes
KW  - insertable laparoscopic camera
KW  - robotic-assisted insertable laparoscopic surgical camera
KW  - lost force feedback
KW  - noninvasive approach
KW  - Cameras
KW  - Force
KW  - Robot vision systems
KW  - Stators
KW  - Actuators
KW  - Force measurement
DO  - 10.1109/ICRA.2019.8793640
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fully insertable laparoscopic cameras feature more locomotive flexibility in a larger workspace compared to conventional trocar-based laparoscopes and thus represent a promising future of minimally invasive surgery. These cameras are principally anchored and actuated by transabdominal magnetic coupling. Although several proof-of-concept prototypes have shown the technical feasibility in terms of camera actuation and laparoscopic imaging, none of them are getting close to clinical practice due to concerns about safety. One common problem lies in that the interaction force between the camera and the abdominal wall tissue is completely unknown and not controlled. The camera is being manipulated in an open loop which exposes the patient to a high risk of being injured. In this paper, a noninvasive real-time camera-tissue interaction force measurement approach for an insertable laparoscopic camera is proposed, implemented, and validated.Ex-vivo experiments using a simulated abdominal cavity have demonstrated the effectiveness of this approach during anchoring, translation, and rotation camera behaviors. Potential surgical impacts enabled by the force feedback have also been exemplified by a robotic-assisted camera control experiment using shared autonomy.
ER  - 

TY  - CONF
TI  - Development of a Multi-level Stiffness Soft Robotic Module with Force Haptic Feedback for Endoscopic Applications*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1527
EP  - 1533
AU  - H. Naghibi
AU  - M. W. Gifari
AU  - W. Hoitzing
AU  - J. W. Lageveen
AU  - D. M. M. van As
AU  - S. Stramigioli
AU  - M. Abayazid
PY  - 2019
KW  - endoscopes
KW  - finite element analysis
KW  - medical robotics
KW  - surgery
KW  - 3D kinematics control
KW  - finite element analysis
KW  - maneuverability
KW  - endoscopic module
KW  - endoscopic surgical interventions
KW  - structural stiffness
KW  - haptic feedback control
KW  - force sensing module
KW  - multilevel stiffening mechanism
KW  - soft robotics endoscope
KW  - surgical manipulators
KW  - natural orifice transluminal endoscopic surgeries
KW  - minimally invasive orifice transluminal endoscopic surgeries
KW  - soft endoscopes
KW  - endoscopic applications
KW  - force haptic feedback
KW  - multilevel stiffness soft robotic module
KW  - Endoscopes
KW  - Haptic interfaces
KW  - Force
KW  - Surgery
KW  - Sensors
KW  - Phantoms
KW  - Control systems
DO  - 10.1109/ICRA.2019.8793584
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Despite the recent advances in soft endoscopes, they could not yet fully fulfill the requirements for minimally invasive and natural orifice transluminal endoscopic surgeries. Maneuverability, bendability, different structural stiffness required for different endoscopic surgical interventions, the space needed for surgical manipulators and patient's safety are amongst the main factors which can contribute to implementing the new soft robotics endoscope in practice. In this study, based on finite element analysis on an existing endoscopic segment, a new improved endoscopic module was developed. A novel approach for stiffening of the endoscopic module was proposed. The actuation and stiffening components were combined to introduce a multi-level stiffening mechanism to the endoscope, and also to provide a free lumen for manipulators. To increase patient's safety, a force sensing module was developed to estimate the magnitude and direction of the force from tissues to the endoscope. The developed endoscopic system was integrated to a haptic control system. The 3D kinematics control and haptic feedback control of the endoscopic module were validated.
ER  - 

TY  - CONF
TI  - Feasibility Study of Robotic Needles with a Rotational Tip-Joint and Notch Patterns
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1534
EP  - 1540
AU  - S. Pattanshetti
AU  - R. Sandström
AU  - A. Kottala
AU  - N. M. Amato
AU  - S. C. Ryu
PY  - 2019
KW  - industrial robots
KW  - needles
KW  - nickel alloys
KW  - rods (structures)
KW  - springs (mechanical)
KW  - titanium alloys
KW  - laser machining
KW  - cosserat rod theory
KW  - spring model
KW  - dynamic region RRT
KW  - planning algorithm
KW  - tissue reaction
KW  - microtools
KW  - embedded rotational tip joint
KW  - proximal notch patterns
KW  - steerable needle
KW  - robotic needles
KW  - Needles
KW  - Fasteners
KW  - Electron tubes
KW  - Tendons
KW  - Force
KW  - Robots
KW  - Planning
DO  - 10.1109/ICRA.2019.8793574
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present the design of a steerable needle with proximal notch patterns for compliance and an embedded rotational tip joint for articulation. The device is fabricated by laser machining NiTi tube so that an inner working channel exists (to enable delivery of fluids, drugs or microtools) and no assembly is required for the joints. We formulate its model based on the classical Cosserat Rod theory. This is extended with incremental state prediction and a simple spring model for tissue reaction to integrate into a planning algorithm based on Dynamic Region RRT which efficiently explores the needle's state space. The planner was initialized with a target zone and arbitrary anatomical obstacles before running simulations which propagated incremental state changes at every step while adhering to constraints based on the physical system. Finally, we demonstrate the steering capability of the needle through insertion tests into a phantom.
ER  - 

TY  - CONF
TI  - Autonomous Laparoscopic Robotic Suturing with a Novel Actuated Suturing Tool and 3D Endoscope
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1541
EP  - 1547
AU  - H. Saeidi
AU  - H. N. D. Le
AU  - J. D. Opfermann
AU  - S. Leonard
AU  - A. Kim
AU  - M. H. Hsieh
AU  - J. U. Kang
AU  - A. Krieger
PY  - 2019
KW  - biological tissues
KW  - biomedical optical imaging
KW  - endoscopes
KW  - medical image processing
KW  - medical robotics
KW  - surgery
KW  - STAR
KW  - laparoscopic suturing tool
KW  - suture repositioning
KW  - suture spacing
KW  - suture pads
KW  - suture planning strategy
KW  - 3D imaging endoscope
KW  - smart tissue anastomosis robot
KW  - autonomous laparoscopic robotic suturing system
KW  - surgical tools
KW  - laparoscopic surgery
KW  - patient recovery time
KW  - collateral tissue damage
KW  - laparoscopic surgical methods
KW  - open surgical techniques
KW  - Tools
KW  - Three-dimensional displays
KW  - Laparoscopes
KW  - Surgery
KW  - Robot kinematics
KW  - Imaging
DO  - 10.1109/ICRA.2019.8794306
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Compared to open surgical techniques, laparoscopic surgical methods aim to reduce the collateral tissue damage and hence decrease the patient recovery time. However, constraints imposed by the laparoscopic surgery, i.e. the operation of surgical tools in limited spaces, turn simple surgical tasks such as suturing into time-consuming and inconsistent tasks for surgeons. In this paper, we develop an autonomous laparoscopic robotic suturing system. More specific, we expand our smart tissue anastomosis robot (STAR) by developing i) a new 3D imaging endoscope, ii) a novel actuated laparoscopic suturing tool, and iii) a suture planning strategy for the autonomous suturing. We experimentally test the accuracy and consistency of our developed system and compare it to sutures performed manually by surgeons. Our test results on suture pads indicate that STAR can reach 2.9 times better consistency in suture spacing compared to manual method and also eliminate suture repositioning and adjustments. Moreover, the consistency of suture bite sizes obtained by STAR matches with those obtained by manual suturing.
ER  - 

TY  - CONF
TI  - Active Contraints for Tool-Shaft Collision Avoidance in Minimally Invasive Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1556
EP  - 1562
AU  - A. Banach
AU  - K. Leibrandt
AU  - M. Grammatikopoulou
AU  - G. Yang
PY  - 2019
KW  - force control
KW  - medical robotics
KW  - surgery
KW  - telerobotics
KW  - tool-shaft collision avoidance
KW  - clinical adoption
KW  - master-slave surgical systems
KW  - physical separation
KW  - Active Constraints
KW  - sensory information
KW  - surgical robot operators
KW  - haptic cues
KW  - visual cues
KW  - audible cues
KW  - surgical tool-clashing
KW  - elasto-plastic frictional force control
KW  - ACs methods
KW  - teleoperated da Vinci Surgical System
KW  - ACs assistance
KW  - teleoperation-based robotic-assisted minimally invasive surgery
KW  - minimally invasive partial nephrectomy
KW  - Force
KW  - Tools
KW  - Surgery
KW  - Image segmentation
KW  - Arteries
KW  - Shafts
KW  - Robots
DO  - 10.1109/ICRA.2019.8794147
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent advances in teleoperation-based robotic-assisted Minimally Invasive Surgery (MIS) have made significant inroads in clinical adoption. However, such master-slave surgical systems create a physical separation between the surgeon and the patient. The concept of Active Constraints (ACs) provides guidance and sensory information to surgical robot operators in a form of haptic, visual or audible cues. This work proposes a novel ACs approach to avoid surgical tool-clashing and collision of the tool-shaft with delicate anatomy using elasto-plastic frictional force control. The presented framework is designed to reduce the occurence of direct coupling during electrocautery and to protect high-risk regions in Minimally Invasive Partial Nephrectomy (MIPN). Moreover, we combine aforementioned ACs methods and propose a solution when simultaneous penetration of both constraints occurs. The proposed methodology is implemented on the teleoperated da Vinci Surgical System using the da Vinci Research Kit (dVRK) and its performance is demonstrated through three types of user experiments. The experimental results show that the developed algorithms are of significant benefit in performing the tasks with ACs assistance.
ER  - 

TY  - CONF
TI  - Energy Budget Transaction Protocol for Distributed Robotic Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1563
EP  - 1568
AU  - S. S. Groothuis
AU  - S. Stramigioli
PY  - 2019
KW  - energy management systems
KW  - protocols
KW  - robots
KW  - telecommunication power management
KW  - energy transaction protocol
KW  - distributed robotic system
KW  - simulated unreliable communication channel
KW  - energy budget transaction protocol
KW  - necessary condition
KW  - energy generating system
KW  - energy-aware actuation
KW  - allocated energy budget
KW  - system stability
KW  - energy monitoring
KW  - accidental energy generation
KW  - naive communication strategy
KW  - Protocols
KW  - Robots
KW  - Communication channels
KW  - Task analysis
KW  - Real-time systems
KW  - Stability criteria
KW  - Network architecture
DO  - 10.1109/ICRA.2019.8794388
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Passivity is a necessary condition for a system's stability, meaning that an energy generating system may readily become unstable. Energy-aware actuation can enforce passivity by monitoring the amount of energy that is exchanged with a system, while using an allocated energy budget to execute a task. Careful communication of the energy budgets is important to prevent accidental generation of energy. Therefore, this paper proposes an energy transaction protocol to communicate energy budgets in a distributed robotic system to guarantee that passivity is kept. Simulations are performed with a model of the protocol that is applied to a simulated unreliable communication channel. It is verified that the proposed protocol keeps passivity in the system, while a naive communication strategy either violates passivity or is unnecessarily dissipative.
ER  - 

TY  - CONF
TI  - Tele-Echography using a Two-Layer Teleoperation Algorithm with Energy Scaling
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1569
EP  - 1575
AU  - E. Sartori
AU  - C. Tadiello
AU  - C. Secchi
AU  - R. Muradore
PY  - 2019
KW  - biomedical ultrasonics
KW  - delays
KW  - force control
KW  - haptic interfaces
KW  - manipulators
KW  - medical robotics
KW  - stability
KW  - telerobotics
KW  - time-varying systems
KW  - sonographer
KW  - communication delays
KW  - passivity-based bilateral teleoperation architecture
KW  - unknown time-varying delay
KW  - control laws
KW  - slave manipulator
KW  - significant forces
KW  - WAM Barrett robot
KW  - two-layer teleoperation algorithm
KW  - energy scaling
KW  - stable behavior
KW  - touch haptic device
KW  - tele-echography system
KW  - ultrasound procedures
KW  - Delays
KW  - Ultrasonic imaging
KW  - Damping
KW  - Force
KW  - Manipulator dynamics
DO  - 10.1109/ICRA.2019.8794152
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Performing ultrasound procedures from a remote site is a challenging task since both a stable behavior, for the safety of the patient, and a high-level of usability, to exploit the sonographer's expertise, need to be guaranteed. Furthermore, a teleoperation system that provides such requirements has to deal with communication delays as well. To address this issue, we use the two-layer algorithm: a passivity-based bilateral teleoperation architecture able to guarantee stability despite unknown and time-varying delay. Its flexibility allows to implement different kinds of control laws. In a Tele-Echography system, the slave manipulator has to apply significant forces needed by the procedure whereas the haptic device at the master side should be very light to avoid tiring the operator. Therefore, the energy needed by these two robots to perform their movements is very different and the energy injected into the system by the operator is often not sufficient to implement the desired action at the slave side. Methods to overcome this problem require to perfectly know the dynamical models of the robots. The solution proposed in this paper does not require such knowledge and is based on properly scaling the energy exchanged between the master and the slave side. We show the effectiveness of this approach in a real setup using a TOUCH haptic device and a WAM Barrett robot holding an ultrasound probe.
ER  - 

TY  - CONF
TI  - EMG-Controlled Non-Anthropomorphic Hand Teleoperation Using a Continuous Teleoperation Subspace
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1576
EP  - 1582
AU  - C. Meeker
AU  - M. Ciocarlie
PY  - 2019
KW  - dexterous manipulators
KW  - electromyography
KW  - human-robot interaction
KW  - sensors
KW  - signal processing
KW  - telerobotics
KW  - EMG-controlled nonanthropomorphic hand teleoperation
KW  - continuous teleoperation subspace
KW  - EMG-driven teleoperation
KW  - EMG sensors
KW  - EMG signals
KW  - pose space
KW  - forearm EMG
KW  - robot hand
KW  - EMG teleoperation methods
KW  - nonanthropomorphic multiDOF robot hands
KW  - Electromyography
KW  - Aerospace electronics
KW  - Grippers
KW  - Wrist
KW  - Muscles
KW  - Teleoperators
DO  - 10.1109/ICRA.2019.8794108
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a method for EMG-driven teleoperation of non-anthropomorphic robot hands. EMG sensors are appealing as a wearable, inexpensive, and unobtrusive way to gather information about the teleoperator's hand pose. However, mapping from EMG signals to the pose space of a non-anthropomorphic hand presents multiple challenges. We present a method that first projects from forearm EMG into a subspace relevant to teleoperation. To increase robustness, we use a model which combines continuous and discrete predictors along different dimensions of this subspace. We then project from the teleoperation subspace into the pose space of the robot hand. Our method is effective and intuitive, as it enables novice users to teleoperate pick and place tasks faster and more robustly than state-of-the-art EMG teleoperation methods when applied to a non-anthropomorphic, multi-DOF robot hand.
ER  - 

TY  - CONF
TI  - Enhancing the Force Transparency of Time Domain Passivity Approach: Observer-Based Gradient Controller
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1583
EP  - 1589
AU  - H. Singh
AU  - A. Jafari
AU  - J. Ryu
PY  - 2019
KW  - bang-bang control
KW  - control system synthesis
KW  - delays
KW  - feedback
KW  - force control
KW  - gradient methods
KW  - observers
KW  - position control
KW  - stability
KW  - telerobotics
KW  - time-domain analysis
KW  - vibrations
KW  - time domain passivity approach
KW  - communication time delay
KW  - force jittering
KW  - teleoperation setup
KW  - master device
KW  - passivity controller
KW  - virtual mass-spring system
KW  - high frequency force vibrations
KW  - conservative passivity-based approaches
KW  - stable controller design
KW  - observer-based gradient controller
KW  - force transparency
KW  - TDPA
KW  - position-force bilateral teleoperation system
KW  - system parameters
KW  - delayed feedback force
KW  - Force
KW  - Delays
KW  - Communication channels
KW  - High frequency
KW  - Vibrations
KW  - Time-domain analysis
KW  - Teleoperators
DO  - 10.1109/ICRA.2019.8793902
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Passivity has been the most often used constraint for the stable controller design of bilateral teleoperation systems. Especially, Time Domain Passivity Approach (TDPA) has been used in many applications since it has been known as one of the least conservative passivity-based approaches. Although TDPA were able to stabilize the system with the least conservatism, it has its own drawbacks as the cost of achieving the least conservative passivity especially when there is communication time-delay. Due to the on/off bang-bang control-like modification for instantaneous passivity recovery, it has high frequency force vibrations on the slave and especially master side. By implementing a virtual mass-spring system between the passivity controller and master device, these high frequency vibration has been eliminated. However, the gains need proper tuning as they are dependent on the teleoperation setup and application. It also tends to make the system sluggish which further distorts the transparency. We propose a new observer-based gradient controller to eliminate the force jittering on the master side. It rectifies the delayed feedback force by removing the undesired increase in force which is generated by the delay in communication channel. It does not require any system parameters and there are no gains to tune, thus it can be added to any teleoperator irrespective of its dynamics and without having any prior system information. The proposed approach was implemented to a position-force bilateral teleoperation system, and compared with TDPA with virtual mass spring with round-trip delays of up to 500 ms for hard wall contacts.
ER  - 

TY  - CONF
TI  - Motion Scaling Solutions for Improved Performance in High Delay Surgical Teleoperation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1590
EP  - 1595
AU  - F. Richter
AU  - R. K. Orosco
AU  - M. C. Yip
PY  - 2019
KW  - delays
KW  - medical robotics
KW  - surgery
KW  - telerobotics
KW  - high delay surgical teleoperation
KW  - robotic teleoperation
KW  - surgeon
KW  - telerobotic surgery
KW  - surgical workflow
KW  - commercial surgical robotic systems
KW  - intuitive motion scaling solutions
KW  - teleoperated robotic systems
KW  - Delays
KW  - Task analysis
KW  - Surgery
KW  - Haptic interfaces
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794085
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic teleoperation brings great potential for advances within the field of surgery. The ability of a surgeon to reach patient remotely opens exciting opportunities. Early experience with telerobotic surgery has been interesting, but the clinical feasibility remains out of reach, largely due to the deleterious effects of communication delays. Teleoperation tasks are significantly impacted by unavoidable signal latency, which directly results in slower operations, less precision in movements, and increased human errors. Introducing significant changes to the surgical workflow, for example by introducing semi-automation or self-correction, present too significant a technological and ethical burden for commercial surgical robotic systems to adopt. In this paper, we present three simple and intuitive motion scaling solutions to combat teleoperated robotic systems under delay and help improve operator accuracy. Motion scaling offers potentially improved user performance and reduction in errors with minimal change to the underlying teleoperation architecture. To validate the use of motion scaling as a performance enhancer in telesurgery, we conducted a user study with 17 participants, and our results show that the proposed solutions do indeed reduce the error rate when operating under high delay.
ER  - 

TY  - CONF
TI  - Robust object grasping in clutter via singulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1596
EP  - 1600
AU  - M. Kiatos
AU  - S. Malassiotis
PY  - 2019
KW  - function approximation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - object detection
KW  - robot vision
KW  - robust object grasping
KW  - singulation
KW  - cluttered environment
KW  - collision free grasp affordances
KW  - optimal push policies
KW  - action-value function approximation
KW  - robot training
KW  - deep neural network
KW  - reinforcement learning
KW  - Robots
KW  - Task analysis
KW  - Image segmentation
KW  - Reinforcement learning
KW  - Clutter
KW  - Neural networks
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793972
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Grasping objects in a cluttered environment is challenging due to the lack of collision free grasp affordances. In such conditions, the target object touches or is covered by other objects in the scene, resulting in a failed grasp. To address this problem, we propose a strategy of singulating the object from its surrounding clutter, which consists of previously unseen objects, by means of lateral pushing movements. We employ reinforcement learning for obtaining optimal push policies given depth observations of the scene. The action-value function(Q-function) is approximated with a deep neural network. We train the robot in simulation and we demonstrate that the transfer of learned policies to the real environment is robust.
ER  - 

TY  - CONF
TI  - Towards an Integrated Autonomous Data-Driven Grasping System with a Mobile Manipulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1601
EP  - 1607
AU  - M. Hegedus
AU  - K. Gupta
AU  - M. Mehrandezh
PY  - 2019
KW  - dexterous manipulators
KW  - grippers
KW  - image reconstruction
KW  - image registration
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - arbitrary object
KW  - scan overlap
KW  - grasp analysis
KW  - autonomous data-driven grasping system
KW  - volumetric next-best-view algorithm
KW  - NBV algorithm
KW  - force closure
KW  - base pose uncertainty
KW  - integrated grasping system
KW  - mobile manipulator
KW  - Uncertainty
KW  - Manipulators
KW  - Grasping
KW  - Robot sensing systems
KW  - Planning
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793759
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an integrated grasping system for a mobile manipulator to grasp an unknown object of interest (OI) in an unknown environment. The system autonomously scans its environment, models the OI, plans and executes a grasp, while taking into account base pose uncertainty. Due to inherent line of sight limitations in sensing, a single scan of the OI often does not reveal enough information to complete grasp analysis; as a result, our system autonomously builds a model of an object via multiple scans from different locations until a grasp can be performed. A volumetric next-best-view (NBV) algorithm is used to model an arbitrary object and terminates modeling when force closure for the gripper is satisfied. Two experiments are presented: i) modeling and registration error is reduced by selecting viewpoints with more scan overlap, and ii) model reconstruction and grasps are successfully achieved while experiencing base pose uncertainty.
ER  - 

TY  - CONF
TI  - Design Principles and Optimization of a Planar Underactuated Hand for Caging Grasps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1608
EP  - 1613
AU  - W. G. Bircher
AU  - A. M. Dollar
PY  - 2019
KW  - design engineering
KW  - dexterous manipulators
KW  - elastic constants
KW  - grippers
KW  - pulleys
KW  - springs (mechanical)
KW  - planar underactuated hand
KW  - underactuated grippers
KW  - passive adaptability
KW  - finger phalanx length
KW  - design parameters
KW  - caging grasp performance
KW  - mechanical compliance
KW  - free-swing motion
KW  - joint spring stiffness
KW  - pulley radius
KW  - Tendons
KW  - Pulleys
KW  - Measurement
KW  - Springs
KW  - Grasping
KW  - Torque
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793465
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we address the problem of creating planar caging grasps on objects using simple, underactuated grippers with no sensing or control. Specifically, we examine how changes in mechanical compliance, passive adaptability due to underactuation, and finger phalanx length affect the ability to create caging grasps passively, by altering the free-swing motion of the fingers. We present a simple model for simulating the underactuated hand, develop a metric for quantifying a hand design's caging ability, and perform a design parameter space search to reveal the important design factors influencing passive caging behavior. The results show that both palm width and the interplay between joint spring stiffness and pulley radius ratios play the largest roles in determining caging behavior. The effect of varying design parameters on the caging grasp performance of the hand is discussed, the best resulting design is shown, and a list of principles to guide the design of simple underactuated hands for caging grasps is presented.
ER  - 

TY  - CONF
TI  - Mechanical Search: Multi-Step Retrieval of a Target Object Occluded by Clutter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1614
EP  - 1621
AU  - M. Danielczuk
AU  - A. Kurenkov
AU  - A. Balakrishna
AU  - M. Matl
AU  - D. Wang
AU  - R. Martín-Martín
AU  - A. Garg
AU  - S. Savarese
AU  - K. Goldberg
PY  - 2019
KW  - image colour analysis
KW  - object recognition
KW  - robot vision
KW  - mechanical search
KW  - distractor objects
KW  - robots
KW  - RGBD perception system
KW  - target object multistep retrieval
KW  - Search problems
KW  - Task analysis
KW  - Grasping
KW  - Image segmentation
KW  - Visualization
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794143
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When operating in unstructured environments such as warehouses, homes, and retail centers, robots are frequently required to interactively search for and retrieve specific objects from cluttered bins, shelves, or tables. Mechanical Search describes the class of tasks where the goal is to locate and extract a known target object. In this paper, we formalize Mechanical Search and study a version where distractor objects are heaped over the target object in a bin. The robot uses an RGBD perception system and control policies to iteratively select, parameterize, and perform one of 3 actions - push, suction, grasp - until the target object is extracted, or either a time limit is exceeded, or no high confidence push or grasp is available. We present a study of 5 algorithmic policies for mechanical search, with 15,000 simulated trials and 300 physical trials for heaps ranging from 10 to 20 objects. Results suggest that success can be achieved in this long-horizon task with algorithmic policies in over 95% of instances and that the number of actions required scales approximately linearly with the size of the heap. Code and supplementary material can be found at http://ai.stanford.edu/mech-search.
ER  - 

TY  - CONF
TI  - Transferring Grasp Configurations using Active Learning and Local Replanning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1622
EP  - 1628
AU  - H. Tian
AU  - C. Wang
AU  - D. Manocha
AU  - X. Zhang
PY  - 2019
KW  - dexterous manipulators
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - path planning
KW  - robot vision
KW  - grasp configurations
KW  - active learning
KW  - prior example objects
KW  - similar shapes
KW  - geometric shape characteristics
KW  - semantic shape characteristics
KW  - grasp space
KW  - model parts
KW  - corresponding grasps
KW  - local replanning
KW  - point cloud
KW  - robotic hands
KW  - Shape
KW  - Grasping
KW  - Semantics
KW  - Three-dimensional displays
KW  - Robots
KW  - Stability analysis
KW  - Particle swarm optimization
DO  - 10.1109/ICRA.2019.8793796
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a new approach to transfer grasp configurations from prior example objects to novel objects. We assume the novel and example objects have the same topology and similar shapes. We perform 3D segmentation on these objects using geometric and semantic shape characteristics. We compute a grasp space for each part of the example object using active learning. We build bijective contact mapping between these model parts and compute the corresponding grasps for novel objects. Finally, we assemble the individual parts and use local replanning to adjust grasp configurations while maintaining its stability and physical constraints. Our approach is general, can handle all kind of objects represented using mesh or point cloud and a variety of robotic hands.
ER  - 

TY  - CONF
TI  - Kinematic Analysis of a 4-DOF Parallel Mechanism with Large Translational and Orientational Workspace
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1637
EP  - 1643
AU  - S. Kamada
AU  - T. Laliberté
AU  - C. Gosselin
PY  - 2019
KW  - Jacobian matrices
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - kinematic analysis
KW  - parallel mechanism
KW  - 3 translational DOFs
KW  - 1 rotational DOF
KW  - parallel sliders
KW  - parallelogram linkages
KW  - kinematic equations
KW  - Jacobian matrices
KW  - geometric description
KW  - Actuators
KW  - Kinematics
KW  - Jacobian matrices
KW  - Redundancy
KW  - Legged locomotion
KW  - Solid modeling
KW  - parallel mechanism
KW  - translational workspace
KW  - orientational workspace
KW  - parallelogram
DO  - 10.1109/ICRA.2019.8793962
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces a novel four-degree-of-freedom (4-DOF) parallel mechanism having 3 translational DOFs and 1 rotational DOF. The mechanism comprises 2 sets of parallelogram linkages, which constrain two of the rotational DOFs of the mechanism. An interesting feature of the mechanism is that it can be driven using 4 parallel sliders mounted on its base. As a result, one of the translational DOFs can be infinitely large. Also, the architecture of the mechanism provides a large rotational DOF in one direction. The kinematic equations of the mechanism are derived and the Jacobian matrices are obtained. The mathematical conditions that lead to singularities are also found. Moreover, a geometric description of the boundaries of the workspace is given, which can be expressed using simple equations. Finally, some design examples are proposed and a prototype is presented.
ER  - 

TY  - CONF
TI  - Kinematically Redundant (6+3)-dof Hybrid Parallel Robot with Large orientational Workspace and Remotely Operated Gripper
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1672
EP  - 1678
AU  - K. Wen
AU  - D. Harton
AU  - T. Laliberté
AU  - C. Gosselin
PY  - 2019
KW  - actuators
KW  - CAD
KW  - grippers
KW  - manipulator kinematics
KW  - orientational workspace
KW  - type II singularities
KW  - robot actuators
KW  - kinematically redundant (6+3)-dof hybrid parallel robot
KW  - remotely operated gripper
KW  - 3-[R(RR-RRR)SR] kinematically redundant 6+3-degree-of-freedom spatial hybrid parallel robot
KW  - revolute actuators
KW  - constraint conditions
KW  - CAD model
KW  - computer animation
KW  - Legged locomotion
KW  - Kinematics
KW  - Redundancy
KW  - Silicon
KW  - Actuators
KW  - Parallel robots
DO  - 10.1109/ICRA.2019.8793772
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A novel 3-[R(RR-RRR)SR] kinematically redundant 6+3-degree-of-freedom (dof)spatial hybrid parallel robot with revolute actuators is proposed. The kinematic model is developed based on the constraint conditions of the robot. It is shown that the type II (parallel) singularities can be completely avoided, thereby greatly extending the orientational workspace. Mechanisms are then introduced to use the redundant degrees of freedom of the robot to operate a gripper with the robot actuators, which are mounted on or close to the base. A CAD model of the robot is shown and a computer animation is provided to demonstrate the resulting architecture, which has full 6-dof capabilities and a large orientational workspace.
ER  - 

TY  - CONF
TI  - Modeling Variable Curvature Parallel Continuum Robots Using Euler Curves
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1679
EP  - 1685
AU  - P. S. Gonthina
AU  - A. D. Kapadia
AU  - I. S. Godage
AU  - I. D. Walker
PY  - 2019
KW  - manipulator kinematics
KW  - Euler spiral models
KW  - Euler spiral method
KW  - Euler curves
KW  - Cornu spirals
KW  - kinematic modeling
KW  - variable curvature parallel continuum robots
KW  - Clothoids
KW  - McKibben actuators
KW  - Robots
KW  - Spirals
KW  - Kinematics
KW  - Shape
KW  - Muscles
KW  - Mathematical model
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794238
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose and investigate a new approach to modeling variable curvature continuum robot sections, based on Euler spirals. Euler spirals, also termed Clothoids, or Cornu spirals, are those curves in which the curvature increases linearly with their arc length. In this work, Euler spirals are applied to the kinematic modeling of continuum robots for the first time. The approach was evaluated using the sections of numerous continuum robots, including two novel parallel continuum robots. Each robot consists of three parallel sections, each with three thin, long McKibben actuators. These sections are poorly modeled by the widely used constant curvature kinematic model. The constant curvature and Euler spiral models were compared and the Euler spiral method was seen to be a significantly better match for a wide range of configurations of the robot hardware.
ER  - 

TY  - CONF
TI  - Variable Damping Control of the Robotic Ankle Joint to Improve Trade-off between Performance and Stability
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1699
EP  - 1704
AU  - J. Arnold
AU  - H. Hanzlick
AU  - H. Lee
PY  - 2019
KW  - biomechanics
KW  - control system synthesis
KW  - damping
KW  - human-robot interaction
KW  - medical robotics
KW  - mobile robots
KW  - robot dynamics
KW  - stability
KW  - wearable robots
KW  - ankle exoskeleton robot
KW  - human ankle damping
KW  - human-robot system
KW  - robotic controller design
KW  - stability
KW  - robotic damping conditions
KW  - Damping
KW  - Stability analysis
KW  - Robot kinematics
KW  - Task analysis
KW  - Exoskeletons
KW  - Impedance
DO  - 10.1109/ICRA.2019.8793869
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a variable damping control strategy to improve trade-off between agility/performance and stability in the control of the ankle exoskeleton robot. Depending on the user's intent of movement, the proposed variable damping controller determines the robotic ankle damping from negative to positive damping values. The range of damping values is determined by incorporating the knowledge of human ankle damping in order to always secure stability of the ankle joint of the coupled human-robot system. To evaluate the effectiveness of the proposed controller, we performed a set of human experiments with three different robotic damping conditions: fixed positive damping, fixed negative damping, and variable damping. Comparison of the two fixed damping conditions confirmed that there exists a clear trade-off between ankle agility and stability. Further, analysis of the variable damping condition demonstrated that humans could get benefits of not only positive damping to stabilize the ankle but also negative damping to enhance the agility of ankle movement as necessary during dynamic ankle movement. On average, the variable damping condition improved the agility of ankle movement by 76% and stability by 37% compared to the constant positive damping condition and the constant negative damping condition, respectively. Outcomes of this study would allow us to design a robotic controller that significantly improves agility/performance of the human-robot system without compromising its coupled stability.
ER  - 

TY  - CONF
TI  - An Autonomous Exoskeleton for Ankle Plantarflexion Assistance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1713
EP  - 1719
AU  - A. Wu
AU  - X. Yang
AU  - J. Kuan
AU  - H. M. Herr
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - brushless DC motors
KW  - feedforward
KW  - gait analysis
KW  - legged locomotion
KW  - machine vector control
KW  - medical robotics
KW  - patient rehabilitation
KW  - robot kinematics
KW  - torque control
KW  - ankle assistance
KW  - autonomous platform
KW  - torque control bandwidth
KW  - field oriented control
KW  - feed-forward controller
KW  - high efficiency transmission system
KW  - untethered exoskeleton
KW  - ankle plantarflexion assistance
KW  - autonomous exoskeleton platform
KW  - robotics community
KW  - lower-limb exoskeletons
KW  - frequency 17.5 Hz
KW  - Exoskeletons
KW  - Torque
KW  - Brushless DC motors
KW  - Voltage measurement
KW  - Voltage control
DO  - 10.1109/ICRA.2019.8793913
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Lower-limb exoskeletons are of great interest in the robotics community because of their various applications in enhancement and rehabilitation. In this paper we present an autonomous exoskeleton platform for ankle plantarflexion assistance. The untethered exoskeleton has a high efficiency transmission system with reduction ratio of 27.4:1. This allows relocating the actuator to the wearer's hip, which reduces device inertia. A feed-forward controller based on field oriented control was implemented to control the brushless DC motor on the exoskeleton. Through various performance tests, the exoskeleton was shown to provide a torque control bandwidth of 17.5Hz and can effectively track biological torque profiles. The augmentation factor (AF) of the exoskeleton is 64.7W, implying potential to reduce walking metabolic cost. This exoskeleton establishes an autonomous platform for experiments involving ankle assistance.
ER  - 

TY  - CONF
TI  - Analytic Collision Risk Calculation for Autonomous Vehicle Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1744
EP  - 1750
AU  - A. Philipp
AU  - D. Goehring
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - Monte Carlo methods
KW  - navigation
KW  - probability
KW  - road traffic control
KW  - road vehicles
KW  - autonomous vehicle navigation
KW  - Monte Carlo simulations
KW  - autonomous systems
KW  - self-driving car
KW  - Freie Universität Berlin
KW  - collision octagon
KW  - analytic collision risk calculation
KW  - trajectory prediction
KW  - ground vehicle navigation
KW  - autonomous driving
KW  - planning system
KW  - Trajectory
KW  - Integral equations
KW  - Autonomous vehicles
KW  - Monte Carlo methods
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793264
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Collision checking and avoidance is an import part of the perception and planning system for autonomous driving. We present a new analytic approach to calculate the probability of a future collision and extend another already known solution to be suitable for ground vehicle navigation. Our new concept of the collision octagon facilitates in both cases the derivation of an analytic solution. Both approaches are compared to each other using simulated and real world scenarios. By comparing the results of the analytic solutions to the corresponding Monte Carlo simulations, their accuracy and real-time capability is demonstrated. The suitability of the analytic solutions for real world autonomous systems is further proven by integrating them into the trajectory prediction and planning system of the self-driving car of the Freie Universität Berlin.
ER  - 

TY  - CONF
TI  - A new approach to local navigation for autonomous driving vehicles based on the curvature velocity method
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1751
EP  - 1757
AU  - J. López
AU  - C. Otero
AU  - R. Sanz
AU  - E. Paz
AU  - E. Molinos
AU  - R. Barea
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - road traffic
KW  - local navigation
KW  - autonomous driving vehicles
KW  - curvature velocity method
KW  - car navigation system
KW  - road path
KW  - motion control
KW  - high-level planning
KW  - lower-level reactive control
KW  - beam curvature method
KW  - pure pursuit method
KW  - lane obstacle avoidance
KW  - elderly people
KW  - Navigation
KW  - Planning
KW  - Automobiles
KW  - Robot sensing systems
KW  - Vehicle dynamics
KW  - Computer architecture
DO  - 10.1109/ICRA.2019.8794380
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents an approach for a car navigation system to follow a road path consisting on a sequence of lanelets. The motion control is divided into high-level planning that produces the road path and lower-level reactive control that safely follows the path. The approach presented here is the lower-level reactive control that combines the simple pure pursuit method to obtain a reference curvature with the beam curvature method (BCM) that keeps the car in the center of the free space in the lane avoiding obstacles that can partially block the lane. The whole system has been applied to an autonomous vehicle aimed for elderly or disable people.
ER  - 

TY  - CONF
TI  - Goal-Driven Navigation for Non-holonomic Multi-Robot System by Learning Collision
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1758
EP  - 1764
AU  - H. W. Jun
AU  - H. J. Kim
AU  - B. H. Lee
PY  - 2019
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - goal-driven navigation
KW  - nonholonomic multirobot system
KW  - learning collision
KW  - reinforcement learning
KW  - multirobot collision avoidance approach
KW  - training agent robots
KW  - agent robot
KW  - trained policy
KW  - multiple obstacle robots
KW  - robot simulation
KW  - robot experiment
KW  - Robots
KW  - Collision avoidance
KW  - Training
KW  - Planning
KW  - Task analysis
KW  - Servers
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8793810
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose the reinforcement learning based multi-robot collision avoidance approach by learning collision. Dynamical path re-planning, which is massively used in classical collision avoidance methods, needs overall information of the environment. Also, training agent robots to avoid the collision and pursue a goal point simultaneously is inefficient since the agent should learn two tasks. As the number of tasks that the agent should learn increases, it is difficult to make the performance of an algorithm consistent, which is known as reproducibility issue. To overcome these limitations, Collision Avoidance by Learning Collision (CALC), which learns collision instead of avoiding an obstacle robot is suggested. To solve the collision avoidance problem efficiently, the proposed method divides the problem into training and planning. In the training algorithm, an agent robot learns how to collide with a single obstacle robot and then generates a trained policy. With the trained policy, the agent can pursue a goal point since the policy leads the agent to `collide' with the goal. Furthermore, by taking action in a reverse way from the trained policy, the agent can avoid multiple obstacle robots in the planning algorithm at once. The proposed method is validated both in the robot simulation and real robot experiment, and compared with the existing collision avoidance method.
ER  - 

TY  - CONF
TI  - Efficient Exact Collision Detection between Ellipsoids and Superquadrics via Closed-form Minkowski Sums
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1765
EP  - 1771
AU  - S. Ruan
AU  - K. L. Poblete
AU  - Y. Li
AU  - Q. Lin
AU  - Q. Ma
AU  - G. S. Chirikjian
PY  - 2019
KW  - collision avoidance
KW  - computational geometry
KW  - convex programming
KW  - mesh generation
KW  - mobile robots
KW  - ellipsoid
KW  - superquadric
KW  - closed-form parametric expression
KW  - general convex differentiable parametric surface
KW  - efficient exact collision detection
KW  - closed-form Minkowski sums
KW  - computer graphics
KW  - robot motion planning
KW  - convex polytopes
KW  - collision detection scheme
KW  - n-dimensional Euclidean space
KW  - principal kinematic formula
KW  - PKF
KW  - Gilbert-Johnson-Keerthi
KW  - GJK
KW  - algebraic separation conditions
KW  - ASC
KW  - meshes
KW  - Ellipsoids
KW  - Collision avoidance
KW  - Shape
KW  - Two dimensional displays
KW  - Three-dimensional displays
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793496
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Collision detection has attracted attention of researchers for decades in the field of computer graphics, robot motion planning, computer aided design, etc. A large number of successful algorithms have been proposed and applied, which make use of convex polytopes and bounding volumes as primitives. However, algorithms for those shapes rely significantly on the complexity of the meshes. This paper deals with collision detection for shapes with simple and exact mathematical descriptions, such as ellipsoids and superquadrics. These primitives have a wide range of applications in representing complex objects and have much fewer parameters than meshes. The foundation of the proposed collision detection scheme relies on the closed-form Minkowski sums between ellipsoids and superquadrics in n-dimensional Euclidean space. The basic idea here is to shrink the ellipsoid into a point and expand each superquadric into a new offset surface with closed-form parametric expression. The solutions for detecting relative positions between a point and a general convex differentiable parametric surface in both 2D and 3D are derived, leading to an algorithm for exact collision detection. To compare between exact and inexact algorithms, an accuracy metric is introduced based on the Principal Kinematic Formula (PKF). The proposed algorithm is then compared with existing wellknown algorithms: Gilbert-Johnson-Keerthi (GJK) and Algebraic Separation Conditions (ASC). The results show that the proposed algorithm performs competitively with these efficient checkers.
ER  - 

TY  - CONF
TI  - Positioning Uncertainty Reduction of Magnetically Guided Actuation on Planar Surfaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1772
EP  - 1778
AU  - M. Juřík
AU  - J. Kuthan
AU  - J. Vlček
AU  - F. Mach
PY  - 2019
KW  - magnetic actuators
KW  - microrobots
KW  - mobile robots
KW  - numerical analysis
KW  - position control
KW  - magnetically guided actuation
KW  - miniature robots
KW  - planar surfaces
KW  - robot actuation
KW  - positioning uncertainty reduction
KW  - actuation superposition
KW  - lock-up field
KW  - numerical analysis
KW  - Coils
KW  - Robots
KW  - Force
KW  - Permanent magnets
KW  - Wires
KW  - Uncertainty
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8794190
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Key design and operation parameters of the system for magnetically guided actuation of miniature robots on planar surfaces are analyzed and discussed. The study is carried out on the numerical analysis and also on the experimental measurement on the prototype of the system. Special attention is paid to robot actuation under uncertainty, which can be caused by both external and internal effects. A technique based on a superposition of actuation and lock-up field is proposed.
ER  - 

TY  - CONF
TI  - Robot Localization Based on Aerial Images for Precision Agriculture Tasks in Crop Fields
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1787
EP  - 1793
AU  - N. Chebrolu
AU  - P. Lottes
AU  - T. Läbe
AU  - C. Stachniss
PY  - 2019
KW  - autonomous aerial vehicles
KW  - crops
KW  - data visualisation
KW  - feature extraction
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - robot localization
KW  - aerial images
KW  - precision agriculture tasks
KW  - crop field environment
KW  - visual aliasing
KW  - localization system
KW  - aerial map
KW  - visual ambiguity problem
KW  - autonomous robots
KW  - Agriculture
KW  - Feature extraction
KW  - Cameras
KW  - Semantics
KW  - Visualization
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8794030
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Localization is a pre-requisite for most autonomous robots. For example, to carry out precision agriculture tasks effectively, a robot must be able to localize itself accurately in crop fields. The crop field environment presents unique challenges such as the highly repetitive structure of the crops leading to visual aliasing as well as the continuously changing appearance of the field, which makes it difficult to localize over time. In this paper, we present a localization system, which uses an aerial map of the field and exploits the semantic information of the crops, weeds, and their stem positions to resolve the visual ambiguity problem and to enable robot localization over extended periods of time. We evaluate our approach on a real field over multiple sessions spanning several weeks. Experiments suggest that our approach provides the necessary accuracy required by precision agriculture applications and works in cases where current techniques using typical visual features tend to fail.
ER  - 

TY  - CONF
TI  - Visual Appearance Analysis of Forest Scenes for Monocular SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1794
EP  - 1800
AU  - J. Garforth
AU  - B. Webb
PY  - 2019
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - robot vision
KW  - SLAM (robots)
KW  - managed forests
KW  - tree health
KW  - SLAM research
KW  - structured human environments
KW  - unstructured forests
KW  - forest data
KW  - photorealistic simulated forest
KW  - straightforward forest terrain
KW  - forest scenes
KW  - natural scenes
KW  - visual appearance analysis
KW  - cheap energy efficient way
KW  - unmanned aerial vehicles
KW  - monocular SLAM systems
KW  - SLAM systems
KW  - visual appearance statistics
KW  - Forestry
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Visualization
KW  - Vegetation
KW  - Feature extraction
KW  - Lighting
DO  - 10.1109/ICRA.2019.8793771
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Monocular simultaneous localisation and mapping (SLAM) is a cheap and energy efficient way to enable Unmanned Aerial Vehicles (UAVs) to safely navigate managed forests and gather data crucial for monitoring tree health. SLAM research, however, has mostly been conducted in structured human environments, and as such is poorly adapted to unstructured forests. In this paper, we compare the performance of state of the art monocular SLAM systems on forest data and use visual appearance statistics to characterise the differences between forests and other environments, including a photorealistic simulated forest. We find that SLAM systems struggle with all but the most straightforward forest terrain and identify key attributes (lighting changes and in-scene motion) which distinguish forest scenes from “classic” urban datasets. These differences offer an insight into what makes forests harder to map and open the way for targeted improvements. We also demonstrate that even simulations that look impressive to the human eye can fail to properly reflect the difficult attributes of the environment they simulate, and provide suggestions for more closely mimicking natural scenes.
ER  - 

TY  - CONF
TI  - An Approach for Semantic Segmentation of Tree-like Vegetation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1801
EP  - 1807
AU  - S. Tejaswi Digumarti
AU  - L. M. Schmid
AU  - G. M. Rizzi
AU  - J. Nieto
AU  - R. Siegwart
AU  - P. Beardsley
AU  - C. Cadena
PY  - 2019
KW  - convolutional neural nets
KW  - forestry
KW  - image classification
KW  - image colour analysis
KW  - image fusion
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - vegetation
KW  - semantic segmentation
KW  - tree-like vegetation
KW  - pipeline
KW  - single RGB-D image
KW  - deep network
KW  - multiple convolutional neural network architectures
KW  - colour data
KW  - asynchronous training approach
KW  - 3-channel HHA image
KW  - late fusion architecture
KW  - synthetic dataset
KW  - broadleaf trees
KW  - tree species
KW  - Vegetation
KW  - Image segmentation
KW  - Image color analysis
KW  - Semantics
KW  - Vegetation mapping
KW  - Training
KW  - Robots
DO  - 10.1109/ICRA.2019.8793576
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a pipeline for semantic segmentation of trees into their components. Given a single RGB-D image of a tree, we employ a deep network to predict labels to classify each pixel of the tree into trunk, branches, twigs and leaves. Multiple convolutional neural network architectures to combine the complementary modalities of depth and colour data are investigated. An asynchronous training approach where two networks trained separately on RGB and depth encoded as a 3-channel HHA image are combined using a late fusion architecture with different learning rates performs the best. Training and evaluation are performed on a synthetic dataset of 6 species of broadleaf trees. We further demonstrate the network's generalization capabilities, across various tree species on the synthetic dataset, achieving an accuracy of upto 92.5%. Furthermore, we present a qualitative evaluation of our approach on real-world data.
ER  - 

TY  - CONF
TI  - Thermal Image Based Navigation System for Skid-Steering Mobile Robots in Sugarcane Crops*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1808
EP  - 1814
AU  - M. F. S. Xaud
AU  - A. C. Leite
AU  - P. J. From
PY  - 2019
KW  - agricultural machinery
KW  - agriculture
KW  - crops
KW  - Global Positioning System
KW  - infrared imaging
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - thermal image
KW  - navigation system
KW  - skid-steering mobile robots
KW  - sugarcane crops
KW  - autonomous navigation
KW  - sugarcane plantations
KW  - ordinary agricultural fields
KW  - sugarcane farms
KW  - row crop tunnels
KW  - low-cost skid-steering mobile robot
KW  - bioenergy farm
KW  - infrared thermal imaging
KW  - laser-based sensors
KW  - image analysis
KW  - navigation methodology
KW  - robot swarm
KW  - tankette for intelligent bioenergy agriculture
KW  - Agriculture
KW  - Robot kinematics
KW  - Navigation
KW  - Mobile robots
KW  - Computed tomography
KW  - Image color analysis
DO  - 10.1109/ICRA.2019.8794354
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work proposes a new strategy for autonomous navigation of mobile robots in sugarcane plantations based on thermal imaging. Unlike ordinary agricultural fields, sugarcane farms are generally vast and accommodates numerous arrangements of row crop tunnels, which are very tall, dense and hard-to-access. Moreover, sugarcane crops lie in harsh regions, which hinder the logistics for employing staff and heavy machinery for mapping, monitoring, and sampling. One solution for this problem is TIBA (Tankette for Intelligent BioEnergy Agriculture), a low-cost skid-steering mobile robot capable of infiltrating the crop tunnels with several sensing/sampling systems. The project concept is to reduce the product cost for making the deployment of a robot swarm feasible over a larger area. A prototype was built and tested in a bioenergy farm in order to improve the understanding of the environment and bring about the challenges for the next development steps. The major problem is the navigation through the crop tunnels, since most of the developed systems are suitable for open field operations and employ laser scanners and/or GPS/IMU, which in general are expensive technologies. In this context, we propose a low-cost solution based on infrared (IR) thermal imaging. IR cameras are simple and inexpensive devices, which do not pose risks to the user health, unlike laser-based sensors. This idea was highly motivated by the data collected in the field, which have shown a significant temperature difference between the ground and the crop. From the image analysis, it is possible to clearly visualize a distinguishable corridor and, consequently, generate a straight path for the robot to follow by using computationally efficient approaches. A rigorous analysis of the collected thermal data, numerical simulations and preliminary experiments in the real environment were included to illustrate the efficiency and feasibility of the proposed navigation methodology.
ER  - 

TY  - CONF
TI  - Dynamic Obstacles Detection for Robotic Soil Explorations*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1815
EP  - 1820
AU  - F. Visentin
AU  - A. Sadeghi
AU  - B. Mazzolai
PY  - 2019
KW  - collision avoidance
KW  - feedback
KW  - force sensors
KW  - mobile robots
KW  - complex environment
KW  - dynamic obstacles detection
KW  - 6-axis force torque sensor
KW  - plant-inspired robot
KW  - soil exploration
KW  - complex environments
KW  - dynamic environments
KW  - robotic soil explorations
KW  - Soil
KW  - Robot sensing systems
KW  - Navigation
KW  - Force measurement
KW  - Shafts
KW  - Force
DO  - 10.1109/ICRA.2019.8794470
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Nowadays, robots can navigate complex and dynamic environments such as air, water, and different terrain. However, moving into the underground, and especially into the soil, is still a challenge. Soil is a complex environment, and its exploration and monitoring is a crucial aspect in different engineering fields. Although some robotic solutions for mapping the soil are available, none of them can navigate into it. In this work, we propose a new solution for dynamic obstacles detection by embedding a 6-axis force torque sensor into a plant-inspired robot for soil exploration. We measured the forces acting on the apical part of the robot while it penetrates the soil by growing. We tested the system in different configurations, and at different depths. Results show that it is possible to identify the relative position of the obstacle before touching it with the robot. By using the proposed method as control feedback it is possible to move toward the development of novel robotic systems for navigating in complex and dynamic environments, such as the soil.
ER  - 

TY  - CONF
TI  - Non-Destructive Robotic Assessment of Mango Ripeness via Multi-Point Soft Haptics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1821
EP  - 1826
AU  - L. Scimeca
AU  - P. Maiolino
AU  - D. Cardin-Catalan
AU  - A. P. d. Pobil
AU  - A. Morales
AU  - F. Iida
PY  - 2019
KW  - agricultural products
KW  - agricultural robots
KW  - capacitive sensors
KW  - food products
KW  - grippers
KW  - nondestructive testing
KW  - sensor arrays
KW  - standards
KW  - tactile sensors
KW  - waste reduction
KW  - nondestructive robotic assessment
KW  - mango ripeness
KW  - multipoint soft haptics
KW  - destructive fruit ripeness estimation
KW  - capacitive tactile sensor array
KW  - mango stiffness
KW  - penetrometer measurements
KW  - automatic method
KW  - surface areas
KW  - fresh product standards
KW  - waste reduction
KW  - custom-made gripper
KW  - simplified spring model
KW  - Keitt variety
KW  - Grippers
KW  - Tactile sensors
KW  - Springs
KW  - Force
KW  - Skin
DO  - 10.1109/ICRA.2019.8793956
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To match the ever increasing standards of fresh products, and the need to reduce waste, we devise an alternative to the destructive and highly variable fruit ripeness estimation by a penetrometer. We propose a fully automatic method to assess the ripeness of mango which is non-destructive, allows the user to test multiple surface areas with a single touch and is capable of dissociating between ripe and non-ripe fruits. A custom-made gripper equipped with a capacitive tactile sensor array is used to palpate the fruit. The ripeness is estimated as mango stiffness extracted through a simplified spring model. We test the framework on a set of 25 mangoes of the Keitt variety, and compare the results to penetrometer measurements. We show it is possible to correctly classify 88% of the mango without removing the skin of the fruit. The method can be a valuable substitute for non-destructive fruit ripeness testing. To the authors knowledge, this is the first robotics ripeness estimation system based on capacitive tactile sensing technology.
ER  - 

TY  - CONF
TI  - UAV Pose Estimation using Cross-view Geolocalization with Satellite Imagery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1827
EP  - 1833
AU  - A. Shetty
AU  - G. X. Gao
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - Kalman filters
KW  - neural nets
KW  - pose estimation
KW  - unseen images
KW  - visual odometry
KW  - trajectory estimation errors
KW  - UAV pose estimation
KW  - image-based cross-view geolocalization method
KW  - georeferenced satellite imagery
KW  - Siamese neural networks
KW  - UAV camera
KW  - satellite images
KW  - crossview geolocalization
KW  - Satellites
KW  - Geology
KW  - Cameras
KW  - Feature extraction
KW  - Training
KW  - Visual odometry
KW  - Google
DO  - 10.1109/ICRA.2019.8794228
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose an image-based cross-view geolocalization method that estimates the global pose of a UAV with the aid of georeferenced satellite imagery. Our method consists of two Siamese neural networks that extract relevant features despite large differences in viewpoints. The input to our method is an aerial UAV image and nearby satellite images, and the output is the weighted global pose estimate of the UAV camera. We also present a framework to integrate our crossview geolocalization output with visual odometry through a Kalman filter. We build a dataset of simulated UAV images and satellite imagery to train and test our networks. We show that our method performs better than previous camera pose estimation methods, and we demonstrate our networks ability to generalize well to test datasets with unseen images. Finally, we show that integrating our method with visual odometry significantly reduces trajectory estimation errors.
ER  - 

TY  - CONF
TI  - The Open Vision Computer: An Integrated Sensing and Compute System for Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1834
EP  - 1840
AU  - M. Quigley
AU  - K. Mohta
AU  - S. S. Shivakumar
AU  - M. Watterson
AU  - Y. Mulgaonkar
AU  - M. Arguedas
AU  - K. Sun
AU  - S. Liu
AU  - B. Pfrommer
AU  - V. Kumar
AU  - C. J. Taylor
PY  - 2019
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - microrobots
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - Falcon 250 quadrotor platform
KW  - vision guided autonomous drone flight
KW  - mobile robots
KW  - integrated sensing
KW  - open vision computer
KW  - navigation operations
KW  - outdoor exploration
KW  - OVC system
KW  - computational performance
KW  - power consumption
KW  - relatively small-scale flying platforms
KW  - Field programmable gate arrays
KW  - Image sensors
KW  - Streaming media
KW  - Robot sensing systems
KW  - Aircraft navigation
KW  - Sensor arrays
DO  - 10.1109/ICRA.2019.8794472
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we describe the Open Vision Computer (OVC) which was designed to support high speed, vision guided autonomous drone flight. In particular our aim was to develop a system that would be suitable for relatively small-scale flying platforms where size, weight, power consumption and computational performance were all important considerations. This manuscript describes the primary features of our OVC system and explains how they are used to support fully autonomous indoor and outdoor exploration and navigation operations on our Falcon 250 quadrotor platform.
ER  - 

TY  - CONF
TI  - RaD-VIO: Rangefinder-aided Downward Visual-Inertial Odometry
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1841
EP  - 1847
AU  - B. Fu
AU  - K. S. Shankar
AU  - N. Michael
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cameras
KW  - mobile robots
KW  - robot vision
KW  - common local planarity assumption
KW  - frame-to-frame visual-inertial odometry algorithm
KW  - downward facing cameras
KW  - RaD-VIO
KW  - cost function
KW  - rangefinder-aided downward visual-inertial odometry
KW  - complementary odometry algorithm
KW  - IMU regularisation term
KW  - homography based photometric cost
KW  - microaerial vehicles
KW  - Cameras
KW  - Optimization
KW  - Visualization
KW  - Laser beams
KW  - Reliability
KW  - Angular velocity
DO  - 10.1109/ICRA.2019.8793741
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - State-of-the-art forward facing monocular visual-inertial odometry algorithms are often brittle in practice, especially whilst dealing with initialisation and motion in directions that render the state unobservable. In such cases having a reliable complementary odometry algorithm enables robust and resilient flight. Using the common local planarity assumption, we present a fast, dense, and direct frame-to-frame visual-inertial odometry algorithm for downward facing cameras that minimises a joint cost function involving a homography based photometric cost and an IMU regularisation term. Via extensive evaluation in a variety of scenarios we demonstrate superior performance than existing state-of-the-art downward facing odometry algorithms for Micro Aerial Vehicles (MAVs).
ER  - 

TY  - CONF
TI  - Learning to Capture a Film-Look Video with a Camera Drone
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1871
EP  - 1877
AU  - C. Huang
AU  - Z. Yang
AU  - Y. Kong
AU  - P. Chen
AU  - X. Yang
AU  - K. T. Cheng
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - decision making
KW  - image capture
KW  - image sensors
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - object tracking
KW  - robot vision
KW  - video cameras
KW  - video signal processing
KW  - film-look video
KW  - camera drone
KW  - intelligent drones
KW  - smarter assistant tools
KW  - autonomous aerial filming
KW  - camera motion planning
KW  - cinematic footages
KW  - film-look aerial footage
KW  - camera position
KW  - automatic filming onboard
KW  - data-driven planning approach
KW  - image composition
KW  - data-driven learning-based approach
KW  - professional cameramans intention
KW  - decision-making process
KW  - Cameras
KW  - Drones
KW  - Training
KW  - Skeleton
KW  - Streaming media
KW  - Two dimensional displays
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8793915
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The development of intelligent drones has simplified aerial filming and provided smarter assistant tools for users to capture a film-look footage. Existing methods of autonomous aerial filming either specify predefined camera movements for a drone to capture a footage, or employ heuristic approaches for camera motion planning. However, both predefined movements and heuristically planned motions are hardly able to provide cinematic footages for various dynamic scenarios. In this paper, we propose a data-driven learning-based approach, which can imitate a professional cameraman's intention for capturing a film-look aerial footage of a single subject in real-time. We model the decision-making process of the cameraman with two steps: 1) we train a network to predict the future image composition and camera position, and 2) our system then generates control commands to achieve the desired shot framing. At the system level, we deploy our algorithm on the limited resources of a drone and demonstrate the feasibility of running automatic filming onboard in real-time. Our experiments show how our data-driven planning approach achieves film-look footages and successfully mimics the work of a professional cameraman.
ER  - 

TY  - CONF
TI  - Design and Experiments for MultI-Section-Transformable (MIST)-UAV
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1878
EP  - 1883
AU  - R. D’Sa
AU  - N. Papanikolopoulos
PY  - 2019
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multiple sequential transformations
KW  - shape-shifting transformation
KW  - MIST-UAV
KW  - in-air transformation
KW  - multirotor
KW  - multisection-transformable-UAV
KW  - transformable vertical take off and landing UAV
KW  - transformable VTOL UAV
KW  - tail-sitter
KW  - fixed-wing operation
KW  - Fasteners
KW  - Propulsion
KW  - Mathematical model
KW  - Attitude control
KW  - Batteries
KW  - Actuators
KW  - Servomotors
DO  - 10.1109/ICRA.2019.8793575
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Presented in this paper are the design and experiments for a transformable Vertical Take Off and Landing (VTOL) UAV. This work demonstrates shape-shifting transformation, building upon the conceptual designs put forth in [1] and [2], along with hardware prototyping and component testing from [3]. A deterministic model is presented to characterize the flight of the MIST-UAV in simulation. Experimental results from the platform demonstrate for the first time successful in-air transformation from multi-rotor, tail-sitter, and fixed-wing operation. Experiments also validated transformation repeatability, successfully testing multiple sequential transformations.
ER  - 

TY  - CONF
TI  - Online Estimation of Geometric and Inertia Parameters for Multirotor Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1884
EP  - 1890
AU  - V. Wüest
AU  - V. Kumar
AU  - G. Loianno
PY  - 2019
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multi-robot systems
KW  - nonlinear control systems
KW  - observers
KW  - robust control
KW  - multirotor aerial vehicles
KW  - moment of inertia
KW  - center of mass
KW  - nonlinear observability analysis
KW  - load transportation
KW  - motor speed
KW  - aerial vehicles
KW  - robust control
KW  - precise control
KW  - inertia parameters
KW  - Rotors
KW  - Vehicle dynamics
KW  - Estimation
KW  - Quaternions
KW  - Real-time systems
KW  - Task analysis
KW  - Transportation
DO  - 10.1109/ICRA.2019.8794274
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate knowledge of geometric and inertia parameters are a necessity for precise and robust control of aerial vehicles. We propose a novel filter that is able to fuse motor speed, inertia, and pose measurements to estimate the vehicle's key dynamic properties online. The presented framework is able to estimate the multirotor's moment of inertia, mass, center of mass and each sensor module's relative position. Obtaining these estimates in-flight allow the multirotor to be precisely controlled even during tasks such as load transportation or after configuration changes on scene. We provide a nonlinear observability analysis, proving that the presented model is locally weakly observable. Experimental results validate the proposed approach, showing the ability to estimate the dynamic properties accurately and demonstrate its capability to do so even while additional loads are added. The framework is flexible and can easily be adapted to a wide range of applications, including self-calibration, object grasping, and single robot or multi-robot payload transportation.
ER  - 

TY  - CONF
TI  - External Wrench Estimation for Multilink Aerial Robot by Center of Mass Estimator Based on Distributed IMU System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1891
EP  - 1897
AU  - F. Shi
AU  - M. Zhao
AU  - T. Anzai
AU  - X. Chen
AU  - K. Okada
AU  - M. Inaba
PY  - 2019
KW  - aerospace robotics
KW  - collision avoidance
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - robot dynamics
KW  - sensors
KW  - external wrench estimation
KW  - mass estimator
KW  - distributed IMU system
KW  - aerial exploration
KW  - external force
KW  - torque
KW  - aerial manipulation tasks
KW  - aerial multilink robot
KW  - onboard inertial measurement unit sensors
KW  - two-dimensional multilink aerial robot
KW  - external wrench estimator
KW  - contact point
KW  - motion primitives library
KW  - robot dynamic models
KW  - acceleration data
KW  - Acceleration
KW  - Estimation
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794325
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - External wrench estimation is very helpful for aerial exploration and manipulation tasks. During the exploration, there might be unseen obstacles to cause dangerous collisions. The estimation of the external force and torque is also beneficial in aerial manipulation tasks. In this paper, we present a framework of estimating the external wrench for the aerial multilink robot based on the onboard inertial measurement unit (IMU) sensors, joints state and robot dynamic models. Compared to the conventional multirotor robot, the center of mass (CoM) is always changing when the robot transforms. The sensor could not be attached to CoM to observe the acceleration data. Consequently, we present a novel method by applying a distributed IMU system to estimate the CoM linear and angular accelerations for the external wrench estimation. With the help of the robot model, the position of the contact point could be estimated, which is useful in exploring tasks to safely interact with the physical world. We design the contact-aided navigation strategy and computationally efficient motion primitives library to help our robot react to the unexpected collision. We experimentally validate our framework with a two-dimensional multilink aerial robot to show the results of external wrench estimator and its further applications2.2Experiment video: https://youtu.be/R-WDReLnWWI
ER  - 

TY  - CONF
TI  - A Novel Development of Robots with Cooperative Strategy for Long-term and Close-proximity Autonomous Transmission-line Inspection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1898
EP  - 1904
AU  - J. Bian
AU  - X. Hui
AU  - X. Zhao
AU  - M. Tan
PY  - 2019
KW  - automatic optical inspection
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - inspection
KW  - laser ranging
KW  - mobile robots
KW  - power overhead lines
KW  - robot vision
KW  - sensors
KW  - service robots
KW  - close-proximity autonomous transmission-line inspection
KW  - power transmission lines inspection
KW  - overhead ground wire
KW  - OGW
KW  - sensor data collection
KW  - unmanned aerial vehicle
KW  - grabbing mechanism
KW  - mechanical structures
KW  - autonomous navigation
KW  - 2D Laser Range Finder
KW  - LRF
KW  - CBR platforms
KW  - artificially constructed PTLs environment outdoors
KW  - high inspection accuracy
KW  - close-proximity inspection
KW  - long-term inspection
KW  - Inspection
KW  - Three-dimensional displays
KW  - Unmanned aerial vehicles
KW  - Microswitches
KW  - Delay effects
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793559
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We develop two cooperative robots for power transmission lines (PTLs) inspection - a light climbing robot (CBR) which can stably move on the overhead ground wire (OGW) for sensor data collection and an unmanned aerial vehicle (UAV) with a grabbing mechanism, which can automatically put the CBR on the OGW and take it off. In order to guarantee the safety, the mechanical structures of the connectors are designed in the shape of a trumpet. Further, a self-locked structure of the CBR is developed to automatically seize and release the OGW. For autonomous navigation, the UAV is equipped with a movable sliding rail and a 2D Laser Range Finder (LRF). The LRF can not only detect the position and orientation of the OGW but also detect the top beam of the CBR and the grabbing position in it. Furthermore, the action of the grabbing mechanism is automatically triggered by a microswitch. Finally, by the developed UAV and CBR platforms, we test the whole loading and unloading strategy in an artificially constructed PTLs environment outdoors and achieve an encouraging result1. Combining the flexible motion of the UAV and the high inspection accuracy of the CBR, the CBR can negotiate any obstacle by flying and abandon the traditional heavy obstacle crossing mechanism to effectively realize close-proximity inspection. Due to the light weight and low power consumption, the CBRs can be deployed once in many power corridors to conduct a long-term inspection.
ER  - 

TY  - CONF
TI  - Hunting Drones with Other Drones: Tracking a Moving Radio Target
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1905
EP  - 1912
AU  - L. Dressel
AU  - M. J. Kochenderfer
PY  - 2019
KW  - aerospace communication
KW  - aerospace robotics
KW  - mobile radio
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - target tracking
KW  - telemetry
KW  - moving radio target
KW  - unauthorized drone flights
KW  - antennas
KW  - commodity radios
KW  - telemetry radio emissions
KW  - passenger safety
KW  - bystander safety
KW  - Drones
KW  - Antenna measurements
KW  - Telemetry
KW  - Target tracking
KW  - Antennas
KW  - Aircraft
KW  - Radio frequency
DO  - 10.1109/ICRA.2019.8794243
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Unauthorized drone flights near aircraft, airports, and emergency operations compromise the safety of passengers and bystanders. A detection system that can quickly find and track drones could help mitigate the risk of unauthorized drone flights. In this work, we show how a consumer drone outfitted with antennas and commodity radios can autonomously localize another drone by its telemetry radio emissions. We show how a non-myopic planner improves tracking performance over traditionally used greedy, one-step planners. Improved tracking is validated with simulations and the system is demonstrated with real drones in flight tests.
ER  - 

TY  - CONF
TI  - Design and Testing of a New Cell Microinjector with Embedded Soft Force Sensor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1913
EP  - 1918
AU  - Y. Wei
AU  - Q. Xu
PY  - 2019
KW  - cellular biophysics
KW  - force sensors
KW  - medical control systems
KW  - embedded soft force sensor
KW  - manual cell microinjection
KW  - position-based robotic cell microinjection
KW  - force-assisted robotic cell microinjection
KW  - survival rate
KW  - piezoresistive force sensor
KW  - soft materials
KW  - soft sensors
KW  - force measurement
KW  - force-sensing cell injector
KW  - Force sensors
KW  - Piezoresistance
KW  - Force
KW  - Force measurement
KW  - Microinjection
KW  - Prototypes
DO  - 10.1109/ICRA.2019.8793469
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Cell microinjection plays an important role in genetics, transgenics, and other biomedical fields. As compared with manual cell microinjection and position-based robotic cell microinjection, force-assisted robotic cell microinjection can improve the success rate and survival rate of the injected cells. In this paper, a novel force-sensing cell injector is designed with piezoresistive force sensor embedded in soft materials. The soft sensors act as fixed-guided beams, which are introduced to achieve the force measurement with high sensitivity in pure one-degree-of-freedom (1-DOF) direction. The injector is developed by considering the installation and replacement issues of the micropipette as well as the connection convenience between the micropipette and tube of compressed air. A prototype of the cell injector with the force sensor is fabricated. Experimental study is conducted to verify its performance in practice.
ER  - 


TY  - CONF
TI  - Energy optimization for a Robust and Flexible Interaction Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1919
EP  - 1925
AU  - C. Secchi
AU  - F. Ferraguti
PY  - 2019
KW  - humanoid robots
KW  - human-robot interaction
KW  - optimisation
KW  - stability
KW  - tanks (containers)
KW  - admittance controllers
KW  - energy optimization problem
KW  - interactive behavior
KW  - stable interaction
KW  - robot interaction
KW  - admittance control strategy
KW  - Admittance
KW  - Optimization
KW  - Dynamics
KW  - Manipulators
KW  - Collaboration
KW  - Buildings
DO  - 10.1109/ICRA.2019.8794055
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The possibility of adapting online the way a robot interacts with the environment is becoming more and more important. In this paper we introduce the tank based admittance controller. We show that all the admittance controllers can be modeled as an energy optimization problem and then we introduce a novel admittance control strategy that allows to change online the interactive behavior while preserving a stable interaction with the environment. The effectiveness of the proposed architecture is experimentally validated.
ER  - 

TY  - CONF
TI  - Design of Versatile and Low-Cost Shaft Sensor for Health Monitoring
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1926
EP  - 1932
AU  - E. Gest
AU  - M. Furokawa
AU  - T. Hirano
AU  - K. Youcef-Toumi
PY  - 2019
KW  - bending
KW  - condition monitoring
KW  - power transmission (mechanical)
KW  - prototypes
KW  - shafts
KW  - strain sensors
KW  - torque measurement
KW  - velocity measurement
KW  - vibration measurement
KW  - design engineering
KW  - transportation
KW  - torque measurement
KW  - speed measurement
KW  - vibration measurement
KW  - bending measurement
KW  - strain sensor
KW  - prototype
KW  - mechanical power transmission
KW  - rotating shafts
KW  - robotic system
KW  - industrial equipment
KW  - power generation system
KW  - health monitoring
KW  - low-cost shaft sensor
KW  - Shafts
KW  - Torque
KW  - Strain
KW  - Bridges
KW  - Strain measurement
KW  - Robot sensing systems
KW  - Torque measurement
DO  - 10.1109/ICRA.2019.8794408
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Virtually every mechanized form of transportation, power generation system, industrial equipment, and robotic system has rotating shafts. As the shaft is often the main means of mechanical power transmission, measuring the torque, speed, vibration, and bending of the shaft can be used in many cases to access device performance and health and to implement controls. This paper proposes a shaft sensor that measures all of these phenomena with reasonable accuracy while having a low cost and simple installation process. This sensor transfers strain from the shaft and amplifies it to increase sensitivity. Furthermore, this sensor requires no components to be in the stationary reference frame, allowing the entire device to rotate with the shaft. A prototype is presented. Experimental results illustrate the effectiveness of the proposed system.
ER  - 

TY  - CONF
TI  - Robust Execution of Contact-Rich Motion Plans by Hybrid Force-Velocity Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1933
EP  - 1939
AU  - Y. Hou
AU  - M. T. Mason
PY  - 2019
KW  - control system synthesis
KW  - force control
KW  - industrial manipulators
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - trajectory control
KW  - velocity control
KW  - robust execution
KW  - contact-rich motion plans
KW  - trajectory hybrid servoing
KW  - hybrid force-velocity control actions
KW  - control synthesis
KW  - positional errors
KW  - optimization problems
KW  - contact-rich manipulation tasks
KW  - Robots
KW  - Force
KW  - Force control
KW  - Aerospace electronics
KW  - Collision avoidance
KW  - Planning
KW  - Velocity control
DO  - 10.1109/ICRA.2019.8794366
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In hybrid force-velocity control, the robot can use velocity control in some directions to follow a trajectory, while performing force control in other directions to maintain contacts with the environment regardless of positional errors. We call this way of executing a trajectory hybrid servoing. We propose an algorithm to compute hybrid force-velocity control actions for hybrid servoing. We quantity the robustness of a control action and make trade-offs between different requirements by formulating the control synthesis as optimization problems. Our method can efficiently compute the dimensions, directions and magnitudes of force and velocity controls. We demonstrated by experiments the effectiveness of our method in several contact-rich manipulation tasks. Link to the video: https://youtu.be/KtSNmvwOenM.
ER  - 

TY  - CONF
TI  - Endoscope Force Generation and Intrinsic Sensing with Environmental Scaffolding
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1940
EP  - 1946
AU  - J. E. Bernth
AU  - J. Back
AU  - G. Abrahams
AU  - L. Lindenroth
AU  - B. Hayee
AU  - H. Liu
PY  - 2019
KW  - actuators
KW  - cantilevers
KW  - endoscopes
KW  - force control
KW  - manipulator dynamics
KW  - medical robotics
KW  - skin
KW  - surgery
KW  - cantilevered configuration
KW  - environmental scaffolding
KW  - contact forces
KW  - tip force estimation
KW  - actuation forces
KW  - skin wounds
KW  - laparoscopic techniques
KW  - endoscopic surgery
KW  - intrinsic sensing
KW  - endoscope force generation
KW  - Endoscopes
KW  - Tendons
KW  - Force
KW  - Shape
KW  - Robot sensing systems
KW  - Endoscopes
KW  - Finite element analysis
KW  - Intrinsic force measurement
KW  - Minimally invasive surgery
DO  - 10.1109/ICRA.2019.8793726
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Endoscopic surgery is an increasingly popular alternative to laparoscopic techniques for many conditions, as the operation site can be reached without skin wounds. In many tasks, sufficient force generation is desired. As endoscopes must be highly flexible and slim, however, the force generation and sensing capabilities associated with these tools is limited due their compliance, significantly hindering the adoption rate of endoscopic surgeries. This paper proposes a technique, termed `environmental scaffolding', to stabilize an actuated, flexible segment in the intestine such that larger forces can be applied. Through the measurement of actuation forces, a method for intrinsically sensing multiple contact forces when in this configuration is presented. Experimental results show that with the environmental scaffolding technique, the tip force generated can be increased by over 50% on average compared to using the device in a purely cantilevered configuration, and the tip force estimation is accurate to within 2.97%.
ER  - 

TY  - CONF
TI  - On The Combination of Gamification and Crowd Computation in Industrial Automation and Robotics Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1955
EP  - 1961
AU  - T. Bewley
AU  - M. Liarokapis
PY  - 2019
KW  - cognition
KW  - computer games
KW  - human computer interaction
KW  - mobile robots
KW  - cognitive versatility
KW  - industrial automation
KW  - robotics applications
KW  - human-machine collaboration
KW  - gamification
KW  - video games
KW  - human workers
KW  - autonomous intelligent systems
KW  - crowd computation
KW  - Crowdsourcing
KW  - Games
KW  - Task analysis
KW  - Service robots
KW  - Automation
KW  - Collaboration
DO  - 10.1109/ICRA.2019.8794040
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous intelligent systems outperform human workers in an expanding range of domains, typically those in which success is a function of speed, precision and repeatability. However, many cognitive tasks remain beyond the reach of automation. In this work, we propose the use of video games to crowdsource the cognitive versatility and creativity of human players to solve complex problems in industrial automation and robotics applications. To do so, we introduce a theoretical framework in which robotics problems are embedded into video game environments and gameplay from crowds of players is aggregated to inform robot actions. Such a framework could enable a future of synergistic human-machine collaboration for industrial automation, in which members of the public not only freely offer the fruits of their intelligent reasoning for productive use, but have fun whilst doing so. There is also potential for significant negative consequences surrounding safety, accountability and ethics if great care is not taken in the implementation. Further work is needed to explore these wider implications, as well as to develop the technical theory behind the framework and build prototype applications.
ER  - 

TY  - CONF
TI  - A New Overloading Fatigue Model for Ergonomic Risk Assessment with Application to Human-Robot Collaboration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1962
EP  - 1968
AU  - M. Lorenzini
AU  - W. Kim
AU  - E. D. Momi
AU  - A. Ajoudani
PY  - 2019
KW  - biomechanics
KW  - electromyography
KW  - ergonomics
KW  - fatigue
KW  - human-robot interaction
KW  - injuries
KW  - medical disorders
KW  - medical robotics
KW  - occupational health
KW  - occupational safety
KW  - patient monitoring
KW  - risk analysis
KW  - work-related musculoskeletal disorders
KW  - electromyography analysis
KW  - overloading fatigue model
KW  - risk factors
KW  - excessive fatigue accumulation
KW  - HRC framework
KW  - painting task
KW  - fatigue ratio parameter
KW  - joint torque variations
KW  - robot assistance
KW  - body posture optimisation procedure
KW  - human-robot collaboration framework
KW  - light payloads
KW  - overloading torque
KW  - cumulative effect
KW  - whole-body fatigue model
KW  - human joints
KW  - severe injuries
KW  - local muscle fatigue
KW  - light-weight tools
KW  - monotonous movements
KW  - WMSD
KW  - ergonomic risk assessment
KW  - Fatigue
KW  - Torque
KW  - Task analysis
KW  - Muscles
KW  - Load modeling
KW  - Tools
KW  - Robots
DO  - 10.1109/ICRA.2019.8794044
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Among the numerous risk factors associated to work-related musculoskeletal disorders (WMSD), repetitive and monotonous movements with light-weight tools are one of the most frequently cited. Such tasks may indeed result in the excessive accumulation of local muscle fatigue, causing severe injuries in human joints. Accordingly, this paper proposes a new whole-body fatigue model to evaluate the cumulative effect of the overloading torque induced on the joints over time by light payloads. The proposed model is then integrated into a human-robot collaboration (HRC) framework to set the timing of a body posture optimisation procedure guided by the robot assistance, by the time fatigue overcomes a threshold in any joint. Our overloading fatigue model is based on an estimation method we developed in a previous work, to monitor joint torque variations due to external forces in real-time. To account for individuals' different perception of fatigue, the fatigue ratio parameter in the model is computed experimentally for each subject. The proposed model is first studied on ten subjects by means of an electromyography analysis. Next, its performance is assessed in a painting task and finally evaluated within the HRC framework, which is proved to be able to reduce the risk of injuries caused by excessive fatigue accumulation.
ER  - 

TY  - CONF
TI  - Human-inspired balance model to account for foot-beam interaction mechanics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1969
EP  - 1974
AU  - J. Lee
AU  - M. E. Huber
AU  - E. Chiovetto
AU  - M. Giese
AU  - D. Sternad
AU  - N. Hogan
PY  - 2019
KW  - legged locomotion
KW  - nonlinear control systems
KW  - pendulums
KW  - stability
KW  - human-inspired balance model
KW  - foot-beam interaction mechanics
KW  - bipedal robots
KW  - mediolateral balance
KW  - foot-beam interaction dynamics
KW  - human balancing behavior
KW  - human controller
KW  - whole-body behavior
KW  - balance controllers
KW  - foot contact conditions
KW  - foot-ground interaction dynamics
KW  - double inverted pendulum model
KW  - Foot
KW  - Torque
KW  - Robot kinematics
KW  - Mathematical model
KW  - Task analysis
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8793981
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The locomotion and balance capabilities of bipedal robots have greatly improved in recent years. However, maintaining balance on difficult terrain still poses a significant challenge. In this paper, we examined how humans maintain mediolateral balance when standing on a narrow beam with bare feet and wearing rigid soles. Our results show that foot-beam interaction dynamics critically influence balancing behavior. Importantly, this suggests that differences in human balancing behavior across different support surfaces may not solely result from changes in their neural control strategy. They may also result from changes in foot-ground interaction. Thus, the altered foot-ground interaction dynamics must be considered to accurately capture changes in the human controller across different support surfaces. A simplified model of foot-beam interaction was added to a double inverted pendulum model for human balancing. This extended model could replicate the change in human behavior across different foot contact conditions (bare feet vs. rigid feet). A better understanding of how humans coordinate whole-body behavior across a range of conditions may inform the development of balance controllers for bipedal robots.
ER  - 

TY  - CONF
TI  - Real-time Robot-assisted Ergonomics*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1975
EP  - 1981
AU  - A. Shafti
AU  - A. Ataka
AU  - B. U. Lazpita
AU  - A. Shiva
AU  - H. A. Wurdemann
AU  - K. Althoefer
PY  - 2019
KW  - ergonomics
KW  - human-robot interaction
KW  - image colour analysis
KW  - pose estimation
KW  - real-time systems
KW  - human-robot relative position
KW  - human ergonomics
KW  - human-robot interaction
KW  - cooperative robot movements
KW  - real-time robot-assisted ergonomics
KW  - human user posture
KW  - RGB-D camera
KW  - Ergonomics
KW  - Service robots
KW  - Robot sensing systems
KW  - Wrist
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793739
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes a novel approach in human-robot interaction driven by ergonomics. With a clear focus on optimising ergonomics, the approach proposed here continuously observes a human user's posture and by invoking appropriate cooperative robot movements, the user's posture is, whenever required, brought back to an ergonomic optimum. Effectively, the new protocol optimises the human-robot relative position and orientation as a function of human ergonomics. An RGB-D camera is used to calculate and monitor human joint angles in real-time and to determine the current ergonomics state. A total of 6 main causes of low ergonomic states are identified, leading to 6 universal robot responses to allow the human to return to an optimal ergonomics state. The algorithmic framework identifies these 6 causes and controls the cooperating robot to always adapt the environment (e.g. change the pose of the workpiece) in a way that is ergonomically most comfortable for the interacting user. Hence, human-robot interaction is continuously re-evaluated optimizing ergonomics states. The approach is validated through an experimental study, based on established ergonomic methods and their adaptation for real-time application. The study confirms improved ergonomics using the new approach.
ER  - 

TY  - CONF
TI  - A Fog Robotic System for Dynamic Visual Servoing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1982
EP  - 1988
AU  - N. Tian
AU  - A. K. Tanwani
AU  - J. Chen
AU  - M. Ma
AU  - R. Zhang
AU  - B. Huang
AU  - K. Goldberg
AU  - S. Sojoudi
PY  - 2019
KW  - cloud computing
KW  - control engineering computing
KW  - Internet
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - object recognition
KW  - position control
KW  - robot vision
KW  - service robots
KW  - telerobotics
KW  - visual servoing
KW  - dynamic visual
KW  - cloud robotics
KW  - multiple robots
KW  - cloud services
KW  - unlimited computation power
KW  - network communication
KW  - dynamic compliant service robots
KW  - human compliant service robots
KW  - dynamic self-balancing robot
KW  - cloud teleoperation
KW  - cloud-based image based visual servoing module
KW  - cloud teleoperator
KW  - real-time automation system
KW  - cloud-edge hybrid design
KW  - dynamic robotic control
KW  - deep-learning recognition systems
KW  - self-balancing service robot
KW  - fog robotic object recognition system
KW  - Cloud computing
KW  - Service robots
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793600
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Cloud Robotics is a paradigm where multiple robots are connected to cloud services via Internet to access “unlimited” computation power, at the cost of network communication. However, due to limitations such as network latency and variability, it is difficult to control dynamic, human compliant service robots directly from the cloud. In this work, we combine cloud robotics with an agile edge device to build a Fog Robotic system by leveraging an asynchronous protocol with a “heartbeat” signal. We use the system to enable robust teleoperation of a dynamic self-balancing robot from the cloud. We use the system to pick up boxes from static locations, a task commonly performed in warehouse logistics. To make cloud teleoperation more intuitive and efficient, we program a cloud-based image based visual servoing (IBVS) module to automatically assist the cloud teleoperator during the object pickups. Visual feedbacks, including apriltag recognition and tracking, are performed in the cloud to emulate a Fog Robotic object recognition system for IBVS. We demonstrate the feasibility of a dynamic real-time automation system using this cloud-edge hybrid design, which opens up possibilities of deploying dynamic robotic control with deep-learning recognition systems in Fog Robotics. Finally, we show that Fog Robotics enables the self-balancing service robot to pick up a box automatically from a person under unstructured environments.
ER  - 

TY  - CONF
TI  - Approximate Probabilistic Security for Networked Multi-Robot Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1997
EP  - 2003
AU  - R. Wehbe
AU  - R. K. Williams
PY  - 2019
KW  - binary decision diagrams
KW  - computational complexity
KW  - control system security
KW  - graph theory
KW  - multi-robot systems
KW  - networked control systems
KW  - optimisation
KW  - probability
KW  - MRS
KW  - approximate probabilistic security
KW  - networked multirobot systems
KW  - combinatorial optimization problem
KW  - lower bound estimate
KW  - computational complexity
KW  - binary decision diagrams
KW  - exact probability
KW  - optimal subset
KW  - multipoint optimization
KW  - left invertiblility
KW  - disjoint path sets
KW  - online optimization
KW  - Security
KW  - Observers
KW  - Robot sensing systems
KW  - Probabilistic logic
KW  - Boolean functions
KW  - Probability
DO  - 10.1109/ICRA.2019.8794232
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we formulate a combinatorial optimization problem that aims to maximize the accuracy of a lower bound estimate of the probability of security of a multi-robot system (MRS), while minimizing the computational complexity involved in its calculation. Security of an MRS is defined using the well-known control theoretic notion of left invertiblility, and the probability of security of an MRS can be calculated using binary decision diagrams (BDDs). The complexity of a BDD depends on the number of disjoint path sets considered during its construction. Taking into account all possible disjoint paths results in an exact probability of security, however, selecting an optimal subset of disjoint paths leads to a good estimate of the probability while significantly reducing computation. To deal with the dynamic nature of MRSs, we introduce two methods: (1) multi-point optimization, a technique that requires some a priori knowledge of the topology of the MRS over time, and (2) online optimization, a technique that does not require a priori knowledge, but must construct BDDs while the MRS is operating. Finally, our approach is validated on an MRS performing a rendezvous objective while exchanging information according to a noisy state agreement process.
ER  - 

TY  - CONF
TI  - A Decentralized Heterogeneous Control Strategy for a Class of Infinitesimally Shape-Similar Formations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2004
EP  - 2010
AU  - I. Buckley
AU  - M. Egerstedt
PY  - 2019
KW  - decentralised control
KW  - geometry
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - decentralized formation control strategy
KW  - assembled triangulation
KW  - infinitesimally shape-similar formations
KW  - asymptotic controllers
KW  - differential-drive robots
KW  - decentralized heterogeneous control strategy
KW  - sensing modalities
KW  - multirobot team
KW  - infinitesimal shape-similarity
KW  - Robot sensing systems
KW  - Shape
KW  - Robot kinematics
KW  - Self-assembly
KW  - Maintenance engineering
KW  - Multi-Robot Systems
DO  - 10.1109/ICRA.2019.8793514
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The sensing modalities available to individual agents in a multi-robot team have a significant effect on what the team can accomplish. Previous work on infinitesimal shape-similarity has shown that maintaining relative angles between robots equipped with bearing-only sensors can render a formation of these robots invariant to translation, rotation, and uniform scaling; however, previous work has not proposed decentralized control strategies for exploiting this invariance. To address this deficiency, this paper proposes a decentralized formation control strategy for assembled triangulations, a class of infinitesimally shape-similar formations. Heterogeneous in terms of sensing and control, a decentralized formation control strategy is developed in which one robot sets the position of the formation, a robot capable of measuring bearings and distances controls the scale and heading, and the remaining robots maintain the assembled triangulation. The asymptotic controllers that compose the formation control strategy of this work are implemented on a team of differential-drive robots.
ER  - 

TY  - CONF
TI  - Asynchronous Network Formation in Unknown Unbounded Environments*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2011
EP  - 2017
AU  - S. Engin
AU  - V. Isler
PY  - 2019
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - trees (mathematics)
KW  - mobile multirobot system
KW  - arbitrary robot deployments
KW  - robot initial positions
KW  - robot configuration
KW  - online network formation problem
KW  - asynchronous network formation
KW  - unknown unbounded environments
KW  - ONFP
KW  - bounded communication range
KW  - competitive ratio
KW  - Euclidean minimum spanning tree
KW  - Robot kinematics
KW  - Task analysis
KW  - Partitioning algorithms
KW  - Vegetation
KW  - Protocols
KW  - Peer-to-peer computing
DO  - 10.1109/ICRA.2019.8794031
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we study the Online Network Formation Problem (ONFP) for a mobile multi-robot system. Consider a group of robots with a bounded communication range operating in a large open area. One of the robots has a piece of information which has to be propagated to all other robots. What strategy should the robots pursue to disseminate the information to the rest of the robots as quickly as possible? The initial locations of the robots are unknown to each other, therefore the problem must be solved in an online fashion. For this problem, we present an algorithm whose competitive ratio is O(H · max{M, √MH}) for arbitrary robot deployments, where M is the largest edge length in the Euclidean minimum spanning tree on the initial robot configuration and H is the height of the tree. We also study the case when the robot initial positions are chosen uniformly at random and improve the ratio to O(M). Finally, we present simulation results to validate the performance in larger scales and demonstrate our algorithm using three robots in a field experiment.
ER  - 

TY  - CONF
TI  - Switching Topology for Resilient Consensus using Wi-Fi Signals
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2018
EP  - 2024
AU  - T. Wheeler
AU  - E. Bharathi
AU  - S. Gil
PY  - 2019
KW  - graph theory
KW  - multi-robot systems
KW  - probability
KW  - telecommunication network topology
KW  - telecommunication security
KW  - telecommunication switching
KW  - wireless channels
KW  - wireless LAN
KW  - resilient consensus
KW  - physical networks
KW  - multiagent consensus
KW  - Sybil attack
KW  - physical properties
KW  - wireless transmissions
KW  - wireless channels
KW  - switching signal
KW  - untrustworthy agents
KW  - arbitrary malicious node values
KW  - initial topology
KW  - connected topology
KW  - legitimate agents
KW  - Wi-Fi signals
KW  - societal integration
KW  - multirobot team security
KW  - untrustworthy transmissions
KW  - switching topology
KW  - true graph
KW  - Wireless communication
KW  - Switches
KW  - Communication system security
KW  - Wireless sensor networks
KW  - Network topology
KW  - Security
KW  - Topology
DO  - 10.1109/ICRA.2019.8793788
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Securing multi-robot teams against malicious activity is crucial as these systems accelerate towards widespread societal integration. This emerging class of “physical networks” requires research into new methods of security that exploit their physical nature. This paper derives a theoretical framework for securing multi-agent consensus against the Sybil attack by using the physical properties of wireless transmissions. Our frame-work uses information extracted from the wireless channels to design a switching signal that stochastically excludes potentially untrustworthy transmissions from the consensus. Intuitively, this amounts to selectively ignoring incoming communications from untrustworthy agents, allowing for consensus to the true average to be recovered with high probability if initiated after a certain observation time T0 that we derive. This work is different from previous work in that it allows for arbitrary malicious node values and is insensitive to the initial topology of the network so long as a connected topology over legitimate nodes in the network is feasible. We show that our algorithm will recover consensus and the true graph over the system of legitimate agents with an error rate that vanishes exponentially with time.
ER  - 

TY  - CONF
TI  - Multi-Vehicle Trajectory optimisation On Road Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2025
EP  - 2031
AU  - P. Gun
AU  - A. Hill
AU  - R. Vujanic
PY  - 2019
KW  - integer programming
KW  - linear programming
KW  - path planning
KW  - multivehicle trajectory optimisation
KW  - road networks
KW  - planning time-optimal trajectories
KW  - multiple cooperative agents
KW  - static road network
KW  - vehicle interactions
KW  - nontrivial decisions
KW  - complex flow-on effects
KW  - globally optimal time trajectory
KW  - minimum time trajectory
KW  - MILP
KW  - computational performance
KW  - binary variables
KW  - collision constraints
KW  - open-pit mining scenario
KW  - mixed integer linear programming
KW  - goal constraints
KW  - heuristic method
KW  - Roads
KW  - Trajectory
KW  - Planning
KW  - Automation
KW  - Optimization
KW  - Iterative methods
KW  - Mixed integer linear programming
DO  - 10.1109/ICRA.2019.8793831
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of planning time-optimal trajectories for multiple cooperative agents along specified paths through a static road network. Vehicle interactions at intersections create non-trivial decisions, with complex flow-on effects for subsequent interactions. A globally optimal, minimum time trajectory is found for all vehicles using Mixed Integer Linear Programming (MILP). Computational performance is improved by minimising binary variables using iteratively applied targeted collision constraints, and efficient goal constraints. Simulation results in an open-pit mining scenario compare the proposed method against a fast heuristic method and a reactive approach based on site practices. The heuristic is found to scale better with problem size while the MILP is able to avoid local minima.
ER  - 

TY  - CONF
TI  - Disturbance Compensation Based Control for an Indoor Blimp Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2040
EP  - 2046
AU  - Y. Wang
AU  - G. Zheng
AU  - D. Efimov
AU  - W. Perruquetti
PY  - 2019
KW  - autonomous aerial vehicles
KW  - compensation
KW  - control system synthesis
KW  - feedback
KW  - mobile robots
KW  - nonlinear control systems
KW  - observers
KW  - robust control
KW  - uncertain systems
KW  - blimp disturbance compensation based controller
KW  - indoor blimp robot
KW  - robust controller
KW  - horizontal plane
KW  - slider-like nonlinear system
KW  - uncertain bounded disturbances
KW  - output feedback controller
KW  - disturbance evaluation
KW  - exogenous disturbances
KW  - control scheme
KW  - concrete blimp
KW  - homogeneous differentiator
KW  - observer
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Biological system modeling
KW  - Output feedback
KW  - Robot sensing systems
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793535
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents design of a robust controller with disturbance compensation for an indoor blimp robot and its realization. The movement of blimp in horizontal plane is modeled as a slider-like nonlinear system complemented with uncertain bounded disturbances. To design the output feedback controller, a homogeneous differentiator is used as an observer. Then the method for disturbance evaluation is designed, the perturbation estimate is next used in the controller for cancellation of the influence of exogenous disturbances. Control scheme is implemented on a concrete blimp, finally, the performance of blimp disturbance compensation based controller is verified in experiments.
ER  - 

TY  - CONF
TI  - Informed Information Theoretic Model Predictive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2047
EP  - 2053
AU  - R. Kusumoto
AU  - L. Palmieri
AU  - M. Spies
AU  - A. Csiszar
AU  - K. O. Arras
PY  - 2019
KW  - nonlinear control systems
KW  - nonlinear dynamical systems
KW  - optimal control
KW  - optimisation
KW  - predictive control
KW  - robust control
KW  - sampling methods
KW  - informed sampling distribution
KW  - optimized controls
KW  - informed information theoretic model predictive control
KW  - nonlinear control systems
KW  - uncertainties
KW  - highly nonlinear dynamics
KW  - contextual information
KW  - generative models
KW  - trajectory control
KW  - sampling-based MPC methods
KW  - robustness properties
KW  - conditional variational autoencoders
KW  - autonomous navigation domain
KW  - Task analysis
KW  - Optimal control
KW  - Trajectory
KW  - Decoding
KW  - Robots
KW  - Planning
KW  - Cost function
DO  - 10.1109/ICRA.2019.8793945
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The problem of minimizing cost in nonlinear control systems with uncertainties or disturbances remains a major challenge. Model predictive control (MPC), and in particular sampling-based MPC has recently shown great success in complex domains such as aggressive driving with highly nonlinear dynamics. Sampling-based methods rely on a prior distribution to generate samples in the first place. Obviously, the choice of this distribution highly influences efficiency of the controller. Existing approaches such as sampling around the control trajectory of the previous time step perform suboptimally, especially in multi-modal or highly dynamic settings. In this work, we therefore propose to learn models that generate samples in low-cost areas of the state-space, conditioned on the environment and on contextual information of the task to solve. By using generative models as an informed sampling distribution, our approach exploits guidance from the learned models and at the same time maintains robustness properties of the MPC methods. We use Conditional Variational Autoencoders (CVAE) to learn distributions that imitate samples from a training dataset containing optimized controls. An extensive evaluation in the autonomous navigation domain suggests that replacing previous sampling schemes with our learned models considerably improves performance in terms of path quality and planning efficiency.
ER  - 

TY  - CONF
TI  - A Generic Optimization Based Cartesian Controller for Robotic Mobile Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2054
EP  - 2060
AU  - E. Brzozowska
AU  - O. Lima
AU  - R. Ventura
PY  - 2019
KW  - angular velocity control
KW  - closed loop systems
KW  - end effectors
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - probability
KW  - robot vision
KW  - service robots
KW  - sequential phases
KW  - closed loop perspective
KW  - generic optimization-based Cartesian controller
KW  - motion commands
KW  - robotic system
KW  - mobile platform
KW  - velocity space
KW  - end effector velocity
KW  - joint platform velocities
KW  - base platform velocities
KW  - mobile service robot architecture
KW  - domestic tasks
KW  - robotic mobile manipulation
KW  - random arm configurations
KW  - Optimization
KW  - Kinematics
KW  - Manipulators
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Planning
DO  - 10.1109/ICRA.2019.8793635
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Typically, the problem of robotic manipulation is divided among two sequential phases: a planning one and an execution one. However, since the second one is executed in open loop, the robot is unable to react in real time to changes in the task (e.g. moving object). This paper addresses the mobile manipulation problem from a real-time, closed loop perspective. In particular, we propose a generic optimization-based Cartesian controller, that given a continuous monitoring of the goal, determines the best motion commands. We target our controller to a robotic system comprising an arm and a mobile platform. However, the approach can in principle be extended to more complex mechanisms. The approach is based on shifting the problem to velocity space, where end effector velocity is a linear function of joint and base platform velocities. Our approach was quantitatively evaluated both on simulation and on a real service robot. It was also integrated into a mobile service robot architecture targeting domestic tasks and evaluated on the RoboCup@Home scientific competition. Our results show that the controller is able to reach random arm configurations with a high probability of success.
ER  - 

TY  - CONF
TI  - Task-Driven Estimation and Control via Information Bottlenecks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2061
EP  - 2067
AU  - V. Pacelli
AU  - A. Majumdar
PY  - 2019
KW  - information theory
KW  - iterative methods
KW  - robots
KW  - state estimation
KW  - general algorithmic framework
KW  - task-driven estimation
KW  - state representations
KW  - state estimation
KW  - task-driven representation
KW  - task-relevant variables
KW  - performant control policy
KW  - robotic system control
KW  - principled algorithmic framework
KW  - iterative algorithms
KW  - information bottleneck optimization problem
KW  - Task analysis
KW  - Robot sensing systems
KW  - Robustness
KW  - Optimized production technology
KW  - Estimation
DO  - 10.1109/ICRA.2019.8794213
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Our goal is to develop a principled and general algorithmic framework for task-driven estimation and control for robotic systems. State-of-the-art approaches for controlling robotic systems typically rely heavily on accurately estimating the full state of the robot (e.g., a running robot might estimate joint angles and velocities, torso state, and position relative to a goal). However, full state representations are often excessively rich for the specific task at hand and can lead to significant computational inefficiency and brittleness to errors in state estimation. In contrast, we present an approach that eschews such rich representations and seeks to create task-driven representations. The key technical insight is to leverage the theory of information bottlenecks to formalize the notion of a “task-driven representation” in terms of information theoretic quantities that measure the minimality of a representation. We propose novel iterative algorithms for automatically synthesizing (offline) a task-driven representation (given in terms of a set of task-relevant variables (TRVs)) and a performant control policy that is a function of the TRVs. We present online algorithms for estimating the TRVs in order to apply the control policy. We demonstrate that our approach results in significant robustness to unmodeled measurement uncertainty both theoretically and via thorough simulation experiments including a spring-loaded inverted pendulum running to a goal location.
ER  - 

TY  - CONF
TI  - Feasibility Analysis For Constrained Model Predictive Control Based Motion Cueing Algorithm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2076
EP  - 2082
AU  - C. Rengifo
AU  - J. Chardonnet
AU  - H. Mohellebi
AU  - D. Paillot
AU  - A. Kemeny
PY  - 2019
KW  - closed loop systems
KW  - motion control
KW  - optimal control
KW  - predictive control
KW  - road traffic control
KW  - stability
KW  - feasibility issues
KW  - implicit model predictive control-based motion cueing algorithms
KW  - prediction horizons
KW  - control inputs
KW  - feasibility analysis
KW  - constrained model predictive control based motion cueing algorithm
KW  - motion control
KW  - constrained optimal control
KW  - high performance driving simulator
KW  - Acceleration
KW  - Force
KW  - Stability criteria
KW  - Cost function
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794129
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper deals with motion control for an 8-degree-of-freedom (DOF) high performance driving simulator. We formulate a constrained optimal control that defines the dynamical behavior of the system. Furthermore, the paper brings together various methodologies for addressing feasibility issues arising in implicit model predictive control-based motion cueing algorithms. The implementation of different techniques is described and discussed subsequently. Several simulations are carried out in the simulator platform. It is observed that the only technique that can provide ensured closed-loop stability by assuring feasibility over all prediction horizons is a braking law that basically saturates the control inputs in the constrained form.
ER  - 

TY  - CONF
TI  - Robustness to Out-of-Distribution Inputs via Task-Aware Generative Uncertainty
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2083
EP  - 2089
AU  - R. McAllister
AU  - G. Kahn
AU  - J. Clune
AU  - S. Levine
PY  - 2019
KW  - Bayes methods
KW  - belief networks
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - robust control
KW  - uncertainty-aware robotic perception
KW  - explicit generative model
KW  - observation distribution
KW  - action-conditioned collision prediction task
KW  - Bayesian neural network techniques
KW  - task-aware generative uncertainty
KW  - deep learning
KW  - open world
KW  - real-world robotic systems
KW  - mobile robots
KW  - out-of-distribution observations
KW  - neural network predictions
KW  - robotic perception
KW  - approximate Bayesian approach
KW  - Uncertainty
KW  - Robots
KW  - Predictive models
KW  - Bayes methods
KW  - Neural networks
KW  - Training
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793552
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deep learning provides a powerful tool for robotic perception in the open world. However, real-world robotic systems, especially mobile robots, must be able to react intelligently and safely even in unexpected circumstances. This requires a system that knows what it knows, and can estimate its own uncertainty for unfamiliar, out-of-distribution observations. Approximate Bayesian approaches are commonly used to estimate uncertainty for neural network predictions, but struggle with out-of-distribution observations. Generative models can in principle detect out-of-distribution observations as those with a low estimated density, but overly pessimistic as an uncertainty measure, since the mere presence of an out-of-distribution input does not by itself indicate an unsafe situation. Intuitively, we would like a perception system that can detect when task-salient parts of the image are unfamiliar or uncertain, while ignoring task-irrelevant features. In this paper, we present a method for uncertainty-aware robotic perception that combines generative modeling and model uncertainty. Our method estimates an uncertainty measure about the model's prediction, taking into account an explicit generative model of the observation distribution to handle out-of-distribution inputs. We evaluate our method on an action-conditioned collision prediction task with both simulated and real data, and demonstrate that our approach improves on a variety of Bayesian neural network techniques.
ER  - 

TY  - CONF
TI  - Multimodal Trajectory Predictions for Autonomous Driving using Deep Convolutional Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2090
EP  - 2096
AU  - H. Cui
AU  - V. Radosavljevic
AU  - F. Chou
AU  - T. Lin
AU  - T. Nguyen
AU  - T. Huang
AU  - J. Schneider
AU  - N. Djuric
PY  - 2019
KW  - convolutional neural nets
KW  - driver information systems
KW  - feature extraction
KW  - image processing
KW  - mobile robots
KW  - probability
KW  - road accidents
KW  - road safety
KW  - road traffic
KW  - road vehicles
KW  - multimodal trajectory predictions
KW  - autonomous driving
KW  - deep convolutional networks
KW  - robotics
KW  - artificial intelligence communities
KW  - self-driving vehicles
KW  - SDVs
KW  - road accidents
KW  - human drivers
KW  - traffic behavior
KW  - safe operations
KW  - autonomous vehicle
KW  - raster image
KW  - probabilities
KW  - Trajectory
KW  - Predictive models
KW  - Roads
KW  - Hidden Markov models
KW  - Task analysis
KW  - Radar tracking
DO  - 10.1109/ICRA.2019.8793868
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous driving presents one of the largest problems that the robotics and artificial intelligence communities are facing at the moment, both in terms of difficulty and potential societal impact. Self-driving vehicles (SDVs) are expected to prevent road accidents and save millions of lives while improving the livelihood and life quality of many more. However, despite large interest and a number of industry players working in the autonomous domain, there still remains more to be done in order to develop a system capable of operating at a level comparable to best human drivers. One reason for this is high uncertainty of traffic behavior and large number of situations that an SDV may encounter on the roads, making it very difficult to create a fully generalizable system. To ensure safe and efficient operations, an autonomous vehicle is required to account for this uncertainty and to anticipate a multitude of possible behaviors of traffic actors in its surrounding. We address this critical problem and present a method to predict multiple possible trajectories of actors while also estimating their probabilities. The method encodes each actor's surrounding context into a raster image, used as input by deep convolutional networks to automatically derive relevant features for the task. Following extensive offline evaluation and comparison to state-of-the-art baselines, the method was successfully tested on SDVs in closed-course tests.
ER  - 

TY  - CONF
TI  - Classifying Pedestrian Actions In Advance Using Predicted Video Of Urban Driving Scenes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2097
EP  - 2103
AU  - P. Gujjar
AU  - R. Vaughan
PY  - 2019
KW  - feature extraction
KW  - graphics processing units
KW  - image classification
KW  - image representation
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - pedestrians
KW  - traffic engineering computing
KW  - video signal processing
KW  - encoder-decoder network models
KW  - predicted video
KW  - urban driving scenes
KW  - traffic scene
KW  - pedestrian behaviour
KW  - urban pedestrian
KW  - binary action classifier
KW  - iterative transform
KW  - image sequence
KW  - GPU
KW  - Hidden Markov models
KW  - Decoding
KW  - Predictive models
KW  - Kernel
KW  - Training
KW  - Automobiles
KW  - Iterative decoding
DO  - 10.1109/ICRA.2019.8794278
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fig. 1.Generating predictions of a future for a pedestrian attempting to cross the street. We pick out two key frames from the (a) input sequence and the (b) ground truth sequence, 16 frames apart. Image (c) shows our prediction at the same time instant as the ground truth.We explore prediction of urban pedestrian actions by generating a video future of the traffic scene, and show promising results in classifying pedestrian behaviour before it is observed. We compare several encoder-decoder network models that predict 16 frames (400-600 milliseconds of video) from the preceding 16 frames. Our main contribution is a method for learning a sequence of representations to iteratively transform features learnt from the input to the future. Then we use a binary action classifier network for determining a pedestrian's crossing intent from predicted video. Our results show an average precision of 81%, significantly higher than previous methods. The model with the best classification performance runs for 117 ms on commodity GPU, giving an effective look-ahead of 416 ms.
ER  - 

TY  - CONF
TI  - Lightweight Contrast Modeling for Attention-Aware Visual Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2104
EP  - 2110
AU  - L. Huang
AU  - G. Li
AU  - Y. Li
AU  - L. Lin
PY  - 2019
KW  - intelligent robots
KW  - object detection
KW  - salient object detection task
KW  - object saliency details
KW  - lightweight refinement module
KW  - high-level visual contrast
KW  - superior lightweight network architecture
KW  - computational resource consumption
KW  - detection performance
KW  - attention-aware visual objects
KW  - attention-aware visual localization
KW  - lightweight contrast modeling
KW  - Convolution
KW  - Visualization
KW  - Object detection
KW  - Feature extraction
KW  - Robots
KW  - Training
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794442
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Salient object detection, which aims at localizing the attention-aware visual objects, is the indispensable technology for intelligent robots to understand and interact with the complicated environments. Existing salient object detection approaches mainly focus on the optimization of detection performance, while ignoring the considerations for computational resource consumption and algorithm efficiency. Contrarily, we build a superior lightweight network architecture to simultaneously improve performance on both accuracy and efficiency for salient object detection. Specifically, our proposed approach adopts the lightweight bottleneck as its primary building block to significantly reduce the number of parameters and to speed up the process of training and inference. In practice, the visual contrast is insufficiently discovered with the limitation of the small empirical receptive field of CNN. To alleviate this issue, we design a multi-scale convolution module to rapidly discover high-level visual contrast. Moreover, a lightweight refinement module is utilized to restore object saliency details with negligible extra cost. Extensive experiments on efficiency and accuracy trade-offs show that our model is more competitive than the state-of-the-art works on salient object detection task and has prominent potentials for robots applications in real time.
ER  - 

TY  - CONF
TI  - Learning to Write Anywhere with Spatial Transformer Image-to-Motion Encoder-Decoder Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2111
EP  - 2117
AU  - B. Ridge
AU  - R. Pahič
AU  - A. Ude
AU  - J. Morimoto
PY  - 2019
KW  - affine transforms
KW  - handwritten character recognition
KW  - humanoid robots
KW  - image coding
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - DMP
KW  - digit drawings
KW  - image-to-motion encoder-decoder networks
KW  - convolutional layers
KW  - humanoid robot
KW  - affine transformed digits
KW  - fully differentiable overall network
KW  - spatial transformer
KW  - motion trajectories
KW  - digit images
KW  - robot vision
KW  - handwritten characters
KW  - Trajectory
KW  - Robots
KW  - Transforms
KW  - Task analysis
KW  - Writing
KW  - Neural networks
KW  - Decoding
DO  - 10.1109/ICRA.2019.8794253
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning to recognize and reproduce handwritten characters is already a challenging task both for humans and robots alike, but learning to do the same thing for characters that can be transformed arbitrarily in space, as humans do when writing on a blackboard for instance, significantly ups the ante from a robot vision and control perspective. In previous work we proposed various different forms of encoder-decoder networks that were capable of mapping raw images of digits to dynamic movement primitives (DMPs) such that a robot could learn to translate the digit images into motion trajectories in order to reproduce them in written form. However, even with the addition of convolutional layers in the image encoder, the extent to which these networks are spatially invariant or equivariant is rather limited. In this paper, we propose a new architecture that incorporates both an image-to-motion encoder-decoder and a spatial transformer in a fully differentiable overall network that learns to rectify affine transformed digits in input images into canonical forms, before converting them into DMPs with accompanying motion trajectories that are finally transformed back to match up with the original digit drawings such that a robot can write them in their original forms. We present experiments with various challenging datasets that demonstrate the superiority of the new architecture compared to our previous work and demonstrate its use with a humanoid robot in a real writing task.
ER  - 

TY  - CONF
TI  - Motion Planning Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2118
EP  - 2124
AU  - A. H. Qureshi
AU  - A. Simeonov
AU  - M. J. Bency
AU  - M. C. Yip
PY  - 2019
KW  - collision avoidance
KW  - computational complexity
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - neurocontrollers
KW  - computational complexity
KW  - neural network
KW  - collision-free paths
KW  - motion planning networks
KW  - robotics applications
KW  - self-driving cars
KW  - 7 DOF Baxter robot manipulator
KW  - MPNet
KW  - Planning
KW  - Three-dimensional displays
KW  - Neural networks
KW  - Training
KW  - Manipulators
KW  - Encoding
DO  - 10.1109/ICRA.2019.8793889
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fast and efficient motion planning algorithms are crucial for many state-of-the-art robotics applications such as self-driving cars. Existing motion planning methods become ineffective as their computational complexity increases exponentially with the dimensionality of the motion planning problem. To address this issue, we present Motion Planning Networks (MPNet), a neural network-based novel planning algorithm. The proposed method encodes the given workspaces directly from a point cloud measurement and generates the end-to-end collision-free paths for the given start and goal configurations. We evaluate MPNet on various 2D and 3D environments including the planning of a 7 DOF Baxter robot manipulator. The results show that MPNet is not only consistently computationally efficient in all environments but also generalizes to completely unseen environments. The results also show that the computation time of MPNet consistently remains less than 1 second in all presented experiments, which is significantly lower than existing state-of-the-art motion planning algorithms.
ER  - 

TY  - CONF
TI  - Improving Data Efficiency of Self-supervised Learning for Robotic Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2125
EP  - 2131
AU  - L. Berscheid
AU  - T. Rühr
AU  - T. Kröger
PY  - 2019
KW  - convolutional neural nets
KW  - force feedback
KW  - grippers
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - fully-convolutional neural network
KW  - gripper parameters
KW  - inference performance
KW  - random grasp success rate
KW  - grasp space
KW  - systematic manner
KW  - typical bin picking scenarios
KW  - self-supervised learning
KW  - robotic grasping
KW  - depth camera input
KW  - gripper force feedback
KW  - learning algorithm
KW  - geometric consistency
KW  - undistorted depth images
KW  - task space
KW  - grasp attempts
KW  - data efficiency
KW  - training data
KW  - Grasping
KW  - Grippers
KW  - Robot kinematics
KW  - Artificial neural networks
KW  - Task analysis
KW  - Training
DO  - 10.1109/ICRA.2019.8793952
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Given the task of learning robotic grasping solely based on a depth camera input and gripper force feedback, we derive a learning algorithm from an applied point of view to significantly reduce the amount of required training data. Major improvements in time and data efficiency are achieved by: Firstly, we exploit the geometric consistency between the undistorted depth images and the task space. Using a relative small, fully-convolutional neural network, we predict grasp and gripper parameters with great advantages in training as well as inference performance. Secondly, motivated by the small random grasp success rate of around 3 %, the grasp space was explored in a systematic manner. The final system was learned with 23 000 grasp attempts in around 60 h, improving current solutions by an order of magnitude. For typical bin picking scenarios, we measured a grasp success rate of (96.6 ± 1.0) %. Further experiments showed that the system is able to generalize and transfer knowledge to novel objects and environments.
ER  - 

TY  - CONF
TI  - Online Object and Task Learning via Human Robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2132
EP  - 2138
AU  - M. Dehghan
AU  - Z. Zhang
AU  - M. Siam
AU  - J. Jin
AU  - L. Petrich
AU  - M. Jagersand
PY  - 2019
KW  - force control
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - motion control
KW  - neural nets
KW  - deep learning based localization
KW  - recognition system
KW  - intuitive user interface
KW  - 3D motion task
KW  - hybrid force-vision control module
KW  - compliant motion
KW  - task learning
KW  - human robot interaction
KW  - KUKA Innovation Award competition
KW  - Hanover Messe 2018
KW  - online object learning
KW  - incremental object learning module
KW  - Robots
KW  - Education
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Feature extraction
KW  - Human-robot interaction
DO  - 10.1109/ICRA.2019.8794036
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work describes the development of a robotic system that acquires knowledge incrementally through human interaction where new objects and motions are taught on the fly. The robotic system developed was one of the five finalists in the KUKA Innovation Award competition and demonstrated during the Hanover Messe 2018 in Germany. The main contributions of the system are i) a novel incremental object learning module - a deep learning based localization and recognition system - that allows a human to teach new objects to the robot, ii) an intuitive user interface for specifying 3D motion task associated with the new object, and iii) a hybrid force-vision control module for performing compliant motion on an unstructured surface. This paper describes the implementation and integration of the main modules of the system and summarizes the lessons learned from the competition.
ER  - 

TY  - CONF
TI  - Dynamic Manipulation of Flexible Objects with Torque Sequence Using a Deep Neural Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2139
EP  - 2145
AU  - K. Kawaharazuka
AU  - T. Ogawa
AU  - J. Tamura
AU  - C. Nabeshima
PY  - 2019
KW  - control engineering computing
KW  - flexible manipulators
KW  - manipulator dynamics
KW  - motion control
KW  - neural nets
KW  - time series
KW  - torque control
KW  - dynamic manipulation
KW  - torque sequence
KW  - deep neural network
KW  - acquisition method
KW  - flexible object motion equation model
KW  - time-series joint torque command
KW  - Torque
KW  - Mathematical model
KW  - Dynamics
KW  - Optical imaging
KW  - Manipulator dynamics
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793513
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For dynamic manipulation of flexible objects, we propose an acquisition method of a flexible object motion equation model using a deep neural network and a control method to realize a target state by calculating an optimized time-series joint torque command. By using the proposed method, any physics model of a target object is not needed, and the object can be controlled as intended. We applied this method to manipulations of a rigid object, a flexible object with and without environmental contact, and a cloth, and verified its effectiveness.
ER  - 

TY  - CONF
TI  - Color-Coded Fiber-Optic Tactile Sensor for an Elastomeric Robot Skin
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2146
EP  - 2152
AU  - Z. Kappassov
AU  - D. Baimukashev
AU  - Z. Kuanyshuly
AU  - Y. Massalin
AU  - A. Urazbayev
AU  - H. A. Varol
PY  - 2019
KW  - cameras
KW  - robots
KW  - tactile sensors
KW  - contact localization
KW  - robotic perception system
KW  - force sensing range
KW  - color-coded tactile sensor
KW  - tactile exploration
KW  - robust tactile sensing
KW  - color-coded fiber-optic tactile sensor
KW  - elastomeric robot skin
KW  - artificial tactile skin
KW  - transparent silicone rubber
KW  - off-the-shelf color camera
KW  - camera POFs
KW  - Optical sensors
KW  - Tactile sensors
KW  - Image color analysis
KW  - Cameras
DO  - 10.1109/ICRA.2019.8793262
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The sense of touch is essential for reliable mapping between the environment and a robot which interacts physically with objects. Presumably, an artificial tactile skin would facilitate safe interaction of the robots with the environment. In this work, we present our color-coded tactile sensor, incorporating plastic optical fibers (POF), transparent silicone rubber and an off-the-shelf color camera. Processing electronics are placed away from the sensing surface to make the sensor robust to harsh environments. Contact localization is possible thanks to the lower number of light sources compared to the number of camera POFs. Classical machine learning techniques and a hierarchical classification scheme were used for contact localization. Specifically, we generated the mapping from stimulation to sensation of a robotic perception system using our sensor. We achieved a force sensing range up to 18 N with the force resolution of around 3.6 N and the spatial resolution of 8 mm. The color-coded tactile sensor is suitable for tactile exploration and might enable further innovations in robust tactile sensing.
ER  - 

TY  - CONF
TI  - Reinforcement Learning in Topology-based Representation for Human Body Movement with Whole Arm Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2153
EP  - 2160
AU  - W. Yuan
AU  - K. Hang
AU  - H. Song
AU  - D. Kragic
AU  - M. Y. Wang
AU  - J. A. Stork
PY  - 2019
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - medical robotics
KW  - path planning
KW  - patient care
KW  - position control
KW  - topology-based representation
KW  - human body movement
KW  - bulky object
KW  - WAM
KW  - manipulation places
KW  - global properties
KW  - local contacts
KW  - grasping
KW  - reinforcement learning problem
KW  - robot behavior
KW  - human motion
KW  - robot-human interaction
KW  - topology-based coordinates
KW  - torso positions
KW  - learned policy
KW  - body shapes
KW  - dynamic sea rescue scenario
KW  - unseen scenarios
KW  - differently-shaped humans
KW  - whole arm manipulation
KW  - Robot kinematics
KW  - Humanoid robots
KW  - Manipulators
KW  - Laplace equations
KW  - Torso
KW  - Shape
DO  - 10.1109/ICRA.2019.8794160
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Moving a human body or a large and bulky object may require the strength of whole arm manipulation (WAM). This type of manipulation places the load on the robot's arms and relies on global properties of the interaction to succeed- rather than local contacts such as grasping or non-prehensile pushing. In this paper, we learn to generate motions that enable WAM for holding and transporting of humans in certain rescue or patient care scenarios. We model the task as a reinforcement learning problem in order to provide a robot behavior that can directly respond to external perturbation and human motion. For this, we represent global properties of the robot-human interaction with topology-based coordinates that are computed from arm and torso positions. These coordinates also allow transferring the learned policy to other body shapes and sizes. For training and evaluation, we simulate a dynamic sea rescue scenario and show in quantitative experiments that the policy can solve unseen scenarios with differently-shaped humans, floating humans, or with perception noise. Our qualitative experiments show the subsequent transporting after holding is achieved and we demonstrate that the policy can be directly transferred to a real world setting.
ER  - 

TY  - CONF
TI  - Demonstration-Guided Deep Reinforcement Learning of Control Policies for Dexterous Human-Robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2161
EP  - 2167
AU  - S. Christen
AU  - S. Stevšić
AU  - O. Hilliges
PY  - 2019
KW  - dexterous manipulators
KW  - humanoid robots
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - motion control
KW  - neural nets
KW  - handshake
KW  - hand clap
KW  - finger touch
KW  - training control policies
KW  - human-robot interactions
KW  - hand claps
KW  - humanoid Shadow Dexterous Hand
KW  - robot arm
KW  - multiobjective reward function
KW  - reward structure
KW  - motion capture data
KW  - human-human interactions
KW  - hand interactions
KW  - dexterous human-robot interaction
KW  - demonstration-guided deep reinforcement learning
KW  - Training
KW  - Humanoid robots
KW  - Task analysis
KW  - Robot kinematics
KW  - Reinforcement learning
KW  - Convergence
DO  - 10.1109/ICRA.2019.8794065
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a method for training control policies for human-robot interactions such as handshakes or hand claps via Deep Reinforcement Learning. The policy controls a humanoid Shadow Dexterous Hand, attached to a robot arm. We propose a parameterizable multi-objective reward function that allows learning of a variety of interactions without changing the reward structure. The parameters of the reward function are estimated directly from motion capture data of human-human interactions in order to produce policies that are perceived as being natural and human-like by observers. We evaluate our method on three significantly different hand interactions: handshake, hand clap and finger touch. We provide detailed analysis of the proposed reward function and the resulting policies and conduct a large-scale user study, indicating that our policy produces natural looking motions.
ER  - 

TY  - CONF
TI  - Team-Based Robot Righting via Pushing and Shell Design
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2168
EP  - 2173
AU  - D. L. McPherson
AU  - R. S. Fearing
PY  - 2019
KW  - control system synthesis
KW  - mobile robots
KW  - multi-robot systems
KW  - shells (structures)
KW  - team-based robot righting
KW  - minimalist robot designs
KW  - specialized escape actuator
KW  - emergency actuator
KW  - teammate pushing
KW  - VelociRoACH robots
KW  - robot exterior hull
KW  - shell design
KW  - Force
KW  - Friction
KW  - Shape
KW  - Actuators
KW  - Robot kinematics
KW  - Potential energy
DO  - 10.1109/ICRA.2019.8793958
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The minimalist robot designs typically employed in swarms and teams can fall and get trapped when traversing irregular terrain. To protect against this contingency the design could add a specialized escape actuator, but each actuator drives up cost multiplicatively for the whole team. Instead, the emergency actuator can be found for free in the form of another teammate. Teammate pushing can be efficiently directed by careful shaping of the robot's exterior hull. This approach is illustrated by designing a shell for VelociRoACH robots that enables them to roll pronated comrades back onto their feet. The designed maneuver can be performed in open-loop with 87% success and an average time of 0.7 seconds.
ER  - 

TY  - CONF
TI  - Deformation-based shape control with a multirobot system
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2174
EP  - 2180
AU  - M. Aranda
AU  - J. A. Corrales
AU  - Y. Mezouar
PY  - 2019
KW  - feedback
KW  - gradient methods
KW  - manipulators
KW  - mobile robots
KW  - multi-robot systems
KW  - 2D space
KW  - useful team behaviors
KW  - deformation-based control framework
KW  - manipulation task
KW  - resulting multirobot controller
KW  - robot motions
KW  - feedback loop
KW  - global measure
KW  - typical goal
KW  - deformable object
KW  - application scenario
KW  - robotic team
KW  - multirobot system
KW  - deformation-based shape control
KW  - Robot kinematics
KW  - Shape
KW  - Strain
KW  - Task analysis
KW  - Geometry
KW  - Shape control
DO  - 10.1109/ICRA.2019.8793811
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel method to control the relative positions of the members of a robotic team. The application scenario we consider is the cooperative manipulation of a deformable object in 2D space. A typical goal in this kind of scenario is to minimize the deformation of the object with respect to a desired state. Our contribution, then, is to use a global measure of deformation directly in the feedback loop. In particular, the robot motions are based on the descent along the gradient of a metric that expresses the difference between the team's current configuration and its desired shape. Crucially, the resulting multirobot controller has a simple expression and is inexpensive to compute, and the approach lends itself to analysis of both the transient and asymptotic dynamics of the system. This analysis reveals a number of properties that are interesting for a manipulation task: fundamental geometric parameters of the team (size, orientation, centroid, and distances between robots) can be suitably steered or bounded. We describe different policies within the proposed deformation-based control framework that produce useful team behaviors. We illustrate the methodology with computer simulations.
ER  - 

TY  - CONF
TI  - One-to-many bipartite matching based coalition formation for multi-robot task allocation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2181
EP  - 2187
AU  - A. Dutta
AU  - A. Asaithambi
PY  - 2019
KW  - approximation theory
KW  - computational complexity
KW  - graph theory
KW  - multi-robot systems
KW  - multirobot task allocation
KW  - multirobot coalition formation
KW  - OTMaM problem
KW  - multiple robots
KW  - robot-task pairs
KW  - worst-case approximation ratio
KW  - worst-case time complexity
KW  - NP-hard problem
KW  - one-to-many bipartite matching based coalition formation
KW  - Task analysis
KW  - Robot kinematics
KW  - Resource management
KW  - Bipartite graph
KW  - Approximation algorithms
KW  - Time complexity
DO  - 10.1109/ICRA.2019.8793855
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we study the NP-Hard problem of multi-robot coalition formation for task allocation. To tackle this notoriously difficult problem, we model it as a variant of classical bipartite matching, which we call One-To-Many Bipartite Matching (OTMaM). Unlike the classical bipartite matching techniques used for matching a unique robot to a unique task, in the OTMaM problem, we let multiple robots to be matched to a single task while restricting the opposite. To this end, we propose a novel heuristic algorithm that allocates robots to tasks by finding mutually best robot-task pairs. Our algorithm provides a similar theoretical worst-case approximation ratio and guarantees a better worst-case time complexity than a comparable algorithm from the literature. The proposed approach in this paper is proved to be deterministic and the resultant matching is perfect. Simulation results also demonstrate the scalability of the presented algorithm (taking less than 1 millisecond with 100 robots and 10 tasks).
ER  - 

TY  - CONF
TI  - Coordinated multi-robot planning while preserving individual privacy
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2188
EP  - 2194
AU  - L. Li
AU  - A. Bayuelo
AU  - L. Bobadilla
AU  - T. Alam
AU  - D. A. Shell
PY  - 2019
KW  - collision avoidance
KW  - cryptography
KW  - data privacy
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - coordinated multirobot planning
KW  - individual privacy
KW  - multiple robots
KW  - privacy-preserving rendezvous
KW  - persistent monitoring
KW  - joint plan
KW  - collective motions
KW  - collective task
KW  - joint-collision determination
KW  - mobile robots
KW  - secure path intersection primitives
KW  - homomorphic encryption
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Protocols
KW  - Task analysis
KW  - Privacy
KW  - Encryption
DO  - 10.1109/ICRA.2019.8794460
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of multiple robots that must cooperate within a shared environment, but which wish to limit the information they disclose during their coordination efforts. Specifically, we examine the problems of privacy-preserving rendezvous and persistent monitoring. In the former, the robots construct a joint plan to have them meet, without either knowing beforehand where or when the meeting will occur. In the latter, multiple robots dynamically cover a region of space-they plan collective motions which are collision-free but with the assurance that agents remain ignorant of the paths of others. Accordingly, the tasks are sort of inverses in that the robots must collectively determine whether their joint paths collide or not, then, using this, achieve their collective task. Other than what is learned by the outcome of the joint-collision determination, the robots possess no details of the other paths. Our approach builds on garbled circuits and homomorphic encryption to realize basic secure path intersection primitives. We present algorithms, a software implementation, and a physical experiment on mobile robots to test the practical feasibility of our approach. We believe that these ideas provide a valuable direction for adoption in small Unmanned Systems belonging to different stakeholders.
ER  - 

TY  - CONF
TI  - Multi-Agent Synchronization Using Online Model-Free Action Dependent Dual Heuristic Dynamic Programming Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2195
EP  - 2201
AU  - M. Abouheaf
AU  - W. Gueaieb
PY  - 2019
KW  - adaptive control
KW  - approximation theory
KW  - discrete time systems
KW  - dynamic programming
KW  - iterative methods
KW  - learning systems
KW  - multi-agent systems
KW  - neurocontrollers
KW  - nonlinear control systems
KW  - optimal control
KW  - action dependent dual heuristic dynamic programming schemes
KW  - fast solution platforms
KW  - unknown models
KW  - uncertain dynamical models
KW  - online model-free adaptive
KW  - dynamic graphical games
KW  - approximate the optimal value function
KW  - associated model-free control strategy
KW  - model-free coupled Bellman optimality equation
KW  - multiagent synchronization
KW  - online model-free action dependent dual heuristic dynamic programming approach
KW  - approximate dynamic programming platforms
KW  - agents interaction
KW  - communication graphs
KW  - policy iteration process
KW  - Mathematical model
KW  - Adaptation models
KW  - Optimal control
KW  - Dynamic programming
KW  - Synchronization
KW  - Games
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8794438
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Approximate dynamic programming platforms are employed to solve dynamic graphical games, where the agents interact among each other using communication graphs in order to achieve synchronization. Although the action dependent dual heuristic dynamic programming schemes provide fast solution platforms for several control problems, their capabilities degrade for systems with unknown or uncertain dynamical models. An online model-free adaptive learning solution based on action dependent dual heuristic dynamic programming is proposed to solve the dynamic graphical games. It employs distributed actor-critic neural networks to approximate the optimal value function and the associated model-free control strategy for each agent. This is done using a policy iteration process where it does not employ any extensive computational effort, as traditionally observed. The duality between the model-free coupled Bellman optimality equation and the underlying coupled Riccati equation is highlighted. This is followed by a graph simulation scenario to test the usefulness of the proposed policy iteration process.
ER  - 

TY  - CONF
TI  - Robust Area Coverage with Connectivity Maintenance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2202
EP  - 2208
AU  - L. Siligardi
AU  - J. Panerati
AU  - M. Kaufmann
AU  - M. Minelli
AU  - C. Ghedini
AU  - G. Beltrame
AU  - L. Sabattini
PY  - 2019
KW  - computational geometry
KW  - multi-robot systems
KW  - robust swarm connectivity
KW  - coverage task
KW  - Khepera IV robots
KW  - tri-objective control law
KW  - potential-based coverage
KW  - network connectivity
KW  - robust area coverage
KW  - connectivity maintenance
KW  - robotic swarm
KW  - control laws
KW  - swarm robotics
KW  - globally coordinated behavior
KW  - Voronoi tessellation
KW  - Robot kinematics
KW  - Robustness
KW  - Multi-robot systems
KW  - Maintenance engineering
KW  - Robot sensing systems
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793555
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot swarms herald the ability to solve complex tasks using a large collection of simple devices. However, engineering a robotic swarm is far from trivial, with a major hurdle being the definition of the control laws leading to the desired globally coordinated behavior. Communication is a key element for coordination and it is considered one of the current most important challenges for swarm robotics. In this paper, we study the problem of maintaining robust swarm connectivity while performing a coverage task based on the Voronoi tessellation of an area of interest. We implement our methodology in a team of eight Khepera IV robots. With the assumptions that robots have a limited sensing and communication range-and cannot rely on centralized processing-we propose a tri-objective control law that outperforms other simpler strategies (e.g. a potential-based coverage) in terms of network connectivity, robustness to failure, and area coverage.
ER  - 

TY  - CONF
TI  - Living with a Mobile Companion Robot in your Own Apartment - Final Implementation and Results of a 20-Weeks Field Study with 20 Seniors*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2253
EP  - 2259
AU  - H. Gross
AU  - A. Scheidig
AU  - S. Müller
AU  - B. Schütz
AU  - C. Fricke
AU  - S. Meyer
PY  - 2019
KW  - geriatrics
KW  - home automation
KW  - mobile robots
KW  - service robots
KW  - mobile companion robot
KW  - apartment
KW  - German research project SYMPARTNER
KW  - functional-emotional robot companion
KW  - mobile domestic robot companion
KW  - elderly people
KW  - developed robot
KW  - system architecture
KW  - essential skills
KW  - friendly home companion
KW  - long-term field study
KW  - robustness
KW  - domestic operating conditions
KW  - social scientific questions
KW  - autonomous companion robots
KW  - single-person households
KW  - senior households
KW  - time 20 week
KW  - Tactile sensors
KW  - Three-dimensional displays
KW  - Legged locomotion
KW  - Navigation
DO  - 10.1109/ICRA.2019.8793693
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the results of the German research project SYMPARTNER (4/2015 - 6/2018), which aimed at developing a functional-emotional, mobile domestic robot companion for elderly people. The paper gives an overview of the developed robot, its system architecture, and essential skills and behaviors required for being a friendly home companion. Based on this, in a long-term field study running from January to June 2018 both technical aspects regarding the practical suitability and robustness of the robot under domestic operating conditions and social scientific questions on usability and acceptance of the robot and the users' familiarization with their new housemate were evaluated. In the field study, two of these autonomous companion robots were used in 20 senior households in Erfurt (Germany). All participants lived with their robot in their apartments for one week without the need for supervising or supporting persons being present on-site. The tests in 20 single-person households in the age group 62 to 94 years (average 74 years) provided important insights into the special challenges of domesticity from a technical, social scientific, and user-oriented point of view. The results of the study show how seniors can shape their everyday life with a companion robot and how quickly they get used to the new housemate.
ER  - 

TY  - CONF
TI  - Enabling Identity-Aware Tracking via Fusion of Visual and Inertial Features
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2260
EP  - 2266
AU  - R. Y. Tsai
AU  - H. T. Ke
AU  - K. C. Lin
AU  - Y. Tseng
PY  - 2019
KW  - calibration
KW  - robot vision
KW  - sensor fusion
KW  - synchronisation
KW  - target tracking
KW  - robust PIT
KW  - data fusion technique
KW  - RGB-D camera
KW  - wearable inertial sensors
KW  - time synchronization
KW  - robotic platform
KW  - biological feature
KW  - recognition rate
KW  - visual features
KW  - inertial features
KW  - computer vision
KW  - robotic applications
KW  - RFID
KW  - environmental constraints
KW  - recognition accuracy
KW  - identity-aware tracking
KW  - Skeleton
KW  - Cameras
KW  - Robot sensing systems
KW  - Target tracking
KW  - Robot kinematics
KW  - Computer Vision
KW  - Data Fusion
KW  - IoT
KW  - Person Identification
KW  - Tracking
KW  - Robotics
KW  - Wearable Computing
DO  - 10.1109/ICRA.2019.8793839
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Person identification and tracking (PIT) is an essential issue in computer vision and robotic applications. It has long been studied and achieved by technologies such as RFID or face/fingerprint/iris recognition. These approaches, however, have their limitations due to environmental constraints (such as lighting and obstacles) or require close contact to specific devices. Therefore, their recognition accuracy highly depends on use scenarios. In this work, we propose RCU (Robot Catch yoU), an accompanyist robot system that provides follow-me or guide-me services. Such robots are capable of distinguishing users' profiles in front of them and keep tracking a specific target person. We study a more challenging scenario where the target person may be under occlusion from time to time. To enable robust PIT, we develop a data fusion technique that integrates two types of sensors, an RGB-D camera and wearable inertial sensors. Since the data generated by these sensors share common features, we are able to fuse them to achieve identity-aware tracking. Practical issues, such as time synchronization and coordinate calibration, are also addressed. We implement our design on a robotic platform and show that it can track a target person even when no biological feature is captured by the RGB-D camera. Our experimental evaluation shows a recognition rate of 95% and a following rate of 88%.
ER  - 

TY  - CONF
TI  - Inverse Reinforcement Learning of Interaction Dynamics from Demonstrations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2267
EP  - 2274
AU  - M. Hussein
AU  - M. Begum
AU  - M. Petrik
PY  - 2019
KW  - decision theory
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - inverse reinforcement learning methods
KW  - high-level sequential tasks
KW  - human demonstrations
KW  - POMDP policies
KW  - interaction dynamics
KW  - human-robot interaction domain
KW  - structured interactions
KW  - partially observable Markov decision process
KW  - learning from demonstration
KW  - IRL algorithms
KW  - reward function learning
KW  - MDPIRL algorithm
KW  - Robots
KW  - Task analysis
KW  - Education
KW  - Reinforcement learning
KW  - Uncertainty
KW  - Aircraft navigation
KW  - Human-robot interaction
DO  - 10.1109/ICRA.2019.8793867
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a framework to learn the reward function underlying high-level sequential tasks from demonstrations. The purpose of reward learning, in the context of learning from demonstration (LfD), is to generate policies that mimic the demonstrator's policies, thereby enabling imitation learning. We focus on a human-robot interaction (HRI) domain where the goal is to learn and model structured interactions between a human and a robot. Such interactions can be modeled as a partially observable Markov decision process (POMDP) where the partial observability is caused by uncertainties associated with the ways humans respond to different stimuli. The key challenge in finding a good policy in such a POMDP is determining the reward function that was observed by the demonstrator. Existing inverse reinforcement learning (IRL) methods for POMDPs are computationally very expensive and the problem is not well understood. In comparison, IRL algorithms for Markov decision process (MDP) are well defined and computationally efficient. We propose an approach of reward function learning for high-level sequential tasks from human demonstrations where the core idea is to reduce the underlying POMDP to an MDP and apply any efficient MDPIRL algorithm. Our extensive experiments suggest that the reward function learned this way generates POMDP policies that mimic the policies of the demonstrator well.
ER  - 

TY  - CONF
TI  - Investigating Design Elements of Companion Robots for Older Adults
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2275
EP  - 2281
AU  - Y. H. Oh
AU  - J. Kim
AU  - S. Jeong
AU  - a. Y. Ju
PY  - 2019
KW  - age issues
KW  - design engineering
KW  - health care
KW  - human-robot interaction
KW  - medical robotics
KW  - psychology
KW  - service robots
KW  - older adults
KW  - robot design elements
KW  - depression
KW  - physical preferences
KW  - psychological health
KW  - depressive symptoms
KW  - companion robots
KW  - Robots
KW  - Dogs
KW  - Analysis of variance
KW  - Pediatrics
KW  - Psychology
KW  - Synthetic fibers
KW  - Aging
DO  - 10.1109/ICRA.2019.8793583
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Older adults are vulnerable to symptoms of depression. The degree of depression is particularly high among older adults who live alone. To address this issue, various companion robots, which are capable of psychologically communicating with users, have been proposed. However, older adults' preferences on the appearance of these robots have not been systematically investigated; this forms the focus of the present study. We interviewed 191 older adults; investigated their preferences on the design elements of robots including type, weight, and material; and analyzed the data by age, gender, and living arrangement. Our primary goal was to determine how companion robots should be designed, paying special attention to older adults who live alone. Our findings indicated that those living alone prefer a bear-like robot and negative to the heavy robot. Our results suggest that companion robots need to be designed with careful consideration of older adults' physical and psychological preferences.
ER  - 

TY  - CONF
TI  - Development of Informative Path Planning for Inspection of the Hanford Tank Farm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2297
EP  - 2303
AU  - S. A. Zanlongo
AU  - L. Bobadilla
AU  - D. McDaniel
AU  - Y. T. Tan
PY  - 2019
KW  - inspection
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - rastering technique
KW  - high-level nuclear waste tanks
KW  - Hanford facility
KW  - robotic inspection
KW  - utility function
KW  - informative path planning
KW  - Hanford tank farm
KW  - structural monitoring
KW  - static sensor networks
KW  - predetermined locations
KW  - mobile robots
KW  - Bayesian optimization approach
KW  - Robot sensing systems
KW  - Kernel
KW  - Inspection
KW  - Temperature measurement
KW  - Gaussian processes
KW  - Welding
DO  - 10.1109/ICRA.2019.8794138
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Traditional environmental and structural monitoring often uses static sensor networks deployed at predetermined locations or mobile robots that use a rastering technique for area coverage. These methods rely on the operators making assumptions about the nature of the unknown field that is being measured and are often time-consuming for localizing an area of interest. Here, we aim to quickly localize possible leaks within high-level nuclear waste tanks at the Hanford facility. The structure of these tanks precludes most sensor network approaches and raises many issues with robotic inspection, such as navigation within highly constrained environments. This work uses a Bayesian Optimization approach for guiding a mobile robot's search strategy and implements a utility function that allows for prior knowledge of the structure to be incorporated when selecting future search locations. Compared to traditional exhaustive approaches, our method quickly reduces RMSE error and shortens the distance the robot must travel.
ER  - 

TY  - CONF
TI  - A Fuzzy Based Accessibility Model for Disaster Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2304
EP  - 2310
AU  - K. Balan
AU  - M. P. Manuel
AU  - M. Faied
AU  - M. Krishnan
AU  - M. Santora
PY  - 2019
KW  - angular velocity control
KW  - collision avoidance
KW  - disasters
KW  - fuzzy control
KW  - fuzzy reasoning
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - terrain accessibility index
KW  - robots position
KW  - angular velocities
KW  - VFH algorithm
KW  - disaster prone environment
KW  - FISVFH algorithm
KW  - fuzzy based accessibility model
KW  - disaster environment
KW  - autonomous maneuvering
KW  - robot estimate
KW  - two-output fuzzy inference system
KW  - sector accessibility index
KW  - fuzzy inference system vector field histogram method
KW  - obstacle distance
KW  - linear velocities
KW  - two-input fuzzy inference system
KW  - Indexes
KW  - Angular velocity
KW  - Fuzzy logic
KW  - Robot sensing systems
KW  - Histograms
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8793602
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots that perform autonomous maneuvering in a disaster environment usually dont have perfect understanding of the environment in advance. The robot is continuously evaluating the environment as it proceeds, deciding the optimal way to traverse the environment to get to the goal. A critical aspect of this decision is the robot estimate of the terrain accessibility index, which quantifies how easy it is to navigate through the immediate terrain. This paper represents a new method to calculate terrain accessibility index based on obstacle distance to the robots position. In addition, a Fuzzy Inference System Vector Field Histogram (FISVFH) method has been designed for automating the selection of the robots linear and angular velocities in the VFH (Vector Field Histogram) algorithm, based on the calculated sector accessibility index. The proposed method is a two-input and two-output Fuzzy Inference System, where the current robot heading, and sector accessibility index serve as the input, and the corresponding linear and angular velocities to the VFH algorithm are outputs. The VFH, VFH + and FISVFH are tested both in simulation and experimentation in 4 environments that are known to result in failures in VFH and VFH +, for comparison purposes. In addition, the algorithm was verified through experimental setup of a disaster prone environment. In both simulation and experimentation the results show that FISVFH outperforms VFH and VFH +. It is also shown that the FISVFH algorithm is capable of handling the disaster prone environment. Overall, the FISVFH algorithm enables the robot to get to the goal faster and also produces a smoother path while doing so.
ER  - 

TY  - CONF
TI  - Learning to Predict the Wind for Safe Aerial Vehicle Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2311
EP  - 2317
AU  - F. Achermann
AU  - N. R. J. Lawrance
AU  - R. Ranftl
AU  - A. Dosovitskiy
AU  - J. J. Chung
AU  - R. Siegwart
PY  - 2019
KW  - autonomous aerial vehicles
KW  - convolutional neural nets
KW  - mobile robots
KW  - path planning
KW  - sampling methods
KW  - wind
KW  - safe aerial vehicle planning
KW  - local wind
KW  - unmanned aerial vehicles
KW  - wind environment
KW  - relatively low mass
KW  - high-resolution wind fields
KW  - terrain elevation model
KW  - deep convolutional neural network
KW  - sampling-based planner
KW  - strong wind scenarios
KW  - UAV
KW  - inflow conditions
KW  - prediction error
KW  - wind estimation techniques
KW  - Wind forecasting
KW  - Planning
KW  - Computational modeling
KW  - Wind speed
KW  - Predictive models
KW  - Data models
DO  - 10.1109/ICRA.2019.8793547
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Obtaining an accurate estimate of the local wind remains a significant challenge for small unmanned aerial vehicles (UAVs). Small UAVs often operate at low altitudes near terrain, where the wind environment can be more complex than at higher altitudes. Combined with their relatively low mass, this makes small UAVs particularly susceptible to wind. In this paper we present an approach for predicting high-resolution wind fields based on a terrain elevation model and known inflow conditions. Our approach uses a deep convolutional neural network (CNN) to generate 3D wind estimates. We show that our approach produces wind estimates with lower prediction error than existing methods, and that inference can be performed on an on-board computer in less than two seconds. By providing the wind estimate to a sampling-based planner we show that the improved estimates allow the planner to generate safer paths in strong wind scenarios than with alternative wind estimation techniques.
ER  - 

TY  - CONF
TI  - Distributed Radiation Field Estimation and Informative Path Planning for Nuclear Environment Characterization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2318
EP  - 2324
AU  - F. Mascarich
AU  - C. Papachristos
AU  - T. Wilson
AU  - K. Alexis
PY  - 2019
KW  - Global Positioning System
KW  - mobile robots
KW  - optical radar
KW  - path planning
KW  - photomultipliers
KW  - scintillation counters
KW  - solid scintillation detectors
KW  - thallium
KW  - distributed radiation field estimation
KW  - informative path planning
KW  - nuclear environment characterization
KW  - autonomous estimation
KW  - distributed nuclear radiation fields
KW  - GPS-denied environments
KW  - sensing apparatus
KW  - radially placed Thallium-doped Cesium Iodide
KW  - Silicon Photomultipliers
KW  - pulse counting circuitry
KW  - provided readings
KW  - LiDAR-based localization
KW  - radiation intensity readings
KW  - immediate field gradient
KW  - believed field intensity
KW  - local measurement
KW  - field gradient co-estimation
KW  - informative data gathering
KW  - path planning strategy
KW  - uncertainty
KW  - admissible paths
KW  - autonomous exploration
KW  - SiPm
KW  - Estimation
KW  - Detectors
KW  - Robot sensing systems
KW  - Path planning
KW  - Uncertainty
KW  - Area measurement
DO  - 10.1109/ICRA.2019.8794402
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper details the system and methods designed to enable the autonomous estimation of distributed nuclear radiation fields within complex and possibly GPS-denied environments. A sensing apparatus consisting of three radially placed Thallium-doped Cesium Iodide (CsI(Tl)) scintillators and Silicon Photomultipliers (SiPm) combined with custom- built pulse counting circuitry is designed and the provided readings are pose-annotated using LiDAR-based localization. Given this capacity, a method that utilizes the radiation intensity readings to first calculate the immediate field gradient and then combine this information to update and co-estimate the believed field intensity and gradient across the whole environment is developed. The strategy propagates the effect of each local measurement through field gradient co-estimation and simultaneously derives a model of the underlying uncertainty. To further support the need for informative data gathering, especially in the framework of emergency and rapid reconnaissance missions, a path planning strategy is also developed that first utilizes the field intensity and uncertainty estimates to select its new waypoint and then performs terrain traversability analysis to derive admissible paths. The complete system is evaluated both in simulation and experimentally. The experimental results refer to the autonomous exploration and field estimation inside an indoor facility within which actual radioactive uranium and thorium ore sources have been distributed.
ER  - 

TY  - CONF
TI  - Visual recognition in the wild by sampling deep similarity functions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2341
EP  - 2347
AU  - M. Usvyatsov
AU  - K. Schindler
PY  - 2019
KW  - convolutional neural nets
KW  - image representation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - pattern classification
KW  - probability
KW  - probabilities
KW  - class variability
KW  - images range
KW  - training exemplars
KW  - relative similarities
KW  - class predictions
KW  - class labels
KW  - CNN
KW  - test data
KW  - training data
KW  - recognition system
KW  - target class
KW  - deep convolutional neural networks
KW  - supervised machine learning
KW  - autonomous robot
KW  - deep similarity functions
KW  - visual recognition
KW  - Training
KW  - Computer aided instruction
KW  - Visualization
KW  - Robots
KW  - Neural networks
KW  - Labeling
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794162
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recognising relevant objects or object states in its environment is a basic capability for an autonomous robot. The dominant approach to object recognition in images and range images is classification by supervised machine learning, nowadays mostly with deep convolutional neural networks (CNNs). This works well for target classes whose variability can be completely covered with training examples. However, a robot moving in the wild, i.e., in an environment that is not known at the time the recognition system is trained, will often face domain shift: the training data cannot be assumed to exhaustively cover all the within-class variability that will be encountered in the test data. In that situation, learning is in principle possible, since the training set does capture the defining properties, respectively dissimilarities, of the target classes. But directly training a CNN to predict class probabilities is prone to overfitting to irrelevant correlations between the class labels and the specific subset of the target class that is represented in the training set. We explore the idea to instead learn a Siamese CNN that acts as similarity function between pairs of training examples. Class predictions are then obtained by measuring the similarities between a new test instance and the training samples. We show that the CNN embedding correctly recovers the relative similarities to arbitrary class exemplars in the training set. And that therefore few, randomly picked training exemplars are sufficient to achieve good predictions, making the procedure efficient.
ER  - 

TY  - CONF
TI  - Evaluating Merging Strategies for Sampling-based Uncertainty Techniques in Object Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2348
EP  - 2354
AU  - D. Miller
AU  - F. Dayoub
AU  - M. Milford
AU  - N. Sünderhauf
PY  - 2019
KW  - merging
KW  - neural nets
KW  - object detection
KW  - pattern clustering
KW  - sampling methods
KW  - statistical analysis
KW  - merging strategies
KW  - sampling-based uncertainty techniques
KW  - epistemic uncertainty
KW  - deep neural networks
KW  - affinity-clustering combination
KW  - spatial uncertainty estimation
KW  - object detection
KW  - Uncertainty
KW  - Object detection
KW  - Detectors
KW  - Clustering methods
KW  - Semantics
KW  - Measurement uncertainty
KW  - Robots
DO  - 10.1109/ICRA.2019.8793821
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There has been a recent emergence of sampling-based techniques for estimating epistemic uncertainty in deep neural networks. While these methods can be applied to classification or semantic segmentation tasks by simply averaging samples, this is not the case for object detection, where detection sample bounding boxes must be accurately associated and merged. A weak merging strategy can significantly degrade the performance of the detector and yield an unreliable uncertainty measure. This paper provides the first in-depth investigation of the effect of different association and merging strategies. We compare different combinations of three spatial and two semantic affinity measures with four clustering methods for MC Dropout with a Single Shot Multi-Box Detector. Our results show that the correct choice of affinity-clustering combination can greatly improve the effectiveness of the classification and spatial uncertainty estimation and the resulting object detection performance. We base our evaluation on a new mix of datasets that emulate near open-set conditions (semantically similar unknown classes), distant open-set conditions (semantically dissimilar unknown classes) and the common closed-set conditions (only known classes).
ER  - 

TY  - CONF
TI  - Training a Binary Weight Object Detector by Knowledge Transfer for Autonomous Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2379
EP  - 2384
AU  - J. Xu
AU  - Y. Nie
AU  - P. Wang
AU  - A. M. López
PY  - 2019
KW  - computer vision
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - object detection
KW  - road traffic
KW  - traffic engineering computing
KW  - binary weight object detector
KW  - autonomous driving
KW  - energy efficiency
KW  - on-board object detection
KW  - object detectors
KW  - low-precision neural networks
KW  - computation requirements
KW  - memory footprint
KW  - binary weight neural networks
KW  - BWNs
KW  - knowledge transfer method
KW  - full-precision teacher network
KW  - MobileNet-based binary weight YOLOv2 detectors
KW  - pedestrian
KW  - cyclist detection
KW  - KITTI benchmark
KW  - MobileNet-YOLO
KW  - DarkNet-YOLO
KW  - deep convolutional neural network
KW  - word length 1.0 bit
KW  - memory size 8.8 MByte to 257.0 MByte
KW  - memory size 7.9 MByte to 193.0 MByte
KW  - Training
KW  - Detectors
KW  - Neural networks
KW  - Quantization (signal)
KW  - Knowledge transfer
KW  - Task analysis
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2019.8793743
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous driving has harsh requirements of small model size and energy efficiency, in order to enable the embedded system to achieve real-time on-board object detection. Recent deep convolutional neural network based object detectors have achieved state-of-the-art accuracy. However, such models are trained with numerous parameters and their high computational costs and large storage prohibit the deployment to memory and computation resource limited systems. Low-precision neural networks are popular techniques for reducing the computation requirements and memory footprint. Among them, binary weight neural networks (BWNs) are the extreme case which quantizes the float-point into just 1 bit. BWNs are difficult to train and suffer from accuracy deprecation due to the extreme low-bit representation. To address this problem, we propose a knowledge transfer (KT) method to aid the training of BWN using a full-precision teacher network. We built DarkNet- and MobileNet-based binary weight YOLOv2 detectors and conduct experiments on KITTI benchmark for car, pedestrian and cyclist detection. The experimental results show that the proposed method maintains high detection accuracy while reducing the model size of DarkNet-YOLO from 257 MB to 8.8 MB and MobileNet-YOLO from 193 MB to 7.9 MB.
ER  - 

TY  - CONF
TI  - Visual SLAM: Why Bundle Adjust?
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2385
EP  - 2391
AU  - Á. P. Bustos
AU  - T. Chin
AU  - A. Eriksson
AU  - I. Reid
PY  - 2019
KW  - cameras
KW  - feature extraction
KW  - image sequences
KW  - motion estimation
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - video signal processing
KW  - bundle adjustment
KW  - feature-based monocular SLAM
KW  - camera orientation optimisation
KW  - camera position estimation
KW  - quasiconvex formulation
KW  - keyframe rate
KW  - SLAM optimisation
KW  - rotational motion
KW  - slow motion
KW  - SLAM algorithm
KW  - 3D structure estimation
KW  - input feature tracks
KW  - 3D point cloud
KW  - 3D map estimation
KW  - 6DOF camera trajectory estimation
KW  - visual SLAM
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Estimation
KW  - Bundle adjustment
KW  - Optimization
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793749
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Bundle adjustment plays a vital role in feature-based monocular SLAM. In many modern SLAM pipelines, bundle adjustment is performed to estimate the 6DOF camera trajectory and 3D map (3D point cloud) from the input feature tracks. However, two fundamental weaknesses plague SLAM systems based on bundle adjustment. First, the need to carefully initialise bundle adjustment means that all variables, in particular the map, must be estimated as accurately as possible and maintained over time, which makes the overall algorithm cumbersome. Second, since estimating the 3D structure (which requires sufficient baseline) is inherent in bundle adjustment, the SLAM algorithm will encounter difficulties during periods of slow motion or pure rotational motion. We propose a different SLAM optimisation core: instead of bundle adjustment, we conduct rotation averaging to incrementally optimise only camera orientations. Given the orientations, we estimate the camera positions and 3D points via a quasi-convex formulation that can be solved efficiently and globally optimally. Our approach not only obviates the need to estimate and maintain the positions and 3D map at keyframe rate (which enables simpler SLAM systems), it is also more capable of handling slow motions or pure rotational motions.
ER  - 

TY  - CONF
TI  - Illumination Robust Monocular Direct Visual Odometry for Outdoor Environment Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2392
EP  - 2398
AU  - X. Wu
AU  - C. Pradalier
PY  - 2019
KW  - distance measurement
KW  - image colour analysis
KW  - lighting
KW  - mobile robots
KW  - motion estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - illumination-robust direct monocular SLAM system
KW  - global lighting changes
KW  - local lighting changes
KW  - stereo SLAM systems
KW  - camera motion
KW  - scene structure
KW  - high-precision motion estimation
KW  - illumination robust monocular direct visual odometry
KW  - outdoor environment
KW  - illumination invariant photometric costs
KW  - vision-based localization and mapping
KW  - RGB-D
KW  - DSO system
KW  - ORBSLAM2 system
KW  - Lighting
KW  - Optimization
KW  - Robustness
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Motion estimation
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793607
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Vision-based localization and mapping in outdoor environments is still a challenging issue, which requests significant robustness against various unpredictable illumination changes. In this paper, an illumination-robust direct monocular SLAM system that focuses on modeling outdoor scenery is presented. To deal with global and local lighting changes, such as solar flares, the state-of-art illumination invariant photometric costs for RGB-D and stereo SLAM systems are revisited in the context of their monocular counterpart, where the camera motion and scene structure are jointly optimized with a reasonably poor initialization. Based on our analysis, a combined cost is proposed to achieve a high-precision motion estimation with an improved convergence radius. The proposed system is extensively evaluated on the synthetic and real-world datasets regarding accuracy, robustness, and processing time, where our approach outperforms systems with other costs and state-of-art DSO and ORBSLAM2 systems.
ER  - 

TY  - CONF
TI  - A Comparison of CNN-Based and Hand-Crafted Keypoint Descriptors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2399
EP  - 2404
AU  - Z. Dai
AU  - X. Huang
AU  - W. Chen
AU  - L. He
AU  - H. Zhang
PY  - 2019
KW  - convolutional neural nets
KW  - image matching
KW  - neurocontrollers
KW  - robot vision
KW  - SLAM (robots)
KW  - pre-trained CNN descriptors
KW  - viewpoint changes
KW  - illumination changes
KW  - hand-crafted keypoint descriptors
KW  - keypoint matching
KW  - computer vision
KW  - keypoint description
KW  - trained convolutional neural networks
KW  - pre-trained CNNs
KW  - hand-crafted descriptors
KW  - visual simultaneous localization and mapping
KW  - CNN-based descriptors
KW  - SLAM
KW  - Lighting
KW  - Computational modeling
KW  - Detectors
KW  - Dogs
KW  - Simultaneous localization and mapping
KW  - Measurement
DO  - 10.1109/ICRA.2019.8793701
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Keypoint matching is an important operation in computer vision and its applications such as visual simultaneous localization and mapping (SLAM) in robotics. This matching operation heavily depends on the descriptors of the keypoints, and it must be performed reliably when images undergo condition changes such as those in illumination and viewpoint. Previous research in keypoint description has pursued three classes of descriptors: hand-crafted, those from trained convolutional neural networks (CNN), and those from pre-trained CNNs. This paper provides a comparative study of the three classes of keypoint descriptors, in terms of their ability to handle conditional changes. The study is conducted on the latest benchmark datasets in computer vision with challenging conditional changes. Our study finds that (a) in general CNN-based descriptors outperform hand-crafted descriptors, (b) the trained CNN descriptors perform better than pre-trained CNN descriptors with respect to viewpoint changes, and (c) pre-trained CNN descriptors perform better than trained CNN descriptors with respect to illumination changes. These findings can serve as a basis for selecting appropriate keypoint descriptors for various applications.
ER  - 

TY  - CONF
TI  - Environment Driven Underwater Camera-IMU Calibration for Monocular Visual-Inertial SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2405
EP  - 2411
AU  - C. Gu
AU  - Y. Cong
AU  - G. Sun
PY  - 2019
KW  - autonomous underwater vehicles
KW  - calibration
KW  - cameras
KW  - inertial navigation
KW  - mobile robots
KW  - SLAM (robots)
KW  - visual-inertial SLAM
KW  - shallow water
KW  - calibration errors
KW  - environmental indexes
KW  - underwater camera-inertial measurement unit
KW  - simultaneous localization and mapping
KW  - intrinsic parameters
KW  - extrinsic parameters
KW  - underwater monocular vision systems
KW  - environment driven underwater camera-IMU calibration
KW  - Cameras
KW  - Calibration
KW  - Atmospheric modeling
KW  - Simultaneous localization and mapping
KW  - Geometry
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793577
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Most state-of-the-art underwater vision systems are calibrated manually in shallow water and used in open seas without changing. However, the refractivity of the water is adaptively changed depending on the salinity, temperature, depth or other underwater environmental indexes, which inevitably generate the calibration errors and induces incorrectness e.g., for underwater Simultaneously Localization and Mapping (SLAM). To address this issue, in this paper, we propose a new underwater Camera-Inertial Measurement Unit (IMU) calibration model, which just needs to be calibrated once in the air, and then both the intrinsic parameters and extrinsic parameters between the camera and IMU could be automatically calculated depending on the environment indexes. To our best knowledge, this is the first work to consider the underwater Camera-IMU calibration via environmental indexes. We also build a verification platform to validate the effectiveness of our proposed method on real experiments, and use it for underwater monocular Visual-Inertial SLAM.
ER  - 

TY  - CONF
TI  - Leveraging Structural Regularity of Atlanta World for Monocular SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2412
EP  - 2418
AU  - H. Li
AU  - Y. Xing
AU  - J. Zhao
AU  - J. Bazin
AU  - Z. Liu
AU  - Y. Liu
PY  - 2019
KW  - Kalman filters
KW  - maximum likelihood estimation
KW  - polynomials
KW  - SLAM (robots)
KW  - multiple local Atlanta frames
KW  - global Atlanta frames
KW  - world frame
KW  - structural regularity
KW  - monocular SLAM
KW  - common vertical axis
KW  - multiple horizontal axes
KW  - camera frame
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Cameras
KW  - Estimation
KW  - Optimization
KW  - Reliability
DO  - 10.1109/ICRA.2019.8793716
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A wide range of man-made environments can be abstracted as the Atlanta world. It consists of a set of Atlanta frames with a common vertical (gravitational) axis and multiple horizontal axes orthogonal to this vertical axis. This paper focuses on leveraging the regularity of Atlanta world for monocular SLAM. First, we robustly cluster image lines. Based on these clusters, we compute the local Atlanta frames in the camera frame by solving polynomial equations. Our method provides the global optimum and satisfies inherent geometric constraints. Second, we define the posterior probabilities to refine the initial clusters and Atlanta frames alternately by the maximum a posteriori estimation. Third, based on multiple local Atlanta frames, we compute the global Atlanta frames in the world frame using Kalman filtering. We optimize rotations by the global alignment and then refine translations and 3D line-based map under the directional constraints. Experiments on both synthesized and real data have demonstrated that our approach outperforms state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Multimodal Semantic SLAM with Probabilistic Data Association
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2419
EP  - 2425
AU  - K. Doherty
AU  - D. Fourie
AU  - J. Leonard
PY  - 2019
KW  - image fusion
KW  - image representation
KW  - inference mechanisms
KW  - mobile robots
KW  - object detection
KW  - path planning
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - nonGaussian sensor model
KW  - multimodal semantic SLAM
KW  - probabilistic data association
KW  - robot navigation
KW  - semantic SLAM problem
KW  - discrete inference problem
KW  - object class labels
KW  - measurement-landmark correspondences
KW  - continuous inference problem
KW  - robot poses
KW  - object detection systems
KW  - simultaneous localization and mapping
KW  - object-based representations
KW  - object locations
KW  - nonGaussian inference problem
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Belief propagation
KW  - Maximum likelihood estimation
KW  - Maximum likelihood detection
DO  - 10.1109/ICRA.2019.8794244
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The recent success of object detection systems motivates object-based representations for robot navigation; i.e. semantic simultaneous localization and mapping (SLAM). The semantic SLAM problem can be decomposed into a discrete inference problem: determining object class labels and measurement-landmark correspondences (the data association problem), and a continuous inference problem: obtaining the set of robot poses and object locations in the environment. A solution to the semantic SLAM problem necessarily addresses this joint inference, but under ambiguous data associations this is in general a non-Gaussian inference problem, while the majority of previous work focuses on Gaussian inference. Previous solutions to data association either produce solutions between potential hypotheses or maintain multiple explicit hypotheses for each association. We propose a solution that represents hypotheses as multiple modes of an equivalent non-Gaussian sensor model. We then solve the resulting non-Gaussian inference problem using nonparametric belief propagation. We validate our approach in a simulated hallway environment under a variety of sensor noise characteristics, as well as using real data from the KITTI dataset, demonstrating improved robustness to perceptual aliasing and odometry uncertainty.
ER  - 

TY  - CONF
TI  - Improving Incremental Planning Performance through Overlapping Replanning and Execution
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2426
EP  - 2432
AU  - M. Orton
AU  - S. Dai
AU  - S. Schaffert
AU  - A. Hofmann
AU  - B. Williams
PY  - 2019
KW  - path planning
KW  - robots
KW  - trajectory control
KW  - integrated motion planning
KW  - Chekov
KW  - trajectory optimization problems
KW  - roadmap seed trajectories
KW  - motion planning algorithms
KW  - control information
KW  - incremental planning
KW  - Planning
KW  - Dynamics
KW  - Mobile robots
KW  - Trajectory optimization
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793642
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deployment of motion planning algorithms in practical applications has lagged due to their slow speed in reacting to disturbances. We believe that the best way to address this is to reuse learned planning and control information across queries. In previous work, we introduced Chekov, a reactive, integrated motion planning and execution system that reuses learned information in the form of an enhanced roadmap. We have previously shown how we can use Chekov to formulate trajectory optimization problems that result in superior performance in static environments. In this work, we show how incremental planning can be incorporated into the formulation of optimized trajectories from roadmap seed trajectories. Further, we show how an incremental planner can be adapted to reduce the overhead incurred for replanning when trajectories become invalid during execution.
ER  - 

TY  - CONF
TI  - Multimodal Policy Search using Overlapping Mixtures of Sparse Gaussian Process Prior
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2433
EP  - 2439
AU  - H. Sasaki
AU  - T. Matsubara
PY  - 2019
KW  - Bayes methods
KW  - Gaussian processes
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - search problems
KW  - OMSGPs
KW  - optimal policies
KW  - reinforcement learning
KW  - multimodal policy search algorithm
KW  - overlapping mixtures of sparse Gaussian process
KW  - Bayesian inference
KW  - object grasping
KW  - table-sweep tasks
KW  - Task analysis
KW  - Grasping
KW  - Kernel
KW  - Gaussian processes
KW  - Robots
KW  - Inference algorithms
KW  - Prediction algorithms
DO  - 10.1109/ICRA.2019.8794131
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a novel policy search reinforcement learning algorithm that can deal with multimodality in control policies based on Gaussian processes. Our approach employs Overlapping Mixtures of Gaussian Processes (OMGPs) for a control policy, in which all the GPs in the mixture are global and overlapped in the input space. We first extend the OMGPs by combing sparse pseudo-input GPs as OMSGPs to reduce its computational cost of learning and prediction suitable for policy search. Then, we derive a novel multimodal policy search algorithm based on variational Bayesian inference by placing the OMSGPs as the prior of the multimodal control policy. To validate the effectiveness of our algorithm, we applied it to two typical robotic tasks in simulation: 1) object grasping and 2) table-sweep tasks since they both require the multimodality in the optimal policies. Simulation results demonstrate that our algorithm can efficiently learn multimodal policies even with high dimensional observations.
ER  - 

TY  - CONF
TI  - Online adaptation of uncertain models using neural network priors and partially observable planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2440
EP  - 2446
AU  - A. Hayashi
AU  - D. Ruiken
AU  - C. Goerick
AU  - T. Hasegawa
PY  - 2019
KW  - Markov processes
KW  - mobile robots
KW  - neural nets
KW  - planning (artificial intelligence)
KW  - uncertain systems
KW  - online adaptation
KW  - uncertain models
KW  - neural network priors
KW  - partially observable planning
KW  - manipulation tasks
KW  - encode prior experiences
KW  - physics engine
KW  - online POMDP solver
KW  - observed environments
KW  - prediction model
KW  - domain complexity
KW  - Adaptation models
KW  - Task analysis
KW  - Physics
KW  - Planning
KW  - Robots
KW  - Engines
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793630
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - One of the key challenges in realizing a robot that is capable of completing a variety of manipulation tasks in the real world is the need to utilize sufficiently compact and rich world models. If the assumed prediction model does not match real observations, planning systems are unable to perform properly. We propose a system that corrects the models based on information collected from the robot's sensors. We encode prior experiences in a neural network to generate possible parameters of the models for a physics engine from real observations. An online POMDP solver is used to plan actions to complete the task while progressively validating and improving the models. We perform experiments in simulations and on a real robot. The results show that this approach appropriately clarifies observed environments, can handle dynamics with discontinuities, and with increasing domain complexity achieves a better success rate than baseline methods.
ER  - 

TY  - CONF
TI  - Contact-Implicit Trajectory Optimization Based on a Variable Smooth Contact Model and Successive Convexification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2447
EP  - 2453
AU  - A. Ö. Önol
AU  - P. Long
AU  - T. Padır
PY  - 2019
KW  - gradient methods
KW  - linear quadratic control
KW  - manipulators
KW  - mobile robots
KW  - optimisation
KW  - trajectory control
KW  - CITO
KW  - variable smooth contact model
KW  - VSCM
KW  - successive convexification
KW  - gradient-based optimization
KW  - nonprehensile manipulation tasks
KW  - iterative linear quadratic regulator
KW  - physically-consistent motions
KW  - SCvx-based method
KW  - iLQR-based method
KW  - contact-implicit trajectory optimization method
KW  - robot platform
KW  - Robots
KW  - Convergence
KW  - Trajectory optimization
KW  - Task analysis
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794250
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a contact-implicit trajectory optimization (CITO) method based on a variable smooth contact model (VSCM) and successive convexification (SCvx). The VSCM facilitates the convergence of gradient-based optimization without compromising physical fidelity. On the other hand, the proposed SCvx-based approach combines the advantages of direct and shooting methods for CITO. For evaluations, we consider non-prehensile manipulation tasks. The proposed method is compared to a version based on iterative linear quadratic regulator (iLQR) on a planar example. The results demonstrate that both methods can find physically-consistent motions that complete the tasks without a meaningful initial guess owing to the VSCM. The proposed SCvx-based method outperforms the iLQR-based method in terms of convergence, computation time, and the quality of motions found. Finally, the proposed SCvx-based method is tested on a standard robot platform and shown to perform efficiently for a real-world application.
ER  - 

TY  - CONF
TI  - Energy Gradient-Based Graphs for Planning Within-Hand Caging Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2462
EP  - 2467
AU  - W. G. Bircher
AU  - A. S. Morgan
AU  - K. Hang
AU  - A. M. Dollar
PY  - 2019
KW  - dexterous manipulators
KW  - gradient methods
KW  - graph theory
KW  - grippers
KW  - mobile robots
KW  - path planning
KW  - hand-object configurations
KW  - Yale T42 hand
KW  - stored energy profile
KW  - energy gradient-based graph
KW  - energy map
KW  - low energy states
KW  - actuation input
KW  - underactuated hands
KW  - caging grasps
KW  - within-hand caging manipulation
KW  - Actuators
KW  - Computational modeling
KW  - Grippers
KW  - Force
KW  - Planning
KW  - Energy states
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8794411
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we present a within-hand manipulation approach that leverages a simple energy model based on caging grasps made by underactuated hands. Instead of explicitly modeling the contacts and dynamics in manipulation, we can calculate a map to describe the energy states of different hand-object configurations under an actuation input. Since the system intrinsically steers towards low energy states, the object's movement is uniquely described by the gradient of the energy map if the corresponding actuation is applied. Such maps are pre-calculated for a range of actuation inputs to represent the system's energy profile. We discretize the workspace into a grid and construct an energy gradient-based graph by locally exploring the gradients of the stored energy profile. Given a goal configuration of a simple cylindrical object, a sequence of actuation inputs can be calculated to manipulate it towards the goal by exploiting the connectivity in the graph. The proposed approach is experimentally implemented on a Yale T42 hand. Our evaluation results show that parts of the graph are well connected, explaining our ability to successfully plan and execute trajectories within the gripper's workspace.
ER  - 

TY  - CONF
TI  - A new robot skating on water surface intimating water striders based on flexible driving mechanism*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2468
EP  - 2473
AU  - J. Yan
AU  - K. Yang
AU  - Y. Yang
AU  - J. Zhao
AU  - G. Liu
AU  - S. Tang
PY  - 2019
KW  - cantilevers
KW  - elasticity
KW  - hydrodynamics
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - water surface
KW  - flexible driven robot prototype
KW  - water strider robot
KW  - flexible driving legs
KW  - flexible driving robot
KW  - biological water striders
KW  - robot skating
KW  - flexible materials
KW  - ellipse-like spatial trajectories
KW  - pin-linkage mechanism
KW  - microelement cantilever method
KW  - similarity analysis
KW  - hydrodynamic characteristic constants
KW  - Legged locomotion
KW  - Strain
KW  - Force
KW  - Surface treatment
KW  - Trajectory
KW  - Ganglia
DO  - 10.1109/ICRA.2019.8793996
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The amazing ability of water striders on water surface has attracted many scholars. Especially the flexible driving mechanism enable the driving legs conform to the deformation of the water surface, which effectively improving water striders' floating ability and stability. However, the current research on water striders has never designed a flexible driven robot prototype like water striders. This paper proposes a new water strider robot that can walk on water surface based on flexible driving mechanism. The robot's driving legs are designed with flexible materials and possess ellipse-like spatial trajectories like water striders through a limit pin-linkage mechanism. Based on microelement cantilever method, the flexible driving effect was analyzed with different elastic modulus and diameter. It shows that the flexible legs can row at a higher frequency before puncturing the water surface and achieve bigger work in one period compared with the rigid one. At last, the skating experiment of the robot under different stiffness and rowing frequency was carried out. The results verified that the limit frequency of the flexible driving legs and maximum moving speed of the robot are about 41.3% and 36.2% higher than those with rigid legs, respectively. Moreover, a similarity analysis of hydrodynamic characteristic constants reveals that the locomotion of the flexible driving robot is more analogous to the biological water striders than the rigid one.
ER  - 

TY  - CONF
TI  - Performance Metrics for a Robotic Actuation System using Static and Mobile Electromagnets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2474
EP  - 2480
AU  - R. Chen
AU  - D. Folio
AU  - A. Ferreira
PY  - 2019
KW  - electromagnetic actuators
KW  - medical robotics
KW  - microrobots
KW  - surgery
KW  - telerobotics
KW  - robotic EMA platform
KW  - ophthalmic MIS
KW  - magnetic force
KW  - dexterity indexes
KW  - performance metrics
KW  - robotic actuation system
KW  - wireless magnetic microrobots
KW  - small-scale minimally invasive surgery
KW  - electromagnetic actuation system
KW  - reliable medical applications
KW  - Magnetic resonance imaging
KW  - Electromagnets
KW  - Robots
KW  - Micromagnetics
KW  - Electromagnetics
KW  - Coils
KW  - Torque
DO  - 10.1109/ICRA.2019.8794092
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Wireless magnetic microrobots can perform complex tasks for small-scale minimally invasive surgery (MIS) that requires high precision and dexterity. The choice of the configuration of the electromagnetic actuation (EMA) system is a key issue for reliable medical applications. This paper addresses the study of a robotic EMA platform firstly devoted to ophthalmic MIS, aiming at improving the manipulability and dexterity of the procedure. To this end, a robotic EMA system comprising four static and four mobile electromagnets is investigated. Evaluation of the magnetic force and torque, the manipulability and the dexterity indexes of EMA platforms are studied. The results demonstrate that a robotic EMA platform increases the versatility of the EMA system, and becomes resourceful to perform various tasks.
ER  - 

TY  - CONF
TI  - Yaw Torque Authority for a Flapping-Wing Micro-Aerial Vehicle
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2481
EP  - 2487
AU  - R. Steinmeyer
AU  - N. P. Hyun
AU  - E. F. Helbling
AU  - R. J. Wood
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - control nonlinearities
KW  - microrobots
KW  - mobile robots
KW  - piezoelectric actuators
KW  - torque
KW  - reliable torque
KW  - controllable yaw torque
KW  - yaw torque authority
KW  - flapping-wing microaerial vehicle
KW  - high-frequency wing
KW  - reliable yaw control authority
KW  - split-cycle flapping
KW  - flapping frequency
KW  - flapping signal
KW  - Torque
KW  - Actuators
KW  - Harmonic analysis
KW  - Force
KW  - Power harmonic filters
KW  - Shape
KW  - Resonant frequency
DO  - 10.1109/ICRA.2019.8793873
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Flapping-wing micro-aerial vehicles rely on subtle changes in the kinematics of high-frequency wing flapping to produce roll, pitch, and yaw torques. To generate yaw torque, the Harvard RoboBee changes the ratio of upstroke to downstroke speed (“split-cycling”) by applying a second harmonic to the fundamental flapping signal for each wing. However, since flapping typically occurs near resonance (for efficiency), these higher harmonics are filtered out by the transmission and actuator dynamics. Therefore, reliable yaw control authority has proven elusive. We propose a method to generate yaw torque sufficient for in-flight control by using split-cycle flapping in an “iso-lift” regime, to mitigate resonant filtering by decreasing the flapping frequency and increasing the drive voltage, which produces lift identical to typical flight conditions. We model the expected torque at iso-lift conditions and apply this method to the physical RoboBee, achieving reliable, controllable yaw torque. Finally, we demonstrate yaw control with a simple heading controller, achieving a step response with a time constant an order of magnitude faster than previous attempts.
ER  - 

TY  - CONF
TI  - Data-efficient Learning of Morphology and Controller for a Microrobot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2488
EP  - 2494
AU  - T. Liao
AU  - G. Wang
AU  - B. Yang
AU  - R. Lee
AU  - K. Pister
AU  - S. Levine
AU  - R. Calandra
PY  - 2019
KW  - Bayes methods
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - microrobots
KW  - optimisation
KW  - data-efficient learning
KW  - robot design
KW  - HPC-BBO
KW  - hierarchical Bayesian optimization process
KW  - morphology configurations
KW  - controller learning process
KW  - hardware validation
KW  - hardware configurations design
KW  - 6-legged microrobot
KW  - Morphology
KW  - Optimization
KW  - Robots
KW  - Bayes methods
KW  - Hardware
KW  - Process control
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793802
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot design is often a slow and difficult process requiring the iterative construction and testing of prototypes, with the goal of sequentially optimizing the design. For most robots, this process is further complicated by the need, when validating the capabilities of the hardware to solve the desired task, to already have an appropriate controller, which is in turn designed and tuned for the specific hardware. In this paper, we propose a novel approach, HPC-BBO, to efficiently and automatically design hardware configurations, and evaluate them by also automatically tuning the corresponding controller. HPC-BBO is based on a hierarchical Bayesian optimization process which iteratively optimizes morphology configurations (based on the performance of the previous designs during the controller learning process) and subsequently learns the corresponding controllers (exploiting the knowledge collected from optimizing for previous morphologies). Moreover, HPC-BBO can select a “batch” of multiple morphology designs at once, thus parallelizing hardware validation and reducing the number of time-consuming production cycles. We validate HPC-BBO on the design of the morphology and controller for a simulated 6-legged microrobot. Experimental results show that HPC-BBO outperforms multiple competitive baselines, and yields a 360% reduction in production cycles over standard Bayesian optimization, thus reducing the hypothetical manufacturing time of our microrobot from 21 to 4 months.
ER  - 

TY  - CONF
TI  - Retrieval of magnetic medical microrobots from the bloodstream
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2495
EP  - 2501
AU  - V. Iacovacci
AU  - L. Ricotti
AU  - G. Signore
AU  - F. Vistoli
AU  - E. Sinibaldi
AU  - A. Menciassi
PY  - 2019
KW  - catheters
KW  - magnetic particles
KW  - medical robotics
KW  - microrobots
KW  - patient treatment
KW  - magnetoresponsive agents
KW  - capture efficiency
KW  - magnetic particles
KW  - human body
KW  - untethered magnetic microrobots
KW  - magnetic medical microrobots
KW  - body compartments
KW  - retrieval catheter
KW  - magnetic cores
KW  - retrieval tools
KW  - magnetic capture model
KW  - bloodstream
KW  - clinical translation
KW  - body fluids
KW  - magnetic microrobots retrieval
KW  - magnetoresponsive microrobots
KW  - Magnetic separation
KW  - Magnetic confinement
KW  - Saturation magnetization
KW  - Catheters
KW  - Magnetic cores
KW  - Micromagnetics
DO  - 10.1109/ICRA.2019.8794322
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Untethered magnetic microrobots hold the potential to penetrate hard-to-reach areas of the human body and to perform therapy in a controlled way. In the past decade, impressive advancements have been made in this field but the clinical adoption of magnetoresponsive microrobots is still hampered by safety issues. A tool appointed for magnetic microrobots retrieval within body fluids could enable a real paradigm change, fostering their clinical translation.By starting from the general problem to retrieve magnetic microrobots injected into the bloodstream, the authors introduce a magnetic capture model that allows to design retrieval tools for magnetic cores of different diameters (down to 10 nm) and in different environmental conditions (fluid speed up to 7 cms-1). The model robustness is demonstrated by the design and testing of a retrieval catheter. In its optimal configuration, the catheter includes 27 magnets and fits a 12 F catheter. The model provides a good prediction of capture efficiency for 250 nm magnetic particles (experimental data: 77.6%, model prediction: 65%) and a very good prediction for 500 nm particles (experimental data: 93.6%, model prediction: 94%). The results support the proposed model-based design approach, which can be extended to retrieve other magnetoresponsive agents from body compartments.
ER  - 

TY  - CONF
TI  - Experiments with Human-inspired Behaviors in a Humanoid Robot: Quasi-static Balancing using Toe-off Motion and Stretched Knees
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2510
EP  - 2516
AU  - B. Henze
AU  - M. A. Roa
AU  - A. Werner
AU  - A. Dietrich
AU  - C. Ott
AU  - A. Albu-Schäffer
PY  - 2019
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - human-inspired behaviors
KW  - toe-off motion
KW  - stretched knees
KW  - locomotion patterns
KW  - flat foot-ground contact
KW  - human gait
KW  - physiological mechanisms
KW  - TORO DLR humanoid robot
KW  - quasistatic whole-body balancing
KW  - kinematic capabilities
KW  - quasistatic whole-body balancing controller
KW  - Task analysis
KW  - Knee
KW  - Humanoid robots
KW  - Legged locomotion
KW  - Null space
KW  - End effectors
DO  - 10.1109/ICRA.2019.8794096
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humanoid robots typically display locomotion patterns that include walking with flat foot-ground contact, and knees slightly bent. However, analysis of human gait indicate that several physiological mechanisms like stretched knees, heel-strike and toe push-off increase the step length and energetic efficiency of locomotion. This paper presents an implementation of two of those mechanisms, namely stretched knees and push-off, on a quasi-static whole-body balancing controller. The influence of such mechanisms on the kinematic capabilities of the DLR humanoid robot TORO is analyzed in different experiments, and their benefits are thoroughly discussed. As a result, the energetic savings of balancing with stretched knees are shown to be of reduced magnitude with respect to the overall power consumption of the robot, and the ability of TORO for negotiating stairs is greatly enhanced.
ER  - 

TY  - CONF
TI  - Prediction Maps for Real-Time 3D Footstep Planning in Dynamic Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2517
EP  - 2523
AU  - P. Karkowski
AU  - M. Bennewitz
PY  - 2019
KW  - collision avoidance
KW  - humanoid robots
KW  - mobile robots
KW  - robot vision
KW  - humanoids
KW  - smaller wheeled robots
KW  - planar regions
KW  - simple 2D occupancy map
KW  - environment representation
KW  - height information
KW  - prediction maps
KW  - real-time 3D footstep planning
KW  - mobile robots
KW  - dynamic obstacle detection
KW  - time 10.0 ms
KW  - Three-dimensional displays
KW  - Tracking
KW  - Real-time systems
KW  - Mobile robots
KW  - Task analysis
KW  - Humanoid robots
DO  - 10.1109/ICRA.2019.8793999
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Perception of the local environment is a precondition for mobile robots to navigate safely in dynamic environments. Most robots, i.e., humanoids and smaller wheeled robots rely on planar regions. For humanoids, a simple 2D occupancy map as environment representation on which a path is planned is hereby not sufficient since they can step over and onto objects and therefore need height information. Considering dynamic obstacles introduces another level of complexity, since they can lead to necessary replanning or collisions at later stages. In this paper, we present a framework that first extracts planar regions in height maps and detects dynamic obstacles. Our system then uses this information to create a set of prediction maps, in which paths can be efficiently planned in real time at low CPU cost. We show in simulation and real-world experiments that our framework keeps run times well under 10ms for one computation cycle and allows for foresighted real-time 3D footstep planning.
ER  - 

TY  - CONF
TI  - See and Be Seen – Rapid and Likeable High-Definition Camera-Eye for Anthropomorphic Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2524
EP  - 2530
AU  - S. Schulz
AU  - S. M. z. Borgsen
AU  - S. Wachsmuth
PY  - 2019
KW  - cameras
KW  - eye
KW  - humanoid robots
KW  - human-robot interaction
KW  - interactive systems
KW  - mobile robots
KW  - robot vision
KW  - integrated high resolution camera
KW  - robot eye
KW  - human eye movements
KW  - high-definition camera-eye
KW  - anthropomorphic robots
KW  - social robots
KW  - robotic faces
KW  - anthropomorphic face
KW  - anthropomorphic robot head Floka
KW  - Cameras
KW  - Robot vision systems
KW  - Eyelids
KW  - Prototypes
KW  - Acceleration
KW  - Humanoid robots
DO  - 10.1109/ICRA.2019.8794319
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While many social robots already include carefully designed robotic faces, functional robot eyes that meet human expectations are still an open challenge. As a consequence, many robots either have cameras separated from their robot eyes or active camera heads missing an anthropomorphic face. In this paper, we propose a new robot eye that is integrated in the anthropomorphic robot head Floka and fulfills a similar technical specification as a human eye including zero backlash, an increased range of motion, high velocities and accelerations, an integrated high resolution camera, and fast actuated eyelids. The robot eye is built using state-of-the-art off-the-shelf components and the CAD model of our prototype is available free of charge on request for non-commercial applications. We evaluate the technical properties of the robot eye and show that it meets and partially outperforms human eye movements and saccades.
ER  - 

TY  - CONF
TI  - Generalized Orientation Learning in Robot Task Space
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2531
EP  - 2537
AU  - Y. Huang
AU  - F. J. Abu-Dakka
AU  - J. Silvério
AU  - D. G. Caldwell
PY  - 2019
KW  - control engineering computing
KW  - end effectors
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - generalized orientation learning
KW  - robot task space
KW  - imitation learning
KW  - human skills
KW  - joint space
KW  - end-effector orientation
KW  - arbitrary desired points
KW  - adapting learned orientation skills
KW  - angular velocity
KW  - learning Cartesian positions suffices
KW  - learning multiple orientation trajectories
KW  - kernelized treatment
KW  - dynamic movement primitives
KW  - Quaternions
KW  - Trajectory
KW  - Probabilistic logic
KW  - Task analysis
KW  - Robots
KW  - Angular velocity
KW  - Transforms
DO  - 10.1109/ICRA.2019.8793540
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In the context of imitation learning, several approaches have been developed so as to transfer human skills to robots, with demonstrations often represented in Cartesian or joint space. While learning Cartesian positions suffices for many applications, the end-effector orientation is required in many others. However, several crucial issues arising from learning orientations have not been adequately addressed yet. For instance, how can demonstrated orientations be adapted to pass through arbitrary desired points that comprise orientations and angular velocities? In this paper, we propose an approach that is capable of learning multiple orientation trajectories and adapting learned orientation skills to new situations (e.g., via-point and end-point), where both orientation and angular velocity are addressed. Specifically, we introduce a kernelized treatment to alleviate explicit basis functions when learning orientations. Several examples including comparison with the state-of-the-art dynamic movement primitives are provided to verify the effectiveness of our method.
ER  - 

TY  - CONF
TI  - ATLAS FaST: Fast and Simple Scheduled TDOA for Reliable Ultra-Wideband Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2554
EP  - 2560
AU  - J. Tiemann
AU  - Y. Elmasry
AU  - L. Koring
AU  - C. Wietfeld
PY  - 2019
KW  - direction-of-arrival estimation
KW  - mobile robots
KW  - operating systems (computers)
KW  - public domain software
KW  - time-of-arrival estimation
KW  - ATLAS FaST
KW  - fast scheduled TDOA
KW  - simple scheduled TDOA
KW  - ultra-wideband localization
KW  - wireless localization
KW  - aerial robot control
KW  - high precision personal safety tracking
KW  - required localization systems
KW  - multiuser scalability
KW  - energy efficiency
KW  - real-time capabilities
KW  - real-time localization
KW  - robot operating system
KW  - open source access
KW  - precise robotic location estimation
KW  - scheduled time-difference of arrival channel access
KW  - Synchronization
KW  - Clocks
KW  - Mobile nodes
KW  - Reliability
KW  - Wireless communication
KW  - Batteries
DO  - 10.1109/ICRA.2019.8793737
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ever increasing need for precise location estimation in robotics is challenging a significant amount of research. Hence, new applications such as wireless localization based aerial robot control or high precision personal safety tracking are developed. However, most of the current developments and research solely focus on the accuracy of the required localization systems. Multi-user scalability, energy efficiency and real-time capabilities are often neglected. This work aims to overcome the technology barrier by providing scalable, high accuracy, real-time localization through energy-efficient, scheduled time-difference of arrival channel access. We could show that simultaneous processing and provisioning of more than a thousand localization results per second with high reliability is possible using the proposed approach. To enable wide-spread adoption, we provide an open source implementation of our system for the robot operating system (ROS). Furthermore, we provide open source access to the raw data created during our evaluation.
ER  - 

TY  - CONF
TI  - HD Map Change Detection with a Boosted Particle Filter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2561
EP  - 2567
AU  - D. Pannen
AU  - M. Liebner
AU  - W. Burgard
PY  - 2019
KW  - image classification
KW  - learning (artificial intelligence)
KW  - object detection
KW  - particle filtering (numerical methods)
KW  - probability
KW  - road vehicles
KW  - traffic engineering computing
KW  - automated driving
KW  - landmark readings
KW  - probability distribution
KW  - HD map change detection
KW  - boosted particle filter
KW  - change detection algorithm
KW  - backend-based stream processing pipeline
KW  - floating car data
KW  - series-production vehicles
KW  - automotive high definition digital map
KW  - crowd-based approach
KW  - Roads
KW  - Global navigation satellite system
KW  - Measurement
KW  - Visualization
KW  - Automobiles
KW  - Robot sensing systems
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8794329
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a change detection algorithm that can run in real time as part of a backend-based stream processing pipeline. It can process the floating car data collected by series-production vehicles to detect changes in an automotive high definition digital (HD) map used for automated driving. The algorithm uses a particle filter approach with odometry, GNSS and landmark readings to localize the vehicle within the digital map. While all particles together represent the probability distribution for the vehicle's position at a given time, each individual particle also serves as a hypothesis about the vehicle's position. This is used to compute various metrics for how well the current sensor readings match the world model encoded in the HD map. The different metrics are evaluated by a number of weak classifiers that are used as input for a trained Adaboost classifier. The achievable detection rate of a single vehicle is then compared to that of a simple crowd-based approach, where each vehicle votes on whether or not the current section of the road has changed.
ER  - 

TY  - CONF
TI  - Non-parametric Error Modeling for Ultra-wideband Localization Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2568
EP  - 2574
AU  - A. Haggenmiller
AU  - M. Krogius
AU  - E. Olson
PY  - 2019
KW  - optimisation
KW  - probability
KW  - ultra wideband antennas
KW  - wireless sensor networks
KW  - antenna delays
KW  - line-of-sight conditions
KW  - nonline-of-sight conditions
KW  - nonparametric error modeling
KW  - ultra-wideband localization networks
KW  - nonparametric estimation
KW  - measurement probability densities
KW  - explicit modeling
KW  - multimodal errors
KW  - linear estimation methods
KW  - size 3.0 cm
KW  - size 30.0 cm
KW  - Antenna measurements
KW  - Delays
KW  - Probability density function
KW  - Antennas
KW  - Optimization
KW  - Density measurement
KW  - Hardware
DO  - 10.1109/ICRA.2019.8794291
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose an ultra-wideband-based (UWB) localization system that achieves high accuracy through nonparametric estimation of measurement probability densities and explicit modeling of antenna delays. This problem is difficult because non-line-of-sight conditions give rise to multimodal errors, which make linear estimation methods ineffective. The primary contribution in this paper is an approach for both characterizing these errors in situ and an optimization framework that recovers both positions and antenna delays. We evaluate our system with a network of 8 nodes based on the DecaWave DWM1000 and achieve accuracies from 3 cm RMSE in line-of-sight conditions to 30 cm RMSE in non-line-of-sight conditions. Collecting measurements and localizing the network in this manner requires less than a minute, after which the realized network may be used for dynamic real-time tracking.
ER  - 

TY  - CONF
TI  - Self-Supervised Incremental Learning for Sound Source Localization in Complex Indoor Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2599
EP  - 2605
AU  - H. Liu
AU  - Z. Zhang
AU  - Y. Zhu
AU  - S. Zhu
PY  - 2019
KW  - direction-of-arrival estimation
KW  - geometry
KW  - indoor environment
KW  - learning (artificial intelligence)
KW  - microphone arrays
KW  - mobile robots
KW  - geometry features
KW  - self-supervision process
KW  - ground truth label
KW  - pre-collected data
KW  - human supervisions
KW  - explicit GCC-PHAT features
KW  - supervised incremental learning
KW  - sound source localization
KW  - complex indoor environment
KW  - incremental learning framework
KW  - mobile robots
KW  - human sound source
KW  - microphone array
KW  - multiple rooms
KW  - training data
KW  - prediction model
KW  - incremental learning scheme
KW  - implicit acoustic features
KW  - training samples
KW  - direction-of-arrival estimation
KW  - Feature extraction
KW  - Robots
KW  - Acoustics
KW  - Predictive models
KW  - Indoor environment
KW  - Microphones
KW  - Data models
DO  - 10.1109/ICRA.2019.8794231
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents an incremental learning framework for mobile robots localizing the human sound source using a microphone array in a complex indoor environment consisting of multiple rooms. In contrast to conventional approaches that leverage direction-of-arrival (DOA) estimation, the framework allows a robot to accumulate training data and improve the performance of the prediction model over time using an incremental learning scheme. Specifically, we use implicit acoustic features obtained from an auto-encoder together with the geometry features from the map for training. A self-supervision process is developed such that the model ranks the priority of rooms to explore and assigns the ground truth label to the collected data, updating the learned model on-the-fly. The framework does not require pre-collected data and can be directly applied to real-world scenarios without any human supervisions or interventions. In experiments, we demonstrate that the prediction accuracy reaches 67% using about 20 training samples and eventually achieves 90% accuracy within 120 samples, surpassing prior classification-based methods with explicit GCC-PHAT features.
ER  - 

TY  - CONF
TI  - Automated Models of Human Everyday Activity based on Game and Virtual Reality Technology
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2606
EP  - 2612
AU  - A. Haidu
AU  - M. Beetz
PY  - 2019
KW  - computer games
KW  - knowledge acquisition
KW  - virtual reality
KW  - virtual reality technology
KW  - human everyday manipulation activity
KW  - virtual human living
KW  - working environments
KW  - recorded activity data
KW  - knowledge acquisition
KW  - human manipulation activities
KW  - AMEvA
KW  - automated models of everyday activities
KW  - knowledge interpretation
KW  - knowledge processing system
KW  - KNOWROB
KW  - Solid modeling
KW  - Task analysis
KW  - Robots
KW  - Force
KW  - Games
KW  - Virtual reality
DO  - 10.1109/ICRA.2019.8793859
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we will describe AMEvA (Automated Models of Everyday Activities), a special-purpose knowledge acquisition, interpretation, and processing system for human everyday manipulation activity that can automatically: (1) create and simulate virtual human living and working environments (such as kitchens and apartments) with a scope, extent, level of detail, physics, and close to photorealism that facilitates and promotes the natural and realistic execution of human everyday manipulation activities; (2) record human manipulation activities performed in the respective virtual reality environment as well as their effects on the environment and detect force-dynamic states and events; (3) decompose and segment the recorded activity data into meaningful motions and categorize the motions according to action models used in cognitive science; and (4) represent the interpreted activities symbolically in KNOWROB [1] using a first-order time interval logic representation.
ER  - 

TY  - CONF
TI  - Development of a strain gauge based disturbance estimation and compensation technique for a wheeled inverted pendulum robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2613
EP  - 2619
AU  - L. Canete
AU  - T. Takahashi
PY  - 2019
KW  - compensation
KW  - force control
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - position control
KW  - robot dynamics
KW  - service robots
KW  - strain gauges
KW  - wheels
KW  - strain gauge based disturbance estimation
KW  - compensation technique
KW  - wheeled inverted pendulum robot
KW  - I-PENTAR
KW  - strain gauge based sensor
KW  - purely estimation based control
KW  - inverted pendulum type assistant robot
KW  - Wheels
KW  - Robot sensing systems
KW  - Strain measurement
KW  - Task analysis
KW  - Mobile robots
KW  - Axles
DO  - 10.1109/ICRA.2019.8793995
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ongoing development of the Inverted PENdulum Type Assistant Robot (I-PENTAR) is being undertaken by the authors. The I-PENTAR has many tasks like lifting objects with unknown mass, pushing and pulling a carts and many more. During execution of these tasks unknown disturbances enter the system and cause dynamic responses and errors. Most notably, the wheels of the robot move with excessively transients. To alleviate this problem, a strain gauge based sensor is attached to the existing structure of the robot to gain information regarding the disturbances. This allows minimal change to the system design while improving robustness to disturbances. In this paper the development of the sensor, the corresponding model and a method of updating the existing purely estimation based control is presented together with tests.
ER  - 

TY  - CONF
TI  - Spatio-temporal representation for long-term anticipation of human presence in service robotics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2620
EP  - 2626
AU  - T. Vintr
AU  - Z. Yan
AU  - T. Duckett
AU  - T. Krajník
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - service robots
KW  - spatiotemporal phenomena
KW  - spatio-temporal representation
KW  - long-term anticipation
KW  - service robotics
KW  - mobile autonomous robots
KW  - human populated environments
KW  - wrapped dimensions
KW  - periodicities
KW  - 2D spatial model
KW  - multidimensional representation
KW  - memory efficient spatio-temporal model
KW  - long-term predictions
KW  - mobile robots
KW  - periodic temporal patterns
KW  - Hidden Markov models
KW  - Predictive models
KW  - Market research
KW  - Mobile robots
KW  - Spectral analysis
KW  - Time series analysis
DO  - 10.1109/ICRA.2019.8793534
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose an efficient spatio-temporal model for mobile autonomous robots operating in human populated environments. Our method aims to model periodic temporal patterns of people presence, which are based on peoples' routines and habits. The core idea is to project the time onto a set of wrapped dimensions that represent the periodicities of people presence. Extending a 2D spatial model with this multidimensional representation of time results in a memory efficient spatio-temporal model. This model is capable of long-term predictions of human presence, allowing mobile robots to schedule their services better and to plan their paths. The experimental evaluation, performed over datasets gathered by a robot over a period of several weeks, indicates that the proposed method achieves more accurate predictions than the previous state of the art used in robotics.
ER  - 

TY  - CONF
TI  - Object Transfer Point Estimation for Fluent Human-Robot Handovers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2627
EP  - 2633
AU  - H. Nemlekar
AU  - D. Dutia
AU  - Z. Li
PY  - 2019
KW  - estimation theory
KW  - humanoid robots
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - robot vision
KW  - human-robot interaction
KW  - collaboration tasks
KW  - offline OTP
KW  - human preferences
KW  - dynamic OTP
KW  - OTP predictor
KW  - humanoid nursing robot
KW  - handover motion
KW  - reach-to-grasp response time
KW  - natural human receiver
KW  - human-robot handovers
KW  - human-robot motion
KW  - object transfer point estimation
KW  - robot visible workspace
KW  - user-adaptive reference frame
KW  - time 3.1 s
KW  - Handover
KW  - Receivers
KW  - Robot kinematics
KW  - Estimation
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794008
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Handing over objects is the foundation of many human-robot interaction and collaboration tasks. In the scenario where a human is handing over an object to a robot, the human chooses where the object needs to be transferred. The robot needs to accurately predict this point of transfer to reach out proactively, instead of waiting for the final position to be presented. This work presents an efficient method for predicting the Object Transfer Point (OTP), which synthesizes (1) an offline OTP calculated based on human preferences observed in a human-robot motion study with (2) a dynamic OTP predicted based on the observed human motion. Our proposed OTP predictor is implemented on a humanoid nursing robot and experimentally validated in human-robot handover tasks. Compared to only using static or dynamic OTP estimators, it has better accuracy at the earlier phase of handover (up to 45% of the handover motion) and can render fluent handovers with a reach-to-grasp response time (about 3.1 secs) close to natural human receiver's response. In addition, the OTP prediction accuracy is maintained across the robot's visible workspace by utilizing a user-adaptive reference frame.
ER  - 

TY  - CONF
TI  - Controlling AeroBot: Development of a Motion Planner for an Actively Articulated Wheeled Humanoid Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2634
EP  - 2640
AU  - M. V. Otubela
AU  - M. F. Cullinan
AU  - C. McGinn
PY  - 2019
KW  - controllability
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - position control
KW  - quadratic programming
KW  - robot kinematics
KW  - stability
KW  - velocity control
KW  - wheels
KW  - robot morphologies
KW  - legged robots
KW  - humanlike form factor
KW  - wheeled systems
KW  - controllability
KW  - motion planner
KW  - actively articulated wheeled humanoid robot
KW  - gap crossing
KW  - dynamically stable motion
KW  - robots kinematics
KW  - sequential quadratic program algorithm
KW  - postural configuration adjustment requirements
KW  - velocity control
KW  - drive wheels
KW  - terrain adaptability
KW  - energy consumption
KW  - aerobot robot
KW  - step climbing
KW  - nonlinear constraints
KW  - stability
KW  - zero moment point
KW  - Trajectory
KW  - Robot kinematics
KW  - Kinematics
KW  - Stability analysis
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8794217
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There is value in exploring new robot morphologies that combine the benefits of legged robots (i.e. high terrain adaptability, humanlike form factor) with those of wheeled systems (i.e. high stability, low energy consumption). Once the basic design concept has been demonstrated, there is a further requirement to validate the controllability of the system through adaptation and implementation of advanced control techniques. This research presents a motion planner that enables the Aerobot robot, an actively articulated wheeled humanoid robot capable of performing step climbing and gap crossing, to plan dynamically stable motion in response to a range of task conditions. Using a model of the robots kinematics, a motion planner is developed. The sequential quadratic program algorithm is used to solve quadratic objectives and non-linear constraints pertaining to stability and postural configuration adjustment requirements. The results showed good tracking of the robot's Zero Moment Point while transitioning between postural configurations and traversing obstacles. During these phase transitions, robustness in maintaining balance and position is also demonstrated via velocity control of the drive wheels.
ER  - 

TY  - CONF
TI  - User Centric Device Registration for Streamlined Workflows in Surgical Navigation Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2641
EP  - 2647
AU  - P. Thienphrapa
AU  - P. Vagdargi
AU  - A. Chen
AU  - D. Stanton
PY  - 2019
KW  - computerised tomography
KW  - health care
KW  - image registration
KW  - medical image processing
KW  - medical robotics
KW  - surgery
KW  - surgery
KW  - health care
KW  - user centric device registration
KW  - registration gesture
KW  - preoperative registration
KW  - medical imaging modalities
KW  - device tracking
KW  - surgical navigation systems
KW  - Navigation
KW  - Robots
KW  - Tracking
KW  - Fixtures
KW  - Monitoring
KW  - Market research
KW  - Medical services
DO  - 10.1109/ICRA.2019.8793822
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Alongside sweeping transformations in healthcare, a timeless drive to make surgical interventions less invasive and more effective has led to the integration of disparate technologies into surgical navigation systems. Fusions of device tracking and medical imaging modalities have been comprehensively investigated for opportunities to improve care. Such composite systems provide more and better information, enabling clinicians to operate less invasively and more effectively. Because of these merits, the preoperative ritual of harmonizing multiple information sources has been tacitly adopted. In this paper, we challenge the paradigm of preoperative registration. Proposed herein is a technique in which a clinician registers an interventional device to a navigation system simply by gesturing the device through a strategically designed fixture. In the background, the system continuously monitors the device path for this registration gesture. We demonstrate generality by applying the method to both robotic and electromagnetically tracked devices, and exhibit versatility by repeating the registration at multiple device base locations. Experiments indicate sub-millimeter accuracy versus conventional approaches on the same setup. Consequently, clinicians can register devices on the fly, increasing flexibility in setup and redefining workflow possibilities in surgery.
ER  - 

TY  - CONF
TI  - Compliant four degree-of-freedom manipulator with locally deformable elastic elements for minimally invasive surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2663
EP  - 2669
AU  - J. Arata
AU  - Y. Fujisawa
AU  - R. Nakadate
AU  - K. Kiguchi
AU  - K. Harada
AU  - M. Mitsuishi
AU  - M. Hashizume
PY  - 2019
KW  - bending
KW  - finite element analysis
KW  - manipulators
KW  - medical robotics
KW  - needles
KW  - optimisation
KW  - surgery
KW  - locally deformable elastic elements
KW  - minimally invasive surgery
KW  - MIS
KW  - surgical robots
KW  - robotic technology
KW  - compliant four degree-of-freedom manipulator
KW  - mechanical parts
KW  - robotic instruments
KW  - optimization method
KW  - FEA
KW  - prototype implementation
KW  - Springs
KW  - Instruments
KW  - Strain
KW  - Surgery
KW  - Manipulators
KW  - Medical robotics
DO  - 10.1109/ICRA.2019.8793798
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Minimally Invasive Surgery (MIS) is one of the most successful applications of surgical robots. Although the introduction of robotic technology has brought a number of benefits, further advancements in MIS are limited by the size and bending radius of instruments. In this paper, we present a compliant four degree-of-freedom manipulator that consists of elastic elements with partly thinner structures. The proposed mechanism allows the elastic element to deform locally, thus minimizing its bending radius while the low number of mechanical parts greatly contributes to its compactness. This paper describes the design strategy, optimization method using FEA, prototype implementation, and evaluations. The evaluations reveal high accuracy and repeat accuracy, which are key elements for robotic instruments in MIS. Further, the prototype is able to exert sufficient force and it is possible to perform a simulated needle insertion task using the manipulator, demonstrating the feasibility of the proposed mechanism.
ER  - 

TY  - CONF
TI  - Safe teleoperation of a laparoscope holder with dynamic precision but low stiffness.
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2693
EP  - 2699
AU  - J. Mago
AU  - M. Aricò
AU  - J. D. Silva
AU  - G. Morel
PY  - 2019
KW  - haptic interfaces
KW  - interactive devices
KW  - medical robotics
KW  - position control
KW  - surgery
KW  - telerobotics
KW  - three-term control
KW  - rigid laparoscope holders
KW  - high-gain PID position control
KW  - dynamic precision
KW  - undetected obstacles
KW  - stiff systems
KW  - compliant behaviour
KW  - unknown friction
KW  - compliant- scope holder
KW  - -precise laparo-scope holder
KW  - haptic interfaces
KW  - high backdrivability
KW  - intelligent PID position controller
KW  - low PID gains
KW  - satisfactory tracking precision
KW  - safe teleoperation
KW  - laparoscope holder
KW  - low stiffness
KW  - Minimally Invasive Surgery
KW  - MIS
KW  - visual feedback
KW  - human assistant
KW  - end-effector
KW  - robotic assistant
KW  - laparoscope displacements
KW  - master input interface
KW  - voice control
KW  - slave level
KW  - Laparoscopes
KW  - Friction
KW  - Surgery
KW  - Robots
KW  - Optimized production technology
KW  - Force
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794076
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A laparoscope is a key element in Minimally Invasive Surgery (MIS) as it provides visual feedback to the surgeon. To overcome the drawbacks induced by its manual operation by a human assistant, it can be fixed on the end-effector of a robotic assistant teleoperated by the surgeon: laparoscope displacements are commanded through a master input interface (e.g., joysticks, voice control, etc.) and replicated accordingly at the slave level. In this approach, precision is of high importance to ensure a good operability by the surgeon. This is why the state-of-the-art relies on rigid laparoscope holders with high-gain PID position control, ensuring high static and dynamic precision. However, in the event of undetected obstacles, such stiff systems generate high forces that may cause harm to the patient. Rather, a compliant behaviour is desirable but it leads to a lack of precision when disturbances occur, such as the unknown friction between the trocar and the laparoscope. In this paper we present a “compliant-and-precise” laparo-scope holder with 4 active Degrees of Freedom (DoFs). Its design is based on cable transmission used for haptic interfaces, thus it exhibits very high backdrivability. The paper shows how an intelligent PID position controller can be used to compensate for unknown friction at the trocar while keeping very low PID gains and a satisfactory tracking precision.
ER  - 

TY  - CONF
TI  - Real-time Teleoperation of Flexible Beveled-tip Needle Insertion using Haptic Force Feedback and 3D Ultrasound Guidance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2700
EP  - 2706
AU  - J. Chevrie
AU  - A. Krupa
AU  - M. Babel
PY  - 2019
KW  - biological tissues
KW  - biomedical ultrasonics
KW  - force feedback
KW  - haptic interfaces
KW  - medical image processing
KW  - medical robotics
KW  - needles
KW  - phantoms
KW  - telemedicine
KW  - telerobotics
KW  - gelatin phantom
KW  - real-time teleoperation
KW  - 3D ultrasound guidance
KW  - flexible beveled-tip needle
KW  - tip trajectory
KW  - user-controlled tasks
KW  - haptic force feedback
KW  - 3D ultrasound probe
KW  - real-time visual feedback
KW  - haptic interface
KW  - needle tip
KW  - beveledtip flexible needle steering
KW  - teleoperation framework
KW  - control loop
KW  - robotic systems
KW  - needle insertion procedures
KW  - Needles
KW  - Task analysis
KW  - Haptic interfaces
KW  - Robots
KW  - Surgery
KW  - Trajectory
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8794012
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Needle insertion procedures can greatly benefit from robotic systems to improve their accuracy and success rate. However, a fully automated system is usually not desirable and the clinicians need to be included in the control loop. In this paper we present a teleoperation framework for beveledtip flexible needle steering that enables the user to directly and intuitively control the trajectory of the needle tip via a haptic interface. The 6 degrees of freedom of the needle base are used to perform several automatic safety and targeting tasks in addition to the one controlled by the user. Real-time visual feedback is provided by a 3D ultrasound probe and used to track the 3D location of the needle and of a spherical target. Several haptic force feedback are compared as well as two different levels of mix between automated and user-controlled tasks. A validation of the framework is conducted in gelatin phantom and a mean targeting accuracy of 2.5 mm is achieved. The results show that providing an adequate haptic guidance to the user can reduce the risks of damage to the tissues while still letting the surgeon in control of the tip trajectory.
ER  - 

TY  - CONF
TI  - End-User Robot Programming Using Mixed Reality
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2707
EP  - 2713
AU  - S. Y. Gadre
AU  - E. Rosen
AU  - G. Chien
AU  - E. Phillips
AU  - S. Tellex
AU  - G. Konidaris
PY  - 2019
KW  - augmented reality
KW  - dexterous manipulators
KW  - helmet mounted displays
KW  - robot programming
KW  - MR-HMD interface
KW  - end-user robot programming
KW  - immersive 3D visualization
KW  - hand gestures
KW  - robot motions
KW  - robot arm
KW  - mixed reality head-mounted display
KW  - pick-and-place programs
KW  - Task analysis
KW  - Visualization
KW  - Two dimensional displays
KW  - Virtual reality
KW  - Programming
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793988
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mixed Reality (MR) is a promising interface for robot programming because it can project an immersive 3D visualization of a robot's intended movement onto the real world. MR can also support hand gestures, which provide an intuitive way for users to construct and modify robot motions. We present a Mixed Reality Head-Mounted Display (MRHMD) interface that enables end-users to easily create and edit robot motions using waypoints. We describe a user study where 20 participants were asked to program a robot arm using 2D and MR interfaces to perform two pick-and-place tasks. In the primitive task, participants created typical pickand-place programs. In the adapted task, participants adapted their primitive programs to address a more complex pickand-place scenario, which included obstacles and conditional reasoning. Compared to the 2D interface, a higher number of users were able to complete both tasks in significantly less time, and reported experiencing lower cognitive workload, higher usability, and higher naturalness with the MR-HMD interface.
ER  - 

TY  - CONF
TI  - Control of Delayed Bilateral Teleoperation System for Robotic Tele-Echography
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2714
EP  - 2720
AU  - J. H. Cho
AU  - M. Kristalny
AU  - J. Seo
AU  - H. J. Lee
AU  - K. Kim
AU  - H. S. Woo
PY  - 2019
KW  - control system synthesis
KW  - delays
KW  - medical robotics
KW  - mobile robots
KW  - stability
KW  - telerobotics
KW  - robotic tele-echography
KW  - controllerfor bilateral robotic system
KW  - delayed communications
KW  - identical 6DOF robotic devices
KW  - Stewart-Gough mechanisms
KW  - controller design
KW  - teleoperation setup
KW  - slave devices
KW  - identical geometry
KW  - measurement arrays
KW  - independent IDOF settings
KW  - intuitively shape teleoperator performance
KW  - control method
KW  - Teleoperators
KW  - Stability analysis
KW  - Service robots
KW  - Internet
KW  - Real-time systems
KW  - Haptic interfaces
DO  - 10.1109/ICRA.2019.8794196
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes development of a controllerfor bilateral robotic system for tele-echography with delayed communications. The system comprises two identical 6DOF robotic devices based on Stewart-Gough mechanisms, which were developed especially for the sake of the considered application. Controller design is facilitated by a symmetry of the teleoperation setup, in which the master and slave devices have identical geometry, actuation and measurement arrays. To further simplify the analysis, we treat coupling between degrees of freedom as exogenous disturbances and this allows us to split the control problem into six independent IDOF settings. The IDOF problems are addressed then using a novel approach to bilateral teleoperation control, based on a complete parameterization of feasible teleoperators. It allows to intuitively shape teleoperator performance while guaranteeing passivity and thus coupled stability of the system. The potential of the proposed control method is demonstrated with experimental results.
ER  - 

TY  - CONF
TI  - A Unified Framework for the Teleoperation of Surgical Robots in Constrained Workspaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2721
EP  - 2727
AU  - M. M. Marinho
AU  - B. V. Adorno
AU  - K. Harada
AU  - K. Deie
AU  - A. Deguet
AU  - P. Kazanzides
AU  - R. H. Taylor
AU  - M. Mitsuishi
PY  - 2019
KW  - dexterous manipulators
KW  - force feedback
KW  - medical robotics
KW  - optimisation
KW  - surgery
KW  - telerobotics
KW  - constrained workspaces
KW  - robot geometry
KW  - slave-side constrained optimization algorithm
KW  - robotic systems
KW  - adult laparoscopy
KW  - infant surgery
KW  - surgical robots
KW  - robot-aided surgery
KW  - operating rooms
KW  - robotic tools
KW  - robot control techniques
KW  - pediatric surgery
KW  - microsurgery
KW  - nonredundant robots
KW  - teleoperation
KW  - dexterity
KW  - Robots
KW  - Surgery
KW  - Optimization
KW  - Jacobian matrices
KW  - Quaternions
KW  - Kinematics
KW  - Laparoscopes
DO  - 10.1109/ICRA.2019.8794363
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In adult laparoscopy, robot-aided surgery is a reality in thousands of operating rooms worldwide, owing to the increased dexterity provided by the robotic tools. Many robots and robot control techniques have been developed to aid in more challenging scenarios, such as pediatric surgery and microsurgery. However, the prevalence of case-specific solutions, particularly those focused on non-redundant robots, reduces the reproducibility of the initial results in more challenging scenarios. In this paper, we propose a general framework for the control of surgical robotics in constrained workspaces under teleoperation, regardless of the robot geometry. Our technique is divided into a slave-side constrained optimization algorithm, which provides virtual fixtures, and with Cartesian impedance on the master side to provide force feedback. Experiments with two robotic systems, one redundant and one non-redundant, show that smooth teleoperation can be achieved in adult laparoscopy and infant surgery.
ER  - 

TY  - CONF
TI  - High-Speed Ring Insertion by Dynamic Observable Contact Hand
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2744
EP  - 2750
AU  - Y. Karako
AU  - S. Kawakami
AU  - K. Koyama
AU  - M. Shimojo
AU  - T. Senoo
AU  - M. Ishikawa
PY  - 2019
KW  - assembling
KW  - design of experiments
KW  - dexterous manipulators
KW  - error compensation
KW  - masks
KW  - position control
KW  - robot hand
KW  - impact reduction
KW  - position-error compensation
KW  - objects contact
KW  - DOC hand
KW  - 6-degrees-of- freedom dynamic passivity
KW  - robot system
KW  - high-speed precision assembly
KW  - dynamic observable contact hand
KW  - multifingered hand
KW  - high speed ring insertion
KW  - time 2.42 s
KW  - time 2.58 s
KW  - Robots
KW  - Shafts
KW  - Task analysis
KW  - Shape
KW  - Force
KW  - Grippers
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794120
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study proposes a dynamic observable contact (DOC) hand as a new multifingered hand to ensure high- speed insertion in an assembly process with a small clearance between objects. To achieve insertion with a small clearance at high speed, a robot hand must realize both impact reduction and position-error compensation when the two objects contact each other. The DOC hand, with its features of 6-degrees-of- freedom dynamic passivity and object-pose observability, can realize both impact reduction and position-error compensation. To evaluate the effectiveness of the DOC hand, we construct a robot system using the DOC hand. We evaluate the performance of the system in the task of ring insertion with a small clearance (0-36um). The results indicate that the robot system performs with a higher speed than a human. In fact, the average cycle time is 2.42 s for the robot, whereas it is 2.58 s for a human. The DOC hand has opened up the possibility for achieving high-speed precision assembly using robots.
ER  - 

TY  - CONF
TI  - Learning To Grasp Under Uncertainty Using POMDPs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2751
EP  - 2757
AU  - N. P. Garg
AU  - D. Hsu
AU  - W. S. Lee
PY  - 2019
KW  - grippers
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - Markov processes
KW  - object detection
KW  - recurrent neural nets
KW  - robust control
KW  - service robots
KW  - uncertainty handling
KW  - visual sensing
KW  - partially observable Markov decision process
KW  - grasp policy
KW  - deep recurrent neural network
KW  - imitation learning
KW  - model-based POMDP planning
KW  - G3DB object dataset
KW  - service robots
KW  - far-field sensors
KW  - open-loop grasp
KW  - tactile sensing
KW  - adaptive grasping
KW  - robust object grasping strategy
KW  - uncertainty handling
KW  - Uncertainty
KW  - Grippers
KW  - Grasping
KW  - Planning
KW  - Sensors
KW  - Shape
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793818
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robust object grasping under uncertainty is an essential capability of service robots. Many existing approaches rely on far-field sensors, such as cameras, to compute a grasp pose and perform open-loop grasp after placing gripper under the pose. This often fails as a result of sensing or environment uncertainty. This paper presents a principled, general and efficient approach to adaptive grasping, using both tactile and visual sensing as feedback. We first model adaptive grasping as a partially observable Markov decision process (POMDP), which handles uncertainty naturally. We solve the POMDP for sampled objects from a set, in order to generate data for learning. Finally, we train a grasp policy, represented as a deep recurrent neural network (RNN), in simulation through imitation learning. By combining model-based POMDP planning and imitation learning, the proposed approach achieves robustness under uncertainty, generalization over many objects, and fast execution. In particular, we show that modeling only a small sample of objects enables us to learn a robust strategy to grasp previously unseen objects of varying shapes and recover from failure over multiple steps. Experiments on the G3DB object dataset in simulation and a smaller object set with a real robot indicate promising results.
ER  - 

TY  - CONF
TI  - Soft Hands with Embodied Constraints: The Soft ScoopGripper
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2758
EP  - 2764
AU  - G. Salvietti
AU  - Z. Iqbal
AU  - M. Malvezzi
AU  - T. Eslami
AU  - D. Prattichizzo
PY  - 2019
KW  - control system synthesis
KW  - grippers
KW  - uncertain systems
KW  - soft ScoopGripper
KW  - underactuation
KW  - robust grasps
KW  - robotic gripper design
KW  - modular under actuated soft hand
KW  - object grasping
KW  - Robots
KW  - Grippers
KW  - Tendons
KW  - Actuators
KW  - Grasping
KW  - Force
KW  - Fasteners
DO  - 10.1109/ICRA.2019.8793563
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The design of robotic grippers requires the accomplishment of several contrasting requirements. Research in under actuated soft hands is a lively topic, with several potentialities and challenges. Soft hands are simple, robust and able of adapting to uncertain environment and operative conditions, however their intrinsic compliance and underactuation reduce control capabilities and precision. Recent studies attempted to compensate this limitation by wisely exploiting environmental constraints and considering them as supports to accomplish the task rather than obstacle to avoid. The development of grasp primitives taking into account environment features leaded to interesting and encouraging results. In this paper, we propose to embed on the hand the positive aspects of studies on environmental constraints exploitation. We present a modular under actuated soft hand in which we added a scoop as a feature of the palm, which simplify object grasping. The scoop allows to grasp objects in narrow spaces, augments the possible contact areas, allows to obtain more robust grasps, with lower forces. The paper illustrates the main design principles, a prototype and experimental results.
ER  - 

TY  - CONF
TI  - A Simple Electric Soft Robotic Gripper with High-Deformation Haptic Feedback
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2765
EP  - 2771
AU  - L. Chin
AU  - M. C. Yuen
AU  - J. Lipton
AU  - L. H. Trueba
AU  - R. Kramer-Bottiglio
AU  - D. Rus
PY  - 2019
KW  - auxetics
KW  - deformation
KW  - feedback
KW  - grippers
KW  - haptic interfaces
KW  - pressure sensors
KW  - grasping tasks
KW  - electric soft robotic gripper
KW  - fabrication techniques
KW  - sensorized system
KW  - object classification
KW  - gripper proprioception
KW  - coupling deformable sensors
KW  - electric motors
KW  - structurally-compliant handed shearing auxetic structures
KW  - pressure sensors
KW  - high-deformation strain
KW  - complex driving hardware
KW  - proprioceptive soft robotic grippers
KW  - proprioceptive feedback
KW  - tactile feedback
KW  - manipulation tasks
KW  - compliant robotic grippers
KW  - high-deformation haptic feedback
KW  - Grippers
KW  - Strain
KW  - Capacitive sensors
KW  - Robot sensing systems
KW  - Servomotors
KW  - Pressure sensors
DO  - 10.1109/ICRA.2019.8794098
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Compliant robotic grippers are more robust to uncertainties in grasping and manipulation tasks, especially when paired with tactile and proprioceptive feedback. Although considerable progress has been made towards achieving proprioceptive soft robotic grippers, current efforts require complex driving hardware or fabrication techniques. In this paper, we present a simple scalable soft robotic gripper integrated with high-deformation strain and pressure sensors. The gripper is composed of structurally-compliant handed shearing auxetic structures actuated by electric motors. Coupling deformable sensors with the compliant grippers enables gripper proprioception and object classification. With this sensorized system, we are able to identify objects' size to within 33% of actual radius and sort objects as hard/soft with 78% accuracy.
ER  - 

TY  - CONF
TI  - Using Geometric Features to Represent Near-Contact Behavior in Robotic Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2772
EP  - 2777
AU  - E. Dessalene
AU  - Y. H. Ong
AU  - J. Morrow
AU  - R. Balasubramanian
AU  - C. Grimm
PY  - 2019
KW  - geometry
KW  - grippers
KW  - learning (artificial intelligence)
KW  - kinematic noise
KW  - contact points
KW  - binary grasp success classifier
KW  - hand morphologies
KW  - hand-object geometric relationships
KW  - near-contact behavior
KW  - near-contact stage
KW  - feature representations
KW  - robotic grasping
KW  - geometric features
KW  - Measurement
KW  - Robots
KW  - Grasping
KW  - Surface morphology
KW  - Geometry
KW  - Morphology
KW  - Machine learning algorithms
DO  - 10.1109/ICRA.2019.8793779
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we define two feature representations for grasping. These representations capture hand-object geometric relationships at the near-contact stage - before the fingers close around the object. Their benefits are: 1) They are stable under noise in both joint and pose variation. 2) They are largely hand and object agnostic, enabling direct comparison across different hand morphologies. 3) Their format makes them suitable for direct application of machine learning techniques developed for images. We validate the representations by: 1) Demonstrating that they can accurately predict the distribution of ε-metric values generated by kinematic noise. I.e., they capture much of the information inherent in contact points and force vectors without the corresponding instabilities. 2) Training a binary grasp success classifier on a real-world data set consisting of 588 grasps.
ER  - 

TY  - CONF
TI  - A GPU Based Parallel Genetic Algorithm for the Orientation Optimization Problem in 3D Printing*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2786
EP  - 2792
AU  - Z. Li
AU  - G. Xiong
AU  - X. Zhang
AU  - Z. Shen
AU  - C. Luo
AU  - X. Shang
AU  - X. Dong
AU  - G. Bian
AU  - X. Wang
AU  - F. Wang
PY  - 2019
KW  - genetic algorithms
KW  - graphics processing units
KW  - parallel algorithms
KW  - production engineering computing
KW  - three-dimensional printing
KW  - parallel genetic algorithm
KW  - 3D printing
KW  - additive manufacturing
KW  - GA
KW  - single-objective optimization
KW  - building time
KW  - multiobjective optimization problem
KW  - model orientation problem
KW  - orientation optimization problem
KW  - GPU
KW  - Optimization
KW  - Silicon
KW  - Solid modeling
KW  - Graphics processing units
KW  - Genetic algorithms
KW  - Three-dimensional printing
KW  - Orientation Optimization
KW  - GPU
KW  - parallel computing
KW  - genetic algorithm
KW  - Additive Manufacturing
DO  - 10.1109/ICRA.2019.8793989
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The choice of model orientation is a very important issue in Additive Manufacturing (AM). In this paper, the model orientation problem is formulated as a multi-objective optimization problem, aiming at minimizing the building time, the surface quality, and the supporting area. Then we convert the problem into a single-objective optimization in the linear-weighted way. After that, the Genetic Algorithm (GA) is used to solve the optimization problem and the process of GA is parallelized and implemented on GPU. Experimental results show that when dealing with complex models in AM, compared with CPU only implementation, the GPU based GA can speed up the process by about 50 times, which helps to significantly reduce the optimization time and ensure the quality of solutions. The GPU based parallel methods we proposed can help to reduce the execution time and improve the efficiency greatly, making the processes more efficient.
ER  - 

TY  - CONF
TI  - Where Should We Place LiDARs on the Autonomous Vehicle? - An Optimal Design Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2793
EP  - 2799
AU  - Z. Liu
AU  - M. Arief
AU  - D. Zhao
PY  - 2019
KW  - ant colony optimisation
KW  - evolutionary computation
KW  - minimax techniques
KW  - object detection
KW  - optical radar
KW  - nondetectable subspace
KW  - min-max optimization problem
KW  - cuboid-based approach
KW  - VSR-based measure
KW  - object detection rate
KW  - tractable cost function computation
KW  - VSR measure
KW  - cost-effectiveness configuration
KW  - optimal design approach
KW  - autonomous vehicle manufacturers
KW  - accurate 3D views
KW  - precise distance measures
KW  - optimal LiDAR configuration problem
KW  - utility maximization
KW  - artificial bee colony evolutionary algorithm
KW  - uncertain driving conditions
KW  - bio-inspired measure
KW  - Laser radar
KW  - Laser beams
KW  - Cost function
KW  - Shape
KW  - Three-dimensional displays
KW  - Cameras
DO  - 10.1109/ICRA.2019.8793619
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous vehicle manufacturers recognize that LiDAR provides accurate 3D views and precise distance measures under highly uncertain driving conditions. Its practical implementation, however, remains costly. This paper investigates the optimal LiDAR configuration problem to achieve utility maximization. We use the perception area and non-detectable subspace to construct the design procedure as solving a min-max optimization problem and propose a bio-inspired measure - volume to surface area ratio (VSR) - as an easy-to-evaluate cost function representing the notion of the size of the non-detectable subspaces of a given configuration. We then adopt a cuboid-based approach to show that the proposed VSR-based measure is a well-suited proxy for object detection rate. It is found that the Artificial Bee Colony evolutionary algorithm yields a tractable cost function computation. Our experiments highlight the effectiveness of our proposed VSR measure in terms of cost-effectiveness configuration as well as providing insightful analyses that can improve the design of AV systems.
ER  - 

TY  - CONF
TI  - A Robotic Cell for Multi-Resolution Additive Manufacturing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2800
EP  - 2807
AU  - P. M. Bhatt
AU  - A. M. Kabir
AU  - R. K. Malhan
AU  - B. Shah
AU  - A. V. Shembekar
AU  - Y. J. Yoon
AU  - S. K. Gupta
PY  - 2019
KW  - extrusion
KW  - industrial robots
KW  - manipulators
KW  - nozzles
KW  - rapid prototyping (industrial)
KW  - surface finishing
KW  - three-dimensional printing
KW  - trajectory control
KW  - planar layers
KW  - robot manipulators
KW  - robotic cell
KW  - multiresolution additive manufacturing
KW  - heated nozzle
KW  - surface finish
KW  - fiber orientations
KW  - extrusion
KW  - layer-by-layer deposition
KW  - fused deposition model
KW  - nonplanar layers
KW  - degrees of freedom
KW  - collision-free trajectories
KW  - Tools
KW  - Printing
KW  - Surface treatment
KW  - Manipulators
KW  - Collision avoidance
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793730
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Extrusion-based additive manufacturing (AM), also known as fused deposition modeling (FDM) extrudes filaments through a heated nozzle and builds a part layer-by-layer. Using a smaller diameter nozzle can achieve better surface finish. However, there is a trade-off between surface finish and build times as using a small diameter nozzle leads to smaller layer thickness and long build times. Traditional FDM printers create a part with planar layers, and this restricts control over fiber orientations. This paper presents a robotic cell for multi-resolution AM. The cell consists of two 6 degrees of freedom (DOF) robot manipulators capable of printing non-planar and/or planar layers. We describe algorithms for decomposing parts into multi-resolution layers and generating collision-free trajectories for the robot manipulators. We validate our approach by printing five parts with multi-resolution.
ER  - 

TY  - CONF
TI  - Multimodal Bin Picking System with Compliant Tactile Sensor Arrays for Flexible Part Handling*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2824
EP  - 2830
AU  - V. Müller
AU  - N. Elkmann
PY  - 2019
KW  - control engineering computing
KW  - grippers
KW  - manipulators
KW  - object recognition
KW  - pose estimation
KW  - robot vision
KW  - sensor arrays
KW  - tactile sensors
KW  - compliant tactile sensor arrays
KW  - flexible part handling
KW  - robot control architecture
KW  - vision sensors
KW  - reliable handling
KW  - tactile grasp validation system
KW  - in-hand object monitoring
KW  - industrial grippers
KW  - magnetic gripper
KW  - flexible vacuum gripper
KW  - compliant custom tactile sensor array
KW  - specific gripper
KW  - in-hand object recognition
KW  - tactile-based object
KW  - grasp monitoring
KW  - tactile sensing
KW  - multimodal bin picking system
KW  - off-the-shelf bin picking system
KW  - vision-based picking approaches
KW  - Grippers
KW  - Grasping
KW  - Tactile sensors
KW  - Pose estimation
KW  - Monitoring
KW  - Sensor arrays
DO  - 10.1109/ICRA.2019.8793950
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a robot control architecture comprised of tactile and vision sensors incorporated into an off-the-shelf bin picking system. The proposed architecture facilitates flexible and reliable handling of objects and materials by employing a tactile grasp validation system and in-hand object monitoring. Two industrial grippers, specifically a magnetic gripper and a flexible vacuum gripper, are equipped with a compliant custom tactile sensor array. The algorithms used are for each specific gripper and respective sensor, however are transferrable to other grippers as well. The tactile sensing augments vision-based picking approaches, thus supporting in-hand object recognition [1] that is particularly useful for hard-to-recognize objects such as objects with transparent or shiny surfaces. Algorithms for tactile-based object pose estimation in the gripper and for grasp monitoring, including grasp validation, complete the approach.
ER  - 

TY  - CONF
TI  - Offline Policy Iteration Based Reinforcement Learning Controller for Online Robotic Knee Prosthesis Parameter Tuning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2831
EP  - 2837
AU  - M. Li
AU  - X. Gao
AU  - Y. Wen
AU  - J. Si
AU  - H. H. Huang
PY  - 2019
KW  - biomechanics
KW  - finite state machines
KW  - iterative methods
KW  - learning systems
KW  - medical robotics
KW  - optimal control
KW  - prosthetics
KW  - offline policy iteration
KW  - online robotic knee prosthesis parameter
KW  - optimal controller
KW  - personalized control
KW  - optimal control problems
KW  - human-prosthesis system
KW  - prototypic robotic prosthesis
KW  - approximate policy iteration algorithm
KW  - reinforcement learning-based control
KW  - near-normal knee kinematics
KW  - offline learning
KW  - robotic lower limb prosthesis
KW  - RL control
KW  - control policy
KW  - impedance control parameters
KW  - prosthesis control parameters
KW  - Prosthetics
KW  - Knee
KW  - Impedance
KW  - Kinematics
KW  - Reinforcement learning
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8794212
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper aims to develop an optimal controller that can automatically provide personalized control of robotic knee prosthesis in order to best support gait of individual prosthesis wearers. We introduced a new reinforcement learning (RL) controller for this purpose based on the promising ability of RL controllers to solve optimal control problems through interactions with the environment without requiring an explicit system model. However, collecting data from a human-prosthesis system is expensive and thus the design of a RL controller has to take into account data and time efficiency. We therefore propose an offline policy iteration based reinforcement learning approach. Our solution is built on the finite state machine (FSM) impedance control framework, which is the most used prosthesis control method in commercial and prototypic robotic prosthesis. Under such a framework, we designed an approximate policy iteration algorithm to devise impedance parameter update rules for 12 prosthesis control parameters in order to meet individual users' needs. The goal of the reinforcement learning-based control was to reproduce near-normal knee kinematics during gait. We tested the RL controller obtained from offline learning in real time experiment involving the same able-bodied human subject wearing a robotic lower limb prosthesis. Our results showed that the RL control resulted in good convergent behavior in kinematic states, and the offline learning control policy successfully adjusted the prosthesis control parameters to produce near-normal knee kinematics in 10 updates of the impedance control parameters.
ER  - 

TY  - CONF
TI  - Consolidated control framework to control a powered transfemoral prosthesis over inclined terrain conditions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2838
EP  - 2844
AU  - W. Hong
AU  - V. Paredes
AU  - K. Chao
AU  - S. Patrick
AU  - P. Hur
PY  - 2019
KW  - legged locomotion
KW  - medical control systems
KW  - optimisation
KW  - PD control
KW  - prosthetics
KW  - PD controller
KW  - AMPRO II
KW  - cubic Bezier polynomials
KW  - proportional-derivative controller
KW  - impedance parameters
KW  - impedance control scheme
KW  - trajectory tracking
KW  - sloped terrains
KW  - inclined terrain conditions
KW  - consolidated control framework
KW  - terrain inclinations
KW  - powered transfemoral prosthesis
KW  - terminal swing phase
KW  - slope walking trajectories
KW  - human slope walking data
KW  - offline optimization problem
KW  - Proportional-Derivative controller
KW  - compliant stance phase
KW  - Legged locomotion
KW  - Prosthetics
KW  - Trajectory
KW  - Impedance
KW  - Knee
KW  - Thigh
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794140
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For amputees, walking on sloped surfaces is one of the most challenging tasks in their daily lives. Unfortunately, designing a prosthesis that can effectively adapt to varying terrain is an ongoing problem. In this paper, we propose a unified control scheme that enables a powered transfemoral prosthesis to perform human-like walking on sloped terrains regardless of the slope and without any knowledge of the upcoming slope. The control scheme implements impedance control and trajectory tracking during the stance and swing phase, respectively. In the impedance control scheme, properly tuned impedance parameters are used to provide a stable and compliant stance phase that adapts to the slope of the ground. During the swing phase, the system is controlled by a Proportional-Derivative (PD) controller to track the desired trajectories based on cubic Bezier polynomials. These trajectories were obtained by solving an offline optimization problem compared to human slope walking data. Any slope walking trajectories can be generated online by using the optimized Bezier coefficients. At the terminal swing phase, a low gain PD controller is utilized to adapt to the unexpected terrains and smoothly track the generated trajectories. The proposed control framework is implemented on a powered transfemoral prosthesis, AMPRO II, on various slopes. The results validate the controller's ability to adapt to terrain inclinations within the range of ± 10°.
ER  - 

TY  - CONF
TI  - Estimating Loads Along Elastic Rods
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2867
EP  - 2873
AU  - V. A. Aloi
AU  - D. C. Rucker
PY  - 2019
KW  - bending
KW  - elasticity
KW  - inverse problems
KW  - manipulators
KW  - nonlinear programming
KW  - rods (structures)
KW  - elastic structures
KW  - distributed loads
KW  - elastic rod
KW  - large-deflection Cosserat-rod model
KW  - rod length
KW  - double-bend shapes
KW  - shape approximation
KW  - mechanics-based models
KW  - mechanics inverse problem
KW  - constrained nonlinear optimization
KW  - Force
KW  - Robot sensing systems
KW  - Shape
KW  - Load modeling
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794301
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mechanics-based models of thin elastic structures are prevalent in robotics research, both in soft/continuum robot modeling, and in robotic manipulation of strings, sutures, needles, and endoscopes. In all these applications, distributed loads along the device's length can affect its shape in space. Estimation of the distributed loading based on observation of the object's shape constitutes a classical mechanics inverse problem that would be useful in many applications, but this problem has received relatively little attention to date. In this paper, we propose methods to estimate distributed loads on an elastic rod using a large-deflection Cosserat-rod model and constrained nonlinear optimization. We perform experiments that illustrate the feasibility of using these methods to locate regions of high contact force along the rod, and to estimate magnitudes of the forces that are applied. Results show that overall force magnitudes and locations can be estimated with average error of 0.29 N (6.7% of average resultant magnitude) and 4 mm (2% of rod length) for complex double-bend shapes, and the shape approximation has near-zero error.
ER  - 

TY  - CONF
TI  - Oriented Point Sampling for Plane Detection in Unorganized Point Clouds
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2917
EP  - 2923
AU  - B. Sun
AU  - P. Mordohai
PY  - 2019
KW  - image reconstruction
KW  - image segmentation
KW  - image sensors
KW  - object detection
KW  - octrees
KW  - robot vision
KW  - SLAM (robots)
KW  - solid modelling
KW  - unorganized point clouds
KW  - crucial pre-processing step
KW  - point cloud segmentation
KW  - organized point clouds
KW  - plane hypotheses
KW  - unoriented points
KW  - efficient plane detection method
KW  - semantic mapping
KW  - SLAM
KW  - plane detection methods
KW  - OPS
KW  - oriented point sampling
KW  - Three-dimensional displays
KW  - Sun
KW  - Surface treatment
KW  - Clustering algorithms
KW  - Octrees
KW  - Estimation
KW  - Image segmentation
DO  - 10.1109/ICRA.2019.8793487
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Plane detection in 3D point clouds is a crucial pre-processing step for applications such as point cloud segmentation, semantic mapping and SLAM. In contrast to many recent plane detection methods that are only applicable on organized point clouds, our work is targeted to unorganized point clouds that do not permit a 2D parametrization. We compare three methods for detecting planes in point clouds efficiently. One is a novel method proposed in this paper that generates plane hypotheses by sampling from a set of points with estimated normals. We named this method Oriented Point Sampling (OPS) to contrast with more conventional techniques that require the sampling of three unoriented points to generate plane hypotheses. We also implemented an efficient plane detection method based on local sampling of three unoriented points and compared it with OPS and the 3D-KHT algorithm, which is based on octrees, on the detection of planes on 10,000 point clouds from the SUN RGB-D dataset.
ER  - 

TY  - CONF
TI  - The Importance of Metric Learning for Robotic Vision: Open Set Recognition and Active Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2924
EP  - 2931
AU  - B. J. Meyer
AU  - T. Drummond
PY  - 2019
KW  - convolutional neural nets
KW  - image classification
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - robotic vision
KW  - robotic problems
KW  - training set distribution
KW  - robotic applications
KW  - real-world robotic action
KW  - deep metric learning classification system
KW  - open set recognition problems
KW  - open set active learning approach
KW  - active learning problems
KW  - deep neural network recognition systems
KW  - Training
KW  - Robots
KW  - Labeling
KW  - Semantics
KW  - Task analysis
KW  - Extraterrestrial measurements
DO  - 10.1109/ICRA.2019.8794188
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - State-of-the-art deep neural network recognition systems are designed for a static and closed world. It is usually assumed that the distribution at test time will be the same as the distribution during training. As a result, classifiers are forced to categorise observations into one out of a set of predefined semantic classes. Robotic problems are dynamic and open world; a robot will likely observe objects that are from outside of the training set distribution. Classifier outputs in robotic applications can lead to real-world robotic action and as such, a practical recognition system should not silently fail by confidently misclassifying novel observations. We show how a deep metric learning classification system can be applied to such open set recognition problems, allowing the classifier to label novel observations as unknown. Further to detecting novel examples, we propose an open set active learning approach that allows a robot to efficiently query a user about unknown observations. Our approach enables a robot to improve its understanding of the true distribution of data in the environment, from a small number of label queries. Experimental results show that our approach significantly outperforms comparable methods in both the open set recognition and active learning problems.
ER  - 

TY  - CONF
TI  - Learning Discriminative Embeddings for Object Recognition on-the-fly
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2932
EP  - 2938
AU  - M. Lagunes-Fortiz
AU  - D. Damen
AU  - W. Mayol-Cuevas
PY  - 2019
KW  - image classification
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - lightweight classifier
KW  - Computer Vision applications
KW  - real-world images datasets
KW  - inference time
KW  - unseen objects
KW  - trained model
KW  - Supervised Triplet Loss
KW  - separable embeddings
KW  - high-end computational resources
KW  - CNNs
KW  - object recognition on-the-fly
KW  - discriminative embeddings
KW  - Training
KW  - Measurement
KW  - Computational modeling
KW  - Robots
KW  - Computer architecture
KW  - Object recognition
KW  - Support vector machines
DO  - 10.1109/ICRA.2019.8793715
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We address the problem of learning to recognize new objects on-the-fly efficiently. When using CNNs, a typical approach for learning new objects is by fine-tuning the model. However, this approach relies on the assumption that the original training set is available and requires high-end computational resources for training the ever-growing dataset efficiently, which can be unfeasible for robots with limited hardware. To overcome these limitations, we propose a new architecture that: 1) Instead of predicting labels, it learns to generate discriminative and separable embeddings of an object's viewpoints by using a Supervised Triplet Loss, which is easier to implement than current smart mining techniques and the trained model can be applied to unseen objects. 2) Infers an object's identity efficiently by utilizing a lightweight classifier in the features embedding space, this keeps the inference time in the order of milliseconds and can be retrained efficiently when new objects are learned. We evaluate our approach on four real-world images datasets used for Robotics and Computer Vision applications: Amazon Robotics Challenge 2017 by MIT-Princeton, T-LESS, ToyBoX, and CORe50 datasets. Code available at [1].
ER  - 

TY  - CONF
TI  - A Novel Multi-layer Framework for Tiny Obstacle Discovery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2939
EP  - 2945
AU  - F. Xue
AU  - A. Ming
AU  - M. Zhou
AU  - Y. Zhou
PY  - 2019
KW  - collision avoidance
KW  - edge detection
KW  - feature extraction
KW  - mobile robots
KW  - probability
KW  - regression analysis
KW  - robot vision
KW  - tiny obstacle discovery
KW  - monocular image
KW  - obstacle-aware discovery method
KW  - multilayer regions
KW  - tiny obstacle proposals
KW  - multilayer framework
KW  - edge detection
KW  - missing contour recovery
KW  - visual cues
KW  - obstacle-aware occlusion edge maps
KW  - proposals extraction
KW  - obstacle occupied probability map
KW  - obstacle-aware regressor
KW  - Lost and Found dataset
KW  - Image edge detection
KW  - Proposals
KW  - Visualization
KW  - Roads
KW  - Cameras
KW  - Three-dimensional displays
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8794279
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For tiny obstacle discovery in a monocular image, edge is a fundamental visual element. Nevertheless, because of various reasons, e.g., noise and similar color distribution with background, it is still difficult to detect the edges of tiny (b) obstacles at long distance. In this paper, we propose an obstacle-aware discovery method to recover the missing contours of these obstacles, which helps to obtain obstacle proposals as much as possible. First, by using visual cues in monocular images, several multi-layer regions are elaborately inferred to reveal the distances from the camera. Second, several novel obstacle-aware occlusion edge maps are constructed to well capture the contours of tiny obstacles, which combines cues from each layer. Third, to ensure the existence of the tiny obstacle proposals, the maps from all layers are used for proposals extraction. Finally, based on these proposals containing tiny obstacles, a novel obstacle-aware regressor is proposed to generate an obstacle occupied probability map with high confidence. The convincing experimental results with comparisons on the Lost and Found dataset demonstrate the effectiveness of our approach, achieving around 9.5% improvement on the accuracy than FPHT and PHT, it even gets comparable performance to MergeNet. Moreover, our method outperforms the state-of-the-art algorithms and significantly improves the discovery ability for tiny obstacles at long distance.
ER  - 


TY  - CONF
TI  - DSNet: Joint Learning for Scene Segmentation and Disparity Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2946
EP  - 2952
AU  - W. Zhan
AU  - X. Ou
AU  - Y. Yang
AU  - L. Chen
PY  - 2019
KW  - feature extraction
KW  - image coding
KW  - image matching
KW  - image segmentation
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - semantic features
KW  - deep disparity features
KW  - semantic labels
KW  - scene segmentation
KW  - disparity estimation
KW  - scene semantics
KW  - optical flow estimation
KW  - depth information
KW  - dense depth maps
KW  - image frames
KW  - deep semantic information
KW  - disparity feature maps
KW  - independent encoding modules
KW  - semantic disparity information
KW  - multitasking architecture DSNet
KW  - ResNet encoding module
KW  - Semantics
KW  - Estimation
KW  - Task analysis
KW  - Feature extraction
KW  - Optical imaging
KW  - Training
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793573
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recently, research works have attempted the joint prediction of scene semantics and optical flow estimation, which demonstrate the mutual improvement between both tasks. Besides, the depth information is also indispensable for the scene understanding, and disparity estimation is necessary for outputting dense depth maps. Such task shares a great similarity with the optical flow estimation since they can all be cast into a problem of capturing the difference at a location of two image frames. However, as far as we know, currently there are few networks for the joint learning of semantic and disparity. Moreover, since deep semantic information and disparity feature maps can learn from each other, we find it unnecessary with two independent encoding modules to separately extract semantic and disparity features. Therefore, we propose a unified multi-tasking architecture DSNet, for the simultaneous estimation of semantic and disparity information. In our model, semantic features, extracted by the encoding module ResNet from the left and right images, are used to obtain the deep disparity features via a novel matching module which performs pixel-to-pixel matching. In addition, we also use the disparity map to perform warp operation on deep features of the right image to deal with the problem of lacking of semantic labels. The effectiveness of our method is demonstrated by extensive experiments.
ER  - 

TY  - CONF
TI  - Spatial change detection using voxel classification by normal distributions transform
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2953
EP  - 2959
AU  - U. Katsura
AU  - K. Matsumoto
AU  - A. Kawamura
AU  - T. Ishigami
AU  - T. Okada
AU  - R. Kurazume
PY  - 2019
KW  - image classification
KW  - image colour analysis
KW  - image sensors
KW  - mobile robots
KW  - normal distribution
KW  - object detection
KW  - optical scanners
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - transforms
KW  - voxel classification
KW  - robotic applications
KW  - mobile robot
KW  - 3D laser scanner
KW  - grid data
KW  - ND voxels
KW  - normal distributions transform
KW  - spatial change detection
KW  - onboard RGB-D camera
KW  - stereo camera
KW  - real-time range sensors
KW  - real-time localization
KW  - Three-dimensional displays
KW  - Mobile robots
KW  - Cameras
KW  - Real-time systems
KW  - Measurement by laser beam
KW  - Sensors
DO  - 10.1109/ICRA.2019.8794173
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Detection of spatial change around a robot is indispensable in several robotic applications, such as search and rescue, security, and surveillance. The present paper proposes a fast spatial change detection technique for a mobile robot using an on-board RGB-D/stereo camera and a highly precise 3D map created by a 3D laser scanner. This technique first converts point clouds in a map and measured data to grid data (ND voxels) using normal distributions transform and classifies the ND voxels into three categories. The voxels in the map and the measured data are then compared according to the category and features of the ND voxels. Overlapping and voting techniques are also introduced in order to detect the spatial changes more robustly. We conducted experiments using a mobile robot equipped with real-time range sensors to confirm the performance of the proposed real-time localization and spatial change detection techniques in indoor and outdoor environments.
ER  - 

TY  - CONF
TI  - Set-based Inverse Kinematics Control of an Anthropomorphic Dual Arm Aerial Manipulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2960
EP  - 2966
AU  - E. Cataldi
AU  - F. Real
AU  - A. Suarez
AU  - P. A. Di Lillo
AU  - F. Pierri
AU  - G. Antonelli
AU  - F. Caccavale
AU  - G. Heredia
AU  - A. Ollero
PY  - 2019
KW  - autonomous aerial vehicles
KW  - end effectors
KW  - helicopters
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - redundant manipulators
KW  - inverse kinematics control
KW  - anthropomorphic dual arm aerial manipulator
KW  - multiple task-priority inverse kinematics algorithm
KW  - dual-arm aerial manipulator
KW  - equality constraints
KW  - inequality constraints
KW  - singularity robust method
KW  - motion control
KW  - underactuated aerial hexarotor vehicle
KW  - manipulators
KW  - null-space based behavioral control
KW  - Task analysis
KW  - Kinematics
KW  - End effectors
KW  - Jacobian matrices
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793470
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper presents a multiple task-priority inverse kinematics algorithm for a dual-arm aerial manipulator. Both tasks defined as equality constraints and inequality constraints are handled by means of a singularity robust method based on the Null-Space based Behavioral control. The proposed schema is constituted by the inverse kinematics control, that receives the desired behavior of the system and outputs the reference values for the motion variables, i.e. the UAV pose and the arm joints position, and a motion control, that computes the vehicle thrusts and the joint torques. The method has been experimentally validated on a system composed by an underactuated aerial hexarotor vehicle equipped with two lightweight 4-DOF manipulators, involved in operations requiring the coordination of the two arms and the vehicle.
ER  - 

TY  - CONF
TI  - Detection and Tracking of Small Objects in Sparse 3D Laser Range Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2967
EP  - 2973
AU  - J. Razlaw
AU  - J. Quenzel
AU  - S. Behnke
PY  - 2019
KW  - autonomous aerial vehicles
KW  - data structures
KW  - image segmentation
KW  - image sensors
KW  - laser ranging
KW  - median filters
KW  - mobile robots
KW  - object detection
KW  - object tracking
KW  - robot vision
KW  - solid modelling
KW  - autonomous behavior
KW  - microaerial vehicles
KW  - multiobject tracking
KW  - lightweight sensors
KW  - sparse point clouds
KW  - Velodyne VLP-16 sensor
KW  - MAV hardware
KW  - unlabeled data
KW  - sparse 3d laser range data
KW  - objects detection
KW  - median filters
KW  - data structure
KW  - Three-dimensional displays
KW  - Sensors
KW  - Target tracking
KW  - Object tracking
KW  - Real-time systems
KW  - Vehicle dynamics
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794204
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Detection and tracking of dynamic objects is a key feature for autonomous behavior in a continuously changing environment. With the increasing popularity and capability of micro aerial vehicles (MAVs) efficient algorithms have to be utilized to enable multi object tracking on limited hardware and data provided by lightweight sensors. We present a novel segmentation approach based on a combination of median filters and an efficient pipeline for detection and tracking of small objects within sparse point clouds generated by a Velodyne VLP-16 sensor. We achieve real-time performance on a single core of our MAV hardware by exploiting the inherent structure of the data. Our approach is evaluated on simulated and real scans of in- and outdoor environments, obtaining results comparable to the state of the art. Additionally, we provide an application for filtering the dynamic and mapping the static part of the data, generating further insights into the performance of the pipeline on unlabeled data.
ER  - 

TY  - CONF
TI  - GPS-Denied UAV Localization using Pre-existing Satellite Imagery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2974
EP  - 2980
AU  - H. Goforth
AU  - S. Lucey
PY  - 2019
KW  - artificial satellites
KW  - autonomous aerial vehicles
KW  - cameras
KW  - convolutional neural nets
KW  - distance measurement
KW  - Global Positioning System
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - flight location
KW  - UAV imagery
KW  - image capturing conditions
KW  - localization accuracy
KW  - adjacent UAV frames
KW  - satellite map
KW  - GPS-denied flight
KW  - average localization error
KW  - GPS-denied UAV localization
KW  - onboard GPS system
KW  - noisy GPS signal
KW  - unreliable GPS signal
KW  - monocular RGB camera
KW  - convolutional neural network representations
KW  - satellite data
KW  - satellite imagery
KW  - unmanned aerial vehicles
KW  - distance 0.85 km
KW  - distance 0.2 km
KW  - Satellites
KW  - Global Positioning System
KW  - Unmanned aerial vehicles
KW  - Training
KW  - Meters
KW  - Imaging
KW  - Buildings
DO  - 10.1109/ICRA.2019.8793558
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a method for localization of Unmanned Aerial Vehicles (UAVs) which is meant to replace an onboard GPS system in the event of a noisy or unreliable GPS signal. Our method requires only a downward-facing monocular RGB camera on the UAV, and pre-existing satellite imagery of the flight location to which the UAV imagery is compared and aligned. To overcome differences in the image capturing conditions between the satellite and UAV, such as seasonal and perspective changes, we propose the use of Convolutional Neural Network (CNN) representations trained on readily available satellite data. To increase localization accuracy, we also develop an optimization which jointly minimizes the error between adjacent UAV frames as well as the satellite map. We demonstrate how our method improves on recent systems from literature by achieving greater performance in flight environments with very few landmarks. For a GPS-denied flight at 0.2km altitude, over a flight distance of 0.85km, we achieve average localization error of less than 8 meters. We make our source code and datasets available to encourage further work on this emerging topic.
ER  - 

TY  - CONF
TI  - Adaptive View Planning for Aerial 3D Reconstruction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2981
EP  - 2987
AU  - C. Peng
AU  - V. Isler
PY  - 2019
KW  - autonomous aerial vehicles
KW  - image reconstruction
KW  - optimisation
KW  - trajectory control
KW  - aerial 3D reconstruction
KW  - aerial vehicles
KW  - high quality reconstruction
KW  - adaptive view planning method
KW  - coarse proxy
KW  - reconstruction error
KW  - 3D free space
KW  - Image reconstruction
KW  - Trajectory
KW  - Three-dimensional displays
KW  - Planning
KW  - Image resolution
KW  - Feature extraction
KW  - Drones
DO  - 10.1109/ICRA.2019.8793532
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - With the proliferation of small aerial vehicles, acquiring close up imagery for high quality reconstruction is gaining importance. We present an adaptive view planning method to collect such images in an automated fashion. We first start by sampling a small set of views to build a coarse proxy to the scene. We then present (i) a method that builds a set of adaptive viewing planes for efficient view selection and (ii) an algorithm to plan a trajectory that guarantees high reconstruction quality which does not deviate too much from the optimal one. The vehicle then follows the trajectory to cover the scene, and the procedure is repeated until reconstruction quality converges or a desired level of quality is achieved. The set of viewing planes provides an effective compromise between using the entire 3D free space and using a single view hemisphere to select the views. We compare our algorithm to existing methods in three challenging scenes. Our algorithm generates views which produce the least reconstruction error comparing to three different baseline approaches.
ER  - 

TY  - CONF
TI  - An Autonomous Loop-Closure Approach for Simultaneous Exploration and Coverage of Unknown Infrastructure Using MAVs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2988
EP  - 2994
AU  - D. G. Vutetakis
AU  - J. Xiao
PY  - 2019
KW  - autonomous aerial vehicles
KW  - inspection
KW  - microrobots
KW  - mobile robots
KW  - spatial measurements
KW  - MAV motions
KW  - complete exploration
KW  - autonomous loop-closure approach
KW  - simultaneous exploration
KW  - unknown infrastructure
KW  - attractive means
KW  - critical infrastructure
KW  - autonomous tasks
KW  - precise spatial model
KW  - operational area
KW  - sensor measurements
KW  - autonomous inspection capabilities
KW  - autonomous MAV exploration
KW  - unknown structure
KW  - spatial information
KW  - high-fidelity 3D model
KW  - low-cost microaerial vehicles
KW  - Planning
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Inspection
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2019.8794110
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The recent proliferation of low-cost Micro Aerial Vehicles (MAV) offers an attractive means for inspecting critical infrastructure autonomously. However, to enable such autonomous tasks requires a precise spatial model of the structure and operational area, typically constructed using sensor measurements obtained from the environment. To facilitate autonomous inspection capabilities, we address the problem of autonomous MAV exploration and coverage of an unknown structure to acquire the spatial information necessary for the development of a high-fidelity 3D model of the structure. Key to this problem is to not only cover the entire structure to acquire a complete set of spatial measurements, but also to minimize accumulative data errors during the exploration through direct planning of loop closures. We introduce a real-time waypoint planning approach to guide MAV motions to achieve complete exploration, coverage, and loop closure while respecting limited onboard resources.
ER  - 

TY  - CONF
TI  - Unsupervised Learning of Assistive Camera Views by an Aerial Co-robot in Augmented Reality Multitasking Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3003
EP  - 3009
AU  - W. Bentz
AU  - S. Dhanjal
AU  - D. Panagou
PY  - 2019
KW  - augmented reality
KW  - autonomous aerial vehicles
KW  - cameras
KW  - computer displays
KW  - mobile robots
KW  - unsupervised learning
KW  - unsupervised learning
KW  - assistive camera views
KW  - augmented reality multitasking environments
KW  - assistive aerial robot
KW  - task domain
KW  - head motion
KW  - anisotropic spherical sensor
KW  - expectation maximization solver
KW  - Gaussians
KW  - dynamic coverage control law
KW  - augmented reality display
KW  - human operator
KW  - assistive robot
KW  - reflex time
KW  - task completion time
KW  - aerial co-robot
KW  - Visualization
KW  - Task analysis
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793587
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel method by which an assistive aerial robot can learn the relevant camera views within a task domain through tracking the head motions of a human collaborator. The human's visual field is modeled as an anisotropic spherical sensor, which decays in acuity towards the periphery, and is integrated in time throughout the domain. This data is resampled and fed into an expectation maximization solver in order to estimate the environment's visual interest as a mixture of Gaussians. A dynamic coverage control law directs the robot to capture camera views of the peaks of these Gaussians which is broadcast to an augmented reality display worn by the human operator. An experimental study is presented that assesses the influence of the assistive robot on reflex time, head motion, and task completion time.
ER  - 

TY  - CONF
TI  - Visual Coverage Control for Teams of Quadcopters via Control Barrier Functions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3010
EP  - 3016
AU  - R. Funada
AU  - M. Santos
AU  - J. Yamauchi
AU  - T. Hatanaka
AU  - M. Fujita
AU  - M. Egerstedt
PY  - 2019
KW  - computational geometry
KW  - distributed control
KW  - gradient methods
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - visual coverage control
KW  - quadcopters
KW  - control barrier functions
KW  - coverage control strategy
KW  - visual sensors
KW  - locational cost
KW  - cost function
KW  - distributed control law
KW  - gradient ascent control law
KW  - Space missions
KW  - Monitoring
KW  - Visualization
KW  - Robot sensing systems
KW  - Cameras
DO  - 10.1109/ICRA.2019.8793477
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a coverage control strategy for teams of quadcopters that ensures that no area is left unsurveyed in between the fields of view of the visual sensors mounted on the quadcopters. We present a locational cost that quantifies the team's coverage performance according to the sensors' performance function. Moreover, the cost function penalizes overlaps between the fields of view of the different sensors, with the objective of increasing the area covered by the team. A distributed control law is derived for the quadcopters so that they adjust their position and zoom according to the direction of ascent of the cost. Control barrier functions are implemented to ensure that, while executing the gradient ascent control law, no holes appear in between the fields of view of neighboring robots. The performance of the algorithm is evaluated in simulated experiments.
ER  - 

TY  - CONF
TI  - Robot Co-design: Beyond the Monotone Case
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3024
EP  - 3030
AU  - L. Carlone
AU  - C. Pinciroli
PY  - 2019
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - software aspects
KW  - robotic platform
KW  - robot design process
KW  - small-volumes low-cost applications
KW  - computational robot co-design problem
KW  - robotic modules
KW  - binary optimization formulation
KW  - co-design problems
KW  - autonomous drone racing platform
KW  - multirobot system
KW  - monotone case
KW  - miniaturized robotic hardware
KW  - inexpensive robots
KW  - disposable robots
KW  - scientific discovery
KW  - confined spaces
KW  - nanodrones
KW  - task-specific robots clashes
KW  - human experts
KW  - search-and-rescue
KW  - Robot sensing systems
KW  - Drones
KW  - Task analysis
KW  - Hardware
KW  - Legged locomotion
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793926
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent advances in 3D printing and manufacturing of miniaturized robotic hardware and computing are paving the way to build inexpensive and disposable robots. This will have a large impact on several applications including scientific discovery (e.g., hurricane monitoring), search-and-rescue (e.g., operation in confined spaces), and entertainment (e.g., nano drones). The need for inexpensive and task-specific robots clashes with the current practice, where human experts are in charge of designing hardware and software aspects of the robotic platform. This makes the robot design process expensive and time consuming, and ultimately unsuitable for small-volumes low-cost applications. This paper considers the computational robot co-design problem, which aims to create an automatic algorithm that selects the best robotic modules (sensing, actuation, computing) in order to maximize the performance on a task, while satisfying given specifications (e.g., maximum cost of the resulting design). We propose a binary optimization formulation of the co-design problem and show that such formulation generalizes previous work based on strong modeling assumptions. We show that the proposed formulation can solve relatively large co-design problems in seconds and with minimal human intervention. We demonstrate the proposed approach in two applications: the co-design of an autonomous drone racing platform and the co-design of a multi-robot system.
ER  - 

TY  - CONF
TI  - Multi-Vehicle Close Enough Orienteering Problem with Bézier Curves for Multi-Rotor Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3039
EP  - 3044
AU  - J. Faigl
AU  - P. Váňa
AU  - R. Pěnička
PY  - 2019
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - remotely operated vehicles
KW  - unsupervised learning
KW  - travel cost
KW  - travel budget
KW  - Bézier curves
KW  - multivehicle CEOP
KW  - multirotor aerial vehicles
KW  - maximal velocity
KW  - acceleration limits
KW  - rewarding target locations
KW  - multivehicle close enough orienteering problem
KW  - surveillance planning
KW  - unsupervised learning
KW  - Trajectory
KW  - Acceleration
KW  - Adaptive arrays
KW  - Planning
KW  - Unsupervised learning
KW  - Optimization
KW  - Surveillance
DO  - 10.1109/ICRA.2019.8794339
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces the Close Enough Orienteering Problem (CEOP) for planning missions with multi-rotor aerial vehicles considering their maximal velocity and acceleration limits. The addressed problem stands to select the most rewarding target locations and sequence to visit them in the given limited travel budget. The reward is collected within a non-zero range from a particular target location that allows saving the travel cost, and thus collect more rewards. Hence, we are searching for the fastest trajectories to collect the most valuable rewards such that the motion constraints are not violated, and the travel budget is satisfied. We leverage on existing trajectory parametrization based on Bézier curves recently deployed in surveillance planning using unsupervised learning, and we propose to employ the learning in a solution of the introduced multi-vehicle CEOP. Feasibility of the proposed approach is supported by empirical evaluation and experimental deployment using multi-rotor vehicles.
ER  - 

TY  - CONF
TI  - Critically fast pick-and-place with suction cups
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3045
EP  - 3051
AU  - H. Pham
AU  - Q. Pham
PY  - 2019
KW  - logistics
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mechanical contact
KW  - path planning
KW  - stability
KW  - time optimal control
KW  - suction cup contacts
KW  - fast robotics pick-and-place
KW  - contact stability constraint
KW  - logistics
KW  - factory lines
KW  - object transport
KW  - object movement
KW  - contact handling
KW  - kinodynamic constraint
KW  - time-optimal parameterization
KW  - geometric paths
KW  - physical robot system
KW  - Stability analysis
KW  - Robots
KW  - Planning
KW  - Friction
KW  - Force
KW  - Computational modeling
KW  - Pipelines
DO  - 10.1109/ICRA.2019.8794081
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fast robotics pick-and-place with suction cups is a crucial component in the current development of automation in logistics (factory lines, e-commerce, etc.). By “critically fast” we mean the fastest possible movement for transporting an object such that it does not slip or fall from the suction cup. The main difficulties are: (i) handling the contact between the suction cup and the object, which fundamentally involves kinodynamic constraints; and (ii) doing so at a low computational cost, typically a few hundreds of milliseconds. To address these difficulties, we propose (a) a model for suction cup contacts, (b) a procedure to identify the contact stability constraint based on that model, and (c) a pipeline to parameterize, in a time-optimal manner, arbitrary geometric paths under the identified contact stability constraint. We experimentally validate the proposed pipeline on a physical robot system: the cycle time for a typical pick-and-place task was less than 5 seconds, planning and execution times included. The full pipeline is released as opensource for the robotics community.
ER  - 

TY  - CONF
TI  - Robust Link Position Tracking Control for Robot Manipulators with Series Elastic Actuators Using Time-delay Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3052
EP  - 3058
AU  - S. H. Park
AU  - J. Lee
AU  - K. Seo
AU  - M. Jin
PY  - 2019
KW  - closed loop systems
KW  - delay estimation
KW  - delays
KW  - manipulators
KW  - nonlinear dynamical systems
KW  - position control
KW  - robust control
KW  - variable structure systems
KW  - closed-loop stability
KW  - link inertia information
KW  - dynamic coupling terms
KW  - terminal sliding mode control
KW  - modified TDE
KW  - complicated nonlinear dynamics terms
KW  - SEA dynamics
KW  - SEA-driven manipulator
KW  - robust link position tracking control
KW  - robot manipulator
KW  - series elastic actuators
KW  - time-delay estimation technique
KW  - constant gain matrix
KW  - TDE framework
KW  - Robot sensing systems
KW  - Manipulator dynamics
KW  - Estimation
KW  - Service robots
KW  - Torque
DO  - 10.1109/ICRA.2019.8794083
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper aims to develop a controller for a robot manipulator equipped with series elastic actuators (SEAs) to precisely track the desired link position coping with deflections from the intrinsic compliance. The well-known time-delay estimation (TDE) technique is modified for devising the new controller. In this paper, we first report that the conventional use of a constant gain matrix for the TDE framework is insufficient for high accuracy tracking because the tracking accuracy is significantly deteriorated and the closed-loop stability may be threatened. Accordingly, the new controller employs link inertia information with dynamic coupling terms to define the gain for TDE and then employs terminal sliding mode (TSM) control to enhance robustness and convergence speed. Particularly, the modified TDE is applied in the two-staged manner which enables to compensate the complicated nonlinear dynamics terms in SEA dynamics. The TSM synergistically amalgamates the accuracy, robustness, and convergence in tracking. The proposed controller is numerically validated by comparative experiments with a SEA-driven manipulator.
ER  - 

TY  - CONF
TI  - A Simple but Robust Impedance Controller for Series Elastic Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3059
EP  - 3065
AU  - D. Kim
AU  - K. Koh
AU  - G. Cho
AU  - L. Zhang
PY  - 2019
KW  - actuators
KW  - control system synthesis
KW  - delay estimation
KW  - elasticity
KW  - force control
KW  - perturbation theory
KW  - robust control
KW  - robust impedance controller
KW  - series elastic actuators
KW  - singular perturbation theory
KW  - SP theory
KW  - TDE technique
KW  - time-delay estimation technique
KW  - numerical analysis
KW  - Impedance
KW  - Bandwidth
KW  - End effectors
KW  - Position control
KW  - Actuators
DO  - 10.1109/ICRA.2019.8793809
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study presents an impedance controller for series elastic actuators (SEAs), using the singular perturbation (SP) theory and time-delay estimation (TDE) technique. While the SP theory attenuates the requirement for states to be measured, the TDE technique eliminates the requirement for identifying system parameters. Through a numerical analysis and experimental validation, we demonstrate that the proposed controller produces satisfactory tracking performance while-at the same time-pursues wider operational bandwidth and lower driving-point impedance.
ER  - 

TY  - CONF
TI  - Robotic Cutting: Mechanics and Control of Knife Motion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3066
EP  - 3072
AU  - X. Mu
AU  - Y. Xue
AU  - Y. Jia
PY  - 2019
KW  - blades
KW  - dexterous manipulators
KW  - force sensors
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - material toughness
KW  - blade-material friction
KW  - shape deformation
KW  - robotic arm
KW  - separate control strategy
KW  - Cartesian space
KW  - force constraints
KW  - smooth motions
KW  - robotic cutting
KW  - knife motion
KW  - material fracture
KW  - smooth knife movements
KW  - Force
KW  - Friction
KW  - Strain
KW  - Torque
KW  - Robot sensing systems
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8793880
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Effectiveness of cutting is measured by the ability to achieve material fracture with smooth knife movements. The work performed by a knife overcomes the material toughness, acts against the blade-material friction, and generates shape deformation. This paper studies how to control a 2-DOF robotic arm equipped with a force/torque sensor to cut through an object in a sequence of three moves: press, push, and slice. For each move, a separate control strategy in the Cartesian space is designed to incorporate contact and/or force constraints while following some prescribed trajectory. Experiments conducted over several types of natural foods have demonstrated smooth motions like would be commanded by a human hand.
ER  - 

TY  - CONF
TI  - A constrained control-planning strategy for redundant manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3073
EP  - 3079
AU  - C. Barbalata
AU  - R. Vasudevan
AU  - M. Johnson-Roberson
PY  - 2019
KW  - adaptive control
KW  - control system synthesis
KW  - fuzzy control
KW  - path planning
KW  - redundant manipulators
KW  - constrained control-planning strategy
KW  - redundant manipulators
KW  - interconnected control-planning strategy
KW  - high-level planning components
KW  - adaptive control rule
KW  - multibody robotic system
KW  - Task analysis
KW  - Manipulators
KW  - Mathematical model
KW  - Optimal control
KW  - Planning
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793843
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents an interconnected control-planning strategy for redundant manipulators, subject to system and environmental constraints. The method incorporates low-level control characteristics and high-level planning components into a robust strategy for manipulators acting in complex environments, subject to joint limits. This strategy is formulated using an adaptive control rule, a computational efficient estimation of the robot's mathematical model and the nullspace of the constraints. A path is generated that takes into account the capabilities of the platform. The proposed method is computationally efficient, enabling its implementation on a real multi-body robotic system. Through experimental results with a 7 degree-of-freedom (DOF) manipulator, we demonstrate the performance of the method in real-world scenarios.
ER  - 

TY  - CONF
TI  - Reinforcement Learning on Variable Impedance Controller for High-Precision Robotic Assembly
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3080
EP  - 3087
AU  - J. Luo
AU  - E. Solowjow
AU  - C. Wen
AU  - J. A. Ojea
AU  - A. M. Agogino
AU  - A. Tamar
AU  - P. Abbeel
PY  - 2019
KW  - assembling
KW  - control engineering computing
KW  - force control
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - neural net architecture
KW  - position control
KW  - robotic assembly
KW  - wheels
KW  - high-precision robotic assembly
KW  - precise robotic manipulation skills
KW  - industrial settings
KW  - reinforcement learning methods
KW  - RL
KW  - perceived forces
KW  - high-precision tasks
KW  - proper operational space force controller
KW  - open-source Siemens Robot Learning Challenge
KW  - precise force-controlled behavior
KW  - delicate force-controlled behavior
KW  - variable impedance controller
KW  - Task analysis
KW  - Gears
KW  - Aerospace electronics
KW  - Robots
KW  - Reinforcement learning
KW  - Trajectory
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793506
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Precise robotic manipulation skills are desirable in many industrial settings, reinforcement learning (RL) methods hold the promise of acquiring these skills autonomously. In this paper, we explicitly consider incorporating operational space force/torque information into reinforcement learning; this is motivated by humans heuristically mapping perceived forces to control actions, which results in completing high-precision tasks in a fairly easy manner. Our approach combines RL with force/torque information by incorporating a proper operational space force controller; where we also exploit different ablations on processing this information. Moreover, we propose a neural network architecture that generalizes to reasonable variations of the environment. We evaluate our method on the open-source Siemens Robot Learning Challenge, which requires precise and delicate force-controlled behavior to assemble a tight-fit gear wheel set.
ER  - 

TY  - CONF
TI  - A Compliant and Precise Pneumatic Rotary Drive Using Pneumatic Artificial Muscles in a Swash Plate Design
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3088
EP  - 3094
AU  - J. T. Stoll
AU  - K. Schanz
AU  - A. Pott
PY  - 2019
KW  - design engineering
KW  - human-robot interaction
KW  - muscle
KW  - pneumatic actuators
KW  - position control
KW  - torque
KW  - mechanic design
KW  - pneumatic control system
KW  - electric control system
KW  - drive unit
KW  - adjustable stiffness
KW  - stick-slip phenomenon
KW  - high precision positioning
KW  - pneumatic systems
KW  - pneumatic rotary drive unit
KW  - human-robot collaboration
KW  - articulated robots
KW  - precise rotary drive units
KW  - compliant drive units
KW  - swash plate design
KW  - pneumatic artificial muscles
KW  - Shafts
KW  - Force
KW  - Muscles
KW  - Torque
KW  - Pneumatic systems
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794185
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Compliant and precise rotary drive units are essential for the design of articulated robots that are capable of safe human-robot collaboration. In this paper, we present a new pneumatic rotary drive unit that combines the compliance of pneumatic systems with the ability to perform high precision positioning. We use pneumatic artificial muscles (PAMs) pulling on a swash plate to avoid the stick-slip phenomenon and to realize adjustable stiffness. Furthermore, the presented drive unit can operate in 360° continuous rotation. These properties make the drive particularly suitable for the later use in human-robot collaboration. We explain the mechanic design as well as the pneumatic and electric control system that we use to operate the drive unit. We derive the equations to calculate the static torque distribution and compare the theoretical results to the data measured on the realized laboratory test stand, depicted in figure 1. The accuracy of the used 16-bit encoder is achieved and adjustable stiffness is realized and measured on the laboratory test stand. The measurements of the reaction to a step response are discussed based on a first and basic control strategy.
ER  - 

TY  - CONF
TI  - Passivity based Control of Antagonistic Tendon-Driven Mechanism
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3095
EP  - 3100
AU  - J. Park
AU  - G. Y. Hong
AU  - Y. Choi
AU  - D. Peng
AU  - Q. Lu
PY  - 2019
KW  - asymptotic stability
KW  - control system synthesis
KW  - end effectors
KW  - force control
KW  - manipulator dynamics
KW  - nonlinear control systems
KW  - torque control
KW  - antagonistic tendon-driven mechanism
KW  - passivity-based control law
KW  - passivity theorem
KW  - complex tendon-driven mechanism
KW  - control strategy
KW  - impedance control schemes
KW  - gravity compensation
KW  - interconnected subsystems
KW  - Tendons
KW  - Gravity
KW  - Torque
KW  - Asymptotic stability
KW  - Robots
KW  - Control systems
DO  - 10.1109/ICRA.2019.8794151
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper presents a passivity-based control law for an antagonistic tendon-driven mechanism. It is proven, by using the passivity theorem, that the proposed control law is able to achieve two properties such as the passivity of interconnected subsystems when the external torque is applied and the global asymptotic stability during free motion when the external force is absent. The proposed controller is simple to be implemented for a complex tendon-driven mechanism because it requires only gravity compensation. In addition, it brings a robustness to the entire control system. And finally, the control strategy can be treated as one of the impedance control schemes so as to achieve the desired performance efficiently.
ER  - 

TY  - CONF
TI  - Exact Modal Characterization of the Non Conservative Non Linear Radial Mass Spring System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3101
EP  - 3107
AU  - C. D. Santina
AU  - D. Lakatos
AU  - A. Bicchi
AU  - A. Albu-Schaeffer
PY  - 2019
KW  - damping
KW  - elasticity
KW  - linear systems
KW  - modal analysis
KW  - nonlinear dynamical systems
KW  - robot dynamics
KW  - shock absorbers
KW  - springs (mechanical)
KW  - vibration control
KW  - exact modal characterization
KW  - modal analysis
KW  - linear mechanical systems
KW  - nonlinear elastic robot
KW  - nonlinear normal modes
KW  - nonlinear oscillatory behaviors
KW  - dissipative effects
KW  - damping
KW  - nonconservative nonlinear radial mass spring damper system
KW  - Manifolds
KW  - Springs
KW  - Force
KW  - Damping
KW  - Soft robotics
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8793732
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Since the spread of robotic systems embedding in their mechanics purposefully designed elastic elements, the interest in characterizing and exploiting non-linear oscillatory behaviors has progressively grown. However, few works so far looked at the problem from the point of view of modal analysis. This is particularly surprising if considered the central role that modal theory had in the development of classic results in analysis and control of linear mechanical systems. With the aim of making a step toward translating and extending this powerful tool to the robotic field, we present the complete modal characterization of a simple yet representative non-linear elastic robot: the 2D planar mass-spring-damper system. Generic non-linear elastic forces and dissipative effects are considered. We provide here exact descriptions of the two non-linear normal modes of the system. We then extend the analysis to generic combinations of the modes in conservative case and for small damping. Simulations are provided to illustrate the theoretical results. This is one of the very firsts applications of normal mode theory to dynamically coupled non-linear systems, and the first exact result in the field.
ER  - 

TY  - CONF
TI  - Body Lift and Drag for a Legged Millirobot in Compliant Beam Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3108
EP  - 3114
AU  - C. Koc
AU  - C. Koc
AU  - B. Su
AU  - C. S. Casarez
AU  - R. S. Fearing
PY  - 2019
KW  - beams (structures)
KW  - drag
KW  - force sensors
KW  - legged locomotion
KW  - microrobots
KW  - shells (structures)
KW  - legged millirobots
KW  - body lift
KW  - robot locomotion
KW  - body-beam forces
KW  - body motion
KW  - light-weight legged robots
KW  - dense terrains
KW  - drag energy
KW  - drag forces increase
KW  - negative lift forces
KW  - VelociRoACH robotic platform
KW  - densely cluttered environment
KW  - compliant beams
KW  - hexapedal millirobot
KW  - interaction forces
KW  - body contact forces
KW  - terrain
KW  - granular media
KW  - foot traction forces
KW  - legged locomotion
KW  - compliant beam environment
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Drag
KW  - Shape
KW  - Force measurement
DO  - 10.1109/ICRA.2019.8793597
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Much current study of legged locomotion has rightly focused on foot traction forces, including on granular media. Future legged millirobots will need to go through terrain, such as brush or other vegetation, where the body contact forces significantly affect locomotion. In this work, a (previously developed) low-cost 6-axis force/torque sensing shell is used to measure the interaction forces between a hexapedal millirobot and a set of compliant beams, which act as a surrogate for a densely cluttered environment. Experiments with a VelociRoACH robotic platform are used to measure lift and drag forces on the tactile shell, where negative lift forces can increase traction, even while drag forces increase. The drag energy and specific resistance required to pass through dense terrains can be measured. Furthermore, some contact between the robot and the compliant beams can lower specific resistance of locomotion. For small, light-weight legged robots in the beam environment, the body motion depends on both legground and body-beam forces. A shell-shape which reduces drag but increases negative lift, such as the half-ellipsoid used, is suggested to be advantageous for robot locomotion in this type of environment.
ER  - 

TY  - CONF
TI  - Tightly Coupled 3D Lidar Inertial Odometry and Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3144
EP  - 3150
AU  - H. Ye
AU  - Y. Chen
AU  - M. Liu
PY  - 2019
KW  - distance measurement
KW  - image fusion
KW  - mobile robots
KW  - motion estimation
KW  - optical radar
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - fast motion conditions
KW  - ego-motion estimation
KW  - mobile robotic applications
KW  - sensor fusion
KW  - stand-alone sensors
KW  - tightly coupled lidar-IMU fusion method
KW  - IMU measurements
KW  - lidarIMU odometry
KW  - lidar measurement
KW  - rotation-constrained refinement algorithm
KW  - LIO-mapping
KW  - sensor pair
KW  - IMU update rate
KW  - lidar pose estimation
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Estimation
KW  - Robot sensing systems
KW  - Feature extraction
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793511
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Ego-motion estimation is a fundamental requirement for most mobile robotic applications. By sensor fusion, we can compensate the deficiencies of stand-alone sensors and provide more reliable estimations. We introduce a tightly coupled lidar-IMU fusion method in this paper. By jointly minimizing the cost derived from lidar and IMU measurements, the lidarIMU odometry (LIO) can perform well with considerable drifts after long-term experiment, even in challenging cases where the lidar measurement can be degraded. Besides, to obtain more reliable estimations of the lidar poses, a rotation-constrained refinement algorithm (LIO-mapping) is proposed to further align the lidar poses with the global map. The experiment results demonstrate that the proposed method can estimate the poses of the sensor pair at the IMU update rate with high precision, even under fast motion conditions or with insufficient features.
ER  - 

TY  - CONF
TI  - Expectation-Maximization for Adaptive Mixture Models in Graph Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3151
EP  - 3157
AU  - T. Pfeifer
AU  - P. Protzel
PY  - 2019
KW  - expectation-maximisation algorithm
KW  - Gaussian processes
KW  - optimisation
KW  - probability
KW  - sensor fusion
KW  - error distribution
KW  - multimodal Gaussian mixture model
KW  - sensor fusion problem
KW  - expectation-maximization
KW  - adaptive mixture algorithm
KW  - static parametrization
KW  - graph optimization
KW  - NonGaussian
KW  - multimodal distributions
KW  - robust cost functions
KW  - convergence properties
KW  - robust sensor fusion algorithms
KW  - Optimization
KW  - Estimation
KW  - Convergence
KW  - Global navigation satellite system
KW  - Adaptation models
KW  - Sensor fusion
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793601
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Non-Gaussian and multimodal distributions are an important part of many recent robust sensor fusion algorithms. In difference to robust cost functions, they are probabilistically founded and have good convergence properties. Since their robustness depends on a close approximation of the real error distribution, their parametrization is crucial. We propose a novel approach that allows to adapt a multi-modal Gaussian mixture model to the error distribution of a sensor fusion problem. By combining expectation-maximization and non-linear least squares optimization, we are able to provide a computationally efficient solution with well-behaved convergence properties. We demonstrate the performance of these algorithms on several real-world GNSS and indoor localization datasets. The proposed adaptive mixture algorithm outperforms state-of-the-art approaches with static parametrization. Source code and datasets are available under https://mytuc.org/libRSF.
ER  - 

TY  - CONF
TI  - Multi-Camera Visual-Inertial Navigation with Online Intrinsic and Extrinsic Calibration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3158
EP  - 3164
AU  - K. Eckenhoff
AU  - P. Geneva
AU  - J. Bloecker
AU  - G. Huang
PY  - 2019
KW  - calibration
KW  - cameras
KW  - image sensors
KW  - inertial navigation
KW  - interpolation
KW  - Kalman filters
KW  - extrinsic calibration
KW  - asynchronous cameras
KW  - standard multistate constraint Kalman Filter framework
KW  - IMU poses
KW  - single base camera
KW  - state vector
KW  - camera images
KW  - inertial measurements
KW  - tightly-coupled state estimation
KW  - online sensor calibration
KW  - mc-VINS algorithm
KW  - high-precision localization
KW  - multicamera visual-inertial navigation
KW  - online intrinsic calibration
KW  - pose interpolation
KW  - high-fidelity localization
KW  - sensor configurations
KW  - Cameras
KW  - Calibration
KW  - Navigation
KW  - Cloning
KW  - Interpolation
KW  - Estimation
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793886
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a general multi-camera visual-inertial navigation system (mc-VINS) with online instrinsic and extrinsic calibration, which is able to utilize all the information from an arbitrary number of asynchronous cameras. In particular, within the standard multi-state constraint Kalman Filter (MSCKF) framework, we only clone the IMU poses related to a single “base camera” (rather than all cameras) in the state vector, while the IMU poses corresponding to all other camera images are represented via an interpolation of the poses bounding the measuring time. By doing so, we can fuse all observations from all cameras with inertial measurements while allowing for efficient, tightly-coupled state estimation through parallelization and asynchrony. Moreover, we perform online sensor calibration of each camera's intrinsics as well as the spatial (transformation) and temporal (time offset) extrinsic parameters between all involved sensors (cameras and IMU), thus enabling high-fidelity localization. We validate the proposed mc-VINS algorithm in various real-world experiments with different sensor configurations, showing the ability to offer real-time high-precision localization and calibration results.
ER  - 

TY  - CONF
TI  - Joint Inference of Kinematic and Force Trajectories with Visuo-Tactile Sensing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3165
EP  - 3171
AU  - A. S. Lambert
AU  - M. Mukadam
AU  - B. Sundaralingam
AU  - N. Ratliff
AU  - B. Boots
AU  - D. Fox
PY  - 2019
KW  - biomimetics
KW  - force control
KW  - force sensors
KW  - graph theory
KW  - inference mechanisms
KW  - manipulator kinematics
KW  - optimisation
KW  - probability
KW  - robot vision
KW  - sensor fusion
KW  - state estimation
KW  - tactile sensors
KW  - trajectory control
KW  - biomimetic tactile sensor
KW  - force-torque sensor
KW  - probabilistic inference
KW  - vision sensors
KW  - multimodal sensor data
KW  - visuo-tactile sensing
KW  - robust state estimation
KW  - vision-based articulated model tracker
KW  - force trajectories
KW  - kinematic trajectories
KW  - robots
KW  - factor graphs
KW  - optimization
KW  - manipulation platforms
KW  - Force
KW  - Trajectory
KW  - Tactile sensors
KW  - Noise measurement
KW  - Estimation
DO  - 10.1109/ICRA.2019.8794048
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To perform complex tasks, robots must be able to interact with and manipulate their surroundings. One of the key challenges in accomplishing this is robust state estimation during physical interactions, where the state involves not only the robot and the object being manipulated, but also the state of the contact itself. In this work, within the context of planar pushing, we extend previous inference-based approaches to state estimation in several ways. We estimate the robot, object, and the contact state on multiple manipulation platforms configured with a vision-based articulated model tracker, and either a biomimetic tactile sensor or a force-torque sensor. We show how to fuse raw measurements from the tracker and tactile sensors to jointly estimate the trajectory of the kinematic states and the forces in the system via probabilistic inference on factor graphs, in both batch and incremental settings. We perform several benchmarks with our framework and show how performance is affected by incorporating various geometric and physics based constraints, occluding vision sensors, or injecting noise in tactile sensors. We also compare with prior work on multiple datasets and demonstrate that our approach can effectively optimize over multi-modal sensor data and reduce uncertainty to find better state estimates.
ER  - 

TY  - CONF
TI  - Every Hop is an Opportunity: Quickly Classifying and Adapting to Terrain During Targeted Hopping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3188
EP  - 3194
AU  - A. H. Chang
AU  - C. Hubicki
AU  - A. Ames
AU  - P. A. Vela
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mobile robots
KW  - pattern classification
KW  - robot programming
KW  - terrain properties
KW  - terrain-informed learning
KW  - low shot learning
KW  - targeted hopping
KW  - task-relevant objectives
KW  - hopping robot
KW  - control strategies
KW  - jumping task
KW  - closed-loop jumping
KW  - real-world jumping data
KW  - terrain classification
KW  - online learning experiments
KW  - Task analysis
KW  - Optimal control
KW  - Solids
KW  - Force
KW  - Robot sensing systems
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8793757
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Practical use of robots in diverse domains requires programming for, or adapting to, each domain and its unique characteristics. Failure to do so compromises the ability of the robot to achieve task-relevant objectives. Here we describe how the learned terrain reaction force profiles of a hopping robot serve the additional objectives of classifying terrain and quickly learning control strategies to accomplish a jumping task on novel terrain. We show that the reaction forces experienced during closed-loop jumping are sufficient to discriminate between three different terrain types (granular, trampoline, and rigid) when using the learned models as discriminators. Building on this, we show that applying the classification to unknown terrain types leads to faster task completion, where the task objective is to meet a specific jump height. The classification experiments, utilizing real-world jumping data, achieve 95% prediction accuracy. The online learning experiments leverage simulation as there is more control over the terrain properties. Terrain-informed learning achieves the target hop heights more than 2x faster than without terrain knowledge when the prediction is correct, and 1.5x faster when the prediction is incorrect. Thus, applying the closest approximately known terrain knowledge facilitates low shot learning when hopping on unknown terrain.
ER  - 

TY  - CONF
TI  - Semiparametrical Gaussian Processes Learning of Forward Dynamical Models for Navigating in a Circular Maze
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3195
EP  - 3202
AU  - D. Romeres
AU  - D. K. Jha
AU  - A. DallaLibera
AU  - B. Yerazunis
AU  - D. Nikovski
PY  - 2019
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - regression analysis
KW  - robot dynamics
KW  - trajectory control
KW  - Gaussian process regression
KW  - semiparametrical Gaussian processes learning
KW  - robot learning
KW  - ball trajectories
KW  - physics first principles
KW  - motion dynamics
KW  - dry friction
KW  - nonlinear effects
KW  - degrees of freedom
KW  - circular maze environment
KW  - forward dynamical models
KW  - Computational modeling
KW  - Heuristic algorithms
KW  - Servomotors
KW  - Navigation
KW  - Cameras
KW  - Gaussian processes
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794229
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a problem of model learning for the purpose of learning how to navigate a ball to a goal state in a circular maze environment with two degrees of freedom. The motion of the ball in the maze environment is influenced by several non-linear effects such as dry friction and contacts, which are difficult to model physically. We propose a semiparametric model to estimate the motion dynamics of the ball based on Gaussian Process Regression equipped with basis functions obtained from physics first principles. The accuracy of this semiparametric model is shown not only in estimation but also in prediction at n-steps ahead and its compared with standard algorithms for model learning. The learned model is then used in a trajectory optimization algorithm to compute ball trajectories. We propose the system presented in the paper as a benchmark problem for reinforcement and robot learning, for its interesting and challenging dynamics and its relative ease of reproducibility.
ER  - 

TY  - CONF
TI  - Semantic Predictive Control for Explainable and Efficient Policy Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3203
EP  - 3209
AU  - X. Pan
AU  - X. Chen
AU  - Q. Cai
AU  - J. Canny
AU  - F. Yu
PY  - 2019
KW  - image motion analysis
KW  - image representation
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - predictive control
KW  - visual explanation
KW  - policy decisions
KW  - SPC
KW  - future semantic segmentation
KW  - multiscale feature maps
KW  - guidance model
KW  - multiple simulation environments
KW  - model-based reinforcement
KW  - data efficiency
KW  - short time horizons
KW  - human-level performance
KW  - complex environments
KW  - driving policy learning framework
KW  - feature representations
KW  - sampling-based optimization
KW  - semantic predictive control framework
KW  - Semantics
KW  - Predictive models
KW  - Feature extraction
KW  - Visualization
KW  - Task analysis
KW  - Predictive control
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794437
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual anticipation of ego and object motion over a short time horizons is a key feature of human-level performance in complex environments. We propose a driving policy learning framework that predicts feature representations of future visual inputs; our predictive model infers not only future events but also semantics, which provide a visual explanation of policy decisions. Our Semantic Predictive Control (SPC) framework predicts future semantic segmentation and events by aggregating multi-scale feature maps. A guidance model assists action selection and enables efficient sampling-based optimization. Experiments on multiple simulation environments show that networks which implement SPC can outperform existing model-based reinforcement learning algorithms in terms of data efficiency and total rewards while providing clear explanations for the policy's behavior.
ER  - 

TY  - CONF
TI  - Adaptive Variance for Changing Sparse-Reward Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3210
EP  - 3216
AU  - X. Lin
AU  - P. Guo
AU  - C. Florensa
AU  - D. Held
PY  - 2019
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - robot programming
KW  - adaptive variance
KW  - sparse-reward environments
KW  - optimal exploration
KW  - Gaussian-parameterized policy
KW  - robots
KW  - Robots
KW  - Task analysis
KW  - Reinforcement learning
KW  - Training
KW  - Adaptation models
KW  - Friction
KW  - Navigation
DO  - 10.1109/ICRA.2019.8793650
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots that are trained to perform a task in a fixed environment often fail when facing unexpected changes to the environment due to a lack of exploration. We propose a principled way to adapt the policy for better exploration in changing sparse-reward environments. Unlike previous works which explicitly model environmental changes, we analyze the relationship between the value function and the optimal exploration for a Gaussian-parameterized policy and show that our theory leads to an effective strategy for adjusting the variance of the policy, enabling fast adapt to changes in a variety of sparse-reward environments.
ER  - 

TY  - CONF
TI  - Combining Physical Simulators and Object-Based Networks for Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3217
EP  - 3223
AU  - A. Ajay
AU  - M. Bauza
AU  - J. Wu
AU  - N. Fazeli
AU  - J. B. Tenenbaum
AU  - A. Rodriguez
AU  - L. P. Kaelbling
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object-based neural network
KW  - interacting objects
KW  - complex control tasks
KW  - object shapes
KW  - physical simulators
KW  - physics engine
KW  - robot planning
KW  - real-world control problems
KW  - complex contact dynamics
KW  - hybrid dynamics model
KW  - simulator-augmented interaction networks
KW  - Physics
KW  - Engines
KW  - Analytical models
KW  - Task analysis
KW  - Robots
KW  - Predictive models
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8794358
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Physics engines play an important role in robot planning and control; however, many real-world control problems involve complex contact dynamics that cannot be characterized analytically. Most physics engines therefore employ approximations that lead to a loss in precision. In this paper, we propose a hybrid dynamics model, simulator-augmented interaction networks (SAIN), combining a physics engine with an object-based neural network for dynamics modeling. Compared with existing models that are purely analytical or purely data-driven, our hybrid model captures the dynamics of interacting objects in a more accurate and data-efficient manner. Experiments both in simulation and on a real robot suggest that it also leads to better performance when used in complex control tasks. Finally, we show that our model generalizes to novel environments with varying object shapes and materials.
ER  - 

TY  - CONF
TI  - Using Data-Driven Domain Randomization to Transfer Robust Control Policies to Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3224
EP  - 3230
AU  - M. Sheckells
AU  - G. Garimella
AU  - S. Mishra
AU  - M. Kobilarov
PY  - 2019
KW  - automobiles
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - probability
KW  - robust control
KW  - stochastic processes
KW  - trajectory control
KW  - deep stochastic dynamics model
KW  - collision avoidance
KW  - 1/5 scale agile ground vehicle
KW  - robust control policies
KW  - vehicle data
KW  - collision probability
KW  - trajectory tracking accuracy
KW  - stochasticity
KW  - simple analytic car model
KW  - high quality stochastic dynamics model
KW  - robot motion trajectories
KW  - mobile robots
KW  - data-driven domain randomization
KW  - Stochastic processes
KW  - Data models
KW  - Vehicle dynamics
KW  - Optimization
KW  - Robots
KW  - Uncertainty
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794343
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work develops a technique for using robot motion trajectories to create a high quality stochastic dynamics model that is then leveraged in simulation to train control policies with associated performance guarantees. We demonstrate the idea by collecting dynamics data from a 1/5 scale agile ground vehicle, fitting a stochastic dynamics model, and training a policy in simulation to drive around an oval track at up to 6.5 m/s while avoiding obstacles. We show that the control policy can be transferred back to the real vehicle with little loss in predicted performance. We compare this to an approach that uses a simple analytic car model to train a policy in simulation and show that using a model with stochasticity learned from data leads to higher performance in terms of trajectory tracking accuracy and collision probability. Furthermore, we show empirically that simulation-derived performance guarantees transfer to the actual vehicle when executing a policy optimized using a deep stochastic dynamics model fit to vehicle data.
ER  - 

TY  - CONF
TI  - Coordinating multi-robot systems through environment partitioning for adaptive informative sampling
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3231
EP  - 3237
AU  - N. Fung
AU  - J. Rogers
AU  - C. Nieto
AU  - H. I. Christensen
AU  - S. Kemna
AU  - G. Sukhatme
PY  - 2019
KW  - image segmentation
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - sampling methods
KW  - coordinating multirobot systems
KW  - environment partitioning
KW  - adaptive informative sampling
KW  - robotic platforms
KW  - time sensitive applications
KW  - sensor measurements
KW  - highest expected information
KW  - multiple robots
KW  - system partitions
KW  - information rate adaptive sampling approach
KW  - simulation environment
KW  - region segmentation approach
KW  - adaptive information gain rate tasking
KW  - naïve closest point approach
KW  - region segmentation technique
KW  - real world robots
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Adaptation models
KW  - Entropy
KW  - Task analysis
KW  - Data models
DO  - 10.1109/ICRA.2019.8794103
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - As robotic platforms have become more capable and autonomous, they have increasingly been utilized in time sensitive applications such as search and rescue. To that end, we have developed a system for teams of robots to efficiently explore an environment while taking sensor measurements. The system utilizes an information seeking algorithm that generates high priority points of interest based on the highest expected information gained per distance travelled. In order to coordinate multiple robots, the system partitions the area into different regions according to the effort needed to explore each region. Robots are assigned different regions to measure in order to minimize repetition of work and reduce interference between each robot.We present an information rate adaptive sampling approach for tasking robots within an environment to gather sensor measurements. We evaluated our approach within a simulation environment with one to four robots. Multiple robots are coordinated through our region segmentation approach. The data shows efficiency gains through the use of adaptive information gain rate tasking above a naïve closest point approach. We also see positive results from using the region segmentation technique. We further the experimentation by testing the algorithm on real world robots and verify the results in real world experimentation.
ER  - 

TY  - CONF
TI  - A Fleet of Miniature Cars for Experiments in Cooperative Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3238
EP  - 3244
AU  - N. Hyldmar
AU  - Y. He
AU  - A. Prorok
PY  - 2019
KW  - automobiles
KW  - human factors
KW  - mobile robots
KW  - motion control
KW  - steering systems
KW  - trajectory control
KW  - vehicle dynamics
KW  - unique experimental testbed
KW  - trajectory planning
KW  - miniature robotic car
KW  - Cambridge Minicar
KW  - autonomous control strategies
KW  - physical multilane setup
KW  - miniature highway
KW  - large-fleet experimental research
KW  - driver models
KW  - multilane road topographies
KW  - miniature Ackermann-steering vehicles
KW  - Automobiles
KW  - Trajectory
KW  - Traffic control
KW  - DC motors
KW  - Servomotors
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8794445
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We introduce a unique experimental testbed that consists of a fleet of 16 miniature Ackermann-steering vehicles. We are motivated by a lack of available low-cost platforms to support research and education in multi-car navigation and trajectory planning. This article elaborates the design of our miniature robotic car, the Cambridge Minicar, as well as the fleet's control architecture. Our experimental testbed allows us to implement state-of-the-art driver models as well as autonomous control strategies, and test their validity in a real, physical multi-lane setup. Through experiments on our miniature highway, we are able to tangibly demonstrate the benefits of cooperative driving on multi-lane road topographies. Our setup paves the way for indoor large-fleet experimental research.
ER  - 

TY  - CONF
TI  - Multi-robot Informative Path Planning with Continuous Connectivity Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3245
EP  - 3251
AU  - A. Dutta
AU  - A. Ghosh
AU  - O. P. Kreidl
PY  - 2019
KW  - graph theory
KW  - integer programming
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - collision-free informative locations
KW  - informative paths
KW  - base station performs
KW  - multirobot system
KW  - information collection
KW  - continuous connectivity constraints
KW  - multirobot informative path planning
KW  - time 0.75 s
KW  - Robot sensing systems
KW  - Base stations
KW  - Path planning
KW  - Collision avoidance
KW  - Entropy
KW  - Bipartite graph
DO  - 10.1109/ICRA.2019.8794090
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of information collection from a polygonal environment using a multi-robot system, subject to continuous connectivity constraints. In particular, the robots, having a common radius of communication range, must remain connected throughout the exploration maximizing the information collection. The information gained through the exploration of the terrain is wirelessly transmitted to a base station. The base station performs the centralized planning of informative paths for the robots based on the information collected by them and thereafter, the robots follow these paths. This paper formulates the problem of multi-robot informative path planning under continuous connectivity constraints as an integer program leveraging the ideas of bipartite graph matching and minimal node separators. Theoretical analysis of the proposed solution proves that the informative paths will be collision-free and will be free of both livelock and deadlock. Experimental results demonstrate the low computational requirements of our algorithm for planning the informative paths, taking only about 0.75 sec. for planning a joint set of collision-free informative locations for 10 robots.
ER  - 

TY  - CONF
TI  - Sensor Coverage Control Using Robots Constrained to a Curve
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3252
EP  - 3258
AU  - G. Notomista
AU  - M. Santos
AU  - S. Hutchinson
AU  - M. Egerstedt
PY  - 2019
KW  - approximation theory
KW  - convex programming
KW  - gradient methods
KW  - mobile robots
KW  - sensors
KW  - mobile robots
KW  - two-dimensional domain
KW  - unconstrained coverage problem
KW  - gradient descent
KW  - direct projection
KW  - unconstrained problem
KW  - sensor coverage control
KW  - robots constrained
KW  - constrained coverage control problem
KW  - locational cost minimization
KW  - spatial allocation
KW  - convex approximation
KW  - Robot sensing systems
KW  - Optimization
KW  - Density functional theory
KW  - Wires
KW  - Environmental monitoring
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794261
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we consider a constrained coverage control problem for a team of mobile robots. The robots are asked to provide sensor coverage over a two-dimensional domain, while being constrained to only move on a curve. The unconstrained coverage problem can be effectively solved by defining a locational cost to be minimized by the robots, in a decentralized fashion, using gradient descent. However, a direct projection of the solution to the unconstrained problem onto the curve may result in a very poor spatial allocation of the team within the two-dimensional domain. Therefore, we propose a modification to the locational cost, which incorporates the constraints, and a convex relaxation that allows us to efficiently minimize a convex approximation of the cost using a decentralized strategy. The resulting algorithm is implemented on a team of mobile robots.
ER  - 

TY  - CONF
TI  - Coverage of an Environment Using Energy-Constrained Unmanned Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3259
EP  - 3265
AU  - K. Yu
AU  - J. M. O’Kane
AU  - P. Tokekar
PY  - 2019
KW  - approximation theory
KW  - autonomous aerial vehicles
KW  - computational complexity
KW  - mobile robots
KW  - path planning
KW  - travelling salesman problems
KW  - UGV
KW  - area coverage problem
KW  - energy-constrained unmanned aerial vehicle
KW  - unmanned ground vehicle
KW  - symbiotic UAV
KW  - NP-hard problem
KW  - generalized traveling salesperson problem
KW  - boustrophedon cells
KW  - limited battery capacity
KW  - Batteries
KW  - Unmanned aerial vehicles
KW  - Agriculture
KW  - Robot sensing systems
KW  - Strips
KW  - Routing
DO  - 10.1109/ICRA.2019.8794150
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We study the problem of covering an environment using an Unmanned Aerial Vehicle (UAV) with limited battery capacity. We consider a scenario where the UAV can land on an Unmanned Ground Vehicle (UGV) and recharge the onboard battery. The UGV can also recharge the UAV while transporting the UAV to the next take-off site. We present an algorithm to solve a new variant of the area coverage problem that takes into account this symbiotic UAV and UGV system. The input consists of a set of boustrophedon cells - rectangular strips whose width is equal to the field-of-view of the sensor on the UAV. The goal is to find a tour for the UAV that visits and covers all cells in minimum time. This includes flight time for visiting and covering all cells, recharging time, as well as the take-off and landing times. We show how to reduce this problem to a known NP-hard problem, Generalized Traveling Salesperson Problem (GTSP). Given an optimal GTSP solver, our approach finds the optimal coverage paths for the UAV and UGV. We evaluate our algorithm through simulations and proof-of-concept experiments.
ER  - 

TY  - CONF
TI  - Point Cloud Compression for 3D LiDAR Sensor using Recurrent Neural Network with Residual Blocks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3274
EP  - 3280
AU  - C. Tu
AU  - E. Takeuchi
AU  - A. Carballo
AU  - K. Takeda
PY  - 2019
KW  - computational geometry
KW  - data compression
KW  - image coding
KW  - iterative methods
KW  - mobile robots
KW  - octrees
KW  - optical radar
KW  - recurrent neural nets
KW  - SLAM (robots)
KW  - recurrent neural network
KW  - residual blocks
KW  - generic octree point cloud compression method
KW  - potential application scenarios
KW  - decompressed point cloud data
KW  - 3D LiDAR sensor
KW  - autonomous driving systems
KW  - 3D LiDAR data
KW  - raw D formatted LiDAR data
KW  - 2D formatted LiDAR data
KW  - Three-dimensional displays
KW  - Image coding
KW  - Laser radar
KW  - Two dimensional displays
KW  - Robot sensing systems
KW  - Decoding
KW  - Recurrent neural networks
DO  - 10.1109/ICRA.2019.8794264
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The use of 3D LiDAR, which has proven its capabilities in autonomous driving systems, is now expanding into many other fields. The sharing and transmission of point cloud data from 3D LiDAR sensors has broad application prospects in robotics. However, due to the sparseness and disorderly nature of this data, it is difficult to compress it directly into a very low volume. A potential solution is utilizing raw LiDAR data. We can rearrange the raw data from each frame losslessly in a 2D matrix, making the data compact and orderly. Due to the special structure of 3D LiDAR data, the texture of the 2D matrix is irregular, in contrast to 2D matrices of camera images. In order to compress this raw, 2D formatted LiDAR data efficiently, in this paper we propose a method which uses a recurrent neural network and residual blocks to progressively compress one frame's information from 3D LiDAR. Compared to our previous image compression based method and generic octree point cloud compression method, the proposed approach needs much less volume while giving the same decompression accuracy. Potential application scenarios for point cloud compression are also considered in this paper. We describe how decompressed point cloud data can be used with SLAM (simultaneous localization and mapping) as well as for localization using a given map, illustrating potential uses of the proposed method in real robotics applications.
ER  - 

TY  - CONF
TI  - Depth Completion with Deep Geometry and Context Guidance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3281
EP  - 3287
AU  - B. Lee
AU  - H. Jeon
AU  - S. Im
AU  - I. S. Kweon
PY  - 2019
KW  - computer vision
KW  - convolutional neural nets
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - object detection
KW  - bilateral weight
KW  - deep geometry
KW  - context guidance
KW  - geometry network
KW  - context network
KW  - single encoder-decoder network
KW  - initial propagated depth map
KW  - slanted surfaces
KW  - convolutional neural network
KW  - CNN-based depth completions
KW  - local feature extraction
KW  - global feature extraction
KW  - Three-dimensional displays
KW  - Geometry
KW  - Feature extraction
KW  - Image edge detection
KW  - Reliability
KW  - Laser radar
KW  - Convolution
DO  - 10.1109/ICRA.2019.8794161
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present an end-to-end convolutional neural network (CNN) for depth completion. Our network consists of a geometry network and a context network. The geometry network, a single encoder-decoder network, learns to optimize a multi-task loss to generate an initial propagated depth map and a surface normal. The complementary outputs allow it to correctly propagate initial sparse depth points in slanted surfaces. The context network extracts a local and a global feature of an image to compute a bilateral weight, which enables it to preserve edges and fine details in the depth maps. At the end, a final output is produced by multiplying the initially propagated depth map with the bilateral weight. In order to validate the effectiveness and the robustness of our network, we performed extensive ablation studies and compared the results against state-of-the-art CNN-based depth completions, where we showed promising results on various scenes.
ER  - 

TY  - CONF
TI  - Self-Supervised Sparse-to-Dense: Self-Supervised Depth Completion from LiDAR and Monocular Camera
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3288
EP  - 3295
AU  - F. Ma
AU  - G. V. Cavalheiro
AU  - S. Karaman
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image fusion
KW  - image sequences
KW  - optical radar
KW  - regression analysis
KW  - robot vision
KW  - semidense annotations
KW  - KITTI depth completion benchmark
KW  - self-supervised sparse-to-dense
KW  - self-supervised depth completion
KW  - dense depth image
KW  - sparse depth measurements
KW  - irregularly spaced pattern
KW  - multiple sensor modalities
KW  - dense level ground truth depth
KW  - pixel-level ground truth depth
KW  - self-supervised training framework
KW  - sparse depth images
KW  - color images
KW  - Laser radar
KW  - Training
KW  - Color
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Convolution
KW  - Extraterrestrial measurements
DO  - 10.1109/ICRA.2019.8793637
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Depth completion, the technique of estimating a dense depth image from sparse depth measurements, has a variety of applications in robotics and autonomous driving. However, depth completion faces 3 main challenges: the irregularly spaced pattern in the sparse depth input, the difficulty in handling multiple sensor modalities (when color images are available), as well as the lack of dense, pixel-level ground truth depth labels for training. In this work, we address all these challenges. Specifically, we develop a deep regression model to learn a direct mapping from sparse depth (and color images) input to dense depth prediction. We also propose a self-supervised training framework that requires only sequences of color and sparse depth images, without the need for dense depth labels. Our experiments demonstrate that the self-supervised framework outperforms a number of existing solutions trained with semi-dense annotations. Furthermore, when trained with semi-dense annotations, our network attains state-of-the-art accuracy and is the winning approach on the KITTI depth completion benchmark at the time of submission.
ER  - 

TY  - CONF
TI  - In-hand Object Scanning via RGB-D Video Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3296
EP  - 3302
AU  - F. Wang
AU  - K. Hauser
PY  - 2019
KW  - image colour analysis
KW  - image reconstruction
KW  - image segmentation
KW  - object detection
KW  - object tracking
KW  - video signal processing
KW  - video-segmentation-based object tracking algorithm
KW  - hand object scanning
KW  - RGB-D video segmentation
KW  - in-hand manipulation
KW  - video camera
KW  - multiple grasps
KW  - household objects
KW  - in-hand object tracking
KW  - video tracking algorithms
KW  - RGB-D in-hand object manipulation dataset
KW  - 3D object scanning
KW  - Three-dimensional displays
KW  - Pipelines
KW  - Image color analysis
KW  - Cameras
KW  - Solid modeling
KW  - Image segmentation
KW  - Proposals
DO  - 10.1109/ICRA.2019.8794467
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a technique for 3D object scanning via in-hand manipulation, in which an object reoriented in front of a video camera with multiple grasps and regrasps. In-hand object tracking is a significant challenge under fast movement, rapid appearance changes, and occlusions. This paper proposes a novel video-segmentation-based object tracking algorithm that tracks arbitrary in-hand objects more effectively than existing techniques. It also describes a novel RGB-D in-hand object manipulation dataset consisting of several common household objects. Experiments show that the new method achieves 6% increase in accuracy compared to top performing video tracking algorithms and results in noticeably higher quality reconstructed models. Moreover, testing with a novice user on a set of 200 objects demonstrates relatively rapid construction of complete 3D object models.
ER  - 

TY  - CONF
TI  - Multi-Modal Generative Models for Learning Epistemic Active Sensing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3319
EP  - 3325
AU  - T. Korthals
AU  - D. Rudolph
AU  - J. Leitner
AU  - M. Hesse
AU  - U. Rückert
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-agent systems
KW  - neural nets
KW  - statistical analysis
KW  - multimodal deep generative models
KW  - coordinated heterogeneous multiagent active sensing
KW  - joint latent representation
KW  - epistemic active sensing behavior
KW  - multimodal variational auto encoder
KW  - sensor modalities
KW  - multiagent deep reinforcement learning setup
KW  - direct reward signal
KW  - evidence lower bound
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Training
KW  - Feature extraction
KW  - Reinforcement learning
DO  - 10.1109/ICRA.2019.8794458
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel approach of multi-modal deep generative models and apply this to coordinated heterogeneous multi-agent active sensing. A major approach to achieve this objective is to train a multi-modal variational Auto Encoder (M2VAE) that integrates the information of different sensor modalities into a joint latent representation. Furthermore, we derive an objective from the M2VAE that enables the maximization of the evidence lower bound via selection of sensor modalities. Using this approach as a direct reward signal to a multi-modal and multi-agent deep reinforcement learning setup leads intuitively to an epistemic active sensing behavior that coordinately resolves the ambiguity of observations.
ER  - 

TY  - CONF
TI  - Decentralized Formation Coordination of Multiple Quadcopters under Communication Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3326
EP  - 3332
AU  - P. Abichandani
AU  - K. Levin
AU  - D. Bucci
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - decentralised control
KW  - helicopters
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - multi-robot systems
KW  - nonlinear programming
KW  - robot dynamics
KW  - robot kinematics
KW  - RSSI
KW  - tree searching
KW  - outdoor formation coordination
KW  - multiple quadcopters
KW  - time-optimal speed profile
KW  - minimum snap spline path
KW  - quadcopter kinematics
KW  - wireless communication connectivity
KW  - geometric formations
KW  - maximum separation distance
KW  - minimum viable received signal strength
KW  - path loss attenuation
KW  - outdoor flight test
KW  - formation type
KW  - robin communication scheduling scheme
KW  - decentralized formation coordination
KW  - communication constraints
KW  - RH-MINLP
KW  - quadcopter dynamics
KW  - collision avoidance
KW  - outer-approximation branch and bound solver
KW  - warm-starting scheme
KW  - hardware-in-the-loop
KW  - HITL
KW  - average radio packet loss statistics
KW  - round robin communication scheduling scheme
KW  - receding horizon mixed-integer nonlinear program
KW  - Splines (mathematics)
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Planning
KW  - Optimization
KW  - Mobile ad hoc networks
DO  - 10.1109/ICRA.2019.8794246
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of decentralized, outdoor formation coordination with multiple quadcopters. The problem is formulated as a receding horizon, mixed-integer non-linear program (RH-MINLP). Each quadcopter solves this RH-MINLP to generate its time-optimal speed profile along a minimum snap spline path while coordinating its position in a desired formation with other quadcopters. Constraints on quadcopter kinematics, dynamics, collision avoidance, wireless communication connectivity, and geometric formations are modeled. Communication connectivity is modeled as a constraint on maximum separation distance based on a minimum viable received signal strength in the presence of path loss attenuation. The resulting RH-MINLP is non-convex, and is solved using an outer-approximation branch and bound solver with a warm-starting scheme. The framework is validated via Hardware-in-the-Loop (HITL) and outdoor flight test with up to 6 quadcopters. Results demonstrate the effect of number of quadcopters and formation type on total transit time. Average radio packet loss statistics during transit indicate robust network performance for a round robin communication scheduling scheme.
ER  - 

TY  - CONF
TI  - Online Plan Repair in Multi-robot Coordination with Disturbances
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3333
EP  - 3339
AU  - A. Coskun
AU  - J. M. O’Kane
PY  - 2019
KW  - collision avoidance
KW  - Gaussian processes
KW  - multi-robot systems
KW  - path planning
KW  - RMTRACK control law
KW  - Gaussian process
KW  - coordination space obstacle
KW  - disturbance probabilities
KW  - multirobot coordination
KW  - online plan repair
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Trajectory
KW  - Maintenance engineering
KW  - System recovery
KW  - Delays
DO  - 10.1109/ICRA.2019.8793522
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of multi-robot coordination in scenarios where the robots may experience unexpected delays in their movements. Prior work by Čáp, Gregoire, and Frazzołi introduced a control law, called RMTRACK, which enables robots in such scenarios to execute preplanned paths in spite of disturbances in the execution speed of each robot, while guaranteeing that each robot can reach its goal without collisions and without deadlocks. We extend that approach to handle scenarios in which the disturbance probabilities are unknown at the start and non-uniform across the environment. The key idea is to `repair' a plan on-the-fly, by swapping the order in which a pair of robots passes through a mutual collision region (i.e. a coordination space obstacle), when making such a change can be estimated to improve the overall performance of the system. We introduce a technique based on Gaussian Processes to estimate future disturbances, and propose two algorithms for testing, at appropriate times, whether a swap of a given obstacle would be beneficial. Tests in simulation demonstrate that our algorithm achieves significantly smaller average travel time than RMTRACK at only a modest computational expense.
ER  - 

TY  - CONF
TI  - Integrated Mapping and Path Planning for Very Large-Scale Robotic (VLSR) Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3356
EP  - 3362
AU  - J. Morelli
AU  - P. Zhu
AU  - B. Doerr
AU  - R. Linares
AU  - S. Ferrari
PY  - 2019
KW  - collision avoidance
KW  - control engineering computing
KW  - mobile robots
KW  - multi-robot systems
KW  - regression analysis
KW  - sensor fusion
KW  - decentralized approach
KW  - obstacle mapping
KW  - continuous probabilistic representation
KW  - mapping problem
KW  - binary classification task
KW  - kernel logistic regression
KW  - discriminative classifier online
KW  - individual robot maps
KW  - path planning algorithm
KW  - maximum information value
KW  - obstacle avoidance
KW  - VLSR system
KW  - prior obstacle information
KW  - robot paths
KW  - Hilbert map fusion method
KW  - large-scale robotic systems
KW  - onboard range sensors
KW  - Robot sensing systems
KW  - Entropy
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Path planning
DO  - 10.1109/ICRA.2019.8793795
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper develops a decentralized approach for mapping and information-driven path planning for Very Large Scale Robotic (VLSR) systems. In this approach, obstacle mapping is performed using a continuous probabilistic representation known as a Hilbert map, which formulates the mapping problem as a binary classification task and uses kernel logistic regression to train a discriminative classifier online. A novel Hilbert map fusion method is presented that quickly and efficiently combines the information from individual robot maps. An integrated mapping and path planning algorithm is presented to determine paths of maximum information value, while simultaneously performing obstacle avoidance. Furthermore, the effect of how percentage communication failure effects the overall performance of the system is investigated. The approach is demonstrated on a VLSR system with hundreds of robots that must map obstacles collaboratively over a large region of interest using onboard range sensors and no prior obstacle information. The results show that, through fusion and decentralized processing, the entropy of the map decreases over time and robot paths remain collision-free.
ER  - 

TY  - CONF
TI  - Methodology of Designing Multi-agent Robot Control Systems Utilising Hierarchical Petri Nets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3363
EP  - 3369
AU  - M. Figat
AU  - C. Zieliński
PY  - 2019
KW  - finite state machines
KW  - multi-agent systems
KW  - multi-robot systems
KW  - Petri nets
KW  - multiagent robot system layer
KW  - agent layer
KW  - subsystem layer
KW  - communication layer
KW  - robotic system
KW  - robot controller code
KW  - multiagent robot control systems
KW  - embodied agent
KW  - cooperating subsystems
KW  - hierarchical finite state machines
KW  - hierarchical Petri nets
KW  - Petri nets
KW  - Tools
KW  - Data models
KW  - Systematics
KW  - Automation
KW  - Robot control
DO  - 10.1109/ICRA.2019.8794201
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A robot system is designed as a set of embodied agents. An embodied agent is decomposed into cooperating subsystems. In our previous work activities of subsystems were defined by hierarchical finite state machines. With their states activities were associated. In that approach communication between subsystems was treated as an implementation issue. This paper represents activities of a robot system using hierarchical Petri nets with conditions. Such net is created by specifying consecutive layers: multi-agent robot system layer, agent layer, subsystem layer, behaviour layer and communication layer. This decomposition not only organizes in a systematic manner the development of a robot system, but also introduces a comprehensive description of concurrently acting subsystems. Based on those theoretical considerations, a tool was created for producing hierarchical Petri nets defining the model of a robotic system and enabling automatic generation of the robot controller code, resulting in a significant acceleration of the implementation phase. The capabilities of the tool are presented by the development of a robot controller performing a rudimentary task.
ER  - 

TY  - CONF
TI  - Interaction-Aware Multi-Agent Reinforcement Learning for Mobile Agents with Individual Goals
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3370
EP  - 3376
AU  - A. Mohseni-Kabir
AU  - D. Isele
AU  - K. Fujimura
PY  - 2019
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - robot programming
KW  - interaction-aware multiagent reinforcement learning
KW  - mobile agents
KW  - individual goals
KW  - optimal policy
KW  - decentralized learning
KW  - mobile robot navigation
KW  - policy gradient algorithms
KW  - nonstationary policies
KW  - curriculum-based strategy
KW  - interactive policy learning
KW  - Training
KW  - Robots
KW  - Games
KW  - Markov processes
KW  - Reinforcement learning
KW  - Navigation
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2019.8793721
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In a multi-agent setting, the optimal policy of a single agent is largely dependent on the behavior of other agents. We investigate the problem of multi-agent reinforcement learning, focusing on decentralized learning in non-stationary domains for mobile robot navigation. We identify a cause for the difficulty in training non-stationary policies: mutual adaptation to sub-optimal behaviors, and we use this to motivate a curriculum-based strategy for learning interactive policies. The curriculum has two stages. First, the agent leverages policy gradient algorithms to learn a policy that is capable of achieving multiple goals. Second, the agent learns a modifier policy to learn how to interact with other agents in a multi-agent setting. We evaluated our approach on both an autonomous driving lane-change domain and a robot navigation domain.
ER  - 

TY  - CONF
TI  - Coverage Control for Multiple Event Types with Heterogeneous Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3377
EP  - 3383
AU  - A. Sadeghi
AU  - S. L. Smith
PY  - 2019
KW  - distributed algorithms
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - continuous environments
KW  - discrete environments
KW  - locally optimal positions
KW  - density function
KW  - coverage control
KW  - multiple event types
KW  - heterogeneous robots
KW  - autonomous robots
KW  - total sensing quality
KW  - homogeneous problem
KW  - Robot sensing systems
KW  - Density functional theory
KW  - Distributed algorithms
KW  - Linear programming
KW  - Silicon
DO  - 10.1109/ICRA.2019.8793639
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper focuses on the problem of deploying a set of autonomous robots to efficiently monitor multiple types of events in an environment. There is a density function over the environment for each event type representing the weighted likelihood of the event at each location. The robots are heterogeneous in that each robot is equipped with a set of sensors and it is capable of sensing a subset of event types. The objective is to deploy the robots in the environment to minimize a linear combination of the total sensing quality of the events. We propose a new formulation for the problem which is a natural extension of the homogeneous problem. We propose distributed algorithms that drive the robots to locally optimal positions in both continuous environments that are obstacle-free, and in discrete environments that may contain obstacles. In both cases we prove convergence to locally optimal positions. We provide extension to the case where the density functions are unknown prior to the deployment in continuous environments. Finally, we present benchmarking results and physical experiments to characterize the solution quality.
ER  - 

TY  - CONF
TI  - Active Perception in Adversarial Scenarios using Maximum Entropy Deep Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3384
EP  - 3390
AU  - M. Shen
AU  - J. P. How
PY  - 2019
KW  - belief networks
KW  - entropy
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - neural nets
KW  - planning (artificial intelligence)
KW  - stochastic processes
KW  - partial observability
KW  - adversary agent
KW  - autonomous agent
KW  - belief space planning
KW  - generative adversary modeling
KW  - maximum entropy reinforcement learning
KW  - stochastic belief space policy
KW  - unmodeled adversarial strategies
KW  - maximum entropy deep reinforcement learning
KW  - active perception problem
KW  - potentially adversarial behaviors
KW  - uncertainty modeling
KW  - standard chance-constraint partially observable Markov decision
KW  - Uncertainty
KW  - Games
KW  - Autonomous agents
KW  - Reinforcement learning
KW  - Nash equilibrium
KW  - Planning
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8794389
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We pose an active perception problem where an autonomous agent actively interacts with a second agent with potentially adversarial behaviors. Given the uncertainty in the intent of the other agent, the objective is to collect further evidence to help discriminate potential threats. The main technical challenges are the partial observability of the agent intent, the adversary modeling, and the corresponding uncertainty modeling. Note that an adversary agent may act to mislead the autonomous agent by using a deceptive strategy that is learned from past experiences. We propose an approach that combines belief space planning, generative adversary modeling, and maximum entropy reinforcement learning to obtain a stochastic belief space policy. By accounting for various adversarial behaviors in the simulation framework and minimizing the predictability of the autonomous agent's action, the resulting policy is more robust to unmodeled adversarial strategies. This improved robustness is empirically shown against an adversary that adapts to and exploits the autonomous agent's policy when compared with a standard Chance-Constraint Partially Observable Markov Decision Process robust approach.
ER  - 

TY  - CONF
TI  - A Competitive Algorithm for Online Multi-Robot Exploration of a Translating Plume
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3391
EP  - 3397
AU  - Y. Sung
AU  - P. Tokekar
PY  - 2019
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multi-robot systems
KW  - velocity control
KW  - arbitrary shape
KW  - plume shape
KW  - plume speed
KW  - robot speed
KW  - tour
KW  - aerial robots
KW  - translating plume
KW  - online multirobot exploration
KW  - competitive algorithm
KW  - Robot kinematics
KW  - Two dimensional displays
KW  - Approximation algorithms
KW  - Shape
KW  - Unmanned aerial vehicles
KW  - Binary trees
DO  - 10.1109/ICRA.2019.8793850
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we study the problem of exploring a translating plume with a team of aerial robots. The shape and the size of the plume are unknown to the robots. The objective is to find a tour for each robot such that they collectively explore the plume. Specifically, the tours must be such that each point in the plume must be visible from the field-of-view of some robot along its tour. We propose a recursive Depth-First Search (DFS)-based algorithm that yields a constant competitive ratio for the exploration problem. The competitive ratio is 2(Sr + Sp)(R+⌊log R⌋)/(Sr + Sp)(R+⌊log R⌋) where R is the number of robots, and Sr and Sp are the robot speed and the plume speed, respectively. We also consider a more realistic scenario where the plume shape is not restricted to grid cells but an arbitrary shape. We show our algorithm has 2(Sr + Sp)(18 R+⌊log R⌋)/(Sr + Sp)(1+⌊log R⌋) competitive ratio under the fat condition. We empirically verify our algorithm using simulations.
ER  - 

TY  - CONF
TI  - Online Estimation of Ocean Current from Sparse GPS Data for Underwater Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3443
EP  - 3449
AU  - K. M. B. Lee
AU  - C. Yoo
AU  - B. Hollings
AU  - S. Anstee
AU  - S. Huang
AU  - R. Fitch
PY  - 2019
KW  - expectation-maximisation algorithm
KW  - Gaussian processes
KW  - Global Positioning System
KW  - mobile robots
KW  - position control
KW  - regression analysis
KW  - underwater vehicles
KW  - online estimation
KW  - Gaussian process-based expectation-maximisation algorithm
KW  - dead-reckoned position estimates
KW  - specialised GP regression scheme
KW  - best-fitting ocean
KW  - ocean current field
KW  - underwater vehicles
KW  - underwater robots
KW  - Oceans
KW  - Sea measurements
KW  - Current measurement
KW  - Global Positioning System
KW  - Trajectory
KW  - Estimation
DO  - 10.1109/ICRA.2019.8794308
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Underwater robots are subject to position drift due to the effect of ocean currents and the lack of accurate localisation while submerged. We are interested in exploiting such position drift to estimate the ocean current in the surrounding area, thereby assisting navigation and planning. We present a Gaussian process (GP)-based expectation-maximisation (EM) algorithm that estimates the underlying ocean current using sparse GPS data obtained on the surface and dead-reckoned position estimates. We first develop a specialised GP regression scheme that exploits the incompressibility of ocean currents to counteract the underdetermined nature of the problem. We then use the proposed regression scheme in an EM algorithm that estimates the best-fitting ocean current in between each GPS fix. The proposed algorithm is validated in simulation and on a real dataset, and is shown to be capable of reconstructing the underlying ocean current field. We expect to use this algorithm to close the loop between planning and estimation for underwater navigation in unknown ocean currents.
ER  - 

TY  - CONF
TI  - Working towards Adaptive Sensing for Terrain-aided Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3450
EP  - 3456
AU  - M. Zhou
AU  - R. Bachmayer
AU  - B. de Young
PY  - 2019
KW  - adaptive signal processing
KW  - altimeters
KW  - autonomous underwater vehicles
KW  - Kalman filters
KW  - marine navigation
KW  - particle filtering (numerical methods)
KW  - sonar
KW  - underwater vehicles
KW  - velocity measurement
KW  - terrain-aided navigation
KW  - adaptive sensing method
KW  - pinging rate
KW  - localization accuracy
KW  - TAN
KW  - sonar pinging interval
KW  - local seafloor topography
KW  - modified Teager Kaiser energy operator
KW  - pinging interval
KW  - downward-looking sonar
KW  - autonomous underwater vehicle
KW  - particle filter
KW  - bias velocity estimator
KW  - Kalman filter
KW  - depth variation
KW  - Atmospheric measurements
KW  - Sea measurements
KW  - Particle measurements
KW  - Sonar navigation
KW  - Sensors
KW  - Sonar
DO  - 10.1109/ICRA.2019.8794149
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - An adaptive sensing method is presented to control the pinging interval of a downward-looking sonar on an Autonomous Underwater Vehicle. The goal is to conserve energy via adjusting the pinging rate automatically without reducing the localization accuracy when using terrain-aided navigation (TAN). In this paper, the TAN is implemented using a particle filter and a bias velocity estimator developed based on a Kalman filter. The adaptation on the sonar pinging interval is determined based on the depth variation of local seafloor topography which is quantified using a modified Teager Kaiser energy operator. As a result, more measurements are collected on high relief regions, and less measurements are obtained on relatively flat and smooth regions. We evaluated the adaptive sensing method in a simulated environment and applied it to a field data set. The results show that the adaptive sensing method produces an improved navigational accuracy compared to the missions with fixed sonar pinging rates. In the offline field missions, the energy consumed by the altimeter is reduced to about 30% in the adaptive sensing missions compared to continuously sensing missions where the altimeter is pinging consistently without switching off.
ER  - 

TY  - CONF
TI  - Non-Gaussian SLAM utilizing Synthetic Aperture Sonar
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3457
EP  - 3463
AU  - M. Y. Cheung
AU  - D. Fourie
AU  - N. R. Rypkema
AU  - P. V. Teixeira
AU  - H. Schmidt
AU  - J. Leonard
PY  - 2019
KW  - acoustic signal processing
KW  - array signal processing
KW  - graph theory
KW  - marine navigation
KW  - pose estimation
KW  - probability
KW  - sensor fusion
KW  - SLAM (robots)
KW  - synthetic aperture sonar
KW  - SLAM framework
KW  - beacon position
KW  - acoustic measurements
KW  - factor graph formulation
KW  - nonGaussian SLAM
KW  - spatial resolution
KW  - navigational measurements
KW  - underwater missions
KW  - synthetic aperture sonar
KW  - SAS
KW  - simultaneous localization and mapping
KW  - accurate pose estimation
KW  - hydrophones acoustic data
KW  - empirical probability distribution
KW  - conventional beamformer
KW  - autonomous surface vehicle
KW  - Acoustics
KW  - Synthetic aperture sonar
KW  - Array signal processing
KW  - Simultaneous localization and mapping
KW  - Apertures
KW  - Receivers
KW  - Sonar navigation
DO  - 10.1109/ICRA.2019.8793536
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Synthetic Aperture Sonar (SAS) is a technique to improve the spatial resolution from a moving set of receivers by extending the array in time, increasing the effective array length and aperture. This technique is limited by the accuracy of the receiver position estimates, necessitating highly accurate, typically expensive aided-inertial navigation systems for submerged platforms. We leverage simultaneous localization and mapping to fuse acoustic and navigational measurements and obtain accurate pose estimates even without the benefit of absolute positioning for lengthy underwater missions. We demonstrate a method of formulating the well-known SAS problem in a SLAM framework, using acoustic data from hydrophones to simultaneously estimate platform and beacon position. An empirical probability distribution is computed from a conventional beamformer to correctly account for uncertainty in the acoustic measurements. The non-parametric method relieves the familiar Gaussian-only assumption currently used in the localization and mapping discipline and fits effectively into a factor graph formulation with conventional factors such as ground-truth priors and odometry. We present results from field experiments performed on the Charles River with an autonomous surface vehicle which demonstrate simultaneous localization of an unknown acoustic beacon and vehicle positioning, and provide comparison to GPS ground truths.
ER  - 

TY  - CONF
TI  - Easily Deployable Underwater Acoustic Navigation System for Multi-Vehicle Environmental Sampling Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3464
EP  - 3470
AU  - A. Quraishi
AU  - A. Bahr
AU  - F. Schill
AU  - A. Martinoli
PY  - 2019
KW  - autonomous underwater vehicles
KW  - inertial navigation
KW  - lakes
KW  - mobile robots
KW  - path planning
KW  - underwater acoustic communication
KW  - clock synchronization
KW  - underwater robotics
KW  - autonomous underwater vehicles
KW  - GNSS
KW  - Lake Geneva
KW  - feature tracking
KW  - adaptive sampling
KW  - underwater environmental sensing
KW  - electromagnetic waves
KW  - radio communication
KW  - satellite based positioning
KW  - aerial robotics
KW  - multivehicle environmental sampling applications
KW  - acoustic navigation system
KW  - absolute time information
KW  - AUV position
KW  - underwater acoustic positioning system
KW  - inertial navigation
KW  - Acoustics
KW  - Global navigation satellite system
KW  - Acoustic measurements
KW  - Receivers
KW  - Clocks
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793699
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Water as a medium poses a number of challenges for robots, limiting the progress of research in underwater robotics vis-á-vis ground or aerial robotics. The primary challenges are satellite based positioning and radio communication being unusable due to high attenuation of electromagnetic waves in water. We have developed miniature, agile, easy to carry and deploy Autonomous Underwater Vehicles (AUVs) equipped with a suite of sensors for underwater environmental sensing. We previously demonstrated adaptive sampling and feature tracking, and gathered data from a lake for limnological research, with the AUV performing inertial navigation. In this paper, we demonstrate a new underwater acoustic positioning system, which allows on-board estimation of AUV position. Our system uses absolute time information from GNSS for initial clock synchronization and uses one-way-travel-time for range measurements, which makes it scalable in the number of robots. It is easily deployable and does not rely on any installed infrastructure in the environment. We describe various hardware and software components of our system, and present results from experiments in Lake Geneva.
ER  - 

TY  - CONF
TI  - Underwater Terrain Reconstruction from Forward-Looking Sonar Imagery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3471
EP  - 3477
AU  - J. Wang
AU  - T. Shan
AU  - B. Englot
PY  - 2019
KW  - feature extraction
KW  - Gaussian processes
KW  - graph theory
KW  - image reconstruction
KW  - mobile robots
KW  - remotely operated vehicles
KW  - SLAM (robots)
KW  - sonar imaging
KW  - terrain mapping
KW  - underwater vehicles
KW  - terrain reconstruction
KW  - forward-looking sonar imagery
KW  - underwater simultaneous localization
KW  - multibeam imaging sonar
KW  - 3D terrain mapping tasks
KW  - elevation angle information
KW  - data association
KW  - accurate 3D mapping
KW  - Euclidean space
KW  - optical flow
KW  - bearing-range images
KW  - subsea terrain
KW  - Gaussian Process random field
KW  - terrain factors
KW  - factor graph
KW  - terrain elevation estimate
KW  - variable-elevation tank environment
KW  - smooth height estimate
KW  - sonar images
KW  - Chow-Liu tree
KW  - extracted feature tracking
KW  - Feature extraction
KW  - Sonar measurements
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Gaussian processes
KW  - Imaging
DO  - 10.1109/ICRA.2019.8794473
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a novel approach for underwater simultaneous localization and mapping using a multibeam imaging sonar for 3D terrain mapping tasks. The high levels of noise and the absence of elevation angle information in sonar images present major challenges for data association and accurate 3D mapping. Instead of repeatedly projecting extracted features into Euclidean space, we apply optical flow within bearing-range images for tracking extracted features. To deal with degenerate cases, such as when tracking is interrupted by noise, we model the subsea terrain as a Gaussian Process random field on a Chow-Liu tree. Terrain factors are incorporated into the factor graph, aimed at smoothing the terrain elevation estimate. We demonstrate the performance of our proposed algorithm in a simulated environment, which shows that terrain factors effectively reduce estimation error. We also show ROV experiments performed in a variable-elevation tank environment, where we are able to construct a descriptive and smooth height estimate of the tank bottom.
ER  - 

TY  - CONF
TI  - Detect in RGB, Optimize in Edge: Accurate 6D Pose Estimation for Texture-less Industrial Parts
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3486
EP  - 3492
AU  - H. Zhang
AU  - Q. Cao
PY  - 2019
KW  - convolutional neural nets
KW  - edge detection
KW  - image colour analysis
KW  - manipulators
KW  - object recognition
KW  - pose estimation
KW  - robot vision
KW  - texture-less industrial parts
KW  - robotic bin-picking problem
KW  - industrial applications
KW  - single RGB image
KW  - discriminative local appearance descriptors
KW  - optimization stage
KW  - coarse initializations
KW  - surface texture
KW  - edge image
KW  - edge optimization
KW  - accurate 6D object pose estimation
KW  - 2D bounding box
KW  - tiny convolutional neural network
KW  - hypothesis-evaluation scheme
KW  - robotic manipulation platform
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA.2019.8794330
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In order to solve robotic bin-picking problem in many industrial applications, accurate 6D object pose estimation is one of fundamental technologies. This paper presents a method for accurate 6D pose estimation from a single RGB image for texture-less industrial parts. These objects are common but still challenging to deal with, due to the fact that poor surface texture and brightness makes difficult to compute discriminative local appearance descriptors. The proposed method mainly consists of two stages, which ranges from the detection stage to the optimization stage. Firstly, all known objects in the RGB image are detected with 2D bounding box via a tiny convolutional neural network. Then, the second stage will optimize the 6D pose in the Edge image given several coarse initializations. These coarse initializations are generated from the Edge image via a hypothesis-evaluation scheme. Furthermore, the proposed method is validated by achieving state-of-the-art results of texture-less industrial parts for RGB input. According to practical experiments, the proposed method is accurate and robust enough to be applied on the robotic manipulation platform to complete a simple assembly task.
ER  - 

TY  - CONF
TI  - POSEAMM: A Unified Framework for Solving Pose Problems using an Alternating Minimization Method
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3493
EP  - 3499
AU  - J. Campos
AU  - J. R. Cardoso
AU  - P. Miraldo
PY  - 2019
KW  - computer vision
KW  - minimisation
KW  - pose estimation
KW  - alternating minimization method
KW  - pose estimation
KW  - computer vision
KW  - camera models
KW  - pose problem
KW  - objective function
KW  - simple minimization problem
KW  - distinct pose problems
KW  - alternating minimization methods
KW  - pose problems
KW  - Cameras
KW  - Linear programming
KW  - Three-dimensional displays
KW  - Optimization
KW  - Minimization methods
KW  - Computer vision
DO  - 10.1109/ICRA.2019.8793694
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pose estimation is one of the most important problems in computer vision. It can be divided in two different categories - absolute and relative - and may involve two different types of camera models: central and non-central. State-of-the-art methods have been designed to solve separately these problems. This paper presents a unified framework that is able to solve any pose problem by alternating optimization techniques between two set of parameters, rotation and translation. In order to make this possible, it is necessary to define an objective function that captures the problem at hand. Since the objective function will depend on the rotation and translation it is not possible to solve it as a simple minimization problem. Hence the use of Alternating Minimization methods, in which the function will be alternatively minimized with respect to the rotation and the translation. We show how to use our framework in three distinct pose problems. Our methods are then benchmarked with both synthetic and real data, showing their better balance between computational time and accuracy.
ER  - 

TY  - CONF
TI  - Learning Object Localization and 6D Pose Estimation from Simulation and Weakly Labeled Real Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3500
EP  - 3506
AU  - J. Mercier
AU  - C. Mitash
AU  - P. Giguère
AU  - A. Boularias
PY  - 2019
KW  - image annotation
KW  - image classification
KW  - image segmentation
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - unsupervised learning
KW  - 6D pose estimation
KW  - computer vision models
KW  - object localization
KW  - multiple domain classifiers
KW  - synthetic images
KW  - object poses
KW  - time-consuming annotations
KW  - occluded scenes
KW  - cluttered scenes
KW  - weak object detector
KW  - deep learning approaches
KW  - cluttered environments
KW  - robust robotic grasping
KW  - Feature extraction
KW  - Pose estimation
KW  - Training
KW  - Robots
KW  - Heating systems
KW  - Solid modeling
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794112
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate pose estimation is often a requirement for robust robotic grasping and manipulation of objects placed in cluttered, tight environments, such as a shelf with multiple objects. When deep learning approaches are employed to perform this task, they typically require a large amount of training data. However, obtaining precise 6 degrees of freedom for ground-truth can be prohibitively expensive. This work therefore proposes an architecture and a training process to solve this issue. More precisely, we present a weak object detector that enables localizing objects and estimating their 6D poses in cluttered and occluded scenes. To minimize the human labor required for annotations, the proposed detector is trained with a combination of synthetic and a few weakly annotated real images (as little as 10 images per object), for which a human provides only a list of objects present in each image (no time-consuming annotations, such as bounding boxes, segmentation masks and object poses). To close the gap between real and synthetic images, we use multiple domain classifiers trained adversarially. During the inference phase, the resulting class-specific heatmaps of the weak detector are used to guide the search of 6D poses of objects. Our proposed approach is evaluated on several publicly available datasets for pose estimation. We also evaluated our model on classification and localization in unsupervised and semi-supervised settings. The results clearly indicate that this approach could provide an efficient way toward fully automating the training process of computer vision models used in robotics.
ER  - 

TY  - CONF
TI  - STAMPEDE: A Discrete-Optimization Method for Solving Pathwise-Inverse Kinematics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3507
EP  - 3513
AU  - D. Rakita
AU  - B. Mutlu
AU  - M. Gleicher
PY  - 2019
KW  - collision avoidance
KW  - dynamic programming
KW  - end effectors
KW  - graph theory
KW  - manipulator kinematics
KW  - motion control
KW  - nonlinear programming
KW  - search problems
KW  - trajectory control
KW  - adaptive sampling
KW  - search-space
KW  - input end-effector trace
KW  - nonlinear trajectory-optimization approach
KW  - discrete-optimization method
KW  - joint-angles
KW  - robot motion translation problem
KW  - discrete-space graph-search problem
KW  - nonlinear optimization
KW  - dynamic-programming algorithm
KW  - configuration space
KW  - diversity sampling
KW  - robot arm trajectories
KW  - Stampede
KW  - end-effector path function
KW  - pathwise-inverse kinematics
KW  - per-frame inverse kinematics
KW  - collision-free robot motions
KW  - 6-DOF Cartesian-space end-effector paths
KW  - End effectors
KW  - Kinematics
KW  - Robot motion
KW  - Planning
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793617
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a discrete-optimization technique for finding feasible robot arm trajectories that pass through provided 6-DOF Cartesian-space end-effector paths with high accuracy, a problem called pathwise-inverse kinematics. The output from our method consists of a path function of joint-angles that best follows the provided end-effector path function, given some definition of “best”. Our method, called Stampede, casts the robot motion translation problem as a discrete-space graph-search problem where the nodes in the graph are individually solved for using non-linear optimization; framing the problem in such a way gives rise to a well-structured graph that affords an effective best path calculation using an efficient dynamic-programming algorithm. We present techniques for sampling configuration space, such as diversity sampling and adaptive sampling, to construct the search-space in the graph. Through an evaluation, we show that our approach performs well in finding smooth, feasible, collision-free robot motions that match the input end-effector trace with very high accuracy, while alternative approaches, such as a state-of-the-art per-frame inverse kinematics solver and a global non-linear trajectory-optimization approach, performed unfavorably.
ER  - 

TY  - CONF
TI  - Reconstructing Human Hand Pose and Configuration using a Fixed-Base Exoskeleton
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3514
EP  - 3520
AU  - A. Pereira
AU  - G. Stillfried
AU  - T. Baker
AU  - A. Schmidt
AU  - A. Maier
AU  - B. Pleintinger
AU  - Z. Chen
AU  - T. Hulin
AU  - N. Y. Lii
PY  - 2019
KW  - augmented reality
KW  - biomechanics
KW  - biomedical MRI
KW  - image reconstruction
KW  - medical image processing
KW  - medical robotics
KW  - telemedicine
KW  - telerobotics
KW  - virtual reality
KW  - augmented reality
KW  - teleoperation
KW  - virtual reality
KW  - force-feedback
KW  - motion capture
KW  - MRI data
KW  - fixed-base hand exoskeleton
KW  - joint angles
KW  - dexterous haptic input device
KW  - fixed-base exoskeleton
KW  - human hand pose
KW  - Exoskeletons
KW  - Kinematics
KW  - Thumb
KW  - Robot kinematics
KW  - Magnetic resonance imaging
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8794059
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate real-time estimation of the pose and configuration of the human hand attached to a dexterous haptic input device is crucial to improve the interaction possibilities for teleoperation and in virtual and augmented reality. In this paper, we present an approach to reconstruct the pose of the human hand and the joint angles of the fingers when wearing a novel fixed-base (grounded) hand exoskeleton. Using a kinematic model of the human hand built from MRI data, we can reconstruct the hand pose and joint angles without sensors on the human hand, from attachment points on the first three fingers and the palm. We test the accuracy of our approach using motion capture as a ground truth. This reconstruction can be used to determine contact geometry and force-feedback from virtual or remote objects in virtual reality or teleoperation.
ER  - 

TY  - CONF
TI  - Learning Pose Estimation for High-Precision Robotic Assembly Using Simulated Depth Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3521
EP  - 3527
AU  - Y. Litvak
AU  - A. Biess
AU  - A. Bar-Hillel
PY  - 2019
KW  - CAD
KW  - cameras
KW  - convolutional neural nets
KW  - end effectors
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - production engineering computing
KW  - robot vision
KW  - robotic assembly
KW  - 3D CAD models
KW  - depth camera
KW  - deep convolutional neural networks
KW  - industrial robotic assembly tasks
KW  - depth images
KW  - pose estimation learning
KW  - two-stage pose estimation procedure
KW  - end-effector
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA.2019.8794226
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Most of industrial robotic assembly tasks today require fixed initial conditions for successful assembly. These constraints induce high production costs and low adaptability to new tasks. In this work we aim towards flexible and adaptable robotic assembly by using 3D CAD models for all parts to be assembled. We focus on a generic assembly task - the Siemens Innovation Challenge - in which a robot needs to assemble a gear-like mechanism with high precision into an operating system. To obtain the millimeter-accuracy required for this task and industrial settings alike, we use a depth camera mounted near the robot's end-effector. We present a high-accuracy two-stage pose estimation procedure based on deep convolutional neural networks, which includes detection, pose estimation, refinement, and handling of near- and full symmetries of parts. The networks are trained on simulated depth images with means to ensure successful transfer to the real robot. We obtain an average pose estimation error of 2.16 millimeters and 0.64 degree leading to 91% success rate for robotic assembly of randomly distributed parts. To the best of our knowledge, this is the first time that the Siemens Innovation Challenge is fully addressed, with all the parts assembled with high success rates.
ER  - 

TY  - CONF
TI  - Aided Inertial Navigation: Unified Feature Representations and Observability Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3528
EP  - 3534
AU  - Y. Yang
AU  - G. Huang
PY  - 2019
KW  - inertial navigation
KW  - Jacobian matrices
KW  - Monte Carlo methods
KW  - observability
KW  - global yaw rotation
KW  - line features
KW  - closest point parameterization
KW  - observability properties
KW  - unified representations
KW  - closest point form
KW  - unified parameterizations
KW  - CP representations
KW  - EKF-based vision-aided INS
KW  - geometrical features
KW  - unified feature representations
KW  - aided inertial navigation systems
KW  - homogeneous geometric features
KW  - general aided INS
KW  - linearized aided INS
KW  - minimal representation
KW  - observability analysis
KW  - 4D Euclidean vector
KW  - analytically-computed Jacobians
KW  - Monte-Carlo simulations
KW  - Observability
KW  - Quaternions
KW  - Jacobian matrices
KW  - Noise measurement
KW  - Pollution measurement
KW  - Three-dimensional displays
KW  - Q measurement
DO  - 10.1109/ICRA.2019.8793507
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Extending our recent work [1] that focuses on the observability analysis of aided inertial navigation systems (INS) using homogeneous geometric features including points, lines and planes, in this paper, we complete the analysis for the general aided INS using different combinations of geometric features (i.e., points, lines and planes). We analytically show that the linearized aided INS with different feature combinations generally possesses the same observability properties as those with same features, i.e., 4 unobservable directions, corresponding to the global yaw rotation and the global position of the sensor platform. During the analysis, we particularly propose a novel minimal representation of line features, i.e., the “closest point” parameterization, which uses a 4D Euclidean vector to describe a line and is proved to preserve the same observability properties. Based on that, for the first time, we provide two sets of unified representations for points, lines and planes, i.e., the quaternion form and the closest point (CP) form, and perform extensive observability analysis with analytically-computed Jacobians for these unified parameterizations. We validate the proposed CP representations and observability analysis with Monte-Carlo simulations, in which EKF-based vision-aided INS (VINS) with combinations of geometrical features in CP form are developed and compared.
ER  - 

TY  - CONF
TI  - A Linear-Complexity EKF for Visual-Inertial Navigation with Loop Closures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3535
EP  - 3541
AU  - P. Geneva
AU  - K. Eckenhoff
AU  - G. Huang
PY  - 2019
KW  - computational complexity
KW  - correlation methods
KW  - inertial navigation
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - robot vision
KW  - SLAM (robots)
KW  - Schmidt-MSCKF
KW  - real-time visual-inertial navigation
KW  - bounded-error performance
KW  - robotic applications
KW  - visual-inertial localization
KW  - loop closure constraints
KW  - long-term persistent navigation
KW  - Schmidt-Kalman formulation
KW  - multistate constraint Kalman filter framework
KW  - state vector
KW  - linear-complexity EKF
KW  - cross-correlations
KW  - navigation states
KW  - computational complexity
KW  - performance improvement
KW  - Navigation
KW  - Microsoft Windows
KW  - Standards
KW  - Current measurement
KW  - Real-time systems
KW  - Trajectory
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793836
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Enabling real-time visual-inertial navigation in unknown environments while achieving bounded-error performance holds great potentials in robotic applications. To this end, in this paper, we propose a novel linear-complexity EKF for visual-inertial localization, which can efficiently utilize loop closure constraints, thus allowing for long-term persistent navigation. The key idea is to adapt the Schmidt-Kalman formulation within the multi-state constraint Kalman filter (MSCKF) framework, in which we selectively include keyframes as nuisance parameters in the state vector for loop closures but do not update their estimates and covariance in order to save computations while still tracking their cross-correlations with the current navigation states. As a result, the proposed Schmidt-MSCKF has only O(n) computational complexity while still incorporating loop closures into the system. The proposed approach is validated extensively on large-scale real-world experiments, showing significant performance improvements when compared to the standard MSCKF, while only incurring marginal computational overhead.
ER  - 

TY  - CONF
TI  - Sensor-Failure-Resilient Multi-IMU Visual-Inertial Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3542
EP  - 3548
AU  - K. Eckenhoff
AU  - P. Geneva
AU  - G. Huang
PY  - 2019
KW  - calibration
KW  - inertial navigation
KW  - sensor fusion
KW  - sensor-failure-resilient multiIMU visual-inertial navigation
KW  - real-time multiIMU visual-inertial navigation system
KW  - multiple inertial measurement units
KW  - mi-VINS formulation
KW  - auxiliary sensors
KW  - base IMU failure
KW  - sensor failure
KW  - conventional VINS
KW  - multiple IMUs
KW  - Calibration
KW  - Cameras
KW  - Robot sensing systems
KW  - Navigation
KW  - Covariance matrices
KW  - Fuses
KW  - Visualization
DO  - 10.1109/ICRA.2019.8794295
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a real-time multi-IMU visual-inertial navigation system (mi-VINS) that utilizes the information from multiple inertial measurement units (IMUs) and thus is resilient to IMU sensor failures. In particular, in the proposed mi-VINS formulation, one of the IMUs serves as the “base” of the system, while the rest act as auxiliary sensors aiding in state estimation. A key advantage of this architecture is the ability to seamlessly “promote” an auxiliary IMU as a new base, for example, upon detection of the base IMU failure, thus being resilient to the single point of sensor failure as seen in conventional VINS. Moreover, in order to properly fuse the information of multiple IMUs, both the spatial (relative pose) and temporal (time offset) calibration parameters between each sensor and the base IMU are estimated online. The proposed miVINS with online spatial and temporal calibration is validated in both simulations and real-world experiments, and is shown to be able to provide accurate localization and calibration even in scenarios with IMU sensor failures.
ER  - 

TY  - CONF
TI  - Learning Monocular Visual Odometry through Geometry-Aware Curriculum Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3549
EP  - 3555
AU  - M. R. U. Saputra
AU  - P. P. B. de Gusmao
AU  - S. Wang
AU  - A. Markham
AU  - N. Trigoni
PY  - 2019
KW  - distance measurement
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - recurrent neural nets
KW  - regression analysis
KW  - windowed composition layer
KW  - CL-VO
KW  - learning monocular visual odometry
KW  - optical flow network
KW  - geometry-aware objective function
KW  - complex geometry problems
KW  - geometry-aware Curriculum Learning
KW  - Training
KW  - Geometry
KW  - Cameras
KW  - Task analysis
KW  - Estimation
KW  - Feature extraction
KW  - Optical fiber networks
DO  - 10.1109/ICRA.2019.8793581
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Inspired by the cognitive process of humans and animals, Curriculum Learning (CL) trains a model by gradually increasing the difficulty of the training data. In this paper, we study whether CL can be applied to complex geometry problems like estimating monocular Visual Odometry (VO). Unlike existing CL approaches, we present a novel CL strategy for learning the geometry of monocular VO by gradually making the learning objective more difficult during training. To this end, we propose a novel geometry-aware objective function by jointly optimizing relative and composite transformations over small windows via bounded pose regression loss. A cascade optical flow network followed by recurrent network with a differentiable windowed composition layer, termed CL-VO, is devised to learn the proposed objective. Evaluation on three real-world datasets shows superior performance of CL-VO over state-of-the-art feature-based and learning-based VO.
ER  - 

TY  - CONF
TI  - Visual-Odometric Localization and Mapping for Ground Vehicles Using SE(2)-XYZ Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3556
EP  - 3562
AU  - F. Zheng
AU  - Y. Liu
PY  - 2019
KW  - feature extraction
KW  - graph theory
KW  - mobile robots
KW  - motion control
KW  - object detection
KW  - path planning
KW  - road vehicles
KW  - robot vision
KW  - ground vehicle
KW  - odometric sensors
KW  - monocular visual sensors
KW  - stochastic constraint
KW  - odometric measurement processing
KW  - visual-odometric localization
KW  - mapping system
KW  - out-of SE(2) motion perturbation
KW  - SE(2)-XYZ constraint
KW  - image feature measurement
KW  - preintegration algorithm
KW  - graph optimization structure
KW  - Visualization
KW  - Optimization
KW  - Land vehicles
KW  - Perturbation methods
KW  - Robots
KW  - Jacobian matrices
KW  - Sensors
DO  - 10.1109/ICRA.2019.8793928
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper focuses on the localization and mapping problem on ground vehicles using odometric and monocular visual sensors. To improve the accuracy of vision based estimation on ground vehicles, researchers have exploited the constraint of approximately planar motion, and usually implemented it as a stochastic constraint on an SE(3) pose. In this paper, we propose a simpler algorithm that directly parameterizes the ground vehicle poses on SE(2). The out-of SE(2) motion perturbations are not neglected, but incorporated into an integrated noise term of a novel SE(2)-XYZ constraint, which associates an SE(2) pose and a 3D landmark via the image feature measurement. For odometric measurement processing, we also propose an efficient preintegration algorithm on SE(2). Utilizing these constraints, a complete visual-odometric localization and mapping system is developed, in a commonly used graph optimization structure. Its superior performance in accuracy and robustness is validated by real-world experiments in industrial indoor environments.
ER  - 

TY  - CONF
TI  - Keyframe-based Direct Thermal–Inertial Odometry
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3563
EP  - 3569
AU  - S. Khattak
AU  - C. Papachristos
AU  - K. Alexis
PY  - 2019
KW  - cameras
KW  - distance measurement
KW  - Global Positioning System
KW  - inertial navigation
KW  - measurement errors
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - radiometry
KW  - sensor fusion
KW  - temperature measurement
KW  - temperature sensors
KW  - keyframe-based direct thermal-inertial odometry
KW  - thermal camera
KW  - inertial measurements
KW  - airborne obscurants
KW  - fog
KW  - smoke
KW  - optimization based approach
KW  - inertial measurement errors
KW  - GPS
KW  - direct radiometric data fusion
KW  - aerial robotic capabilities
KW  - visually degraded environments
KW  - reprojection error minimisation
KW  - 3D landmark error
KW  - indoor laboratory setting
KW  - underground mine
KW  - Cameras
KW  - Robot vision systems
KW  - Radiometry
KW  - Estimation
KW  - Unmanned aerial vehicles
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793927
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes an approach for fusing direct radiometric data from a thermal camera with inertial measurements to extend the robotic capabilities of aerial robots for navigation in GPS-denied and visually degraded environments in the conditions of darkness and in the presence of airborne obscurants such as dust, fog and smoke. An optimization based approach is developed that jointly minimizes the re-projection error of 3D landmarks and inertial measurement errors. The developed solution is extensively verified against both ground-truth in an indoor laboratory setting, as well as inside an underground mine under severely visually degraded conditions.
ER  - 

TY  - CONF
TI  - On Parameter Estimation of Space Manipulator Systems with Flexible Joints Using the Energy Balance*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3570
EP  - 3576
AU  - K. Nanos
AU  - E. Papadopoulos
PY  - 2019
KW  - aerospace robotics
KW  - damping
KW  - flexible manipulators
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - parameter estimation
KW  - path planning
KW  - manipulators
KW  - joint flexibilities
KW  - path planning
KW  - tracking capabilities
KW  - system inertial parameters
KW  - damping parameters
KW  - space flexible-joint manipulator system
KW  - system full dynamics
KW  - space manipulator systems
KW  - flexible joints
KW  - stiffness parameters
KW  - parameter estimation
KW  - Mathematical model
KW  - Space vehicles
KW  - Manipulator dynamics
KW  - Parameter estimation
KW  - Damping
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793960
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The parameter estimation of space manipulator systems on orbit is studied, whose manipulators are subject to joint flexibilities. To improve path planning and tracking capabilities, advanced control strategies that benefit from the knowledge of system parameters are required. These parameters include the system inertial parameters as well as the stiffness and damping parameters, which describe joint flexibilities. During operation some of these parameters may change or be unknown. Estimation methods based on the equations of motion are sensitive to noise, while methods based on the angular momentum conservation, while they are tolerant to noise, they cannot estimate the parameters that describe joint flexibilities. A parameter estimation method, based on the energy balance, applied during the motion of a space flexible-joint manipulator system in the free-floating mode, is developed. The method is tolerant to noise and can reconstruct the system full dynamics. It is shown that the parameters estimated by the proposed method can describe the system dynamics fully. The application of the developed method is valid for spatial systems; it is illustrated by a planar 7 degrees of freedom (DoF) example system.
ER  - 

TY  - CONF
TI  - Central Pattern Generators Control of Momentum Driven Compliant Structures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3585
EP  - 3591
AU  - S. Bonardi
AU  - J. Romanishin
AU  - D. Rus
AU  - T. Kubota
PY  - 2019
KW  - actuators
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - robot dynamics
KW  - co-evolved structures
KW  - control-only optimized equivalent
KW  - MDS
KW  - inertially actuated units
KW  - compliant elements
KW  - control method
KW  - bio-inspired concept
KW  - compliance distribution
KW  - locomotion performance
KW  - population based optimization techniques
KW  - momentum driven compliant structures
KW  - central pattern generator control
KW  - hardware complexity
KW  - CPG
KW  - rough environment exploration
KW  - Robots
KW  - Torque
KW  - Three-dimensional displays
KW  - Complexity theory
KW  - Generators
KW  - Aerospace electronics
KW  - Space exploration
DO  - 10.1109/ICRA.2019.8793806
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We introduce the concept of Momentum Driven Structures (MDS) made of inertially actuated units linked together by compliant elements as a potential solution for rough environments exploration. We propose a control method for MDS based on the bio-inspired concept of Central Pattern Generator (CPG) and study in simulation the impact of compliance distribution on locomotion performance using population based optimization techniques. Our results suggest that compliant structures outperform their rigid counterparts in terms of distance traveled. In addition, we show that co-evolved structures perform only marginally better than their control-only optimized equivalent, highlighting the fact that compliance modulation may not be a significant asset in such experiments, considering the related hardware complexity it introduces.
ER  - 

TY  - CONF
TI  - Contact-Event-Triggered Mode Estimation for Dynamic Rigid Body Impedance-Controlled Capture
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3600
EP  - 3606
AU  - H. Kato
AU  - D. Hirano
AU  - J. Ota
PY  - 2019
KW  - aerospace robotics
KW  - force control
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - position control
KW  - sensors
KW  - contact-event-triggered mode estimation
KW  - dynamic rigid body impedance-controlled capture
KW  - contact-event-triggered filter
KW  - impedance control
KW  - particle filter
KW  - sliding contact mode cases
KW  - force-torque sensor
KW  - air bearing robotic system
KW  - time 8.3 ms
KW  - time 4.2 ms
KW  - Robot sensing systems
KW  - Estimation
KW  - Collision avoidance
KW  - Impedance
KW  - Robot kinematics
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793677
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a contact-event-triggered filter using only a force-torque sensor with impedance control for non-cooperative, rotating, heavy object capture. Contact events are modeled for prediction, and detected to trigger the particle filter's updating process. By combining these features, a computationally efficient, contact-event-triggered filter is proposed. For our purpose of capture using impedance control, expected contact events, collisions and sliding are defined for prediction and detection. This novel method is implemented in an air bearing robotic system, and has demonstrated its superiority with the highest success rate (100%) for sliding contact mode cases, whereas the previous method could only yield a success rate of 87.9%. The computation resource is demonstrated to be limited, with a computation time of 4.2 milliseconds on average and 8.3 milliseconds at worst.
ER  - 

TY  - CONF
TI  - Leveraging Contact Forces for Learning to Grasp
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3615
EP  - 3621
AU  - H. Merzić
AU  - M. Bogdanović
AU  - D. Kappler
AU  - L. Righetti
AU  - J. Bohg
PY  - 2019
KW  - grippers
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - grasp acquisition
KW  - model-free deep reinforcement learning
KW  - control policies
KW  - contact sensing
KW  - robust grasping
KW  - multifingered hand
KW  - complex finger coordination
KW  - learned policies
KW  - grasping policies
KW  - contact feedback
KW  - open problem
KW  - robotics research
KW  - noisy observations
KW  - sensor feedback
KW  - visual feedback
KW  - contact forces
KW  - Grasping
KW  - Robot sensing systems
KW  - Uncertainty
KW  - Visualization
KW  - Grippers
DO  - 10.1109/ICRA.2019.8793733
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Grasping objects under uncertainty remains an open problem in robotics research. This uncertainty is often due to noisy or partial observations of the object pose or shape. To enable a robot to react appropriately to unforeseen effects, it is crucial that it continuously takes sensor feedback into account. While visual feedback is important for inferring a grasp pose and reaching for an object, contact feedback offers valuable information during manipulation and grasp acquisition. In this paper, we use model-free deep reinforcement learning to synthesize control policies that exploit contact sensing to generate robust grasping under uncertainty. We demonstrate our approach on a multi-fingered hand that exhibits more complex finger coordination than the commonly used two-fingered grippers. We conduct extensive experiments in order to assess the performance of the learned policies, with and without contact sensing. While it is possible to learn grasping policies without contact sensing, our results suggest that contact feedback allows for a significant improvement of grasping robustness under object pose uncertainty and for objects with a complex shape.
ER  - 

TY  - CONF
TI  - Learning Latent Space Dynamics for Tactile Servoing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3622
EP  - 3628
AU  - G. Sutanto
AU  - N. Ratliff
AU  - B. Sundaralingam
AU  - Y. Chebotar
AU  - Z. Su
AU  - A. Handa
AU  - D. Fox
PY  - 2019
KW  - dexterous manipulators
KW  - feedback
KW  - haptic interfaces
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - tactile sensors
KW  - tactile servoing
KW  - tactile sensing information
KW  - tactile skin geometry
KW  - tactile finger
KW  - dexterous robotic manipulation
KW  - tactile feedback capability
KW  - latent space dynamics learning
KW  - contact point tracking
KW  - manifold learning
KW  - Robot sensing systems
KW  - Skin
KW  - Aerospace electronics
KW  - Two dimensional displays
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793520
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To achieve a dexterous robotic manipulation, we need to endow our robot with tactile feedback capability, i.e. the ability to drive action based on tactile sensing. In this paper, we specifically address the challenge of tactile servoing, i.e. given the current tactile sensing and a target/goal tactile sensing - memorized from a successful task execution in the past - what is the action that will bring the current tactile sensing to move closer towards the target tactile sensing at the next time step. We develop a data-driven approach to acquire a dynamics model for tactile servoing by learning from demonstration. Moreover, our method represents the tactile sensing information as to lie on a surface - or a 2D manifold - and perform a manifold learning, making it applicable to any tactile skin geometry. We evaluate our method on a contact point tracking task using a robot equipped with a tactile finger.
ER  - 

TY  - CONF
TI  - PointNetGPD: Detecting Grasp Configurations from Point Sets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3629
EP  - 3635
AU  - H. Liang
AU  - X. Ma
AU  - S. Li
AU  - M. Görner
AU  - S. Tang
AU  - B. Fang
AU  - F. Sun
AU  - J. Zhang
PY  - 2019
KW  - computational geometry
KW  - feature extraction
KW  - grippers
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - PointNetGPD
KW  - end-to-end grasp evaluation
KW  - object grasping
KW  - 3D point cloud
KW  - grasp configuration detection
KW  - point sets
KW  - robot grasp configurations
KW  - complex geometric structure
KW  - gripper
KW  - 3D geometry information
KW  - deep neural network
KW  - RGB-D camera
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Measurement
KW  - Grippers
KW  - Grasping
KW  - Solid modeling
KW  - Geometry
DO  - 10.1109/ICRA.2019.8794435
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose an end-to-end grasp evaluation model to address the challenging problem of localizing robot grasp configurations directly from the point cloud. Compared to recent grasp evaluation metrics that are based on handcrafted depth features and a convolutional neural network (CNN), our proposed PointNetGPD is lightweight and can directly process the 3D point cloud that locates within the gripper for grasp evaluation. Taking the raw point cloud as input, our proposed grasp evaluation network can capture the complex geometric structure of the contact area between the gripper and the object even if the point cloud is very sparse. To further improve our proposed model, we generate a large-scale grasp dataset with 350k real point cloud and grasps with the YCB object set for training. The performance of the proposed model is quantitatively measured both in simulation and on robotic hardware. Experiments on object grasping and clutter removal show that our proposed model generalizes well to novel objects and outperforms state-of-the-art methods. Code and video are available at https://lianghongzhuo.github.io/PointNetGPD.
ER  - 

TY  - CONF
TI  - Learning Deep Visuomotor Policies for Dexterous Hand Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3636
EP  - 3643
AU  - D. Jain
AU  - A. Li
AU  - S. Singhal
AU  - A. Rajeswaran
AU  - V. Kumar
AU  - E. Todorov
PY  - 2019
KW  - dexterous manipulators
KW  - learning (artificial intelligence)
KW  - tactile sensors
KW  - touch sensing information
KW  - expert demonstration trajectories
KW  - high dimensional visual observations
KW  - manipulation tasks
KW  - imitation learning
KW  - on-board sensors
KW  - tactile sensors
KW  - external tracking
KW  - on-board sensing capabilities
KW  - in-hand manipulation
KW  - multifingered dexterous hands
KW  - dexterous hand manipulation
KW  - deep visuomotor policies
KW  - Task analysis
KW  - Visualization
KW  - Training
KW  - Tactile sensors
DO  - 10.1109/ICRA.2019.8794033
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Multi-fingered dexterous hands are versatile and capable of acquiring a diverse set of skills such as grasping, in-hand manipulation, and tool use. To fully utilize their versatility in real-world scenarios, we require algorithms and policies that can control them using on-board sensing capabilities, without relying on external tracking or motion capture systems. Cameras and tactile sensors are the most widely used on-board sensors that do not require instrumentation of the world. In this work, we demonstrate an imitation learning based approach to train deep visuomotor policies for a variety of manipulation tasks with a simulated five fingered dexterous hand. These policies directly control the hand using high dimensional visual observations of the world and propreoceptive observations from the robot, and can be trained efficiently with a few hundred expert demonstration trajectories. We also find that using touch sensing information enables faster learning and better asymptotic performance for tasks with high degree of occlusions. Video demonstration of our results are available at: https://sites.google.com/view/hand-vil/.
ER  - 

TY  - CONF
TI  - Learning to Identify Object Instances by Touch: Tactile Recognition via Multimodal Matching
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3644
EP  - 3650
AU  - J. Lin
AU  - R. Calandra
AU  - S. Levine
PY  - 2019
KW  - image recognition
KW  - object recognition
KW  - tactile sensors
KW  - visual modality
KW  - global observation
KW  - robotic manipulation
KW  - visual object identification
KW  - touch-based instance recognition
KW  - multimodal recognition
KW  - visual observation
KW  - tactile observation
KW  - multimodal instance recognition problem
KW  - GelSight touch sensors
KW  - autonomous data collection procedure
KW  - tactile observations
KW  - tactile recognition
KW  - robotic perception
KW  - Visualization
KW  - Cameras
KW  - Grippers
KW  - Tactile sensors
KW  - Data collection
DO  - 10.1109/ICRA.2019.8793885
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Much of the literature on robotic perception focuses on the visual modality. Vision provides a global observation of a scene, making it broadly useful. However, in the domain of robotic manipulation, vision alone can sometimes prove inadequate: in the presence of occlusions or poor lighting, visual object identification might be difficult. The sense of touch can provide robots with an alternative mechanism for recognizing objects. In this paper, we study the problem of touch-based instance recognition. We propose a novel framing of the problem as multi-modal recognition: the goal of our system is to recognize, given a visual and tactile observation, whether or not these observations correspond to the same object. To our knowledge, our work is the first to address this type of multi-modal instance recognition problem on such a large-scale with our analysis spanning 98 different objects. We employ a robot equipped with two GelSight touch sensors, one on each finger, and a self-supervised, autonomous data collection procedure to collect a dataset of tactile observations and images. Our experimental results show that it is possible to accurately recognize object instances by touch alone, including instances of novel objects that were never seen during training. Our learned model outperforms other methods on this complex task, including that of human volunteers.
ER  - 

TY  - CONF
TI  - Dexterous Manipulation with Deep Reinforcement Learning: Efficient, General, and Low-Cost
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3651
EP  - 3657
AU  - H. Zhu
AU  - A. Gupta
AU  - A. Rajeswaran
AU  - S. Levine
AU  - V. Kumar
PY  - 2019
KW  - control engineering computing
KW  - dexterous manipulators
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - robot programming
KW  - deep reinforcement learning
KW  - multifingered hands
KW  - contact-rich manipulation behavior
KW  - model-free deep RL algorithms
KW  - complex multifingered manipulation skills
KW  - direct deep RL training
KW  - model-based control
KW  - dexterous manipulation
KW  - dexterous multifingered robotic hands
KW  - general-purpose robotic manipulators
KW  - autonomous control
KW  - complex intermittent contact interactions
KW  - Task analysis
KW  - Valves
KW  - Acceleration
KW  - Reinforcement learning
KW  - Robot sensing systems
KW  - Hardware
DO  - 10.1109/ICRA.2019.8794102
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dexterous multi-fingered robotic hands can perform a wide range of manipulation skills, making them an appealing component for general-purpose robotic manipulators. However, such hands pose a major challenge for autonomous control, due to the high dimensionality of their configuration space and complex intermittent contact interactions. In this work, we propose deep reinforcement learning (deep RL) as a scalable solution for learning complex, contact rich behaviors with multi-fingered hands. Deep RL provides an end-to-end approach to directly map sensor readings to actions, without the need for task specific models or policy classes. We show that contact-rich manipulation behavior with multi-fingered hands can be learned by directly training with model-free deep RL algorithms in the real world, with minimal additional assumption and without the aid of simulation. We learn to perform a variety of tasks on two different low-cost hardware platforms entirely from scratch, and further study how the learning can be accelerated by using a small number of human demonstrations. Our experiments demonstrate that complex multi-fingered manipulation skills can be learned in the real world in about 4-7 hours for most tasks, and that demonstrations can decrease this to 2-3 hours, indicating that direct deep RL training in the real world is a viable and practical alternative to simulation and model-based control. https:// sites.google.com/view/deeprl-handmanipulation.
ER  - 

TY  - CONF
TI  - Inkjet Printable Actuators and Sensors for Soft-bodied Crawling Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3658
EP  - 3664
AU  - T. D. Ta
AU  - T. Umedachi
AU  - Y. Kawahara
PY  - 2019
KW  - actuators
KW  - angular measurement
KW  - ink jet printing
KW  - mobile robots
KW  - nanoparticles
KW  - nonlinear control systems
KW  - plastics
KW  - silver
KW  - temperature measurement
KW  - temperature sensors
KW  - thin film sensors
KW  - all-printed paper caterpillar robots
KW  - inkjet printable actuator
KW  - rigid sensor-actuators
KW  - soft-bodied crawling robot design
KW  - nanoparticle ink printing
KW  - flexible plastic film
KW  - bending sensors
KW  - thermal based actuators
KW  - home-commodity inkjet printers
KW  - Actuators
KW  - Heating systems
KW  - Ink
KW  - Silver
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793827
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft-bodied robots are getting attention from researchers as their potential in designing compliant and adaptive robots. However, soft-bodied robots also pose many challenges not only in non-linear controlling but also in design and fabrication. Especially, the non-compatibility between soft materials and rigid sensors/actuators makes it more difficult to design a fully compliant soft-bodied robot. In this paper, we propose an all-printed sensor and actuator for designing soft-bodied robots by printing silver nano-particle ink on top of a flexible plastic film. We can print bending sensors and thermal based actuators instantly with home-commodity inkjet printers without any pre/post-processing. We exemplify the application of this fabrication method with an all-printed paper caterpillar robots which can inch forward and sense its body bending angle.
ER  - 

TY  - CONF
TI  - Design and Evaluation of an Energy-Saving Drive for a Versatile Robotic Gripper
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3665
EP  - 3671
AU  - J. Neven
AU  - M. Baioumy
AU  - W. Wolfslag
AU  - M. Wisse
PY  - 2019
KW  - actuators
KW  - dexterous manipulators
KW  - energy conservation
KW  - energy consumption
KW  - grippers
KW  - motion control
KW  - path planning
KW  - energy-saving drive
KW  - robotic grippers
KW  - energy consumption
KW  - energy-savings
KW  - energy-neutral grippers
KW  - robotic energy-efficient drive
KW  - grip performance metric
KW  - nonbackdrivable mechanism
KW  - statically balanced force amplifier
KW  - SBFA
KW  - NBDM
KW  - Grippers
KW  - Force
KW  - Measurement
KW  - Robots
KW  - Energy consumption
KW  - Task analysis
KW  - Springs
DO  - 10.1109/ICRA.2019.8793723
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The main task of robotic grippers, holding an object, does not require work theoretically. Yet grippers consume significant amounts of energy in practice. This paper presents an approach for designing an energy-saving drive for robotic grippers employing a Statically Balanced Force Amplifier (SBFA) and a Non-backdrivable mechanism (NBDM). A novel metric (Grip Performance Metric) to systematically evaluate drives regarding their energy consumption, is used in the design phase; afterwards, the realization and testing of a prototype (REED, Robotic Energy-Efficient Drive) are presented. Results show that the actuation force can be reduced by 92%, resulting in energy-savings of 86% for an example task. This shows the potential of drives based on SBFAs and NBDMs to achieve energy-neutral grippers.
ER  - 

TY  - CONF
TI  - Generative Deformation: Procedural Perforation for Elastic Structures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3672
EP  - 3678
AU  - S. Transue
AU  - M. Choi
PY  - 2019
KW  - deformation
KW  - elasticity
KW  - finite element analysis
KW  - solid modelling
KW  - stress analysis
KW  - three-dimensional printing
KW  - generative deformation
KW  - procedural perforation
KW  - elastic structures
KW  - procedural generation
KW  - controlling designing 3D printed deformable object behaviors
KW  - generative algorithms
KW  - cohesive process
KW  - variable elasticity
KW  - automated method
KW  - simulated deformations
KW  - cohesive pipeline model
KW  - volumetric structures
KW  - stress analysis
KW  - consumer-level 3D printers
KW  - finite element analysis metrics
KW  - elastic 3D prints
KW  - design objectives
KW  - elastic material behaviors
KW  - heterogeneous geometric structure
KW  - 3D print deformations
KW  - automated pipeline
KW  - design environment
KW  - perforated deformation models
KW  - heterogeneous lattice structures
KW  - automated generation
KW  - 3D print procedure
KW  - elastic material capabilities
KW  - Three-dimensional displays
KW  - Strain
KW  - Deformable models
KW  - Stress
KW  - Pipelines
KW  - Solid modeling
KW  - Printers
DO  - 10.1109/ICRA.2019.8793883
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Procedural generation of elastic structures provides the fundamental basis for controlling and designing 3D printed deformable object behaviors. The automation through generative algorithms provides flexibility in how design and functionality can be seamlessly integrated into a cohesive process that generates 3D prints with variable elasticity. Generative deformation introduces an automated method for perforating existing volumetric structures, promoting simulated deformations, and integrating stress analysis into a cohesive pipeline model that can be used with existing consumer-level 3D printers with elastic material capabilities. In this work, we present a consolidated implementation of the design, simulate, refine, and 3D print procedure based on the automated generation of heterogeneous lattice structures. We utilize Finite Element Analysis (FEA) metrics to generate perforated deformation models that adhere to deformation behaviors created within our design environment. We present the core algorithms, automated pipeline, and 3D print deformations of various objects. Quantitative results illustrate how the heterogeneous geometric structure can influence elastic material behaviors towards design objectives. Our method provides an automated open-source tool for quickly prototyping elastic 3D prints.
ER  - 

TY  - CONF
TI  - Robotics Education and Research at Scale: A Remotely Accessible Robotics Development Platform
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3679
EP  - 3685
AU  - W. Wiedmeyer
AU  - M. Mende
AU  - D. Hartmann
AU  - R. Bischoff
AU  - C. Ledermann
AU  - T. Kroger
PY  - 2019
KW  - control engineering computing
KW  - educational robots
KW  - laboratories
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - research and development
KW  - telerobotics
KW  - remotely accessible robotics development platform
KW  - KUKA Robot Learning Lab
KW  - industrial lightweight robots
KW  - Service robots
KW  - Robot sensing systems
KW  - Robot learning
KW  - Mobile robots
KW  - Collision avoidance
KW  - Hardware
DO  - 10.1109/ICRA.2019.8793976
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces the KUKA Robot Learning Lab at KIT - a remotely accessible robotics testbed. The motivation behind the laboratory is to make state-of-the-art industrial lightweight robots more accessible for education and research. Such expensive hardware is usually not available to students or less privileged researchers to conduct experiments. This paper describes the design and operation of the Robot Learning Lab and discusses the challenges that one faces when making experimental robot cells remotely accessible. Especially safety and security must be ensured, while giving users as much freedom as possible when developing programs to control the robots. A fully automated and efficient processing pipeline for experiments makes the lab suitable for a large amount of users and allows a high usage rate of the robots.
ER  - 

TY  - CONF
TI  - Automated Seedling Height Assessment for Tree Nurseries Using Point Cloud Processing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3686
EP  - 3691
AU  - T. R. Wanasinghe
AU  - B. R. Dowden
AU  - O. D. Silva
AU  - G. K. I. Mann
AU  - C. Lundrigan
PY  - 2019
KW  - computer vision
KW  - forestry
KW  - height measurement
KW  - image sampling
KW  - solid modelling
KW  - stereo image processing
KW  - seedling measurement process
KW  - scanning laser profilometer
KW  - application specific point-cloud
KW  - point-cloud generation methods
KW  - 3D structured light sensing
KW  - light intensity detection
KW  - height measurement
KW  - measurement accuracy
KW  - measurement system
KW  - tree nurseries
KW  - point cloud processing
KW  - automated seedling height assessment system
KW  - offline identification
KW  - report generation
KW  - seedling development process
KW  - production optimization purposes
KW  - data samples
KW  - industrial scale operations
KW  - measurement sample size
KW  - measurement resolution
KW  - Centre for Agriculture and Forestry Development
KW  - Canada
KW  - Newfoundland and Labrador
KW  - Wooddale
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Measurement by laser beam
KW  - Control systems
KW  - Vegetation
KW  - Laser radar
DO  - 10.1109/ICRA.2019.8793790
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a prototype of an automated seedling height assessment system for tree nurseries. The proposed system can acquire and store real-time 3D point-cloud data of seedlings; and perform offline identification, measurement, and report generation of seedling heights with an overall system accuracy that meets a 5mm accuracy specification. Periodic growth information of seedlings allows quantifying effects of different factors on the overall seedling development process for research and production optimization purposes. However, current manual sampling approaches used at these facilities produce quite limited data samples, and the process is rather time-consuming and labor intensive for industrial scale operations. In contrast, the proposed system is capable of significantly increasing the measurement sample size, measurement resolution, and frequency of measurement by automating the seedling measurement process using a scanning laser profilometer and an application specific point-cloud processing algorithm. The performance of the proposed profilometry solution for point-cloud generation is compared with several other point-cloud generation methods such as a 3D structured light sensing, light intensity detection and ranging (LiDAR), stereovision, and photogrammetry. This comparison results demonstrate a superior performance of the laser-profilometer over other sensing solutions available for seedling height measurement. The proposed system is experimentally validated for its measurement accuracy and repeatability. The field-test of the measurement system was conducted at Centre for Agriculture and Forestry Development, Wooddale, Newfoundland and Labrador (NL), Canada, and the results demonstrate the practical applicability and technological readiness of the proposed system for field deployment.
ER  - 

TY  - CONF
TI  - Adsorption Pad using Capillary Force for Uneven Surface
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3692
EP  - 3697
AU  - A. Ichikawa
AU  - S. Kajino
AU  - A. Takeyama
AU  - Y. Adachi
AU  - K. Totsuka
AU  - Y. Ikemoto
AU  - K. Ohara
AU  - T. Oomichi
AU  - T. Fukuda
PY  - 2019
KW  - adsorption
KW  - capillarity
KW  - mobile robots
KW  - seals (stoppers)
KW  - porous part
KW  - capillary part
KW  - capillary force
KW  - uneven surface
KW  - irregular surface object
KW  - Super Wet Adsorption pad
KW  - wall climbing robot
KW  - SWA pad
KW  - salt reaching method
KW  - water sealing
KW  - Adsorption
KW  - Fabrication
KW  - Force
KW  - Robots
KW  - Wires
KW  - Business
KW  - Surface treatment
DO  - 10.1109/ICRA.2019.8793746
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel adsorption pad for wall climbing robot and irregular surface object using capillary force and water sealing. We call this adsorption pad as Super Wet Adsorption pad. The SWA pad has a porous part and a capillary part. The porous part is made by salt reaching method. When the SWA pad adsorbs to the wall which some sand and dust are attached, water comes from the porous part to avoid vacuum breaking. The capillary part is connected to the porous part to supply and stock the water. In this paper, we show the design of the porous part and the capillary part, fabrication process of each parts, and perform the evaluation experiment of the capillary force and adsorption of uneven surfaces, demonstration of wall climbing robot and adsorption of irregular surface foods.
ER  - 

TY  - CONF
TI  - Effects of Foot Stiffness and Damping on Walking Robot Performance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3698
EP  - 3704
AU  - E. Schumann
AU  - N. Smit-Anseeuw
AU  - P. Zaytsev
AU  - R. Gleason
AU  - K. A. Shorter
AU  - C. D. Remy
PY  - 2019
KW  - damping
KW  - legged locomotion
KW  - robot dynamics
KW  - stability
KW  - foot stiffness
KW  - robot performance
KW  - damping properties
KW  - soft robotic feet
KW  - stability
KW  - energetic economy
KW  - bipedal robotic walking
KW  - hollow rubber
KW  - damping values
KW  - drop test rig
KW  - planar bipedal robot RAM
KW  - mechanical energy
KW  - walking speeds
KW  - foot properties
KW  - spherical feet
KW  - walking instability
KW  - Foot
KW  - Legged locomotion
KW  - Damping
KW  - Rubber
KW  - Soft robotics
KW  - Animals
DO  - 10.1109/ICRA.2019.8794050
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we investigated how the stiffness and damping properties of soft robotic feet affect the stability and energetic economy of bipedal robotic walking. To this end, we manufactured four different spherical feet from the following materials: hollow rubber, Sorbothane, Norsorex, and Neoprene. The materials were specifically chosen to cover a wide range of stiffness and damping values. The impact response of each design was first characterized in a drop test rig. We then evaluated the performance of each foot in an extensive series of walking experiments on the planar bipedal robot RAM one. Our results showed that, at low speeds, the feet with lower damping had a smaller energy cost of walking, possibly due to greater return of mechanical energy at lift-off. However, at speeds above 0.5m\s, the feet with lower damping started to exhibit a bouncing behaviour which led to higher walking instability and increased the energy cost of walking. Additionally, we found the feet with lower stiffness to be more economical across all walking speeds. Our results provide insight into the role of foot properties in bipedal walking and may help with the design of walking robots.
ER  - 

TY  - CONF
TI  - Dynamic Walking on Slippery Surfaces : Demonstrating Stable Bipedal Gaits with Planned Ground Slippage*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3705
EP  - 3711
AU  - W. Ma
AU  - Y. Or
AU  - A. D. Ames
PY  - 2019
KW  - legged locomotion
KW  - nonlinear control systems
KW  - optimisation
KW  - robot dynamics
KW  - stability
KW  - stick-slip
KW  - trajectory control
KW  - lubricated surface
KW  - rough no-slip surface
KW  - foot slippage
KW  - slippery surfaces
KW  - stable bipedal gaits
KW  - planned ground slippage
KW  - dynamic bipedal robot locomotion
KW  - trajectory generation
KW  - nonlinear control
KW  - stabilization
KW  - low-friction surfaces
KW  - outdoor terrains
KW  - trajectory optimization
KW  - stick-slip transitions
KW  - point foot contact
KW  - Coulomb's friction law
KW  - slippery walking gait
KW  - AMBER-3M planar biped robot
KW  - dynamic walking
KW  - robot stance foot
KW  - Legged locomotion
KW  - Foot
KW  - Friction
KW  - Dynamics
KW  - Rough surfaces
KW  - Surface roughness
DO  - 10.1109/ICRA.2019.8793761
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dynamic bipedal robot locomotion has achieved remarkable success due in part to recent advances in trajectory generation and nonlinear control for stabilization. A key assumption utilized in both theory and experiments is that the robot's stance foot always makes no-slip contact with the ground, including at impacts. This assumption breaks down on slippery low-friction surfaces, as commonly encountered in outdoor terrains, leading to failure and loss of stability. In this work, we extend the theoretical analysis and trajectory optimization to account for stick-slip transitions at point foot contact using Coulomb's friction law. Using AMBER-3M planar biped robot as an experimental platform, we demonstrate for the first time a slippery walking gait which can be stabilized successfully both on a lubricated surface and on a rough no-slip surface. We also study the influence of foot slippage on reducing the mechanical cost of transport, and compare energy efficiency in both numerical simulation and experimental measurement.
ER  - 

TY  - CONF
TI  - Torque and velocity controllers to perform jumps with a humanoid robot: theory and implementation on the iCub robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3712
EP  - 3718
AU  - F. Bergonti
AU  - L. Fiorio
AU  - D. Pucci
PY  - 2019
KW  - angular velocity control
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - torque control
KW  - torque controller
KW  - velocity controller
KW  - velocity controllers
KW  - iCub robot
KW  - jumping
KW  - iCub humanoid robot
KW  - optimization
KW  - predefined CoM trajectory
KW  - centroidal angular momentum
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Trajectory
KW  - Angular velocity
KW  - Optimization
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794142
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Jumping can be an effective way of locomotion to overcome small terrain gaps or obstacles. In this paper we propose two different approaches to perform jumps with a humanoid robot. Specifically, starting from a pre-defined CoM trajectory we develop the theory for a velocity controller and for a torque controller based on an optimization technique for the evaluation of the joints input. The controllers have been tested both in simulation and on the humanoid robot iCub. In simulation the robot was able to jump using both controllers, while the real system jumped with the velocity controller only. The results highlight the importance of controlling the centroidal angular momentum and they suggest that the joint performances, namely maximum power, of the legs and torso joints, and the low level control performances are fundamental to achieve acceptable results.
ER  - 

TY  - CONF
TI  - Safe Adaptive Switching among Dynamical Movement Primitives: Application to 3D Limit-Cycle Walkers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3719
EP  - 3725
AU  - S. Veer
AU  - I. Poulakakis
PY  - 2019
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - robot dynamics
KW  - safe adaptive switching
KW  - dynamical movement primitives
KW  - robot motion plans
KW  - 3D bipedal robot model
KW  - dynamic movement primitives
KW  - primitive movements
KW  - limit-cycle walking gait
KW  - control-theoretic tools
KW  - Switches
KW  - Limit-cycles
KW  - Safety
KW  - Task analysis
KW  - Legged locomotion
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8793519
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Complex robot motions are frequently generated by composing simpler primitive movements. We use this approach to formulate robot motion plans as sequences of primitives to be executed one after the other. When dealing with dynamical movement primitives, besides accomplishing the high-level objective, planners must also reason about the effect of the plan's execution on the safety of the platform. This task is exacerbated by the presence of disturbances, such as non-vanishing external forces. To address this issue, we present a framework that builds on rigorous control-theoretic tools to generate safely executable motion plans for externally excited robotic systems. We illustrate the proposed framework on adapting the motion of a 3D bipedal robot model to persistent external forcing by switching among dynamic movement primitives, each corresponding to a limit-cycle walking gait.
ER  - 

TY  - CONF
TI  - Interactive Open-Ended Object, Affordance and Grasp Learning for Robotic Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3747
EP  - 3753
AU  - S. H. Kasaei
AU  - N. Shafii
AU  - L. S. Lopes
AU  - A. M. Tomé
PY  - 2019
KW  - dexterous manipulators
KW  - end effectors
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - position control
KW  - robot vision
KW  - service robots
KW  - human-centric environments
KW  - end-effector positions
KW  - affordance category
KW  - grasp configuration
KW  - Bayesian approach
KW  - learning recognition
KW  - object categories
KW  - instance-based approach
KW  - robotic manipulation
KW  - service robots
KW  - object perception
KW  - grasp affordances
KW  - training data
KW  - batch learning
KW  - end-effector orientations
KW  - Task analysis
KW  - Three-dimensional displays
KW  - Education
KW  - Object detection
KW  - Object recognition
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794184
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Service robots are expected to autonomously and efficiently work in human-centric environments. For this type of robots, object perception and manipulation are challenging tasks due to need for accurate and real-time response. This paper presents an interactive open-ended learning approach to recognize multiple objects and their grasp affordances concurrently. This is an important contribution in the field of service robots since no matter how extensive the training data used for batch learning, a robot might always be confronted with an unknown object when operating in human-centric environments. The paper describes the system architecture and the learning and recognition capabilities. Grasp learning associates grasp configurations (i.e., end-effector positions and orientations) to grasp affordance categories. The grasp affordance category and the grasp configuration are taught through verbal and kinesthetic teaching, respectively. A Bayesian approach is adopted for learning and recognition of object categories and an instance-based approach is used for learning and recognition of affordance categories. An extensive set of experiments has been performed to assess the performance of the proposed approach regarding recognition accuracy, scalability and grasp success rate on challenging datasets and real-world scenarios.
ER  - 

TY  - CONF
TI  - A parallel low-impedance sensing approach for highly responsive physical human-robot interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3754
EP  - 3760
AU  - G. Boucher
AU  - T. Laliberté
AU  - C. Gosselin
PY  - 2019
KW  - dexterous manipulators
KW  - end effectors
KW  - human-robot interaction
KW  - human-robot interaction
KW  - serial robotic arm
KW  - macro-mini robot architecture
KW  - general multidegree-of-freedom serial robot
KW  - five-degree-of-freedom robotic arm
KW  - low-impedance sensing approach
KW  - impedance control scheme
KW  - Robot sensing systems
KW  - Impedance
KW  - Manipulators
KW  - Robot kinematics
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793849
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel sensing approach for the physical interaction between a human user and a serial robotic arm. The approach is inspired from the concept of macro-mini robot architecture. The framework is developed for a general multi-degree-of-freedom serial robot and a corresponding impedance control scheme is proposed. In order to illustrate the concept, a five-degree-of-freedom robotic arm was built as well as a six-degree-of-freedom low-impedance sensing device that is used to control the robot. Experimental results are provided.
ER  - 

TY  - CONF
TI  - Safe Human Robot Cooperation in Task Performed on the Shared Load
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3761
EP  - 3767
AU  - M. Anvaripour
AU  - M. Khoshnam
AU  - C. Menon
AU  - M. Saif
PY  - 2019
KW  - collision avoidance
KW  - human-robot interaction
KW  - industrial robots
KW  - motion control
KW  - neurocontrollers
KW  - robot dynamics
KW  - human-robot collaboration
KW  - safety framework
KW  - force myography data
KW  - human worker
KW  - human muscles
KW  - FMG signal
KW  - robot dynamics
KW  - robot motion
KW  - neural network
KW  - industrial settings
KW  - collision avoidance
KW  - Force
KW  - Robot kinematics
KW  - Muscles
KW  - Dynamics
KW  - Task analysis
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794176
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Human-robot collaboration in industrial settings calls for implementing safety measures to ensure there is no risk to humans working in such an environment. In human-robot physical collaboration, an object or a load is handled by both human and the robot. Developing a safety framework for the robot is a requirement for preventing collisions during performing a task. In this paper, force myography (FMG) data are used to develop a control scheme for the robot such that it can work with the human worker while avoiding collisions. Force myography quantifies the activities of human muscles when applying forces to handle an object. A neural network-based approach is then used to select the most informative features of the FMG signal. The developed control scheme incorporates the FMG data and the robot dynamics to obtain a prediction about the next step of the cooperation task and to plan the robot motion accordingly. The proposed approach is evaluated experimentally in real time in a moving objects task which requires appropriate complementary actions from the robot and the human user. The results of this study show that the proposed scheme can successfully plan the robot motion based on the actions of the human user.
ER  - 

TY  - CONF
TI  - A Multi-modal Sensor Array for Safe Human-Robot Interaction and Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3768
EP  - 3774
AU  - C. Abah
AU  - A. L. Orekhov
AU  - G. L. H. Johnston
AU  - P. Yin
AU  - H. Choset
AU  - N. Simaan
PY  - 2019
KW  - electric sensing devices
KW  - end effectors
KW  - force sensors
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - sensor arrays
KW  - multimodal sensor array
KW  - safe human-robot interaction
KW  - time-of-flight sensors
KW  - accidental contact detection
KW  - contact localization
KW  - force sensing
KW  - proximity sensing
KW  - proximity mapping
KW  - Hall effect
KW  - collaborative continuum robot
KW  - bracing constraint
KW  - admissible rolling motion
KW  - end effector
KW  - I2C communication network
KW  - Robot sensing systems
KW  - Force
KW  - Sensor arrays
KW  - Hall effect
KW  - Multiplexing
KW  - Robot perception
KW  - Collaborative robots
KW  - Continuum robots
KW  - Bracing
KW  - Mapping
DO  - 10.1109/ICRA.2019.8793466
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In the future, human-robot interaction will include collaboration in close-quarters where the environment geometry is partially unknown. As a means for enabling such interaction, this paper presents a multi-modal sensor array capable of contact detection and localization, force sensing, proximity sensing, and mapping. The sensor array integrates Hall effect and time-of-flight (ToF) sensors in an I2C communication network. The design, fabrication, and characterization of the sensor array for a future in-situ collaborative continuum robot are presented. Possible perception benefits of the sensor array are demonstrated for accidental contact detection, mapping of the environment, selection of admissible zones for bracing, and constrained motion control of the end effector while maintaining a bracing constraint with an admissible rolling motion.
ER  - 

TY  - CONF
TI  - Dynamic Primitives in Human Manipulation of Non-Rigid Objects
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3783
EP  - 3789
AU  - H. Guang
AU  - S. Bazzi
AU  - D. Sternad
AU  - N. Hogan
PY  - 2019
KW  - biomechanics
KW  - human-robot interaction
KW  - learning systems
KW  - manipulator dynamics
KW  - motion control
KW  - optimisation
KW  - pendulums
KW  - position control
KW  - sloshing
KW  - human manipulation
KW  - nonrigid objects
KW  - liquid sloshing
KW  - horizontal line
KW  - virtual environment
KW  - human subjects
KW  - robotic manipulandum
KW  - residual oscillations
KW  - humans simplified control
KW  - human movements
KW  - continuous optimization-based control
KW  - control model
KW  - flexible objects
KW  - motion profile
KW  - human profiles
KW  - robot control
KW  - input shaping model
KW  - cart-and-pendulum system
KW  - Task analysis
KW  - Mathematical model
KW  - Oscillators
KW  - Trajectory
KW  - Robots
KW  - Predictive models
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793687
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study examined strategies humans chose to manipulate an object with complex (nonlinear, underactuated) dynamics, such as liquid sloshing in a cup of coffee. The problem was simplified to the well-known cart-and-pendulum system moving on a horizontal line. This model was implemented in a virtual environment and human subjects manipulated the object via a robotic manipulandum. The task was to maneuver the system from rest to arrive at a target position such that no residual oscillations of the pendulum bob remained. Our goal was to test whether humans simplified control by employing dynamic primitives, specifically submovements. Experimental velocity profiles of the human movements were compared to those predicted by three different control models. Two models used continuous optimization-based control, the third control model was based on Input Shaping. Input Shaping is a method for controlling flexible objects by convolving a motion profile with impulses of appropriate amplitude and timing. To evaluate whether humans used Input Shaping, we decomposed the velocity profiles recorded from humans into submovements, as proxies for the convolved impulses. Comparing the motion profiles from the 3 models with the experimentally measured human profiles showed superior performance of the Input Shaping model. These initial results are consistent with our hypothesis that combining dynamic primitives, submovements, is a competent description of human performance and may provide a simpler alternative to computationally complex optimization-based methods of robot control.
ER  - 

TY  - CONF
TI  - State Estimation in Contact-Rich Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3790
EP  - 3796
AU  - F. Wirnshofer
AU  - P. S. Schmitt
AU  - P. Meister
AU  - G. v. Wichert
AU  - W. Burgard
PY  - 2019
KW  - Bayes methods
KW  - manipulator dynamics
KW  - multi-robot systems
KW  - robot kinematics
KW  - robot vision
KW  - state estimation
KW  - torque control
KW  - complex manipulation scenario
KW  - state estimation
KW  - Bayesian state estimator
KW  - nonprehensile manipulation
KW  - industrial assembly
KW  - in-hand localization
KW  - contact dynamics
KW  - torque-based robot controller
KW  - robot kinematics
KW  - multiple robots
KW  - articulated objects
KW  - physical robot
KW  - freedom object
KW  - multimodal distributions
KW  - Dynamics
KW  - Computational modeling
KW  - Manipulators
KW  - Bayes methods
KW  - Estimation
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2019.8793572
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces a Bayesian state estimator for contact-rich manipulation tasks with application in non-prehensile manipulation, industrial assembly or in-hand localization. The core idea of our approach is to explicitly model both the contact dynamics and a torque-based robot controller as part of the underlying system model. Our approach is capable of estimating the state of movable objects for various robot kinematics and geometries of robots and objects. This includes complex scenarios with multiple robots, multiple objects and articulated objects. We have validated our approach in simulation and on a physical robot. The experiments show that multimodal distributions of six degrees of freedom object poses can be accurately tracked in real-time in a complex manipulation scenario.
ER  - 

TY  - CONF
TI  - Improved Proximity, Contact, and Force Sensing via Optimization of Elastomer-Air Interface Geometry
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3797
EP  - 3803
AU  - P. E. Lancaster
AU  - J. R. Smith
AU  - S. S. Srinivasa
PY  - 2019
KW  - distance measurement
KW  - elastomers
KW  - force measurement
KW  - force sensors
KW  - manipulators
KW  - object detection
KW  - optical sensors
KW  - optimisation
KW  - force sensing
KW  - elastomer-air interface geometry
KW  - robot manipulation
KW  - contact detection
KW  - signal-to-noise ratio
KW  - elastomer-air boundary
KW  - deformation measurement
KW  - distance measurement
KW  - contact force measurement
KW  - proximity sensor design
KW  - contact sensor design
KW  - optimization
KW  - single fingertip-mounted sensing system
KW  - optical time-of-flight range measurement modules
KW  - object detection
KW  - emitted light path control
KW  - Robot sensing systems
KW  - Receivers
KW  - Force
KW  - Force measurement
KW  - Optical sensors
DO  - 10.1109/ICRA.2019.8793959
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We describe a single fingertip-mounted sensing system for robot manipulation that provides proximity (pre-touch), contact detection (touch), and force sensing (post-touch). The sensor system consists of optical time-of-flight range measurement modules covered in a clear elastomer. Because the elastomer is clear, the sensor can detect and range nearby objects, as well as measure deformations caused by objects that are in contact with the sensor and thereby estimate the applied force. We examine how this sensor design can be improved with respect to invariance to object reflectivity, signal-to-noise ratio, and continuous operation when switching between the distance and force measurement regimes. By harnessing time-of-flight technology and optimizing the elastomer-air boundary to control the emitted light's path, we develop a sensor that is able to seamlessly transition between measuring distances of up to 50 mm and contact forces of up to 10 newtons. We demonstrate that our sensor improves manipulation accuracy in a block unstacking task. Thorough instructions for manufacturing the sensor from inexpensive, commercially available components are provided, as well as all relevant hardware design files and software sources.
ER  - 

TY  - CONF
TI  - Improving Haptic Adjective Recognition with Unsupervised Feature Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3804
EP  - 3810
AU  - B. A. Richardson
AU  - K. J. Kuchenbecker
PY  - 2019
KW  - feature extraction
KW  - image classification
KW  - iterative methods
KW  - unsupervised learning
KW  - unsupervised feature learning
KW  - densely innervated skin
KW  - haptics researchers
KW  - haptic intelligence
KW  - concrete tasks
KW  - object recognition
KW  - feature learning methods
KW  - haptic adjectives
KW  - diverse interactions
KW  - abstract binary classification tasks
KW  - spatio-temporal hierarchical matching pursuit
KW  - haptic adjective recognition
KW  - Haptic interfaces
KW  - Feature extraction
KW  - Task analysis
KW  - Dictionaries
KW  - Matching pursuit algorithms
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793544
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humans can form an impression of how a new object feels simply by touching its surfaces with the densely innervated skin of the fingertips. Many haptics researchers have recently been working to endow robots with similar levels of haptic intelligence, but these efforts almost always employ hand-crafted features, which are brittle, and concrete tasks, such as object recognition. We applied unsupervised feature learning methods, specifically K-SVD and Spatio-Temporal Hierarchical Matching Pursuit (ST-HMP), to rich multi-modal haptic data from a diverse dataset. We then tested the learned features on 19 more abstract binary classification tasks that center on haptic adjectives such as smooth and squishy. The learned features proved superior to traditional hand-crafted features by a large margin, almost doubling the average F1 score across all adjectives. Additionally, particular exploratory procedures (EPs) and sensor channels were found to support perception of certain haptic adjectives, underlining the need for diverse interactions and multi-modal haptic data.
ER  - 

TY  - CONF
TI  - Tactile Mapping and Localization from High-Resolution Tactile Imprints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3811
EP  - 3817
AU  - M. Bauza
AU  - O. Canal
AU  - A. Rodriguez
PY  - 2019
KW  - haptic interfaces
KW  - manipulators
KW  - tactile sensors
KW  - high-resolution tactile imprints
KW  - shape reconstruction
KW  - object localization
KW  - vision-based tactile sensor
KW  - local shapes
KW  - reconstructed objects
KW  - tactile sensing
KW  - tactile feedback
KW  - online object identification
KW  - Shape
KW  - Image reconstruction
KW  - Tactile sensors
KW  - Three-dimensional displays
KW  - Estimation
DO  - 10.1109/ICRA.2019.8794298
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work studies the problem of shape reconstruction and object localization using a vision-based tactile sensor, GelSlim. The main contributions are the recovery of local shapes from contact, an approach to reconstruct the tactile shape of objects from tactile imprints, and an accurate method for object localization of previously reconstructed objects. The algorithms can be applied to a large variety of 3D objects and provide accurate tactile feedback for in-hand manipulation. Results show that by exploiting the dense tactile information we can reconstruct the shape of objects with high accuracy and do on-line object identification and localization, opening the door to reactive manipulation guided by tactile sensing. We provide videos and supplemental information in the project's website web.mit.edu/mcube/research/tactile localization.html.
ER  - 

TY  - CONF
TI  - Maintaining Grasps within Slipping Bounds by Monitoring Incipient Slip
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3818
EP  - 3824
AU  - S. Dong
AU  - D. Ma
AU  - E. Donlon
AU  - A. Rodriguez
PY  - 2019
KW  - dexterous manipulators
KW  - force control
KW  - grippers
KW  - slip
KW  - tactile sensors
KW  - grasped object
KW  - sensor surface
KW  - 2D rigid-body motion
KW  - motion field
KW  - 2D planar rigid transformation
KW  - dense slip field
KW  - highly deformable objects
KW  - slip feedback
KW  - monitoring incipient slip
KW  - high-resolution vision-based tactile sensor
KW  - tactile imprints
KW  - detection accuracy
KW  - frequency 24.0 Hz
KW  - Force
KW  - Tactile sensors
KW  - Grasping
KW  - Cameras
DO  - 10.1109/ICRA.2019.8793538
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose an approach to detect incipient slip, i.e. predict slip, by using a high-resolution vision-based tactile sensor, GelSlim. The sensor dynamically captures the tactile imprints of the grasped object and their changes with a soft gel pad. The method assumes the object is mostly rigid and expects the motion of object's imprint on the sensor surface to be a 2D rigid-body motion. We use the deviation of the true motion field from that of a 2D planar rigid transformation as a measure of slip. The output is a dense slip field which we monitor in real time to detect when small areas of the contact patch start to slip (incipient slip). The method can detect incipient slip in any direction without any prior knowledge of the object at 24 Hz. We test the method on 10 objects for 240 times and achieve 86.25% detection accuracy with the vast majority of failure cases occurring when grasping highly deformable objects. We further show how the slip feedback can be used to adjust the gripping force to avoid slip with a closed-loop bottle-cap screwing and unscrewing experiment. The method can be used to enable many manipulation tasks in both structured and unstructured environments.
ER  - 

TY  - CONF
TI  - Road Detection through CRF based LiDAR-Camera Fusion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3832
EP  - 3838
AU  - S. Gu
AU  - Y. Zhang
AU  - J. Tang
AU  - J. Yang
AU  - H. Kong
PY  - 2019
KW  - cameras
KW  - convolutional neural nets
KW  - image colour analysis
KW  - image fusion
KW  - image sampling
KW  - object detection
KW  - optical radar
KW  - KITTI-Road dataset
KW  - CRF based LiDAR-camera fusion
KW  - road detection method
KW  - color information
KW  - camera image domain
KW  - CRF fusion method
KW  - conditional random field framework
KW  - binary road detection
KW  - dense road detection
KW  - LiDAR-camera calibration
KW  - height-difference based scanning strategy
KW  - convolutional network
KW  - Laser radar
KW  - Roads
KW  - Cameras
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Image segmentation
KW  - Transforms
DO  - 10.1109/ICRA.2019.8793585
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a road detection method with LiDAR-camera fusion in a novel conditional random field (CRF) framework to exploit both range and color information. In the LiDAR based part, a fast height-difference based scanning strategy is applied in the 2D LiDAR range-image domain and a dense road detection result in camera image domain can be obtained through geometric upsampling given the LiDAR-camera calibration parameters. In the camera based part, a fully convolutional network is applied in the camera image domain. Finally, we fuse the dense and binary road detection results from both LiDAR and camera in a single CRF framework. Experiments show that using a single thread of CPU, the proposed LiDAR based part can operate at a frequency of over 250Hz with sparse output in range image and 40Hz with dense result in camera image for the 64-beam Velodyne scanner. Our CRF fusion method achieves very promising road detection performance on the KITTI-Road dataset.
ER  - 

TY  - CONF
TI  - Semantic mapping extension for OpenStreetMap applied to indoor robot navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3839
EP  - 3845
AU  - L. Naik
AU  - S. Blumenthal
AU  - N. Huebel
AU  - H. Bruyninckx
AU  - E. Prassler
PY  - 2019
KW  - graph theory
KW  - mobile robots
KW  - path planning
KW  - OpenStreetMap
KW  - geometrical information
KW  - basic indoor structures
KW  - architectural principles
KW  - application-specific knowledge
KW  - graph-based map representation
KW  - hierarchical structure
KW  - semantic mapping extension
KW  - indoor robot navigation
KW  - grid-based motion planning algorithms
KW  - Robots
KW  - Semantics
KW  - Data models
KW  - Geometry
KW  - Navigation
KW  - Indoor environment
KW  - Tagging
DO  - 10.1109/ICRA.2019.8793641
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work a graph-based, semantic mapping approach for indoor robotics applications is presented, which is extending OpenStreetMap (OSM) with robotic-specific, semantic, topological, and geometrical information. Models are introduced for basic indoor structures such as walls, doors, corridors, elevators, etc. The architectural principles support composition with additional domain and application-specific knowledge. As an example, a model for an area is introduced, and it is explained how this can be used in navigation. A key advantage of the proposed graph-based map representation is that it allows exploiting the hierarchical structure of the graphs. Finally, the compatibility of the approach with existing, grid-based motion planning algorithms is shown.
ER  - 

TY  - CONF
TI  - Adaptive Probabilistic Vehicle Trajectory Prediction Through Physically Feasible Bayesian Recurrent Neural Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3846
EP  - 3852
AU  - C. Tang
AU  - J. Chen
AU  - M. Tomizuka
PY  - 2019
KW  - Bayes methods
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - probability
KW  - recurrent neural nets
KW  - stochastic processes
KW  - traffic engineering computing
KW  - Bayesian recurrent neural network
KW  - prediction horizon
KW  - target human driver
KW  - naturalistic car following data
KW  - multimodal stochastic feedback gain
KW  - particle-filter-based parameter adaptation algorithm
KW  - adopted gradient-based training method
KW  - embedded physical model
KW  - trajectory distribution
KW  - Bayesian-neural-network-based policy model
KW  - Bayesian recurrent neural network model
KW  - driving policy
KW  - predicted distribution
KW  - physical feasibility
KW  - long-term trajectory prediction
KW  - autonomous driving
KW  - robust safety
KW  - adaptive probabilistic vehicle trajectory prediction
KW  - Trajectory
KW  - Adaptation models
KW  - Probabilistic logic
KW  - Bayes methods
KW  - Vehicle dynamics
KW  - Vehicles
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8794130
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Probabilistic vehicle trajectory prediction is essential for robust safety of autonomous driving. Current methods for long-term trajectory prediction cannot guarantee the physical feasibility of predicted distribution. Moreover, their models cannot adapt to the driving policy of the predicted target human driver. In this work, we propose to overcome these two shortcomings by a Bayesian recurrent neural network model consisting of Bayesian-neural-network-based policy model and known physical model of the scenario. Bayesian neural network can ensemble complicated output distribution, enabling rich family of trajectory distribution. The embedded physical model ensures feasibility of the distribution. Moreover, the adopted gradient-based training method allows direct optimization for better performance in long prediction horizon. Furthermore, a particle-filter-based parameter adaptation algorithm is designed to adapt the policy Bayesian neural network to the predicted target online. Effectiveness of the proposed methods is verified with a toy example with multi-modal stochastic feedback gain and naturalistic car following data.
ER  - 

TY  - CONF
TI  - Optimizing Vehicle Distributions and Fleet Sizes for Shared Mobility-on-Demand
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3853
EP  - 3859
AU  - A. Wallar
AU  - J. Alonso-Mora
AU  - D. Rus
PY  - 2019
KW  - optimisation
KW  - road vehicles
KW  - traffic engineering computing
KW  - transportation
KW  - optimizing vehicle distributions
KW  - fleet sizes
KW  - urban transit
KW  - ride-sharing
KW  - vehicle congestion
KW  - multiple passengers
KW  - historical demand data
KW  - MoD systems
KW  - travel demand
KW  - taxi demand
KW  - shared mobility-on-demand systems
KW  - taxi requests
KW  - city's transportation infrastructure
KW  - four passenger vehicles
KW  - Schedules
KW  - Delays
KW  - Urban areas
KW  - Public transportation
KW  - Cost function
KW  - Automation
DO  - 10.1109/ICRA.2019.8793685
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mobility-on-demand (MoD) systems are revolutionizing urban transit with the introduction of ride-sharing. Such systems have the potential to reduce vehicle congestion and improve accessibility of a city's transportation infrastructure. Recently developed algorithms can compute routes for vehicles in real-time for a city-scale volume of requests while allowing vehicles to carry multiple passengers at the same time. However, these algorithms focus on optimizing the performance for a given fleet of vehicles and do not tell us how many vehicles are needed to service all the requests. In this paper, we present an offline method to optimize the vehicle distributions and fleet sizes on historical demand data for MoD systems that allow passengers to share vehicles. We present an algorithm to determine how many vehicles are needed, where they should be initialized, and how they should be routed to service all the travel demand for a given period of time. Evaluation using 23,529,740 historical taxi requests from one month in Manhattan shows that on average 2864 four passenger vehicles are needed to service all of the taxi demand in a day with an average added travel delay of 2.8 mins.
ER  - 

TY  - CONF
TI  - Global Vision-Based Reconstruction of Three-Dimensional Road Surfaces Using Adaptive Extended Kalman Filter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3860
EP  - 3866
AU  - D. Li
AU  - T. Furukawa
PY  - 2019
KW  - adaptive Kalman filters
KW  - cameras
KW  - computer vision
KW  - image filtering
KW  - image reconstruction
KW  - nonlinear filters
KW  - pose estimation
KW  - road safety
KW  - traffic engineering computing
KW  - AEKF
KW  - local road surface reconstruction techniques
KW  - on-road test
KW  - global vision-based reconstruction
KW  - three-dimensional road surfaces
KW  - vision-based technique
KW  - adaptive extended Kalman filter
KW  - global camera pose estimation
KW  - real-world global 3D road surface reconstruction
KW  - Roads
KW  - Surface reconstruction
KW  - Cameras
KW  - Image reconstruction
KW  - Uncertainty
KW  - Global Positioning System
KW  - Kalman filters
DO  - 10.1109/ICRA.2019.8794039
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a vision-based technique and a system developed for the global reconstruction of three-dimensional (3-D) road surfaces. Using the system, the technique globally reconstructs 3-D road surfaces by estimating the global camera pose using the Adaptive Extended Kalman Filter (AEKF) and integrating it with existing local road surface reconstruction techniques. The AEKF adaptively updates the covariance of uncertainties such that the estimation works well even in environments with varying uncertainties. Numerical results show the efficacy of the proposed technique over the Extended Kalman Filter (EKF)-based technique by 50% in accuracy, and the on-road test has demonstrated the ability of the proposed technique for the real-world global 3-D road surface reconstruction.
ER  - 


TY  - CONF
TI  - Autonomous Tissue Manipulation via Surgical Robot Using Learning Based Model Predictive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3875
EP  - 3881
AU  - C. Shin
AU  - P. W. Ferguson
AU  - S. A. Pedram
AU  - J. Ma
AU  - E. P. Dutson
AU  - J. Rosen
PY  - 2019
KW  - biological tissues
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - medical robotics
KW  - mobile robots
KW  - predictive control
KW  - robot vision
KW  - surgery
KW  - autonomous tissue manipulation
KW  - soft tissue
KW  - AI learning
KW  - vision strategies
KW  - Raven IV surgical robotic system
KW  - predictive control algorithms
KW  - reinforcement learning
KW  - Robots
KW  - Heuristic algorithms
KW  - Prediction algorithms
KW  - Surgery
KW  - Neural networks
KW  - Task analysis
KW  - Aerospace electronics
KW  - Robotic Tissue Manipulation
KW  - Reinforcement Learning
KW  - Learning from Demonstration
KW  - Neural Networks
KW  - Simulation
KW  - Surgery
KW  - Automation
KW  - Machine Learning
KW  - Artificial Intelligence
KW  - AI
KW  - Raven Surgical Robot
KW  - Medical Robotics
DO  - 10.1109/ICRA.2019.8794159
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Tissue manipulation is a frequently used fundamental subtask of any surgical procedures, and in some cases it may require the involvement of a surgeon's assistant. The complex dynamics of soft tissue as an unstructured environment is one of the main challenges in any attempt to automate the manipulation of it via a surgical robotic system. Two AI learning based model predictive control algorithms using vision strategies are proposed and studied: (1) reinforcement learning and (2) learning from demonstration. Comparison of the performance of these AI algorithms in a simulation setting indicated that the learning from demonstration algorithm can boost the learning policy by initializing the predicted dynamics with given demonstrations. Furthermore, the learning from demonstration algorithm is implemented on a Raven IV surgical robotic system and successfully demonstrated feasibility of the proposed algorithm using an experimental approach. This study is part of a profound vision in which the role of a surgeon will be redefined as a pure decision maker whereas the vast majority of the manipulation will be conducted autonomously by a surgical robotic system. A supplementary video can be found at: http://bionics.seas.ucla.edu/research/surgeryproject17.html.
ER  - 

TY  - CONF
TI  - Robotic Control of a Multi-Modal Rigid Endoscope Combining Optical Imaging with All-Optical Ultrasound
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3882
EP  - 3888
AU  - G. Dwyer
AU  - R. J. Colchester
AU  - E. J. Alles
AU  - E. Maneas
AU  - S. Ourselin
AU  - T. Vercauteren
AU  - J. Deprest
AU  - E. V. Poorten
AU  - P. D. Coppi
AU  - A. E. Desjardins
AU  - D. Stoyanov
PY  - 2019
KW  - biomedical optical imaging
KW  - biomedical ultrasonics
KW  - cameras
KW  - endoscopes
KW  - medical robotics
KW  - optical sensors
KW  - phantoms
KW  - ultrasonic transducers
KW  - spiral scan
KW  - placenta phantom
KW  - white light stereo camera
KW  - robotic multimodal endoscope
KW  - low diameter endoscopes
KW  - dynamic environment
KW  - technically challenging surgery
KW  - fetoscopy
KW  - all-optical ultrasound
KW  - optical imaging
KW  - multimodal rigid endoscope
KW  - robotic control
KW  - surface visualisations
KW  - optical ultrasound sensor
KW  - Endoscopes
KW  - Ultrasonic imaging
KW  - Optical imaging
KW  - Optical sensors
KW  - Cameras
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794289
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fetoscopy is a technically challenging surgery, due to the dynamic environment and low diameter endoscopes often resulting in a limited field of view. In this paper, we report on the design and operation of a robotic multimodal endoscope with optical ultrasound and white light stereo camera. The manufacture and control of the endoscope is presented, along with large area (80 mm ×80 mm) surface visualisations of a placenta phantom using the optical ultrasound sensor. The repeatability of the surface visualisations was found to be 0. 446 ± 0.139 mm and 0. 267 ± 0.017 mm for a raster and spiral scan, respectively.
ER  - 

TY  - CONF
TI  - Enabling Technology for Safe Robot-Assisted Retinal Surgery: Early Warning for Unsafe Scleral Force
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3889
EP  - 3894
AU  - C. He
AU  - N. Patel
AU  - I. Iordachita
AU  - M. Kobilarov
PY  - 2019
KW  - calibration
KW  - eye
KW  - force sensors
KW  - manipulators
KW  - medical robotics
KW  - phantoms
KW  - surgery
KW  - manipulation task
KW  - early warning system
KW  - unsafe manipulation events
KW  - safe robot-assisted retinal surgery
KW  - unsafe scleral force
KW  - retinal microsurgery
KW  - high surgical skill
KW  - manipulation error
KW  - constant contact
KW  - unexpected manipulation
KW  - extreme tool-sclera contact force
KW  - robotic assistance
KW  - surgeon
KW  - potential intra-operative danger
KW  - robotic systems
KW  - imminent unsafe manipulation
KW  - sclera damage
KW  - force-sensing tool
KW  - unsafe events
KW  - steady hand eye robot
KW  - force safety status
KW  - Force
KW  - Surgery
KW  - Tools
KW  - Retina
KW  - Robot kinematics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794427
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Retinal microsurgery is technically demanding and requires high surgical skill with very little room for manipulation error. During surgery the tool needs to be inserted into the eyeball while maintaining constant contact with the sclera. Any unexpected manipulation could cause extreme tool-sclera contact force (scleral force) thus damage the sclera. The introduction of robotic assistance could enhance and expand the surgeon's manipulation capabilities during surgery. However, the potential intra-operative danger from surgeon's mis-operations remains difficult to detect and prevent by existing robotic systems. Therefore, we propose a method to predict imminent unsafe manipulation in robot-assisted retinal surgery and generate feedback to the surgeon via auditory substitution. The surgeon could then react to the possible unsafe events in advance. This work specifically focuses on minimizing sclera damage using a force-sensing tool calibrated to measure small scleral forces. A recurrent neural network is designed and trained to predict the force safety status up to 500 milliseconds in the future. The system is implemented using an existing “steady hand” eye robot. A vessel following manipulation task is designed and performed on a dry eye phantom to emulate the retinal surgery and to analyze the proposed method. Finally, preliminary validation experiments are performed by five users, the results of which indicate that the proposed early warning system could help to reduce the number of unsafe manipulation events.
ER  - 

TY  - CONF
TI  - Robotic bronchoscopy drive mode of the Auris Monarch platform*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3895
EP  - 3901
AU  - C. F. Graetzel
AU  - A. Sheehy
AU  - D. P. Noonan
PY  - 2019
KW  - biomechanics
KW  - cancer
KW  - computerised tomography
KW  - endoscopes
KW  - lung
KW  - manipulators
KW  - medical image processing
KW  - medical robotics
KW  - physiological models
KW  - safety algorithms
KW  - robotic bronchoscopy drive mode
KW  - Auris Monarch platform
KW  - lung cancer
KW  - ten degree-of-freedom bronchoscope
KW  - three degree-of-freedom user input
KW  - paired driving concept
KW  - tension monitoring
KW  - lung porcine models
KW  - Robot sensing systems
KW  - Bronchoscopy
KW  - Lung
KW  - Manipulators
KW  - Cancer
DO  - 10.1109/ICRA.2019.8793704
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic bronchoscopy has the potential to improve the early detection of lung cancer. For the technology to be broadly adopted, the physician needs to be able to control the robotic bronchoscope in an instinctive and effective manner. In this paper, we describe the algorithms used to manipulate/drive the Auris Monarch Platform, a 10 degree-of-freedom bronchoscope and sheath, using a 3 degree-of-freedom user input. We introduce the concept of paired driving where the devices co-insert and co-articulate depending on their relative insertion. The paper presents safety algorithms such as auto-relax on retract and tension monitoring. The drive modes were developed, optimized, and clinically tested in lung models, human cadavers and live porcine models prior to their commercial release. Clinical studies show that the physician is able to reach significantly deeper in the lung than with classic bronchoscopes.
ER  - 

TY  - CONF
TI  - Using comanipulation with active force feedback to undistort stiffness perception in laparoscopy
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3902
EP  - 3908
AU  - F. Schmitt
AU  - J. Sulub
AU  - I. Avellino
AU  - J. D. Silva
AU  - L. Barbé
AU  - O. Piccin
AU  - B. Bayle
AU  - G. Morel
PY  - 2019
KW  - force feedback
KW  - force measurement
KW  - medical computing
KW  - medical robotics
KW  - surgery
KW  - laparoscopic surgery
KW  - undistort stiffness perception
KW  - comanipulation paradigm
KW  - fulcrum
KW  - lever effect
KW  - laparoscopy
KW  - stiffness perception
KW  - active force feedback
KW  - preliminary assessment experiment
KW  - lever ratio
KW  - tool tip
KW  - surgeon
KW  - robotic device
KW  - Tools
KW  - Force
KW  - Robot sensing systems
KW  - Surgery
KW  - Instruments
KW  - Laparoscopes
DO  - 10.1109/ICRA.2019.8793662
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Surgeons performing laparoscopic surgery experience distortion when perceiving the stiffness of a patient's tissues. This is due to the lever effect induced by the introduction of instruments in their patient's body through a fulcrum. To address this problem, we propose to use the comanipulation paradigm. A robotic device is connected to the handle of the instrument while simultaneously being held by the surgeon. This device applies a force on the handle that reflects the force measured at the tool tip, with a gain that depends on the lever ratio. The implementation of this method is presented on an experimental setup and a preliminary assessment experiment is presented.
ER  - 

TY  - CONF
TI  - Stiffness-Tuneable Limb Segment with Flexible Spine for Malleable Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3969
EP  - 3975
AU  - A. B. Clark
AU  - N. Rojas
PY  - 2019
KW  - bending
KW  - design engineering
KW  - elasticity
KW  - finite element analysis
KW  - flexible structures
KW  - humanoid robots
KW  - manipulator kinematics
KW  - motion control
KW  - structural engineering
KW  - multimaterial spine-inspired flexible structure
KW  - stiffness-controllable layer-jamming-based robotic links
KW  - spine mechanism
KW  - robotic link
KW  - layer jamming
KW  - hollow structure
KW  - light structure
KW  - flexible spine
KW  - link utilising
KW  - limb segments
KW  - granular jamming
KW  - bending angles
KW  - stiffness-tuneable limb segment
KW  - malleable robots
KW  - robotic arms
KW  - stiffness-adjustable
KW  - bending segments
KW  - revolute joints
KW  - mechanical architecture
KW  - degrees of freedom
KW  - suitable links
KW  - robotic manipulators
KW  - reduced performance
KW  - structural deformation
KW  - inner support structure
KW  - increased stiffening performance
KW  - stiffening mechanisms
KW  - Jamming
KW  - Manipulators
KW  - Strain
KW  - Ligaments
KW  - Force
KW  - Service robots
DO  - 10.1109/ICRA.2019.8793713
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic arms built from stiffness-adjustable, continuously bending segments serially connected with revolute joints have the ability to change their mechanical architecture and workspace, thus allowing high flexibility and adaptation to different tasks with less than six degrees of freedom, a concept that we call malleable robots. Known stiffening mechanisms may be used to implement suitable links for these novel robotic manipulators; however, these solutions usually show a reduced performance when bending due to structural deformation. By including an inner support structure this deformation can be minimised, resulting in an increased stiffening performance. This paper presents a new multi-material spine-inspired flexible structure for providing support in stiffness-controllable layer-jamming-based robotic links of large diameter. The proposed spine mechanism is highly movable with type and range of motions that match those of a robotic link using solely layer jamming, whilst maintaining a hollow and light structure. The mechanics and design of the flexible spine are explored, and a prototype of a link utilising it is developed and compared with limb segments based on granular jamming and layer jamming without support structure. Results of experiments verify the advantages of the proposed design, demonstrating that it maintains a constant central diameter across bending angles and presents an improvement of more than 203% of resisting force at 180°.
ER  - 

TY  - CONF
TI  - A Reconfigurable Variable Stiffness Manipulator by a Sliding Layer Mechanism
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3976
EP  - 3982
AU  - D. C. F. Li
AU  - Z. Wang
AU  - B. Ouyang
AU  - Y. Liu
PY  - 2019
KW  - actuators
KW  - compliance control
KW  - elastic constants
KW  - honeycomb structures
KW  - manipulator dynamics
KW  - mechanical stability
KW  - medical robotics
KW  - surgery
KW  - sliding layer mechanism
KW  - interlocking jamming layers
KW  - reconfigurable variable stiffness manipulator
KW  - soft robots
KW  - variable stiffness mechanism
KW  - structural stability
KW  - manipulator
KW  - laparoscopic surgeries
KW  - Jamming
KW  - Manipulators
KW  - Tendons
KW  - Strips
KW  - Friction
KW  - Soft robotics
DO  - 10.1109/ICRA.2019.8793571
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Inherent compliance plays an enabling role in soft robots, which rely on it to mechanically conform to the environment. However, it also limits the payload of the robots. Various variable stiffness approaches have been adopted to limit compliance and provide structural stability, but most of them can only achieve stiffening of discrete fixed regions which means compliance cannot be precisely adjusted for different needs. This paper offers an approach to enhance the payload with finely adjusted compliance for different needs. We have developed a manipulator that incorporates a novel variable stiffness mechanism and a sliding layer mechanism. The variable stiffness mechanism can achieve a 6.4 stiffness changing ratio with a miniaturized size (10 mm diameter for the testing prototype) through interlocking jamming layers with a honeycomb core. The sliding layer mechanism can actively shift the position of the stiffening regions through sliding of jamming layers. A model to predict the robot shape is derived with verifications via an experiment. The stiffening capacity of the variable stiffness mechanism is also empirically evaluated. A case study of a potential application in laparoscopic surgeries is showcased. The payload of the manipulator is investigated, and the prototype shows up to 57.8 percentage decrease of the vertical deflection due to an external load after reconfigurations.
ER  - 

TY  - CONF
TI  - A Novel Variable Stiffness Actuator Based on Pneumatic Actuation and Supercoiled Polymer Artificial Muscles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3983
EP  - 3989
AU  - Y. Yang
AU  - Z. Kan
AU  - Y. Zhang
AU  - Y. A. Tse
AU  - M. Y. Wang
PY  - 2019
KW  - bending
KW  - control system synthesis
KW  - elastic constants
KW  - electroactive polymer actuators
KW  - pneumatic actuators
KW  - polymers
KW  - position control
KW  - pressure control
KW  - variable structure systems
KW  - supercoiled polymer artificial muscles
KW  - variable stiffness soft actuator
KW  - soft pneumatic actuation
KW  - muscle-like supercoiled polymer actuation
KW  - soft pneumatic actuator
KW  - SCP actuation
KW  - soft robot locomotion
KW  - soft robot manipulation
KW  - stiffness tuning
KW  - pressure control
KW  - SCP artificial muscle tension
KW  - Muscles
KW  - Pneumatic actuators
KW  - Soft robotics
KW  - Fabrication
KW  - Strain
DO  - 10.1109/ICRA.2019.8793844
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This article describes an innovative design of variable stiffness soft actuator, which can potentially be utilized for manipulation and locomotion of soft robots. The new actuator is a combination of two types of actuations: soft pneumatic actuation and muscle-like supercoiled polymer (SCP) actuation. Soft pneumatic actuator has two roles: first is to generate bending motions and second is to increase the stiffness of the whole actuator together with SCP artificial muscles. SCP artificial muscles are exploited to generate pre-load to resist the whole actuator from (excessive) deformation when external load is applied. These two types of actuations are arranged antagonistically to realize stiffness tuning of the whole actuator. At a given bending position, stiffness of the actuator could be tuned by controlling the pressure inside the air chamber and the tension on the SCP artificial muscles. In experimental section, tests are conducted to characterize the applied SCP artificial muscles before they are applied to the proposed actuator. Afterwards, tests of proposed actuator are performed to examine its variable stiffness capability. From experimental results, the proposed actuator can achieve 3.47 times stiffness variation ratio from 0.0312 N/mm(40kPa air pressure and no SCP actuation) to 0.1083 N/mm(82kPa air pressure and SCP actuation at 0.143 W/cm) at the same position (bending angle of 56 degree). This study exhibits the potential of applying SCP artificial muscles to promote the performance of soft robots.
ER  - 

TY  - CONF
TI  - A Novel Iterative Learning Model Predictive Control Method for Soft Bending Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4004
EP  - 4010
AU  - Z. Q. Tang
AU  - H. L. Heung
AU  - K. Y. Tong
AU  - Z. Li
PY  - 2019
KW  - actuators
KW  - bending
KW  - elasticity
KW  - iterative learning control
KW  - predictive control
KW  - robots
KW  - soft bending actuators
KW  - soft robots
KW  - pseudorigid-body model
KW  - bending behavior
KW  - learning curve
KW  - learning process
KW  - soft-elastic composite actuator
KW  - iterative learning model predictive control method
KW  - Mathematical model
KW  - Predictive models
KW  - Soft robotics
KW  - Actuators
KW  - Iterative methods
KW  - Predictive control
KW  - Computational modeling
KW  - Soft Material Robotics
KW  - Motion Control
KW  - Model Learning for Control
DO  - 10.1109/ICRA.2019.8793871
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robots attract research interests worldwide. However, its control remains challenging due to the difficulty in sensing and accurate modeling. In this paper, we propose a novel iterative learning model predictive control (ILMPC) method for soft bending actuators. The uniqueness of our approach is the ability to improve model accuracy gradually. In this method, a pseudo-rigid-body model is used to take an initial guess of the bending behavior of the actuator and the model accuracy is improved with iterative learning. Compared with conventional model free iterative learning control (ILC), the proposed method significantly reduces the learning curve. Compared with the model predictive control (MPC), the proposed method does not rely on an accurate model and it will output a satisfactory model after the learning process. A soft-elastic composite actuator (SECA) is used to validate the proposed method. Both simulation and experimental results show that the proposed method outperforms the conventional MPC and ILC.
ER  - 

TY  - CONF
TI  - Design and Experimental Validation of a 2DOF Sidestick Powered by Hyper-Redundant Magnetorheological Actuators Providing Active Feedback
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4011
EP  - 4017
AU  - M. Bégin
AU  - M. Denninger
AU  - J. Plante
PY  - 2019
KW  - aerospace components
KW  - aerospace control
KW  - closed loop systems
KW  - clutches
KW  - control system synthesis
KW  - force control
KW  - force feedback
KW  - haptic interfaces
KW  - interactive devices
KW  - magnetic actuators
KW  - magnetorheology
KW  - man-machine systems
KW  - jam-free design
KW  - actuation strategy
KW  - tendon driven 2DOF MR powered manipulator
KW  - electromechanical actuators
KW  - human controlled machines
KW  - tendon-driven 2-degree-of-freedom spherical gimbal
KW  - hyper-redundant MR clutches
KW  - closed-loop force control
KW  - electromagnetic actuators
KW  - aerospace flight control
KW  - man-machine interaction
KW  - haptic joysticks
KW  - active feedback
KW  - hyper-redundant magnetorheological actuators
KW  - 2DOF sidestick
KW  - reliability requirements
KW  - system design
KW  - force density
KW  - Force
KW  - Torque
KW  - Reliability
KW  - Aerospace control
KW  - Electromagnetics
KW  - Actuators
KW  - Aircraft
DO  - 10.1109/ICRA.2019.8794346
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Haptic joysticks for man-machine interaction used in aerospace flight control have highly demanding requirements of reliability, force density, and high dynamics that can hardly be met with conventional electromagnetic actuators. This work explores the potential of using an alternative actuation strategy based on hyper-redundant MR clutches that modulate the force of a tendon-driven 2-degree-of-freedom spherical gimbal. A system design and its closed-loop force control scheme are proposed. Experimental results for an open-loop characterization, static force control and dynamic force control are set out and compared with typical requirements for such devices from the literature. Results show that the proposed architecture leads to one of the lightest systems reported in the literature that has the potential to meet reliability requirements by providing a jam-free design with duplex fault tolerance, and yet, can generate high force levels while providing enough force resolution. The approach is promising and can extend to high-performance collaborative robot applications.
ER  - 

TY  - CONF
TI  - A Lightweight Force-Controllable Wearable Arm Based on Magnetorheological-Hydrostatic Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4018
EP  - 4024
AU  - C. Véronneau
AU  - J. Denis
AU  - L. Lebel
AU  - M. Denninger
AU  - J. Plante
AU  - A. Girard
PY  - 2019
KW  - electromagnetic actuators
KW  - force control
KW  - friction
KW  - human-robot interaction
KW  - magnetorheology
KW  - manipulators
KW  - medical robotics
KW  - motion control
KW  - patient rehabilitation
KW  - robot dynamics
KW  - electromagnetic actuators
KW  - supernumerary robotic limbs
KW  - wearable robots
KW  - human arms
KW  - lightweight SRL
KW  - MR-hydrostatic actuation system
KW  - magnetorheological-hydrostatic actuators
KW  - human environment
KW  - force-control approaches
KW  - elbow joints
KW  - wearable robotic arm
KW  - force-controllable SRL
KW  - low-friction hydrostatic transmission
KW  - interaction forces
KW  - mechanical backdrivability
KW  - size 25.0 nm
KW  - frequency 25.0 Hz
KW  - Force
KW  - Manipulators
KW  - Bandwidth
KW  - Friction
KW  - Hydraulic systems
KW  - Task analysis
KW  - Supernumerary robotic limbs
KW  - Wearable robotic
KW  - Lightweight
KW  - Force-Control
KW  - Magnetorheological
KW  - Hydrostatic Transmission
KW  - High-Bandwidth
KW  - Backdrivability
DO  - 10.1109/ICRA.2019.8793978
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Supernumerary Robotic Limbs (SRLs) are wearable robots augmenting human capabilities by acting as a co-worker, reaching objects, support human arms, etc. However, existing SRLs lack the mechanical backdrivability and bandwidth required for tasks where the interaction forces must be controlled such as painting, drilling, manipulating fragile objects, etc. Being highly backdrivable with a high bandwidth while minimizing weight presents a major technological challenge imposed by the limited performances of conventional electromagnetic actuators. This paper studies the feasibility of using magnetorheological (MR) clutches coupled-to a low-friction hydrostatic transmission to provide a highly capable, but yet lightweight, force-controllable SRL. A 2.7 kg 2-DOFs wearable robotic arm is designed and built. Shoulder and elbow joints are designed to deliver 39 and 25 Nm, with 115 and 180° of range of motion. Experimental studies conducted on a one-DOF test bench and validated analytically demonstrate a high force bandwidth (>25 Hz) and a good ability to control interaction forces even when interacting with an external impedance. Furthermore, three force-control approaches are studied and demonstrated experimentally: open-loop, closed-loop on force, and closed-loop on pressure. All three methods are shown to be effective. Overall, the proposed MR-Hydrostatic actuation system is well-suited for a lightweight SRL interacting with both human and environment that add unpredictable disturbances.
ER  - 

TY  - CONF
TI  - Optical Force Sensing In Minimally Invasive Robotic Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4033
EP  - 4039
AU  - A. H. H. Hosseinabadi
AU  - M. Honarvar
AU  - S. E. Salcudean
PY  - 2019
KW  - beams (structures)
KW  - force measurement
KW  - force sensors
KW  - light emitting diodes
KW  - medical robotics
KW  - optical sensors
KW  - prototypes
KW  - shafts
KW  - surgery
KW  - invasive robotic surgery
KW  - bandwidth measurement
KW  - force measurement
KW  - infrared LED-bicell pair
KW  - 3D printed prototype
KW  - structural dynamics
KW  - sensor limitations
KW  - flexible beam model
KW  - differential photocurrent
KW  - instrument shaft
KW  - optical slit
KW  - daVinci EndoWrist instruments
KW  - optical force sensing
KW  - Conferences
KW  - Automation
KW  - Surgical Robotics: Laparoscopy
KW  - Force and Tactile Sensing
KW  - Haptics and Haptic Interfaces
DO  - 10.1109/ICRA.2019.8793589
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper evaluates the feasibility of a novel optical sensing concept to measure forces applied at the tip of daVinci EndoWrist instruments. An optical slit is clamped onto the instrument shaft, in-line with an infrared LED-bicell pair. Deflection of the shaft moves the slit with respect to the LED-bicell pair and modulates the light incident on each active element of the bicell. The differential photocurrent is conditioned and monitored to estimate the tip forces. The feasibility evaluation consists of a flexible beam model to quantify the required sensor performance, experimental results with a 3D printed prototype and estimation of the sensor limitations including the measurement bandwidth due to the structural dynamics. The proposed approach requires no modifications to the instrument, is adaptable to different instruments and robot platforms, and leads to high-resolution, high-dynamic range sensing without hysteresis.
ER  - 

TY  - CONF
TI  - Mechanical Framework Design with Experimental Verification of a Wearable Exoskeleton Chair
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4040
EP  - 4045
AU  - B. Han
AU  - Z. Du
AU  - T. Huang
AU  - T. Zhang
AU  - Z. Li
AU  - O. Bai
AU  - X. Chen
PY  - 2019
KW  - bending
KW  - biomechanics
KW  - electromyography
KW  - ergonomics
KW  - finite element analysis
KW  - medical signal processing
KW  - orthotics
KW  - solid modelling
KW  - HUST-EC
KW  - vastus lateralis
KW  - vastus medialis
KW  - biceps femoris
KW  - rectus femoris
KW  - muscle activation
KW  - chair height
KW  - bending angles
KW  - chair angles
KW  - MATLAB-based acquisition software
KW  - EMG sensors
KW  - electromyography test platform
KW  - finite element analysis program
KW  - solid models
KW  - prototype chair
KW  - wearable chair design
KW  - human-chair model
KW  - wearable exoskeleton chair
KW  - Conferences
KW  - Automation
KW  - exoskeleton
KW  - wearable chair
KW  - EMG
KW  - mechanism design
DO  - 10.1109/ICRA.2019.8794466
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this study, a human-chair model was developed as the basis for a wearable chair design. A prototype chair, HUST-EC, was fabricated and evaluated. Employing the optimization under an inner point penalty function, an optimized simulation of the operating mode with the lowest chair height was implemented. The solid models were established by using the finite element analysis program embedded in Solidworks, which revealed that the support from the designed chair was steady to the user. An electromyography (EMG) test platform has been developed, consisting of four EMG sensors, a MATLAB-based acquisition software, and a loaded vest. Four healthy subjects participated in the evaluation experiment, in which EMGs were collected from the muscle groups of rectus femoris, biceps femoris, vastus medialis, and vastus lateralis under different loads and chair angles. The experimental data demonstrate that (1) the HUST-EC can greatly reduce muscle activation at a variety of loads and bending angles; (2) under the same load, the muscle activation decreases slightly with an increased bending angle; and (3) at the same bending angle, muscle activation increases slightly with an increased load. The results show that the designed chair can effectively reduce the physical burden in workers and may improve work efficiency.
ER  - 

TY  - CONF
TI  - KO-Fusion: Dense Visual SLAM with Tightly-Coupled Kinematic and Odometric Tracking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4054
EP  - 4060
AU  - C. Houseago
AU  - M. Bloesch
AU  - S. Leutenegger
PY  - 2019
KW  - cameras
KW  - distance measurement
KW  - image colour analysis
KW  - image fusion
KW  - image texture
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - KO-fusion
KW  - dense visual SLAM methods
KW  - observer
KW  - visual information
KW  - SLAM systems
KW  - inertial measurements
KW  - dense RGB-D SLAM system
KW  - wheeled robot
KW  - kinematic data
KW  - odometric data
KW  - kinematic measurements
KW  - tightly-coupled kinematic
KW  - odometric tracking
KW  - manipulator
KW  - odometry measurements
KW  - motion estimation
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Robot vision systems
KW  - Kinematics
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8793471
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dense visual SLAM methods are able to estimate the 3D structure of an environment and locate the observer within them. They estimate the motion of a camera by matching visual information between consecutive frames, and are thus prone to failure under extreme motion conditions or when observing texture-poor regions. The integration of additional sensor modalities has shown great promise in improving the robustness and accuracy of such SLAM systems. In contrast to the popular use of inertial measurements we propose to tightly-couple a dense RGB-D SLAM system with kinematic and odometry measurements from a wheeled robot equipped with a manipulator. The system has real-time capability while running on GPU. It optimizes the camera pose by considering the geometric alignment of the map as well as kinematic and odometric data from the robot. Through experimentation in the real-world, we show that the system is more robust to challenging trajectories featuring fast and loopy motion than the equivalent system without the additional kinematic and odometric knowledge, whilst retaining comparable performance to the equivalent RGB-D only system on easy trajectories.
ER  - 

TY  - CONF
TI  - Diffraction-Aware Sound Localization for a Non-Line-of-Sight Source
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4061
EP  - 4067
AU  - I. An
AU  - D. Lee
AU  - J. Choi
AU  - D. Manocha
AU  - S. Yoon
PY  - 2019
KW  - acoustic signal processing
KW  - acoustic wave diffraction
KW  - acoustic wave propagation
KW  - particle filtering (numerical methods)
KW  - ray tracing
KW  - generated acoustic rays
KW  - estimated source position
KW  - static NLOS sound sources
KW  - dynamic NLOS sound sources
KW  - actual source locations
KW  - state-of-the-art localization method
KW  - nonline-of-sight source
KW  - sound localization algorithm
KW  - nonline-of-sight sound source
KW  - indoor environments
KW  - diffraction properties
KW  - sound waves
KW  - bending effects
KW  - virtual sound source
KW  - indoor scene
KW  - diffraction acoustic rays
KW  - ray tracing-based sound propagation
KW  - diffraction-aware sound localization
KW  - UTD
KW  - uniform theory of diffraction
KW  - wedge precomputing
KW  - reconstructed mesh
KW  - particle filter
KW  - size 7.0 m
KW  - size 3.0 m
KW  - Diffraction
KW  - Ray tracing
KW  - Three-dimensional displays
KW  - Computational modeling
KW  - Acoustic diffraction
KW  - Robots
DO  - 10.1109/ICRA.2019.8794093
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel sound localization algorithm for a non-line-of-sight (NLOS) sound source in indoor environments. Our approach exploits the diffraction properties of sound waves as they bend around a barrier or an obstacle in the scene. We combine a ray tracing-based sound propagation algorithm with a Uniform Theory of Diffraction (UTD) model, which simulate bending effects by placing a virtual sound source on a wedge in the environment. We precompute the wedges of a reconstructed mesh of an indoor scene and use them to generate diffraction acoustic rays to localize the 3D position of the source. Our method identifies the convergence region of those generated acoustic rays as the estimated source position based on a particle filter. We have evaluated our algorithm in multiple scenarios consisting of static and dynamic NLOS sound sources. In our tested cases, our approach can localize a source position with an average accuracy error of 0.7m, measured by the L2 distance between estimated and actual source locations in a 7m×7m×3m room. Furthermore, we observe 37% to 130% improvement in accuracy over a state-of-the-art localization method that does not model diffraction effects, especially when a sound source is not visible to the robot.
ER  - 

TY  - CONF
TI  - DeepFusion: Real-Time Dense 3D Reconstruction for Monocular SLAM using Single-View Depth and Gradient Predictions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4068
EP  - 4074
AU  - T. Laidlow
AU  - J. Czarnowski
AU  - S. Leutenegger
PY  - 2019
KW  - cameras
KW  - computerised instrumentation
KW  - graphics processing units
KW  - image fusion
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - minimisation
KW  - neurocontrollers
KW  - photometry
KW  - probability
KW  - SLAM (robots)
KW  - stereo image processing
KW  - target tracking
KW  - depth cameras
KW  - CNN
KW  - DeepFusion
KW  - semidense multiview stereo algorithm
KW  - gradient predictions
KW  - monocular SLAM
KW  - single-view depth
KW  - keypoint-based maps
KW  - camera tracking
KW  - dense 3D reconstructions
KW  - convolutional neural network
KW  - sparse monocular simultaneous localisation and mapping systems
KW  - real-time dense 3D reconstruction system
KW  - photometric error minimization
KW  - GPU
KW  - probability
KW  - Image reconstruction
KW  - Uncertainty
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Real-time systems
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793527
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While the keypoint-based maps created by sparse monocular Simultaneous Localisation and Mapping (SLAM) systems are useful for camera tracking, dense 3D reconstructions may be desired for many robotic tasks. Solutions involving depth cameras are limited in range and to indoor spaces, and dense reconstruction systems based on minimising the photometric error between frames are typically poorly constrained and suffer from scale ambiguity. To address these issues, we propose a 3D reconstruction system that leverages the output of a Convolutional Neural Network (CNN) to produce fully dense depth maps for keyframes that include metric scale. Our system, DeepFusion, is capable of producing real-time dense reconstructions on a GPU. It fuses the output of a semi-dense multiview stereo algorithm with the depth and gradient predictions of a CNN in a probabilistic fashion, using learned uncertainties produced by the network. While the network only needs to be run once per keyframe, we are able to optimise for the depth map with each new frame so as to constantly make use of new geometric constraints. Based on its performance on synthetic and real world datasets, we demonstrate that DeepFusion is capable of performing at least as well as other comparable systems.
ER  - 

TY  - CONF
TI  - Dynamic Hilbert Maps: Real-Time Occupancy Predictions in Changing Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4091
EP  - 4097
AU  - V. Guizilini
AU  - R. Senanayake
AU  - F. Ramos
PY  - 2019
KW  - Hilbert spaces
KW  - mobile robots
KW  - remotely operated vehicles
KW  - real-time occupancy predictions
KW  - static occupancy models
KW  - continuous occupancy map
KW  - high-dimensional feature space
KW  - data-efficient model
KW  - crowded unstructured outdoor environments
KW  - dynamic Hilbert maps
KW  - temporal dependencies
KW  - 3D laser data
KW  - 2D laser data
KW  - Vehicle dynamics
KW  - Predictive models
KW  - Uncertainty
KW  - Dynamics
KW  - Indexes
KW  - Real-time systems
KW  - Clustering algorithms
DO  - 10.1109/ICRA.2019.8793914
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of learning instantaneous occupancy levels of dynamic environments and predicting future occupancy levels. Due to the complexity of most real environments, such as urban streets or crowded areas, the efficient and robust incorporation of temporal dependencies into otherwise static occupancy models remains a challenge. We propose a method to capture the uncertainty of moving objects and incorporate this uncertainty information into a continuous occupancy map represented in a rich high-dimensional feature space. This data-efficient model not only allows us to learn the occupancy states incrementally, but also makes predictions about what the future occupancy states will be. Experiments performed using 2D and 3D laser data collected from crowded unstructured outdoor environments show that the proposed methodology can accurately predict occupancy states for areas of around 1000 m2 at 10 Hz, making the proposed framework ideal for online applications under real-time constraints.
ER  - 

TY  - CONF
TI  - Evaluating the Effectiveness of Perspective Aware Planning with Panoramas
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4098
EP  - 4103
AU  - D. Mox
AU  - A. Cowley
AU  - M. A. Hsieh
AU  - C. J. Taylor
PY  - 2019
KW  - image colour analysis
KW  - image sensors
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - binary coverage
KW  - goal selection strategy
KW  - image morphology
KW  - search space
KW  - CSQMI
KW  - perspective aware planning
KW  - information based exploration strategy
KW  - high resolution 3D maps
KW  - RGBD panoramas
KW  - angle enhanced occupancy grid
KW  - exploration strategy
KW  - maximal Cauchy-Schwarz quadratic mutual information
KW  - logging image control
KW  - Skeleton
KW  - Mutual information
KW  - Task analysis
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793897
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we present an information based exploration strategy tailored for the generation of high resolution 3D maps. We employ RGBD panoramas because they have been shown to provide memory efficient high quality representations of space. Robots explore the environment by selecting locations with maximal Cauchy-Schwarz Quadratic Mutual Information (CSQMI) computed on an angle enhanced occupancy grid to collect these RGBD panoramas. By employing the angle enhanced occupancy grid, the resulting exploration strategy emphasizes perspective in addition to binary coverage. Furthermore, the goal selection strategy is improved by using image morphology to reduce the search space over which CSQMI is computed. We present experimental results demonstrating the improved performance in perception related tasks by capturing panoramas using this approach, near frontier exploration, and a control of logging images at regular intervals while teleoperating the robot through the workspace. Collect imagery was passed through an object detection library with our perspective aware approach yielding a greater number of successful detections compared to near frontier exploration.
ER  - 

TY  - CONF
TI  - Actively Improving Robot Navigation On Different Terrains Using Gaussian Process Mixture Models
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4104
EP  - 4110
AU  - L. Nardi
AU  - C. Stachniss
PY  - 2019
KW  - Gaussian processes
KW  - mixture models
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot navigation
KW  - outdoor environments
KW  - place-dependent model
KW  - aerial image
KW  - path planning
KW  - Gaussian process mixture model
KW  - Robots
KW  - Navigation
KW  - Vibrations
KW  - Mixture models
KW  - Energy consumption
KW  - Gaussian processes
KW  - Planning
DO  - 10.1109/ICRA.2019.8794079
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot navigation in outdoor environments is exposed to detrimental factors such as vibrations or power consumption due to the different terrains on which the robot navigates. In this paper, we address the problem of actively improving navigation by planning paths that aim at reducing over time phenomena such as vibrations during traversal. Our approach uses a Gaussian Process (GP) mixture model and an aerial image of the environment to learn and improve continuously a place-dependent model of such phenomena from the experiences of the robot. We use this model to plan paths that trade-off the exploration of unknown promising regions and the exploitation of known areas where the impact of the detrimental factors on navigation is low, leading to an improved navigation over time. We implemented our approach and thoroughly tested it using real-world data. Our experiments suggest that our approach with no initial information leads the robot, after few runs, to follow paths along which it experiences similar vibrations or energy consumption as if it was following the optimal path computed given the ground truth information.
ER  - 

TY  - CONF
TI  - Continuous Occupancy Map Fusion with Fast Bayesian Hilbert Maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4111
EP  - 4117
AU  - W. Zhi
AU  - L. Ott
AU  - R. Senanayake
AU  - F. Ramos
PY  - 2019
KW  - Bayes methods
KW  - image fusion
KW  - mobile robots
KW  - multi-robot systems
KW  - SLAM (robots)
KW  - multirobot Hilbert Map systems
KW  - individual Fast-BHMs
KW  - decentralised manner
KW  - continuous representation
KW  - robot autonomy
KW  - traditional occupancy grid maps
KW  - continuous nature
KW  - continuous occupancy map fusion
KW  - fused fast-BHMs
KW  - global fast-BHM models
KW  - Bayesian Hilbert map models
KW  - fast Bayesian Hilbert maps
KW  - Bayes methods
KW  - Robots
KW  - Covariance matrices
KW  - Merging
KW  - Time complexity
KW  - Real-time systems
KW  - Training
DO  - 10.1109/ICRA.2019.8793508
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mapping the occupancy of an environment is central for robot autonomy. Traditional occupancy grid maps discretise the environment into independent cells, neglecting important spatial correlations, and are unable to capture the continuous nature of the real world. With these drawbacks of grid maps in mind, Hilbert Maps (HM) and more recently Bayesian Hilbert Maps (BHMs), were introduced as a continuous representation of the environment. In this paper we propose a method to merge Bayesian Hilbert Maps built by a team of robots in a decentralised manner. The training of BHMs requires the inversion of a large covariance matrix, incurring cubic complexity. We introduce an approximation, Fast Bayesian Hilbert Maps (Fast-BHM), which reduces the time complexity to below quadratic. Such speed-ups allow the building and merging of Bayesian Hilbert Map models to be practical, opening the door for multi-robot Hilbert Map systems which can be much faster and more robust than an individual robot. By merging several individual Fast-BHMs in a decentralised manner we obtain a unified model of the environment which is itself a Fast-BHM. We conduct experiments to show that global Fast-BHM models do not deteriorate after repeated merging and training. We then empirically demonstrate, due to its the compact representation, fused Fast-BHMs outperform fusion methods involving discretising continuous representations, when the amount of information communicated is limited.
ER  - 

TY  - CONF
TI  - Fault-tolerant Flight Control of a VTOL Tailsitter UAV
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4134
EP  - 4140
AU  - S. Fuhrer
AU  - S. Verling
AU  - T. Stastny
AU  - R. Siegwart
PY  - 2019
KW  - actuators
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - fault tolerant control
KW  - remotely operated vehicles
KW  - minimalistic actuation
KW  - possible actuator failures
KW  - light-weight adaptations
KW  - nominal flight controller
KW  - tailsitter VTOL aircraft
KW  - fault-tolerant flight control
KW  - landing systems
KW  - moving parts
KW  - vertical take-off and landing systems
KW  - Propellers
KW  - Actuators
KW  - Aircraft
KW  - Aerospace electronics
KW  - Force
KW  - Fault tolerance
KW  - Fault tolerant systems
DO  - 10.1109/ICRA.2019.8793467
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Compared to other vertical take-off and landing (VTOL) systems, a tailsitter minimizes the number of actuators and moving parts necessary. The downside of having a minimalistic actuation is its inherent low fault-tolerance. The failure of an actuator usually results in a loss of controllability, resulting in a crash. In this paper we analyze possible actuator failures and the constraints they pose on the capabilities of the system. We further present light-weight adaptations to the nominal flight controller to make it fault-tolerant. The fault-tolerant controller is implemented on a small tailsitter VTOL aircraft and adjusted to the system by means of extensive experimental studies. Finally, the capabilities and performance under failures are demonstrated and analyzed.
ER  - 

TY  - CONF
TI  - Modeling and Control of a Passively-Coupled Tilt-Rotor Vertical Takeoff and Landing Aircraft
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4141
EP  - 4147
AU  - R. Chiappinelli
AU  - M. Cohen
AU  - M. Doff-Sotta
AU  - M. Nahon
AU  - J. R. Forbes
AU  - J. Apkarian
PY  - 2019
KW  - actuators
KW  - aerospace components
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - cascade control
KW  - control system synthesis
KW  - helicopters
KW  - hinges
KW  - mobile robots
KW  - propellers
KW  - rotors (mechanical)
KW  - three-term control
KW  - velocity control
KW  - quadrotor frame
KW  - fixed-wing aircraft
KW  - hover
KW  - forward flight
KW  - tilting actuators
KW  - coupled dynamics
KW  - aircraft frame
KW  - cascaded control architecture
KW  - control design
KW  - forward velocity control
KW  - passively-coupled tilt-rotor vertical takeoff and landing aircraft
KW  - differential thrust
KW  - propellers
KW  - inner-loop attitude
KW  - height control
KW  - constrained Lagrangian approach
KW  - P-PID controllers
KW  - unactuated hinged mechanism
KW  - equations of motion
KW  - unmanned aerial vehicles
KW  - UAVs
KW  - Aircraft
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Aerodynamics
KW  - Aerospace control
KW  - Rotors
KW  - Angular velocity
KW  - Vertical takeoff and landing aircraft
KW  - passively-coupled tilt-rotor
KW  - dynamic modeling
KW  - cascade PID control
KW  - PX4 autopilot
DO  - 10.1109/ICRA.2019.8793606
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the modeling and control of a passively-coupled tilt-rotor vertical takeoff and landing aircraft. The aircraft consists of a quadrotor frame attached to a fixed-wing aircraft by an unactuated hinged mechanism. The platform is capable of smooth transitions from hover to forward flight without the use of tilting actuators. The transition from hover to forward flight is made possible by differential thrust between the fore and aft propellers of the quadrotor frame. In this paper, the coupled dynamics between the quadrotor frame and the aircraft frame are modeled as a constrained multi-body system. The equations of motion are established using a constrained Lagrangian approach and the model developed is used to build a realistic simulation environment for control design purpose. A cascaded control architecture based on P/PID controllers is proposed to achieve inner-loop attitude, height and forward velocity control. Simulated and experimental results are obtained with a close match for hover, transitions, forward flight, and banked turn maneuvers.
ER  - 

TY  - CONF
TI  - Power-Minimizing Control of a Variable-Pitch Propulsion System for Versatile Unmanned Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4148
EP  - 4153
AU  - T. Henderson
AU  - N. Papanikolopoulos
PY  - 2019
KW  - aerospace propulsion
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - motion control
KW  - pitch control (position)
KW  - power consumption
KW  - power control
KW  - propellers
KW  - robot dynamics
KW  - propeller design
KW  - propeller-based propulsion mechanisms
KW  - variable-pitch propeller
KW  - versatile UAVs
KW  - quasisteady propulsive state
KW  - power-minimizing control
KW  - electrical power consumption
KW  - versatile unmanned aerial vehicles
KW  - variable-pitch propulsion system
KW  - Power demand
KW  - Propellers
KW  - Servomotors
KW  - Unmanned aerial vehicles
KW  - Brushless DC motors
DO  - 10.1109/ICRA.2019.8794357
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In response to an abundance of applications, Unmanned Aerial Vehicles are being called upon to perform missions of high difficulty for increasingly long periods of time. Traditional paradigms of propeller design and actuation are reaching a design ceiling, motivating creative approaches to the design of propeller-based propulsion mechanisms. Within the last decade, one particular kind of mechanism, the variable-pitch propeller, has been studied by researchers for its applications to the class of small UAVs. This paper pushes for new results in this area by exploring the use of Variable Pitch Propulsion (VPP) to minimize power consumption for small, versatile UAVs. A control algorithm is presented to minimize the consumed electrical power during a quasi-steady propulsive state. In particular, the algorithm is not confined to operation in limited regions of the state space, but it seeks to minimize power at whatever point in the state space a steady state is reached. Several experimental results are presented to validate the approach.
ER  - 

TY  - CONF
TI  - Rapid Inertial Reorientation of an Aerial Insect-sized Robot Using a Piezo-actuated Tail
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4154
EP  - 4160
AU  - A. Singh
AU  - T. Libby
AU  - S. B. Fuller
PY  - 2019
KW  - aerodynamics
KW  - aerospace robotics
KW  - feedforward
KW  - gears
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - open loop systems
KW  - piezoelectric actuators
KW  - stability
KW  - rapid inertial reorientation
KW  - aerial insect-sized robot
KW  - bio-inspired inertial tail
KW  - DC electric motor
KW  - geared motor system
KW  - piezo-tail system
KW  - resonant system
KW  - piezo-driven inertial reorientation
KW  - open-loop feedforward controller
KW  - rapid dynamic maneuvers
KW  - piezoactuator
KW  - mass 142.0 mg
KW  - Actuators
KW  - Robots
KW  - Analytical models
KW  - Torque
KW  - Fabrication
KW  - Aerodynamics
KW  - Prototypes
DO  - 10.1109/ICRA.2019.8793948
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present the design, fabrication, and feedforward control of a insect-sized (142 mg) aerial robot that is equipped with a bio-inspired inertial tail. A tail allows the robot to perform rapid inertial reorientation as well as to shift weight to modulate aerodynamic torques on its body. Here we present the first analysis of inertial reorientation using a piezo actuator, departing from previous work to date that has focused exclusively on actuation by DC electric motor. The primary difference is that unlike a geared motor system, the piezo-tail system operates as a resonant system, exhibiting slowly-decaying oscillations. We present a dynamic model of piezo-driven inertial reorientation, along with an open-loop feedforward controller that reduces excitation of the resonant mode. We validate our approach on a tethered testbed as well as a flight-capable prototype. Our results indicate that incorporating a tail can allow for more rapid dynamic maneuvers and could stabilize the robot during flight.
ER  - 

TY  - CONF
TI  - Contact–based Navigation Path Planning for Aerial Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4161
EP  - 4167
AU  - N. Khedekar
AU  - F. Mascarich
AU  - C. Papachristos
AU  - T. Dang
AU  - K. Alexis
PY  - 2019
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - robot dynamics
KW  - robot kinematics
KW  - aerial robots
KW  - in-contact operation
KW  - contact missions
KW  - flying robot
KW  - navigation mode
KW  - cartwheel mode
KW  - navigation modalities
KW  - in-contact navigation
KW  - specialized contact mechanism
KW  - contact-based navigation path planning
KW  - Navigation
KW  - Task analysis
KW  - Unmanned aerial vehicles
KW  - Inspection
KW  - Path planning
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8793794
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper the problem of contact-based navigation path planning for aerial robots is considered with the goal of enabling the autonomous in-contact operation on surfaces that can be highly anomalous. Such a capacity can prove critical in inspection through contact missions, as well as when a flying robot is tasked to operate in very narrow environments rendering safe free-flight impossible. To achieve this objective, beyond sliding in contact, a new locomotion primitive is introduced, namely that of azimuth rotations perpendicular to the surface under consideration. This new navigation mode, called flying cartwheel mode, offers navigation resourcefulness and resilience when the system is tasked to move in contact with surfaces that are otherwise non-traversable. The designed path planning method exploits both navigation modalities and a traversability metric to decide when to switch from sliding to flying cartwheel mode, and overall provides cost-optimal trajectories for in-contact navigation. The proposed approach is verified both in simulation, as well as experimentally using a surface presenting complex anomalies. It is highlighted that the proposed method does not assume any specialized contact mechanism or a control law tailored to physical interaction tasks, and hence is applicable to almost any micro aerial vehicle integrating protective shrouds around its propellers.
ER  - 

TY  - CONF
TI  - Cargo Transportation Strategy using T3-Multirotor UAV
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4168
EP  - 4173
AU  - S. J. Lee
AU  - D. Lee
AU  - H. J. Kim
PY  - 2019
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - freight handling
KW  - helicopters
KW  - motion control
KW  - servomechanisms
KW  - cargo transportation strategy
KW  - stable flight performance
KW  - constant flight performance
KW  - fuselage part
KW  - relative attitude control strategy
KW  - T3-multirotor UAV platform
KW  - thrust generating part
KW  - servomechanism
KW  - moment of inertia
KW  - motion control
KW  - Mathematical model
KW  - Servomechanisms
KW  - Attitude control
KW  - Torque
KW  - Transportation
KW  - Radio frequency
DO  - 10.1109/ICRA.2019.8794203
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we introduce a cargo transportation method with a new type of multi-rotor UAV platform known as T3-multirotor, to achieve stable and constant flight performance regardless of the type of cargo attached to the fuselage. The T3-multirotor, which consists of the `Thrust Generating Part' and the `Fuselage Part', can directly control the relative attitude between the two parts using the novel servomechanism. By utilizing the servomechanism with the proposed relative attitude control strategy, the T3-multirotor with cargo attached to the fuselage part can behave as a multi-rotor with only the moment of inertia of the thrust generating part during entire transportation. This allows the T3-multirotor to achieve the reliable performance in the event of any cargo being attached to the fuselage, achieving stable platform motion control. Detailed hardware description and dynamic analysis of T3-Multirotor is performed in this paper, and the validity of the proposed control strategy is also analyzed. The feasibility of the proposed control strategy is verified through experimental results with analysis.
ER  - 

TY  - CONF
TI  - Experimental Learning of a Lift-Maximizing Central Pattern Generator for a Flapping Robotic Wing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1997
EP  - 2003
AU  - Y. E. Bayiz
AU  - S. Hsu
AU  - A. N. Aguiles
AU  - Y. Shade-Alexander
AU  - B. Cheng
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - motion control
KW  - multi-agent systems
KW  - robot dynamics
KW  - robot kinematics
KW  - robot programming
KW  - experimental learning
KW  - lift-maximizing central pattern generator
KW  - flapping robotic wing
KW  - policy gradient algorithm
KW  - dynamically scaled robotic wing
KW  - constant Reynolds number
KW  - central pattern generator model
KW  - CPG
KW  - motion controller
KW  - rhythmic wing motion patterns
KW  - half-stroke symmetry constraint
KW  - learning agent
KW  - robotic learning
KW  - wing kinematic learning
KW  - Kinematics
KW  - Robots
KW  - Oscillators
KW  - Trajectory
KW  - Servomotors
KW  - Heuristic algorithms
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794016
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we present an application of a policy gradient algorithm to a real-time robotic learning problem, where the goal is to maximize the average lift generation of a dynamically scaled robotic wing at a constant Reynolds number (Re). Compared to our previous work, the merit of this work is two-fold. First, a central pattern generator (CPG) model was used as the motion controller, which provided a smooth generation and transition of rhythmic wing motion patterns while the CPG was being updated by the policy gradient, thereby accelerating the sample generation and reducing the total learning time. Second, the kinematics included three degrees of freedom (stroke, deviation, pitching) and were also free of half-stroke symmetry constraint, together they yielded a larger kinematic space which later explored by the policy gradient to maximize the lift generation. The learned wing kinematics used the full range of stroke and deviation to maximize the lift generation, implying that the wing trajectories with larger disk area and lower frequencies were preferred for high lift generation at constant Re. Furthermore, the wing pitching amplitude converged to values between 45°-49° regardless of what the other parameters were. Notably, the learning agent was able to find two locally optimal wing motion patterns, which had distinct shapes of wing trajectory but generated similar cycle-averaged lift.
ER  - 

TY  - CONF
TI  - Toward Lateral Aerial Grasping & Manipulation Using Scalable Suction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4181
EP  - 4186
AU  - C. C. Kessens
AU  - M. Horowitz
AU  - C. Liu
AU  - J. Dotterweich
AU  - M. Yim
AU  - H. L. Edge
PY  - 2019
KW  - grippers
KW  - mobile robots
KW  - self-adjusting systems
KW  - stability
KW  - scalable suction
KW  - aerial robot
KW  - lateral physical work
KW  - ground-based robots
KW  - functional work
KW  - lateral force
KW  - hovering vehicle
KW  - environmental forces
KW  - self-sealing suction cup
KW  - flight vehicle
KW  - physical grasping demonstrations
KW  - suction-based gripper
KW  - Grippers
KW  - Force
KW  - Spirals
KW  - Propulsion
KW  - Electron tubes
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793672
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper is an initial step toward the realization of an aerial robot that can perform lateral physical work, such as drilling a hole or fastening a screw in a wall. Aerial robots are capable of high maneuverability and can provide access to locations that would be difficult or impossible for ground-based robots to reach. However, to fully utilize this mobility, systems would ideally be able to perform functional work in those locations, requiring the ability to exert lateral forces. To substantially improve a hovering vehicle's ability to stably deliver large lateral forces, we propose the use of a versatile suction-based gripper that can establish pulling contact on featureless surfaces. Such contact enables access to environmental forces that can be used to further stabilize the vehicle and also increase the lateral force delivered to the surface through a possible secondary mechanism. This paper introduces the concept, describes the design of a new self-sealing suction cup based on a previous design, details the design of a gripper using those cups, and describes the arm and flight vehicle. It then evaluates the cup and gripper performance in several ways, culminating in physical grasping demonstrations using the arm and gripper, including one in the presence of simulated flight noise based on data from preliminary indoor flight experiments.
ER  - 

TY  - CONF
TI  - Design and Implementation of Computer Vision based In-Row Weeding System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4218
EP  - 4224
AU  - X. Wu
AU  - S. Aravecchia
AU  - C. Pradalier
PY  - 2019
KW  - agricultural robots
KW  - agrochemicals
KW  - cameras
KW  - crops
KW  - feature extraction
KW  - mobile robots
KW  - robot vision
KW  - spraying
KW  - sustainable development
KW  - computer vision
KW  - autonomous robotic weeding systems
KW  - precision farming
KW  - current dependency
KW  - herbicides
KW  - pesticides
KW  - selective spraying
KW  - mechanical weed removal modules
KW  - environmental pollution
KW  - real-time treatment
KW  - weeding control system
KW  - indeterminate classification delays
KW  - in-row weeding system design
KW  - sustainability
KW  - nonoverlapping multicamera system
KW  - terrain conditions
KW  - Cameras
KW  - Agriculture
KW  - Delays
KW  - Control systems
KW  - Robots
KW  - Three-dimensional displays
KW  - Tracking
DO  - 10.1109/ICRA.2019.8793974
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous robotic weeding systems in precision farming have demonstrated their full potential to alleviate the current dependency on herbicides or pesticides by introducing selective spraying or mechanical weed removal modules, thus reducing the environmental pollution and improving the sustainability. However, most previous works require fast weed detection system to achieve real-time treatment. In this paper, a novel computer vision based weeding control system is presented, where a non-overlapping multi-camera system is introduced to compensate the indeterminate classification delays, thus allowing for more complicated and advanced detection algorithms, e.g. deep learning based methods. The suitable tracking and control strategies are developed to achieve accurate and robust in-row weed treatment, and the performance of the proposed system is evaluated in different terrain conditions in the presence of various delays.
ER  - 

TY  - CONF
TI  - LSTM-based Network for Human Gait Stability Prediction in an Intelligent Robotic Rollator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4225
EP  - 4232
AU  - G. Chalvatzaki
AU  - P. Koutras
AU  - J. Hadfield
AU  - X. S. Papageorgiou
AU  - C. S. Tzafestas
AU  - P. Maragos
PY  - 2019
KW  - adaptive control
KW  - control engineering computing
KW  - gait analysis
KW  - geriatrics
KW  - handicapped aids
KW  - image colour analysis
KW  - intelligent robots
KW  - Kalman filters
KW  - laser ranging
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - mobile robots
KW  - nonlinear filters
KW  - pose estimation
KW  - robust control
KW  - state estimation
KW  - legs positions
KW  - UKF
KW  - pose estimation
KW  - deep learning
KW  - laser range finder data
KW  - augmented gait state estimation
KW  - human gait stability predictor
KW  - user-adaptive control architecture
KW  - unscented Kalman filter
KW  - body center of mass
KW  - long short term memory networks
KW  - robust predictions
KW  - encoder-decoder sequence
KW  - LRF data
KW  - nonwearable sensors
KW  - multimodal RGB-D
KW  - elderly users
KW  - intelligent robotic rollator
KW  - LSTM-based network
KW  - Stability analysis
KW  - Legged locomotion
KW  - Laser stability
KW  - Robot sensing systems
KW  - Senior citizens
DO  - 10.1109/ICRA.2019.8793899
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we present a novel framework for on-line human gait stability prediction of the elderly users of an intelligent robotic rollator using Long Short Term Memory (LSTM) networks, fusing multimodal RGB-D and Laser Range Finder (LRF) data from non-wearable sensors. A Deep Learning (DL) based approach is used for the upper body pose estimation. The detected pose is used for estimating the body Center of Mass (CoM) using Unscented Kalman Filter (UKF). An Augmented Gait State Estimation framework exploits the LRF data to estimate the legs' positions and the respective gait phase. These estimates are the inputs of an encoder-decoder sequence to sequence model which predicts the gait stability state as Safe or Fall Risk walking. It is validated with data from real patients, by exploring different network architectures, hyperparameter settings and by comparing the proposed method with other baselines. The presented LSTM-based human gait stability predictor is shown to provide robust predictions of the human stability state, and thus has the potential to be integrated into a general user-adaptive control architecture as a fall-risk alarm.
ER  - 

TY  - CONF
TI  - Urban Swarms: A new approach for autonomous waste management
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4233
EP  - 4240
AU  - A. L. Alfeo
AU  - E. C. Ferrer
AU  - Y. L. Carrillo
AU  - A. Grignard
AU  - L. A. Pastor
AU  - D. T. Sleeper
AU  - M. G. C. A. Cimino
AU  - B. Lepri
AU  - G. Vaglini
AU  - K. Larson
AU  - M. Dorigo
AU  - A. Pentland
PY  - 2019
KW  - geographic information systems
KW  - mobile robots
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - refuse disposal
KW  - service robots
KW  - garbage collection scenarios
KW  - urban swarms
KW  - ecosystems
KW  - bio-inspired foraging methods
KW  - multiplace foraging
KW  - real-world GIS data
KW  - robot swarms
KW  - urban waste management system
KW  - stigmergy-based navigation
KW  - urban environment
KW  - swarm robotics system
KW  - autonomous waste management
KW  - Robots
KW  - Urban areas
KW  - Roads
KW  - Waste management
KW  - RFID tags
KW  - Swarm robotics
KW  - Batteries
DO  - 10.1109/ICRA.2019.8794020
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Modern cities are growing ecosystems that face new challenges due to the increasing population demands. One of the many problems they face nowadays is waste management, which has become a pressing issue requiring new solutions. Swarm robotics systems have been attracting an increasing amount of attention in the past years and they are expected to become one of the main driving factors for innovation in the field of robotics. The research presented in this paper explores the feasibility of a swarm robotics system in an urban environment. By using bio-inspired foraging methods such as multi-place foraging and stigmergy-based navigation, a swarm of robots is able to improve the efficiency and autonomy of the urban waste management system in a realistic scenario. To achieve this, a diverse set of simulation experiments was conducted using real-world GIS data and implementing different garbage collection scenarios driven by robot swarms. Results presented in this research show that the proposed system outperforms current approaches. Moreover, results not only show the efficiency of our solution, but also give insights about how to design and customize these systems.
ER  - 

TY  - CONF
TI  - Automated Aortic Pressure Regulation in ex vivo Heart Perfusion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4241
EP  - 4246
AU  - L. Xin
AU  - W. Yao
AU  - Y. Peng
AU  - N. Qi
AU  - M. Badiwala
AU  - Y. Sun
PY  - 2019
KW  - adaptive control
KW  - blood vessels
KW  - cardiovascular system
KW  - haemodynamics
KW  - physiological models
KW  - automated aortic pressure regulation
KW  - physiological aerobic metabolism
KW  - ex vivo heart perfusion
KW  - aortic pressure regulation
KW  - isolated porcine heart
KW  - animal hearts
KW  - control parameters
KW  - adaptation algorithm
KW  - virtual controller forms
KW  - nonlinear equivalent circuit fluid flow model
KW  - perfusion system
KW  - mathematical model
KW  - AoP regulation
KW  - adaptive controller
KW  - Heart
KW  - Adaptation models
KW  - Integrated circuit modeling
KW  - Mathematical model
KW  - Biochemistry
KW  - Predictive models
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793745
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the first system for automated ex vivo perfusion of an isolated heart and regulating the heart's aortic pressure (AoP). An adaptive controller was developed for AoP regulation and maintained the heart's physiological aerobic metabolism. A mathematical model of the perfusion system was established based on a nonlinear equivalent circuit fluid flow model. The model combined with a virtual controller forms a reference model to generate the ideal trajectory of AoP. An adaptation algorithm tunes the control parameters based on the reference model and the isolated heart. Experiments were conducted using large animal hearts (55±5 kg porcine, n=6) to validate the adaptive controller's performance for stepwise and fast switching AoP references. The results confirmed that the the proposed controller is able to regulate the AoP of an isolated porcine heart in an accurate (mean error less than 2 mmHg) and fast (4~8 s of settling time) manner.
ER  - 

TY  - CONF
TI  - A Multi-Vehicle Trajectories Generator to Simulate Vehicle-to-Vehicle Encountering Scenarios
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4255
EP  - 4261
AU  - W. Ding
AU  - W. Wang
AU  - D. Zhao
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - position control
KW  - remotely operated vehicles
KW  - road traffic
KW  - road vehicles
KW  - vehicle-to-vehicle encountering scenarios
KW  - autonomous vehicle development
KW  - multivehicle trajectory generator
KW  - MTG
KW  - multivehicle interaction scenarios
KW  - driving encounter scenarios
KW  - multibranch decoder
KW  - vehicle-to-vehicle encounters
KW  - autonomous vehicles
KW  - Trajectory
KW  - Measurement
KW  - Decoding
KW  - Generators
KW  - Bidirectional control
KW  - Generative adversarial networks
KW  - Stability analysis
DO  - 10.1109/ICRA.2019.8793776
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Generating multi-vehicle trajectories from existing limited data can provide rich resources for autonomous vehicle development and testing. This paper introduces a multi-vehicle trajectory generator (MTG) that can encode multi-vehicle interaction scenarios (called driving encounters) into an interpretable representation from which new driving encounter scenarios are generated by sampling. The MTG consists of a bi-directional encoder and a multi-branch decoder. A new disentanglement metric is then developed for model analyses and comparisons in terms of model robustness and the independence of the latent codes. Comparison of our proposed MTG with β-VAE and InfoGAN demonstrates that the MTG has stronger capability to purposely generate rational vehicle-to-vehicle encounters through operating the disentangled latent codes. Thus the MTG could provide more data for engineers and researchers to develop testing and evaluation scenarios for autonomous vehicles.
ER  - 

TY  - CONF
TI  - Deep n-Shot Transfer Learning for Tactile Material Classification with a Flexible Pressure-Sensitive Skin
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4262
EP  - 4268
AU  - B. Bäuml
AU  - A. Tulbure
PY  - 2019
KW  - convolutional neural nets
KW  - haptic interfaces
KW  - learning (artificial intelligence)
KW  - pattern classification
KW  - 1-shot learning
KW  - knowledge transfer
KW  - deep n-shot transfer learning
KW  - tactile material classification
KW  - flexible pressure-sensitive skin
KW  - active sensing tasks
KW  - deep end-to-end transfer learning
KW  - deep convolutional neural network
KW  - superhuman tactile classification performance
KW  - Task analysis
KW  - Robot sensing systems
KW  - Feature extraction
KW  - Training
KW  - Skin
KW  - Learning systems
DO  - 10.1109/ICRA.2019.8794021
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - n-shot learning, i.e., learning a classifier from only few or even one training samples per class, is the ultimate goal in minimizing the cost of sample acquisition. This is esp. important for active sensing tasks like tactile material classification. Achieving high classification accuracy from only few samples is typically possible only when pre-knowledge is used. In n-shot transfer learning, knowledge from pre-training on a large knowledge set with many classes and samples per class has to be transferred to support the training for a given task set with only few samples per new class. In this paper, we show for the first time that deep end-to-end transfer learning is feasible for tactile material classification. Based on the previously presented (TactNet-II) [1], a deep convolutional neural network (CNN) which reaches superhuman tactile classification performance, we adapt state-of-the art deep transfer learning methods. We evaluate the resulting deep n-shot learning methods with a publicly available tactile material data set with 36 materials [1] in a 6-way n-shot learning task with 30 materials in the knowledge set. In 1-shot learning, our deep transfer learning method reaches 75.5% classification accuracy and in 10-shot more than 90%, outperforming classification without knowledge transfer by more than 40%. This results in an up to 15 time reduction in the number of samples needed to reach a desired accuracy level. We also provide insights of the inner workings of the derived deep transfer learning methods.
ER  - 

TY  - CONF
TI  - Towards Effective Tactile Identification of Textures using a Hybrid Touch Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4269
EP  - 4275
AU  - T. Taunyazov
AU  - H. F. Koh
AU  - Y. Wu
AU  - C. Cai
AU  - H. Soh
PY  - 2019
KW  - convolutional neural nets
KW  - feature extraction
KW  - humanoid robots
KW  - image classification
KW  - image texture
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - recurrent neural nets
KW  - robot vision
KW  - tactile sensors
KW  - hybrid touch approach
KW  - human sense
KW  - interacted objects
KW  - standard sensory modalities
KW  - sliding movements
KW  - tactile-based texture classification
KW  - machine-learning methods
KW  - surface textures
KW  - hand-engineered features
KW  - recurrent neural network layers
KW  - feature representations
KW  - tactile data
KW  - touch data
KW  - tactile identification
KW  - sense of touch
KW  - touch movements
KW  - convolutional neural network layers
KW  - iCub platform
KW  - Support vector machines
KW  - Robot sensing systems
KW  - Standards
KW  - Machine learning
KW  - Recurrent neural networks
DO  - 10.1109/ICRA.2019.8793967
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The sense of touch is arguably the first human sense to develop. Empowering robots with the sense of touch may augment their understanding of interacted objects and the environment beyond standard sensory modalities (e.g., vision). This paper investigates the effect of hybridizing touch and sliding movements for tactile-based texture classification. We develop three machine-learning methods within a framework to discriminate between surface textures; the first two methods use hand-engineered features, whilst the third leverages convolutional and recurrent neural network layers to learn feature representations from raw data. To compare these methods, we constructed a dataset comprising tactile data from 23 textures gathered using the iCub platform under a loosely constrained setup, i.e., with nonlinear motion. In line with findings from neuroscience, our experiments show that a good initial estimate can be obtained via touch data, which can be further refined via sliding; combining both touch and sliding data results in 98% classification accuracy over unseen test data.
ER  - 

TY  - CONF
TI  - “Touching to See” and “Seeing to Feel”: Robotic Cross-modal Sensory Data Generation for Visual-Tactile Perception
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4276
EP  - 4282
AU  - J. Lee
AU  - D. Bollegala
AU  - S. Luo
PY  - 2019
KW  - data visualisation
KW  - haptic interfaces
KW  - image texture
KW  - mobile robots
KW  - neural nets
KW  - robot vision
KW  - touch (physiological)
KW  - visual perception
KW  - robotic cross-modal sensory data generation
KW  - visual-tactile perception
KW  - visual-tactile stimulus
KW  - unimodal visual perception
KW  - robotic tasks
KW  - texture perception
KW  - conditional generative adversarial networks
KW  - pseudovisual images
KW  - tactile outputs
KW  - perception performance
KW  - sensory outputs
KW  - ViTac dataset
KW  - Robot sensing systems
KW  - Visualization
KW  - Task analysis
KW  - Image color analysis
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8793763
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The integration of visual-tactile stimulus is common while humans performing daily tasks. In contrast, using unimodal visual or tactile perception limits the perceivable dimensionality of a subject. However, it remains a challenge to integrate the visual and tactile perception to facilitate robotic tasks. In this paper, we propose a novel framework for the cross-modal sensory data generation for visual and tactile perception. Taking texture perception as an example, we apply conditional generative adversarial networks to generate pseudo visual images or tactile outputs from data of the other modality. Extensive experiments on the ViTac dataset of cloth textures show that the proposed method can produce realistic outputs from other sensory inputs. We adopt the structural similarity index to evaluate similarity of the generated output and real data and results show that realistic data have been generated. Classification evaluation has also been performed to show that the inclusion of generated data can improve the perception performance. The proposed framework has potential to expand datasets for classification tasks, generate sensory outputs that are not easy to access, and also advance integrated visual-tactile perception.
ER  - 

TY  - CONF
TI  - Shear-invariant Sliding Contact Perception with a Soft Tactile Sensor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4283
EP  - 4289
AU  - K. Aquilina
AU  - D. A. W. Barton
AU  - N. F. Lepora
PY  - 2019
KW  - manipulators
KW  - principal component analysis
KW  - shear deformation
KW  - tactile sensors
KW  - continuous contact data
KW  - shear deformation
KW  - output path-dependent readings
KW  - contact readings
KW  - continuous-contact tasks
KW  - sensor signal
KW  - shear-invariant perception method
KW  - principal component analysis
KW  - sliding motion
KW  - compliant tactile sensor
KW  - continuous tactile contact
KW  - contour-following task
KW  - soft tactile sensor
KW  - manipulation tasks
KW  - tactile perception systems
KW  - shear-invariant sliding contact perception
KW  - Principal component analysis
KW  - Training
KW  - Tactile sensors
KW  - Task analysis
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8794307
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Manipulation tasks often require robots to be continuously in contact with an object. Therefore tactile perception systems need to handle continuous contact data. Shear deformation causes the tactile sensor to output path-dependent readings in contrast to discrete contact readings. As such, in some continuous-contact tasks, sliding can be regarded as a disturbance over the sensor signal. Here we present a shear-invariant perception method based on principal component analysis (PCA) which outputs the required information about the environment despite sliding motion. A compliant tactile sensor (the TacTip) is used to investigate continuous tactile contact. First, we evaluate the method offline using test data collected whilst the sensor slides over an edge. Then, the method is used within a contour-following task applied to 6 objects with varying curvatures; all contours are successfully traced. The method demonstrates generalisation capabilities and could underlie a more sophisticated controller for challenging manipulation or exploration tasks in unstructured environments.
ER  - 

TY  - CONF
TI  - Soft tactile sensing: retrieving force, torque and contact point information from deformable surfaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4290
EP  - 4296
AU  - S. Ciotti
AU  - T. Sun
AU  - E. Battaglia
AU  - A. Bicchi
AU  - H. Liu
AU  - M. Bianchi
PY  - 2019
KW  - force measurement
KW  - force sensors
KW  - iterative methods
KW  - surface topography measurement
KW  - tactile sensors
KW  - torque measurement
KW  - contact point information
KW  - geometric surface description
KW  - contact centroid
KW  - force-deformation characteristics
KW  - force-indentation behavior
KW  - intrinsic soft tactile sensing
KW  - ITS
KW  - iterative procedure
KW  - soft surface deformation characteristics
KW  - ellipsoid silicone specimens
KW  - ROS-based toolbox
KW  - Robot sensing systems
KW  - Force
KW  - Surface impedance
KW  - Mathematical model
KW  - Strain
DO  - 10.1109/ICRA.2019.8794087
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Intrinsic Tactile Sensing (ITS) is a well-established technique, relying on force/torque and geometric surface description to find contact centroids. The method works well for rigid surfaces. However, finding a solution for deformable surfaces is an open issue. This work presents two solutions to extend ITS to deformable surfaces, relying on force-deformation characteristics of the surface under exploration: (i) a closed-form approach that calculates the contact centroid using standard ITS, but on a shrunk geometry approximating the deformed surface; (ii) an iterative procedure that takes into account soft surface deformation, and force/torque equilibrium to minimize a cost function. We have tested both using ellipsoid silicone specimens, with different softness levels and indented along different directions. Both linear and quadratic fitting for the force-indentation behavior were employed. The two methods have distinct advantages and limitations. However, a combination of two methods, using one to produce the initial guess for the other, turns out to be very effective. Indeed, in our validation this solution showed convergence under 1ms, attaining errors lower than 1 mm. The proposed approaches were implemented in a ROS-based toolbox, integrating both solutions.
ER  - 

TY  - CONF
TI  - Miniaturization of multistage high dynamic range six-axis force sensor composed of resin material
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4297
EP  - 4302
AU  - D. Okumura
AU  - S. Sakaino
AU  - T. Tsuji
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - robot vision
KW  - mobile robots
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - path planning
KW  - motion control
KW  - medical robotics
KW  - optimisation
KW  - object detection
KW  - position control
KW  - collision avoidance
KW  - Force sensors
KW  - Structural beams
KW  - Force
KW  - Robot sensing systems
KW  - Stress
KW  - Strain
KW  - Creep
DO  - 10.1109/ICRA.2019.8793929
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The following topics are dealt with: mobile robots; learning (artificial intelligence); robot vision; path planning; motion control; medical robotics; optimisation; object detection; position control; collision avoidance.
ER  - 

TY  - CONF
TI  - Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4303
EP  - 4309
AU  - Y. Yoon
AU  - W. Ko
AU  - M. Jang
AU  - J. Lee
AU  - J. Kim
AU  - G. Lee
PY  - 2019
KW  - gesture recognition
KW  - humanoid robots
KW  - human-robot interaction
KW  - knowledge based systems
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - speech recognition
KW  - text analysis
KW  - TED talks
KW  - NAO robot
KW  - speech text understanding
KW  - end-to-end neural network model
KW  - learning-based co-speech gesture generation
KW  - human labor
KW  - rule-based speech-gesture association
KW  - humanoid robots
KW  - end-to-end learning
KW  - robots learn social skills
KW  - Robots
KW  - Videos
KW  - Decoding
KW  - Natural languages
KW  - Training
KW  - Recurrent neural networks
KW  - Principal component analysis
DO  - 10.1109/ICRA.2019.8793720
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.
ER  - 

TY  - CONF
TI  - The Doctor will See You Now: Could a Robot Be a medical Receptionist?
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4310
EP  - 4316
AU  - C. J. Sutherland
AU  - B. K. Ahn
AU  - B. Brown
AU  - J. Lim
AU  - D. L. Johanson
AU  - E. Broadbent
AU  - B. A. MacDonald
AU  - H. S. Ahn
PY  - 2019
KW  - human computer interaction
KW  - human-robot interaction
KW  - interactive systems
KW  - medical administrative data processing
KW  - visual perception
KW  - personal friend
KW  - doctor
KW  - medical receptionist
KW  - robotic system
KW  - clinic visit
KW  - wizard-of-Oz study
KW  - friendly receptionist
KW  - people perceptions
KW  - Educational robots
KW  - Medical services
KW  - Service robots
KW  - Head
KW  - Task analysis
KW  - Software
DO  - 10.1109/ICRA.2019.8794439
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A robot cannot be warm and friendly - or can it? To explore whether a robot can be a medical receptionist, we developed a robotic system for interacting with patients at a doctor's clinic, including acting friendly. We designed the robot to interact naturally with patients at the start and finish of a clinic visit. We investigated people's perceptions to the robot in a wizard-of-Oz study, where the participants interacted with the robot over four interactions. 40 participants evaluated the robot. The results indicate the participants thought the robot could be a friendly receptionist, especially after repeated interactions with the robot. However, the participants mainly thought the robot was friendly in a “professional” way, rather than a personal friend.
ER  - 

TY  - CONF
TI  - Designing a Personality-Driven Robot for a Human-Robot Interaction Scenario
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4317
EP  - 4324
AU  - H. B. Mohammadi
AU  - N. Xirakia
AU  - F. Abawi
AU  - I. Barykina
AU  - K. Chandran
AU  - G. Nair
AU  - C. Nguyen
AU  - D. Speck
AU  - T. Alpay
AU  - S. Griffiths
AU  - S. Heinrich
AU  - E. Strahl
AU  - C. Weber
AU  - S. Wermter
PY  - 2019
KW  - control engineering computing
KW  - convolutional neural nets
KW  - game theory
KW  - humanoid robots
KW  - human-robot interaction
KW  - psychology
KW  - autonomous AI system
KW  - dice game scenario
KW  - competitive personality
KW  - humanoid robot
KW  - user interaction
KW  - turn-taking dice game
KW  - HRI scenario
KW  - human-robot interaction scenario
KW  - convolutional neural network
KW  - participants facial feedback
KW  - socially engaged personality
KW  - godspeed questionnaire
KW  - mind perception questionnaire
KW  - personality-driven robot
KW  - Robots
KW  - Games
KW  - Task analysis
KW  - Grasping
KW  - Natural languages
KW  - Face
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793770
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present an autonomous AI system designed for a Human-Robot Interaction (HRI) study, set around a dice game scenario. We conduct a case study to answer our research question: Does a robot with a socially engaged personality lead to a higher acceptance than a competitive personality? The flexibility of our proposed system allows us to construct and attribute two different personalities to a humanoid robot: a socially engaged personality that maximizes its user interaction and a competitive personality that is focused on playing and winning the game. We evaluate both personalities in a user study, in which the participants play a turn-taking dice game with the robot. Each personality is assessed with four different evaluation tools: 1) the Godspeed Questionnaire, 2) the Mind Perception Questionnaire, 3) a custom questionnaire concerning the overall HRI experience, and 4) a Convolutional Neural Network analyzing the emotions on the participants' facial feedback throughout the game. Our results show that the socially engaged personality evokes stronger emotions among the participants and is rated higher in likability and animacy than the competitive one. We conclude that designing the robot with a socially engaged personality contributes to a higher acceptance within an HRI scenario.
ER  - 

TY  - CONF
TI  - How Shall I Drive? Interaction Modeling and Motion Planning towards Empathetic and Socially-Graceful Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4325
EP  - 4331
AU  - Y. Ren
AU  - S. Elliott
AU  - Y. Wang
AU  - Y. Yang
AU  - W. Zhang
PY  - 2019
KW  - game theory
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - predictive control
KW  - remotely operated vehicles
KW  - AV
KW  - human driver
KW  - social awareness
KW  - passive-aggressive motions
KW  - interaction modeling
KW  - socially-graceful driving
KW  - autonomous vehicles
KW  - two-player game
KW  - model predictive control
KW  - social gracefulness
KW  - intent inference
KW  - motion planning
KW  - Planning
KW  - Games
KW  - Vehicles
KW  - Adaptation models
KW  - Inference algorithms
KW  - Estimation
KW  - Loss measurement
DO  - 10.1109/ICRA.2019.8793835
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While intelligence of autonomous vehicles (AVs) has significantly advanced in recent years, accidents involving AVs suggest that these autonomous systems lack gracefulness in driving when interacting with human drivers. In the setting of a two-player game, we propose model predictive control based on social gracefulness, which is measured by the discrepancy between the actions taken by the AV and those that could have been taken in favor of the human driver. We define social awareness as the ability of an agent to infer such favorable actions based on knowledge about the other agent's intent, and further show that empathy, i.e., the ability to understand others' intent by simultaneously inferring others' understanding of the agent's self intent, is critical to successful intent inference. Lastly, through an intersection case, we show that the proposed gracefulness objective allows an AV to learn more sophisticated behavior, such as passive-aggressive motions that gently force the other agent to yield.
ER  - 

TY  - CONF
TI  - Detection-by-Localization: Maintenance-Free Change Object Detector
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4348
EP  - 4355
AU  - T. Kanji
PY  - 2019
KW  - feature extraction
KW  - image fusion
KW  - image retrieval
KW  - image segmentation
KW  - object detection
KW  - query processing
KW  - robot vision
KW  - object-level subimages
KW  - pixel-wise LoC maps
KW  - detection-by-localization scheme
KW  - ranking function
KW  - ranked list
KW  - ranking based self-localization model
KW  - unsupervised rank fusion
KW  - cross-season change detection
KW  - maintenance-free change object detector
KW  - likelihood-of-change
KW  - object-level change detection
KW  - generalized task
KW  - query image
KW  - subimagelevel pixel-wise LoC maps
KW  - publicly available North Campus Long-Term dataset
KW  - publicly available NCLT dataset
KW  - multimodal information retrieval
KW  - MMR
KW  - Image segmentation
KW  - Task analysis
KW  - Robots
KW  - Computational modeling
KW  - Visualization
KW  - Databases
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793482
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent researches demonstrate that selflocalization performance is a very useful measure of likelihood-of-change (LoC) for change detection. In this paper, this “detection-by-localization” scheme is studied in a novel generalized task of object-level change detection. In our framework, a given query image is segmented into object-level subimages (termed “scene parts”), which are then converted to subimagelevel pixel-wise LoC maps via the detection-by-localization scheme. Our approach models a self-localization system as a ranking function, outputting a ranked list of reference images, without requiring relevance score. Thanks to this new setting, we can generalize our approach to a broad class of selflocalization systems. We further propose an aggregation of different self-localization results from different queries so as to achieve higher precision. Our ranking based self-localization model allows to fuse self-localization results from different modalities via an unsupervised rank fusion derived from a field of multi-modal information retrieval (MMR). Our framework does not rely on the raw-score-merging hypothesis. Challenging experiments of cross-season change detection using the publicly available North Campus Long-Term (NCLT) dataset validates the efficacy of our proposed method.
ER  - 

TY  - CONF
TI  - Customized Object Recognition and Segmentation by One Shot Learning with Human Robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4356
EP  - 4361
AU  - P. Guo
AU  - L. Zhang
AU  - L. Cao
AU  - Y. Shen
AU  - X. Shi
AU  - H. Ren
AU  - Y. Zhang
PY  - 2019
KW  - Big Data
KW  - human-robot interaction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - object recognition
KW  - human robot interaction
KW  - robotic applications
KW  - deep learning models
KW  - labeled training data
KW  - pre-defined big data
KW  - segmentation method
KW  - target object
KW  - data generation method
KW  - segmentation model
KW  - lightweight segmentation net
KW  - object recognition
KW  - one shot learning
KW  - Proposals
KW  - Robots
KW  - Adaptation models
KW  - Training data
KW  - Data models
KW  - Object recognition
KW  - Testing
DO  - 10.1109/ICRA.2019.8793845
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There are two difficulties to utilize state-of-the-art object recognition/detection/segmentation methods to robotic applications. First, most of the deep learning models heavily depend on large amounts of labeled training data, which are expensive to obtain for each individual application. Second, the object categories must be pre-defined in the dataset, thus not practical to scenarios with varying object categories. To alleviate the reliance on pre-defined big data, this paper proposes a customized object recognition and segmentation method. It aims to recognize and segment any object defined by the user, given only one annotation. There are three steps in the proposed method. First, the user takes an exemplar video of the target object with the robot, defines its name, and mask its boundary on only one frame. Then the robot automatically propagates the annotation through the exemplar video based on a proposed data generation method. In the meantime, a segmentation model continuously updates itself on the generated data. Finally, only a lightweight segmentation net is required at testing stage, to recognize and segment the user-defined object in any scenes.
ER  - 

TY  - CONF
TI  - SEG-VoxelNet for 3D Vehicle Detection from RGB and LiDAR Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4362
EP  - 4368
AU  - J. Dou
AU  - J. Xue
AU  - J. Fang
PY  - 2019
KW  - image colour analysis
KW  - image segmentation
KW  - object detection
KW  - optical radar
KW  - SEG-VoxelNet
KW  - LiDAR data
KW  - RGB images
KW  - LiDAR point clouds
KW  - autonomous driving scenarios
KW  - semantic segmentation technique
KW  - 3D LiDAR point cloud based detection
KW  - image semantic segmentation network
KW  - SEG-Net
KW  - improved-VoxelNet
KW  - semantic segmentation map
KW  - point cloud data
KW  - image semantic feature
KW  - KITTI 3D vehicle detection benchmark
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Semantics
KW  - Vehicle detection
KW  - Feature extraction
KW  - Image segmentation
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8793492
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a SEG-VoxelNet that takes RGB images and LiDAR point clouds as inputs for accurately detecting 3D vehicles in autonomous driving scenarios, which for the first time introduces semantic segmentation technique to assist the 3D LiDAR point cloud based detection. Specifically, SEG-VoxelNet is composed of two sub-networks: an image semantic segmentation network (SEG-Net) and an improved-VoxelNet. The SEG-Net generates the semantic segmentation map which represents the probability of the category for each pixel. The improved-VoxelNet is capable of effectively fusing point cloud data with image semantic feature and generating accurate 3D bounding boxes of vehicles. Experiments on the KITTI 3D vehicle detection benchmark show that our approach outperforms the methods of state-of-the-art.
ER  - 

TY  - CONF
TI  - Object Classification Based on Unsupervised Learned Multi-Modal Features For Overcoming Sensor Failures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4369
EP  - 4375
AU  - J. Nitsch
AU  - J. Nieto
AU  - R. Siegwart
AU  - M. Schmidt
AU  - C. Cadena
PY  - 2019
KW  - driver information systems
KW  - feature extraction
KW  - image classification
KW  - image fusion
KW  - unsupervised learning
KW  - unsupervised learned multimodal features
KW  - autonomous driving applications
KW  - road users
KW  - road side infrastructure
KW  - autonomous cars
KW  - classification modules
KW  - unseen sensor noise
KW  - object classification module
KW  - total sensor failure
KW  - unsupervised feature training
KW  - uni-modal classifiers training
KW  - multimodal classifiers training
KW  - feature space
KW  - sensor modalities
KW  - decision module
KW  - unsupervised learned multi-modal features
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Robot sensing systems
KW  - Computer architecture
KW  - Training
KW  - Decoding
KW  - Convolutional codes
DO  - 10.1109/ICRA.2019.8793628
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For autonomous driving applications it is critical to know which type of road users and road side infrastructure are present to plan driving manoeuvres accordingly. Therefore autonomous cars are equipped with different sensor modalities to robustly perceive its environment. However, for classification modules based on machine learning techniques it is challenging to overcome unseen sensor noise. This work presents an object classification module operating on unsupervised learned multi-modal features with the ability to overcome gradual or total sensor failure. A two stage approach composed of an unsupervised feature training and a uni-modal and multimodal classifiers training is presented. We propose a simple but effective decision module switching between uni-modal and multi-modal classifiers based on the closeness in the feature space to the training data. Evaluations on the ModelNet 40 data set show that the proposed approach has a 14% accuracy gain compared to a late fusion approach operating on a noisy point cloud data and a 6% accuracy gain when operating on noisy image data.
ER  - 

TY  - CONF
TI  - SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4376
EP  - 4382
AU  - B. Wu
AU  - X. Zhou
AU  - S. Zhao
AU  - X. Yue
AU  - K. Keutzer
PY  - 2019
KW  - image segmentation
KW  - object detection
KW  - optical radar
KW  - rendering (computer graphics)
KW  - unsupervised learning
KW  - LiDAR point cloud
KW  - deep-learning-based approaches
KW  - point cloud segmentation
KW  - SqueezeSetV2
KW  - data collection
KW  - domain-adaptation training pipeline
KW  - domain adaptation pipeline
KW  - unsupervised domain adaptation
KW  - road-object segmentation
KW  - domain-adaptation methods
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Training
KW  - Adaptation models
KW  - Data models
KW  - Pipelines
KW  - Sensors
DO  - 10.1109/ICRA.2019.8793495
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Earlier work demonstrates the promise of deep-learning-based approaches for point cloud segmentation; however, these approaches need to be improved to be practically useful. To this end, we introduce a new model SqueezeSegV2. With an improved model structure, SqueezeSetV2 is more robust against dropout noises in LiDAR point cloud and therefore achieves significant accuracy improvement. Training models for point cloud segmentation requires large amounts of labeled data, which is expensive to obtain. To sidestep the cost of data collection and annotation, simulators such as GTA-V can be used to create unlimited amounts of labeled, synthetic data. However, due to domain shift, models trained on synthetic data often do not generalize well to the real world. Existing domain-adaptation methods mainly focus on images and most of them cannot be directly applied to point clouds. We address this problem with a domain-adaptation training pipeline consisting of three major components: 1) learned intensity rendering, 2) geodesic correlation alignment, and 3) progressive domain calibration. When trained on real data, our new model exhibits segmentation accuracy improvements of 6.0-8.6% over the original SqueezeSeg. When training our new model on synthetic data using the proposed domain adaptation pipeline, we nearly double test accuracy on real-world data, from 29.0% to 57.4%. Our source code and synthetic dataset are open sourced. https://github.com/xuanyuzhou98/SqueezeSegV2.
ER  - 

TY  - CONF
TI  - RoPose-Real: Real World Dataset Acquisition for Data-Driven Industrial Robot Arm Pose Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4389
EP  - 4395
AU  - T. Gulde
AU  - D. Ludl
AU  - J. Andrejtschik
AU  - S. Thalji
AU  - C. Curio
PY  - 2019
KW  - control engineering computing
KW  - convolutional neural nets
KW  - industrial manipulators
KW  - manipulator kinematics
KW  - pose estimation
KW  - production engineering computing
KW  - robot system
KW  - world robotic scenario
KW  - world dataset acquisition
KW  - data-driven industrial robot arm pose estimation
KW  - smart sensory systems
KW  - industrial robots
KW  - mobile platforms
KW  - convolutional neural network architecture
KW  - industrial robot arm system
KW  - automatically annotated datasets
KW  - extracted pose information
KW  - RoPose-system
KW  - Calibration
KW  - Robot kinematics
KW  - Cameras
KW  - Robot vision systems
KW  - Tools
DO  - 10.1109/ICRA.2019.8793900
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - It is necessary to employ smart sensory systems in dynamic and mobile workspaces where industrial robots are mounted on mobile platforms. Such systems should be aware of flexible and non-stationary workspaces and able to react autonomously to changing situations. Building upon our previously presented RoPose-system [1], which employs a convolutional neural network architecture that has been trained on pure synthetic data to estimate the kinematic chain of an industrial robot arm system, we now present RoPose-Real. RoPose-Real extends the prior system with a comfortable and targetless extrinsic calibration tool, to allow for the production of automatically annotated datasets for real robot systems. Furthermore, we use the novel datasets to train the estimation network with real world data. The extracted pose information is used to automatically estimate the observing sensor pose relative to the robot system. Finally we evaluate the performance of the presented subsystems in a real world robotic scenario.
ER  - 

TY  - CONF
TI  - A Framework for Self-Training Perceptual Agents in Simulated Photorealistic Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4396
EP  - 4402
AU  - P. Mania
AU  - M. Beetz
PY  - 2019
KW  - computer games
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - virtual reality
KW  - self-training perceptual agents
KW  - simulated photorealistic environments
KW  - high-performance perception
KW  - mobile robotic agents
KW  - gaming industry
KW  - game engines
KW  - perceptual agent
KW  - virtual environment
KW  - task-specific object distribution
KW  - description language
KW  - learning environments
KW  - object recognition
KW  - sensory input
KW  - robotic system
KW  - Task analysis
KW  - Robots
KW  - Training data
KW  - Engines
KW  - Virtual environments
KW  - Games
KW  - Data models
KW  - Self-Training Perception
KW  - Robotic Simulation
KW  - Unreal Engine
KW  - Scenario Description
DO  - 10.1109/ICRA.2019.8793474
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The development of high-performance perception for mobile robotic agents is still challenging. Learning appropriate perception models usually requires extensive amounts of labeled training data that ideally follows the same distribution as the data an agent will encounter in its target task. Recent developments in gaming industry led to game engines able to generate photorealistic environments in real-time, which can be used to realistically simulate the sensory input of an agent.We propose a novel framework which allows the definition of different learning scenarios and instantiates these scenarios in a high quality game engine where a perceptual agent can act and learn in. The scenarios are specified in a newly developed scenario description language that allows the parametrization of the virtual environment and the perceptual agent. New scenarios can be sampled from a task-specific object distribution that allows the automatic generation of extensive amounts of different learning environments for the perceptual agent.We will demonstrate the plausibility of the framework by conducting object recognition experiments on a real robotic system which has been trained within our framework.
ER  - 

TY  - CONF
TI  - Fast and Precise Detection of Object Grasping Positions with Eigenvalue Templates
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4403
EP  - 4409
AU  - K. Mano
AU  - T. Hasegawa
AU  - T. Yamashita
AU  - H. Fujiyoshi
AU  - Y. Domae
PY  - 2019
KW  - dexterous manipulators
KW  - eigenvalues and eigenfunctions
KW  - grippers
KW  - industrial robots
KW  - object detection
KW  - position control
KW  - singular value decomposition
KW  - hand templates
KW  - target object
KW  - optimum grasping posture
KW  - singular value decomposition
KW  - eigenvalue templates
KW  - parallel hands
KW  - three-finger hands
KW  - industrial robots
KW  - object grasping position detection
KW  - fast graspability evaluation
KW  - eigenfunctions
KW  - arbitrary parameters
KW  - Eigenvalues and eigenfunctions
KW  - Grasping
KW  - Convolution
KW  - Three-dimensional displays
KW  - Collision avoidance
KW  - Service robots
DO  - 10.1109/ICRA.2019.8793830
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fast Graspability Evaluation (FGE) has been proposed as a method for detecting grasping positions on objects and is now being used for industrial robots. FGE uses convolution of hand templates with regions on the target object to estimate the optimum grasping posture. However, the hand opening width and rotation angles must be set with high resolution to achieve highly accurate results and the computational load is high. To address that issue, we propose a method in which hand templates are represented in compact form for faster processing by using singular value decomposition. Applying singular value decomposition enables hand templates to be represented as linear combinations of a small number of eigenvalue templates and eigenfunctions. Eigenfunctions take discrete values, but response values can be calculated with arbitrary parameters by fitting a continuous function. Experimental results show that the proposed method reduces computation time by two thirds while maintaining the same detection accuracy as conventional FGE for both parallel hands and three-finger hands.
ER  - 

TY  - CONF
TI  - Improved Coverage Path Planning Using a Virtual Sensor Footprint: a Case Study on Demining
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4410
EP  - 4415
AU  - S. Dogru
AU  - L. Marques
PY  - 2019
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - sensors
KW  - physical sensor
KW  - virtual footprint
KW  - optimization problem
KW  - energy performances
KW  - virtual sensor footprint
KW  - coverage path planning problem
KW  - robotic arm
KW  - larger areas
KW  - platform moves
KW  - larger footprint
KW  - metal detector
KW  - Robot sensing systems
KW  - Manipulators
KW  - Metals
KW  - Detectors
KW  - Trajectory
KW  - Shape
DO  - 10.1109/ICRA.2019.8793695
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Coverage performance in a coverage path planning problem depends both on the path created and on the footprint of the sensor used. The footprint can be increased either by increasing the size of the sensor, or by mounting the sensor on a robotic arm to allow scanning over larger areas as the platform moves, effectively creating a virtual sensor with a larger footprint than the physical sensor's. However, the virtual footprint comes at a cost requiring formulating an optimization problem for the area of interest. In this work, three common strategies to use a metal detector on a platform are discussed, their time and energy performances are formulated and the corresponding optima are found.
ER  - 

TY  - CONF
TI  - Model-Based Estimation of the Gravity-Loaded Shape and Scene Depth for a Slim 3-Actuator Continuum Robot with Monocular Visual Feedback
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4416
EP  - 4421
AU  - Y. Chen
AU  - S. Zhang
AU  - L. Zeng
AU  - X. Zhu
AU  - K. Xu
PY  - 2019
KW  - actuators
KW  - cameras
KW  - feedback
KW  - gravity
KW  - image filtering
KW  - Kalman filters
KW  - manipulator kinematics
KW  - motion control
KW  - nonlinear filters
KW  - robot vision
KW  - shape control
KW  - shape measurement
KW  - model-based estimation
KW  - slim 3-actuator continuum robot
KW  - separately modeled segments
KW  - actuated segments
KW  - gravity-loaded shape estimation
KW  - scene depth estimation
KW  - monocular visual feedback
KW  - robot movements
KW  - manipulation capabilities
KW  - confined spaces
KW  - robot control
KW  - constant curvature
KW  - variable curvature
KW  - spatial locations
KW  - robot shape
KW  - monocular camera
KW  - unscented Kalman filters
KW  - UKF
KW  - feature depth estimation
KW  - robot kinematics model
KW  - motion control
KW  - Cameras
KW  - Estimation
KW  - Conferences
KW  - Automation
KW  - IEEE members
KW  - Kinematics
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8793861
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fruitful developments on continuum robots have been witnessed in recent years due to their movements and manipulation capabilities in confined spaces. Due to the nature that a continuum robot has an infinite number of DoFs (Degrees of Freedom), majority of the existing systems deployed abundant actuators such that the robot can be controlled in separately modeled and actuated segments with constant or variable curvature. As the shape of a continuum robot is always jointly determined by its actuation and the interactions from the environment, it is hence worth exploring the opposite approach that how a task can be accomplished with a minimal number of actuators. This paper presents the first step of such an investigation where a slim 3-actuator continuum robot is actuated to reach different spatial locations under gravity. As the gravity greatly affects the robot's shape, a monocular camera, together with two UKFs (Unscented Kalman Filters), was used to concurrently estimate the robot's shape and the feature depth. Then the estimated shape can be used in updating the kinematics model of the robot to achieve motion control. Experiments were conducted to validate the effectiveness of the proposed shape estimation, which promises the motion control implementation in the near future work.
ER  - 

TY  - CONF
TI  - Design of a Modular Continuum Robot Segment for use in a General Purpose Manipulator*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4430
EP  - 4435
AU  - N. P. Castledine
AU  - J. H. Boyle
AU  - J. Kim
PY  - 2019
KW  - actuators
KW  - bending
KW  - control system synthesis
KW  - DC motors
KW  - manipulators
KW  - motion control
KW  - position control
KW  - three-dimensional printing
KW  - torsion
KW  - modular continuum robot segment
KW  - general purpose manipulator
KW  - tendon-driven continuum robot segment
KW  - modular design
KW  - continuous flexible core
KW  - rigid interlocking vertebrae
KW  - torsional movement
KW  - antagonistic tendon pairs
KW  - single geared DC motor
KW  - bulky actuation unit
KW  - torsional rigidity
KW  - rigid vertebrae
KW  - tendons
KW  - multimaterial 3D printing
KW  - Tendons
KW  - Manipulators
KW  - Actuators
KW  - Routing
KW  - Shafts
DO  - 10.1109/ICRA.2019.8794249
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the development of a tendon-driven continuum robot segment with a modular design, simple construction and significant lifting capabilities. The segment features a continuous flexible core combined with rigid interlocking vertebrae evenly distributed along its length. This design allows bending in two degrees of freedom while minimising torsional movement. The segment is actuated by two antagonistic tendon pairs, each of which is driven by a single geared DC motor. Modularity is achieved by embedding these motors in one end of the segment, avoiding the need for a bulky actuation unit and allowing variable numbers of segments to be connected. The design features a large hollow central bore which could be used as a vacuum channel for suction-assisted gripping or to allow ingress and egress of fluids. The design process goes through four iterations, the final two of which are subjected to quantitative experiments to evaluate workspace, lifting capabilities and torsional rigidity. All iterations are fabricated using multi-material 3D printing, which allows the entire structure to be printed as a pre-assembled unit with the rigid vertebrae fused to the flexible core. Assembly is then a simple case of inserting the motors and connecting the tendons. This unconventional manufacturing approach is found to be efficient, effective and relatively cheap.
ER  - 

TY  - CONF
TI  - Reshaping Particle Configurations by Collisions with Rigid Objects
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4436
EP  - 4443
AU  - S. Shahrokhi
AU  - H. Zhao
AU  - A. T. Becker
PY  - 2019
KW  - actuators
KW  - collision avoidance
KW  - multi-robot systems
KW  - shear modulus
KW  - uniform global external field
KW  - magnetic fields
KW  - workspace obstacles
KW  - shape control
KW  - navigation
KW  - driving force
KW  - torque
KW  - rectangular rigid body
KW  - particle group
KW  - circular workspace
KW  - mean variance configurations
KW  - Shape
KW  - Force
KW  - Torque
KW  - Shape control
KW  - Magnetic resonance imaging
KW  - Magnetoacoustic effects
KW  - Correlation
DO  - 10.1109/ICRA.2019.8794405
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Consider many particles actuated by a uniform global external field (e.g. gravitational or magnetic fields). This paper presents analytical results using workspace obstacles and global inputs to reshape such a group of particles. Shape control of many particles is necessary for conveying information, construction, and navigation. First we show how the particles' characteristic angle of repose can be used to reshape the particles by controlling angle of attack and the magnitude of the driving force. These can then be used to control the force and torque applied to a rectangular rigid body. Next, we examine the full set of stable, achievable mean and variance configurations for the shape of a particle group in two canonical environments: a square and a circular workspace. Finally, we show how workspaces with linear boundary layers can be used to achieve a more rich set of mean and variance configurations.
ER  - 

TY  - CONF
TI  - Velocity Constrained Trajectory Generation for a Collinear Mecanum Wheeled Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4444
EP  - 4450
AU  - M. T. Watson
AU  - D. T. Gladwin
AU  - T. J. Prescott
AU  - S. O. Conran
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - trajectory control
KW  - velocity constrained trajectory generation
KW  - underactuated unstable aerial vehicles
KW  - linear accelerations
KW  - trajectory planner
KW  - trajectory timing characteristics
KW  - omnidirectional balancing robot
KW  - collinear Mecanum wheeled robot
KW  - ground based omnidirectional dynamically balancing robots
KW  - trajectory optimisation methods
KW  - differentially flat model
KW  - collinear Mecanum drive
KW  - Trajectory
KW  - Planning
KW  - Wheels
KW  - Mobile robots
KW  - Transmission line matrix methods
KW  - Acceleration
DO  - 10.1109/ICRA.2019.8794019
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While much research has been conducted into the generation of smooth trajectories for underactuated unstable aerial vehicles such as quadrotors, less attention has been paid to the application of the same techniques to ground based omnidirectional dynamically balancing robots. These systems have more control authority over their linear accelerations than aerial vehicles, meaning trajectory smoothness is less of a critical design parameter. However, when operating in indoor environments these systems must often adhere to relatively low velocity constraints, resulting in very conservative trajectories when enforced using existing trajectory optimisation methods. This paper makes two contributions; this gap is bridged by the extension of these existing methods to create a fast velocity constrained trajectory planner, with trajectory timing characteristics derived from the optimal minimum-time solution of a simplified acceleration and velocity constrained model. Next, a differentially flat model of an omnidirectional balancing robot utilizing a collinear Mecanum drive is derived, which is used to allow an experimental prototype of this configuration to smoothly follow these velocity constrained trajectories.
ER  - 

TY  - CONF
TI  - Vibration Control for Manipulators on a Translationally Flexible Base
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4451
EP  - 4457
AU  - F. Beck
AU  - G. Garofalo
AU  - C. Ott
PY  - 2019
KW  - damping
KW  - flexible manipulators
KW  - Lyapunov methods
KW  - manipulator dynamics
KW  - numerical analysis
KW  - springs (mechanical)
KW  - stability
KW  - vibration control
KW  - vibration control
KW  - manipulators
KW  - translationally flexible base
KW  - fundamental oscillatory system
KW  - mass spring system
KW  - control strategy couples
KW  - n-link manipulator
KW  - linear translational stiffness
KW  - conditional stability argument
KW  - base vibrations
KW  - input transformation
KW  - coordinate transformation
KW  - semidefinite Lyapunov functions
KW  - Vibrations
KW  - Manipulator dynamics
KW  - Task analysis
KW  - Robot kinematics
KW  - Damping
DO  - 10.1109/ICRA.2019.8793904
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this contribution the problem of vibration control is studied on the basis of a fundamental oscillatory system consisting of a mass spring system and an additional mass. The proposed control strategy couples the orbits of the two masses such that both masses stop, while simultaneously stabilizing the second mass to a desired equilibrium. Using a coordinate and input transformation, the control strategy is directly transferred to an n-link manipulator mounted on a base with linear translational stiffness. Using semidefinite Lyapunov functions and a conditional stability argument, it is shown that the proposed control strategy damps out base vibrations, while additionally achieving a desired configuration in the task-space. Finally, the proposed method is compared to a state-of-the-art approach using numerical simulations.
ER  - 

TY  - CONF
TI  - Gaussian Processes Model-Based Control of Underactuated Balance Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4458
EP  - 4464
AU  - K. Chen
AU  - J. Yi
AU  - D. Song
PY  - 2019
KW  - control system synthesis
KW  - Gaussian processes
KW  - mobile robots
KW  - pendulums
KW  - predictive control
KW  - robot dynamics
KW  - robust control
KW  - trajectory control
KW  - control design
KW  - robot dynamics
KW  - underactuated balance robot
KW  - model predictive control
KW  - Gaussian process regression model
KW  - trajectory tracking
KW  - learning-based control
KW  - GP model
KW  - robustness
KW  - Furuta pendulum system
KW  - Trajectory
KW  - Mathematical model
KW  - Computational modeling
KW  - Robot kinematics
KW  - Predictive models
KW  - Trajectory tracking
DO  - 10.1109/ICRA.2019.8794097
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Control of underactuated balance robot requires external subsystem trajectory tracking and internal unstable subsystem balancing with limited control authority. We present a learning-based control approach for underactuated balance robots. The tracking and balancing control is designed the controller in fast- and slow-time scales. In the slow-time scale, model predictive control is adopted to plan desired internal state profile to achieve external trajectory tracking task. The internal state is then stabilized around the planned profile in the fast-time scale. The control design is based on a learned Gaussian process (GP) regression model without need of a priori knowledge about the robot dynamics. The controller also incorporates the GP model predicted variance to enhance robustness to modeling errors. Experiments are presented using a Furuta pendulum system.
ER  - 

TY  - CONF
TI  - Analysis of 3D Position Control for a Multi-Agent System of Self-Propelled Agents Steered by a Shared, Global Control Input
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4465
EP  - 4471
AU  - L. Huang
AU  - J. Leclerc
AU  - A. T. Becker
PY  - 2019
KW  - closed loop systems
KW  - controllability
KW  - matrix algebra
KW  - multi-agent systems
KW  - multi-robot systems
KW  - nonlinear control systems
KW  - position control
KW  - control laws
KW  - multiagent system
KW  - self-propelled agents
KW  - shared control input
KW  - global control input
KW  - 3D multiagent position control
KW  - control inputs
KW  - rotation commands
KW  - rotation matrix
KW  - controllability results
KW  - 2D case
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Orbits
KW  - Position control
KW  - Perturbation methods
KW  - Aerospace electronics
KW  - Robots
DO  - 10.1109/ICRA.2019.8793800
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper investigates strategies for 3D multi-agent position control using a shared control input and self-propelled agents. The only control inputs allowed are rotation commands that rotate all agents by the same rotation matrix. In the 2D case, only two degrees-of-freedom (DOF) in position are controllable. We review controllability results in 2D, and then show that interesting things happen in 3D. We provide control laws for steering up to nine DOF in position, which can be mapped in various ways, including to control the x, y, z position of three agents, make four agents meet, or reduce the spread of n agents.
ER  - 

TY  - CONF
TI  - A Heuristic for Task Allocation and Routing of Heterogeneous Robots while Minimizing Maximum Travel Cost
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4531
EP  - 4537
AU  - J. Bae
AU  - J. Lee
AU  - W. Chung
PY  - 2019
KW  - approximation theory
KW  - minimax techniques
KW  - path planning
KW  - robots
KW  - travelling salesman problems
KW  - task allocation
KW  - heterogeneous robots
KW  - path planning problem
KW  - min-max objective
KW  - min-max MDHTSP
KW  - travel cost
KW  - multiple depot heterogeneous traveling salesman problem
KW  - primal-dual technique
KW  - Robots
KW  - Task analysis
KW  - Routing
KW  - Resource management
KW  - Traveling salesman problems
KW  - Approximation algorithms
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794257
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The article proposes a new heuristic for task allocation and routing of heterogeneous robots. Specifically, we consider a path planning problem where there are two (structurally) heterogeneous robots that start from distinctive depots and a set of targets to visit. The objective is to find a tour for each robot in a manner that enables each target location to be visited at least once by one of the robots while minimizing the maximum travel cost. A solution for Multiple Depot Heterogeneous Traveling Salesman Problem (MDHTSP) with min-max objective is in great demand with many potential applications, because it can significantly reduce the job completion duration. However, there are still no reliable algorithms that can run in short amount of time. As an initial idea of solving min-max MDHTSP, we present a heuristic based on a primal-dual technique that solves for a case involving two robots while focusing on task allocation. Based on computational results of the implementation, we show that the proposed algorithm produces a good quality of feasible solution within a relatively short computation time.
ER  - 

TY  - CONF
TI  - Solving Methods for Multi-Robot Missions Planning with Energy Capacity Consideration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4538
EP  - 4544
AU  - M. K. Habibi
AU  - C. Grand
AU  - C. Lesire
AU  - C. Pralet
PY  - 2019
KW  - autonomous aerial vehicles
KW  - iterative methods
KW  - matrix algebra
KW  - minimisation
KW  - multi-robot systems
KW  - path planning
KW  - distance matrix
KW  - multiphase heuristic
KW  - two-phase iterative heuristic
KW  - branch-and-cut algorithm
KW  - decomposition-based approximate methods
KW  - high quality solutions
KW  - heterogeneous vehicles
KW  - energy capacity consideration
KW  - multirobot missions planning
KW  - Robots
KW  - Iterative methods
KW  - Task analysis
KW  - Linear programming
KW  - Planning
KW  - Resource management
KW  - Routing
DO  - 10.1109/ICRA.2019.8793700
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider a problem minimizing the total duration of accomplishing missions performed by heterogeneous vehicles. The problem respects constraints related to vehicles' capabilities and energy capacities. The goal is to determine the best routes of each vehicle deployed by choosing which waypoints to pass and which observations to perform. Each vehicle has a particular distance matrix and a limited energy. In order to provide high quality solutions within reasonable computational time, two decomposition-based approximate methods were implemented: (i) the Multiphase heuristic, and (ii) the Two-Phase iterative heuristic. The performance of the methods is evaluated against the Branch-and-Cut algorithm using generated instances.
ER  - 

TY  - CONF
TI  - Salty-A Domain Specific Language for GR(1) Specifications and Designs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4545
EP  - 4551
AU  - T. Elliott
AU  - M. Alshiekh
AU  - L. R. Humphrey
AU  - L. Pike
AU  - U. Topcu
PY  - 2019
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - formal specification
KW  - mobile robots
KW  - path planning
KW  - program debugging
KW  - remotely operated vehicles
KW  - specification languages
KW  - sanity checking
KW  - high-level specifications
KW  - domain-specific language
KW  - specification optimization
KW  - robot controller design
KW  - specification patterns
KW  - Salty domain specific language
KW  - GR(1) specifications
KW  - correct-by-construction synthesis approach
KW  - generalized reactivity(1) specifications
KW  - Slugs synthesis tool
KW  - multiple unmanned air vehicles
KW  - UAV
KW  - Target tracking
KW  - Robot kinematics
KW  - Tools
KW  - Software
KW  - Unmanned aerial vehicles
KW  - Control systems
DO  - 10.1109/ICRA.2019.8793722
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Designing robot controllers that correctly react to changes in the environment is a time-consuming and error-prone process. An alternative is to use “correct-by-construction” synthesis approaches to automatically generate controller designs from high-level specifications. In particular, Generalized Reactivity(l) or GR(1) specifications are well-suited to express specifications for robots that must act in dynamic environments, and approaches to generate controller designs from GR(1) specifications are highly computationally efficient. Toward that end, this paper presents Salty, a domain-specific language for GR(1) specifications. While tools exist to synthesize system designs from GR(1) specifications, Salty makes such specifications easier to write and debug by supporting features such as richer input and output types, user-defined macros, common specification patterns, and specification optimization and sanity checking. Salty interfaces with the separately developed synthesis tool Slugs to produce a system or controller design, and Salty translates this design to a software implementation in a variety of languages. We demonstrate Salty on an application involving coordination of multiple unmanned air vehicles (UAVs) and provide a workflow for connecting synthesized UAV controllers to freely available UAV planning and simulation software suites UxAS and AMASE.
ER  - 

TY  - CONF
TI  - Persistent Multi-Robot Mapping in an Uncertain Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4552
EP  - 4558
AU  - D. Mitchell
AU  - N. Michael
PY  - 2019
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - path planning
KW  - probability
KW  - multiagent spatio-temporal states
KW  - world model
KW  - persistent multirobot mapping
KW  - uncertain environment
KW  - constrained energy capacities
KW  - typical occupancy map approaches
KW  - static world
KW  - occupancy probability
KW  - grid cells
KW  - promotes revisitation
KW  - unchanging areas
KW  - naive planning
KW  - tractable subproblems
KW  - tractable computation time
KW  - Robots
KW  - Clustering algorithms
KW  - Indexes
KW  - Planning
KW  - Computational modeling
KW  - Sensors
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794469
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a method to deploy teams of robots with constrained energy capacities to persistently maintain a map of an uncertain environment. Typical occupancy map approaches assume a static world; however, we introduce a decay in confidence that degrades the occupancy probability of grid cells and promotes revisitation. Further, sections of the map whose occupancy differs between observations are visited more frequently, while unchanging areas are scheduled less frequently. While naive planning is intractable through the entire space of multi-agent spatio-temporal states, the proposed algorithm decouples planning such that constraints are resolved separately by solving tracTable subproblems. We evaluate this approach in simulation and show how the uncertainty of our world model is maintained below an acceptable threshold while the algorithm retains a tractable computation time.
ER  - 

TY  - CONF
TI  - A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4559
EP  - 4566
AU  - A. K. Tanwani
AU  - N. Mor
AU  - J. Kubiatowicz
AU  - J. E. Gonzalez
AU  - K. Goldberg
PY  - 2019
KW  - cloud computing
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - path planning
KW  - robot programming
KW  - robot vision
KW  - storage management
KW  - fog robotics
KW  - mobile robot
KW  - grasp planning model
KW  - nonpublic synthetic images
KW  - deep object recognition
KW  - nonprivate synthetic images
KW  - deep models
KW  - centralized Cloud Robotics model
KW  - surface decluttering
KW  - deep robot learning
KW  - Cloud computing
KW  - Robot sensing systems
KW  - Computational modeling
KW  - Adaptation models
KW  - Security
KW  - Data models
DO  - 10.1109/ICRA.2019.8793690
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.
ER  - 

TY  - CONF
TI  - Streamlines for Motion Planning in Underwater Currents
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4619
EP  - 4625
AU  - K. Y. C. To
AU  - K. M. B. Lee
AU  - C. Yoo
AU  - S. Anstee
AU  - R. Fitch
PY  - 2019
KW  - autonomous underwater vehicles
KW  - motion control
KW  - path planning
KW  - reachability analysis
KW  - sampling methods
KW  - stream functions
KW  - control space
KW  - complicated flows
KW  - underwater currents
KW  - underwater vehicles
KW  - ocean currents
KW  - reachability
KW  - sampling-based motion planning
KW  - Australia
KW  - Aerospace electronics
KW  - Planning
KW  - Underwater vehicles
KW  - Two dimensional displays
KW  - Oceans
KW  - Australia
KW  - Level set
DO  - 10.1109/ICRA.2019.8793567
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Motion planning for underwater vehicles must consider the effect of ocean currents. We present an efficient method to compute reachability and cost between sample points in sampling-based motion planning that supports long-range planning over hundreds of kilometres in complicated flows. The idea is to search a reduced space of control inputs that consists of stream functions whose level sets, or streamlines, optimally connect two given points. Such stream functions are generated by superimposing a control input onto the underlying current flow. A streamline represents the resulting path that a vehicle would follow as it is carried along by the current given that control input. We provide rigorous analysis that shows how our method avoids exhaustive search of the control space, and demonstrate simulated examples in complicated flows including a traversal along the east coast of Australia, using actual current predictions, between Sydney and Brisbane.
ER  - 

TY  - CONF
TI  - A Distributed Predictive Control Approach for Cooperative Manipulation of Multiple Underwater Vehicle Manipulator Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4626
EP  - 4632
AU  - S. Heshmati-alamdari
AU  - G. C. Karras
AU  - K. J. Kyriakopoulos
PY  - 2019
KW  - autonomous underwater vehicles
KW  - collision avoidance
KW  - distributed control
KW  - feedback
KW  - manipulator dynamics
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - nonlinear control systems
KW  - position control
KW  - predictive control
KW  - control input saturations
KW  - coupled dynamics
KW  - load sharing coefficients
KW  - distributed NMPC
KW  - object transportation
KW  - constrained workspace
KW  - static obstacles
KW  - kinematic representation singularities
KW  - joint limits
KW  - multiple underwater vehicle manipulator systems
KW  - nonlinear model predictive control approach
KW  - distributed predictive control approach
KW  - UVMS locally measurements
KW  - Task analysis
KW  - Kinematics
KW  - Robot sensing systems
KW  - Jacobian matrices
KW  - End effectors
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8793476
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of cooperative object transportation for multiple Underwater Vehicle Manipulator Systems (UVMSs) in a constrained workspace involving static obstacles. We propose a Nonlinear Model Predictive Control (NMPC) approach for a team of UVMSs in order to transport an object while avoiding significant constraints and limitations such as: kinematic and representation singularities, obstacles within the workspace, joint limits and control input saturations. More precisely, by exploiting the coupled dynamics between the robots and the object, and using certain load sharing coefficients, we design a distributed NMPC for each UVMS in order to cooperatively transport the object within the workspace's feasible region. Moreover, the control scheme adopts load sharing among the UVMSs according to their specific payload capabilities. Additionally, the feedback relies on each UVMS's locally measurements and no explicit data is exchanged online among the robots, thus reducing the required communication bandwidth. Finally, real-time simulation results conducted in UwSim dynamic simulator running in ROS environment verify the efficiency of the theoretical finding.
ER  - 

TY  - CONF
TI  - Coordinated Control of a Reconfigurable Multi-Vessel Platform: Robust Control Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4633
EP  - 4639
AU  - S. Park
AU  - E. Kayacan
AU  - C. Ratti
AU  - D. Rus
PY  - 2019
KW  - control system synthesis
KW  - feedback
KW  - marine engineering
KW  - position control
KW  - propellers
KW  - robust control
KW  - coordinated robust control scheme
KW  - reconfigurable multivessel platform
KW  - feedback control system
KW  - control variables
KW  - control system design
KW  - propeller-driven vessels
KW  - trajectory tracking
KW  - disturbance attenuation performance
KW  - orientation tracking error
KW  - maximum tracking error-to-disturbance ratio
KW  - Trajectory tracking
KW  - Robust control
KW  - Feedback control
KW  - Attenuation
KW  - Uncertainty
KW  - Irrigation
DO  - 10.1109/ICRA.2019.8794075
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a feedback control system for a reconfigurable multi-vessel platform. The platform consists of N propeller-driven vessels each of which is capable of latching to another vessel to form a rigid body of connected vessels. The main technical challenges are that i) depending on configurations of the platform the dynamic model would be different, and ii) the number of control variables in control system design increases as does the total number of vessels in the platform. To address these challenges, we develop a coordinated robust control scheme. Through experiments we assess trajectory tracking and disturbance attenuation performance of the control scheme in various configurations of the platform. Experiment results yield that average position and orientation tracking error are approximately 0.09m and 3°, and the maximum tracking error-to-disturbance ratio is 1.12.
ER  - 

TY  - CONF
TI  - Ambient light based depth control of underwater robotic unit aMussel
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4640
EP  - 4645
AU  - G. Vasiljevic
AU  - B. Arbanas
AU  - S. Bogdan
PY  - 2019
KW  - autonomous underwater vehicles
KW  - mobile robots
KW  - pressure sensors
KW  - underwater robotic unit
KW  - 1DOF
KW  - ambient light sensor
KW  - aMussel holding depth
KW  - pressure sensor
KW  - one degree-of-freedom
KW  - weather conditions
KW  - acoustic communication
KW  - Robot sensing systems
KW  - Pressure sensors
KW  - Buoyancy
KW  - Pistons
KW  - Simulation
KW  - Force
DO  - 10.1109/ICRA.2019.8794440
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a method for depth control of one degree of freedom (1DOF) underwater robotic platform aMussel, based on the measurements from the ambient light sensor. Since ambient light values change during the day and depend on the weather conditions, references for the controller are acquired from other aMussel holding depth using pressure sensor based controller. Control inputs are transmitted using acoustic communication.
ER  - 

TY  - CONF
TI  - A Unified Closed-Loop Motion Planning Approach For An I-AUV In Cluttered Environment With Localization Uncertainty
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4646
EP  - 4652
AU  - H. Yu
AU  - W. Lu
AU  - D. Liu
PY  - 2019
KW  - autonomous underwater vehicles
KW  - closed loop systems
KW  - collision avoidance
KW  - cooperative systems
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - position control
KW  - remotely operated vehicles
KW  - cluttered environment
KW  - localization uncertainty
KW  - trajectory optimization problem
KW  - optimal trajectory
KW  - I-AUV trajectories
KW  - optimization solvers
KW  - quasiquadratic optimization problems
KW  - null space saturation controller
KW  - cluttered underwater environments
KW  - optimal collision-free
KW  - intervention autonomous underwater vehicle
KW  - linear-quadratic-Gaussian controller
KW  - base trajectories
KW  - unified closed-loop motion planning approach
KW  - Trajectory
KW  - Planning
KW  - Manipulators
KW  - Uncertainty
KW  - Optimization
KW  - Aerospace electronics
KW  - Task analysis
KW  - Intervention AUV
KW  - Motion planning
KW  - Uncertainty minimization
DO  - 10.1109/ICRA.2019.8794300
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a unified motion planning approach for an Intervention Autonomous Underwater Vehicle (I-AUV) in a cluttered environment with localization uncertainty. With the uncertainty being propagated by an information filter, a trajectory optimization problem closed by a Linear-Quadratic-Gaussian controller is formulated for a coupled design of optimal trajectory, localization, and control. Due to the presence of obstacles or complexity of the cluttered environment, a set of feasible initial I-AUV trajectories covering multiple homotopy classes are required by optimization solvers. Parameterized through polynomials, the initial base trajectories are from solving quasi-quadratic optimization problems that are linearly constrained by waypoints from RRTconnect, while the initial trajectories of the manipulator are generated by a null space saturation controller. Simulations on an I-AUV with a 3 DOF manipulator in cluttered underwater environments demonstrated that initial trajectories are generated efficiently and that optimal and collision-free I-AUV trajectories with low state uncertainty are obtained.
ER  - 

TY  - CONF
TI  - A bio-robotic remora disc with attachment and detachment capabilities for reversible underwater hitchhiking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4653
EP  - 4659
AU  - S. Wang
AU  - L. Li
AU  - Y. Chen
AU  - Y. Wang
AU  - W. Sun
AU  - J. Xiao
AU  - D. Wainwright
AU  - T. Wang
AU  - R. J. Wood
AU  - L. Wen
PY  - 2019
KW  - actuators
KW  - biomimetics
KW  - cables (mechanical)
KW  - elastic constants
KW  - mobile robots
KW  - motion control
KW  - polymers
KW  - underwater vehicles
KW  - bio-robotic remora disc
KW  - detachment capabilities
KW  - reversible underwater hitchhiking
KW  - remoras
KW  - adhesive discs
KW  - biological disc
KW  - multimaterial biomimetic disc
KW  - flexible cable-driven mechanism
KW  - silicone soft lip
KW  - internal pressure
KW  - disc lamellae
KW  - attached carbon fiber spinules
KW  - ambient underwater pressure
KW  - Lips
KW  - Hydraulic systems
KW  - Force
KW  - Substrates
KW  - Prototypes
KW  - Rough surfaces
KW  - Surface roughness
KW  - Attachment and detachment
KW  - soft robotics
KW  - underwater adhesion
DO  - 10.1109/ICRA.2019.8793703
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Remoras employ their adhesive discs to rapidly attach to and detach from a wide range of marine surfaces. By analyzing high-speed images of remoras' (Echeneis naucrates) hitchhiking behavior, we describe the fish's detachment mechanism as a lip curling up to break the seal between the disc and substrate. By mimicking the kinematic and morphological properties of the biological disc, we fabricated a multi-material biomimetic disc (whose stiffness spans four orders of magnitude) that is capable of both attachment and detachment. Detachment is realized by a flexible cable-driven mechanism that curls the anterior region of the silicone soft lip, allows leakage under the disc, and equalizes the internal pressure to the external pressure. The disc lamellae with attached carbon fiber spinules can be rotated by hydraulic soft actuators whose internal pressure is precisely tuned to the ambient underwater pressure. During attachment, increasing the rotational angle of the lamellae and the preload of the disc significantly enhanced the adhesive forces. We found that curling up the soft lip and folding down the lamellae rapidly reduced the pulling force of the disc by a factor of 254 compared to that under the attached state, which lead to detachment. Based on these mechanisms, underwater maneuvers involving repeated attachment and detachment were demonstrated with an integrated ROV unit that had a self-contained actuation and control system for the disc. This study lays a foundation for the development of fully untethered robotic systems for underwater hitchhiking in real-world marine environments.
ER  - 

TY  - CONF
TI  - Robot Communication Via Motion: Closing the Underwater Human-Robot Interaction Loop
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4660
EP  - 4666
AU  - M. Fulton
AU  - C. Edge
AU  - J. Sattar
PY  - 2019
KW  - control engineering computing
KW  - human-robot interaction
KW  - mobile robots
KW  - robot communication
KW  - underwater human-robot interaction loop
KW  - colored lights
KW  - underwater robots
KW  - robot-to-human communication methods
KW  - body language gestures
KW  - communication vector
KW  - Robots
KW  - Solids
KW  - Task analysis
KW  - Unmanned underwater vehicles
KW  - Communication systems
KW  - Human-robot interaction
KW  - Hardware
DO  - 10.1109/ICRA.2019.8793491
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a novel method for underwater robot-to-human communication using the motion of the robot as “body language”. To evaluate this system, we develop simulated examples of the system's body language gestures, called kinemes, and compare them to a baseline system using flashing colored lights through a user study. Our work shows evidence that motion can be used as a successful communication vector which is accurate, easy to learn, and quick enough to be used, all without requiring any additional hardware to be added to our platform. We thus contribute to “closing the loop” for human-robot interaction underwater by proposing and testing this system, suggesting a library of possible body language gestures for underwater robots, and offering insight on the design of nonverbal robot-to-human communication methods.
ER  - 

TY  - CONF
TI  - Three-Dimensionally Maneuverable Robotic Fish Enabled by Servo Motor and Water Electrolyser
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4667
EP  - 4673
AU  - W. Zuo
AU  - A. Keow
AU  - Z. Chen
PY  - 2019
KW  - biomechanics
KW  - compressed air systems
KW  - design engineering
KW  - mobile robots
KW  - motion control
KW  - open loop systems
KW  - pistons
KW  - servomotors
KW  - tanks (containers)
KW  - underwater vehicles
KW  - servo motor
KW  - three-dimensionally maneuverable robotic fish
KW  - depth control mechanism
KW  - compressed air tank
KW  - on-board water electrolyzer
KW  - two-dimensionally planar motion
KW  - open-loop control experiments
KW  - underwater robot
KW  - pistons
KW  - asymmetric flapping motion
KW  - caudal fin
KW  - design engineering
KW  - forward velocity
KW  - turning rate
KW  - velocity 0.13 m/s
KW  - time 10.0 s
KW  - time 5.5 s
KW  - size 0.55 m
KW  - Robots
KW  - Buoyancy
KW  - Three-dimensional displays
KW  - Force
KW  - Dynamics
KW  - Two dimensional displays
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8793870
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Three-dimensionally (3D) maneuverable robotic fish are highly desirable due to their abilities to explore and survey the underwater environment. Existing depth control mechanism is focused on using compressed air or piston to generate volume change, which makes the system bulky and impractical in a small size underwater robot. In this paper, a small and compact 3D maneuverable robotic fish is developed. Instead of using a compressed air tank, the robot is equipped with an on-board water electrolyzer to generate the gases for depth change. The fabricated robotic fish shows fast diving and rising performance. A servo motor is used to generate asymmetric flapping motion on the caudal fin, which leads to a two-dimensionally (2D) planar motion. A 3D dynamic model is then derived for the fabricated robotic fish. Several open-loop control experiments have been conducted to validate the model as well as the design. It has been demonstrated in the experimental results that the robot is capable of generating 3D motion. The robot can achieve 0.13 m/s forward velocity, 30.6 degree/s turning rate, and it takes about 5.5 s to dive to 0.55 m and 10 s to rise.
ER  - 

TY  - CONF
TI  - A Multimodal Aerial Underwater Vehicle with Extended Endurance and Capabilities
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4674
EP  - 4680
AU  - D. Lu
AU  - C. Xiong
AU  - Z. Zeng
AU  - L. Lian
PY  - 2019
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - autonomous underwater vehicles
KW  - design engineering
KW  - motion control
KW  - pneumatic systems
KW  - three-term control
KW  - vehicle dynamics
KW  - multimodal hybrid aerial underwater vehicle
KW  - MHAUV
KW  - design concept
KW  - fixed-wing unmanned aerial vehicle
KW  - extended endurance
KW  - Newton-Euler formalism
KW  - multidomain simulation
KW  - underwater glide test
KW  - design principles
KW  - proportional-integral-derivative
KW  - multirotor
KW  - lightweight pneumatic buoyancy adjustment system
KW  - vehicle's physical parameters
KW  - gliding equilibrium points
KW  - vehicle's motion control
KW  - Buoyancy
KW  - Bladder
KW  - Underwater vehicles
KW  - Prototypes
KW  - Rotors
KW  - Unmanned aerial vehicles
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793985
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A new solution to improving the poor endurance of the existing hybrid aerial underwater vehicle (HAUV) is proposed in this paper. The proposed multimodal hybrid aerial underwater vehicle (MHAUV) merges the design concept of the fixed-wing unmanned aerial vehicle (UAV), the multirotor, and the underwater glider (UG) and has a novel lightweight pneumatic buoyancy adjustment system. MHAUV is well suited for moving in distinct medium and can achieve extended endurance for long distance travel in both air and water. The mathematical model is given based on Newton-Euler formalism. Necessary design principles of the vehicle's physical parameters are obtained through different gliding equilibrium points. Then, a control scheme composed of two separate proportional-integral-derivative (PID) is employed for the vehicle's motion control in multi-domain simulation. The simulation results are presented to verify the multi-domain mobility and the mode switch ability of the proposed vehicle intuitively. Finally, a prototype, NEZHA, is introduced to be the experimental platform. The success of the flight test, the hovering test, the underwater glide test, and the medium transition test all contribute to prove the feasibility of the proposed concept of the novel MHAUV.
ER  - 

TY  - CONF
TI  - Design and Experiments of a Squid-Like Aquatic-Aerial Vehicle with Soft Morphing Fins and Arms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4681
EP  - 4687
AU  - T. Hou
AU  - X. Yang
AU  - H. Su
AU  - B. Jiang
AU  - L. Chen
AU  - T. Wang
AU  - J. Liang
PY  - 2019
KW  - actuators
KW  - aircraft control
KW  - biomimetics
KW  - drag
KW  - hinges
KW  - legged locomotion
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - numerical analysis
KW  - pneumatic control equipment
KW  - pneumatic systems
KW  - robot kinematics
KW  - soft morphable structures
KW  - soft morphing fins
KW  - aquatic-aerial multimodal vehicle
KW  - concept aircraft
KW  - natural organisms
KW  - multilocomotion
KW  - rigid link mechanisms
KW  - hinges
KW  - pneumatically-driven soft fins
KW  - flying squid
KW  - lift force
KW  - drag force
KW  - wind
KW  - water tunnel
KW  - squid-like aquatic-aerial vehicle
KW  - Prototypes
KW  - Force
KW  - Cavity resonators
KW  - Propulsion
KW  - Valves
KW  - Wind tunnels
KW  - Drag
DO  - 10.1109/ICRA.2019.8793702
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Aquatic-aerial multimodal vehicle is a new concept aircraft that can freely shuttle between water and air. Some of the natural organisms provide the inspiration to realize this multi-locomotion. Most of current prototypes use rigid link mechanisms or hinges to morph the structure thus to adapt to the aquatic-aerial environment, which is commonly complicated and bulky. In this paper, we present a novel prototype with pneumatically-driven soft fins and arms that can fold and spread just like the flying squid. The fins and arms can augment the lift force during flying by spreading and reduce drag force during swimming by folding. The performance of the morphable structures was investigated in wind and water tunnel. The results explain the tradeoff strategies of multimodal-locomotion between water and air, and verify the feasibility of the novel aquatic-aerial vehicle with soft morphable structures.
ER  - 

TY  - CONF
TI  - Nonlinear Orientation Controller for a Compliant Robotic Fish Based on Asymmetric Actuation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4688
EP  - 4694
AU  - C. Meurer
AU  - A. Simha
AU  - Ü. Kotta
AU  - M. Kruusmaa
PY  - 2019
KW  - actuators
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - robot dynamics
KW  - underwater vehicles
KW  - nonlinear orientation controller
KW  - compliant robotic fish
KW  - asymmetric actuation
KW  - compliant fish-like robot
KW  - rigid tails
KW  - flexible tail
KW  - underactuated robotic fish
KW  - asymmetric velocity profiles
KW  - skewed triangle waves
KW  - nonlinear control law
KW  - simple actuation mechanism
KW  - underwater observation
KW  - sinusoidal tail actuation
KW  - turning motion
KW  - Robot sensing systems
KW  - Turning
KW  - Position control
KW  - Torque
KW  - Oscillators
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8793892
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Compliant fish-like robots are being developed as efficient and dependable underwater observation platforms with low impact on the observed environment. Orientation control is an essential building block to achieve autonomy for those vehicles. So far, the major focus has been on rigid tails or on flexible tails with a high degree of actuation. We present a novel control strategy for an underactuated robotic fish with a flexible tail optimized for cruising. The basis for our approach is the generation of asymmetric velocity profiles of the robot's tail beats. To achieve such velocity profiles, the usual sinusoidal tail actuation is replaced with skewed triangle waves. We provide a simple formulation for such waves, where their skew is dependent on only one variable which we define as skew factor. Furthermore, a nonlinear control law is derived to achieve the desired turning motions. We implement the controller on a compliant fish-like robot with a simple actuation mechanism. The control scheme is experimentally validated, and its robustness is tested in field trials.
ER  - 

TY  - CONF
TI  - Project AutoVision: Localization and 3D Scene Perception for an Autonomous Vehicle with a Multi-Camera System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4695
EP  - 4702
AU  - L. Heng
AU  - B. Choi
AU  - Z. Cui
AU  - M. Geppert
AU  - S. Hu
AU  - B. Kuan
AU  - P. Liu
AU  - R. Nguyen
AU  - Y. C. Yeo
AU  - A. Geiger
AU  - G. H. Lee
AU  - M. Pollefeys
AU  - T. Sattler
PY  - 2019
KW  - cameras
KW  - geometry
KW  - image reconstruction
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - robot vision
KW  - stereo image processing
KW  - video signal processing
KW  - sensor suite
KW  - autonomous vehicle
KW  - multicamera system
KW  - 3D scene perception capabilities
KW  - self-driving vehicle
KW  - autonomous navigation
KW  - urban environments
KW  - rural environments
KW  - exteroceptive sensors
KW  - AutoVision project
KW  - multiview geometry
KW  - Cameras
KW  - Sensors
KW  - Three-dimensional displays
KW  - Calibration
KW  - Laser radar
KW  - Autonomous vehicles
KW  - Lighting
DO  - 10.1109/ICRA.2019.8793949
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Project AutoVision aims to develop localization and 3D scene perception capabilities for a self-driving vehicle. Such capabilities will enable autonomous navigation in urban and rural environments, in day and night, and with cameras as the only exteroceptive sensors. The sensor suite employs many cameras for both 360-degree coverage and accurate multi-view stereo; the use of low-cost cameras keeps the cost of this sensor suite to a minimum. In addition, the project seeks to extend the operating envelope to include GNSS-less conditions which are typical for environments with tall buildings, foliage, and tunnels. Emphasis is placed on leveraging multi-view geometry and deep learning to enable the vehicle to localize and perceive in 3D space. This paper presents an overview of the project, and describes the sensor suite and current progress in the areas of calibration, localization, and perception.
ER  - 

TY  - CONF
TI  - Improving the Robustness of Visual-Inertial Extended Kalman Filtering
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4703
EP  - 4709
AU  - J. Jackson
AU  - J. Nielsen
AU  - T. McLain
AU  - R. Beard
PY  - 2019
KW  - drag
KW  - image filtering
KW  - inertial navigation
KW  - Kalman filters
KW  - Monte Carlo methods
KW  - nonlinear filters
KW  - observability
KW  - state estimation
KW  - observability
KW  - consistency problems
KW  - three-fold improvement
KW  - linear drag term
KW  - velocity dynamics
KW  - estimation accuracy
KW  - partial-update formulation
KW  - linearization errors
KW  - partially-observable states
KW  - sensor biases
KW  - normally unobservable position
KW  - heading states
KW  - visual-inertial state estimation problem
KW  - Monte Carlo simulation experiment
KW  - visual-inertial Kalman filters
KW  - visual-inertial extended Kalman filtering
KW  - visual-inertial navigation methods
KW  - global measurements
KW  - Cameras
KW  - Quaternions
KW  - Estimation
KW  - Kalman filters
KW  - Mathematical model
KW  - Robustness
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794164
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual-inertial navigation methods have been shown to be an effective, low-cost way to operate autonomously without GPS or other global measurements, however most filtering approaches to VI suffer from observability and consistency problems. To increase robustness of the state-of-the-art methods, we propose a three-fold improvement. First, we propose the addition of a linear drag term in the velocity dynamics which improves estimation accuracy. Second, we propose the use of a partial-update formulation which limits the effect of linearization errors in partially-observable states, such as sensor biases. Finally, we propose the use of a keyframe reset step to enforce observability and consistency of the normally unobservable position and heading states. While all of these concepts have been used independently in the past, our experiments demonstrate additional strength when they are used simultaneously in a visual-inertial state estimation problem. In this paper, we derive the proposed filter and use a Monte Carlo simulation experiment to analyze the response of visual-inertial Kalman filters with the above described additions. The results of this study show that the combination of all of these features significantly improves estimation accuracy and consistency.
ER  - 

TY  - CONF
TI  - Towards Fully Dense Direct Filter-Based Monocular Visual-Inertial Odometry
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4710
EP  - 4716
AU  - A. Hardt-Stremayr
AU  - S. Weiss
PY  - 2019
KW  - covariance matrices
KW  - distance measurement
KW  - gradient methods
KW  - image filtering
KW  - image texture
KW  - matrix inversion
KW  - mobile robots
KW  - robot vision
KW  - smoothing methods
KW  - low-textured areas
KW  - smooth gradients
KW  - complexity reduction methods
KW  - direct filter-based monocular visual-inertial odometry
KW  - direct filter-based visual-inertial odometry method
KW  - Cameras
KW  - Integrated circuits
KW  - Uncertainty
KW  - Complexity theory
KW  - Estimation
KW  - Covariance matrices
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2019.8793837
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a fully dense direct filter-based visual-inertial odometry method estimating both pixel depth for all pixels and robot state simultaneously, having all uncertainties in the same state vector. Due to the fully dense method, our approach works even in low-textured areas with very low, smooth gradients (i.e. scenes where feature based or semi-dense approaches fail). Our algorithm performs in real-time on a CPU with a time complexity linearly dependent on the amount of pixels in the provided image. To achieve this, we propose complexity reduction methods for fast matrix inversion, exploiting specific structures of the covariance matrix. We provide both simulated and real-world results in low-textured areas with a smooth gradient.
ER  - 

TY  - CONF
TI  - Enhancing V-SLAM Keyframe Selection with an Efficient ConvNet for Semantic Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4717
EP  - 4723
AU  - I. Alonso
AU  - L. Riazuelo
AU  - A. C. Murillo
PY  - 2019
KW  - convolutional neural nets
KW  - microprocessor chips
KW  - mobile robots
KW  - neural net architecture
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - video signal processing
KW  - image quality
KW  - semantic information
KW  - robotic systems
KW  - V-SLAM keyframe selection
KW  - semantic analysis
KW  - semantic image analysis
KW  - visual information
KW  - ConvNet
KW  - video
KW  - Visual-SLAM
KW  - CNN architecture
KW  - onboard CPU
KW  - Robots
KW  - Semantics
KW  - Task analysis
KW  - Computer architecture
KW  - Visualization
KW  - Image segmentation
KW  - Standards
DO  - 10.1109/ICRA.2019.8793923
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Selecting relevant visual information from a video is a challenging task on its own and even more in robotics, due to strong computational restrictions. This work proposes a novel keyframe selection strategy based on image quality and semantic information, which boosts strategies currently used in Visual-SLAM (V-SLAM). Commonly used V-SLAM methods select keyframes based only on relative displacements and amount of tracked feature points. Our strategy to select more carefully these keyframes allows the robotic systems to make better use of them. With minimal computational cost, we show that our selection includes more relevant keyframes, which are useful for additional posterior recognition tasks, without penalizing the existing ones, mainly place recognition. A key ingredient is our novel CNN architecture to run a quick semantic image analysis at the onboard CPU of the robot. It provides sufficient accuracy significantly faster than related works. We demonstrate our hypothesis with several public datasets with challenging robotic data.
ER  - 

TY  - CONF
TI  - Unsupervised Learning of Monocular Depth and Ego-Motion Using Multiple Masks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4724
EP  - 4730
AU  - G. Wang
AU  - H. Wang
AU  - Y. Liu
AU  - W. Chen
PY  - 2019
KW  - cameras
KW  - image matching
KW  - image sequences
KW  - motion estimation
KW  - object detection
KW  - unsupervised learning
KW  - video signal processing
KW  - monocular depth
KW  - multiple masks
KW  - unsupervised learning method
KW  - depth estimation network
KW  - ego-motion estimation network
KW  - projection target imaging plane
KW  - fine masks
KW  - image pixel mismatch
KW  - repeated masking
KW  - KITTI dataset
KW  - low-quality uncalibrated bike video dataset
KW  - Image reconstruction
KW  - Estimation
KW  - Cameras
KW  - Unsupervised learning
KW  - Training
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2019.8793622
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A new unsupervised learning method of depth and ego-motion using multiple masks from monocular video is proposed in this paper. The depth estimation network and the ego-motion estimation network are trained according to the constraints of depth and ego-motion without truth values. The main contribution of our method is to carefully consider the occlusion of the pixels generated when the adjacent frames are projected to each other, and the blank problem generated in the projection target imaging plane. Two fine masks are designed to solve most of the image pixel mismatch caused by the movement of the camera. In addition, some relatively rare circumstances are considered, and repeated masking is proposed. To some extent, the method is to use a geometric relationship to filter the mismatched pixels for training, making unsupervised learning more efficient and accurate. The experiments on KITTI dataset show our method achieves good performance in terms of depth and ego-motion. The generalization capability of our method is demonstrated by training on the low-quality uncalibrated bike video dataset and evaluating on KITTI dataset, and the results are still good.
ER  - 

TY  - CONF
TI  - Characterizing the Effects of Reduced Gravity on Rover Wheel-Soil Interactions using Computer Vision Techniques
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4739
EP  - 4745
AU  - P. Niksirat
AU  - K. Skonieczny
AU  - A. F. Nassiraei
PY  - 2019
KW  - computer vision
KW  - Mars
KW  - mobile robots
KW  - planetary rovers
KW  - planetary surfaces
KW  - soil
KW  - wheels
KW  - lower gravity
KW  - soil resistance
KW  - weaker soil bonding
KW  - rover mobility
KW  - reduced-mass rover
KW  - full-mass rover
KW  - rover wheel-soil interactions
KW  - computer vision techniques
KW  - planetary rovers
KW  - Martian soil simulant
KW  - rover-soil visualization technique
KW  - reduced gravity wheel-terrain interaction
KW  - ExoMars wheel prototype
KW  - simulated Martian gravity
KW  - wheel normal load
KW  - ExoMars space mission
KW  - Wheels
KW  - Soil
KW  - Gravity
KW  - Moon
KW  - Aircraft
KW  - Space vehicles
KW  - Earth
DO  - 10.1109/ICRA.2019.8793895
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mitigating potential hazards for planetary rovers posed by soft soils requires testing in representative environments such as with Martian soil simulants in reduced gravity. This work describes the experimentation, methods, and results of a rover-soil visualization technique that produced rich datasets of reduced gravity wheel-terrain interaction. The activities are linked to the upcoming ExoMars space mission, through the use of ExoMars wheel prototype and Martian soil simulant in simulated Martian gravity produced in parabolic flights. The results indicate that, with wheel normal load held equal between experiments, the amount of soil mobilized by wheel-soil interaction increases as gravity decreases. Moreover, the amount of soil mobilized is more sensitive to slip in lower gravity. The results of the visualization analysis suggest a deterioration in the soil resistance and weaker soil bonding at lower gravities, which undermines the rover mobility by reducing the net traction. The results have important implications regarding the practice of using a reduced-mass rover on Earth to assess the performance of a full-mass rover in similar soil on an extraterrestrial surface.
ER  - 

TY  - CONF
TI  - Adaptive H∞ Controller for Precise Manoeuvring of a Space Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4746
EP  - 4752
AU  - A. Seddaoui
AU  - C. M. Saaj
AU  - S. Eckersley
PY  - 2019
KW  - adaptive control
KW  - aerospace robotics
KW  - assembling
KW  - control system synthesis
KW  - H∞ control
KW  - manipulators
KW  - mirrors
KW  - motion control
KW  - nonlinear control systems
KW  - position control
KW  - robust control
KW  - space vehicles
KW  - space robot
KW  - precise manoeuvring
KW  - controlled-floating mode
KW  - in-orbit telescope assembly
KW  - robotic arm
KW  - slow manoeuvres
KW  - precise manoeuvres
KW  - orbital assembly missions
KW  - robustness
KW  - optical mirrors
KW  - nonlinear H∞ controller
KW  - adaptive H∞ controller
KW  - Space vehicles
KW  - Aerospace electronics
KW  - Robot kinematics
KW  - Manipulators
KW  - Uncertainty
KW  - Orbits
DO  - 10.1109/ICRA.2019.8794374
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A space robot working in a controlled-floating mode can be used for performing in-orbit telescope assembly through simultaneously controlling the motion of the spacecraft base and its robotic arm. Handling and assembling optical mirrors requires the space robot to achieve slow and precise manoeuvres regardless of the disturbances and errors in the trajectory. The robustness offered by the nonlinear H∞ controller, in the presence of environmental disturbances and parametric uncertainties, makes it a viable solution. However, using fixed tuning parameters for this controller does not always result in the desired performance as the arm's trajectory is not known a priori for orbital assembly missions. In this paper, a complete study on the impact of the different tuning parameters is performed and a new adaptive H∞ controller is developed based on bounded functions. The simulation results presented show that the proposed adaptive H∞ controller guarantees robustness and precise tracking using a minimal amount of forces and torques for assembly operations using a small space robot.
ER  - 

TY  - CONF
TI  - Belief Space Planning for Reducing Terrain Relative Localization Uncertainty in Noisy Elevation Maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4753
EP  - 4759
AU  - E. Fang
AU  - P. M. Furlong
AU  - W. Whittaker
PY  - 2019
KW  - astronomical image processing
KW  - digital elevation models
KW  - Global Positioning System
KW  - mobile robots
KW  - path planning
KW  - planetary rovers
KW  - robot vision
KW  - solid modelling
KW  - terrain mapping
KW  - belief space planning
KW  - noisy map data
KW  - elevation data
KW  - lunar orbital imagery
KW  - terrain relative localization uncertainty
KW  - noisy elevation
KW  - accurate global localization
KW  - operational risk
KW  - initial exploration missions
KW  - global position
KW  - terrain relative navigation
KW  - TRN
KW  - planetary rover-perspective images
KW  - digital elevation models
KW  - absolute positioning
KW  - orbital data
KW  - terrain features
KW  - GPS
KW  - satellite orbital imagery
KW  - Uncertainty
KW  - Planning
KW  - Noise measurement
KW  - Space vehicles
KW  - Navigation
KW  - Planetary orbits
DO  - 10.1109/ICRA.2019.8793255
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate global localization is essential for planetary rovers to reach mission goals and mitigate operational risk. For initial exploration missions, it is inappropriate to deploy GPS or build other infrastructure for navigating. One way of determining global position is to use terrain relative navigation (TRN). TRN compares planetary rover-perspective images and 3D models to existing satellite orbital imagery and digital elevation models (DEMs) for absolute positioning. However, TRN is limited by the quality of orbital data and the presence and uniqueness of terrain features. This work presents a novel combination of belief space planning with terrain relative navigation. Additionally, we introduce a new method for increasing the robustness of belief space planning to noisy map data. The new algorithm provides a statistically significant reduction in localization uncertainty when tested on elevation data produced from lunar orbital imagery.
ER  - 

TY  - CONF
TI  - Soil Displacement Terramechanics for Wheel-Based Trenching with a Planetary Rover
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4760
EP  - 4766
AU  - C. Pavlov
AU  - A. M. Johnson
PY  - 2019
KW  - aerospace robotics
KW  - mobile robots
KW  - planetary rovers
KW  - soil
KW  - wheels
KW  - trenching
KW  - autonomous trenching
KW  - front wheel
KW  - rear wheel
KW  - deep trench
KW  - single wheel experiments
KW  - driving strategy
KW  - closed-form model
KW  - digging operations
KW  - wheel actuators
KW  - planetary exploration rovers
KW  - wheel-based trenching
KW  - soil displacement terramechanics
KW  - Wheels
KW  - Soil
KW  - Geometry
KW  - Deformable models
KW  - Mathematical model
KW  - Predictive models
KW  - Finite element analysis
DO  - 10.1109/ICRA.2019.8793645
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Planetary exploration rovers are expensive, weight constrained, and cannot be serviced once deployed. Here, we explore one way to increase their capabilities while avoiding the cost, mass, and complexity leading to these issues. We propose to re-use the large wheel actuators for trenching and other digging operations, which will enable a range of missions such as sampling deeper layers of soil. We present a new, closed-form model of the soil displaced by an angled, spinning wheel to analyze the trenching potential of a driving strategy and inform the control of the wheel. The model is demonstrated with single wheel experiments under different driving conditions. The model suggests: that a deep trench does not require large tractive efforts; that the shape of the trench can be controlled; and that a rear wheel has a lower risk of entrapment when trenching than a front wheel. Ultimately this model could be used in a nonprehensile manipulation planning or learning algorithm to enable autonomous trenching.
ER  - 

TY  - CONF
TI  - Experimental Evaluation of Teleoperation Interfaces for Cutting of Satellite Insulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4775
EP  - 4781
AU  - W. Pryor
AU  - B. P. Vagvolgyi
AU  - W. J. Gallagher
AU  - A. Deguet
AU  - S. Leonard
AU  - L. L. Whitcomb
AU  - P. Kazanzides
PY  - 2019
KW  - aerospace robotics
KW  - artificial satellites
KW  - cameras
KW  - control engineering computing
KW  - data visualisation
KW  - medical robotics
KW  - robot vision
KW  - telerobotics
KW  - da Vinci master console
KW  - conventional control interface
KW  - conventional visualization
KW  - operator performance
KW  - cutting task
KW  - conventional teleoperation interface
KW  - da Vinci surgical robot
KW  - conventional camera-based visualization
KW  - augmented virtuality visualization
KW  - trained NASA robot teleoperators
KW  - ground-based experiments
KW  - available cameras
KW  - round-trip telemetry delay
KW  - human operator
KW  - servicing operation
KW  - protective thermal blanketing
KW  - satellite insulation
KW  - teleoperation interfaces
KW  - experimental evaluation
KW  - Satellites
KW  - Cameras
KW  - Visualization
KW  - Solid modeling
KW  - Robot vision systems
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793968
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - On-orbit servicing of satellites is complicated by the fact that almost all existing satellites were not designed to be serviced. This creates a number of challenges, one of which is to cut and partially remove the protective thermal blanketing that encases a satellite prior to performing the servicing operation. A human operator on Earth can perform this task telerobotically, but must overcome difficulties presented by the multi-second round-trip telemetry delay between the satellite and the operator and the limited, or even obstructed, views from the available cameras. This paper reports the results of ground-based experiments with trained NASA robot teleoperators to compare our recently-reported augmented virtuality visualization to the conventional camera-based visualization. We also compare the master console of a da Vinci surgical robot to the conventional teleoperation interface. The results show that, for the cutting task, the augmented virtuality visualization can improve operator performance compared to the conventional visualization, but that operators are more proficient with the conventional control interface than with the da Vinci master console.
ER  - 

TY  - CONF
TI  - OmniDRL: Robust Pedestrian Detection using Deep Reinforcement Learning on Omnidirectional Cameras*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4782
EP  - 4789
AU  - G. Dias Pais
AU  - T. J. Dias
AU  - J. C. Nascimento
AU  - P. Miraldo
PY  - 2019
KW  - cameras
KW  - computerised instrumentation
KW  - image processing
KW  - learning (artificial intelligence)
KW  - robust pedestrian detection
KW  - omnidirectional cameras
KW  - computer vision
KW  - robotics
KW  - deep learning methods
KW  - omnidirectional imaging
KW  - OmniDRL
KW  - deep reinforcement learning
KW  - 3D bounding boxes
KW  - Cameras
KW  - Three-dimensional displays
KW  - Distortion
KW  - Image segmentation
KW  - Robot vision systems
KW  - Object detection
DO  - 10.1109/ICRA.2019.8794471
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pedestrian detection is one of the most explored topics in computer vision and robotics. The use of deep learning methods allowed the development of new and highly competitive algorithms. Deep Reinforcement Learning has proved to be within the state-of-the-art in terms of both detection in perspective cameras and robotics applications. However, for detection in omnidirectional cameras, the literature is still scarce, mostly because of their high levels of distortion. This paper presents a novel and efficient technique for robust pedestrian detection in omnidirectional images. The proposed method uses deep Reinforcement Learning that takes advantage of the distortion in the image. By considering the 3D bounding boxes and their distorted projections into the image, our method is able to provide the pedestrian's position in the world, in contrast to the image positions provided by most state-of-the-art methods for perspective cameras. Our method avoids the need of pre-processing steps to remove the distortion, which is computationally expensive. Beyond the novel solution, our method compares favorably with the state-of-the-art methodologies that do not consider the underlying distortion for the detection task.
ER  - 

TY  - CONF
TI  - 2D3D-Matchnet: Learning To Match Keypoints Across 2D Image And 3D Point Cloud
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4790
EP  - 4796
AU  - M. Feng
AU  - S. Hu
AU  - M. H. Ang
AU  - G. H. Lee
PY  - 2019
KW  - cameras
KW  - feature extraction
KW  - image classification
KW  - image matching
KW  - image representation
KW  - image retrieval
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - pose estimation
KW  - solid modelling
KW  - visual databases
KW  - image-based counterpart
KW  - visual pose estimation
KW  - 2D-3D image
KW  - cloud correspondences
KW  - end-to-end deep network architecture
KW  - query image
KW  - 3D point cloud reference map
KW  - Oxford 2D-3D Patches dataset
KW  - Oxford Robotcar dataset
KW  - ground truth camera pose
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Pose estimation
KW  - Visualization
KW  - Cameras
KW  - Training
KW  - Detectors
DO  - 10.1109/ICRA.2019.8794415
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Large-scale point cloud generated from 3D sensors is more accurate than its image-based counterpart. However, it is seldom used in visual pose estimation due to the difficulty in obtaining 2D-3D image to point cloud correspondences. In this paper, we propose the 2D3D-MatchNet - an end-to-end deep network architecture to jointly learn the descriptors for 2D and 3D keypoint from image and point cloud, respectively. As a result, we are able to directly match and establish 2D-3D correspondences from the query image and 3D point cloud reference map for visual pose estimation. We create our Oxford 2D-3D Patches dataset from the Oxford Robotcar dataset with the ground truth camera poses and 2D-3D image to point cloud correspondences for training and testing the deep network. Experimental results verify the feasibility of our approach.
ER  - 

TY  - CONF
TI  - Teaching Robots To Draw
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4797
EP  - 4803
AU  - A. Kotani
AU  - S. Tellex
PY  - 2019
KW  - handwritten character recognition
KW  - manipulators
KW  - natural language processing
KW  - teaching
KW  - just-drawn handwritten characters
KW  - writing utensil
KW  - target stroke
KW  - continuous drawing motion
KW  - handcrafted rules
KW  - predefined paths
KW  - stroke-based drawing
KW  - teaching robots
KW  - manipulator robots
KW  - line drawings
KW  - Automation
KW  - Machine-to-machine communications
DO  - 10.1109/ICRA.2019.8793484
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we introduce an approach which enables manipulator robots to write handwritten characters or line drawings. Given an image of just-drawn handwritten characters, the robot infers a plan to replicate the image with a writing utensil, and then reproduces the image. Our approach draws each target stroke in one continuous drawing motion and does not rely on handcrafted rules or on predefined paths of characters. Instead, it learns to write from a dataset of demonstrations. We evaluate our approach in both simulation and on two real robots. Our model can draw handwritten characters in a variety of languages which are disjoint from the training set, such as Greek, Tamil, or Hindi, and also reproduce any stroke-based drawing from an image of the drawing.
ER  - 

TY  - CONF
TI  - Learning Probabilistic Multi-Modal Actor Models for Vision-Based Robotic Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4804
EP  - 4810
AU  - M. Yan
AU  - A. Li
AU  - M. Kalakrishnan
AU  - P. Pastor
PY  - 2019
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - robot vision
KW  - statistical distributions
KW  - inference time
KW  - probabilistic multimodal actor models
KW  - vision-based robotic grasping
KW  - neural density model
KW  - neural network
KW  - normalizing flows
KW  - complex probability distributions
KW  - Gaussian mixture
KW  - conditional distribution
KW  - 4 dimensional action space
KW  - Training
KW  - Grasping
KW  - Robots
KW  - Neural networks
KW  - Computational modeling
KW  - Predictive models
KW  - Probability distribution
DO  - 10.1109/ICRA.2019.8794024
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Many previous works approach vision-based robotic grasping by training a value network that evaluates grasp proposals. These approaches require an optimization process at run-time to infer the best action from the value network. As a result, the inference time grows exponentially as the dimension of action space increases. We propose an alternative method, by directly training a neural density model to approximate the conditional distribution of successful grasp poses from the input images. We construct a neural network that combines Gaussian mixture and normalizing flows, which is able to represent multi-modal, complex probability distributions. We demonstrate on both simulation and real robot that the proposed actor model achieves similar performance compared to the value network using the Cross-Entropy Method (CEM) for inference, on top-down grasping with a 4 dimensional action space. Our actor model reduces the inference time by 3 times compared to the state-of-the-art CEM method. We believe that actor models will play an important role when scaling up these approaches to higher dimensional action spaces.
ER  - 

TY  - CONF
TI  - Self-supervised Learning for Single View Depth and Surface Normal Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4811
EP  - 4817
AU  - H. Zhan
AU  - C. S. Weerasekera
AU  - R. Garg
AU  - I. Reid
PY  - 2019
KW  - convolutional neural nets
KW  - natural scenes
KW  - stereo image processing
KW  - supervised learning
KW  - single view depth
KW  - surface normal estimation
KW  - self-supervised learning framework
KW  - surface normals
KW  - outdoor scenes
KW  - fronto-parallel planes
KW  - piece-wise smooth depth
KW  - surface orientation
KW  - natural scenes
KW  - piece-wise smooth normals
KW  - trained normal network
KW  - depth network
KW  - realistic smooth normal assumption
KW  - self-supervised depth prediction network
KW  - convolutional neural networks
KW  - depth-normal consistency
KW  - Training
KW  - Estimation
KW  - Geometry
KW  - Cameras
KW  - Sensors
KW  - Visual odometry
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793984
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we present a self-supervised learning framework to simultaneously train two Convolutional Neural Networks (CNNs) to predict depth and surface normals from a single image. In contrast to most existing frameworks which represent outdoor scenes as fronto-parallel planes at piece-wise smooth depth, we propose to predict depth with surface orientation while assuming that natural scenes have piece-wise smooth normals. We show that a simple depth-normal consistency as a soft-constraint on the predictions is sufficient and effective for training both these networks simultaneously. The trained normal network provides state-of-the-art predictions while the depth network, relying on much realistic smooth normal assumption, outperforms the traditional self-supervised depth prediction network by a large margin on the KITTI benchmark.
ER  - 

TY  - CONF
TI  - Learning to Drive from Simulation without Real World Labels
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4818
EP  - 4824
AU  - A. Bewley
AU  - J. Rigley
AU  - Y. Liu
AU  - J. Hawke
AU  - R. Shen
AU  - V. Lam
AU  - A. Kendall
PY  - 2019
KW  - cameras
KW  - closed loop systems
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mobile robots
KW  - road vehicles
KW  - robot vision
KW  - traffic engineering computing
KW  - domain transfer
KW  - single-camera control policy
KW  - simulation control labels
KW  - driving performance
KW  - rural roads
KW  - urban roads
KW  - machine learning systems
KW  - simulated environment
KW  - vision-based lane
KW  - driving policy
KW  - rural road
KW  - image-to-image translation
KW  - autonomous vehicle
KW  - open-loop regression metric
KW  - Aerospace electronics
KW  - Image reconstruction
KW  - Task analysis
KW  - Semantics
KW  - Training
KW  - Roads
KW  - Measurement
DO  - 10.1109/ICRA.2019.8793668
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Simulation can be a powerful tool for under-standing machine learning systems and designing methods to solve real-world problems. Training and evaluating methods purely in simulation is often “doomed to succeed” at the desired task in a simulated environment, but the resulting models are incapable of operation in the real world. Here we present and evaluate a method for transferring a vision-based lane following driving policy from simulation to operation on a rural road without any real-world labels. Our approach leverages recent advances in image-to-image translation to achieve domain transfer while jointly learning a single-camera control policy from simulation control labels. We assess the driving performance of this method using both open-loop regression metrics, and closed-loop performance operating an autonomous vehicle on rural and urban roads.
ER  - 

TY  - CONF
TI  - Fabrication and Characterization of Muscle Rings Using Circular Mould and Rotary Electrical Stimulation for Bio-Syncretic Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4825
EP  - 4830
AU  - C. Zhang
AU  - J. Shi
AU  - W. Wang
AU  - N. Xi
AU  - Y. Wang
AU  - L. Liu
PY  - 2019
KW  - actuators
KW  - biological tissues
KW  - biomechanics
KW  - cardiology
KW  - cellular biophysics
KW  - electromechanical actuators
KW  - medical robotics
KW  - muscle
KW  - physiological models
KW  - tissue engineering
KW  - circular mould
KW  - rotary electrical stimulation
KW  - bio-syncretic robots
KW  - high-quality muscle rings
KW  - living biological systems
KW  - electromechanical systems
KW  - natural biological entities
KW  - 3D skeletal muscles
KW  - contraction force
KW  - electrical pulses stimulation
KW  - control property
KW  - 3D muscle tissues
KW  - muscle tissue engineering
KW  - Muscles
KW  - Electrical stimulation
KW  - Electrodes
KW  - Service robots
KW  - Skeleton
DO  - 10.1109/ICRA.2019.8793903
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Bio-syncretic robots made up of living biological systems and electromechanical systems may have the potential excellent performance of natural biological entities. Therefore, the study of the bio-syncretic robots has got lots of attention in recent years. The 3D skeletal muscles have been used widely, due to the considerable contraction force and the controllability. However, the low differentiation quality of the C2C12 in the tissues hinders the broad application in the development of the skeleton muscle actuated bio-syncretic robots. In this work, an approach based on circular mould and rotary electrical stimulation to build high-quality muscle rings, which can be used to actuate various bio-syncretic robots, has been proposed. Firstly, the advantage of the proposed circular mould for the muscle rings culture has been shown by simulation. Then, the muscle rings have been fabricated with different moulds using the experiment-optimized compositions of the biological mixture. After that, the muscle rings in the circular moulds with different electrical stimulations have been cultured, to show the superiority of the proposed rotary electrical stimulation. Moreover, the contractility of the muscle rings have been measured under the different electrical pulses stimulation, for the study of the control property of the muscle rings. This work may be meaningful not only the development of bio-syncretic robots actuated by 3D muscle tissues but also the muscle tissue engineering.
ER  - 

TY  - CONF
TI  - Cell Injection Microrobot Development and Evaluation in Microfluidic Chip
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4831
EP  - 4836
AU  - L. Feng
AU  - D. Chen
AU  - Q. Zhou
AU  - B. Song
AU  - W. Zhang
PY  - 2019
KW  - bioMEMS
KW  - cellular biophysics
KW  - lab-on-a-chip
KW  - medical robotics
KW  - microfluidics
KW  - microrobots
KW  - membrane
KW  - cell suction
KW  - elastic forces
KW  - magnetic forces
KW  - ejection forces
KW  - microrobot body
KW  - mammalian oocyte
KW  - cell injection microrobot development
KW  - microfluidic chip
KW  - micronewton forces
KW  - cell nuclei
KW  - nozzle
KW  - Permanent magnets
KW  - Strain
KW  - Glass
KW  - Robots
KW  - Magnetic forces
KW  - Microfluidics
KW  - Biomembranes
DO  - 10.1109/ICRA.2019.8793799
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose an innovative design of microrobot, which can achieve donor cell suction, delivery and injection in a mammalian oocyte on microfluidic chip. The microrobot body contains a hollow space that produces suction and ejection forces for injection of cell nuclei using a nozzle at the tip of the robot. Specifically, a controller changes the hollow volume by balancing the magnetic and elastic forces of the membrane, and along with motion of stages in the XY plane. A glass capillary attached at the tip of the robot contains the nozzle is able to absorb and inject cell nuclei. The microrobot provides three degrees of freedom and generates micronewton forces. We demonstrate the effectiveness of the proposed microrobot through an experiment of absorption and ejection of 20 μm particles from the nozzle using magnetic control in a microfluidic chip.
ER  - 

TY  - CONF
TI  - Orienting Oocytes using Vibrations for In-Vitro Fertilization Procedures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4837
EP  - 4843
AU  - D. Meyer
AU  - M. L. P. Colon
AU  - H. V. Alizadeh
AU  - L. Su
AU  - B. Behr
AU  - D. B. Camarillo
PY  - 2019
KW  - biomedical equipment
KW  - bioMEMS
KW  - cellular biophysics
KW  - genetics
KW  - medical robotics
KW  - micromanipulators
KW  - patient diagnosis
KW  - vibrations
KW  - orienting oocytes
KW  - vibrations
KW  - assisted reproductive technologies
KW  - sperm injection
KW  - manual manipulation
KW  - error procedure
KW  - skilled embryologists
KW  - desired orientation
KW  - IVF clinics
KW  - extensive changes
KW  - standard equipment
KW  - surface transducer
KW  - pipette holder
KW  - pipette tip axis
KW  - vibration burst
KW  - polar body detection algorithm
KW  - system cause rotation
KW  - micropipettes
KW  - in-vitro fertilization procedures
KW  - 2D motion
KW  - Vibrations
KW  - Transducers
KW  - Automation
KW  - Subspace constraints
KW  - Glass
KW  - Cameras
KW  - Resonant frequency
DO  - 10.1109/ICRA.2019.8793498
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate positioning of cells is a fundamental task for many procedures in assisted reproductive technologies (e.g. intracytoplasmic sperm injection or preimplantation genetic diagnosis) to extract or insert materials into and from the cell without causing damage to it. The current method of manual manipulation is based on a trial and error procedure performed by skilled embryologists, where they use two different micropipettes to rotate the cell and immobilize it in the desired orientation. This procedure is time consuming, inconsistent and has a low efficiency. Attempts to automate the process presented in the literature have not yet been implemented in IVF clinics because their high degree of automation requires extensive changes to the current systems used in the clinics. We designed a system that can easily be integrated into standard equipment of IVF clinics and allows automated as well as manual manipulation of cells. The system uses vibrations induced by a surface transducer at the pipette holder to rotate the cell around the pipette tip axis, resulting in 2D motion. To detect if the polar body is in the desired position after a vibration burst, we developed a polar body detection algorithm. We performed simulations and experiments to confirm that vibrations at the natural frequencies of the system cause rotation around the pipette tip axis. Experimental results show that the system is capable of positioning the polar body in plane in less than 5.41 seconds.
ER  - 

TY  - CONF
TI  - Vision-Based Automated Sorting of C. Elegans on a Microfluidic Device
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4844
EP  - 4849
AU  - X. Dong
AU  - P. Song
AU  - X. Liu
PY  - 2019
KW  - cellular biophysics
KW  - microfluidics
KW  - size measurement
KW  - sorting
KW  - valves
KW  - multiworm loading
KW  - body size measurement
KW  - size-based sorting
KW  - vision-based algorithms
KW  - double-layer microfluidic device
KW  - vision-based worm detection
KW  - active sorting
KW  - passive sorting mechanisms
KW  - conventional worm sorting
KW  - high-speed sorting
KW  - automated speed sorting
KW  - vision-based microfluidic system
KW  - vision-based automated sorting
KW  - sequential loading
KW  - computer-controlled pneumatic valves
KW  - worm body length measurement
KW  - worm body width measurement
KW  - vision-based worm size measurement
KW  - worm biology
KW  - automated on-chip worm manipulation
KW  - nematode worm C. elegans
KW  - Grippers
KW  - Sorting
KW  - Loading
KW  - Valves
KW  - Size measurement
KW  - Image processing
KW  - Length measurement
DO  - 10.1109/ICRA.2019.8793689
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper reports a vision-based microfluidic system for automated, high-speed sorting of the nematode worm C. elegans. Exceeding the capabilities of conventional worm sorting microfluidic devices purely relying on passive sorting mechanisms, our system is capable of accurate measurement of the worm body length/width and active sorting of worms with the desired sizes from a mixture of worms at different developmental stages. This feature is enabled by the combination of vision-based worm detection and sizing algorithms and automated on-chip worm manipulation. A double-layer microfluidic device with computer-controlled pneumatic valves is developed for sequential loading, trapping, imaging, and sorting of single worms based on vision-based worm size measurement results. To keep the system operation robust, vision-based algorithms for detecting multi-worm loading and worm size measurement failure have also been developed. We conducted sorting experiments on 319 worms and achieve an average sorting speed of 10.4 worms per minute (5.8 s/worm) with an operation success rate of 90.3%. This system will facilitate worm biology studies where body size measurement and size-based sorting of many worms are needed.
ER  - 

TY  - CONF
TI  - Asymmetric Local Metric Learning with PSD Constraint for Person Re-identification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4862
EP  - 4868
AU  - Z. Wen
AU  - M. Sun
AU  - Y. Li
AU  - S. Ying
AU  - Y. Peng
PY  - 2019
KW  - approximation theory
KW  - image recognition
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - matrix algebra
KW  - video signal processing
KW  - visual databases
KW  - asymmetric local metric learning
KW  - machine learning
KW  - positive sample pairs
KW  - adaptive local metric learning method
KW  - single distance metric
KW  - smooth metric matrix function
KW  - linear combinations
KW  - learning process
KW  - positive semidefinite constraint
KW  - person reidentification
KW  - metric learning
KW  - PSD constraint
KW  - UCI databases
KW  - GRID database
KW  - VIPeR database
KW  - CUHK01 database
KW  - video monitor
KW  - approximation error bound
KW  - Measurement
KW  - Learning systems
KW  - Manifolds
KW  - Databases
KW  - Symmetric matrices
KW  - Machine learning
KW  - Machine learning algorithms
DO  - 10.1109/ICRA.2019.8794455
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Person re-identification is one of the key issues in both machine learning and video monitor application. In particular, defining an appropriate distance metric between the person images is very important. Existing metric learning approaches used in person re-identification either learn a single measure, or ignore the positive semi-definite (PSD) of measurement matrix, at the same time, since the number of negative sample pairs largely exceeds the number of positive sample pairs, some metric learning methods are largely influenced by the sample imbalance. Considering the above issues, we propose a new adaptive local metric learning method with positive semi-definite (PSD) constraint. Unlike existing metric learning methods which learn a single distance metric, we use an approximation error bound of a smooth metric matrix function over the data manifold to learn local metrics as linear combinations of basis metrics defined on anchor points over different regions of the instance space. Besides, we develop an efficient two stage algorithm that first learns the anchor points and the linear combinations of each instance, then learns the metric matrices of the anchor points. We employ the fast iterative shrinkage-thresholding algorithm which is a fast first-order optimization algorithm in the learning process of the linear combinations as well as the basis metrics of the anchor points. Our metric learning method has excellent performance. We firstly apply the proposed method on 5 UCI databases, which are widely used in machine learning, to test and evaluate the effectiveness of the proposed method. Then the proposed approach is applied for person re-identification, achieving better performance on three challenging databases (GRID, VIPeR, CUHK01) than the existing methods. The experimental results show that the proposed method can prvide the theoretical and practical support for the person re-identification problem.
ER  - 

TY  - CONF
TI  - Fast and Robust 3D Person Detector and Posture Estimator for Mobile Robotic Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4869
EP  - 4875
AU  - B. Lewandowski
AU  - J. Liebner
AU  - T. Wengefeld
AU  - S. Müller
AU  - H. Gross
PY  - 2019
KW  - computer vision
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - pose estimation
KW  - high posture variance
KW  - real-time detection rates
KW  - 3D object detection domain
KW  - mobile application
KW  - 3D point clouds
KW  - robust 3D person detector
KW  - posture estimator
KW  - mobile robotic applications
KW  - computer vision domain
KW  - mobile robotics
KW  - standing postures
KW  - socially aware navigation
KW  - deep learning techniques
KW  - Kinect2 depth sensor
KW  - Three-dimensional displays
KW  - Detectors
KW  - Feature extraction
KW  - Robots
KW  - Histograms
KW  - Deep learning
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793712
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Due to recent deep learning techniques, person detection seems to be solved in the computer vision domain, however, it is still an issue in mobile robotics. On a robot only limited computing capacities are available. The challenge gets even more difficult when operating in an environment, with people in poses different from the standard upright ones. In this work the environment of a supermarket is considered. Unlike most scenarios targeted by the community, persons not only occur in standing postures, but also grasping into the shelves or squatting in front of them. Furthermore, people are heavily occluded, e.g. by shopping carts. In such a challenging environment, it is important to perceive people early enough and in real-time in order to enable a socially aware navigation. Classical person detectors often suffer from a high posture variance or do not achieve acceptable real-time detection rates. For this reason, different components from the 3D object detection domain have been used to create a new robust person detector for mobile application. Operating on 3D point clouds allows fast detections in real-time up to our goal distance of ten meters and above using the Kinect2 depth sensor. The detector can even differentiate between typical postures of customers who stand or squat in front of shelves.
ER  - 

TY  - CONF
TI  - Spatiotemporal and Kinetic Gait Analysis System Based on Multisensor Fusion of Laser Range Sensor and Instrumented Insoles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4876
EP  - 4881
AU  - R. Eguchi
AU  - A. Yorozu
AU  - M. Takahashi
PY  - 2019
KW  - biomedical measurement
KW  - force sensors
KW  - gait analysis
KW  - Kalman filters
KW  - laser applications in medicine
KW  - optical sensors
KW  - sensor fusion
KW  - data association
KW  - Kalman filter
KW  - fusion algorithm
KW  - in-shoe devices
KW  - spatiotemporal gait analysis system
KW  - data association methods
KW  - tracked leg motions
KW  - motion capture cameras
KW  - gait disorders
KW  - elderly patients
KW  - movement function
KW  - human legs
KW  - laser range sensor
KW  - walking
KW  - motion models
KW  - gait phases
KW  - gait events
KW  - force sensors
KW  - multisensor fusion algorithm
KW  - instrumented insoles
KW  - kinetic gait analysis system
KW  - Legged locomotion
KW  - Tracking
KW  - Acceleration
KW  - Kalman filters
KW  - Instruments
KW  - Force
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794271
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Tracking of human legs during walking are key technologies for gait analysis evaluating the movement function of the elderly and patients with gait disorders. Although the motion capture cameras are the gold standard method for gait analysis because of their high accuracy, they are not always accessible in clinical sites because of their cost, scale, and usability. In response, a laser range sensor (LRS), which is used for obstacle avoidance and human detection of mobile robots, has recently been employed for tracking of leg motions. Some previous studies set LRS at shin height and tracked leg motions during walking using three or five observation patterns and the Kalman filtering and data association methods. However, these systems had difficulty in tracking during walking along a circular trajectory including frequent overlaps and occlusions of legs. Therefore, this paper presents a spatiotemporal and kinetic gait analysis system using a single LRS and instrumented insoles and proposes a multisensor fusion algorithm for tracking leg motions. The instrumented insoles are in-shoe devices embedded force sensors and can detect accurate timings of gait events via force sensing. The system identifies gait phases by the fusion algorithm and switches acceleration input added to motion models of tracked legs for the Kalman filter and data association. The tracking performance of the proposed system was evaluated by measuring walking on a circular trajectory in experiments.
ER  - 

TY  - CONF
TI  - Part Segmentation for Highly Accurate Deformable Tracking in Occlusions via Fully Convolutional Neural Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4882
EP  - 4888
AU  - W. Wan
AU  - A. Walsman
AU  - D. Fox
PY  - 2019
KW  - convolutional neural nets
KW  - image filtering
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object tracking
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - visual perception
KW  - direct pose estimation
KW  - machine learning
KW  - direct estimation techniques
KW  - geometric tracking methods
KW  - robotic applications
KW  - observed point clouds
KW  - segmentation maps
KW  - Fast-FCN network architecture
KW  - convolutional neural networks
KW  - Three-dimensional displays
KW  - Semantics
KW  - Computational modeling
KW  - Robots
KW  - Image segmentation
KW  - Computer architecture
KW  - Pose estimation
DO  - 10.1109/ICRA.2019.8793656
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Successfully tracking the human body is an important perceptual challenge for robots that must work around people. Existing methods fall into two broad categories: geometric tracking and direct pose estimation using machine learning. While recent work has shown direct estimation techniques can be quite powerful, geometric tracking methods using point clouds can provide a very high level of 3D accuracy which is necessary for many robotic applications. However these approaches can have difficulty in clutter when large portions of the subject are occluded. To overcome this limitation, we propose a solution based on fully convolutional neural networks (FCN). We develop an optimized Fast-FCN network architecture for our application which allows us to filter observed point clouds and improve tracking accuracy while maintaining interactive frame rates. We also show that this model can be trained with a limited number of examples and almost no manual labelling by using an existing geometric tracker and data augmentation to automatically generate segmentation maps. We demonstrate the accuracy of our full system by comparing it against an existing geometric tracker, and show significant improvement in these challenging scenarios.
ER  - 

TY  - CONF
TI  - Using Variable Natural Environment Brain-Computer Interface Stimuli for Real-time Humanoid Robot Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4889
EP  - 4895
AU  - N. K. N. Aznan
AU  - J. D. Connolly
AU  - N. A. Moubayed
AU  - T. P. Breckon
PY  - 2019
KW  - brain-computer interfaces
KW  - convolutional neural nets
KW  - electroencephalography
KW  - humanoid robots
KW  - medical robotics
KW  - medical signal processing
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - telerobotics
KW  - video streaming
KW  - visual evoked potentials
KW  - specialised secondary CNN
KW  - teleoperation robot commands
KW  - SSVEP decoding model
KW  - real-time humanoid robot navigation
KW  - humanoid robot teleoperation
KW  - natural indoor environment
KW  - dry-EEG technology
KW  - cortical waveforms
KW  - on-board robot camera
KW  - onscreen object selection
KW  - variable steady state visual evoked potential
KW  - real-time video streaming
KW  - variable natural environment
KW  - brain-computer interface stimuli
KW  - deep convolutional neural network
KW  - dry-electroencephalography based human cortical brain bio-signals decoding
KW  - variable BCI stimuli
KW  - natural scene objects detection
KW  - dry-EEG enabled SSVEP methodology
KW  - Navigation
KW  - Electroencephalography
KW  - Real-time systems
KW  - Humanoid robots
KW  - Object detection
KW  - Headphones
DO  - 10.1109/ICRA.2019.8794060
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the challenge of humanoid robot teleoperation in a natural indoor environment via a Brain-Computer Interface (BCI). We leverage deep Convolutional Neural Network (CNN) based image and signal understanding to facilitate both real-time object detection and dry-Electroencephalography (EEG) based human cortical brain bio-signals decoding. We employ recent advances in dry-EEG technology to stream and collect the cortical waveforms from subjects while they fixate on variable Steady State Visual Evoked Potential (SSVEP) stimuli generated directly from the environment the robot is navigating. To these ends, we propose the use of novel variable BCI stimuli by utilising the real-time video streamed via the on-board robot camera as visual input for SSVEP, where the CNN detected natural scene objects are altered and flickered with differing frequencies (10Hz, 12Hz and 15Hz). These stimuli are not akin to traditional stimuli - as both the dimensions of the flicker regions and their on-screen position changes depending on the scene objects detected. Onscreen object selection via such a dry-EEG enabled SSVEP methodology, facilitates the on-line decoding of human cortical brain signals, via a specialised secondary CNN, directly into teleoperation robot commands (approach object, move in a specific direction: right, left or back). This SSVEP decoding model is trained via a priori offline experimental data in which very similar visual input is present for all subjects. The resulting classification demonstrates high performance with mean accuracy of 85% for the real-time robot navigation experiment across multiple test subjects.
ER  - 


TY  - CONF
TI  - Estimating the Localizability in Tunnel-like Environments using LiDAR and UWB
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4903
EP  - 4908
AU  - W. Zhen
AU  - S. Scherer
PY  - 2019
KW  - Global Positioning System
KW  - inspection
KW  - mobile robots
KW  - optical radar
KW  - path planning
KW  - probability
KW  - robot vision
KW  - sensor fusion
KW  - tunnels
KW  - ultra wideband technology
KW  - UWB
KW  - inspection tasks
KW  - autonomous navigation technology
KW  - robot localization techniques
KW  - GPS-denied environments
KW  - onboard sensors
KW  - cameras
KW  - LiDAR
KW  - probabilistic sensor fusion method
KW  - tunnel-like environments
KW  - degeneration characterization model
KW  - ultra-wideband ranging radio
KW  - Robot sensing systems
KW  - Laser radar
KW  - Uncertainty
KW  - Probabilistic logic
KW  - Distance measurement
DO  - 10.1109/ICRA.2019.8794167
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The application of robots in inspection tasks has been growing quickly thanks to the advancements in autonomous navigation technology, especially the robot localization techniques in GPS-denied environments. Although many methods have been proposed to localize a robot using onboard sensors such as cameras and LiDARs, achieving robust localization in geometrically degenerated environments, e.g. tunnels, remains a challenging problem. In this work, we focus on the robust localization problem in such situations. A novel degeneration characterization model is presented to estimate the localizability at a given location in the prior map. And the localizability of a LiDAR and an Ultra-Wideband (UWB) ranging radio is analyzed. Additionally, a probabilistic sensor fusion method is developed to combine IMU, LiDAR and the UWB. Experiment results show that this method allows for robust localization inside a long straight tunnel.
ER  - 

TY  - CONF
TI  - Global Localization with Object-Level Semantics and Topology
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4909
EP  - 4915
AU  - Y. Liu
AU  - Y. Petillot
AU  - D. Lane
AU  - S. Wang
PY  - 2019
KW  - feature extraction
KW  - graph theory
KW  - image matching
KW  - image representation
KW  - pose estimation
KW  - stereo image processing
KW  - object-level representation
KW  - semantic object association
KW  - semantic-level point alignment
KW  - object-level semantics
KW  - appearance-based approach
KW  - 3D dense semantics
KW  - semantic graph
KW  - vision-based global localization
KW  - topology
KW  - autonomous navigation
KW  - simultaneous localization and mapping
KW  - place recognition
KW  - 6-DoF pose estimation
KW  - visual feature matching
KW  - Semantics
KW  - Three-dimensional displays
KW  - Topology
KW  - Simultaneous localization and mapping
KW  - Visualization
KW  - Cameras
KW  - Pose estimation
DO  - 10.1109/ICRA.2019.8794475
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Global localization lies at the heart of autonomous navigation and Simultaneous Localization and Mapping (SLAM). The appearance-based approach has been successful, but still faces many open challenges in environments where visual conditions vary significantly over time. In this paper, we propose an integrated solution to leverage object-level dense semantics and spatial understanding of the environment for global localization. Our approach models an environment with 3D dense semantics, semantic graph and their topology. This object-level representation is then used for place recognition via semantic object association, followed by 6-DoF pose estimation by the semantic-level point alignment. Extensive experiments show that our approach can achieve robust global localization under extreme appearance changes. It is also capable of coping with other challenging scenarios, such as dynamic environments and incomplete query observations.
ER  - 

TY  - CONF
TI  - Look No Deeper: Recognizing Places from Opposing Viewpoints under Varying Scene Appearance using Single-View Depth Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4916
EP  - 4923
AU  - S. Garg
AU  - M. Babu V
AU  - T. Dharmasiri
AU  - S. Hausler
AU  - N. Suenderhauf
AU  - S. Kumar
AU  - T. Drummond
AU  - M. Milford
PY  - 2019
KW  - cameras
KW  - computer vision
KW  - feature extraction
KW  - image filtering
KW  - image matching
KW  - image representation
KW  - image sensors
KW  - image sequences
KW  - object detection
KW  - keypoint sequence
KW  - single query image
KW  - depth-filtered keypoint sequences
KW  - camera motion
KW  - varying scene appearance
KW  - single-view depth estimation
KW  - familiar visual place
KW  - extreme environmental appearance change
KW  - field-of-view vision
KW  - temporal-aware visual place recognition system
KW  - extreme appearance-change visual place recognition problem
KW  - sequence-to-single frame matching
KW  - depth-filtered keypoints
KW  - depth estimation pipeline
KW  - Visualization
KW  - Estimation
KW  - Feature extraction
KW  - Cameras
KW  - Indexes
KW  - Robots
KW  - Measurement
DO  - 10.1109/ICRA.2019.8794178
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual place recognition (VPR) - the act of recognizing a familiar visual place - becomes difficult when there is extreme environmental appearance change or viewpoint change. Particularly challenging is the scenario where both phenomena occur simultaneously, such as when returning for the first time along a road at night that was previously traversed during the day in the opposite direction. While such problems can be solved with panoramic sensors, humans solve this problem regularly with limited field-of-view vision and without needing to constantly turn around. In this paper, we present a new depth- and temporal-aware visual place recognition system that solves the opposing viewpoint, extreme appearance-change visual place recognition problem. Our system performs sequence-to-single frame matching by extracting depth-filtered keypoints using a state-of-the-art depth estimation pipeline, constructing a keypoint sequence over multiple frames from the reference dataset, and comparing these keypoints to the keypoints extracted from a single query image. We evaluate the system on a challenging benchmark dataset and show that it consistently outperforms state-of-the-art techniques. We also develop a range of diagnostic simulation experiments that characterize the contribution of depth-filtered keypoint sequences with respect to key domain parameters including the degree of appearance change and camera motion.
ER  - 

TY  - CONF
TI  - Exploiting Trademark Databases for Robotic Object Fetching
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4946
EP  - 4952
AU  - J. Song
AU  - H. Kurniawati
PY  - 2019
KW  - feature extraction
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - object recognition
KW  - robot vision
KW  - service robots
KW  - shape recognition
KW  - trademarks
KW  - synthetic data
KW  - convolutional neural network logo detector
KW  - domain randomization
KW  - soft drinks
KW  - logo images
KW  - large-scale data
KW  - household objects
KW  - service robots
KW  - robotic object
KW  - trademark databases
KW  - object fetching
KW  - Databases
KW  - Trademarks
KW  - Robots
KW  - Detectors
KW  - Task analysis
KW  - Training
KW  - Shape
DO  - 10.1109/ICRA.2019.8793829
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Service robots require the ability to recognize various household objects in order to carry out certain tasks, such as fetching an object for a person. Manually collecting information on all the objects a robot may encounter in a household is tedious and time-consuming; therefore this paper proposes the use of large-scale data from existing trademark databases. These databases contain logo images and a description of the goods and services the logo was registered under. For example, Pepsi is registered under soft drinks. We extend domain randomization in order to generate synthetic data to train a convolutional neural network logo detector, which outperformed previous logo detectors trained on synthetic data. We also provide a practical implementation for object fetching on a robot, which uses a Kinect and the logo detector to identify the object the human user requested. Tests on this robot indicate promising results, despite not using any real world photos for training.
ER  - 

TY  - CONF
TI  - Object Detection Approach for Robot Grasp Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4953
EP  - 4959
AU  - H. Karaoguz
AU  - P. Jensfelt
PY  - 2019
KW  - convolutional neural nets
KW  - grippers
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - robot platform
KW  - object detection approach
KW  - robot grasp detection
KW  - robot grasping problem
KW  - parallel gripper
KW  - image data
KW  - end-to-end approach
KW  - RGB images
KW  - transfer learning
KW  - adapted network
KW  - convolutional neural network based based object detection architecture
KW  - Grasping
KW  - Robot kinematics
KW  - Grippers
KW  - Neural networks
KW  - Object detection
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793751
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we focus on the robot grasping problem with parallel grippers using image data. For this task, we propose and implement an end-to-end approach. In order to detect the good grasping poses for a parallel gripper from RGB images, we have employed transfer learning for a Convolutional Neural Network (CNN) based object detection architecture. Our obtained results show that, the adapted network either outperforms or is on-par with the state-of-the art methods on a benchmark dataset. We also performed grasping experiments on a real robot platform to evaluate our method's real world performance.
ER  - 

TY  - CONF
TI  - MetaGrasp: Data Efficient Grasping by Affordance Interpreter Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4960
EP  - 4966
AU  - J. Cai
AU  - H. Cheng
AU  - Z. Zhang
AU  - J. Su
PY  - 2019
KW  - dexterous manipulators
KW  - grippers
KW  - image colour analysis
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - data efficient grasping
KW  - data-driven approach
KW  - training data
KW  - data collection
KW  - grasp training system
KW  - model inference
KW  - antipodal grasp rule
KW  - affordance map
KW  - ungraspability
KW  - grasp affordances
KW  - pixel-level affordance interpreter network
KW  - quantitative experiments
KW  - real-world grasp experiments
KW  - qualitative experiments
KW  - Grasping
KW  - Training
KW  - Data collection
KW  - Data models
KW  - Grippers
KW  - Robots
KW  - Deep learning
DO  - 10.1109/ICRA.2019.8793912
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Data-driven approach for grasping shows significant advance recently. But these approaches usually require much training data. To increase the efficiency of grasping data collection, this paper presents a novel grasp training system including the whole pipeline from data collection to model inference. The system can collect effective grasp sample with a corrective strategy assisted by antipodal grasp rule, and we design an affordance interpreter network to predict pixelwise grasp affordance map. We define graspability, ungraspability and background as grasp affordances. The key advantage of our system is that the pixel-level affordance interpreter network trained with only a small number of grasp samples under antipodal rule can achieve significant performance on totally unseen objects and backgrounds. The training sample is only collected in simulation. Extensive qualitative and quantitative experiments demonstrate the accuracy and robustness of our proposed approach. In the real-world grasp experiments, we achieve a grasp success rate of 93% on a set of household items and 91% on a set of adversarial items with only about 6,300 simulated samples. We also achieve 87% accuracy in clutter scenario. Although the model is trained using only RGB image, when changing the background textures, it also performs well and can achieve even 94% accuracy on the set of adversarial objects, which outperforms current state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Toward Fingertip Non-Contact Material Recognition and Near-Distance Ranging for Robotic Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4967
EP  - 4974
AU  - C. Fang
AU  - D. Wang
AU  - D. Song
AU  - J. Zou
PY  - 2019
KW  - displacement measurement
KW  - grippers
KW  - image sensors
KW  - photoacoustic effect
KW  - ultrasonic imaging
KW  - ultrasonic transducers
KW  - pre-touch approaches
KW  - fingertip noncontact material recognition
KW  - conventional contact
KW  - acoustic bi-modal distance
KW  - near-distance ranging
KW  - sensor design
KW  - nimble grasping
KW  - robust grasping
KW  - material type
KW  - robotic fingers
KW  - single-element air-coupled transducers
KW  - optoacoustic effects
KW  - pulse-echo ultrasound
KW  - last-moment perception
KW  - robot fingertip
KW  - robotic grasping
KW  - optical bi-modal distance
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA.2019.8793922
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We report the feasibility study of a new acoustic and optical bi-modal distance & material sensor for robotic grasping. The new sensor is designed to be mounted on the robot fingertip to provide last-moment perception before contact happens. It is based on both pulse-echo ultrasound and optoacoustic effects enabled by single-element air-coupled transducers. In contrast to conventional contact-based and recent pre-touch approaches, this new method overcomes their disadvantages and provides robotic fingers with the capability to detect the distance and material type of the target at a near distance before contact occurs, which is crucial for robust and nimble grasping. The proposed sensor has been tested with different materials, shapes, and porous properties. The experimental results show that this sensor design is functional and practical.
ER  - 

TY  - CONF
TI  - Video-based Prediction of Hand-grasp Preshaping with Application to Prosthesis Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4975
EP  - 4982
AU  - L. T. Taverne
AU  - M. Cognolato
AU  - T. Bützer
AU  - R. Gassert
AU  - O. Hilliges
PY  - 2019
KW  - dexterous manipulators
KW  - electromyography
KW  - learning (artificial intelligence)
KW  - medical control systems
KW  - medical signal processing
KW  - orthotics
KW  - prosthetics
KW  - video signal processing
KW  - deep learning
KW  - automatic prediction
KW  - hand prosthesis
KW  - video sequences
KW  - RGB-D video data
KW  - orthotic devices
KW  - prosthetic devices
KW  - surface electromyography pattern recognition
KW  - arbitrary objects
KW  - video-based technique
KW  - grasp-type selection techniques
KW  - prosthesis control
KW  - hand-grasp
KW  - video-based prediction
KW  - Cameras
KW  - Prosthetics
KW  - Deep learning
KW  - Predictive models
KW  - Grasping
KW  - Object recognition
KW  - Pattern recognition
DO  - 10.1109/ICRA.2019.8794175
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Among the currently available grasp-type selection techniques for hand prostheses, there is a distinct lack of intuitive, robust, low-latency solutions. In this paper we investigate the use of a portable, forearm-mounted, video-based technique for the prediction of hand-grasp preshaping for arbitrary objects. The purpose of this system is to automatically select the grasp-type for the user of the prosthesis, potentially increasing ease-of-use and functionality. This system can be used to supplement and improve existing control strategies, such as surface electromyography (sEMG) pattern recognition, for prosthetic and orthotic devices. We designed and created a suitable dataset consisting of RGB-D video data for 2212 grasp examples split evenly across 7 classes; 6 grasps commonly used in activities of daily living, and an additional no-grasp category. We processed and analyzed the dataset using several state-of-the-art deep learning architectures. Our selected model shows promising results for realistic, intuitive, real-world use, reaching per-frame accuracies on video sequences of up to 95.90% on the validation set. Such a system could be integrated into the palm of a hand prosthesis, allowing an automatic prediction of the grasp-type without requiring any special movements or aiming by the user.
ER  - 

TY  - CONF
TI  - Reactive Walking Based on Upper-Body Manipulability: An application to Intention Detection and Reaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4991
EP  - 4997
AU  - P. Mohammadi
AU  - E. M. Hoffman
AU  - L. Muratore
AU  - N. G. Tsagarakis
AU  - J. J. Steil
PY  - 2019
KW  - humanoid robots
KW  - human-robot interaction
KW  - legged locomotion
KW  - manipulators
KW  - motion control
KW  - position control
KW  - robot platforms
KW  - reactive walking
KW  - upper-body manipulability
KW  - intention detection
KW  - human robot interaction
KW  - hand-in-hand interaction scenario
KW  - impedance controlled humanoid
KW  - velocity transmission
KW  - robot arms manipulation quality
KW  - appropriate directions
KW  - robot manipulation ability
KW  - COMAN + humanoid robot
KW  - manipulation motion
KW  - human operator
KW  - reactive steps
KW  - humanoid COMAN+ control
KW  - walking pattern generators
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Manipulators
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2019.8794309
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we look at the challenge of human robot interaction in locomotion. We consider a hand-in-hand interaction scenario where a human compliantly interacts with the upper-body of an impedance controlled humanoid. By exploring the velocity transmission of the robot arms, and the interaction in terms of robot arms manipulation quality evaluated through the monitoring of their manipulability the proposed method derives suitable reactive steps in appropriate directions to ensure that the robot manipulation ability is maintained with the robot arms providing high capacity of motion along the different directions. The proposed approach can be combined with different walking pattern generators and is not tailored to a specific one used in this work. The results of the proposed method are experimentally validated on the COMAN + humanoid robot showing the efficacy of the method to generate reactive stepping driven by the interaction and manipulation motion of the human operator. Besides, the work also provides a real-time software architecture to control humanoid COMAN+, but it is also flexible to be used for the control of other robot platforms.
ER  - 

TY  - CONF
TI  - A Self-Modulated Impedance Multimodal Interaction Framework for Human-Robot Collaboration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4998
EP  - 5004
AU  - L. Muratore
AU  - A. Laurenzi
AU  - N. G. Tsagarakis
PY  - 2019
KW  - active disturbance rejection control
KW  - humanoid robots
KW  - human-robot interaction
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - unexpected interaction forces
KW  - online self-tuning stiffness regulation principle
KW  - unexpected interaction loads
KW  - unnecessary motion commands
KW  - human generated motions
KW  - verbal interaction channel
KW  - human-robot collaboration task
KW  - self-modulated impedance multimodal interaction framework
KW  - human robot interaction
KW  - manipulation manoeuvres
KW  - humanoid robot COMAN +
KW  - Task analysis
KW  - Impedance
KW  - Collaboration
KW  - Robot sensing systems
KW  - Payloads
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794168
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Human Robot interaction is a fundamental perquisite for any robot performing a physical task in collaboration with a human. The presence of disturbances arising from the partially known tasks payloads, the unexpected interaction forces in general, and the uncertainty in the interpretation of the human intention in terms of motions and forces can pose significant challenges and eventually compromise the execution of the collaborative task. This work presents a novel, intrinsically adaptable multimodal (force, motion and verbal) interaction framework for human-robot collaboration (HRC) that leverages on an online self-tuning stiffness regulation principle to provide adaptation to interaction/payload forces and reject disturbances arising by unexpected interaction loads. Besides the presented method, it enables the rejection of unnecessary motion commands (e.g. oscillations generated by the human operator) to reach the robot co-worker through the filtering of the human generated motions, that are outside the range (in terms of speed and acceleration) of the envisioned manipulation manoeuvres. Finally, a verbal interaction channel allows the operator to convey securely his high level intentions and to control the states of the task execution. We evaluated and demonstrated the effectiveness of the proposed multimodal interaction framework in a high weight carrying human-robot collaboration task using the humanoid robot COMAN +.
ER  - 

TY  - CONF
TI  - SMT-Based Control and Feedback for Social Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5005
EP  - 5011
AU  - T. Campos
AU  - A. Pacheck
AU  - G. Hoffman
AU  - H. Kress-Gazit
PY  - 2019
KW  - collision avoidance
KW  - computability
KW  - feedback
KW  - human-robot interaction
KW  - motion control
KW  - SMT-based control
KW  - social navigation
KW  - HRI
KW  - socially acceptable distance
KW  - robot motion
KW  - high-level formal specifications
KW  - human behavior
KW  - formal methods
KW  - human-robot interaction
KW  - collision avoidance
KW  - satisfiability modulo theories
KW  - utility-based side-by-side navigation control
KW  - SMT formula
KW  - Navigation
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Legged locomotion
KW  - Mathematical model
KW  - Safety
DO  - 10.1109/ICRA.2019.8794208
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper combines techniques from Formal Methods and Human-Robot Interaction (HRI) to address the challenge of a robot walking with a human while maintaining a socially acceptable distance and avoiding collisions. We formulate a set of constraints on the robot motion using Satisfiability Modulo Theories (SMT) formulas, and synthesize robot control that is guaranteed to be safe and correct. Due to its use of high-level formal specifications, the controller is able to provide feedback to the user in situations where human behavior causes the robot to fail. This feedback allows the human to adjust their behavior and recover joint navigation. We demonstrate the behavior of the robot in a variety of simulated scenarios and compare it to utility-based side-by-side navigation control.
ER  - 

TY  - CONF
TI  - Safe and Efficient High Dimensional Motion Planning in Space-Time with Time Parameterized Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5012
EP  - 5018
AU  - S. Li
AU  - J. A. Shah
PY  - 2019
KW  - collision avoidance
KW  - human-robot interaction
KW  - manipulators
KW  - mobile robots
KW  - probability
KW  - trajectory control
KW  - human-robot collaborative environments
KW  - pre-planned path
KW  - 6-joint manipulator
KW  - human hand
KW  - robot trajectories
KW  - obstacle-avoidance strategies
KW  - motion planning
KW  - lazy safe interval probabilistic roadmap
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Prediction algorithms
KW  - Heuristic algorithms
KW  - Collision avoidance
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793580
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we propose an algorithm that can plan safe and efficient robot trajectories in real time, given time-parameterized motion predictions, in order to avoid fast-moving obstacles in human-robot collaborative environments. Our algorithm is able to reduce the robot configuration space and the time domain significantly by constructing a Lazy Safe Interval Probabilistic Roadmap based on a pre-planned path. The algorithm then plans efficient obstacle-avoidance strategies within the space-time roadmap. We benchmarked our algorithm by evaluating the performance of a simulated 6-joint manipulator attempting to avoid a quickly moving human hand, using a dataset collected from human experiments. We compared our algorithm's performance with those of 8 variations of prior state-of-the-art planners. Results from this empirical evaluation indicate that our method generated safe plans in 97.5% of the evaluated situations, achieved a planning speed 30 times faster than the benchmarked methods that planned in the time domain without space reduction, and accomplished the minimal solution execution time among the benchmarked planners with a similar planning speed.
ER  - 

TY  - CONF
TI  - Fast Online Segmentation of Activities from Partial Trajectories
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5019
EP  - 5025
AU  - T. Iqbal
AU  - S. Li
AU  - C. Fourie
AU  - B. Hayes
AU  - J. A. Shah
PY  - 2019
KW  - assembling
KW  - hidden Markov models
KW  - image segmentation
KW  - industrial robots
KW  - maximum likelihood estimation
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - robot vision
KW  - fast online segmentation
KW  - partial trajectory
KW  - efficient plan
KW  - safe plan
KW  - online activity segmentation algorithm
KW  - hidden Markov model
KW  - efficient particle-filtering approach
KW  - activity sequence
KW  - online search process
KW  - task model information
KW  - partial order
KW  - human activity datasets
KW  - industrial mobile robot
KW  - automotive assembly task
KW  - Trajectory
KW  - Hidden Markov models
KW  - Robots
KW  - Task analysis
KW  - Computational modeling
KW  - Prediction algorithms
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8794054
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Augmenting a robot with the capacity to understand the activities of the people it collaborates with in order to then label and segment those activities allows the robot to generate an efficient and safe plan for performing its own actions. In this work, we introduce an online activity segmentation algorithm that can detect activity segments by processing a partial trajectory. We model the transitions through activities as a hidden Markov model, which runs online by implementing an efficient particle-filtering approach to infer the maximum a posteriori estimate of the activity sequence. This process is complemented by an online search process to refine activity segments using task model information about the partial order of activities. We evaluated our algorithm by comparing its performance to two state-of-the-art activity segmentation algorithms on three human activity datasets. The proposed algorithm improved activity segmentation accuracy across all three datasets compared with the other two approaches, with a range from 11.3% to 65.5%, and could accurately recognize an activity through observation alone for 31.6% of the initial trajectory of that activity, on average. We also implemented the algorithm onto an industrial mobile robot during an automotive assembly task in which the robot tracked a human worker's progress and provided the worker with the correct materials at the appropriate time.
ER  - 

TY  - CONF
TI  - Laparoscopy instrument tracking for single view camera and skill assessment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5039
EP  - 5045
AU  - B. Gautier
AU  - H. Tugal
AU  - B. Tang
AU  - G. Nabi
AU  - M. S. Erden
PY  - 2019
KW  - cameras
KW  - medical computing
KW  - surgery
KW  - visual tracking algorithm
KW  - 3D reconstructed trajectories
KW  - linear discriminant analysis
KW  - frequency analysis
KW  - simple colored tapes
KW  - standard physical training box
KW  - extracted tool trajectories
KW  - single webcam camera
KW  - standard laparoscopy training box
KW  - minimally invasive surgical skills
KW  - single view camera
KW  - laparoscopy instrument tracking
KW  - Instruments
KW  - Laparoscopes
KW  - Training
KW  - Estimation
KW  - Kalman filters
KW  - Trajectory
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794038
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Assessment of minimally invasive surgical skills is a non-trivial task, usually requiring the presence and time of expert observers, including subjectivity and requiring special and expensive equipment and software. This study develops an algorithm for tracking laparoscopy instruments in the video cues of a standard laparoscopy training box with a single webcam camera and proposes new criteria to assess skill level using the extracted tool trajectories. Instrument tracking and assessment criteria together constitute a significant step towards developing a low cost, automated, and widely applicable laparoscopy training and assessment system using a standard physical training box equipped with a webcam. The developed visual tracking algorithm recovers the 3D positions of the laparoscopic instruments tips to which simple colored tapes (markers) are attached. The new assessment criteria are based on frequency analysis and linear discriminant analysis of the 3D reconstructed trajectories of the instruments. The performance of these proposed criteria are compared to the conventional criteria for laparoscopy training and demonstrated to be superior on the data we have recorded from six professional laparoscopy surgeons and ten novice subjects.
ER  - 

TY  - CONF
TI  - OffsetNet: Deep Learning for Localization in the Lung using Rendered Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5046
EP  - 5052
AU  - J. Sganga
AU  - D. Eng
AU  - C. Graetzel
AU  - D. Camarillo
PY  - 2019
KW  - cameras
KW  - closed loop systems
KW  - image reconstruction
KW  - image registration
KW  - medical computing
KW  - medical image processing
KW  - phantoms
KW  - rendering (computer graphics)
KW  - surgery
KW  - bronchoscope
KW  - update rate
KW  - average position error
KW  - conserved regions
KW  - training dataset
KW  - simulated images
KW  - simulated domains
KW  - conservative thresholds
KW  - rendered images
KW  - surgical tools
KW  - dynamic anatomy
KW  - tortuous anatomy
KW  - real-time localization
KW  - preoperative scan
KW  - human operators
KW  - closed-loop control
KW  - autonomous agents
KW  - deep learning architecture
KW  - recorded camera images
KW  - lung phantom
KW  - OffsetNet
KW  - time 30.0 min
KW  - frequency 47.0 Hz
KW  - Lung
KW  - Computed tomography
KW  - Training
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Cameras
KW  - Imaging phantoms
DO  - 10.1109/ICRA.2019.8793940
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Navigating surgical tools in the dynamic and tortuous anatomy of the lung's airways requires accurate, real-time localization of the tools with respect to the preoperative scan of the anatomy. Such localization can inform human operators or enable closed-loop control by autonomous agents, which would require accuracy not yet reported in the literature. In this paper, we introduce a deep learning architecture, called OffsetNet, to accurately localize a bronchoscope in the lung in real-time. After training on only 30 minutes of recorded camera images in conserved regions of a lung phantom, OffsetNet tracks the bronchoscope's motion on a held-out recording through these same regions at an update rate of 47 Hz and an average position error of 1.4 mm. Because this model performs poorly in less conserved regions, we augment the training dataset with simulated images from these regions. To bridge the gap between camera and simulated domains, we implement domain randomization and a generative adversarial network (GAN). After training on simulated images, OffsetNet tracks the bronchoscope's motion in less conserved regions at an average position error of 2.4 mm, which meets conservative thresholds required for successful tracking.
ER  - 

TY  - CONF
TI  - Using Augmentation to Improve the Robustness to Rotation of Deep Learning Segmentation in Robotic-Assisted Surgical Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5068
EP  - 5075
AU  - D. Itzkovich
AU  - Y. Sharon
AU  - A. Jarc
AU  - Y. Refaely
AU  - I. Nisky
PY  - 2019
KW  - data handling
KW  - learning (artificial intelligence)
KW  - medical computing
KW  - medical robotics
KW  - recurrent neural nets
KW  - robot kinematics
KW  - surgery
KW  - telerobotics
KW  - JIGSAWS dataset
KW  - data augmentation
KW  - kinematic data
KW  - surgical data science
KW  - deep learning segmentation
KW  - robotic-assisted surgical data
KW  - Robotic-Assisted Minimally Invasive Surgery
KW  - automated segmentation
KW  - data-intensive segmentation algorithms
KW  - da Vinci Research Kit
KW  - recurrent neural network
KW  - Surgery
KW  - Task analysis
KW  - Training
KW  - Robots
KW  - Kinematics
KW  - Deep learning
KW  - Robustness
KW  - Surgical Robotics: Laparoscopy
KW  - Deep Learning in Robotics and Automation
KW  - Rotation augmentation
KW  - Network generalization
DO  - 10.1109/ICRA.2019.8793963
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic-Assisted Minimally Invasive Surgery allows for easy recording of kinematic data, and presents excellent opportunities for data-intensive approaches to assessment of surgical skill, system design, and automation of procedures. However, typical surgical cases result in long data streams, and therefore, automated segmentation into gestures is important. The public release of the JIGSAWS dataset allowed for developing and benchmarking data-intensive segmentation algorithms. However, this dataset is small and the gestures are similar in their structure and directions. This may limit the generalization of the algorithms to real surgical data that are characterized by movements in arbitrary directions. In this paper, we use a recurrent neural network to segment a suturing task, and demonstrate one such generalization problem-limited generalization to rotation. We propose a simple augmentation that can solve this problem without collecting new data, and demonstrate its benefit using: (1) the JIGSAWS dataset, and (2) a new dataset that we recorded with a da Vinci Research Kit. Our study highlights the prospect of using data augmentation in the analysis of kinematic data in surgical data science.
ER  - 

TY  - CONF
TI  - Deep Learning based Motion Prediction for Exoskeleton Robot Control in Upper Limb Rehabilitation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5076
EP  - 5082
AU  - J. Ren
AU  - Y. Chien
AU  - E. Chia
AU  - L. Fu
AU  - J. Lai
PY  - 2019
KW  - biomechanics
KW  - electromyography
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - medical signal processing
KW  - mobile robots
KW  - motion control
KW  - patient rehabilitation
KW  - trajectory control
KW  - wearable robots
KW  - deep learning based motion prediction model
KW  - human arm dynamics
KW  - surface electromyography
KW  - deep learning model
KW  - robot arm
KW  - exoskeleton robot control
KW  - robot-assisted training
KW  - motion trajectory
KW  - 8 degrees-of-freedom upper limb rehabilitation exoskeleton
KW  - NTUH-II
KW  - user motion prediction
KW  - RAT
KW  - wireless sensors
KW  - sEMG
KW  - 8DoFs
KW  - Manipulators
KW  - Exoskeletons
KW  - Sensors
KW  - Deep learning
KW  - Muscles
KW  - Training
DO  - 10.1109/ICRA.2019.8794187
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The synchronization of the movement between exoskeleton robot and human arm is crucial for Robot-assisted training (RAT) in upper limb rehabilitation. In this paper, we propose a deep learning based motion prediction model which is applied to our recently developed 8 degrees-of-freedom (DoFs) upper limb rehabilitation exoskeleton, named NTUH-II. The human arm dynamics and surface electromyography (sEMG) can be first measured by two wireless sensors and used as input of deep learning model to predict user's motion. Then, the prediction can be used as desired motion trajectory of the exoskeleton. As a result, the robot arm can follow the movement on either side of the user's arm in real-time. Various experiments have been conducted to verify the performance of the proposed motion prediction model, and the results show that the proposed motion prediction implementation can reduce the mean absolute error and the average delay time of movement between human arm and robot arm.
ER  - 

TY  - CONF
TI  - Adaptive Gait Planning for Walking Assistance Lower Limb Exoskeletons in Slope Scenarios
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5083
EP  - 5089
AU  - C. Zou
AU  - R. Huang
AU  - H. Cheng
AU  - Q. Chen
AU  - J. Qiu
PY  - 2019
KW  - adaptive control
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - medical robotics
KW  - motion control
KW  - pendulums
KW  - robot dynamics
KW  - adaptive gait planning approach
KW  - lower-limb walking assistance exoskeletons
KW  - human-exoskeleton system
KW  - reference foot locations
KW  - adaptive gait trajectories
KW  - level ground walking
KW  - paraplegic patients
KW  - slope terrains
KW  - stepping locations
KW  - dynamic movement primitives
KW  - 2D linear inverted pendulum model
KW  - dynamic gait generator
KW  - conventional capture point theory
KW  - Legged locomotion
KW  - Exoskeletons
KW  - Foot
KW  - Trajectory
KW  - Adaptation models
KW  - Force
KW  - Planning
KW  - Adaptive Gait Planning
KW  - Lower-limb Exoskeleton
KW  - LIPM
KW  - Dynamic Movement Primitives
KW  - Slope
DO  - 10.1109/ICRA.2019.8793863
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Lower-limb exoskeleton has gained considerable interests in walking assistance applications for paraplegic patients. In walking assistance of paraplegic patients, the exoskeleton should have the ability to help patients to walk over different terrains in the daily life, such as slope terrains. One critical issue is how to plan the stepping locations on slopes with different gradients, and generate stable and human-like gaits for patients. This paper proposed an adaptive gait planning approach which can generate gait trajectories adapt to slopes with different gradients for lower-limb walking assistance exoskeletons. We modeled the human-exoskeleton system as a 2D Linear Inverted Pendulum Model (2D-LIPM) with an external force in the two-dimensional sagittal plane, and proposed a Dynamic Gait Generator (DGG) based on an extension of the conventional Capture Point (CP) theory and Dynamic Movement Primitives (DMPs). The proposed approach can dynamically generate reference foot locations for each step on slopes, and human-like adaptive gait trajectories can be reproduced after the learning from demonstrated trajectories that sampled from level ground walking of normal healthy human. We demonstrated the efficiency of the proposed approach on both the Gazebo simulation platform and an exoskeleton named AIDER. Experimental results indicate that the proposed approach is able to provide the ability for exoskeletons to generate appropriate gaits adapt to slopes with different gradients.
ER  - 

TY  - CONF
TI  - A Data-Driven Predictive Model of Individual-Specific Effects of FES on Human Gait Dynamics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5090
EP  - 5096
AU  - L. Drnach
AU  - J. L. Allen
AU  - I. Essa
AU  - L. H. Ting
PY  - 2019
KW  - bioelectric phenomena
KW  - gait analysis
KW  - kinematics
KW  - medical robotics
KW  - muscle
KW  - patient rehabilitation
KW  - gait coordination patterns
KW  - robotic control strategies
KW  - functional electrical stimulation
KW  - gait cycle
KW  - Switched Linear Dynamical Systems
KW  - joint angles
KW  - kinematic model
KW  - SLDS predictions
KW  - SLDS dynamics matrices
KW  - gait phase information
KW  - joint angle trajectories
KW  - SLDS models
KW  - normal gait
KW  - joint angle kinematic data
KW  - data-driven gait models
KW  - electrical perturbations
KW  - mechanical perturbations
KW  - gait kinematics
KW  - gait rehabilitation robotics
KW  - human gait dynamics
KW  - individual-specific effects
KW  - data-driven predictive model
KW  - Superluminescent diodes
KW  - Legged locomotion
KW  - Kinematics
KW  - Trajectory
KW  - Predictive models
KW  - Iron
KW  - Data models
DO  - 10.1109/ICRA.2019.8794304
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Modeling individual-specific gait dynamics based on kinematic data could aid development of gait rehabilitation robotics by enabling robots to predict the user's gait kinematics with and without external inputs, such as mechanical or electrical perturbations. Here we address a current limitation of data-driven gait models, which do not yet predict human gait dynamics nor responses to perturbations. We used Switched Linear Dynamical Systems (SLDS) to model joint angle kinematic data from healthy individuals walking on a treadmill during normal gait and during gait perturbed by functional electrical stimulation (FES) to the ankle muscles. Our SLDS models were able to generate joint angle trajectories in each of four gait phases, as well as across an entire gait cycle, given initial conditions and gait phase information. Because the SLDS dynamics matrices encoded significant coupling across joints that differed across indivdiuals, we compared the SLDS predictions to that of a kinematic model, where the joint angles were independent. Joint angle trajectories generated by SLDS and kinematic models were similar over time horizons of a few milliseconds, but SLDS models provided better predictions of gait kinematics over time horizons of up to a second. We also demonstrated that SLDS models can infer and predict individual-specific responses to FES during swing phase. As such, SLDS models may be a promising approach for online estimation and control of and human gait dynamics, allowing robotic control strategies to be tailored to an individual's specific gait coordination patterns.
ER  - 

TY  - CONF
TI  - The (Sensorized) Hand is Quicker than the Eye: Restoring Grasping Speed and Confidence for Amputees with Tactile Reflexes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5097
EP  - 5102
AU  - J. A. Fishel
AU  - B. Matulevich
AU  - K. A. Muller
AU  - G. M. Berke
PY  - 2019
KW  - electromyography
KW  - medical control systems
KW  - prosthetics
KW  - tactile sensors
KW  - touch (physiological)
KW  - myoelectric prosthetic hand
KW  - closing signals
KW  - open-cell self-skinning polyurethane foam
KW  - tactile reflexes
KW  - user confidence
KW  - sound side limb
KW  - rigid items
KW  - fragile items
KW  - unilateral myoelectric prosthesis users
KW  - inhibitory reflex controller
KW  - contact signal
KW  - air pressure
KW  - excessive forces
KW  - simple tactile reflex
KW  - tactile sensors
KW  - human hand dexterity
KW  - fragile objects
KW  - myoelectric prosthetic hand users
KW  - grasping speed
KW  - Electromyography
KW  - Grasping
KW  - Prosthetic hand
KW  - Task analysis
KW  - Tactile sensors
DO  - 10.1109/ICRA.2019.8793643
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Myoelectric prosthetic hand users have difficulty with, and frequently avoid, grasping fragile objects with their prosthesis. While the sense of touch is known to be critical for human hand dexterity, it has been virtually absent in prosthetic hands. In this study, a standard myoelectric prosthetic hand was modified with tactile sensors and a simple tactile reflex to inhibit excessive forces on contact. The tactile sensors were made from an open-cell self-skinning polyurethane foam that produced a detectable increase in air pressure inside the foam when contacted. This contact signal was then used by an inhibitory reflex controller which served to reduce the gain of weaker closing signals after contact but allow stronger closing signals to pass through. Four unilateral myoelectric prosthesis users completed five trials of three different timed grasping tasks with fragile and rigid items. Subjects performed each task in three different scenarios: with their sound side limb, their current myoelectric hand, and the modified prosthesis with tactile reflex. Findings demonstrated that grasping performance with fragile objects was significantly enhanced using the modified prosthesis, even nearing the performance of subject's sound side limb. Results suggest that this approach can substantially improve the speed and success of grasping fragile items, leading to improved use patterns, decreased cognitive effort, and improved user confidence.
ER  - 

TY  - CONF
TI  - Development of A Soft Power Suit for Lower Back Assistance*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5103
EP  - 5109
AU  - Z. Yao
AU  - C. Linnenberg
AU  - R. Weidner
AU  - J. Wulfsberg
PY  - 2019
KW  - actuators
KW  - bending
KW  - biomechanics
KW  - bone
KW  - kinematics
KW  - medical control systems
KW  - muscle
KW  - biomechanical study
KW  - fabric construction
KW  - twisted string actuators
KW  - mechanical stresses
KW  - lower back assistance
KW  - static forward bending
KW  - trunk flexion
KW  - bending kinematics
KW  - static bending posture
KW  - risk factor
KW  - muscle activation
KW  - lightweight design
KW  - tensile forces
KW  - force transmission
KW  - dynamic lifting
KW  - physical load
KW  - repetitive heavy lifting
KW  - occupational activities
KW  - low back pain
KW  - soft power suit
KW  - Back
KW  - Force
KW  - Muscles
KW  - Fabrics
KW  - Thigh
KW  - Hip
KW  - Actuators
DO  - 10.1109/ICRA.2019.8794026
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mechanical stresses on the spine are a significant risk factor for low back pain, a highly prevalent health problem around the world. Certain occupational activities such as repetitive heavy lifting and static bending posture lead to high loads on the lower back. To address this problem, we are developing a soft power suit capable of reducing physical load on the lower back during dynamic lifting and static forward bending. The power suit is designed to mimic the force transmission in the body and duplicate the force generated by muscles and tendons. Two twisted string actuators (TSAs) attached to a back brace are used to generate tensile forces which assist the underlying muscles to control trunk flexion. The fabric construction and TSA enable a lightweight design of the suit: without the battery, the entire system weighs only 2.4kg. Here we present the design and implementation of the prototype system along with a preliminary biomechanical study that evaluates the effect of the system on the body. The results show that the power suit does not change the wearer's bending kinematics and helps the subject to keep the static bending posture. Moreover, using the power suit significantly reduced the muscle activation required for both static bending and dynamic lifting (50.2-54.0% and 21.4-25.2% reduction, respectively).
ER  - 

TY  - CONF
TI  - A new soft fingertip based on electroactive hydrogels
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5126
EP  - 5132
AU  - A. López-Díaz
AU  - A. Martín-Pacheco
AU  - R. Fernández
AU  - A. M. Rodríguez
AU  - M. A. Herrero
AU  - E. Vázquez
AU  - A. S. Vázquez
PY  - 2019
KW  - control system synthesis
KW  - dexterous manipulators
KW  - hydrogels
KW  - robotic hands
KW  - aqueous solutions
KW  - fingertip applications
KW  - stiffness
KW  - electric fields
KW  - fingertip properties
KW  - electroactive hydrogels
KW  - active soft fingertip
KW  - Ions
KW  - Grasping
KW  - Electrodes
KW  - Mathematical model
KW  - Soft robotics
KW  - Polymers
DO  - 10.1109/ICRA.2019.8794105
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we present the design and application of an active soft fingertip for robotic hands. This fingertip is based on a new type of hydrogel which has been designed with the purpose of overcoming some of the major drawbacks of previous hydrogels such as the dependency of aqueous solutions. Fingertip applications benefit from the changes of stiffness and volume which take place in our hydrogel when electric fields are applied. Theoretical modeling and experimental verification of the fingertip properties are presented in this work, showing its potential usability in grasping and manipulation tasks.
ER  - 

TY  - CONF
TI  - Open Loop Position Control of Soft Continuum Arm Using Deep Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5133
EP  - 5139
AU  - S. Satheeshbabu
AU  - N. K. Uppalapati
AU  - G. Chowdhary
AU  - G. Krishnan
PY  - 2019
KW  - bending
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - neural nets
KW  - numerical analysis
KW  - pneumatic actuators
KW  - position control
KW  - torsion
KW  - open loop position control
KW  - deep reinforcement learning
KW  - soft robots
KW  - nonlinear spatial deformations
KW  - inherent actuation
KW  - numerical models
KW  - soft spatial continuum arm
KW  - unidirectional bending deformation
KW  - bidirectional torsional deformation
KW  - Deep-Q Learning
KW  - continuum arm prototype
KW  - external loading conditions
KW  - Manipulators
KW  - Load modeling
KW  - Mathematical model
KW  - Numerical models
KW  - Strain
DO  - 10.1109/ICRA.2019.8793653
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robots undergo large nonlinear spatial deformations due to both inherent actuation and external loading. The physics underlying these deformations is complex, and often requires intricate analytical and numerical models. The complexity of these models may render traditional model-based control difficult and unsuitable. Model-free methods offer an alternative for analyzing the behavior of such complex systems without the need for elaborate modeling techniques. In this paper, we present a model-free approach for open loop position control of a soft spatial continuum arm, based on deep reinforcement learning. The continuum arm is pneumatically actuated and attains a spatial work-space by a combination of unidirectional bending and bidirectional torsional deformation. We use Deep-Q Learning with experience replay to train the system in simulation. The efficacy and robustness of the control policy obtained from the system is validated both in simulation and on the continuum arm prototype for varying external loading conditions.
ER  - 

TY  - CONF
TI  - Fast Motion Planning for High-DOF Robot Systems Using Hierarchical System Identification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5140
EP  - 5147
AU  - B. Jia
AU  - Z. Pan
AU  - D. Manocha
PY  - 2019
KW  - actuators
KW  - elasticity
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - motion control
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - reinforcement-learning-based feedback control
KW  - underwater swimming robot
KW  - line-actuated elastic robot arm
KW  - optimization-based motion planning
KW  - hierarchical adaptive grid
KW  - forward dynamics
KW  - articulated robots
KW  - soft robots
KW  - hierarchical system identification
KW  - high-DOF robot systems
KW  - fast motion planning
KW  - Dynamics
KW  - Planning
KW  - Heuristic algorithms
KW  - Soft robotics
KW  - Finite element analysis
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793814
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an efficient algorithm for motion planning and controlling a robot system with a high number of degrees-of-freedom (DOF). These systems include high-DOF soft robots and articulated robots interacting with a deformable environment. We present a novel technique to accelerate the evaluations of the forward dynamics function by storing the results of costly computations in a hierarchical adaptive grid. Furthermore, we exploit the underactuated properties of the robot systems and build the grid in a low-dimensional space. Our approach approximates the forward dynamics function with guaranteed error bounds and can be used in optimization-based motion planning and reinforcement-learning-based feed-back control. We highlight the performance on two high-DOF robot systems: a line-actuated elastic robot arm and an underwater swimming robot in water. Compared to prior techniques based on exact dynamics evaluation, we observe one to two orders of magnitude improvement in the performance.
ER  - 

TY  - CONF
TI  - Resilient Task Planning and Execution for Reactive Soft Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5148
EP  - 5154
AU  - S. Hamill
AU  - J. Whitehead
AU  - P. Ferenz
AU  - R. F. Shepherd
AU  - H. Kress-Gazit
PY  - 2019
KW  - control system synthesis
KW  - legged locomotion
KW  - temporal logic
KW  - physical soft robot
KW  - reactive soft robots
KW  - compliant materials
KW  - rigid bodied systems
KW  - soft actuator fabrication methods
KW  - multigait walking soft robots
KW  - soft materials
KW  - resilient task planning
KW  - reactive controllers
KW  - formal synthesis
KW  - sensing-based abstraction
KW  - linear temporal logic
KW  - Actuators
KW  - Legged locomotion
KW  - Soft robotics
KW  - Robot sensing systems
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794303
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robots utilize compliant materials to perform motions and behaviors not typically achievable by rigid bodied systems. These materials and soft actuator fabrication methods have been leveraged to create multigait walking soft robots. However, soft materials are prone to failure, restricting the ability of soft robots to accomplish tasks. In this work we address the problem of generating reactive controllers for multigait walking soft robots that are resilient to actuator failure by applying methods of formal synthesis. We present a sensing-based abstraction for actuator performance, provide a framework for encoding multigait behavior and actuator failure in Linear Temporal Logic (LTL), and demonstrate synthesized controllers on a physical soft robot.
ER  - 

TY  - CONF
TI  - Dynamic morphological computation through damping design of soft material robots: application to under-actuated grippers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5155
EP  - 5161
AU  - A. D. Lallo
AU  - M. Catalano
AU  - M. Garabini
AU  - G. Grioli
AU  - M. Gabiccini
AU  - A. Bicchi
PY  - 2019
KW  - bending
KW  - damping
KW  - design engineering
KW  - dexterous manipulators
KW  - elasticity
KW  - granular materials
KW  - grippers
KW  - pneumatic actuators
KW  - pneumatic systems
KW  - granular material
KW  - bending actuators
KW  - dynamic morphological computation
KW  - damping design
KW  - soft material robots
KW  - under-actuated grippers
KW  - multichamber pneumatic systems
KW  - mechanical parameters
KW  - stiffness system
KW  - viscous oil
KW  - immersion
KW  - deformation pattern
KW  - Damping
KW  - Strain
KW  - Oils
KW  - Viscosity
KW  - Robots
KW  - Pneumatic systems
KW  - Actuators
DO  - 10.1109/ICRA.2019.8793987
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This article presents the design of soft material robots with tunable damping properties. This study derives from the investigation of an under-actuated dynamic approach involving multi-chamber pneumatic systems. The co-design of the mechanical parameters (stiffness and damping) of the system along with the time profile of the input allows to obtain different behaviors using a reduced number of feeding line. In this work we analyze via simulations and experiments several approaches to tune the damping of soft robots. The most effective solution employs a layer of granular material immersed in viscous oil within the chamber wall. This method has been employed to realize bending actuators with a continuous deformation pattern. Finally, we show an application involving a two-fingered gripper fed by a single pneumatic line, which is able to perform pinch and power grasp.
ER  - 

TY  - CONF
TI  - Augmented Reality Assisted Instrument Insertion and Tool Manipulation for the First Assistant in Robotic Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5173
EP  - 5179
AU  - L. Qian
AU  - A. Deguet
AU  - Z. Wang
AU  - Y. Liu
AU  - P. Kazanzides
PY  - 2019
KW  - augmented reality
KW  - helmet mounted displays
KW  - mean square error methods
KW  - medical robotics
KW  - robot vision
KW  - surgery
KW  - telerobotics
KW  - hand-eye configurations
KW  - root-mean-square path deviation
KW  - novice assistants
KW  - hand-eye coordination
KW  - tool manipulation time
KW  - navigation time
KW  - experienced surgeons
KW  - head-mounted display
KW  - augmented reality application
KW  - ARssist
KW  - hand-held tools
KW  - FA
KW  - robotic-assisted laparoscopic surgery
KW  - first assistant
KW  - augmented reality assisted instrument insertion
KW  - Instruments
KW  - Endoscopes
KW  - Surgery
KW  - Robot kinematics
KW  - Tools
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794263
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In robotic-assisted laparoscopic surgery, the first assistant (FA) stands at the bedside assisting the intervention, while the surgeon sits at the console teleoperating the robot. Tasks for the FA include navigating new instruments into the surgeon's field-of-view and passing in or retracting materials from the body using hand-held tools. We previously developed ARssist, an augmented reality application based on an optical see-through head-mounted display, to aid the FA. In this paper, we refine the system and first perform a pilot study with three experienced surgeons for two specific tasks: instrument insertion and tool manipulation. The results suggest that ARssist would be especially useful for less experienced assistants and for difficult hand-eye configurations. We then perform a multi-user study with inexperienced subjects. The results show that ARssist can reduce navigation time by 34.57%, enhance insertion path consistency by 41.74%, reduce root-mean-square path deviation by 40.04%, and reduce tool manipulation time by 72.25%. Thus, ARssist has the potential to improve efficiency, safety and hand-eye coordination, especially for novice assistants.
ER  - 

TY  - CONF
TI  - High-Fidelity Grasping in Virtual Reality using a Glove-based System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5180
EP  - 5186
AU  - H. Liu
AU  - Z. Zhang
AU  - X. Xie
AU  - Y. Zhu
AU  - Y. Liu
AU  - Y. Wang
AU  - S. Zhu
PY  - 2019
KW  - computational geometry
KW  - computer simulation
KW  - data gloves
KW  - haptic interfaces
KW  - human computer interaction
KW  - manipulators
KW  - object tracking
KW  - virtual reality
KW  - physics-based simulation
KW  - haptic feedback
KW  - glove-based design
KW  - collision geometry
KW  - Vive Tracker
KW  - high-fidelity grasping
KW  - virtual objects
KW  - caging-based approach
KW  - virtual environments
KW  - virtual object manipulation
KW  - high-fidelity hand
KW  - VR
KW  - Virtual Reality
KW  - real-time stable grasps
KW  - hand localization
KW  - glove-based system
KW  - Haptic interfaces
KW  - Robot sensing systems
KW  - Vibrations
KW  - Real-time systems
KW  - Hardware
KW  - Geometry
DO  - 10.1109/ICRA.2019.8794230
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a design that jointly provides hand pose sensing, hand localization, and haptic feedback to facilitate real-time stable grasps in Virtual Reality (VR). The design is based on an easy-to-replicate glove-based system that can reliably perform (i) a high-fidelity hand pose sensing in real time through a network of 15 IMUs, and (ii) the hand localization using a Vive Tracker. The supported physics-based simulation in VR is capable of detecting collisions and contact points for virtual object manipulation, which drives the collision event to trigger the physical vibration motors on the glove to signal the user, providing a better realism inside virtual environments. A caging-based approach using collision geometry is integrated to determine whether a grasp is stable. In the experiment, we showcase successful grasps of virtual objects with large geometry variations. Comparing to the popular LeapMotion sensor, we demonstrate the proposed glove-based design yields a higher success rate in various tasks in VR. We hope such a glove-based system can simplify the data collection of human manipulations with VR.
ER  - 

TY  - CONF
TI  - On the role of wearable haptics for force feedback in teleimpedance control for dual-arm robotic teleoperation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5187
EP  - 5193
AU  - J. P. Clark
AU  - G. Lentini
AU  - F. Barontini
AU  - M. G. Catalano
AU  - M. Bianchi
AU  - M. K. O’Malley
PY  - 2019
KW  - dexterous manipulators
KW  - force feedback
KW  - haptic interfaces
KW  - telerobotics
KW  - haptic sensation
KW  - wearable haptic devices
KW  - wearable haptics
KW  - force feedback
KW  - teleimpedance control
KW  - dual-arm robotic teleoperation
KW  - box placement task
KW  - higher mean interaction forces
KW  - wearable haptic feedback
KW  - safely complete exploratory procedures
KW  - deep sea exploration
KW  - haptic interactions
KW  - dual arm robotic coordination
KW  - Task analysis
KW  - Force feedback
KW  - Force
KW  - Manipulators
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793652
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic teleoperation enables humans to safely complete exploratory procedures in remote locations for applications such as deep sea exploration or building assessments following natural disasters. Successful task completion requires meaningful dual arm robotic coordination and proper understanding of the environment. While these capabilities are inherent to humans via impedance regulation and haptic interactions, they can be challenging to achieve in telerobotic systems. Teleimpedance control has allowed impedance regulation in such applications, and bilateral teleoperation systems aim to restore haptic sensation to the operator, though often at the expense of stability or workspace size. Wearable haptic devices have the potential to apprise the operator of key forces during task completion while maintaining stability and transparency. In this paper, we evaluate the impact of wearable haptics for force feedback in teleimpedance control for dual-arm robotic teleoperation. Participants completed a peg-in-hole, box placement task, aiming to seat as many boxes as possible within the trial period. Experiments were conducted both transparent and opaque boxes. With the opaque box, participants achieved a higher number of successful placements with haptic feedback, and we saw higher mean interaction forces. Results suggest that the provision of wearable haptic feedback may increase confidence when visual cues are obscured.
ER  - 

TY  - CONF
TI  - CNN-SVO: Improving the Mapping in Semi-Direct Visual Odometry Using Single-Image Depth Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5218
EP  - 5223
AU  - S. Y. Loo
AU  - A. J. Amiri
AU  - S. Mashohor
AU  - S. H. Tang
AU  - H. Zhang
PY  - 2019
KW  - feature extraction
KW  - motion estimation
KW  - probability
KW  - SLAM (robots)
KW  - SVO mapping results
KW  - frame rate camera motion estimation
KW  - map points
KW  - initialized map point
KW  - depth uncertainty
KW  - single-image depth prediction network
KW  - feature location
KW  - probabilistic mapping method
KW  - direct pixel correspondence
KW  - semidirect visual odometry
KW  - V-SLAM algorithms
KW  - visual simultaneous localization
KW  - Uncertainty
KW  - Cameras
KW  - Visual odometry
KW  - Feature extraction
KW  - Reliability
KW  - Estimation
KW  - Motion estimation
DO  - 10.1109/ICRA.2019.8794425
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Reliable feature correspondence between frames is a critical step in visual odometry (VO) and visual simultaneous localization and mapping (V-SLAM) algorithms. In comparison with existing VO and V-SLAM algorithms, semi-direct visual odometry (SVO) has two main advantages that lead to state-of-the-art frame rate camera motion estimation: direct pixel correspondence and efficient implementation of probabilistic mapping method. This paper improves the SVO mapping by initializing the mean and the variance of the depth at a feature location according to the depth prediction from a single-image depth prediction network. By significantly reducing the depth uncertainty of the initialized map point (i.e., small variance centred about the depth prediction), the benefits are twofold: reliable feature correspondence between views and fast convergence to the true depth in order to create new map points. We evaluate our method with two outdoor datasets: KITTI dataset and Oxford Robotcar dataset. The experimental results indicate that improved SVO mapping results in increased robustness and camera tracking accuracy. The implementation of this work is available at https: //github.com/yan99033/CNN-SVO.
ER  - 

TY  - CONF
TI  - A Unified Framework for Mutual Improvement of SLAM and Semantic Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5224
EP  - 5230
AU  - K. Wang
AU  - Y. Lin
AU  - L. Wang
AU  - L. Han
AU  - M. Hua
AU  - X. Wang
AU  - S. Lian
AU  - B. Huang
PY  - 2019
KW  - image motion analysis
KW  - image segmentation
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - segmentation algorithms
KW  - semantic segmentation
KW  - robotics
KW  - refined 3D pose information
KW  - vision-based tasks
KW  - mutual improvement
KW  - unified framework
KW  - instantaneous motion change handling
KW  - long-term changes
KW  - simultaneous localization and segmentation
KW  - Image segmentation
KW  - Task analysis
KW  - Robot sensing systems
KW  - Motion segmentation
KW  - Feature extraction
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793499
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel framework for simultaneously implementing localization and segmentation, which are two of the most important vision-based tasks for robotics. While the goals and techniques used for them were considered to be different previously, we show that by making use of the intermediate results of the two modules, their performance can be enhanced at the same time. Our framework is able to handle both the instantaneous motion and long-term changes of instances in localization with the help of the segmentation result, which also benefits from the refined 3D pose information. We conduct experiments on various datasets, and prove that our framework works effectively on improving the precision and robustness of the two tasks and outperforms existing localization and segmentation algorithms.
ER  - 

TY  - CONF
TI  - MID-Fusion: Octree-based Object-Level Multi-Instance Dynamic SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5231
EP  - 5237
AU  - B. Xu
AU  - W. Li
AU  - D. Tzoumanikas
AU  - M. Bloesch
AU  - A. Davison
AU  - S. Leutenegger
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image motion analysis
KW  - image segmentation
KW  - image sequences
KW  - object detection
KW  - object tracking
KW  - octrees
KW  - pose estimation
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - video signal processing
KW  - robustly track
KW  - foreground object probabilities
KW  - object model
KW  - object-level dynamic volumetric map
KW  - instance segmentation part
KW  - octree-based object-level multiinstance dynamic SLAM
KW  - multiinstance dynamic RGB-D SLAM system
KW  - robust camera tracking
KW  - geometric motion properties
KW  - geometric motion information
KW  - object-oriented tracking method
KW  - camera pose estimation
KW  - semantic motion properties
KW  - frequency 2.0 Hz to 3.0 Hz
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Tracking
KW  - Motion segmentation
KW  - Semantics
KW  - Dynamics
KW  - Measurement uncertainty
DO  - 10.1109/ICRA.2019.8794371
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a new multi-instance dynamic RGB-D SLAM system using an object-level octree-based volumetric representation. It can provide robust camera tracking in dynamic environments and at the same time, continuously estimate geometric, semantic, and motion properties for arbitrary objects in the scene. For each incoming frame, we perform instance segmentation to detect objects and refine mask boundaries using geometric and motion information. Meanwhile, we estimate the pose of each existing moving object using an object-oriented tracking method and robustly track the camera pose against the static scene. Based on the estimated camera pose and object poses, we associate segmented masks with existing models and incrementally fuse corresponding colour, depth, semantic, and foreground object probabilities into each object model. In contrast to existing approaches, our system is the first system to generate an object-level dynamic volumetric map from a single RGB-D camera, which can be used directly for robotic tasks. Our method can run at 2-3 Hz on a CPU, excluding the instance segmentation part. We demonstrate its effectiveness by quantitatively and qualitatively testing it on both synthetic and real-world sequences.
ER  - 

TY  - CONF
TI  - Surfel-Based Dense RGB-D Reconstruction With Global And Local Consistency
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5238
EP  - 5244
AU  - Y. Yang
AU  - W. Dong
AU  - M. Kaess
PY  - 2019
KW  - computer vision
KW  - image colour analysis
KW  - image reconstruction
KW  - optimisation
KW  - pose estimation
KW  - surfel-based dense RGB-D reconstruction
KW  - local consistency
KW  - high surface reconstruction accuracy
KW  - dense mapping
KW  - vision communities
KW  - robotics literature
KW  - RGB-D cameras
KW  - dense map
KW  - depth input
KW  - accurate local pose estimation
KW  - locally consistent model
KW  - pose tracking
KW  - offline computer vision methods
KW  - structure-from-motion
KW  - multiview stereo
KW  - batch optimization
KW  - global consistency
KW  - heavy computation loads
KW  - consistent reconstruction
KW  - offline SfM pipeline
KW  - strong global constraints
KW  - off-the-shelf SLAM systems
KW  - high local accuracy
KW  - factor graph optimization
KW  - accurate camera
KW  - dense reconstruction
KW  - dense SLAM systems
KW  - SfM-MVS pipelines
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Pose estimation
KW  - Image reconstruction
KW  - Geometry
DO  - 10.1109/ICRA.2019.8794355
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Achieving high surface reconstruction accuracy in dense mapping has been a desirable target for both robotics and vision communities. In the robotics literature, simultaneous localization and mapping (SLAM) systems use RGB-D cameras to reconstruct a dense map of the environment. They leverage the depth input to provide accurate local pose estimation and a locally consistent model. However, drift in the pose tracking over time leads to misalignments and artifacts. On the other hand, offline computer vision methods, such as the pipeline that combines structure-from-motion (SfM) and multi-view stereo (MVS), estimate the camera poses by performing batch optimization. These methods achieve global consistency, but suffer from heavy computation loads. We propose a novel approach that integrates both methods to achieve locally and globally consistent reconstruction. First, we estimate poses of keyframes in the offline SfM pipeline to provide strong global constraints at relatively low cost. Afterwards, we compute odometry between frames driven by off-the-shelf SLAM systems with high local accuracy. We fuse the two pose estimations using factor graph optimization to generate accurate camera poses for dense reconstruction. Experiments on real-world and synthetic datasets demonstrate that our approach produces more accurate models comparing to existing dense SLAM systems, while achieving significant speedup with respect to state-of-the-art SfM-MVS pipelines.
ER  - 

TY  - CONF
TI  - A-SLAM: Human in-the-loop Augmented SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5245
EP  - 5251
AU  - A. Sidaoui
AU  - M. K. Zein
AU  - I. H. Elhajj
AU  - D. Asmar
PY  - 2019
KW  - augmented reality
KW  - human-robot interaction
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - real-time systems
KW  - SLAM (robots)
KW  - telerobotics
KW  - A-SLAM
KW  - map editing
KW  - navigation-forbidden areas
KW  - navigation goals
KW  - SLAM algorithm
KW  - occupancy grid maps
KW  - human in-the-loop augmented SLAM
KW  - real environment representation
KW  - Microsoft HoloLens
KW  - robot teleoperation
KW  - pose correction
KW  - map correction
KW  - AR interface
KW  - Simultaneous localization and mapping
KW  - Navigation
KW  - Collaboration
KW  - Three-dimensional displays
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793539
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we are proposing an intuitive Augmented SLAM method (A-SLAM) that allows the user to interact, in real-time, with a robot running SLAM to correct for pose and map errors. We built an AR application that works on HoloLens and allows the operator to view the robot's map superposed on the physical environment and edit it. Through map editing, the operator can account for errors affecting real environment's representation by adding navigation-forbidden areas to the map in addition to the ability to correct errors affecting the localization. The proposed system allows the operator to edit the robot's pose (based on SLAM request) and can be extended to sending navigation goals to the robot, viewing the planned path to evaluate it before execution, and teleoperating the robot. The proposed solution could be applied on any 2D-based SLAM algorithm and can easily be extended to 3D SLAM techniques. We validated our system through experimentation on pose correction and map editing. Experiments demonstrated that through A-SLAM, SLAM runtime is cut to half, post-processing of maps is totally eliminated, and high quality occupancy grid maps could be achieved with minimal added computational and hardware costs.
ER  - 

TY  - CONF
TI  - Balance Map Analysis as a Measure of Walking Balance Based on Pendulum-Like Leg Movements
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5260
EP  - 5265
AU  - T. Kagawa
PY  - 2019
KW  - legged locomotion
KW  - linearisation techniques
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - state-space methods
KW  - balance map analysis
KW  - pendulum-like leg movements
KW  - swing legs
KW  - inverted pendulum
KW  - simple pendulum
KW  - linearization
KW  - nondimensionalization
KW  - compass gait model
KW  - energy ratio
KW  - phase difference
KW  - stance leg
KW  - swing leg
KW  - orbital energy conservation
KW  - step transition
KW  - balance loss
KW  - state space
KW  - reachability
KW  - walking balance
KW  - Legged locomotion
KW  - Trajectory
KW  - Orbits
KW  - Mathematical model
KW  - Compass
KW  - Computational modeling
KW  - Computer simulation
DO  - 10.1109/ICRA.2019.8793651
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes an analysis of walking balance in terms of movements of stance and swing legs based on an inverted pendulum and a simple pendulum. Linearization, decoupling, and non-dimensionalization of a compass gait model enable to characterize the relationship of the trajectories between the stance and swing legs by only two parameters (energy ratio and phase difference). The energy ratio is defined by the ratio of the orbital energy between the pendulums. The phase difference represents the position of the stance leg in relation to the swing leg. This study considers an orbital energy conservation of a step transition and analyzes reachability of a desirable touchdown condition. If the time evolution from a current state is not reachable to the desired touchdown region, the state is labeled as a state in balance loss. By analyzing the reachability limits of the energy ratio and phase difference, we illustrate the balance loss and safe regions on the state space of the inverted pendulum, which is termed as balance map. We examined the effects of the simplification and linearization of the compass gait model by using computer simulations. Through the simulations of walking with perturbations, we confirmed that the balance map analysis could predict a future fall in an early phase for even trajectories derived by the nonlinear model.
ER  - 

TY  - CONF
TI  - Non-parametric Imitation Learning of Robot Motor Skills
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5266
EP  - 5272
AU  - Y. Huang
AU  - L. Rozo
AU  - J. Silvério
AU  - D. G. Caldwell
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - nonparametric imitation learning
KW  - robot motor skills
KW  - learning capabilities
KW  - learning approach
KW  - kernel treatment
KW  - human skills
KW  - correlation-adaptive imitation learning
KW  - collaborative task
KW  - Trajectory
KW  - Robots
KW  - Task analysis
KW  - Probabilistic logic
KW  - Kernel
KW  - Databases
KW  - Correlation
DO  - 10.1109/ICRA.2019.8794267
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Unstructured environments impose several challenges when robots are required to perform different tasks and adapt to unseen situations. In this context, a relevant problem arises: how can robots learn to perform various tasks and adapt to different conditions? A potential solution is to endow robots with learning capabilities. In this line, imitation learning emerges as an intuitive way to teach robots different motor skills. This learning approach typically mimics human demonstrations by extracting invariant motion patterns and subsequently applies these patterns to new situations. In this paper, we propose a novel kernel treatment of imitation learning, which endows the robot with imitative and adaptive capabilities. In particular, due to the kernel treatment, the proposed approach is capable of learning human skills associated with high-dimensional inputs. Furthermore, we study a new concept of correlation-adaptive imitation learning, which allows for the adaptation of correlations exhibited in high-dimensional demonstrated skills. Several toy examples and a collaborative task with a real robot are provided to verify the effectiveness of our approach.
ER  - 

TY  - CONF
TI  - Dynamic Stepping on Unknown Obstacles With Upper-Body Compliance and Angular Momentum Damping From the Reaction Null-Space
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5273
EP  - 5279
AU  - Y. Hidaka
AU  - K. Nishizawa
AU  - D. N. Nenchev
PY  - 2019
KW  - acceleration control
KW  - angular momentum
KW  - damping
KW  - feedback
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - stability
KW  - short time interval
KW  - reaction null-space
KW  - stepping time
KW  - general whole-body controller
KW  - relative angular acceleration control component
KW  - angular momentum damping
KW  - dynamic stepping
KW  - unknown obstacles
KW  - upper-body compliance
KW  - robot steps
KW  - unknown height
KW  - RNS
KW  - iterative optimization
KW  - simulated dynamic stepping
KW  - Acceleration
KW  - Robots
KW  - Optimization
KW  - Damping
KW  - Dynamics
KW  - Task analysis
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793832
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Contact destabilization after an impact that occurs at high-speed, e.g. when a robot steps on an obstacle of unknown height, can be tackled by injecting angular momentum damping for a short time interval immediately after the impact. This is done by making use of the motion from within the reaction null-space (RNS). The angular momentum damping results in an appropriate arm motion that stabilizes the contacts. An impact at high-speed occurs when the stepping time is very short. In this case, conventional controllers cannot handle the reaction stemming from the swing leg dynamics. A general whole-body controller is designed that makes use of the relative angular acceleration control component to inject the angular momentum damping. The proposed control method is robust; it can deal with obstacles of various height and inclination without altering the feedback gains. The controller is fast since iterative optimization is avoided. The performance is examined via a simulated dynamic stepping.
ER  - 

TY  - CONF
TI  - Efficient Humanoid Contact Planning using Learned Centroidal Dynamics Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5280
EP  - 5286
AU  - Y. Lin
AU  - B. Ponton
AU  - L. Righetti
AU  - D. Berenson
PY  - 2019
KW  - computational complexity
KW  - convex programming
KW  - humanoid robots
KW  - integer programming
KW  - legged locomotion
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot dynamics
KW  - learned centroidal dynamics prediction
KW  - humanoid robots
KW  - intermittent contact
KW  - contact sequence
KW  - quasistatic balance criterion
KW  - dynamic motions
KW  - efficient mixed integer convex programming solvers
KW  - dynamic contact sequences
KW  - short time horizon contact sequences
KW  - dynamic evolution
KW  - robot centroidal momenta
KW  - dynamically robust contact sequences
KW  - search-based contact planner
KW  - humanoid contact planning
KW  - Dynamics
KW  - Planning
KW  - End effectors
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794032
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humanoid robots dynamically navigate an environment by interacting with it via contact wrenches exerted at intermittent contact poses. Therefore, it is important to consider dynamics when planning a contact sequence. Traditional contact planning approaches assume a quasi-static balance criterion to reduce the computational challenges of selecting a contact sequence over a rough terrain. This however limits the applicability of the approach when dynamic motions are required, such as when walking down a steep slope or crossing a wide gap. Recent methods overcome this limitation with the help of efficient mixed integer convex programming solvers capable of synthesizing dynamic contact sequences. Nevertheless, its exponential-time complexity limits its applicability to short time horizon contact sequences within small environments. In this paper, we go beyond current approaches by learning a prediction of the dynamic evolution of the robot centroidal momenta, which can then be used for quickly generating dynamically robust contact sequences for robots with arms and legs using a search-based contact planner. We demonstrate the efficiency and quality of the results of the proposed approach in a set of dynamically challenging scenarios.
ER  - 

TY  - CONF
TI  - Scalable Closed-Form Trajectories for Periodic and Non-Periodic Human-Like Walking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5295
EP  - 5301
AU  - S. Faraji
AU  - A. J. Ijspeert
PY  - 2019
KW  - gait analysis
KW  - medical control systems
KW  - optimal control
KW  - trajectory control
KW  - humanoid robots
KW  - linear simplified model
KW  - nonperiodic walking
KW  - lower-limb trajectories
KW  - closed-form trajectories
KW  - torso style
KW  - body mass
KW  - gait parameters
KW  - body properties
KW  - walking gaits
KW  - numerical optimization
KW  - geometric variables
KW  - kinematic conversion
KW  - stabilization
KW  - gait generation
KW  - footstep locations
KW  - optimal time-projecting controller
KW  - Legged locomotion
KW  - Trajectory
KW  - Pelvis
KW  - Foot
KW  - Kinematics
KW  - Torso
KW  - Knee
DO  - 10.1109/ICRA.2019.8793877
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a new framework to generate human-like lower-limb trajectories in periodic and non-periodic walking. In our method, walking dynamics is encoded in 3LP, a linear simplified model composed of three pendulums to simulate falling, swing, and torso balancing dynamics. To stabilize the motion, we use an optimal time-projecting controller which suggests new footstep locations. On top of gait generation and stabilization in the simplified space, we introduce a kinematic conversion that synthesizes more humanlike trajectories by combining geometric variables of the 3LP model adaptively. Without any tuning, numerical optimization or off-line data, our walking gaits are scalable with respect to body properties and gait parameters. We can change body mass and height, walking direction, speed, frequency, double support time, torso style, ground clearance, and terrain inclinations. We can also simulate constant external dragging forces or momentary perturbations. The proposed framework offers closed-form solutions with simulation speeds orders of magnitude faster than real time. This can be used for video games and animations on portable electronic devices with limited power. It also gives insights for generation of more human-like walking gaits on humanoid robots.
ER  - 

TY  - CONF
TI  - Flying STAR, a Hybrid Crawling and Flying Sprawl Tuned Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5302
EP  - 5308
AU  - N. Meiri
AU  - D. Zarrouk
PY  - 2019
KW  - control engineering computing
KW  - helicopters
KW  - legged locomotion
KW  - mobile robots
KW  - path planning
KW  - three-dimensional printing
KW  - Flying STAR
KW  - hybrid crawling
KW  - reconfigurable hybrid
KW  - quadcopter robot
KW  - STAR robots
KW  - sprawling mechanism
KW  - propellers
KW  - FSTAR robot
KW  - experimental robot
KW  - flying modes
KW  - flying sprawl tuned robot
KW  - running modes
KW  - 3D printed prototype
KW  - Mobile robots
KW  - Wheels
KW  - Servomotors
KW  - Propellers
KW  - Torque
KW  - Force
KW  - Crawling Robot
KW  - Flying Robot
KW  - Mechanical Design
KW  - Reconfigurable Robot
KW  - Sprawl Tuning
DO  - 10.1109/ICRA.2019.8794260
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents Flying STAR (FSTAR) a reconfigurable hybrid flying quadcopter robot. FSTAR is the latest in the family of the STAR robots fitted with a sprawling mechanism and propellers allowing it to both run and fly using the same motors. The combined capabilities of running and flying allows FSTAR to fly over obstacles or run underneath them and move inside pipes. The robot can reduce its width to crawl in confined spaces or underneath obstacles while touching the ground. We first describe the design of the robot and the configuration of the wheels and propellers in the flying and running modes. Then we present the 3D printed prototype of the FSTAR robot which we used for our experiments. We evaluate the energy requirements of the robot and the forces it can generate. The experimental robot can fly like an ordinary quadcopter but can also run on the ground at a speed of up to 2.6 m/s to save energy (see video).
ER  - 

TY  - CONF
TI  - Autonomous Cooperative Flight of Rigidly Attached Quadcopters
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5309
EP  - 5315
AU  - D. G. Morín
AU  - J. Araujo
AU  - S. Tayamon
AU  - L. A. A. Andersson
PY  - 2019
KW  - adaptive control
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - parameter estimation
KW  - quadcopter inertial measurement units
KW  - IMU
KW  - plug and play assembly
KW  - reinforcement learning
KW  - quadcopters stable operation
KW  - autonomous flight
KW  - controller parameters
KW  - adaptive controller architecture
KW  - estimated physical attachment
KW  - short online experiments
KW  - physical structure
KW  - automatic control
KW  - online parameter estimation
KW  - rigidly attached quadcopters
KW  - autonomous cooperative flight
KW  - Propellers
KW  - Estimation
KW  - Acceleration
KW  - Parameter estimation
KW  - Adaptation models
KW  - Force
KW  - Measurement units
DO  - 10.1109/ICRA.2019.8794266
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, a method for online parameter estimation and automatic control of a system of rigidly attached quadcopters is introduced. First, the method performs an estimation of the physical structure attaching the quadcopters by relying solely on information from the quadcopters' Inertial Measurement Units (IMU). This information is obtained via simple and short online experiments, allowing their plug and play assembly without any human intervention. Then, given the estimated physical attachment's parameters, a stable operation of the quadcopters is achieved via an adaptive controller architecture, where the controller parameters are obtained using Reinforcement Learning. Finally, experimental results validate the proposed method, showing that a correct estimation of the physical structure is obtained allowing the autonomous flight of a pair of attached quadcopters.
ER  - 

TY  - CONF
TI  - Energy Optimal Control Allocation in a Redundantly Actuated Omnidirectional UAV
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5316
EP  - 5322
AU  - E. Dyer
AU  - S. Sirouspour
AU  - M. Jafarinasab
PY  - 2019
KW  - autonomous aerial vehicles
KW  - convex programming
KW  - motion control
KW  - optimal control
KW  - propellers
KW  - trajectory control
KW  - energy optimal control allocation
KW  - redundantly actuated omnidirectional UAV
KW  - actuation model
KW  - control allocation strategy
KW  - redundantly-actuated multirotor unmanned aerial vehicle
KW  - omnicopter
KW  - actuation redundancy
KW  - inverse actuator model
KW  - propeller airflows
KW  - convex constrained optimization problem
KW  - propellers thrusts
KW  - propeller thrust limits
KW  - underactuated multirotors
KW  - motion trajectories
KW  - Propellers
KW  - Actuators
KW  - Atmospheric modeling
KW  - Aerodynamics
KW  - Pulse width modulation
KW  - Resource management
DO  - 10.1109/ICRA.2019.8793549
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel actuation model and control allocation strategy for a redundantly-actuated multirotor unmanned aerial vehicle (UAV), referred to as the omnicopter. With an unconventional configuration, the omnicopter's eight propellers are able to produce all the six components of net force/torque, with two degrees of actuation redundancy. This enables the vehicle to execute motion trajectories unattainable with conventional underactuated multi-rotors. A new inverse actuator model is proposed that accounts for the significant interactions between propeller airflows by relating their output thrust forces to their input motor commands. Actuation redundancy is resolved by solving a convex constrained optimization problem. Its solution yields the most power efficient set of propellers thrusts that would produce a required net force/torque, while respecting the propeller thrust limits. When the required force/torque is infeasible due to the thrust limits, the solution would minimize the norm of the error between the desired and actual net force/torque vectors. Experimental results demonstrate the effectiveness of the proposed model and control allocation strategy.
ER  - 

TY  - CONF
TI  - Development of SAM: cable-Suspended Aerial Manipulator*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5323
EP  - 5329
AU  - Y. S. Sarkisov
AU  - M. J. Kim
AU  - D. Bicego
AU  - D. Tsetserukou
AU  - C. Ott
AU  - A. Franchi
AU  - K. Kondak
PY  - 2019
KW  - actuators
KW  - aerospace robotics
KW  - cables (mechanical)
KW  - collision avoidance
KW  - control system synthesis
KW  - manipulators
KW  - stability
KW  - SAM
KW  - rotor blades
KW  - robotic manipulator
KW  - aerial carrier
KW  - actuation systems
KW  - suspended aerial manipulator
KW  - collision risk
KW  - winches
KW  - propulsion units
KW  - Manipulators
KW  - Winches
KW  - Legged locomotion
KW  - Propellers
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793592
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - High risk of a collision between rotor blades and the obstacles in a complex environment imposes restrictions on the aerial manipulators. To solve this issue, a novel system cable-Suspended Aerial Manipulator (SAM) is presented in this paper. Instead of attaching a robotic manipulator directly to an aerial carrier, it is mounted on an active platform which is suspended on the carrier by means of a cable. As a result, higher safety can be achieved because the aerial carrier can keep a distance from the obstacles. For self-stabilization, the SAM is equipped with two actuation systems: winches and propulsion units. This paper presents an overview of the SAM including the concept behind, hardware realization, control strategy, and the first experimental results.
ER  - 

TY  - CONF
TI  - The Phoenix Drone: An Open-Source Dual-Rotor Tail-Sitter Platform for Research and Education
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5330
EP  - 5336
AU  - Y. Wu
AU  - X. Du
AU  - R. Duivenvoorden
AU  - J. Kelly
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - educational robots
KW  - helicopters
KW  - microrobots
KW  - mobile robots
KW  - rotors
KW  - educational purposes
KW  - design methodology
KW  - open-source Phoenix reference design
KW  - software design
KW  - Phoenix drone
KW  - open-source dual-rotor tail-sitter platform
KW  - open-source tail-sitter microaerial vehicle platform
KW  - dual-rotor design
KW  - open-source release
KW  - design documents
KW  - high-performance tail-sitter
KW  - testing
KW  - open-source materials
KW  - aerodynamics
KW  - flight control
KW  - state estimation
KW  - Open source software
KW  - Propellers
KW  - Aerodynamics
KW  - Vehicle dynamics
KW  - Attitude control
KW  - Drones
KW  - Atmospheric modeling
DO  - 10.1109/ICRA.2019.8794433
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we introduce the Phoenix drone: the first completely open-source tail-sitter micro aerial vehicle (MAV) platform. The vehicle has a highly versatile, dual-rotor design and is engineered to be low-cost and easily extensible/modifiable. Our open-source release includes all of the design documents, software resources, and simulation tools needed to build and fly a high-performance tail-sitter for research and educational purposes.The drone has been developed for precision flight with a high degree of control authority. Our design methodology included extensive testing and characterization of the aerodynamic properties of the vehicle. The platform incorporates many off-the-shelf components and 3D-printed parts, in order to keep the cost down. Nonetheless, the paper includes results from flight trials which demonstrate that the vehicle is capable of very stable hovering and accurate trajectory tracking.Our hope is that the open-source Phoenix reference design will be useful to both researchers and educators. In particular, the details in this paper and the available open-source materials should enable learners to gain an understanding of aerodynamics, flight control, state estimation, software design, and simulation, while experimenting with a unique aerial robot.
ER  - 

TY  - CONF
TI  - 1-Actuator 3-DoF Manipulation Using an Underactuated Mechanism with Multiple Nonparallel and Viscoelastic Passive Joints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5345
EP  - 5351
AU  - T. Kurita
AU  - M. Higashimori
PY  - 2019
KW  - actuators
KW  - end effectors
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - motion control
KW  - plates (structures)
KW  - position control
KW  - viscoelasticity
KW  - sinusoidal displacement input
KW  - orbital shape
KW  - orbital direction
KW  - input frequency
KW  - switching frequency
KW  - mechanical parameters
KW  - three-DoF manipulation
KW  - plate orbital motions
KW  - 1-actuator 3-DoF manipulation
KW  - underactuated mechanism
KW  - multiple nonparallel
KW  - nonprehensile manipulation
KW  - planar part
KW  - manipulator
KW  - flat plate end effector
KW  - active joint joints
KW  - multiple passive viscoelastic joints
KW  - joint axes
KW  - viscoelastic passive joints
KW  - Orbits
KW  - Actuators
KW  - End effectors
KW  - Layout
KW  - Switches
KW  - Manipulator dynamics
DO  - 10.1109/ICRA.2019.8794157
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a nonprehensile manipulation based on the vibration of a plate, in which three degrees of freedom (DoF) of a planar part are controlled using only one actuator. First, the model of a manipulator with a flat plate end effector is proposed. The manipulator employs an underactuated mechanism including an active joint and multiple passive viscoelastic joints, in which the joint axes are arranged nonparallel to each other. Based on the model, the orbit of the plate for a sinusoidal displacement input to the active joint is theoretically derived. It is revealed that not only the orbital shape but also the orbital direction can be varied according to the input frequency. Based on the switching frequency of the orbital direction, a design index for the mechanical parameters is shown. Subsequently, the contribution of the switching of the orbital direction to the three-DoF manipulation of a part is explored via simulation. Eight primitives utilizing the plate orbital motions in both counter-clockwise and clockwise directions are provided. Finally, the proposed method is demonstrated by experiments.
ER  - 

TY  - CONF
TI  - Spline Based Curve Path Following of Underactuated Snake Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5352
EP  - 5358
AU  - W. Yang
AU  - G. Wang
AU  - H. Shao
AU  - Y. Shen
PY  - 2019
KW  - biomimetics
KW  - interpolation
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - splines (mathematics)
KW  - time-varying systems
KW  - underactuated snake robots
KW  - planar underactuated bio-inspired snake robots
KW  - time-varying line-of-sight guidance law
KW  - cubic spline interpolation path-planning method
KW  - snake robot motion control
KW  - 8-link custom-built snake robot
KW  - spline based curve path following
KW  - integral controller
KW  - Snake robots
KW  - Friction
KW  - Turning
KW  - Splines (mathematics)
KW  - Interpolation
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793531
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper investigates the curve path following problem for a class of planar underactuated bio-inspired snake robots. The time-varying line-of-sight (LOS) guidance law and the cubic spline interpolation (CSI) path-planning method are employed. Existing studies focus on straight line path following which only gives a solution for snake robot motion control in relatively simple environments. Considering the snake robot's many degrees of freedom and excellent mobility in terrains, we propose a more applicable solution of curve path following for snake robots on the ground. The improved LOS helps the snake robot to steer aggressively at a sharp turning point. Furthermore, to avoid the sideslip of the snake robot caused by the ground friction change, an integral controller is introduced in the design of the heading reference. Simulations and experiments on an 8-link custom-built snake robot are conducted and the results demonstrate and validate the effectiveness of the proposed curve path following algorithm.
ER  - 

TY  - CONF
TI  - High-Bandwidth Control of Twisted String Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5359
EP  - 5364
AU  - S. Nedelchev
AU  - I. Gaponov
AU  - J. Ryu
PY  - 2019
KW  - actuators
KW  - adaptive control
KW  - control system synthesis
KW  - feedforward
KW  - parameter estimation
KW  - position control
KW  - twisted string behavior
KW  - adaptive control methodology
KW  - TSA-based systems
KW  - online parameter estimation
KW  - outline adaptive estimation methods
KW  - variable controller gain
KW  - adaptive control architecture
KW  - high-bandwidth control
KW  - adaptive control strategies
KW  - TSA control system
KW  - mechatronics
KW  - twisted string actuators
KW  - Mathematical model
KW  - Robots
KW  - Adaptation models
KW  - Jacobian matrices
KW  - Adaptive control
KW  - Task analysis
KW  - Actuators
KW  - Tendon/Wire Mechanism
KW  - Motion Control
KW  - Learning and Adaptive Systems
DO  - 10.1109/ICRA.2019.8794259
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Twisted string actuators are an emerging type of transmission systems that may benefit various applications of robotics and mechatronics. However, control of TSAs in applications that require high bandwidth has attracted comparatively little interest from research community, mainly due to complexity of twisted string behavior. This paper proposes a new adaptive control methodology that allows to sufficiently increase bandwidth of TSA-based systems. We reformulate mathematical model of the TSA into a suitable form for online parameter estimation, outline adaptive estimation methods and propose a method to design variable controller gain that rectifies nonlinearities in the system. we present experimental comparison of proposed adaptive control strategies with two conventional tsa control techniques. experimental results demonstrated that the proposed adaptive control architecture with feedforward speed term was nearly insensitive to increase in input signal frequency while reducing position tracking error by 80%. proposed algorithm can be applied in any tsa control system that has input and output signal measurements.
ER  - 

TY  - CONF
TI  - TREE: A Variable Topology, Branching Continuum Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5365
EP  - 5371
AU  - M. C. Lastinger
AU  - S. Verma
AU  - A. D. Kapadia
AU  - I. D. Walker
PY  - 2019
KW  - adaptive systems
KW  - manipulators
KW  - TREE
KW  - variable topology
KW  - cleaning operations
KW  - hard-to-reach environments
KW  - hybrid concentric-tube
KW  - fully retractable continuum branches
KW  - branching continuum robot
KW  - inspection operations
KW  - tendon actuated continuum trunk core
KW  - Electron tubes
KW  - Tendons
KW  - Prototypes
KW  - Manipulators
KW  - Meters
KW  - Inspection
DO  - 10.1109/ICRA.2019.8794463
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We describe the design and physical realization of a novel branching continuum robot, aimed at inspection and cleaning operations in hard-to-reach environments at depths greater than human arm lengths. The design, based on a hybrid concentric-tube/tendon actuated continuum trunk core, features two pairs of fully retractable continuum branches. The retractable nature of the branches allows the robot to actively change its topology, allowing it to penetrate narrow openings and expand to adaptively engage complex environmental geometries. We detail and discuss the realization of a physical prototype of the design, and its testing in a simulated glove box environment.
ER  - 

TY  - CONF
TI  - Model Based In Situ Calibration with Temperature compensation of 6 axis Force Torque Sensors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5397
EP  - 5403
AU  - F. J. A. Chavez
AU  - G. Nava
AU  - S. Traversaro
AU  - F. Nori
AU  - D. Pucci
PY  - 2019
KW  - calibration
KW  - compensation
KW  - force measurement
KW  - force sensors
KW  - humanoid robots
KW  - temperature measurement
KW  - temperature sensors
KW  - torque measurement
KW  - temperature compensation
KW  - sensor measurements
KW  - model based in situ calibration
KW  - 6 axis force torque sensors method
KW  - strain gauges
KW  - F-T measurement
KW  - humanoid robot platform iCub
KW  - Temperature sensors
KW  - Temperature measurement
KW  - Calibration
KW  - Robot sensing systems
KW  - Strain measurement
KW  - Force Torque Sensing
KW  - Calibration and Identification
KW  - Humanoid Robots
DO  - 10.1109/ICRA.2019.8794382
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - It is well known that sensors using strain gauges have a potential dependency on temperature. This creates temperature drift in the measurements of six axis force torque sensors (F/T). The temperature drift can be considerable if an experiment is long or the environmental conditions are different from when the calibration of the sensor was performed. Other in situ methods disregard the effect of temperature on the sensor measurements. Experiments performed using the humanoid robot platform iCub show that the effect of temperature is relevant. The model based in situ calibration of six axis force torque sensors method is extended to perform temperature compensation.
ER  - 

TY  - CONF
TI  - Whole-Body Active Compliance Control for Humanoid Robots with Robot Skin
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5404
EP  - 5410
AU  - E. Dean-Leon
AU  - J. R. Guadarrama-Olvera
AU  - F. Bergner
AU  - G. Cheng
PY  - 2019
KW  - compliance control
KW  - humanoid robots
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - skin
KW  - tactile sensors
KW  - control systems
KW  - control framework
KW  - skin cells
KW  - whole-body active compliance control
KW  - multicontact interactions
KW  - whole-body control methods
KW  - human environments
KW  - humanoid robots
KW  - body active compliance control
KW  - position-controlled stiff humanoid robot
KW  - multiple control strategies
KW  - robot body
KW  - full-size humanoid robot
KW  - robot skin
KW  - multimodal tactile information
KW  - compliant robots
KW  - tactile sensor information
KW  - physical interactions
KW  - online information
KW  - touch sensing
KW  - Skin
KW  - Robot sensing systems
KW  - Task analysis
KW  - Legged locomotion
KW  - Humanoid robots
DO  - 10.1109/ICRA.2019.8793258
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humanoid robots are expected to interact in human environments, where physical interactions are unavoidable. Therefore, whole-body control methods that include multi-contact interactions are required. The new emerging technologies in touch sensing are fundamental to acquire online and rich information about these physical interactions with the environment. These technologies lead to the design of novel control systems that can profit from the tactile sensor information in an efficient form, thus producing reactive and compliant robots capable of interacting with their environment. In this paper, we present a novel control framework to integrate the multi-modal tactile information of a robot skin with different control strategies, producing dynamic behaviours suitable for Human-Robot Interactions (HRI). The control framework was experimentally evaluated on a full-size humanoid robot covered with more than 1260 skin cells distributed in the whole robot body. The results show that multi-modal tactile information can be fused hierarchically with multiple control strategies, producing active compliance in a position-controlled stiff humanoid robot.
ER  - 

TY  - CONF
TI  - Internal Array Electrodes Improve the Spatial Resolution of Soft Tactile Sensors Based on Electrical Resistance Tomography
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5411
EP  - 5417
AU  - H. Lee
AU  - K. Park
AU  - J. Kim
AU  - K. J. Kuchenbecker
PY  - 2019
KW  - electrodes
KW  - tactile sensors
KW  - tomography
KW  - soft tactile sensors
KW  - electrical resistance tomography
KW  - unstructured environments
KW  - whole-body tactile sensors
KW  - complex electrical wiring
KW  - sensing elements
KW  - reconstruction method
KW  - sensing region
KW  - central region
KW  - ERT approach
KW  - optimal pairwise current injection patterns
KW  - ERT system
KW  - electrode pair
KW  - fabric-based soft tactile sensor
KW  - sensor-specific calibration
KW  - constructed sensor
KW  - internal array electrodes
KW  - frequency 200.0 Hz
KW  - Electrodes
KW  - Tactile sensors
KW  - Conductivity
KW  - Voltage measurement
KW  - Spatial resolution
KW  - Fabrics
DO  - 10.1109/ICRA.2019.8794276
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots operating in unstructured environments would benefit from soft whole-body tactile sensors, but implementing such systems typically requires complex electrical wiring to a large number of sensing elements. The reconstruction method called electrical resistance tomography (ERT) has shown promising results (good coverage, manufacturability, and robustness) using electrodes located only along the boundary of the sensing region. However, relatively poor spatial resolution in the sensor's central region is a major drawback of the ERT approach. This paper introduces a new scheme of internal array electrodes to improve spatial resolution. We also systematically derive the optimal pairwise current injection patterns from a mathematical formulation of the ERT system. By highlighting the importance of each electrode pair, this approach enabled us to reduce the number of current injection patterns. Simulation of the standard and proposed sensor designs revealed that the internal array electrodes greatly improve distinguishability in the central region. For validation, a fabric-based soft tactile sensor made of multiple conductive fabrics was developed, including electronics that enable sampling at 200 Hz. During a 225-point localization test conducted without sensor-specific calibration, the constructed sensor showed average localization errors of 2.85 cm ± 1.02 cm. This result is notable because only 16 point electrodes were used to achieve this performance.
ER  - 

TY  - CONF
TI  - Dense Tactile Force Estimation using GelSlim and inverse FEM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5418
EP  - 5424
AU  - D. Ma
AU  - E. Donlon
AU  - S. Dong
AU  - A. Rodriguez
PY  - 2019
KW  - deformation
KW  - finite element analysis
KW  - image sensors
KW  - tactile sensors
KW  - tactile sensor
KW  - GelSlim 2
KW  - inverse FEM
KW  - Kendama manipulations
KW  - force field
KW  - reconstructed force distribution
KW  - marker displacements
KW  - inverse finite element method
KW  - gel pad
KW  - contact force distribution
KW  - dense tactile force estimation
KW  - Force
KW  - Tactile sensors
KW  - Finite element analysis
KW  - Cameras
KW  - Force measurement
KW  - Strain
DO  - 10.1109/ICRA.2019.8794113
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a new version of tactile sensor GelSlim 2.0 with the capability to estimate the contact force distribution in real time. The sensor is vision-based and uses an array of markers to track deformations on a gel pad due to contact. A new hardware design makes the sensor more rugged, parametrically adjusTable AND Improves illumination. leveraging the sensor's increased functionality, we propose to use inverse finite element method (ifem), a numerical method to reconstruct the contact force distribution based on marker displacements. the sensor is able to provide force distribution of contact with high spatial density. experiments and comparison with ground truth show that the reconstructed force distribution is physically reasonable with good accuracy.A sequence of Kendama manipulations with corresponding displacement field (yellow) and force field (red). Video can be found on Youtube: https://youtu.be/hWw9A0ZBZuU.
ER  - 

TY  - CONF
TI  - Pose Graph optimization for Unsupervised Monocular Visual Odometry
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5439
EP  - 5445
AU  - Y. Li
AU  - Y. Ushiku
AU  - T. Harada
PY  - 2019
KW  - graph theory
KW  - neural nets
KW  - optimisation
KW  - pose estimation
KW  - unsupervised learning
KW  - pose graph optimization
KW  - unsupervised monocular visual odometry
KW  - unsupervised learning
KW  - label-free leaning ability
KW  - drift correction technique
KW  - large-scale odometry estimation
KW  - loop closure detection
KW  - hybrid VO system
KW  - NeuralBundler
KW  - temporal loss
KW  - spatial photometric loss
KW  - multiview 6DoF constraints
KW  - cycle consistency loss
KW  - global pose graph
KW  - local loop 6DoF constraints
KW  - KITTI odometry dataset
KW  - unsupervised monocular VO estimation
KW  - monocular SLAM systems
KW  - Optimization
KW  - Visual odometry
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Training
KW  - Neural networks
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793706
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Unsupervised Learning based monocular visual odometry (VO) has lately drawn significant attention for its potential in label-free leaning ability and robustness to camera parameters and environmental variations. However, partially due to the lack of drift correction technique, these methods are still by far less accurate than geometric approaches for large-scale odometry estimation. In this paper, we propose to leverage graph optimization and loop closure detection to overcome limitations of unsupervised learning based monocular visual odometry. To this end, we propose a hybrid VO system which combines an unsupervised monocular VO called NeuralBundler with a pose graph optimization back-end. NeuralBundler is a neural network architecture that uses temporal and spatial photometric loss as main supervision and generates a windowed pose graph consists of multi-view 6DoF constraints. We propose a novel pose cycle consistency loss to relieve the tensions in the windowed pose graph, leading to improved performance and robustness. In the back-end, a global pose graph is built from local and loop 6DoF constraints estimated by NeuralBundler, and is optimized over SE(3). Empirical evaluation on the KITTI odometry dataset demonstrates that 1) NeuralBundler achieves state-of-the-art performance on unsupervised monocular VO estimation, and 2) our whole approach can achieve efficient loop closing and show favorable overall translational accuracy compared to established monocular SLAM systems.
ER  - 

TY  - CONF
TI  - Probably Unknown: Deep Inverse Sensor Modelling Radar
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5446
EP  - 5452
AU  - R. Weston
AU  - S. Cen
AU  - P. Newman
AU  - I. Posner
PY  - 2019
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - optical radar
KW  - probability
KW  - radar computing
KW  - radar imaging
KW  - autonomous vehicle applications
KW  - weather conditions
KW  - raw radar power returns
KW  - sensor noise
KW  - occlusion
KW  - Inverse Sensor Model
KW  - grid map
KW  - grid cell
KW  - heteroscedastic uncertainty
KW  - deep Inverse Sensor modelling radar
KW  - sensor observation
KW  - model formulation
KW  - standard CFAR filtering approaches
KW  - dynamic urban environment
KW  - world occupancy
KW  - lidar
KW  - partial occupancy labels
KW  - deep neural network
KW  - occupancy probabilities
KW  - Uncertainty
KW  - Robot sensing systems
KW  - Laser radar
KW  - Training
KW  - Spaceborne radar
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793263
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Radar presents a promising alternative to lidar and vision in autonomous vehicle applications, able to detect objects at long range under a variety of weather conditions. However, distinguishing between occupied and free space from raw radar power returns is challenging due to complex interactions between sensor noise and occlusion. To counter this we propose to learn an Inverse Sensor Model (ISM) converting a raw radar scan to a grid map of occupancy probabilities using a deep neural network. Our network is selfsupervised using partial occupancy labels generated by lidar, allowing a robot to learn about world occupancy from past experience without human supervision. We evaluate our approach on five hours of data recorded in a dynamic urban environment. By accounting for the scene context of each grid cell our model is able to successfully segment the world into occupied and free space, outperforming standard CFAR filtering approaches. Additionally by incorporating heteroscedastic uncertainty into our model formulation, we are able to quantify the variance in the uncertainty throughout the sensor observation. Through this mechanism we are able to successfully identify regions of space that are likely to be occluded.
ER  - 

TY  - CONF
TI  - Uncertainty-Aware Occupancy Map Prediction Using Generative Networks for Robot Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5453
EP  - 5459
AU  - K. Katyal
AU  - K. Popek
AU  - C. Paxton
AU  - P. Burlina
AU  - G. D. Hager
PY  - 2019
KW  - mobile robots
KW  - multi-robot systems
KW  - neural net architecture
KW  - path planning
KW  - sensor field of view
KW  - sensor FOV
KW  - generated hypotheses
KW  - information-theoretic exploration strategy
KW  - combined map prediction
KW  - neural network architecture
KW  - custom loss function
KW  - deep neural networks
KW  - future robot motions
KW  - sensor data
KW  - occupancy map representations
KW  - biological systems
KW  - sensor field
KW  - future motion
KW  - robotic systems
KW  - robot navigation
KW  - generative networks
KW  - uncertainty-aware occupancy map prediction
KW  - Neural networks
KW  - Robot sensing systems
KW  - Training
KW  - Measurement
KW  - Navigation
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793500
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Efficient exploration through unknown environments remains a challenging problem for robotic systems. In these situations, the robot's ability to reason about its future motion is often severely limited by sensor field of view (FOV). By contrast, biological systems routinely make decisions by taking into consideration what might exist beyond their FOV based on prior experience. We present an approach for predicting occupancy map representations of sensor data for future robot motions using deep neural networks. We develop a custom loss function used to make accurate prediction while emphasizing physical boundaries. We further study extensions to our neural network architecture to account for uncertainty and ambiguity inherent in mapping and exploration. Finally, we demonstrate a combined map prediction and information-theoretic exploration strategy using the variance of the generated hypotheses as the heuristic for efficient exploration of unknown environments.
ER  - 

TY  - CONF
TI  - Empty Cities: Image Inpainting for a Dynamic-Object-Invariant Space
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5460
EP  - 5466
AU  - B. Bescos
AU  - J. Neira
AU  - R. Siegwart
AU  - C. Cadena
PY  - 2019
KW  - augmented reality
KW  - convolutional neural nets
KW  - image classification
KW  - image restoration
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - object recognition
KW  - robot vision
KW  - augmented reality
KW  - static structure
KW  - image inpainting
KW  - dynamic-object-invariant space
KW  - vehicles
KW  - pedestrians
KW  - plausible imagery
KW  - multiclass semantic segmentation
KW  - inpainting methods
KW  - deep learning
KW  - generative adversarial model
KW  - convolutional network
KW  - vision-based robot localization
KW  - visual place recognition
KW  - Vehicle dynamics
KW  - Semantics
KW  - Task analysis
KW  - Image segmentation
KW  - Deep learning
KW  - Image reconstruction
KW  - Training
DO  - 10.1109/ICRA.2019.8794417
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we present an end-to-end deep learning framework to turn images that show dynamic content, such as vehicles or pedestrians, into realistic static frames. This objective encounters two main challenges: detecting all the dynamic objects, and inpainting the static occluded background with plausible imagery. The former challenge is addressed by the use of a convolutional network that learns a multiclass semantic segmentation of the image. The second problem is approached with a conditional generative adversarial model that, taking as input the original dynamic image and its dynamic/static binary mask, is capable of generating the final static image. These generated images can be used for applications such as augmented reality or vision-based robot localization purposes. To validate our approach, we show both qualitative and quantitative comparisons against other state-of-the-art inpainting methods by removing the dynamic objects and hallucinating the static structure behind them. Furthermore, to demonstrate the potential of our results, we carry out pilot experiments that show the benefits of our proposal for visual place recognition.
ER  - 

TY  - CONF
TI  - Autonomous Exploration, Reconstruction, and Surveillance of 3D Environments Aided by Deep Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5467
EP  - 5473
AU  - L. Ly
AU  - Y. R. Tsai
PY  - 2019
KW  - collision avoidance
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - neural nets
KW  - autonomous exploration
KW  - surveillance
KW  - greedy learning approach
KW  - supervised learning approach
KW  - level set representation
KW  - convolutional neural network
KW  - visibility
KW  - on-line computational cost
KW  - topologically accurate maps
KW  - complex 3D environments
KW  - frontier-based strategies
KW  - potential vantage points
KW  - deep learning approaches
KW  - obstacle avoidance
KW  - local navigation
KW  - global exploration problem
KW  - 3D urban environments
KW  - Training
KW  - Level set
KW  - Surveillance
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Sensors
KW  - Convolution
DO  - 10.1109/ICRA.2019.8794426
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a greedy and supervised learning approach for visibility-based exploration, reconstruction and surveillance. Using a level set representation, we train a convolutional neural network to determine vantage points that maximize visibility. We show that this method drastically reduces the on-line computational cost and determines a small set of vantage points that solve the problem. This enables us to efficiently produce highly-resolved and topologically accurate maps of complex 3D environments. Unlike traditional next-best-view and frontier-based strategies, the proposed method accounts for geometric priors while evaluating potential vantage points. While existing deep learning approaches focus on obstacle avoidance and local navigation, our method aims at finding near-optimal solutions to the more global exploration problem. We present realistic simulations on 2D and 3D urban environments.
ER  - 

TY  - CONF
TI  - GANVO: Unsupervised Deep Monocular Visual Odometry and Depth Estimation with Generative Adversarial Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5474
EP  - 5480
AU  - Y. Almalioglu
AU  - M. R. U. Saputra
AU  - P. P. B. d. Gusmão
AU  - A. Markham
AU  - N. Trigoni
PY  - 2019
KW  - cameras
KW  - convolutional neural nets
KW  - distance measurement
KW  - image colour analysis
KW  - image motion analysis
KW  - image sequences
KW  - pose estimation
KW  - unsupervised learning
KW  - unlabelled RGB image sequences
KW  - deep convolutional Generative Adversarial Networks
KW  - single-view depth generation network
KW  - unsupervised deep VO methods
KW  - unsupervised deep monocular visual odometry
KW  - depth estimation
KW  - supervised deep learning approaches
KW  - visual odometry applications
KW  - unsupervised deep learning approaches
KW  - VO research
KW  - generative unsupervised learning framework
KW  - multiview pose estimation
KW  - 6-DoF pose camera motion
KW  - Image reconstruction
KW  - Pose estimation
KW  - Cameras
KW  - Deep learning
KW  - Training
KW  - Feature extraction
KW  - Gallium nitride
DO  - 10.1109/ICRA.2019.8793512
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In the last decade, supervised deep learning approaches have been extensively employed in visual odometry (VO) applications, which is not feasible in environments where labelled data is not abundant. On the other hand, unsupervised deep learning approaches for localization and mapping in unknown environments from unlabelled data have received comparatively less attention in VO research. In this study, we propose a generative unsupervised learning framework that predicts 6-DoF pose camera motion and monocular depth map of the scene from unlabelled RGB image sequences, using deep convolutional Generative Adversarial Networks (GANs). We create a supervisory signal by warping view sequences and assigning the re-projection minimization to the objective loss function that is adopted in multi-view pose estimation and single-view depth generation network. Detailed quantitative and qualitative evaluations of the proposed framework on the KITTI [1] and Cityscapes [2] datasets show that the proposed method outperforms both existing traditional and unsupervised deep VO methods providing better results for both pose estimation and depth recovery.
ER  - 

TY  - CONF
TI  - Fast Instance and Semantic Segmentation Exploiting Local Connectivity, Metric Learning, and One-Shot Detection for Robotics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5481
EP  - 5487
AU  - A. Milioto
AU  - L. Mandtler
AU  - C. Stachniss
PY  - 2019
KW  - convolutional neural nets
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural net architecture
KW  - object detection
KW  - robot vision
KW  - metric learning
KW  - one-shot detection
KW  - semantic scene understanding
KW  - autonomous robots
KW  - dynamic environments
KW  - instance segmentation
KW  - multitask convolutional neural network architecture
KW  - object instances
KW  - local connectivity
KW  - semantic segmentation
KW  - Semantics
KW  - Image segmentation
KW  - Decoding
KW  - Feature extraction
KW  - Task analysis
KW  - Robots
KW  - Object detection
DO  - 10.1109/ICRA.2019.8793593
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Semantic scene understanding is important for autonomous robots that aim to navigate dynamic environments, manipulate objects, or interact with humans in a natural way. In this paper, we address the problem of jointly performing semantic segmentation as well as instance segmentation in an online fashion, so that autonomous robots can use this information on-the-go and without sacrificing accuracy. We achieve this by exploiting a local connectivity prior of objects in the real world and a multi-task convolutional neural network architecture. The network identifies the individual object instances and their classes without region proposals or pre-segmentation of the images into individual classes. We implemented and thoroughly evaluated our approach, and our experiments suggest that our method can be used to accurately segment instance masks of objects and identify their class in an online fashion.
ER  - 

TY  - CONF
TI  - Adding Cues to Binary Feature Descriptors for Visual Place Recognition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5488
EP  - 5494
AU  - D. Schlegel
AU  - G. Grisetti
PY  - 2019
KW  - feature extraction
KW  - image retrieval
KW  - binary feature descriptors
KW  - visual place recognition
KW  - multidimensional continuous cues
KW  - feature descriptor
KW  - binary string
KW  - continuous cue
KW  - binary descriptor types
KW  - Hamming distance
KW  - Search problems
KW  - Quantization (signal)
KW  - Visualization
KW  - Measurement
KW  - Simultaneous localization and mapping
KW  - Image retrieval
DO  - 10.1109/ICRA.2019.8793753
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we propose an approach to embed multi-dimensional continuous cues in binary feature descriptors used for visual place recognition. The embedding is achieved by extending each feature descriptor with a binary string that encodes a cue and supports the Hamming distance metric. Augmenting the descriptors in such a way has the advantage of being transparent to the procedure used to compare them. We present a concrete application of our methodology, demonstrating the considered type of continuous cue. Additionally, we conducted a broad quantitative and comparative evaluation on that application, covering five benchmark datasets and several state-of-the-art image retrieval approaches in combination with various binary descriptor types.
ER  - 

TY  - CONF
TI  - Recursive Bayesian Classification for Perception of Evolving Targets using a Gaussian Toroid Prediction Model
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5495
EP  - 5501
AU  - J. J. Steckenrider
AU  - T. Furukawa
PY  - 2019
KW  - Bayes methods
KW  - belief networks
KW  - feature extraction
KW  - Gaussian processes
KW  - image classification
KW  - real-time systems
KW  - recursive estimation
KW  - uncertainty handling
KW  - Gaussian toroid prediction model
KW  - probabilistic framework
KW  - recursive Bayesian estimation
KW  - perception-oriented context
KW  - recursive Bayesian classification scheme
KW  - high-dimensional belief spaces
KW  - evolving target classification
KW  - perception target evolution
KW  - RBC scheme
KW  - feature extraction
KW  - multiGaussian belief representation
KW  - real-time analysis
KW  - observational uncertainty
KW  - Predictive models
KW  - Bayes methods
KW  - Probabilistic logic
KW  - Probability density function
KW  - Estimation
KW  - Decision making
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793951
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a probabilistic framework for classification of evolving targets, leveraging the principles of recursive Bayesian estimation in a perception-oriented context. By implementing a Gaussian toroid prediction model of the perception target's evolution, the proposed recursive Bayesian classification (RBC) scheme provides probabilistically robust classification. Appropriate features are extracted from the target, which is then probabilistically represented in a belief space. This approach is capable of handling high-dimensional belief spaces, while simultaneously allowing for multi-Gaussian representation of belief without computational complexity that hinders real-time analysis. The proposed technique is validated over several parameter values by thousands of simulated experiments, where it is shown to outperform naıve classification when high observational uncertainty is present.
ER  - 

TY  - CONF
TI  - Large-Scale Object Mining for Object Discovery from Unlabeled Video
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5502
EP  - 5508
AU  - A. Ošep
AU  - P. Voigtlaender
AU  - J. Luiten
AU  - S. Breuers
AU  - B. Leibe
PY  - 2019
KW  - data mining
KW  - image representation
KW  - object tracking
KW  - pattern clustering
KW  - traffic engineering computing
KW  - video signal processing
KW  - video streaming
KW  - generic object tracker
KW  - unlabeled video
KW  - unlabeled driving videos
KW  - raw video streams
KW  - object distribution
KW  - object discovery
KW  - object tracks
KW  - object categories
KW  - large scale object mining
KW  - realistic automotive setting
KW  - feature representations
KW  - clustering strategies
KW  - Proposals
KW  - Data mining
KW  - Detectors
KW  - Automobiles
KW  - Feature extraction
KW  - Streaming media
KW  - Robots
DO  - 10.1109/ICRA.2019.8793683
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of object discovery from unlabeled driving videos captured in a realistic automotive setting. Identifying recurring object categories in such raw video streams is a very challenging problem. Not only do object candidates first have to be localized in the input images, but many interesting object categories occur relatively infrequently. Object discovery will therefore have to deal with the difficulties of operating in the long tail of the object distribution. We demonstrate the feasibility of performing fully automatic object discovery in such a setting by mining object tracks using a generic object tracker. In order to facilitate further research in objet discovery, we release a collection of more than 360,000 automatically mined object tracks from 10 + hours of video data (560,000 frames). We use this dataset to evaluate the suitability of different feature representations and clustering strategies for object discovery.
ER  - 

TY  - CONF
TI  - Goal-oriented Object Importance Estimation in On-road Driving Videos
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5509
EP  - 5515
AU  - M. Gao
AU  - A. Tawari
AU  - S. Martin
PY  - 2019
KW  - driver information systems
KW  - feature extraction
KW  - object detection
KW  - road traffic
KW  - road vehicles
KW  - video signal processing
KW  - on-road driving videos
KW  - OIE
KW  - driving scene
KW  - visual model
KW  - object importance estimation
KW  - ego-vehicles driver
KW  - driving control
KW  - binary brake prediction
KW  - Vehicles
KW  - Feature extraction
KW  - Videos
KW  - Roads
KW  - Visualization
KW  - Task analysis
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8793970
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We formulate a new problem as Object Importance Estimation (OIE) in on-road driving videos, where the road users are considered as important objects if they have influence on the control decision of the ego-vehicle's driver. The importance of a road user depends on both its visual dynamics, e.g., appearance, motion and location, in the driving scene and the driving goal, e.g., the planned path, of the ego vehicle. We propose a novel framework that incorporates both visual model and goal representation to conduct OIE. To evaluate our framework, we collect an on-road driving dataset at traffic intersections in the real world and conduct human-labeled annotation of the important objects. Experimental results show that our goal-oriented method outperforms baselines and has much more improvement on the left-turn and right-turn scenarios. Furthermore, we explore the possibility of using object importance for driving control prediction and demonstrate that binary brake prediction can be improved with the information of object importance.
ER  - 

TY  - CONF
TI  - Priming Deep Pedestrian Detection with Geometric Context
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5516
EP  - 5522
AU  - I. Chakraborty
AU  - G. Hua
PY  - 2019
KW  - computational geometry
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - pedestrians
KW  - deep neural networks
KW  - deep object detectors
KW  - geometric context
KW  - deep pedestrian detection
KW  - DNN detectors
KW  - DNN feature learning
KW  - Cameras
KW  - Detectors
KW  - Proposals
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Geometry
KW  - Context modeling
DO  - 10.1109/ICRA.2019.8794018
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We investigate the role of geometric context in deep neural networks to establish better pedestrian detectors that are more robust to occlusions. Notwithstanding their demonstrated successes, deep object detectors under-perform in crowded scenes with high intra-category occlusions. One brute-force solution is to collect a large number of labeled training samples under occlusion, but the combinatorial increase in the labeling effort makes it an unaffordable solution. We argue that a promising and complementary direction to solve this problem is to bring geometric context to modulate feature learning in a DNN. We identify that an effective way to leverage geometric context is to induce it in two steps - through early fusion, by guiding region proposal generation to focus on occluded regions, and through late fusion, by penalizing misalignments of bounding boxes in both 2D and 3D. Our experiments on multiple state-of-the-art DNN detectors and detection benchmarks clearly demonstrates that our proposed method outperforms strong baselines by an average of 5%.
ER  - 

TY  - CONF
TI  - The Robust Canadian Traveler Problem Applied to Robot Routing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5523
EP  - 5529
AU  - H. Guo
AU  - T. D. Barfoot
PY  - 2019
KW  - graph theory
KW  - mobile robots
KW  - stochastic processes
KW  - telecommunication network routing
KW  - worst-case cost
KW  - Robust Canadian Traveler Problem applied
KW  - stochastic Canadian Traveler Problem
KW  - CTP
KW  - robot route selection
KW  - traversal policy
KW  - policy cost
KW  - evaluation criteria
KW  - approximate algorithm
KW  - traversal cost
KW  - robot field trials
KW  - RCTP framework
KW  - sub-optimal policy alternatives
KW  - minimum expected cost
KW  - distance 5.0 km
KW  - Approximation algorithms
KW  - Robot sensing systems
KW  - Visualization
KW  - Search problems
KW  - Heuristic algorithms
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8794252
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The stochastic Canadian Traveler Problem (CTP), which finds application in robot route selection under uncertainty, aims to find the traversal policy with the minimum expected cost. This paper extends the CTP to what we call the Robust Canadian Traveler Problem (RCTP), in which the variability of the policy cost is also part of the evaluation criteria. An optimal (offline) algorithm and an approximate (online) algorithm are then proposed to compute the policy that has a good balance of both mean and variation of the traversal cost. The benefit of the proposed framework versus traditional approaches is shown by doing simulations in randomly generated worlds as well as on a map of 5 km of paths built from robot field trials. Specifically, the RCTP framework is able to search for sub-optimal policy alternatives with significantly lower worst-case cost and less computational time compared to the optimal policy, but with little sacrifice on the expected cost.
ER  - 

TY  - CONF
TI  - Improved A-search guided tree construction for kinodynamic planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5530
EP  - 5536
AU  - Y. Wang
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - robot dynamics
KW  - robot kinematics
KW  - search problems
KW  - trees (mathematics)
KW  - A-search guided tree
KW  - node selection
KW  - heuristic cost
KW  - computation efficiency
KW  - improved AGT
KW  - i-AGT
KW  - node expansion
KW  - prioritizing control actions
KW  - prioritizing nodes
KW  - bi-directional AGT
KW  - BAGT
KW  - kinodynamic planning
KW  - second tree encodes obstacles information
KW  - Robots
KW  - Path planning
KW  - Aerospace electronics
KW  - Complexity theory
KW  - Probabilistic logic
KW  - Lattices
KW  - Planning
DO  - 10.1109/ICRA.2019.8793705
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - With node selection being directed by a heuristic cost [1]-[3], A-search guided tree (AGT) is constructed on-the-fly and enables fast kinodynamic planning. This work presents two variants of AGT to improve computation efficiency. An improved AGT (i-AGT) biases node expansion through prioritizing control actions, an analogy of prioritizing nodes. Focusing on node selection, a bi-directional AGT (BAGT) introduces a second tree originated from the goal in order to offer a better heuristic cost of the first tree. Effectiveness of BAGT pivots on the fact that the second tree encodes obstacles information near the goal. Case study demonstrates that i-AGT consistently reduces the complexity of the tree and improves computation efficiency; and BAGT works largely but not always, particularly with no benefit observed for simple cases.
ER  - 

TY  - CONF
TI  - Balancing Global Exploration and Local-connectivity Exploitation with Rapidly-exploring Random disjointed-Trees
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5537
EP  - 5543
AU  - T. Lai
AU  - F. Ramos
AU  - G. Francis
PY  - 2019
KW  - Markov processes
KW  - path planning
KW  - robots
KW  - sampling methods
KW  - search problems
KW  - trees (mathematics)
KW  - local-connectivity exploitation
KW  - sampling efficiency
KW  - sampling-based planners
KW  - incremental optimal multiquery planner
KW  - RRdT
KW  - Markov Chain random sampling
KW  - active balancing
KW  - sampling-based motion planners
KW  - incremental planners
KW  - rapidly-exploring random disjointed-trees
KW  - Convergence
KW  - Space exploration
KW  - Probabilistic logic
KW  - Planning
KW  - Path planning
KW  - Proposals
KW  - Markov processes
DO  - 10.1109/ICRA.2019.8793618
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Sampling efficiency in a highly constrained environment has long been a major challenge for sampling-based planners. In this work, we propose Rapidly-exploring Random disjointed-Trees* (RRdT*), an incremental optimal multi-query planner. RRdT* uses multiple disjointed-trees to exploit local-connectivity of spaces via Markov Chain random sampling, which utilises neighbourhood information derived from previous successful and failed samples. To balance local exploitation, RRdT* actively explore unseen global spaces when local-connectivity exploitation is unsuccessful. The active trade-off between local exploitation and global exploration is formulated as a multi-armed bandit problem. We argue that the active balancing of global exploration and local exploitation is the key to improving sample efficient in sampling-based motion planners. We provide rigorous proofs of completeness and optimal convergence for this novel approach. Furthermore, we demonstrate experimentally the effectiveness of RRdT*'s locally exploring trees in granting improved visibility for planning. Consequently, RRdT* outperforms existing state-of-the-art incremental planners, especially in highly constrained environments.
ER  - 

TY  - CONF
TI  - Locomotion Planning through a Hybrid Bayesian Trajectory Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5544
EP  - 5550
AU  - T. Seyde
AU  - J. Carius
AU  - R. Grandia
AU  - F. Farshidian
AU  - M. Hutter
PY  - 2019
KW  - Bayes methods
KW  - computational complexity
KW  - Gaussian processes
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - nonlinear programming
KW  - optimal control
KW  - path planning
KW  - locomotion planning
KW  - legged systems
KW  - suitable contact schedules
KW  - contact sequence
KW  - hybrid dynamical system
KW  - achievable motions
KW  - optimal control problem
KW  - computational complexity
KW  - motion optimization
KW  - plans contacts
KW  - contact schedule selection
KW  - high-level task descriptors
KW  - motion planning nonlinear program
KW  - single-legged hopping
KW  - task appropriate contact schedules
KW  - hybrid Bayesian trajectory optimization
KW  - Bayesian optimization
KW  - Gaussian process model
KW  - bilevel optimization
KW  - Optimization
KW  - Schedules
KW  - Trajectory
KW  - Kernel
KW  - Task analysis
KW  - Robots
DO  - 10.1109/ICRA.2019.8794067
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Locomotion planning for legged systems requires reasoning about suitable contact schedules. The contact sequence and timings constitute a hybrid dynamical system and prescribe a subset of achievable motions. State-of-the-art approaches cast motion planning as an optimal control problem. In order to decrease computational complexity, one common strategy separates footstep planning from motion optimization and plans contacts using heuristics. In this paper, we propose to learn contact schedule selection from high-level task descriptors using Bayesian Optimization. A bi-level optimization is defined in which a Gaussian Process model predicts the performance of trajectories generated by a motion planning nonlinear program. The agent, therefore, retains the ability to reason about suitable contact schedules, while explicit computation of the corresponding gradients is avoided. We delineate the algorithm in its general form and provide results for planning single-legged hopping. Our method is capable of learning contact schedule transitions that align with human intuition. It performs competitively against a heuristic baseline in predicting task appropriate contact schedules.
ER  - 

TY  - CONF
TI  - Dynamic Channel: A Planning Framework for Crowd Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5551
EP  - 5557
AU  - C. Cao
AU  - P. Trautman
AU  - S. Iba
PY  - 2019
KW  - collision avoidance
KW  - graph theory
KW  - mobile robots
KW  - navigation
KW  - pedestrians
KW  - search problems
KW  - crowd navigation
KW  - real-time navigation
KW  - robotics
KW  - imminent collision avoidance
KW  - path planning problem
KW  - graph-searching
KW  - triangulation space
KW  - obstacle dynamics
KW  - public pedestrian datasets
KW  - dynamic obstacle avoidance
KW  - dynamic channels
KW  - motion planners
KW  - pedestrian dynamics
KW  - mobile robot applications
KW  - Robots
KW  - Collision avoidance
KW  - Navigation
KW  - Planning
KW  - Heuristic algorithms
KW  - Trajectory
KW  - Logic gates
DO  - 10.1109/ICRA.2019.8794192
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Real-time navigation in dense human environments is a challenging problem in robotics. Most existing path planners fail to account for the dynamics of pedestrians because introducing time as an additional dimension in search space is computationally prohibitive. Alternatively, most local motion planners only address imminent collision avoidance and fail to offer long-term optimality. In this work, we present an approach, called Dynamic Channels, to solve this global to local quandary. Our method combines the high-level topological path planning with low-level motion planning into a complete pipeline. By formulating the path planning problem as graph-searching in the triangulation space, our planner is able to explicitly reason about the obstacle dynamics and capture the environmental change efficiently. We evaluate efficiency and performance of our approach on public pedestrian datasets and compare it to a state-of-the-art planning algorithm for dynamic obstacle avoidance. Completeness proofs are provided in the supplement at http://caochao.me/files/proof.pdf. An extended version of the paper is available on arXiv.
ER  - 

TY  - CONF
TI  - Composition of Local Potential Functions with Reflection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5558
EP  - 5564
AU  - A. Stager
AU  - H. G. Tanner
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - navigation
KW  - local potential functions
KW  - reflections
KW  - collision capable robot platforms
KW  - reflection surfaces
KW  - reflection capable omnidirectional robot
KW  - cell decompositions
KW  - navigation
KW  - global convergence
KW  - Omnipuck
KW  - Robots
KW  - Collision avoidance
KW  - Convergence
KW  - Planning
KW  - Navigation
KW  - Trajectory
KW  - Pins
DO  - 10.1109/ICRA.2019.8793807
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper suggests reflections can be practically useful if they are included in planning for collision capable robot platforms. By modifying a proven strategy for navigation with reflections we maintain global convergence results and reach the goal in less time. An algorithm for identifying reflection surfaces for a given cell decomposition is reported. Baseline and reflected scenarios are compared for two different cell decompositions. Omnipuck, a reflection capable omnidirectional robot meant to store and release impact energy, is used to obtain experimental results and draw conclusions for future work.
ER  - 

TY  - CONF
TI  - Analyzing Electromagnetic Actuator based on Force Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5565
EP  - 5570
AU  - J. Ahn
AU  - D. Yun
PY  - 2019
KW  - electric field effects
KW  - electromagnetic actuators
KW  - embossing
KW  - hot working
KW  - impact (mechanical)
KW  - magnetic field effects
KW  - impact hot embossing
KW  - force analysis
KW  - magnetic field
KW  - system equation
KW  - electromagnetic actuator
KW  - electrical field
KW  - mechanical system
KW  - Simulink analysis
KW  - Mathematical model
KW  - Actuators
KW  - Magnetic flux
KW  - Force
KW  - Magnetic forces
KW  - Magnetic circuits
KW  - Embossing
KW  - Hot Embossing
KW  - electromagnetic actuator
KW  - linear actuator
KW  - system modeling
KW  - equivalent magnetic circuit
DO  - 10.1109/ICRA.2019.8793518
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - By modeling the system with the mechanical, electrical, and magnetic field, we can derive the system equation for the actuator modeling. As it is not easy to conclude the output signal from the equations, we used Simulink to simulate and check the performance aspect of the system. After that, we did several experiments to verify whether experimental force meets with the needed condition for impact hot embossing and matches with simulation force. We tried to adjust the parameters of the system to match the force of experiment result and that of the simulation result. From the comparison, we can consider the analysis of the actuator as precise. A successful study can contribute to the better application of new type hot embossing techniques and better understanding and usage of the electromagnetic actuator when it is applied to another technology and research.
ER  - 

TY  - CONF
TI  - A Novel Robotic System for Finishing of Freeform Surfaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5571
EP  - 5577
AU  - Y. Wen
AU  - J. Hu
AU  - P. R. Pagilla
PY  - 2019
KW  - closed loop systems
KW  - end effectors
KW  - fixtures
KW  - force sensors
KW  - industrial manipulators
KW  - industrial robots
KW  - mobile robots
KW  - optical scanners
KW  - surface finishing
KW  - freeform surfaces
KW  - consistent surface quality
KW  - robotic surface finishing system
KW  - finishing tool
KW  - proximity laser sensor
KW  - surface finishing process
KW  - surface profile mesh
KW  - robot closed-loop control system
KW  - robot base coordinates
KW  - surface finishing experiments
KW  - wooden surfaces
KW  - surface finish
KW  - robotic system
KW  - perception system
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Surface impedance
KW  - Surface treatment
KW  - Surface emitting lasers
KW  - End effectors
DO  - 10.1109/ICRA.2019.8793734
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Surface finishing of freeform surfaces is predominately a manual operation that requires a considerable amount of operator skill; automation of this process has many benefits, including consistent surface quality, preventing hazardous exposure to particulate, etc. A novel robotic surface finishing system, consisting of a robot and an end-effector that includes a force sensor, finishing tool, and proximity laser sensor, is developed in this paper to automate the surface finishing process. The laser sensor is treated as an additional link, and based on it a novel perception system is developed for real-time scanning of the surface that provides the surface profile mesh and the corresponding normal vectors which can be used directly by the robot closed-loop control system for pose tracking. A unique feature of the perception system is that the geometry of the surface profile and normal vectors are all obtained in real-time in the robot base coordinate system, thus eliminating issues such as precise registration of the work piece in the fixture and its location with respect to the robot base coordinates. An impedance-type closed-loop control algorithm is developed for pose tracking. The proposed system and control algorithm are employed to conduct surface finishing experiments on wooden surfaces. A representative sample of the results and measurement images of surface finish are provided to illustrate the capabilities of the robotic surface finishing system. A video of the system in operation is also provided.
ER  - 

TY  - CONF
TI  - Context-Dependent Compensation Scheme to Reduce Trajectory Execution Errors for Industrial Manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5578
EP  - 5584
AU  - P. M. Bhatt
AU  - P. Rajendran
AU  - K. McKay
AU  - S. K. Gupta
PY  - 2019
KW  - compensation
KW  - end effectors
KW  - industrial manipulators
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - execution error
KW  - end-effector loads
KW  - general purpose automated compensation scheme
KW  - trajectory errors
KW  - learned compensation scheme
KW  - context-dependent compensation scheme
KW  - automatically generated trajectories
KW  - robot model
KW  - actuator errors
KW  - low production volume applications
KW  - reduced trajectory execution errors
KW  - Trajectory
KW  - Service robots
KW  - End effectors
KW  - Trajectory tracking
KW  - Error correction
DO  - 10.1109/ICRA.2019.8793876
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Currently, automatically generated trajectories cannot be directly used on tasks that require high execution accuracies due to errors accused by inaccuracies in the robot model, actuator errors, and controller limitations. These trajectories often need manual refinement. This is not economically viable on low production volume applications. Unfortunately, execution errors are dependent on the nature of the trajectory and end-effector loads, and therefore devising a general purpose automated compensation scheme for reducing trajectory errors is not possible. This paper presents a method for analyzing the given trajectory, executing an exploratory physical run for a small portion of the given trajectory, and learning a compensation scheme based on the measured data. The learned compensation scheme is context-dependent and can be used to reduce the execution error. We have demonstrated the feasibility of this approach by conducting physical experiments.
ER  - 

TY  - CONF
TI  - Identifying Feasible Workpiece Placement with Respect to Redundant Manipulator for Complex Manufacturing Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5585
EP  - 5591
AU  - R. K. Malhan
AU  - A. M. Kabir
AU  - B. Shah
AU  - S. K. Gupta
PY  - 2019
KW  - end effectors
KW  - industrial manipulators
KW  - machine tools
KW  - nonlinear programming
KW  - redundant manipulators
KW  - redundant manipulator
KW  - complex manufacturing task
KW  - robot workspace
KW  - task surfaces
KW  - nonlinear optimization problem
KW  - complex workpieces
KW  - feasible workpiece placement
KW  - end-effector
KW  - constraint violation functions
KW  - Task analysis
KW  - Robot kinematics
KW  - End effectors
KW  - Tools
KW  - Indexes
DO  - 10.1109/ICRA.2019.8794353
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Successfully completing a complex manufacturing task requires finding a feasible placement of the workpiece in the robot workspace. The workpiece placement should be such that the task surfaces on the workpiece are reachable by the robot, the robot can apply the required forces, and the end-effector/tool can move with the desired velocity. This paper formulates the problem of identifying a feasible placement as a non-linear optimization problem over the constraint violation functions. This is a computationally challenging problem. We show that this problem can be solved by successively searching for the solution by incrementally applying different constraints. We demonstrate the feasibility of our approach using several complex workpieces.
ER  - 

TY  - CONF
TI  - Geometric Search-Based Inverse Kinematics of 7-DoF Redundant Manipulator with Multiple Joint Offsets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5592
EP  - 5598
AU  - A. Sinha
AU  - N. Chakraborty
PY  - 2019
KW  - end effectors
KW  - geometry
KW  - iterative methods
KW  - Jacobian matrices
KW  - manipulator kinematics
KW  - position control
KW  - redundant manipulators
KW  - geometric search-based inverse kinematics
KW  - geometric method
KW  - inverse kinematics problems
KW  - inverse position kinematics
KW  - manipulator Jacobian
KW  - IK algorithm
KW  - elbow joints
KW  - geometry-based IK solvers
KW  - redundant Baxter robot
KW  - End effectors
KW  - Kinematics
KW  - Shoulder
KW  - Wrist
KW  - Elbow
DO  - 10.1109/ICRA.2019.8793725
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a geometric method to solve inverse kinematics (IK) problems of 7-DoF manipulators with joint offsets at shoulder, elbow, and wrist. Traditionally, inverse position kinematics for redundant manipulators are solved by using an iterative method based on the pseudo-inverse of the manipulator Jacobian. This provides a single solution among the infinitely many possible solutions for the IK problem of redundant manipulators. There are no closed-form IK solutions for redundant manipulators with multiple joint offsets. Using our method we can compute multiple IK solutions using two-parameter search by exploiting geometry of the structure of a redundant manipulator. Our proposed IK algorithm can handle multiple joint offsets and is mathematically simple to implement in a few lines of code. We apply our algorithm to compute IK solutions for 7-DoF redundant Baxter robot (that has joint offsets at shoulder, wrist, and elbow joints) for end-effector configurations where existing geometry-based IK solvers fail to find solutions. We also demonstrate the use of our algorithm in an application where we want to compute an IK solution (among the infinitely many possible solutions) that has minimum error bound in end-effector position, in the presence of random joint actuation and sensing uncertainties.
ER  - 

TY  - CONF
TI  - Design and Formal Verification of a Safe Stop Supervisor for an Automated Vehicle*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5607
EP  - 5613
AU  - J. Krook
AU  - L. Svensson
AU  - Y. Li
AU  - L. Feng
AU  - M. Fabian
PY  - 2019
KW  - Global Positioning System
KW  - mobile robots
KW  - remotely operated vehicles
KW  - road safety
KW  - road vehicles
KW  - model-based approach
KW  - model checking
KW  - demonstration vehicle
KW  - formal verification
KW  - safe stop supervisor
KW  - automated vehicle
KW  - autonomous vehicles
KW  - pertinent planning
KW  - control algorithms
KW  - mode switch
KW  - nominal planners
KW  - safe fallback routine
KW  - safe position
KW  - nominal operational conditions
KW  - system failure
KW  - mode switching
KW  - safe stop trajectory planner
KW  - research concept vehicle
KW  - Trajectory
KW  - Planning
KW  - Automation
KW  - Global Positioning System
KW  - Software
KW  - Switches
KW  - Roads
DO  - 10.1109/ICRA.2019.8793636
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous vehicles apply pertinent planning and control algorithms under different driving conditions. The mode switch between these algorithms should also be autonomous. On top of the nominal planners, a safe fallback routine is needed to stop the vehicle at a safe position if nominal operational conditions are violated, such as for a system failure. This paper describes the design and formal verification of a supervisor to manage all requirements for mode switching between nominal planners, and additional requirements for switching to a safe stop trajectory planner that acts as the fallback routine. The supervisor is designed via a model-based approach and its abstraction is formally verified by model checking. The supervisor is implemented and integrated with the Research Concept Vehicle, an experimental research and demonstration vehicle developed at the KTH Royal Institute of Technology. Simulations and experiments show that the vehicle is able to autonomously drive in a safe manner between two parking lots and can successfully come to a safe stop upon GPS sensor failure.
ER  - 

TY  - CONF
TI  - Optimization-Based Terrain Analysis and Path Planning in Unstructured Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5614
EP  - 5620
AU  - U. Graf
AU  - P. Borges
AU  - E. Hernández
AU  - R. Siegwart
AU  - R. Dubé
PY  - 2019
KW  - data structures
KW  - graph theory
KW  - mobile robots
KW  - navigation
KW  - optimisation
KW  - path planning
KW  - position control
KW  - remotely operated vehicles
KW  - terrain mapping
KW  - trees (mathematics)
KW  - path planning
KW  - environment representation
KW  - terrain modeling
KW  - graph edge expansions
KW  - optimization-based terrain analysis
KW  - unmanned ground vehicle
KW  - hierarchical model
KW  - local terrain map
KW  - graph search algorithms
KW  - vertex positions
KW  - compact data structure
KW  - space-dividing tree
KW  - environment model
KW  - rough environments
KW  - real-time optimization-based approach
KW  - unstructured environments
KW  - autonomous ground vehicle navigation
KW  - Optimization
KW  - Path planning
KW  - Planning
KW  - Data structures
KW  - Collision avoidance
KW  - Navigation
KW  - Robots
DO  - 10.1109/ICRA.2019.8794331
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate environment representation is one of the key challenges in autonomous ground vehicle navigation in unstructured environments. We propose a real-time optimization-based approach to terrain modeling and path planning in off-road and rough environments. Our method uses an irregular, hierarchical, graph-like environment model. A space-dividing tree is used to define a compact data structure capturing vertex positions and establishing connectivity. The same unique underlying data structure is used for both terrain modeling and path planning without memory reallocation. Local plans are generated by graph search algorithms and are continuously regenerated for on-the-fly obstacle avoidance inside the scope of the local terrain map. We show that implementing a hierarchical model over a regular space division reduces graph edge expansions by up to 84%. We illustrate the applicability of the method through experiments with an unmanned ground vehicle in both structured and unstructured environments.
ER  - 

TY  - CONF
TI  - Pedestrian Dominance Modeling for Socially-Aware Robot Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5621
EP  - 5628
AU  - T. Randhavane
AU  - A. Bera
AU  - E. Kubin
AU  - A. Wang
AU  - K. Gray
AU  - D. Manocha
PY  - 2019
KW  - collision avoidance
KW  - human-robot interaction
KW  - mobile robots
KW  - socially-aware robot navigation
KW  - dominance characteristics
KW  - PDM models
KW  - perceived dominance levels
KW  - dominance-based collision-avoidance
KW  - pedestrian dominance model
KW  - robot navigation
KW  - autonomous vehicle navigation
KW  - Robots
KW  - Navigation
KW  - Trajectory
KW  - Psychology
KW  - Computational modeling
KW  - Prediction algorithms
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8794465
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a Pedestrian Dominance Model (PDM) to identify the dominance characteristics of pedestrians for robot navigation. Through a perception study on a simulated dataset of pedestrians, PDM models the perceived dominance levels of pedestrians with varying motion behaviors corresponding to trajectory, speed, and personal space. At runtime, we use PDM to identify the dominance levels of pedestrians to facilitate socially-aware navigation for the robots. PDM can predict dominance levels from trajectories with ~85% accuracy. Prior studies in psychology literature indicate that when interacting with humans, people are more comfortable around people that exhibit complementary movement behaviors. Our algorithm leverages this by enabling the robots to exhibit complementing responses to pedestrian dominance. We also present an application of PDM for generating dominance-based collision-avoidance behaviors in the navigation of autonomous vehicles among pedestrians. We demonstrate the benefits of our algorithm for robots navigating among tens of pedestrians in simulated environments.
ER  - 

TY  - CONF
TI  - Dynamic Traffic Scene Classification with Space-Time Coherence
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5629
EP  - 5635
AU  - A. Narayanan
AU  - I. Dwivedi
AU  - B. Dariush
PY  - 2019
KW  - feature extraction
KW  - image classification
KW  - image motion analysis
KW  - object detection
KW  - road safety
KW  - road traffic
KW  - road vehicles
KW  - traffic engineering computing
KW  - video signal processing
KW  - space-time variations
KW  - dynamic traffic scene classification
KW  - road scenes
KW  - space-time coherence
KW  - San Francisco Bay area
KW  - semantic context
KW  - feature extraction
KW  - tactical driver behavior understanding
KW  - driving behavior detection
KW  - vehicle ego-motion
KW  - time 80.0 hour
KW  - Roads
KW  - Meteorology
KW  - Vehicle dynamics
KW  - Semantics
KW  - Heuristic algorithms
KW  - Task analysis
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794137
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper examines the problem of dynamic traffic scene classification under space-time variations in viewpoint that arise from video captured on-board a moving vehicle. Solutions to this problem are important for realization of effective driving assistance technologies required to interpret or predict road user behavior. Currently, dynamic traffic scene classification has not been adequately addressed due to a lack of benchmark datasets that consider spatiotemporal evolution of traffic scenes resulting from a vehicle's ego-motion. This paper has three main contributions. First, an annotated dataset is released to enable dynamic scene classification that includes 80 hours of diverse high quality driving video data clips collected in the San Francisco Bay area. The dataset includes temporal annotations for road places, road types, weather, and road surface conditions. Second, we introduce novel and baseline algorithms that utilize semantic context and temporal nature of the dataset for dynamic classification of road scenes. Finally, we showcase algorithms and experimental results that highlight how extracted features from scene classification serve as strong priors and help with tactical driver behavior understanding. The results show significant improvement from previously reported driving behavior detection baselines in the literature.
ER  - 

TY  - CONF
TI  - Towards the Design of Robotic Drivers for Full-Scale Self-Driving Racing Cars
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5643
EP  - 5649
AU  - D. Caporale
AU  - A. Settimi
AU  - F. Massa
AU  - F. Amerotti
AU  - A. Corti
AU  - A. Fagiolini
AU  - M. Guiggiani
AU  - A. Bicchi
AU  - L. Pallottino
PY  - 2019
KW  - automobiles
KW  - control system synthesis
KW  - mobile robots
KW  - nonlinear control systems
KW  - path planning
KW  - predictive control
KW  - full-scale self-driving racing cars
KW  - autonomous vehicles
KW  - planning
KW  - control methods
KW  - autonomous racing cars
KW  - electric full scale autonomous racing car
KW  - control system architecture
KW  - localization methods
KW  - nonlinear model predictive control
KW  - pre-planned racing line
KW  - robotic driver design
KW  - Automobiles
KW  - Planning
KW  - Real-time systems
KW  - Computer architecture
KW  - Optimization
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8793882
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous vehicles are undergoing a rapid development thanks to advances in perception, planning and control methods and technologies achieved in the last two decades. Moreover, the lowering costs of sensors and computing platforms are attracting industrial entities, empowering the integration and development of innovative solutions for civilian use. Still, the development of autonomous racing cars has been confined mainly to laboratory studies and small to middle scale vehicles. This paper tackles the development of a planning and control framework for an electric full scale autonomous racing car, which is an absolute novelty in the literature, upon which we report our preliminary experiments and perspectives on future work. Our system leverages real time Nonlinear Model Predictive Control to track a pre-planned racing line. We describe the whole control system architecture including the mapping and localization methods employed.
ER  - 

TY  - CONF
TI  - Model-free Online Motion Adaptation for Optimal Range and Endurance of Multicopters
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5650
EP  - 5656
AU  - A. Tagliabue
AU  - X. Wu
AU  - M. W. Mueller
PY  - 2019
KW  - adaptive control
KW  - aerodynamics
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - motion control
KW  - optimal control
KW  - path planning
KW  - position control
KW  - quadcopter
KW  - on-board power measurement
KW  - power consumption
KW  - energy-efficient loitering strategy
KW  - model-free online motion adaptation
KW  - extremum seeking control
KW  - aerodynamic disturbances
KW  - Power demand
KW  - Aerodynamics
KW  - Payloads
KW  - Propellers
KW  - Robots
KW  - Batteries
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8793708
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we introduce an approach that allows a quadcopter to find the velocity which maximizes its flight time (endurance) or flight distance (range) while moving along a given path, using on-board power measurement. The proposed strategy is based on Extremum Seeking control and (a) does not require any model of the power consumption of the system, (b) can be executed on-line, and (c) guarantees adaptation to unknown disturbances. We show experimentally that hovering is not the most energy-efficient loitering strategy, and we demonstrate the proposed method's ability to adapt to different aerodynamic disturbances, such as payloads. The method may be especially useful in applications where a quadcopter carries an unknown payload, allowing it to adapt for improved range.
ER  - 

TY  - CONF
TI  - Multi-view Reconstruction of Wires using a Catenary Model
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5657
EP  - 5664
AU  - R. Madaan
AU  - M. Kaess
AU  - S. Scherer
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cameras
KW  - extrapolation
KW  - image reconstruction
KW  - image segmentation
KW  - inspection
KW  - object detection
KW  - power cables
KW  - power engineering computing
KW  - robot vision
KW  - stereo image processing
KW  - multiview reconstruction
KW  - catenary model
KW  - UAV community
KW  - wire avoidance capabilities
KW  - powerline corridor inspection
KW  - multiview algorithm
KW  - catenary curve
KW  - partial wire detections
KW  - bundle-adjustment approaches
KW  - binarized wire segmentation images
KW  - approximate extrapolation
KW  - Wires
KW  - Image reconstruction
KW  - Three-dimensional displays
KW  - Cameras
KW  - Transforms
KW  - Computational modeling
KW  - Atmospheric modeling
DO  - 10.1109/ICRA.2019.8793852
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Reliable detection and reconstruction of wires is one of the hardest problems in the UAV community, with a wide ranging impact in the industry in terms of wire avoidance capabilities and powerline corridor inspection. In this work, we introduce a real-time, model-based, multi-view algorithm to reconstruct wires from a set of images with known camera poses, while exploiting their natural shape - the catenary curve. Using a model-based approach helps us deal with partial wire detections in images, which may occur due to natural occlusion and false negatives. In addition, using a parsimonious model makes our algorithm efficient as we only need to optimize for 5 model parameters, as opposed to hundreds of 3D points in bundle-adjustment approaches. Our algorithm obviates the need for pixel correspondences by computing the reprojection error via the distance transform of binarized wire segmentation images. Further, we make our algorithm robust to arbitrary initializations by introducing an on-demand, approximate extrapolation of the distance transform based objective. We demonstrate the effectiveness of our algorithm against false negatives and random initializations in simulation, and show qualitative results with real data collected from a small UAV.
ER  - 

TY  - CONF
TI  - Real-time Optimal Planning and Model Predictive Control of a Multi-rotor with a Suspended Load
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5665
EP  - 5671
AU  - C. Y. Son
AU  - D. Jang
AU  - H. Seo
AU  - T. Kim
AU  - H. Lee
AU  - H. J. Kim
PY  - 2019
KW  - aerospace robotics
KW  - collision avoidance
KW  - convex programming
KW  - helicopters
KW  - mobile robots
KW  - nonlinear control systems
KW  - path planning
KW  - predictive control
KW  - high-dimensional nonlinear system
KW  - differential flatness property
KW  - nonconvex constraints
KW  - convex optimization problem
KW  - optimal trajectory
KW  - semifeasible trajectory
KW  - model predictive control
KW  - suspended load
KW  - control algorithms
KW  - multirotor dynamics
KW  - real-time trajectory generation
KW  - collision-free trajectories
KW  - collision-free trajectory
KW  - dynamic coupling
KW  - real-time optimal planning
KW  - concave obstacle-avoidance constraints
KW  - sequential linear quadratic solver
KW  - Trajectory
KW  - Real-time systems
KW  - Planning
KW  - Convex functions
KW  - Vehicle dynamics
KW  - Nonlinear dynamical systems
KW  - Load modeling
DO  - 10.1109/ICRA.2019.8793674
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents planning and control algorithms for a multi-rotor with a suspended load. The suspended load cannot be controlled easily by the multi-rotor due to severe dynamic coupling between them. Difficulties are exacerbated by under-actuated, highly nonlinear nature of multi-rotor dynamics. Although many studies have been proposed to plan trajectories and control this system, there exist only a few reports on real-time trajectory generation. With this in mind, we propose a planning method which is capable of generating collision-free trajectories real-time and applicable to a high-dimensional nonlinear system. Using a differential flatness property, the system can be linearized entirely with elaborately chosen flat outputs. Convexification of non-convex constraints is carried out, and concave obstacle-avoidance constraints are converted to convex ones. After that, a convex optimization problem is solved to generate an optimal trajectory, but semi-feasible trajectory which considers only some parts of the initial state. We apply model predictive control with a sequential linear quadratic solver to compute a feasible collision-free trajectory and to control the system. Performance of the algorithm is validated by flight experiment.
ER  - 

TY  - CONF
TI  - Bioinspired Direct Visual Estimation of Attitude Rates with Very Low Resolution Images using Deep Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5672
EP  - 5678
AU  - M. Mérida-Floriano
AU  - F. Caballero
AU  - D. Acedo
AU  - D. García-Morales
AU  - F. Casares
AU  - L. Merino
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cameras
KW  - data visualisation
KW  - image resolution
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - robot vision
KW  - light source direction
KW  - artificial neural networks
KW  - deep networks
KW  - bioinspired visual system sensor
KW  - low resolution images
KW  - attitude rates
KW  - bioinspired direct visual estimation
KW  - source code
KW  - classical computer vision based method
KW  - learning approach
KW  - low resolution cameras
KW  - Drosophila's ocellar system
KW  - hardware setup
KW  - UAV
KW  - unmanned aerial vehicles
KW  - angular rates
KW  - Cameras
KW  - Robot sensing systems
KW  - Visualization
KW  - Estimation
KW  - Neural networks
KW  - Computer vision
KW  - Image resolution
DO  - 10.1109/ICRA.2019.8794057
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we present a bioinspired visual system sensor to estimate angular rates in unmanned aerial vehicles (UAV) using Neural Networks. We have conceived a hardware setup to emulate Drosophila's ocellar system, three simple eyes related to stabilization. This device is composed of three low resolution cameras with a similar spatial configuration as the ocelli. There have been previous approaches based on this ocellar system, most of them considering assumptions such as known light source direction or a punctual light source. In contrast, here we present a learning approach using Artificial Neural Networks in order to recover the system's angular rates indoors and outdoors without previous knowledge. A classical computer vision based method is also derived to be used as a benchmark for the learning approach. The method is validated with a large dataset of images (more than half a million samples) including synthetic and real data. The source code of the algorithms and the datasets used in this paper have been released in an open repository.
ER  - 

TY  - CONF
TI  - Automatic Real-time Anomaly Detection for Autonomous Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5679
EP  - 5685
AU  - A. Keipour
AU  - M. Mousaei
AU  - S. Scherer
PY  - 2019
KW  - actuators
KW  - aerospace components
KW  - aerospace simulation
KW  - aircraft testing
KW  - autonomous aerial vehicles
KW  - fault diagnosis
KW  - fault tolerant control
KW  - least squares approximations
KW  - mobile robots
KW  - recursive least squares method
KW  - anomaly detection method
KW  - aircraft model
KW  - fault detection research
KW  - fixed-wing flights
KW  - ground truth
KW  - mid-flight actuator failures
KW  - fault detection open dataset
KW  - autonomous aircraft
KW  - correlated input-output pairs
KW  - autonomous aerial vehicles
KW  - Aircraft
KW  - Atmospheric modeling
KW  - Fault detection
KW  - Actuators
KW  - Reliability
KW  - Computational modeling
KW  - Safety
DO  - 10.1109/ICRA.2019.8794286
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The recent increase in the use of aerial vehicles raises concerns about the safety and reliability of autonomous operations. There is a growing need for methods to monitor the status of these aircraft and report any faults and anomalies to the safety pilot or to the autopilot to deal with the emergency situation. In this paper, we present a real-time approach using the Recursive Least Squares method to detect anomalies in the behavior of an aircraft. The method models the relationship between correlated input-output pairs online and uses the model to detect the anomalies. The result is an easy-to-deploy anomaly detection method that does not assume a specific aircraft model and can detect many types of faults and anomalies in a wide range of autonomous aircraft. The experiments on this method show a precision of 88.23%, recall of 88.23% and 86.36% accuracy for over 22 flight tests. The other contribution is providing a new fault detection open dataset for autonomous aircraft, which contains complete data and the ground truth for 22 fixed-wing flights with eight different types of mid-flight actuator failures to help future fault detection research for aircraft.
ER  - 

TY  - CONF
TI  - Learning ad-hoc Compact Representations from Salient Landmarks for Visual Place Recognition in Underwater Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5739
EP  - 5745
AU  - A. Maldonado-Ramírez
AU  - L. A. Torres-Mendez
PY  - 2019
KW  - convolutional neural nets
KW  - feature extraction
KW  - image coding
KW  - image representation
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - SLAM (robots)
KW  - unsupervised learning
KW  - salient landmarks
KW  - visual place recognition
KW  - underwater environments
KW  - visual attention algorithm
KW  - hand-crafted local descriptors
KW  - ad hoc descriptor generator
KW  - convolutional autoencoder
KW  - ad-hoc compact representations
KW  - SeqSLAM
KW  - FAB-MAP
KW  - SURF method
KW  - Visualization
KW  - Feature extraction
KW  - Image color analysis
KW  - Training
KW  - Robots
KW  - Task analysis
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793550
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose an approach to learn compact representations from salient landmarks detected by a visual attention algorithm to recognize previously visited places in underwater environments. Instead of using hand-crafted local descriptors as it has been typically done in visual place recognition, we use a convolutional autoencoder to obtain an ad hoc descriptor generator from salient landmarks. The main advantage of using an autoencoder is that it can learn in an unsupervised manner directly from the salient landmarks. In addition, we show that it is possible to do the training with less than 100,000 examples instead of several hundreds of thousands or even millions of labeled examples as in other convolutional architectures. The trained convolutional autoencoder is used to obtain descriptors for salient landmarks that are later utilized in a voting scheme to calculate similarity between images with the objective of finding if a place has already been visited. The proposed method has obtained good results compared to SeqSLAM and FAB-MAP in different datasets obtained from robotic explorations of coral reefs in real life conditions. Moreover, when the visual attention algorithm is used, fewer features are required to get a good performance in terms of precision and recall compared when using the SURF method to extract visual features.
ER  - 

TY  - CONF
TI  - Finding divers with SCUBANet
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5746
EP  - 5751
AU  - R. Codd-Downey
AU  - M. Jenkin
PY  - 2019
KW  - autonomous underwater vehicles
KW  - convolutional neural nets
KW  - gesture recognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - diver-diver communication
KW  - diver-robot communication
KW  - underwater detection dataset
KW  - standard diver gestures
KW  - diver recognition
KW  - diver body-head-hand localization
KW  - CNN-based approach
KW  - SCUBANet dataset
KW  - human-robot communication
KW  - diver component recognition
KW  - robot-diver communication
KW  - human operators
KW  - divers finding
KW  - RF signal attenuation
KW  - gesture visual recognition
KW  - per-instance bounding boxes
KW  - crowd sourcing
KW  - transfer learning
KW  - Web-based interface
KW  - Standards
KW  - Training
KW  - Object detection
KW  - Robot sensing systems
KW  - Computer vision
KW  - Human-robot interaction
KW  - computer vision
KW  - object detection
KW  - dataset
KW  - underwater
KW  - robotics
DO  - 10.1109/ICRA.2019.8793655
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot-diver communication underwater is complicated by the attenuation of RF signals, the complexities of the environment in terms of deploying interaction devices, and issues related to the cognitive loading of human operators. Humans operating underwater have developed a simple yet effective strategy for diver-diver communication based on the visual recognition of gestures. Can a similar approach be effective for diver-robot communication? Here we present experiments with SCUBANet, an underwater detection dataset of body parts associated with diver-robot communication. Given the nature of standard diver gestures, here we concentrate on diver recognition and in particular on diver body-head-hand localization and examine the feasibility of using a CNN-based approach to address this problem. Such data-driven approaches typically require an appropriately annotated dataset. The SCUBANet dataset contains images of object classes commonly encountered during human-robot communication underwater. Object classes are labeled using per-instance bounding boxes. Annotations were created through crowd sourcing via a web-based interface to ease deployment. We provide baseline performance on diver and diver component recognition and localization using transfer learning on three widely available pre-trained models.
ER  - 

TY  - CONF
TI  - Robotic Detection of Marine Litter Using Deep Visual Detection Models
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5752
EP  - 5758
AU  - M. Fulton
AU  - J. Hong
AU  - M. J. Islam
AU  - J. Sattar
PY  - 2019
KW  - autonomous underwater vehicles
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - marine engineering
KW  - marine pollution
KW  - mobile robots
KW  - neural net architecture
KW  - object detection
KW  - robotic detection
KW  - marine litter
KW  - deep visual detection models
KW  - trash deposits
KW  - aquatic environments
KW  - marine ecosystems
KW  - autonomous underwater vehicles
KW  - AUV
KW  - deep-learning algorithms
KW  - convolutional neural network architectures
KW  - object detection
KW  - trained networks
KW  - underwater trash removal
KW  - Plastics
KW  - Training
KW  - Oceans
KW  - Data models
KW  - Object detection
KW  - Visualization
KW  - Biological system modeling
DO  - 10.1109/ICRA.2019.8793975
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Trash deposits in aquatic environments have a destructive effect on marine ecosystems and pose a long-term economic and environmental threat. Autonomous underwater vehicles (AUVs) could very well contribute to the solution of this problem by finding and eventually removing trash. This paper evaluates a number of deep-learning algorithms performing the task of visually detecting trash in realistic underwater environments, with the eventual goal of exploration, mapping, and extraction of such debris by using AUVs. A large and publicly-available dataset of actual debris in open-water locations is annotated for training a number of convolutional neural network architectures for object detection. The trained networks are then evaluated on a set of images from other portions of that dataset, providing insight into approaches for developing the detection capabilities of an AUV for underwater trash removal. In addition, the evaluation is performed on three different platforms of varying processing power, which serves to assess these algorithms' fitness for real-time applications.
ER  - 

TY  - CONF
TI  - A Dual-Bladder Buoyancy Engine for a Cephalopod-Inspired AUV
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5759
EP  - 5764
AU  - N. Sholl
AU  - K. Mohseni
PY  - 2019
KW  - actuators
KW  - asymptotic stability
KW  - autonomous underwater vehicles
KW  - feedback
KW  - flow sensors
KW  - gears
KW  - Lyapunov methods
KW  - mobile robots
KW  - nonlinear control systems
KW  - pressure measurement
KW  - pressure sensors
KW  - pumps
KW  - remotely operated vehicles
KW  - robot dynamics
KW  - dual-bladder buoyancy engine
KW  - cephalopod-inspired AUV
KW  - nonlinear depth
KW  - backstepping depth
KW  - pitch controller
KW  - flow-rate feedback
KW  - custom flow sensor
KW  - differential pressure sensor
KW  - 3D-printed attachment
KW  - depth control capability
KW  - single-bladder buoyancy engine
KW  - depth controller
KW  - autonomous underwater vehicle
KW  - Buoyancy
KW  - Engines
KW  - Bladder
KW  - Backstepping
KW  - Force
KW  - Vehicle dynamics
KW  - Pressure sensors
DO  - 10.1109/ICRA.2019.8793872
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a nonlinear, backstepping depth and pitch controller for a dual-bladder buoyancy engine actuated by gear pumps. Flow-rate feedback is obtained using a custom flow sensor comprised of a differential pressure sensor and a small, 3D-printed attachment. The controller is simulated using a model of the CephaloBot, our in-house developed autonomous underwater vehicle (AUV). Its depth control capability is also experimentally validated using a single-bladder buoyancy engine on-board a smaller-scale test cylinder. Lyapunov stability analysis shows global, asymptotic stability, which is exhibited in our simulation. Our experiments verify that this buoyancy engine is a feasible and effective depth controller for AUVs.
ER  - 

TY  - CONF
TI  - Uncertainty-Aware Path Planning for Navigation on Road Networks Using Augmented MDPs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5780
EP  - 5786
AU  - L. Nardi
AU  - C. Stachniss
PY  - 2019
KW  - decision theory
KW  - Markov processes
KW  - mobile robots
KW  - path planning
KW  - probability
KW  - state estimation
KW  - uncertainty-aware path planning
KW  - road networks
KW  - augmented MDPs
KW  - probabilistic algorithms
KW  - state estimation problems
KW  - robot
KW  - computationally expensive algorithms
KW  - uncertainty-augmented Markov Decision Process
KW  - planning approach
KW  - navigation policies
KW  - partially observable Markov decision process
KW  - navigation problems
KW  - Uncertainty
KW  - Roads
KW  - Planning
KW  - Navigation
KW  - Markov processes
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794121
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Although most robots use probabilistic algorithms to solve state estimation problems, path planning is often performed without considering the uncertainty about the robot's position. Uncertainty, however, matters in planning, but considering it often leads to computationally expensive algorithms. In this paper, we investigate the problem of path planning considering the uncertainty in the robot's belief about the world, in its perceptions and in its action execution. We propose the use of an uncertainty-augmented Markov Decision Process to approximate the underlying Partially Observable Markov Decision Process, and we employ a localization prior to estimate how the belief about the robot's position propagates through the environment. This yields to a planning approach that generates navigation policies able to make decisions according to the degree of uncertainty while being computationally tractable. We implemented our approach and thoroughly evaluated it on different navigation problems. Our experiments suggest that we are able to compute policies that are more effective than approaches that ignore the uncertainty, and that also outperform policies that always take the safest actions.
ER  - 

TY  - CONF
TI  - Real-time Model Based Path Planning for Wheeled Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5787
EP  - 5792
AU  - J. Jordan
AU  - A. Zell
PY  - 2019
KW  - electric vehicles
KW  - image colour analysis
KW  - image sensors
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - road safety
KW  - road vehicles
KW  - robot vision
KW  - search problems
KW  - wheels
KW  - model based traversability analysis method
KW  - complex environments
KW  - vehicles 3D pose
KW  - chassis collision
KW  - elevation map
KW  - reactive planning
KW  - safe paths
KW  - wheeled mobile robots
KW  - real world environment setups
KW  - real-time model
KW  - real-time path planning
KW  - simulated world environment setups
KW  - wheeled vehicles
KW  - vehicle model
KW  - scoring function
KW  - A*-like search strategy
KW  - RGB-D sensor
KW  - frequency 30.0 Hz
KW  - Wheels
KW  - Path planning
KW  - Robot sensing systems
KW  - Planning
KW  - Mobile robots
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8794133
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work presents a model based traversability analysis method which employs a detailed vehicle model to perform real-time path planning in complex environments. The vehicle model represents the vehicle's wheels and chassis, allowing it to accurately predict the vehicles 3D pose, detailed contact information for each wheel and the occurrence of a chassis collision given a 2D pose on an elevation map. These predictions are weighted, depending on the safety requirements of the vehicle, to provide a scoring function for an A*-like search strategy. The proposed method is designed to run at frame rates of 30Hz on data from a RGB-D sensor to provide reactive planning of safe paths. For evaluation, two wheeled mobile robots in different simulated and real world environment setups were tested to show the reliability and performance of the proposed method.
ER  - 

TY  - CONF
TI  - Integrity Risk-Based Model Predictive Control for Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5793
EP  - 5799
AU  - O. A. Hafez
AU  - G. D. Arana
AU  - M. Spenko
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - predictive control
KW  - risk management
KW  - localization sensors
KW  - mission-critical situations
KW  - local nearest neighbor integrity risk evaluation methodology
KW  - data association faults
KW  - localization safety
KW  - control-input constraints
KW  - mobile robots
KW  - navigation integrity risk
KW  - integrity risk-based model predictive control
KW  - MPC
KW  - Feature extraction
KW  - Safety
KW  - Technological innovation
KW  - Predictive models
KW  - Mobile robots
KW  - Navigation
DO  - 10.1109/ICRA.2019.8793521
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a Model Predictive Controller (MPC) that uses navigation integrity risk as a constraint. Navigation integrity risk accounts for the presence of faults in localization sensors and algorithms, an increasingly important consideration as the number of robots operating in life and mission-critical situations is expected to increase dramatically in near future (e.g. a potential influx of self-driving cars). Specifically, the work uses a local nearest neighbor integrity risk evaluation methodology that accounts for data association faults as a constraint in order to guarantee localization safety over a receding horizon. Moreover, state and control-input constraints have also been enforced in this work. The proposed MPC design is tested using real-world mapped environments, showing that a robot is capable of maintaining a predefined minimum level of localization safety while operating in an urban environment.
ER  - 

TY  - CONF
TI  - What lies in the shadows? Safe and computation-aware motion planning for autonomous vehicles using intent-aware dynamic shadow regions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5800
EP  - 5806
AU  - Y. Nager
AU  - A. Censi
AU  - E. Frazzoli
PY  - 2019
KW  - inference mechanisms
KW  - mobile robots
KW  - path planning
KW  - road safety
KW  - road vehicles
KW  - sensor fusion
KW  - autonomous driving safety
KW  - inference planning
KW  - passive safety
KW  - sensor observations
KW  - intent-aware dynamic shadow regions
KW  - computation-aware motion planning
KW  - driving behaviour
KW  - autonomous vehicle
KW  - Robot sensing systems
KW  - Planning
KW  - Safety
KW  - Automobiles
KW  - Autonomous vehicles
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793557
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - One of the challenges of developing autonomous vehicles is planning in an inhabited environment under sensing uncertainty as well as limited perception and computational resources. Besides reasoning about the behaviour of traffic participants that are within the vehicles' field of view, safe autonomous driving also requires the vehicle to reason about possible traffic participants that might exist beyond its sensing horizon, and to adapt its driving behaviour accordingly. This paper describes an inference and motion planning pipeline that is able to guarantee passive safety (collisions are possible, but the autonomous vehicle will be at rest) with respect to hypothetical hidden agents that have not been observed yet. We also incorporate the vehicle's reaction time due to sensing and computational delays into the planning process; for example, we show how having a fast reaction time due to the availability of more computational resources leads to more aggressive trajectories, while a car with a larger reaction time will choose more relaxed trajectories that require less attention.
ER  - 

TY  - CONF
TI  - Dynamic Risk Density for Autonomous Navigation in Cluttered Environments without Object Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5807
EP  - 5814
AU  - A. Pierson
AU  - C. Vasile
AU  - A. Gandhi
AU  - W. Schwarting
AU  - S. Karaman
AU  - D. Rus
PY  - 2019
KW  - collision avoidance
KW  - handicapped aids
KW  - object detection
KW  - path planning
KW  - wheelchairs
KW  - dynamic risk density
KW  - congestion density
KW  - cost function
KW  - occupancy risk
KW  - velocity fields
KW  - object-based congestion cost
KW  - cluttered environments
KW  - autonomous navigation
KW  - object detection
KW  - object tracking
KW  - autonomous wheelchair
KW  - Navigation
KW  - Cost function
KW  - Wheelchairs
KW  - Dynamics
KW  - Vehicle dynamics
KW  - Planning
KW  - Level set
DO  - 10.1109/ICRA.2019.8793813
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we examine the problem of navigating cluttered environments without explicit object detection and tracking. We introduce the dynamic risk density to map the congestion density and spatial flow of the environment to a cost function for the agent to determine risk when navigating that environment. We build upon our prior work, wherein the agent maps the density and motion of objects to an occupancy risk, then navigate the environment over a specified risk level set. Here, the agent does not need to identify objects to compute the occupancy risk, and instead computes this cost function using the occupancy density and velocity fields around them. Simulations show how this dynamic risk density encodes movement information for the ego agent and closely models the object-based congestion cost. We implement our dynamic risk density on an autonomous wheelchair and show how it can be used for navigating unstructured, crowded and cluttered environments.
ER  - 

TY  - CONF
TI  - Deep Local Trajectory Replanning and Control for Robot Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5815
EP  - 5822
AU  - A. Pokle
AU  - R. Martín-Martín
AU  - P. Goebel
AU  - V. Chow
AU  - H. M. Ewald
AU  - J. Yang
AU  - Z. Wang
AU  - A. Sadeghian
AU  - D. Sadigh
AU  - S. Savarese
AU  - M. Vázquez
PY  - 2019
KW  - collision avoidance
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - navigation
KW  - velocity control
KW  - robot navigation
KW  - hierarchical planning
KW  - machine learning
KW  - optimal paths
KW  - deep local trajectory planner
KW  - velocity controller
KW  - motion commands
KW  - attention mechanisms
KW  - nearby pedestrians
KW  - map global plan information
KW  - sensor data
KW  - velocity commands
KW  - hand-designed traditional navigation system
KW  - deep local trajectory replanning
KW  - global planner
KW  - Navigation
KW  - Robot kinematics
KW  - Trajectory
KW  - Planning
KW  - Robot sensing systems
KW  - Laser radar
DO  - 10.1109/ICRA.2019.8794062
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a navigation system that combines ideas from hierarchical planning and machine learning. The system uses a traditional global planner to compute optimal paths towards a goal, and a deep local trajectory planner and velocity controller to compute motion commands. The latter components of the system adjust the behavior of the robot through attention mechanisms such that it moves towards the goal, avoids obstacles, and respects the space of nearby pedestrians. Both the structure of the proposed deep models and the use of attention mechanisms make the system's execution interpretable. Our simulation experiments suggest that the proposed architecture outperforms baselines that try to map global plan information and sensor data directly to velocity commands. In comparison to a hand-designed traditional navigation system, the proposed approach showed more consistent performance.
ER  - 

TY  - CONF
TI  - Learning from Transferable Mechanics Models: Generalizable Online Mode Detection in Underactuated Dexterous Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5823
EP  - 5829
AU  - A. S. Morgan
AU  - W. G. Bircher
AU  - B. Calli
AU  - A. M. Dollar
PY  - 2019
KW  - control engineering computing
KW  - dexterous manipulators
KW  - grippers
KW  - Jacobian matrices
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - random forests
KW  - supervised learning
KW  - transferable mechanics models
KW  - generalizable online mode detection
KW  - underactuated dexterous manipulation
KW  - mechanics-inspired framework
KW  - fingertip-based planar within-hand manipulation
KW  - underactuated robotic gripper
KW  - hand-object system
KW  - grasp matrix
KW  - manipulability metrics
KW  - planar manipulation modes
KW  - supervised learning model
KW  - contact curvatures
KW  - prediction transferability
KW  - visual approach
KW  - gripper models
KW  - finger Jacobians
KW  - random forests classifier
KW  - Grippers
KW  - Transmission line matrix methods
KW  - Feature extraction
KW  - Jacobian matrices
KW  - Kinematics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793727
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we investigate a mechanics-inspired framework for describing fingertip-based planar within-hand manipulation with an underactuated robotic gripper. In particular, this framework leverages fundamental mechanics properties of the hand-object system, including basic terms such as local contact curvature as well as more complex features including the grasp matrix and manipulability metrics. These are extracted using a simple visual approach and then in real-time used for predicting planar manipulation modes: namely rolling, dropped, stuck, and sliding. Given a desired cartesian motion for the object, a supervised learning model predicts these four manipulation modes before they occur, allowing us to either avoid or trigger these different behaviors. Since we utilize strictly fundamental properties of the grasp matrix, finger Jacobians, and contact curvatures, we are able to demonstrate prediction transferability between different grippers using our original classifier. In particular, a Random Forests classifier trained on one gripper successfully predicts manipulation modes for grippers with different fingers with 84% accuracy, compared to just 56% from an approach in previous work. Overall, we find that the features designed in our approach better describes fingertip manipulation when precise gripper models are not available.
ER  - 

TY  - CONF
TI  - CARA system Architecture - A Click and Assemble Robotic Assembly System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5830
EP  - 5836
AU  - H. Fakhurldeen
AU  - F. Dailami
AU  - A. G. Pipe
PY  - 2019
KW  - CAD
KW  - product design
KW  - robotic assembly
KW  - tolerance analysis
KW  - implemented architecture capabilities
KW  - CARA system architecture
KW  - click and assemble robotic assembly system
KW  - industrial product
KW  - tolerances
KW  - CAD
KW  - end to end robotic assembly premise
KW  - Robotic assembly
KW  - Robot sensing systems
KW  - Task analysis
KW  - Planning
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8794114
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Future robotic assembly systems will allow product designers to upload their assembled product models remotely such that they can be assembled autonomously. In this work we present the architecture for a Click and Assemble Robotic Assembly (CARA) system. This architecture takes an assembly file uploaded by the user through a web interface as the only input. It then performs all the necessary planning before executing the assembly. To the authors' knowledge, this is the first time that all of the required components from previous advances in robotic assembly have been brought together, with all interconnecting challenges solved, into a complete working system for physical, real world assembly tasks. To demonstrate the implemented architecture capabilities, a real industrial product with tight tolerances was assembled from its CAD file only, illustrating the end to end robotic assembly premise in a real world setting.
ER  - 

TY  - CONF
TI  - Tool Macgyvering: Tool Construction Using Geometric Reasoning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5837
EP  - 5843
AU  - L. Nair
AU  - J. Balloch
AU  - S. Chernova
PY  - 2019
KW  - hand tools
KW  - manipulators
KW  - tool construction
KW  - geometric reasoning
KW  - tool Macgyvering problem
KW  - substitution problems
KW  - 7-DOF robot arm
KW  - Tools
KW  - Robots
KW  - Task analysis
KW  - Fasteners
KW  - Pipelines
KW  - Cognition
KW  - Complexity theory
DO  - 10.1109/ICRA.2019.8793257
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - MacGyvering is defined as creating or repairing something in an inventive or improvised way by utilizing objects that are available at hand. In this paper, we explore a subset of Macgyvering problems involving tool construction, i.e., creating tools from parts available in the environment. We formalize the overall problem domain of tool Macgyvering, introducing three levels of complexity for tool construction and substitution problems, and presenting a novel computational framework aimed at solving one level of the tool Macgyvering problem, specifically contributing a novel algorithm for tool construction based on geometric reasoning. We validate our approach by constructing three tools using a 7-DOF robot arm.
ER  - 

TY  - CONF
TI  - A Framework for Robot Manipulation: Skill Formalism, Meta Learning and Adaptive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5844
EP  - 5850
AU  - L. Johannsmeier
AU  - M. Gerchow
AU  - S. Haddadin
PY  - 2019
KW  - adaptive control
KW  - learning systems
KW  - manipulators
KW  - adaptive control
KW  - adaptive impedance control
KW  - meta parameter learning
KW  - compatible skill specifications
KW  - abstract expert knowledge
KW  - quality evaluation metrics
KW  - adaptive impedance controller
KW  - carefully defined skill formalism
KW  - manipulation tasks
KW  - learned tasks
KW  - learning-based solution
KW  - learning force-sensitive robot manipulation skills
KW  - submillimeter industrial tolerances
KW  - time 20.0 min
KW  - Robots
KW  - Impedance
KW  - Task analysis
KW  - Trajectory
KW  - Reinforcement learning
KW  - Complexity theory
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793542
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we introduce a novel framework for expressing and learning force-sensitive robot manipulation skills. It is based on a formalism that extends our previous work on adaptive impedance control with meta parameter learning and compatible skill specifications. This way the system is also able to make use of abstract expert knowledge by incorporating process descriptions and quality evaluation metrics. We evaluate various state-of-the-art schemes for meta parameter learning and experimentally compare selected ones. Our results clearly indicate that the combination of our adaptive impedance controller with a carefully defined skill formalism significantly reduces the complexity of manipulation tasks even for learning peg-in-hole with submillimeter industrial tolerances. Overall, the considered system is able to learn variations of this skill in under 20 minutes. In fact, experimentally the system was able to perform the learned tasks without visual feedback faster than humans, leading to the first learning-based solution of complex assembly at such real-world performance.
ER  - 

TY  - CONF
TI  - Open-Loop Collective Assembly Using a Light Field to Power and Control a Phototaxic Mini-Robot Swarm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5851
EP  - 5857
AU  - A. Bignell
AU  - L. Li
AU  - R. Vaughan
PY  - 2019
KW  - artificial life
KW  - computational geometry
KW  - mobile robots
KW  - multi-robot systems
KW  - open loop systems
KW  - path planning
KW  - open-loop collective assembly
KW  - collective construction
KW  - dynamic light field design strategies
KW  - assembled shapes
KW  - mobile robots
KW  - polygonal shapes
KW  - phototaxic minirobot swarm
KW  - nonconvex polygons
KW  - global light field
KW  - Robot kinematics
KW  - Shape
KW  - Robot sensing systems
KW  - Mobile robots
KW  - Task analysis
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8794148
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel scheme that jointly addresses the problems of powering and coordinating a population of mini-robots for collective construction. In our setting, a population of simple mobile robots must push blocks into desired polygonal shapes. Each robot performs only simple phototaxis. Coordination is purely open-loop: a global light field guides and powers the robots. We demonstrate this concept in simulation and explore a series of dynamic light field design strategies that robustly result in assembled shapes including nonconvex polygons.
ER  - 


TY  - CONF
TI  - A Variational Observation Model of 3D Object for Probabilistic Semantic SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5866
EP  - 5872
AU  - H. W. Yu
AU  - J. Y. Moon
AU  - B. H. Lee
PY  - 2019
KW  - Bayes methods
KW  - cameras
KW  - feature extraction
KW  - image colour analysis
KW  - inference mechanisms
KW  - object detection
KW  - pose estimation
KW  - probability
KW  - SLAM (robots)
KW  - variational techniques
KW  - probabilistic observation model
KW  - Bayesian inference
KW  - viewpoint-independent loop closure
KW  - variational observation model
KW  - Bayesian object observation model
KW  - 3D object detection
KW  - probabilistic semantic SLAM
KW  - single view projection
KW  - RGB monocamera
KW  - object-oriented feature extraction
KW  - 3D mapping
KW  - volumetric 3D object shape information
KW  - variational likelihood estimation
KW  - pose estimation
KW  - feature estimation
KW  - loop detector
KW  - Shape
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Object oriented modeling
KW  - Solid modeling
KW  - Semantics
DO  - 10.1109/ICRA.2019.8794111
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a Bayesian object observation model for complete probabilistic semantic SLAM. Recent studies on object detection and feature extraction have become important for scene understanding and 3D mapping. However, 3D shape of the object is too complex to formulate the probabilistic observation model; therefore, performing the Bayesian inference of the object-oriented features as well as their pose is less considered. Besides, when the robot equipped with an RGB mono camera only observes the projected single view of an object, a significant amount of the 3D shape information is abandoned. Due to these limitations, semantic SLAM and viewpoint-independent loop closure using volumetric 3D object shape is challenging. In order to enable the complete formulation of probabilistic semantic SLAM, we approximate the observation model of a 3D object with a tractable distribution. We also estimate the variational likelihood from the 2D image of the object to exploit its observed single view. In order to evaluate the proposed method, we perform pose and feature estimation, and demonstrate that the automatic loop closure works seamlessly without additional loop detector in various environments.
ER  - 

TY  - CONF
TI  - Learning Action Representations for Self-supervised Visual Exploration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5873
EP  - 5879
AU  - C. Oh
AU  - A. Cavallaro
PY  - 2019
KW  - cameras
KW  - image representation
KW  - learning (artificial intelligence)
KW  - learning action
KW  - self-supervised visual exploration
KW  - on-board camera
KW  - initial state
KW  - self-supervised prediction network
KW  - intrinsic rewards
KW  - current state-action pair
KW  - higher dimensional representations
KW  - representational power
KW  - transition network
KW  - sparse extrinsic rewards
KW  - camera view
KW  - input actions
KW  - action representation module
KW  - Training
KW  - Navigation
KW  - Task analysis
KW  - Visualization
KW  - Robots
KW  - Predictive models
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794401
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning to efficiently navigate an environment using only an on-board camera is a difficult task for an agent when the final goal is far from the initial state and extrinsic rewards are sparse. To address this problem, we present a self-supervised prediction network to train the agent with intrinsic rewards that relate to achieving the desired final goal. The network learns to predict its future camera view (the future state) from a current state-action pair through an Action Representation Module that decodes input actions as higher dimensional representations. To increase the representational power of the network during exploration we fuse the responses from the Action Representation Module in the transition network, which predicts the future state. Moreover, to enhance the discrimination capability between predictions from different input actions we introduce joint regression and triplet ranking loss functions. We show that, despite the sparse extrinsic rewards, by learning action representations we achieve a faster training convergence than state-of-the-art methods with only a small increase in the number of the model parameters.
ER  - 

TY  - CONF
TI  - Plug-and-Play: Improve Depth Prediction via Sparse Data Propagation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5880
EP  - 5886
AU  - T. Wang
AU  - F. Wang
AU  - J. Lin
AU  - Y. Tsai
AU  - W. Chiu
AU  - M. Sun
PY  - 2019
KW  - image colour analysis
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - optical radar
KW  - PnP module updates
KW  - intermediate feature map
KW  - sparse data propagation
KW  - RGB image
KW  - sparse LiDAR points
KW  - plug-and-play module
KW  - sparse depths
KW  - pretrained depth prediction model
KW  - dense depth map
KW  - Estimation
KW  - Training
KW  - Laser radar
KW  - Image reconstruction
KW  - Predictive models
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794404
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel plug-and-play (PnP) module for improving depth prediction with taking arbitrary patterns of sparse depths as input. Given any pre-trained depth prediction model, our PnP module updates the intermediate feature map such that the model outputs new depths consistent with the given sparse depths. Our method requires no additional training and can be applied to practical applications such as leveraging both RGB and sparse LiDAR points to robustly estimate dense depth map. Our approach achieves consistent improvements on various state-of-the-art methods on indoor (i.e., NYU-v2) and outdoor (i.e., KITTI) datasets. Various types of LiDARs are also synthesized in our experiments to verify the general applicability of our PnP module in practice.
ER  - 

TY  - CONF
TI  - DFNet: Semantic Segmentation on Panoramic Images with Dynamic Loss Weights and Residual Fusion Block
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5887
EP  - 5892
AU  - W. Jiang
AU  - Y. Wu
AU  - L. Guan
AU  - J. Zhao
PY  - 2019
KW  - feature extraction
KW  - image fusion
KW  - image segmentation
KW  - neural nets
KW  - object detection
KW  - roads
KW  - traffic engineering computing
KW  - visual perception
KW  - sight images
KW  - DFNet
KW  - dynamic loss weights
KW  - fusion layer
KW  - boundary information loss
KW  - semantic segmentation
KW  - automatic parking
KW  - lane markings
KW  - parking slots
KW  - pavement information
KW  - pixel multiplication
KW  - PSV dataset
KW  - residual fusion block
KW  - RFB
KW  - Image segmentation
KW  - Semantics
KW  - Feature extraction
KW  - Deep learning
KW  - Convolution
KW  - Training
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8794476
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For the domain of self-driving and automatic parking, perception is a basic and critical technique, moreover, the detection of lane markings and parking slots is an important part of visual perception. Compared with front sight images, panoramic images(PI) can capture more comprehensive pavement information. However, the imbalance of different classes in PI is even more serious. Additionally, the judgment of boundary information between areas is a hard problem in deep models. Therefore, we propose a new model named DFNet to solve these problems. The proposed model has two main contributions, one is dynamic loss weights, and the other is residual fusion block(RFB). DFNet use dynamic loss weights to overcome the negative effect of imbalance dataset, which are calculated according to the pixel number of each class in a batch. RFB is composed of several convolutional layers, a pooling layer, and a fusion layer to combine the feature maps by pixel multiplication, which can reduce boundary information loss. We evaluate our method on PSV dataset, and the achieved advanced results demonstrate the effectiveness of the proposed model.
ER  - 

TY  - CONF
TI  - Anytime Stereo Image Depth Estimation on Mobile Devices
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5893
EP  - 5900
AU  - Y. Wang
AU  - Z. Lai
AU  - G. Huang
AU  - B. H. Wang
AU  - L. van der Maaten
AU  - M. Campbell
AU  - K. Q. Weinberger
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile computing
KW  - stereo image processing
KW  - end-to-end learned approach
KW  - inference time
KW  - mobile devices
KW  - stereo depth estimation
KW  - memory-constrained devices
KW  - disparity prediction
KW  - disparity maps
KW  - computational constraints
KW  - stereo image depth estimation
KW  - NVIDIA Jetson TX2 module
KW  - AnyNet
KW  - Estimation
KW  - Image resolution
KW  - Feature extraction
KW  - Computational modeling
KW  - Three-dimensional displays
KW  - Cameras
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8794003
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Many applications of stereo depth estimation in robotics require the generation of accurate disparity maps in real time under significant computational constraints. Current state-of-the-art algorithms force a choice between either generating accurate mappings at a slow pace, or quickly generating inaccurate ones, and additionally these methods typically require far too many parameters to be usable on power- or memory-constrained devices. Motivated by these shortcomings, we propose a novel approach for disparity prediction in the anytime setting. In contrast to prior work, our end-to-end learned approach can trade off computation and accuracy at inference time. Depth estimation is performed in stages, during which the model can be queried at any time to output its current best estimate. Our final model can process 1242×375 resolution images within a range of 10-35 FPS on an NVIDIA Jetson TX2 module with only marginal increases in error - using two orders of magnitude fewer parameters than the most competitive baseline. The source code is available at https://github.com/mileyan/AnyNet.
ER  - 

TY  - CONF
TI  - Improved Generalization of Heading Direction Estimation for Aerial Filming Using Semi-Supervised Regression
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5901
EP  - 5907
AU  - W. Wang
AU  - A. Ahuja
AU  - Y. Zhang
AU  - R. Bonatti
AU  - S. Scherer
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cinematography
KW  - image sequences
KW  - regression analysis
KW  - robot vision
KW  - unsupervised learning
KW  - video signal processing
KW  - improved generalization
KW  - semisupervised regression
KW  - visual input
KW  - data distributions
KW  - semisupervised algorithm
KW  - generalization ability
KW  - autonomous aerial filming
KW  - heading direction estimation problem
KW  - temporal continuity
KW  - unsupervised signal
KW  - testing performance
KW  - unlabeled sequences
KW  - performance improvement
KW  - labeled loss
KW  - unlabeled loss
KW  - moving actor filming
KW  - Task analysis
KW  - Drones
KW  - Training
KW  - Estimation
KW  - Data models
KW  - Cameras
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8793994
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In the task of Autonomous aerial filming of a moving actor (e.g. a person or a vehicle), it is crucial to have a good heading direction estimation for the actor from the visual input. However, the models obtained in other similar tasks, such as pedestrian collision risk analysis and human-robot interaction, are very difficult to generalize to the aerial filming task, because of the difference in data distributions. Towards improving generalization with less amount of labeled data, this paper presents a semi-supervised algorithm for heading direction estimation problem. We utilize temporal continuity as the unsupervised signal to regularize the model and achieve better generalization ability. This semi-supervised algorithm is applied to both training and testing phases, which increases the testing performance by a large margin. We show that by leveraging unlabeled sequences, the amount of labeled data required can be significantly reduced. We also discuss several important details on improving the performance by balancing labeled and unlabeled loss, and making good combinations. Experimental results show that our approach robustly outputs the heading direction for different types of actor. The aesthetic value of the video is also improved in the aerial filming task.
ER  - 

TY  - CONF
TI  - Graduated Fidelity Lattices for Motion Planning under Uncertainty
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5908
EP  - 5914
AU  - A. González-Sieira
AU  - M. Mucientes
AU  - A. Bugarín
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - probability
KW  - robot shape
KW  - motion models
KW  - graduated fidelity lattices
KW  - motion planning
KW  - state lattice based approach
KW  - mobile robotics
KW  - motion uncertainty
KW  - multiresolution heuristic
KW  - collision probability
KW  - Uncertainty
KW  - Planning
KW  - Robots
KW  - Lattices
KW  - Collision avoidance
KW  - Shape
KW  - Probability density function
DO  - 10.1109/ICRA.2019.8794400
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we present a state lattice based approach for motion planning in mobile robotics. Sensing and motion uncertainty are managed at planning time to obtain safe and optimal paths. To do this reliably, our approach estimates the probability of collision taking into account the robot shape and the uncertainty in heading. We also introduce a novel graduated fidelity approach and a multi-resolution heuristic which adapt to the obstacles in the map, improving the planning efficiency while maintaining its performance. Results for different environments, shapes and motion models are reported, including experiments with real robots.
ER  - 

TY  - CONF
TI  - Non-Parametric Informed Exploration for Sampling-Based Motion Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5915
EP  - 5921
AU  - S. S. Joshi
AU  - T. Panagiotis
PY  - 2019
KW  - collision avoidance
KW  - path planning
KW  - sampling methods
KW  - search problems
KW  - effective sampling method
KW  - good initial solution
KW  - nonparametric exploration technique
KW  - nonparametric informed exploration
KW  - sampling-based motion planning
KW  - search space
KW  - Kernel
KW  - Planning
KW  - Heuristic algorithms
KW  - Sampling methods
KW  - Convergence
KW  - Search problems
KW  - Benchmark testing
DO  - 10.1109/ICRA.2019.8793933
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Efficient exploration of the search space is crucial for faster convergence in sampling-based motion planning. An effective sampling method must first concentrate on quickly finding a good initial solution and then focus the search on regions that can potentially improve the current best solution. In this paper, we propose a non-parametric exploration technique that addresses these challenges. The proposed algorithm prioritizes search by utilizing heuristics. After an initial solution is found, the method generates samples in the “$L_{2} -$informed set”, while leveraging collision data to reduce the number of samples in the obstacle space. We demonstrate the efficiency of the proposed approach with several benchmarking experiments.
ER  - 

TY  - CONF
TI  - Simulated Annealing-optimized Trajectory Planning within Non-Collision Nominal Intervals for Highway Autonomous Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5922
EP  - 5928
AU  - L. Claussmann
AU  - M. Revilloud
AU  - S. Glaser
PY  - 2019
KW  - acceleration control
KW  - collision avoidance
KW  - mobile robots
KW  - predictive control
KW  - road traffic control
KW  - simulated annealing
KW  - time-varying systems
KW  - trajectory control
KW  - sigmoid trajectory
KW  - collision-free intervals
KW  - nominal conditions
KW  - velocity-space representation
KW  - highway autonomous driving
KW  - near-optimal trajectory generation
KW  - autonomous vehicles
KW  - highways
KW  - predictive reference trajectory
KW  - free evolution space
KW  - pre-calculated set
KW  - candidate trajectories
KW  - decoupling path
KW  - velocity optimizations
KW  - multicriteria functions
KW  - decision evaluation function
KW  - trajectory generator
KW  - simulated annealing approach
KW  - noncollision nominal intervals
KW  - simulated annealing-optimized trajectory planning
KW  - Trajectory
KW  - Roads
KW  - Acceleration
KW  - Vehicle dynamics
KW  - Autonomous vehicles
KW  - Decision making
DO  - 10.1109/ICRA.2019.8793838
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This article considers the problem of near-optimal trajectory generation for autonomous vehicles on highways. The goal is to select a predictive reference trajectory in the free evolution space, while avoiding both generating a pre-calculated set of candidate trajectories and decoupling path and velocity optimizations. Moreover, this trajectory aims at optimizing a decision process based on multi-criteria functions, which are not straightforward to design and can have a blackbox formulation. The main idea of this article is to use the decision evaluation function in the trajectory generator with a Simulated Annealing (SA) approach. The parameters of a sigmoid trajectory are optimized within Non-Collision Nominal Intervals (NCNI), which are defined as collision-free intervals under nominal conditions using a velocity-space representation.
ER  - 

TY  - CONF
TI  - On the Impact of Uncertainty for Path Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5929
EP  - 5935
AU  - J. Guzzi
AU  - R. O. Chavez-Garcia
AU  - L. M. Gambardella
AU  - A. Giusti
PY  - 2019
KW  - graph theory
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - probability
KW  - travelling salesman problems
KW  - path planning
KW  - planning paths
KW  - uncertain edge
KW  - learned classifier
KW  - mobile robots
KW  - partially-known environments
KW  - simulation campaign
KW  - real-world maps
KW  - planning strategy
KW  - traversability estimates
KW  - Canadian traveller problem
KW  - Robot sensing systems
KW  - Navigation
KW  - Uncertainty
KW  - Path planning
KW  - Estimation
KW  - Optimized production technology
DO  - 10.1109/ICRA.2019.8793782
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of planning paths on graphs with some edges whose traversability is uncertain; for each uncertain edge, we are given a probability of being traversable (e.g., by a learned classifier). We categorize different interpretations of the problem that are meaningful for mobile robots navigating partially-known environments, each of which yields a different formalization; we then focus on the case in which the true traversability of an edge is revealed only when the agent visits one of its endpoints (Canadian Traveller Problem). In this context, we design a large simulation campaign on synthetic and real-world maps to study the impact of two different factors: the planning strategy, and the amount of uncertainty (which could depend on the quality of the classifier producing traversability estimates).
ER  - 

TY  - CONF
TI  - Localization with Sliding Window Factor Graphs on Third-Party Maps for Automated Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5951
EP  - 5957
AU  - D. Wilbers
AU  - C. Merfels
AU  - C. Stachniss
PY  - 2019
KW  - optimisation
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - position measurement
KW  - window factor graphs
KW  - third-party maps
KW  - robotic applications
KW  - window optimization
KW  - odometry measurements
KW  - fast vehicle localization
KW  - accurate vehicle localization
KW  - estimation problem
KW  - sliding window formulation
KW  - factor graph
KW  - landmark detections
KW  - automated car
KW  - automated driving applications
KW  - Microsoft Windows
KW  - Optimization
KW  - Simultaneous localization and mapping
KW  - Global navigation satellite system
KW  - Laser radar
KW  - Measurement uncertainty
DO  - 10.1109/ICRA.2019.8793971
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Localizing a vehicle in a map is essential for automated driving and various other robotic applications. This paper addresses the problem of vehicle localization in urban environments. Our approach performs a graph-based sliding window optimization over a set of recent landmark and odometry measurements for fast and accurate vehicle localization on third-party maps. Our work incorporates landmark priors from third-party maps into the estimation problem and shows how to exploit the sliding window formulation for revising data associations. We describe how to construct our factor graph and derive its necessary factors to model the information from the map as a prior over the landmark detections. We implemented our approach on an automated car and thoroughly tested it on real-world data. The experiments suggest that the approach provides highly accurate pose estimates, is fast enough for automated driving applications, and outperforms localization using particle filters.
ER  - 

TY  - CONF
TI  - Night-to-Day Image Translation for Retrieval-based Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5958
EP  - 5964
AU  - A. Anoosheh
AU  - T. Sattler
AU  - R. Timofte
AU  - M. Pollefeys
AU  - L. V. Gool
PY  - 2019
KW  - approximation theory
KW  - image retrieval
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - visual databases
KW  - geo-tagged images
KW  - night-to-day image translation
KW  - retrieval-based localization
KW  - visual localization
KW  - robotics pipelines
KW  - image retrieval techniques
KW  - database image retrieval
KW  - neural models
KW  - pose estimation
KW  - visual query photo
KW  - ToDayGAN
KW  - Task analysis
KW  - Visualization
KW  - Cameras
KW  - Feature extraction
KW  - Training
KW  - Generators
KW  - Data models
DO  - 10.1109/ICRA.2019.8794387
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual localization is a key step in many robotics pipelines, allowing the robot to (approximately) determine its position and orientation in the world. An efficient and scalable approach to visual localization is to use image retrieval techniques. These approaches identify the image most similar to a query photo in a database of geo-tagged images and approximate the query's pose via the pose of the retrieved database image. However, image retrieval across drastically different illumination conditions, e.g. day and night, is still a problem with unsatisfactory results, even in this age of powerful neural models. This is due to a lack of a suitably diverse dataset with true correspondences to perform end-to-end learning. A recent class of neural models allows for realistic translation of images among visual domains with relatively little training data and, most importantly, without ground-truth pairings.In this paper, we explore the task of accurately localizing images captured from two traversals of the same area in both day and night. We propose ToDayGAN - a modified image-translation model to alter nighttime driving images to a more useful daytime representation. We then compare the daytime and translated night images to obtain a pose estimate for the night image using the known 6-DOF position of the closest day image. Our approach improves localization performance by over 250% compared the current state-of-the-art, in the context of standard metrics in multiple categories.
ER  - 

TY  - CONF
TI  - Accurate and Efficient Self-Localization on Roads using Basic Geometric Primitives
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5965
EP  - 5971
AU  - J. Kümmerle
AU  - M. Sons
AU  - F. Poggenhans
AU  - T. Kühner
AU  - M. Lauer
AU  - C. Stiller
PY  - 2019
KW  - automobiles
KW  - distance measurement
KW  - graph theory
KW  - path planning
KW  - pose estimation
KW  - position control
KW  - road traffic control
KW  - localization update rate
KW  - roads
KW  - basic geometric primitives
KW  - behavior generation
KW  - distinctive signature
KW  - map elements
KW  - localization framework
KW  - next generation series cars
KW  - association measurement
KW  - odometry measurement
KW  - robust pose graph optimization
KW  - time 30.0 min
KW  - size 10.0 cm
KW  - frequency 50.0 Hz
KW  - Roads
KW  - Automobiles
KW  - Frequency modulation
KW  - Detectors
KW  - Global navigation satellite system
KW  - Feature extraction
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793497
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Highly accurate localization with very limited amount of memory and computational power is one of the big challenges for next generation series cars. We propose localization based on geometric primitives which are compact in representation and further valuable for other tasks like planning and behavior generation. The primitives lack distinctive signature which makes association between detections and map elements highly ambiguous. We resolve ambiguities early in the pipeline by online building up a local map which is key to runtime efficiency. Further, we introduce a new framework to fuse association and odometry measurements based on robust pose graph optimization.We evaluate our localization framework on over 30 min of data recorded in urban scenarios. Our map is memory efficient with less than 8 kB/km and we achieve high localization accuracy with a mean position error of less than 10 cm and a mean yaw angle error of less than 0. 25° at a localization update rate of 50Hz.
ER  - 

TY  - CONF
TI  - Efficient 2D-3D Matching for Multi-Camera Visual Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5972
EP  - 5978
AU  - M. Geppert
AU  - P. Liu
AU  - Z. Cui
AU  - M. Pollefeys
AU  - T. Sattler
PY  - 2019
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - image matching
KW  - motion estimation
KW  - pose estimation
KW  - autonomous driving
KW  - multicamera visual inertial localization algorithm
KW  - prioritized feature matching scheme
KW  - multicamera systems
KW  - monocular cameras
KW  - prioritization function
KW  - multicamera setup
KW  - matching efforts
KW  - pose priors
KW  - localization system
KW  - motion estimates
KW  - multicamera visual inertial odometry pipeline
KW  - large scale environments
KW  - pose estimation stages
KW  - pre-built global 3D map
KW  - Cameras
KW  - Three-dimensional displays
KW  - Pose estimation
KW  - Visualization
KW  - Feature extraction
KW  - Pipelines
KW  - Reliability
DO  - 10.1109/ICRA.2019.8794280
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual localization, i.e., determining the position and orientation of a vehicle with respect to a map, is a key problem in autonomous driving. We present a multi-camera visual inertial localization algorithm for large scale environments. To efficiently and effectively match features against a pre-built global 3D map, we propose a prioritized feature matching scheme for multi-camera systems. In contrast to existing works, designed for monocular cameras, we (1) tailor the prioritization function to the multi-camera setup and (2) run feature matching and pose estimation in parallel. This significantly accelerates the matching and pose estimation stages and allows us to dynamically adapt the matching efforts based on the surrounding environment. In addition, we show how pose priors can be integrated into the localization system to increase efficiency and robustness. Finally, we extend our algorithm by fusing the absolute pose estimates with motion estimates from a multi-camera visual inertial odometry pipeline (VIO). This results in a system that provides reliable and drift-less pose estimation. Extensive experiments show that our localization runs fast and robust under varying conditions, and that our extended algorithm enables reliable real-time pose estimation.
ER  - 

TY  - CONF
TI  - Localizing Discriminative Visual Landmarks for Place Recognition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5979
EP  - 5985
AU  - Z. Xin
AU  - Y. Cai
AU  - T. Lu
AU  - X. Xing
AU  - S. Cai
AU  - J. Zhang
AU  - Y. Yang
AU  - Y. Wang
PY  - 2019
KW  - computer vision
KW  - convolutional neural nets
KW  - feature extraction
KW  - image representation
KW  - object recognition
KW  - visual place recognition
KW  - perceptual changes
KW  - robust image representations
KW  - environmental changes
KW  - viewpoint changes
KW  - convolutional neural networks
KW  - landmark localization network
KW  - appearance changes
KW  - vegetations
KW  - buildings
KW  - similarity measurement
KW  - CNN
KW  - feature extraction
KW  - discriminative visual landmark localization
KW  - Visualization
KW  - Feature extraction
KW  - Training
KW  - Image recognition
KW  - Buildings
KW  - Task analysis
KW  - Measurement
DO  - 10.1109/ICRA.2019.8794383
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We address the problem of visual place recognition with perceptual changes. The fundamental problem of visual place recognition is generating robust image representations which are not only insensitive to environmental changes but also distinguishable to different places. Taking advantage of the feature extraction ability of Convolutional Neural Networks (CNNs), we further investigate how to localize discriminative visual landmarks that positively contribute to the similarity measurement, such as buildings and vegetations. In particular, a Landmark Localization Network (LLN) is designed to indicate which regions of an image are used for discrimination. Detailed experiments are conducted on open source datasets with varied appearance and viewpoint changes. The proposed approach achieves superior performance against state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Beyond Point Clouds: Fisher Information Field for Active Visual Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5986
EP  - 5992
AU  - Z. Zhang
AU  - D. Scaramuzza
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - point clouds
KW  - Fisher information field
KW  - active visual localization
KW  - mobile robots
KW  - perception requirement
KW  - planning stage
KW  - localization information
KW  - perception-aware planning
KW  - 3D landmarks
KW  - sensor visibility
KW  - Three-dimensional displays
KW  - Planning
KW  - Visualization
KW  - Cameras
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2019.8793680
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For mobile robots to localize robustly, actively considering the perception requirement at the planning stage is essential. In this paper, we propose a novel representation for active visual localization. By formulating the Fisher information and sensor visibility carefully, we are able to summarize the localization information into a discrete grid, namely the Fisher information field. The information for arbitrary poses can then be computed from the field in constant time, without the need of costly iterating all the 3D landmarks. Experimental results on simulated and real-world data show the great potential of our method in efficient active localization and perception-aware planning. To benefit related research, we release our implementation of the information field to the public.
ER  - 

TY  - CONF
TI  - Deep Reinforcement Learning of Navigation in a Complex and Crowded Environment with a Limited Field of View
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 5993
EP  - 6000
AU  - J. Choi
AU  - K. Park
AU  - M. Kim
AU  - S. Seok
PY  - 2019
KW  - cameras
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - neural nets
KW  - optical radar
KW  - path planning
KW  - robot vision
KW  - deep reinforcement learning-based methods
KW  - DRL agents
KW  - LSTM agent
KW  - Local-Map Critic
KW  - LSTM-LMC
KW  - wide FOV
KW  - single depth camera
KW  - mobile robots
KW  - lidar devices
KW  - DRL method
KW  - depth cameras
KW  - dynamics randomization technique
KW  - Navigation
KW  - Mobile robots
KW  - Reinforcement learning
KW  - Laser radar
KW  - Robot sensing systems
KW  - Cameras
DO  - 10.1109/ICRA.2019.8793979
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mobile robots are required to navigate freely in a complex and crowded environment in order to provide services to humans. For this navigation ability, deep reinforcement learning (DRL)-based methods are gaining increasing attentions. However, existing DRL methods require a wide field of view (FOV), which imposes the usage of high-cost lidar devices. In this paper, we explore the possibility of replacing expensive lidar devices with affordable depth cameras which have a limited FOV. First, we analyze the effect of a limited field of view in the DRL agents. Second, we propose a LSTM agent with Local-Map Critic (LSTM-LMC), which is a novel DRL method to learn efficient navigation in a complex environment with a limited FOV. Lastly, we introduce the dynamics randomization technique to improve the robustness of the DRL agents in the real world. We found that our method with a limited FOV can outperform the methods having a wide FOV but limited memory. We provide the empirical evidence that our method learns to implicitly model the surrounding environment and dynamics of other agents. We also show that a robot with a single depth camera can navigate through a complex real-world environment using our method.
ER  - 

TY  - CONF
TI  - Sim-to-Real Transfer Learning using Robustified Controllers in Robotic Tasks involving Complex Dynamics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6001
EP  - 6007
AU  - J. v. Baar
AU  - A. Sullivan
AU  - R. Cordorel
AU  - D. Jha
AU  - D. Romeres
AU  - D. Nikovski
PY  - 2019
KW  - learning (artificial intelligence)
KW  - robot dynamics
KW  - robust control
KW  - robustified controller
KW  - robotic tasks
KW  - complex dynamics
KW  - robot tasks
KW  - deep reinforcement learning
KW  - simulated environment
KW  - learned task
KW  - fine-tuning
KW  - simulation parameters
KW  - nontrivial task
KW  - nonrobustified controller
KW  - sim-to-real transfer learning
KW  - robustified controllers
KW  - Task analysis
KW  - Robots
KW  - Physics
KW  - Games
KW  - Reinforcement learning
KW  - Training
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793561
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning robot tasks or controllers using deep reinforcement learning has been proven effective in simulations. Learning in simulation has several advantages. For example, one can fully control the simulated environment, including halting motions while performing computations. Another advantage when robots are involved, is that the amount of time a robot is occupied learning a task-rather than being productive-can be reduced by transferring the learned task to the real robot. Transfer learning requires some amount of fine-tuning on the real robot. For tasks which involve complex (non-linear) dynamics, the fine-tuning itself may take a substantial amount of time. In order to reduce the amount of fine-tuning we propose to learn robustified controllers in simulation. Robustified controllers are learned by exploiting the ability to change simulation parameters (both appearance and dynamics) for successive training episodes. An additional benefit for this approach is that it alleviates the precise determination of physics parameters for the simulator, which is a non-trivial task. We demonstrate our proposed approach on a real setup in which a robot aims to solve a maze game, which involves complex dynamics due to static friction and potentially large accelerations. We show that the amount of fine-tuning in transfer learning for a robustified controller is substantially reduced compared to a non-robustified controller.
ER  - 

TY  - CONF
TI  - Generalization through Simulation: Integrating Simulated and Real Data into Deep Reinforcement Learning for Vision-Based Autonomous Flight
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6008
EP  - 6014
AU  - K. Kang
AU  - S. Belkhale
AU  - G. Kahn
AU  - P. Abbeel
AU  - S. Levine
PY  - 2019
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - data analysis
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - vision-based autonomous flight
KW  - fragile scale quadrotors
KW  - small-scale quadrotors
KW  - complex physics
KW  - air currents
KW  - hybrid deep reinforcement learning algorithm
KW  - generalizable perception system
KW  - nanoaerial vehicle collision avoidance task
KW  - real data
KW  - simulated data
KW  - Data models
KW  - Robots
KW  - Task analysis
KW  - Predictive models
KW  - Neural networks
KW  - Reinforcement learning
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793735
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deep reinforcement learning provides a promising approach for vision-based control of real-world robots. However, the generalization of such models depends critically on the quantity and variety of data available for training. This data can be difficult to obtain for some types of robotic systems, such as fragile, small-scale quadrotors. Simulated rendering and physics can provide for much larger datasets, but such data is inherently of lower quality: many of the phenomena that make the real-world autonomous flight problem challenging, such as complex physics and air currents, are modeled poorly or not at all, and the systematic differences between simulation and the real world are typically impossible to eliminate. In this work, we investigate how data from both simulation and the real world can be combined in a hybrid deep reinforcement learning algorithm. Our method uses real-world data to learn about the dynamics of the system, and simulated data to learn a generalizable perception system that can enable the robot to avoid collisions using only a monocular camera. We demonstrate our approach on a real-world nano aerial vehicle collision avoidance task, showing that with only an hour of real-world data, the quadrotor can avoid collisions in new environments with various lighting conditions and geometry. Code, instructions for building the aerial vehicles, and videos of the experiments can be found at github.com/gkahn13/GtS.
ER  - 

TY  - CONF
TI  - Crowd-Robot Interaction: Crowd-Aware Robot Navigation With Attention-Based Deep Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6015
EP  - 6022
AU  - C. Chen
AU  - Y. Liu
AU  - S. Kreiss
AU  - A. Alahi
PY  - 2019
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - pedestrians
KW  - crowded spaces
KW  - Human-Human interactions
KW  - deep reinforcement learning framework
KW  - dense crowds
KW  - human dynamics
KW  - crowd-aware robot navigation
KW  - attention-based deep reinforcement learning
KW  - robot operations
KW  - crowd-robot interaction
KW  - Robots
KW  - Navigation
KW  - Reinforcement learning
KW  - Planning
KW  - Task analysis
KW  - Human-robot interaction
KW  - Biological system modeling
DO  - 10.1109/ICRA.2019.8794134
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mobility in an effective and socially-compliant manner is an essential yet challenging task for robots operating in crowded spaces. Recent works have shown the power of deep reinforcement learning techniques to learn socially cooperative policies. However, their cooperation ability deteriorates as the crowd grows since they typically relax the problem as a one-way Human-Robot interaction problem. In this work, we want to go beyond first-order Human-Robot interaction and more explicitly model Crowd-Robot Interaction (CRI). We propose to (i) rethink pairwise interactions with a self-attention mechanism, and (ii) jointly model Human-Robot as well as Human-Human interactions in the deep reinforcement learning framework. Our model captures the Human-Human interactions occurring in dense crowds that indirectly affects the robot's anticipation capability. Our proposed attentive pooling mechanism learns the collective importance of neighboring humans with respect to their future states. Various experiments demonstrate that our model can anticipate human dynamics and navigate in crowds with time efficiency, outperforming state-of-the-art methods.
ER  - 

TY  - CONF
TI  - Residual Reinforcement Learning for Robot Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6023
EP  - 6029
AU  - T. Johannink
AU  - S. Bahl
AU  - A. Nair
AU  - J. Luo
AU  - A. Kumar
AU  - M. Loskyll
AU  - J. A. Ojea
AU  - E. Solowjow
AU  - S. Levine
PY  - 2019
KW  - continuous systems
KW  - control system synthesis
KW  - feedback
KW  - friction
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mechanical contact
KW  - motion control
KW  - robot dynamics
KW  - first-order physical modeling
KW  - brittle controllers
KW  - inaccurate controllers
KW  - reinforcement learning methods
KW  - continuous robot controllers
KW  - control signals
KW  - robot control problems
KW  - modern manufacturing
KW  - control design
KW  - feedback control methods
KW  - control policy
KW  - residual reinforcement learning
KW  - rigid body equations of motion
KW  - contacts
KW  - friction
KW  - robot learning
KW  - unstable objects
KW  - block assembly task
KW  - Robots
KW  - Task analysis
KW  - Feedback control
KW  - Reinforcement learning
KW  - Mathematical model
KW  - Manufacturing
KW  - Adaptive control
DO  - 10.1109/ICRA.2019.8794127
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Conventional feedback control methods can solve various types of robot control problems very efficiently by capturing the structure with explicit models, such as rigid body equations of motion. However, many control problems in modern manufacturing deal with contacts and friction, which are difficult to capture with first-order physical modeling. Hence, applying control design methodologies to these kinds of problems often results in brittle and inaccurate controllers, which have to be manually tuned for deployment. Reinforcement learning (RL) methods have been demonstrated to be capable of learning continuous robot controllers from interactions with the environment, even for problems that include friction and contacts. In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals. We demonstrate our approach by training an agent to successfully perform a real-world block assembly task involving contacts and unstable objects.
ER  - 

TY  - CONF
TI  - A Reinforcement Learning Approach for Control of a Nature-Inspired Aerial Vehicle
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6030
EP  - 6036
AU  - D. Sufiyan
AU  - L. T. S. Win
AU  - S. K. H. Win
AU  - G. S. Soh
AU  - S. Foong
PY  - 2019
KW  - autonomous aerial vehicles
KW  - function approximation
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - position control
KW  - three-term control
KW  - nature-inspired aerial vehicle
KW  - position controller
KW  - UAV
KW  - fixed-wing aircraft
KW  - neural network function approximators
KW  - reinforcement learning agent
KW  - learned controller
KW  - deep deterministic policy gradients
KW  - PID controller
KW  - Ape-X distributed prioritized experience replay
KW  - multi-rotors
KW  - underactuated nature-inspired unmanned aerial vehicle
KW  - body contrary
KW  - Training
KW  - Aerodynamics
KW  - Neural networks
KW  - Mathematical model
KW  - Reinforcement learning
KW  - Drag
KW  - Prototypes
DO  - 10.1109/ICRA.2019.8794446
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, reinforcement learning is used to develop a position controller for an underactuated nature-inspired Unmanned Aerial Vehicle (UAV). This particular configuration of UAVs achieves lift by spinning its entire body contrary to standard multi-rotors or fixed-wing aircraft. Deep Deterministic Policy Gradients (DDPG) with Ape-X Distributed Prioritized Experience Replay was used to train neural network function approximators that were implemented as the final control policy. The reinforcement learning agent was trained in simulations and directly ported over to real-life hardware. Position control tests were performed on the learned control policy and compared to a baseline PID controller. The learned controller was found to exhibit better control over the inherent oscillations that arise from the non-linear dynamics of the platform.
ER  - 

TY  - CONF
TI  - Formal Policy Learning from Demonstrations for Reachability Properties
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6037
EP  - 6043
AU  - H. Ravanbakhsh
AU  - S. Sankaranarayanan
AU  - S. A. Seshia
PY  - 2019
KW  - closed loop systems
KW  - feedback
KW  - learning (artificial intelligence)
KW  - predictive control
KW  - reachability analysis
KW  - formal behavioral specifications
KW  - counterexample-guided iterative loop
KW  - receding horizon model-predictive controllers
KW  - demonstrator actions
KW  - formally-verified policies
KW  - formal policy learning from demonstrations
KW  - reachability properties
KW  - structured closed-loop policies
KW  - MPC
KW  - cost-to-go function
KW  - Robots
KW  - Trajectory
KW  - Training data
KW  - Predictive models
KW  - Real-time systems
KW  - Measurement
DO  - 10.1109/ICRA.2019.8793828
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of learning structured, closed-loop policies (feedback laws) from demonstrations in order to control under-actuated robotic systems, so that formal behavioral specifications such as reaching a target set of states are satisfied. Our approach uses a “counterexample-guided” iterative loop that involves the interaction between a policy learner, a demonstrator and a verifier. The learner is responsible for querying the demonstrator in order to obtain the training data to guide the construction of a policy candidate. This candidate is analyzed by the verifier and either accepted as correct, or rejected with a counterexample. In the latter case, the counterexample is used to update the training data and further refine the policy.The approach is instantiated using receding horizon model-predictive controllers (MPCs) as demonstrators. Rather than using regression to fit a policy to the demonstrator actions, we extend the MPC formulation with the gradient of the cost-to-go function evaluated at sample states in order to constrain the set of policies compatible with the behavior of the demonstrator. We demonstrate the successful application of the resulting policy learning schemes on two case studies and we show how simple, formally-verified policies can be inferred starting from a complex and unverified nonlinear MPC implementations. As a further benefit, the policies are many orders of magnitude faster to implement when compared to the original MPCs.
ER  - 

TY  - CONF
TI  - Formalized Task Characterization for Human-Robot Autonomy Allocation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6044
EP  - 6050
AU  - M. Young
AU  - C. Miller
AU  - Y. Bi
AU  - W. Chen
AU  - B. D. Argall
PY  - 2019
KW  - design of experiments
KW  - human-robot interaction
KW  - multi-robot systems
KW  - Taguchi methods
KW  - task characterization
KW  - human-robot autonomy allocation
KW  - human-robot teams
KW  - conjoint analysis
KW  - rotational features
KW  - translational features
KW  - autonomy assistance
KW  - robotic arm
KW  - kinematic features
KW  - Task analysis
KW  - Kinematics
KW  - Complexity theory
KW  - Manipulators
KW  - Feature extraction
KW  - Service robots
DO  - 10.1109/ICRA.2019.8793475
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humans and robots team together to perform tasks in various domains. Some tasks are easier to perform than others, but little work focuses on discovering the underlying mechanisms that affect perceived difficulty and task performance. To fill this gap, we propose a formalized approach to task characterization for human-robot teams using Taguchi design of experiments and conjoint analysis. With this, we conduct a 20 person study where participants operate a 6 degree of freedom robotic arm to perform manipulations defined by 6 kinematic features. We find that rotational features of a task contribute significantly more to decreased performance and increased difficulty than translational features. The participants also perform the activities with autonomy assistance. The data shows a reduction in the effect of these features on performance and difficulty when assistance is active. Furthermore, we examine when to trigger assistance based on thresholds set from outlier detection. The analysis indicates that rotational features and features leading to kinematic singularities are useful for triggering assistance.
ER  - 

TY  - CONF
TI  - DoS-Resilient Multi-Robot Temporal Logic Motion Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6051
EP  - 6057
AU  - X. Sun
AU  - R. Nambiar
AU  - M. Melhorn
AU  - Y. Shoukry
AU  - P. Nuzzo
PY  - 2019
KW  - convex programming
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - robot dynamics
KW  - robust control
KW  - temporal logic
KW  - DoS-resilient multirobot temporal logic motion planning
KW  - multirobot motion
KW  - linear temporal logic specifications
KW  - denial-of-service attacks
KW  - robot trajectories
KW  - DoS attacks
KW  - DoS-free workspace
KW  - DoS-resilient mission constraints
KW  - robot dynamics
KW  - DoS-resilient plans
KW  - satisfiability modulo convex programming
KW  - Base stations
KW  - Planning
KW  - Trajectory
KW  - Robot kinematics
KW  - Jamming
KW  - Radar
DO  - 10.1109/ICRA.2019.8794477
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose an efficient multi-robot motion planning algorithm for missions captured by linear temporal logic (LTL) specifications, in the presence of bounded disturbances and denial-of-service (DoS) attacks against the communication between robots and base stations. Given an LTL formula Ψ, our goal is to construct robot trajectories, and associated control strategies, to satisfy Ψ and continuously establish communication paths between robots and base stations despite the DoS attacks and the disturbances on the robot states. Our approach combines and extends results from robust control and efficient motion planning via satisfiability modulo convex programming (SMC). We first compute a feedback controller that rejects the disturbance together with a perturbation of the DoS-free workspace that accounts for the worst-case disturbance scenario. On the perturbed workspace, we formulate the planning problem as a feasibility problem over Boolean and convex constraints, respectively capturing the DoS-resilient mission constraints and the constraints on the nominal, disturbance-free, robot dynamics. Numerical results show the effectiveness of our algorithm in providing DoS-resilient plans that are robust to disturbances and support the execution of complex missions.
ER  - 

TY  - CONF
TI  - Task-Based Design of Ad-hoc Modular Manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6058
EP  - 6064
AU  - T. Campos
AU  - J. P. Inala
AU  - A. Solar-Lezama
AU  - H. Kress-Gazit
PY  - 2019
KW  - control system synthesis
KW  - genetic algorithms
KW  - manipulators
KW  - demand robots
KW  - modular robots
KW  - task description
KW  - degree-of-freedom modules
KW  - task-based design
KW  - ad-hoc modular manipulators
KW  - genetic algorithm
KW  - Task analysis
KW  - Manipulators
KW  - Trajectory
KW  - Actuators
KW  - Genetic algorithms
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794171
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The great promise of modular robots is the ability to create on demand robots; however, choosing the “right” design based on a task is still a challenging problem. In this paper, we present an approach to automatically synthesize both the design and control for modular robots from a task description. In particular, we focus on manipulators composed of one degree-of-freedom (DoF) modules. Our approach is able to handle partially infeasible tasks by either identifying the infeasible part and finding a design that satisfies the feasible part or searching for multiple designs that together satisfy the entire task. We compare our approach to a baseline genetic algorithm in a series of increasingly complex environments.
ER  - 

TY  - CONF
TI  - SweepNet: Wide-baseline Omnidirectional Depth Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6073
EP  - 6079
AU  - C. Won
AU  - J. Ryu
AU  - J. Lim
PY  - 2019
KW  - calibration
KW  - cameras
KW  - image reconstruction
KW  - image sensors
KW  - lenses
KW  - neural nets
KW  - object recognition
KW  - robot vision
KW  - stereo image processing
KW  - multiple sets
KW  - rectified images
KW  - dense omnidirectional depth map
KW  - rig global coordinate system
KW  - warped images
KW  - final depth map
KW  - aggregated cost volume
KW  - deep neural network
KW  - conventional depth estimation methods
KW  - highly accurate depth maps
KW  - wide-baseline omnidirectional depth estimation
KW  - omnidirectional depth sensing
KW  - conventional stereo systems
KW  - blind regions
KW  - novel wide-baseline omnidirectional stereo algorithm
KW  - dense depth estimate
KW  - fisheye images
KW  - deep convolutional neural network
KW  - capture system
KW  - multiple cameras
KW  - wide-baseline rig
KW  - ultra-wide field
KW  - view lenses
KW  - calibration algorithm
KW  - Cameras
KW  - Lenses
KW  - Calibration
KW  - Neural networks
KW  - Three-dimensional displays
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793823
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Omnidirectional depth sensing has its advantage over the conventional stereo systems since it enables us to recognize the objects of interest in all directions without any blind regions. In this paper, we propose a novel wide-baseline omnidirectional stereo algorithm which computes the dense depth estimate from the fisheye images using a deep convolutional neural network. The capture system consists of multiple cameras mounted on a wide-baseline rig with ultra-wide field of view (FOV) lenses, and we present the calibration algorithm for the extrinsic parameters based on the bundle adjustment. Instead of estimating depth maps from multiple sets of rectified images and stitching them, our approach directly generates one dense omnidirectional depth map with full 360° coverage at the rig global coordinate system. To this end, the proposed neural network is designed to output the cost volume from the warped images in the sphere sweeping method, and the final depth map is estimated by taking the minimum cost indices of the aggregated cost volume by SGM. For training the deep neural network and testing the entire system, realistic synthetic urban datasets are rendered using Blender. The experiments using the synthetic and real-world datasets show that our algorithm outperforms the conventional depth estimation methods and generate highly accurate depth maps.
ER  - 

TY  - CONF
TI  - 3D Surface Reconstruction Using A Two-Step Stereo Matching Method Assisted with Five Projected Patterns
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6080
EP  - 6086
AU  - C. Sui
AU  - K. He
AU  - C. Lyu
AU  - Z. Wang
AU  - Y. Liu
PY  - 2019
KW  - correlation methods
KW  - image matching
KW  - image reconstruction
KW  - image resolution
KW  - robot vision
KW  - solid modelling
KW  - stereo image processing
KW  - surface reconstruction
KW  - three-dimensional vision
KW  - 3D surface reconstruction scheme
KW  - stereo matching pattern projection
KW  - stereo images
KW  - phase maps
KW  - phase-shifting patterns
KW  - image acquisition time
KW  - correspondence refinement algorithm
KW  - high-resolution reconstruction
KW  - object reconstruction
KW  - two-step stereo matching method
KW  - Three-dimensional displays
KW  - Image reconstruction
KW  - Surface reconstruction
KW  - Cameras
KW  - Robots
KW  - Pattern matching
KW  - Robustness
DO  - 10.1109/ICRA.2019.8794063
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Three-dimensional vision plays an important role in robotics. In this paper, we present a 3D surface reconstruction scheme based on combination of stereo matching and pattern projection. A two-step matching scheme is proposed to establish reliable correspondence between stereo images with high computation efficiency and accuracy. The first step (coarse matching) can quickly find the correlation candidates, and the second step (precise matching) is responsible for determining the most precise correspondence within the candidates. Two phase maps serve as codewords and are utilized in the two-step stereo matching, respectively. The phase maps are derived from phase-shifting patterns to provide robustness to the background noises. Only five patterns are required, which reduces the image acquisition time. Moreover, the precision is further enhanced by applying a correspondence refinement algorithm. The precision and accuracy are validated by experiments on standard objects. Furthermore, various experiments are conducted to verify the capability of the proposed method, which includes the complex object reconstruction, the high-resolution reconstruction, and the occlusion avoidance. The real-time experimental results are also provided.
ER  - 

TY  - CONF
TI  - Real-Time Dense Mapping for Self-Driving Vehicles using Fisheye Cameras
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6087
EP  - 6093
AU  - Z. Cui
AU  - L. Heng
AU  - Y. C. Yeo
AU  - A. Geiger
AU  - M. Pollefeys
AU  - T. Sattler
PY  - 2019
KW  - cameras
KW  - image capture
KW  - image fusion
KW  - image resolution
KW  - image sensors
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - stereo image processing
KW  - visual perception
KW  - fisheye cameras
KW  - real-time dense geometric mapping algorithm
KW  - pinhole cameras
KW  - visual-inertial odometry
KW  - visual localization
KW  - vision-only 3D scene perception
KW  - depth map
KW  - reference camera
KW  - plane-sweeping stereo
KW  - fast object detection framework
KW  - YOLOv3
KW  - fisheye depth images
KW  - computer vision applications
KW  - angular resolution
KW  - image resolutions
KW  - in-vehicle PC
KW  - truncated signed distance function
KW  - TSDF volume
KW  - 3D map
KW  - self-driving vehicles
KW  - Cameras
KW  - Three-dimensional displays
KW  - Real-time systems
KW  - Image resolution
KW  - Vehicle dynamics
KW  - Estimation
KW  - Object detection
DO  - 10.1109/ICRA.2019.8793884
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a real-time dense geometric mapping algorithm for large-scale environments. Unlike existing methods which use pinhole cameras, our implementation is based on fisheye cameras whose large field of view benefits various computer vision applications for self-driving vehicles such as visual-inertial odometry, visual localization, and object detection. Our algorithm runs on in-vehicle PCs at approximately 15 Hz, enabling vision-only 3D scene perception for self-driving vehicles. For each synchronized set of images captured by multiple cameras, we first compute a depth map for a reference camera using plane-sweeping stereo. To maintain both accuracy and efficiency, while accounting for the fact that fisheye images have a lower angular resolution, we recover the depths using multiple image resolutions. We adopt the fast object detection framework, YOLOv3, to remove potentially dynamic objects. At the end of the pipeline, we fuse the fisheye depth images into the truncated signed distance function (TSDF) volume to obtain a 3D map. We evaluate our method on large-scale urban datasets, and results show that our method works well in complex dynamic environments.
ER  - 

TY  - CONF
TI  - Tightly-Coupled Aided Inertial Navigation with Point and Plane Features
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6094
EP  - 6100
AU  - Y. Yang
AU  - P. Geneva
AU  - X. Zuo
AU  - K. Eckenhoff
AU  - Y. Liu
AU  - G. Huang
PY  - 2019
KW  - feature extraction
KW  - image fusion
KW  - image sensors
KW  - inertial navigation
KW  - mobile robots
KW  - Monte Carlo methods
KW  - object tracking
KW  - SLAM (robots)
KW  - planar point features
KW  - nonplanar point features
KW  - point-on-plane constraints
KW  - effective plane feature initialization algorithm
KW  - depth sensor
KW  - general sensor fusion framework
KW  - point feature tracking
KW  - plane extraction
KW  - geometrical structures
KW  - closest point
KW  - plane parameterization
KW  - Monte-Carlo simulations
KW  - visual sensor
KW  - tightly-coupled aided inertial navigation system
KW  - feature-based simultaneous localization and mapping
KW  - Feature extraction
KW  - Cameras
KW  - Calibration
KW  - Laser radar
KW  - Jacobian matrices
KW  - Simultaneous localization and mapping
KW  - Estimation
DO  - 10.1109/ICRA.2019.8794078
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a tightly-coupled aided inertial navigation system (INS) with point and plane features, a general sensor fusion framework applicable to any visual and depth sensor (e.g., RGBD, LiDAR) configuration, in which the camera is used for point feature tracking and depth sensor for plane extraction. The proposed system exploits geometrical structures (planes) of the environments and adopts the closest point (CP) for plane parameterization. Moreover, we distinguish planar point features from non-planar point features in order to enforce point-on-plane constraints which are used in our state estimator, thus further exploiting structural information from the environment. We also introduce a simple but effective plane feature initialization algorithm for feature-based simultaneous localization and mapping (SLAM). In addition, we perform online spatial calibration between the IMU and the depth sensor as it is difficult to obtain this critical calibration parameter in high precision. Both Monte-Carlo simulations and real-world experiments are performed to validate the proposed approach.
ER  - 

TY  - CONF
TI  - FastDepth: Fast Monocular Depth Estimation on Embedded Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6101
EP  - 6108
AU  - D. Wofk
AU  - F. Ma
AU  - T. Yang
AU  - S. Karaman
AU  - V. Sze
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cameras
KW  - computational complexity
KW  - embedded systems
KW  - estimation theory
KW  - image colour analysis
KW  - image segmentation
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - microrobots
KW  - mobile robots
KW  - neural nets
KW  - object detection
KW  - robot vision
KW  - low-latency decoder
KW  - NYU Depth v2 dataset
KW  - real-time monocular depth estimation
KW  - deep neural network
KW  - embedded platform
KW  - microaerial vehicle
KW  - embedded systems
KW  - robotic tasks
KW  - obstacle detection
KW  - single RGB image
KW  - monocular cameras
KW  - lightweight encoder-decoder network architecture
KW  - computational complexity
KW  - FastDepth
KW  - fast monocular depth estimation
KW  - depth sensing
KW  - deep neural networks
KW  - Estimation
KW  - Decoding
KW  - Neural networks
KW  - Runtime
KW  - Convolution
KW  - Complexity theory
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794182
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Depth sensing is a critical function for robotic tasks such as localization, mapping and obstacle detection. There has been a significant and growing interest in depth estimation from a single RGB image, due to the relatively low cost and size of monocular cameras. However, state-of-the-art single-view depth estimation algorithms are based on fairly complex deep neural networks that are too slow for real-time inference on an embedded platform, for instance, mounted on a micro aerial vehicle. In this paper, we address the problem of fast depth estimation on embedded systems. We propose an efficient and lightweight encoder-decoder network architecture and apply network pruning to further reduce computational complexity and latency. In particular, we focus on the design of a low-latency decoder. Our methodology demonstrates that it is possible to achieve similar accuracy as prior work on depth estimation, but at inference speeds that are an order of magnitude faster. Our proposed network, FastDepth, runs at 178 fps on an NVIDIA Jetson TX2 GPU and at 27 fps when using only the TX2 CPU, with active power consumption under 10 W. FastDepth achieves close to state-of-the-art accuracy on the NYU Depth v2 dataset. To the best of the authors' knowledge, this paper demonstrates real-time monocular depth estimation using a deep neural network with the lowest latency and highest throughput on an embedded platform that can be carried by a micro aerial vehicle.
ER  - 

TY  - CONF
TI  - Sliding Mode Momentum Observers for Estimation of External Torques and Joint Acceleration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6117
EP  - 6123
AU  - G. Garofalo
AU  - N. Mansfeld
AU  - J. Jankowski
AU  - C. Ott
PY  - 2019
KW  - collision avoidance
KW  - end effectors
KW  - human-robot interaction
KW  - observers
KW  - torque control
KW  - variable structure systems
KW  - external torques
KW  - joint acceleration
KW  - external wrenches
KW  - robot structure
KW  - human-robot interaction
KW  - momentum dynamics
KW  - classic momentum observer
KW  - reaction strategies
KW  - sliding mode momentum observers
KW  - control loop
KW  - proprioceptive sensors
KW  - first-order filtered version
KW  - finite-time convergence
KW  - Observers
KW  - Robots
KW  - Collision avoidance
KW  - Torque
KW  - Convergence
KW  - Noise measurement
DO  - 10.1109/ICRA.2019.8793529
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Interactions between robots and their environment give rise to external wrenches acting on the robot structure. The estimation of the resulting torques in the joints is fundamental in human-robot interaction to detect/identify collisions and perform suitable reaction strategies. Other applications may require to use the estimation for compensating the effects of the external torques within the control loop. The well-established momentum observer, which relies on proprioceptive sensors only, is usually used for these purposes. In this work, the momentum dynamics is used to derive new observers. While the classic momentum observer provides a first-order filtered version of the external torques, here a (theoretically) finite-time convergence is achieved. Simulations and experiments are used to validate the performance of the proposed methods.
ER  - 

TY  - CONF
TI  - Discrete Layer Jamming for Safe Co-Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6124
EP  - 6129
AU  - Y. Zhou
AU  - L. M. Headings
AU  - M. J. Dapino
PY  - 2019
KW  - beams (structures)
KW  - bending
KW  - clamps
KW  - elasticity
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - mechanical testing
KW  - multi-robot systems
KW  - pneumatic actuators
KW  - position control
KW  - safe co-robots
KW  - stiff robot arm
KW  - robot systems
KW  - safe interaction
KW  - tunable stiffness mechanism
KW  - discrete layer jamming mechanism
KW  - robot link
KW  - multiple clamps
KW  - safer human-robot interaction
KW  - discrete layer jamming beam
KW  - injury severity
KW  - clamping pressure
KW  - pneumatic layer jamming
KW  - positioning performance
KW  - payload capacity
KW  - dynamic actuators
KW  - ABS laminates
KW  - aluminum clamps
KW  - stiffness tests
KW  - bending stiffness
KW  - pressure 0.0 MPa to 1.0 MPa
KW  - Clamps
KW  - Robots
KW  - Jamming
KW  - Laminates
KW  - Force
KW  - Friction
KW  - Safety
DO  - 10.1109/ICRA.2019.8793908
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - High injury severity occurs when a stiff robot arm hits an operator. Introducing compliance into robot systems reduces the impact and enables safe interaction, but at the expense of positioning performance and payload capacity. This paper presents a tunable stiffness mechanism for safe human-robot interaction based on discrete layer jamming. The proposed design of a discrete layer jamming mechanism is a robot link made of multiple thin layers of ABS and multiple clamps. By applying high clamping pressure to the laminates, the link behaves like a rigid link; reducing the clamping pressure softens the link which yields safer human-robot interaction. Compared to conventional pneumatic layer jamming, discrete layer jamming allows for simplicity of installation with dynamic actuators, faster control, greater portability since no air supply is needed, and no sealing issues. To validate the concept, this paper investigates a discrete layer jamming beam made of ten ABS laminates and two aluminum clamps that cover 10% of the surface of the beam. Stiffness tests have been performed, showing that around 17 times bending stiffness change is achieved by increasing the clamping pressure of two clamps from 0 to 1 MPa.
ER  - 

TY  - CONF
TI  - Admittance Control for Human-Robot Interaction Using an Industrial Robot Equipped with a F/T Sensor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6130
EP  - 6136
AU  - E. Mariotti
AU  - E. Magrini
AU  - A. D. Luca
PY  - 2019
KW  - end effectors
KW  - force sensors
KW  - human-robot interaction
KW  - industrial manipulators
KW  - manipulator kinematics
KW  - closed control architecture
KW  - robot dynamics
KW  - low-level joint controllers
KW  - kinematic information
KW  - admittance control law
KW  - whole-body collision detection
KW  - KUKA KR5 Sixx R650 robot
KW  - industrial robot
KW  - physical human-robot interaction
KW  - torque sensors
KW  - pHRI strategy
KW  - end-effector
KW  - force/torque sensor
KW  - ATI F/T sensor
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Service robots
KW  - Collaboration
KW  - End effectors
KW  - Current measurement
DO  - 10.1109/ICRA.2019.8793657
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an approach to safe physical Human-Robot Interaction (pHRI) for industrial robots, including collision detection, distinguishing accidental from intentional contacts, and achieving collaborative tasks. Typical industrial robots have a closed control architecture that accepts only velocity/position reference inputs, there are no joint torque sensors, and little or no information is available to the user on robot dynamics and on low-level joint controllers. Nonetheless, taking also advantage of the presence of a Force/Torque (F/T) sensor at the end-effector, a safe pHRI strategy based on kinematic information, on measurements from joint encoders and motor currents, and on end-effector forces/torques can be realized. An admittance control law has been implemented for collaboration in manual guidance mode, with whole-body collision detection in place both when the robot is in autonomous operation and when is simultaneously collaborating with a human. Several pHRI experiments validate the approach on a KUKA KR5 Sixx R650 robot equipped with an ATI F/T sensor.
ER  - 

TY  - CONF
TI  - Effect of Mechanical Resistance on Cognitive Conflict in Physical Human-Robot Collaboration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6137
EP  - 6143
AU  - S. Aldini
AU  - A. Akella
AU  - A. K. Singh
AU  - Y. Wang
AU  - M. Carmichael
AU  - D. Liu
AU  - C. Lin
PY  - 2019
KW  - bioelectric potentials
KW  - cognition
KW  - electroencephalography
KW  - human-robot interaction
KW  - medical signal processing
KW  - cognitive conflict
KW  - pHRC
KW  - PEN
KW  - mechanical resistance
KW  - conflict level
KW  - human operator
KW  - direct contact
KW  - intuitiveness
KW  - prediction error negativity
KW  - negative deflection
KW  - event related potential
KW  - physical human-robot collaboration
KW  - Robots
KW  - Task analysis
KW  - Immune system
KW  - Electroencephalography
KW  - Force
KW  - Collaboration
DO  - 10.1109/ICRA.2019.8793748
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Physical Human-Robot Collaboration (pHRC) is about the interaction between one or more human operator(s) and one or more robot(s) in direct contact and voluntarily exchanging forces to accomplish a common task. In any pHRC, the intuitiveness of the interaction has always been a priority, so that the operator can comfortably and safely interact with the robot. So far, the intuitiveness has always been described in a qualitative way. In this paper, we suggest an objective way to evaluate intuitiveness, known as prediction error negativity (PEN) using electroencephalogram (EEG). PEN is defined as a negative deflection in event related potential (ERP) due to cognitive conflict, as a consequence of a mismatch between perception and reality. Experimental results showed that the forces exchanged between robot and human during pHRC modulate the amplitude of PEN, representing different levels of cognitive conflict. We also found that PEN amplitude significantly decreases (p <; 0.05) when a mechanical resistance is being applied smoothly and more time in advance before an invisible obstacle, when compared to a scenario in which the resistance is applied abruptly before the obstacle. These results indicate that an earlier and smoother resistance reduces the conflict level. Consequently, this suggests that smoother changes in resistance make the interaction more intuitive.
ER  - 

TY  - CONF
TI  - Lifelong Learning for Heterogeneous Multi-Modal Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6158
EP  - 6164
AU  - H. Liu
AU  - F. Sun
AU  - B. Fang
PY  - 2019
KW  - learning (artificial intelligence)
KW  - pattern classification
KW  - heterogeneous modalities
KW  - learned classifier
KW  - multimodal task
KW  - multimodal lifelong learning framework
KW  - consecutive multimodal learning tasks
KW  - multimodal lifelong learning problem
KW  - heterogeneous multimodal tasks
KW  - heterogeneous multimodal fusion
KW  - material recognition task
KW  - online dictionary learning algorithm
KW  - Task analysis
KW  - Dictionaries
KW  - Knowledge based systems
KW  - Machine learning
KW  - Encoding
KW  - Optimization
KW  - Robots
DO  - 10.1109/ICRA.2019.8793517
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we investigate the lifelong learning problem from the viewpoint of heterogeneous multi-modal fusion. The main challenges come from the fact that the common representation between heterogeneous modalities should be persistently learned and the learned classifier for each multi-modal task should be persistently updated. To address this problem, we construct a multi-modal lifelong learning framework which deals with the consecutive multi-modal learning tasks and develop an efficient online dictionary learning algorithm to solve the multi-modal lifelong learning problem. Finally, we perform experimental validation on a complicated material recognition task and show the promising results.
ER  - 

TY  - CONF
TI  - Magnetic-Field-Inspired Navigation for Quadcopter Robot in Unknown Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6165
EP  - 6171
AU  - A. Ataka
AU  - H. K. Lam
AU  - K. Althoefer
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - control engineering computing
KW  - helicopters
KW  - mobile robots
KW  - navigation
KW  - robot vision
KW  - flying robots
KW  - local sensory information
KW  - quadcopter robot
KW  - magnetic-field-inspired robot navigation
KW  - under-actuated quad-copter
KW  - arbitrary-shaped convex obstacles
KW  - magnetic field interaction
KW  - reactive navigation algorithms
KW  - unknown environments
KW  - motion commands
KW  - local minima configurations
KW  - dynamic model
KW  - commercial AscTec Pelican microaerial vehicle
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Navigation
KW  - Wires
KW  - Force
DO  - 10.1109/ICRA.2019.8793682
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, a magnetic-field-inspired robot navigation is used to navigate an under-actuated quad-copter towards the desired position amidst previously-unknown arbitrary-shaped convex obstacles. Taking inspiration from the phenomena of magnetic field interaction with charged particles observed in nature, the algorithm outperforms previous reactive navigation algorithms for flying robots found in the literature as it is able to reactively generate motion commands relying only on a local sensory information without prior knowledge of the obstacles' shape or location and without getting trapped in local minima configurations. The application of the algorithm in a dynamic model of quadcopter system and in the realistic model of the commercial AscTec Pelican micro-aerial vehicle confirm the superior performance of the algorithm.
ER  - 

TY  - CONF
TI  - Human-Care Rounds Robot with Contactless Breathing Measurement
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6172
EP  - 6177
AU  - R. Saegusa
AU  - H. Ito
AU  - D. M. Duong
PY  - 2019
KW  - biomedical measurement
KW  - handicapped aids
KW  - health care
KW  - human-robot interaction
KW  - medical robotics
KW  - mobile robots
KW  - patient care
KW  - pneumodynamics
KW  - robot vision
KW  - physical support
KW  - care staffs
KW  - medical facilities
KW  - vision-based contactless breathing measurement system
KW  - human detection
KW  - nursing facility
KW  - human measurement system
KW  - autonomous rounds robot
KW  - breathing measurement system
KW  - human-care rounds robot
KW  - three-dimensional shape
KW  - thermal information
KW  - Lucia robot
KW  - body postures
KW  - Robot kinematics
KW  - Machine vision
KW  - Monitoring
KW  - Medical services
KW  - Cameras
KW  - Frequency-domain analysis
DO  - 10.1109/ICRA.2019.8794037
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes a human measurement system for autonomous rounds robot aiming in physical support of care staffs working in nursing and medical facilities. We propose a novel scheme of vision-based contactless breathing measurement system that integrates three-dimensional shape and thermal information of the target person. We developed the human-care rounds robot Lucia and implemented the measurement system on the robot. We then evaluated the human detection and breathing measurement based on the conditions of real incident cases that occurred in the nursing facility for the physically handicapped. In the experiments, we examined that the breathing measurement system successfully measured volume variation of human subjects with different configurations of body postures. The robot is also capable of discrimination between the breathing and non-breathing states of targets based on the difference in the power spectrum patterns in the frequency domain. The experimental results showed that the proposed system detected the presence of breathing within the accuracy of about 90% or more, and moreover, the ability of anomaly detection in breathing was suggested.
ER  - 

TY  - CONF
TI  - An Improved Control-Oriented Modeling of the Magnetic Field
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6178
EP  - 6184
AU  - M. Etiévant
AU  - A. Bolopion
AU  - S. Régnier
AU  - N. Andreff
PY  - 2019
KW  - closed loop systems
KW  - coils
KW  - interpolation
KW  - magnetic fields
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - control-oriented model
KW  - coil
KW  - untethered microscale mobile robotics
KW  - elliptic integral functions
KW  - magnetically actuated microrobots
KW  - map-based interpolation
KW  - computation time
KW  - closed-loop control
KW  - dipole approximation
KW  - Magnetic domains
KW  - Computational modeling
KW  - Magnetic hysteresis
KW  - Soft magnetic materials
KW  - Numerical models
KW  - Robots
KW  - Magnetic cores
DO  - 10.1109/ICRA.2019.8793679
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a new control-oriented model to compute the magnetic field created by a coil. A major challenge for untethered microscale mobile robotics is the control of objects for precise and fast displacements. In this work, we propose to use an alternative implementation of a model based on elliptic integral functions to control magnetically actuated micro-robots. It allows to compute the magnetic field even in the area close to the coil quickly and accurately. This model is evaluated numerically and compared to classical approaches - dipole approximation, map-based interpolation and classical elliptic integral models - in terms of accuracy, computation time and memory requirement. Simulation results show that this works allows to have an accurate model in the whole workspace by avoiding numerical issues encountered in previous works. It can be computed in a few milliseconds, making it the right candidate for closed-loop control of magnetically actuated micro-robots.
ER  - 

TY  - CONF
TI  - Efficient Micro Waveguide Coupling based on Microrobotic Positioning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6185
EP  - 6190
AU  - P. Wang
AU  - D. Li
AU  - H. Lu
AU  - Y. Yang
AU  - S. Shen
AU  - Y. Shen
PY  - 2019
KW  - fuzzy control
KW  - integrated optics
KW  - micro-optics
KW  - microrobots
KW  - optical fibre couplers
KW  - optical microscopy
KW  - path planning
KW  - fuzzy controller
KW  - degrees of freedoms
KW  - microwaveguide coupling
KW  - path planning strategy
KW  - integrated optical component
KW  - optical fiber
KW  - micromanufacture field
KW  - traditional manual method
KW  - optical microscopy
KW  - microrobotic positioning system
KW  - light intensity feedback
KW  - commercial optoelectronic devices
KW  - optical devices
KW  - time 40.0 s
KW  - Couplings
KW  - Optical fibers
KW  - Optical fiber sensors
KW  - Optical distortion
DO  - 10.1109/ICRA.2019.8794444
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Coupling the endface of an optical fiber to an integrated optical component is currently a low-throughput and costly manual process in the fabrication of the optical devices. In order to meet the high-volume demand for commercial optoelectronic devices, coupling must be automated. This paper presents a robotic positioning system and corresponding path planning strategy based on both the position and light intensity feedback. In this work, a micro-robotic positioning system with 3 degrees of freedoms (DOFs) is developed and integrated with an optical microscopy. Then the fuzzy controller is developed to design the trajectory. Lastly, simulation and experimental results demonstrate the accuracy and efficiency of the proposed system. Compared with the traditional manual method, the robotic positioning system can realize the coupling within 40 seconds. This method will have a significant impact on the automatic process of the micro manufacture field.
ER  - 

TY  - CONF
TI  - Assembly of Multilayered Hepatic Lobule-like Vascular Network by using Heptapole Magnetic Tweezer
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6200
EP  - 6205
AU  - E. Kim
AU  - M. Takeuchi
AU  - T. Kozuka
AU  - T. Nomura
AU  - A. Hasegawa
AU  - A. Ichikawa
AU  - Q. Huang
AU  - T. Fukuda
PY  - 2019
KW  - biomedical materials
KW  - blood
KW  - blood vessels
KW  - cellular biophysics
KW  - hydrogels
KW  - liver
KW  - multilayers
KW  - steel
KW  - rat liver cells
KW  - fibrin gel
KW  - cell viability
KW  - cellular structure
KW  - 3D channel network
KW  - magnetic tweezer
KW  - magnetic fields
KW  - central veins
KW  - portal veins
KW  - hepatic lobule tissue
KW  - magnetic hydrogel fibers
KW  - multilayered channel system
KW  - cell-laden hydrogels
KW  - heptapole magnetic tweezer
KW  - multilayered hepatic lobule-like vascular network
KW  - steel rods
KW  - Steel
KW  - Three-dimensional displays
KW  - Optical fiber networks
KW  - Veins
KW  - Magnetic flux
KW  - Magnetic fields
KW  - Magnetic multilayers
DO  - 10.1109/ICRA.2019.8794210
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we have fabricated a multilayered hepatic lobule-like vascular network in a 3D tissue using a heptapole magnetic tweezer. The tissue consists of cell-laden hydrogels with 3D channel networks. To fabricate multilayered channel system, magnetic hydrogel fibers were manipulated by a magnetic tweezer. The hepatic lobule tissue shows a hexagonal structure with different sizes of veins. Six portal veins transfer the blood including nutrients and oxygen to a central vein by sinusoids. The portal and central veins are made by steel rods, whereas the magnetic hydrogel fibers has a role of sinusoids. An important point of this research is to connect two veins - portal and central vein - by magnetic fibers. For this, we used magnetic tweezer with seven poles to magnetize the steel rods. In order to generate high magnetic fields, we design magnetic tweezer with a flat tip and additional lower tweezer based on simulation data. The manipulation was performed in fibrin gel inside rat liver cells. By applying high magnetic fields, we attracted magnetic fibers to the steel rods and constructed 3D channel network in cellular structure. To verify the efficiency of the channel, we supply culture medium to the channel and then analyze the cell viability according to the distance from the channel. As a result, the cells located at close to the channel show higher cell viability than others.
ER  - 

TY  - CONF
TI  - Sizing the aortic annulus with a robotised, commercially available soft balloon catheter: in vitro study on idealised phantoms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6230
EP  - 6236
AU  - A. Palombi
AU  - G. M. Bosi
AU  - S. D. Giuseppe
AU  - E. De Momi
AU  - S. Homer-Vanniasinkam
AU  - G. Burriesci
AU  - H. A. Wurdemann
PY  - 2019
KW  - blood vessels
KW  - cardiology
KW  - catheters
KW  - diseases
KW  - iterative methods
KW  - medical robotics
KW  - phantoms
KW  - prosthetics
KW  - surgery
KW  - intraballoon pressure
KW  - soft balloon catheter
KW  - heart valve diseases
KW  - linear regression
KW  - iterative method
KW  - pressure-volume data
KW  - idealised aortic phantoms
KW  - balloon free inflation
KW  - inflation device
KW  - robotised valvuloplasty balloon catheter
KW  - cardiac electrical signal
KW  - prosthetic valve leakage
KW  - implanted prosthetic valve
KW  - aortic heart valve diseases
KW  - minimally invasive surgical technique
KW  - transcatheter aortic valve implantation
KW  - aortic annulus
KW  - Valves
KW  - Catheters
KW  - Prosthetics
KW  - Robots
KW  - Three-dimensional displays
KW  - Geometry
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8794041
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Transcatheter aortic valve implantation (TAVI) is a minimally invasive surgical technique to treat aortic heart valve diseases. According to current clinical guidelines, the implanted prosthetic valve replacing the native one is selected based on pre-operative size assessment of the aortic annulus through different imaging techniques. That very often leads to suboptimal device selection resulting in major complications, such as prosthetic valve leakage or interruption of the cardiac electrical signal. In this paper, we propose a new, intra-operative approach to determine the diameter of theaortic annulus exploiting intra-balloon pressure and volume data, acquired from a robotised valvuloplasty balloon catheter. An inflation device, capable of collecting real-time intra-balloon pressure and volume data, was designed and interfaced with a commercially available valvuloplasty balloon catheter. A sizing algorithm allowing to precisely estimate the annular diameter was integrated. The algorithm relies on a characterised analytical model of the balloon free inflation and an iterative method based on linear regression. In vitro tests were performed on idealised aortic phantoms. Experimental results show that pressure-volume data can be used to determine annular diameters bigger than the unstretched diameter of the balloon catheter. For these cases, the proposed approach exhibited good precision (maximum average error 0.93%) and good repeatability (maximum standard deviation ±0.11 mm).
ER  - 

TY  - CONF
TI  - Miniature Robotic Tubes with Rotational Tip-Joints as a Medical Delivery Platform
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6237
EP  - 6243
AU  - R. Karthikeyan
AU  - S. Pattanshetti
AU  - S. C. Ryu
PY  - 2019
KW  - controllability
KW  - hinges
KW  - medical robotics
KW  - motion control
KW  - needles
KW  - position control
KW  - robot kinematics
KW  - surgery
KW  - miniature robotic tubes
KW  - rotational tip-joints
KW  - medical delivery platform
KW  - medical-needle-sized robotic tube
KW  - instrument tip
KW  - two-axis laser micromachining
KW  - direct tip controllability
KW  - human body
KW  - hinged instrument
KW  - flexure joints
KW  - shorter joint length
KW  - compact articulation
KW  - joint strength
KW  - lateral directions
KW  - robust delivery platform
KW  - hinge rotation
KW  - instrumented prototype
KW  - laser beam
KW  - fine angle control
KW  - kinematic model
KW  - tip motion control
KW  - Fasteners
KW  - Joints
KW  - Robots
KW  - Instruments
KW  - Electron tubes
KW  - Kinematics
KW  - Tendons
DO  - 10.1109/ICRA.2019.8794391
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a medical-needle-sized robotic tube with multi-degrees of freedom (M-DOF) rotational hinge joints at the instrument tip, fabricated by two-axis laser micro-machining. Due to the presence of an ample working channel and direct tip controllability, this tube is a potential candidate for the precise delivery of radioactive seeds, probes and micro-forceps to regions of interest within the human body. In this paper, the advantages of the proposed hinged instrument are studied in contrast with that of flexure joints, which include-fine angle control (posability), and a shorter joint length that enables compact articulation. In addition, the joint strength both in the axial and lateral directions was experimentally investigated to demonstrate its feasibility as a robust delivery platform. Further, the intuitive nature of hinge rotation permits the use of a simple kinematic model for accurate tip motion control, under fewer simplifying assumptions than flexure joints which are impeded by material non-linearity and geometric discontinuities. An instrumented prototype was used to test this model by delivering a laser beam along a prescribed path (synonymous to simple ablation tasks). The observed RMS position error for the projected beam was ~0.364 mm.
ER  - 

TY  - CONF
TI  - Nonlinear System Identification of Soft Robot Dynamics Using Koopman Operator Theory
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6244
EP  - 6250
AU  - D. Bruder
AU  - C. D. Remy
AU  - R. Vasudevan
PY  - 2019
KW  - autoregressive processes
KW  - identification
KW  - learning (artificial intelligence)
KW  - mean square error methods
KW  - mobile robots
KW  - neural nets
KW  - nonlinear control systems
KW  - nonlinear dynamical systems
KW  - pneumatic actuators
KW  - regression analysis
KW  - robot dynamics
KW  - state-space methods
KW  - soft robot dynamics
KW  - Koopman operator theory
KW  - large-scale data collection
KW  - system identification method
KW  - nonlinear dynamical systems
KW  - linear regression
KW  - linear representation
KW  - infinite-dimensional space
KW  - nonlinear system identification methods
KW  - dynamic model
KW  - pneumatic soft robot arm
KW  - linear state space model
KW  - nonlinear Hammerstein-Wiener model
KW  - neural network
KW  - total normalized-root-mean-square error
KW  - NRMSE
KW  - Soft robotics
KW  - Nonlinear dynamical systems
KW  - Predictive models
KW  - Linear regression
KW  - Data models
KW  - Tuning
DO  - 10.1109/ICRA.2019.8793766
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robots are challenging to model due in large part to the nonlinear properties of soft materials. Fortunately, this softness makes it possible to safely observe their behavior under random control inputs, making them amenable to large-scale data collection and system identification. This paper implements and evaluates a system identification method based on Koopman operator theory in which models of nonlinear dynamical systems are constructed via linear regression of observed data by exploiting the fact that every nonlinear system has a linear representation in the infinite-dimensional space of real-valued functions called observables. The approach does not suffer from some of the shortcomings of other nonlinear system identification methods, which typically require the manual tuning of training parameters and have limited convergence guarantees. A dynamic model of a pneumatic soft robot arm is constructed via this method, and used to predict the behavior of the real system. The total normalized-root-mean-square error (NRMSE) of its predictions is lower than that of several other identified models including a neural network, NLARX, nonlinear Hammerstein-Wiener, and linear state space model.
ER  - 

TY  - CONF
TI  - Data Driven Inverse Kinematics of Soft Robots using Local Models
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6251
EP  - 6257
AU  - F. Holsten
AU  - M. P. Engell-Nørregård
AU  - S. Darkner
AU  - K. Erleben
PY  - 2019
KW  - computational complexity
KW  - data visualisation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - robot kinematics
KW  - data driven inverse kinematics
KW  - soft robot
KW  - computational approaches
KW  - data quantity
KW  - memory complexity
KW  - time complexity
KW  - actuation system
KW  - visual markers
KW  - motion planning
KW  - motion control
KW  - learning cube environment
KW  - Shape
KW  - Soft robotics
KW  - Sensors
KW  - Kinematics
KW  - Calibration
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794191
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robots are advantageous in terms of flexibility, safety and adaptability. It is challenging to find efficient computational approaches for planning and controlling their motion. This work takes a direct data-driven approach to learn the kinematics of the three-dimensional shape of a soft robot, by using visual markers. No prior information about the robot at hand is required. The model is oblivious to the design of the robot and type of actuation system. This allows adaptation to erroneous manufacturing. We present a highly versatile and inexpensive learning cube environment for collecting and analysing data. We prove that using multiple, lower order models of data opposed to one global, higher order model, will reduce the required data quantity, time complexity and memory complexity significantly without compromising accuracy. Further, our approach allows for embarrassingly parallelism. Yielding an overall much more simple and efficient approach.
ER  - 

TY  - CONF
TI  - Modal Dynamics and Analysis of a Vertical Stretch-Retractable Continuum Manipulator with Large Deflection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6258
EP  - 6264
AU  - H. Wang
AU  - G. Gao
AU  - Q. Xia
AU  - X. Zhang
PY  - 2019
KW  - beams (structures)
KW  - bending
KW  - dynamic response
KW  - elasticity
KW  - integral equations
KW  - manipulator dynamics
KW  - vibrations
KW  - vertical stretch-retractable continuum manipulator
KW  - backbone continuum manipulator
KW  - deformation modal properties
KW  - tip horizontal load
KW  - elastic bending potential energy
KW  - free dynamic response
KW  - modal dynamic models
KW  - static model
KW  - vibration modal characteristics
KW  - equivalent-guided beam
KW  - frequency properties
KW  - elliptic integral approach
KW  - Manipulator dynamics
KW  - Analytical models
KW  - Potential energy
KW  - Shape
KW  - Dynamics
KW  - Force
DO  - 10.1109/ICRA.2019.8794172
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Efficient and reliable dynamic modelling and analysis is critical to the shape control and estimate of a backbone continuum manipulator. This paper presents a novel dynamic modelling method to investigate the deformation modal properties of a vertical stretch-retractable continuum manipulator (VSRCM) under the tip horizontal load. Based on the equivalence of the elastic bending potential energy, this method simplifies the backbone continuum manipulator to a single beam, an equivalent-guided beam (EGB). One end of the EGB is fixed, and the other end is guided. The modal dynamics model of the EGB is then established by employing the vibration theory of a continuous beam, and the modal properties of the continuum manipulator are analyzed. Static and Dynamic experiments of the VSRCM are performed to validate the dynamic modeling method through the comparison and analysis of the free dynamic response and frequency properties of the continuum manipulator. To analyze the free dynamic response, the large deflection static model with tip horizontal load is also established based on the elliptic integral approach. Experimental results and comparison demonstrate that the static model is efficient and precise to predict the large deformation, and the modal dynamic models well reflect the actual vibration modal characteristics of the VSRCM.
ER  - 

TY  - CONF
TI  - ChainQueen: A Real-Time Differentiable Physical Simulator for Soft Robotics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6265
EP  - 6271
AU  - Y. Hu
AU  - J. Liu
AU  - A. Spielberg
AU  - J. B. Tenenbaum
AU  - W. T. Freeman
AU  - J. Wu
AU  - D. Rus
AU  - W. Matusik
PY  - 2019
KW  - deformation
KW  - elasticity
KW  - gradient methods
KW  - inverse problems
KW  - least squares approximations
KW  - manipulator dynamics
KW  - mobile robots
KW  - multi-robot systems
KW  - optimal control
KW  - optimisation
KW  - path planning
KW  - ChainQueen
KW  - real-time differentiable physical simulator
KW  - robot planning
KW  - gradient-based optimization algorithms
KW  - inverse problems
KW  - optimal control
KW  - motion planning
KW  - rigid body simulators
KW  - deformable objects
KW  - rigid body dynamics
KW  - Lagrangian-Eulerian physical simulator
KW  - MLS-MPM
KW  - soft robotic systems
KW  - forward simulation
KW  - backward gradient computation
KW  - moving least squares material point method
KW  - Graphics processing units
KW  - Computational modeling
KW  - Soft robotics
KW  - Three-dimensional displays
KW  - Planning
KW  - Inverse problems
DO  - 10.1109/ICRA.2019.8794333
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Physical simulators have been widely used in robot planning and control. Among them, differentiable simulators are particularly favored, as they can be incorporated into gradient-based optimization algorithms that are efficient in solving inverse problems such as optimal control and motion planning. Therefore, rigid body simulators and recently their differentiable variants are studied extensively. Simulating deformable objects is, however, more challenging compared to rigid body dynamics. The underlying physical laws of deformable objects are more complex, and the resulting systems have orders of magnitude more degrees of freedom and there-fore they are significantly more computationally expensive to simulate. Computing gradients with respect to physical design or controller parameters is typically even more computationally challenging. In this paper, we propose a real-time, differentiable hybrid Lagrangian-Eulerian physical simulator for deformable objects, ChainQueen, based on the Moving Least Squares Material Point Method (MLS-MPM). MLS-MPM can simulate deformable objects with collisions and can be seamlessly incorporated into soft robotic systems. We demonstrate that our simulator achieves high precision in both forward simulation and backward gradient computation. We have successfully employed it in a diverse set of inference, control and co-design tasks for soft robotics.
ER  - 

TY  - CONF
TI  - A Validated Physical Model For Real-Time Simulation of Soft Robotic Snakes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6272
EP  - 6279
AU  - R. Gasoto
AU  - M. Macklin
AU  - X. Liu
AU  - Y. Sun
AU  - K. Erleben
AU  - C. Onal
AU  - J. Fu
PY  - 2019
KW  - actuators
KW  - biomimetics
KW  - closed loop systems
KW  - deformation
KW  - legged locomotion
KW  - pneumatic actuators
KW  - robot dynamics
KW  - constraint-based dynamics model
KW  - multiphysics environment
KW  - soft robotic actuators
KW  - real-time simulation
KW  - validated physical model
KW  - real-time performance
KW  - dynamic locomotion open-loop control experiments
KW  - multiple 1D actuators
KW  - soft robotic snake
KW  - internal pressure forces
KW  - 1-dimensional pneumatic soft actuator
KW  - Actuators
KW  - Deformable models
KW  - Soft robotics
KW  - Strain
KW  - Finite element analysis
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8794375
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we present a framework that is capable of accurately representing soft robotic actuators in a multiphysics environment in real-time. We propose a constraint-based dynamics model of a 1-dimensional pneumatic soft actuator that accounts for internal pressure forces, as well as the effect of actuator latency and damping under inflation and deflation and demonstrate its accuracy a full soft robotic snake with the composition of multiple 1D actuators. We verify our model's accuracy in static deformation and dynamic locomotion open-loop control experiments. To achieve real-time performance we leverage the parallel computation power of GPUs to allow interactive control and feedback.
ER  - 

TY  - CONF
TI  - SpaceBok: A Dynamic Legged Robot for Space Exploration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6288
EP  - 6294
AU  - P. Arm
AU  - R. Zenkl
AU  - P. Barton
AU  - L. Beglinger
AU  - A. Dietsche
AU  - L. Ferrazzini
AU  - E. Hampp
AU  - J. Hinder
AU  - C. Huber
AU  - D. Schaufelberger
AU  - F. Schmitt
AU  - B. Sun
AU  - B. Stolz
AU  - H. Kolvenbach
AU  - M. Hutter
PY  - 2019
KW  - aerospace robotics
KW  - force control
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - SpaceBok
KW  - dynamic legged robot
KW  - space exploration
KW  - quadrupedal robot
KW  - dynamic legged locomotion
KW  - parallel elastic elements
KW  - high-torque brushless motors
KW  - force control
KW  - walking velocity
KW  - planetary gear transmissions
KW  - optimized parallel motion
KW  - jumping maneuvers
KW  - Legged locomotion
KW  - Hip
KW  - Actuators
KW  - Gravity
KW  - Torque
KW  - Foot
DO  - 10.1109/ICRA.2019.8794136
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces SpaceBok, a quadrupedal robot created to investigate dynamic legged locomotion for the exploration of low-gravity celestial bodies. With a hip height of 500 mm and a mass of 20 kg, its dimensions are comparable to a medium-sized dog. The robot's leg configuration is based on an optimized parallel motion mechanism that allows the integration of parallel elastic elements to store and release energy for powerful jumping maneuvers. High-torque brushless motors in combination with customized single-stage planetary gear transmissions enable force control at the foot contact points based on motor currents. We present successful walking, trotting, and pronking experiments. Thereby, Spacebok achieved maximal jump heights in single jump experiments of up to 1.05 m (more than twice the hip height) and a walking velocity of 1m/s. Moreover, simulation results for low gravity on the moon suggest that our robot can move with up to 1.1m/s at an approximate cost of transport of 1 in moon gravity when using the pronking gait.
ER  - 

TY  - CONF
TI  - Mini Cheetah: A Platform for Pushing the Limits of Dynamic Quadruped Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6295
EP  - 6301
AU  - B. Katz
AU  - J. D. Carlo
AU  - S. Kim
PY  - 2019
KW  - force control
KW  - legged locomotion
KW  - motion control
KW  - nonlinear control systems
KW  - optimisation
KW  - predictive control
KW  - robot dynamics
KW  - Mini Cheetah
KW  - powerful robot
KW  - mechanically robust quadruped robot
KW  - control systems
KW  - legged robots
KW  - custom backdriveable modular actuators
KW  - high-bandwidth force control
KW  - high force density
KW  - dynamic trot
KW  - dynamic quadruped control
KW  - convex model-predictive control
KW  - cMPC
KW  - offline nonlinear optimization
KW  - size 0.3 m
KW  - mass 9.0 kg
KW  - Actuators
KW  - Legged locomotion
KW  - Torque
KW  - Bandwidth
KW  - Knee
KW  - Torque control
DO  - 10.1109/ICRA.2019.8793865
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mini Cheetah is a small and inexpensive, yet powerful and mechanically robust quadruped robot, intended to enable rapid development of control systems for legged robots. The robot uses custom backdriveable modular actuators, which enable high-bandwidth force control, high force density, and robustness to impacts. Standing around 0.3 m tall and weighing 9 kg, Mini Cheetah can easily be handled by a single operator. We have demonstrated dynamic trot, trot-run, bounding, and pronking gaits on the robot to speeds of up to 2.45 meters per second using Convex Model-Predictive Control (cMPC). In addition to locomotion, we have used the robot to execute 360° backflips, with trajectories generated using offline nonlinear optimization.
ER  - 

TY  - CONF
TI  - Optimal Leg Sequencing for a Hexapod Subject to External Forces and Slopes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6302
EP  - 6308
AU  - G. Rekleitis
AU  - M. Vidakis
AU  - E. Papadopoulos
PY  - 2019
KW  - force control
KW  - gait analysis
KW  - legged locomotion
KW  - stability
KW  - hexapod subject
KW  - optimal leg sequence selection method
KW  - hexapod robot stability
KW  - terrain slope
KW  - stable leg sequence
KW  - search method
KW  - force-angle stability margin criterion
KW  - Legged locomotion
KW  - Stability criteria
KW  - Robot sensing systems
KW  - Foot
DO  - 10.1109/ICRA.2019.8793826
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - An optimal leg sequence selection method is developed, which maximizes hexapod robot stability, considering feasible gaits, motion modes, and terrain slope. A novel and fast search method is employed to find the most stable leg sequence for a given gait; if no such sequence exists, the next fastest stable gait is chosen and the most stable leg sequence for this gait is selected. The method can be based on any stability measure; here the Force-Angle Stability Margin criterion is employed that is sensitive to top-heaviness, and inertial and external forces. Results show that the developed method senses instabilities accurately and selects the best leg sequence for maximum stability far faster than exhaustive searches, offering distinct advantages when varied external forces are applied.
ER  - 

TY  - CONF
TI  - Stanford Doggo: An Open-Source, Quasi-Direct-Drive Quadruped
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6309
EP  - 6315
AU  - N. Kau
AU  - A. Schultz
AU  - N. Ferrante
AU  - P. Slade
PY  - 2019
KW  - legged locomotion
KW  - robot dynamics
KW  - robot kinematics
KW  - legged robots
KW  - quasidirect-drive quadruped
KW  - open-source
KW  - quasidirect-drive design methodology
KW  - performing animal
KW  - average vertical speed
KW  - vertical jumping agility
KW  - common performance metrics
KW  - dynamic locomotion
KW  - Stanford Doggo
KW  - Legged locomotion
KW  - Torque
KW  - Force
KW  - Measurement
KW  - Robot sensing systems
KW  - Foot
DO  - 10.1109/ICRA.2019.8794436
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents Stanford Doggo, a quasi-direct-drive quadruped capable of dynamic locomotion. This robot matches or exceeds common performance metrics of state-of-the-art legged robots. In terms of vertical jumping agility, a measure of average vertical speed, Stanford Doggo matches the best performing animal and surpasses the previous best robot by 22%. An overall design architecture is presented with focus on our quasi-direct-drive design methodology. The hardware and software to replicate this robot is open-source, requires only hand tools for manufacturing and assembly, and costs less than $3000.
ER  - 

TY  - CONF
TI  - Workspace CPG with Body Pose Control for Stable, Directed Vision during Omnidirectional Locomotion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6316
EP  - 6322
AU  - S. Shaw
AU  - G. Sartoretti
AU  - J. Olkin
AU  - W. Paivine
AU  - H. Choset
PY  - 2019
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - vision system
KW  - DOF
KW  - central pattern generator
KW  - degree-of-freedom
KW  - gaze orientation
KW  - body velocity
KW  - path planning
KW  - legged robot
KW  - omnidirectional locomotion
KW  - hexapod robot
KW  - CPG framework
KW  - body pose control
KW  - robot body
KW  - Foot
KW  - Machine vision
KW  - Legged locomotion
KW  - Trajectory
KW  - Transforms
KW  - Phase change materials
DO  - 10.1109/ICRA.2019.8794313
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we focus on the problem of directing the gaze of a vision system mounted to the body of a high-degree-of-freedom (DOF) legged robot for active perception deployments. In particular, we consider the case where the vision system is rigidly attached to the robot's body (i.e., without any additional DOF between the vision system and robot body) and show how the supernumerary DOFs of the robot can be leveraged to allow independent locomotion and gaze control. Specifically, we augment a workspace central pattern generator (CPG) with omnidirectional capabilities by coupling it with a body pose control mechanism. We leverage the smoothing nature of the CPG framework to allow online adaptation of relevant locomotion parameters, and obtain a stable mid-level controller that translates desired gaze orientation and body velocity directly into joint angles. We validate our approach on an 18-DOF hexapod robot, in a series of indoor and outdoor trials, where the robot inspects an environmental feature or follows a pre-planned path relative to a visually-tracked landmark, demonstrating simultaneous locomotion and directed vision.
ER  - 

TY  - CONF
TI  - Robotic Forceps without Position Sensors using Visual SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6331
EP  - 6336
AU  - T. Iwai
AU  - T. Kanno
AU  - T. Miyazaki
AU  - T. Kawase
AU  - K. Kawashima
PY  - 2019
KW  - cameras
KW  - mobile robots
KW  - position control
KW  - robot vision
KW  - servomechanisms
KW  - SLAM (robots)
KW  - visual servoing
KW  - robotic forceps
KW  - position sensors
KW  - visual SLAM
KW  - wrist joint
KW  - joint angle sensing
KW  - rear end
KW  - rear joint
KW  - parallel linkage
KW  - monocular camera
KW  - position sensing
KW  - joint angles
KW  - visual servo system
KW  - static experiments
KW  - dynamic positioning experiments
KW  - visual servoing system
KW  - forceps tip
KW  - Cameras
KW  - Robot vision systems
KW  - Visualization
KW  - Gravity
DO  - 10.1109/ICRA.2019.8794321
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this study, a robotic forceps with a wrist joint using visual SLAM for joint angle sensing was developed. The forceps has a flexible joint connected to the wrist joint at its rear end and the motion of the rear joint is driven by a parallel linkage. A monocular camera attached on the rear of the parallel linkage is in charge of position sensing, and the joint angles are estimated from the pose of the camera. The pose of the camera is obtained by a visual SLAM. The visual servo system realizes a simple attaching mechanism. The static and dynamic positioning experiments are conducted. We confirmed that the visual servoing system controls the forceps tip within the error of 3 deg in the motion range of 50 deg.
ER  - 

TY  - CONF
TI  - 3D Keypoint Repeatability for Heterogeneous Multi-Robot SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6337
EP  - 6343
AU  - E. R. Boroson
AU  - N. Ayanian
PY  - 2019
KW  - feature extraction
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - SLAM (robots)
KW  - point cloud registration
KW  - loop closure
KW  - heterogenous multirobot SLAM applications
KW  - NARF detector
KW  - 3D keypoint repeatability
KW  - heterogeneous multirobot SLAM
KW  - multirobot SLAM scenario
KW  - sensor measurement point clouds
KW  - point density
KW  - 3D keypoint detectors
KW  - multirobot SLAM system
KW  - KPQ-SI
KW  - relative repeatability
KW  - Three-dimensional displays
KW  - Detectors
KW  - Simultaneous localization and mapping
KW  - Cameras
KW  - Laser radar
DO  - 10.1109/ICRA.2019.8793609
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For robots with different types of sensors, loop closure in a multi-robot SLAM scenario requires keypoints that can be matched between sensor measurement point clouds with different properties such as point density and noise. In this paper, we evaluate the performance of several 3D keypoint detectors (Harris3D, ISS, KPQ, KPQ-SI, and NARF) for repeatability between scans from different sensors towards building a heterogeneous multi-robot SLAM system. We find that KPQ-SI and NARF have the best relative repeatability, with KPQ-SI finding more keypoints overall and a higher number of repeatable keypoints, at the cost of significantly worse computational performance. In scans of the same area from different poses, both detectors find enough keypoints for point cloud registration and loop closure. For heterogenous multirobot SLAM applications with computational or bandwidth restrictions, the NARF detector consistently finds repeatable keypoints while also allowing for real-time performance.
ER  - 

TY  - CONF
TI  - ROVO: Robust Omnidirectional Visual Odometry for Wide-baseline Wide-FOV Camera Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6344
EP  - 6350
AU  - H. Seok
AU  - J. Lim
PY  - 2019
KW  - cameras
KW  - distance measurement
KW  - feature extraction
KW  - image matching
KW  - image sequences
KW  - lenses
KW  - motion estimation
KW  - optimisation
KW  - pose estimation
KW  - stereo image processing
KW  - hybrid projection model
KW  - multiview P3P RANSAC algorithm
KW  - multiview images
KW  - wide-baseline wide-FOV camera systems
KW  - robust visual odometry system
KW  - wide-baseline camera rig
KW  - field-of-view fisheye lenses
KW  - omnidirectional stereo observations
KW  - ego-motion estimation
KW  - VO pipeline
KW  - feature matching
KW  - pose estimation
KW  - omnidirectional visual odometry
KW  - Cameras
KW  - Robot vision systems
KW  - Visual odometry
KW  - Calibration
KW  - Pose estimation
DO  - 10.1109/ICRA.2019.8793758
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we propose a robust visual odometry system for a wide-baseline camera rig with wide field-of-view (FOV) fisheye lenses, which provides full omnidirectional stereo observations of the environment. For more robust and accurate ego-motion estimation we adds three components to the standard VO pipeline, 1) the hybrid projection model for improved feature matching, 2) multi-view P3P RANSAC algorithm for pose estimation, and 3) online update of rig extrinsic parameters. The hybrid projection model combines the perspective and cylindrical projection to maximize the overlap between views and minimize the image distortion that degrades feature matching performance. The multi-view P3P RANSAC algorithm extends the conventional P3P RANSAC to multi-view images so that all feature matches in all views are considered in the inlier counting for robust pose estimation. Finally the online extrinsic calibration is seamlessly integrated in the backend optimization framework so that the changes in camera poses due to shocks or vibrations can be corrected automatically. The proposed system is extensively evaluated with synthetic datasets with ground-truth and real sequences of highly dynamic environment, and its superior performance is demonstrated.
ER  - 

TY  - CONF
TI  - SLAMBench 3.0: Systematic Automated Reproducible Evaluation of SLAM Systems for Robot Vision Challenges and Scene Understanding
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6351
EP  - 6358
AU  - M. Bujanca
AU  - P. Gafton
AU  - S. Saeedi
AU  - A. Nisbet
AU  - B. Bodin
AU  - M. F. P. O'Boyle
AU  - A. J. Davison
AU  - P. H. J. Kelly
AU  - G. Riley
AU  - B. Lennox
AU  - M. Luján
AU  - S. Furber
PY  - 2019
KW  - control engineering computing
KW  - convolutional neural nets
KW  - image reconstruction
KW  - natural scenes
KW  - robot vision
KW  - SLAM (robots)
KW  - scene understanding
KW  - nonrigid environments
KW  - dynamic SLAM
KW  - SLAMBench 3
KW  - evaluation infrastructure
KW  - systematic automated reproducible evaluation
KW  - robot vision
KW  - visual SLAM
KW  - SLAM research area
KW  - visulation aids
KW  - visulation metrics
KW  - convolutional neural networks
KW  - dynamicfusion
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Three-dimensional displays
KW  - Measurement
KW  - Benchmark testing
KW  - Heuristic algorithms
KW  - C++ languages
DO  - 10.1109/ICRA.2019.8794369
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - As the SLAM research area matures and the number of SLAM systems available increases, the need for frameworks that can objectively evaluate them against prior work grows. This new version of SLAMBench moves beyond traditional visual SLAM, and provides new support for scene understanding and non-rigid environments (dynamic SLAM). More concretely for dynamic SLAM, SLAMBench 3.0 includes the first publicly available implementation of DynamicFusion, along with an evaluation infrastructure. In addition, we include two SLAM systems (one dense, one sparse) augmented with convolutional neural networks for scene understanding, together with datasets and appropriate metrics. Through a series of use-cases, we demonstrate the newly incorporated algorithms, visulation aids and metrics (6 new metrics, 4 new datasets and 5 new algorithms).
ER  - 

TY  - CONF
TI  - Beyond Photometric Loss for Self-Supervised Ego-Motion Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6359
EP  - 6365
AU  - T. Shen
AU  - Z. Luo
AU  - L. Zhou
AU  - H. Deng
AU  - R. Zhang
AU  - T. Fang
AU  - L. Quan
PY  - 2019
KW  - motion estimation
KW  - pose estimation
KW  - SLAM (robots)
KW  - photometric loss
KW  - self-supervised ego-motion estimation
KW  - accurate relative pose
KW  - SLAM
KW  - self-supervised learning framework
KW  - image depth
KW  - photometric error
KW  - systematic error
KW  - realistic scenes
KW  - geometric loss
KW  - matching loss
KW  - self-supervised framework
KW  - unsupervised egomotion estimation methods
KW  - Simultaneous localization and mapping
KW  - Estimation
KW  - Geometry
KW  - Cameras
KW  - Motion estimation
KW  - Visualization
KW  - Visual odometry
DO  - 10.1109/ICRA.2019.8793479
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate relative pose is one of the key components in visual odometry (VO) and simultaneous localization and mapping (SLAM). Recently, the self-supervised learning framework that jointly optimizes the relative pose and target image depth has attracted the attention of the community. Previous works rely on the photometric error generated from depths and poses between adjacent frames, which contains large systematic error under realistic scenes due to reflective surfaces and occlusions. In this paper, we bridge the gap between geometric loss and photometric loss by introducing the matching loss constrained by epipolar geometry in a self-supervised framework. Evaluated on the KITTI dataset, our method outperforms the state-of-the-art unsupervised egomotion estimation methods by a large margin. The code and data are available at https://github.com/hlzz/DeepMatchVO.
ER  - 

TY  - CONF
TI  - Efficient Integrity Monitoring for KF-based Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6374
EP  - 6380
AU  - G. D. Arana
AU  - M. Joerger
AU  - M. Spenko
PY  - 2019
KW  - Kalman filters
KW  - location based services
KW  - mobile radio
KW  - mobile robots
KW  - KF-based localization
KW  - localization safety
KW  - mobile robots
KW  - aviation performance metric
KW  - aviation integrity monitoring solutions
KW  - robot navigation
KW  - integrity monitoring
KW  - global navigation satellite system
KW  - positioning sensors
KW  - Kalman filter-based localization
KW  - autonomous navigation
KW  - Sensors
KW  - Monitoring
KW  - Current measurement
KW  - Mathematical model
KW  - Fault detection
KW  - Safety
KW  - Time measurement
DO  - 10.1109/ICRA.2019.8794362
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a new method to efficiently monitor localization safety in mobile robots. Localization safety is quantified by measuring the system's integrity risk, which is a well-known aviation performance metric. However, aviation integrity monitoring solutions almost exclusively rely on the Global Navigation Satellite System (GNSS) while robot navigation usually needs the additional information provided by a state evolution model and/or relative positioning sensors, which makes previously established approaches impractical. In response, this paper develops an efficient integrity monitoring methodology applicable to Kalman Filter-based localization. The work is intended for life-or mission-critical operations such as co-robot applications where ignoring the impact of faults can jeopardize human safety.
ER  - 

TY  - CONF
TI  - High-Precision Localization Using Ground Texture
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6381
EP  - 6387
AU  - L. Zhang
AU  - A. Finkelstein
AU  - S. Rusinkiewicz
PY  - 2019
KW  - cameras
KW  - Global Positioning System
KW  - image capture
KW  - image texture
KW  - location based services
KW  - location-aware applications
KW  - satellite-based localization
KW  - image-based global localization system
KW  - index distinctive local keypoints
KW  - fine texture
KW  - image processing pipeline
KW  - captured texture patch
KW  - test images
KW  - outdoor ground surfaces
KW  - indoor ground surfaces
KW  - ground textures
KW  - Cameras
KW  - Global Positioning System
KW  - Databases
KW  - Robots
KW  - Feature extraction
KW  - Three-dimensional displays
KW  - Asphalt
DO  - 10.1109/ICRA.2019.8794106
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Location-aware applications play an increasingly critical role in everyday life. However, satellite-based localization (e.g., GPS) has limited accuracy and can be unusable in dense urban areas and indoors. We introduce an image-based global localization system that is accurate to a few millimeters and performs reliable localization both indoors and outside. The key idea is to capture and index distinctive local keypoints in ground textures. This is based on the observation that ground textures including wood, carpet, tile, concrete, and asphalt may look random and homogeneous, but all contain cracks, scratches, or unique arrangements of fibers. These imperfections are persistent, and can serve as local features. Our system incorporates a downward-facing camera to capture the fine texture of the ground, together with an image processing pipeline that locates the captured texture patch in a compact database constructed offline. We demonstrate the capability of our system to robustly, accurately, and quickly locate test images on various types of outdoor and indoor ground surfaces. This paper contains a supplementary video. All datasets and code are available online at microgps.cs.princeton.edu.
ER  - 

TY  - CONF
TI  - IN2LAMA: INertial Lidar Localisation And MApping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6388
EP  - 6394
AU  - C. L. Gentil
AU  - T. Vidal-Calleja
AU  - S. Huang
PY  - 2019
KW  - mobile robots
KW  - motion estimation
KW  - optical radar
KW  - optimisation
KW  - probability
KW  - robot vision
KW  - IN2LAMA
KW  - spinning mechanisms
KW  - resulting point clouds
KW  - lidar mapping literature
KW  - constant velocity motion model
KW  - upsampled inertial data
KW  - motion distortion
KW  - explicit motion-model
KW  - temporally precise upsampled preintegrated measurement
KW  - frame-to-frame planar
KW  - edge features association
KW  - probabilistic framework
KW  - inertial lidar localisation and mapping
KW  - batch on-manifold optimisation formulation
KW  - state change estimation
KW  - front-end interaction
KW  - back-end interaction
KW  - Laser radar
KW  - Distortion measurement
KW  - Three-dimensional displays
KW  - Distortion
KW  - Optimization
KW  - Trajectory
KW  - Gyroscopes
DO  - 10.1109/ICRA.2019.8794429
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we introduce a probabilistic framework for INertial Lidar Localisation And MApping (IN2LAMA). Most of today's lidars are based on spinning mechanisms that do not capture snapshots of the environment. As a result, movement of the sensor can occur while scanning. Without a good estimation of this motion, the resulting point clouds might be distorted. In the lidar mapping literature, a constant velocity motion model is commonly assumed. This is an approximation that does not necessarily always hold. The key idea of the proposed framework is to exploit preintegrated measurements over upsampled inertial data to handle motion distortion without the need for any explicit motion-model. It tightly integrates inertial and lidar data in a batch on-manifold optimisation formulation. Using temporally precise upsampled preintegrated measurement allows frame-to-frame planar and edge features association. Moreover, features are re-computed when the estimate of the state changes, consolidating front-end and back-end interaction. We validate the effectiveness of the approach through simulated and real data.
ER  - 

TY  - CONF
TI  - Speeding Up Iterative Closest Point Using Stochastic Gradient Descent
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6395
EP  - 6401
AU  - F. A. Maken
AU  - F. Ramos
AU  - L. Ott
PY  - 2019
KW  - gradient methods
KW  - image colour analysis
KW  - image registration
KW  - iterative methods
KW  - optimisation
KW  - pose estimation
KW  - SLAM (robots)
KW  - stochastic gradient descent
KW  - 3D laser scanners
KW  - RGB-D cameras
KW  - model registration
KW  - iterative closest point
KW  - SGD
KW  - convergence speed
KW  - 3D point clouds
KW  - pose estimation
KW  - SLAM
KW  - optimisation problem
KW  - Three-dimensional displays
KW  - Standards
KW  - Stochastic processes
KW  - Euclidean distance
KW  - Cost function
KW  - Sensors
DO  - 10.1109/ICRA.2019.8794011
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Sensors producing 3D point clouds such as 3D laser scanners and RGB-D cameras are widely used in robotics, be it for autonomous driving or manipulation. Aligning point clouds produced by these sensors is a vital component in such applications to perform tasks such as model registration, pose estimation, and SLAM. Iterative closest point (ICP) is the most widely used method for this task, due to its simplicity and efficiency. In this paper we propose a novel method which solves the optimisation problem posed by ICP using stochastic gradient descent (SGD). Using SGD allows us to improve the convergence speed of ICP without sacrificing solution quality. Experiments using Kinect as well as Velodyne data show that, our proposed method is faster than existing methods, while obtaining solutions comparable to standard ICP. An additional benefit is robustness to parameters when processing data from different sensors.
ER  - 

TY  - CONF
TI  - Energy Tank-Based Wrench/Impedance Control of a Fully-Actuated Hexarotor: A Geometric Port-Hamiltonian Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6418
EP  - 6424
AU  - R. Rashad
AU  - J. B. C. Engelen
AU  - S. Stramigioli
PY  - 2019
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - controllability
KW  - end effectors
KW  - feedback
KW  - force control
KW  - helicopters
KW  - mobile robots
KW  - nonlinear control systems
KW  - observers
KW  - stability
KW  - trajectory control
KW  - fully-actuated hexarotor
KW  - geometrically consistent manner
KW  - wrench observer
KW  - geometric port-Hamiltonian approach
KW  - aerial robot
KW  - port-Hamiltonian framework
KW  - special Euclidean group
KW  - UAV nonlinear geometric structure
KW  - energy tanks concept
KW  - contact stability
KW  - Unmanned aerial vehicles
KW  - Impedance
KW  - Robots
KW  - Springs
KW  - Propellers
KW  - Mathematical model
KW  - Observers
DO  - 10.1109/ICRA.2019.8793939
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we show how the interactive behavior of an aerial robot can be modeled and controlled effectively and elegantly in the port-Hamiltonian framework. We present an observer-based wrench/impedance controller for a fully-actuated hexarotor. The analysis and control are performed in a geometrically consistent manner on the configuration manifold of the special Euclidean group SE (3) such that the UAV's nonlinear geometric structure is exploited. The controller uses a wrench observer to estimate the interaction wrench without the use of a force/torque sensor. Moreover, the concept of energy tanks is used to guarantee the system's overall contact stability to arbitrary passive environments. The reliability and robustness of the proposed approach is validated through simulation and experiment.
ER  - 

TY  - CONF
TI  - Integral Backstepping Position Control for Quadrotors in Tunnel-Like Confined Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6425
EP  - 6431
AU  - C. H. Vong
AU  - K. Ryan
AU  - H. Chung
PY  - 2019
KW  - aerodynamics
KW  - aerospace robotics
KW  - helicopters
KW  - Kalman filters
KW  - mechanical stability
KW  - mobile robots
KW  - pose estimation
KW  - position control
KW  - robot dynamics
KW  - robot vision
KW  - SLAM (robots)
KW  - tunnels
KW  - vision-based localisation
KW  - cross-sectional localisation system
KW  - integral backstepping controller
KW  - quadrotors
KW  - tunnel-like confined environments
KW  - integral backstepping position control
KW  - kinematic Kalman filter
KW  - semiautonomous system
KW  - flying robots
KW  - aerodynamic disturbances
KW  - Backstepping
KW  - Aerodynamics
KW  - Kinematics
KW  - Kalman filters
KW  - Navigation
KW  - Rail transportation
KW  - Sensors
DO  - 10.1109/ICRA.2019.8793893
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There are many potential applications that require flying robots to navigate through tunnel-like environments, such as inspections of small railway culverts and mineral mappings of mining tunnels. Nevertheless, those environments present many challenges for quadrotors to navigate through. The aerodynamic disturbances created from the fluid interaction between the propellers' downwash and the surrounding surfaces of the environment, as well as longitudinal wind gusts, add hardship in stabilising the vehicle while the restricted narrow space increases the risk of collision. Furthermore, poor visibility and dust blown by the downwash make vision-based localisation extremely difficult. This paper presents a cross-sectional localisation system using Hough Scan Matching and a simple kinematic Kalman filter. Using the estimated state information, an integral backstepping controller is implemented which enables quadrotors to robustly fly in tunnel-like confined environments. A semi-autonomous system is proposed with self-stabilisation in the vertical and lateral axes while a pilot provides commands in the longitudinal direction. The results of a series of experiments in a simulated tunnel show that the proposed system successfully hovered itself and tracked various trajectories in a cross-sectional area without the aid of any external sensing or computing system.
ER  - 

TY  - CONF
TI  - Control and Configuration Planning of an Aerial Cable Towed System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6440
EP  - 6446
AU  - J. Erskine
AU  - A. Chriette
AU  - S. Caro
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cables (mechanical)
KW  - feedback
KW  - helicopters
KW  - linearisation techniques
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - robust control
KW  - trajectory control
KW  - aerial cable towed system
KW  - robot configuration
KW  - kinematic models
KW  - centralized feedback linearization controller
KW  - optimal configurations
KW  - dynamic trajectories
KW  - ACTS
KW  - quadrotors manipulating
KW  - robustness
KW  - Payloads
KW  - Kinematics
KW  - Vehicle dynamics
KW  - Dynamics
KW  - Mathematical model
KW  - Trajectory
KW  - Propulsion
KW  - Aerial Systems
KW  - Multi-Robot Systems
KW  - Quadrotors
KW  - Control
KW  - Reconfiguration
KW  - Cable-Driven Parallel Robots
DO  - 10.1109/ICRA.2019.8794396
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper investigates the effect of the robot configuration on the performance of an aerial cable towed system (ACTS) composed of three quadrotors manipulating a point mass payload. The kinematic and dynamic models of the ACTS are derived in a minimal set of geometric coordinates, and a centralized feedback linearization controller is developed. Independent to the payload trajectory, the configuration of the ACTS is controlled and is evaluated using a robustness index named the capacity margin. Experiments are performed with optimal, suboptimal, and wrench infeasible configurations. It is shown that configurations near the point of zero capacity margin allow the ACTS to hover but not to follow dynamic trajectories, and that the ACTS cannot fly with a negative capacity margin. Dynamic tests of the ACTS show the effects of the configuration on the achievable accelerations.
ER  - 

TY  - CONF
TI  - Adaptive Control of Aerobatic Quadrotor Maneuvers in the Presence of Propeller-Aerodynamic-Coefficient and Torque-Latency Time-Variations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6447
EP  - 6453
AU  - Y. Chen
AU  - N. O. Pérez-Arancibia
PY  - 2019
KW  - adaptive control
KW  - aerodynamics
KW  - aerospace propulsion
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control nonlinearities
KW  - control system synthesis
KW  - helicopters
KW  - least squares approximations
KW  - linear systems
KW  - momentum
KW  - time-varying systems
KW  - torque control
KW  - aerobatic flight
KW  - time-varying torque generation
KW  - propeller-aerodynamic-coefficient
KW  - torque-latency time-variations
KW  - momentum-theory-based analysis
KW  - dynamic linear time-varying description
KW  - flyer
KW  - backstepping controller
KW  - time-varying dynamics
KW  - aerobatic quadrotor
KW  - adaptive control
KW  - robot
KW  - LTV
KW  - recursive least-squares estimation
KW  - Pugachev's Cobras
KW  - triple flips
KW  - aerial vehicle
KW  - Rotors
KW  - Aerodynamics
KW  - Vehicle dynamics
KW  - Torque
KW  - Propellers
KW  - Analytical models
KW  - Robots
DO  - 10.1109/ICRA.2019.8793614
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a study of the dynamics and control of a 28-gram quadrotor during the execution of aerobatic maneuvers in the presence of propeller-aerodynamic-coefficient and torque-latency time-variations. First, through a momentum-theory-based analysis of the flow field surrounding the robot during aerobatic flight, we develop a dynamic linear time-varying (LTV) description of the torque acting on the flyer in which both considered effects explicitly appear as distinct mathematical terms. Then, an adaptive control scheme, composed of a backstepping controller and a modified recursive least-squares (RLS) estimator, is designed to counteract the negative effects produced by the time-varying dynamics of the torque that drives the flyer. The suitability and efficacy of the proposed methods are demonstrated through real-time flight experiments in which the quadrotor autonomously performs three different types of aerobatic maneuvers: triple flips, Pugachev's Cobras and mixed flips. Furthermore, analyses of the experimental data compellingly show that the proposed control scheme consistently improves the performance of the aerial vehicle during aerobatic flight, compared to those achieved by using a high-performance linear time-invariant (LTI) controller that does not account for time-varying torque generation.
ER  - 

TY  - CONF
TI  - Fast Terminal Sliding Mode Super Twisting Controller For Position And Altitude Tracking of the Quadrotor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6468
EP  - 6474
AU  - V. K. Tripathi
AU  - A. K. Kamath
AU  - N. K. Verma
AU  - L. Behera
PY  - 2019
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - closed loop systems
KW  - control system synthesis
KW  - helicopters
KW  - Lyapunov methods
KW  - nonlinear control systems
KW  - position control
KW  - stability
KW  - variable structure systems
KW  - fast terminal sliding mode super twisting controller
KW  - altitude tracking
KW  - nonlinear fast terminal sliding manifold
KW  - super twisting reaching law
KW  - quadrotor position
KW  - FTSMSTC design
KW  - chattering phenomena
KW  - Lyapunov stability theory
KW  - MATLAB simulation
KW  - DJI Matrice M100
KW  - complete closed loop system stability
KW  - Convergence
KW  - Manifolds
KW  - Attitude control
KW  - Stability analysis
KW  - Sliding mode control
KW  - Trajectory
KW  - Backstepping
DO  - 10.1109/ICRA.2019.8794296
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a fast terminal sliding mode super twisting controller (FTSMSTC) design for quadrotor position and altitude tracking in the presence of bounded disturbances. A nonlinear fast terminal sliding manifold has been proposed for fast convergence of the tracking error to zero in finite time unlike the conventional sliding mode control (CSMC) that guarantee only asymptotic convergence of the tracking error. The super twisting reaching law has been proposed to deal with the chattering phenomena, which is inherent in the CSMC. The finite time stability of the complete closed loop system is investigated using Lyapunov stability theory and an analytical expression for the convergence time has also been derived. The effectiveness of the designed controller is checked against the CSMC using MATLAB simulation. The controller has been experimentally validated using the DJI Matrice M100 as a proof of utility in real time applications.
ER  - 

TY  - CONF
TI  - Multirotor dynamics based online scale estimation for monocular SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6475
EP  - 6481
AU  - M. Ludhiyani
AU  - V. Rustagi
AU  - R. Dasgupta
AU  - A. Sinha
PY  - 2019
KW  - autonomous aerial vehicles
KW  - cameras
KW  - helicopters
KW  - image sensors
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - observability
KW  - robot vision
KW  - SLAM (robots)
KW  - observability
KW  - online scale estimation
KW  - extended Kalman filter framework
KW  - multirotor dynamics model
KW  - monocular camera
KW  - metric sensor
KW  - conventional scale estimation methods
KW  - monocular SLAM
KW  - monocular vision
KW  - Cameras
KW  - Observability
KW  - Drag
KW  - Estimation
KW  - Force
KW  - Mathematical model
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8794372
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a novel method to estimate the scale online for monocular SLAM. Unlike conventional scale estimation methods that require a metric sensor such as an IMU and apriori knowledge of its biases, this approach estimates the scale online by solely using the monocular camera and multirotor dynamics model in an extended Kalman Filter framework. Further, we discuss the observability of scale and theoretically show that the scale becomes observable when multirotor dynamics model and monocular vision are used in conjunction. We validate our proposition with extensive experimentation on the local as well as on the standard datasets and compare the same with other state of the art methods.
ER  - 

TY  - CONF
TI  - Real Time Dense Depth Estimation by Fusing Stereo with Sparse Depth Measurements
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6482
EP  - 6488
AU  - S. S. Shivakumar
AU  - K. Mohta
AU  - B. Pfrommer
AU  - V. Kumar
AU  - C. J. Taylor
PY  - 2019
KW  - image fusion
KW  - image matching
KW  - stereo image processing
KW  - sparse depth measurements
KW  - stereo pair
KW  - sparse range measurements
KW  - LIDAR sensor
KW  - range camera
KW  - sensor modalities
KW  - randomly sampled ground truth range measurements
KW  - sparse depth input
KW  - PMDTec Monstar sensor
KW  - stereo information
KW  - stereo images
KW  - real time dense depth estimation
KW  - anisotropic diffusion
KW  - semi-global matching
KW  - frequency 5.0 Hz
KW  - Robot sensing systems
KW  - Estimation
KW  - Laser radar
KW  - Cameras
KW  - Pipelines
KW  - Three-dimensional displays
KW  - Gray-scale
DO  - 10.1109/ICRA.2019.8794023
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an approach to depth estimation that fuses information from a stereo pair with sparse range measurements derived from a LIDAR sensor or a range camera. The goal of this work is to exploit the complementary strengths of the two sensor modalities, the accurate but sparse range measurements and the ambiguous but dense stereo information. These two sources are effectively and efficiently fused by combining ideas from anisotropic diffusion and semi-global matching.We evaluate our approach on the KITTI 2015 and Middlebury 2014 datasets, using randomly sampled ground truth range measurements as our sparse depth input. We achieve significant performance improvements with a small fraction of range measurements on both datasets. We also provide qualitative results from our platform using the PMDTec Monstar sensor. Our entire pipeline runs on an NVIDIA TX-2 platform at 5Hz on 1280×1024 stereo images with 128 disparity levels.
ER  - 

TY  - CONF
TI  - Vision-based Control of a Quadrotor in User Proximity: Mediated vs End-to-End Learning Approaches
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6489
EP  - 6495
AU  - D. Mantegazza
AU  - J. Guzzi
AU  - L. M. Gambardella
AU  - A. Giusti
PY  - 2019
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - state estimation
KW  - vision-based control
KW  - quadrotor
KW  - onboard camera
KW  - control signals
KW  - high-level state estimation
KW  - learning approaches
KW  - Task analysis
KW  - Drones
KW  - Robot sensing systems
KW  - Training
KW  - Cameras
KW  - Computer architecture
DO  - 10.1109/ICRA.2019.8794377
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the task of controlling a quadrotor to hover in front of a freely moving user, using input data from an onboard camera. On this specific task we compare two widespread learning paradigms: a mediated approach, which learns a high-level state from the input and then uses it for deriving control signals; and an end-to-end approach, which skips high-level state estimation altogether. We show that despite their fundamental difference, both approaches yield equivalent performance on this task. We finally qualitatively analyze the behavior of a quadrotor implementing such approaches.
ER  - 

TY  - CONF
TI  - Parity-Based Diagnosis in UAVs: Detectability and Robustness Analyses
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6496
EP  - 6502
AU  - G. Zogopoulos-Papaliakos
AU  - K. J. Kyriakopoulos
PY  - 2019
KW  - autonomous aerial vehicles
KW  - fault diagnosis
KW  - particle swarm optimisation
KW  - robust control
KW  - real flight data
KW  - parity-based methodologies
KW  - parity-based diagnosis
KW  - particle swarm optimization
KW  - static residuals
KW  - robustness metrics
KW  - robustness analyses
KW  - detectability
KW  - nonlinear residual generators
KW  - fault diagnosis
KW  - UAV model
KW  - fault detection system
KW  - dynamic residuals
KW  - Mathematical model
KW  - Robustness
KW  - Generators
KW  - Measurement
KW  - Numerical models
KW  - Atmospheric modeling
KW  - Unmanned aerial vehicles
DO  - 10.1109/ICRA.2019.8794125
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Parity-Based methodologies for fault diagnosis in UAVs often result in nonlinear residual generators. Still, a systematic framework to perform detectability and robustness analyses of residual generators does not exist. In this work, detectability and robustness metrics for static and dynamic residuals are presented, while numerical methods, specifically Particle Swarm Optimization, are employed to calculate them. The results are used to characterize the performance of a fault detection system. An application on a UAV model is shown, based on real flight data.
ER  - 

TY  - CONF
TI  - Exploiting a Human-Aware World Model for Dynamic Task Allocation in Flexible Human-Robot Teams
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6511
EP  - 6517
AU  - D. Riedelbauch
AU  - D. Henrich
PY  - 2019
KW  - cameras
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - robot vision
KW  - human participation
KW  - human models
KW  - human-robot teaming framework
KW  - human-aware world model
KW  - dynamic task allocation
KW  - human-robot teams
KW  - human-robot cooperation
KW  - eye-in-hand camera images
KW  - task operations
KW  - trust measure
KW  - action selection algorithm
KW  - Task analysis
KW  - Resource management
KW  - Cameras
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Dynamic scheduling
DO  - 10.1109/ICRA.2019.8794288
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a highly flexible approach to human-robot cooperation, where a robot dynamically selects operations contributing to a shared goal from a given task model. Therefore, knowledge on the task progress is extracted from a world model constructed from eye-in-hand camera images. Data generated from such partial workspace observations is not reliable over time, as humans may interact with resources. We therefore use a human-aware world model maintaining a measure for trust in stored objects regarding recent human presence and previous task progress. Our contribution is an action selection algorithm that uses this trust measure to interleave task operations with active vision to refresh the world model. Large-scale experiments cover various sorts of human participation in different benchmark tasks through simulation of simplified, partially randomized human models. Results illuminate system behaviour and performance for different parametrizations of our human-robot teaming framework.
ER  - 

TY  - CONF
TI  - Group Surfing: A Pedestrian-Based Approach to Sidewalk Robot Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6518
EP  - 6524
AU  - Y. Du
AU  - N. J. Hetherington
AU  - C. L. Oon
AU  - W. P. Chan
AU  - C. P. Quintero
AU  - E. Croft
AU  - H. F. Machiel Van der Loos
PY  - 2019
KW  - collision avoidance
KW  - edge detection
KW  - human-robot interaction
KW  - mobile robots
KW  - navigation
KW  - pedestrians
KW  - traffic engineering computing
KW  - pedestrian-based approach
KW  - sidewalk robot navigation
KW  - mobile robots
KW  - pedestrian-rich sidewalk environments
KW  - pedestrian-shared space
KW  - indoor spaces
KW  - pedestrian movement
KW  - linear flows
KW  - opposing directions
KW  - pedestrians
KW  - random movements
KW  - safe navigation
KW  - sidewalk space
KW  - natural human motion
KW  - socially-compliant manner
KW  - group surfing method
KW  - optimal pedestrian group
KW  - pedestrian-sparse environments
KW  - sidewalk edge detection
KW  - following method
KW  - integrated navigation stack
KW  - Navigation
KW  - Collision avoidance
KW  - Robot kinematics
KW  - Roads
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8793608
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a novel navigation system for mobile robots in pedestrian-rich sidewalk environments. Sidewalks are unique in that the pedestrian-shared space has characteristics of both roads and indoor spaces. Like vehicles on roads, pedestrian movement often manifests as linear flows in opposing directions. On the other hand, pedestrians also form crowds and can exhibit much more random movements than vehicles. Classical algorithms are insufficient for safe navigation around pedestrians and remaining on the sidewalk space. Thus, our approach takes advantage of natural human motion to allow a robot to adapt to sidewalk navigation in a safe and socially-compliant manner. We developed a group surfing method which aims to imitate the optimal pedestrian group for bringing the robot closer to its goal. For pedestrian-sparse environments, we propose a sidewalk edge detection and following method. Underlying these two navigation methods, the collision avoidance scheme is human-aware. The integrated navigation stack is evaluated and demonstrated in simulation. A hardware demonstration is also presented.
ER  - 

TY  - CONF
TI  - Dentronics: Review, First Concepts and Pilot Study of a New Application Domain for Collaborative Robots in Dental Assistance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6525
EP  - 6532
AU  - J. Grischke
AU  - L. Johannsmeier
AU  - L. Eich
AU  - S. Haddadin
PY  - 2019
KW  - dentistry
KW  - human-robot interaction
KW  - medical robotics
KW  - dentronics
KW  - new application domain
KW  - collaborative robots
KW  - dental assistance
KW  - multimodal interaction framework
KW  - Dentistry
KW  - Robots
KW  - Task analysis
KW  - Reliability
KW  - Prototypes
KW  - Standards
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8794139
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we introduce dentronics as a new emerging application domain for collaborative lightweight robots in the dental context backed up by a user survey supporting the clear need. Specifically, we developed a multi-modal interaction framework, applied this framework to a specific dental use-case, and conducted a preliminary user-study for evaluation. Our results demonstrate usability and feasibility beyond a controlled experimental setup. We conclude that dentronics is indeed within reach given today's technology and deserves further investigation towards clinical use.
ER  - 

TY  - CONF
TI  - Activity recognition in manufacturing: The roles of motion capture and sEMG+inertial wearables in detecting fine vs. gross motion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6533
EP  - 6539
AU  - A. Kubota
AU  - T. Iqbal
AU  - J. A. Shah
AU  - L. D. Riek
PY  - 2019
KW  - assembling
KW  - feature extraction
KW  - human-robot interaction
KW  - image classification
KW  - image motion analysis
KW  - industrial robots
KW  - manufacturing systems
KW  - production engineering computing
KW  - sensor fusion
KW  - wearable computers
KW  - unimodal sensor data
KW  - UCSD-MIT Human Motion dataset
KW  - Vicon motion capture system
KW  - gross motion recognition
KW  - sensor modalities
KW  - sEMG
KW  - human activity recognition
KW  - inertial wearables
KW  - fine motion detection
KW  - manufacturing
KW  - safety-critical environments
KW  - assembly tasks
KW  - HAR algorithms
KW  - Robot sensing systems
KW  - Task analysis
KW  - Wearable sensors
KW  - Grasping
KW  - Automotive engineering
KW  - Tracking
DO  - 10.1109/ICRA.2019.8793954
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In safety-critical environments, robots need to reliably recognize human activity to be effective and trust-worthy partners. Since most human activity recognition (HAR) approaches rely on unimodal sensor data (e.g. motion capture or wearable sensors), it is unclear how the relationship between the sensor modality and motion granularity (e.g. gross or fine) of the activities impacts classification accuracy. To our knowledge, we are the first to investigate the efficacy of using motion capture as compared to wearable sensor data for recognizing human motion in manufacturing settings. We introduce the UCSD-MIT Human Motion dataset, composed of two assembly tasks that entail either gross or fine-grained motion. For both tasks, we compared the accuracy of a Vicon motion capture system to a Myo armband using three widely used HAR algorithms. We found that motion capture yielded higher accuracy than the wearable sensor for gross motion recognition (up to 36.95%), while the wearable sensor yielded higher accuracy for fine-grained motion (up to 28.06%). These results suggest that these sensor modalities are complementary, and that robots may benefit from systems that utilize multiple modalities to simultaneously, but independently, detect gross and fine-grained motion. Our findings will help guide researchers in numerous fields of robotics including learning from demonstration and grasping to effectively choose sensor modalities that are most suitable for their applications.
ER  - 

TY  - CONF
TI  - Optimal Proactive Path Planning for Collaborative Robots in Industrial Contexts
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6540
EP  - 6546
AU  - A. Casalino
AU  - D. Bazzi
AU  - A. M. Zanchettin
AU  - P. Rocco
PY  - 2019
KW  - collision avoidance
KW  - industrial manipulators
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - motion controllers
KW  - production plants
KW  - optimal proactive path planning
KW  - Industry 4.0
KW  - ABB YuMi
KW  - industrial contexts
KW  - collaborative robots
KW  - 7 degrees robotic arm
KW  - human operator
KW  - robotic paths
KW  - proactive approach
KW  - local corrective actions
KW  - safe motion planning strategies
KW  - Trajectory
KW  - Service robots
KW  - Probabilistic logic
KW  - Computational modeling
KW  - Collaboration
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793847
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The coexistence of humans and robots in the future production plants is one of the pillars of Industry 4.0. Humans and robots will collaborate to accomplish common tasks in order to mutually compensate their deficiencies. In recent years, many efforts have been spent to develop safe motion planning strategies, designed to prevent robots from injuring humans. Most of the previous techniques are classifiable as reactive, since the considered motion controllers impose some local corrective actions in order to dodge the space occupied by the human. In this paper, a proactive approach is adopted, optimizing robotic paths according to a prediction of the volume occupied by the human when collaborating with the robot. The validity of the approach is shown in a realistic use-case involving the collaboration of a human operator with a 7 degrees robotic arm, the ABB YuMi.
ER  - 

TY  - CONF
TI  - Build your own hybrid thermal/EO camera for autonomous vehicle
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6555
EP  - 6560
AU  - Y. Zhang
AU  - Y. Gao
AU  - S. Gu
AU  - Y. Guo
AU  - M. Liu
AU  - Z. Sun
AU  - Z. Hou
AU  - H. Yang
AU  - Y. Wang
AU  - J. Yang
AU  - J. Ponce
AU  - H. Kong
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image motion analysis
KW  - image registration
KW  - image resolution
KW  - image sensors
KW  - image sequences
KW  - object detection
KW  - remotely operated vehicles
KW  - single hybrid camera
KW  - hybrid camera array
KW  - disparity images
KW  - spatial-alignment
KW  - autonomous vehicle
KW  - thermal RGB frames
KW  - thermal EO cameras
KW  - pixel-wise spatial registration
KW  - visible-light camera
KW  - hybrid thermal/EO camera
KW  - RGB frames
KW  - constant homography warping
KW  - image modalities
KW  - Cameras
KW  - Layout
KW  - Technological innovation
KW  - Tuners
KW  - Optical sensors
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2019.8794320
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we propose a novel paradigm to design a hybrid thermal/EO (Electro-Optical or visible-light) camera, whose thermal and RGB frames are pixel-wisely aligned and temporally synchronized. Compared with the existing schemes, we innovate in three ways in order to make it more compact in dimension, and thus more practical and extendable for real-world applications. The first is a redesign of the structure layout of the thermal and EO cameras. The second is on obtaining a pixel-wise spatial registration of the thermal and RGB frames by a coarse mechanical adjustment and a fine alignment through a constant homography warping. The third innovation is on extending one single hybrid camera to a hybrid camera array, through which we can obtain wide-view spatially aligned thermal, RGB and disparity images simultaneously. The experimental results show that the average error of spatial-alignment of two image modalities can be less than one pixel.
ER  - 

TY  - CONF
TI  - Redundant Perception and State Estimation for Reliable Autonomous Racing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6561
EP  - 6567
AU  - N. Gosala
AU  - A. Bühler
AU  - M. Prajapat
AU  - C. Ehmke
AU  - M. Gupta
AU  - R. Sivanesan
AU  - A. Gawel
AU  - M. Pfeiffer
AU  - M. Bürki
AU  - I. Sa
AU  - R. Dubé
AU  - R. Siegwart
PY  - 2019
KW  - automobiles
KW  - driver information systems
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - SLAM (robots)
KW  - state estimation
KW  - vehicle dynamics
KW  - reliable autonomous racing
KW  - sensor failure
KW  - critical consequences
KW  - state estimation approaches
KW  - autonomous race car
KW  - track delimiting objects
KW  - sensor modalities
KW  - learning-based approaches
KW  - camera data
KW  - redundant perception inputs
KW  - probabilistic failure detection algorithm
KW  - real-world racing conditions
KW  - slip dynamics
KW  - particle filter based SLAM algorithm
KW  - pose estimates
KW  - velocity 90.0 km/h
KW  - Robot sensing systems
KW  - Cameras
KW  - Three-dimensional displays
KW  - Automobiles
KW  - Image color analysis
KW  - Laser radar
KW  - Reliability
DO  - 10.1109/ICRA.2019.8794155
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In autonomous racing, vehicles operate close to the limits of handling and a sensor failure can have critical consequences. To limit the impact of such failures, this paper presents the redundant perception and state estimation approaches developed for an autonomous race car. Redundancy in perception is achieved by estimating the color and position of the track delimiting objects using two sensor modalities independently. Specifically, learning-based approaches are used to generate color and pose estimates, from LiDAR and camera data respectively. The redundant perception inputs are fused by a particle filter based SLAM algorithm that operates in real-time. Velocity is estimated using slip dynamics, with reliability being ensured through a probabilistic failure detection algorithm. The sub-modules are extensively evaluated in real-world racing conditions using the autonomous race car gotthard driverless, achieving lateral accelerations up to 1. 7G and a top speed of 90km/h.
ER  - 

TY  - CONF
TI  - UWB/LiDAR Fusion For Cooperative Range-Only SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6568
EP  - 6574
AU  - Y. Song
AU  - M. Guan
AU  - W. P. Tay
AU  - C. L. Law
AU  - C. Wen
PY  - 2019
KW  - distance measurement
KW  - laser ranging
KW  - mobile robots
KW  - optical radar
KW  - SLAM (robots)
KW  - ultra wideband radar
KW  - wireless sensor networks
KW  - cooperative sensor network
KW  - 2D LiDAR sensor
KW  - UWB-LiDAR fusion
KW  - UWB beacon nodes
KW  - peer-to-peer ranges
KW  - nearby objects-obstacles
KW  - surrounding environment
KW  - drift-free SLAM
KW  - mobile robot
KW  - 2D laser rangefinder
KW  - ultra-wideband node
KW  - cooperative range-only SLAM
KW  - LiDAR-based SLAM algorithm
KW  - UWB ranging measurements
KW  - UWB-only localization accuracy
KW  - LiDAR mapping
KW  - laser scanning information
KW  - Laser radar
KW  - Peer-to-peer computing
KW  - Distance measurement
KW  - Simultaneous localization and mapping
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8794222
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We equip an ultra-wideband (UWB) node and a 2D LiDAR sensor a.k.a. 2D laser rangefinder on a mobile robot, and place UWB beacon nodes at unknown locations in an unknown environment. All UWB nodes can do ranging with each other thus forming a cooperative sensor network. We propose to fuse the peer-to-peer ranges measured between UWB nodes and laser scanning information, i.e., range measured between robot and nearby objects/obstacles, for simultaneous localization of the robot, all UWB beacons and LiDAR mapping. The fusion is inspired by two facts: 1) LiDAR may improve UWB-only localization accuracy as it gives a more precise and comprehensive picture of the surrounding environment; 2) on the other hand, UWB ranging measurements may remove the error accumulated in the LiDAR-based SLAM algorithm. Our experiments demonstrate that UWB/LiDAR fusion enables drift-free SLAM in real-time based on ranging measurements only.
ER  - 

TY  - CONF
TI  - Localization and Tracking of Uncontrollable Underwater Agents: Particle Filter Based Fusion of On-Body IMUs and Stationary Cameras
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6575
EP  - 6581
AU  - D. Zhang
AU  - J. Gabaldon
AU  - L. Lauderdale
AU  - M. Johnson-Roberson
AU  - L. J. Miller
AU  - K. Barton
AU  - K. A. Shorter
PY  - 2019
KW  - cameras
KW  - fuzzy set theory
KW  - marine control
KW  - multi-agent systems
KW  - object tracking
KW  - particle filtering (numerical methods)
KW  - nonlinear agent dynamics
KW  - sparse camera observations
KW  - robust agent localization
KW  - uncontrollable underwater agents
KW  - stationary cameras
KW  - multiagent control
KW  - multiagent tracking problem
KW  - wearable sensors
KW  - uncontrollable biological agents
KW  - camera detections
KW  - on-body IMUs
KW  - fuzzy observation concept
KW  - nonGaussian noise
KW  - particle filter based fusion
KW  - Cameras
KW  - Two dimensional displays
KW  - Tracking
KW  - Wearable sensors
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Particle filters
DO  - 10.1109/ICRA.2019.8794141
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Tracking of uncontrollable agents in a controlled environment is an important research question for the coordination of controllable and uncontrollable agents and bio-inspired multi-agent control. This paper presents a framework that approaches the multiagent tracking problem from a localization perspective, utilizing a combination of wearable sensors and stationary cameras. Specifically, this framework was applied to localize uncontrollable biological agents (dolphins) in a well defined environment. The biological agents were outfitted with wearable sensors (IMU, speed, depth) and were free to move in their three dimensional habitat. The dynamic data collected by the wearable sensors was supplemented with image data collected using a pair of cameras mounted above the habitat. The framework presented in this paper combines data from these sensor streams to calculate an accurate estimate of the animal's location during extended periods of free movement. The associations between camera detections and tagged agents are handled using a particle filter embedded with a fuzzy observation concept. The platform is readily implementable in similar water / land environments, and is able to handle nonlinear agent dynamics, non-Gaussian noise, and sparse camera observations while maintaining robust agent localization and tracking.
ER  - 

TY  - CONF
TI  - Steering Co-centered and Co-directional Optical and Acoustic Beams with a Water-immersible MEMS Scanning Mirror for Underwater Ranging and Communication*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6582
EP  - 6587
AU  - X. Duan
AU  - D. Song
AU  - J. Zou
PY  - 2019
KW  - beam steering
KW  - integrated optics
KW  - laser beams
KW  - laser ranging
KW  - micromechanical devices
KW  - micromirrors
KW  - microsensors
KW  - optical communication equipment
KW  - photodetectors
KW  - remotely operated vehicles
KW  - underwater optics
KW  - underwater vehicles
KW  - Hall effect
KW  - reception modes
KW  - transmission modes
KW  - underwater ranging and communication
KW  - steering co-directional optical beams
KW  - steering co-directional acoustic beams
KW  - steering co-centered laser beams
KW  - steering co-centered ultrasonic beams
KW  - steering co-directional ultrasonic beams
KW  - steering co-directional laser beams
KW  - steering co-centered acoustic beams
KW  - steering co-centered optical beams
KW  - bi-modal communication
KW  - scan position sensors
KW  - ultrasound beams
KW  - water-immersible MEMS scanning mirror
KW  - Laser beams
KW  - Ultrasonic imaging
KW  - Mirrors
KW  - Acoustic beams
KW  - Optical beams
KW  - Optical sensors
DO  - 10.1109/ICRA.2019.8793747
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper reports the development of a compact optical-acoustic frontend module for underwater communication and ranging. The module is enabled by a new water-immersible MEMS scanning mirror (WIMSM). It is capable of transmitting, receiving and steering co-centered and co-directional laser and ultrasound beams under water. To monitor its rotating angle in real time, scan position sensors based on Hall effect have been integrated into the WIMSM. The angular alignment of the laser and ultrasound beams in both transmission and reception modes has been examined. The experimental results show that the laser and ultrasound beams can remain aligned with less than 2.1 degrees under envelope of pan and tilt rotations. This capability is critical for the continuing development of the new bi-modal communication and ranging underwater Vehicles (AUVs).
ER  - 

TY  - CONF
TI  - A Simple Adaptive Tracker with Reminiscences
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6596
EP  - 6603
AU  - C. Xie
AU  - E. Fox
AU  - Z. Harchaoui
PY  - 2019
KW  - convex programming
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object tracking
KW  - VOT benchmark dataset
KW  - OTB benchmark dataset
KW  - gradient-based convex optimization
KW  - MTCF
KW  - appearance changes
KW  - adaptive tracker
KW  - temporal windows
KW  - base trackers
KW  - ensemble method
KW  - visual object tracking
KW  - correlation filters
KW  - reminiscences
KW  - visual appearance
KW  - video history
KW  - Correlation
KW  - Visualization
KW  - Object tracking
KW  - History
KW  - Standards
KW  - Convolution
KW  - Training
DO  - 10.1109/ICRA.2019.8794234
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Correlation filters have provided exceptional results in the field of visual object tracking in the past few years. However, these methods typically learn a single filter to be robust to many different appearance changes, which can be challenging. We propose a simple solution to this problem by utilizing an ensemble method of base trackers trained on different temporal windows of the video history. The proposed tracker, called MTCF, exhibits the following features: i) it can be trained using gradient-based convex optimization; ii) it is robust to short-term and long-term changes in visual appearance. MTCF performs on par with or outperforms state-of-the-art trackers on the OTB and the VOT benchmark datasets. We present an extensive analysis of the performance of MTCF on these benchmark datasets.
ER  - 

TY  - CONF
TI  - Learning-driven Coarse-to-Fine Articulated Robot Tracking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6604
EP  - 6610
AU  - C. Rauch
AU  - V. Ivan
AU  - T. Hospedales
AU  - J. Shotton
AU  - M. Fallon
PY  - 2019
KW  - computer vision
KW  - edge detection
KW  - image colour analysis
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - object tracking
KW  - coarse-to-fine articulated robot tracking
KW  - articulated tracking approach
KW  - robotic manipulators
KW  - visual cues
KW  - subpixel-level accurate correspondences
KW  - discriminative depth information
KW  - coarse-to-fine articulated state estimator
KW  - robot state distribution
KW  - depth image
KW  - Schunk SDH2 hand interacting
KW  - edge tracking
KW  - depth keypoints
KW  - articulated model fitting
KW  - colour edge correspondences
KW  - RGB-D sequences
KW  - KUICA LWR arm
KW  - palm position estimation
KW  - Visualization
KW  - Optimization
KW  - Manipulators
KW  - Image edge detection
KW  - Two dimensional displays
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794359
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we present an articulated tracking approach for robotic manipulators, which relies only on visual cues from colour and depth images to estimate the robot's state when interacting with or being occluded by its environment. We hypothesise that articulated model fitting approaches can only achieve accurate tracking if subpixel-level accurate correspondences between observed and estimated state can be established. Previous work in this area has exclusively relied on either discriminative depth information or colour edge correspondences as tracking objective and required initialisation from joint encoders. In this paper we propose a coarse-to-fine articulated state estimator, which relies only on visual cues from colour edges and learned depth keypoints, and which is initialised from a robot state distribution predicted from a depth image. We evaluate our approach on four RGB-D sequences showing a KUICA LWR arm with a Schunk SDH2 hand interacting with its environment and demonstrate that this combined keypoint and edge tracking objective can estimate the palm position with an average error of 2. 5cm without using any joint encoder sensing.
ER  - 

TY  - CONF
TI  - Diagonally-Decoupled Direct Visual Servoing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6611
EP  - 6616
AU  - G. Silveira
AU  - L. Mirisola
PY  - 2019
KW  - observers
KW  - robot vision
KW  - visual servoing
KW  - diagonally-decoupled direct visual servoing
KW  - vision-based robot control
KW  - reference image
KW  - intensity-based nonmetric solutions
KW  - fully coupled control error dynamics
KW  - translational part
KW  - lower triangular system
KW  - system dynamics
KW  - analysis complexity
KW  - system performance
KW  - nonlinear observer
KW  - rotational part
KW  - decoupling properties
KW  - robotic arm
KW  - control error dynamics
KW  - Visual servoing
KW  - Cameras
KW  - Convergence
KW  - Observers
KW  - Transmission line matrix methods
KW  - Voltage control
DO  - 10.1109/ICRA.2019.8793717
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of vision-based robot control where a reference image defines the equilibrium. Specifically, we consider the class of intensity-based nonmetric solutions, which provide for high accuracy, versatility, and robustness. Existing techniques within that class present either a fully coupled control error dynamics or at best only achieve decoupling of the translational part, i.e., they can only obtain a lower triangular system. These couplings in the system dynamics increase analysis complexity and may degrade system performance. This work proposes a new nonlinear observer for also decoupling the rotational part, i.e., for diagonally decoupling the entire control error dynamics. Theoretical proofs of stability and of those decoupling properties are provided. Improved performances are also experimentally confirmed using synthetic and real data, planar and nonplanar objects, simulating and applying a camera-mounted 6-DoF robotic arm.
ER  - 

TY  - CONF
TI  - 2D LiDAR Map Prediction via Estimating Motion Flow with GRU
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6617
EP  - 6623
AU  - Y. Song
AU  - Y. Tian
AU  - G. Wang
AU  - M. Li
PY  - 2019
KW  - feature extraction
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - motion estimation
KW  - optical radar
KW  - radar imaging
KW  - recurrent neural nets
KW  - LiDAR-FlowNet model
KW  - motion flow based method
KW  - 2D LiDAR map prediction
KW  - optical flow
KW  - recurrent neural network
KW  - motion flow estimation
KW  - gated recurrent unit
KW  - robotics navigation
KW  - path planning
KW  - Laser radar
KW  - Two dimensional displays
KW  - Dynamics
KW  - Logic gates
KW  - Recurrent neural networks
KW  - Training
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793490
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - It is a significant problem to predict the 2D LiDAR map at next moment for robotics navigation and path-planning. To tackle this problem, we resort to the motion flow between adjacent maps, as motion flow is a powerful tool to process and analyze the dynamic data, which is named optical flow in video processing. However, unlike video, which contains abundant visual features in each frame, a 2D LiDAR map lacks distinctive local features. To alleviate this challenge, we propose to estimate the motion flow based on deep neural networks inspired by its powerful representation learning ability in estimating the optical flow of the video. To this end, we design a recurrent neural network based on gated recurrent unit, which is named LiDAR-FlowNet. As a recurrent neural network can encode the temporal dynamic information, our LiDAR-FlowNet can estimate motion flow between the current map and the unknown next map only from the current frame and previous frames. A self-supervised strategy is further designed to train the LiDAR-FlowNet model effectively, while no training data need to be manually annotated. With the estimated motion flow, it is straightforward to predict the 2D LiDAR map at the next moment. Experimental results verify the effectiveness of our LiDAR-FlowNet as well as the proposed training strategy. The results of the predicted LiDAR map also show the advantages of our motion flow based method.
ER  - 

TY  - CONF
TI  - Robot eye-hand coordination learning by watching human demonstrations: a task function approximation approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6624
EP  - 6630
AU  - J. Jin
AU  - L. Petrich
AU  - M. Dehghan
AU  - Z. Zhang
AU  - M. Jagersand
PY  - 2019
KW  - feedback
KW  - function approximation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - visual servoing
KW  - human demonstrations
KW  - task function approximation approach
KW  - robot eye-hand coordination learning method
KW  - visual task specification
KW  - inverse reinforcement learning
KW  - learned reward model
KW  - uncalibrated visual servoing
KW  - hand-engineered task specification
KW  - traditional UVS controller
KW  - learned policy
KW  - robot platforms
KW  - Task analysis
KW  - Robot kinematics
KW  - Videos
KW  - Training
KW  - Visualization
KW  - Visual servoing
DO  - 10.1109/ICRA.2019.8793649
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a robot eye-hand coordination learning method that can directly learn visual task specification by watching human demonstrations. Task specification is represented as a task function, which is learned using inverse reinforcement learning(IRL [1]) by inferring a reward model from state transitions. The learned reward model is then used as continuous feedbacks in an uncalibrated visual servoing(UVS [2]) controller designed for the execution phase. Our proposed method can directly learn from raw videos, which removes the need for hand-engineered task specification. Benefiting from the use of a traditional UVS controller, the training on real robot only happens at initial Jacobian estimation which takes an average of 4-7 seconds for a new task. Besides, the learned policy is independent from a particular robot, thus has the potential of fast adapting to other robot platforms. Various experiments were designed to show that, for a task with certain DOFs, our method can adapt to task/environment changes in target positions, backgrounds, illuminations, and occlusions.
ER  - 

TY  - CONF
TI  - Vision-Based Dynamic Control of Car-Like Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6631
EP  - 6636
AU  - S. Zhou
AU  - Z. Liu
AU  - C. Suo
AU  - H. Wang
AU  - H. Zhao
AU  - Y. Liu
PY  - 2019
KW  - automobiles
KW  - Lyapunov methods
KW  - mobile robots
KW  - robot vision
KW  - stability
KW  - steering systems
KW  - velocity control
KW  - car-like mobile robots
KW  - CLMR
KW  - steering control system
KW  - slipping effects
KW  - velocity estimation error
KW  - speed tracking error
KW  - vision-based dynamic control
KW  - visual algorithm
KW  - skidding effects
KW  - speed control system
KW  - Lyapunov method
KW  - stability
KW  - electric autonomous tractor
KW  - Aerodynamics
KW  - Mobile robots
KW  - Velocity measurement
KW  - Estimation
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8793980
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Most existing controllers for Car-Like Mobile Robots (CLMR) are designed to handle dynamic effects by decoupling speed and steering controls, also assume that full states are accessible, which are unrealistic for real-world applications. This paper presents a combined speed and steering control system for CLMR. To provide the essential state for the controller, a newly developed visual algorithm is adopted for estimating the high-update rate longitudinal and lateral velocities of the robot which cannot be accurately measured by wheel encoders due to the skidding and slipping effects. The stability of the proposed system can be guaranteed by Lyapunov method since the velocity estimation error, the speed tracking error and the lateral deviation converging to zero simultaneously. Real-world experiments are conducted on an electric autonomous tractor with online estimation to demonstrate the feasibility of the approach.
ER  - 

TY  - CONF
TI  - Uncertainty Estimation for Projecting Lidar Points onto Camera Images for Moving Platforms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6637
EP  - 6643
AU  - C. De Alvis
AU  - M. Shan
AU  - S. Worrall
AU  - E. Nebot
PY  - 2019
KW  - calibration
KW  - cameras
KW  - distance measurement
KW  - optical radar
KW  - radar imaging
KW  - heterogeneous sensors
KW  - lidar sensors
KW  - precise range information
KW  - visual image data
KW  - context based algorithms
KW  - intrinsic calibration
KW  - extrinsic calibration
KW  - lidar measurements
KW  - consistent odometry frame
KW  - image frame
KW  - moving platforms
KW  - projection error
KW  - motion correction algorithm
KW  - extended uncertainty model
KW  - real-world data
KW  - wide-angle cameras
KW  - 16-beam scanning lidar
KW  - uncertainty estimation
KW  - lidar points
KW  - camera images
KW  - advanced perception
KW  - crucial requirement
KW  - autonomous vehicle navigation
KW  - sensor frames
KW  - Laser radar
KW  - Cameras
KW  - Calibration
KW  - Uncertainty
KW  - Sensors
KW  - Distortion
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8794424
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Combining multiple sensors for advanced perception is a crucial requirement for autonomous vehicle navigation. Heterogeneous sensors are used to obtain rich information about the surrounding environment. The combination of the camera and lidar sensors enables precise range information that can be projected onto the visual image data. This gives a high level understanding of the scene which can be used to enable context based algorithms such as collision avoidance and navigation. The main challenge when combining these sensors is aligning the data into a common domain. This can be difficult due to the errors in the intrinsic calibration of the camera, extrinsic calibration between the camera and the lidar and errors resulting from the motion of the platform. In this paper, we examine the algorithms required to provide motion correction for scanning lidar sensors. The error resulting from the projection of the lidar measurements into a consistent odometry frame is not possible to remove entirely, and as such it is essential to incorporate the uncertainty of this projection when combining the two different sensor frames. This work proposes a novel framework for the prediction of the uncertainty of lidar measurements (in 3D) projected in to the image frame (in 2D) for moving platforms. The proposed approach fuses the uncertainty of the motion correction with uncertainty resulting from errors in the extrinsic and intrinsic calibration. By incorporating the main components of the projection error, the uncertainty of the estimation process is better represented. Experimental results for our motion correction algorithm and the proposed extended uncertainty model are demonstrated using real-world data collected on an electric vehicle equipped with wide-angle cameras covering a 180-degree field of view and a 16-beam scanning lidar.
ER  - 

TY  - CONF
TI  - Modeling and Analysis of Motion Data from Dynamically Positioned Vessels for Sea State Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6644
EP  - 6650
AU  - X. Cheng
AU  - G. Li
AU  - R. Skulstad
AU  - S. Chen
AU  - H. P. Hildre
AU  - H. Zhang
PY  - 2019
KW  - convolutional neural nets
KW  - data analysis
KW  - fast Fourier transforms
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - marine engineering
KW  - position control
KW  - recurrent neural nets
KW  - sensitivity analysis
KW  - sensor fusion
KW  - ships
KW  - state estimation
KW  - time series
KW  - long dependency
KW  - ship motion data
KW  - convolutional neural network
KW  - frequency features
KW  - feature fusion layer
KW  - raw time series data
KW  - hand-engineered features
KW  - sensitivity analysis method
KW  - data preprocessing
KW  - ship motion dataset
KW  - SeaStateNet
KW  - sea state estimation
KW  - dynamically positioned vessels
KW  - autonomous ship
KW  - deep neural network model
KW  - time-invariant feature extraction
KW  - long-short-term memory recurrent neural network
KW  - fast Fourier transform block
KW  - Sea state
KW  - Marine vehicles
KW  - Time series analysis
KW  - Estimation
KW  - Sensors
KW  - Feature extraction
KW  - Data models
DO  - 10.1109/ICRA.2019.8794069
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Developing a reliable model to identify the sea state is significant for the autonomous ship. This paper introduces a novel deep neural network model (SeaStateNet) to estimate the sea state based on the ship motion data from dynamically positioned vessels. The SeaStateNet mainly consists of three components: an Long-Short-Term Memory (LSTM) recurrent neural network to capture the long dependency in the ship motion data; a convolutional neural network (CNN) to extract time-invariant features; and a Fast Fourier Transform (FFT) block to extract frequency features. A feature fusion layer is designed to learn the degree affected by each component. The proposed model is applied directly to the raw time series data, without needing of any hand-engineered features. A sensitivity analysis (SA) method is applied to assess the influence of data preprocessing. Through benchmark test and experiment on ship motion dataset, SeaStateNet is verified effective for sea state estimation. The investigation on real-time test further shows the practicality of the proposed model.
ER  - 

TY  - CONF
TI  - Visual Localization at Intersections with Digital Maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6651
EP  - 6657
AU  - A. L. Ballardini
AU  - D. Cattaneo
AU  - D. G. Sorrenti
PY  - 2019
KW  - computer vision
KW  - feature extraction
KW  - image reconstruction
KW  - image segmentation
KW  - neural nets
KW  - object detection
KW  - pose estimation
KW  - road vehicles
KW  - stereo image processing
KW  - traffic engineering computing
KW  - ego-vehicle localization
KW  - autonomous road driving
KW  - online vision-based method
KW  - digital map service
KW  - pixel-level semantic segmentation
KW  - intersection approaches
KW  - visual localization
KW  - deep neural networks
KW  - coarse street-level pose estimation
KW  - Roads
KW  - Three-dimensional displays
KW  - Semantics
KW  - Image segmentation
KW  - Pipelines
KW  - Geometry
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794413
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper deals with the task of ego-vehicle localization at intersections, a significant task in autonomous road driving. We propose an online vision-based method that can hence be applied if the intersection is visible. It relies on stereo images and on a coarse street-level pose estimate, used to retrieve intersection data from a digital map service. Pixel-level semantic segmentation, and 3D reconstruction from state-of-the art Deep Neural Networks are coupled with an intersection model; this allows good positioning accuracy compared to the state-of-the-art in this task. To demonstrate the effectiveness of the method and make it possible to compare it with other methods, an extensive activity has been conducted in order to set up a dataset of approaches to an intersection, which has then been used to benchmark the proposed method. The dataset is made available to the community, and it currently includes more than forty intersection approaches, from KITTI. Another important contribution of the paper is the definition of criteria for the comparison of different methods, on recorded datasets. The proposed method achieves nearly sub-meter accuracy in difficult real conditions.
ER  - 

TY  - CONF
TI  - Interaction-aware Multi-agent Tracking and Probabilistic Behavior Prediction via Adversarial Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6658
EP  - 6664
AU  - J. Li
AU  - H. Ma
AU  - M. Tomizuka
PY  - 2019
KW  - decision making
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - neural nets
KW  - probability
KW  - hyperparameter values
KW  - adversarial learning
KW  - interaction-aware multiagent tracking
KW  - probabilistic behavior prediction
KW  - motion planning
KW  - intelligent systems
KW  - multiple interactive agents
KW  - distribution learning
KW  - decision making
KW  - generative adversarial network
KW  - Generators
KW  - Gallium nitride
KW  - Predictive models
KW  - Training
KW  - Generative adversarial networks
KW  - State estimation
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793661
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In order to enable high-quality decision making and motion planning of intelligent systems such as robotics and autonomous vehicles, accurate probabilistic predictions for surrounding interactive objects is a crucial prerequisite. Although many research studies have been devoted to making predictions on a single entity, it remains an open challenge to forecast future behaviors for multiple interactive agents simultaneously. In this work, we take advantage of the Generative Adversarial Network (GAN) due to its capability of distribution learning and propose a generic multi-agent probabilistic prediction and tracking framework which takes the interactions among multiple entities into account, in which all the entities are treated as a whole. However, since GAN is very hard to train, we make an empirical research and present the relationship between training performance and hyperparameter values with a numerical case study. The results imply that the proposed model can capture both the mean, variance and multi-modalities of the groundtruth distribution. Moreover, we apply the proposed approach to a real-world task of vehicle behavior prediction to demonstrate its effectiveness and accuracy. The results illustrate that the proposed model trained by adversarial learning can achieve a better prediction performance than other state-of-the-art models trained by traditional supervised learning which maximizes the data likelihood. The well-trained model can also be utilized as an implicit proposal distribution for particle filtered based Bayesian state estimation.
ER  - 

TY  - CONF
TI  - Model Predictive Control of Ride-sharing Autonomous Mobility-on-Demand Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6665
EP  - 6671
AU  - M. Tsao
AU  - D. Milojevic
AU  - C. Ruch
AU  - M. Salazar
AU  - E. Frazzoli
AU  - M. Pavone
PY  - 2019
KW  - predictive control
KW  - road traffic control
KW  - model predictive control approach
KW  - self-driving vehicles
KW  - on-demand mobility
KW  - time-expanded network flow model
KW  - real-time MPC algorithm
KW  - customer-carrying vehicles
KW  - social welfare
KW  - RAMoD system
KW  - ride-sharing autonomous mobility-on-demand systems
KW  - empty vehicle
KW  - customer-carrying vehicle
KW  - San Francisco
KW  - CA
KW  - Roads
KW  - Automobiles
KW  - Prediction algorithms
KW  - Artificial neural networks
KW  - Analytical models
KW  - Optimization
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8794194
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a model predictive control (MPC) approach to optimize routes for Ride-sharing Autonomous Mobility-on-Demand (RAMoD) systems, whereby self-driving vehicles provide coordinated on-demand mobility, possibly allowing multiple customers to share a ride. Specifically, we first devise a time-expanded network flow model for RAMoD. Second, leveraging this model, we design a real-time MPC algorithm to optimize the routes of both empty and customer-carrying vehicles, with the goal of optimizing social welfare, namely, a weighted combination of customers' travel time and vehicles' mileage. Finally, we present a real-world case study for the city of San Francisco, CA, by using the micro-scopic traffic simulator MATSim. The simulation results show that a RAMoD system can significantly improve social welfare with respect to a single-occupancy Autonomous Mobility-on-Demand (AMoD) system, and that the predictive structure of the proposed MPC controller allows it to outperform existing reactive ride-sharing coordination algorithms for RAMoD.
ER  - 

TY  - CONF
TI  - A Hierarchical Framework for Coordinating Large-Scale Robot Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6672
EP  - 6677
AU  - Z. Liu
AU  - S. Zhou
AU  - H. Wang
AU  - Y. Shen
AU  - H. Li
AU  - Y. Liu
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - road traffic control
KW  - hierarchical framework
KW  - large-scale robot networks
KW  - motion coordination problems
KW  - multirobot system
KW  - robotic warehouses
KW  - automated transportation systems
KW  - life-long planning problem
KW  - coordination performance
KW  - robot motion uncertainties
KW  - hierarchical path planning
KW  - motion coordination structure
KW  - traffic heat-map
KW  - path planning level
KW  - sector-level path
KW  - path distance
KW  - motion coordination level
KW  - collision-free local path
KW  - rolling planning manner
KW  - traffic condition
KW  - robot uncertainty
KW  - Robot kinematics
KW  - Path planning
KW  - Task analysis
KW  - Collision avoidance
KW  - Planning
KW  - Topology
DO  - 10.1109/ICRA.2019.8793719
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we study the cooperative path planning and motion coordination problems of the multi-robot system with large number of robots, aiming for practical applications in robotic warehouses and automated transportation systems. Particularly, we solve the life-long planning problem and guarantee the coordination performance in the presence of robot motion uncertainties. A hierarchical path planning and motion coordination structure is presented. The environment is divided into several sectors and a traffic heat-map is presented to describe the current sector-level traffic condition. In path planning level, the sector-level path is calculated by considering the path distance, the current traffic condition and the current robot uncertainty. In motion coordination level, local cooperative A* algorithm and conflict-based searching strategy are utilized within each sector to generate the collision-free local path of each robot in a rolling planning manner. The effectiveness and practical applicability of the proposed approach are validated by simulations with more than one thousand robots and real experiments.
ER  - 

TY  - CONF
TI  - EasyLabel: A Semi-Automatic Pixel-wise Object Annotation Tool for Creating Robotic RGB-D Datasets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6678
EP  - 6684
AU  - M. Suchi
AU  - T. Patten
AU  - D. Fischinger
AU  - M. Vincze
PY  - 2019
KW  - feature extraction
KW  - image colour analysis
KW  - image segmentation
KW  - mobile robots
KW  - object detection
KW  - object recognition
KW  - robot vision
KW  - video signal processing
KW  - object segmentation methods
KW  - object-wise annotation
KW  - robot vision
KW  - OCID
KW  - robots face
KW  - robot perception systems
KW  - computer vision algorithms
KW  - expected operating domain
KW  - ground truth data
KW  - EasyLabel tool
KW  - high-quality ground truth annotation
KW  - pixel-level
KW  - densely cluttered scenes
KW  - semiautomatic process
KW  - complex scenes
KW  - sensor
KW  - scene distance
KW  - robotic RGB-d datasets
KW  - object masks
KW  - object cluttered indoor dataset
KW  - Robots
KW  - Three-dimensional displays
KW  - Tools
KW  - Object segmentation
KW  - Clutter
KW  - Image segmentation
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793917
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Developing robot perception systems for recognizing objects in the real world requires computer vision algorithms to be carefully scrutinized with respect to the expected operating domain. This demands large quantities of ground truth data to rigorously evaluate the performance of algorithms. This paper presents the EasyLabel tool for easily acquiring high-quality ground truth annotation of objects at pixel-level in densely cluttered scenes. In a semi-automatic process, complex scenes are incrementally built and EasyLabel exploits depth changes to extract precise object masks at each step. We use this tool to generate the Object Cluttered Indoor Dataset (OCID) that captures diverse settings of objects, background, context, sensor to scene distance, viewpoint angle and lighting conditions. OCID is used to perform a systematic comparison of existing object segmentation methods. The baseline comparison supports the need for pixel- and object-wise annotation to progress robot vision towards realistic applications. This insight reveals the usefulness of EasyLabel and OCID to better understand the challenges that robots face in the real world.
ER  - 

TY  - CONF
TI  - BLVD: Building A Large-scale 5D Semantics Benchmark for Autonomous Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6685
EP  - 6691
AU  - J. Xue
AU  - J. Fang
AU  - T. Li
AU  - B. Zhang
AU  - P. Zhang
AU  - Z. Ye
AU  - J. Dou
PY  - 2019
KW  - image segmentation
KW  - object detection
KW  - robot vision
KW  - stereo image processing
KW  - autonomous driving community
KW  - large-scale dataset platform
KW  - large-scale 5D semantics benchmark
KW  - 3D+temporal
KW  - 4D+interactive
KW  - 5D interactive event recognition
KW  - 5D intention prediction
KW  - dynamic 4D tracking
KW  - Three-dimensional displays
KW  - Benchmark testing
KW  - Trajectory
KW  - Roads
KW  - Task analysis
KW  - Semantics
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8793523
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In autonomous driving community, numerous benchmarks have been established to assist the tasks of 3D/2D object detection, stereo vision, semantic/instance segmentation. However, the more meaningful dynamic evolution of the surrounding objects of ego-vehicle is rarely exploited, and lacks a large-scale dataset platform. To address this, we introduce BLVD, a large-scale 5D semantics benchmark which does not concentrate on the static detection or semantic/instance segmentation tasks tackled adequately before. Instead, BLVD aims to provide a platform for the tasks of dynamic 4D (3D+temporal) tracking, 5D (4D+interactive) interactive event recognition and intention prediction. This benchmark will boost the deeper understanding of traffic scenes than ever before. We totally yield 249, 129 3D annotations, 4, 902 independent individuals for tracking with the length of overall 214, 922 points, 6, 004 valid fragments for 5D interactive event recognition, and 4, 900 individuals for 5D intention prediction. These tasks are contained in four kinds of scenarios depending on the object density (low and high) and light conditions (daytime and nighttime). The benchmark can be downloaded from our project site https://github.com/VCCIV/BLVD/.
ER  - 

TY  - CONF
TI  - A Benchmarking Framework for Systematic Evaluation of Robotic Pick-and-Place Systems in an Industrial Grocery Setting
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6692
EP  - 6698
AU  - P. Triantafyllou
AU  - H. Mnyusiwalla
AU  - P. Sotiropoulos
AU  - M. A. Roa
AU  - D. Russell
AU  - G. Deacon
PY  - 2019
KW  - end effectors
KW  - industrial manipulators
KW  - materials handling equipment
KW  - path planning
KW  - robot vision
KW  - benchmarking framework
KW  - industrial grocery setting
KW  - robotic manipulation
KW  - industrial robotic applications
KW  - robotic solution
KW  - industrial setting
KW  - motion planning
KW  - pick-and-place operations
KW  - pick-and-place task
KW  - object placement
KW  - end-effectors
KW  - robotic pick-and-place systems
KW  - Benchmark testing
KW  - Task analysis
KW  - Service robots
KW  - Grasping
KW  - Protocols
KW  - System performance
DO  - 10.1109/ICRA.2019.8793993
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic manipulation is a very active field of research nowadays; however, pick-and-place operations constitute the majority of today's industrial robotic applications. In order to adopt a robotic solution for an industrial setting, proper evaluation processes should be defined to assess the system's performance. A number of benchmarks have been proposed in the literature focusing mainly on individual components needed to perform the task, like grasping, perception and motion planning; thus, they do not provide enough information on the performance of the entire robotic system. To address this, we propose a benchmarking framework for a pick-and-place task inspired by a use case for picking fruits and vegetables in an industrial setting. To foster reproducible research and comparison of different robotic systems, the benchmarking framework uses surrogate objects with instructions on how to build them, an easy-to-reproduce environment, and guidelines for object placement. The proposed benchmark is applied to evaluate the performance of two variants of a robotic system with different end-effectors.
ER  - 

TY  - CONF
TI  - Characterizing Visual Localization and Mapping Datasets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6699
EP  - 6705
AU  - S. Saeedi
AU  - E. D. C. Carvalho
AU  - W. Li
AU  - D. Tzoumanikas
AU  - S. Leutenegger
AU  - P. H. J. Kelly
AU  - A. J. Davison
PY  - 2019
KW  - motion estimation
KW  - rendering (computer graphics)
KW  - SLAM (robots)
KW  - Wasserstein distance
KW  - motion estimation algorithm
KW  - robotics SLAM benchmarking
KW  - visual localization
KW  - mapping algorithms
KW  - real-world trajectories
KW  - high-quality scenes
KW  - synthetic datasets
KW  - dense map
KW  - key SLAM applications
KW  - ground robotics
KW  - mapping datasets
KW  - motion estimation algorithms
KW  - computer vision
KW  - Simultaneous localization and mapping
KW  - Trajectory
KW  - Time measurement
KW  - Visualization
KW  - Benchmark testing
DO  - 10.1109/ICRA.2019.8793528
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Benchmarking mapping and motion estimation algorithms is established practice in robotics and computer vision. As the diversity of datasets increases, in terms of the trajectories, models, and scenes, it becomes a challenge to select datasets for a given benchmarking purpose. Inspired by the Wasserstein distance, this paper addresses this concern by developing novel metrics to evaluate trajectories and the environments without relying on any SLAM or motion estimation algorithm. The metrics, which so far have been missing in the research community, can be applied to the plethora of datasets that exist. Additionally, to improve the robotics SLAM benchmarking, the paper presents a new dataset for visual localization and mapping algorithms. A broad range of real-world trajectories is used in very high-quality scenes and a rendering framework to create a set of synthetic datasets with ground-truth trajectory and dense map which are representative of key SLAM applications such as virtual reality (VR), micro aerial vehicle (MAV) flight, and ground robotics.
ER  - 

TY  - CONF
TI  - Quantifying the Reality Gap in Robotic Manipulation Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6706
EP  - 6712
AU  - J. Collins
AU  - D. Howard
AU  - J. Leitner
PY  - 2019
KW  - image motion analysis
KW  - manipulators
KW  - mobile robots
KW  - robot vision
KW  - robotic manipulation tasks
KW  - Kinova robotic manipulator
KW  - motion capture system
KW  - manipulation-oriented robotic tasks
KW  - robotic reaching task
KW  - robotic interaction task
KW  - quantitative data
KW  - Physics
KW  - Engines
KW  - Task analysis
KW  - Hardware
KW  - Manipulators
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793591
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We quantify the accuracy of various simulators compared to a real world robotic reaching and interaction task. Simulators are used in robotics to design solutions for real world hardware without the need for physical access. The `reality gap' prevents solutions developed or learnt in simulation from performing well, or at all, when transferred to real-world hardware. Making use of a Kinova robotic manipulator and a motion capture system, we record a ground truth enabling comparisons with various simulators, and present quantitative data for various manipulation-oriented robotic tasks. We show the relative strengths and weaknesses of numerous contemporary simulators, highlighting areas of significant discrepancy, and assisting researchers in the field in their selection of appropriate simulators for their use cases.
ER  - 

TY  - CONF
TI  - Are We Ready for Autonomous Drone Racing? The UZH-FPV Drone Racing Dataset
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6713
EP  - 6719
AU  - J. Delmerico
AU  - T. Cieslewski
AU  - H. Rebecq
AU  - M. Faessler
AU  - D. Scaramuzza
PY  - 2019
KW  - helicopters
KW  - image capture
KW  - image sensors
KW  - image sequences
KW  - motion estimation
KW  - remotely operated vehicles
KW  - video cameras
KW  - UZH-FPV Drone Racing dataset
KW  - first-person-view racing quadrotor
KW  - state estimation algorithms
KW  - autonomous Drone Racing
KW  - visual-inertial state estimation
KW  - motion estimation
KW  - Drones
KW  - Optical imaging
KW  - Cameras
KW  - Trajectory
KW  - Optical sensors
KW  - Measurement
KW  - High-speed optical techniques
DO  - 10.1109/ICRA.2019.8793887
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Despite impressive results in visual-inertial state estimation in recent years, high speed trajectories with six degree of freedom motion remain challenging for existing estimation algorithms. Aggressive trajectories feature large accelerations and rapid rotational motions, and when they pass close to objects in the environment, this induces large apparent motions in the vision sensors, all of which increase the difficulty in estimation. Existing benchmark datasets do not address these types of trajectories, instead focusing on slow speed or constrained trajectories, targeting other tasks such as inspection or driving. We introduce the UZH-FPV Drone Racing dataset, consisting of over 27 sequences, with more than 10 km of flight distance, captured on a first-person-view (FPV) racing quadrotor flown by an expert pilot. The dataset features camera images, inertial measurements, event-camera data, and precise ground truth poses. These sequences are faster and more challenging, in terms of apparent scene motion, than any existing dataset. Our goal is to enable advancement of the state of the art in aggressive motion estimation by providing a dataset that is beyond the capabilities of existing state estimation algorithms.
ER  - 

TY  - CONF
TI  - Practical guide to solve the minimum-effort problem with geometric algorithms and B-Splines
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6720
EP  - 6726
AU  - A. Paz
AU  - G. Arechavaleta
PY  - 2019
KW  - geometry
KW  - Jacobian matrices
KW  - legged locomotion
KW  - Lie algebras
KW  - Lie groups
KW  - motion control
KW  - optimal control
KW  - splines (mathematics)
KW  - discrete representation
KW  - direct collocation method
KW  - B-splines
KW  - biped robot
KW  - robot motions
KW  - articulated robots
KW  - Jacobian function
KW  - Lie groups
KW  - Lie algebra
KW  - transcription methods
KW  - numerical optimal control
KW  - geometric algorithms
KW  - minimum-effort problem
KW  - Splines (mathematics)
KW  - Robot motion
KW  - Optimal control
KW  - Mathematical model
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2019.8794398
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper focuses on important implementation issues of numerical optimal control that are often overlooked. In particular, transcription methods should be carefully implemented for obtaining a discrete representation of the problem. For this purpose, we explain the algorithms to solve the minimum-effort problem by applying a direct collocation method based on B-Splines. In addition, we describe how to compute the gradient of the objective function as well as the Jacobian of the constraints without the use of finite differences and automatic differentiation. Geometric algorithms based on Lie groups and Lie algebra are examined to efficiently compute the analytical derivatives of the equations of motion of articulated robots. These ingredients allow the fast computation of dynamically feasible robot motions. We provide numerical comparisons with a biped robot to validate our recipe against classical direct collocation methods.
ER  - 


TY  - CONF
TI  - Augmenting Action Model Learning by Non-Geometric Features
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7769
EP  - 7775
AU  - I. Nematollahi
AU  - D. Kuhner
AU  - T. Welschehold
AU  - W. Burgard
PY  - 2019
KW  - Gaussian processes
KW  - grippers
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mixture models
KW  - mobile robots
KW  - teaching
KW  - action model learning
KW  - nongeometric features
KW  - manipulation actions
KW  - action-induced reactions
KW  - measured liquid levels
KW  - explicit case dependent programming
KW  - external features
KW  - dynamic system
KW  - action imitation
KW  - geometric trajectory
KW  - real-world robot experiments
KW  - Gaussian mixture model representation
KW  - Robots
KW  - Trajectory
KW  - Task analysis
KW  - Liquids
KW  - Force measurement
KW  - Grippers
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794153
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning from demonstration is a powerful tool for teaching manipulation actions to a robot. It is, however, an unsolved problem how to consider knowledge about the world and action-induced reactions such as forces imposed onto the gripper or measured liquid levels during pouring without explicit and case dependent programming. In this paper, we present a novel approach to include such knowledge directly in form of measured features. To this end, we use action demonstrations together with external features to learn a motion encoded by a dynamic system in a Gaussian Mixture Model (GMM) representation. Accordingly, during action imitation, the system is able to couple the geometric trajectory of the motion to measured features in the scene. We demonstrate the feasibility of our approach with a broad range of external features in real-world robot experiments including a drinking, a handover and a pouring task.
ER  - 

TY  - CONF
TI  - Skill Acquisition via Automated Multi-Coordinate Cost Balancing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7776
EP  - 7782
AU  - H. Ravichandar
AU  - S. R. Ahmadzadeh
AU  - M. A. Rana
AU  - S. Chernova
PY  - 2019
KW  - convex programming
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - learning framework
KW  - MCCB
KW  - point-to-point movement skills
KW  - multiple differential coordinates
KW  - local geometric properties
KW  - convex optimization problem
KW  - multicoordinate cost function
KW  - complex skill datasets
KW  - skill acquisition
KW  - automated multicoordinate cost balancing
KW  - Trajectory
KW  - Laplace equations
KW  - Cost function
KW  - Task analysis
KW  - Encoding
KW  - Robots
DO  - 10.1109/ICRA.2019.8793762
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a learning framework, named Multi-Coordinate Cost Balancing (MCCB), to address the problem of acquiring point-to-point movement skills from demonstrations. MCCB encodes demonstrations simultaneously in multiple differential coordinates that specify local geometric properties. MCCB generates reproductions by solving a convex optimization problem with a multi-coordinate cost function and linear constraints on the reproductions, such as initial, target, and via points. Further, since the relative importance of each coordinate system in the cost function might be unknown for a given skill, MCCB learns optimal weighting factors that balance the cost function. We demonstrate the effectiveness of MCCB via detailed experiments conducted on one handwriting dataset and three complex skill datasets.
ER  - 

TY  - CONF
TI  - Real-time Multisensory Affordance-based Control for Adaptive Object Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7783
EP  - 7790
AU  - V. Chu
AU  - R. A. Gutierrez
AU  - S. Chernova
AU  - A. L. Thomaz
PY  - 2019
KW  - haptic interfaces
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - adaptive object manipulation
KW  - RMAC
KW  - multisensory inputs
KW  - real-time multisensory affordance-based control
KW  - affordance models
KW  - Robot sensing systems
KW  - Hidden Markov models
KW  - Trajectory
KW  - Adaptation models
KW  - Real-time systems
KW  - Data models
DO  - 10.1109/ICRA.2019.8793860
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We address the challenge of how a robot can adapt its actions to successfully manipulate objects it has not previously encountered. We introduce Real-time Multisensory Affordance-based Control (RMAC), which enables a robot to adapt existing affordance models using multisensory inputs. We show that using the combination of haptic, audio, and visual information with RMAC allows the robot to learn afforance models and adaptively manipulate two very different objects (drawer, lamp), in multiple novel configurations. Offline evaluations and real-time online evaluations show that RMAC allows the robot to accurately open different drawer configurations and turn-on novel lamps with an average accuracy of 75%.
ER  - 

TY  - CONF
TI  - Learning Behavior Trees From Demonstration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7791
EP  - 7797
AU  - K. French
AU  - S. Wu
AU  - T. Pan
AU  - Z. Zhou
AU  - O. C. Jenkins
PY  - 2019
KW  - control engineering computing
KW  - decision trees
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - LfD methods
KW  - decision trees
KW  - household cleaning task
KW  - Robotic Learning from Demonstration
KW  - primitive actions
KW  - Fetch robot
KW  - human teaching
KW  - robot programming
KW  - behavior trees
KW  - Task analysis
KW  - Decision trees
KW  - Service robots
KW  - Hidden Markov models
KW  - Real-time systems
KW  - Games
DO  - 10.1109/ICRA.2019.8794104
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic Learning from Demonstration (LfD) allows anyone, not just experts, to program a robot for an arbitrary task. Many LfD methods focus on low level primitive actions such as manipulator trajectories. Complex multistep task with many primitive actions must be learned from demonstration if LfD is to encompass the full range of task a user may desire. Existing methods represent the high level task in various forms including, finite state machines, decision trees, formal logic, among others. Behavior trees are proposed as an alternative representation of high level task. Behavior trees are an execution model for the control of a robot designed for real time execution, modularity, and, consequently, transparency. Real time execution allows the robot to reactively perform the task. Modularity allows the reuse of learned primitive actions and high level task in new situations, speeding up the process of learning in new scenarios. Transparency allows users to understand and interactively modify the learned model. Behavior trees are used to represent high level tasks by building on the relationship it has with decision trees. We demonstrate a human teaching our Fetch robot a household cleaning task.
ER  - 

TY  - CONF
TI  - Leveraging Temporal Reasoning for Policy Selection in Learning from Demonstration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7798
EP  - 7804
AU  - E. Carpio
AU  - M. Clark-Turner
AU  - P. Gesel
AU  - M. Begum
PY  - 2019
KW  - graph theory
KW  - learning by example
KW  - probability
KW  - temporal reasoning
KW  - policy selection
KW  - temporal reasoning model
KW  - Allen's interval algebra
KW  - sequential relations
KW  - parallel temporal relations
KW  - probabilistic inference
KW  - temporal context graph
KW  - learning from demonstration
KW  - perceptual aliasing
KW  - Task analysis
KW  - Hidden Markov models
KW  - Cognition
KW  - Context modeling
KW  - Robots
KW  - Algebra
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2019.8794461
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - High-level human activities often have rich temporal structures that determine the order in which atomic actions are executed. We propose the Temporal Context Graph (TCG), a temporal reasoning model that integrates probabilistic inference with Allen's interval algebra, to capture these temporal structures. TCGs are capable of modeling tasks with cyclical atomic actions and consisting of sequential and parallel temporal relations. We present Learning from Demonstration as the application domain where the use of TCGs can improve policy selection and address the problem of perceptual aliasing. Experiments validating the model are presented for learning two tasks from demonstration that involve structured human-robot interactions. The source code for this implementation is available at https://github.com/AssistiveRoboticsUNH/TCG.
ER  - 

TY  - CONF
TI  - Imitating Human Search Strategies for Assembly
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7821
EP  - 7827
AU  - D. Ehlers
AU  - M. Suomalainen
AU  - J. Lundell
AU  - V. Kyrki
PY  - 2019
KW  - collision avoidance
KW  - end effectors
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - robot vision
KW  - alignment tasks
KW  - human demonstrations
KW  - state invariant dynamics model
KW  - exploration distribution
KW  - search trajectory
KW  - deterministic ergodic control
KW  - position domains
KW  - superposed forces
KW  - learnt strategy
KW  - 3D electricity socket task
KW  - search task
KW  - human search strategies
KW  - Trajectory
KW  - Task analysis
KW  - Robot sensing systems
KW  - Search problems
KW  - Sockets
KW  - Impedance
DO  - 10.1109/ICRA.2019.8793780
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a Learning from Demonstration method for teaching robots to perform search strategies imitated from humans in scenarios where alignment tasks fail due to position uncertainty. The method utilizes human demonstrations to learn both a state invariant dynamics model and an exploration distribution that captures the search area covered by the demonstrator. We present two alternative algorithms for computing a search trajectory from the exploration distribution, one based on sampling and another based on deterministic ergodic control. We augment the search trajectory with forces learnt through the dynamics model to enable searching both in force and position domains. An impedance controller with superposed forces is used for reproducing the learnt strategy. We experimentally evaluate the method on a KUKA LWR4+ performing a 2D peg-in-hole and a 3D electricity socket task. Results show that the proposed method can, with only few human demonstrations, learn to complete the search task.
ER  - 

TY  - CONF
TI  - Active Multi-Contact Continuous Tactile Exploration with Gaussian Process Differential Entropy
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7844
EP  - 7850
AU  - D. Driess
AU  - D. Hennes
AU  - M. Toussaint
PY  - 2019
KW  - end effectors
KW  - entropy
KW  - Gaussian processes
KW  - mobile robots
KW  - path planning
KW  - tactile sensors
KW  - touch (physiological)
KW  - active multicontact continuous tactile exploration
KW  - Gaussian process differential entropy
KW  - active tactile exploration framework
KW  - exploration strategy
KW  - information theoretic context
KW  - nonmyopic multistep planning
KW  - end-effectors
KW  - tactile stimuli
KW  - compliant controller framework
KW  - tactile exploration approach
KW  - nonconvex objects
KW  - Gaussian process implicit surface model
KW  - sliding based tactile exploration
KW  - End effectors
KW  - Surface treatment
KW  - Robot sensing systems
KW  - Shape
KW  - Gaussian processes
KW  - Entropy
DO  - 10.1109/ICRA.2019.8793773
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In the present work, we propose an active tactile exploration framework to obtain a surface model of an unknown object utilizing multiple contacts simultaneously. To incorporate these multiple contacts, the exploration strategy is based on the differential entropy of the underlying Gaussian process implicit surface model, which formalizes the exploration with multiple contacts within an information theoretic context and additionally allows for nonmyopic multi-step planning. In contrast to many previous approaches, the robot continuously slides along the surface with its end-effectors to gather the tactile stimuli, instead of touching it at discrete locations. This is realized by closely integrating the surface model into the compliant controller framework. Furthermore, we extend our recently proposed sliding based tactile exploration approach to handle non-convex objects. In the experiments, it is shown that multiple contacts simultaneously leads to a more efficient exploration of complex, non-convex objects, not only in terms of time, but also with respect to the total moved distance of all end-effectors. Finally, we demonstrate our methodology with a real PR2 robot that explores an object with both of its arms.
ER  - 

TY  - CONF
TI  - Learning Robust Manipulation Skills with Guided Policy Search via Generative Motor Reflexes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7851
EP  - 7857
AU  - P. Ennen
AU  - P. Bresenitz
AU  - R. Vossen
AU  - F. Hees
PY  - 2019
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - search problems
KW  - trajectory control
KW  - robust manipulation skills
KW  - control policies
KW  - complex manipulation tasks
KW  - high-dimensional neural networks
KW  - robot actions
KW  - real-world trajectory samples
KW  - resulting neural networks
KW  - policy representation
KW  - robust actions
KW  - broader state space
KW  - state-dependent motor reflex
KW  - similar motor reflexes
KW  - real-world manipulation tasks
KW  - guided policy search
KW  - generative motor reflexes map states
KW  - state-action policies
KW  - Neural networks
KW  - Trajectory
KW  - Robots
KW  - Robustness
KW  - Reinforcement learning
KW  - Space exploration
KW  - Training
DO  - 10.1109/ICRA.2019.8793775
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Guided Policy Search enables robots to learn control policies for complex manipulation tasks efficiently. Therein, the control policies are represented as high-dimensional neural networks which derive robot actions based on states. However, due to the small number of real-world trajectory samples in Guided Policy Search, the resulting neural networks are only robust in the neighbourhood of the trajectory distribution explored by real-world interactions. In this paper, we present a new policy representation called Generative Motor Reflexes, which is able to generate robust actions over a broader state space compared to previous methods. In contrast to prior state-action policies, Generative Motor Reflexes map states to parameters for a state-dependent motor reflex, which is then used to derive actions. Robustness is achieved by generating similar motor reflexes for many states. We evaluate the presented method in simulated and real-world manipulation tasks, including contact-rich peg-in-hole tasks. Using these evaluation tasks, we show that policies represented as Generative Motor Reflexes lead to robust manipulation skills also outside the explored trajectory distribution with less training needs compared to previous methods.
ER  - 

TY  - CONF
TI  - Incremental Learning of Spatial-Temporal Features in Human Motion Patterns with Mixture Model for Planning Motion of a Collaborative Robot in Assembly Lines
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7858
EP  - 7864
AU  - A. KANAZAWA
AU  - J. KINUGAWA
AU  - K. KOSUGE
PY  - 2019
KW  - assembling
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - product quality
KW  - productivity
KW  - spatial-temporal features
KW  - human motion patterns
KW  - collaborative robot
KW  - assembly lines
KW  - incremental learning system
KW  - planning motion
KW  - products quality
KW  - workers behavior
KW  - Task analysis
KW  - Hidden Markov models
KW  - Mixture models
KW  - Predictive models
KW  - Data models
KW  - Trajectory
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8794227
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Collaborative robots are expected to work in cooperation with humans to improve productivity and maintain the quality of products. In the previous study, we have proposed an incremental learning system for adaptively scheduling a motion of the collaborative robot based on a worker's behavior. Although this system could model the worker's motion pattern precisely and robustly without collecting the worker's data in advance, it required two different models for modeling the worker's spatial and temporal features respectively and was not well considered for generalization. In this paper, we extend the previous incremental learning system by integrating the spatial and temporal models using a mixture model. In addition, we install a new incremental learning algorithm which improves a generalization capability of the mixture model and avoids overfitting in the situation where the prior information is limited. Implementing the proposed algorithm, we evaluate the effectiveness of the proposed system by experiments for several workers and for several assembly processes.
ER  - 

TY  - CONF
TI  - Learning Quickly to Plan Quickly Using Modular Meta-Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7865
EP  - 7871
AU  - R. Chitnis
AU  - L. P. Kaelbling
AU  - T. Lozano-Pérez
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - path planning
KW  - multiobject manipulation problems
KW  - continuous state
KW  - continuous operator parameters
KW  - state description
KW  - discrete parameters
KW  - single specializer
KW  - modular meta-learning approach
KW  - action spaces
KW  - 3D pick-and-place tasks
KW  - Task analysis
KW  - Planning
KW  - Robots
KW  - Skeleton
KW  - Search problems
KW  - Companies
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8794342
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Multi-object manipulation problems in continuous state and action spaces can be solved by planners that search over sampled values for the continuous parameters of operators. The efficiency of these planners depends critically on the effectiveness of the samplers used, but effective sampling in turn depends on details of the robot, environment, and task. Our strategy is to learn functions called speciatizers that generate values for continuous operator parameters, given a state description and values for the discrete parameters. Rather than trying to learn a single specializer for each operator from large amounts of data on a single task, we take a modular meta-learning approach. We train on multiple tasks and learn a variety of specializers that, on a new task, can be quickly adapted using relatively little data - thus, our system learns quickly to plan quickly using these specializers. We validate our approach experimentally in simulated 3D pick-and-place tasks with continuous state and action spaces. Visit http://tinyurl.com/chitnis-icra-19 for a supplementary video.
ER  - 

TY  - CONF
TI  - Deep Multi-Sensory Object Category Recognition Using Interactive Behavioral Exploration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7872
EP  - 7878
AU  - G. Tatiya
AU  - J. Sinapov
PY  - 2019
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - recurrent neural nets
KW  - robot vision
KW  - multisensory object category recognition
KW  - interactive behavioral exploration
KW  - deep learning methodology
KW  - visual data
KW  - haptic sensory data
KW  - haptic data
KW  - auditory data
KW  - sensory modality
KW  - visual information
KW  - dominant modality
KW  - auditory networks
KW  - convolutional neural networks
KW  - haptic networks
KW  - tensor-train gated recurrent unit network
KW  - robot category recognition
KW  - Haptic interfaces
KW  - Robot sensing systems
KW  - Visualization
KW  - Convolution
KW  - Network architecture
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8794095
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When identifying an object and its properties, humans use features from multiple sensory modalities produced when manipulating the object. Motivated by this cognitive process, we propose a deep learning methodology for object category recognition which uses visual, auditory, and haptic sensory data coupled with exploratory behaviors (e.g., grasping, lifting, pushing, etc.). In our method, as the robot performs an action on an object, it uses a Tensor-Train Gated Recurrent Unit network to process its visual data, and Convolutional Neural Networks to process haptic and auditory data. We propose a novel strategy to train a single neural network that inputs video, audio and haptic data, and demonstrate that its performance is better than separate neural networks for each sensory modality. The proposed method was evaluated on a dataset in which the robot explored 100 different objects, each belonging to one of 20 categories. While the visual information was the dominant modality for most categories, adding the additional haptic and auditory networks further improves the robot's category recognition accuracy. For some of the behaviors, our approach outperforms the previous published baseline for the dataset which used handcrafted features for each modality. We also show that a robot does not need the sensory data from the entire interaction, but instead can make a good prediction early on during behavior execution.
ER  - 

TY  - CONF
TI  - Discontinuity-Sensitive Optimal Control Learning by Mixture of Experts
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7892
EP  - 7898
AU  - G. Tang
AU  - K. Hauser
PY  - 2019
KW  - approximation theory
KW  - function approximation
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - nonlinear control systems
KW  - optimal control
KW  - optimisation
KW  - discontinuity-sensitive optimal control learning
KW  - machine learning method
KW  - parametric input
KW  - problem parameters
KW  - optimal solutions
KW  - problem-optimum map
KW  - discrete homotopy classes
KW  - control switching
KW  - MoE
KW  - standard neural networks
KW  - dynamic vehicle control problems
KW  - nonlinear optimal control problems
KW  - function approximators
KW  - mixture of experts model
KW  - trajectory prediction
KW  - Trajectory
KW  - Training
KW  - Optimal control
KW  - Neural networks
KW  - Optimization
KW  - Standards
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8793909
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a machine learning method to predict the solutions of related nonlinear optimal control problems given some parametric input, such as the initial state. The map between problem parameters to optimal solutions is called the problem-optimum map, and is often discontinuous due to nonconvexity, discrete homotopy classes, and control switching. This causes difficulties for traditional function approximators such as neural networks, which assume continuity of the underlying function. This paper proposes a mixture of experts (MoE) model composed of a classifier and several regressors, where each regressor is tuned to a particular continuous region. A novel training approach is proposed that trains classifier and regressors independently. MoE greatly outperforms standard neural networks, and achieves highly reliable trajectory prediction (over 99.5% accuracy) in several dynamic vehicle control problems.
ER  - 

TY  - CONF
TI  - Wormhole Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7899
EP  - 7905
AU  - A. Zanardi
AU  - J. Zilly
AU  - A. Aumiller
AU  - A. Censi
AU  - E. Frazzoli
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image sensors
KW  - infrared detectors
KW  - learning (artificial intelligence)
KW  - object detection
KW  - object detector
KW  - invariance properties
KW  - visible-light RGB camera
KW  - infrared sensor
KW  - temporary sensor
KW  - infrared detector
KW  - RGB-inferred labels
KW  - infrared-inferred labels
KW  - transfer learning
KW  - wormhole learning
KW  - pretrained RGB detector
KW  - Detectors
KW  - Task analysis
KW  - Robot sensing systems
KW  - Cameras
KW  - Lighting
KW  - Training
KW  - Mutual information
DO  - 10.1109/ICRA.2019.8794336
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Typically, to enlarge the operating domain of an object detector, more labeled training data is required. We describe a method called wormhole learning, which allows to extend the operating domain without additional data, but only with temporary access to an auxiliary sensor with certain invariance properties. We describe the instantiation of this principle with a regular visible-light RGB camera as the main sensor, and an infrared sensor as the temporary sensor. We start with a pre-trained RGB detector; then we train the infrared detector based on the RGB-inferred labels; finally we re-train the RGB detector based on the infrared-inferred labels. After these two transfer-learning steps, the RGB detector has enlarged its operating domain by inheriting part of the invariance to illumination of the infrared sensor; in particular, the RGB detector is now able to see much better at night. We analyze the wormhole learning phenomenon by bounding the possible gain in accuracy using mutual information properties of the two sensors and considered operating domain.
ER  - 

TY  - CONF
TI  - Sharing the Load: Human-Robot Team Lifting Using Muscle Activity
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7906
EP  - 7912
AU  - J. DelPreto
AU  - D. Rus
PY  - 2019
KW  - control engineering computing
KW  - electromyography
KW  - groupware
KW  - human computer interaction
KW  - human-robot interaction
KW  - lifting
KW  - muscle
KW  - neural nets
KW  - robotic assembly
KW  - signal detection
KW  - human-robot team lifting
KW  - muscle activity
KW  - surface electromyography
KW  - muscle signals
KW  - continuous setpoint algorithm
KW  - biceps activity
KW  - triceps activity
KW  - assembly tasks
KW  - physical human-robot collaboration
KW  - surface EMG
KW  - neural network
KW  - Muscles
KW  - Task analysis
KW  - Electromyography
KW  - Robot kinematics
KW  - Signal processing algorithms
KW  - Pipelines
DO  - 10.1109/ICRA.2019.8794414
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Seamless communication of desired motions and goals is essential for enabling effective physical human-robot collaboration. In such cases, muscle activity measured via surface electromyography (EMG) can provide insight into a person's intentions while minimally distracting from the task. The presented system uses two muscle signals to create a control framework for team lifting tasks in which a human and robot lift an object together. A continuous setpoint algorithm uses biceps activity to estimate changes in the user's hand height, and also allows the user to explicitly adjust the robot by stiffening or relaxing their arm. In addition to this pipeline, a neural network trained only on previous users classifies biceps and triceps activity to detect up or down gestures on a rolling basis; this enables finer control over the robot and expands the feasible workspace. The resulting system is evaluated by 10 untrained subjects performing a variety of team lifting and assembly tasks with rigid and flexible objects.
ER  - 

TY  - CONF
TI  - Position control of medical cable-driven flexible instruments by combining machine learning and kinematic analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7913
EP  - 7919
AU  - R. A. Porto
AU  - F. Nageotte
AU  - P. Zanne
AU  - M. d. Mathelin
PY  - 2019
KW  - cables (mechanical)
KW  - control engineering computing
KW  - endoscopes
KW  - flexible manipulators
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - medical computing
KW  - medical robotics
KW  - position control
KW  - robot kinematics
KW  - surgery
KW  - medical cable-driven flexible instruments
KW  - machine learning
KW  - kinematic analysis
KW  - cable transmissions
KW  - medical endoscopic systems
KW  - flexible medical robotic systems
KW  - open-loop accuracy
KW  - Position Inverse Kinematic Model
KW  - off-line learning
KW  - learning process
KW  - STRAS medical robot
KW  - position control
KW  - kinematic models
KW  - hysteresis effects
KW  - Instruments
KW  - Hysteresis motors
KW  - Hysteresis
KW  - Training
KW  - Kinematics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793692
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Non-linearities in cable transmissions are important limitations for the accurate control of flexible instruments used in medical endoscopic systems. Hysteresis effects greatly impact the accuracy of conventional kinematic models. This is especially critical for implementing automatic motions in flexible medical robotic systems. In this paper, we propose a method for improving open-loop accuracy of flexible instruments by implementing a Position Inverse Kinematic Model which is able to take into account hysteresis effects. In order to avoid complex physical modeling, the method relies on the off-line learning of the behavior of the instruments. Basic knowledge of the kinematic is also incorporated in the learning process in order to make it fast. The validity of the approach is demonstrated by the execution of 2D and 3D trajectories with the instruments of the STRAS medical robot. The accuracy is shown to be significantly improved with respect to other learning-based methods.
ER  - 

TY  - CONF
TI  - Online Learning for Proactive Obstacle Avoidance with Powered Transfemoral Prostheses
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7920
EP  - 7925
AU  - M. Gordon
AU  - N. Thatte
AU  - H. Geyer
PY  - 2019
KW  - adaptive control
KW  - collision avoidance
KW  - kinematics
KW  - medical control systems
KW  - prosthetics
KW  - regression analysis
KW  - regression model
KW  - kinematic data
KW  - obstacle avoidance system
KW  - obstacle avoidance success rates
KW  - prosthetic limb
KW  - adaptive system
KW  - powered prosthetic limbs
KW  - stumble recovery systems
KW  - powered prostheses
KW  - direct knee control
KW  - mechanically-passive transfemoral prosthetic limbs
KW  - powered transfemoral prostheses
KW  - proactive obstacle avoidance
KW  - online learning
KW  - amputee subject
KW  - obstacle negotiation success rate
KW  - trip avoidance system
KW  - nonamputee subject
KW  - Collision avoidance
KW  - Trajectory
KW  - Knee
KW  - Prosthetics
KW  - Legged locomotion
KW  - Sensitivity
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8794001
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Avoiding obstacles poses a significant challenge for amputees using mechanically-passive transfemoral prosthetic limbs due to their lack of direct knee control. In contrast, powered prostheses can potentially improve obstacle avoidance via their ability to add energy to the system. In past work, researchers have proposed stumble recovery systems for powered prosthetic limbs that provide assistance in the event of a trip. However, these systems only aid recovery after an obstacle has disrupted the user's gait and do not proactively help the amputee avoid obstacles. To address this problem, we designed an adaptive system that learns online to use kinematic data from the prosthetic limb to detect the user's obstacle avoidance intent in early swing. When the system detects an obstacle, it alters the planned swing trajectory to help avoid trips. Additionally, the system uses a regression model to predict the required knee flexion angle for the trip response. We validated the system by comparing obstacle avoidance success rates with and without the obstacle avoidance system. For a non-amputee subject wearing the prosthesis through an adapter, the trip avoidance system improved the obstacle negotiation success rate from 37% to 89%, while an amputee subject improved his success rate from 35% to 71% when compared to utilizing minimum jerk trajectories for the knee and ankle joints.
ER  - 

TY  - CONF
TI  - Passive Dynamic Object Locomotion by Rocking and Walking Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7926
EP  - 7932
AU  - A. Nazir
AU  - J. Seo
PY  - 2019
KW  - end effectors
KW  - gait analysis
KW  - legged locomotion
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - motion control
KW  - path planning
KW  - passive dynamic object locomotion
KW  - walking manipulation
KW  - zigzag path
KW  - kinematics
KW  - rocking motion
KW  - manipulator arm
KW  - robotic manipulation technique
KW  - rock-and-walk object transportation technique
KW  - simple end-effector
KW  - stable gait
KW  - rock-walk object locomotion
KW  - gravity force
KW  - Dynamics
KW  - Legged locomotion
KW  - Gravity
KW  - Manipulator dynamics
KW  - Kinematics
KW  - Rocks
DO  - 10.1109/ICRA.2019.8794163
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel robotic manipulation technique for transporting objects on the ground in a passive dynamic, nonprehensile manner. The object is manipulated to rock from side to side repeatedly; in the meantime, the force of gravity enables the object to roll along a zigzag path that is eventually heading forward. We call it rock-and-walk object locomotion. First, we examine the kinematics and dynamics of the rocking motion to understand how the states of the object evolve. We then discuss how to control the robot to connect individual rocking motions into a stable gait of the object. Our rock-and-walk object transportation technique is implemented using a conventional manipulator arm and a simple end-effector, interacting with the object in a nonprehensile manner in favor of the passive dynamics of the object. A set of experiments demonstrates successful object locomotion.
ER  - 

TY  - CONF
TI  - Autonomous Latching System for Robotic Boats
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7933
EP  - 7939
AU  - L. A. Mateos
AU  - W. Wang
AU  - B. Gheneti
AU  - F. Duarte
AU  - C. Ratti
AU  - D. Rus
PY  - 2019
KW  - boats
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - robot vision
KW  - robotic assembly
KW  - autonomous latching system
KW  - autonomous robotic boats
KW  - multiple boats
KW  - dynamic united floating infrastructure
KW  - latching mechanism
KW  - vision-based robot controller
KW  - docking
KW  - rotation movement
KW  - self-driving robotic boats
KW  - Robots
KW  - Boats
KW  - Sockets
KW  - Latches
KW  - Computer interfaces
KW  - Three-dimensional displays
KW  - Laser beams
DO  - 10.1109/ICRA.2019.8793525
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous robotic boats are devised to transport people and goods similar to self-driving cars. One of the attractive features specially applied in water environment is to dynamically link and join multiple boats into one unit in order to form floating infrastructure such as bridges, markets or concert stages, as well as autonomously self-detach to perform individual tasks.In this paper we present a novel latching system that enables robotic boats to create dynamic united floating infrastructure while overcoming water disturbances. The proposed latching mechanism is based on the spherical joint (ball and socket) that allows rotation and free movements in two planes at the same time. In this configuration, the latching system is capable to securely and efficiently assemble/disassemble floating structures. The vision-based robot controller guides the self-driving robotic boats to latch with high accuracy in the millimeter range. Moreover, in case the robotic boat fails to latch due to harsh weather, the autonomous latching system is capable to recompute and reposition to latch successfully. We present experimental results from latching and docking in indoor environments. Also, we present results in outdoor environments from latching a couple of robotic boats in open water with calm and turbulent currents.
ER  - 

TY  - CONF
TI  - Streaming Scene Maps for Co-Robotic Exploration in Bandwidth Limited Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7940
EP  - 7946
AU  - Y. Girdhar
AU  - L. Cai
AU  - S. Jamieson
AU  - N. McGuire
AU  - G. Flaspohler
AU  - S. Suman
AU  - B. Claus
PY  - 2019
KW  - autonomous underwater vehicles
KW  - geophysical image processing
KW  - image representation
KW  - object detection
KW  - oceanographic techniques
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - unsupervised learning
KW  - co-robotic exploration
KW  - bandwidth tunable technique
KW  - real-time probabilistic scene modeling
KW  - communication constrained environments
KW  - deep sea
KW  - scene complexity
KW  - bandwidth requirements
KW  - underwater robot
KW  - high-level semantic scene constructs
KW  - artificially constructed tank environment
KW  - science interests
KW  - unsupervised scene model impact
KW  - resulting scene model
KW  - coral reef
KW  - bandwidth constraints
KW  - scene maps streaming
KW  - Robot sensing systems
KW  - Bandwidth
KW  - Oceans
KW  - Data models
KW  - Visualization
KW  - Bayes methods
DO  - 10.1109/ICRA.2019.8794132
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a bandwidth tunable technique for real-time probabilistic scene modeling and mapping to enable co-robotic exploration in communication constrained environments such as the deep sea. The parameters of the system enable the user to characterize the scene complexity represented by the map, which in turn determines the bandwidth requirements. The approach is demonstrated using an underwater robot that learns an unsupervised scene model of the environment and then uses this scene model to communicate the spatial distribution of various high-level semantic scene constructs to a human operator. Preliminary experiments in an artificially constructed tank environment as well as simulated missions over a 10m×10m coral reef using real data show the tunability of the maps to different bandwidth constraints and science interests. To our knowledge this is the first paper to quantity how the free parameters of the unsupervised scene model impact both the scientific utility of and bandwidth required to communicate the resulting scene model.
ER  - 

TY  - CONF
TI  - UWStereoNet: Unsupervised Learning for Depth Estimation and Color Correction of Underwater Stereo Imagery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7947
EP  - 7954
AU  - K. A. Skinner
AU  - J. Zhang
AU  - E. A. Olson
AU  - M. Johnson-Roberson
PY  - 2019
KW  - cameras
KW  - computerised instrumentation
KW  - feature extraction
KW  - geophysical image processing
KW  - image colour analysis
KW  - image matching
KW  - image resolution
KW  - image restoration
KW  - light propagation
KW  - neural nets
KW  - oceanographic techniques
KW  - spatial variables measurement
KW  - stereo image processing
KW  - unsupervised learning
KW  - visual perception
KW  - unsupervised learning
KW  - stereo cameras
KW  - navigation
KW  - underwater robotic systems
KW  - constrained camera geometry
KW  - feature detection
KW  - underwater light propagation lead
KW  - deep learning
KW  - underwater image restoration
KW  - unsupervised deep neural network
KW  - input raw color underwater stereo imagery
KW  - color corrected imagery
KW  - underwater image formation
KW  - image processing techniques
KW  - depth estimation
KW  - stereo vision algorithms
KW  - disparity estimation
KW  - DNN
KW  - Image color analysis
KW  - Estimation
KW  - Image restoration
KW  - Cameras
KW  - Attenuation
KW  - Stereo vision
KW  - Deep learning
DO  - 10.1109/ICRA.2019.8794272
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Stereo cameras are widely used for sensing and navigation of underwater robotic systems. They can provide high resolution color views of a scene; the constrained camera geometry enables metrically accurate depth estimation; they are also relatively cost-effective. Traditional stereo vision algorithms rely on feature detection and matching to enable triangulation of points for estimating disparity. However, for underwater applications, the effects of underwater light propagation lead to image degradation, reducing image quality and contrast. This makes it especially challenging to detect and match features, especially from varying viewpoints. Recently, deep learning has shown success in end-to-end learning of dense disparity maps from stereo images. Still, many state-of-the-art methods are supervised and require ground truth depth or disparity, which is challenging to gather in subsea environments. Simultaneously, deep learning has also been applied to the problem of underwater image restoration. Again, it is difficult or impossible to gather real ground truth data for this problem. In this work, we present an unsupervised deep neural network (DNN) that takes input raw color underwater stereo imagery and outputs dense depth maps and color corrected imagery of underwater scenes. We leverage a model of the process of underwater image formation, image processing techniques, as well as the geometric constraints inherent to the stereo vision problem to develop a modular network that outperforms existing methods.
ER  - 

TY  - CONF
TI  - Design and Parameter Optimization of a 3-PSR Parallel Mechanism for Replicating Wave and Boat Motion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7955
EP  - 7961
AU  - K. Talke
AU  - D. Drotman
AU  - N. Stroumtsos
AU  - M. de Oliveira
AU  - T. Bewley
PY  - 2019
KW  - autonomous aerial vehicles
KW  - boats
KW  - marine safety
KW  - motion control
KW  - optimisation
KW  - pitch control (position)
KW  - ball joint mounting angle
KW  - experimental testing
KW  - boat motion replication
KW  - parameter optimization
KW  - 3-PSR parallel mechanism
KW  - three-degree-of-freedom
KW  - prismatic-spherical-revolute parallel mechanism
KW  - unmanned aerial vehicle
KW  - unmanned surface vehicle
KW  - lookup table
KW  - geometric constraints
KW  - wave replication
KW  - three actuated linear rails
KW  - UAV winch payload
KW  - inertial measurement unit
KW  - Boats
KW  - Fasteners
KW  - Testing
KW  - Rails
KW  - Sea state
KW  - Kinematics
KW  - Unmanned aerial vehicles
DO  - 10.1109/ICRA.2019.8793473
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a low-cost, three-degree-of-freedom (3-DOF) prismatic-spherical-revolute (PSR) parallel mechanism used as a testing platform for an unmanned aerial vehicle (UAV) tethered to an unmanned surface vehicle (USV). The mechanism has three actuated linear rails kinematically linked to a platform which replicates boat motion up to 2.5 m vertical heave (sea state 4, Douglas Sea Scale). A lookup table relating relative slider heights to platform roll and pitch was developed numerically leveraging geometric constraints. A design parameter study optimized the arm length, platform size, and ball joint mounting angle relative to the overall radius to maximize the workspace. For this design, a maximum roll and pitch range from -32° to 32° and -25° to 35°, respectively, is achievable. A prototype was manufactured to carry the tethered UAV winch payload. Experimental testing confirmed the workspace and demonstrated boat motion replication, validated using an inertial measurement unit (IMU).
ER  - 

TY  - CONF
TI  - A Framework for On-line Learning of Underwater Vehicles Dynamic Models
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7969
EP  - 7975
AU  - B. Wehbe
AU  - M. Hildebrandt
AU  - F. Kirchner
PY  - 2019
KW  - marine navigation
KW  - mobile robots
KW  - regression analysis
KW  - robot dynamics
KW  - support vector machines
KW  - tracking
KW  - underwater vehicles
KW  - vehicle dynamics
KW  - on-line learning
KW  - underwater vehicles dynamic models
KW  - accurate tracking controllers
KW  - navigation algorithms
KW  - high fidelity performance
KW  - robot dynamics
KW  - incremental support vector regression method
KW  - Robots
KW  - Vehicle dynamics
KW  - Adaptation models
KW  - Computational modeling
KW  - Heuristic algorithms
KW  - Support vector machines
KW  - Data models
DO  - 10.1109/ICRA.2019.8794403
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Learning the dynamics of robots from data can help achieve more accurate tracking controllers, or aid their navigation algorithms. However, when the actual dynamics of the robots change due to external conditions, on-line adaptation of their models is required to maintain high fidelity performance. In this work, a framework for on-line learning of robot dynamics is developed to adapt to such changes. The proposed framework employs an incremental support vector regression method to learn the model sequentially from data streams. In combination with the incremental learning, strategies for including and forgetting data are developed to obtain better generalization over the whole state space. The framework is tested in simulation and real experimental scenarios demonstrating its adaptation capabilities to changes in the robot's dynamics.
ER  - 

TY  - CONF
TI  - Incorporating End-to-End Speech Recognition Models for Sentiment Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7976
EP  - 7982
AU  - E. Lakomkin
AU  - M. A. Zamani
AU  - C. Weber
AU  - S. Magg
AU  - S. Wermter
PY  - 2019
KW  - emotion recognition
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - pattern classification
KW  - recurrent neural nets
KW  - speech recognition
KW  - text analysis
KW  - linguistic modality
KW  - expressed emotion
KW  - spoken text
KW  - ground-truth transcriptions
KW  - speech recognition mistakes
KW  - automatic speech recognition output
KW  - character-level recurrent neural network
KW  - sentiment recognition
KW  - acoustic modality
KW  - binary sentiment classification task
KW  - emotion recognition
KW  - synergistic effect
KW  - auditory transcribed text
KW  - transcribed text
KW  - sentiment intensity
KW  - end-to-end speech recognition models
KW  - sentiment analysis
KW  - ASR systems
KW  - multimodal corpus of sentiment intensity
KW  - MOSI
KW  - Acoustics
KW  - Feature extraction
KW  - Speech recognition
KW  - Training
KW  - Computational modeling
KW  - Computer architecture
KW  - Emotion recognition
DO  - 10.1109/ICRA.2019.8794468
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Previous work on emotion recognition demonstrated a synergistic effect of combining several modalities such as auditory, visual, and transcribed text to estimate the affective state of a speaker. Among these, the linguistic modality is crucial for the evaluation of an expressed emotion. However, manually transcribed spoken text cannot be given as input to a system practically. We argue that using ground-truth transcriptions during training and evaluation phases leads to a significant discrepancy in performance compared to real-world conditions, as the spoken text has to be recognized on the fly and can contain speech recognition mistakes. In this paper, we propose a method of integrating an automatic speech recognition (ASR) output with a character-level recurrent neural network for sentiment recognition. In addition, we conduct several experiments investigating sentiment recognition for human-robot interaction in a noise-realistic scenario which is challenging for the ASR systems. We quantify the improvement compared to using only the acoustic modality in sentiment recognition. We demonstrate the effectiveness of this approach on the Multimodal Corpus of Sentiment Intensity (MOSI) by achieving 73,6% accuracy in a binary sentiment classification task, exceeding previously reported results that use only acoustic input. In addition, we set a new state-of-the-art performance on the MOSI dataset (80.4% accuracy, 2% absolute improvement).
ER  - 

TY  - CONF
TI  - Improved Optical Flow for Gesture-based Human-robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7983
EP  - 7989
AU  - J. Chang
AU  - A. Tejero-de-Pablos
AU  - T. Harada
PY  - 2019
KW  - feature extraction
KW  - gesture recognition
KW  - human-robot interaction
KW  - neural nets
KW  - service robots
KW  - gesture interaction
KW  - human motion
KW  - gesture-based human-robot interaction
KW  - house service robot
KW  - practical robot applications
KW  - gesture recognition methods
KW  - optical flow estimation method
KW  - speed-accuracy trade-off
KW  - deep learning-based methods
KW  - feature extractors
KW  - midway features
KW  - Estimation
KW  - Optical imaging
KW  - Feature extraction
KW  - Gesture recognition
KW  - Robots
KW  - Optical fiber networks
KW  - Human-robot interaction
DO  - 10.1109/ICRA.2019.8793825
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Gesture interaction is a natural way of communicating with a robot as an alternative to speech. Gesture recognition methods leverage optical flow in order to understand human motion. However, while accurate optical flow estimation (i.e., traditional) methods are costly in terms of runtime, fast estimation (i.e., deep learning) methods' accuracy can be improved. In this paper, we present a pipeline for gesture-based human-robot interaction that uses a novel optical flow estimation method in order to achieve an improved speed-accuracy trade-off. Our optical flow estimation method introduces four improvements to previous deep learning-based methods: strong feature extractors, attention to contours, midway features, and a combination of these three. This results in a better understanding of motion, and a finer representation of silhouettes. In order to evaluate our pipeline, we generated our own dataset, MIBURI, which contains gestures to command a house service robot. In our experiments, we show how our method improves not only optical flow estimation, but also gesture recognition, offering a speed-accuracy trade-off more realistic for practical robot applications.
ER  - 

TY  - CONF
TI  - Decentralization of Multiagent Policies by Learning What to Communicate
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7990
EP  - 7996
AU  - J. Paulos
AU  - S. W. Chen
AU  - D. Shishika
AU  - V. Kumar
PY  - 2019
KW  - decentralised control
KW  - multi-agent systems
KW  - multi-robot systems
KW  - neurocontrollers
KW  - optimisation
KW  - multiagent policies
KW  - agent architecture
KW  - training methodology
KW  - neural networks
KW  - task-oriented communication semantics
KW  - communication-unaware expert policy
KW  - perimeter defense game
KW  - communication constraints
KW  - collaborative tasks
KW  - optimization
KW  - decentralization
KW  - Neural networks
KW  - Pins
KW  - Task analysis
KW  - Training
KW  - Games
KW  - Computer architecture
KW  - Decoding
DO  - 10.1109/ICRA.2019.8793777
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Effective communication is required for teams of robots to solve sophisticated collaborative tasks. In practice it is typical for both the encoding and semantics of communication to be manually defined by an expert; this is true regardless of whether the behaviors themselves are bespoke, optimization based, or learned. We present an agent architecture and training methodology using neural networks to learn task-oriented communication semantics based on the example of a communication-unaware expert policy. A perimeter defense game illustrates the system's ability to handle dynamically changing numbers of agents and its graceful degradation in performance as communication constraints are tightened or the expert's observability assumptions are broken.
ER  - 

TY  - CONF
TI  - Acquisition of Word-Object Associations from Human-Robot and Human-Human Dialogues
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7997
EP  - 8003
AU  - S. Sadeghi
AU  - B. Oosterveld
AU  - E. Krause
AU  - M. Scheutz
PY  - 2019
KW  - human-robot interaction
KW  - knowledge acquisition
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - human-robot dialogues
KW  - word-object associations
KW  - human-human dialogues
KW  - robotic system
KW  - AI agents
KW  - cross-situational learning
KW  - Instruction-based word learning
KW  - Robots
KW  - Semantics
KW  - Syntactics
KW  - Learning systems
KW  - Linguistics
KW  - Education
KW  - Computer architecture
DO  - 10.1109/ICRA.2019.8793615
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Past work on acquisition of word-object associations in robots has focused on either fast instruction-based methods which accept highly constrained input or gradual cross-situational learning methods, but not a mixture of both. In this paper, we present an integrated robotic system which allows for a combination of these methods to contribute to the task of learning the labels of objects in AI agents. We demonstrate the expanded word learning capabilities in the outcome system and how learning from both human-human and human-robot dialogues can be achieved in one integrated system.
ER  - 

TY  - CONF
TI  - Robot Object Referencing through Legible Situated Projections
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8004
EP  - 8010
AU  - T. Weng
AU  - L. Perlmutter
AU  - S. Nikolaidis
AU  - S. Srinivasa
AU  - M. Cakmak
PY  - 2019
KW  - helmet mounted displays
KW  - human-robot interaction
KW  - mobile robots
KW  - object detection
KW  - target object
KW  - PR2 robot
KW  - robot object
KW  - legible situated projections
KW  - reference objects
KW  - complex task-oriented human-robot collaborations
KW  - robot-to-human information transfer
KW  - visual referencing
KW  - arrow-object match functions
KW  - head-mounted projector
KW  - Task analysis
KW  - Collaboration
KW  - Legged locomotion
KW  - Communication channels
KW  - Visualization
KW  - Computer science
DO  - 10.1109/ICRA.2019.8793638
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to reference objects in the environment is a key communication skill that robots need for complex, task-oriented human-robot collaborations. In this paper we explore the use of projections, which are a powerful communication channel for robot-to-human information transfer as they allow for situated, instantaneous, and parallelized visual referencing. We focus on the question of what makes a good projection for referencing a target object. To that end, we mathematically formulatelegibility of projections intended to reference an object, and propose alternative arrow-object match functions for optimally computing the placement of an arrow to indicate a target object in a cluttered scene. We implement our approach on a PR2 robot with a head-mounted projector. Through an online (48 participants) and an in-person (12 participants) user study we validate the effectiveness of our approach, identify the types of scenes where projections may fail, and characterize the differences between alternative match functions.
ER  - 

TY  - CONF
TI  - Security-Aware Synthesis of Human-UAV Protocols
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8011
EP  - 8017
AU  - M. Elfar
AU  - H. Zhu
AU  - M. L. Cummings
AU  - M. Pajic
PY  - 2019
KW  - autonomous aerial vehicles
KW  - command and control systems
KW  - control engineering computing
KW  - formal verification
KW  - learning (artificial intelligence)
KW  - military aircraft
KW  - stochastic games
KW  - security-aware synthesis
KW  - human-UAV protocols
KW  - collaboration protocols
KW  - human-unmanned aerial vehicle
KW  - geolocation task
KW  - stochastic game-based model
KW  - stealthy false-data injection attacks
KW  - collected experimental data
KW  - human-UAV coalition
KW  - H-UAV protocol synthesis
KW  - human operators
KW  - UAV hidden-information constraint
KW  - RESCHU-SA testbed
KW  - geolocation strategies
KW  - model checkers
KW  - command and control systems
KW  - Games
KW  - Task analysis
KW  - Protocols
KW  - Geology
KW  - Stochastic processes
KW  - Security
KW  - Global Positioning System
DO  - 10.1109/ICRA.2019.8794385
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we synthesize collaboration protocols for human-unmanned aerial vehicle (H-UAV) command and control systems, where the human operator aids in securing the UAV by intermittently performing geolocation tasks to confirm its reported location. We first present a stochastic game-based model for the system that accounts for both the operator and an adversary capable of launching stealthy false-data injection attacks, causing the UAV to deviate from its path. We also describe a synthesis challenge due to the UAV's hidden-information constraint. Next, we perform human experiments using a developed RESCHU-SA testbed to recognize the geolocation strategies that operators adopt. Furthermore, we deploy machine learning techniques on the collected experimental data to predict the correctness of a geolocation task at a given location based on its geographical features. By representing the model as a delayed-action game and formalizing the system objectives, we utilize off-the-shelf model checkers to synthesize protocols for the human-UAV coalition that satisfy these objectives. Finally, we demonstrate the usefulness of the H-UAV protocol synthesis through a case study where the protocols are experimentally analyzed and further evaluated by human operators.
ER  - 

TY  - CONF
TI  - Underwater Communication Using Full-Body Gestures and Optimal Variable-Length Prefix Codes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8018
EP  - 8025
AU  - K. Koreitem
AU  - J. Li
AU  - I. Karp
AU  - T. Manderson
AU  - G. Dudek
PY  - 2019
KW  - convolutional neural nets
KW  - decoding
KW  - encoding
KW  - gesture recognition
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-robot systems
KW  - protocols
KW  - variable length codes
KW  - optimal variable-length prefix codes
KW  - interrobot communication
KW  - action sequences
KW  - swimming robot
KW  - communication protocol
KW  - whole-body gestures
KW  - radio-denied environments
KW  - passive communication
KW  - full-body gestures
KW  - underwater communication
KW  - robot gesture execution
KW  - classical decoding methods
KW  - observer robot
KW  - convolutional network
KW  - natural activity
KW  - Robots
KW  - Encoding
KW  - Decoding
KW  - Three-dimensional displays
KW  - Visualization
KW  - Heuristic algorithms
KW  - Target tracking
DO  - 10.1109/ICRA.2019.8793644
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we consider inter-robot communication in the context of joint activities. In particular, we focus on convoying and passive communication for radio-denied environments by using whole-body gestures to provide cues regarding future actions. We develop a communication protocol whereby information described by codewords is transmitted by a series of actions executed by a swimming robot. These action sequences are chosen to optimize robustness and transmission duration given the observability, natural activity of the robot and the frequency of different messages. Our approach uses a convolutional network to make core observations of the pose of the robot being tracked, which is sending messages. The observer robot then uses an adaptation of classical decoding methods to infer a message that is being transmitted. The system is trained and validated using simulated data, tested in the pool and is targeted for deployment in the open ocean. Our decoder achieves.94 precision and.66 recall on real footage of robot gesture execution recorded in a swimming pool.
ER  - 

TY  - CONF
TI  - WISDOM: WIreless Sensing-assisted Distributed Online Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8026
EP  - 8033
AU  - C. Adhivarahan
AU  - K. Dantu
PY  - 2019
KW  - least mean squares methods
KW  - mobile robots
KW  - path planning
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - WISDOM
KW  - spatial sensing
KW  - robotics
KW  - augmented reality
KW  - urban spaces
KW  - wireless access points
KW  - coarse orientation
KW  - average Root Mean Square mapping error
KW  - wireless sensing-assisted distributed online mapping
KW  - robot swarm
KW  - custom ICP algorithm
KW  - absolute trajectory error
KW  - average root mean square mapping error
KW  - size 0.2 m
KW  - size 1.3 m
KW  - Three-dimensional displays
KW  - Simultaneous localization and mapping
KW  - Robot kinematics
KW  - Visualization
KW  - Merging
DO  - 10.1109/ICRA.2019.8793932
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Spatial sensing is a fundamental requirement for applications in robotics and augmented reality. In urban spaces such as malls, airports, apartments, and others, it is quite challenging for a single robot to map the whole environment. So, we employ a swarm of robots to perform the mapping. One challenge with this approach is merging sub-maps built by each robot. In this work, we use wireless access points, which are ubiquitous in most urban spaces, to provide us with coarse orientation between sub-maps, and use a custom ICP algorithm to refine this orientation to merge them. We demonstrate our approach with maps from a building on campus and evaluate it using two metrics. Our results show that, in the building we studied, we can achieve an average Absolute Trajectory error of 0.2m in comparison to a map created by a single robot and average Root Mean Square mapping error of 1.3m from ground truth landmark locations.
ER  - 

TY  - CONF
TI  - Learning Recursive Bayesian Nonparametric Modeling of Moving Targets via Mobile Decentralized Sensors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8034
EP  - 8040
AU  - C. Liu
AU  - Y. Chen
AU  - J. Gemerek
AU  - H. Yang
AU  - S. Ferrari
PY  - 2019
KW  - Bayes methods
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - recursive estimation
KW  - sensor fusion
KW  - mobile decentralized sensors
KW  - multisensor applications
KW  - GP recursive fusion law
KW  - recursive DPGP fusion approach
KW  - data fusion
KW  - Gaussian processes
KW  - recursive Bayesian nonparametric modeling
KW  - Dirichlet process
KW  - Sensor fusion
KW  - Computational modeling
KW  - Gaussian processes
KW  - Time measurement
KW  - Kinematics
KW  - Velocity measurement
DO  - 10.1109/ICRA.2019.8793879
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Bayesian nonparametric models, such as the Dirichlet Process Gaussian Process (DPGP), have been shown very effective at learning models of dynamic targets exclusively from data. Previous work on batch DPGP learning and inference, however, ceases to be efficient in multi-sensor applications that require decentralized measurements to be obtained sequentially over time. Batch processing, in this case, leads to redundant computations that may hinder online applicability. This paper develops a recursive approach for DPGP learning and inference in which a novel Dirichlet Process prior based on Wasserstein metric is used for measuring the similarity between multiple Gaussian Processes (GPs). Combined with the GP recursive fusion law, the proposed recursive DPGP fusion approach enables efficient online data fusion. The problem of active sensing for recursive DPGP learning and inference is also investigated by uncertainty reduction via expected mutual information. Simulation and experimental results show that the proposed approach successfully learns the models of moving targets and outperforms existing benchmark methods.
ER  - 

TY  - CONF
TI  - UAV/UGV Autonomous Cooperation: UAV assists UGV to climb a cliff by attaching a tether
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8041
EP  - 8047
AU  - T. Miki
AU  - P. Khrapchenkov
AU  - K. Hori
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - inertial navigation
KW  - mobile robots
KW  - off-road vehicles
KW  - robot vision
KW  - SLAM (robots)
KW  - Unmanned Aerial Vehicle
KW  - Unmanned Ground Vehicle
KW  - tether attachment device
KW  - steep terrain
KW  - tether anchoring
KW  - UGV autonomous cooperation
KW  - UAV autonomous cooperation
KW  - visual inertial navigation
KW  - collaborative navigation
KW  - 3D voxel mapping
KW  - obstacle avoidance planning
KW  - traversability analysis
KW  - Robot sensing systems
KW  - Navigation
KW  - Three-dimensional displays
KW  - Unmanned aerial vehicles
KW  - Trajectory
KW  - Attitude control
DO  - 10.1109/ICRA.2019.8794265
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a novel cooperative system for an Unmanned Aerial Vehicle (UAV) and an Unmanned Ground Vehicle (UGV) which utilizes the UAV not only as a flying sensor but also as a tether attachment device. Two robots are connected with a tether, allowing the UAV to anchor the tether to a structure located at the top of a steep terrain, impossible to reach for UGVs. Thus, enhancing the poor traversability of the UGV by not only providing a wider range of scanning and mapping from the air, but also by allowing the UGV to climb steep terrains with the winding of the tether. In addition, we present an autonomous framework for the collaborative navigation and tether attachment in an unknown environment. The UAV employs visual inertial navigation with 3D voxel mapping and obstacle avoidance planning. The UGV makes use of the voxel map and generates an elevation map to execute path planning based on a traversability analysis. Furthermore, we compared the pros and cons of possible methods for the tether anchoring from multiple points of view. To increase the probability of successful anchoring, we evaluated the anchoring strategy with an experiment. Finally, the feasibility and capability of our proposed system were demonstrated by an autonomous mission experiment in the field with an obstacle and a cliff.
ER  - 

TY  - CONF
TI  - Distributed Motion Tomography for Reconstruction of Flow Fields*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8048
EP  - 8054
AU  - D. Chang
AU  - F. Zhang
AU  - J. Sun
PY  - 2019
KW  - inverse problems
KW  - linear systems
KW  - multi-agent systems
KW  - nonlinear equations
KW  - nonlinear systems
KW  - optimisation
KW  - distributed nonlinear Kaczmarz method
KW  - constrained consensus problem
KW  - gyre flow field
KW  - distributed motion tomography
KW  - mobile sensing agents
KW  - inverse problem
KW  - distributed multiagent systems
KW  - flow field reconstruction
KW  - nonlinear system of equations
KW  - optimization approach
KW  - linear system of equations
KW  - Trajectory
KW  - Mathematical model
KW  - Robot sensing systems
KW  - Optimization
KW  - Tomography
KW  - Estimation
KW  - Inverse problems
DO  - 10.1109/ICRA.2019.8793797
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper considers a group of mobile sensing agents in a flow field and presents a distributed method for motion tomography (MT) that estimates the underlying flow field. MT formulates an underdetermined nonlinear system of equations as an inverse problem. Inspired by the Kaczmarz method which is an optimization approach for solving a linear system of equations, our previous work developed a nonlinear Kaczmarz method that solves the system of equations associated with MT. Considering distributed multi-agent systems for MT, this paper extends the nonlinear Kaczmarz method into a distributed framework. The distributed nonlinear Kaczmarz method is developed by formulating a constrained consensus problem that belongs to a class of projected consensus algorithms. To study the convergence and consensus for the method, its linear case is analyzed first and then its nonlinear case is discussed. The nonlinear case of the method is further validated through simulations by estimating a gyre flow field using mobile sensor networks with different numbers of neighboring agents. Resulting estimated flow fields are compared with a flow field estimated by its centralized counterpart.
ER  - 

TY  - CONF
TI  - Who Takes What: Using RGB-D Camera and Inertial Sensor for Unmanned Monitor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8063
EP  - 8069
AU  - H. Kao
AU  - T. Ke
AU  - K. C. Lin
AU  - Y. Tseng
PY  - 2019
KW  - cameras
KW  - feature extraction
KW  - human computer interaction
KW  - image colour analysis
KW  - image matching
KW  - image sensors
KW  - Internet of Things
KW  - robot vision
KW  - video signal processing
KW  - WTW
KW  - IMU data
KW  - inertial sensor
KW  - RGB-d camera
KW  - unmanned monitor
KW  - IoT
KW  - human-environment interaction
KW  - Internet of Things
KW  - vision-based approaches
KW  - user-object matching
KW  - video recorded
KW  - Cameras
KW  - Skeleton
KW  - Feature extraction
KW  - Monitoring
KW  - Reliability
KW  - Trajectory
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793858
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Advanced Internet of Things (IoT) techniques have made human-environment interaction much easier. Existing solutions usually enable such interactions without knowing the identities of action performers. However, identifying users who are interacting with environments is a key to enable personalized service. To provide such add-on service, we propose WTW (who takes what), a system that identifies which user takes what object. Unlike traditional vision-based approaches, which are typically vulnerable to blockage, our WTW combines the feature information of three types of data, i.e., images, skeletons and IMU data, to enable reliable user-object matching and identification. By correlating the moving trajectory of a user monitored by inertial sensors with the movement of an object recorded in the video, our WTW reliably identifies a user and matches him/her with the object on action. Our prototype evaluation shows that WTW achieves a recognition rate of over 90% even in a crowd. The system is reliable even when users locate close by and take objects roughly at the same time.
ER  - 

TY  - CONF
TI  - Sound-Indicated Visual Object Detection for Robotic Exploration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8070
EP  - 8076
AU  - F. Wang
AU  - D. Guo
AU  - H. Liu
AU  - J. Zhou
AU  - F. Sun
PY  - 2019
KW  - acoustic signal detection
KW  - audio signal processing
KW  - microphones
KW  - mobile robots
KW  - neural net architecture
KW  - object detection
KW  - source separation
KW  - supervised learning
KW  - robotic exploration
KW  - microphones
KW  - cameras
KW  - physical world
KW  - visual modalities
KW  - audio modalities
KW  - robotic platforms
KW  - robotic sound-indicated visual object detection framework
KW  - two-stream weakly-supervised deep learning architecture
KW  - sounding object localization
KW  - AudioSet
KW  - Visualization
KW  - Object detection
KW  - Robots
KW  - Feature extraction
KW  - Task analysis
KW  - Semantics
KW  - Deep learning
DO  - 10.1109/ICRA.2019.8794166
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots are usually equipped with microphones and cameras to perceive and understand the physical world. Though visual object detection technology has achieved great success, the detection in other modalities remains unsolved. In this paper, we establish a novel robotic sound-indicated visual object detection framework, and develop a two-stream weakly-supervised deep learning architecture to connect the visual and audio modalities for localizing the sounding object. A dataset is constructed from the AudioSet to validate the proposed method and some promising applications are demonstrated on robotic platforms.
ER  - 

TY  - CONF
TI  - HG-DAgger: Interactive Imitation Learning with Human Experts
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8077
EP  - 8083
AU  - M. Kelly
AU  - C. Sidrane
AU  - K. Driggs-Campbell
AU  - M. J. Kochenderfer
PY  - 2019
KW  - learning (artificial intelligence)
KW  - HG-DAgger
KW  - interactive imitation learning
KW  - behavioral cloning
KW  - data mismatch
KW  - DAgger algorithm
KW  - sampling schemes
KW  - action labels
KW  - autonomous driving task
KW  - corrective actions
KW  - Safety
KW  - Cloning
KW  - Training
KW  - Measurement
KW  - Trajectory
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793698
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Imitation learning has proven to be useful for many real-world problems, but approaches such as behavioral cloning suffer from data mismatch and compounding error issues. One attempt to address these limitations is the DAgger algorithm, which uses the state distribution induced by the novice to sample corrective actions from the expert. Such sampling schemes, however, require the expert to provide action labels without being fully in control of the system. This can decrease safety and, when using humans as experts, is likely to degrade the quality of the collected labels due to perceived actuator lag. In this work, we propose HG-DAgger, a variant of DAgger that is more suitable for interactive imitation learning from human experts in real-world systems. In addition to training a novice policy, HG-DAgger also learns a safety threshold for a model-uncertainty-based risk metric that can be used to predict the performance of the fully trained novice in different regions of the state space. We evaluate our method on both a simulated and real-world autonomous driving task, and demonstrate improved performance over both DAgger and behavioral cloning.
ER  - 

TY  - CONF
TI  - Proximity Human-Robot Interaction Using Pointing Gestures and a Wrist-mounted IMU
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8084
EP  - 8091
AU  - B. Gromov
AU  - G. Abbate
AU  - L. M. Gambardella
AU  - A. Giusti
PY  - 2019
KW  - gesture recognition
KW  - human-robot interaction
KW  - mobile robots
KW  - pointed locations
KW  - slow ground robots
KW  - proximity human-robot interaction
KW  - pointing gestures
KW  - wrist-mounted IMU
KW  - co-located humans
KW  - mobile robots
KW  - moving robot
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Real-time systems
KW  - Drones
KW  - Trajectory
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8794399
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a system for interaction between co-located humans and mobile robots, which uses pointing gestures sensed by a wrist-mounted IMU. The operator begins by pointing, for a short time, at a moving robot. The system thus simultaneously determines: that the operator wants to interact; the robot they want to interact with; and the relative pose among the two. Then, the system can reconstruct pointed locations in the robot's own reference frame, and provide real-time feedback about them so that the user can adapt to misalignments. We discuss the challenges to be solved to implement such a system and propose practical solutions, including variants for fast flying robots and slow ground robots. We report different experiments with real robots and untrained users, validating the individual components and the system as a whole.
ER  - 

TY  - CONF
TI  - Lidar Measurement Bias Estimation via Return Waveform Modelling in a Context of 3D Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8100
EP  - 8106
AU  - J. Laconte
AU  - S. Deschênes
AU  - M. Labussière
AU  - F. Pomerleau
PY  - 2019
KW  - Gaussian distribution
KW  - optical radar
KW  - sensor fusion
KW  - multiple sensors
KW  - Robosense RS-LiDAR-16
KW  - accurate maps
KW  - lidar measurement bias estimation
KW  - return waveform modelling
KW  - zero-mean Gaussian distribution
KW  - localisation drifts
KW  - Laser radar
KW  - Laser beams
KW  - Two dimensional displays
KW  - Sensors
KW  - Laser modes
KW  - Robots
KW  - Computational modeling
KW  - Bias Estimation
KW  - Sensor Error Modelling
KW  - Waveform Modelling
KW  - LIDAR
KW  - 3D Mapping
DO  - 10.1109/ICRA.2019.8793671
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In a context of 3D mapping, it is very important to obtain accurate measurements from sensors. In particular, Light Detection And Ranging (LIDAR) measurements are typically treated as a zero-mean Gaussian distribution. We show that this assumption leads to predictable localisation drifts, especially when a bias related to measuring obstacles with high incidence angles is not taken into consideration. Moreover, we present a way to physically understand and model this bias, which generalizes to multiple sensors. Using an experimental setup, we measured the bias of the Sick LMS151, Velodyne HDL-32E, and Robosense RS-LiDAR-16 as a function of depth and incidence angle, and showed that the bias can reach 20 cm for high incidence angles. We then used our model to remove the bias from the measurements, leading to more accurate maps and a reduced localisation drift.
ER  - 

TY  - CONF
TI  - An Extrinsic Calibration Tool for Radar, Camera and Lidar
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8107
EP  - 8113
AU  - J. Domhof
AU  - J. F. P. Kooij
AU  - D. M. Gavrila
PY  - 2019
KW  - calibration
KW  - cameras
KW  - Gaussian noise
KW  - optical radar
KW  - pose estimation
KW  - probability
KW  - radar imaging
KW  - lidar
KW  - joint extrinsic calibration
KW  - sensing modalities
KW  - calibration target design
KW  - calibration procedure
KW  - multimodal measurements
KW  - optimization criterion
KW  - error terms
KW  - sensor pairs
KW  - calibration boards
KW  - calibration performance
KW  - camera errors
KW  - radar errors
KW  - extrinsic calibration tool
KW  - novel open-source tool
KW  - loop closure constraints
KW  - pose estimation
KW  - zero mean Gaussian noise
KW  - probabilistic model
KW  - Calibration
KW  - Cameras
KW  - Laser radar
KW  - Tools
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8794186
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel open-source tool for extrinsic calibration of radar, camera and lidar. Unlike currently available offerings, our tool facilitates joint extrinsic calibration of all three sensing modalities on multiple measurements. Furthermore, our calibration target design extends existing work to obtain simultaneous measurements for all these modalities. We study how various factors of the calibration procedure affect the outcome on real multi-modal measurements of the target. Three different configurations of the optimization criterion are considered, namely using error terms for a minimal amount of sensor pairs, or using terms for all sensor pairs with additional loop closure constraints, or by adding terms for structure estimation in a probabilistic model. The experiments further evaluate how the number of calibration boards affect calibration performance, and robustness against different levels of zero mean Gaussian noise. Our results show that all configurations achieve good results for lidar to camera errors and that fully connected pose estimation shows the best performance for lidar to radar errors when more than five board locations are used.
ER  - 

TY  - CONF
TI  - Compensation of measurement noise and bias in geometric attitude estimation*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8130
EP  - 8135
AU  - Y. Mitikiri
AU  - K. Mohseni
PY  - 2019
KW  - approximation theory
KW  - geometry
KW  - Kalman filters
KW  - nonlinear filters
KW  - measurement noise
KW  - geometric attitude estimation
KW  - geometry-based analytic attitude estimation
KW  - single reference vector
KW  - rigid body attitude estimation
KW  - residual error
KW  - geometric solution
KW  - rate measurements
KW  - methodical perturbation analysis
KW  - bias estimator
KW  - nonlinear problem
KW  - optimal Kalman gain
KW  - vector measurement
KW  - linearization approximations
KW  - sxtended Kalman filter
KW  - Angular velocity
KW  - Velocity measurement
KW  - Noise measurement
KW  - Measurement uncertainty
KW  - Q measurement
KW  - Estimation
KW  - Quaternions
DO  - 10.1109/ICRA.2019.8793504
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A geometry-based analytic attitude estimation using a rate measurement and measurement of a single reference vector has been recently proposed. Because rigid body attitude estimation is a fundamentally nonlinear problem, the geometry-based method does not contain errors consequent to linearization approximations. A critical source of residual error in the geometric solution is on account of the noise and bias in the vector and rate measurements. A methodical perturbation analysis of the attitude estimate is performed in this paper that reveals the effects of measurement noise and bias, and provides means to compensate for, or filter out, such errors. Application of the filter and compensation provides better attitude estimation than a standard Extended Kalman filter using an optimal Kalman gain. The geometric method is first verified in experiments and then simulation results are provided that validate the better performance of the geometric attitude and bias estimator.
ER  - 

TY  - CONF
TI  - Hierarchical Depthwise Graph Convolutional Neural Network for 3D Semantic Segmentation of Point Clouds
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8152
EP  - 8158
AU  - Z. Liang
AU  - M. Yang
AU  - L. Deng
AU  - C. Wang
AU  - B. Wang
PY  - 2019
KW  - convolutional neural nets
KW  - feature extraction
KW  - graph theory
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - stereo image processing
KW  - hierarchical depthwise graph convolutional neural network
KW  - 3D semantic segmentation
KW  - point clouds
KW  - point cloud semantic segmentation
KW  - depthwise convolution
KW  - pointwise convolution
KW  - local feature extraction
KW  - local features
KW  - global features
KW  - graph convolution
KW  - depthwise graph convolution
KW  - Three-dimensional displays
KW  - Convolution
KW  - Feature extraction
KW  - Semantics
KW  - Memory management
KW  - Shape
KW  - Convolutional neural networks
DO  - 10.1109/ICRA.2019.8794052
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a hierarchical depthwise graph convolutional neural network (HDGCN) for point cloud semantic segmentation. The main chanllenge for learning on point clouds is to capture local structures or relationships. Graph convolution has the strong ability to extract local shape information from neighbors. Inspired by depthwise convolution, we propose a depthwise graph convolution which requires less memory consumption compared with the previous graph convolution. While depthwise graph convolution aggregates features channel-wisely, pointwise convolution is used to learn features across different channels. A customized block called DGConv is specially designed for local feature extraction based on depthwise graph convolution and pointwise convolution. The DGConv block can extract features from points and transfer features to neighbors while being invariant to different point orders. HDGCN is constructed by a series of DGConv blocks using a hierarchical structure which can extract both local and global features of point clouds. Experiments show that HDGCN achieves the state-of-the-art performance in the indoor dataset S3DIS and the outdoor dataset Paris-Lille-3D.
ER  - 

TY  - CONF
TI  - CELLO-3D: Estimating the Covariance of ICP in the Real World
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8190
EP  - 8196
AU  - D. Landry
AU  - F. Pomerleau
AU  - P. Giguère
PY  - 2019
KW  - covariance analysis
KW  - covariance matrices
KW  - data analysis
KW  - image registration
KW  - iterative methods
KW  - state estimation
KW  - CELLO-3D
KW  - state estimation frameworks
KW  - closed-form covariance estimation algorithms
KW  - data-driven approach
KW  - uncertainty estimation
KW  - closed-form solutions
KW  - covariance estimation and learning through likelihood optimization framework
KW  - iterative closest point registrations
KW  - 3D datasets
KW  - ICP registrations
KW  - real 3D point clouds
KW  - Three-dimensional displays
KW  - Estimation
KW  - Linear programming
KW  - Uncertainty
KW  - Prediction algorithms
KW  - Measurement
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793516
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The fusion of Iterative Closest Point (ICP) registrations in existing state estimation frameworks relies on an accurate estimation of their uncertainty. In this paper, we study the estimation of this uncertainty in the form of a covariance. First, we scrutinize the limitations of existing closed-form covariance estimation algorithms over 3D datasets. Then, we set out to estimate the covariance of ICP registrations through a data-driven approach, with over 5100000 registrations on 1020 pairs from real 3D point clouds. We assess our solution upon a wide spectrum of environments, ranging from structured to unstructured and indoor to outdoor. The capacity of our algorithm to predict covariances is accurately assessed, as well as the usefulness of these estimations for uncertainty estimation over trajectories. The proposed method estimates covariances better than existing closed-form solutions, and makes predictions that are consistent with observed trajectories.
ER  - 

TY  - CONF
TI  - Low-latency Visual SLAM with Appearance-Enhanced Local Map Building
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8213
EP  - 8219
AU  - Y. Zhao
AU  - W. Ye
AU  - P. A. Vela
PY  - 2019
KW  - file organisation
KW  - image enhancement
KW  - image fusion
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - appearance-enhanced local map building
KW  - local map module
KW  - local map contents
KW  - co-visibility local map building
KW  - compact local map
KW  - downstream data association
KW  - mapped features
KW  - local map size
KW  - appearance-based local map building method
KW  - low-latency visual SLAM
KW  - pose estimation
KW  - multi-index hashing
KW  - online hash table selection algorithm
KW  - MIH
KW  - VO-VSLAM mean performance
KW  - Three-dimensional displays
KW  - Buildings
KW  - Optimization
KW  - Feature extraction
KW  - Indexing
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2019.8794046
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A local map module is often implemented in modern VO/VSLAM systems to improve data association and pose estimation. Conventionally, the local map contents are determined by co-visibility. While co-visibility is cheap to establish, it utilizes the relatively-weak temporal prior (i.e. seen before, likely to be seen now), therefore admitting more features into the local map than necessary. This paper describes an enhancement to co-visibility local map building by incorporating a strong appearance prior, which leads to a more compact local map and latency reduction in downstream data association. The appearance prior collected from the current image influences the local map contents: only the map features visually similar to the current measurements are potentially useful for data association. To that end, mapped features are indexed and queried with Multi-index Hashing (MIH). An online hash table selection algorithm is developed to further reduce the query overhead of MIH and the local map size. The proposed appearance-based local map building method is integrated into a state-of-the-art VO/VSLAM system. When evaluated on two public benchmarks, the size of the local map, as well as the latency of real-time pose tracking in VO/VSLAM are significantly reduced. Meanwhile, the VO/VSLAM mean performance is preserved or improves.
ER  - 

TY  - CONF
TI  - Incremental Visual-Inertial 3D Mesh Generation with Structural Regularities
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8220
EP  - 8226
AU  - A. Rosinol
AU  - T. Sattler
AU  - M. Pollefeys
AU  - L. Carlone
PY  - 2019
KW  - computational complexity
KW  - computational geometry
KW  - graph theory
KW  - mesh generation
KW  - mobile robots
KW  - optimisation
KW  - robot vision
KW  - SLAM (robots)
KW  - state estimation
KW  - structural regularities
KW  - point cloud representation
KW  - tightly couple mesh regularization
KW  - VIO optimization
KW  - per-frame approach
KW  - visual-inertial odometry algorithms
KW  - visual-inertial 3D mesh generation
KW  - decouple state estimation
KW  - factor-graph formulation
KW  - computational complexity
KW  - memory usage
KW  - localization accuracy
KW  - Three-dimensional displays
KW  - Optimization
KW  - Two dimensional displays
KW  - State estimation
KW  - Cameras
KW  - Histograms
KW  - Mesh generation
KW  - SLAM
KW  - Vision-Based Navigation
KW  - Sensor Fusion
DO  - 10.1109/ICRA.2019.8794456
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual-Inertial Odometry (VIO) algorithms typically rely on a point cloud representation of the scene that does not model the topology of the environment. A 3D mesh instead offers a richer, yet lightweight, model. Nevertheless, building a 3D mesh out of the sparse and noisy 3D landmarks triangulated by a VIO algorithm often results in a mesh that does not fit the real scene. In order to regularize the mesh, previous approaches decouple state estimation from the 3D mesh regularization step, and either limit the 3D mesh to the current frame [1], [2] or let the mesh grow indefinitely [3], [4]. We propose instead to tightly couple mesh regularization and state estimation by detecting and enforcing structural regularities in a novel factor-graph formulation. We also propose to incrementally build the mesh by restricting its extent to the time-horizon of the VIO optimization; the resulting 3D mesh covers a larger portion of the scene than a per-frame approach while its memory usage and computational complexity remain bounded. We show that our approach successfully regularizes the mesh, while improving localization accuracy, when structural regularities are present, and remains operational in scenes without regularities.
ER  - 

TY  - CONF
TI  - Unsupervised Out-of-context Action Understanding
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8227
EP  - 8233
AU  - H. Kataoka
AU  - Y. Satoh
PY  - 2019
KW  - convolutional neural nets
KW  - image sequences
KW  - motion estimation
KW  - unsupervised learning
KW  - human action
KW  - video sequence
KW  - unsupervised label
KW  - synthetic databases
KW  - unsupervised learning method
KW  - O2CA ground truth
KW  - SURREAL-O2CA
KW  - unsupervised out-of-context action understanding
KW  - Databases
KW  - Unsupervised learning
KW  - Sports
KW  - Context modeling
KW  - Legged locomotion
KW  - Video sequences
DO  - 10.1109/ICRA.2019.8793709
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper presents an unsupervised out-of-context action (O2CA) paradigm that is based on facilitating understanding by separately presenting both human action and context within a video sequence. As a means of generating an unsupervised label, we comprehensively evaluate responses from action-based (ActionNet) and context-based (ContextNet) convolutional neural networks (CNNs). Additionally, we have created three synthetic databases based on the human action (UCF101, HMDB51) and motion capture (mocap) (SURREAL) datasets. We then conducted experimental comparisons between our approach and conventional approaches. We also compared our unsupervised learning method with supervised learning using an O2CA ground truth given by synthetic data. From the results obtained, we achieved a 96.8 score on Synth-UCF, a 96.8 score on Synth-HMDB, and 89.0 on SURREAL-O2CA with F-score.
ER  - 

TY  - CONF
TI  - Air-to-Ground Surveillance Using Predictive Pursuit
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8234
EP  - 8240
AU  - S. Dutta
AU  - C. Ekenna
PY  - 2019
KW  - autonomous aerial vehicles
KW  - Markov processes
KW  - mobile robots
KW  - object tracking
KW  - path planning
KW  - surveillance
KW  - target tracking
KW  - air-to-ground surveillance
KW  - predictive pursuit
KW  - Markov decision process
KW  - tracking time
KW  - location detection accuracy
KW  - air-to-ground robot surveillance scenario
KW  - surveillance algorithms
KW  - camera
KW  - unmanned ground vehicle
KW  - UGV
KW  - observed path
KW  - pursuit algorithm
KW  - target localization
KW  - high predictive accuracy
KW  - Planning
KW  - Surveillance
KW  - Markov processes
KW  - Prediction algorithms
KW  - Trajectory
KW  - Measurement
KW  - Drones
DO  - 10.1109/ICRA.2019.8794073
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces a probabilistic prediction model with a novel variant of the Markov decision process to improve tracking time and location detection accuracy in an air-to-ground robot surveillance scenario. While most surveillance algorithms focus mainly on controls of an unmanned aerial vehicle (UAV) and camera for faster tracking of an unmanned ground vehicle (UGV), this paper proposes a way of minimizing detection and tracking time by applying a prediction model to the first observed path taken by the UGV. We present a pursuit algorithm that addresses the problem of target (UGV) localization by combining prediction of used planning algorithm by the target, and application of the same planning algorithm to predict future trajectories. Our results show a high predictive accuracy based on a final position attained by the target and the location predicted by our model.
ER  - 

TY  - CONF
TI  - Online Planning for Target Object Search in Clutter under Partial Observability
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8241
EP  - 8247
AU  - Y. Xiao
AU  - S. Katt
AU  - A. t. Pas
AU  - S. Chen
AU  - C. Amato
PY  - 2019
KW  - manipulators
KW  - Markov processes
KW  - Monte Carlo methods
KW  - path planning
KW  - PA-POMCP algorithm
KW  - action partially observable Monte-Carlo planning
KW  - object movements
KW  - manipulation actions
KW  - partially observable Markov decision process
KW  - target object search task
KW  - partial observability
KW  - online planning
KW  - Search problems
KW  - Task analysis
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Uncertainty
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793494
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The problem of finding and grasping a target object in a cluttered, uncertain environment, target object search, is a common and important problem in robotics. One key challenge is the uncertainty of locating and recognizing each object in a cluttered environment due to noisy perception and occlusions. Furthermore, the uncertainty in localization makes manipulation difficult and uncertain. To cope with these challenges, we formulate the target object search task as a partially observable Markov decision process (POMDP), enabling the robot to reason about perceptual and manipulation uncertainty while searching. To further address the manipulation difficulty, we propose Parameterized Action Partially Observable Monte-Carlo Planning (PA-POMCP), an algorithm that evaluates manipulation actions by taking into account the effect of the robot's current belief on the success of the action execution. In addition, a novel run-time initial belief generator and a state value estimator are introduced in this paper to facilitate the PA-POMCP algorithm. Our experiments show that our methods solve the target object search task in settings where simpler methods either take more object movements or fail.
ER  - 

TY  - CONF
TI  - Learning to Drive in a Day
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8248
EP  - 8254
AU  - A. Kendall
AU  - J. Hawke
AU  - D. Janz
AU  - P. Mazur
AU  - D. Reda
AU  - J. Allen
AU  - V. Lam
AU  - A. Bewley
AU  - A. Shah
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - road safety
KW  - road traffic control
KW  - road vehicles
KW  - robot vision
KW  - autonomous driving tasks
KW  - single monocular image
KW  - safety driver
KW  - model-free deep reinforcement learning algorithm
KW  - lane following
KW  - on-vehicle
KW  - Reinforcement learning
KW  - Autonomous vehicles
KW  - Task analysis
KW  - Markov processes
KW  - Global Positioning System
KW  - Sensors
KW  - Training
DO  - 10.1109/ICRA.2019.8793742
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We demonstrate the first application of deep reinforcement learning to autonomous driving. From randomly initialised parameters, our model is able to learn a policy for lane following in a handful of training episodes using a single monocular image as input. We provide a general and easy to obtain reward: the distance travelled by the vehicle without the safety driver taking control. We use a continuous, model-free deep reinforcement learning algorithm, with all exploration and optimisation performed on-vehicle. This demonstrates a new framework for autonomous driving which moves away from reliance on defined logical rules, mapping, and direct supervision. We discuss the challenges and opportunities to scale this approach to a broader range of autonomous driving tasks.
ER  - 

TY  - CONF
TI  - Generating Adversarial Driving Scenarios in High-Fidelity Simulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8271
EP  - 8277
AU  - Y. Abeysirigoonawardena
AU  - F. Shkurti
AU  - G. Dudek
PY  - 2019
KW  - automobile industry
KW  - Bayes methods
KW  - computer vision
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - program testing
KW  - road traffic
KW  - road vehicles
KW  - traffic engineering computing
KW  - transportation
KW  - self-driving policy
KW  - simulated pedestrians
KW  - self-driving behavior
KW  - high-fidelity simulators
KW  - public roads
KW  - software tests
KW  - self-driving software
KW  - adversarial self-driving scenarios
KW  - self-driving vehicles
KW  - transportation systems
KW  - simulated driving scenarios
KW  - driving scenario generation
KW  - self-driving car industry
KW  - Bayesian optimization
KW  - vision-based imitation learning
KW  - Optimization
KW  - Accidents
KW  - Rendering (computer graphics)
KW  - Bayes methods
KW  - Reinforcement learning
KW  - Roads
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793740
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems. Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on high-fidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle. It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios. The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1]. In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using vision-based imitation learning we obtain safer self-driving behavior.
ER  - 

TY  - CONF
TI  - Data-Driven Contact Clustering for Robot Simulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8278
EP  - 8284
AU  - M. Kim
AU  - J. Yoon
AU  - D. Son
AU  - D. Lee
PY  - 2019
KW  - control engineering computing
KW  - force sensors
KW  - learning (artificial intelligence)
KW  - multilayer perceptrons
KW  - optimisation
KW  - pattern clustering
KW  - robots
KW  - data-driven contact clustering
KW  - rigid-body robot simulation
KW  - multilayer perceptron network
KW  - constraint-based optimization contact solver
KW  - contact simulation
KW  - data-driven learning-based contact clustering
KW  - force sensors
KW  - torque sensors
KW  - MLP network
KW  - Force
KW  - Numerical models
KW  - Robot sensing systems
KW  - Data models
KW  - Numerical stability
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793938
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel data-driven learning-based contact clustering (i.e., of contact points and contact normals) framework for rigid-body robot simulation, with its accuracy established/verified by real experimental data. We first construct an experimental robotic setup with force/torque (F/T) sensors to collect real contact motion/force data. We then design a multilayer perceptron (MLP) network for the contact clustering based on the full motion and force/torque information of the contacts. We also adopt the constraint-based optimization contact solver to facilitate the learning of our MLP network during the training. Our proposed data-driven/learning-based contact clustering framework is then verified against the experimental setup, compared with other techniques/simulators and shown to significantly (or meaningfully) enhance the accuracy of contact simulation as compared to them.
ER  - 

TY  - CONF
TI  - Pavilion: Bridging Photo-Realism and Robotics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8285
EP  - 8290
AU  - F. Jiang
AU  - Q. Hao
PY  - 2019
KW  - control engineering computing
KW  - image sequences
KW  - mobile robots
KW  - sensor fusion
KW  - virtual reality
KW  - Pavilion
KW  - bridging photo-realism
KW  - robotics
KW  - sensor fusion
KW  - robot control
KW  - novel open-source simulation system
KW  - robot perception
KW  - kinematic control
KW  - ROS
KW  - shader-based method
KW  - optical flow ground-truth data
KW  - Gazebo-compatible real-time simulation system
KW  - control algorithms
KW  - simulation environment
KW  - state-of-the-art simulators
KW  - simulation accuracy
KW  - simulation environments
KW  - unreal engine
KW  - simulation description format robot models
KW  - robot operating system
KW  - Engines
KW  - Robot sensing systems
KW  - Data models
KW  - Real-time systems
KW  - Pipelines
KW  - Optical sensors
DO  - 10.1109/ICRA.2019.8794235
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Simulation environments play a centric role in the research of sensor fusion and robot control. This paper presents Pavilion, a novel open-source simulation system, for robot perception and kinematic control based on the Unreal Engine and the Robot Operating System (ROS). The novelty of this work includes threefold: (1) developing a shader-based method to generate optical flow ground-truth data with the Unreal Engine, (2) developing a toolset to remove binary incompatibility between ROS and the Unreal Engine to enable real-time interaction, and (3) developing a method to directly import Simulation Description Format (SDF) robot models into the Unreal Engine at runtime. Finally, a Gazebo-compatible real-time simulation system is developed to enable training and evaluation of a large number of sensor fusion, planning, decision and control algorithms. The system can be implemented on both Linux and macOS, with the latest version of ROS. Various experiments have been performed to validate the superior performance of the proposed simulation environment over other state-of-the-art simulators in terms of number of modalities, simulation accuracy, latency and degree of integration difficulty.
ER  - 

TY  - CONF
TI  - A Real-Time Interactive Augmented Reality Depth Estimation Technique for Surgical Robotics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8291
EP  - 8297
AU  - M. Kalia
AU  - N. Navab
AU  - T. Salcudean
PY  - 2019
KW  - augmented reality
KW  - kinematics
KW  - medical computing
KW  - medical robotics
KW  - surgery
KW  - Stereo-No CDE
KW  - CDE technique
KW  - forward kinematics joint encoder data
KW  - surgical field
KW  - virtual surgical instrument method
KW  - AR technique
KW  - blue-red color spectrum
KW  - tissue surface
KW  - tumor
KW  - medical abnormality
KW  - surgical robotics
KW  - color depth encoding
KW  - real-time interactive augmented reality depth estimation
KW  - Tools
KW  - Robots
KW  - Tumors
KW  - Image color analysis
KW  - Cameras
KW  - Instruments
KW  - Biomedical imaging
DO  - 10.1109/ICRA.2019.8793610
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Augmented reality (AR) is a promising technology where the surgeon can see the medical abnormality in the context of the patient. It makes the anatomy of interest visible to the surgeon which otherwise is not visible. It can result in better surgical precision and therefore, potentially better surgical outcomes and faster recovery times. Despite these benefits, the current AR systems suffer from two major challenges; first, incorrect depth perception and, second, the lack of suitable evaluation systems. Therefore, in the current paper we addressed both of these problems. We proposed a color depth encoding (CDE) technique to estimate the distance between the tumor and the tissue surface using a surgical instrument. We mapped the distance between the tumor and the tissue surface to the blue-red color spectrum. For evaluation and interaction with our AR technique, we propose to use a virtual surgical instrument method using the CAD model of the instrument. The users were asked to reach the judged distance in the surgical field using the virtual tool. Realistic tool movement was simulated by collecting the forward kinematics joint encoder data. The results showed significant improvement in depth estimation, time for task completion and confidence, using our CDE technique with and without stereo versus other two cases, that are, Stereo-No CDE and No Stereo-No CDE.
ER  - 

TY  - CONF
TI  - Force-based Heterogeneous Traffic Simulation for Autonomous Vehicle Testing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8298
EP  - 8304
AU  - Q. Chao
AU  - X. Jin
AU  - H. Huang
AU  - S. Foong
AU  - L. Yu
AU  - S. Yeung
PY  - 2019
KW  - computer simulation
KW  - control engineering computing
KW  - driver information systems
KW  - mobile robots
KW  - road safety
KW  - road traffic control
KW  - road vehicles
KW  - traffic engineering computing
KW  - self-driving tests
KW  - force-based concept
KW  - heterogenous traffic simulation
KW  - realistic urban environment
KW  - personal mobility devices
KW  - pedestrians
KW  - autonomous vehicles
KW  - traffic control
KW  - high-fidelity driving simulator
KW  - autonomous vehicle testing
KW  - force-based heterogeneous traffic simulation
KW  - Force
KW  - Autonomous vehicles
KW  - Roads
KW  - Acceleration
KW  - Bicycles
KW  - Testing
KW  - Urban areas
DO  - 10.1109/ICRA.2019.8794430
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent failures in real-world self-driving tests have suggested a paradigm shift from directly learning in real-world roads to building a high-fidelity driving simulator as an alternative, effective, and safe tool to handle intricate traffic environments in urban areas. To date, traffic simulation can construct virtual urban environments with various weather conditions, day and night, and traffic control for autonomous vehicle testing. However, mutual interactions between autonomous vehicles and pedestrians are rarely modeled in existing simulators. Besides vehicles and pedestrians, the usage of personal mobility devices is increasing in congested cities as an alternative to the traditional transport system. A simulator that considers all potential road-users in a realistic urban environment is urgently desired. In this work, we propose a novel, extensible, and microscopic method to build heterogenous traffic simulation using the force-based concept. This force-based approach can accurately replicate the sophisticated behaviors of various road users and their interactions through a simple and unified way. Furthermore, we validate our approach through simulation experiments and comparisons to the popular simulators currently used for research and development of autonomous vehicles.
ER  - 

TY  - CONF
TI  - Dual Refinement Network for Single-Shot Object Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8305
EP  - 8310
AU  - X. Chen
AU  - X. Yang
AU  - S. Kong
AU  - Z. Wu
AU  - J. Yu
PY  - 2019
KW  - convolutional neural nets
KW  - object detection
KW  - single-stage detector
KW  - dual refinement network
KW  - anchor refinement
KW  - single-shot object detection
KW  - object detection methods
KW  - two-stage detectors
KW  - anchor-offset detection
KW  - PASCAL VOC
KW  - ImageNet VID datasets
KW  - Feature extraction
KW  - Detectors
KW  - Head
KW  - Proposals
KW  - Object detection
KW  - Fuses
KW  - Pipelines
DO  - 10.1109/ICRA.2019.8793816
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Object detection methods fall into two categories, i.e., two-stage and single-stage detectors. The former is characterized by high detection accuracy while the latter usually has a considerable inference speed. Hence, it is imperative to fuse their merits for a better accuracy vs. speed trade-off. To this end, we propose a dual refinement network (DRN) to boost the performance of the single-stage detector. Inheriting from the advantages of two-stage approaches (i.e., two-step regression and accurate features for detection), anchor refinement and feature offset refinement are conducted in a novel anchor-offset detection, where the detection head is comprised of deformable convolutions. Moreover, to leverage contextual information for describing objects, we design a multi-deformable head, in which multiple detection paths with different receptive field sizes devote themselves to detecting objects. Extensive experiments on PASCAL VOC and ImageNet VID datasets are conducted, and we achieve a state-of-the-art detection performance in terms of both accuracy and inference speed.
ER  - 

TY  - CONF
TI  - Distant Vehicle Detection Using Radar and Vision
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8311
EP  - 8317
AU  - S. Chadwick
AU  - W. Maddern
AU  - P. Newman
PY  - 2019
KW  - cameras
KW  - computer vision
KW  - convolutional neural nets
KW  - image capture
KW  - object detection
KW  - road vehicle radar
KW  - distant vehicle detection
KW  - autonomous vehicles
KW  - convolutional neural networks
KW  - image-based object detectors
KW  - radar data
KW  - vision
KW  - KITTI
KW  - cameras
KW  - focal lengths
KW  - Cameras
KW  - Radar imaging
KW  - Detectors
KW  - Object detection
KW  - Doppler radar
KW  - Training
DO  - 10.1109/ICRA.2019.8794312
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For autonomous vehicles to be able to operate successfully they need to be aware of other vehicles with sufficient time to make safe, stable plans. Given the possible closing speeds between two vehicles, this necessitates the ability to accurately detect distant vehicles. Many current image-based object detectors using convolutional neural networks exhibit excellent performance on existing datasets such as KITTI. However, the performance of these networks falls when detecting small (distant) objects. We demonstrate that incorporating radar data can boost performance in these difficult situations. We also introduce an efficient automated method for training data generation using cameras of different focal lengths.
ER  - 

TY  - CONF
TI  - Customizing Object Detectors for Indoor Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8318
EP  - 8324
AU  - S. Alabachi
AU  - G. Sukthankar
AU  - R. Sukthankar
PY  - 2019
KW  - control engineering computing
KW  - convolutional neural nets
KW  - helicopters
KW  - neurocontrollers
KW  - object detection
KW  - robot vision
KW  - indoor robots
KW  - object detection models
KW  - convolutional neural networks
KW  - large-scale labeled datasets
KW  - training data
KW  - DUNet
KW  - dense upscaled network
KW  - Detectors
KW  - Object detection
KW  - Robots
KW  - Feature extraction
KW  - Labeling
KW  - Computer architecture
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793551
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Object detection models based on convolutional neural networks (CNNs) demonstrate impressive performance when trained on large-scale labeled datasets. While a generic object detector trained on such a dataset performs adequately in applications where the input data is similar to user photographs, the detector performs poorly on small objects, particularly ones with limited training data or imaged from uncommon viewpoints. Also, a specific room will have many objects that are missed by standard object detectors, frustrating a robot that continually operates in the same indoor environment.This paper describes a system for rapidly creating customized object detectors. Data is collected from a quadcopter that is teleoperated with an interactive interface. Once an object is selected, the quadcopter autonomously photographs the object from multiple viewpoints to collect data to train DUNet (Dense Upscaled Network), our proposed model for learning customized object detectors from scratch given limited data. Our experiments compare the performance of learning models from scratch with DUNet vs. fine tuning existing state of the art object detectors, both on our indoor robotics domain and on standard datasets.
ER  - 

TY  - CONF
TI  - Semi Supervised Deep Quick Instance Detection and Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8325
EP  - 8331
AU  - A. Kumar
AU  - L. Behera
PY  - 2019
KW  - convolutional neural nets
KW  - data acquisition
KW  - image segmentation
KW  - object detection
KW  - supervised learning
KW  - class-agnostic object detection
KW  - semisupervised labeling
KW  - occlusion aware clutter synthesis
KW  - online learning
KW  - semisupervised deep quick instance detection
KW  - semisupervised deep quick learning framework
KW  - data acquisition
KW  - convolutional neural network
KW  - pixelwise semantic segmentation
KW  - Image segmentation
KW  - Task analysis
KW  - Object segmentation
KW  - Clutter
KW  - Semantics
KW  - Labeling
KW  - Object detection
DO  - 10.1109/ICRA.2019.8793595
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a semi supervised deep quick learning framework for instance detection and pixelwise semantic segmentation of images in a dense clutter of items. The framework can quickly and incrementally learn novel items in an online manner by real-time data acquisition and generating corresponding ground truths on its own. To learn various combinations of items, it can synthesize cluttered scenes, in real time. The overall approach is based on the tutor-child analogy in which a deep network (tutor) is pretrained for class-agnostic object detection which generates labeled data for another deep network (child). The child utilizes a customized convolutional neural network head for the purpose of quick learning. There are broadly four key components of the proposed framework: semi supervised labeling, occlusion aware clutter synthesis, a customized convolutional neural network head, and instance detection. The initial version of this framework was implemented during our participation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked 3rd rd, 4th and 5 th worldwide in pick, stow-pick and stow task respectively. The proposed framework is an improved version over ARC'17 where novel features such as instance detection and online learning has been added.
ER  - 

TY  - CONF
TI  - Mixed Frame-/Event-Driven Fast Pedestrian Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8332
EP  - 8338
AU  - Z. Jiang
AU  - P. Xia
AU  - K. Huang
AU  - W. Stechele
AU  - G. Chen
AU  - Z. Bing
AU  - A. Knoll
PY  - 2019
KW  - cameras
KW  - computer vision
KW  - convolutional neural nets
KW  - image fusion
KW  - image sensors
KW  - pedestrians
KW  - traffic engineering computing
KW  - conventional frame-based camera
KW  - bad light condition
KW  - high-speed motion
KW  - gray-scale frames
KW  - traffic monitoring scenario
KW  - YOLOv3 models
KW  - YOLO-tiny models
KW  - confidence map fusion method
KW  - CNN-based detection results
KW  - DAVIS channels
KW  - intelligent transportation system
KW  - mixed frame-event-driven fast pedestrian detection
KW  - ITS
KW  - frame-based camera
KW  - dynamic and active pixel sensor
KW  - asynchronous low-latency temporal contrast events
KW  - convolutional neural networks
KW  - TUM campus
KW  - Voltage control
KW  - Vision sensors
KW  - Feature extraction
KW  - Neuromorphics
KW  - Cameras
KW  - Object detection
DO  - 10.1109/ICRA.2019.8793924
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pedestrian detection has attracted enormous research attention in the field of Intelligent Transportation System (ITS) due to that pedestrians are the most vulnerable traffic participants. So far, almost all pedestrian detection solutions are based on the conventional frame-based camera. However, they cannot perform very well in scenarios with bad light condition and high-speed motion. In this work, a Dynamic and Active Pixel Sensor (DAVIS), whose two channels concurrently output conventional gray-scale frames and asynchronous low-latency temporal contrast events of light intensity, was first used to detect pedestrians in a traffic monitoring scenario. Data from two camera channels were fed into Convolutional Neural Networks (CNNs) including three YOLOv3 models and three YOLO-tiny models to gather bounding boxes of pedestrians with respective confidence map. Furthermore, a confidence map fusion method combining the CNN-based detection results from both DAVIS channels was proposed to obtain higher accuracy. The experiments were conducted on a custom dataset collected on TUM campus. Benefiting from the high speed, low latency and wide dynamic range of the event channel, our method achieved higher frame rate and lower latency than those only using a conventional camera. Additionally, it reached higher average precision by using the fusion approach.
ER  - 

TY  - CONF
TI  - Real-Time Vehicle Detection from Short-range Aerial Image with Compressed MobileNet
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8339
EP  - 8345
AU  - Y. He
AU  - Z. Pan
AU  - L. Li
AU  - Y. Shan
AU  - D. Cao
AU  - L. Chen
PY  - 2019
KW  - feature extraction
KW  - mobile computing
KW  - motorcycles
KW  - neural nets
KW  - object detection
KW  - road vehicles
KW  - traffic engineering computing
KW  - MobileNet family network engineering
KW  - compressed MobileNet
KW  - feature map downsampling stage
KW  - feature map plateau stage
KW  - reduced inference time
KW  - vehicle categories
KW  - crowded bicycles
KW  - high detection accuracy
KW  - real-time detection speed
KW  - real time vehicle detection
KW  - object interference
KW  - short-range aerial image
KW  - crowded motorcycles
KW  - truck
KW  - car
KW  - bus
KW  - Convolution
KW  - Neural networks
KW  - Proposals
KW  - Vehicle detection
KW  - Object detection
KW  - Computational modeling
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8793673
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Vehicle detection from short-range aerial image faces challenges including vehicle blocking, irrelevant object interference, motion blurring, color variation etc., leading to the difficulty to achieve high detection accuracy and real-time detection speed. In this paper, benefiting from the recent development in MobileNet family network engineering, we propose a compressed MobileNet which is not only internally resistant to the above listed challenges but also gains the best detection accuracy/speed tradeoff when comparing with the original MobileNet. In a nutshell, we reduce the bottleneck architecture number during the feature map downsampling stage but add more bottlenecks during the feature map plateau stage, neither extra FLOPs nor parameters are thus involved but reduced inference time and better accuracy are expected. We conduct experiment on our collected 5-k short-range aerial images, containing six vehicle categories: truck, car, bus, bicycle, motorcycle, crowded bicycles and crowded motorcycles. Our proposed compressed MobileNet achieves 110 FPS (GPU), 31 FPS (CPU) and 15 FPS (mobile phone), 1.2 times faster and 2% more accurate (mAP) than the original MobileNet.
ER  - 

TY  - CONF
TI  - Guaranteed Active Constraints Enforcement on Point Cloud-approximated Regions for Surgical Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8346
EP  - 8352
AU  - T. Kastritsi
AU  - D. Papageorgiou
AU  - I. Sarantopoulos
AU  - S. Stavridis
AU  - Z. Doulgeri
AU  - G. A. Rovithakis
PY  - 2019
KW  - end effectors
KW  - force control
KW  - haptic interfaces
KW  - human-robot interaction
KW  - manipulator dynamics
KW  - medical robotics
KW  - mobile robots
KW  - path planning
KW  - surgery
KW  - point cloud-approximated regions
KW  - surgical applications
KW  - human-robot interaction controller
KW  - pHRI
KW  - sensitive tissues
KW  - restricted region
KW  - constraint enforcement
KW  - interaction force
KW  - constraint satisfaction
KW  - KUKA LWR4+ robot
KW  - 3D point-cloud
KW  - artificial potential fields
KW  - active constraint enforcement
KW  - kinesthetic guidance
KW  - KUKA LWR4+ robot end-effector
KW  - KUKA virtual slave
KW  - Tools
KW  - Force
KW  - Three-dimensional displays
KW  - Surgery
KW  - End effectors
KW  - Stability analysis
DO  - 10.1109/ICRA.2019.8793953
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, a passive physical human-robot interaction (pHRI) controller is proposed to intraoperatively ensure that sensitive tissues will not be damaged by the robot's tool. The proposed scheme uses the point cloud of the restricted region's surface as constraint definition and Artificial Potential fields for constraint enforcement. The controller is proven to be passive with respect to the interaction force and to guarantee constraint satisfaction in all cases. The proposed methodology is experimentally validated by the kinesthetic guidance of a KUKA LWR4+ robot's end-effector driving a virtual slave KUKA in the vicinity of a 3D point-cloud of a kidney and its adjacent vessels.
ER  - 

TY  - CONF
TI  - Designing an Accurate and Customizable Epidural Anesthesia Haptic Simulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8353
EP  - 8359
AU  - T. sénac
AU  - A. Lelevé
AU  - R. Moreau
AU  - L. Krahenbuhl
AU  - F. Sigwalt
AU  - C. Bauert
AU  - Q. Rouby
PY  - 2019
KW  - computer simulation
KW  - haptic interfaces
KW  - medical computing
KW  - pneumatic cylinder
KW  - electrical haptic interface
KW  - epidural anesthesia haptic simulator
KW  - medical procedure
KW  - Needles
KW  - Haptic interfaces
KW  - Force
KW  - Anesthesia
KW  - Prototypes
KW  - Bones
KW  - Training
DO  - 10.1109/ICRA.2019.8794199
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Epidural anesthesia, despite being a relatively common medical procedure, remains quite demanding in terms of skills as it is mostly blind and thus heavily reliant on the haptic sensations. Although some training support solutions exist, anesthetists consider them mostly inefficient or impractical. A few attempts at creating a simulator for this particular procedure exist but each one lacks one of the important requirements of the procedure. This article introduces a haptic simulator featuring a more complete and realistic simulation of the procedure than we could observe in existing simulators. The simulator is composed of a generic electrical haptic interface coupled with a pneumatic cylinder.
ER  - 

TY  - CONF
TI  - Sleeve Pneumatic Artificial Muscles for Antagonistically Actuated Joints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8360
EP  - 8366
AU  - M. F. Cullinan
AU  - C. McGinn
AU  - K. Kelly
PY  - 2019
KW  - biomechanics
KW  - medical robotics
KW  - muscle
KW  - orthotics
KW  - pneumatic actuators
KW  - PAM types
KW  - sleeve pneumatic artificial muscles
KW  - paper sleeve PAMs
KW  - popular muscle configuration
KW  - joint rotation
KW  - traditional PAMs
KW  - joint configuration
KW  - antagonistically actuated joints
KW  - Muscles
KW  - Force
KW  - Torque
KW  - Actuators
KW  - Fitting
KW  - Pulleys
KW  - Bladder
DO  - 10.1109/ICRA.2019.8794193
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pneumatic artificial muscles (PAMs) have been researched for applications in powered exoskeletons, orthosis and robotics. Their high force to mass ratio, low cost and inherent compliance are particularly advantageous for systems requiring physical interaction with humans.Sleeve PAMs, which introduce an internal structure to the actuator, offer improved force capacity, contraction ratio, efficiency and operating bandwidth. In this paper sleeve PAMs are applied to a popular muscle configuration; that of a joint operated antagonistically by two muscles. It is shown that the sleeve PAM can increases the range of joint rotation by 14% or load capacity by over 50% of that of a comparable joint actuated with traditional PAMs, depending on the joint configuration. The stiffness of joints actuated with both PAM types is also studied, particularly the case of closed system operation (mass of air in the PAMs is constant), where the reduced volume of the sleeve PAM significantly increases the observed stiffness. Finally energy consumption is considered, showing substantial savings in the case of joints actuated with sleeve PAMs.
ER  - 

TY  - CONF
TI  - Sensing Shear Forces During Food Manipulation: Resolving the Trade-Off Between Range and Sensitivity
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8367
EP  - 8373
AU  - H. Song
AU  - T. Bhattacharjee
AU  - S. S. Srinivasa
PY  - 2019
KW  - dexterous manipulators
KW  - force feedback
KW  - force sensors
KW  - grippers
KW  - haptic interfaces
KW  - sensors
KW  - shear strength
KW  - tactile sensors
KW  - bite acquisition success
KW  - shear forces
KW  - food manipulation
KW  - autonomous assistive feeding systems
KW  - deformable food items
KW  - force feedback
KW  - shear sensing fingertip tactile sensors
KW  - sensing range
KW  - bite acquisition successes
KW  - robotic gripper
KW  - varying weights
KW  - compliance
KW  - Tactile sensors
KW  - Sensitivity
KW  - Force
KW  - Calibration
KW  - Force measurement
DO  - 10.1109/ICRA.2019.8794350
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous assistive feeding systems need to acquire deformable food items of varying physical characteristics to be able to feed users. However, bite acquisition of these deformable food items is challenging without force feedback of appropriate range and sensitivity. We developed custom solutions using two widely-used shear sensing fingertip tactile sensors and calibrated them to the range of forces needed for manipulating food items. We compared their performance with traditional force/torque sensors and showed the trade-off between the range and the sensitivity of the fingertip tactile sensors in detecting potential bite acquisition successes for food items with widely varying weights and compliance. We then developed a control policy, using which a robotic gripper equipped with the fingertip tactile sensors can autonomously regulate the sensing range and the sensitivity to be able to skewer food items of different compliance and detect their bite acquisition success attempts.
ER  - 

TY  - CONF
TI  - Benchmarking Resilience of Artificial Hands
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8374
EP  - 8380
AU  - F. Negrello
AU  - M. Garabini
AU  - G. Grioli
AU  - N. Tsagarakis
AU  - A. Bicchi
AU  - M. G. Catalano
PY  - 2019
KW  - actuators
KW  - dexterous manipulators
KW  - end effectors
KW  - human-robot interaction
KW  - impact testing
KW  - prosthetics
KW  - artificial hands
KW  - harsh interactions
KW  - irregular physical interactions
KW  - disaster scenario
KW  - standardized test
KW  - hand resilience
KW  - impact tests
KW  - standard test
KW  - robot hands
KW  - resilience evaluation framework
KW  - Resilience
KW  - Soft robotics
KW  - Robustness
KW  - Strain
KW  - Standards
KW  - Prosthetics
DO  - 10.1109/ICRA.2019.8793793
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The deployment of robotics in real-world scenarios, which may involve harsh and irregular physical interactions with the environment, such as those when robots operating in a disaster scenario, or the interactions that prosthetic devices may experience, demands hardware, which is physically resilient. The end-effectors, as the main media of interaction, are probably the parts at the highest risk. The capability of robotic hands to survive severe impacts is thus a necessity for the effective deployment of reliable robotic solutions in real-world tasks. Although, this robustness capability has been noted and discussed in the robotics community for long time, the literature does not provide a systematic study nor there is any proposal of standardized test or metric to evaluate hand resilience. In this work, inspired by the works of Charpy and Izod for the systematic definition of resilience and toughness of materials through impact tests, we consider extending the standard test to robot hands. We introduce a resilience evaluation framework, including a precisely defined experimental set-up and test procedure. As an example of application of the procedure, we apply it to experimentally characterize two robot hands, with a similar conceptual architecture but different size and material. From these tests we obtain several insights, including the observation that the dominant factor in hand resilience is their compliance and actuation principle, and that the use, under certain design conditions, of lightweight materials, such as plastic instead of aluminum, may not necessarily reduce the mechanical strength of the overall system.
ER  - 

TY  - CONF
TI  - CHiMP: A Contact based Hilbert Map Planner
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8381
EP  - 8387
AU  - C. Uhde
AU  - E. Dean-Leon
AU  - G. Cheng
PY  - 2019
KW  - gradient methods
KW  - manipulators
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - stochastic processes
KW  - tactile sensors
KW  - multimodal robot skin
KW  - contact-based robot system
KW  - skin compliant control
KW  - tactile-based explorative behavior
KW  - CHiMP
KW  - skin-based sparse contact data
KW  - contact-based 3D path planning approach
KW  - 6 DOF robot arm
KW  - stochastic functional gradient path planner
KW  - contact based Hilbert map planner
KW  - manipulators
KW  - Trajectory
KW  - Skin
KW  - Planning
KW  - Kernel
KW  - Robot sensing systems
KW  - Cost function
DO  - 10.1109/ICRA.2019.8794013
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work presents a new contact-based 3D path planning approach for manipulators using robot skin. We make use of the Stochastic Functional Gradient Path Planner, extending it to the 3D case, and assess its usefulness in combination with multi-modal robot skin. Our proposed algorithm is verified on a 6 DOF robot arm that has been covered with multi-modal robot skin. The experimental platform is combined with a skin based compliant controller, making the robot inherently reactive. We implement different state-of-the-art planners within our contact-based robot system to compare their performance under the same conditions. In this way, all the planners use the same skin compliant control during evaluation. Furthermore, we extend the stochastic planner with tactile-based explorative behavior to improve its performance, especially for unknown environments. We show that CHiMP is able to outperform state of the art algorithms when working with skin-based sparse contact data.
ER  - 

TY  - CONF
TI  - A Novel Reconfigurable Revolute Joint with Adjustable Stiffness
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8388
EP  - 8393
AU  - Z. Li
AU  - W. Chen
AU  - S. Bai
PY  - 2019
KW  - elasticity
KW  - mechanical engineering computing
KW  - springs (mechanical)
KW  - adjustable stiffness
KW  - JASR
KW  - zero-length base link four-bar linkage
KW  - hard-spring behaviour
KW  - light-weight structure
KW  - design parameters
KW  - reconfigurable revolute joint
KW  - Springs
KW  - Rubber
KW  - Pins
KW  - Shafts
KW  - Couplings
KW  - Robots
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8793906
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, a novel revolute joint of adjustable stiffness with reconfigurability (JASR) is presented. The JASR is designed with zero-length base link four-bar linkage, and allows adjusting its stiffness to achieve soft- and hard-spring behaviour. The new joint has a compact and light-weight structure and can be integrated in robot and transmissions for different applications. In the paper, mathematical models are developed for the JASR, with which influences of design parameters on stiffness performance are analyzed. A prototype of JASR is constructed and preliminary test results demonstrate the compliance properties of the new joint.
ER  - 

TY  - CONF
TI  - A novel force sensor with zero stiffness at contact transition based on optical line generation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8394
EP  - 8400
AU  - J. Begey
AU  - M. Nierenberger
AU  - P. Pfeiffer
AU  - S. Lecler
AU  - P. Renaud
PY  - 2019
KW  - fibre optic sensors
KW  - force sensors
KW  - medical robotics
KW  - zero stiffness
KW  - contact transition
KW  - optical line generation
KW  - robotic system
KW  - stiff environment
KW  - passive compliance
KW  - robot control
KW  - optical measurement process
KW  - compliant sensor body
KW  - force sensor
KW  - medical robotization
KW  - low off-axis sensitivity
KW  - additive manufacturing
KW  - Springs
KW  - Optical variables measurement
KW  - Optical sensors
KW  - Laser beams
KW  - Robot sensing systems
KW  - Force
KW  - Force sensors
DO  - 10.1109/ICRA.2019.8794183
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotization of medical acts often requires the evaluation of contacts between a robotic system and a patient, for safety or efficiency reasons. When contact occurs with a stiff environment, instabilities and vibrations can appear and a passive compliance is therefore needed. In this paper, we propose to embed compliance in a force sensor and to develop a novel force sensor with large compliance, i.e. a zero stiffness at contact transition to ease robot control. To get at the same time a satisfying measurement range and low off-axis sensitivity, an optical measurement process based on an optical line generated thanks to additive manufacturing is exploited. A compliant sensor body allowing the desired stiffness profile is presented and the specific optical measurement technique is developed. Finally, a prototype of the proposed force sensor is evaluated experimentally.
ER  - 

TY  - CONF
TI  - Hydraulically-actuated compliant revolute joint for medical robotic systems based on multimaterial additive manufacturing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8401
EP  - 8407
AU  - A. Pfeil
AU  - M. Siegfarth
AU  - F. Geiskopf
AU  - T. P. Pusch
AU  - L. Barbé
AU  - P. Renaud
PY  - 2019
KW  - biomedical MRI
KW  - compliance control
KW  - design engineering
KW  - hydraulic actuators
KW  - manipulator kinematics
KW  - medical image processing
KW  - medical robotics
KW  - polymers
KW  - rapid prototyping (industrial)
KW  - telerobotics
KW  - three-dimensional printing
KW  - hydraulic cylinder
KW  - hydraulically-actuated compliant revolute joint
KW  - medical robotic systems
KW  - multimaterial additive manufacturing
KW  - hydraulic energy
KW  - seal design
KW  - miniature hydraulic cylinders
KW  - rack-and-pinion mechanism
KW  - magnetic resonance imaging
KW  - Gears
KW  - Hydraulic systems
KW  - Robots
KW  - Standards
KW  - Shape
KW  - Force
KW  - Three-dimensional printing
DO  - 10.1109/ICRA.2019.8793666
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, an active compliant revolute joint actuated by hydraulic energy is developed. The joint is made of polymer for integration in medical robotic systems, even in a challenging environment such as Magnetic Resonance Imaging (MRI). The use of multimaterial additive manufacturing allows us to develop two original aspects. First, a new seal design is proposed to build miniature hydraulic cylinders embedded in the active joint, with low level of friction. Second, a rack-and-pinion mechanism is being integrated to a compliant revolute joint to obtain a high level of compactness. Design and experimental assessment of the hydraulic cylinder and the compliant joint with embedded rack-and-pinion are presented, as well as an illustration in the context of needle manipulation with passive teleoperation.
ER  - 

TY  - CONF
TI  - Model-Based On-line Estimation of Time-Varying Nonlinear Joint Stiffness on an e-Series Universal Robots Manipulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8408
EP  - 8414
AU  - E. Madsen
AU  - O. S. Rosenlund
AU  - D. Brandt
AU  - X. Zhang
PY  - 2019
KW  - actuators
KW  - control system synthesis
KW  - elasticity
KW  - feedback
KW  - feedforward
KW  - flexible manipulators
KW  - gears
KW  - least squares approximations
KW  - manipulator dynamics
KW  - position control
KW  - time-varying systems
KW  - model-based feedforward controllers
KW  - e-series manipulators
KW  - UR5e manipulator
KW  - transmission deformation
KW  - elastic torques
KW  - parametric model
KW  - recursive least squares strategy
KW  - robot joint stiffness
KW  - feedback controllers
KW  - robot joints
KW  - gear meshing
KW  - driven link
KW  - drive actuator
KW  - dynamic time-varying displacement
KW  - lightweight strain-wave type transmissions
KW  - elasticity
KW  - e-series universal robots manipulator
KW  - time-varying nonlinear joint stiffness
KW  - model-based on-line estimation
KW  - Torque
KW  - Robot sensing systems
KW  - Friction
KW  - Mathematical model
KW  - Manipulator dynamics
DO  - 10.1109/ICRA.2019.8793935
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Flexibility commonly exists in the joints of many industrial robots due to the elasticity of the lightweight strain-wave type transmissions being used. This leads to a dynamic time-varying displacement between the position of the drive actuator and that of the driven link. Furthermore, the joint flexibility changes with time due to the material slowly being worn off at the gear meshing. Knowing the stiffness of the robot joints is of great value, e.g. in the design of new model-based feedforward and feedback controllers, and for predictive maintenance in the case of gearing unit failure. In this paper, we address on-line estimation of robot joint stiffness using a recursive least squares strategy based on a parametric model taking into account the elastic torques' nonlinear dependency on transmission deformation. Robustness is achieved in the presence of measurement noise and in poor excitation conditions. The method can be easily extended to general classes of serial-link multi-degree-of-freedom robots. The estimation technique uses only feedback signals that are readily available on Universal Robots' e-Series manipulators. Experiments on the new UR5e manipulator demonstrate the effectiveness of the proposed method.
ER  - 

TY  - CONF
TI  - A Rolling Flexure Mechanism for Progressive Stiffness Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8415
EP  - 8421
AU  - J. Malzahn
AU  - E. Barrett
AU  - N. Tsagarakis
PY  - 2019
KW  - actuators
KW  - elasticity
KW  - finite element analysis
KW  - mobile robots
KW  - prototypes
KW  - springs (mechanical)
KW  - torque control
KW  - progressive stiffness Actuators
KW  - robot performance
KW  - 2D components
KW  - physical interaction performance
KW  - passive rolling flexure design principle
KW  - linear series elastic actuators
KW  - torque-deflection characteristics
KW  - finite element analysis
KW  - laboratory prototypes
KW  - Force
KW  - Actuators
KW  - Springs
KW  - Torque
KW  - Stress
KW  - Robots
KW  - Torque control
DO  - 10.1109/ICRA.2019.8794004
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Linear Series Elastic Actuators exhibit a restricted design space. This inevitably leads to design trade-offs translating into robot performance limitations. These prevent robots from eventually reaching human comparable soft but also powerful physical interaction performance.This work presents a novel fixed passive rolling flexure design principle enabling the realization of a wide range of progressive torque-deflection characteristics. The proposed principle displays low hysteresis and can be manufactured in single 2D components. The paper derives the analytic foundation for the rolling flexure principle and is supported by numerical finite element analysis. The theory is validated by experimental results obtained on two laboratory prototypes.
ER  - 

TY  - CONF
TI  - Locomotion Dynamics of a Miniature Wave-Like Robot, Modeling and Experiments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8422
EP  - 8428
AU  - L. Drory
AU  - D. Zarrouk
PY  - 2019
KW  - actuators
KW  - force control
KW  - friction
KW  - legged locomotion
KW  - motion control
KW  - pipes
KW  - robot dynamics
KW  - locomotion dynamics
KW  - dynamic locomotion analysis
KW  - wave robot
KW  - propulsion force
KW  - locomotion models
KW  - advance time ratio
KW  - friction forces
KW  - miniature model
KW  - miniature wave-like robot
KW  - minimally actuated wave-like robot kinematics
KW  - crawling environments
KW  - flexible tube-like shapes
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA.2019.8794015
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In a recent study, we developed a minimally actuated wave-like robot and analyzed its kinematics. In this paper, we present the dynamic locomotion analysis of a miniature version of this wave robot. We examine different crawling environments, determine under which conditions it can advance, and evaluate its propulsion force. We first developed two locomotion models to characterize the cases where the robot is crawling between two straight surfaces or over a single flat surface. We specified the conditions in which the robot will advance and the advance time ratio as a function of the friction forces and weight of the robot. Next, we developed highly flexible tube-like shapes that we molded from silicone rubber to experimentally test the forces acting on the robot inside these tubes. Finally, we designed a miniature model of the robot and experimentally validated its crawling conditions (see video).
ER  - 

TY  - CONF
TI  - Fabric Soft Poly-Limbs for Physical Assistance of Daily Living Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8429
EP  - 8435
AU  - P. H. Nguyen
AU  - I. B. Imran Mohd
AU  - C. Sparks
AU  - F. L. Arellano
AU  - W. Zhang
AU  - P. Polygerinos
PY  - 2019
KW  - actuators
KW  - artificial limbs
KW  - fabrics
KW  - finite element analysis
KW  - manipulators
KW  - soft-waist belt
KW  - physical assistance
KW  - daily living tasks
KW  - additional limb
KW  - mobile manipulation assistance
KW  - soft actuators
KW  - high-strength inflatable fabrics
KW  - systematic design rules
KW  - highly compliant soft robotic limbs
KW  - fabric based components behavior
KW  - finite-element method models
KW  - FEM models
KW  - fSPL articulation capabilities
KW  - fabric soft arm
KW  - fabric soft poly-limbs
KW  - Actuators
KW  - Fabrics
KW  - Payloads
KW  - Manipulators
KW  - Heating systems
KW  - Force
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794294
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the design and development of a highly articulated, continuum, wearable, fabric-based Soft Poly-Limb (fSPL). This fabric soft arm acts as an additional limb that provides the wearer with mobile manipulation assistance through the use of soft actuators made with high-strength inflatable fabrics. In this work, a set of systematic design rules is presented for the creation of highly compliant soft robotic limbs through an understanding of the fabric based components behavior as a function of input pressure. These design rules are generated by investigating a range of parameters through computational finite-element method (FEM) models focusing on the fSPL's articulation capabilities and payload capacity in 3D space. The theoretical motion and payload outputs of the fSPL and its components are experimentally validated as well as additional evaluations verify its capability to safely carry loads 10.1x its body weight, by wrapping around the object. Finally, we demonstrate how the fully collapsible fSPL can comfortably be stored in a soft-waist belt and interact with the wearer through spatial mobility and preliminary pick-and-place control experiments.
ER  - 

TY  - CONF
TI  - Design of a Soft Ankle-Foot Orthosis Exosuit for Foot Drop Assistance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8436
EP  - 8442
AU  - C. M. Thalman
AU  - J. Hsu
AU  - L. Snyder
AU  - P. Polygerinos
PY  - 2019
KW  - actuators
KW  - elastic constants
KW  - electromyography
KW  - finite element analysis
KW  - gait analysis
KW  - kinematics
KW  - medical control systems
KW  - orthotics
KW  - soft ankle-foot orthosis exosuit
KW  - foot drop assistance
KW  - natural gait restoration
KW  - soft actuators
KW  - thermally-bonded nylon
KW  - swing phase
KW  - gait cycle
KW  - ankle joint proprioception
KW  - variable stiffness soft actuator
KW  - computational model
KW  - fabric actuators
KW  - dorsiflexion actuator
KW  - soft AFO
KW  - ankle dorsiflexion
KW  - finite element analysis
KW  - electromyography studies
KW  - Actuators
KW  - Foot
KW  - Fabrics
KW  - Force
KW  - Fabrication
KW  - Muscles
DO  - 10.1109/ICRA.2019.8794005
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the design of a soft ankle-foot orthosis (AFO) exosuit to aid natural gait restoration for individuals suffering from foot drop. The sock-like AFO is comprised of soft actuators made from fabric-based, thermally-bonded nylon and designed to be worn over the users shoes. The system assists dorsiflexion during swing phase of the gait cycle utilizing a contracting soft actuator, and provides ankle joint proprioception during stance with a variable stiffness soft actuator. A computational model is developed using finite element analysis to optimize the performance characteristics of the fabric actuators prior to fabrication, maximize contraction, and minimize overall volume. The dorsiflexion actuator is able to achieve a linear tensile force of 197 N at 200 kPa. The variable stiffness actuator generates up to 1. 2 Nm of torque at the same pressure. The computational model and soft AFO are experimentally validated and with a healthy participant through kinematic and electromyography studies. When active the AFO is capable of reducing by 13.3% the activity of the muscle responsible for ankle dorsiflexion during the swing phase.
ER  - 

TY  - CONF
TI  - A Depth Camera-Based Soft Fingertip Device for Contact Region Estimation and Perception-Action Coupling
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8443
EP  - 8449
AU  - I. Huang
AU  - J. Liu
AU  - R. Bajcsy
PY  - 2019
KW  - cameras
KW  - deformation
KW  - estimation theory
KW  - robots
KW  - tactile sensors
KW  - depth camera-based soft fingertip device
KW  - contact region estimation
KW  - perception-action coupling
KW  - robotic applications
KW  - unconstrained environments
KW  - dynamic environments
KW  - soft robotic technologies
KW  - soft tactile sensor design
KW  - human fingertip
KW  - perception mechanism
KW  - compliance-modulating capabilities
KW  - estimation sensitivity
KW  - internal fluid states
KW  - force-deformation characteristics
KW  - Robot sensing systems
KW  - Cameras
KW  - Three-dimensional displays
KW  - Force
KW  - Estimation
KW  - Image reconstruction
DO  - 10.1109/ICRA.2019.8793612
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - As the demand for robotic applications in unconstrained and dynamic environments rises, so does the benefit of advancing the state of the art in soft robotic technologies. However, the complex capabilities of soft robots elicited by their high-dimensional, non-linear characteristics simultaneously yield difficult challenges in control and sensing. Moreover, embedding tactile sensing capabilities in soft materials is often expensive and difficult to fabricate. In recent years, however, the invention of small-scale depth-sensing cameras introduced a promising channel for soft tactile sensor design. In this work, we propose a novel soft device inspired by the human fingertip that not only utilizes a small depth camera as the perception mechanism, but also possesses compliance-modulating capabilities. We demonstrate its ability to accurately estimate contact regions upon interaction with an external obstacle, and show that the estimation sensitivity can be modulated via internal fluid states. In addition, we determine an empirical model of the device's force-deformation characteristics under simplifying assumptions, and validate its performance with real-time force matching control experiments.
ER  - 

TY  - CONF
TI  - A Pipe-Climbing Soft Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8450
EP  - 8456
AU  - G. Singh
AU  - S. Patiballa
AU  - X. Zhang
AU  - G. Krishnan
PY  - 2019
KW  - bending
KW  - design engineering
KW  - elastomers
KW  - mobile robots
KW  - motion control
KW  - pipes
KW  - pneumatic actuators
KW  - modular design
KW  - flexible actuators
KW  - pipe-climbing soft robot
KW  - bio-inspired soft pneumatic robot
KW  - cylinder
KW  - soft pneumatic actuators
KW  - FREEs
KW  - deformation behavior
KW  - bending actuators
KW  - fiber reinforced elastomeric enclosure
KW  - forward motion
KW  - Actuators
KW  - Pneumatic systems
KW  - Prototypes
KW  - Soft robotics
KW  - Strain
KW  - Torso
KW  - Soft robotics
KW  - Crawling Robot
KW  - Artificial muscles
KW  - McKibben muscles
DO  - 10.1109/ICRA.2019.8793815
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the design and testing of a bio-inspired soft pneumatic robot that can achieve locomotion along the outside of a cylinder. The robot uses soft pneumatic actuators called FREEs (Fiber Reinforced Elastomeric Enclosure), which can have a wide range of deformation behavior upon pressurization. The robot being soft and compliant can grasp and move along cylinders of varying dimensions. Two different types of FREEs are used in the robot namely (a) extending FREEs and (b) bending FREEs. These actuators are arranged in such a way that the bending actuators are used to grip the pipe while the extending actuators generate forward motion as well as bending for direction control. The modular design of the robot provides simplicity and ease of maintenance. The entire robot is made of flexible actuators and can withstand external impact with minimal to no damage. The maximum speed achieved for horizontal motion is 4.2 mm/s and for vertical motion is 2.1 mm/s.
ER  - 

TY  - CONF
TI  - Generation of Stealth Walking Gait on Low-friction Road Surface
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8464
EP  - 8469
AU  - F. Asano
PY  - 2019
KW  - friction
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - wheels
KW  - AMCC
KW  - horizontal ground reaction force
KW  - low-friction road surface
KW  - planar underactuated rimless wheel
KW  - stealth walking gait
KW  - adaptive walking gaits
KW  - underactuated walkers
KW  - control torques
KW  - frictionless road surface
KW  - angular momentum constraint control
KW  - stance-leg motion
KW  - linearized motion equation
KW  - Legged locomotion
KW  - Foot
KW  - Mathematical model
KW  - Wheels
KW  - Roads
KW  - Trajectory
KW  - Force
DO  - 10.1109/ICRA.2019.8794409
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The author has investigated the method of stealth walking for generating adaptive walking gaits of underactuated walkers without having the control torques at the feet. This approach is also effective for achieving careful walking on the frictionless road surface by applying angular momentum constraint control (AMCC); the generated gait completes in one step while maintaining the horizontal ground reaction force to zero. The result is mathematically thorough, but is not realistic because any uncertainties in the system cannot be permitted. This paper then discusses more realistic slidingresistant situation: stealth walking on the low-friction road surface. First, we introduce a model of a planar underactuated rimless wheel, and describe the equation of motion and the control input for AMCC. Second, we specify the linearized equation of motion with AMCC, and derive the analytical solution of the stance-leg motion which is used as a desired trajectory for the nonlinear model. Furthermore, we discuss the optimality of the upper-body control during the double-limb support phase from the sliding-resistant characteristics point of view through mathematical and numerical investigations.
ER  - 

TY  - CONF
TI  - Support Surface Estimation for Legged Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8470
EP  - 8476
AU  - T. Homberger
AU  - L. Wellhausen
AU  - P. Fankhauser
AU  - M. Hutter
PY  - 2019
KW  - Gaussian processes
KW  - legged locomotion
KW  - path planning
KW  - regression analysis
KW  - robot dynamics
KW  - terrain mapping
KW  - legged robots
KW  - legged systems
KW  - rugged outdoor environments
KW  - terrain geometry
KW  - foothold planning
KW  - safe locomotion
KW  - penetrable terrain
KW  - depth sensors
KW  - haptic information
KW  - foot contact closure locations
KW  - exteroceptive sensing
KW  - dense support surface estimate
KW  - Gaussian process regression
KW  - support surface estimation procedure
KW  - penetrable surface layer
KW  - discrete penetration depth measurements
KW  - continuous support surface estimate
KW  - partial exteroceptive information
KW  - terrain topography
KW  - quadrupedal robot ANYmal
KW  - Vegetation mapping
KW  - Surface topography
KW  - Kernel
KW  - Estimation
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793646
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The high agility of legged systems allows them to operate in rugged outdoor environments. In these situations, knowledge about the terrain geometry is key for foothold planning to enable safe locomotion. However, on penetrable or highly compliant terrain (e.g. grass) the visibility of the supporting ground surface is obstructed, i.e. it cannot directly be perceived by depth sensors. We present a method to estimate the underlying terrain topography by fusing haptic information about foot contact closure locations with exteroceptive sensing. To obtain a dense support surface estimate from sparsely sampled footholds we apply Gaussian process regression. Exteroceptive information is integrated into the support surface estimation procedure by estimating the height of the penetrable surface layer from discrete penetration depth measurements at the footholds. The method is designed such that it provides a continuous support surface estimate even if there is only partial exteroceptive information available due to shadowing effects. Field experiments with the quadrupedal robot ANYmal show how the robot can smoothly and safely navigate in dense vegetation.
ER  - 

TY  - CONF
TI  - ALMA - Articulated Locomotion and Manipulation for a Torque-Controllable Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8477
EP  - 8483
AU  - C. D. Bellicoso
AU  - K. Krämer
AU  - M. Stäuble
AU  - D. Sako
AU  - F. Jenelten
AU  - M. Bjelonic
AU  - M. Hutter
PY  - 2019
KW  - end effectors
KW  - human-robot interaction
KW  - legged locomotion
KW  - manipulator dynamics
KW  - motion control
KW  - optimisation
KW  - path planning
KW  - torque control
KW  - unstructured environments
KW  - ALMA
KW  - torque-controlled quadrupedal robot
KW  - dynamic locomotion
KW  - online motion planning framework
KW  - whole-body controller
KW  - hierarchical optimization algorithm
KW  - operational space end-effector control
KW  - human-robot collaboration
KW  - torso posture optimization
KW  - torque-controllable robot
KW  - robotic mobile manipulation
KW  - six degrees of freedom robotic arm
KW  - articulated locomotion and manipulation
KW  - reactive human-robot collaboration
KW  - Legged locomotion
KW  - Task analysis
KW  - Grippers
KW  - Robot kinematics
KW  - Tracking
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794273
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The task of robotic mobile manipulation poses several scientific challenges that need to be addressed to execute complex manipulation tasks in unstructured environments, in which collaboration with humans might be required. Therefore, we present ALMA, a motion planning and control framework for a torque-controlled quadrupedal robot equipped with a six degrees of freedom robotic arm capable of performing dynamic locomotion while executing manipulation tasks. The online motion planning framework, together with a whole-body controller based on a hierarchical optimization algorithm, enables the system to walk, trot and pace while executing operational space end-effector control, reactive human-robot collaboration and torso posture optimization to increase the arm's workspace. The torque control of the whole system enables the implementation of compliant behavior, allowing a user to safely interact with the robot. We verify our framework on the real robot by performing tasks such as opening a door and carrying a payload together with a human.
ER  - 

TY  - CONF
TI  - Real-time Model Predictive Control for Versatile Dynamic Motions in Quadrupedal Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8484
EP  - 8490
AU  - Y. Ding
AU  - A. Pandala
AU  - H. Park
PY  - 2019
KW  - legged locomotion
KW  - motion control
KW  - predictive control
KW  - quadratic programming
KW  - robot dynamics
KW  - versatile dynamic motions
KW  - quadrupedal robot
KW  - single rigid body dynamics
KW  - rotation matrices
KW  - quaternions
KW  - unwinding phenomenon
KW  - MPC control law
KW  - periodic quadrupedal gaits
KW  - model predictive control framework
KW  - quadratic program
KW  - QP
KW  - Euler angles
KW  - acrobatic maneuvers
KW  - Legged locomotion
KW  - Dynamics
KW  - Robot kinematics
KW  - Three-dimensional displays
KW  - Trajectory
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793669
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a new Model Predictive Control (MPC) framework for controlling various dynamic movements of a quadrupedal robot. System dynamics are represented by linearizing single rigid body dynamics in three-dimensional (3D) space. Our formulation linearizes rotation matrices without resorting to parameterizations like Euler angles and quaternions, avoiding issues of singularity and unwinding phenomenon, respectively. With a carefully chosen configuration error function, the MPC control law is transcribed into a Quadratic Program (QP) which can be solved efficiently in realtime. Our formulation can stabilize a wide range of periodic quadrupedal gaits and acrobatic maneuvers. We show various simulation as well as experimental results to validate our control strategy. Experiments prove the application of this framework with a custom QP solver could reach execution rates of 160 Hz on embedded platforms.
ER  - 

TY  - CONF
TI  - Scanning the Internet for ROS: A View of Security in Robotics Research
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8514
EP  - 8521
AU  - N. DeMarinis
AU  - S. Tellex
AU  - V. P. Kemerlis
AU  - G. Konidaris
AU  - R. Fonseca
PY  - 2019
KW  - control engineering computing
KW  - image sensors
KW  - Internet
KW  - IP networks
KW  - operating systems (computers)
KW  - robot programming
KW  - robot vision
KW  - ROS
KW  - public Internet
KW  - image sensor information
KW  - publicly-accessible platforms
KW  - robotics research
KW  - Robot Operating System
KW  - robotic sensors
KW  - robotic actuators
KW  - IPv4 address space
KW  - American university
KW  - Robot sensing systems
KW  - Security
KW  - Actuators
KW  - Internet
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794451
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Security is particularly important in robotics, as robots can directly perceive and affect the physical world. We describe the results of a scan of the entire IPv4 address space of the Internet for instances of the Robot Operating System (ROS), a widely used robotics software platform. We identified a number of hosts supporting ROS that are exposed to the public Internet, thereby allowing anyone to access robotic sensors and actuators. As a proof of concept, and with the consent of the relevant researchers, we were able to read image sensor information from and actuate a physical robot present in a research lab in an American university. This paper gives an overview of our findings, including our methodology, the geographic distribution of publicly-accessible platforms, the sorts of sensor and actuator data that is available, and the different kinds of robots and sensors that our scan uncovered. Additionally, we offer recommendations on best practices to mitigate these security issues in the future.
ER  - 

TY  - CONF
TI  - Risk Averse Robust Adversarial Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8522
EP  - 8528
AU  - X. Pan
AU  - D. Seita
AU  - Y. Gao
AU  - J. Canny
PY  - 2019
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - probability
KW  - risk averse robust adversarial reinforcement learning
KW  - deep reinforcement learning
KW  - computer games
KW  - robotic control
KW  - automotive accidents
KW  - optimization
KW  - probability
KW  - RARARL
KW  - self-driving vehicle controller
KW  - Reinforcement learning
KW  - Training
KW  - Mathematical model
KW  - Robustness
KW  - Autonomous vehicles
KW  - Task analysis
KW  - Accidents
DO  - 10.1109/ICRA.2019.8794293
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deep reinforcement learning has recently made significant progress in solving computer games and robotic control tasks. A known problem, though, is that policies overfit to the training environment and may not avoid rare, catastrophic events such as automotive accidents. A classical technique for improving the robustness of reinforcement learning algorithms is to train on a set of randomized environments, but this approach only guards against common situations. Recently, robust adversarial reinforcement learning (RARL) was developed, which allows efficient applications of random and systematic perturbations by a trained adversary. A limitation of RARL is that only the expected control objective is optimized; there is no explicit modeling or optimization of risk. Thus the agents do not consider the probability of catastrophic events (i.e., those inducing abnormally large negative reward), except through their effect on the expected objective. In this paper we introduce risk-averse robust adversarial reinforcement learning (RARARL), using a risk-averse protagonist and a risk-seeking adversary. We test our approach on a self-driving vehicle controller. We use an ensemble of policy networks to model risk as the variance of value functions. We show through experiments that a risk-averse agent is better equipped to handle a risk-seeking adversary, and experiences substantially fewer crashes compared to agents trained without an adversary. Supplementary materials are available at https://sites.google.com/view/rararl.
ER  - 

TY  - CONF
TI  - Bounded Collision Force by the Sobolev Norm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8529
EP  - 8535
AU  - K. Haninger
AU  - D. Surdilovic
PY  - 2019
KW  - compliance control
KW  - control system synthesis
KW  - end effectors
KW  - feedback
KW  - force control
KW  - H2 control
KW  - manipulator dynamics
KW  - mechanical contact
KW  - springs (mechanical)
KW  - Sobolev norm
KW  - robot inertia
KW  - analytical models
KW  - maximum collision force
KW  - simplified mass-spring robot model
KW  - end-effector compliance
KW  - system norm
KW  - maximum force
KW  - general dynamic system
KW  - feedback control
KW  - control theory
KW  - controller synthesis
KW  - admittance-controlled robot
KW  - linear flexible-joint robot
KW  - bounded collision force
KW  - robot contact
KW  - safety risks
KW  - collision force minimisation
KW  - Force
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Measurement
KW  - End effectors
KW  - Admittance
DO  - 10.1109/ICRA.2019.8793711
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A robot making contact with an environment or human presents potential safety risks, including excessive collision force. While experiments on the effect of robot inertia, relative velocity, and interface stiffness on collision are in literature, analytical models for maximum collision force are limited to a simplified mass-spring robot model. This simplified model limits the analysis of control (force/torque, impedance, or admittance) or compliant robots (joint and end-effector compliance). Here, the Sobolev norm is adapted to be a system norm, giving rigorous bounds on the maximum force on a stiffness element in a general dynamic system, allowing the study of collision with more accurate models and feedback control. The Sobolev norm can be found through the H2 norm of a transformed system, allowing efficient computation, connection with existing control theory, and controller synthesis to minimize collision force. The Sobolev norm is validated, first experimentally with an admittance-controlled robot, then in simulation with a linear flexible-joint robot. It is then used to investigate the impact of control, joint flexibility and end-effector compliance on collision, and a trade-off between collision performance and environmental estimation uncertainty is shown.
ER  - 

TY  - CONF
TI  - Liability, Ethics, and Culture-Aware Behavior Specification using Rulebooks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8536
EP  - 8542
AU  - A. Censi
AU  - K. Slutsky
AU  - T. Wongpiromsarn
AU  - D. Yershov
AU  - S. Pendleton
AU  - J. Fu
AU  - E. Frazzoli
PY  - 2019
KW  - automobiles
KW  - cultural aspects
KW  - ethical aspects
KW  - formal specification
KW  - intelligent transportation systems
KW  - mobile robots
KW  - multi-agent systems
KW  - culture-aware behavior specification
KW  - autonomous agents
KW  - self-driving domain
KW  - liability-aware behavior specification
KW  - ethics-aware behavior specification
KW  - self-driving car behavior
KW  - Aptiv company
KW  - nuTonomy
KW  - violation metric
KW  - rulebook semantics
KW  - Automobiles
KW  - Planning
KW  - Autonomous automobiles
KW  - Ethics
KW  - Measurement
KW  - Trajectory
KW  - Semantics
DO  - 10.1109/ICRA.2019.8794364
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The behavior of self-driving cars must be compatible with an enormous set of conflicting and ambiguous objectives, from law, from ethics, from the local culture, and so on. This paper describes a new way to conveniently define the desired behavior for autonomous agents, which we use on the self-driving cars developed at nuTonomy, an Aptiv company. We define a “rulebook” as a pre-ordered set of “rules”, each akin to a violation metric on the possible outcomes (“realizations”). The rules are partially ordered by priority. The semantics of a rulebook imposes a pre-order on the set of realizations. We study the compositional properties of the rulebooks, and we derive which operations we can allow on the rulebooks to preserve previously-introduced constraints. While we demonstrate the application of these techniques in the self-driving domain, the methods are domain-independent.
ER  - 

TY  - CONF
TI  - Early Failure Detection of Deep End-to-End Control Policy by Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8543
EP  - 8549
AU  - K. Lee
AU  - K. Saigol
AU  - E. A. Theodorou
PY  - 2019
KW  - belief networks
KW  - control engineering computing
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - observability
KW  - predictive control
KW  - learned control policies
KW  - reinforcement learning
KW  - end-to-end imitation
KW  - predictive uncertainty
KW  - model predictive controller
KW  - fully-observable vision-based partially-observable systems
KW  - deep convolutional Bayesian neural networks
KW  - deep end-to-end control policy
KW  - Bayesian networks
KW  - mean value
KW  - corrective action
KW  - partial state observability
KW  - Uncertainty
KW  - Bayes methods
KW  - Task analysis
KW  - Neural networks
KW  - Safety
KW  - Training
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2019.8794189
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose the use of Bayesian networks, which provide both a mean value and an uncertainty estimate as output, to enhance the safety of learned control policies under circumstances in which a test-time input differs significantly from the training set. Our algorithm combines reinforcement learning and end-to-end imitation learning to simultaneously learn a control policy as well as a threshold over the predictive uncertainty of the learned model, with no hand-tuning required. Corrective action, such as a return of control to the model predictive controller or human expert, is taken before the failure of tasks, when the uncertainty threshold is exceeded. We validate our method on fully-observable and vision-based partially-observable systems using cart-pole and autonomous driving simulations using deep convolutional Bayesian neural networks. We demonstrate that our method is robust to uncertainty resulting from varying system dynamics as well as from partial state observability.
ER  - 

TY  - CONF
TI  - Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8550
EP  - 8556
AU  - J. F. Fisac
AU  - N. F. Lugovoy
AU  - V. Rubies-Royo
AU  - S. Ghosh
AU  - C. J. Tomlin
PY  - 2019
KW  - approximation theory
KW  - control engineering computing
KW  - dynamic programming
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimal control
KW  - partial differential equations
KW  - dynamic programming equation
KW  - contraction mapping
KW  - Hamilton-Jacobi safety analysis
KW  - control-theoretic safety analysis
KW  - optimal safety policy
KW  - quantitative safety analysis
KW  - reinforcement learning techniques
KW  - time-discounted modification
KW  - optimal control problems
KW  - robust optimal control theory
KW  - autonomous robotic systems
KW  - policy gradient techniques
KW  - value learning
KW  - Safety
KW  - Automation
KW  - Reinforcement learning
KW  - Robots
KW  - Optimal control
KW  - Jacobian matrices
KW  - Reachability analysis
DO  - 10.1109/ICRA.2019.8794107
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Safety analysis is a necessary component in the design and deployment of autonomous robotic systems. Techniques from robust optimal control theory, such as Hamilton-Jacobi reachability analysis, allow a rigorous formalization of safety as guaranteed constraint satisfaction. Unfortunately, the computational complexity of these tools for general dynamical systems scales poorly with state dimension, making existing tools impractical beyond small problems. Modern reinforcement learning methods have shown promising ability to find approximate yet proficient solutions to optimal control problems in complex and high-dimensional systems, however their application has in practice been restricted to problems with an additive payoff over time, unsuitable for reasoning about safety. In recent work, we introduced a time-discounted modification of the problem of maximizing the minimum payoff over time, central to safety analysis, through a modified dynamic programming equation that induces a contraction mapping. Here, we show how a similar contraction mapping can render reinforcement learning techniques amenable to quantitative safety analysis as tools to approximate the safe set and optimal safety policy. This opens a new avenue of research connecting control-theoretic safety analysis and the reinforcement learning domain. We validate the correctness of our formulation by comparing safety results computed through Q-learning to analytic and numerical solutions, and demonstrate its scalability by learning safe sets and control policies for simulated systems of up to 18 state dimensions using value learning and policy gradient techniques.
ER  - 

TY  - CONF
TI  - Trajectory Planning for a Tractor with Multiple Trailers in Extremely Narrow Environments: A Unified Approach*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8557
EP  - 8562
AU  - B. Li
AU  - Y. Zhang
AU  - T. Acarma
AU  - Q. Kong
AU  - Y. Zhang
PY  - 2019
KW  - agricultural machinery
KW  - optimal control
KW  - path planning
KW  - sampling methods
KW  - search problems
KW  - vehicle dynamics
KW  - trajectory planning
KW  - multiple trailers
KW  - extremely narrow environments
KW  - unified approach
KW  - vehicle kinematics
KW  - underactuated constraints
KW  - nonholonomic constraints
KW  - prevalent sampling-based
KW  - rigid-body vehicles
KW  - tractor-trailer vehicle cases
KW  - generic n-trailer cases
KW  - tiny environments
KW  - adaptively homotopic warm-starting approach
KW  - numerical solution process
KW  - extremely tiny scenarios
KW  - online planning opportunities
KW  - Trajectory
KW  - Planning
KW  - Agricultural machinery
KW  - Kinematics
KW  - Optimal control
KW  - Wheels
KW  - Dispersion
DO  - 10.1109/ICRA.2019.8793955
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Trajectory planning for a tractor-trailer vehicle is challenging because the vehicle kinematics consists of underactuated and nonholonomic constraints that are highly coupled. Prevalent sampling-based or search-based planners suitable for rigid-body vehicles are not capable of handling the tractor-trailer vehicle cases. This work aims to deal with generic n-trailer cases in the tiny environments. To this end, an optimal control problem is formulated, which is beneficial in being accurate, straightforward, and unified. An adaptively homotopic warm-starting approach is proposed to facilitate the numerical solution process of the formulated optimal control problem. Compared with the existing sequential warm starting strategies, our proposal can adaptively define the subproblems with the purpose of making the gaps between adjacent subproblems “pleasant” for the solver. Unification and efficiency of the proposed adaptively homotopic warm-starting approach have been investigated in several extremely tiny scenarios. Our planner finds solutions that other existing planners cannot. Online planning opportunities are briefly discussed as well.
ER  - 

TY  - CONF
TI  - A Friction-Based Kinematic Model for Skid-Steer Wheeled Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8563
EP  - 8569
AU  - S. Rabiee
AU  - J. Biswas
PY  - 2019
KW  - friction
KW  - mobile robots
KW  - robot dynamics
KW  - robot kinematics
KW  - wheels
KW  - friction-based kinematic model
KW  - skid-steer drive systems
KW  - mobile robot platforms
KW  - normal operation
KW  - slippages
KW  - forward kinematics
KW  - slip prediction
KW  - skid-steer wheeled mobile robots
KW  - translational prediction error
KW  - rotational prediction error
KW  - skid-steer robot
KW  - system identification
KW  - model learning research
KW  - Mobile robots
KW  - Kinematics
KW  - Wheels
KW  - Force
KW  - Predictive models
KW  - Acceleration
DO  - 10.1109/ICRA.2019.8794216
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Skid-steer drive systems are widely used in mobile robot platforms. Such systems are subject to significant slippage and skidding during normal operation due to their nature. The ability to predict and compensate for such slippages in the forward kinematics of these types of robots is of great importance and provides the means for accurate control and safe navigation. In this work, we propose a new kinematic model capable of slip prediction for skid-steer wheeled mobile robots (SSWMRs). The proposed model outperforms the state-of-the-art in terms of both translational and rotational prediction error on a dataset composed of more than 6 km worth of trajectories traversed by a skid-steer robot. We also publicly release our dataset to serve as a benchmark for system identification and model learning research for SSWMRs.
ER  - 

TY  - CONF
TI  - Turning a Corner with a Dubins Car
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8570
EP  - 8576
AU  - A. Koval
AU  - V. Isler
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - optimisation
KW  - closed-form optimal path
KW  - efficient path planner
KW  - shortest collision-free Dubins paths
KW  - sufficient condition
KW  - closed-form solution
KW  - interior corner
KW  - elementary Dubins paths
KW  - RSRSR
KW  - RSRSL
KW  - LSRSR
KW  - LSRSL
KW  - Turning
KW  - Automobiles
KW  - Heuristic algorithms
KW  - Planning
KW  - Path planning
KW  - Approximation algorithms
KW  - Terminology
DO  - 10.1109/ICRA.2019.8794361
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We study the problem of computing shortest collision-free Dubins paths when turning a corner. We present a sufficient condition for a closed-form solution. Specifically, consider S as the set consisting of paths of the form RSRSR, RSRSL, LSRSR and LSRSL that pass through the interior corner, where sub-paths RSR, RSL, and LSR are elementary Dubins paths composed of segments which are either straight (S) or turning left (L) or right (R). We find the closed-form optimal path around a corner when S is nonempty. Our solution can be used in an efficient path planner, for example, when navigating corridors. It can also be used as a subroutine for planners such as RRTs.
ER  - 

TY  - CONF
TI  - Modeling and state estimation of a Micro Ball-balancing Robot using a high yaw-rate dynamic model and an Extended Kalman Filter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8577
EP  - 8583
AU  - E. Sihite
AU  - D. Yang
AU  - T. Bewley
PY  - 2019
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear control systems
KW  - nonlinear filters
KW  - robot dynamics
KW  - state estimation
KW  - microball-balancing robot
KW  - extended Kalman filter
KW  - linearized dynamic model
KW  - state estimator
KW  - yaw-rate ball-balancing robot dynamic model
KW  - raw on-board sensor measurements
KW  - EKF
KW  - Robot kinematics
KW  - Wheels
KW  - Mathematical model
KW  - Robot sensing systems
KW  - Torque
KW  - Kalman filters
DO  - 10.1109/ICRA.2019.8794169
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The state estimation and control of a ball-balancing robot under high yaw rate is a challenging problem due to its highly nonlinear 3D dynamic. The small size and low-cost components in our Micro Ball-Balancing Robot makes the system inherently very noisy which further increases the complexity of the problem. In order to drive the robot more aggressively such as translating and spinning at the same time, a good state estimator which works well under high yaw rates is required. This paper presents the derivation of a high yaw-rate Ball-Balancing Robot dynamic model and the implementation of said model in an Extended Kalman Filter (EKF) using raw on-board sensor measurements. The EKF using the new model is then compared to a Kalman Filter which uses a linearized dynamic model. The accuracy of the attitude estimates and the controller performance under high yaw rates were verified using a motion capture system.
ER  - 

TY  - CONF
TI  - Orientation-Aware Motion Planning in Complex Workspaces using Adaptive Harmonic Potential Fields
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8592
EP  - 8598
AU  - P. Vlantis
AU  - C. Vrohidis
AU  - C. P. Bechlioulis
AU  - K. J. Kyriakopoulos
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - orientation-aware motion planning
KW  - complex workspaces
KW  - adaptive harmonic potential fields
KW  - hybrid control scheme
KW  - navigation problem
KW  - planar robotic platform
KW  - approximate configuration space decomposition techniques
KW  - appropriate workspace transformations
KW  - adaptive potential field based control laws
KW  - configuration space representation
KW  - obstacle cluttered workspace
KW  - Aerospace electronics
KW  - Robot kinematics
KW  - Harmonic analysis
KW  - Navigation
KW  - Shape
KW  - Approximation algorithms
DO  - 10.1109/ICRA.2019.8794053
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, a hybrid control scheme is presented in order to address the navigation problem for a planar robotic platform of arbitrary shape that is moving inside an obstacle cluttered workspace. Given an initial and desired robot configuration, we propose a methodology based on approximate configuration space decomposition techniques that makes use of heuristics to adaptively refine a partition of the configuration space into non-overlapping, adjacent slices. Furthermore, we employ appropriate workspace transformations and adaptive potential field based control laws that integrate elegantly with the type of configuration space representation used, in order to safely navigate within a given cell and successfully cross over to the next, for almost all initial configurations, until the desired configuration is reached. Finally, we present simulation results that demonstrate the efficacy of the proposed control scheme.
ER  - 

TY  - CONF
TI  - Energy-Aware Temporal Logic Motion Planning for Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8599
EP  - 8605
AU  - T. Kundu
AU  - I. Saha
PY  - 2019
KW  - computability
KW  - mobile robots
KW  - path planning
KW  - power aware computing
KW  - temporal logic
KW  - trajectory control
KW  - motion planning problem
KW  - SMT solving problem
KW  - optimal trajectory
KW  - energy-aware trajectories
KW  - LTL specification
KW  - mobile robot
KW  - motion plan
KW  - battery charge
KW  - LTL formula
KW  - linear temporal logic
KW  - charging station locations
KW  - energy-aware temporal logic motion planning
KW  - satisfiability modulo theory
KW  - Trajectory
KW  - Charging stations
KW  - Batteries
KW  - Planning
KW  - Task analysis
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8794395
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a methodology for synthesizing a motion plan for a mobile robot to ensure that the robot never gets depleted with battery charge while carrying out its mission successfully. The specification of the robot is provided in the form of an LTL (Linear Temporal Logic) formula. A trajectory satisfying an LTL formula may contain a loop whose repetitive execution causes the depletion of battery charge in the robot. The motion plan generated by our methodology ensures that the robot visits the charging station periodically in such a way that it never gets depleted with battery charge while carrying out its mission optimally. Given a set of potential charging station locations and an LTL specification, our algorithm also finds the best location for the charging station along with the optimal trajectory for the robot. We encode the motion planning problem as an SMT (Satisfiability Modulo Theory) solving problem and use the off-the-shelf SMT solver Z3 to solve the constraints to find the location of the charging station and generate an optimal trajectory for the robot. We apply our methodology to synthesize energy-aware trajectories for robots with different dynamics in various workspaces and for various LTL specifications.
ER  - 

TY  - CONF
TI  - Using Local Experiences for Global Motion Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8606
EP  - 8612
AU  - C. Chamzas
AU  - A. Shrivastava
AU  - L. E. Kavraki
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - sampling methods
KW  - global motion planning
KW  - sampling-based planners
KW  - collision-free path
KW  - sampling strategy
KW  - Databases
KW  - Planning
KW  - Task analysis
KW  - Kinematics
KW  - Trajectory
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8794317
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Sampling-based planners are effective in many real-world applications such as robotics manipulation, navigation, and even protein modeling. However, it is often challenging to generate a collision-free path in environments where key areas are hard to sample. In the absence of any prior information, sampling-based planners are forced to explore uniformly or heuristically, which can lead to degraded performance. One way to improve performance is to use prior knowledge of environments to adapt the sampling strategy to the problem at hand. In this work, we decompose the workspace into local primitives, memorizing local experiences by these primitives in the form of local samplers, and store them in a database. We synthesize an efficient global sampler by retrieving local experiences relevant to the given situation. Our method transfers knowledge effectively between diverse environments that share local primitives and speeds up the performance dramatically. Our results show, in terms of solution time, an improvement of multiple orders of magnitude in two traditionally challenging high-dimensional problems compared to state-of-the-art approaches.
ER  - 

TY  - CONF
TI  - DMP Based Trajectory Tracking for a Nonholonomic Mobile Robot With Automatic Goal Adaptation and Obstacle Avoidance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8613
EP  - 8619
AU  - R. S. Sharma
AU  - S. Shukla
AU  - H. Karki
AU  - A. Shukla
AU  - L. Behera
AU  - V. K.S.
PY  - 2019
KW  - collision avoidance
KW  - fuzzy logic
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - Lyapunov methods
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - radial basis function networks
KW  - stability
KW  - steering systems
KW  - trajectory control
KW  - Dynamic Movement Primitive
KW  - motion planning
KW  - robot manipulator
KW  - nonholonomic mobile robot
KW  - Radial Basis Function Networks
KW  - robot goal position
KW  - Lyapunov stability theory-based analysis
KW  - dynamic obstacles
KW  - automatic goal adaptation
KW  - RBFN
KW  - DMP
KW  - gradient descent
KW  - static obstacles
KW  - trajectory tracking
KW  - damped spring model
KW  - steering angle dynamics
KW  - fuzzy logic
KW  - Mobile robots
KW  - Trajectory
KW  - Mathematical model
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8793911
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dynamic Movement Primitive (DMP) which is popular for motion planning of a robot manipulator, has been adapted for a nonholonomic mobile robot to track the desired trajectory. DMP is a simple damped spring model with a forcing function, which learns the trajectory. The damped spring model attracts the robot towards the goal position, and the forcing function forces the robot to follow the given trajectory. Two Radial Basis Function Networks (RBFNs) have been used to learn the forcing function associated with the DMP model. Weight update laws are derived using the gradient descent approach to train the RBFNs. Fuzzy logic based steering angle dynamics is proposed to handle the asymmetric nature of an obstacle. The proposed scheme is capable enough to generate a smooth trajectory in the presence of an obstacle even when start and goal positions are altered, without losing the spatial information embedded while training. The convergence of the robot goal position has been shown using Lyapunov stability theory-based analysis. The approach has been extended to multiple static and dynamic obstacles for the successful convergence of the robot at the goal position. Both simulation and experimental results are provided to confirm the efficacy of the proposed scheme.
ER  - 

TY  - CONF
TI  - Predictive Collision Avoidance for the Dynamic Window Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8620
EP  - 8626
AU  - M. Missura
AU  - M. Bennewitz
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - predictive collision avoidance
KW  - dynamic window approach
KW  - foresighted navigation
KW  - mobile robots
KW  - factory floor installations
KW  - dynamic collision model
KW  - nonholonomic vehicles
KW  - Trajectory
KW  - Vehicle dynamics
KW  - Dynamics
KW  - Acceleration
KW  - Collision avoidance
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794386
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Foresighted navigation is an essential skill for robots to rise from rigid factory floor installations to much more versatile mobile robots that partake in our everyday environment. The current state of the art that provides this mobility to some extent is the Dynamic Window Approach combined with a global start-to-target path planner. However, neither the Dynamic Window Approach nor the path planner are equipped to predict the motion of other objects in the environment. We propose a change in the Dynamic Window Approach-a dynamic collision model-that is capable of predicting future collisions with the environment by also taking into account the motion of other objects. We show in simulated experiments that our new way of computing the Dynamic Window Approach significantly reduces the number of collisions in a dynamic setting with nonholonomic vehicles while still being computationally efficient.
ER  - 

TY  - CONF
TI  - Kinematic Constraints Based Bi-directional RRT (KB-RRT) with Parameterized Trajectories for Robot Path Planning in Cluttered Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8627
EP  - 8633
AU  - D. Ghosh
AU  - G. Nandakumar
AU  - K. Narayanan
AU  - V. Honkote
AU  - S. Sharma
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - path planning
KW  - robot dynamics
KW  - robot kinematics
KW  - Bi-RRT algorithm
KW  - parameterized trajectories
KW  - robot path planning
KW  - complex missions
KW  - navigation capability
KW  - autonomous mobile robots
KW  - robust path planning algorithms
KW  - bidirectional-RRT
KW  - kinodynamic constraints
KW  - bidirectional RRT
KW  - trajectory planning
KW  - memory utilization
KW  - kinematic constraints
KW  - KB-RRT algorithm
KW  - Kinematics
KW  - Trajectory
KW  - Mobile robots
KW  - Navigation
KW  - Planning
DO  - 10.1109/ICRA.2019.8793896
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Optimal path planning and smooth trajectory planning are critical for effective navigation of mobile robots working towards accomplishing complex missions. For autonomous, real time and extended operations of mobile robots, the navigation capability needs to be executed at the edge. Thus, efficient compute, minimum memory utilization and smooth trajectory are the key parameters that drive the successful operation of autonomous mobile robots. Traditionally, navigation solutions focus on developing robust path planning algorithms which are complex and compute/memory intensive. Bidirectional-RRT(Bi-RRT) based path planning algorithms have gained increased attention due to their effectiveness and computational efficiency in generating feasible paths. However, these algorithms neither optimize memory nor guarantee smooth trajectories. To this end, we propose a kinematically constrained Bi-RRT (KB-RRT) algorithm, which restricts the number of nodes generated without compromising on the accuracy and incorporates kinodynamic constraints for generating smooth trajectories, together resulting in efficient navigation of autonomous mobile robots. The proposed algorithm is tested in a highly cluttered environment on an Ackermannsteering vehicle model with severe kinematic constraints. The experimental results demonstrate that KB-RRT achieves three times (3 X) better performance in terms of convergence rate and memory utilization compared to a standard Bi-RRT algorithm.
ER  - 

TY  - CONF
TI  - Predicting Vehicle Behaviors Over An Extended Horizon Using Behavior Interaction Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8634
EP  - 8640
AU  - W. Ding
AU  - J. Chen
AU  - S. Shen
PY  - 2019
KW  - recurrent neural nets
KW  - road vehicles
KW  - traffic engineering computing
KW  - recurrent neural network
KW  - interaction modeling
KW  - vehicle behaviors
KW  - autonomous vehicles
KW  - behavior detection
KW  - long-term future rewards
KW  - vehicle behavior interaction network
KW  - observation encoding
KW  - Planning
KW  - Trajectory
KW  - Vehicle dynamics
KW  - Encoding
KW  - Autonomous vehicles
KW  - Recurrent neural networks
KW  - Prediction methods
DO  - 10.1109/ICRA.2019.8794146
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Anticipating possible behaviors of traffic participants is an essential capability of autonomous vehicles. Many behavior detection and maneuver recognition methods only have a very limited prediction horizon that leaves inadequate time and space for planning. To avoid unsatisfactory reactive decisions, it is essential to count long-term future rewards in planning, which requires extending the prediction horizon. In this paper, we uncover that clues to vehicle behaviors over an extended horizon can be found in vehicle interaction, which makes it possible to anticipate the likelihood of a certain behavior, even in the absence of any clear maneuver pattern. We adopt a recurrent neural network (RNN) for observation encoding, and based on that, we propose a novel vehicle behavior interaction network (VBIN) to capture the vehicle interaction from the hidden states and connection feature of each interaction pair. The output of our method is a probabilistic likelihood of multiple behavior classes, which matches the multimodal and uncertain nature of the distant future. A systematic comparison of our method against two state-of-the-art methods and another two baseline methods on a publicly available real highway dataset is provided, showing that our method has superior accuracy and advanced capability for interaction modeling.
ER  - 

TY  - CONF
TI  - Multimodal Spatio-Temporal Information in End-to-End Networks for Automotive Steering Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8641
EP  - 8647
AU  - M. Abou-Hussein
AU  - S. H. Müller
AU  - J. Boedecker
PY  - 2019
KW  - cameras
KW  - driver information systems
KW  - image sequences
KW  - road safety
KW  - steering systems
KW  - visual input data
KW  - onboard vehicle camera
KW  - empirical comparison
KW  - spatial spatio-temporal
KW  - real-life driver
KW  - predicted steering command
KW  - recurrent multimodal model
KW  - steering correction concept
KW  - multimodal spatio-temporal information
KW  - end-to-end networks
KW  - automotive steering prediction
KW  - end-to-end steering problem
KW  - Optical imaging
KW  - Adaptive optics
KW  - Computational modeling
KW  - Kernel
KW  - Training
KW  - Roads
KW  - Cameras
KW  - Autonomous steering
KW  - deep learning
KW  - spatio-temporal model
KW  - multimodal input
KW  - optical flow
KW  - RNN-LSTM
DO  - 10.1109/ICRA.2019.8794410
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We study the end-to-end steering problem using visual input data from an onboard vehicle camera. An empirical comparison between spatial, spatio-temporal and multimodal models is performed assessing each concept's performance from two points of evaluation. First, how close the model is in predicting and imitating a real-life driver's behavior, second, the smoothness of the predicted steering command. The latter is a newly proposed metric. Building on our results, we propose a new recurrent multimodal model. The suggested model has been tested on a custom dataset recorded by BMW, as well as the public dataset provided by Udacity. Results show that it outperforms previously released scores. Further, a steering correction concept from off-lane driving through the inclusion of correction frames is presented. We show that our suggestion leads to promising results empirically.
ER  - 

TY  - CONF
TI  - OVPC Mesh: 3D Free-space Representation for Local Ground Vehicle Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8648
EP  - 8654
AU  - F. Ruetz
AU  - E. Hernández
AU  - M. Pfeiffer
AU  - H. Oleynikova
AU  - M. Cox
AU  - T. Lowe
AU  - P. Borges
PY  - 2019
KW  - computational geometry
KW  - mesh generation
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - remotely operated vehicles
KW  - robot vision
KW  - stereo image processing
KW  - OVPC Mesh
KW  - 3D free-space representation
KW  - local ground vehicle navigation
KW  - autonomous unmanned ground vehicle
KW  - Visible Point Clouds Mesh
KW  - local point cloud data
KW  - UGV navigation
KW  - on visible point clouds mesh
KW  - watertight 3D mesh generation
KW  - trajectory planning
KW  - robot
KW  - Three-dimensional displays
KW  - Navigation
KW  - Robot sensing systems
KW  - Planning
KW  - Laser radar
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793503
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel approach for local 3D environment representation for autonomous unmanned ground vehicle (UGV) navigation called On Visible Point Clouds Mesh (OVPC Mesh). Our approach represents the surrounding of the robot as a watertight 3D mesh generated from local point cloud data in order to represent the free space surrounding the robot. It is a conservative estimation of the free space and provides a desirable trade-off between representation precision and computational efficiency, without having to discretize the environment into a fixed grid size. Our experiments analyze the usability of the approach for UGV navigation in rough terrain, both in simulation and in a fully integrated real-world system. Additionally, we compare our approach to well-known state-of the-art solutions, such as Octomap and Elevation Mapping and show that OVPC Mesh can provide reliable 3D information for trajectory planning while fulfilling real-time constraints.
ER  - 

TY  - CONF
TI  - Attention-based Lane Change Prediction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8655
EP  - 8661
AU  - O. Scheel
AU  - N. S. Nagaraja
AU  - L. Schwarz
AU  - N. Navab
AU  - F. Tombari
PY  - 2019
KW  - path planning
KW  - recurrent neural nets
KW  - road vehicles
KW  - traffic engineering computing
KW  - function estimation problem
KW  - model understandability
KW  - lane change prediction model
KW  - attention-based recurrent model
KW  - prediction quality
KW  - attention-based lane change prediction
KW  - path planning
KW  - driver discomfort
KW  - Automobiles
KW  - Predictive models
KW  - Hidden Markov models
KW  - Task analysis
KW  - Vehicle dynamics
KW  - Bayes methods
DO  - 10.1109/ICRA.2019.8793648
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Lane change prediction of surrounding vehicles is a key building block of path planning. The focus has been on increasing the accuracy of prediction by posing it purely as a function estimation problem at the cost of model understandability. However, the efficacy of any lane change prediction model can be improved when both corner and failure cases are humanly understandable. We propose an attention-based recurrent model to tackle both understandability and prediction quality. We also propose metrics which reflect the discomfort felt by the driver. We show encouraging results on a publicly available dataset and proprietary fleet data.
ER  - 

TY  - CONF
TI  - Safe Reinforcement Learning With Model Uncertainty Estimates
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8662
EP  - 8668
AU  - B. Lütjens
AU  - M. Everett
AU  - J. P. How
PY  - 2019
KW  - Bayes methods
KW  - collision avoidance
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - safety
KW  - model uncertainty estimates
KW  - current autonomous systems
KW  - strong reliance
KW  - black box predictions
KW  - deep neural networks
KW  - DNNs
KW  - unpredictable results
KW  - far-from-distribution test data
KW  - distributional shift
KW  - safety-critical applications
KW  - pedestrians
KW  - state-of-the-art extraction methods
KW  - Bayesian neural networks
KW  - MC-Dropout
KW  - computationally tractable uncertainty estimates
KW  - parallelizable uncertainty estimates
KW  - uncertainty-aware navigation
KW  - collision avoidance policy
KW  - unseen behavior
KW  - uncertainty-unaware baseline
KW  - safe reinforcement learning framework
KW  - Uncertainty
KW  - Collision avoidance
KW  - Neural networks
KW  - Computational modeling
KW  - Training
KW  - Data models
KW  - Reinforcement learning
DO  - 10.1109/ICRA.2019.8793611
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Many current autonomous systems are being designed with a strong reliance on black box predictions from deep neural networks (DNNs). However, DNNs tend to be overconfident in predictions on unseen data and can give unpredictable results for far-from-distribution test data. The importance of predictions that are robust to this distributional shift is evident for safety-critical applications, such as collision avoidance around pedestrians. Measures of model uncertainty can be used to identify unseen data, but the state-of-the-art extraction methods such as Bayesian neural networks are mostly intractable to compute. This paper uses MC-Dropout and Bootstrapping to give computationally tractable and parallelizable uncertainty estimates. The methods are embedded in a Safe Reinforcement Learning framework to form uncertainty-aware navigation around pedestrians. The result is a collision avoidance policy that knows what it does not know and cautiously avoids pedestrians that exhibit unseen behavior. The policy is demonstrated in simulation to be more robust to novel observations and take safer actions than an uncertainty-unaware baseline.
ER  - 


TY  - CONF
TI  - Using DP Towards A Shortest Path Problem-Related Application
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8669
EP  - 8675
AU  - J. Jiao
AU  - R. Fan
AU  - H. Ma
AU  - M. Liu
PY  - 2019
KW  - directed graphs
KW  - dynamic programming
KW  - graph theory
KW  - image segmentation
KW  - object detection
KW  - search problems
KW  - traffic engineering computing
KW  - line segments
KW  - directed graph model
KW  - dynamic programming
KW  - shortest path problem-related application
KW  - curved lanes
KW  - autonomous driving systems
KW  - visual recognition tasks
KW  - lane detection
KW  - two-dimensional graph searching problem
KW  - optimal path finding
KW  - Search problems
KW  - Roads
KW  - Visualization
KW  - Shortest path problem
KW  - Mathematical model
KW  - Task analysis
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793603
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The detection of curved lanes is still challenging for autonomous driving systems. Although current cutting-edge approaches have performed well in real applications, most of them are based on strict model assumptions. Similar to other visual recognition tasks, lane detection can be formulated as a two-dimensional graph searching problem, which can be solved by finding several optimal paths along with line segments and boundaries. In this paper, we present a directed graph model, in which dynamic programming is used to deal with a specific shortest path problem. This model is particularly suitable to represent objects with long continuous shape structure, e.g., lanes and roads. We apply the designed model and proposed an algorithm for detecting lanes by formulating it as the shortest path problem. To evaluate the performance of our proposed algorithm, we tested five sequences (including 1573 frames) from the KITTI database. The results showed that our method achieves an average successful detection precision of 97.5%.
ER  - 

TY  - CONF
TI  - Improving dual-arm assembly by master-slave compliance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8676
EP  - 8682
AU  - M. Suomalainen
AU  - S. Calinon
AU  - E. Pignat
AU  - V. Kyrki
PY  - 2019
KW  - force control
KW  - human-robot interaction
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - motion control
KW  - multi-robot systems
KW  - robotic assembly
KW  - telerobotics
KW  - learning method
KW  - master-slave compliance
KW  - dual-arm assembly task
KW  - compliance parameters
KW  - human demonstration
KW  - compliant motions
KW  - assembly tasks
KW  - convergence region
KW  - alignment task
KW  - compliant axes
KW  - orientation error
KW  - single teleoperated manipulator
KW  - manipulators compliant
KW  - total joint motions
KW  - Task analysis
KW  - Manipulators
KW  - Tools
KW  - Jamming
KW  - Wrist
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793977
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we show how different choices regarding compliance affect a dual-arm assembly task. In addition, we present how the compliance parameters can be learned from a human demonstration. Compliant motions can be used in assembly tasks to mitigate pose errors originating from, for example, inaccurate grasping. We present analytical background and accompanying experimental results on how to choose the center of compliance to enhance the convergence region of an alignment task. Then we present the possible ways of choosing the compliant axes for accomplishing alignment in a scenario where orientation error is present. We show that an earlier presented Learning from Demonstration method can be used to learn motion and compliance parameters of an impedance controller for both manipulators. The learning requires a human demonstration with a single teleoperated manipulator only, easing the execution of demonstration and enabling usage of manipulators at difficult locations as well. Finally, we experimentally verify our claim that having both manipulators compliant in both rotation and translation can accomplish the alignment task with less total joint motions and in shorter time than moving one manipulator only. In addition, we show that the learning method produces the parameters that achieve the best results in our experiments.
ER  - 

TY  - CONF
TI  - Generation of Synchronized Configuration Space Trajectories of Multi-Robot Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8683
EP  - 8690
AU  - A. M. Kabir
AU  - A. Kanyuck
AU  - R. K. Malhan
AU  - A. V. Shembekar
AU  - S. Thakar
AU  - B. C. Shah
AU  - S. K. Gupta
PY  - 2019
KW  - multi-robot systems
KW  - optimisation
KW  - synchronized configuration space trajectories
KW  - multirobot systems
KW  - path-constrained trajectory generation
KW  - synchronous motion
KW  - nonlinear optimization problem
KW  - configuration variables
KW  - successive refinement techniques
KW  - parametric representation
KW  - Trajectory
KW  - Manipulators
KW  - Splines (mathematics)
KW  - Optimization
KW  - Robot kinematics
KW  - Tools
DO  - 10.1109/ICRA.2019.8794275
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We pose the problem of path-constrained trajectory generation for the synchronous motion of multi-robot systems as a non-linear optimization problem. Our method determines appropriate parametric representation for the configuration variables, generates an approximate solution as a starting point for the optimization method, and uses successive refinement techniques to solve the problem in a computationally efficient manner. We have demonstrated the effectiveness of the proposed method on challenging simulation and physical experiments with high degrees of freedom robotic systems.
ER  - 

TY  - CONF
TI  - REPLAB: A Reproducible Low-Cost Arm Benchmark for Robotic Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8691
EP  - 8697
AU  - B. Yang
AU  - D. Jayaraman
AU  - J. Zhang
AU  - S. Levine
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot programming
KW  - robot vision
KW  - reproducible low-cost arm benchmark
KW  - robotic learning
KW  - vision-based manipulation benchmark
KW  - robot arm
KW  - robotics
KW  - grasping benchmark
KW  - evaluation protocol
KW  - standardized evaluation
KW  - machine learning
KW  - REPLAB
KW  - Robots
KW  - Benchmark testing
KW  - Task analysis
KW  - Grasping
KW  - Hardware
KW  - Cameras
KW  - Calibration
DO  - 10.1109/ICRA.2019.8794390
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Standardized evaluation measures have aided in the progress of machine learning approaches in disciplines such as computer vision and machine translation. In this paper, we make the case that robotic learning would also benefit from benchmarking, and present a template for a vision-based manipulation benchmark. Our benchmark is built on “REPLAB,” a reproducible and self-contained hardware stack (robot arm, camera, and workspace) that costs about 2000 USD and occupies a cuboid of size 70x40x60 cm. Each REPLAB cell may be assembled within a few hours. Through this low-cost, compact design, REPLAB aims to drive wide participation by lowering the barrier to entry into robotics and to enable easy scaling to many robots. We envision REPLAB as a framework for reproducible research across manipulation tasks, and as a step in this direction, we define a grasping benchmark consisting of a task definition, evaluation protocol, performance measures, and a dataset of over 50,000 grasp attempts. We implement, evaluate, and analyze several previously proposed grasping approaches to establish baselines for this benchmark. Project page with assembly instructions, additional details, and videos: https://goo.gl/5F9dP4.
ER  - 

TY  - CONF
TI  - Stable Bin Packing of Non-convex 3D Objects with a Robot Manipulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8698
EP  - 8704
AU  - F. Wang
AU  - K. Hauser
PY  - 2019
KW  - computational geometry
KW  - control engineering computing
KW  - industrial manipulators
KW  - production engineering computing
KW  - warehouse automation
KW  - nonconvex objects
KW  - bin packing
KW  - heightmap-minimization heuristic
KW  - constructive packing pipeline
KW  - placement plans
KW  - robot motion
KW  - automated warehousing domain
KW  - packing problem
KW  - fully automatic object packing
KW  - robot manipulator
KW  - nonconvex 3D objects
KW  - high-quality packing
KW  - robot packability constraints
KW  - Robots
KW  - Three-dimensional displays
KW  - Containers
KW  - Stability analysis
KW  - Collision avoidance
KW  - Pipelines
KW  - Geometry
DO  - 10.1109/ICRA.2019.8794049
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent progress in the field of robotic manipulation has generated interest in fully automatic object packing in warehouses. This paper proposes a formulation of the packing problem that is tailored to the automated warehousing domain. Besides minimizing waste space inside a container, the problem requires stability of the object pile during packing and the feasibility of the robot motion executing the placement plans. To address this problem, a set of constraints are formulated, and a constructive packing pipeline is proposed to solve these constraints. The pipeline is able to pack geometrically complex, non-convex objects while satisfying stability and robot packability constraints. In particular, a new 3D positioning heuristic called Heightmap-Minimization heuristic is proposed, and heightmaps are used to speed up the search. Experimental evaluation of the method is conducted with a realistic physical simulator on a dataset of scanned real-world items, demonstrating stable and high-quality packing plans compared with other 3D packing methods.
ER  - 

TY  - CONF
TI  - A Constraint Programming Approach to Simultaneous Task Allocation and Motion Scheduling for Industrial Dual-Arm Manipulation Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8705
EP  - 8711
AU  - J. K. Behrens
AU  - R. Lange
AU  - M. Mansouri
PY  - 2019
KW  - constraint handling
KW  - industrial manipulators
KW  - motion control
KW  - optimisation
KW  - robot programming
KW  - robotic assembly
KW  - scheduling
KW  - robotic platforms
KW  - constraint programming approach
KW  - simultaneous task allocation
KW  - motion scheduling
KW  - industrial dual-arm manipulation tasks
KW  - dual-arm robots
KW  - industrial manipulation
KW  - assembly tasks
KW  - robot motion models
KW  - constraint optimization problems
KW  - makespan-optimized robot programs
KW  - industrial workplaces
KW  - robot-independent task model
KW  - lightweight dual-arm robots
KW  - ordered visiting constraint
KW  - ordering constraints
KW  - Task analysis
KW  - Planning
KW  - Manipulators
KW  - Robot kinematics
KW  - Job shop scheduling
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794022
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Modern lightweight dual-arm robots bring the physical capabilities to quickly take over tasks at typical industrial workplaces designed for workers. Low setup times - including the instructing/specifying of new tasks - are crucial to stay competitive. We propose a constraint programming approach to simultaneous task allocation and motion scheduling for such industrial manipulation and assembly tasks. Our approach covers the robot as well as connected machines. The key concept are Ordered Visiting Constraints, a descriptive and extensible model to specify such tasks with their spatiotemporal requirements and combinatorial or ordering constraints. Our solver integrates such task models and robot motion models into constraint optimization problems and solves them efficiently using various heuristics to produce makespan-optimized robot programs. For large manipulation tasks with 200 objects, our solver implemented using Google's Operations Research tools requires less than a minute to compute usable plans. The proposed task model is robot-independent and can easily be deployed to other robotic platforms. This portability is validated through several simulation-based experiments.
ER  - 

TY  - CONF
TI  - Self-Supervised Surgical Tool Segmentation using Kinematic Information
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8720
EP  - 8726
AU  - C. d. C. Rocha
AU  - N. Padoy
AU  - B. Rosa
PY  - 2019
KW  - calibration
KW  - convolutional neural nets
KW  - endoscopes
KW  - image classification
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - medical robotics
KW  - optimisation
KW  - pose estimation
KW  - robot vision
KW  - surgery
KW  - training labels
KW  - optimization method
KW  - unknown hand-eye calibration
KW  - imprecise kinematic model
KW  - fully-convolutional neural network
KW  - endoscopic images
KW  - flexible robotized endoscopy system
KW  - self-supervised surgical tool segmentation
KW  - kinematic information
KW  - task automation
KW  - minimally invasive surgical operations
KW  - modern machine learning methods
KW  - manually-annotated images
KW  - surgical context
KW  - patient-to-patient differences
KW  - annotated data
KW  - self-supervised approach
KW  - robot-assisted context
KW  - pose estimation
KW  - subtask automation
KW  - hand-eye calibration
KW  - pixel-wise classification
KW  - Tools
KW  - Image segmentation
KW  - Kinematics
KW  - Shape
KW  - Robot kinematics
KW  - Cost function
DO  - 10.1109/ICRA.2019.8794334
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Surgical tool segmentation in endoscopic images is the first step towards pose estimation and (sub-)task automation in challenging minimally invasive surgical operations. While many approaches in the literature have shown great results using modern machine learning methods such as convolutional neural networks, the main bottleneck lies in the acquisition of a large number of manually-annotated images for efficient learning. This is especially true in surgical context, where patient-to-patient differences impede the overall generalizability. In order to cope with this lack of annotated data, we propose a self-supervised approach in a robot-assisted context. To our knowledge, the proposed approach is the first to make use of the kinematic model of the robot in order to generate training labels. The core contribution of the paper is to propose an optimization method to obtain good labels for training despite an unknown hand-eye calibration and an imprecise kinematic model. The labels can subsequently be used for fine-tuning a fully-convolutional neural network for pixel-wise classification. As a result, the tool can be segmented in the endoscopic images without needing a single manually-annotated image. Experimental results on phantom and in vivo datasets obtained using a flexible robotized endoscopy system are very promising.
ER  - 

TY  - CONF
TI  - Needle Localization for Robot-assisted Subretinal Injection based on Deep Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8727
EP  - 8732
AU  - M. Zhou
AU  - X. Wang
AU  - J. Weiss
AU  - A. Eslami
AU  - K. Huang
AU  - M. Maier
AU  - C. P. Lohmann
AU  - N. Navab
AU  - A. Knoll
AU  - M. A. Nasseri
PY  - 2019
KW  - biomedical optical imaging
KW  - eye
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - medical robotics
KW  - needles
KW  - optical tomography
KW  - surgery
KW  - visual feedback
KW  - microscope-integrated optical coherence tomography
KW  - robotic subretinal injection
KW  - needle segment
KW  - retinal surface
KW  - OCT volumetric images
KW  - MI-OCT
KW  - needle detection
KW  - human surgeons
KW  - robot-assisted surgery
KW  - high surgical precision
KW  - deep learning
KW  - robot-assisted subretinal injection
KW  - needle localization
KW  - Needles
KW  - Retina
KW  - Surgery
KW  - Image segmentation
KW  - Robots
KW  - Microscopy
KW  - Agriculture
DO  - 10.1109/ICRA.2019.8793756
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Subretinal injection is known to be a complicated task for ophthalmologists to perform, the main sources of difficulties are the fine anatomy of the retina, insufficient visual feedback, and high surgical precision. Image guided robot-assisted surgery is one of the promising solutions that bring significant surgical enhancement in treatment outcome and reduces the physical limitations of human surgeons. In this paper, we demonstrate a robust framework for needle detection and localization in subretinal injection using microscope-integrated Optical Coherence Tomography (MI-OCT) based on deep learning. The proposed method consists of two main steps: a) the preprocessing of OCT volumetric images; b) needle localization in the processed images. The first step is to coarsely localize the needle position based on the needle information above the retinal surface and crop the original image into a small region of interest (ROI). Afterward, the cropped small image is fed into a well trained network for detection and localization of the needle segment. The entire framework is extensively validated in ex-vivo pig eye experiments with robotic subretinal injection. The results show that the proposed method can localize the needle accurately with a confidence of 99.2%.
ER  - 

TY  - CONF
TI  - Robust Generalized Point Set Registration using Inhomogeneous Hybrid Mixture Models via Expectation Maximization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8733
EP  - 8739
AU  - Z. Min
AU  - M. Q. -. Meng
PY  - 2019
KW  - computer vision
KW  - expectation-maximisation algorithm
KW  - Gaussian distribution
KW  - Gaussian processes
KW  - image registration
KW  - iterative methods
KW  - optimisation
KW  - generalized point set registration
KW  - translation vector
KW  - surface points
KW  - inhomogeneous hybrid mixture models
KW  - expectation maximization
KW  - biomedical engineering communities
KW  - orientational vector
KW  - expectation-maximization framework
KW  - registration methods
KW  - Fisher distribution mixture models
KW  - GMM
KW  - FMM
KW  - PSR
KW  - Hidden Markov models
KW  - Mixture models
KW  - Probabilistic logic
KW  - Maximum likelihood estimation
KW  - Data models
KW  - Principal component analysis
KW  - Nonhomogeneous media
DO  - 10.1109/ICRA.2019.8794135
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Point set registration (PSR) is an important problem in computer vision, robotics and biomedical engineering communities. Usually, only positional information at each point is adopted in a registration. In this paper, the orientational vector (or normal vector) associated with each point is also utilized. Generalized point set registration is formulated and solved under the Expectation-Maximization (EM) framework. In the E-step, the posterior probabilities representing the correspondence probabilities are computed. In the Mstep, rigid transformation parameters including the rotation matrix, the translation vector are updated. The proposed algorithm stops when it converges to the optimal solution or a maximum number of iterations is achieved. The observed position set and normal vector set are assumed to follow Gaussian Mixture Models (GMMs) and Fisher distribution Mixture Models (FMMs), respectively. To further improve our algorithm's robustness, the hybrid mixture models (HMMs) are assumed to be inhomogeneous. Experimental results on the surface points extracted from a human femur' CT model show that our algorithm can achieve lower registration error, is more robust to noise and outliers than the state-of-the-art registration methods.
ER  - 

TY  - CONF
TI  - Visual Guidance and Automatic Control for Robotic Personalized Stent Graft Manufacturing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8740
EP  - 8746
AU  - Y. Guo
AU  - M. Sun
AU  - F. P. W. Lo
AU  - B. Lo
PY  - 2019
KW  - blood vessels
KW  - cameras
KW  - diseases
KW  - image matching
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - manipulator dynamics
KW  - medical image processing
KW  - medical robotics
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - stents
KW  - stereo image processing
KW  - robotic platforms
KW  - autonomous personalized stent graft manufacturing
KW  - stereo vision systems
KW  - personalized stent-graft manufacturing
KW  - robotic arm
KW  - dynamic stereo microscope
KW  - static wide angle view stereo webcam
KW  - multiple stereo camera configuration
KW  - sewing process
KW  - stereo matching
KW  - feature identifications
KW  - visual-servoing system
KW  - real-time intelligent robotic control
KW  - visual guidance
KW  - automatic control
KW  - robotic personalized stent graft manufacturing
KW  - AAA patient
KW  - hybrid vision system
KW  - abdominal aortic aneurysms patient
KW  - DDPG
KW  - reinforcement learning
KW  - object localization
KW  - Microscopy
KW  - Robot kinematics
KW  - Needles
KW  - Webcams
KW  - Manipulators
KW  - Aneurysm
DO  - 10.1109/ICRA.2019.8794123
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Personalized stent graft is designed to treat Abdominal Aortic Aneurysms (AAA). Due to the individual difference in arterial structures, stent graft has to be custom made for each AAA patient. Robotic platforms for autonomous personalized stent graft manufacturing have been proposed in recently which rely upon stereo vision systems for coordinating multiple robots for fabricating customized stent grafts. This paper proposes a novel hybrid vision system for real-time visual-sevoing for personalized stent-graft manufacturing. To coordinate the robotic arms, this system is based on projecting a dynamic stereo microscope coordinate system onto a static wide angle view stereo webcam coordinate system. The multiple stereo camera configuration enables accurate localization of the needle in 3D during the sewing process. The scale-invariant feature transform (SIFT) method and color filtering are implemented for stereo matching and feature identifications for object localization. To maintain the clear view of the sewing process, a visual-servoing system is developed for guiding the stereo microscopes for tracking the needle movements. The deep deterministic policy gradient (DDPG) reinforcement learning algorithm is developed for real-time intelligent robotic control. Experimental results have shown that the robotic arm can learn to reach the desired targets autonomously.
ER  - 

TY  - CONF
TI  - Towards 3D Path Planning from a Single 2D Fluoroscopic Image for Robot Assisted Fenestrated Endovascular Aortic Repair
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8747
EP  - 8753
AU  - J. Zheng
AU  - X. Zhou
AU  - C. Riga
AU  - G. Yang
PY  - 2019
KW  - blood vessels
KW  - computerised tomography
KW  - diagnostic radiography
KW  - image registration
KW  - image segmentation
KW  - medical image processing
KW  - medical robotics
KW  - path planning
KW  - phantoms
KW  - CT scans
KW  - computed tomography
KW  - 2D intra-operative AAA skeletons
KW  - graph matching method
KW  - 3D preoperative AAA
KW  - 3D distance error
KW  - skeleton length
KW  - skeleton deformation
KW  - real-time 3D robotic path planning
KW  - Abdominal Aortic Aneurysm
KW  - skeleton instantiation framework
KW  - 2D fluoroscopic images
KW  - fenestrated endovascular aortic repair
KW  - single 2D fluoroscopic image
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Skeleton
KW  - Indexes
KW  - Robots
KW  - Arteries
KW  - Path planning
DO  - 10.1109/ICRA.2019.8793918
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The current standard of intra-operative navigation during Fenestrated Endovascular Aortic Repair (FEVAR) calls for the need of 3D alignments between inserted devices and aortic branches. The navigation commonly via 2D fluoroscopic images, lacks anatomical information, resulting in longer operation hours and radiation exposure. In this paper, a skeleton instantiation framework of Abdominal Aortic Aneurysm (AAA) from a single 2D fluoroscopic image is introduced for real-time 3D robotic path planning. A graph matching method is proposed to establish the correspondences between the 3D preoperative and 2D intra-operative AAA skeletons, and then the two skeletons are registered by skeleton deformation and regularization in respect to skeleton length and smoothness. Furthermore, deep learning was used to segment 3D preoperative AAA from Computed Tomography (CT) scans to facilitate the framework automation. Simulation, phantom and patient AAA data sets have been used to validate the proposed framework. 3D distance error of 2mm was achieved in the phantom setup. Performance advantages were also achieved in terms of accuracy, robustness and time-efficiency.
ER  - 

TY  - CONF
TI  - Multi-View Picking: Next-best-view Reaching for Improved Grasping in Clutter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8762
EP  - 8768
AU  - D. Morrison
AU  - P. Corke
AU  - J. Leitner
PY  - 2019
KW  - cameras
KW  - clutter
KW  - grippers
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - uncertainty handling
KW  - clutter
KW  - occlusions
KW  - active perception approach
KW  - informative viewpoints
KW  - MVP controller
KW  - multiple fixed viewpoints
KW  - next-best-view reaching
KW  - improved grasping
KW  - camera viewpoint selection
KW  - visual grasp detection
KW  - multiview picking controller
KW  - real-time grasp pose estimates
KW  - uncertainty reduction
KW  - Visualization
KW  - Entropy
KW  - Cameras
KW  - Grasping
KW  - Clutter
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793805
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Camera viewpoint selection is an important aspect of visual grasp detection, especially in clutter where many occlusions are present. Where other approaches use a static camera position or fixed data collection routines, our Multi-View Picking (MVP) controller uses an active perception approach to choose informative viewpoints based directly on a distribution of grasp pose estimates in real time, reducing uncertainty in the grasp poses caused by clutter and occlusions. In trials of grasping 20 objects from clutter, our MVP controller achieves 80% grasp success, outperforming a single-viewpoint grasp detector by 12%. We also show that our approach is both more accurate and more efficient than approaches which consider multiple fixed viewpoints. Code is available at https://github.com/dougsm/mvp_grasp.
ER  - 

TY  - CONF
TI  - A Multi-Sensor Next-Best-View Framework for Geometric Model-Based Robotics Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8769
EP  - 8775
AU  - J. Cui
AU  - J. T. Wen
AU  - J. Trinkle
PY  - 2019
KW  - computational geometry
KW  - image reconstruction
KW  - image sensors
KW  - inspection
KW  - mobile robots
KW  - robot vision
KW  - solid modelling
KW  - model building process
KW  - weld seam inspection
KW  - multisensor next-best-view framework
KW  - geometric model-based robotics applications
KW  - consecutive sensing actions
KW  - robotic 3D reconstruction systems
KW  - reconstruction goals
KW  - Modeling
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Cameras
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794423
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Geometric models are crucial for many robotics applications. Current robotic 3D reconstruction systems only focus on specific reconstruction goals which make them hard to adapt to different tasks. In this paper we present a next-best-view framework which allows robots to construct a geometric model incrementally through consecutive sensing actions. Instead of limiting the type and total number of sensors, in each sensing step we evaluate actions from all available sensors and pick the best to execute. Our framework is more comprehensive since the model building process can be designed to best accomplish different tasks. The system has been demonstrated in two experiments on 3D reconstruction and weld seam inspection, yielding promising results.
ER  - 

TY  - CONF
TI  - Model-Free Optimal Estimation and Sensor Placement Framework for Elastic Kinematic Chain
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8776
EP  - 8782
AU  - J. Ahn
AU  - J. Yoon
AU  - J. Lee
AU  - D. Lee
PY  - 2019
KW  - elasticity
KW  - manipulator kinematics
KW  - maximum likelihood estimation
KW  - motion control
KW  - optimal control
KW  - probability
KW  - sensor placement
KW  - sensors
KW  - inertial measurement unit sensors
KW  - high-DOF EKC
KW  - high-degree-of-freedom EKC
KW  - maximum a posteriori estimation
KW  - posterior probability
KW  - real-time output estimation
KW  - optimal placement
KW  - optimal IMU placement
KW  - MAP estimation
KW  - POD mode
KW  - nondominant modes
KW  - proper orthogonal decomposition
KW  - IMU sensors
KW  - elastic kinematic chain
KW  - sensor placement framework
KW  - model-free optimal estimation
KW  - Estimation
KW  - Robot sensing systems
KW  - Vibrations
KW  - Kinematics
KW  - Manipulators
KW  - Telerobotics
KW  - Covariance matrices
DO  - 10.1109/ICRA.2019.8793665
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel model-free optimal estimation and sensor placement framework for a high-DOF (degree-of-freedom) EKC (elastic kinematic chain) with only a limited number of IMU (inertial measurement unit) sensors based on POD (proper orthogonal decomposition) and MAP (maximum a posteriori) estimation. First, we (off-line) excite the system richly enough, collect the data and perform the POD to extract dominant and non-dominant modes. We then decide the minimum number of IMUs according to the dominant modes, and construct the prior distribution of the output (i.e., top-end position of EKC) based on the singular value of each POD mode. We also formulate the MAP estimation given the prior distribution and different placements of the IMUs and choose the optimal IMU placement to maximize the posterior probability. This optimal placement is then used for real-time output estimation of the EKC. Experiments are also performed to verify the theory.
ER  - 

TY  - CONF
TI  - Tree Search Techniques for Minimizing Detectability and Maximizing Visibility
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8791
EP  - 8797
AU  - Z. Zhang
AU  - J. Lee
AU  - J. M. Smereka
AU  - Y. Sung
AU  - L. Zhou
AU  - P. Tokekar
PY  - 2019
KW  - game theory
KW  - minimax techniques
KW  - Monte Carlo methods
KW  - tree searching
KW  - trees (mathematics)
KW  - tree search techniques
KW  - reconnaissance mission
KW  - pursuit-evasion problem
KW  - finite-horizon path
KW  - zero-sum game
KW  - game tree search algorithms
KW  - minimax search tree
KW  - Monte-Carlo search tree
KW  - detectability minimization
KW  - visibility maximization
KW  - visibility-based target search
KW  - pruning techniques
KW  - Games
KW  - Search problems
KW  - Planning
KW  - Monte Carlo methods
KW  - Game theory
KW  - Task analysis
KW  - Reconnaissance
DO  - 10.1109/ICRA.2019.8794305
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We introduce and study the problem of planning a trajectory for an agent to carry out a reconnaissance mission while avoiding being detected by an adversarial guard. This introduces a multi-objective version of classical visibility-based target search and pursuit-evasion problem. In our formulation, the agent receives a positive reward for increasing its visibility (by exploring new regions) and a negative penalty every time it is detected by the guard. The objective is to find a finite-horizon path for the agent that balances the trade off between maximizing visibility and minimizing detectability.We model this problem as a discrete, sequential, two-player, zero-sum game. We use two types of game tree search algorithms to solve this problem: minimax search tree and Monte-Carlo search tree. Both search trees can yield the optimal policy but may require possibly exponential computational time and space. We propose several pruning techniques to reduce the computational cost while still preserving optimality guarantees. Simulation results show that the proposed strategy prunes approximately three orders of magnitude nodes as compared to the brute-force strategy. We also find that the Monte-Carlo search tree saves approximately one order of computational time as compared to the minimax search tree.
ER  - 

TY  - CONF
TI  - Chance Constrained Motion Planning for High-Dimensional Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8805
EP  - 8811
AU  - S. Dai
AU  - S. Schaffert
AU  - A. Jasour
AU  - A. Hofmann
AU  - B. Williams
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - optimal control
KW  - probability
KW  - chance constrained motion planning
KW  - high-dimensional robots
KW  - Probabilistic Chekov
KW  - chance-constrained motion planning system
KW  - degree-of-freedom robots
KW  - motion uncertainty
KW  - state information
KW  - observation noise models
KW  - deterministic motion planning
KW  - integrated trajectory optimization
KW  - sparse roadmap framework
KW  - planning speed
KW  - high-dimensional tasks
KW  - linear-quadratic Gaussian motion planning approach
KW  - robot state probability distribution
KW  - collision risk estimation
KW  - robotic planning tasks
KW  - p-Chekov system
KW  - user-specified chance constraints
KW  - real-world planning scenarios
KW  - Planning
KW  - Robots
KW  - Trajectory
KW  - Collision avoidance
KW  - Task analysis
KW  - Estimation
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793660
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces Probabilistic Chekov (p-Chekov), a chance-constrained motion planning system that can be applied to high degree-of-freedom (DOF) robots under motion uncertainty and imperfect state information. Given process and observation noise models, it can find feasible trajectories which satisfy a user-specified bound over the probability of collision. Leveraging our previous work in deterministic motion planning which integrated trajectory optimization into a sparse roadmap framework, p-Chekov shows superiority in its planning speed for high-dimensional tasks. P-Chekov incorporates a linear-quadratic Gaussian motion planning approach into the estimation of the robot state probability distribution, applies quadrature theories to waypoint collision risk estimation, and adapts risk allocation approaches to assign allowable probabilities of failure among waypoints. Unlike other existing risk-aware planners, p-Chekov can be applied to high-DOF robotic planning tasks without the convexification of the environment. The experiment results in this paper show that this p-Chekov system can effectively reduce collision risk and satisfy user-specified chance constraints in typical real-world planning scenarios for high-DOF robots.
ER  - 

TY  - CONF
TI  - Complete and Near-Optimal Path Planning for Simultaneous Sensor-Based Inspection and Footprint Coverage in Robotic Crack Filling
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8812
EP  - 8818
AU  - K. Yu
AU  - C. Guo
AU  - J. Yi
PY  - 2019
KW  - filling
KW  - inspection
KW  - mobile robots
KW  - optimal control
KW  - path planning
KW  - sensors
KW  - surface cracks
KW  - near-optimal path planning
KW  - robotic crack
KW  - simultaneous robotic footprint
KW  - range sensors
KW  - complete sensor coverage
KW  - planning strategy
KW  - crack-filling robotic prototype
KW  - online planning algorithm
KW  - sensor-based inspection
KW  - near-optimal footprint coverage
KW  - online sensor-based complete coverage planning
KW  - online SCC planning
KW  - Robot sensing systems
KW  - Planning
KW  - Inspection
KW  - Space exploration
KW  - Surface cracks
DO  - 10.1109/ICRA.2019.8794407
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A simultaneous robotic footprint and sensor coverage planning scheme is proposed to efficiently detect all the unknown targets with range sensors and cover the targets with the robot's footprint in a structured environment. The proposed online Sensor-based Complete Coverage (online SCC) planning minimizes the total traveling distance of the robot, guarantees the complete sensor coverage of the whole free space, and achieves near-optimal footprint coverage of all the targets. The planning strategy is applied to a crack-filling robotic prototype to detect and fill all the unknown cracks on ground surfaces. Simulation and experimental results are presented that confirm the efficiency and effectiveness of the proposed online planning algorithm.
ER  - 

TY  - CONF
TI  - Approximate Stability Analysis for Drystacked Structures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8819
EP  - 8824
AU  - Y. Liu
AU  - M. Saboia
AU  - V. Thangavelu
AU  - N. Napp
PY  - 2019
KW  - building materials
KW  - geometry
KW  - linear programming
KW  - mechanical stability
KW  - planning
KW  - road building
KW  - shrinkage
KW  - construction materials
KW  - contact geometry
KW  - geometric safety factor
KW  - automated dry stacking procedure
KW  - building elements
KW  - structural stability analysis
KW  - kern
KW  - shrinkage
KW  - linear programming
KW  - fully simulated shaking test
KW  - heuristics-based planning
KW  - assembly process
KW  - Stability analysis
KW  - Force
KW  - Friction
KW  - Mathematical model
KW  - Stacking
KW  - Numerical stability
KW  - Buildings
DO  - 10.1109/ICRA.2019.8794158
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We introduce a fast approximate stability analysis into an automated dry stacking procedure. Evaluating structural stability is essential for any type of construction, but especially challenging in techniques where building elements remain distinct and do not use fasteners or adhesives. Due to the irregular shape of construction materials, autonomous agents have restricted knowledge of contact geometry, which makes existing analysis tools difficult to deploy. In this paper, a geometric safety factor called kern is used to estimate how much the contact interface can shrink and the structure still be feasible, where feasibility can be checked efficiently using linear programming. We validate the stability measure by comparing the proposed methods with a fully simulated shaking test in 2D. We also improve existing heuristics-based planning by adding the proposed measure into the assembly process.
ER  - 

TY  - CONF
TI  - User-Guided Offline Synthesis of Robot Arm Motion from 6-DoF Paths
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8825
EP  - 8831
AU  - P. Praveena
AU  - D. Rakita
AU  - B. Mutlu
AU  - M. Gleicher
PY  - 2019
KW  - control system synthesis
KW  - end effectors
KW  - manipulator kinematics
KW  - motion control
KW  - trajectory control
KW  - orientation goals
KW  - joint-space discontinuities
KW  - user specifications
KW  - user-guided offline synthesis
KW  - robot arm motion
KW  - 6-DoF path
KW  - robot arms
KW  - end-effector
KW  - trajectories
KW  - pose goals
KW  - self-collisions
KW  - kinematic singularities
KW  - Trajectory
KW  - End effectors
KW  - Interpolation
KW  - Kinematics
KW  - Optimization
KW  - Aerospace electronics
DO  - 10.1109/ICRA.2019.8793483
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an offline method to generate smooth, feasible motion for robot arms such that end-effector pose goals of a 6-DoF path are matched within acceptable limits specified by the user. Our approach aims to accurately match the position and orientation goals of the given path, and allows deviation from these goals if there is danger of self-collisions, joint-space discontinuities or kinematic singularities. Our method generates multiple candidate trajectories, and selects the best by incorporating sparse user input that specifies what kinds of deviations are acceptable. We apply our method to a range of challenging paths and show that our method generates solutions that achieve smooth, feasible motions while closely approximating the given pose goals and adhering to user specifications.
ER  - 

TY  - CONF
TI  - Visual Robot Task Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8832
EP  - 8838
AU  - C. Paxton
AU  - Y. Barnoy
AU  - K. Katyal
AU  - R. Arora
AU  - G. D. Hager
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - Monte Carlo methods
KW  - neural net architecture
KW  - planning (artificial intelligence)
KW  - robot vision
KW  - tree searching
KW  - visual robot task planning
KW  - visual information
KW  - planning algorithm
KW  - neural network architecture
KW  - Monte Carlo tree search
KW  - block-stacking simulation
KW  - Task analysis
KW  - Planning
KW  - Visualization
KW  - Predictive models
KW  - Robots
KW  - Transforms
KW  - Computer architecture
DO  - 10.1109/ICRA.2019.8793736
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Prospection is key to solving challenging problems in new environments, but it has not been deeply explored as applied to task planning for perception-driven robotics. We propose visual robot task planning, where we take in an input image and must generate a sequence of high-level actions and associated observations that achieve some task. In this paper, we describe a neural network architecture and associated planning algorithm that (1) learns a representation of the world that can generate prospective futures, (2) uses this generative model to simulate the result of sequences of high-level actions in a variety of environments, and (3) evaluates these actions via a variant of Monte Carlo Tree Search to find a viable solution to a particular problem. Our approach allows us to visualize intermediate motion goals and learn to plan complex activity from visual information, and used this to generate and visualize task plans on held-out examples of a block-stacking simulation.
ER  - 

TY  - CONF
TI  - Towards Blended Reactive Planning and Acting using Behavior Trees
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8839
EP  - 8845
AU  - M. Colledanchise
AU  - D. Almeida
AU  - P. Ögren
PY  - 2019
KW  - mobile robots
KW  - multi-agent systems
KW  - path planning
KW  - trees (mathematics)
KW  - planning algorithm
KW  - dynamic environment
KW  - solution blend acting
KW  - external disturbances
KW  - external agent
KW  - behavior trees
KW  - robotics scenarios
KW  - blended reactive planning
KW  - back chaining
KW  - Planning
KW  - Heuristic algorithms
KW  - Task analysis
KW  - Service robots
KW  - Industries
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794128
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we show how a planning algorithm can be used to automatically create and update a Behavior Tree (BT), controlling a robot in a dynamic environment. The planning part of the algorithm is based on the idea of back chaining. Starting from a goal condition we iteratively select actions to achieve that goal, and if those actions have unmet preconditions, they are extended with actions to achieve them in the same way. The fact that BTs are inherently modular and reactive makes the proposed solution blend acting and planning in a way that enables the robot to effectively react to external disturbances. If an external agent undoes an action the robot reexecutes it without re-planning, and if an external agent helps the robot, it skips the corresponding actions, again without replanning. We illustrate our approach in two different robotics scenarios.
ER  - 

TY  - CONF
TI  - Visual Representations for Semantic Target Driven Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8846
EP  - 8852
AU  - A. Mousavian
AU  - A. Toshev
AU  - M. Fišer
AU  - J. Košecká
AU  - A. Wahid
AU  - J. Davidson
PY  - 2019
KW  - image representation
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot vision
KW  - visual representations
KW  - semantic target driven navigation
KW  - semantic visual navigation
KW  - semantic segmentation
KW  - domain adaptation
KW  - computer vision algorithms
KW  - robot
KW  - deep network
KW  - navigation policy learning
KW  - Navigation
KW  - Visualization
KW  - Semantics
KW  - Training
KW  - Adaptation models
KW  - Robots
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793493
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - What is a good visual representation for navigation? We study this question in the context of semantic visual navigation, which is the problem of a robot finding its way through a previously unseen environment to a target object, e.g. go to the refrigerator. Instead of acquiring a metric semantic map of an environment and using planning for navigation, our approach learns navigation policies on top of representations that capture spatial layout and semantic contextual cues. We propose to use semantic segmentation and detection masks as observations obtained by state-of-the-art computer vision algorithms and use a deep network to learn the navigation policy. The availability of equitable representations in simulated environments enables joint training using real and simulated data and alleviates the need for domain adaptation or domain randomization commonly used to tackle the sim-to-real transfer of the learned policies. Both the representation and the navigation policy can be readily applied to real non-synthetic environments as demonstrated on the Active Vision Dataset [1]. Our approach successfully gets to the target in 54% of the cases in unexplored environments, compared to 46% for a non-learning based approach, and 28% for a learning-based baseline.
ER  - 

TY  - CONF
TI  - Deep Object-Centric Policies for Autonomous Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8853
EP  - 8859
AU  - D. Wang
AU  - C. Devin
AU  - Q. Cai
AU  - F. Yu
AU  - T. Darrell
PY  - 2019
KW  - computer games
KW  - convolutional neural nets
KW  - data visualisation
KW  - learning (artificial intelligence)
KW  - traffic engineering computing
KW  - object-centric models
KW  - object instances
KW  - end-to-end learning
KW  - Grand Theft Auto V simulator
KW  - object-agnostic methods
KW  - object-centric policies
KW  - autonomous driving
KW  - visuomotor skills
KW  - deep neural networks
KW  - robotics tasks
KW  - intuitive visualization
KW  - Berkeley DeepDrive Video dataset
KW  - Task analysis
KW  - Training
KW  - Taxonomy
KW  - Automobiles
KW  - Autonomous vehicles
KW  - Feature extraction
KW  - Robots
DO  - 10.1109/ICRA.2019.8794224
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While learning visuomotor skills in an end-to-end manner is appealing, deep neural networks are often uninterpretable and fail in surprising ways. For robotics tasks, such as autonomous driving, models that explicitly represent objects may be more robust to new scenes and provide intuitive visualizations. We describe a taxonomy of “object-centric” models which leverage both object instances and end-to-end learning. In the Grand Theft Auto V simulator, we show that object-centric models outperform object-agnostic methods in scenes with other vehicles and pedestrians, even with an imperfect detector. We also demonstrate that our architectures perform well on real-world environments by evaluating on the Berkeley DeepDrive Video dataset, where an object-centric model outperforms object-agnostic models in the low-data regimes.
ER  - 

TY  - CONF
TI  - Neural Autonomous Navigation with Riemannian Motion Policy
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8860
EP  - 8866
AU  - X. Meng
AU  - N. Ratliff
AU  - Y. Xiang
AU  - D. Fox
PY  - 2019
KW  - collision avoidance
KW  - geometry
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - optimal control
KW  - predictive control
KW  - robot vision
KW  - image-based autonomous navigation technique
KW  - Riemannian motion policy framework
KW  - vehicular control
KW  - deep learning
KW  - policy structure
KW  - data complexity
KW  - modeling error
KW  - end-to-end learning
KW  - neural autonomous navigation
KW  - local geometry
KW  - RMP representation
KW  - indoor obstacle avoidance
KW  - Gibson environment
KW  - optimal control commands
KW  - visual images
KW  - control point RMPs
KW  - deep neural network
KW  - Acceleration
KW  - Geometry
KW  - Autonomous robots
KW  - Measurement
KW  - Neural networks
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8794223
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - End-to-end learning for autonomous navigation has received substantial attention recently as a promising method for reducing modeling error. However, its data complexity, especially around generalization to unseen environments, is high. We introduce a novel image-based autonomous navigation technique that leverages in policy structure using the Riemannian Motion Policy (RMP) framework for deep learning of vehicular control. We design a deep neural network to predict control point RMPs of the vehicle from visual images, from which the optimal control commands can be computed analytically. We show that our network trained in the Gibson environment can be used for indoor obstacle avoidance and navigation on a real RC car, and our RMP representation generalizes better to unseen environments than predicting local geometry or predicting control commands directly.
ER  - 

TY  - CONF
TI  - Two-Stage Transfer Learning for Heterogeneous Robot Detection and 3D Joint Position Estimation in a 2D Camera Image Using CNN
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8883
EP  - 8889
AU  - J. Mišeikis
AU  - I. Brijačak
AU  - S. Yahyanejad
AU  - K. Glette
AU  - O. J. Elle
AU  - J. Torresen
PY  - 2019
KW  - calibration
KW  - cameras
KW  - collision avoidance
KW  - convolutional neural nets
KW  - dexterous manipulators
KW  - feature extraction
KW  - image classification
KW  - image colour analysis
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - multi-robot systems
KW  - robot vision
KW  - two-stage transfer learning approach
KW  - multiobjective convolutional neural network
KW  - heterogeneous robot arms
KW  - eye-to-hand calibration
KW  - universal robots
KW  - two-stage transfer learning
KW  - 2D colour image
KW  - collision avoidance algorithms
KW  - fixed robot-camera setups
KW  - collision detection
KW  - factory floors
KW  - collaborative robots
KW  - 2D camera image
KW  - 3D joint position estimation
KW  - heterogeneous robot detection
KW  - multiobjective CNN
KW  - data collection approach
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Cameras
KW  - Robot vision systems
KW  - Calibration
DO  - 10.1109/ICRA.2019.8794077
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Collaborative robots are becoming more common on factory floors as well as regular environments, however, their safety still is not a fully solved issue. Collision detection does not always perform as expected and collision avoidance is still an active research area. Collision avoidance works well for fixed robot-camera setups, however, if they are shifted around, Eye-to-Hand calibration becomes invalid making it difficult to accurately run many of the existing collision avoidance algorithms. We approach the problem by presenting a stand-alone system capable of detecting the robot and estimating its position, including individual joints, by using a simple 2D colour image as an input, where no Eye-to-Hand calibration is needed. As an extension of previous work, a two-stage transfer learning approach is used to re-train a multi-objective convolutional neural network (CNN) to allow it to be used with heterogeneous robot arms. Our method is capable of detecting the robot in real-time and new robot types can be added by having significantly smaller training datasets compared to the requirements of a fully trained network. We present data collection approach, the structure of the multi-objective CNN, the two-stage transfer learning training and test results by using real robots from Universal Robots, Kuka, and Franka Emika. Eventually, we analyse possible application areas of our method together with the possible improvements.
ER  - 

TY  - CONF
TI  - 3D Control of Rotating Millimeter-Scale Swimmers Through Obstacles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8890
EP  - 8896
AU  - J. Leclerc
AU  - H. Zhao
AU  - A. T. Becker
PY  - 2019
KW  - biomechanics
KW  - biomedical equipment
KW  - blood
KW  - blood vessels
KW  - medical control systems
KW  - propulsion
KW  - swimmer designs
KW  - rotating millimeter-scale swimmers
KW  - aorta
KW  - blood clot
KW  - rotational movement
KW  - high speed 3D navigation
KW  - Arteries
KW  - Electromagnets
KW  - Force
KW  - Trajectory
KW  - Manipulators
KW  - Velocity control
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794045
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study investigates the high speed 3D navigation of rotating millimeter-scale swimmers. The swimmers have a spiral-shaped surface to ensure propulsion. The rotational movement is used for propulsion and, in future work, could provide the power needed to remove blood clots. For instance, an abrasive tip could be used to progressively grind a blood clot. An algorithm to perform 3D control of rotating millimeter-scale swimmers was implemented and tested experimentally. The swimmers can follow a trajectory and can navigate without touching the walls inside a tube having a diameter of 15 mm. This diameter is smaller than the average diameter of the distal descending aorta, which is the smallest section of the aorta. Several swimmers designs were built and tested. The maximum velocity recorded for our best swimmer was 103.6 mm/s with a rotational speed of 477.5 rotations per second.
ER  - 

TY  - CONF
TI  - Automatic Optical Coherence Tomography Imaging of Stationary and Moving Eyes with a Robotically-Aligned Scanner
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8897
EP  - 8903
AU  - M. Draelos
AU  - P. Ortiz
AU  - R. Qian
AU  - B. Keller
AU  - K. Hauser
AU  - A. Kuo
AU  - J. Izatt
PY  - 2019
KW  - biomedical optical imaging
KW  - cameras
KW  - eye
KW  - medical image processing
KW  - medical robotics
KW  - optical tomography
KW  - pupil tracking accuracy
KW  - tracking bandwidth
KW  - optical coherence tomography imaging
KW  - sub-millimeter eye tracking accuracy
KW  - tracking eyes
KW  - stationary eyes
KW  - commercial robot arm
KW  - fast axial tracking
KW  - reference arm adjustment
KW  - fine alignment
KW  - stereo pupil cameras
KW  - coarse pupil cameras
KW  - fixed-base RGB-D cameras
KW  - automatic eye imaging
KW  - OCT scanner capable
KW  - ophthalmology offices
KW  - OCT screening
KW  - unconscious patients
KW  - OCT diagnostics
KW  - ophthalmic photographers
KW  - chinrest stabilization
KW  - tabletop instruments
KW  - clinical ophthalmic OCT systems
KW  - robotically-aligned scanner
KW  - size 12.0 mum
KW  - time 83.2 ms
KW  - frequency 9.7 Hz
KW  - Cameras
KW  - Tracking
KW  - Robot vision systems
KW  - Robot kinematics
KW  - Face
KW  - Medical robotics
KW  - optical coherence tomography
KW  - image stabilization
DO  - 10.1109/ICRA.2019.8793524
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Optical coherence tomography (OCT) has found great success in ophthalmology where it plays a key role in screening and diagnostics. Clinical ophthalmic OCT systems are typically deployed as tabletop instruments that require chinrest stabilization and trained ophthalmic photographers to operate. These requirements preclude OCT diagnostics in bedbound or unconscious patients who cannot use a chinrest, and restrict OCT screening to ophthalmology offices. We present a robotically-aligned OCT scanner capable of automatic eye imaging without chinrests. The scanner features eye tracking from fixed-base RGB-D cameras for coarse and stereo pupil cameras for fine alignment, as well as galvanometer aiming for fast lateral tracking, reference arm adjustment for fast axial tracking, and a commercial robot arm for slow lateral and axial tracking. We demonstrate the system's performance autonomously aligning with stationary eyes, pursuing moving eyes, and tracking eyes undergoing physiologic motion. The system demonstrates sub-millimeter eye tracking accuracy, 12 μm lateral pupil tracking accuracy, 83.2 ms stabilization time following step disturbance, and 9.7 Hz tracking bandwidth.
ER  - 

TY  - CONF
TI  - Online Multilayered Motion Planning with Dynamic Constraints for Autonomous Underwater Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8936
EP  - 8942
AU  - E. Vidal
AU  - M. Moll
AU  - N. Palomeras
AU  - J. D. Hernández
AU  - M. Carreras
AU  - L. E. Kavraki
PY  - 2019
KW  - autonomous underwater vehicles
KW  - collision avoidance
KW  - mobile robots
KW  - trajectory control
KW  - vehicle dynamics
KW  - underwater robot
KW  - online multilayered motion planning
KW  - autonomous underwater vehicles
KW  - loosely coupled multilayered planning design
KW  - motion planner
KW  - hydro-dynamic forces
KW  - trajectory planning
KW  - robots onboard computer
KW  - AUVs
KW  - inevitable collision states
KW  - Planning
KW  - Trajectory
KW  - Lead
KW  - Vehicle dynamics
KW  - Robots
KW  - Dynamics
KW  - Unmanned underwater vehicles
DO  - 10.1109/ICRA.2019.8794009
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Underwater robots are subject to complex hydro-dynamic forces. These forces define how the vehicle moves, so it is important to consider them when planning trajectories. However, performing motion planning considering the dynamics on the robot's onboard computer is challenging due to the limited computational resources available. In this paper an efficient motion planning framework for autonomous underwater vehicles (AUVs) is presented. By introducing a loosely coupled multilayered planning design, our framework is able to generate dynamically feasible trajectories while keeping the planning time low enough for online planning. First, a fast path planner operating in a lower-dimensional projected space computes a lead path from the start to the goal configuration. Then, the lead path is used to bias the sampling of a second motion planner, which takes into account all the dynamic constraints. Furthermore, we propose a strategy for online planning that saves computational resources by generating the final trajectory only up to a finite horizon. By using the finite horizon strategy together with the multilayered approach, the sampling of the second planner focuses on regions where good quality solutions are more likely to be found, significantly reducing the planning time. To provide strong safety guarantees our framework also incorporates the conservative approximations of inevitable collision states (icss). finally, we present simulations and experiments using a real underwater robot to demonstrate the capabilities of our framework.
ER  - 

TY  - CONF
TI  - Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8943
EP  - 8950
AU  - M. A. Lee
AU  - Y. Zhu
AU  - K. Srinivasan
AU  - P. Shah
AU  - S. Savarese
AU  - L. Fei-Fei
AU  - A. Garg
AU  - J. Bohg
PY  - 2019
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - haptic feedback
KW  - visual feedback
KW  - robot controller
KW  - deep reinforcement learning
KW  - high-dimensional inputs
KW  - sample complexity
KW  - multimodal representation
KW  - sensory inputs
KW  - policy learning
KW  - peg insertion task
KW  - self-supervised learning
KW  - multimodal representations
KW  - contact-rich manipulation tasks
KW  - Task analysis
KW  - Robot sensing systems
KW  - Haptic interfaces
KW  - Visualization
KW  - Geometry
KW  - Reinforcement learning
DO  - 10.1109/ICRA.2019.8793485
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.
ER  - 

TY  - CONF
TI  - Deep Visuo-Tactile Learning: Estimation of Tactile Properties from Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8951
EP  - 8957
AU  - K. Takahashi
AU  - J. Tan
PY  - 2019
KW  - control engineering computing
KW  - end effectors
KW  - feature extraction
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - robot vision
KW  - tactile sensors
KW  - visual perception
KW  - deep visuo-tactile learning
KW  - tactile sensor data
KW  - Webcam
KW  - tactile properties
KW  - visual perception
KW  - encoder-decoder network
KW  - latent variables
KW  - tactile features
KW  - visual features
KW  - RGB images
KW  - uSkin tactile sensor
KW  - end-effector
KW  - feature space
KW  - Sawyer robot
KW  - Tactile sensors
KW  - Training
KW  - Time series analysis
KW  - Decoding
DO  - 10.1109/ICRA.2019.8794285
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Estimation of tactile properties from vision, such as slipperiness or roughness, is important to effectively interact with the environment. These tactile properties help us decide which actions we should choose and how to perform them. E.g., we can drive slower if we see that we have bad traction or grasp tighter if an item looks slippery. We believe that this ability also helps robots to enhance their understanding of the environment, and thus enables them to tailor their actions to the situation at hand. We therefore propose a model to estimate the degree of tactile properties from visual perception alone (e.g., the level of slipperiness or roughness). Our method extends a encoder-decoder network, in which the latent variables are visual and tactile features. In contrast to previous works, our method does not require manual labeling, but only RGB images and the corresponding tactile sensor data. All our data is collected with a webcam and uSkin tactile sensor mounted on the end-effector of a Sawyer robot, which strokes the surfaces of 25 different materials. We show that our model generalizes to materials not included in the training data by evaluating the feature space, indicating that it has learned to associate important tactile properties with images.
ER  - 

TY  - CONF
TI  - Variational End-to-End Navigation and Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8958
EP  - 8964
AU  - A. Amini
AU  - G. Rosman
AU  - S. Karaman
AU  - D. Rus
PY  - 2019
KW  - cameras
KW  - Global Positioning System
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - probability
KW  - variational techniques
KW  - point-topoint navigation algorithms
KW  - full-scale autonomous vehicle
KW  - localization algorithm
KW  - variational end-to-end navigation
KW  - deep learning
KW  - autonomous vehicle control
KW  - raw sensory data
KW  - navigation instruction
KW  - end-to-end driving networks
KW  - point-to-point navigation
KW  - probabilistic localization
KW  - noisy GPS data
KW  - raw camera data
KW  - higher level roadmaps
KW  - probability distribution
KW  - deterministic control command
KW  - rough localization
KW  - real-world driving data
KW  - variational network
KW  - Navigation
KW  - Roads
KW  - Cameras
KW  - Robot sensing systems
KW  - Visualization
KW  - Partitioning algorithms
DO  - 10.1109/ICRA.2019.8793579
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deep learning has revolutionized the ability to learn “end-to-end” autonomous vehicle control directly from raw sensory data. While there have been recent extensions to handle forms of navigation instruction, these works are unable to capture the full distribution of possible actions that could be taken and to reason about localization of the robot within the environment. In this paper, we extend end-to-end driving networks with the ability to perform point-to-point navigation as well as probabilistic localization using only noisy GPS data. We define a novel variational network capable of learning from raw camera data of the environment as well as higher level roadmaps to predict (1) a full probability distribution over the possible control commands; and (2) a deterministic control command capable of navigating on the route specified within the map. Additionally, we formulate how our model can be used to localize the robot according to correspondences between the map and the observed visual road topology, inspired by the rough localization that human drivers can perform. We test our algorithms on real-world driving data that the vehicle has never driven through before, and integrate our point-topoint navigation algorithms onboard a full-scale autonomous vehicle for real-time performance. Our localization algorithm is also evaluated over a new set of roads and intersections to demonstrates rough pose localization even in situations without any GPS prior.
ER  - 

TY  - CONF
TI  - Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8973
EP  - 8979
AU  - Y. Chebotar
AU  - A. Handa
AU  - V. Makoviychuk
AU  - M. Macklin
AU  - J. Issac
AU  - N. Ratliff
AU  - D. Fox
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - real world experience
KW  - simulation parameter distribution
KW  - policy training
KW  - policy transfer
KW  - policy behavior
KW  - sim-to-real loop
KW  - simulation randomization
KW  - swing-peg-in-hole
KW  - cabinet drawer opening
KW  - Adaptation models
KW  - Training
KW  - Data models
KW  - Robots
KW  - Computational modeling
KW  - Trajectory
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793789
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of transferring policies to the real world by training on a distribution of simulated scenarios. Rather than manually tuning the randomization of simulations, we adapt the simulation parameter distribution using a few real world roll-outs interleaved with policy training. In doing so, we are able to change the distribution of simulations to improve the policy transfer by matching the policy behavior in simulation and the real world. We show that policies trained with our method are able to reliably transfer to different robots in two real world tasks: swing-peg-in-hole and opening a cabinet drawer. The video of our experiments can be found at https://sites.google.com/view/simopt.
ER  - 

TY  - CONF
TI  - Robotic Orientation Control of Deformable Cells
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8980
EP  - 8985
AU  - C. Dai
AU  - Z. Zhang
AU  - Y. Lu
AU  - G. Shan
AU  - X. Wang
AU  - Q. Zhao
AU  - Y. Sun
PY  - 2019
KW  - biomechanics
KW  - cellular biophysics
KW  - deformation
KW  - manipulators
KW  - medical robotics
KW  - mobile robots
KW  - neurocontrollers
KW  - path planning
KW  - position control
KW  - robotic orientation control
KW  - deformable cells
KW  - robotic manipulation
KW  - deformable objects
KW  - rigid objects
KW  - robotics
KW  - deformable synthetic objects
KW  - rubber balls
KW  - clothes
KW  - biological cells
KW  - manual cell rotation control
KW  - robotic approach
KW  - mathematical modeling
KW  - path planning
KW  - minimal cell deformation
KW  - cell damage
KW  - force model
KW  - minimal force
KW  - contact mechanics model
KW  - manipulation path
KW  - compensation controller
KW  - oocyte orientation control
KW  - maximum oocyte deformation
KW  - Position control
KW  - Strain
KW  - Force
KW  - Robots
KW  - Shape
KW  - Path planning
KW  - Standards
DO  - 10.1109/ICRA.2019.8793986
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic manipulation of deformable objects (vs. rigid objects) has been a classic topic in robotics. Compared to deformable synthetic objects such as rubber balls and clothes, biological cells are highly deformable and more prone to damage. This paper presents robotic manipulation of deformable cells for orientation control (both out-of-plane and in-plane), which is required in both clinical (e.g., in vitro fertilization) and biomedical (e.g., clone) applications. Compared to manual cell rotation control based on empirical experience, the robotic approach, based on mathematical modeling and path planning, effectively rotates a cell while consistently maintaining minimal cell deformation to avoid cell damage. A force model is established to determine the minimal force applied by the micropipette to rotate a spherical or more generally, an ellipsoidal mouse oocyte. The force information is translated into indentation through a contact mechanics model, and the manipulation path of the micropipette is formed by connecting the indentation positions on the oocyte. A compensation controller is designed to compensate for the variations of mechanical properties across cells. The polar body of an oocyte is detected by deep neural networks with robustness to shape and size differences. Experimental results demonstrate that the system achieved an accuracy of 97.6% in polar body detection and an accuracy of 0.7° in oocyte orientation control with maximum oocyte deformation of 2.69 μm.
ER  - 

TY  - CONF
TI  - Drift-free Roll and Pitch Estimation for High-acceleration Hopping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8986
EP  - 8992
AU  - J. K. Yim
AU  - E. K. Wang
AU  - R. S. Fearing
PY  - 2019
KW  - acceleration control
KW  - attitude control
KW  - gyroscopes
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - stability
KW  - velocity control
KW  - monopedal jumping robots
KW  - onboard rate gyroscopes
KW  - encoders
KW  - attitude estimate disturbances
KW  - onboard velocity estimation
KW  - extreme stance accelerations
KW  - high-acceleration hopping
KW  - untethered robot
KW  - drift-free roll and pitch estimation
KW  - drift-free roll and pitch attitude estimation scheme
KW  - fully autonomous stable hopping control
KW  - rectangular path
KW  - onboard dead-reckoning
KW  - human wireless joystick direction
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Attitude control
KW  - Estimation
KW  - Gyroscopes
DO  - 10.1109/ICRA.2019.8793259
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We develop a drift-free roll and pitch attitude estimation scheme for monopedal jumping robots. The estimator uses only onboard rate gyroscopes and encoders and does not rely on external sensing or processing. It is capable of recovering from attitude estimate disturbances and, together with onboard velocity estimation, enables fully autonomous stable hopping control. The estimator performs well on a small untethered robot capable of large jumps and extreme stance accelerations. We demonstrate that the robot can follow a rectangular path using onboard dead-reckoning with less than 2 meters of drift over 200 seconds and 300 jumps covering 60 m. We also demonstrate that the robot can operate untethered outdoors under human wireless joystick direction.
ER  - 

TY  - CONF
TI  - Efficient Symbolic Reactive Synthesis for Finite-Horizon Tasks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 8993
EP  - 8999
AU  - K. He
AU  - A. M. Wells
AU  - L. E. Kavraki
AU  - M. Y. Vardi
PY  - 2019
KW  - binary decision diagrams
KW  - mobile robots
KW  - pick-and-place tasks
KW  - binary decision diagram
KW  - UR5 robot
KW  - efficient symbolic reactive synthesis
KW  - compositional approach
KW  - explicit state approach
KW  - finite-horizon tasks
KW  - Task analysis
KW  - Robots
KW  - Planning
KW  - Games
KW  - Robotic assembly
KW  - Semantics
KW  - Binary decision diagrams
DO  - 10.1109/ICRA.2019.8794170
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When humans and robots perform complex tasks together, the robot must have a strategy to choose its actions based on observed human behavior. One well-studied approach for finding such strategies is reactive synthesis. Existing approaches for finite-horizon tasks have used an explicit state approach, which incurs high runtime. In this work, we present a compositional approach to perform synthesis for finite-horizon tasks based on binary decision diagrams. We show that for pick-and-place tasks, the compositional approach achieves orders-of-magnitude speed-ups compared to previous approaches. We demonstrate the synthesized strategy on a UR5 robot.
ER  - 

TY  - CONF
TI  - Combined Task and Motion Planning under Partial Observability: An Optimization-Based Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9000
EP  - 9006
AU  - C. Phiquepal
AU  - M. Toussaint
PY  - 2019
KW  - computational complexity
KW  - decision trees
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - partial observability
KW  - optimization-based approach
KW  - compute optimal plans
KW  - symbolic decision tree
KW  - path tree
KW  - optimal motion
KW  - independent optimizations
KW  - combined task and motion planning
KW  - optimization-based TAMP methods
KW  - Trajectory
KW  - Planning
KW  - Optimization
KW  - Observability
KW  - Task analysis
KW  - Robots
KW  - Decision trees
DO  - 10.1109/ICRA.2019.8793260
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel approach to Combined Task and Motion Planning (TAMP) under partial observability. Previous optimization-based TAMP methods [1][2] compute optimal plans and paths assuming full observability. However, partial observability requires the solution to be a policy that reacts to the observations that the agent receives. We consider a formulation where observations introduce additional branching in the symbolic decision tree. The solution is now given by a reactive policy on the symbolic level together with a path tree that describes the branchings of optimal motion depending on the observations. Our method works in two stages: First, the symbolic policy is optimized using approximate path costs estimated from independent optimizations of trajectory pieces. Second, we fix the best symbolic policy and optimize a joint trajectory tree. We test our approach on object manipulation and autonomous driving examples. We also compare the algorithm's performance to a state-of-the-art TAMP planner in fully observable cases.
ER  - 

TY  - CONF
TI  - Towards Robust Product Packing with a Minimalistic End-Effector
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9007
EP  - 9013
AU  - R. Shome
AU  - W. N. Tang
AU  - C. Song
AU  - C. Mitash
AU  - H. Kourtev
AU  - J. Yu
AU  - A. Boularias
AU  - K. E. Bekris
PY  - 2019
KW  - design engineering
KW  - end effectors
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - warehouse automation
KW  - object detection algorithms
KW  - manipulation primitives
KW  - cubic objects
KW  - vacuum-based end-effector
KW  - single robot arm
KW  - RGB-D data
KW  - failure conditions
KW  - robust pipeline
KW  - unstructured piles
KW  - packing tasks
KW  - order fulfillment
KW  - warehouse automation
KW  - hardware designs
KW  - sensor technologies
KW  - minimalistic end-effector
KW  - towards robust product packing
KW  - End effectors
KW  - Task analysis
KW  - Robot sensing systems
KW  - Pipelines
KW  - Three-dimensional displays
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793966
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Advances in sensor technologies, object detection algorithms, planning frameworks and hardware designs have motivated the deployment of robots in warehouse automation. A variety of such applications, like order fulfillment or packing tasks, require picking objects from unstructured piles and carefully arranging them in bins or containers. Desirable solutions need to be low-cost, easily deployable and controllable, making minimalistic hardware choices desirable. The challenge in designing an effective solution to this problem relates to appropriately integrating multiple components, so as to achieve a robust pipeline that minimizes failure conditions. The current work proposes a complete pipeline for solving such packing tasks, given access only to RGB-D data and a single robot arm with a vacuum-based end-effector, which is also used as a pushing finger. To achieve the desired level of robustness, three key manipulation primitives are identified, which take advantage of the environment and simple operations to successfully pack multiple cubic objects. The overall approach is demonstrated to be robust to execution and perception errors. The impact of each manipulation primitive is evaluated by considering different versions of the proposed pipeline, which incrementally introduce reasoning about object poses and corrective manipulation actions.
ER  - 

TY  - CONF
TI  - Gesture Recognition Via Flexible Capacitive Touch Electrodes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9028
EP  - 9034
AU  - L. J. Dankovich
AU  - S. Bergbreiter
PY  - 2019
KW  - biomechanics
KW  - biomedical electrodes
KW  - biomedical measurement
KW  - Bluetooth
KW  - capacitive sensors
KW  - gesture recognition
KW  - medical computing
KW  - microcontrollers
KW  - random forests
KW  - skin
KW  - tactile sensors
KW  - gesture recognition accuracy
KW  - basic finger
KW  - flexible capacitive touch electrodes
KW  - classification algorithms
KW  - random forest algorithm
KW  - wrist motions
KW  - Cutkosky Grasp Taxonomy
KW  - bluetooth transceiver
KW  - microcontroller
KW  - elbow
KW  - wireless wearable device
KW  - Electrodes
KW  - Muscles
KW  - Capacitance
KW  - Gesture recognition
KW  - Sensors
KW  - Wrist
KW  - Skin
DO  - 10.1109/ICRA.2019.8794202
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A novel wearable device for gesture recognition was developed and tested on five subjects. The low-cost, wireless wearable device was engineered with a set of seven flexible capacitive touch electrodes sewn into an armband to be worn on the forearm between the wrist and elbow. These capacitive touch electrodes were interfaced with a microcontroller and bluetooth transceiver for measurement and transmission. As different gestures are made, flexing muscles beneath the skin affect the capacitance measured on these seven electrodes. A set of 32 gestures were tested including the 16 grasps in the Cutkosky Grasp Taxonomy and 16 basic finger and wrist motions. Several classification algorithms were tested on this data. Using a Random Forest (RF) algorithm to classify the training data, an average gesture recognition accuracy of 95.6 ± 0.06% was achieved across all five subjects individually.
ER  - 

TY  - CONF
TI  - Robust Learning of Tactile Force Estimation through Robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9035
EP  - 9042
AU  - B. Sundaralingam
AU  - A. S. Lambert
AU  - A. Handa
AU  - B. Boots
AU  - T. Hermans
AU  - S. Birchfield
AU  - N. Ratliff
AU  - D. Fox
PY  - 2019
KW  - control engineering computing
KW  - force feedback
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - robots
KW  - tactile sensors
KW  - learned force model
KW  - robust learning
KW  - tactile force estimation
KW  - robot interaction
KW  - analytic models
KW  - robust model
KW  - SynTouch BioTac sensor
KW  - neural networks
KW  - voxelized input feature layer
KW  - spatial signals
KW  - sensor surface
KW  - robust tactile force model
KW  - force torque sensor
KW  - FT sensor
KW  - force inference
KW  - planar pushing task
KW  - force direction
KW  - force estimation
KW  - tactile sensor signals
KW  - force feedback grasp controller
KW  - Force
KW  - Robot sensing systems
KW  - Biological system modeling
KW  - Task analysis
KW  - Biosensors
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793502
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Current methods for estimating force from tactile sensor signals are either inaccurate analytic models or task-specific learned models. In this paper, we explore learning a robust model that maps tactile sensor signals to force. We specifically explore learning a mapping for the SynTouch BioTac sensor via neural networks. We propose a voxelized input feature layer for spatial signals and leverage information about the sensor surface to regularize the loss function. To learn a robust tactile force model that transfers across tasks, we generate ground truth data from three different sources: (1) the BioTac rigidly mounted to a force torque (FT) sensor, (2) a robot interacting with a ball rigidly attached to the same FT sensor, and (3) through force inference on a planar pushing task by formalizing the mechanics as a system of particles and optimizing over the object motion. A total of 140k samples were collected from the three sources. We achieve a median angular accuracy of 3.5 degrees in predicting force direction (66% improvement over the current state of the art) and a median magnitude accuracy of 0.06 N (93% improvement) on a test dataset. Additionally, we evaluate the learned force model in a force feedback grasp controller performing object lifting and gentle placement. Our results can be found on https: //sites.google.com/view/tactile-force.
ER  - 

TY  - CONF
TI  - Soft Robotic Glove with Integrated Sensing for Intuitive Grasping Assistance Post Spinal Cord Injury
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9059
EP  - 9065
AU  - Y. M. Zhou
AU  - D. Wagner
AU  - K. Nuckols
AU  - R. Heimgartner
AU  - C. Correia
AU  - M. Clarke
AU  - D. Orzel
AU  - C. O’Neill
AU  - R. Solinsky
AU  - S. Paganoni
AU  - C. J. Walsh
PY  - 2019
KW  - biomechanics
KW  - capacitive sensors
KW  - data gloves
KW  - elastomers
KW  - handicapped aids
KW  - injuries
KW  - neurophysiology
KW  - patient rehabilitation
KW  - soft robotic glove
KW  - integrated sensing
KW  - intuitive grasping assistance post spinal cord injury
KW  - multiarticular textile actuators
KW  - custom soft sensors
KW  - intuitive state machine intent detection controller
KW  - pressurized actuators
KW  - natural human fingers
KW  - textile-elastomer capacitive sensors
KW  - finger flexion
KW  - intuitive user control
KW  - state machine controller
KW  - integrated sensors
KW  - hand-object interactions
KW  - injury levels
KW  - inadvertent grasp triggers
KW  - Actuators
KW  - Force
KW  - Sensor phenomena and characterization
KW  - Textiles
KW  - Capacitive sensors
KW  - Strain
DO  - 10.1109/ICRA.2019.8794367
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a fully-integrated soft robotic glove with multi-articular textile actuators, custom soft sensors, and an intuitive state machine intent detection controller. We demonstrate that the pressurized actuators can generate motion and force comparable to natural human fingers through bench-top testing. We apply textile-elastomer capacitive sensors to the glove to track finger flexion via strain and detect contact with objects via force. Intuitive user control is achieved via a state machine controller based on signals from the integrated sensors to detect relative changes in hand-object interactions. Results from an initial evaluation with 3 participants with spinal cord injury (SCI), of varied injury levels and years since injury, wearing and controlling the glove show an average of 87% improvement in grasping force, and improvements in functional assessments for participants with recent injuries. A significant variation in response suggests further investigation is required to understand the adaptation needed across different injury levels and durations since injury. Additionally, we evaluate the controller and find an average of 3 seconds from user initiations to completed grasps, and 10% inadvertent grasp triggers and no false releases when objects are held.
ER  - 

TY  - CONF
TI  - Shape Sensing of Variable Stiffness Soft Robots using Electrical Impedance Tomography
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9066
EP  - 9072
AU  - J. Avery
AU  - M. Runciman
AU  - A. Darzi
AU  - G. P. Mylonas
PY  - 2019
KW  - biological tissues
KW  - computerised tomography
KW  - electric impedance imaging
KW  - electric impedance measurement
KW  - image reconstruction
KW  - medical robotics
KW  - pneumatic actuators
KW  - surgery
KW  - tomography
KW  - reduced contact trauma
KW  - soft tissues
KW  - tortuous paths
KW  - minimally invasive surgery
KW  - intraoperative shape sensing
KW  - proprioceptive soft actuator
KW  - self-sensing
KW  - electrically conductive working fluid
KW  - tomographic reconstructions
KW  - two-degree-of-freedom designs
KW  - hydraulic hinged actuator
KW  - pneumatic finger actuator
KW  - EIT images
KW  - FDM-EIT
KW  - shape sensor
KW  - variable stiffness soft robots
KW  - electrical impedance tomography
KW  - deformability
KW  - electrical impedance measurements
KW  - frequency division multiplexed EIT system
KW  - temporal resolution
KW  - Electrodes
KW  - Tomography
KW  - Actuators
KW  - Welding
KW  - Shape
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793862
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robotic systems offer benefits over traditional rigid systems through reduced contact trauma with soft tissues and by enabling access through tortuous paths in minimally invasive surgery. However, the inherent deformability of soft robots places both a greater onus on accurate modelling of their shape, and greater challenges in realising intraoperative shape sensing. Herein we present a proprioceptive (self-sensing) soft actuator, with an electrically conductive working fluid. Electrical impedance measurements from up to six electrodes enabled tomographic reconstructions using Electrical Impedance Tomography (EIT). A new Frequency Division Multiplexed (FDM) EIT system was developed capable of measurements of 66 dB SNR with 20 ms temporal resolution. The concept was examined in two two-degree-of-freedom designs: a hydraulic hinged actuator and a pneumatic finger actuator with hydraulic beams. Both cases demonstrated that impedance measurements could be used to infer shape changes, and EIT images reconstructed during actuation showed distinct patterns with respect to each degree of freedom (DOF). Whilst there was some mechanical hysteresis observed, the repeatability of the measurements and resultant images was high. The results show the potential of FDM-EIT as a low-cost, low profile shape sensor in soft robots.
ER  - 

TY  - CONF
TI  - Adaptive Control of Sclera Force and Insertion Depth for Safe Robot-Assisted Retinal Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9073
EP  - 9079
AU  - A. Ebrahimi
AU  - N. Patel
AU  - C. He
AU  - P. Gehlbach
AU  - M. Kobilarov
AU  - I. Iordachita
PY  - 2019
KW  - adaptive control
KW  - biological tissues
KW  - eye
KW  - force feedback
KW  - force sensors
KW  - medical robotics
KW  - robot vision
KW  - surgery
KW  - 1-dimensional adaptive control method
KW  - 3-dimensional control
KW  - sclera force components
KW  - tool insertion depth
KW  - velocity-controlled Johns Hopkins Steady-Hand Eye Robot
KW  - safe robot-assisted retinal surgery
KW  - surgical tools
KW  - force feedback
KW  - tool-to-eye interactions
KW  - robotic light pipe holding
KW  - Robot kinematics
KW  - Surgery
KW  - Force
KW  - Tools
KW  - Adaptive control
KW  - Retina
DO  - 10.1109/ICRA.2019.8793658
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - One of the significant challenges of moving from manual to robot-assisted retinal surgery is the loss of perception of forces applied to the sclera (sclera forces) by the surgical tools. This damping of force feedback is primarily due to the stiffness and inertia of the robot. The diminished perception of tool-to-eye interactions might put the eye tissue at high risk of injury due to excessive sclera forces or extreme insertion of the tool into the eye. In the present study therefore a 1-dimensional adaptive control method is customized for 3-dimensional control of sclera force components and tool insertion depth and then implemented on the velocity-controlled Johns Hopkins Steady-Hand Eye Robot. The control method enables the robot to perform autonomous motions to make the sclera force and/or insertion depth of the tool tip to follow pre-defined desired and safe trajectories when they exceed safe bounds. A robotic light pipe holding application in retinal surgery is also investigated using the adaptive control method. The implementation results indicate that the adaptive control is able to achieve the imposed safety margins and prevent sclera forces and insertion depth from exceeding safe boundaries.
ER  - 

TY  - CONF
TI  - Distributed Multi-Robot Formation Splitting and Merging in Dynamic Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9080
EP  - 9086
AU  - H. Zhu
AU  - J. Juhl
AU  - L. Ferranti
AU  - J. Alonso-Mora
PY  - 2019
KW  - collision avoidance
KW  - distributed control
KW  - graph theory
KW  - helicopters
KW  - mobile robots
KW  - multi-robot systems
KW  - distributed consensus
KW  - obstacle-free convex regions
KW  - distributed multirobot formation splitting
KW  - distributed multirobot formation merging
KW  - moving obstacles
KW  - static obstacles
KW  - intersection graph
KW  - quadrotors
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Merging
KW  - Navigation
KW  - Partitioning algorithms
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8793765
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a distributed method for splitting and merging of multi-robot formations in dynamic environments with static and moving obstacles. Splitting and merging actions rely on distributed consensus and can be performed to avoid obstacles. Our method accounts for the limited communication range and visibility radius of the robots and relies on the communication of obstacle-free convex regions and the computation of an intersection graph. In addition, our method is able to detect and recover from (permanent and temporary) communication and motion faults. Finally, we demonstrate the applicability and scalability of the proposed method in simulations with up to sixteen quadrotors and real-world experiments with a team of four quadrotors.
ER  - 

TY  - CONF
TI  - Eagle Shoal: A new designed modular tactile sensing dexterous hand for domestic service robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9087
EP  - 9093
AU  - T. Wang
AU  - Z. Geng
AU  - B. Kang
AU  - X. Luo
PY  - 2019
KW  - control engineering computing
KW  - dexterous manipulators
KW  - feature extraction
KW  - object detection
KW  - service robots
KW  - tactile sensors
KW  - domestic service robots
KW  - control boards
KW  - tactile sensor unit
KW  - hand features
KW  - visual data
KW  - tactile data
KW  - Eagle Shoal
KW  - modular tactile sensing dexterous hand
KW  - fully-actuated hand
KW  - embedded tactile sensors
KW  - 2 degrees of freedom
KW  - DOFs
KW  - perceive continuous vibration data
KW  - grasp ability
KW  - consumer market
KW  - robotic manipulation research
KW  - Force
KW  - Tactile sensors
KW  - Piezoelectric transducers
KW  - Sensor arrays
DO  - 10.1109/ICRA.2019.8793842
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces a new designed modular tactile sensing dexterous hand for domestic service robots. This fully-actuated hand consists of 1 palm and 3 fingers, with embedded tactile sensors, motors and control boards. The palm and each finger have 2 degrees of freedom (DOFs). The modular design makes it easy to attach and detach the hand, even by inexperienced users. The tactile sensor unit with new structure can help to decrease sensor number and keep a good sensing ability. A series of experiments to test the sensor unit and evaluated the hand performance with an object set was performed in this paper. The results show that the sensor unit can provide precise sensing result and perceive continuous vibration data, and the hand has excellent grasp ability. In addition to its good performance, the hand features a cost of $500 USD with a scale of one hundred sets. This hand is affordable for researchers and for domestic service robots in the consumer market. In future research, this hand will be used to promote the robotic manipulation research based on visual and tactile data.
ER  - 

TY  - CONF
TI  - Learning Scene Geometry for Visual Localization in Challenging Conditions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9094
EP  - 9100
AU  - N. Piasco
AU  - D. Sidibé
AU  - V. Gouet-Brunet
AU  - C. Demonceaux
PY  - 2019
KW  - feature extraction
KW  - image colour analysis
KW  - image retrieval
KW  - learning (artificial intelligence)
KW  - object detection
KW  - robot vision
KW  - daytime images
KW  - learning scene geometry
KW  - visual localization
KW  - outdoor large scale image
KW  - cross-season
KW  - learned global image descriptor
KW  - scene geometry information
KW  - depth map
KW  - query image
KW  - localization accuracy
KW  - cross-weather
KW  - long-term localization scenario
KW  - night images
KW  - winter localization sequence
KW  - summer localization sequence
KW  - Training
KW  - Decoding
KW  - Feature extraction
KW  - Robots
KW  - Image reconstruction
KW  - Geometry
KW  - Visualization
DO  - 10.1109/ICRA.2019.8794221
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a new approach for outdoor large scale image based localization that can deal with challenging scenarios like cross-season, cross-weather, day/night and long-term localization. The key component of our method is a new learned global image descriptor, that can effectively benefit from scene geometry information during training. At test time, our system is capable of inferring the depth map related to the query image and use it to increase localization accuracy. We are able to increase recall@1 performances by 2.15% on cross-weather and long-term localization scenario and by 4.24% points on a challenging winter/summer localization sequence versus state-of-the-art methods. Our method can also use weakly annotated data to localize night images across a reference dataset of daytime images.
ER  - 

TY  - CONF
TI  - Multi-Robot Region-of-Interest Reconstruction with Dec-MCTS
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9101
EP  - 9107
AU  - F. Sukkar
AU  - G. Best
AU  - C. Yoo
AU  - R. Fitch
PY  - 2019
KW  - manipulators
KW  - Monte Carlo methods
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - tree searching
KW  - motion planning
KW  - high-dimensional configuration space
KW  - multirobot region-of-interest reconstruction
KW  - dec-MCTS
KW  - multiple robot arms
KW  - RGB-D sensors
KW  - precision agriculture
KW  - infrastructure inspection
KW  - viewpoint evaluation function
KW  - nonmyopic planning algorithm
KW  - decentralised Monte Carlo tree search
KW  - navigation graph
KW  - fruit detection
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Manipulators
KW  - Planning
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793560
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of reconstructing regions of interest of a scene using multiple robot arms and RGB-D sensors. This problem is motivated by a variety of applications, such as precision agriculture and infrastructure inspection. A viewpoint evaluation function is presented that exploits predicted observations and the geometry of the scene. A recently proposed non-myopic planning algorithm, Decentralised Monte Carlo tree search, is used to coordinate the actions of the robot arms. Motion planning is performed over a navigation graph that considers the high-dimensional configuration space of the robot arms. Extensive simulated experiments are carried out using real sensor data and then validated on hardware with two robot arms. Our proposed targeted information gain planner is compared to state-of-the-art baselines and outperforms them in every measured metric. The robots quickly observe and accurately detect fruit in a trellis structure, demonstrating the viability of the approach for real-world applications.
ER  - 

TY  - CONF
TI  - Design and Control of a Passively Morphing Quadcopter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9116
EP  - 9122
AU  - N. Bucki
AU  - M. W. Mueller
PY  - 2019
KW  - aerospace components
KW  - design engineering
KW  - helicopters
KW  - hinges
KW  - nonlinear dynamical systems
KW  - position control
KW  - propellers
KW  - passively morphing quadcopter
KW  - passive rotary joints
KW  - rapid aerial morphing
KW  - sprung hinges
KW  - nonmorphing quadcopter
KW  - quadcopter controllers
KW  - trajectory generation algorithms
KW  - control inputs
KW  - gap traversal maneuvers
KW  - rigid connections
KW  - quadcopter design
KW  - propellers
KW  - nonlinear dynamics
KW  - Propellers
KW  - Vehicle dynamics
KW  - Springs
KW  - Force
KW  - Fasteners
KW  - Dynamics
KW  - Actuators
DO  - 10.1109/ICRA.2019.8794373
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel quadcopter design that uses passive rotary joints to enable rapid aerial morphing without the use of additional actuators. The normally rigid connections between the arms of the quadcopter and the central body are replaced by sprung hinges that allow for the arms of the quadcopter to fold downward when low thrusts are produced by the propellers, resulting in a reduction of the largest dimension of the vehicle by approximately 50%. The ability of the vehicle to reduce its size during flight allows, e.g., for the traversal of gaps through which a non-morphing quadcopter could not pass. The vehicle is designed such that existing quadcopter controllers and trajectory generation algorithms can be used, provided that some additional constraints on the control inputs are met. The nonlinear dynamics of the system are presented, and design rules are given that minimize transition time between configurations and maximize the available range of control inputs. A method for performing gap traversal maneuvers is proposed and validated experimentally.
ER  - 

TY  - CONF
TI  - Search-based 3D Planning and Trajectory Optimization for Safe Micro Aerial Vehicle Flight Under Sensor Visibility Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9123
EP  - 9129
AU  - M. Nieuwenhuisen
AU  - S. Behnke
PY  - 2019
KW  - aerospace safety
KW  - collision avoidance
KW  - graph theory
KW  - navigation
KW  - search problems
KW  - trajectory optimisation (aerospace)
KW  - trajectory optimization
KW  - sensor visibility constraints
KW  - obstacle-free flight paths
KW  - Velodyne Puck Lite 3D laser scanner
KW  - flight dynamics
KW  - navigation safety
KW  - allocentric complete planning
KW  - microaerial vehicle flight safety
KW  - search-based 3D planning
KW  - collision avoidance
KW  - graph search
KW  - Planning
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Trajectory optimization
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8794086
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Safe navigation of Micro Aerial Vehicles (MAVs) requires not only obstacle-free flight paths according to a static environment map, but also the perception of and reaction to previously unknown and dynamic objects. This implies that the onboard sensors cover the current flight direction. Due to the limited payload of MAVs, full sensor coverage of the environment has to be traded off with flight time. Thus, often only a part of the environment is covered. We present a combined allocentric complete planning and trajectory optimization approach taking these sensor visibility constraints into account. The optimized trajectories yield flight paths within the apex angle of a Velodyne Puck Lite 3D laser scanner enabling low-level collision avoidance to perceive obstacles in the flight direction. Furthermore, the optimized trajectories take the flight dynamics into account and contain the velocities and accelerations along the path. We evaluate our approach with a DJI Matrice 600 MAV and in simulation employing hardware-in-the-loop.
ER  - 

TY  - CONF
TI  - LineRanger: Analysis and Field Testing of an Innovative Robot for Efficient Assessment of Bundled High-Voltage Powerlines
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9130
EP  - 9136
AU  - P. -. Richard
AU  - N. Pouliot
AU  - F. Morin
AU  - M. Lepage
AU  - P. Hamelin
AU  - M. Lagac©
AU  - A. Sartor
AU  - G. Lambert
AU  - S. Montambault
PY  - 2019
KW  - inspection
KW  - maintenance engineering
KW  - mathematical analysis
KW  - power grids
KW  - power overhead lines
KW  - power transmission control
KW  - robots
KW  - field testing
KW  - innovative robot
KW  - bundled high-voltage powerlines
KW  - robotic platforms
KW  - power grid
KW  - Hydro-Québec
KW  - line maintenance technicians
KW  - passive obstacle-crossing system
KW  - large-scale inspection
KW  - bundled-type powerlines
KW  - mathematical analysis
KW  - LineRanger prototype
KW  - powerline inspection efficiency
KW  - LineScout prototype
KW  - Conductors
KW  - Wheels
KW  - Springs
KW  - Mobile robots
KW  - Blades
KW  - Rotors
DO  - 10.1109/ICRA.2019.8794397
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic platforms dedicated to powerline inspection are often complex to operate, take several minutes to cross any obstacle, and must be operated by highly trained specialists. To further its goal of massive inspection of its power grid, Hydro-Québec developed an innovative robot that is simple to operate and can be used directly by line maintenance technicians. LineRanger was developed following the field deployment of LineROVer and LineScout but aims at surpassing them in terms of inspection efficiency. With an ingenious and passive obstacle-crossing system, this new robot allows large-scale inspection of bundled-type powerlines, since the obstacle crossing time is considerably reduced. In this paper, details on the robot's key features are presented along with its mathematical analysis, which guarantees its stability on flexible bundles and directly influenced the design. Finally, the LineRanger prototype is presented, with insights about its first field deployments.
ER  - 

TY  - CONF
TI  - Adjustable Power Modulation For A Leg Mechanism Suitable For Running
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9137
EP  - 9142
AU  - M. Plecnik
AU  - K. Fearing
AU  - R. S. Fearing
PY  - 2019
KW  - actuators
KW  - legged locomotion
KW  - torque
KW  - kinetic power output
KW  - high power mode
KW  - low-power modes
KW  - adjustable power modulation
KW  - mechanical systems
KW  - robotic locomotor
KW  - actuator system
KW  - leg mechanism
KW  - terrestrial locomotion
KW  - energetic performance
KW  - force-torque ratio
KW  - flat terrain
KW  - finite root generation method
KW  - Legged locomotion
KW  - DC motors
KW  - Springs
KW  - Torque
KW  - Couplings
KW  - Foot
DO  - 10.1109/ICRA.2019.8794379
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent work in the design of mechanical systems for terrestrial locomotion has indicated successful strategies for increasing the energetic performance of a robotic locomotor without upgrading its actuator system. We apply one such strategy, termed power modulation, in a new way: for the design of a leg mechanism useful for running. Power modulation geometrically defines force/torque ratios between robot components to mechanically achieve certain energy transmission characteristics during fast stance dynamics that increase the kinetic power output of the overall system. Furthermore, we investigate the design of a leg mechanism that can adjust to exhibit power modulation. In this way, a leg mechanism would exhibit a low power mode for flat terrain, and can adjust to a high power mode for rough terrain. The latter makes jumping possible and extends the range of available footholds that can be accessed in a single step. To find a suitable leg mechanism, we leverage the Finite Root Generation method to compute a design. The design is advanced to a prototype and basic experiments are conducted to investigate its behavior as adjusted between high-and low-power modes.
ER  - 

TY  - CONF
TI  - Fast and In Sync: Periodic Swarm Patterns for Quadrotors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9143
EP  - 9149
AU  - X. Du
AU  - C. E. Luis
AU  - M. Vukosavljev
AU  - A. P. Schoellig
PY  - 2019
KW  - autonomous aerial vehicles
KW  - helicopters
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - path planning
KW  - motion delays
KW  - drones
KW  - periodic swarm patterns
KW  - quadrotor swarm performances
KW  - integrated unit
KW  - coordinated unit
KW  - swarm motion primitives
KW  - flexible framework
KW  - choreography design
KW  - trajectory generation algorithms
KW  - periodic motion pattern
KW  - Drones
KW  - Trajectory
KW  - Vehicle dynamics
KW  - Surface waves
KW  - Planning
KW  - Aerodynamics
DO  - 10.1109/ICRA.2019.8794017
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper aims to design quadrotor swarm performances, where the swarm acts as an integrated, coordinated unit embodying moving and deforming objects. We divide the task of creating a choreography into three basic steps: designing swarm motion primitives, transitioning between those movements, and synchronizing the motion of the drones. The result is a flexible framework for designing choreographies comprised of a wide variety of motions. The motion primitives can be intuitively designed using a few parameters, providing a rich library for choreography design. Moreover, we combine and adapt existing goal assignment and trajectory generation algorithms to maximize the smoothness of the transitions between motion primitives. Finally, we propose a correction algorithm to compensate for motion delays and synchronize the motion of the drones to a desired periodic motion pattern. The proposed methodology was validated experimentally by generating and executing choreographies on a swarm of 25 quadrotors.
ER  - 

TY  - CONF
TI  - Transfer Learning for Surgical Task Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9166
EP  - 9172
AU  - Y. Tsai
AU  - B. Huang
AU  - Y. Guo
AU  - G. Yang
PY  - 2019
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - surgery
KW  - transfer learning
KW  - surgical task segmentation
KW  - segmentation points
KW  - manually labeled data
KW  - correlated features
KW  - segmentation rule
KW  - high segmentation rates
KW  - Task analysis
KW  - Motion segmentation
KW  - Trajectory
KW  - Feature extraction
KW  - Needles
KW  - Surgery
DO  - 10.1109/ICRA.2019.8794292
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a novel approach for surgical task segmentation. A segmentation policy learns the correlations between features and segmentation points from manually labeled data. The most correlated features and rules for segmenting them are identified and learned. These form a complete set of segmentation policy. The proposed approach is developed to segment new but similar tasks through transfer learning. It is verified through applying the segmentation rule learned from the labeled data to segment other tasks. The performance of the proposed algorithm was evaluated by comparing the results against the ground truths. Experimental results demonstrate that our approach can achieve high segmentation rates with an accuracy of between 68.8% - 81.8%.
ER  - 

TY  - CONF
TI  - Bayesian Optimization of Soft Exosuits Using a Metabolic Estimator Stopping Process
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9173
EP  - 9179
AU  - M. Kim
AU  - C. Liu
AU  - J. Kim
AU  - S. Lee
AU  - A. Meguid
AU  - C. J. Walsh
AU  - S. Kuindersma
PY  - 2019
KW  - Bayes methods
KW  - data acquisition
KW  - gradient methods
KW  - Kalman filters
KW  - legged locomotion
KW  - optimal control
KW  - parameter estimation
KW  - Kalman filter-based metabolic estimator
KW  - soft exosuits
KW  - metabolic estimator stopping process
KW  - human-in-the-loop optimization studies
KW  - wearable devices
KW  - improved average metabolic reduction
KW  - slow metabolic dynamics
KW  - Bayesian optimization
KW  - gradient descent optimization
KW  - Optimization
KW  - Bayes methods
KW  - Time measurement
KW  - Noise measurement
KW  - Estimation
KW  - Standards
KW  - Phase measurement
DO  - 10.1109/ICRA.2019.8793817
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent human-in-the-loop (HIL) optimization studies using wearable devices have shown an improved average metabolic reduction by optimizing a small number of control parameters during short-duration walking experiments. However, the slow metabolic dynamics, high measurement noise, and experimental time constraints create challenges for increasing the number of control parameters to be optimized. Prior work applying gradient descent and Bayesian optimization to this problem have decoupled metabolic estimation and control parameter selection using fixed estimation intervals, which imposes a hard limit on the number of parameter evaluations possible in a given time budget. In this work, we take a different approach that couples estimation and parameter selection, allowing the algorithm to spend less time on refining the metabolic estimates for parameters that are unlikely to improve performance over the best observed values. Our approach uses a Kalman filter-based metabolic estimator to formulate an optimal stopping problem during the data acquisition step of standard Bayesian optimization. Performance was analyzed in numerical simulations and in pilot human subject testing with two subjects that involved optimizing six control parameters of a single-joint exosuit and four parameters of a multi-joint exosuit.
ER  - 

TY  - CONF
TI  - Towards Semi-Autonomous and Soft-Robotics Enabled Upper-Limb Exoprosthetics: First Concepts and Robot-Based Emulation Prototype
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9180
EP  - 9186
AU  - J. Kuhn
AU  - J. Ringwald
AU  - M. Schappler
AU  - L. Johannsmeier
AU  - S. Haddadin
PY  - 2019
KW  - artificial limbs
KW  - biomechanics
KW  - medical robotics
KW  - mobile robots
KW  - motion control
KW  - orthopaedics
KW  - patient rehabilitation
KW  - 3D visual perception
KW  - semiautonomous coordinated motion strategies
KW  - app-based programming framework
KW  - established standard sequential strategies all joints
KW  - human embodied dynamics model
KW  - robot-based exoskeleton substitute
KW  - soft-robotics design
KW  - intelligent coordinated control concepts
KW  - upper body
KW  - gravity effects
KW  - residual limb
KW  - unnecessary interaction forces
KW  - central goal
KW  - prostheses
KW  - exoskeletons
KW  - robot-based emulation prototype
KW  - soft-robotics enabled upper-limb exoprosthetics
KW  - strategy goals
KW  - Prosthetics
KW  - Exoskeletons
KW  - Robot kinematics
KW  - Prototypes
KW  - Task analysis
KW  - End effectors
DO  - 10.1109/ICRA.2019.8794332
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper the first robot-based prototype of a semi-autonomous upper-limb exoprosthesis is introduced, unifying exoskeletons and prostheses [1]. A central goal of this work is to minimize unnecessary interaction forces on the residual limb by compensating gravity effects via a upper body grounded exoskeleton. Furthermore, the exoskeleton provides the residual limb's kinematic data that allows to design more intelligent coordinated control concepts. The soft-robotics design of a prototype consisting of a transhumeral prosthesis and a robot-based exoskeleton substitute is outlined. For this class of hybrid systems a human embodied dynamics model and semi-autonomous coordinated motion strategies are derived. Here, in contrast to established standard sequential strategies all joints are moved simultaneously according to a desired task. In combination with an app-based programming framework the strategy goals are set either user-based via kinesthetic teaching or autonomously via 3D visual perception. This enables the user to execute tasks faster and more intuitive. First experimental evaluations show promising performance with a healthy subject.
ER  - 

TY  - CONF
TI  - A Miniature Suction-Gripper With Passive and Active Microneedle Arrays to Manipulate Peripheral Nerves
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9202
EP  - 9208
AU  - N. Jang
AU  - Y. S. Ihn
AU  - J. Jeong
AU  - S. Yang
AU  - S. Yim
AU  - S. Oh
AU  - K. Kim
AU  - D. Hwang
PY  - 2019
KW  - biological tissues
KW  - grippers
KW  - injuries
KW  - medical robotics
KW  - needles
KW  - neurophysiology
KW  - surgery
KW  - neurosurgical robot
KW  - nervous tissues
KW  - robotic surgical instrument
KW  - nerve damages
KW  - nerve bundles
KW  - flexible peripheral nerves
KW  - active microneedle arrays
KW  - passive microneedle arrays
KW  - miniature suction-gripper
KW  - peripheral nerve
KW  - suction mechanism
KW  - Force
KW  - Grippers
KW  - Instruments
KW  - Wires
KW  - Manipulators
KW  - Hoses
DO  - 10.1109/ICRA.2019.8794154
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We develop a miniature suction-gripper with the goal to realize the novel robotic surgical instrument that can grip slippery and flexible peripheral nerves. In developing the instrument, we place a priority on devising the method that can robustly grip the nerve bundles during the surgical operation for the peripheral nerve. Also, we concentrate to investigate the working principle being able to minimize nerve damages that might be caused when manipulating the nerve. In this study, as the most suitable method to achieve the goal, we scheme to utilize the suction mechanism. Because it can non-invasively grip the nerve based on negative pressure, no external force is applied to the nervous tissues. Therefore the peripheral nerve can be manipulated without serious nerve damage (e.g. crush injury and stretch injury). To improve the gripping ability of the proposed suction gripper, two different types of microneedle arrays are applied to the suction-tips: passive-microneedle (PMN) arrays and active-microneedle (AMN) arrays. Since the most outer membrane of the nerve can be anchored by the penetrated PMN and AMN, the gripper can grip the nerve more robustly. The designed suction-gripper is fabricated as a functional prototype, and its working performances are assessed with in-vitro and in-vivo animal experiments. The experimental results well demonstrate the practical effectiveness of the proposed method and its applicability to the neurosurgical robot for the peripheral nerve.
ER  - 

TY  - CONF
TI  - Robust 3D Distributed Formation Control With Collision Avoidance And Application To Multirotor Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9209
EP  - 9215
AU  - K. Fathian
AU  - S. Safaoui
AU  - T. H. Summers
AU  - N. R. Gans
PY  - 2019
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - distributed control
KW  - helicopters
KW  - mobile robots
KW  - position control
KW  - position measurement
KW  - robust control
KW  - distributed control strategy
KW  - local relative position measurements
KW  - collision avoidance strategy
KW  - robust 3D distributed formation control
KW  - 3D formation
KW  - multirotor aerial vehicles
KW  - quadrotors
KW  - Three-dimensional displays
KW  - Collision avoidance
KW  - Shape
KW  - Vehicle dynamics
KW  - Position measurement
KW  - Sensors
KW  - Topology
KW  - Multi-robot systems
KW  - distributed robotic systems
KW  - 3D formation control
KW  - distributed collision avoidance
DO  - 10.1109/ICRA.2019.8794349
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a distributed control strategy for a team of agents to autonomously achieve a desired 3D formation. Our approach is based on local relative position measurements and can be applied to multirotor aerial vehicles. We assume that agents have a common sense of direction, which is used to align the z-axes of their local coordinate frames. However, this assumption is not crucial, and our approach is provably robust to misalignments in the local coordinate frames or measurement inaccuracies. In particular, agents can move along any direction that projects positively onto the desired direction of motion. This property is exploited to design a fully-distributed collision avoidance strategy. We validate the proposed approach experimentally and show that a team of quadrotors can achieve a desired 3D formation without collisions.
ER  - 

TY  - CONF
TI  - Networked Operation of a UAV Using Gaussian Process-Based Delay Compensation and Model Predictive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9216
EP  - 9222
AU  - D. Jang
AU  - J. Yoo
AU  - C. Y. Son
AU  - H. J. Kim
AU  - K. H. Johansson
PY  - 2019
KW  - autonomous aerial vehicles
KW  - compensation
KW  - control nonlinearities
KW  - delays
KW  - Gaussian processes
KW  - mobile robots
KW  - networked control systems
KW  - nonlinear control systems
KW  - path planning
KW  - predictive control
KW  - stability
KW  - state estimation
KW  - state feedback
KW  - time-varying systems
KW  - Gaussian process-based delay compensation
KW  - model predictive control
KW  - time-varying network delay
KW  - UAV control system
KW  - delayed state feedback
KW  - multirotor-type UAVs
KW  - networked control system
KW  - UAV networked operation
KW  - path planning
KW  - state estimation
KW  - Delays
KW  - Servers
KW  - Uplink
KW  - Downlink
KW  - Predictive models
KW  - Unmanned aerial vehicles
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793472
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study addresses an operation of unmanned aerial vehicles (UAVs) in a network environment where there is time-varying network delay. The network delay entails undesirable effects on the stability of the UAV control system due to delayed state feedback and outdated control input. Although several networked control algorithms have been proposed to deal with the network delay, most existing studies have assumed that the plant dynamics is known and simple, or the network delay is constant. These assumptions are improper to multirotor-type UAVs because of their nonlinearity and time-sensitive characteristics. To deal with these problems, we propose a networked control system using model predictive control (MPC) designed under the consideration of multirotor characteristics. We also apply a Gaussian process (GP) to learn an unknown nonlinear model, which increases the accuracy of path planning and state estimation. Flight experiments show that the proposed algorithm successfully compensates the network delay and Gaussian process learning improves the UAV's path tracking performance.
ER  - 

TY  - CONF
TI  - Flappy Hummingbird: An Open Source Dynamic Simulation of Flapping Wing Robots and Animals
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9223
EP  - 9229
AU  - F. Fei
AU  - Z. Tu
AU  - Y. Yang
AU  - J. Zhang
AU  - X. Deng
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aerospace robotics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - closed loop systems
KW  - control system synthesis
KW  - learning (artificial intelligence)
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - robot dynamics
KW  - robot kinematics
KW  - stability
KW  - vehicle dynamics
KW  - flappy hummingbird
KW  - open source dynamic simulation
KW  - flapping Wing robots
KW  - hummingbirds
KW  - extraordinary flight performance
KW  - stable hovering maneuvering
KW  - aggressive maneuvering
KW  - conventional small scale man-made vehicles
KW  - FWMAVs
KW  - performance gap
KW  - open source high fidelity dynamic simulation
KW  - optimization
KW  - flight control
KW  - at-scale hummingbird robot
KW  - system identification
KW  - dynamic response
KW  - open-loop
KW  - loop systems
KW  - simulated flights
KW  - experimental flights
KW  - highly nonlinear flight dynamics
KW  - control problems
KW  - control algorithms
KW  - linear controller
KW  - control policy
KW  - simulation-to-real transfer
KW  - physical robot
KW  - flapping wing microair vehicles
KW  - Aerodynamics
KW  - Robots
KW  - Vehicle dynamics
KW  - Force
KW  - Torque
KW  - Animals
DO  - 10.1109/ICRA.2019.8794089
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Insects and hummingbirds exhibit extraordinary flight performance and can simultaneously master seemingly conflicting goals: stable hovering and aggressive maneuvering, which are unmatched by conventional small scale man-made vehicles. Flapping Wing Micro Air Vehicles (FWMAVs) hold great promise for closing this performance gap. However, design and control of such systems remain challenging. Here, we present an open source high fidelity dynamic simulation for FWMAVs. The simulator serves as a testbed for the design, optimization and flight control of FWMAVs. To validate the simulation, we recreated the at-scale hummingbird robot developed in our lab in the simulation. System identification was performed to obtain the model parameters. Force generation and dynamic response of open-loop and closed loop systems between simulated and experimental flights were compared. The unsteady aerodynamics and the highly nonlinear flight dynamics present challenging control problems for conventional and learning control algorithms such as Reinforcement Learning. The interface of the simulation is fully compatible with OpenAI Gym environment. As a benchmark study, we present a linear controller for hovering stabilization and a Deep Reinforcement Learning control policy for goal-directed maneuvering. Finally, we demonstrate direct simulation-to-real transfer of both control policies onto the physical robot, further demonstrating the fidelity of the simulation.
ER  - 

TY  - CONF
TI  - Visual Repetition Sampling for Robot Manipulation Planning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9236
EP  - 9242
AU  - E. Y. Puang
AU  - P. Lehner
AU  - Z. Marton
AU  - M. Durner
AU  - R. Triebel
AU  - A. Albu-Schäffer
PY  - 2019
KW  - collision avoidance
KW  - Gaussian processes
KW  - image sampling
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - mobile robots
KW  - robot vision
KW  - trees (mathematics)
KW  - Gaussian mixture models
KW  - rapidly-exploring random tree
KW  - biased sampling methods
KW  - real-time applications
KW  - longer planning times
KW  - optimization-based methods
KW  - complex environments
KW  - sampling-based motion planners
KW  - robot manipulation
KW  - visual repetition sampling
KW  - RRT motion planner
KW  - sampling efficiency
KW  - visual input
KW  - GMM
KW  - Planning
KW  - Databases
KW  - Task analysis
KW  - Visualization
KW  - Robots
KW  - Probability distribution
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8793942
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - One of the main challenges in sampling-based motion planners is to find an efficient sampling strategy. While methods such as Rapidly-exploring Random Tree (RRT) have shown to be more reliable in complex environments than optimization-based methods, they often require longer planning times, which reduces their usability for real-time applications. Recently, biased sampling methods have shown to remedy this issue. For example Gaussian Mixture Models (GMMs) have been used to sample more efficiently in feasible regions of the configuration space. Once the GMM is learned, however, this approach does not adapt its biases to individual planning scene during inference. Hence, we propose in this work a more efficient sampling strategy to further bias the GMM based on visual input upon query. We employ an autoencoder trained entirely in simulation to extract features from depth images and use the latent representation to adjust the weights of each mixture components in the GMM. We show empirically that this improves the sampling efficiency of an RRT motion planner in both real and simulated scenes.
ER  - 

TY  - CONF
TI  - Contact-Driven Posture Behavior for Safe and Interactive Robot Operation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9243
EP  - 9249
AU  - M. Jorda
AU  - E. G. Herrero
AU  - O. Khatib
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - uncertain environments
KW  - unexpected contact
KW  - safe robot behavior
KW  - contact-driven approach
KW  - safe robot operation
KW  - interactive robot operation
KW  - unforeseen contact events
KW  - robot tasks
KW  - robot model
KW  - freedom robot arm
KW  - safe contact behavior
KW  - robot posture requirements
KW  - contact-driven posture behavior
KW  - Task analysis
KW  - Collision avoidance
KW  - Robot sensing systems
KW  - Aerospace electronics
KW  - Robot kinematics
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2019.8793691
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When performing tasks in uncertain environments and around humans, robots are likely to collide unexpectedly with people or objects. In order to ensure safety, most approaches rely on collision avoidance and try to prevent any contact from happening, which may result in unnecessary interruption of a task that would be feasible in spite of the obstacle. On the one hand, when an unexpected contact occurs, a safe robot behavior is required. On the other hand, it might be interesting to exploit the contact instead of moving away from it. In this paper, we present a contact-driven approach for safe and interactive robot operation to react to unforeseen contact events. This approach offers the possibility to control the contact while minimizing its effects on the robot tasks. It relies exclusively on the robot model and proprioceptive sensors. It is tested in simulation and hardware experiments on a 7 degrees of freedom robot arm and shows a safe contact behavior that does not interfere with the task, and as little as possible with the robot posture requirements.
ER  - 

TY  - CONF
TI  - SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9250
EP  - 9256
AU  - S. Pillai
AU  - R. Ambruş
AU  - A. Gaidon
PY  - 2019
KW  - convolutional neural nets
KW  - image classification
KW  - image motion analysis
KW  - image resolution
KW  - image sampling
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - self-supervised monocular depth estimation
KW  - self-supervised monocular depth prediction
KW  - subpixel convolutional layer extension
KW  - depth super-resolution
KW  - high-resolution disparities
KW  - low-resolution convolutional features
KW  - flip-augmentation layer
KW  - single-image super-resolution
KW  - deep learning methods
KW  - super-resolved monocular depth estimation
KW  - public KITTI benchmark
KW  - pose estimation
KW  - Estimation
KW  - Convolutional codes
KW  - Cameras
KW  - Spatial resolution
KW  - Three-dimensional displays
KW  - Training
DO  - 10.1109/ICRA.2019.8793621
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent techniques in self-supervised monocular depth estimation are approaching the performance of supervised methods, but operate in low resolution only. We show that high resolution is key towards high-fidelity self-supervised monocular depth prediction. Inspired by recent deep learning methods for Single-Image Super-Resolution, we propose a subpixel convolutional layer extension for depth super-resolution that accurately synthesizes high-resolution disparities from their corresponding low-resolution convolutional features. In addition, we introduce a differentiable flip-augmentation layer that accurately fuses predictions from the image and its horizontally flipped version, reducing the effect of left and right shadow regions generated in the disparity map due to occlusions. Both contributions provide significant performance gains over the state-of-the-art in self-supervised depth and pose estimation on the public KITTI benchmark. A video of our approach can be found at https://youtu.be/jKNgBeBMx0I.
ER  - 

TY  - CONF
TI  - The Mechanics and Control of Leaning to Lift Heavy Objects with a Dynamically Stable Mobile Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9264
EP  - 9270
AU  - F. Sonnleitner
AU  - R. Shu
AU  - R. L. Hollis
PY  - 2019
KW  - feedback
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - robot dynamics
KW  - wheels
KW  - two-wheeled dynamically stable mobile manipulator robots
KW  - heavy object
KW  - ballbot
KW  - feedback control laws
KW  - dynamically stable mobile robot
KW  - spherical-wheel robots
KW  - unknown mass
KW  - quasistatic center of mass computation
KW  - feedforward control laws
KW  - mass 15.0 kg
KW  - mass 10.0 kg
KW  - Mobile robots
KW  - Task analysis
KW  - Payloads
KW  - Humanoid robots
KW  - Manipulators
KW  - Navigation
DO  - 10.1109/ICRA.2019.8793620
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A control algorithm is developed to enable dynamically stable spherical-wheel robots (ballbots) with arms to detect a heavy object of unknown mass, navigate to it, lift it, transport it, and place it in a desired location semi-autonomously. Previous work has successfully demonstrated two-wheeled dynamically stable mobile manipulator robots transporting heavy objects. We report here the first ballbot to reliably achieve such a task. A successful semi-autonomous lift and transport of a 15 kg heavy box whose actual mass was unknown was achieved using a combination of feedforward and feedback control laws based on a quasi-static center of mass computation. The ballbot's pan and tilt sensor turret tracked fiducial markers on the box. Ballbot-to-human and human-to-ballbot exchanges of a 10 kg heavy object was achieved while dynamically balancing.
ER  - 

TY  - CONF
TI  - Improving Underwater Obstacle Detection using Semantic Image Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9271
EP  - 9277
AU  - B. Arain
AU  - C. McCool
AU  - P. Rigby
AU  - D. Cagara
AU  - M. Dunbabin
PY  - 2019
KW  - feature extraction
KW  - image classification
KW  - image enhancement
KW  - image matching
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - stereo image processing
KW  - image-based underwater obstacle detection
KW  - sparse stereo point clouds
KW  - monocular semantic image segmentation
KW  - cluttered underwater environments
KW  - robust robotic path planning
KW  - feature-based stereo matching
KW  - learning-based segmentation
KW  - robust obstacle map
KW  - direct binary learning
KW  - underwater obstacles
KW  - multiclass learning approach
KW  - binary map
KW  - sparse stereo matching
KW  - 3D obstacle maps
KW  - coral reef environments
KW  - image-wide obstacle detection
KW  - dynamic objects
KW  - image-based obstacle maps
KW  - Image segmentation
KW  - Semantics
KW  - Cameras
KW  - Three-dimensional displays
KW  - Real-time systems
KW  - Training
KW  - Robots
DO  - 10.1109/ICRA.2019.8793588
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents two novel approaches for improving image-based underwater obstacle detection by combining sparse stereo point clouds with monocular semantic image segmentation. Generating accurate image-based obstacle maps in cluttered underwater environments, such as coral reefs, are essential for robust robotic path planning and navigation. However, these maps can be challenged by factors including visibility, lighting and dynamic objects (e.g. fish) that may lead to falsely identified free space or dynamic objects which trajectory planners may react to undesirably. We propose combining feature-based stereo matching with learning-based segmentation to produce a more robust obstacle map. This approach considers direct binary learning of the presence or absence of underwater obstacles, as well as a multiclass learning approach to classify their distance (near, mid and far) in the scene. An enhancement to the binary map is also shown by including depth information from sparse stereo matching to produce 3D obstacle maps of the scene. The performance is evaluated using field data collected in cluttered, and at times, visually degraded coral reef environments. The results show improved image-wide obstacle detection, rejection of transient objects (such as fish), and range estimation compared to feature-based sparse and dense stereo point clouds alone.
ER  - 

TY  - CONF
TI  - RCM-SLAM: Visual localisation and mapping under remote centre of motion constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9278
EP  - 9284
AU  - F. Vasconcelos
AU  - E. Mazomenos
AU  - J. Kelly
AU  - D. Stoyanov
PY  - 2019
KW  - cameras
KW  - image motion analysis
KW  - image reconstruction
KW  - medical robotics
KW  - mobile robots
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - surgery
KW  - laparoscopic camera motion
KW  - RCM constraints
KW  - minimal solver
KW  - absolute camera
KW  - 2D-3D point correspondences
KW  - bundle adjustment optimiser
KW  - RCM-constrained parameterisation
KW  - relative pose estimation
KW  - SLAM pipeline suitable
KW  - robotic surgery
KW  - RCM position
KW  - robotic prostatectomy show
KW  - RCM-SLAM
KW  - visual localisation
KW  - remote centre
KW  - motion constraints
KW  - insertion ports
KW  - Simultaneous Localisation and Mapping
KW  - mapping approach
KW  - RCM-PnP
KW  - Cameras
KW  - Robot vision systems
KW  - Simultaneous localization and mapping
KW  - Laparoscopes
KW  - Three-dimensional displays
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793931
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In robotic surgery the motion of instruments and the laparoscopic camera is constrained by their insertion ports, i. e. a remote centre of motion (RCM). We propose a Simultaneous Localisation and Mapping (SLAM) approach that estimates laparoscopic camera motion under RCM constraints. To achieve this we derive a minimal solver for the absolute camera pose given two 2D-3D point correspondences (RCM-PnP) and also a bundle adjustment optimiser that refines camera poses within an RCM-constrained parameterisation. These two methods are used together with previous work on relative pose estimation under RCM [1] to assemble a SLAM pipeline suitable for robotic surgery. Our simulations show that RCM-PnP outperforms conventional PnP for a wide noise range in the RCM position. Results with video footage from a robotic prostatectomy show that RCM constraints significantly improve camera pose estimation.
ER  - 

TY  - CONF
TI  - Comparing Physical and Simulated Performance of a Deterministic and a Bio-inspired Stochastic Foraging Strategy for Robot Swarms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9285
EP  - 9291
AU  - Q. Lu
AU  - A. D. Griego
AU  - G. M. Fricke
AU  - M. E. Moses
PY  - 2019
KW  - deterministic algorithms
KW  - multi-robot systems
KW  - stochastic processes
KW  - robot swarms
KW  - collective robot foraging
KW  - central-place foraging algorithm
KW  - CPFA
KW  - distributed deterministic spiral algorithm
KW  - DDSA
KW  - swarm robotic algorithms
KW  - bioinspired stochastic foraging strategy
KW  - resource-collection algorithms
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Spirals
KW  - Swarm robotics
KW  - Task analysis
KW  - Cameras
DO  - 10.1109/ICRA.2019.8794240
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Designing resource-collection algorithms for relatively simple robots that are effective given the noise and uncertainty of the real world is a challenge in swarm robotics. This paper describes the performance of two algorithms for collective robot foraging: the stochastic central-place foraging algorithm (CPFA) and the distributed deterministic spiral algorithm (DDSA). With the CPFA, robots mimic the foraging behaviors of ants; they stochastically search for targets and share information to recruit other robots to locations where they detect multiple targets. With the DDSA, robots travel along pre-planned spiral paths; robots detect the nearest targets first and, in theory, guarantee eventual complete coverage of the arena with minimal overlap. We implemented both algorithms and compared their performance in a Gazebo simulation and in physical robots in a large outdoor arena. In a realistic Gazebo simulation, the DDSA outperforms the CPFA. However, in real-world experiments with obstacles, collisions, and errors, the movement patterns of robots implementing the DDSA become visually indistinguishable from the CPFA. The CPFA is less affected by noise and error, and it performs as well as, or better than, the DDSA. Physical experiments change our conclusion about which algorithm has the best performance, emphasizing the importance of systematically comparing the performance of swarm robotic algorithms in the real world.
ER  - 

TY  - CONF
TI  - WheeLeR: Wheel-Leg Reconfigurable Mechanism with Passive Gears for Mobile Robot Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9292
EP  - 9298
AU  - C. Zheng
AU  - K. Lee
PY  - 2019
KW  - gears
KW  - legged locomotion
KW  - robot kinematics
KW  - wheels
KW  - mobile robotic platform
KW  - gear ratio
KW  - wheel-leg reconfigurable mechanism
KW  - passive gears
KW  - mobile robot applications
KW  - passive wheel-leg transformation mechanism
KW  - central gear
KW  - seamless circular wheel
KW  - leg mode
KW  - geared structure
KW  - obstacle climbing
KW  - locomotion capabilities
KW  - Legged locomotion
KW  - Wheels
KW  - Gears
KW  - Torque
KW  - Force
DO  - 10.1109/ICRA.2019.8793686
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a new passive wheel-leg transformation mechanism and its embodiment in a small mobile robot. The mechanism is based on a unique geared structure, allowing the wheel to transform between two modes, i.e., wheel or leg, potentially adapting to varying ground conditions. It consists of a central gear and legs with partial gears that rotate around the central gear to open or close the legs. When fully closed, the mechanism forms a seamless circular wheel; when opened, it operates in the leg mode. The central gear actuated by the driving motor generates opening and closing motions of the legs without using an additional actuator. The number of legs, their physical size, and the gear ratio between the central gear and the partial gears on the legs are adjustable. This design is mechanically simple, customizable, and easy to fabricate. For physical demonstration and experiments, a mobile robotic platform was built and its terrainability was tested using five different sets of the transformable wheels with varying sizes and gear ratios. For each design, the performance with successful wheel-leg transformation, obstacle climbing, and locomotion capabilities was tested in different ground conditions.
ER  - 

TY  - CONF
TI  - Long-Term Occupancy Grid Prediction Using Recurrent Neural Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9299
EP  - 9305
AU  - M. Schreiber
AU  - S. Hoermann
AU  - K. Dietmayer
PY  - 2019
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - Monte Carlo methods
KW  - neural net architecture
KW  - optical radar
KW  - recurrent neural nets
KW  - long-term occupancy grid prediction
KW  - recurrent neural networks
KW  - scene evolution
KW  - automated driving
KW  - Lidar grid fusion
KW  - birds eye view
KW  - RNNs
KW  - CNN architecture
KW  - convolutional long short-term memories
KW  - ConvLSTMs
KW  - Monte Carlo approach
KW  - Vehicle dynamics
KW  - Training
KW  - Predictive models
KW  - Task analysis
KW  - Computer architecture
KW  - Recurrent neural networks
KW  - Correlation
DO  - 10.1109/ICRA.2019.8793582
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We tackle the long-term prediction of scene evolution in a complex downtown scenario for automated driving based on Lidar grid fusion and recurrent neural networks (RNNs). A bird's eye view of the scene, including occupancy and velocity, is fed as a sequence to a RNN which is trained to predict future occupancy. The nature of prediction allows generation of multiple hours of training data without the need of manual labeling. Thus, the training strategy and loss function are designed for long sequences of real-world data (unbalanced, continuously changing situations, false labels, etc.). The deep CNN architecture comprises convolutional long short-term memories (ConvLSTMs) to separate static from dynamic regions and to predict dynamic objects in future frames. Novel recurrent skip connections show the ability to predict small occluded objects, i.e. pedestrians, and occluded static regions. Spatio-temporal correlations between grid cells are exploited to predict multimodal future paths and interactions between objects. Experiments also quantity improvements to our previous network, a Monte Carlo approach, and literature.
ER  - 

TY  - CONF
TI  - Guaranteed Globally Optimal Planar Pose Graph and Landmark SLAM via Sparse-Bounded Sums-of-Squares Programming
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9306
EP  - 9312
AU  - J. G. Mangelson
AU  - J. Liu
AU  - R. M. Eustice
AU  - R. Vasudevan
PY  - 2019
KW  - graph theory
KW  - maximum likelihood estimation
KW  - mobile robots
KW  - navigation
KW  - nonlinear programming
KW  - path planning
KW  - polynomials
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - autonomous navigation
KW  - nonlinear optimization techniques
KW  - maximum likelihood estimate
KW  - robot trajectory
KW  - polynomial optimization programs
KW  - planar pose graph
KW  - landmark SLAM
KW  - sparse-bounded sums-of-squares programming
KW  - simultaneous localization and mapping
KW  - pose-graph SLAM problem
KW  - sum-of-squares convex
KW  - SOS convex
KW  - sparse bounded degree sum-of-squares optimization method
KW  - sparse-BSOS optimization method
KW  - Simultaneous localization and mapping
KW  - Optimization
KW  - Maximum likelihood estimation
KW  - Position measurement
KW  - Noise measurement
KW  - Transmission line matrix methods
DO  - 10.1109/ICRA.2019.8794454
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous navigation requires an accurate model or map of the environment. While dramatic progress in the prior two decades has enabled large-scale simultaneous localization and mapping (SLAM), the majority of existing methods rely on non-linear optimization techniques to find the maximum likelihood estimate (MLE) of the robot trajectory and surrounding environment. These methods are prone to local minima and are thus sensitive to initialization. Several recent papers have developed optimization algorithms for the Pose-Graph SLAM problem that can certify the optimality of a computed solution. Though this does not guarantee a priori that this approach generates an optimal solution, a recent extension has shown that when the noise lies within a critical threshold that the solution to the optimization algorithm is guaranteed to be optimal. To address the limitations of existing approaches, this paper illustrates that the Pose-Graph SLAM and Landmark SLAM can be formulated as polynomial optimization programs that are sum-of-squares (SOS) convex. This paper then describes how the Pose-Graph and Landmark SLAM problems can be solved to a global minimum without initialization regardless of noise level using the sparse bounded degree sum-of-squares (Sparse-BSOS) optimization method. Finally, the superior performance of the proposed approach when compared to existing SLAM methods is illustrated on graphs with several hundred nodes.
ER  - 

TY  - CONF
TI  - Trust Regions for Safe Sampling-Based Model Predictive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9313
EP  - 9319
AU  - M. Koch
AU  - M. Spies
AU  - M. Bürger
PY  - 2019
KW  - nonlinear dynamical systems
KW  - predictive control
KW  - robust control
KW  - sampling methods
KW  - stochastic systems
KW  - trust regions
KW  - safe sampling-based model predictive control
KW  - nonlinear control systems
KW  - complex dynamics
KW  - nonlinear dynamics
KW  - sampling-based MPC scheme
KW  - sampling based estimation
KW  - safe constraint satisfaction
KW  - probabilistic information
KW  - Monte Carlo methods
KW  - Trajectory
KW  - Predictive control
KW  - Optimization
KW  - Safety
KW  - Optimal control
DO  - 10.1109/ICRA.2019.8793846
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Guaranteeing safe constraint satisfaction in nonlinear control systems with uncertainty remains a major challenge for control. The most successful control method handling constraints under uncertainty has without doubt been model predictive control (MPC). In particular, recent sampling-based MPC methods have shown success in controlling stochastic systems with complex, nonlinear dynamics. The sampling-based schemes are appealing since they do not need strong assumptions on the underlying model, except that it can be forward simulated. At the same time, the lack of major assumptions on the models make the statement of safety or robustness guarantees difficult. However, the samples drawn during the control process inherently contain probabilistic information about these properties. In this paper, we formally describe the problem that results by adding chance constraints to a sampling-based MPC scheme. Furthermore, based on a variant of the Chernoff bound, we derive trust regions, in which the sampling based estimation of the safety constraint satisfies a specified quality. Finally, we present a case study in the navigation domain to demonstrate the applicability of the proposed approach.
ER  - 

TY  - CONF
TI  - Removing Leaking Corners to Reduce Dimensionality in Hamilton-Jacobi Reachability
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9320
EP  - 9326
AU  - D. Lee
AU  - M. Chen
AU  - C. J. Tomlin
PY  - 2019
KW  - collision avoidance
KW  - game theory
KW  - mobile robots
KW  - nonlinear dynamical systems
KW  - optimal control
KW  - reachability analysis
KW  - safety
KW  - dimensionality reduction
KW  - HJ computation
KW  - Hamilton-Jacobi reachability
KW  - robotic systems
KW  - nonlinear system dynamics
KW  - safety-preserving controllers
KW  - computational scalability
KW  - continuous state dimensions
KW  - computational burden
KW  - system decomposition methods
KW  - coupled HJ formulation
KW  - leaking corners removal
KW  - safety verification
KW  - computational scalability limits
KW  - vehicle obstacle avoidance problem
KW  - 5D car model
KW  - Safety
KW  - Dimensionality reduction
KW  - Optimal control
KW  - Level set
KW  - Collision avoidance
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793890
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Hamilton-Jacobi (HJ) reachability provides a flexible framework for the verification of safety in robotic systems: it accounts for nonlinear system dynamics and provides safety-preserving controllers. However, computational scalability limits its direct application to systems of less than five continuous state dimensions. To alleviate this computational burden, system decomposition methods have been proposed; however, safety guarantees are lost in situations involving “leaking corners which arise when there are conflicting controls between subsystems. In this paper, a coupled HJ formulation is presented, which addresses leaking corners and guarantees safety, while incorporating dimensionality reduction. We demonstrate our method in two examples, one of which is a vehicle obstacle avoidance problem with a 5D car model, whose HJ computation was previously considered to be intractable.
ER  - 

TY  - CONF
TI  - Control from the Cloud: Edge Computing, Services and Digital Shadow for Automation Technologies*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9327
EP  - 9333
AU  - C. Brecher
AU  - M. Buchsbaum
AU  - S. Storms
PY  - 2019
KW  - agile manufacturing
KW  - cloud computing
KW  - embedded systems
KW  - product development
KW  - production engineering computing
KW  - edge computing
KW  - digital shadow
KW  - agile product development
KW  - production systems
KW  - automation pyramid
KW  - interconnected cyber physical systems
KW  - adaptive process control
KW  - life cycle data management
KW  - Cloud computing
KW  - Automation
KW  - Computer architecture
KW  - Edge computing
KW  - Production
KW  - Process control
KW  - Manufacturing
DO  - 10.1109/ICRA.2019.8793488
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Due to agile product development, production systems have to be flexible and adaptable to meet high quality standards and a high productivity. As a result, set-up processes has to be shorter and more resilient because of the increasing number of variants. To meet future requirements, the processes need to be self-adaptive and reconfigurable at any time. Nowadays, a shift of the automation pyramid to interconnected cyber physical systems can be observed as well as emerging technologies as cloud and edge computing are introduced to production systems. These technologies in combination with the Digital Shadow, which provides information about all production assets, open up potential for an adaptive process control and an overall life cycle data management. For this, the Digital Shadow has to be used not only for the aggregation of data, but also for pushing data back into the system and to control the process. As a result, services in regard to an architecture based on edge computing as an enabling technology for an adaptive production together with the Digital Shadow are presented, implemented and discussed on the basis of an industrial use case.
ER  - 

TY  - CONF
TI  - Improving the Performance of Auxiliary Null Space Tasks via Time Scaling-Based Relaxation of the Primary Task
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9342
EP  - 9348
AU  - N. Mansfeld
AU  - Y. Michel
AU  - T. Bruckmann
AU  - S. Haddadin
PY  - 2019
KW  - path planning
KW  - position control
KW  - redundant manipulators
KW  - auxiliary null space tasks
KW  - task achievement
KW  - null space task
KW  - multiple prioritized tasks
KW  - time scaling-based relaxation
KW  - primary task
KW  - kinematic redundancy
KW  - robot manipulators
KW  - safety criterion
KW  - optimization criterion
KW  - constraint relaxation
KW  - time scaling schemes
KW  - DLR lightweight robot
KW  - KUKA lightweight robot
KW  - Task analysis
KW  - Null space
KW  - Robot kinematics
KW  - Trajectory
KW  - Jacobian matrices
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794225
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Kinematic redundancy enhances the dexterity and flexibility of robot manipulators. By exploiting the redundant degrees of freedom, auxiliary null space tasks can be carried out in addition to the primary task. Such auxiliary tasks are often formulated in terms of a performance or safety criterion that shall be minimized. If the optimization criterion, however, is defined in global terms, then it is directly affected by the primary task. As a consequence, the task achievement of the auxiliary task may be unnecessarily detrimented by the main task. In addition to modifying the primary task via constraint relaxation, a possible solution for improving the performance of the auxiliary task is to relax the primary task temporarily via time scaling. This gives the null space task more time for achieving its objective. In this paper, we propose several such time scaling schemes and verify their performance for a DLR/KUKA Lightweight Robot with one redundant degree of freedom. Finally, we extend the concept to multiple prioritized tasks and provide a simulation example.
ER  - 

TY  - CONF
TI  - Shape Memory Structures-Automated Design of Monolithic Soft Robot Structures with Pre-defined End Poses
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9357
EP  - 9362
AU  - Y. S. Krieger
AU  - S. Schiele
AU  - S. Detzel
AU  - C. Dietz
AU  - T. C. Lueth
PY  - 2019
KW  - actuators
KW  - intelligent robots
KW  - manipulators
KW  - rapid prototyping (industrial)
KW  - shape memory effects
KW  - three-dimensional printing
KW  - soft robotic systems
KW  - automated design process
KW  - monolithic soft robotic structures
KW  - pre-defined end poses
KW  - shape memory structures-automated design
KW  - monolithic soft robot structures
KW  - additive manufacturing methods
KW  - 3D-printable
KW  - actuators
KW  - Fasteners
KW  - Soft robotics
KW  - Three-dimensional printing
KW  - Task analysis
KW  - Shape
KW  - Buildings
DO  - 10.1109/ICRA.2019.8794035
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The particularly compliant and adaptable properties of soft robotic systems and structures offer enormous potential for use in unpredictable environments as well as for safe and interactive work in human environments. Therefore, new approaches for the design of soft robotic systems are constantly being introduced in this still emerging field of research. Through the use of additive manufacturing methods, it is possible to design systems specifically for an individual task. In this paper we present an approach for an automated design process for monolithic soft robotic structures that can assume pre-defined end poses. The idea thereby is to design simple individualizable systems that are 3D-printable and require a minimum number of actuators. Using the automated design process, we could already generate soft robotic systems for different applications which show promising properties.
ER  - 

TY  - CONF
TI  - A Novel Rotating Beam Link for Variable Stiffness Robotic Arms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9387
EP  - 9393
AU  - T. Morrison
AU  - C. Li
AU  - X. Pei
AU  - H. Su
PY  - 2019
KW  - actuators
KW  - beams (structures)
KW  - buckling
KW  - design engineering
KW  - elastic constants
KW  - industrial robots
KW  - servomotors
KW  - safety benefits
KW  - compact design
KW  - rotating beams
KW  - lateral stiffness ratio
KW  - parallel guided beams
KW  - beam roots
KW  - mechanics model
KW  - design concept
KW  - rotating beam link
KW  - variable stiffness robotic arms
KW  - servomotors
KW  - column buckling
KW  - Collision avoidance
KW  - Structural beams
KW  - Prototypes
KW  - Servomotors
KW  - Robot sensing systems
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793833
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a novel design concept for a robot arm link with variable stiffness. Variable stiffness links are intended to grant a robot the safety benefits of compliance and the performance benefits of stiffness. Our compact design actively modulates stiffness via parallel, rotating beams actuated by simple servomotors. It achieves a lateral stiffness ratio greater than ten with a minimum stiffness under 0.2 N/mm. Our novel design offers many benefits over existing variable stiffness link solutions in its compactness, simplicity, and speed of actuation. One challenge of this research lies in the mechanics modeling of variable stiffness. Here we propose a comprehensive mechanics model that considers mechanical compliances due to deflections of parallel guided beams, column buckling, and bearing at the beam roots. By comparing with experimental testing data, we show that our analytical model accurately predicts the lateral stiffness of the robotic link. This model can be used as a design tool in future iterations, including for scaling the design.
ER  - 

TY  - CONF
TI  - Mechanical Fourier Transform using an Array of Additively Manufactured Soft Whisker-like Sensors
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9410
EP  - 9415
AU  - A. Vaish
AU  - S. Y. Lee
AU  - P. V. y. Alvarado
PY  - 2019
KW  - damping
KW  - Fourier transforms
KW  - oscillators
KW  - polymers
KW  - rapid prototyping (industrial)
KW  - sensor arrays
KW  - three-dimensional printing
KW  - mixed-frequency signals
KW  - mechanical Fourier transform
KW  - damped oscillator system
KW  - additively manufactured soft whisker-like sensor array
KW  - single-step additive manufacturing approach
KW  - bioinspired soft whisker-like sensors
KW  - polymer based whisker-array
KW  - Sensor arrays
KW  - Resonant frequency
KW  - Fabrication
KW  - Robot sensing systems
KW  - Shafts
KW  - Power capacitors
DO  - 10.1109/ICRA.2019.8793957
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this study, a single-step additive manufacturing approach to fabricate an array of bio-inspired soft whisker-like sensors is presented. Each whisker is a damped oscillator system that is tuned to a different resonant frequency whose response is characterized through experimentation in an air medium. A 3 × 1 polymer based whisker-array is used to distinguish individual frequency components in mixed-frequency signals, achieving a form of “mechanical Fourier transform”.
ER  - 

TY  - CONF
TI  - Multi-Task Sensorization of Soft Actuators Using Prior Knowledge
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9416
EP  - 9421
AU  - V. Wall
AU  - O. Brock
PY  - 2019
KW  - deformation
KW  - dexterous manipulators
KW  - elastic constants
KW  - pneumatic actuators
KW  - sensors
KW  - sensorized actuators
KW  - soft actuators
KW  - multitask sensorization
KW  - sensor hardware
KW  - multitask method
KW  - RBO Hand 2
KW  - PneuFlex actuator
KW  - sensor placement
KW  - soft actuator
KW  - task-relevant deformations
KW  - soft robotic actuators
KW  - Task analysis
KW  - Actuators
KW  - Strain
KW  - Robot sensing systems
KW  - Layout
KW  - Capacitive sensors
DO  - 10.1109/ICRA.2019.8793697
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The space of all possible deformations of soft robotic actuators is extremely large. It is impossible to explicitly measure each internal degree of freedom, regardless of the number and types of sensors. It is, however, possible to measure a smaller subset of task-relevant deformations using only a few well-placed sensors. But for a different task, the soft actuator's deformation behavior might differ significantly. Instead of finding a new sensor placement for the new task, which would result in a separate hand for every task, we propose a method that maintains the original sensors and uses prior knowledge about each task to extend the applicability of the existing sensorized actuators to new tasks. We demonstrate our approach by the example of a PneuFlex actuator of the RBO Hand 2. When sensorizing the actuator for a single task, the sensor model does not transfer well to other tasks. Using our multi-task method, we train new sensor models that use prior knowledge about the tasks. The new models improve measurement accuracy for the new tasks without having to change the sensor hardware.
ER  - 

TY  - CONF
TI  - Self-Modifying Morphology Experiments with DyRET: Dynamic Robot for Embodied Testing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9446
EP  - 9452
AU  - T. F. Nygaard
AU  - C. P. Martin
AU  - J. Torresen
AU  - K. Glette
PY  - 2019
KW  - adaptive systems
KW  - legged locomotion
KW  - robot dynamics
KW  - self-reconfiguration
KW  - quadruped robots
KW  - DyRET
KW  - embodied testing
KW  - dynamic robot morphology
KW  - locomotion modes
KW  - self-reconfigurable morphology
KW  - servo supply voltage
KW  - four-legged robot
KW  - self-modifying morphology experiments
KW  - uncontrolled outdoor environments
KW  - Legged locomotion
KW  - Morphology
KW  - Servomotors
KW  - Computer architecture
KW  - Robot sensing systems
KW  - Switches
DO  - 10.1109/ICRA.2019.8793663
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - If robots are to become ubiquitous, they will need to be able to adapt to complex and dynamic environments. Robots that can adapt their bodies while deployed might be flexible and robust enough to meet this challenge. Previous work on dynamic robot morphology has focused on simulation, combining simple modules, or switching between locomotion modes. Here, we present an alternative approach: a self-reconfigurable morphology that allows a single four-legged robot to actively adapt the length of its legs to different environments. We report the design of our robot, as well as the results of a study that verifies the performance impact of self-reconfiguration. This study compares three different control and morphology pairs under different levels of servo supply voltage in the lab. We also performed preliminary tests in different uncontrolled outdoor environments to see if changes to the external environment supports our findings in the lab. Our results show better performance with an adaptable body, lending evidence to the value of self-reconfiguration for quadruped robots.
ER  - 

TY  - CONF
TI  - Experimental Validation of High-Efficiency Hydraulic Direct-Drive System for a Biped Humanoid Robot—Comparison with Valve-Based Control System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9453
EP  - 9458
AU  - J. Shimizu
AU  - T. Otani
AU  - H. Mizukami
AU  - K. Hashimoto
AU  - A. Takanishi
PY  - 2019
KW  - humanoid robots
KW  - hydraulic systems
KW  - legged locomotion
KW  - position control
KW  - robot dynamics
KW  - valves
KW  - high-efficiency hydraulic direct-drive system
KW  - biped humanoid robot-comparison
KW  - high-power large electrical motors
KW  - mechanical transmission systems
KW  - valve-based control system
KW  - position-following capability
KW  - energy consumption
KW  - Valves
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Actuators
KW  - Velocity control
DO  - 10.1109/ICRA.2019.8793787
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Biped robots require substantial amounts of power alternately on each leg while walking, hopping, and running. However, it is difficult to mount high-power large electrical motors in conventional mechanical transmission systems owing to spatial limitations. A hydraulic direct-drive system is proposed in which the size of the motor in each leg can be reduced by sharing the motor outputs between the legs. In this paper, the hydraulic direct-drive system is evaluated in an actual hydraulic system. Velocity followability, excellent energy saving, and virtually perfect position tracking are achieved with the proposed system. The results of performance comparison with a valve-based control system show that energy consumption is controlled and good position-following capability is achieved using the proposed system.
ER  - 

TY  - CONF
TI  - Experimental Demonstration of High-Performance Robotic Balancing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9459
EP  - 9465
AU  - J. J. M. Driessen
AU  - A. E. Gkikakis
AU  - R. Featherstone
AU  - B. R. P. Singh
PY  - 2019
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - pendulums
KW  - wheels
KW  - balance control
KW  - fast movements
KW  - narrow support
KW  - reaction wheel pendulum
KW  - motion commands
KW  - high-performance robotic balancing
KW  - Mobile robots
KW  - Robot kinematics
KW  - Wheels
KW  - Robot sensing systems
KW  - Poles and zeros
KW  - Acceleration
DO  - 10.1109/ICRA.2019.8794447
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the first practical demonstration of a recently developed theory of balance control that aims to achieve high performance in the sense of allowing a robot to make large, fast movements while maintaining its balance on a narrow support. This theory includes a simple method of leaning in anticipation of future motion commands, which is largely responsible for the high performance. The experiments reported here use a robot acting as a reaction wheel pendulum, and they test only the 2-D version of the theory. The results show that the balance controller's performance in practice closely resembles its theoretical performance. This paper also presents a simple yet accurate balance offset observer that measures the difference between true and estimated balanced configurations.
ER  - 

TY  - CONF
TI  - OpenRoACH: A Durable Open-Source Hexapedal Platform with Onboard Robot Operating System (ROS)
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9466
EP  - 9472
AU  - L. Wang
AU  - Y. Yang
AU  - G. Correa
AU  - K. Karydis
AU  - R. S. Fearing
PY  - 2019
KW  - accelerometers
KW  - cameras
KW  - control engineering computing
KW  - gyroscopes
KW  - legged locomotion
KW  - operating systems (computers)
KW  - durable open-source hexapedal platform
KW  - hexapedal robot
KW  - onboard single-board computer
KW  - laser cutter
KW  - Beacon sensors
KW  - color vision sensors
KW  - linescan sensors
KW  - cameras
KW  - legged robot
KW  - continuous walking burn-ins
KW  - static payload
KW  - dynamic payload
KW  - robot operating system
KW  - Legged locomotion
KW  - DC motors
KW  - Sensors
KW  - Clamps
KW  - Laser beam cutting
KW  - Shafts
DO  - 10.1109/ICRA.2019.8794042
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - OpenRoACH is a 15-cm 200-gram self-contained hexapedal robot with an onboard single-board computer. To our knowledge, it is the smallest legged robot with the capability of running the Robot Operating System (ROS) onboard. The robot is fully open sourced, uses accessible materials and off-the-shelf electronic components, can be fabricated with benchtop fast-prototyping machines such as a laser cutter and a 3D printer, and can be assembled by one person within two hours. Its sensory capacity has been tested with gyroscopes, accelerometers, Beacon sensors, color vision sensors, linescan sensors and cameras. It is low-cost within $150 including structure materials, motors, electronics, and a battery. The capabilities of OpenRoACH are demonstrated with multi-surface walking and running, 24-hour continuous walking burn-ins, carrying 200-gram dynamic payloads and 800-gram static payloads, and ROS control of steering based on camera feedback. Information and files related to mechanical design, fabrication, assembly, electronics, and control algorithms are all publicly available on https://wiki.eecs.berkeley.edu/biomimetics/Main/OpenRoACH.
ER  - 

TY  - CONF
TI  - Sensorless Force Control of Automated Grinding/Deburring Using an Adjustable force regulation mechanism
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9489
EP  - 9495
AU  - Y. Kuo
AU  - S. Huang
AU  - C. Lan
PY  - 2019
KW  - deburring
KW  - end effectors
KW  - feedback
KW  - force control
KW  - force sensors
KW  - geometry
KW  - grinding
KW  - grinding machines
KW  - industrial robots
KW  - machine tool spindles
KW  - polishing
KW  - position control
KW  - prototypes
KW  - quality control
KW  - sensorless force control
KW  - controller feedback
KW  - constant contact force
KW  - force regulation mechanism
KW  - grinding spindle tool
KW  - industrial grinding-deburring operations
KW  - multiaxis force sensor
KW  - polishing quality
KW  - geometry
KW  - grinder prototype
KW  - compliant mechanism
KW  - end-effector
KW  - industrial robots
KW  - Frequency modulation
KW  - Force
KW  - Conferences
KW  - Automation
KW  - Indexes
KW  - Deburring
KW  - Force control
KW  - Automated deburring and polishing
KW  - force control
KW  - constant force
KW  - zero stiffness
KW  - compliant mechanism
DO  - 10.1109/ICRA.2019.8794058
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Controlling the contact force on workpieces has been a challenging task for industrial grinding/deburring operations. Its realization often requires a grinding spindle with a multi-axis force sensor and controller feedback. The spindle needs to frequently vary its position in order to maintain a constant contact force. The use of sensors and control is costly and introduces extra complexity for grinding tools. To improve the polishing quality of handling workpieces of irregular contours, this paper presents a novel force regulation mechanism (FRM) to be installed on grinding tools. Without using additional sensors and control, the FRM can passively produce an adjusTable NORMAL Contact force between the tooltip and workpiece of various geometry. the spindle does not have to move to regulate the contact force. together with a simple grinder which is much less expensive, this approach offers a more attractive solution in terms of cost and complexity. in this paper, the design concept and simulation results are presented and discussed. a prototype of a grinder with the proposed FRM is illustrated to demonstrate the effectiveness and accuracy of force regulation. this novel mechanism is expected to serve as a reliable alternative for industrial grinding/deburring operation.
ER  - 

TY  - CONF
TI  - Constrained Feedback Control by Prioritized Multi-objective Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9496
EP  - 9501
AU  - L. Li
AU  - D. J. Braun
PY  - 2019
KW  - closed loop systems
KW  - feedback
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - position control
KW  - control inputs
KW  - operational space inverse dynamics control
KW  - constrained prioritized multiobjective optimization-base control formulation
KW  - dynamic-model-free prioritized feedback control formulation
KW  - combined inverse dynamics impedance controller
KW  - planar anthropometric biped robot
KW  - stable locomotion
KW  - Task analysis
KW  - Dynamics
KW  - Impedance
KW  - Optimization
KW  - Feedback control
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8794376
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Prioritized multi-objective optimization has been widely used within the operational space inverse dynamics control framework. In this paper, we present a constrained prioritized multi-objective optimization-base control formulation that extends to impedance control, including the `simple' impedance controller, which does not require the dynamic model. The main contribution of this paper is the dynamic-model-free prioritized feedback control formulation which encompasses arbitrary number of priority levels and takes the saturation constraints on the control inputs rigorously into account. The utility of the proposed formulation is demonstrated by a combined inverse dynamics impedance controller used to simulate stable locomotion of a planar anthropometric biped robot.
ER  - 

TY  - CONF
TI  - Exploitation of Environment Support Contacts for Manipulation Effort Reduction of a Robot Arm
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9502
EP  - 9508
AU  - C. Fang
AU  - N. Kashiri
AU  - G. F. Rigano
AU  - A. Ajoudani
AU  - N. G. Tsagarakis
PY  - 2019
KW  - compliance control
KW  - control system synthesis
KW  - end effectors
KW  - force control
KW  - humanoid robots
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - optimal contact force control
KW  - support plane
KW  - contact control point
KW  - three-level hierarchical compliance controller
KW  - nonend-effector support contact
KW  - wrist level manipulation
KW  - upper arm
KW  - elbow joint
KW  - arm joints
KW  - loco-manipulation tasks
KW  - environment constraints
KW  - robot arm
KW  - manipulation effort reduction
KW  - environment support contacts
KW  - control scheme
KW  - interaction forces
KW  - impedance control
KW  - Task analysis
KW  - Robot kinematics
KW  - Manipulators
KW  - Optimization
KW  - Planning
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2019.8794119
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humans commonly exploit interaction with the environment constraints to assist the execution of the loco-manipulation tasks they perform. One particular example is the exploration of contacts during manipulation to relax the loading of those arm joints that are not directly involved in the generation of the manipulation motions and forces, e.g. establishing a contact with the elbow joint to reduce the effort of the upper arm while executing wrist level manipulation. In this paper, we shall explore the possibility of actively (a) utilizing the environment for a non-end-effector support contact towards reducing the joints efforts during manipulation tasks. This is achieved by our proposed control scheme with a three-level hierarchical compliance controller. The highest priority task is assigned to an impedance control that regulates the interaction at the contact control point on the arm in the normal direction of the support plane prior to contact, and is switched to an optimal contact force control for minimizing the joint effort after the contact is built. The second priority task is an impedance control at the same point in the tangential directions of the plane to stabilize the contact. In the end, an impedance behavior at the end-effector is designed to deal with the interaction forces required by the manipulation tasks. The efficacy of the proposed control scheme was corroborated by simulations and experiments, where significant joint effort reduction was observed.
ER  - 

TY  - CONF
TI  - A Coordinate-based Approach for Static Balancing and Walking Control of Compliantly Actuated Legged Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9509
EP  - 9515
AU  - D. Lakatos
AU  - Y. Federigi
AU  - T. Gumpert
AU  - B. Henze
AU  - M. Hermann
AU  - F. Loeffl
AU  - F. Schmidt
AU  - D. Seidel
AU  - A. Albu-Schäffer
PY  - 2019
KW  - actuators
KW  - elasticity
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - position control
KW  - coordinate-based approach
KW  - static balancing
KW  - elastically actuated legged robots
KW  - motor positions
KW  - bijective relation
KW  - link positions
KW  - static external forces
KW  - fully determined system
KW  - vertical foot positions
KW  - walking task
KW  - imposed constraints
KW  - COM
KW  - compliantly actuated legged robots
KW  - Legged locomotion
KW  - Task analysis
KW  - Robot kinematics
KW  - Actuators
KW  - Elasticity
KW  - Force
DO  - 10.1109/ICRA.2019.8793920
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper addresses the static balancing and walking of elastically actuated legged robots. The control is realized by commanding the motor positions only and exploiting the bijective relation between motor and link positions at equilibrium under static external forces. The approach is formulated in a quite general framework first. The main implementation contribution is the definition of a body coordinate system and of an appropriate set of constraints, which leads to a fully determined system of equations. In addition to the desired COM and the vertical foot positions, which are defined by the walking task and the terrain, the imposed constraints are related to distances between individual legs. The controller is experimentally validated on a compliantly actuated quadruped.
ER  - 

TY  - CONF
TI  - Joint kinematic configuration influence on the passivity of an impedance-controlled robotic leg
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9516
EP  - 9522
AU  - F. Y. G. Higa
AU  - G. J. G. Lahr
AU  - G. A. P. Caurin
AU  - T. Boaventura
PY  - 2019
KW  - actuators
KW  - force control
KW  - legged locomotion
KW  - position control
KW  - robot kinematics
KW  - stability
KW  - joint kinematic configuration influence
KW  - impedance-controlled robotic leg
KW  - legged robots
KW  - impedance controller
KW  - inner force loop gains
KW  - passivity conditions
KW  - joint configurations
KW  - leg workspace
KW  - actuation bandwidth
KW  - passive impedance
KW  - Z-width diagram
KW  - Nyquist plot
KW  - Legged locomotion
KW  - Impedance
KW  - Jacobian matrices
KW  - Stability analysis
KW  - Damping
KW  - Torque
DO  - 10.1109/ICRA.2019.8794094
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Although the design of legged robots may be dependent on the application, all of them share the need to safely deal with physical interaction with the environment in every step they take. Impedance controllers have been applied with success to handle contact, and some authors applied the concept of passivity to guarantee stability during the interaction. Whereas previous studies on the passivity of legged robots considered aspects such as inner force loop gains and actuation bandwidth influence on the Z-width (i.e. the range of renderable passive impedances), they did not take into account the role of the kinematic configuration of the leg on the stability of the interaction. Thus, in this work we present a systematic analysis of the effects of joint positions on the passivity conditions of a robotic leg and show that this is a very relevant aspect that may seriously affect the stability and passivity of an impedance controller. By analyzing a linearized model of the leg via its Nyquist plots and the respective Z-width diagrams, we were able to determine what joint configurations within the leg workspace are more suitable to physically interact with the environment or people.
ER  - 

TY  - CONF
TI  - Towards Robot Interaction Autonomy: Explore, Identify, and Interact
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9523
EP  - 9529
AU  - P. Balatti
AU  - D. Kanoulas
AU  - N. G. Tsagarakis
AU  - A. Ajoudani
PY  - 2019
KW  - adaptive control
KW  - agricultural robots
KW  - damping
KW  - human-robot interaction
KW  - mobile robots
KW  - robot dynamics
KW  - self-adjusting systems
KW  - context-aware
KW  - adaptive interaction
KW  - self-tuning impedance controller
KW  - robot quasistatic parameters
KW  - robot sensory data
KW  - vision module
KW  - robot interaction autonomy
KW  - robot sensory vision
KW  - autonomous robot behaviours
KW  - stiffness
KW  - damping
KW  - agricultural task
KW  - Impedance
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Task analysis
KW  - Damping
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794428
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Nowadays, robots are expected to enter in various application scenarios and interact with unknown and dynamically changing environments. This highlights the need for creating autonomous robot behaviours to explore such environments, identify their characteristics and adapt, and build knowledge for future interactions. To respond to this need, in this paper we present a novel framework that integrates multiple components to achieve a context-aware and adaptive interaction between the robot and uncertain environments. The core of this framework is a novel self-tuning impedance controller that regulates robot quasi-static parameters, i.e., stiffness and damping, based on the robot sensory data and vision. The tuning of the parameters is achieved only in the direction(s) of interaction or movement, by distinguishing expected interactions from external disturbances. A vision module is developed to recognize the environmental characteristics and to associate them to the previously/newly identified interaction parameters, with the robot always being able to adapt to the new changes or unexpected situations. This enables a faster robot adaptability, starting from better initial interaction parameters. The framework is evaluated experimentally in an agricultural task, where the robot effectively interacts with various deformable environments.
ER  - 

TY  - CONF
TI  - Personalized Online Learning of Whole-Body Motion Classes using Multiple Inertial Measurement Units
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9530
EP  - 9536
AU  - V. Losing
AU  - T. Yoshikawa
AU  - M. Hasenjaeger
AU  - B. Hammer
AU  - H. Wersing
PY  - 2019
KW  - body sensor networks
KW  - feature extraction
KW  - image classification
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - personalized online learning
KW  - whole-body motion classes
KW  - online action classification
KW  - machine learning applications
KW  - personal behavior patterns
KW  - offline average user models
KW  - personalized models
KW  - motion sequences
KW  - inertial measuring units
KW  - Adaptation models
KW  - Task analysis
KW  - Sensors
KW  - Computational modeling
KW  - Data models
KW  - Hardware
KW  - Training
DO  - 10.1109/ICRA.2019.8794251
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Online action classification is an important field of research, enabling the particularly interesting application scenario of controlling wearable devices which actively support the user's motions. The majority of machine learning applications of real-world systems are based on pre-trained average-user models without any personalization. Our long-term goal is to provide a system that adapts to its user's personal behavior patterns on the fly and in real-time. Ideally, we want to initiate a continuous collaboration between the system and the user where both alternatively adjust to each other to maximize the system's utility. Such tasks are not feasible with static models. In this paper, we investigate the potential and benefits of personalized online learning in the task of online action classification. We record motion sequences of different subjects wearing the Xsens bodysuit, which incorporates multiple inertial measuring units, enabling a fine-grained discrimination of motions. On this basis, we first perform a feature selection, showing that only a few sensors are necessary to achieve a high classification performance. Subsequently, we compare the recognition capabilities of offline average user models against personalized models trained in an online way. Our experiments conclude that personalized models require only few data to outperform average user systems and are particularly valuable for applications with limited computational hardware which rely on the raw sensor inputs only.
ER  - 

TY  - CONF
TI  - Knowledge is Never Enough: Towards Web Aided Deep Open World Recognition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9537
EP  - 9543
AU  - M. Mancini
AU  - H. Karaoguz
AU  - E. Ricci
AU  - P. Jensfelt
AU  - B. Caputo
PY  - 2019
KW  - data mining
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - deep learning architecture
KW  - deep network
KW  - deep extension
KW  - nonparametric model
KW  - autonomous mining
KW  - robot platform
KW  - deep open world recognition
KW  - visual knowledge gaps
KW  - open set recognition
KW  - visual modules
KW  - Robots
KW  - Visualization
KW  - Training
KW  - Feature extraction
KW  - Task analysis
KW  - Artificial neural networks
KW  - Semantics
DO  - 10.1109/ICRA.2019.8793803
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While today's robots are able to perform sophisticated tasks, they can only act on objects they have been trained to recognize. This is a severe limitation: any robot will inevitably see new objects in unconstrained settings, and thus will always have visual knowledge gaps. However, standard visual modules are usually built on a limited set of classes and are based on the strong prior that an object must belong to one of those classes. Identifying whether an instance does not belong to the set of known categories (i.e. open set recognition), only partially tackles this problem, as a truly autonomous agent should be able not only to detect what it does not know, but also to extend dynamically its knowledge about the world. We contribute to this challenge with a deep learning architecture that can dynamically update its known classes in an end-to-end fashion. The proposed deep network, based on a deep extension of a non-parametric model, detects whether a perceived object belongs to the set of categories known by the system and learns it without the need to retrain the whole system from scratch. Annotated images about the new category can be provided by an `oracle' (i.e. human supervision), or by autonomous mining of the Web. Experiments on two different databases and on a robot platform demonstrate the promise of our approach.
ER  - 

TY  - CONF
TI  - Inferring Robot Morphology from Observation of Unscripted Movement
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9544
EP  - 9551
AU  - N. Bell
AU  - B. Seipp
AU  - J. Tim Oates
AU  - C. Matuszek
PY  - 2019
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - recurrent neural nets
KW  - robot vision
KW  - low-cost RGB-D camera output
KW  - task sharing
KW  - shared communication protocol
KW  - centralized planner
KW  - shared action
KW  - kinematic model
KW  - large-scale data
KW  - RNN-based methods
KW  - unscripted movement observation
KW  - robots morphological structure
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Three-dimensional displays
KW  - Morphology
KW  - Task analysis
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8794211
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Task sharing between heterogeneous robots currently requires a priori capability knowledge, a shared communication protocol, or a centralized planner. However, in practice, when two robots are brought together, the effort required to construct shared action and structure models can be significant. In this paper, we describe our approach to determining the kinematic model of a robot based purely on observation of unscripted movement. We describe construction of large-scale data simulating low-cost RGB-D camera output, and application of two different RNN-based methods to the learning problem. Our results suggest that this is an efficient and effective way to determine a robot's morphological structure without requiring communication or pre-existing knowledge of its capabilities.
ER  - 

TY  - CONF
TI  - The H3D Dataset for Full-Surround 3D Multi-Object Detection and Tracking in Crowded Urban Scenes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9552
EP  - 9557
AU  - A. Patil
AU  - S. Malla
AU  - H. Gang
AU  - Y. Chen
PY  - 2019
KW  - object detection
KW  - object tracking
KW  - optical radar
KW  - optical scanners
KW  - road traffic
KW  - stereo image processing
KW  - large-scale 3D point cloud dataset
KW  - crowded urban scenes
KW  - Honda Research Institute 3D Dataset
KW  - tracking dataset
KW  - 3D LiDAR scanner
KW  - highly interactive traffic scenes
KW  - H3D dataset
KW  - Three-dimensional displays
KW  - Automobiles
KW  - Laser radar
KW  - Labeling
KW  - Robot sensing systems
KW  - Global Positioning System
KW  - Object detection
DO  - 10.1109/ICRA.2019.8793925
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - 3D multi-object detection and tracking are crucial for traffic scene understanding. However, the community pays less attention to these areas due to the lack of a standardized benchmark dataset to advance the field. Moreover, existing datasets (e.g., KITTI [1]) do not provide sufficient data and labels to tackle challenging scenes where highly interactive and occluded traffic participants are present. To address the issues, we present the Honda Research Institute 3D Dataset (H3D), a large-scale full-surround 3D multi-object detection and tracking dataset collected using a 3D LiDAR scanner. H3D comprises of 160 crowded and highly interactive traffic scenes with a total of 1 million labeled instances in 27,721 frames. With unique dataset size, rich annotations, and complex scenes, H3D is gathered to stimulate research on full-surround 3D multi-object detection and tracking. To effectively and efficiently annotate a large-scale 3D point cloud dataset, we propose a labeling methodology to speed up the overall annotation cycle. A standardized benchmark is created to evaluate full-surround 3D multi-object detection and tracking algorithms. 3D object detection and tracking algorithms are trained and tested on H3D. Finally, sources of errors are discussed for the development of future algorithms.
ER  - 

TY  - CONF
TI  - Joint Learning of Instance and Semantic Segmentation for Robotic Pick-and-Place with Heavy Occlusions in Clutter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9558
EP  - 9564
AU  - K. Wada
AU  - K. Okada
AU  - M. Inaba
PY  - 2019
KW  - feature extraction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - robot vision
KW  - image-level reasoning
KW  - joint learning model
KW  - visible region masks
KW  - occluded region masks
KW  - instance occlusion segmentation
KW  - semantic occlusion segmentation
KW  - instance segmentation model
KW  - feature extractor
KW  - robotic pick-and-place tasks
KW  - Feature extraction
KW  - Image segmentation
KW  - Semantics
KW  - Task analysis
KW  - Robots
KW  - Cognition
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8793783
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present joint learning of instance and semantic segmentation for visible and occluded region masks. Sharing the feature extractor with instance occlusion segmentation, we introduce semantic occlusion segmentation into the instance segmentation model. This joint learning fuses the instance-and image-level reasoning of the mask prediction on the different segmentation tasks, which was missing in the previous work of learning instance segmentation only (instance-only). In the experiments, we evaluated the proposed joint learning comparing the instance-only learning on the test dataset. We also applied the joint learning model to 2 different types of robotic pick-and-place tasks (random and target picking) and evaluated its effectiveness to achieve real-world robotic tasks.
ER  - 

TY  - CONF
TI  - Weakly Supervised Recognition of Surgical Gestures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9565
EP  - 9571
AU  - B. v. Amsterdam
AU  - H. Nakawala
AU  - E. D. Momi
AU  - D. Stoyanov
PY  - 2019
KW  - feature extraction
KW  - Gaussian processes
KW  - gesture recognition
KW  - image classification
KW  - image motion analysis
KW  - image representation
KW  - image segmentation
KW  - medical image processing
KW  - medical robotics
KW  - robot kinematics
KW  - surgery
KW  - trajectory control
KW  - unsupervised learning
KW  - action recognition
KW  - surgical trajectories
KW  - ground truth annotations
KW  - gesture recognition
KW  - surgical demonstrations
KW  - kinematic trajectories
KW  - surgical robots
KW  - surgical gestures
KW  - automatic segmentation
KW  - surgical skill assessment
KW  - surgical automation
KW  - unsupervised learning methods
KW  - action units
KW  - supervised recognition approaches
KW  - GMM-based algorithm
KW  - task-agnostic initialization methods
KW  - Needles
KW  - Trajectory
KW  - Kinematics
KW  - Measurement
KW  - Tools
KW  - Task analysis
KW  - Robots
KW  - Classification
KW  - Gaussian Mixture Models
KW  - robotic surgery
KW  - kinematics
KW  - surgical gesture recognition
DO  - 10.1109/ICRA.2019.8793696
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Kinematic trajectories recorded from surgical robots contain information about surgical gestures and potentially encode cues about surgeon's skill levels. Automatic segmentation of these trajectories into meaningful action units could help to develop new metrics for surgical skill assessment as well as to simplify surgical automation. State-of-the-art methods for action recognition relied on manual labelling of large datasets, which is time consuming and error prone. Unsupervised methods have been developed to overcome these limitations. However, they often rely on tedious parameter tuning and perform less well than supervised approaches, especially on data with high variability such as surgical trajectories. Hence, the potential of weak supervision could be to improve unsupervised learning while avoiding manual annotation of large datasets. In this paper, we used at a minimum one expert demonstration and its ground truth annotations to generate an appropriate initialization for a GMM-based algorithm for gesture recognition. We showed on real surgical demonstrations that the latter significantly outperforms standard task-agnostic initialization methods. We also demonstrated how to improve the recognition accuracy further by redefining the actions and optimising the inputs.
ER  - 

TY  - CONF
TI  - Visual-Inertial Navigation: A Concise Review
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9572
EP  - 9582
AU  - G. Huang
PY  - 2019
KW  - augmented reality
KW  - image sensors
KW  - inertial navigation
KW  - mobile computing
KW  - mobile robots
KW  - robot vision
KW  - SLAM (robots)
KW  - inertial sensors
KW  - visual sensors
KW  - visual-inertial navigation systems
KW  - mobile augmented reality
KW  - aerial navigation
KW  - autonomous driving
KW  - VINS
KW  - SLAM
KW  - Cameras
KW  - Visualization
KW  - Navigation
KW  - Sensors
KW  - Acceleration
KW  - Noise measurement
KW  - Fuses
DO  - 10.1109/ICRA.2019.8793604
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - As inertial and visual sensors are becoming ubiquitous, visual-inertial navigation systems (VINS) have prevailed in a wide range of applications from mobile augmented reality to aerial navigation to autonomous driving, in part because of the complementary sensing capabilities and the decreasing costs and size of the sensors. In this paper, we survey thoroughly the research efforts taken in this field and strive to provide a concise but complete review of the related work - which is unfortunately missing in the literature while being greatly demanded by researchers and engineers - in the hope to accelerate the VINS research and beyond in our society as a whole.
ER  - 

TY  - CONF
TI  - Building a Winning Self-Driving Car in Six Months
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9583
EP  - 9589
AU  - K. Burnett
AU  - A. Schimpe
AU  - S. Samavi
AU  - M. Gridseth
AU  - C. W. Liu
AU  - Q. Li
AU  - Z. Kroeze
AU  - A. P. Schoellig
PY  - 2019
KW  - automobiles
KW  - closed loop systems
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - basic autonomy features
KW  - robust algorithms
KW  - multisensor visual localization solution
KW  - winning self-driving car
KW  - SAE AutoDrive Challenge
KW  - Level 4 autonomous vehicle
KW  - Yuma
KW  - Arizona
KW  - Zeus' complete system architecture
KW  - CPU
KW  - closed-loop performance
KW  - Cameras
KW  - Real-time systems
KW  - Navigation
KW  - Computer architecture
KW  - Laser radar
KW  - Visualization
KW  - Systems architecture
DO  - 10.1109/ICRA.2019.8794029
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The SAE AutoDrive Challenge is a three-year competition to develop a Level 4 autonomous vehicle by 2020. The first set of challenges were held in April of 2018 in Yuma, Arizona. Our team (aUToronto/Zeus) placed first. In this paper, we describe Zeus' complete system architecture and specialized algorithms that enabled us to win. We show that it is possible to develop a vehicle with basic autonomy features in just six months relying on simple, robust algorithms. We do not make use of a prior map. Instead, we have developed a multi-sensor visual localization solution. All the algorithms in the paper run in real-time using CPUs only. We also highlight the closed-loop performance of the system in detail in several experiments.
ER  - 

TY  - CONF
TI  - Hierarchical Game-Theoretic Planning for Autonomous Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9590
EP  - 9596
AU  - J. F. Fisac
AU  - E. Bronstein
AU  - E. Stefansson
AU  - D. Sadigh
AU  - S. S. Sastry
AU  - A. D. Dragan
PY  - 2019
KW  - decision making
KW  - game theory
KW  - path planning
KW  - remotely operated vehicles
KW  - road traffic control
KW  - road vehicles
KW  - trajectory control
KW  - game-theoretic trajectory planning algorithm
KW  - trajectory optimization
KW  - dynamic games
KW  - autonomous driving technology
KW  - drivers
KW  - dynamic game theory
KW  - hierarchical game-theoretic planning
KW  - human driver
KW  - autonomous vehicle
KW  - planning horizon
KW  - simplified information structure
KW  - short-horizon tactical game
KW  - long-horizon strategic game
KW  - Vehicle dynamics
KW  - Autonomous vehicles
KW  - Planning
KW  - Games
KW  - Trajectory
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794007
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The actions of an autonomous vehicle on the road affect and are affected by those of other drivers, whether overtaking, negotiating a merge, or avoiding an accident. This mutual dependence, best captured by dynamic game theory, creates a strong coupling between the vehicle's planning and its predictions of other drivers' behavior, and constitutes an open problem with direct implications on the safety and viability of autonomous driving technology. Unfortunately, dynamic games are too computationally demanding to meet the real-time constraints of autonomous driving in its continuous state and action space. In this paper, we introduce a novel game-theoretic trajectory planning algorithm for autonomous driving, that enables real-time performance by hierarchically decomposing the underlying dynamic game into a long-horizon “strategic” game with simplified dynamics and full information structure, and a short-horizon “tactical” game with full dynamics and a simplified information structure. The value of the strategic game is used to guide the tactical planning, implicitly extending the planning horizon, pushing the local trajectory optimization closer to global solutions, and, most importantly, quantitatively accounting for the autonomous vehicle and the human driver's ability and incentives to influence each other. In addition, our approach admits non-deterministic models of human decision-making, rather than relying on perfectly rational predictions. Our results showcase richer, safer, and more effective autonomous behavior in comparison to existing techniques.
ER  - 

TY  - CONF
TI  - IceVisionSet: lossless video dataset collected on Russian winter roads with traffic sign annotations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9597
EP  - 9602
AU  - A. L. Pavlov
AU  - P. A. Karpyshev
AU  - G. V. Ovchinnikov
AU  - I. V. Oseledets
AU  - D. Tsetserukou
PY  - 2019
KW  - cameras
KW  - computer vision
KW  - driver information systems
KW  - image recognition
KW  - road traffic
KW  - visual perception
KW  - camera settings
KW  - weather conditions
KW  - traffic sign images
KW  - Russian winter roads
KW  - Russian traffic code
KW  - IceVisionSet
KW  - lossless video dataset
KW  - traffic sign annotations
KW  - autonomous vehicles
KW  - traffic signs
KW  - image data
KW  - computer vision systems
KW  - Cameras
KW  - Image coding
KW  - Tools
KW  - Roads
KW  - Automobiles
KW  - Autonomous vehicles
KW  - Computer vision
DO  - 10.1109/ICRA.2019.8794341
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Ability of autonomous vehicles to operate in complex dynamic environments requires, among other things, fast and accurate perception of surroundings, which includes recognition and tracking of traffic signs.For development and testing of modern sophisticated computer vision systems large and diverse datasets are of the major importance. To test the robustness of algorithms, image data with different moving speeds, camera settings, lighting and weather conditions are especially important.In this work we present a comprehensive, lifelike dataset of traffic sign images collected on the Russian winter roads in varying conditions, which include different weather, camera exposure, illumination and moving speeds. The dataset was annotated in accordance with the Russian traffic code. Annotation results and images are published under open CC BY 4.0 license and can be downloaded from the project website: http://oscar.skoltech.ru/.
ER  - 

TY  - CONF
TI  - Integrated UWB-Vision Approach for Autonomous Docking of UAVs in GPS-denied Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9603
EP  - 9609
AU  - T. Nguyen
AU  - T. H. Nguyen
AU  - M. Cao
AU  - Z. Qiu
AU  - L. Xie
PY  - 2019
KW  - autonomous aerial vehicles
KW  - computer vision
KW  - displacement measurement
KW  - Global Positioning System
KW  - mobile robots
KW  - robot vision
KW  - unmanned aerial vehicles
KW  - ultrawideband ranging sensor
KW  - approaching phase
KW  - autonomous approaching landing capabilities
KW  - vision-based techniques
KW  - GPS-denied environments
KW  - autonomous docking
KW  - integrated UWB-vision approach
KW  - vision-derived poses
KW  - UWB measurements
KW  - onboard vision system
KW  - relative displacement measurements
KW  - UAV relative
KW  - Displacement measurement
KW  - Unmanned aerial vehicles
KW  - Distance measurement
KW  - Visualization
KW  - Optical variables measurement
KW  - Optical feedback
KW  - Optical saturation
DO  - 10.1109/ICRA.2019.8793851
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Though vision-based techniques have become quite popular for autonomous docking of Unmanned Aerial Vehicles (UAVs), due to limited field of view (FOV), the UAV must rely on other methods to detect and approach the target before vision can be used. In this paper we propose a method combining Ultra-wideband (UWB) ranging sensor with vision-based techniques to achieve both autonomous approaching and landing capabilities in GPS-denied environments. In the approaching phase, a robust and efficient recursive least-square optimization algorithm is proposed to estimate the position of the UAV relative to the target by using the distance and relative displacement measurements. Using this estimate, UAV is able to approach the target until the landing pad is detected by an onboard vision system, then UWB measurements and vision-derived poses are fused with onboard sensor of UAV to facilitate an accurate landing maneuver. Real-world experiments are conducted to demonstrate the efficiency of our method.
ER  - 

TY  - CONF
TI  - Online Vehicle Trajectory Prediction using Policy Anticipation Network and optimization-based Context Reasoning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9610
EP  - 9616
AU  - W. Ding
AU  - S. Shen
PY  - 2019
KW  - inference mechanisms
KW  - optimisation
KW  - regression analysis
KW  - road traffic control
KW  - traffic engineering computing
KW  - ubiquitous computing
KW  - online vehicle trajectory prediction
KW  - two-level vehicle trajectory prediction framework
KW  - urban autonomous driving
KW  - complex contextual factors
KW  - traffic regulations
KW  - moving agents
KW  - high-level policy anticipation
KW  - low-level context reasoning
KW  - short-term memory network
KW  - sequential history observations
KW  - low-level optimization-based context reasoning process
KW  - optimization-based reasoning process
KW  - two-level reasoning process
KW  - continuous trajectory
KW  - regression-based trajectory prediction methods
KW  - vehicle motions
KW  - Trajectory
KW  - Cognition
KW  - Optimization
KW  - Hidden Markov models
KW  - Predictive models
KW  - Geometry
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8793568
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present an online two-level vehicle trajectory prediction framework for urban autonomous driving where there are complex contextual factors, such as lane geometries, road constructions, traffic regulations and moving agents. Our method combines high-level policy anticipation with low-level context reasoning. We leverage a long short-term memory (LSTM) network to anticipate the vehicle's driving policy (e.g., forward, yield, turn left, turn right, etc.) using its sequential history observations. The policy is then used to guide a low-level optimization-based context reasoning process. We show that it is essential to incorporate the prior policy anticipation due to the multimodal nature of the future trajectory. Moreover, contrary to existing regression-based trajectory prediction methods, our optimization-based reasoning process can cope with complex contextual factors. The final output of the two-level reasoning process is a continuous trajectory that automatically adapts to different traffic configurations and accurately predicts future vehicle motions. The performance of the proposed framework is analyzed and validated in an emerging autonomous driving simulation platform (CARLA).
ER  - 

TY  - CONF
TI  - A Flexible Low-Cost Biologically Inspired Sonar Sensor Platform for Robotic Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9617
EP  - 9623
AU  - D. Laurijssen
AU  - R. Kerstens
AU  - G. Schouten
AU  - W. Daems
AU  - J. Steckel
PY  - 2019
KW  - bioacoustics
KW  - biomimetics
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - sonar
KW  - flexible low-cost biologically inspired sonar sensor
KW  - robotic applications
KW  - biomimetic sonar experiments
KW  - autonomous sonar navigation
KW  - ultrasound
KW  - subsumption architecture
KW  - autonomous navigation control system
KW  - P3DX robotics platform
KW  - big-eared bat
KW  - sonar sensor platform
KW  - biomimetic control mechanisms
KW  - Micronycteris microtis
KW  - echolocating animals
KW  - Robot sensing systems
KW  - Sonar
KW  - Microphones
KW  - Sonar navigation
KW  - Universal Serial Bus
KW  - Ultrasonic imaging
DO  - 10.1109/ICRA.2019.8794165
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we present a flexible low-cost sonar sensor platform that can be used for a wide range of biomimetic sonar experiments and autonomous sonar navigation targeted at robotics applications. The navigation abilities of bats using ultrasound (sonar) in unknown cluttered environments are very effective and can be distilled into a sensor architecture and accompanying control methodology that lends itself to be implemented on cost efficient hardware. The sensor architecture and processing methodology of this sensing platform mimics that of bats. In this paper we specifically focused on the common big-eared bat (Micronycteris microtis) although this could be transferred to other bat species or even other echolocating animals since the experimental platform was designed for flexibility. Using this platform we were able to implement a control system using a subsumption architecture that features different behavior patterns based solely on the sonar sensor as a source of exteroceptive information. In order to validate the combination of our autonomous navigation control system and our developed sonar sensor platform, the hardware was mounted on the P3DX robotics platform that was introduced in an unknown testing environment and have it drive autonomously. These experiments were used to validate our assumption of the efficacy of these relatively simple biomimetic control mechanisms and thus alleviating the need for expensive sensing platforms for certain robotics applications.
ER  - 

TY  - CONF
TI  - ClusterNav: Learning-Based Robust Navigation Operating in Cluttered Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9624
EP  - 9630
AU  - G. S. Martins
AU  - R. P. Rocha
AU  - F. J. Pais
AU  - P. Menezes
PY  - 2019
KW  - assisted living
KW  - geriatrics
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robust control
KW  - service robots
KW  - telerobotics
KW  - nonexpert users
KW  - ClusterNav
KW  - cluttered environments
KW  - robust autonomous navigation
KW  - social robots
KW  - elderly users
KW  - traditional model-based navigation techniques
KW  - stable theoretical foundation
KW  - practical foundation
KW  - autonomous operation
KW  - domestic environments
KW  - acceptable behaviour
KW  - novel learning-based technique
KW  - geometric representation
KW  - acceptable manner
KW  - elderly care facility
KW  - traditional model-based approach
KW  - learning-based robust navigation
KW  - Trajectory
KW  - Navigation
KW  - Robot kinematics
KW  - Clustering algorithms
KW  - Reinforcement learning
DO  - 10.1109/ICRA.2019.8794262
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robust autonomous navigation is one of the most important aspects in the acceptance of social robots by elderly users. Traditional model-based navigation techniques provide a stable theoretical and practical foundation for autonomous operation in domestic environments, but fall short in achieving human-like, acceptable behaviour while still being able to robustly navigate cluttered environments. In this work, we propose ClusterNav, a novel learning-based technique for navigation. Our technique consists of teaching the robot how it should move in the environment in a human-like manner, capturing key features of this demonstration in a geometric representation of the environment. This representation is then used to generate new trajectories for execution, allowing the robot move in an acceptable manner. We have tested our technique in a real environment in an elderly care facility, comparing it with the traditional model-based approach. Tests involved both expert and non-expert users teleoperating the robot. Results show that ClusterNav is capable of navigating the environment, achieving better similarity with the reference trajectories and higher execution speed when compared to the model-based approach.
ER  - 


TY  - CONF
TI  - Adaptive motor control and learning in a spiking neural network realised on a mixed-signal neuromorphic processor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9631
EP  - 9637
AU  - S. Glatz
AU  - J. Martel
AU  - R. Kreiser
AU  - N. Qiao
AU  - Y. Sandamirskaya
PY  - 2019
KW  - control engineering computing
KW  - feedback
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural chips
KW  - neurocontrollers
KW  - adaptive motor control
KW  - mixed-signal neuromorphic processor
KW  - neuromorphic computing
KW  - biological neural networks
KW  - spiking neural network architecture
KW  - sensory feedback
KW  - control rotational velocity
KW  - robotic vehicle
KW  - correct motor command
KW  - miniature mobile vehicle
KW  - two-layer spiking neural network
KW  - neuromorphic chip
KW  - purely neuromorphic motor control
KW  - spiking neurons
KW  - neuromorphic device
KW  - on-chip plastic synaptic weights
KW  - Neuromorphics
KW  - Neurons
KW  - Biological neural networks
KW  - Computer architecture
KW  - Robot sensing systems
KW  - Sociology
DO  - 10.1109/ICRA.2019.8794145
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Neuromorphic computing is a new paradigm for design of both the computing hardware and algorithms inspired by biological neural networks. The event-based nature and the inherent parallelism make neuromorphic computing a promising paradigm for building efficient neural network based architectures for control of fast and agile robots. In this paper, we present a spiking neural network architecture that uses sensory feedback to control rotational velocity of a robotic vehicle. When the velocity reaches the target value, the mapping from the target velocity of the vehicle to the correct motor command, both represented in the spiking neural network on the neuromorphic device, is autonomously stored on the device using on-chip plastic synaptic weights. We validate the controller using a wheel motor of a miniature mobile vehicle and inertia measurement unit as the sensory feedback and demonstrate online learning of a simple “inverse model” in a two-layer spiking neural network on the neuromorphic chip. The prototype neuromorphic device that features 256 spiking neurons allows us to realise a simple proof of concept architecture for the purely neuromorphic motor control and learning. The architecture can be easily scaled-up if a larger neuromorphic device is available.
ER  - 

TY  - CONF
TI  - Adaptive Genomic Evolution of Neural Network Topologies (AGENT) for State-to-Action Mapping in Autonomous Agents
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9638
EP  - 9644
AU  - A. Behjat
AU  - S. Chidambaran
AU  - S. Chowdhury
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - genetic algorithms
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - autonomous agents
KW  - neural networks
KW  - NN
KW  - evolutionary algorithm
KW  - state-to-action mapping model
KW  - neuroevolution process
KW  - population diversity
KW  - unmanned aerial vehicle collision avoidance problem
KW  - adaptive genomic evolution
KW  - neural network topologies
KW  - augmented topologies formalism
KW  - Open AI platform
KW  - UAV collision avoidance problem
KW  - Genomics
KW  - Topology
KW  - Sociology
KW  - Statistics
KW  - Artificial neural networks
KW  - Network topology
DO  - 10.1109/ICRA.2019.8793613
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Neuroevolution is a process of training neural networks (NN) through an evolutionary algorithm, usually to serve as a state-to-action mapping model in control or reinforcement learning-type problems. This paper builds on the Neuro Evolution of Augmented Topologies (NEAT) formalism that allows designing topology and weight evolving NNs. Fundamental advancements are made to the neuroevolution process to address premature stagnation and convergence issues, central among which is the incorporation of automated mechanisms to control the population diversity and average fitness improvement within the neuroevolution process. Insights into the performance and efficiency of the new algorithm is obtained by evaluating it on three benchmark problems from the Open AI platform and an Unmanned Aerial Vehicle (UAV) collision avoidance problem.
ER  - 

TY  - CONF
TI  - End to End Learning of a Multi-Layered Snn Based on R-Stdp for a Target Tracking Snake-Like Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9645
EP  - 9651
AU  - Z. Bing
AU  - Z. Jiang
AU  - L. Cheng
AU  - C. Cai
AU  - K. Huang
AU  - A. Knoll
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neurocontrollers
KW  - path planning
KW  - target tracking
KW  - multilayered SNN
KW  - target tracking snake-like robot
KW  - end-to-end learning approach
KW  - R-STDP
KW  - SNN controller
KW  - target tracking tasks
KW  - reward-modulated spike-timing-dependent plasticity
KW  - multilayered spiking neural network
KW  - learning algorithms
KW  - lateral tracking
KW  - Neurons
KW  - Target tracking
KW  - Task analysis
KW  - Synapses
KW  - Robot sensing systems
KW  - Training
DO  - 10.1109/ICRA.2019.8793774
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces an end-to-end learning approach based on Reward-modulated Spike-Timing-Dependent Plasticity (R-STDP) for a multi-layered spiking neural network (SNN). As a case study, a snake-like robot is used as an agent to perform target tracking tasks on the basis of our proposed approach. Since the key of R-STDP is to use rewards to modulate synapse strengthens, we first propose a general way to propagate the reward back through a multi-layered SNN. Upon the proposed approach, we build up an SNN controller that drives a snake-like robot for performing target tracking tasks. We demonstrate the practicability and advantage of our approach in terms of lateral tracking accuracy by comparing it to other state-of-the-art learning algorithms for SNNs based on R-STDP.
ER  - 

TY  - CONF
TI  - Improving collective decision accuracy via time-varying cross-inhibition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9652
EP  - 9659
AU  - M. S. Talamali
AU  - J. A. R. Marshall
AU  - T. Bose
AU  - A. Reina
PY  - 2019
KW  - decision making
KW  - multi-robot systems
KW  - stochastic processes
KW  - time-varying cross-inhibition
KW  - decentralised decision-making
KW  - robot swarm
KW  - diffusive search
KW  - decentralised algorithm
KW  - house-hunting honeybees
KW  - single decentralised parameter
KW  - balance exploration
KW  - swarm robotics simulations
KW  - collective decision accuracy
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Noise measurement
KW  - Task analysis
KW  - Swarm robotics
KW  - Analytical models
DO  - 10.1109/ICRA.2019.8794284
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We investigate decentralised decision-making, in which a robot swarm is tasked with selecting the best-quality option among a set of alternatives. Individual robots are simplistic as they only perform diffusive search, make local noisy estimates of the options' quality, and exchange information with near neighbours. We propose a decentralised algorithm, inspired by house-hunting honeybees, to efficiently aggregate noisy estimations. Individual robots, by varying over time a single decentralised parameter that modulates the interaction strength, balance exploration and agreement. In this way, the swarm first identifies the options under consideration, then rapidly converges on the best available option, even when outnumbered by lower quality options. We present stochastic analyses and swarm robotics simulations to compare the novel strategy with previous methods and to quantify the performance improvement. The proposed strategy limits the spreading of errors within the population and allows swarms of simple noisy units with minimal communication capabilities to make highly accurate collective decisions in predictable time.
ER  - 

TY  - CONF
TI  - A Motion Planning Scheme for Cooperative Loading Using Heterogeneous Robotic Agents
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9660
EP  - 9666
AU  - M. Logothetis
AU  - P. Vlantis
AU  - C. Vrohidis
AU  - G. C. Karras
AU  - K. J. Kyriakopoulos
PY  - 2019
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - probability
KW  - obstacle avoidance
KW  - robotic agents
KW  - probabilistic road maps technique
KW  - cooperative loading task
KW  - redundant static manipulator
KW  - mobile platform
KW  - static obstacles
KW  - cluttered workspace
KW  - control architecture
KW  - decentralized motion planning
KW  - motion planning scheme
KW  - convergence properties
KW  - motion control scheme
KW  - optimal loading configuration
KW  - Manipulators
KW  - Loading
KW  - Task analysis
KW  - Robot kinematics
KW  - Kinematics
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8794323
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we present a decentralized motion planning and control architecture for the cooperative loading task using heterogeneous robotic agents operating in a cluttered workspace with static obstacles. Initially, we tackle the problem of calculating a set of feasible loading configurations via a Probabilistic Road Maps technique. Next, an optimal loading configuration is selected considering the connectivity of the space and the Euclidean distance between the robotic agents. A motion control scheme for each agent is designed and implemented in order to autonomously guide each robot to the desired loading configuration with guaranteed obstacle avoidance and convergence properties. The performance and the applicability of the proposed strategy is experimentally verified in a variety of loading scenarios using a redundant static manipulator and a mobile platform.
ER  - 

TY  - CONF
TI  - Voluntary Retreat for Decentralized Interference Reduction in Robot Swarms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9667
EP  - 9673
AU  - S. Mayya
AU  - P. Pierpaoli
AU  - M. Egerstedt
PY  - 2019
KW  - decentralised control
KW  - mobile robots
KW  - multi-robot systems
KW  - decentralized interference reduction
KW  - densely-packed robot swarms
KW  - confined regions
KW  - physical space-forces robots
KW  - decentralized algorithm
KW  - distributed collection task
KW  - spatial interference
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Task analysis
KW  - Interference
KW  - Analytical models
DO  - 10.1109/ICRA.2019.8794124
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In densely-packed robot swarms operating in confined regions, spatial interference-which manifests itself as a competition for physical space-forces robots to spend more time navigating around each other rather than performing the primary task. This paper develops a decentralized algorithm that enables individual robots to decide whether to stay in the region and contribute to the overall mission, or vacate the region so as to reduce the negative effects that interference has on the overall efficiency of the swarm. We develop this algorithm in the context of a distributed collection task, where a team of robots collect and deposit objects from one set of locations to another in a given region. Robots do not communicate and use only binary information regarding the presence of other robots around them to make the decision to stay or retreat. We illustrate the efficacy of the algorithm with experiments on a team of real robots.
ER  - 

TY  - CONF
TI  - Spatial Coverage Without Computation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9674
EP  - 9680
AU  - A. Özdemir
AU  - M. Gauci
AU  - A. Kolling
AU  - M. D. Hall
AU  - R. Groß
PY  - 2019
KW  - mobile robots
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - random processes
KW  - robot redundancy
KW  - optimized random walk
KW  - performance improvements
KW  - sub-millimeter-sized robots
KW  - spatial coverage
KW  - anonymous robots
KW  - mobile robots
KW  - two-dimensional space
KW  - extremely simple robots
KW  - run-time computation
KW  - computer simulations
KW  - deterministic controller
KW  - off-line optimization
KW  - physical e-puck robots
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Mobile robots
KW  - Wheels
KW  - Area measurement
DO  - 10.1109/ICRA.2019.8793731
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We study the problem of controlling a swarm of anonymous, mobile robots to cooperatively cover an unknown two-dimensional space. The novelty of our proposed solution is that it is applicable to extremely simple robots that lack run-time computation or storage. The solution requires only a single bit of information per robot-whether or not another robot is present in its line of sight. Computer simulations show that our deterministic controller, which was obtained through off-line optimization, achieves around 71-76% coverage in a test scenario with no robot redundancy, which corresponds to a 26-39% reduction of the area that is not covered, when compared to an optimized random walk. A moderately lower level of performance was observed in 20 experimental trials with 25 physical e-puck robots. Moreover, we demonstrate that the same controller can be used in environments of different dimensions and even to navigate a maze. The controller provides a baseline against which one can quantify the performance improvements that more advanced and expensive techniques may offer. Moreover, due to its simplicity, it could potentially be implemented on swarms of sub-millimeter-sized robots. This would pave the way for new applications in micro-medicine.
ER  - 

TY  - CONF
TI  - DeepSignals: Predicting Intent of Drivers Through Visual Signals
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9697
EP  - 9703
AU  - D. Frossard
AU  - E. Kee
AU  - R. Urtasun
PY  - 2019
KW  - alarm systems
KW  - belief networks
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - psychology
KW  - traffic engineering computing
KW  - video signal processing
KW  - driver intention detection
KW  - emergency flashers
KW  - turn signals
KW  - stops
KW  - lane changes
KW  - sudden events
KW  - visual signals
KW  - DeepSignals
KW  - temporal information
KW  - spatial information
KW  - deep neural network
KW  - video sequences
KW  - potentially critical reaction time
KW  - Feature extraction
KW  - Convolution
KW  - Vehicles
KW  - Visualization
KW  - Streaming media
KW  - Computer architecture
KW  - Logic gates
DO  - 10.1109/ICRA.2019.8794214
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Detecting the intention of drivers is an essential task in self-driving, necessary to anticipate sudden events like lane changes and stops. Turn signals and emergency flashers communicate such intentions, providing seconds of potentially critical reaction time. In this paper, we propose to detect these signals in video sequences by using a deep neural network that reasons about both spatial and temporal information. Our experiments on more than a million frames show high per-frame accuracy in very challenging scenarios.
ER  - 

TY  - CONF
TI  - Real-time Intent Prediction of Pedestrians for Autonomous Ground Vehicles via Spatio-Temporal DenseNet
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9704
EP  - 9710
AU  - K. Saleh
AU  - M. Hossny
AU  - S. Nahavandi
PY  - 2019
KW  - cameras
KW  - control engineering computing
KW  - image colour analysis
KW  - image sequences
KW  - mobile robots
KW  - object detection
KW  - object tracking
KW  - pedestrians
KW  - road traffic
KW  - traffic engineering computing
KW  - pedestrians
KW  - complex environments
KW  - vulnerable road users
KW  - intent action prediction
KW  - urban traffic environments
KW  - monocular RGB camera
KW  - tracking-by-detection technique
KW  - spatio-temporal DenseNet model
KW  - autonomous ground vehicles
KW  - image sequences
KW  - real-time intent prediction
KW  - Real-time systems
KW  - Task analysis
KW  - Predictive models
KW  - Two dimensional displays
KW  - Image sequences
KW  - Cameras
KW  - Activity recognition
DO  - 10.1109/ICRA.2019.8793991
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Understanding the behaviors and intentions of humans are one of the main challenges autonomous ground vehicles still faced with. More specifically, when it comes to complex environments such as urban traffic scenes, inferring the intentions and actions of vulnerable road users such as pedestrians become even harder. In this paper, we address the problem of intent action prediction of pedestrians in urban traffic environments using only image sequences from a monocular RGB camera. We propose a real-time framework that can accurately detect, track and predict the intended actions of pedestrians based on a tracking-by-detection technique in conjunction with a novel spatio-temporal DenseNet model. We trained and evaluated our framework based on real data collected from urban traffic environments. Our framework has shown resilient and competitive results in comparison to other baseline approaches. Overall, we achieved an average precision score of 84.76% with real-time performance at 20 FPS.
ER  - 

TY  - CONF
TI  - Egocentric Vision-based Future Vehicle Localization for Intelligent Driving Assistance Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9711
EP  - 9717
AU  - Y. Yao
AU  - M. Xu
AU  - C. Choi
AU  - D. J. Crandall
AU  - E. M. Atkins
AU  - B. Dariush
PY  - 2019
KW  - driver information systems
KW  - image coding
KW  - image sequences
KW  - recurrent neural nets
KW  - road vehicles
KW  - egocentric vision-based future vehicle localization
KW  - intelligent driving assistance systems
KW  - safety-critical applications
KW  - autonomous driving
KW  - target vehicles
KW  - first-person view
KW  - ego-vehicle
KW  - multistream recurrent neural network encoder-decoder model
KW  - object location
KW  - pixel-level observations
KW  - future motion
KW  - prediction accuracy
KW  - intelligent vehicles
KW  - automated vehicles
KW  - motion planning capability
KW  - vehicle trajectories
KW  - dense optical flow
KW  - Trajectory
KW  - Cameras
KW  - Optical imaging
KW  - Decoding
KW  - Videos
KW  - Predictive models
KW  - Advanced driver assistance systems
DO  - 10.1109/ICRA.2019.8794474
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Predicting the future location of vehicles is essential for safety-critical applications such as advanced driver assistance systems (ADAS) and autonomous driving. This paper introduces a novel approach to simultaneously predict both the location and scale of target vehicles in the first-person (egocentric) view of an ego-vehicle. We present a multi-stream recurrent neural network (RNN) encoder-decoder model that separately captures both object location and scale and pixel-level observations for future vehicle localization. We show that incorporating dense optical flow improves prediction results significantly since it captures information about motion as well as appearance change. We also find that explicitly modeling future motion of the ego-vehicle improves the prediction accuracy, which could be especially beneficial in intelligent and automated vehicles that have motion planning capability. To evaluate the performance of our approach, we present a new dataset of first-person videos collected from a variety of scenarios at road intersections, which are particularly challenging moments for prediction because vehicle trajectories are diverse and dynamic. Code and dataset have been made available at: https://usa.honda-ri.com/hevi.
ER  - 

TY  - CONF
TI  - Uncertainty-Aware Driver Trajectory Prediction at Urban Intersections
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9718
EP  - 9724
AU  - X. Huang
AU  - S. G. McGill
AU  - B. C. Williams
AU  - L. Fletcher
AU  - G. Rosman
PY  - 2019
KW  - driver information systems
KW  - neural nets
KW  - road safety
KW  - road traffic
KW  - road vehicles
KW  - variational neural network approach
KW  - multiple sensors
KW  - conditional variational distribution
KW  - confidence estimate
KW  - different time horizons
KW  - additional predictors
KW  - variational predictor
KW  - physics-based predictor
KW  - confidence estimations
KW  - system performance
KW  - vehicle autonomy
KW  - real-world urban driving data
KW  - prediction error
KW  - physics-based model
KW  - uncertainty-aware driver trajectory prediction
KW  - urban intersections
KW  - advanced driving systems
KW  - shared control
KW  - automation systems
KW  - uncertain situations
KW  - driver trajectory distributions
KW  - Trajectory
KW  - Vehicles
KW  - Predictive models
KW  - Sensors
KW  - Uncertainty
KW  - Autonomous systems
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794282
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Predicting the motion of a driver's vehicle is crucial for advanced driving systems, enabling detection of potential risks towards shared control between the driver and automation systems. In this paper, we propose a variational neural network approach that predicts future driver trajectory distributions for the vehicle based on multiple sensors. Our predictor generates both a conditional variational distribution of future trajectories, as well as a confidence estimate for different time horizons. Our approach allows us to handle inherently uncertain situations, and reason about information gain from each input, as well as combine our model with additional predictors, creating a mixture of experts. We show how to augment the variational predictor with a physics-based predictor, and based on their confidence estimations, improve overall system performance. The resulting combined model is aware of the uncertainty associated with its predictions, which can help the vehicle autonomy to make decisions with more confidence. The model is validated on real-world urban driving data collected in multiple locations. This validation demonstrates that our approach improves the prediction error of a physics-based model by 25% while successfully identifying the uncertain cases with 82% accuracy.
ER  - 

TY  - CONF
TI  - Go with the Flow: Exploration and Mapping of Pedestrian Flow Patterns from Partial Observations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9725
EP  - 9731
AU  - S. Molina
AU  - G. Cielniak
AU  - T. Duckett
PY  - 2019
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - pedestrians
KW  - stochastic processes
KW  - pedestrian flow patterns
KW  - partial observations
KW  - safe robot navigation
KW  - spatial constraints
KW  - temporal constraints
KW  - multiple Poisson processes
KW  - long-term pedestrian datasets
KW  - uninformed exploration strategies
KW  - human motion patterns
KW  - robot navigation
KW  - Robots
KW  - Uncertainty
KW  - Predictive models
KW  - Buildings
KW  - Probabilistic logic
KW  - Data models
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8794434
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Understanding how people are likely to behave in an environment is a key requirement for efficient and safe robot navigation. However, mobile platforms are subject to spatial and temporal constraints, meaning that only partial observations of human activities are typically available to a robot, while the activity patterns of people in a given environment may also change at different times. To address these issues we present as the main contribution an exploration strategy for acquiring models of pedestrian flows, which decides not only the locations to explore but also the times when to explore them. The approach is driven by the uncertainty from multiple Poisson processes built from past observations. The approach is evaluated using two long-term pedestrian datasets, comparing its performance against uninformed exploration strategies. The results show that when using the uncertainty in the exploration policy, model accuracy increases, enabling faster learning of human motion patterns.
ER  - 

TY  - CONF
TI  - Design and Analysis of A Miniature Two-Wheg Climbing Robot with Robust Internal and External Transitioning Capabilities
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9740
EP  - 9746
AU  - D. C. Y. Koh
AU  - A. G. Dharmawan
AU  - H. H. Hariri
AU  - G. S. Soh
AU  - S. Foong
AU  - R. Bouffanais
AU  - H. Y. Low
AU  - K. L. Wood
PY  - 2019
KW  - actuators
KW  - design engineering
KW  - legged locomotion
KW  - robot kinematics
KW  - climbing robot
KW  - robust external transitioning capabilities
KW  - robust internal transitioning capabilities
KW  - 4-way external transitions
KW  - 4-way internal transitions
KW  - indepth force analysis
KW  - robust transitioning capabilities
KW  - two-wheg miniature
KW  - plane-to-plane transitioning
KW  - Climbing robots
KW  - Force
KW  - Robot kinematics
KW  - Task analysis
KW  - Adhesives
KW  - Torque
DO  - 10.1109/ICRA.2019.8793910
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Plane-to-plane transitioning has been a significant challenge for climbing robots. To accomplish this, additional actuator or robot module is usually required which significantly increases both size and weight of the robot. This paper presents a two-wheg miniature climbing robot with a novel passive vertical tail component which results in robust transitioning capabilities. The design decision was derived from an indepth force analysis of the climbing robot while performing the transition. The theoretical analysis is verified through a working prototype with robust transitioning capabilities whose performance follows closely the analytical prediction. The climbing robot is able to climb any slope angles, 4-way internal transitions, and 4-way external transitions. This work contributes to the understanding and advancement of the transitioning capabilities and the design of a simple climbing robot, which expands the possibilities of scaling down miniature climbing robot further.
ER  - 

TY  - CONF
TI  - Design and Implementation of CCRobot-II: a Palm-based Cable Climbing Robot for Cable-stayed Bridge Inspection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9747
EP  - 9753
AU  - Z. Zheng
AU  - N. Ding
PY  - 2019
KW  - bridges (structures)
KW  - cables (mechanical)
KW  - design engineering
KW  - inspection
KW  - legged locomotion
KW  - wheels
KW  - cable-stayed bridge inspection
KW  - design method
KW  - bio-inspired climbing robotic technology
KW  - palm-based gripping module
KW  - wheels
KW  - climbing gait
KW  - trajectory algorithm
KW  - mass 25.0 kg
KW  - mass 30.0 kg
KW  - size 1.1 m
KW  - Bridges
KW  - Climbing robots
KW  - Force
KW  - Wheels
KW  - Inspection
DO  - 10.1109/ICRA.2019.8793562
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This project aims at developing a bio-inspired climbing robotic technology for cable inspection on the cable-stayed bridge. The design and implementation of a palm-based cable climbing robot: CCRobot-II with mass 25 kg, maximal payload 30kg and maximal length 1.1 m are described. CCRobot-II consists of several novel design features, including the palm-based gripping module, the alternating-sliding frame specialized for high-speed climbing, and the following wheels. With its carefully designed mechanism, climbing gait and trajectory algorithm, CCRobot-II is able to crawl along a bridge cable with a maximal speed 5.2 m/min. This speed has been hardly achieved by a existing climbing robot with such a large scale, and it is nearly the twice as the climbing speed of CCRobot-I which is designed previously. CCRobot-II also works effectively even if the bridge cable surface is attached with small obstacles. Experiments have been conducted, the results show that CCRobot-II has potential engineering applications on the cable-stayed bridge for fieldwork.
ER  - 

TY  - CONF
TI  - Dynamic Modeling and Gait Analysis for Miniature Robots in the Absence of Foot Placement Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9754
EP  - 9760
AU  - M. Askari
AU  - O. Özcan
PY  - 2019
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - microrobots
KW  - robot dynamics
KW  - dynamic modeling
KW  - gait analysis
KW  - foot placement control
KW  - comprehensive dynamic model
KW  - miniature foldable robot
KW  - gait planning
KW  - foot placement
KW  - miniature robots
KW  - MinIAQ-II robot
KW  - Legged locomotion
KW  - Foot
KW  - Kinematics
KW  - Mathematical model
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Origami-Inspired Robots
KW  - Foldable Robots
KW  - Miniature Robots
KW  - Legged Robots
KW  - Gait Analysis
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8793533
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The study of animals and insects have led to realization that animals select their gaits, patterns of leg movement, according to speed. For proper gait planning, the legs must be controlled for proper foot placement with respect to the body motion and ground interactions. However, in small scale robotic platforms gait planning through foot placement control is neither cost effective nor easily attainable due to a lack of available sensors. Thus, even though a desired gait is envisioned at the design phase, it is not known whether the gait is optimum. In this work, we present the comprehensive dynamic model of the miniature foldable robot, MinIAQ-II, which has four independently actuated legs. Dynamic model is used to perform gait analysis, to investigate the difference between the intended gait and the achieved gait in the absence of foot placement control. The model is verified through slow speed walking experiments on flat terrain. The work presented can be modified for different miniature robots with passive legs to predict their locomotion under no foot placement control.
ER  - 

TY  - CONF
TI  - Memory Efficient Experience Replay for Streaming Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9769
EP  - 9776
AU  - T. L. Hayes
AU  - N. D. Cahill
AU  - C. Kanan
PY  - 2019
KW  - cognition
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - neurophysiology
KW  - learning settings
KW  - memory efficient experience replay
KW  - supervised machine learning
KW  - static settings
KW  - data stream
KW  - streaming learning
KW  - conventional deep neural networks
KW  - full rehearsal
KW  - memory efficient rehearsal
KW  - ExStream algorithm
KW  - Clustering algorithms
KW  - Training
KW  - Prototypes
KW  - Robots
KW  - Buffer storage
KW  - Partitioning algorithms
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793982
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In supervised machine learning, an agent is typically trained once and then deployed. While this works well for static settings, robots often operate in changing environments and must quickly learn new things from data streams. In this paradigm, known as streaming learning, a learner is trained online, in a single pass, from a data stream that cannot be assumed to be independent and identically distributed (iid). Streaming learning will cause conventional deep neural networks (DNNs) to fail for two reasons: 1) they need multiple passes through the entire dataset; and 2) non-iid data will cause catastrophic forgetting. An old fix to both of these issues is rehearsal. To learn a new example, rehearsal mixes it with previous examples, and then this mixture is used to update the DNN. Full rehearsal is slow and memory intensive because it stores all previously observed examples, and its effectiveness for preventing catastrophic forgetting has not been studied in modern DNNs. Here, we describe the ExStream algorithm for memory efficient rehearsal and compare it to alternatives. We find that full rehearsal can eliminate catastrophic forgetting in a variety of streaming learning settings, with ExStream performing well using far less memory and computation.
ER  - 

TY  - CONF
TI  - RoboCSE: Robot Common Sense Embedding
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9777
EP  - 9783
AU  - A. Daruna
AU  - W. Liu
AU  - Z. Kira
AU  - S. Chetnova
PY  - 2019
KW  - belief networks
KW  - embedded systems
KW  - home automation
KW  - mobile robots
KW  - service robots
KW  - statistical analysis
KW  - RoboCSE
KW  - robot common sense embedding
KW  - autonomous service robots
KW  - semantic knowledge
KW  - AI2Thor
KW  - statistical significant
KW  - home environment simulator
KW  - Word2Vec
KW  - Bayesian logic network
KW  - MatterPort3D
KW  - Semantics
KW  - Training
KW  - Robot sensing systems
KW  - Cognition
KW  - Computational modeling
KW  - Training data
DO  - 10.1109/ICRA.2019.8794070
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous service robots require computational frameworks that allow them to generalize knowledge to new situations in a manner that models uncertainty while scaling to real-world problem sizes. The Robot Common Sense Embedding (RoboCSE) showcases a class of computational frameworks, multi-relational embeddings, that have not been leveraged in robotics to model semantic knowledge. We validate RoboCSE on a realistic home environment simulator (AI2Thor) to measure how well it generalizes learned knowledge about object affordances, locations, and materials. Our experiments show that RoboCSE can perform prediction better than a baseline that uses pre-trained embeddings, such as Word2Vec, achieving statistically significant improvements while using orders of magnitude less memory than our Bayesian Logic Network baseline. In addition, we show that predictions made by RoboCSE are robust to significant reductions in data available for training as well as domain transfer to MatterPort3D, achieving statistically significant improvements over a baseline that memorizes training data.
ER  - 

TY  - CONF
TI  - Neural Lander: Stable Drone Landing Control Using Learned Dynamics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9784
EP  - 9790
AU  - G. Shi
AU  - X. Shi
AU  - M. O’Connell
AU  - R. Yu
AU  - K. Azizzadenesheli
AU  - A. Anandkumar
AU  - Y. Yue
AU  - S. Chung
PY  - 2019
KW  - aerodynamics
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - feedback
KW  - helicopters
KW  - learning (artificial intelligence)
KW  - linearisation techniques
KW  - neurocontrollers
KW  - nonlinear control systems
KW  - robust control
KW  - trajectory control
KW  - cross-table trajectory tracking cases
KW  - Neural Lander
KW  - stable drone landing control
KW  - learned dynamics
KW  - precise near-ground trajectory control
KW  - multirotor drones
KW  - complex aerodynamic effects
KW  - multirotor airflow
KW  - complex effects
KW  - smooth landing
KW  - robust nonlinear controller
KW  - control performance
KW  - nominal dynamics model
KW  - Deep Neural Network
KW  - high-order interactions
KW  - Lipschitz constant
KW  - Lipschitz property
KW  - nonlinear feedback linearization controller
KW  - DNN-based nonlinear feedback controller
KW  - arbitrarily large neural nets
KW  - Baseline Nonlinear Tracking Controller
KW  - Aerodynamics
KW  - Stability analysis
KW  - Rotors
KW  - Neural networks
KW  - Trajectory tracking
KW  - Training
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8794351
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Precise near-ground trajectory control is difficult for multi-rotor drones, due to the complex aerodynamic effects caused by interactions between multi-rotor airflow and the environment. Conventional control methods often fail to properly account for these complex effects and fall short in accomplishing smooth landing. In this paper, we present a novel deep-learning-based robust nonlinear controller (Neural-Lander) that improves control performance of a quadrotor during landing. Our approach combines a nominal dynamics model with a Deep Neural Network (DNN) that learns high-order interactions. We apply spectral normalization (SN) to constrain the Lipschitz constant of the DNN. Leveraging this Lipschitz property, we design a nonlinear feedback linearization controller using the learned model and prove system stability with disturbance rejection. To the best of our knowledge, this is the first DNN-based nonlinear feedback controller with stability guarantees that can utilize arbitrarily large neural nets. Experimental results demonstrate that the proposed controller significantly outperforms a Baseline Nonlinear Tracking Controller in both landing and cross-table trajectory tracking cases. We also empirically show that the DNN generalizes well to unseen data outside the training domain.
ER  - 

TY  - CONF
TI  - Distributional Deep Reinforcement Learning with a Mixture of Gaussians
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9791
EP  - 9797
AU  - Y. Choi
AU  - K. Lee
AU  - S. Oh
PY  - 2019
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - statistical distributions
KW  - discrete distribution
KW  - softmax parametrization
KW  - KL divergence loss
KW  - discretization hyperparameters
KW  - Atari games
KW  - distributional deep reinforcement learning
KW  - mixture density network
KW  - return distribution
KW  - mixtures of Gaussians
KW  - Jensen-Tsallis distance
KW  - autonomous vehicle driving
KW  - Measurement
KW  - Reinforcement learning
KW  - Games
KW  - Approximation algorithms
KW  - Neural networks
KW  - Autonomous vehicles
KW  - Stochastic processes
DO  - 10.1109/ICRA.2019.8793505
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a novel distributional reinforcement learning (RL) method which models the distribution of the sum of rewards using a mixture density network. Recently, it has been shown that modeling the randomness of the return distribution leads to better performance in Atari games and control tasks. Despite the success of the prior work, it has limitations which come from the use of a discrete distribution. First, it needs a projection step and softmax parametrization for the distribution, since it minimizes the KL divergence loss. Secondly, its performance depends on discretization hyperparameters such as the number of atoms and bounds of the support which require domain knowledge. We mitigate these problems with the proposed parameterization, a mixture of Gaussians. Furthermore, we propose a new distance metric called the Jensen-Tsallis distance, which allows the computation of the distance between two mixtures of Gaussians in a closed form. We have conducted various experiments to validate the proposed method, including Atari games and autonomous vehicle driving.
ER  - 

TY  - CONF
TI  - Jointly Learning to Construct and Control Agents using Deep Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9798
EP  - 9805
AU  - C. Schaff
AU  - D. Yunis
AU  - A. Chakrabarti
AU  - M. R. Walter
PY  - 2019
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - optimisation
KW  - control policy
KW  - walking gaits
KW  - deep reinforcement learning
KW  - learning-based approaches
KW  - control network
KW  - design distribution
KW  - controller access
KW  - design parameters
KW  - legged locomotion
KW  - physical design
KW  - Physical design
KW  - Optimization
KW  - Reinforcement learning
KW  - Training
KW  - Legged locomotion
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793537
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The physical design of a robot and the policy that controls its motion are inherently coupled, and should be determined according to the task and environment. In an increasing number of applications, data-driven and learning-based approaches, such as deep reinforcement learning, have proven effective at designing control policies. For most tasks, the only way to evaluate a physical design with respect to such control policies is empirical-i.e., by picking a design and training a control policy for it. Since training these policies is time-consuming, it is computationally infeasible to train separate policies for all possible designs as a means to identify the best one. In this work, we address this limitation by introducing a method that jointly optimizes over the physical design and control network. Our approach maintains a distribution over designs and uses reinforcement learning to optimize a control policy to maximize expected reward over the design distribution. We give the controller access to design parameters to allow it to tailor its policy to each design in the distribution. Throughout training, we shift the distribution towards higher-performing designs, eventually converging to a design and control policy that are jointly optimal. We evaluate our approach in the context of legged locomotion, and demonstrate that it discovers novel designs and walking gaits, outperforming baselines across different settings.
ER  - 

TY  - CONF
TI  - DeltaMag: An Electromagnetic Manipulation System with Parallel Mobile Coils
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9814
EP  - 9820
AU  - L. Yang
AU  - X. Du
AU  - E. Yu
AU  - D. Jin
AU  - L. Zhang
PY  - 2019
KW  - biomagnetism
KW  - calibration
KW  - catheters
KW  - closed loop systems
KW  - coils
KW  - electromagnetic actuators
KW  - magnetic fields
KW  - manipulators
KW  - medical robotics
KW  - microrobots
KW  - position control
KW  - magnetic capsule mock-up
KW  - magnetic catheter mock-up
KW  - magnetic field computation
KW  - embedded system
KW  - multiple parallel mobile coils
KW  - 3D magnetic field
KW  - single coil
KW  - field distribution
KW  - calibrated mathematical model
KW  - good space utilization
KW  - magnetic fields
KW  - electromagnetic coils
KW  - proof-of-concept prototype
KW  - parallel mechanism
KW  - enlarged workspace
KW  - magnetic untethered devices
KW  - remote actuation
KW  - novel magnetic manipulation system
KW  - electromagnetic manipulation system
KW  - DeltaMag
KW  - Coils
KW  - Magnetic devices
KW  - Synchronous motors
KW  - Three-dimensional displays
KW  - Prototypes
KW  - Catheters
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793543
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, a novel magnetic manipulation system using mobile coils for remote actuation of magnetic untethered devices in an enlarged workspace is proposed and studied. A parallel mechanism is implemented to actuate the mobile coils. A proof-of-concept prototype is designed and constructed, namely the DeltaMag, which includes three electromagnetic coils for generating magnetic fields and three motors for actuation of the coils. It has good space utilization: ratio between the diameter of the workspace and the diameter of the whole prototype reaches 0.7.A calibrated mathematical model is developed for the field distribution of a single coil, which has an average error of 8.75%. Then, we introduce a calculation method for the 3D magnetic field at any working position for the configuration of multiple parallel mobile coils. Moreover, an embedded system is established for actuating the parallel mechanism, whose pose is fed back via serial communication for magnetic field computation. A vision based approach is developed for closed-loop control of the parallel mechanism. Furthermore, experiments demonstrate the capabilities of the DeltaMag for manipulation of a magnetic catheter mock-up and a magnetic capsule mock-up in a workspace with a diameter more than 200 mm.
ER  - 

TY  - CONF
TI  - Surgical instrument segmentation for endoscopic vision with data fusion of cnn prediction and kinematic pose
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9821
EP  - 9827
AU  - F. Qin
AU  - Y. Li
AU  - Y. Su
AU  - D. Xu
AU  - B. Hannaford
PY  - 2019
KW  - convolutional neural nets
KW  - endoscopes
KW  - feature extraction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - medical image processing
KW  - object tracking
KW  - particle filtering (numerical methods)
KW  - pose estimation
KW  - sensor fusion
KW  - surgery
KW  - endoscopic vision
KW  - data fusion
KW  - robust surgical instrument segmentation
KW  - instrument segmentation method
KW  - convolutional neural networks prediction
KW  - kinematic pose information
KW  - CNN model ToolNet-C
KW  - convolutional feature extractor
KW  - pixel-wise segmentor
KW  - labeled images
KW  - silhouette projection
KW  - instrument body
KW  - endoscopic image
KW  - shape matching likelihood
KW  - accurate silhouette mask
KW  - final segmentation output
KW  - surgical navigation system
KW  - debrider instrument
KW  - unlabeled images
KW  - Instruments
KW  - Image segmentation
KW  - Feature extraction
KW  - Kinematics
KW  - Training
KW  - Shape
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8794122
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The real-time and robust surgical instrument segmentation is an important issue for endoscopic vision. We propose an instrument segmentation method fusing the convolutional neural networks (CNN) prediction and the kinematic pose information. First, the CNN model ToolNet-C is designed, which cascades a convolutional feature extractor trained over numerous unlabeled images and a pixel-wise segmentor trained on few labeled images. Second, the silhouette projection of the instrument body onto the endoscopic image is implemented based on the measured kinematic pose. Third, the particle filter with the shape matching likelihood and the weight suppression is proposed for data fusion, whose estimate refines the kinematic pose. The refined pose determines an accurate silhouette mask, which is the final segmentation output. The experiments are conducted with a surgical navigation system, several animal-tissue backgrounds, and a debrider instrument.
ER  - 

TY  - CONF
TI  - Pneumatically Actuated Deployable Tissue Distension Device for NOTES for Colon
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9828
EP  - 9833
AU  - M. Miyasaka
AU  - J. Liu
AU  - L. Cao
AU  - S. J. Phee
PY  - 2019
KW  - biological tissues
KW  - endoscopes
KW  - medical control systems
KW  - pneumatic actuators
KW  - pneumatic systems
KW  - surgery
KW  - pneumatically actuated deployable tissue distension device
KW  - colon tortuous pathway
KW  - pig colon
KW  - natural orifice transluminal endoscopic surgery
KW  - endoscopic channel
KW  - pneumatically driven deployable structure
KW  - colon tissue
KW  - NOTES technology
KW  - surgical tasks
KW  - actuated deployable tissue distension device
KW  - surgical operations
KW  - surgical instruments
KW  - air pressure
KW  - size 4.5 mm
KW  - size 60.0 mm
KW  - pressure 3.5 bar
KW  - Colon
KW  - Electron tubes
KW  - Surgery
KW  - Task analysis
KW  - Bars
KW  - Shape
KW  - Valves
DO  - 10.1109/ICRA.2019.8793937
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When performing some surgical tasks inside colon with NOTES technology, colon tissue could block the task space and occlude the endoscopic vision. In order to solve this problem, we developed a pneumatically driven deployable and undeployable structure which can distend collapsing tissue and can be delivered through a 4.5 mm endoscopic channel. The structure is designed to be flexible enough to pass through colon's tortuous pathway. Also, it is designed to hold its shape without continually applying air pressure after deployment. This allows to make use of an endoscopic channel for the other surgical instruments. Besides, due to the compliant nature of the device, it is safe to deploy inside a smaller space than its maximum deployable size. The functionality of the device was verified with an in-vitro experiment. The structure was successfully deployed inside a pig's colon with an inner diameter of 60 mm by applying 3.5 bars of air pressure and created a sufficient task space for surgical operations.
ER  - 

TY  - CONF
TI  - Steering a Multi-armed Robotic Sheath Using Eccentric Precurved Tubes
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 9834
EP  - 9840
AU  - J. Wang
AU  - J. Ha
AU  - P. E. Dupont
PY  - 2019
KW  - dexterous manipulators
KW  - elasticity
KW  - medical robotics
KW  - neurophysiology
KW  - pipes
KW  - robot kinematics
KW  - surgery
KW  - kinematic model
KW  - multiarmed robotic sheath
KW  - eccentric precurved tubes
KW  - single-port minimally invasive procedures
KW  - multiple robotic arms
KW  - precurved superelastic tubes
KW  - Cosserat rod theory
KW  - two-arm sheath
KW  - concentric tube balanced pair
KW  - neuroendoscopy
KW  - elastic backbone
KW  - push-pull tendons
KW  - continuum robot sheath
KW  - Electron tubes
KW  - Force
KW  - Kinematics
KW  - Shape
KW  - Endoscopes
KW  - Manipulators
KW  - Steerable sheath
KW  - Multiple arms
KW  - Concentric tube robots
DO  - 10.1109/ICRA.2019.8794245
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel continuum robot sheath for use in single-port minimally invasive procedures such as neuroendoscopy in which the sheath is designed to deliver multiple robotic arms. Articulation of the sheath is achieved by using precurved superelastic tubes lining the working channels used for arm delivery. These tubes perform a similar role to push/pull tendons, but can accomplish shape change of the sheath via rotation as well as translation. A kinematic model using Cosserat rod theory is derived which is based on modeling the system as a set of eccentrically aligned precurved tubes constrained along their length by an elastic backbone. The specific case of a two-arm sheath is considered in detail and its relationship to a concentric tube balanced pair is described. Simulation and experiment are used to investigate the concept, map its workspace and to evaluate the kinematic model.
ER  - 

TY  - CONF
TI  - Circular and Concentric Formation of Kinematic Unicycles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 6
AU  - M. Iqbal
AU  - S. Azuma
AU  - J. Leth
AU  - T. D. Ngo
PY  - 2019
KW  - asymptotic stability
KW  - control system synthesis
KW  - distributed control
KW  - Lyapunov methods
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - robot kinematics
KW  - velocity control
KW  - desired circular orbit
KW  - circular formations
KW  - concentric formations
KW  - kinematic unicycles
KW  - circular formation
KW  - concentric formation stabilization problem
KW  - design distributed control laws
KW  - common circle
KW  - velocity control law
KW  - specific formation
KW  - Kinematics
KW  - Decentralized control
KW  - Orbits
KW  - Laplace equations
KW  - Satellites
KW  - Asymptotic stability
KW  - Angular velocity
DO  - 10.1109/ICRA.2019.8908710
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the circular formation and concentric formation stabilization problem of kinematic unicycles. We design distributed control laws driving unicycles to converge to a common circle at the first stage and a velocity control law enabling unicycles to achieve a specific formation on the circle at the second stage. We also achieve the concentric formation by dividing unicycles into groups and design distributed control laws reinforcing each group at a desired circular orbit from the stationary center. We provide analysis to show that both the circular and concentric formations are asymptotically stable using set stabilization theory. Typical examples are selected to demonstrate and support the theoretical results.
ER  - 

TY  - CONF
TI  - Continuous signed distance computation for polygonal robots in 3D
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1
EP  - 7
AU  - Y. Lee
AU  - A. Kheddar
AU  - Y. J. Kim
PY  - 2019
KW  - collision avoidance
KW  - computational geometry
KW  - humanoid robots
KW  - mobile robots
KW  - collision-free motion
KW  - HRP-2 humanoid robot
KW  - collision avoidance
KW  - minimum of the continuous distance
KW  - continuous signed distance computation
KW  - distance evaluation method
KW  - MCD
KW  - object trajectory
KW  - time interval
KW  - penetration depth
KW  - Euclidean distance
KW  - general polygonal models
KW  - distance function
KW  - adaptive subdivision method
KW  - polygonal robots
DO  - 10.1109/ICRA39644.2019.8975893
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel method adaptive subdivision (AS) to evaluate the distance function for moving general polygonal models. The distance function can have a positive and a negative value, each of which corresponds to the Euclidean distance and penetration depth, respectively. In our approach, the distance between a pair of objects can be evaluated along any time interval of the object's trajectory; therefore it is called “continuous”, and a minimum of the continuous distance (MCD) is determined for collision avoidance. In order to compute a MCD for general polygonal models, we calculate the upper and lower bounds of the distance in the time interval and abandons the time intervals that cannot realize the MCD. We have implemented our distance evaluation method, and have experimentally validated the proposed methods to effectively and accurately find the MCDs to generate a collision-free motion for the HRP-2 humanoid robot.
ER  - 


TY  - CONF
TI  - Dynamics Consensus between Centroidal and Whole-Body Models for Locomotion of Legged Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6727
EP  - 6733
AU  - R. Budhiraja
AU  - J. Carpentier
AU  - N. Mansard
PY  - 2019
KW  - humanoid robots
KW  - legged locomotion
KW  - manipulator dynamics
KW  - motion control
KW  - optimal control
KW  - optimisation
KW  - pendulums
KW  - whole-body level
KW  - whole-body optimal control problem
KW  - centroidal dynamics
KW  - manipulator dynamics
KW  - effective locomotion
KW  - HRP-2 robot
KW  - dynamics consensus
KW  - legged robots
KW  - large control problem
KW  - complex optimal control problem
KW  - numerical solver
KW  - inverted pendulum
KW  - capture points
KW  - whole-body constraints
KW  - reduced level
KW  - reduced solution
KW  - centroidal state dynamics
KW  - mathematical framework
KW  - Dynamics
KW  - Legged locomotion
KW  - Trajectory
KW  - Optimization
KW  - Convex functions
KW  - Optimal control
DO  - 10.1109/ICRA.2019.8793878
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - It is nowadays well-established that locomotion can be written as a large and complex optimal control problem. Yet, current knowledge in numerical solver fails to directly solve it. A common approach is to cut the dimensionality by relying on reduced models (inverted pendulum, capture points, centroidal). However it is difficult both to account for whole-body constraints at the reduced level and also to define what is an acceptable trade-off at the whole-body level between tracking the reduced solution or searching for a new one. The main contribution of this paper is to introduce a rigorous mathematical framework based on the Alternating Direction Method of Multipliers, to enforce the consensus between the centroidal state dynamics at reduced and whole-body level. We propose an exact splitting of the whole-body optimal control problem between the centroidal dynamics (under-actuation) and the manipulator dynamics (full actuation), corresponding to a re-arrangement of the equations already stated in previous works. We then describe with details how alternating descent is a good solution to implement an effective locomotion solver. We validate this approach in simulation with walking experiments on the HRP-2 robot.
ER  - 

TY  - CONF
TI  - Adaptive Bingham Distribution Based Filter for SE (3) Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6734
EP  - 6740
AU  - F. Li
AU  - G. A. G. Ricardez
AU  - J. Takamatsu
AU  - T. Ogasawara
PY  - 2019
KW  - adaptive filters
KW  - Gaussian distribution
KW  - pose estimation
KW  - SO(3) groups
KW  - incremental properties
KW  - Gaussian distribution
KW  - pose parameters
KW  - adaptive filtering ability
KW  - adaptive Bingham distribution
KW  - filter-based methods
KW  - autonomous tuning
KW  - SE (3) estimation
KW  - 3D pose estimation problems
KW  - SO(3) group
KW  - Measurement uncertainty
KW  - Pose estimation
KW  - Uncertainty
KW  - Kalman filters
KW  - Gaussian distribution
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8793997
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Filter-based methods are a suitable option to deal with the burdensome 3D pose estimation problems for their incremental properties. The classical approaches use the Gaussian distribution to model the uncertainty of the pose parameters and recent work has begun to take advantage of the Bingham distribution, which is theoretically more suitable for modeling uncertainty on the SO(3) group. However, these algorithms are still at the very beginning and heavily rely on manual tuning. In this work we equip the Bingham distribution based filter with adaptive filtering ability, which realizes completely autonomous tuning without human interaction. The experiments demonstrate that our method is significantly laborsaving compared to the state-of-the-art methods as well as capable of maintaining high accuracy.
ER  - 

TY  - CONF
TI  - GuSTO: Guaranteed Sequential Trajectory optimization via Sequential Convex Programming
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6741
EP  - 6747
AU  - R. Bonalli
AU  - A. Cauligi
AU  - A. Bylard
AU  - M. Pavone
PY  - 2019
KW  - convex programming
KW  - optimal control
KW  - GuSTO
KW  - control-affine systems
KW  - indirect optimal control
KW  - guaranteed sequential trajectory optimization
KW  - optimal control setups
KW  - SCP-based methods
KW  - theoretical convergence
KW  - sequential convex programming
KW  - algorithmic framework
KW  - Trajectory optimization
KW  - Convergence
KW  - Optimal control
KW  - Robots
KW  - Heuristic algorithms
KW  - Planning
DO  - 10.1109/ICRA.2019.8794205
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Sequential Convex Programming (SCP) has recently seen a surge of interest as a tool for trajectory optimization. However, most available methods lack rigorous performance guarantees and they are often tailored to specific optimal control setups. In this paper, we present GuSTO (Guaranteed Sequential Trajectory optimization), an algorithmic framework to solve trajectory optimization problems for control-affine systems with drift. GuSTO generalizes earlier SCP-based methods for trajectory optimization (by addressing, for example, goal-set constraints and problems with either fixed or free final time) and enjoys theoretical convergence guarantees in terms of convergence to, at least, a stationary point. The theoretical analysis is further leveraged to devise an accelerated implementation of GuSTO, which originally infuses ideas from indirect optimal control into an SCP context. Numerical experiments on a variety of trajectory optimization setups show that GuSTO generally outperforms current state-of-the-art approaches in terms of success rates, solution quality, and computation times.
ER  - 

TY  - CONF
TI  - Efficient Computation of Feedback Control for Equality-Constrained LQR
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6748
EP  - 6754
AU  - F. Laine
AU  - C. Tomlin
PY  - 2019
KW  - discrete time systems
KW  - feedback
KW  - linear quadratic control
KW  - optimisation
KW  - Riccati equations
KW  - robots
KW  - feedback control
KW  - equality-constrained LQR
KW  - discrete-time finite-horizon Linear Quadratic Regulator problem
KW  - auxiliary linear equality constraints
KW  - fixed end-point constraints
KW  - standard Riccati recursion
KW  - linearly-constrained LQR problem
KW  - robotic trajectory optimization
KW  - Robots
KW  - Feedback control
KW  - Optimal control
KW  - Trajectory optimization
KW  - Computational complexity
KW  - Dynamic programming
DO  - 10.1109/ICRA.2019.8793566
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A method is presented for solving the discrete-time finite-horizon Linear Quadratic Regulator (LQR) problem subject to auxiliary linear equality constraints, such as fixed end-point constraints. The method explicitly determines an affine relationship between the control and state variables, as in standard Riccati recursion, giving rise to feedback control policies that account for constraints. Since the linearly-constrained LQR problem arises commonly in robotic trajectory optimization, having a method that can efficiently compute these solutions is important. We demonstrate some of the useful properties and interpretations of said control policies, and we compare the computation time and complexity of our method against existing methods.
ER  - 

TY  - CONF
TI  - Mitigating energy loss in a robot hopping on a physically emulated dissipative substrate
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6763
EP  - 6769
AU  - S. Roberts
AU  - D. E. Koditschek
PY  - 2019
KW  - damping
KW  - energy conservation
KW  - legged locomotion
KW  - motion control
KW  - position control
KW  - sand
KW  - mitigating energy loss
KW  - physically emulated dissipative substrate
KW  - erosion
KW  - desertification
KW  - spatial resolution
KW  - temporal resolution
KW  - data collection
KW  - attractive scout robot candidate
KW  - heavily geared sensor-laden RHex
KW  - long-distance locomotion
KW  - virtual damping force
KW  - Minitaur foot
KW  - simulated granular media
KW  - bulk-behavior force law
KW  - ground emulator
KW  - single-legged hopper
KW  - physical hopping experiments
KW  - substrate emulator
KW  - linear stiffness
KW  - quadratic damping
KW  - Minitaur robot
KW  - ground properties
KW  - bulk-behavior model
KW  - energy savings
KW  - robot hopping
KW  - physical single-legged hopper jumping
KW  - Legged locomotion
KW  - Springs
KW  - Damping
KW  - Media
KW  - Foot
KW  - Force
DO  - 10.1109/ICRA.2019.8793781
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We work with geoscientists studying erosion and desertification to improve the spatial and temporal resolution of their data collection over long transects in difficult realworld environments such as deserts [1]. The Minitaur [2] robot, which can run quickly over uneven terrain and use a single leg to measure relevant ground properties such as stiffness [3], is an attractive scout robot candidate for inclusion in a heterogeneous team in collaboration with a heavily geared, sensor-laden RHex [4]. However, Minitaur is challenged by long-distance locomotion on sand dunes. Previous simulation results [5] suggested that the energetic cost of transport can be mitigated by programming a virtual damping force to slow the intrusion of a Minitaur foot into simulated granular media following a bulk-behavior force law [6]. In this paper, we present a ground emulator that can be used to test such locomotion hypotheses with a physical single-legged hopper jumping on emulated ground programmed to exhibit any compliance and damping characteristics of interest. The new emulator allows us to corroborate the conclusions of our previous simulation with physical hopping experiments. Programming the substrate emulator to exhibit the mechanics of a simplified bulk-behavior model of granular media characterized by linear stiffness and quadratic damping, we achieve a consistent energy savings of 20% in comparison with a nominal controller, with savings of up to 50% under specific conditions.
ER  - 

TY  - CONF
TI  - Energy Efficient Navigation for Running Legged Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6770
EP  - 6776
AU  - M. Y. Harper
AU  - J. V. Nicholson
AU  - E. G. Collins
AU  - J. Pusey
AU  - J. E. Clark
PY  - 2019
KW  - energy conservation
KW  - energy consumption
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - path planning
KW  - robot dynamics
KW  - sampling methods
KW  - search problems
KW  - trajectory control
KW  - mobile robots
KW  - energy savings
KW  - energy consumption
KW  - energy efficient navigation
KW  - running legged robots
KW  - sampling-based model predictive optimization
KW  - LLAMA quadrupedal platform
KW  - heuristic-based search
KW  - robot dynamics
KW  - robot motion plan
KW  - trajectory planning
KW  - Legged locomotion
KW  - Trajectory
KW  - Computational modeling
KW  - Predictive models
KW  - Planning
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8793599
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Energy-efficient navigation is an important technology for mobile robots because of its potential to increase the operation time of the robot. In particular, when coupled with a dynamic legged quadruped, the need for energy savings is made more apparent as payloads are limited. Due to the complexity in modeling motion and power models of these robots, a new approach is necessary to effectively motion plan for these complex robots. We accomplish this by using Sampling-Based Model Predictive optimization (SBMPO) which was extended for use on the LLAMA quadrupedal platform in simulation. SBMPO allows for direct generation of trajectories while using a heuristic-based search to speed up computations. This approach is shown to effectively motion plan while optimizing for energy consumption and maintaining the natural dynamics of the robot in a simulated environment.
ER  - 

TY  - CONF
TI  - Force-controllable Quadruped Robot System with Capacitive-type Joint Torque Sensor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6777
EP  - 6782
AU  - Y. H. Lee
AU  - Y. H. Lee
AU  - H. Lee
AU  - H. Kang
AU  - L. T. Phan
AU  - S. Jin
AU  - Y. B. Kim
AU  - D. Seok
AU  - S. Y. Lee
AU  - H. Moon
AU  - J. C. Koo
AU  - H. R. Choi
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - force control
KW  - gait analysis
KW  - legged locomotion
KW  - motion control
KW  - robot dynamics
KW  - torque control
KW  - force-controllable quadruped robot system
KW  - CJTS
KW  - zero-force control
KW  - walking/trot gait
KW  - capacitive-type joint torque sensor
KW  - joint torque controllability
KW  - actuator module
KW  - size 0.05 nm
KW  - size 70.0 nm
KW  - time 0.04 s
KW  - Robot sensing systems
KW  - Torque
KW  - Actuators
KW  - Legged locomotion
KW  - Torque measurement
DO  - 10.1109/ICRA.2019.8794459
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces a force-controllable quadruped robot system consists of twelve Actuator Modules embedded a novel Capacitive-type Joint Torque Sensor (CJTS) which is accurate (0.05 Nm), robust to impact, and easy to manufacture at low cost. The Actuator Module with CJTS shows accurate joint torque controllability in range of ±70 Nm (90 % settling time 0.04 s). The leg made by the three Actuator Modules is capable of generating forces in the z-axis up to 350 N and shows force control performances with zero-force control and lifting weights in three-dimensional space. To reduce the reflected limb inertia, all the Actuator Modules are located on the body frame and light-weight limbs made of the carbon pipe (3.6 % of total body weight). The introduced robot performed the motion on various terrains with walking/trot gaits.
ER  - 

TY  - CONF
TI  - Visual Diver Recognition for Underwater Human-Robot Collaboration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6839
EP  - 6845
AU  - Y. Xia
AU  - J. Sattar
PY  - 2019
KW  - autonomous underwater vehicles
KW  - convolutional neural nets
KW  - human-robot interaction
KW  - mobile robots
KW  - multi-robot systems
KW  - object detection
KW  - pattern clustering
KW  - visual diver recognition
KW  - underwater human-robot collaboration
KW  - autonomous underwater robot
KW  - visual scene
KW  - human leader
KW  - detected bounding boxes
KW  - mobile robot
KW  - k-means clustering algorithm
KW  - feature vector
KW  - frequency domain descriptors
KW  - spatial domain descriptors
KW  - region proposal network
KW  - faster R-CNN algorithm
KW  - diver identification
KW  - multihuman-robot teams
KW  - multiple divers detection
KW  - Feature extraction
KW  - Robots
KW  - Image color analysis
KW  - Image edge detection
KW  - Visualization
KW  - Target tracking
DO  - 10.1109/ICRA.2019.8794290
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents an approach for autonomous underwater robots to visually detect and identify divers. The proposed approach enables an autonomous underwater robot to detect multiple divers in a visual scene and distinguish between them. Such methods are useful for robots to identify a human leader, for example, in multi-human/robot teams where only designated individuals are allowed to command or lead a team of robots. Initial diver identification is performed using the Faster R-CNN algorithm with a region proposal network which produces bounding boxes around the divers' locations. Subsequently, a suite of spatial and frequency domain descriptors are extracted from the bounding boxes to create a feature vector. A K-Means clustering algorithm, with k set to the number of detected bounding boxes, thereafter identifies the detected divers based on these feature vectors. We evaluate the performance of the proposed approach on video footage of divers swimming in front of a mobile robot and demonstrate its accuracy.
ER  - 

TY  - CONF
TI  - An Integrated Approach to Navigation and Control in Micro Underwater Robotics using Radio-Frequency Localization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6846
EP  - 6852
AU  - D. A. Duecker
AU  - T. Johannink
AU  - E. Kreuzer
AU  - V. Rausch
AU  - E. Solowjow
PY  - 2019
KW  - autonomous underwater vehicles
KW  - marine navigation
KW  - microrobots
KW  - mobile robots
KW  - position control
KW  - radio-frequency localization
KW  - microautonomous underwater vehicles
KW  - μAUVs
KW  - integrated navigation
KW  - control architecture
KW  - low-cost embedded localization module
KW  - integrated approach
KW  - underwater localization systems
KW  - microunderwater robotics
KW  - underwater way-point tracking controller
KW  - Robots
KW  - Attenuation
KW  - Navigation
KW  - Acoustics
KW  - Computer architecture
KW  - Noise measurement
KW  - Measurement uncertainty
DO  - 10.1109/ICRA.2019.8794088
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Navigation and control are a largely unsolved problems for micro autonomous underwater vehicles (μAUVs). The main challenges are due to the lack of accurate underwater localization systems, which fit on-board of μAUVs. In this work, we present an integrated navigation and control architecture consisting of a low-cost embedded localization module and an underwater way-point tracking controller, which fulfills the requirements of μAUVs. The performance of the navigation and control system is benchmarked in two different experimental scenarios.
ER  - 

TY  - CONF
TI  - Online Utility-Optimal Trajectory Design for Time-Varying Ocean Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6853
EP  - 6859
AU  - M. K. Nutalapati
AU  - S. Joshi
AU  - K. Rajawat
PY  - 2019
KW  - convex programming
KW  - energy consumption
KW  - gradient methods
KW  - marine engineering
KW  - mobile robots
KW  - time-varying systems
KW  - trajectory control
KW  - online utility-optimal trajectory design
KW  - time-varying ocean environments
KW  - time-varying environments
KW  - energy-efficient trajectories
KW  - strong disturbances
KW  - uncertain disturbances
KW  - time-varying goal location
KW  - constrained online convex optimization formalism
KW  - gradient descent algorithm
KW  - vehicle locations
KW  - energy consumption
KW  - regional ocean modelling system
KW  - ocean velocity measurements
KW  - Trajectory
KW  - Oceans
KW  - Planning
KW  - Convex functions
KW  - Delays
KW  - Energy consumption
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794365
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper considers the problem of online optimal trajectory design under time-varying environments. Of particular interest is the design of energy-efficient trajectories under strong and uncertain disturbances in ocean environments and time-varying goal location. We formulate the problem within the constrained online convex optimization formalism, and a modified online gradient descent algorithm is motivated. The mobility constraints are met using a carefully chosen stepsize, and the proposed algorithm is shown to incur sublinear regret. Different from the state-of-the-art algorithms that entail planning and re-planning the full trajectory using forecast data at each time instant, the proposed algorithm is entirely online and relies mostly on the current ocean velocity measurements at the vehicle locations. The trade-off between excess delay incurred in reaching the goal and the overall energy consumption is examined via numerical tests carried out on real data obtained from the regional ocean modelling system. As compared to the state-of-the-art algorithms, the proposed algorithm is not only energy-efficient but also several orders of magnitude computationally efficient.
ER  - 

TY  - CONF
TI  - Online Continuous Mapping using Gaussian Process Implicit Surfaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6884
EP  - 6890
AU  - B. Lee
AU  - C. Zhang
AU  - Z. Huang
AU  - D. D. Lee
PY  - 2019
KW  - approximation theory
KW  - Gaussian processes
KW  - mobile robots
KW  - path planning
KW  - regression analysis
KW  - implicit surface
KW  - SDF
KW  - regressor
KW  - gaussian process implicit surface
KW  - robotic tasks
KW  - signed-distance function
KW  - sparse measurements
KW  - grid-based methods
KW  - online continuous mapping
KW  - Surface treatment
KW  - Planning
KW  - Noise measurement
KW  - Training
KW  - Robot kinematics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794324
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The representation of the environment strongly affects how robots can move and interact with it. This paper presents an online approach for continuous mapping using Gaussian Process Implicit Surfaces (GPISs). Compared with grid-based methods, GPIS better utilizes sparse measurements to represent the world seamlessly. It provides direct access to the signed-distance function (SDF) and its derivatives which are invaluable for other robotic tasks and it incorporates uncertainty in the sensor measurements. Our approach incrementally and efficiently updates GPIS by employing a regressor on observations and a spatial tree structure. The effectiveness of the suggested approach is demonstrated using simulations and real world 2D/3D data.
ER  - 

TY  - CONF
TI  - Dense 3D Visual Mapping via Semantic Simplification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6891
EP  - 6897
AU  - L. Morreale
AU  - A. Romanoni
AU  - M. Matteucci
AU  - P. d. Milano
PY  - 2019
KW  - data visualisation
KW  - image reconstruction
KW  - image segmentation
KW  - mesh generation
KW  - robot vision
KW  - solid modelling
KW  - semantic image segmentation
KW  - perceived point cloud
KW  - global statistics
KW  - class boundaries
KW  - infra-class edges
KW  - 3D dense model
KW  - 3D Delaunay Triangulation
KW  - variable point cloud density
KW  - semantic simplification
KW  - dense 3D visual mapping estimates
KW  - dense point clouds
KW  - pixel depths
KW  - point cloud simplification methods
KW  - roughly planar surface
KW  - Three-dimensional displays
KW  - Semantics
KW  - Solid modeling
KW  - Image reconstruction
KW  - Image segmentation
KW  - Structure from motion
KW  - Surface reconstruction
DO  - 10.1109/ICRA.2019.8793256
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dense 3D visual mapping estimates as many as possible pixel depths, for each image. This results in very dense point clouds that often contain redundant and noisy information, especially for surfaces that are roughly planar, for instance, the ground or the walls in the scene. In this paper we leverage on semantic image segmentation to discriminate which regions of the scene require simplification and which should be kept at high level of details. We propose four different point cloud simplification methods which decimate the perceived point cloud by relying on class-specific local and global statistics still maintaining more points in the proximity of class boundaries to preserve the infra-class edges and discontinuities. 3D dense model is obtained by fusing the point clouds in a 3D Delaunay Triangulation to deal with variable point cloud density. In the experimental evaluation we have shown that, by leveraging on semantics, it is possible to simplify the model and diminish the noise affecting the point clouds.
ER  - 

TY  - CONF
TI  - Predicting the Layout of Partially Observed Rooms from Grid Maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6898
EP  - 6904
AU  - M. Luperto
AU  - V. Arcerito
AU  - F. Amigoni
PY  - 2019
KW  - control engineering computing
KW  - mobile robots
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - SLAM algorithms
KW  - 2D metric grid map
KW  - global structure
KW  - partially observed rooms
KW  - autonomous mobile robots
KW  - indoor environments
KW  - robot sensors
KW  - geometrical primitives
KW  - Layout
KW  - Measurement
KW  - Robots
KW  - Indoor environment
KW  - Two dimensional displays
KW  - Three-dimensional displays
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8793489
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In several applications, autonomous mobile robots benefit from knowing the structure of the indoor environments where they operate. This knowledge can be extracted from the metric maps built (e.g., using SLAM algorithms) from the data perceived by the robots' sensors. The layout is a way to represent the structure of an indoor environment with geometrical primitives. Most of the current methods for reconstructing the layout from a metric map represent the parts of the environment that have been fully observed. In this paper, we propose an approach that predicts the layout of rooms which are only partially known in a 2D metric grid map. The prediction is made according to the global structure of the environment, as identified from its known parts. Experiments show that our approach is able to effectively predict the layout of several indoor environments that have been observed to different degrees.
ER  - 

TY  - CONF
TI  - Dense Surface Reconstruction from Monocular Vision and LiDAR
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6905
EP  - 6911
AU  - Z. Li
AU  - P. C. Gogia
AU  - M. Kaess
PY  - 2019
KW  - cameras
KW  - graph theory
KW  - image reconstruction
KW  - mobile robots
KW  - optical radar
KW  - pipelines
KW  - robot vision
KW  - stereo image processing
KW  - surface reconstruction
KW  - LiDAR measurements
KW  - multiview stereo pipeline
KW  - watertight surface mesh
KW  - state-of-the-art camera-only
KW  - LiDAR-only reconstruction methods
KW  - monocular vision
KW  - surface reconstruction pipeline
KW  - monocular camera images
KW  - moving sensor rig
KW  - indoor scenes
KW  - indoor environments
KW  - 3D mesh models
KW  - state-of-the-art multiview stereo
KW  - graph cut algorithm
KW  - Laser radar
KW  - Cameras
KW  - Three-dimensional displays
KW  - Image reconstruction
KW  - Surface reconstruction
KW  - Pipelines
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793729
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we develop a new surface reconstruction pipeline that combines monocular camera images and LiDAR measurements from a moving sensor rig to reconstruct dense 3D mesh models of indoor scenes. For surface reconstruction, the 3D LiDAR and camera are widely deployed for gathering geometric information from environments. Current state-of-the-art multi-view stereo or LiDAR-only reconstruction methods cannot reconstruct indoor environments accurately due to shortcomings of each sensor type. In our approach, LiDAR measurements are integrated into a multi-view stereo pipeline for point cloud densification and tetrahedralization. In addition to that, a graph cut algorithm is utilized to generate a watertight surface mesh. Because our proposed method leverages the complementary nature of these two sensors, the accuracy and completeness of the output model are improved. The experimental results on real world data show that our method significantly outperforms both the state-of-the-art camera-only and LiDAR-only reconstruction methods in accuracy and completeness.
ER  - 

TY  - CONF
TI  - FSMI: Fast Computation of Shannon Mutual Information for Information-Theoretic Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6912
EP  - 6918
AU  - Z. Zhang
AU  - T. Henderson
AU  - V. Sze
AU  - S. Karaman
PY  - 2019
KW  - approximation theory
KW  - gradient methods
KW  - information theory
KW  - mobile robots
KW  - multi-robot systems
KW  - FSMI algorithm
KW  - fast Shannon mutual information
KW  - Cauchy-Schwarz quadratic mutual information
KW  - information-based mapping algorithms
KW  - information-theoretic mapping
KW  - CSQMI
KW  - FSMI
KW  - Mutual information
KW  - Approximation algorithms
KW  - Robot sensing systems
KW  - Measurement
KW  - Standards
KW  - Random variables
DO  - 10.1109/ICRA.2019.8793541
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Information-based mapping algorithms are critical to robot exploration tasks in several applications ranging from disaster response to space exploration. Unfortunately, most existing information-based mapping algorithms are plagued by the computational difficulty of evaluating the Shannon mutual information between potential future sensor measurements and the map. This has lead researchers to develop approximate methods, such as Cauchy-Schwarz Quadratic Mutual Information (CSQMI). In this paper, we propose a new algorithm, called Fast Shannon Mutual Information (FSMI), which is significantly faster than existing methods at computing the exact Shannon mutual information. The key insight behind FSMI is recognizing that the integral over the sensor beam can be evaluated analytically, removing an expensive numerical integration. In addition, we provide a number of approximation techniques for FSMI, which significantly improve computation time. Equipped with these approximation techniques, the FSMI algorithm is more than three orders of magnitude faster than the existing computation for Shannon mutual information; it also outperforms the CSQMI algorithm significantly, being roughly twice as fast, in our experiments.
ER  - 

TY  - CONF
TI  - Real-time Scalable Dense Surfel Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6919
EP  - 6925
AU  - K. Wang
AU  - F. Gao
AU  - S. Shen
PY  - 2019
KW  - image fusion
KW  - image reconstruction
KW  - pose estimation
KW  - SLAM (robots)
KW  - intensity images
KW  - depth images
KW  - globally consistent model
KW  - room-scale environments
KW  - urban-scale environments
KW  - RGB-D cameras
KW  - stereo cameras
KW  - monocular camera
KW  - superpixel-based surfels
KW  - reconstructed models
KW  - fast map deformation
KW  - global consistency
KW  - room-scale reconstruction
KW  - time scalable dense surfel
KW  - CPU computation
KW  - sparse SLAM system
KW  - camera poses
KW  - dense surfel mapping system
KW  - Cameras
KW  - Image reconstruction
KW  - Strain
KW  - Fuses
KW  - Robot vision systems
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8794101
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a novel dense surfel mapping system that scales well in different environments with only CPU computation. Using a sparse SLAM system to estimate camera poses, the proposed mapping system can fuse intensity images and depth images into a globally consistent model. The system is carefully designed so that it can build from room-scale environments to urban-scale environments using depth images from RGB-D cameras, stereo cameras or even a monocular camera. First, superpixels extracted from both intensity and depth images are used to model surfels in the system. superpixel-based surfels make our method both runtime efficient and memory efficient. Second, surfels are further organized according to the pose graph of the SLAM system to achieve O(1) fusion time regardless of the scale of reconstructed models. Third, a fast map deformation using the optimized pose graph enables the map to achieve global consistency in real-time. The proposed surfel mapping system is compared with other state-of-the-art methods on synthetic datasets. The performances of urban-scale and room-scale reconstruction are demonstrated using the KITTI dataset [1] and autonomous aggressive flights, respectively. The code is available for the benefit of the community.
ER  - 

TY  - CONF
TI  - Inferring Compact Representations for Efficient Natural Language Understanding of Robot Instructions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6926
EP  - 6933
AU  - S. Patki
AU  - A. F. Daniele
AU  - M. R. Walter
AU  - T. M. Howard
PY  - 2019
KW  - control engineering computing
KW  - graph theory
KW  - human-robot interaction
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - natural language processing
KW  - probability
KW  - robot programming
KW  - compact environment model
KW  - perceptual classifiers
KW  - succinct instruction-specific environment representation
KW  - probabilistic graphical models
KW  - natural language symbol grounding
KW  - robot instructions
KW  - approximate inference algorithms
KW  - natural language understanding
KW  - environment-related information
KW  - human-robot interaction
KW  - compact representations
KW  - Grounding
KW  - Natural languages
KW  - Computational modeling
KW  - Adaptation models
KW  - Robots
KW  - Semantics
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793667
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The speed and accuracy with which robots are able to interpret natural language is fundamental to realizing effective human-robot interaction. A great deal of attention has been paid to developing models and approximate inference algorithms that improve the efficiency of language understanding. However, existing methods still attempt to reason over a representation of the environment that is flat and unnecessarily detailed, which limits scalability. An open problem is then to develop methods capable of producing the most compact environment model sufficient for accurate and efficient natural language understanding. We propose a model that leverages environment-related information encoded within instructions to identify the subset of observations and perceptual classifiers necessary to perceive a succinct, instruction-specific environment representation. The framework uses three probabilistic graphical models trained from a corpus of annotated instructions to infer salient scene semantics, perceptual classifiers, and grounded symbols. Experimental results on two robots operating in different environments demonstrate that by exploiting the content and the structure of the instructions, our method learns compact environment representations that significantly improve the efficiency of natural language symbol grounding.
ER  - 

TY  - CONF
TI  - Improving Grounded Natural Language Understanding through Human-Robot Dialog
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6934
EP  - 6941
AU  - J. Thomason
AU  - A. Padmakumar
AU  - J. Sinapov
AU  - N. Walker
AU  - Y. Jiang
AU  - H. Yedidsion
AU  - J. Hart
AU  - P. Stone
AU  - R. J. Mooney
PY  - 2019
KW  - grammars
KW  - human-robot interaction
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - natural language understanding
KW  - human-robot dialog
KW  - virtual setting
KW  - Amazon Mechanical Turk
KW  - physical robot platform
KW  - concept grounding
KW  - language parsing
KW  - robot actions
KW  - natural language commands
KW  - end-to-end pipeline
KW  - perceptual concepts
KW  - language constructions
KW  - human environments
KW  - human commands
KW  - Semantics
KW  - Task analysis
KW  - Grounding
KW  - Natural languages
KW  - Robot sensing systems
KW  - Pipelines
DO  - 10.1109/ICRA.2019.8794287
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Natural language understanding for robotics can require substantial domain- and platform-specific engineering. For example, for mobile robots to pick-and-place objects in an environment to satisfy human commands, we can specify the language humans use to issue such commands, and connect concept words like red can to physical object properties. One way to alleviate this engineering for a new domain is to enable robots in human environments to adapt dynamically-continually learning new language constructions and perceptual concepts. In this work, we present an end-to-end pipeline for translating natural language commands to discrete robot actions, and use clarification dialogs to jointly improve language parsing and concept grounding. We train and evaluate this agent in a virtual setting on Amazon Mechanical Turk, and we transfer the learned agent to a physical robot platform to demonstrate it in the real world.
ER  - 

TY  - CONF
TI  - Prospection: Interpretable plans from language by predicting the future
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6942
EP  - 6948
AU  - C. Paxton
AU  - Y. Bisk
AU  - J. Thomason
AU  - A. Byravan
AU  - D. Foxl
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - robot programming
KW  - high-level human instructions
KW  - natural-language command
KW  - crowd-sourcing
KW  - plan fidelity
KW  - representations learning
KW  - robot agent
KW  - Task analysis
KW  - Robots
KW  - Training
KW  - Natural languages
KW  - Visualization
KW  - Planning
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8794441
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - High-level human instructions often correspond to behaviors with multiple implicit steps. In order for robots to be useful in the real world, they must be able to to reason over both motions and intermediate goals implied by human instructions. In this work, we propose a framework for learning representations that convert from a natural-language command to a sequence of intermediate goals for execution on a robot. A key feature of this framework is prospection, training an agent not just to correctly execute the prescribed command, but to predict a horizon of consequences of an action before taking it. We demonstrate the fidelity of plans generated by our framework when interpreting real, crowd-sourced natural language commands for a robot in simulated scenes.
ER  - 

TY  - CONF
TI  - Flight, Camera, Action! Using Natural Language and Mixed Reality to Control a Drone
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6949
EP  - 6956
AU  - B. Huang
AU  - D. Bayazit
AU  - D. Ullman
AU  - N. Gopalan
AU  - S. Tellex
PY  - 2019
KW  - aerospace computing
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - human-robot interaction
KW  - Markov processes
KW  - mobile robots
KW  - natural language processing
KW  - user interfaces
KW  - natural language commands
KW  - Markov decision process framework
KW  - web interface
KW  - MR interface
KW  - exploratory user study
KW  - fully autonomous language grounding
KW  - autonomous drone
KW  - natural language grounding
KW  - goal-oriented setting
KW  - mixed reality
KW  - radio-controlled controller
KW  - users control
KW  - Drones
KW  - Natural languages
KW  - Virtual reality
KW  - Robots
KW  - Task analysis
KW  - Planning
KW  - Grounding
DO  - 10.1109/ICRA.2019.8794200
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - With increasing autonomy, robots like drones are increasingly accessible to untrained users. Most users control drones using a low-level interface, such as a radio-controlled (RC) controller. For a wider adoption of these technologies by the public, a much higher-level interface, such as natural language or mixed reality (MR), allows the automation of the control of the agent in a goal-oriented setting. We present an interface that uses natural language grounding within an MR environment to solve high-level task and navigational instructions given to an autonomous drone. To the best of our knowledge, this is the first work to perform fully autonomous language grounding in an MR setting for a robot. Given a map, our interface first grounds natural language commands to reward specifications within a Markov Decision Process (MDP) framework. Then, it passes the reward specification to an MDP solver. Finally, the drone performs the desired operations in the real world while planning and localizing itself. Our approach uses MR to provide a set of known virtual landmarks, enabling the drone to understand commands referring to objects without being equipped with object detectors for multiple novel objects or a predefined environment model. We conducted an exploratory user study to assess users' experience of our MR interface with and without natural language, as compared to a web interface. We found that users were able to command the drone more quickly via both MR interfaces as compared to the web interface, with roughly equal system usability scores across all three interfaces.
ER  - 

TY  - CONF
TI  - An Interactive Scene Generation Using Natural Language
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6957
EP  - 6963
AU  - Y. Cheng
AU  - Y. Shi
AU  - Z. Sun
AU  - D. Feng
AU  - L. Dong
PY  - 2019
KW  - dexterous manipulators
KW  - discrete event systems
KW  - learning (artificial intelligence)
KW  - natural language processing
KW  - natural scenes
KW  - text analysis
KW  - interactive scene generation
KW  - robotic drawing
KW  - discrete event system
KW  - MSCOCO evaluation dataset
KW  - CIDEr metric
KW  - ROUGH-L metric
KW  - METEOR metric
KW  - Amazon Mechanical Turk
KW  - natural language descriptions
KW  - Layout
KW  - Dogs
KW  - Robots
KW  - Generators
KW  - Natural language processing
KW  - Semantics
KW  - Training
DO  - 10.1109/ICRA.2019.8794327
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Scene generation is an important step of robotic drawing. Recent works have shown success in scene generation conditioned on text using a variety of approaches, with which the generated scenes cannot be revised after its generation. To allow modification on generated scenes, we model the scene generation process as a discrete event system. Instead of training text-to-pixel mappings using large datasets, the proposed approach uses object instances retrieved from the Internet to synthesize scenes. Evaluated on 128 experiments using MSCOCO evaluation dataset, the result shows the scene generation performance has been increased by 197%, 22.3%, and 55.7% compared with the state of the art approach on three standard metrics (CIDEr, ROUGH-L, METEOR), respectively. Human evaluation conducted on Amazon Mechanical Turk shows over 80% of generated scenes are considered to have higher recognizability and better alignment with natural language descriptions than baseline works.
ER  - 

TY  - CONF
TI  - Efficient Generation of Motion Plans from Attribute-Based Natural Language Instructions Using Dynamic Constraint Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6964
EP  - 6971
AU  - J. S. Park
AU  - B. Jia
AU  - M. Bansal
AU  - D. Manocha
PY  - 2019
KW  - graph theory
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - natural language processing
KW  - optimisation
KW  - path planning
KW  - robot programming
KW  - dynamic constraint mapping
KW  - robot motion planning
KW  - dynamic grounding graph
KW  - 7-DOF Fetch robot
KW  - factor graph
KW  - optimization-based motion planning
KW  - parametric constraints
KW  - attribute-based natural language instructions
KW  - motion plans
KW  - Robots
KW  - Grounding
KW  - Natural languages
KW  - Cost function
KW  - Planning
KW  - Dynamics
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794394
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present an algorithm for combining natural language processing (NLP) and fast robot motion planning to automatically generate robot movements. Our formulation uses a novel concept called Dynamic Constraint Mapping to transform complex, attribute-based natural language instructions into appropriate cost functions and parametric constraints for optimization-based motion planning. We generate a factor graph from natural language instructions called the Dynamic Grounding Graph (DGG), which takes latent parameters into account. The coefficients of this factor graph are learned based on conditional random fields (CRFs) and are used to dynamically generate the constraints for motion planning. We map the cost function directly to the motion parameters of the planner and compute smooth trajectories in dynamic scenes. We highlight the performance of our approach in a simulated environment and via a human interacting with a 7-DOF Fetch robot using intricate language commands including negation, orientation specification, and distance constraints.
ER  - 

TY  - CONF
TI  - Safe and Fast Path Planning in Cluttered Environment using Contiguous Free-space Partitioning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 6972
EP  - 6978
AU  - A. K. Sadhu
AU  - S. Shukla
AU  - T. Bera
AU  - R. Dasgupta
PY  - 2019
KW  - convex programming
KW  - graph theory
KW  - mobile robots
KW  - path planning
KW  - random processes
KW  - cluttered environment
KW  - contiguous free-space partitioning
KW  - convex optimization
KW  - convex navigable free-spaces
KW  - contiguous convex free-spaces
KW  - random-walk based seed generation method
KW  - contiguous navigable geometry
KW  - graph search problem
KW  - multiple query planning algorithm
KW  - fast path planning
KW  - undirected graph
KW  - safe path planning
KW  - Path planning
KW  - Planning
KW  - Ellipsoids
KW  - Robots
KW  - Data structures
KW  - Iris
DO  - 10.1109/ICRA.2019.8793921
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper proposes a path planning algorithm for cluttered environment and maze. The proposed planning algorithm exploits the merit of convex optimization while forming the convex navigable free-spaces, ensuring safety of the vehicle. The contiguous convex free-spaces are iteratively computed from a random-walk based seed generation method to create a contiguous navigable geometry. Inside this contiguous navigable geometry an undirected graph is then created, whose each node and edge belong to at least one convex region which boils down the path planning problem into a graph search problem. In addition, the proposed multiple query planning algorithm can merge the user provided feasible initial and goal configuration with the existing undirected graph in each plan, without deteriorating the planning performance in terms of run-time and path length. Simulation and experimental results confirm the superiority of the proposed planning algorithm jointly in terms of both path length and run-time by a significant margin.
ER  - 

TY  - CONF
TI  - Learning from Extrapolated Corrections
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7034
EP  - 7040
AU  - J. Y. Zhang
AU  - A. D. Dragan
PY  - 2019
KW  - control engineering computing
KW  - extrapolation
KW  - function approximation
KW  - learning (artificial intelligence)
KW  - robot programming
KW  - extrapolated corrections
KW  - cost functions
KW  - user guidance
KW  - extrapolation problem
KW  - online function approximation
KW  - function space
KW  - nonEuclidean norms
KW  - robot learning
KW  - Trajectory
KW  - Cost function
KW  - Robot kinematics
KW  - Function approximation
KW  - Kernel
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793554
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Our goal is to enable robots to learn cost functions from user guidance. Often it is difficult or impossible for users to provide full demonstrations, so corrections have emerged as an easier guidance channel. However, when robots learn cost functions from corrections rather than demonstrations, they have to extrapolate a small amount of information - the change of a waypoint along the way - to the rest of the trajectory. We cast this extrapolation problem as online function approximation, which exposes different ways in which the robot can interpret what trajectory the person intended, depending on the function space used for the approximation. Our simulation results and user study suggest that using function spaces with non-Euclidean norms can better capture what users intend, particularly if environments are uncluttered. This, in turn, can lead to the robot learning a more accurate cost function and improves the user's subjective perceptions of the robot.
ER  - 

TY  - CONF
TI  - Merging Position and orientation Motion Primitives
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7041
EP  - 7047
AU  - M. Saveriano
AU  - F. Franzel
AU  - D. Lee
PY  - 2019
KW  - image motion analysis
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - position control
KW  - robot programming
KW  - stability
KW  - orientation motion primitives
KW  - complex robotic trajectories
KW  - time series
KW  - dynamical systems
KW  - merging position
KW  - stability analysis
KW  - merging sequential motion primitives
KW  - pose trajectories
KW  - Quaternions
KW  - Robots
KW  - Stability analysis
KW  - Trajectory
KW  - Task analysis
KW  - Acceleration
KW  - Clocks
DO  - 10.1109/ICRA.2019.8793786
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we focus on generating complex robotic trajectories by merging sequential motion primitives. A robotic trajectory is a time series of positions and orientations ending at a desired target. Hence, we first discuss the generation of converging pose trajectories via dynamical systems, providing a rigorous stability analysis. Then, we present approaches to merge motion primitives which represent both the position and the orientation part of the motion. Developed approaches preserve the shape of each learned movement and allow for continuous transitions among succeeding motion primitives. Presented methodologies are theoretically described and experimentally evaluated, showing that it is possible to generate a smooth pose trajectory out of multiple motion primitives.
ER  - 

TY  - CONF
TI  - Learning Haptic Exploration Schemes for Adaptive Task Execution
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7048
EP  - 7054
AU  - T. Eiband
AU  - M. Saveriano
AU  - D. Lee
PY  - 2019
KW  - end effectors
KW  - haptic interfaces
KW  - human-robot interaction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - robot vision
KW  - teaching
KW  - haptic exploration schemes
KW  - adaptive task execution
KW  - compliant robots
KW  - kinesthetic teaching
KW  - programming physical interactions
KW  - force data
KW  - force sensing
KW  - autonomous exploration strategies
KW  - object targeted manner
KW  - learning framework
KW  - adaptive robot
KW  - systematically changing environment
KW  - generated behavior
KW  - haptic exploration skills
KW  - relative manipulation skills
KW  - manipulation task
KW  - adaptive task structure
KW  - unseen object locations
KW  - teaching strategy
KW  - Grippers
KW  - Robot sensing systems
KW  - Task analysis
KW  - Force
KW  - Motion segmentation
DO  - 10.1109/ICRA.2019.8793934
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The recent generation of compliant robots enables kinesthetic teaching of novel skills by human demonstration. This enables strategies to transfer tasks to the robot in a more intuitive way than conventional programming interfaces. Programming physical interactions can be achieved by manually guiding the robot to learn the behavior from the motion and force data. To let the robot react to changes in the environment, force sensing can be used to identify constraints and act accordingly. While autonomous exploration strategies in the whole workspace are time consuming, we propose a way to learn these schemes from human demonstrations in an object targeted manner. The presented teaching strategy and the learning framework allow to generate adaptive robot behaviors relying on the robot's sense of touch in a systematically changing environment. A generated behavior consists of a hierarchical representation of skills, where haptic exploration skills are used to touch the environment with the end effector, and relative manipulation skills, which are parameterized according to previous exploration events. The effectiveness of the approach has been proven in a manipulation task, where the adaptive task structure is able to generalize to unseen object locations. The robot autonomously manipulates objects without relying on visual feedback.
ER  - 

TY  - CONF
TI  - Learning Motion Trajectories from Phase Space Analysis of the Demonstration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7055
EP  - 7061
AU  - P. Gesel
AU  - M. Begum
AU  - D. L. Roche
PY  - 2019
KW  - approximation theory
KW  - dexterous manipulators
KW  - learning (artificial intelligence)
KW  - linear systems
KW  - motion control
KW  - path planning
KW  - regression analysis
KW  - trajectory control
KW  - closed form solutions
KW  - task generalization
KW  - phase space analysis
KW  - motion trajectories
KW  - kinematic based task
KW  - dynamic motion
KW  - phase space model
KW  - sequential trajectory task
KW  - energy-based analysis
KW  - linear time invariant equations
KW  - trajectory segments
KW  - linear piece-wise regression method
KW  - Trajectory
KW  - Mathematical model
KW  - Dynamics
KW  - Task analysis
KW  - Motion segmentation
KW  - Adaptation models
KW  - Space exploration
DO  - 10.1109/ICRA.2019.8794381
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A major goal of learning from demonstration is task generalization via observation of a teacher. In this paper, we propose a novel framework for learning motion from a single demonstration. Our approach reconstructs the demonstrated trajectory's phase space curve via a linear piece-wise regression method. We approximate dynamics of trajectory segments with linear time invariant equations, each yielding closed form solutions. We show convergence to desired phase space states via an energy-based analysis. The robustness of the model is evaluated on a robot for a sequential trajectory task. Additionally, we show the advantages that the phase space model has over the dynamic motion primitive for a kinematic based task.
ER  - 

TY  - CONF
TI  - I Can See Clearly Now: Image Restoration via De-Raining
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7087
EP  - 7093
AU  - H. Porav
AU  - T. Bruls
AU  - P. Newman
PY  - 2019
KW  - drops
KW  - image denoising
KW  - image restoration
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - rain
KW  - stereo image processing
KW  - traffic engineering computing
KW  - realrain dataset
KW  - image restoration
KW  - image reconstruction
KW  - computer-generated adherent water droplets
KW  - streaks
KW  - CamVid road marking segmentation dataset
KW  - Cityscapes semantic segmentation datasets
KW  - stereo dataset
KW  - denoising generator training
KW  - de-raining
KW  - lens
KW  - Rain
KW  - Image segmentation
KW  - Lenses
KW  - Task analysis
KW  - Computational modeling
KW  - Roads
KW  - Generators
DO  - 10.1109/ICRA.2019.8793486
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a method for improving segmentation tasks on images affected by adherent rain drops and streaks. We introduce a novel stereo dataset recorded using a system that allows one lens to be affected by real water droplets while keeping the other lens clear. We train a denoising generator using this dataset and show that it is effective at removing the effect of real water droplets, in the context of image reconstruction and road marking segmentation. To further test our de-noising approach, we describe a method of adding computer-generated adherent water droplets and streaks to any images, and use this technique as a proxy to demonstrate the effectiveness of our model in the context of general semantic segmentation. We benchmark our results using the CamVid road marking segmentation dataset, Cityscapes semantic segmentation datasets and our own realrain dataset, and show significant improvement on all tasks.
ER  - 

TY  - CONF
TI  - Bonnet: An Open-Source Training and Deployment Framework for Semantic Segmentation in Robotics using CNNs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7094
EP  - 7100
AU  - A. Milioto
AU  - C. Stachniss
PY  - 2019
KW  - computer vision
KW  - control engineering computing
KW  - convolutional neural nets
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - public domain software
KW  - robot vision
KW  - deployment interface
KW  - existing robotics codebase
KW  - label prediction
KW  - open-source training
KW  - CNNs
KW  - semantic segmentation labels each pixel
KW  - class label
KW  - convolutional neural networks
KW  - high-quality open-source frameworks
KW  - neural network implementation
KW  - semantic segmentation task
KW  - modular approach
KW  - robotic platform
KW  - CNN approach
KW  - robotics research
KW  - open-source codebase
KW  - semantic segmentation CNN
KW  - semantic annotation
KW  - Bonnet framework
KW  - Python
KW  - TensorFlow
KW  - C++ library
KW  - Semantics
KW  - Training
KW  - C++ languages
KW  - Tools
KW  - Robot sensing systems
KW  - Hardware
DO  - 10.1109/ICRA.2019.8793510
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to interpret a scene is an important capability for a robot that is supposed to interact with its environment. The knowledge of what is in front of the robot is, for example, relevant for navigation, manipulation, or planning. Semantic segmentation labels each pixel of an image with a class label and thus provides a detailed semantic annotation of the surroundings to the robot. Convolutional neural networks (CNNs) are popular methods for addressing this type of problem. The available software for training and the integration of CNNs for real robots, however, is quite fragmented and often difficult to use for non-experts, despite the availability of several high-quality open-source frameworks for neural network implementation and training. In this paper, we propose a tool called Bonnet, which addresses this fragmentation problem by building a higher abstraction that is specific for the semantic segmentation task. It provides a modular approach to simplify the training of a semantic segmentation CNN independently of the used dataset and the intended task. Furthermore, we also address the deployment on a real robotic platform. Thus, we do not propose a new CNN approach in this paper. Instead, we provide a stable and easy-to-use tool to make this technology more approachable in the context of autonomous systems. In this sense, we aim at closing a gap between computer vision research and its use in robotics research. We provide an open-source codebase for training and deployment. The training interface is implemented in Python using TensorFlow and the deployment interface provides C++ library that can be easily integrated in an existing robotics codebase, a ROS node, and two standalone applications for label prediction in images and videos.
ER  - 

TY  - CONF
TI  - Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7101
EP  - 7107
AU  - V. Nekrasov
AU  - T. Dharmasiri
AU  - A. Spek
AU  - T. Drummond
AU  - C. Shen
AU  - I. Reid
PY  - 2019
KW  - computer vision
KW  - image annotation
KW  - image reconstruction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - depth estimation
KW  - asymmetric annotations
KW  - deep learning models
KW  - sensory information extractors
KW  - generic GPU cards
KW  - asymmetric datasets
KW  - real-time semantic segmentation network
KW  - floating point operations
KW  - hard knowledge distillation
KW  - dense 3D semantic reconstruction
KW  - Task analysis
KW  - Semantics
KW  - Estimation
KW  - Real-time systems
KW  - Adaptation models
KW  - Image segmentation
KW  - Robots
DO  - 10.1109/ICRA.2019.8794220
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deployment of deep learning models in robotics as sensory information extractors can be a daunting task to handle, even using generic GPU cards. Here, we address three of its most prominent hurdles, namely, i) the adaptation of a single model to perform multiple tasks at once (in this work, we consider depth estimation and semantic segmentation crucial for acquiring geometric and semantic understanding of the scene), while ii) doing it in real-time, and iii) using asymmetric datasets with uneven numbers of annotations per each modality. To overcome the first two issues, we adapt a recently proposed real-time semantic segmentation network, making changes to further reduce the number of floating point operations. To approach the third issue, we embrace a simple solution based on hard knowledge distillation under the assumption of having access to a powerful `teacher' network. We showcase how our system can be easily extended to handle more tasks, and more datasets, all at once, performing depth estimation and segmentation both indoors and outdoors with a single model. Quantitatively, we achieve results equivalent to (or better than) current state-of-the-art approaches with one forward pass costing just 13ms and 6.5 GFLOPs on 640×480 inputs. This efficiency allows us to directly incorporate the raw predictions of our network into the SemanticFusion framework [1] for dense 3D semantic reconstruction of the scene.
ER  - 

TY  - CONF
TI  - Semantic Mapping for View-Invariant Relocalization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7108
EP  - 7115
AU  - J. Li
AU  - D. Meger
AU  - G. Dudek
PY  - 2019
KW  - cameras
KW  - feature extraction
KW  - image representation
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - semantic mapping
KW  - view-invariant relocalization
KW  - accurate local tracking
KW  - view-invariant object-driven relocalization
KW  - sampling-based approach
KW  - 2D bounding box object detections
KW  - view-invariant representation
KW  - camera relocalization
KW  - view-invariance
KW  - relocalization rate
KW  - visual simultaneous localization and mapping
KW  - object landmarks
KW  - local appearance-based features
KW  - SLAM
KW  - 3D pose
KW  - SIFT
KW  - mean rotational error
KW  - Three-dimensional displays
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Two dimensional displays
KW  - Visualization
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793624
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a system for visual simultaneous localization and mapping (SLAM) that combines traditional local appearance-based features with semantically meaningful object landmarks to achieve both accurate local tracking and highly view-invariant object-driven relocalization. Our mapping process uses a sampling-based approach to efficiently infer the 3D pose of object landmarks from 2D bounding box object detections. These 3D landmarks then serve as a view-invariant representation which we leverage to achieve camera relocalization even when the viewing angle changes by more than 125 degrees. This level of view-invariance cannot be attained by local appearance-based features (e.g. SIFT) since the same set of surfaces are not even visible when the viewpoint changes significantly. Our experiments show that even when existing methods fail completely for viewpoint changes of more than 70 degrees, our method continues to achieve a relocalization rate of around 90%, with a mean rotational error of around 8 degrees.
ER  - 

TY  - CONF
TI  - Automatic Targeting of Plant Cells via Cell Segmentation and Robust Scene-Adaptive Tracking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7116
EP  - 7122
AU  - I. Paranawithana
AU  - Z. H. Chau
AU  - L. Yang
AU  - Z. Chen
AU  - K. Youcef-Toumi
AU  - U. Tan
PY  - 2019
KW  - biology computing
KW  - botany
KW  - cellular biophysics
KW  - image segmentation
KW  - micromanipulators
KW  - needles
KW  - robot vision
KW  - plant cell manipulation
KW  - plant cell centroids
KW  - automatic targeting
KW  - robust scene-adaptive tracking
KW  - cell segmentation method
KW  - plant cell detection
KW  - plant cell localization
KW  - template tracking
KW  - manipulator trajectory
KW  - score-based normalized weighted averaging
KW  - microneedle tracking
KW  - visual tracking
KW  - plant biology
KW  - Visualization
KW  - Target tracking
KW  - Image segmentation
KW  - Motion segmentation
KW  - Trajectory
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8793944
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Automatic targeting of plant cells to perform tasks like extraction of chloroplast is often desired in the study of plant biology. Hence, this paper proposes an improved cell segmentation method combined with a robust tracking algorithm for vision-guided micromanipulation in plant cells. The objective of this work is to develop an automatic plant cell detection and localization technique to complete the automated workflow for plant cell manipulation. The complex structural properties of plant cells make both segmentation of cells and visual tracking of the microneedle immensely challenging, unlike single animal cell applications. Thus, an improved version of watershed segmentation with adaptive thresholding is proposed to detect the plant cells without the need for staining of the cells or additional tedious preparations. To manipulate the needle to reach the identified centroid of the cells, tracking of the needle tip is required. Visual and motion information from two data sources namely, template tracking and projected manipulator trajectory are combined using score-based normalized weighted averaging to continuously track the microneedle. The selection of trackers is influenced by their complementary nature as the former and latter are individually robust against physical and visual uncertainties, respectively. Experimental results validate the effectiveness of the proposed method by detecting plant cell centroids accurately, tracking the microneedle constantly and reaching the plant cell of interest despite the presence of visual disturbances.
ER  - 

TY  - CONF
TI  - Real-Time Monocular Object-Model Aware Sparse SLAM
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7123
EP  - 7129
AU  - M. Hosseinzadeh
AU  - K. Li
AU  - Y. Latif
AU  - I. Reid
PY  - 2019
KW  - cameras
KW  - convolutional neural nets
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - mobile robotics
KW  - sparse point-based SLAM methods
KW  - CNN-based plane detector
KW  - semantic SLAM
KW  - simultaneous localization and mapping
KW  - camera localization
KW  - deep-learned object detector
KW  - CNN network
KW  - semantic objects representation
KW  - monocular object-model aware sparse SLAM framework
KW  - Simultaneous localization and mapping
KW  - Semantics
KW  - Image reconstruction
KW  - Real-time systems
KW  - Cameras
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793728
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Simultaneous Localization And Mapping (SLAM) is a fundamental problem in mobile robotics. While sparse point-based SLAM methods provide accurate camera localization, the generated maps lack semantic information. On the other hand, state of the art object detection methods provide rich information about entities present in the scene from a single image. This work incorporates a real-time deep-learned object detector to the monocular SLAM framework for representing generic objects as quadrics that permit detections to be seamlessly integrated while allowing the real-time performance. Finer reconstruction of an object, learned by a CNN network, is also incorporated and provides a shape prior for the quadric leading further refinement. To capture the structure of the scene, additional planar landmarks are detected by a CNN-based plane detector and modelled as independent landmarks in the map. Extensive experiments support our proposed inclusion of semantic objects and planar structures directly in the bundle-adjustment of SLAM - Semantic SLAM- that enriches the reconstructed map semantically, while significantly improving the camera localization.
ER  - 

TY  - CONF
TI  - Probabilistic Projective Association and Semantic Guided Relocalization for Dense Reconstruction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7130
EP  - 7136
AU  - S. Yang
AU  - Z. Kuang
AU  - Y. Cao
AU  - Y. Lai
AU  - S. Hu
PY  - 2019
KW  - convolutional neural nets
KW  - image coding
KW  - image recognition
KW  - image reconstruction
KW  - image representation
KW  - image retrieval
KW  - image segmentation
KW  - object detection
KW  - probability
KW  - robot vision
KW  - SLAM (robots)
KW  - convolutional neural networks
KW  - geometric quality
KW  - probabilistic projective association
KW  - loop frames
KW  - 2D labeling
KW  - CNN
KW  - semantic prediction
KW  - simultaneous localization and mapping system
KW  - SLAM system
KW  - 3D scenes
KW  - randomized ferns
KW  - semantic recognition
KW  - geometric reconstruction
KW  - loop detection
KW  - reconstruction pipeline
KW  - semantic information
KW  - camera trajectory estimation
KW  - semantic labels
KW  - real-time dense mapping system
KW  - dense reconstruction
KW  - semantic guided relocalization
KW  - Semantics
KW  - Probabilistic logic
KW  - Labeling
KW  - Two dimensional displays
KW  - Cameras
KW  - Tracking loops
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8794299
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a real-time dense mapping system which uses the predicted 2D semantic labels for optimizing the geometric quality of reconstruction. With a combination of Convolutional Neural Networks (CNNs) for 2D labeling and a Simultaneous Localization and Mapping (SLAM) system for camera trajectory estimation, recent approaches have succeeded in incrementally fusing and labeling 3D scenes. However, the geometric quality of the reconstruction can be further improved by incorporating such semantic prediction results, which is not sufficiently exploited by existing methods. In this paper, we propose to use semantic information to improve two crucial modules in the reconstruction pipeline, namely tracking and loop detection, for obtaining mutual benefits in geometric reconstruction and semantic recognition. Specifically for tracking, we use a novel probabilistic projective association approach to efficiently pick out candidate correspondences, where the confidence of these correspondences is quantified concerning similarities on all available short-term invariant features. For the loop detection, we incorporate these semantic labels into the original encoding through Randomized Ferns to generate a more comprehensive representation for retrieving candidate loop frames. Evaluations on a publicly available synthetic dataset have shown the effectiveness of our approach that considers such semantic hints as a reliable feature for achieving higher geometric quality.
ER  - 

TY  - CONF
TI  - MRS-VPR: a multi-resolution sampling based global visual place recognition method
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7137
EP  - 7142
AU  - P. Yin
AU  - R. A. Srivatsan
AU  - Y. Chen
AU  - X. Li
AU  - H. Zhang
AU  - L. Xu
AU  - L. Li
AU  - Z. Jia
AU  - J. Ji
AU  - Y. He
PY  - 2019
KW  - image filtering
KW  - image matching
KW  - image recognition
KW  - image resolution
KW  - image sampling
KW  - image sequences
KW  - mobile robots
KW  - navigation
KW  - object recognition
KW  - particle filtering (numerical methods)
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - global visual place recognition method
KW  - multiresolution sampling
KW  - particle filter-based global sampling scheme
KW  - matching efficiency
KW  - brute-force sequential matching method
KW  - long-term localization
KW  - long-term visual navigation tasks
KW  - loop closure detection
KW  - MRS-VPR
KW  - SeqSLAM
KW  - Testing
KW  - Feature extraction
KW  - Indexes
KW  - Task analysis
KW  - Trajectory
KW  - Visualization
KW  - Robots
DO  - 10.1109/ICRA.2019.8793853
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Place recognition and loop closure detection are challenging for long-term visual navigation tasks. SeqSLAM is considered to be one of the most successful approaches to achieve long-term localization under varying environmental conditions and changing viewpoints. SeqSLAM uses a brute-force sequential matching method, which is computationally intensive. In this work, we introduce a multi-resolution sampling-based global visual place recognition method (MRS-VPR), which can significantly improve the matching efficiency and accuracy in sequential matching. The novelty of this method lies in the coarse-to-fine searching pipeline and a particle filter-based global sampling scheme, that can balance the matching efficiency and accuracy in the long-term navigation task. Moreover, our model works much better than SeqSLAM when the testing sequence is over a much smaller time scale than the reference sequence. Our experiments demonstrate that MRSVPR is efficient in locating short temporary trajectories within long-term reference ones without compromising on the accuracy compared to SeqSLAM.
ER  - 

TY  - CONF
TI  - Robust low-overlap 3-D point cloud registration for outlier rejection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7143
EP  - 7149
AU  - J. Stechschulte
AU  - N. Ahmed
AU  - C. Heckman
PY  - 2019
KW  - feature extraction
KW  - image registration
KW  - iterative methods
KW  - Markov processes
KW  - stereo image processing
KW  - hidden Markov random field model
KW  - iterative closest point algorithm
KW  - outlier rejection
KW  - 3D point cloud registration
KW  - Hidden Markov models
KW  - Three-dimensional displays
KW  - Cloud computing
KW  - Probabilistic logic
KW  - Robot sensing systems
KW  - Solid modeling
KW  - Measurement
DO  - 10.1109/ICRA.2019.8793857
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - When registering 3-D point clouds it is expected that some points in one cloud do not have corresponding points in the other cloud. These non-correspondences are likely to occur near one another, as surface regions visible from one sensor pose are obscured or out of frame for another. In this work, a hidden Markov random field model is used to capture this prior within the framework of the iterative closest point algorithm. The EM algorithm is used to estimate the distribution parameters and learn the hidden component memberships. Experiments are presented demonstrating that this method outperforms several other outlier rejection methods when the point clouds have low or moderate overlap.
ER  - 

TY  - CONF
TI  - Generalized Controllers in POMDP Decision-Making
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7166
EP  - 7172
AU  - K. H. Wray
AU  - S. Zilberstein
PY  - 2019
KW  - decision making
KW  - Markov processes
KW  - nonlinear programming
KW  - robots
KW  - controller family policy
KW  - finite state controller
KW  - generalized controller policies
KW  - POMDP model
KW  - customized POMDP policy form
KW  - belief-integrated FSC
KW  - vanilla FSC-based policy form
KW  - POMDP robotic solutions
KW  - generalized controllers
KW  - POMDP decision-making
KW  - general policy formulation
KW  - partially observable Markov decision processes
KW  - nonlinear programming
KW  - Power capacitors
KW  - Mathematical model
KW  - Robots
KW  - Approximation algorithms
KW  - Markov processes
KW  - Process control
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794258
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a general policy formulation for partially observable Markov decision processes (POMDPs) called controller family policies that may be used as a framework to facilitate the design of new policy forms. We prove how modern approximate policy forms: point-based, finite state controller (FSC), and belief compression, are instances of this family of generalized controller policies. Our analysis provides a deeper understanding of the POMDP model and suggests novel ways to design POMDP solutions that can combine the benefits of different state-of-the-art methods. We illustrate this capability by creating a new customized POMDP policy form called the belief-integrated FSC (BI-FSC) tailored to overcome the shortcomings of a state-of-the-art algorithm that uses non-linear programming (NLP). Specifically, experiments show that for NLP the BI-FSC offers improved performance over a vanilla FSC-based policy form on benchmark domains. Furthermore, we demonstrate the BI-FSC's execution on a real robot navigating in a maze environment. Results confirm the value of using the controller family policy as a framework to design customized policies in POMDP robotic solutions.
ER  - 

TY  - CONF
TI  - Continuous Value Iteration (CVI) Reinforcement Learning and Imaginary Experience Replay (IER) For Learning Multi-Goal, Continuous Action and State Space Controllers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7173
EP  - 7179
AU  - A. Gerken
AU  - M. Spranger
PY  - 2019
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - optimal control
KW  - state-space methods
KW  - continuous action
KW  - state space controllers
KW  - goal space
KW  - optimal value functions
KW  - nonparametric estimators
KW  - multiple arbitrary goals
KW  - real-world voltage controlled robot
KW  - nonobservable Cartesian task space
KW  - multigoal
KW  - model-free reinforcement learning algorithm
KW  - Aerospace electronics
KW  - Robot kinematics
KW  - Task analysis
KW  - Trajectory
KW  - Mathematical model
KW  - Voltage control
DO  - 10.1109/ICRA.2019.8794347
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel model-free Reinforcement Learning algorithm for learning behavior in continuous action, state, and goal spaces. The algorithm approximates optimal value functions using non-parametric estimators. It is able to efficiently learn to reach multiple arbitrary goals in deterministic and nondeterministic environments. To improve generalization in the goal space, we propose a novel sample augmentation technique. Using these methods, robots learn faster and overall better controllers. We benchmark the proposed algorithms using simulation and a real-world voltage controlled robot that learns to maneuver in a non-observable Cartesian task space.
ER  - 

TY  - CONF
TI  - iX-BSP: Belief Space Planning through Incremental Expectation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7180
EP  - 7186
AU  - E. I. Farhi
AU  - V. Indelman
PY  - 2019
KW  - computational complexity
KW  - mobile robots
KW  - path planning
KW  - statistical analysis
KW  - robotics replanning
KW  - statistical simulation
KW  - incremental expectation calculations
KW  - planning session
KW  - computational complexity
KW  - belief space planning
KW  - iX-BSP
KW  - Planning
KW  - Current measurement
KW  - Robots
KW  - Uncertainty
KW  - History
KW  - Time measurement
KW  - Linear programming
DO  - 10.1109/ICRA.2019.8793548
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Belief space planning (BSP) is a fundamental problem in robotics. Determining an optimal action quickly grows intractable as it involves calculating the expected accumulated cost (reward), where the expectation accounts for all future measurement realizations. State of the art approaches therefore resort to simplifying assumptions and approximations to reduce computational complexity. Importantly, while in robotics re-planning is essential, these approaches calculate each planning session from scratch. In this work we contribute a novel approach, iX-BSP, that is based on the key insight that calculations in consecutive planning sessions are similar in nature and can be thus re-used. Our approach performs incremental calculation of the expectation by appropriately re-using computations already performed in a precursory planing session while accounting for the information obtained in inference between the two planning sessions. The formulation of our approach considers general distributions and accounts for data association aspects. We evaluate iX-BSP in statistical simulation and show that incremental expectation calculations significantly reduce runtime without impacting performance.
ER  - 

TY  - CONF
TI  - What am I touching? Learning to classify terrain via haptic sensing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7187
EP  - 7193
AU  - J. Bednarek
AU  - M. Bednarek
AU  - L. Wellhausen
AU  - M. Hutter
AU  - K. Walas
PY  - 2019
KW  - control engineering computing
KW  - haptic interfaces
KW  - image classification
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - pattern clustering
KW  - robot vision
KW  - terrain mapping
KW  - haptic sensing
KW  - mobile robots
KW  - real-world outdoors applications
KW  - robot control
KW  - optimal terrain negotiation
KW  - terrain classification
KW  - terrain identification
KW  - legged robot foot
KW  - fixed-length step
KW  - controlled environment
KW  - clustering method
KW  - robot perception
KW  - machine learning
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Computer architecture
KW  - Convolution
KW  - Force
KW  - Foot
DO  - 10.1109/ICRA.2019.8794478
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mobile robots are becoming very popular in real-world outdoors applications, where there are many challenges in robot control and perception. One of the most critical problems is to characterise the terrain traversed by the robot. This knowledge is indispensable for optimal terrain negotiation. Currently, most approaches are performing terrain classification from vision, but there is not enough research on terrain identification from a direct interaction of the robot with the environment. In our work, we proposed new methods for classification of force/torque data from an interaction of the legged robot foot with the ground, gathered during the walking process. We provided machine learning methods for terrain classification from raw force/torque signals for which we achieved 93% accuracy on a challenging dataset with 160 minutes of recorded fixed-length steps. We also worked on a dataset where the assumption of a fixed-length step is not valid. In this case, the final result is around 80% of accuracy. The most important fact is that the data in both cases was recorded while the robot was walking, no particular movements or controlled environment were needed. Additionally, we also proposed a clustering method which allows us to learn about the class membership based on the recorded data only, without any human supervision.
ER  - 

TY  - CONF
TI  - Multi-Object Search using Object-Oriented POMDPs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7194
EP  - 7200
AU  - A. Wandzel
AU  - Y. Oh
AU  - M. Fishman
AU  - N. Kumar
AU  - L. L. S. Wong
AU  - S. Tellex
PY  - 2019
KW  - Markov processes
KW  - mobile robots
KW  - Monte Carlo methods
KW  - path planning
KW  - object-oriented POMDPs
KW  - OO-POMDP
KW  - observable Markov decision process
KW  - object-oriented partially observable Monte-Carlo planning
KW  - multiobject search task
KW  - sequential decision making
KW  - mobile robot
KW  - Task analysis
KW  - Uncertainty
KW  - Search problems
KW  - Robot sensing systems
KW  - Planning
KW  - Object oriented modeling
DO  - 10.1109/ICRA.2019.8793888
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A core capability of robots is to reason about multiple objects under uncertainty. Partially Observable Markov Decision Processes (POMDPs) provide a means of reasoning under uncertainty for sequential decision making, but are computationally intractable in large domains. In this paper, we propose Object-Oriented POMDPs (OO-POMDPs), which represent the state and observation spaces in terms of classes and objects. The structure afforded by OO-POMDPs support a factorization of the agent's belief into independent object distributions, which enables the size of the belief to scale linearly versus exponentially in the number of objects. We formulate a novel Multi-Object Search (MOS) task as an OO-POMDP for mobile robotics domains in which the agent must find the locations of multiple objects. Our solution exploits the structure of OO-POMDPs by featuring human language to selectively update the belief at task onset. Using this structure, we develop a new algorithm for efficiently solving OO-POMDPs: Object-Oriented Partially Observable Monte-Carlo Planning (OOPOMCP). We show that OO-POMCP with grounded language commands is sufficient for solving challenging MOS tasks both in simulation and on a physical mobile robot.
ER  - 

TY  - CONF
TI  - Depth Generation Network: Estimating Real World Depth from Stereo and Depth Images*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7201
EP  - 7206
AU  - Z. Dong
AU  - Y. Gao
AU  - Q. Ren
AU  - Y. Yan
AU  - F. Chen
PY  - 2019
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - stereo image processing
KW  - Depth Generation Network
KW  - real world Depth
KW  - dense depth estimation
KW  - deep-learning technique
KW  - stereo RGB images
KW  - stereo pairs
KW  - depth ground-truth
KW  - stereo setting parameters
KW  - image pairs
KW  - supervision learning
KW  - synthetic depth maps
KW  - relative dense depth
KW  - stereo geometric settings
KW  - optic settings
KW  - epipolar geometric cues
KW  - DGN
KW  - falling things dataset
KW  - variational method
KW  - Training
KW  - Estimation
KW  - Three-dimensional displays
KW  - Data models
KW  - Fats
KW  - Cameras
KW  - Robots
DO  - 10.1109/ICRA.2019.8794315
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we propose the Depth Generation Network (DGN) to address the problem of dense depth estimation by exploiting the variational method and the deep-learning technique. In particular, we focus on improving the feasibility of depth estimation under complex scenarios given stereo RGB images, where the stereo pairs and/or depth ground-truth captured by real sensors may be deteriorated; the stereo setting parameters may be unavailable or unreliable, hence hamper efforts to establish the correspondence between image pairs via supervision learning or epipolar geometric cues. Instead of relying on real data, we supervise the training of our model using synthetic depth maps generated by the simulator, which deliver complex scenes and reliable data with ease. Two non-trivial challenges, i.e., (i) attaining reasonable amount yet realistic samples for training, and (ii) developing a model that adapts to both synthetic and real scenes arise, whereas in this work we mainly deal with the later one yet leveraging state-of-the-art Falling Things (FAT) dataset to overcome the first. Experiments on FAT and KITTI datasets demonstrate that our model estimates relative dense depth in fine details, potentially generalizable to real scenes without knowing the stereo geometric and optic settings.
ER  - 

TY  - CONF
TI  - Multi-Task Template Matching for Object Detection, Segmentation and Pose Estimation Using Depth Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7207
EP  - 7213
AU  - K. Park
AU  - T. Patten
AU  - J. Prankl
AU  - M. Vincze
PY  - 2019
KW  - image colour analysis
KW  - image matching
KW  - image sampling
KW  - image segmentation
KW  - object detection
KW  - pose estimation
KW  - MultiTask Template Matching
KW  - object detection
KW  - pose estimation
KW  - color images
KW  - target object
KW  - segmentation masks
KW  - object region
KW  - texture-less objects
KW  - Training
KW  - Pose estimation
KW  - Feature extraction
KW  - Task analysis
KW  - Image segmentation
KW  - Robots
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8794448
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Template matching has been shown to accurately estimate the pose of a new object given a limited number of samples. However, pose estimation of occluded objects is still challenging. Furthermore, many robot application domains encounter texture-less objects for which depth images are more suitable than color images. In this paper, we propose a novel framework, Multi-Task Template Matching (MTTM), that finds the nearest template of a target object from a depth image while predicting segmentation masks and a pose transformation between the template and a detected object in the scene using the same feature map of the object region. The proposed feature comparison network computes segmentation masks and pose predictions by comparing feature maps of templates and cropped features of a scene. The segmentation result from this network improves the robustness of the pose estimation by excluding points that do not belong to the object. Experimental results show that MTTM outperforms baseline methods for segmentation and pose estimation of occluded objects despite using only depth images.
ER  - 

TY  - CONF
TI  - A Clustering Approach to Categorizing 7 Degree-of-Freedom Arm Motions during Activities of Daily Living
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7214
EP  - 7220
AU  - Y. Gloumakov
AU  - A. J. Spiers
AU  - A. M. Dollar
PY  - 2019
KW  - image motion analysis
KW  - motion average
KW  - recorded motions
KW  - on-table motion
KW  - clustering methodology
KW  - K-medoids clustering
KW  - clustering approach
KW  - naturalistic human arm motions
KW  - clustering techniques
KW  - heuristic interpretation
KW  - unsupervised approach
KW  - hierarchical description
KW  - natural human motion
KW  - task achievement
KW  - semiautonomous prosthetic device applications
KW  - motion segments
KW  - DTW barycenter averaging
KW  - Task analysis
KW  - Motion segmentation
KW  - Protocols
KW  - Elbow
KW  - Wrist
KW  - Prosthetics
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8794421
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we present a novel method of categorizing naturalistic human arm motions during activities of daily living using clustering techniques. While many current approaches attempt to define all arm motions using heuristic interpretation, or a combination of several abstract motion primitives, our unsupervised approach generates a hierarchical description of natural human motion with well recognized groups. Reliable recommendation of a subset of motions for task achievement is beneficial to various fields, such as robotic and semi-autonomous prosthetic device applications. The proposed method makes use of well-known techniques such as dynamic time warping (DTW) to obtain a divergence measure between motion segments, DTW barycenter averaging (DBA) to get a motion average, and Ward's distance criterion to build the hierarchical tree. The clusters that emerge summarize the variety of recorded motions into the following general tasks: reach-to-front, transfer-box, drinking from vessel, on-table motion, turning a key or door knob, and reach-to-back pocket. The clustering methodology is justified by comparing against an alternative measure of divergence using Bezier coefficients and K-medoids clustering.
ER  - 

TY  - CONF
TI  - Factored Pose Estimation of Articulated Objects using Efficient Nonparametric Belief Propagation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7221
EP  - 7227
AU  - K. Desingh
AU  - S. Lu
AU  - A. Opipari
AU  - O. C. Jenkins
PY  - 2019
KW  - belief networks
KW  - industrial manipulators
KW  - Markov processes
KW  - message passing
KW  - mobile robots
KW  - pose estimation
KW  - random processes
KW  - robot vision
KW  - uncertainty handling
KW  - articulated objects
KW  - articulation constraint
KW  - continuous pose variable
KW  - robot perception
KW  - PMPNBP
KW  - pull message passing algorithm for nonparametric belief propagation
KW  - hidden node model
KW  - pairwise Markov random field
KW  - pairwise MRF
KW  - object-part pose beliefs
KW  - 3D sensor data
KW  - geometrical models
KW  - nonparametric belief propagation algorithm
KW  - multimodal uncertainty
KW  - perception problem
KW  - high-dimensional continuous space
KW  - human environments
KW  - factored pose estimation
KW  - Robot sensing systems
KW  - Belief propagation
KW  - Pose estimation
KW  - Three-dimensional displays
KW  - Quaternions
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8793973
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots working in human environments often encounter a wide range of articulated objects, such as tools, cabinets, and other jointed objects. Such articulated objects can take an infinite number of possible poses, as a point in a potentially high-dimensional continuous space. A robot must perceive this continuous pose in order to manipulate the object to a desired pose. This problem of perception and manipulation of articulated objects remains a challenge due to its high dimensionality and multi-modal uncertainty. In this paper, we propose a factored approach to estimate the poses of articulated objects using an efficient non-parametric belief propagation algorithm. We consider inputs as geometrical models with articulation constraints, and observed 3D sensor data. The proposed framework produces object-part pose beliefs iteratively. The problem is formulated as a pairwise Markov Random Field (MRF) where each hidden node (continuous pose variable) models an observed object-part's pose and each edge denotes an articulation constraint between a pair of parts. We propose articulated pose estimation by a Pull Message Passing algorithm for Nonparametric Belief Propagation (PMPNBP) and evaluate its convergence properties over scenes with articulated objects.
ER  - 

TY  - CONF
TI  - Domain Randomization for Active Pose Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7228
EP  - 7234
AU  - X. Ren
AU  - J. Luo
AU  - E. SolowjoW
AU  - J. A. Ojea
AU  - A. Gupta
AU  - A. Tamar
AU  - P. Abbeel
PY  - 2019
KW  - image sequences
KW  - image texture
KW  - neural nets
KW  - pose estimation
KW  - domain randomization
KW  - active pose estimation
KW  - robotic control
KW  - robotic manipulation tasks
KW  - robot trains
KW  - domain-randomized simulation
KW  - Pose estimation
KW  - Cameras
KW  - Predictive models
KW  - Three-dimensional displays
KW  - Robot vision systems
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794126
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate state estimation is a fundamental component of robotic control. In robotic manipulation tasks, as is our focus in this work, state estimation is essential for identifying the positions of objects in the scene, forming the basis of the manipulation plan. However, pose estimation typically requires expensive 3D cameras or additional instrumentation such as fiducial markers to perform accurately. Recently, Tobin et al. introduced an approach to pose estimation based on domain randomization, where a neural network is trained to predict pose directly from a 2D image of the scene. The network is trained on computer generated images with a high variation in textures and lighting, thereby generalizing to real world images. In this work, we investigate how to improve the accuracy of domain randomization based pose estimation. Our main idea is that active perception - moving the robot to get a better estimate of pose- can be trained in simulation and transferred to real using domain randomization. In our approach, the robot trains in a domain-randomized simulation how to estimate pose from a sequence of images. We show that our approach can significantly improve the accuracy of standard pose estimation in several scenarios: when the robot holding an object moves, when reference objects are moved in the scene, or when the camera is moved around the object.
ER  - 

TY  - CONF
TI  - GraspFusion: Realizing Complex Motion by Learning and Fusing Grasp Modalities with Instance Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7235
EP  - 7241
AU  - S. Hasegawa
AU  - K. Wada
AU  - S. Kitagawa
AU  - Y. Uchimi
AU  - K. Okada
AU  - M. Inaba
PY  - 2019
KW  - grippers
KW  - image fusion
KW  - image matching
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object detection
KW  - deep learning
KW  - multimodal grippers
KW  - simultaneous pinch
KW  - multimodal grasp fusion
KW  - object-class-agnostic grasp
KW  - modality detection
KW  - object-class-agnostic instance segmentation
KW  - grasp template matching
KW  - object manipulation
KW  - object geometry
KW  - grasp modalities
KW  - instance segmentation
KW  - integrated system
KW  - Image segmentation
KW  - Grippers
KW  - Grasping
KW  - Motion segmentation
KW  - Image color analysis
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793710
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent progress of deep learning improved the capability of a robot to find a proper grasp of a novel object for different grasp modalities (e.g., pinch and suction). While these previous studies consider multiple modalities separately, several studies develop multi-modal grippers that can achieve simultaneous pinch and suction grasp (multi-modal grasp fusion) for more capable and stable object manipulation. However, the previous studies with these grippers restrict the situations: simple object geometry and uncluttered environments. To overcome these difficulties, we propose a system that consists of: 1) object-class-agnostic grasp modality detection; 2) object-class-agnostic instance segmentation; and 3) grasp template matching for different modalities. The key idea of our work is the introduction of instance segmentation to fuse multiple modalities regarding each instance eluding a grasp of multiple objects at once. In the experiments, we evaluated the proposed system on the real-world picking task in clutter. The experimental results show that the effectiveness of modality detection, instance segmentation, and the integrated system as a whole.
ER  - 

TY  - CONF
TI  - Factored Contextual Policy Search with Bayesian optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7242
EP  - 7248
AU  - R. Pinsler
AU  - P. Karkus
AU  - A. Kupcsik
AU  - D. Hsu
AU  - W. S. Lee
PY  - 2019
KW  - learning (artificial intelligence)
KW  - robots
KW  - search problems
KW  - truly complex tasks
KW  - locally learned policies
KW  - data-efficient learning
KW  - parametric context space
KW  - contextual policy representation
KW  - target contexts
KW  - task objectives
KW  - target position
KW  - environment contexts
KW  - contextual policy search algorithms
KW  - Bayesian optimization approach
KW  - active learning settings
KW  - faster learning
KW  - factored contextual policy search
KW  - scarce data
KW  - task contexts
KW  - Task analysis
KW  - Trajectory
KW  - Optimization
KW  - Bayes methods
KW  - Robot kinematics
KW  - Entropy
DO  - 10.1109/ICRA.2019.8793808
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Scarce data is a major challenge to scaling robot learning to truly complex tasks, as we need to generalize locally learned policies over different task contexts. Contextual policy search offers data-efficient learning and generalization by explicitly conditioning the policy on a parametric context space. In this paper, we further structure the contextual policy representation. We propose to factor contexts into two components: target contexts that describe the task objectives, e.g. target position for throwing a ball; and environment contexts that characterize the environment, e.g. initial position or mass of the ball. Our key observation is that experience can be directly generalized over target contexts. We show that this can be easily exploited in contextual policy search algorithms. In particular, we apply factorization to a Bayesian optimization approach to contextual policy search both in sampling-based and active learning settings. Our simulation results show faster learning and better generalization in various robotic domains. See our supplementary video: https://youtu.be/IIJTbBAOufDY.
ER  - 

TY  - CONF
TI  - Structured Domain Randomization: Bridging the Reality Gap by Context-Aware Synthetic Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7249
EP  - 7255
AU  - A. Prakash
AU  - S. Boochoon
AU  - M. Brophy
AU  - D. Acuna
AU  - E. Cameracci
AU  - G. State
AU  - O. Shapira
AU  - S. Birchfield
PY  - 2019
KW  - computer vision
KW  - neural nets
KW  - object detection
KW  - probability
KW  - synthetic SDR data
KW  - structured domain randomization
KW  - context-aware synthetic data
KW  - uniform probability distribution
KW  - SDR places objects
KW  - probability distributions
KW  - SDR-generated imagery
KW  - 2D bounding box car detection
KW  - Splines (mathematics)
KW  - Roads
KW  - Object oriented modeling
KW  - Automobiles
KW  - Object detection
KW  - Neural networks
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8794443
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present structured domain randomization (SDR), a variant of domain randomization (DR) that takes into account the structure of the scene in order to add context to the generated data. In contrast to DR, which places objects and distractors randomly according to a uniform probability distribution, SDR places objects and distractors randomly according to probability distributions that arise from the specific problem at hand. In this manner, SDR-generated imagery enables the neural network to take the context around an object into consideration during detection. We demonstrate the power of SDR for the problem of 2D bounding box car detection, achieving competitive results on real data after training only on synthetic data. On the KITTI easy, moderate, and hard tasks, we show that SDR outperforms other approaches to generating synthetic data (VKITTI, Sim 200k, or DR), as well as real data collected in a different domain (BDD100K). Moreover, synthetic SDR data combined with real KITTI data outperforms real KITTI data alone.
ER  - 

TY  - CONF
TI  - Probabilistic Active Filtering for Object Search in Clutter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7256
EP  - 7261
AU  - J. Poon
AU  - Y. Cui
AU  - J. Ooga
AU  - A. Ogawa
AU  - T. Matsubara
PY  - 2019
KW  - Gaussian processes
KW  - graph theory
KW  - grippers
KW  - image filtering
KW  - learning (artificial intelligence)
KW  - probability
KW  - robot vision
KW  - search problems
KW  - complex state-action space
KW  - Gaussian process active filtering strategy
KW  - object search
KW  - state dynamics
KW  - object search problem
KW  - large-scale model
KW  - heavy occlusions
KW  - clutter
KW  - probabilistic active filtering
KW  - Search problems
KW  - Training
KW  - Robots
KW  - Task analysis
KW  - Probabilistic logic
KW  - Clutter
KW  - Uncertainty
DO  - 10.1109/ICRA.2019.8794418
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a probabilistic approach for object search in clutter. Due to heavy occlusions, it is vital for an agent to be able to gradually reduce uncertainty in observations of the objects in its workspace by systematically rearranging them. Probabilistic methodologies present a promising sample-efficient alternative to handle the massively complex state-action space that inherently comes with this problem, avoiding the need for both exhaustive training samples and the accompanying heuristics for traversing a large-scale model during runtime. We approach the object search problem by extending a Gaussian Process active filtering strategy with an additional model for capturing state dynamics as the objects are moved over the course of the activity. This allows viable models to be built upon relatively scarce training data, while the complexity of the action space is also reduced by shifting objects over relatively short distances. Validation in both simulation and with a real Baxter robot with a limited number of training samples demonstrates the efficacy of the proposed approach.
ER  - 

TY  - CONF
TI  - Robust 3D Object Classification by Combining Point Pair Features and Graph Convolution
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7262
EP  - 7268
AU  - J. Weibel
AU  - T. Patten
AU  - M. Vincze
PY  - 2019
KW  - convolutional neural nets
KW  - feature extraction
KW  - graph theory
KW  - image classification
KW  - image matching
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - object classification
KW  - vital semantic information
KW  - high-level tasks
KW  - point pair features
KW  - modern deep learning methods
KW  - discriminative features
KW  - graph convolutional networks
KW  - Stanford 3D indoor dataset
KW  - robust 3D object classification
KW  - Three-dimensional displays
KW  - Deep learning
KW  - Feature extraction
KW  - Solid modeling
KW  - Sensors
KW  - Robots
KW  - Convolution
DO  - 10.1109/ICRA.2019.8794432
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Object classification is an important capability for robots as it provides vital semantic information that underpin most practical high-level tasks. Classic handcrafted features, such as point pair features, have demonstrated their robustness for this task. Combining these features with modern deep learning methods provide discriminative features that are rotation invariant and robust to various sources of noise. In this work, we aim to improve the descriptiveness of point pair features while retaining their robustness. We propose a method to achieve more structured sampling of pairs and combine this information through the use of graph convolutional networks. We introduce a novel attention model based on a repeatable local reference frame. Experiments show that our approach significantly improves the state of the art for object classification on large scale reconstruction such as the Stanford 3D indoor dataset and ScanNet and obtains competitive accuracy on the artificial dataset ModelNet.
ER  - 

TY  - CONF
TI  - Discrete Rotation Equivariance for Point Cloud Recognition
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7269
EP  - 7275
AU  - J. Li
AU  - Y. Bi
AU  - G. H. Lee
PY  - 2019
KW  - feature extraction
KW  - image recognition
KW  - learning (artificial intelligence)
KW  - discrete rotation equivariance
KW  - point cloud recognition
KW  - point clouds
KW  - deep networks
KW  - deep learning architecture
KW  - rotation group
KW  - rotated inputs
KW  - point cloud based networks
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Task analysis
KW  - Feature extraction
KW  - Robots
KW  - Deep learning
KW  - Computer architecture
DO  - 10.1109/ICRA.2019.8793983
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Despite the recent active research on processing point clouds with deep networks, few attention has been on the sensitivity of the networks to rotations. In this paper, we propose a deep learning architecture that achieves discrete SO(2)/SO(3) rotation equivariance for point cloud recognition. Specifically, the rotation of an input point cloud with elements of a rotation group is similar to shuffling the feature vectors generated by our approach. The equivariance is easily reduced to invariance by eliminating the permutation with operations such as maximum or average. Our method can be directly applied to any existing point cloud based networks, resulting in significant improvements in their performance for rotated inputs. We show state-of-the-art results in the classification tasks with various datasets under both SO(2) and SO(3) rotations. In addition, we further analyze the necessary conditions of applying our approach to PointNet [1] based networks.
ER  - 

TY  - CONF
TI  - MVX-Net: Multimodal VoxelNet for 3D Object Detection
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7276
EP  - 7282
AU  - V. A. Sindagi
AU  - Y. Zhou
AU  - O. Tuzel
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image fusion
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - stereo image processing
KW  - MVX-net
KW  - multimodal VoxelNet
KW  - 3D object detection
KW  - neural network architectures
KW  - point cloud data
KW  - point cloud modalities
KW  - state-of-the-art multimodal algorithms
KW  - 3D detection categories
KW  - simple single stage network
KW  - early-fusion approach
KW  - VoxelNet architecture
KW  - PointFusion
KW  - VoxelFusion
KW  - RGB modalities
KW  - KITTI dataset
KW  - birds eye view
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Feature extraction
KW  - Laser radar
KW  - Object detection
KW  - Proposals
KW  - Fuses
DO  - 10.1109/ICRA.2019.8794195
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Many recent works on 3D object detection have focused on designing neural network architectures that can consume point cloud data. While these approaches demonstrate encouraging performance, they are typically based on a single modality and are unable to leverage information from other modalities, such as a camera. Although a few approaches fuse data from different modalities, these methods either use a complicated pipeline to process the modalities sequentially, or perform late-fusion and are unable to learn interaction between different modalities at early stages. In this work, we present PointFusion and VoxelFusion: two simple yet effective early-fusion approaches to combine the RGB and point cloud modalities, by leveraging the recently introduced VoxelNet architecture. Evaluation on the KITTI dataset demonstrates significant improvements in performance over approaches which only use point cloud data. Furthermore, the proposed method provides results competitive with the state-of-the-art multimodal algorithms, achieving top-2 ranking in five of the six birds eye view and 3D detection categories on the KITTI benchmark, by using a simple single stage network.
ER  - 

TY  - CONF
TI  - Segmenting Unknown 3D Objects from Real Depth Images using Mask R-CNN Trained on Synthetic Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7283
EP  - 7290
AU  - M. Danielczuk
AU  - M. Matl
AU  - S. Gupta
AU  - A. Li
AU  - A. Lee
AU  - J. Mahler
AU  - K. Goldberg
PY  - 2019
KW  - CAD
KW  - convolutional neural nets
KW  - image coding
KW  - image colour analysis
KW  - image enhancement
KW  - image resolution
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - masks
KW  - object tracking
KW  - category-agnostic instance segmentation
KW  - hand-labeled data
KW  - object tracking
KW  - automated dataset generation
KW  - network training
KW  - computer vision research
KW  - RGB imaging
KW  - synthetic depth data sensors
KW  - unknown object segmentation
KW  - SD mask R-CNN
KW  - high-resolution synthetic depth imaging
KW  - synthetic depth mask R-CNN
KW  - unknown 3D object segmentation
KW  - 3D CAD models
KW  - domain randomization
KW  - point cloud clustering baselines
KW  - COCO benchmarks
KW  - hand-labeled RGB datasets
KW  - instance-specific grasping pipeline
KW  - synthetic training dataset
KW  - Image segmentation
KW  - Training
KW  - Solid modeling
KW  - Three-dimensional displays
KW  - Robots
KW  - Cameras
KW  - Grasping
DO  - 10.1109/ICRA.2019.8793744
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled data and we evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution depth images of challenging, densely-cluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall on COCO benchmarks, and achieves performance levels similar to a Mask R-CNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are available at https://bit.ly/2letCuE.
ER  - 

TY  - CONF
TI  - Multi-Modal Geometric Learning for Grasping and Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7339
EP  - 7345
AU  - D. Watkins-Valls
AU  - J. Varley
AU  - P. Allen
PY  - 2019
KW  - computational geometry
KW  - control engineering computing
KW  - convolutional neural nets
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - solid modelling
KW  - multimodal geometric learning
KW  - robotic manipulation tasks
KW  - 3D convolutional neural network
KW  - captured depth information
KW  - object geometry
KW  - visual-tactile approaches
KW  - 3D models
KW  - tactile information
KW  - geometric prediction
KW  - geometric reasoning
KW  - Geometry
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Shape
KW  - Training
KW  - Grasping
DO  - 10.1109/ICRA.2019.8794233
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work provides an architecture that incorporates depth and tactile information to create rich and accurate 3D models useful for robotic manipulation tasks. This is accomplished through the use of a 3D convolutional neural network (CNN). Offline, the network is provided with both depth and tactile information and trained to predict the object's geometry, thus filling in regions of occlusion. At runtime, the network is provided a partial view of an object. Tactile information is acquired to augment the captured depth information. The network can then reason about the object's geometry by utilizing both the collected tactile and depth information. We demonstrate that even small amounts of additional tactile information can be incredibly helpful in reasoning about object geometry. This is particularly true when information from depth alone fails to produce an accurate geometric prediction. Our method is benchmarked against and outperforms other visual-tactile approaches to general geometric reasoning. We also provide experimental results comparing grasping success with our method.
ER  - 

TY  - CONF
TI  - Panthera: Design of a Reconfigurable Pavement Sweeping Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7346
EP  - 7352
AU  - A. A. Hayat
AU  - R. Parween
AU  - M. R. Elara
AU  - K. Parsuraman
AU  - P. S. Kandasamy
PY  - 2019
KW  - cleaning
KW  - couplings
KW  - design engineering
KW  - fasteners
KW  - hygiene
KW  - mobile robots
KW  - motion control
KW  - pedestrians
KW  - roads
KW  - robot kinematics
KW  - service robots
KW  - shafts
KW  - steering systems
KW  - wheels
KW  - Panthera
KW  - urban hygiene
KW  - single lead screw shaft
KW  - linkages mechanism
KW  - reconfigurable pavement sweeping robot design
KW  - pavement cleaning robot
KW  - pedestrian
KW  - in-wheels motors
KW  - steering kinematics
KW  - motion control
KW  - onboard batteries
KW  - Robots
KW  - Fasteners
KW  - Wheels
KW  - Lead
KW  - Cleaning
KW  - Couplings
KW  - Meters
DO  - 10.1109/ICRA.2019.8794268
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The pavement cleaning is essential to maintain urban hygiene and keep the long stretch of pavements spick and span. This paper reports on the development of novel reconfigurable pavement cleaning robot named Panthera. Reconfiguration in Panthera is gained by the expansion and contraction of the body frame using a single lead screw shaft and linkages mechanism. It gives the capability to reshape itself based on factors like pavement width and pedestrian density. The independent steering action is derived using two in-wheels motors for each steering axis. This imparts the flexibility in motion and make system omnidirectional and allows the convenient movement of the robot in any direction along the pavement. It is powered using onboard batteries that generate lesser noise compared to the existing solution powered with gasoline. The modeling and steering kinematics is presented along with experimental results of the path followed and discussion supporting the robot's capability.
ER  - 

TY  - CONF
TI  - Automatic Leg Regeneration for Robot Mobility Recovery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7353
EP  - 7359
AU  - L. Wang
AU  - R. S. Fearing
PY  - 2019
KW  - fault tolerance
KW  - legged locomotion
KW  - microprocessor chips
KW  - automatic leg regeneration
KW  - robot mobility recovery
KW  - automatic repair
KW  - robotic system
KW  - modular approach
KW  - robot functionality
KW  - robot structure regeneration
KW  - leg fabrication
KW  - mechanical structures
KW  - regeneration-based approach
KW  - legged robot disengagement
KW  - Legged locomotion
KW  - Robot sensing systems
KW  - Maintenance engineering
KW  - Fabrication
KW  - Permanent magnet motors
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793596
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Automatic repair of mechanical structures would enable a robot to recover or improve functions after physical damage. Little work exists on real-world execution of automatic repair in robotic systems. State-of-the-art takes a modular approach where the robotic system is modular and a replacement module is available. However, the modular approach suffers from low granularity in repair even with tens of motors. In addition, there is a lack of quantitative evaluation of the effect of automatic repair on robot functionality. Here we propose a cooperative method for automatic repair in a robotic system. Our method is regeneration-based rather than module-based and does not assume availability of a replacement part. It integrates a fabrication process on the fly for robot structure regeneration. With a system that consists of a regenerating robot, a legged robot and a pre-engineered ribbon, we demonstrate end-to-end execution of automated repair of the legged robot's leg by the regenerating robot in 335 seconds. Experiments on repeatability show a 100% success rate for sub-processes such as positioning, leg fabrication, and legged robot disengagement and a 90% success rate for leg detachment. We quantify the effect of leg regeneration on mobility recovery and found a 90% recovery of forward speed, a 19.7% increase of peak power and a 9.3% reduction of cost of transport with a regenerated leg.
ER  - 

TY  - CONF
TI  - Geometric interpretation of the general POE model for a serial-link robot via conversion into D-H parameterization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7360
EP  - 7366
AU  - L. Wu
AU  - R. Crawford
AU  - J. Roberts
PY  - 2019
KW  - calibration
KW  - industrial robots
KW  - robot kinematics
KW  - serial-link robot
KW  - helical joints
KW  - revolute joints
KW  - general joints
KW  - low pair joints
KW  - calibration
KW  - degree of freedom
KW  - Denavit-Hartenberg model
KW  - prismatic joints
KW  - geometric interpretation
KW  - product of exponentials formula
KW  - kinematic parameters
KW  - Robots
KW  - Mathematical model
KW  - Kinematics
KW  - Tools
KW  - Analytical models
KW  - Calibration
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8794384
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While Product of Exponentials (POE) formula has been gaining maturity in modeling the kinematics of a serial-link robot, the Denavit-Hartenberg (D-H) notation is still the most widely used due to its intuitive and concise geometric interpretation of the robot. This paper has developed an analytical solution to automatically convert a POE model into a D-H model for a robot with revolute, prismatic, and helical joints, which are the complete set of three basic one degree of freedom lower pair joints for constructing a serial-link robot. The conversion algorithm developed can be used in applications such as calibration where it is necessary to convert the D-H model to the POE model for identification and then back to the D-H model for compensation. The equivalence of the two models proved in this paper also benefits the analysis of the identifiability of the kinematic parameters. It is found that the maximum number of identifiable parameters in a general POE model is 5h+4r+2t+n+6 where h, r, t, and n stand for the number of helical, revolute, prismatic, and general joints, respectively. It is also suggested that the identifiability of the base frame and the tool frame in the D-H model is restricted rather than the arbitrary six parameters as assumed previously.
ER  - 

TY  - CONF
TI  - Dynamic friction model with thermal and load dependency: modeling, compensation, and external force estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7367
EP  - 7373
AU  - M. Iskandar
AU  - S. Wolf
PY  - 2019
KW  - drives
KW  - gears
KW  - sliding friction
KW  - slip
KW  - dynamic friction model
KW  - external force estimation
KW  - static friction model
KW  - gross sliding regime
KW  - Lund Grenoble
KW  - dynamic simulation
KW  - external torque estimation
KW  - generalized-Maxwell-slip
KW  - harmonic drive CSD 25 gear
KW  - test-bed
KW  - friction compensation
KW  - thermal-load dependency
KW  - nonlinear temperature dependency
KW  - nonlinear velocity dependency
KW  - Friction
KW  - Load modeling
KW  - Torque
KW  - Mathematical model
KW  - Temperature dependence
KW  - Estimation
KW  - Robots
DO  - 10.1109/ICRA.2019.8794406
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A physically-motivated friction model with a parametric description of the nonlinear dependency of the temperature and velocity as well as the dependency on external load is presented. The fully parametric approach extends a static friction model in the gross sliding regime. We show how it can be seamlessly integrated in standard dynamic friction models such as Lund Grenoble (LuGre) and Generalized-Maxwell-Slip (GMS). Parameters of a Harmonic Drive CSD 25 gear are experimentally identified and the final model is evaluated on a dedicated test-bed. We show the integration and effectiveness in dynamic simulation, friction compensation, and external torque estimation.
ER  - 

TY  - CONF
TI  - Echinoderm Inspired Variable Stiffness Soft Actuator with Connected Ossicle Structure
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7389
EP  - 7394
AU  - H. Jeong
AU  - J. Kim
PY  - 2019
KW  - actuators
KW  - biomechanics
KW  - design engineering
KW  - dexterous manipulators
KW  - elastic constants
KW  - elastomers
KW  - grippers
KW  - mobile robots
KW  - muscle
KW  - robot dynamics
KW  - robot kinematics
KW  - structural engineering
KW  - connective tissue
KW  - interossicular muscle
KW  - soft material robots
KW  - stiffness modulation method
KW  - structural stiffness
KW  - calcite ossicles
KW  - echinoderm inspired soft actuator
KW  - ossicle structure
KW  - robot kinematics
KW  - robot dynamics
KW  - load-bearing capability
KW  - design engineering
KW  - elastomer
KW  - finger-shaped stiffening structure
KW  - vacuum level
KW  - robotic gripper
KW  - Shape
KW  - Actuators
KW  - Jamming
KW  - Force
KW  - Muscles
KW  - Soft robotics
DO  - 10.1109/ICRA.2019.8793545
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - An echinoderm can actively modulate the structural stiffness of its body wall by as much as 10 times, using the material and structural features that make up its body, including calcite ossicles, connective tissue and interossicular muscle. This capacity for variable stiffness makes it possible to adapt to the kinematics and dynamics required to perform a given task and the surrounding environment. This characteristic can improve the ability of soft material robots, which currently have limited application because of their low load-bearing capability. This paper presents a stiffness modulation method inspired by the connected ossicle structures of echinoderms. We introduce the mechanism, structure, and stiffness variation of the proposed design with respect to different ossicle shape, interval, and elastomer. Then we built a finger-shaped stiffening structure using the proposed design, measured its stiffness according to vacuum level, and showed its load-bearing capacity under control. The proposed design was then applied to a robotic gripper, a typical device that interacts with unpredictable environments and needs variable stiffening ability.
ER  - 

TY  - CONF
TI  - Controllability pre-verification of silicone soft robots based on finite-element method
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7395
EP  - 7400
AU  - G. Zheng
AU  - O. Goury
AU  - M. Thieffry
AU  - A. Kruszewski
AU  - C. Duriez
PY  - 2019
KW  - controllability
KW  - finite element analysis
KW  - Galerkin method
KW  - reduced order systems
KW  - robots
KW  - finite-element method
KW  - silicone soft robots
KW  - differential geometric method
KW  - controllable parallel soft robot
KW  - controllability pre-verification
KW  - emergent research field
KW  - variant promising applications
KW  - design soft robots
KW  - pre-checking controllability
KW  - numerical design phase
KW  - trial-and-error process
KW  - Soft robotics
KW  - Finite element analysis
KW  - Actuators
KW  - Numerical models
KW  - Analytical models
KW  - Controllability
DO  - 10.1109/ICRA.2019.8794370
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robot is an emergent research field which has variant promising applications. However, the design of soft robots nowadays still follows the trial-and-error process, which is not at all efficient. This paper proposes to design soft robots by pre-checking controllability during the numerical design phase. Finite-element method is used to model the dynamics of silicone soft robots, based on which the differential geometric method is applied to analyze the controllability of the points of interest. Such a verification is also investigated via model order reduction technique and Galerkin projection. The proposed methodology is finally validated by numerically designing a controllable parallel soft robot.
ER  - 

TY  - CONF
TI  - A Vacuum-driven Origami “Magic-ball” Soft Gripper
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7401
EP  - 7408
AU  - S. Li
AU  - J. J. Stampfli
AU  - H. J. Xu
AU  - E. Malkin
AU  - E. V. Diaz
AU  - D. Rus
AU  - R. J. Wood
PY  - 2019
KW  - control system synthesis
KW  - design engineering
KW  - grippers
KW  - mechanical testing
KW  - mobile robots
KW  - pneumatic actuators
KW  - robust control
KW  - vacuum-driven origami magic-ball
KW  - designing soft grippers
KW  - substantial grasping strength
KW  - vacuum-driven soft robotic gripper
KW  - robustness
KW  - flexible thin membrane
KW  - mechanical load tests
KW  - pneumatic pressure
KW  - fabrication method
KW  - Grippers
KW  - Skin
KW  - Skeleton
KW  - Rubber
KW  - Connectors
KW  - Grasping
KW  - Shape
DO  - 10.1109/ICRA.2019.8794068
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robotics has yielded numerous examples of soft grippers that utilize compliance to achieve impressive grasping performances with great simplicity, adaptability, and robustness. Designing soft grippers with substantial grasping strength while remaining compliant and gentle is one of the most important challenges in this field. In this paper, we present a light-weight, vacuum-driven soft robotic gripper made of an origami “magic-ball” and a flexible thin membrane. We also describe the design and fabrication method to rapidly manufacture the gripper with different combinations of low-cost materials for diverse applications. Grasping experiments demonstrate that our gripper can lift a large variety of objects, including delicate foods, heavy bottles, and other miscellaneous items. The grasp force on 3D-printed objects is also characterized through mechanical load tests. The results reveal that our soft gripper can produce significant grasp force on various shapes using negative pneumatic pressure (vacuum). This new gripper holds the potential for many practical applications that require safe, strong, and simple grasping.
ER  - 

TY  - CONF
TI  - Azimuthal Shear Deformation of a Novel Soft Fiber-reinforced Rotary Pneumatic Actuator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7409
EP  - 7414
AU  - Y. M. Lee
AU  - H. J. Lee
AU  - H. P. Moon
AU  - H. R. Choi
AU  - J. C. Koo
PY  - 2019
KW  - bending
KW  - displacement measurement
KW  - elasticity
KW  - electroactive polymer actuators
KW  - finite element analysis
KW  - force measurement
KW  - pneumatic actuators
KW  - shear deformation
KW  - torsion
KW  - fiber pattern lead
KW  - azimuthal deformation
KW  - anisotropically distributed fiber element
KW  - hyper elastic material
KW  - azimuthal shear deformation
KW  - soft materials
KW  - elastic inflatable actuators
KW  - soft fiber-reinforced rotary pneumatic actuator
KW  - structure design
KW  - fabrication process
KW  - FEM simulation
KW  - rotation angles
KW  - Actuators
KW  - Strain
KW  - Windings
KW  - Prototypes
KW  - Limiting
KW  - Fabrication
KW  - Shafts
DO  - 10.1109/ICRA.2019.8794431
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The Elastic Inflatable Actuators (EIAs) has several advantages such as the inherent compliance due to the body comprised of a soft materials such as silicone. Among them, the soft fiber reinforced actuator is based on the principle that the expansion of enclosure and constraint of fiber pattern lead to a desired operation. While lots of researches on the actuator has been attributed to linear and bending motions, however, there are only few researches on rotary, or torsional, motions. In this paper, we propose a new actuator that causes azimuthal deformation due to restriction of anisotropically distributed fiber element along the radial direction and expansion of the hyper elastic material. Structure design of the actuator and a fabrication process of the actuator are presented. Subsequently, FEM simulation and experiment are executed to measure rotation angles of the actuators corresponding to the applied pressure.
ER  - 

TY  - CONF
TI  - INFORA: A Novel Inflatable Origami-based Actuator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7415
EP  - 7420
AU  - A. L. Shoushtari
AU  - G. A. Naselli
AU  - A. Sadeghi
AU  - B. Mazzolai
PY  - 2019
KW  - control system synthesis
KW  - grippers
KW  - pneumatic actuators
KW  - INFORA
KW  - pneumatic actuators
KW  - soft robotics
KW  - inflatable thin membranes
KW  - rigid foldable structure
KW  - high stiffness
KW  - inflatable origami-based actuator
KW  - tendril-like structure
KW  - grasping tasks
KW  - Actuators
KW  - Fabrication
KW  - Grippers
KW  - Task analysis
KW  - Mathematical model
KW  - Grasping
KW  - Laser beam cutting
DO  - 10.1109/ICRA.2019.8794422
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pneumatic actuators have gained huge popularity in the field of soft robotics. A class of this kind of devices exploits inflatable thin membranes which generate a desired displacement upon inflation, but often without providing sufficient force/torque to perform their task. In this paper, we propose a novel actuator combining a membrane and a rigid foldable structure. Experimental tests show that such INFlatable ORigami Actuator (INFORA) is characterized by relatively high stiffness compared to other actuators of the same class. We provide a mathematical model to be used for design purposes and we describe the fabrication process. In addition, we show how the INFORA can be used to build a tendril-like structure capable of performing grasping tasks.
ER  - 

TY  - CONF
TI  - Dynamic Period-two Gait Generation in a Hexapod Robot based on the Fixed-point Motion of a Reduced-order Model
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7427
EP  - 7433
AU  - W. Lu
AU  - P. Lin
PY  - 2019
KW  - gait analysis
KW  - legged locomotion
KW  - pendulums
KW  - reduced order systems
KW  - robot dynamics
KW  - springs (mechanical)
KW  - dynamic period-two gait generation
KW  - hexapod robot
KW  - fixed-point motion
KW  - reduced-order model
KW  - period-two dynamic running motion
KW  - spring-loaded inverted pendulum model
KW  - stance phases
KW  - flight phases
KW  - period-two fixed points
KW  - motion cycle
KW  - period-two motion trajectories
KW  - landing angles
KW  - R-SLIP model
KW  - Legged locomotion
KW  - Trajectory
KW  - Bifurcation
KW  - Numerical models
KW  - Dynamics
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793738
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This research explored the generation of period-two dynamic running motion in a robot, based on the passive dynamic period-two motion of the reduced order, rolling spring-loaded inverted pendulum (R-SLIP) model. Each cycle of period-two motion consists of two stance phases separated by two flight phases. The distribution of the period-two fixed points of the model was analyzed using a return map. Models with the same or different landing angles per motion cycle were studied, and two sets of period-two motion trajectories were implemented in a robot for experimental evaluation. Without sensory feedback or control, this evaluation relied on the open loop trajectory of the model. Based on the experiments, the robot was capable of performing dynamic period-two motion.
ER  - 

TY  - CONF
TI  - Realizing Learned Quadruped Locomotion Behaviors through Kinematic Motion Primitives
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7434
EP  - 7440
AU  - A. Singla
AU  - S. Bhattacharya
AU  - D. Dholakiya
AU  - S. Bhatnagar
AU  - A. Ghosal
AU  - B. Amrutur
AU  - S. Kolathaya
PY  - 2019
KW  - control engineering computing
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - motion control
KW  - principal component analysis
KW  - robot kinematics
KW  - robot programming
KW  - quadruped locomotion behavior learning
KW  - single gait learning
KW  - Stoch
KW  - policy gradient
KW  - PCA
KW  - quadrupedal walking
KW  - walking gaits
KW  - robust locomotion behaviors
KW  - D-RL
KW  - deep reinforcement learning
KW  - kMPs
KW  - kinematic motion primitives
KW  - Legged locomotion
KW  - Trajectory
KW  - Computational modeling
KW  - Kinematics
KW  - Optimization
KW  - Training
DO  - 10.1109/ICRA.2019.8794179
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the “Stoch”. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then analyze the resulting walking by using principal component analysis. We observe that the kMPs extracted from PCA followed a similar pattern irrespective of the type of gaits generated. Leveraging on this underlying structure, we then realize walking in Stoch by a straightforward reconstruction of joint trajectories from kMPs. This type of methodology improves the transferability of these gaits to real hardware, lowers the computational overhead on-board, and also avoids multiple training iterations by generating a set of derived behaviors from a single learned gait.
ER  - 

TY  - CONF
TI  - Single-shot Foothold Selection and Constraint Evaluation for Quadruped Locomotion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7441
EP  - 7447
AU  - D. Belter
AU  - J. Bednarek
AU  - H. Lin
AU  - G. Xin
AU  - M. Mistry
PY  - 2019
KW  - control engineering computing
KW  - convolutional neural nets
KW  - geometry
KW  - legged locomotion
KW  - motion control
KW  - optimal control
KW  - robot dynamics
KW  - robot kinematics
KW  - single-shot foothold selection
KW  - constraint evaluation
KW  - quadruped locomotion
KW  - optimal footholds
KW  - legged systems
KW  - swing leg
KW  - local elevation map
KW  - kinematic constraints
KW  - convolutional neural network
KW  - geometrical characteristics
KW  - Legged locomotion
KW  - Foot
KW  - Kinematics
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793801
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a method for selecting the optimal footholds for legged systems. The goal of the proposed method is to find the best foothold for the swing leg on a local elevation map. First, we evaluate the geometrical characteristics of each cell on the elevation map, checks kinematic constraints and collisions. Then, we apply the Convolutional Neural Network to learn the relationship between the local elevation map and the quality of potential footholds. During execution time, the controller obtains the qualitative measurement of each potential foothold from the neural model. This method evaluates hundreds of potential footholds and checks multiple constraints in a single step which takes 10 ms on a standard computer without GPU. The experiments were carried out on a quadruped robot walking over rough terrain in both simulation and real robotic platforms.
ER  - 

TY  - CONF
TI  - Optimized Jumping on the MIT Cheetah 3 Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7448
EP  - 7454
AU  - Q. Nguyen
AU  - M. J. Powell
AU  - B. Katz
AU  - J. D. Carlo
AU  - S. Kim
PY  - 2019
KW  - legged locomotion
KW  - optimisation
KW  - position control
KW  - robot dynamics
KW  - MIT Cheetah 3 robot
KW  - optimized jumping behavior
KW  - quadruped robots
KW  - precise high-frequency tracking controller
KW  - robust landing controller
KW  - robot body position
KW  - experimental validation
KW  - robot hardware
KW  - trajectory optimization
KW  - robot body orientation
KW  - Legged locomotion
KW  - Optimization
KW  - Torque
KW  - Robot kinematics
KW  - Hardware
KW  - Actuators
DO  - 10.1109/ICRA.2019.8794449
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel methodology for implementing optimized jumping behavior on quadruped robots. Our method includes efficient trajectory optimization, precise high-frequency tracking controller and robust landing controller for stabilizing the robot body position and orientation after impact. Experimental validation was successfully conducted on the MIT Cheetah 3, enabling the robot to repeatably jump onto and jump down from a desk with the height of 30" (0.76 m). The result demonstrates the advantages of the approach as well as the capability of the robot hardware itself.
ER  - 

TY  - CONF
TI  - Lift Your Leg: Mechanics of Running Through Fluids
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7455
EP  - 7461
AU  - R. Alicea
AU  - K. Ladyko
AU  - J. Clark
PY  - 2019
KW  - energy consumption
KW  - gait analysis
KW  - legged locomotion
KW  - robot dynamics
KW  - fluid interaction mechanics
KW  - energy consumption
KW  - center of mass
KW  - gait stability
KW  - mud
KW  - SLIP runner
KW  - viscous medium
KW  - snow
KW  - stream banks
KW  - beach-head
KW  - dense fluids
KW  - shallow fluids
KW  - outdoor environments
KW  - unstructured environments
KW  - legged robotic platforms
KW  - Legged locomotion
KW  - Hip
KW  - Foot
KW  - Drag
KW  - Mathematical model
KW  - Actuators
DO  - 10.1109/ICRA.2019.8793992
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In order for legged robotic platforms to become adept enough to operate in unstructured, outdoor environments it is critical that they have the ability to adapt to a variety of terrains. One class of terrains to consider are regions of shallow, dense fluids, such as a beach-head, stream banks, snow or mud. This work examines the behavior of a simulated SLIP runner operating in such a viscous medium. Simulation results show that intelligently retracting the leg during flight can have a profound effect on the maximum achievable velocity of the runner, the stability of the resulting gait, and the cost of transport of the runner. Results also show that trudging gaits, in which the leg is positioned behind the center of mass, can be favorable in certain situations in terms of energy consumption and forward velocity.
ER  - 

TY  - CONF
TI  - Safely Probabilistically Complete Real-Time Planning and Exploration in Unknown Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7470
EP  - 7476
AU  - D. Fridovich-Keil
AU  - J. F. Fisac
AU  - C. J. Tomlin
PY  - 2019
KW  - approximation theory
KW  - collision avoidance
KW  - mobile robots
KW  - predictive control
KW  - probability
KW  - reachability analysis
KW  - robot dynamics
KW  - robust control
KW  - safe backward reachable set
KW  - real-time simulation
KW  - safely probabilistically complete real-time planning
KW  - motion planning
KW  - kinodynamic planners
KW  - a priori unknown
KW  - static environments
KW  - collision avoidance
KW  - robust controller
KW  - reachability analysis
KW  - motion plans
KW  - robot operating system software environment
KW  - Planning
KW  - Trajectory
KW  - Safety
KW  - Computational modeling
KW  - Real-time systems
KW  - Vehicle dynamics
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2019.8793905
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a new framework for motion planning that wraps around existing kinodynamic planners and guarantees recursive feasibility when operating in a priori unknown, static environments. Our approach makes strong guarantees about overall safety and collision avoidance by utilizing a robust controller derived from reachability analysis. We ensure that motion plans never exit the safe backward reachable set of the initial state, while safely exploring the space. This preserves the safety of the initial state, and guarantees that that we will eventually find the goal if it is possible to do so while exploring safely. We implement our framework in the Robot Operating System (ROS) software environment and demonstrate it in a real-time simulation.
ER  - 

TY  - CONF
TI  - Handling robot constraints within a Set-Based Multi-Task Priority Inverse Kinematics Framework
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7477
EP  - 7483
AU  - P. D. Lillo
AU  - S. Chiaverini
AU  - G. Antonelli
PY  - 2019
KW  - manipulator kinematics
KW  - optimisation
KW  - redundant manipulators
KW  - safety related tasks
KW  - set-based task
KW  - equality tasks
KW  - set-bases tasks
KW  - optimization tasks
KW  - set-based multitask priority framework
KW  - set-based multitask priority inverse kinematics framework
KW  - robot constraint handling
KW  - redundant structures
KW  - 7DOF Jaco2 arm
KW  - Task analysis
KW  - Optimization
KW  - Safety
KW  - Kinematics
KW  - Robots
KW  - Jacobian matrices
KW  - Redundancy
DO  - 10.1109/ICRA.2019.8793625
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Set-Based Multi-Task Priority is a recent framework to handle inverse kinematics for redundant structures. Both equality tasks, i.e., control objectives to be driven to a desired value, and set-bases tasks, i.e., control objectives to be satisfied with a set/range of values can be addressed in a rigorous manner within a priority framework. In addition, optimization tasks, driven by the gradient of a proper function, may be considered as well, usually as lower priority tasks. In this paper the proper design of the tasks, their priority and the use of a Set-Based Multi-Task Priority framework is proposed in order to handle several constraints simultaneously in real-time. It is shown that safety related tasks such as, e.g., joint limits or kinematic singularity, may be properly handled by consider them both at an higher priority as set-based task and at a lower within a proper optimization functional. Experimental results on a 7DOF Jaco2 arm with and without the proposed approach show the effectiveness of the proposed method.
ER  - 

TY  - CONF
TI  - Compliant Limb Sensing and Control for Safe Human-Robot Interactions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7484
EP  - 7490
AU  - C. Miyata
AU  - M. Ahmadi
PY  - 2019
KW  - force control
KW  - friction
KW  - human-robot interaction
KW  - robot dynamics
KW  - robot kinematics
KW  - stability
KW  - transient response
KW  - controller parameters
KW  - maximum safe operating velocity
KW  - linear model
KW  - 1 DoF robotic joint
KW  - traditional admittance control law
KW  - simple control structure
KW  - compliant limb sensing
KW  - safe human-robot interactions
KW  - control methodology
KW  - human-robot interaction
KW  - compliant sensor
KW  - robot links
KW  - existing robots
KW  - mechanical redesign
KW  - linear robot model
KW  - stability analysis
KW  - admittance control law
KW  - comparable transient response
KW  - control structure
KW  - Robot sensing systems
KW  - Collision avoidance
KW  - Impedance
KW  - Safety
KW  - Force
KW  - Analytical models
DO  - 10.1109/ICRA.2019.8793965
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The current paper proposes a control methodology for ensuring safety during human-robot interaction based on a compliant sensor covering the robot links as a lightweight shell. The method can be used with existing robots without the need for mechanical redesign. To assess the behaviour of the proposed control law, the controller is analysed using a linear robot model. Stability analysis is performed and requirements on the controller parameters are derived. The effect of the controller parameters on the perceived impedance and the maximum safe operating velocity of the robot are determined via the linear model. The adverse impact of dry friction is analysed in simulation and methods are developed to mitigate the effects. The controller is implemented on a 1 DoF robotic joint and the results are compared to those of a traditional admittance control law, demonstrating comparable transient response while maintaining a simple control structure and decreased risk of instability.
ER  - 

TY  - CONF
TI  - Ascento: A Two-Wheeled Jumping Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7515
EP  - 7521
AU  - V. Klemm
AU  - A. Morra
AU  - C. Salzmann
AU  - F. Tschopp
AU  - K. Bodie
AU  - L. Gulich
AU  - N. Küng
AU  - D. Mannhart
AU  - C. Pfister
AU  - M. Vierneisel
AU  - F. Weber
AU  - R. Deuber
AU  - R. Siegwart
PY  - 2019
KW  - inspection
KW  - legged locomotion
KW  - robot dynamics
KW  - wheels
KW  - Ascento
KW  - jumping robot
KW  - mobile ground robots
KW  - complex indoor environments
KW  - mobile robotics
KW  - indoor inspection tasks
KW  - compact wheeled bipedal robot
KW  - flat terrain
KW  - mechanical design
KW  - Wheels
KW  - Legged locomotion
KW  - Hip
KW  - Robot kinematics
KW  - Batteries
DO  - 10.1109/ICRA.2019.8793792
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Applications of mobile ground robots demand high speed and agility while navigating in complex indoor environments. These present an ongoing challenge in mobile robotics. A system with these specifications would be of great use for a wide range of indoor inspection tasks. This paper introduces Ascento, a compact wheeled bipedal robot that is able to move quickly on flat terrain, and to overcome obstacles by jumping. The mechanical design and overall architecture of the system is presented, as well as the development of various controllers for different scenarios. A series of experiments1 with the final prototype system validate these behaviors in realistic scenarios.
ER  - 

TY  - CONF
TI  - Path Following Controller for Differentially Driven Planar Robots with Limited Torques and Uncertain and Changing Dynamics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7522
EP  - 7528
AU  - V. Pitkänen
AU  - V. Halonen
AU  - A. Kemppainen
AU  - J. Röning
PY  - 2019
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - robot dynamics
KW  - torque control
KW  - wheel torque commands
KW  - motor torque limits
KW  - internal control elements
KW  - differentially driven planar robots
KW  - asymmetrical planar robots
KW  - limited motor torques
KW  - environmental forces
KW  - unscented Kalman filter
KW  - robot inertia
KW  - Acceleration
KW  - Mobile robots
KW  - Force
KW  - Wheels
KW  - Torque
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8794198
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a path following controller that is suitable for asymmetrical planar robots with significant mass and limited motor torques. the controller is resistant against environmental forces, and inaccurate estimates of robot's inertia, by estimating their effects with unscented kalman filter. the controller outputs wheel torque commands which take in account the motor torque limits and given relative priority of internal control elements. the method presented is thoroughly explained and the simulation results demonstrate the performance of the controller.
ER  - 

TY  - CONF
TI  - Nonlinear Tire Cornering Stiffness Observer for a Double Steering Off-Road Mobile Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7529
EP  - 7534
AU  - M. Fnadi
AU  - F. Plumet
AU  - F. Benamar
PY  - 2019
KW  - linear quadratic control
KW  - mobile robots
KW  - nonlinear control systems
KW  - observers
KW  - off-road vehicles
KW  - path planning
KW  - predictive control
KW  - steering systems
KW  - tyres
KW  - vehicle dynamics
KW  - open environments
KW  - rear contact cornering stiffnesses
KW  - soil proprieties
KW  - steering angles
KW  - LQR controller
KW  - nonlinear tire cornering stiffness observer
KW  - double steering off-road mobile robot
KW  - path tracking controllers
KW  - autonomous vehicle
KW  - dynamic model
KW  - wheel-ground contact
KW  - Kalman-Bucy observer
KW  - ground parameter estimation
KW  - Observers
KW  - Tires
KW  - Mobile robots
KW  - Vehicle dynamics
KW  - Wheels
KW  - Nonlinear optics
DO  - 10.1109/ICRA.2019.8794047
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Path tracking controllers for an autonomous vehicle are often designed by using either a dynamic model or a kinematic one and some models are related to wheel-ground contact, that makes the efficiency of the controller highly dependent on the ground parameters estimation, especially for off-road mobile robots intended to navigate in open environments. This paper proposes a new nonlinear observer designed to estimate the front and rear contact cornering stiffnesses in real time, that are related both on tire and soil proprieties. The latter is estimated using steering angles as well as yaw rate and lateral velocity, which are provided by a preliminary Kalman-Bucy observer. The performance of the proposed nonlinear observer combined with the LQR controller is evaluated by both advanced simulations and experiments in real conditions at different speeds.
ER  - 

TY  - CONF
TI  - Hierarchical optimization for Whole-Body Control of Wheeled Inverted Pendulum Humanoids
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7535
EP  - 7542
AU  - M. Zafar
AU  - S. Hutchinson
AU  - E. A. Theodorou
PY  - 2019
KW  - control system synthesis
KW  - end effectors
KW  - humanoid robots
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - optimisation
KW  - pendulums
KW  - redundant manipulators
KW  - high-level controller plans
KW  - hierarchical optimization
KW  - whole-body control framework
KW  - redundant manipulators
KW  - wheels
KW  - optimal participation
KW  - low level controller
KW  - control zero dynamics
KW  - low-level controller plans
KW  - body joint manipulation
KW  - WIP humanoids
KW  - wheeled inverted pendulum humanoids
KW  - Wheels
KW  - Manipulator dynamics
KW  - Humanoid robots
KW  - Task analysis
KW  - Mobile robots
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8794360
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a whole-body control framework for Wheeled Inverted Pendulum (WIP) Humanoids. WIP Humanoids are redundant manipulators dynamically balancing themselves on wheels. Characterized by several degrees of freedom, they have the ability to perform several tasks simultaneously, such as balancing, maintaining a body pose, controlling the gaze, lifting a load or maintaining end-effector configuration in operation space. The problem of whole-body control is to enable simultaneous performance of these tasks with optimal participation of all degrees of freedom at specified priorities for each objective. The control also has to obey constraint of angle and torque limits on each joint. The proposed approach is hierarchical with a low level controller for body joints manipulation and a high-level controller that defines center of mass (CoM) targets for the low-level controller to control zero dynamics of the system driving the wheels. The low-level controller plans for shorter horizons while considering more complete dynamics of the system, while the high-level controller plans for longer horizon based on an approximate model of the robot for computational efficiency.
ER  - 

TY  - CONF
TI  - An Actively Controlled Variable Stiffness Structure via Layer Jamming and Pneumatic Actuation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7555
EP  - 7561
AU  - C. Mikol
AU  - H. Su
PY  - 2019
KW  - finite element analysis
KW  - friction
KW  - human-robot interaction
KW  - microactuators
KW  - pneumatic actuators
KW  - actively controlled variable stiffness structure
KW  - collaborative robots
KW  - robotic structures
KW  - actuation system
KW  - actively controlled stiffness structure
KW  - structure shape
KW  - shape morphing
KW  - morphed curvature
KW  - input actuator pressure
KW  - stiffness variation range
KW  - robotics field
KW  - lightweight morphing structures
KW  - pneumatic artificial muscles
KW  - human-robot interaction
KW  - bidirectional morphing
KW  - Pneumatic systems
KW  - Actuators
KW  - Jamming
KW  - Shape
KW  - Service robots
KW  - Muscles
DO  - 10.1109/ICRA.2019.8794340
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Current robotics industry trends show an increased interest in the interaction between humans and robots in a variety of fields, ranging from collaborative robots in manufacturing to assisted medical devices in the medical field. One limiting factor in present applications is the ability to actively morph these robotic structures and control their stiffness using the same type of actuation system. This paper focuses on developing an actively controlled, variable stiffness structure that uses a pneumatic system for both morphing and locking the structure shape. The structure design integrates Pneumatic Artificial Muscles (PAMs) that are pressurized to control shape morphing. The pressurization of the PAM provides a radial force that allows bi-directional morphing based on the pressurization scheme. Layer Jamming, which utilizes varied friction between thin sheets based on pressure, is used to control the variable stiffness of the structure. In this paper, a control model is developed to predict the morphed curvature of the structure based on the input actuator pressure. This experimental control model is also validated using a theoretical pseudo-rigid-body model. The repeatability and accuracy of morphing is also discussed. Through experimental testing, a measure of the stiffness variation range of the structure is also developed. This novel research would positively impact the robotics field by creating lightweight morphing structures that are flexible and easily deformed, but also stiff with high load-carrying capability for increased human-robot interaction.
ER  - 

TY  - CONF
TI  - A Floating-Piston Hydrostatic Linear Actuator and Remote-Direct-Drive 2-DOF Gripper
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7562
EP  - 7568
AU  - E. Schwarm
AU  - K. M. Gravesmill
AU  - J. P. Whitney
PY  - 2019
KW  - brushless DC motors
KW  - design engineering
KW  - dexterous manipulators
KW  - diaphragms
KW  - elastomers
KW  - gears
KW  - grippers
KW  - hydraulic actuators
KW  - hydrostatics
KW  - medical robotics
KW  - motion control
KW  - pistons
KW  - prosthetics
KW  - seals (stoppers)
KW  - stiction
KW  - remote-direct-drive 2-DOF gripper
KW  - serial-chain motor-driven robotic arms
KW  - passive compliance
KW  - remote direct-drive manipulator
KW  - low-friction hydrostatic transmission
KW  - soft fiber-elastomer rolling-diaphragm seals
KW  - static friction
KW  - seal rubbing
KW  - gear ratios
KW  - dexterous robotic arm
KW  - floating-piston hydrostatic linear actuator design
KW  - backdrivable brushless electric motors
KW  - system hysteresis
KW  - powered prosthetic hand design
KW  - size 20.0 mm
KW  - Actuators
KW  - Pistons
KW  - Force
KW  - Manipulators
KW  - Hydraulic systems
KW  - Seals
DO  - 10.1109/ICRA.2019.8794378
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dexterous, serial-chain motor-driven robotic arms have high moving mass, since most of the actuators must be located in the arm itself. This necessitates high gear ratios, sacrificing passive compliance, backdrivability, and the capacity for delicate motion. We introduce the concept of a remote direct-drive (RDD) manipulator, in which every motor is located in the base, connected to remote joints via a low-friction hydrostatic transmission. We have designed a new hydrostatic linear actuator with a fully-floating piston; the piston floats within the cylinder using a pair of soft fiber-elastomer rolling-diaphragm seals. This eliminates static friction from seal rubbing and piston/rod misalignment. Actuators were developed with a 20mm bore, weighing 55 grams each with a 400:1 bidirectional strength-to-weight ratio $( + /-230\mathrm {N}$), which drive a 2-DOF manipulator (wrist pitch/finger pinch; 120-degree range-of-motion; 6.6 Nm max grip strength). The gripper is hydrostatically coupled to remotely-located direct-drive/backdrivable brushless electric motors. System hysteresis and friction are 1 percent of full-range force. This low-mass low-friction configuration is of great interest for powered prosthetic hand design, and passively-safe high dynamic range robot arms.
ER  - 

TY  - CONF
TI  - 3D Printed Ferrofluid Based Soft Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7569
EP  - 7574
AU  - E. S. Keneth
AU  - A. R. Epstein
AU  - M. S. Harari
AU  - R. S. Pierre
AU  - S. Magdassi
AU  - S. Bergbreiter
PY  - 2019
KW  - magnetic actuators
KW  - magnetic fluids
KW  - magnetic particles
KW  - three-dimensional printing
KW  - magnetic particles
KW  - polymeric matrix
KW  - actuator response
KW  - 3D printed material
KW  - 3D printed tubes
KW  - 3D printed more complex actuators
KW  - complex motion
KW  - ferrofluid based soft actuators
KW  - 3D printed soft actuators
KW  - complex shapes
KW  - remote actuation
KW  - external magnetic field
KW  - ferrofluid-based actuator
KW  - Electron tubes
KW  - Magnetic moments
KW  - Ferrofluid
KW  - Actuators
KW  - Magnetic separation
KW  - Magnetic resonance imaging
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793998
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work demonstrates 3D printed soft actuators with complex shapes and remote actuation using an external magnetic field. Instead of embedding magnetic particles in a polymeric matrix, we fabricated a novel ferrofluid-based actuator, in which the fluid can be moved to different locations in the actuator to affect actuator response. We studied the effect of both the ferrofluid and the 3D printed material on the motion of simple actuators using 3D printed tubes. In addition, we 3D printed more complex actuators mimicking a human hand and a worm to demonstrate more complex motion.
ER  - 

TY  - CONF
TI  - Learning Primitive Skills for Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7597
EP  - 7603
AU  - Y. Zhu
AU  - D. Schwab
AU  - M. Veloso
PY  - 2019
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - legged locomotion
KW  - multi-robot systems
KW  - robot vision
KW  - robot soccer small-size domain
KW  - tactical level team strategies
KW  - high-level team strategies
KW  - individual robot ball-based skills
KW  - robot primitive skills
KW  - continuous action space
KW  - hardware fidelity
KW  - learned skills
KW  - mobile robots
KW  - hand-coding algorithms
KW  - training parameters
KW  - mobile robot system
KW  - deep reinforcement learning algorithm
KW  - primitive skills
KW  - task performance
KW  - learning algorithms
KW  - Robot kinematics
KW  - Sports
KW  - Task analysis
KW  - Training
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8793688
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Achieving effective task performance on real mobile robots is a great challenge when hand-coding algorithms, both due to the amount of effort involved and manually tuned parameters required for each skill. Learning algorithms instead have the potential to lighten up this challenge by using one single set of training parameters for learning different skills, but the question of the feasibility of such learning in real robots remains a research pursuit. We focus on a kind of mobile robot system - the robot soccer “small-size” domain, in which tactical and high-level team strategies build upon individual robot ball-based skills. In this paper, we present our work using a Deep Reinforcement Learning algorithm to learn three real robot primitive skills in continuous action space: go-to-ball, turn-and-shoot and shoot-goalie, for which there is a clear success metric to reach a destination or score a goal. We introduce the state and action representation, as well as the reward and network architecture. We describe our training and testing using a simulator of high physical and hardware fidelity. Then we test the policies trained from simulation on real robots. Our results show that the learned skills achieve an overall better success rate at the expense of taking 0.29 seconds slower on average for all three skills. In the end, we show that our policies trained in simulation have good performance on real robots by directly transferring the policy.
ER  - 

TY  - CONF
TI  - Coverage Path Planning in Belief Space
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7604
EP  - 7610
AU  - R. Schirmer
AU  - P. Biber
AU  - C. Stachniss
PY  - 2019
KW  - C++ language
KW  - collision avoidance
KW  - control engineering computing
KW  - lawnmowers
KW  - mobile robots
KW  - navigation
KW  - operating systems (computers)
KW  - robot programming
KW  - coverage path planning
KW  - belief space
KW  - robotic lawn mowers
KW  - safety-critical tasks
KW  - robot safety
KW  - cheap range sensors
KW  - low range sensors
KW  - uncertainty-aware coverage path
KW  - lawn mower
KW  - safe navigation
KW  - collision avoidance
KW  - C++ language
KW  - ROS
KW  - Robot sensing systems
KW  - Planning
KW  - Path planning
KW  - Uncertainty
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793969
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For safety reasons, robotic lawn mowers and similar devices are required to stay within a predefined working area. Keeping the robot within its workspace is typically achieved by special safeguards such as a wire installed in the ground. In the case of robotic lawn mowers, this causes a certain customer reluctance. It is more desirable to fulfill those safety-critical tasks by safe navigation and path planning. In this paper, we tackle the problem of planning a coverage path composed of parallel lanes that maximizes robot safety under the constraints of cheap, low range sensors and thus substantial uncertainty in the robot's belief and ability to execute actions. Our approach uses a map of the environment to estimate localizability at all locations, and it uses these estimates to search for an uncertainty-aware coverage path while avoiding collisions. We implemented our approach using C++ and ROS and thoroughly tested it on real garden data. The experiment shows that our approach leads to safer meander patterns for the lawn mower and takes expected localizability information into account.
ER  - 

TY  - CONF
TI  - Continuous Control for High-Dimensional State Spaces: An Interactive Learning Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7611
EP  - 7617
AU  - R. Pérez-Dattari
AU  - C. Celemin
AU  - J. Ruiz-del-Solar
AU  - J. Kober
PY  - 2019
KW  - interactive systems
KW  - learning (artificial intelligence)
KW  - interactive learning approach
KW  - deep reinforcement learning
KW  - corrective advice communicated by humans
KW  - DRL agent
KW  - human training effort
KW  - D-COACH framework
KW  - human corrective feedback
KW  - human knowledge
KW  - machine learning methods
KW  - reward function
KW  - simulated environments
KW  - robotics applications
KW  - complex decision-making problems
KW  - high-dimensional state spaces
KW  - continuous control
KW  - Training
KW  - Robots
KW  - Shape
KW  - Task analysis
KW  - Adaptation models
KW  - Decoding
KW  - Machine learning
DO  - 10.1109/ICRA.2019.8793675
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Deep Reinforcement Learning (DRL) has become a powerful methodology to solve complex decision-making problems. However, DRL has several limitations when used in real-world problems (e.g., robotics applications). For instance, long training times are required and cannot be accelerated in contrast to simulated environments, and reward functions may be hard to specify/model and/or to compute. Moreover, the transfer of policies learned in a simulator to the real-world has limitations (reality gap). On the other hand, machine learning methods that rely on the transfer of human knowledge to an agent have shown to be time efficient for obtaining well performing policies and do not require a reward function. In this context, we analyze the use of human corrective feedback during task execution to learn policies with high-dimensional state spaces, by using the D-COACH framework, and we propose new variants of this framework. D-COACH is a Deep Learning based extension of COACH (COrrective Advice Communicated by Humans), where humans are able to shape policies through corrective advice. The enhanced version of DCOACH, which is proposed in this paper, largely reduces the time and effort of a human for training a policy. Experimental results validate the efficiency of the D-COACH framework in three different problems (simulated and with real robots), and show that its enhanced version reduces the human training effort considerably, and makes it feasible to learn policies within periods of time in which a DRL agent do not reach any improvement.
ER  - 

TY  - CONF
TI  - A Predictive Reward Function for Human-Like Driving Based on a Transition Model of Surrounding Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7618
EP  - 7624
AU  - D. Hayashi
AU  - Y. Xu
AU  - T. Bando
AU  - K. Takeda
PY  - 2019
KW  - decision making
KW  - image processing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - road traffic
KW  - road vehicles
KW  - robot vision
KW  - traffic engineering computing
KW  - autonomous driving vehicles
KW  - deep predictive network
KW  - predictive reward function
KW  - human-like driving
KW  - decision making
KW  - vehicle control
KW  - traffic flow
KW  - occupancy grid image
KW  - prediction network training
KW  - real driving data
KW  - reinforcement learning agent training
KW  - deep neural networks
KW  - Autonomous vehicles
KW  - Roads
KW  - Predictive models
KW  - Reinforcement learning
KW  - Decision making
KW  - Object detection
KW  - Autonomous driving
KW  - Prediction
KW  - Reward
KW  - Deep Learning
KW  - Reinforcement Learning
KW  - naturalistic Driving Data
DO  - 10.1109/ICRA.2019.8794010
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Driving is a complex task that requires the perception of the surrounding environment, decision making and control of the vehicle. Human drivers predict how surrounding objects move and decide an appropriate driving behavior. As with human drivers, autonomous driving vehicles should consider the condition of the surrounding environment and behave naturally so as not to disturb the traffic flow. We propose a reward function for learning how natural the driving is based on the hypothesis that the movement of surrounding vehicles becomes unpredictable when the ego vehicle takes an unnatural driving behavior. The reward function is based on the prediction error of a deep predictive network that models the transition of the surrounding environment. Occupancy grid image is used to perceive the surrounding environment and the predictions up to two seconds are used to calculate the reward function. We evaluated the reward function using both simulated and the real world data. We trained the prediction network using real driving data and trained a reinforcement learning agent based on the reward function. Then we compared the speed planned by the agent and a human driver, which showed a correlation of 0.52. We also confirmed the benefit of taking prediction into account by observing the behavior of the agent in a specific traffic scenario.
ER  - 

TY  - CONF
TI  - ADAPS: Autonomous Driving Via Principled Simulations
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7625
EP  - 7631
AU  - W. Li
AU  - D. Wolinski
AU  - M. C. Lin
PY  - 2019
KW  - hierarchical systems
KW  - remotely operated vehicles
KW  - road traffic control
KW  - robust control
KW  - ADAPS
KW  - autonomous driving
KW  - robust control policy
KW  - autonomous vehicles
KW  - simulation platforms
KW  - learning mechanism
KW  - hierarchical control policy
KW  - DAGGER method
KW  - Task analysis
KW  - Training
KW  - Accidents
KW  - Autonomous vehicles
KW  - Training data
KW  - Trajectory
KW  - Learning systems
DO  - 10.1109/ICRA.2019.8794239
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous driving has gained significant advancements in recent years. However, obtaining a robust control policy for driving remains challenging as it requires training data from a variety of scenarios, including rare situations (e.g., accidents), an effective policy architecture, and an efficient learning mechanism. We propose ADAPS for producing robust control policies for autonomous vehicles. ADAPS consists of two simulation platforms in generating and analyzing accidents to automatically produce labeled training data, and a memoryenabled hierarchical control policy. Additionally, ADAPS offers a more efficient online learning mechanism that reduces the number of iterations required in learning compared to existing methods such as DAGGER [1]. We present both theoretical and experimental results. The latter are produced in simulated environments, where qualitative and quantitative results are generated to demonstrate the benefits of ADAPS.
ER  - 

TY  - CONF
TI  - Planning Coordinated Event Observation for Structured Narratives
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7632
EP  - 7638
AU  - D. A. Shell
AU  - L. Huang
AU  - A. T. Becker
AU  - J. M. O’Kane
PY  - 2019
KW  - finite automata
KW  - mobile robots
KW  - multi-robot systems
KW  - sport
KW  - structured narratives
KW  - autonomous robots
KW  - robot teams
KW  - large-scale road race
KW  - marathon
KW  - legible form
KW  - weighted finite automaton
KW  - simulated race scenario
KW  - coordinated event observation planning
KW  - Videos
KW  - Robot kinematics
KW  - Cameras
KW  - Robot vision systems
KW  - Mobile robots
KW  - Observers
DO  - 10.1109/ICRA.2019.8794450
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of using autonomous robots to record events that obey narrative structure. The work is motivated by a vision of robot teams that can, for example, produce individualized highlight videos for each runner in a large-scale road race such as a marathon. We introduce a method for specifying the desired structure as a function that describes how well the captured events can be used to produce an output that meets the specification. This function is specified in a compact, legible form similar to a weighted finite automaton. Then we describe a planner that uses simple predictions of future events to coordinate the robots' efforts to capture the most important events, as determined by the specification. We describe an implementation of this approach, and demonstrate its effectiveness in a simulated race scenario both in simulation and in a hardware testbed.
ER  - 

TY  - CONF
TI  - Algorithmic Resolution of Multiple Impacts in Nonsmooth Mechanical Systems with Switching Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7639
EP  - 7645
AU  - Y. Li
AU  - H. Yu
AU  - D. J. Braun
PY  - 2019
KW  - complementarity
KW  - differential algebraic equations
KW  - impact (mechanical)
KW  - iterative methods
KW  - legged locomotion
KW  - plasticity
KW  - robot dynamics
KW  - algorithmic resolution
KW  - multiple impacts
KW  - nonsmooth mechanical systems
KW  - switching constraints
KW  - differential-algebraic formulation
KW  - nonsmooth dynamics
KW  - robotic systems
KW  - changing constraints
KW  - kinematic constraints
KW  - algorithmic impact resolution method
KW  - classical plastic impact law
KW  - multiple simultaneous impacts
KW  - prior linear-complementarity-based formulations
KW  - implicit impact resolution
KW  - Switches
KW  - Mathematical model
KW  - Mechanical systems
KW  - Robots
KW  - Dynamics
KW  - Heuristic algorithms
KW  - Plastics
DO  - 10.1109/ICRA.2019.8793767
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a differential-algebraic formulation with switching constraints to model the nonsmooth dynamics of robotic systems subject to changing constraints and multiple impacts. The formulation combines a single structurally simple governing equation, a set of switching kinematic constraints, and the plastic impact law, to represent the dynamics of robots that interact with their environment. The main contribution of this formulation is a novel algorithmic impact resolution method which provides an explicit solution to the classical plastic impact law in the case of multiple simultaneous impacts. This method serves as an alternative to prior linear-complementarity-based formulations which offer an implicit impact resolution through iterative calculation. We demonstrate the utility of the proposed method by simulating the locomotion of a planar anthropometric biped.
ER  - 

TY  - CONF
TI  - Rigid Body Motion Prediction with Planar Non-convex Contact Patch
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7646
EP  - 7652
AU  - J. Xie
AU  - N. Chakraborty
PY  - 2019
KW  - computational geometry
KW  - manipulator dynamics
KW  - mechanical contact
KW  - shear modulus
KW  - planar nonconvex contact patch
KW  - intermittent contact
KW  - rigid body dynamic simulation
KW  - convex contact patches
KW  - contact detection
KW  - contacting rigid bodies
KW  - multiple point contact
KW  - single point contact
KW  - rigid body motion prediction
KW  - convex hull
KW  - Mathematical model
KW  - Dynamics
KW  - Numerical models
KW  - Transmission line matrix methods
KW  - Robots
KW  - Bars
KW  - Symmetric matrices
DO  - 10.1109/ICRA.2019.8793724
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a principled method for motion prediction via dynamic simulation for rigid bodies in intermittent contact with each other where the contact is assumed to be a planar non-convex contact patch. The planar non-convex contact patch can either be a topologically connected set or disconnected set. Such algorithms are useful in planning and control for robotic manipulation. Most work in rigid body dynamic simulation assume that the contact between objects is a point contact, which may not be valid in many applications. In this paper, by using the convex hull of the contact patch, we build on our recent work on simulating rigid bodies with convex contact patches, for simulating motion of objects with planar non-convex contact patches. We formulate a discrete-time mixed complementarity problem where we solve the contact detection and integration of the equations of motion simultaneously. Thus, our method is a geometrically-implicit method and we prove that in our formulation, there is no artificial penetration between the contacting rigid bodies. We solve for the equivalent contact point (ECP) and contact impulse of each contact patch simultaneously along with the state, i.e., configuration and velocity of the objects. We provide empirical evidence to show that our method can seamlessly capture transition between different contact modes like patch contact to multiple or single point contact during simulation.
ER  - 

TY  - CONF
TI  - A Data-driven Approach for Fast Simulation of Robot Locomotion on Granular Media
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7653
EP  - 7659
AU  - Y. Zhu
AU  - L. Abdulmajeid
AU  - K. Hauser
PY  - 2019
KW  - control engineering computing
KW  - data analysis
KW  - granular materials
KW  - legged locomotion
KW  - mechanical contact
KW  - optimisation
KW  - shear modulus
KW  - stick-slip
KW  - data-driven approach
KW  - robot locomotion
KW  - granular media
KW  - semiempirical approach
KW  - contact model
KW  - stick-slip behavior
KW  - rigid objects
KW  - granular grains
KW  - granular substrate
KW  - optimization-based contact force
KW  - contact solver
KW  - contact wrenches
KW  - fast simulation
KW  - convex volume
KW  - frictional dissipation
KW  - plausible interaction response
KW  - Substrates
KW  - Computational modeling
KW  - Force
KW  - Media
KW  - Legged locomotion
KW  - Foot
DO  - 10.1109/ICRA.2019.8794337
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a semi-empirical approach for simulating robot locomotion on granular media. We first develop a contact model based on the stick-slip behavior between rigid objects and granular grains, which is then learned through running extensive experiments. The contact model represents all possible contact wrenches that the granular substrate can provide as a convex volume, which our method formulates as constraints in an optimization-based contact force solver. During simulation, granular substrates are treated as rigid objects that allow penetration and the contact solver solves for wrenches that maximize frictional dissipation. We show that our method is able to simulate plausible interaction response with several granular media at interactive rates.
ER  - 

TY  - CONF
TI  - Controller Synthesis for Discrete-time Hybrid Polynomial Systems via Occupation Measures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7675
EP  - 7682
AU  - W. Han
AU  - R. Tedrake
PY  - 2019
KW  - computational complexity
KW  - control system synthesis
KW  - discrete time systems
KW  - feedback
KW  - legged locomotion
KW  - linear programming
KW  - linear systems
KW  - manipulator dynamics
KW  - optimisation
KW  - polynomials
KW  - stability
KW  - discrete-time hybrid polynomial system
KW  - occupation measures
KW  - controller synthesis
KW  - computational complexity
KW  - polynomial dynamics equation
KW  - feedback design
KW  - rigid body system stabilization
KW  - state-input space
KW  - finite-dimensional semidefinite programs
KW  - robot locomotion
KW  - robot manipulation
KW  - Aerospace electronics
KW  - Switches
KW  - Mathematical model
KW  - Optimization
KW  - Legged locomotion
DO  - 10.1109/ICRA.2019.8793881
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the feedback design for stabilizing a rigid body system by making and breaking multiple contacts with the environment without prespecifying the timing or the number of occurrence of the contacts. We model such a system as a discrete-time hybrid polynomial system, where the state-input space is partitioned into several polytopic regions with each region associated with a different polynomial dynamics equation. Based on the notion of occupation measures, we present a novel controller synthesis approach that solves finite-dimensional semidefinite programs as approximations to an infinite-dimensional linear program to stabilize the system. The optimization formulation is simple and convex, and for any fixed degree of approximations the computational complexity is polynomial in the state and control input dimensions. We illustrate our approach on some robotics examples.
ER  - 

TY  - CONF
TI  - Optimal Path Planning for ω-regular Objectives with Abstraction-Refinement
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7683
EP  - 7689
AU  - Y. P. Leong
AU  - P. Prabhakar
PY  - 2019
KW  - automata theory
KW  - computational complexity
KW  - control system synthesis
KW  - discrete time systems
KW  - game theory
KW  - optimal control
KW  - optimisation
KW  - path planning
KW  - trajectory control
KW  - optimal path planning
KW  - ω-regular objective
KW  - abstraction-refinement based framework
KW  - optimal controller synthesis
KW  - discrete-time concrete system
KW  - finite weighted transition system
KW  - optimal abstract controller
KW  - formal controller synthesis algorithms
KW  - robot surveillance scenario
KW  - Büchi automaton
KW  - Games
KW  - Automata
KW  - Surveillance
KW  - Cost function
KW  - Path planning
KW  - Partitioning algorithms
DO  - 10.1109/ICRA.2019.8794209
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents an abstraction-refinement based framework for optimal controller synthesis of discrete-time systems with respect to ω-regular objectives. It first abstracts the discrete-time “concrete” system into a finite weighted transition system using a finite partition of the state-space. Then, a two-player mean payoff parity game is solved on the product of the abstract system and the Büchi automaton corresponding to the ω-regular objective, to obtain an optimal “abstract” controller that satisfies the ω-regular objective. The abstract controller is guaranteed to be implementable in the concrete discrete-time system, with a sub-optimal cost. The abstraction is refined with finer partitions to reduce the suboptimality. In contrast to existing formal controller synthesis algorithms based on abstractions, this technique provides an upper bound on the trajectory cost when implementing the suboptimal controller. A robot surveillance scenario is presented to illustrate the feasibility of the approach.
ER  - 

TY  - CONF
TI  - Sampling-Based Polytopic Trees for Approximate Optimal Control of Piecewise Affine Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7690
EP  - 7696
AU  - S. Sadraddini
AU  - R. Tedrake
PY  - 2019
KW  - approximation theory
KW  - closed loop systems
KW  - control system synthesis
KW  - convex programming
KW  - discrete time systems
KW  - feedback
KW  - integer programming
KW  - linear quadratic control
KW  - Lyapunov methods
KW  - nonlinear control systems
KW  - optimal control
KW  - piecewise linear techniques
KW  - predictive control
KW  - stability
KW  - piecewise affine systems
KW  - contact dynamics
KW  - robot locomotion
KW  - control techniques
KW  - feedback control policies
KW  - discrete-time PWA systems
KW  - closed-loop trajectories
KW  - cost function
KW  - LQR-trees
KW  - open-loop trajectory optimization
KW  - PWA dynamics
KW  - contact-based dynamics
KW  - sampling-based polytopic trees
KW  - approximate optimal control
KW  - Trajectory
KW  - Robots
KW  - Programming
KW  - Integrated circuit modeling
KW  - Optimization
KW  - Optimal control
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793634
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Piecewise affine (PWA) systems are widely used to model highly nonlinear behaviors such as contact dynamics in robot locomotion and manipulation. Existing control techniques for PWA systems have computational drawbacks, both in offline design and online implementation. In this paper, we introduce a method to obtain feedback control policies and a corresponding set of admissible initial conditions for discrete-time PWA systems such that all the closed-loop trajectories reach a goal polytope, while a cost function is optimized. The idea is conceptually similar to LQR-trees [1], which consists of 3 steps: (1) open-loop trajectory optimization, (2) feedback control for computation of “funnels” of states around trajectories, and (3) repeating (1) and (2) in a way that the funnels are grown backward from the goal in a tree fashion and fill the state-space as much as possible. We show PWA dynamics can be exploited to combine step (1) and (2) into a single step that is tackled using mixed-integer convex programming, which makes the method suitable for dealing with hard constraints. Illustrative examples on contact-based dynamics are presented.
ER  - 

TY  - CONF
TI  - A Classification-based Approach for Approximate Reachability
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7697
EP  - 7704
AU  - V. Rubies-Royo
AU  - D. Fridovich-Keil
AU  - S. Herbert
AU  - C. J. Tomlin
PY  - 2019
KW  - approximation theory
KW  - computational complexity
KW  - controllability
KW  - nonlinear control systems
KW  - optimal control
KW  - pattern classification
KW  - reachability analysis
KW  - goal satisfaction
KW  - safety verification
KW  - nonlinear systems
KW  - computational complexity
KW  - restrictive problem classes
KW  - optimal controller
KW  - HJ reachability problem
KW  - control-affine systems
KW  - dynamical systems
KW  - reachability value function
KW  - classification-based approach
KW  - approximate reachability
KW  - Hamilton-Jacobi reachability analysis
KW  - simple binary classifiers
KW  - grid-based methodologies
KW  - physical quadrotor navigation task
KW  - Optimal control
KW  - Reachability analysis
KW  - Tools
KW  - Neural networks
KW  - Safety
KW  - System dynamics
DO  - 10.1109/ICRA.2019.8793919
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Hamilton-Jacobi (HJ) reachability analysis has been developed over the past decades into a widely-applicable tool for determining goal satisfaction and safety verification in nonlinear systems. While HJ reachability can be formulated very generally, computational complexity can be a serious impediment for many systems of practical interest. Much prior work has been devoted to computing approximate solutions to large reachability problems, yet many of these methods may only apply to very restrictive problem classes, do not generate controllers, and/or can be extremely conservative. In this paper, we present a new method for approximating the optimal controller of the HJ reachability problem for control-affine systems. While also a specific problem class, many dynamical systems of interest are, or can be well approximated, by control-affine models. We explicitly avoid storing a representation of the reachability value function, and instead learn a controller as a sequence of simple binary classifiers. We compare our approach to existing grid-based methodologies in HJ reachability and demonstrate its utility on several examples, including a physical quadrotor navigation task.
ER  - 

TY  - CONF
TI  - Improving drone localisation around wind turbines using monocular model-based tracking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7713
EP  - 7719
AU  - O. Moolan-Feroze
AU  - K. Karachalios
AU  - D. N. Nikolaidis
AU  - A. Calway
PY  - 2019
KW  - convolutional neural nets
KW  - Global Positioning System
KW  - graph theory
KW  - image matching
KW  - image representation
KW  - inertial navigation
KW  - mobile robots
KW  - object tracking
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - wind turbines
KW  - image-based measurements
KW  - drone navigation system
KW  - automated inspection
KW  - wind turbines
KW  - 3D skeleton representation
KW  - image data
KW  - convolutional neural network
KW  - generic turbine model
KW  - turbine shapes
KW  - image measurements
KW  - drone localisation
KW  - monocular model-based tracking
KW  - pose graph optimiser
KW  - Wind turbines
KW  - Blades
KW  - Drones
KW  - Inspection
KW  - Poles and towers
KW  - Cameras
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8794156
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel method of integrating image-based measurements into a drone navigation system for the automated inspection of wind turbines. We take a model-based tracking approach, where a 3D skeleton representation of the turbine is matched to the image data. Matching is based on comparing the projection of the representation to that inferred from images using a convolutional neural network. This enables us to find image correspondences using a generic turbine model that can be applied to a wide range of turbine shapes and sizes. To estimate 3D pose of the drone, we fuse the network output with GPS and IMU measurements using a pose graph optimiser. Results illustrate that the use of the image measurements significantly improves the accuracy of the localisation over that obtained using GPS and IMU alone.
ER  - 

TY  - CONF
TI  - Experimental Assessment of Plume Mapping using Point Measurements from Unmanned Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7720
EP  - 7726
AU  - M. Hutchinson
AU  - P. Ladosz
AU  - C. Liu
AU  - W. Chen
PY  - 2019
KW  - air pollution
KW  - air quality
KW  - autonomous aerial vehicles
KW  - environmental monitoring (geophysics)
KW  - Gaussian processes
KW  - interpolation
KW  - mobile robots
KW  - Monte Carlo methods
KW  - regression analysis
KW  - point measurements
KW  - autonomous robots
KW  - mapping algorithms
KW  - piecewise linear interpolation
KW  - steady state ground truth
KW  - unmanned aerial vehicle
KW  - Gaussian process regression
KW  - polynomial interpolation
KW  - plume mapping
KW  - neural networks
KW  - Robot sensing systems
KW  - Interpolation
KW  - Gaussian processes
KW  - Dispersion
KW  - Noise measurement
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793848
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents experiments to assess the plume mapping performance of autonomous robots. The paper compares several mapping algorithms including Gaussian Process regression, Neural networks and polynomial and piecewise linear interpolation. The methods are compared in Monte Carlo simulations using a well known plume model and in indoor experiments using a ground robot. Unlike previous work on mapping using unmanned vehicles, the indoor experiments were performed in a controlled and repeatable manner where a steady state ground truth could be obtained in order to properly assess the various regression methods using data from a real dispersive source and sensor. The effect of sampling time during data collection was assessed with regards to the mapping accuracy, and the data collected during the experiments have been made available. Overall, the Gaussian Process method was found to perform the best among the regression algorithms, showing more robustness to the noisy measurements obtained from short sampling periods, enabling an accurate map to be produced in significantly less time. Finally, plume mapping results are presented in uncontrolled outdoor conditions, using an unmanned aerial vehicle, to demonstrate the system in a realistic uncontrolled environment.
ER  - 

TY  - CONF
TI  - Online Deep Learning for Improved Trajectory Tracking of Unmanned Aerial Vehicles Using Expert Knowledge
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7727
EP  - 7733
AU  - A. Sarabakha
AU  - E. Kayacan
PY  - 2019
KW  - autonomous aerial vehicles
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - trajectory control
KW  - input-output dataset
KW  - deep neural network-based controller
KW  - trained DNN
KW  - expert knowledge
KW  - learning-based approach
KW  - trajectory tracking performance
KW  - online deep learning
KW  - unmanned aerial vehicles
KW  - online learning-based control method
KW  - trajectory tracking
KW  - Training
KW  - Fuzzy logic
KW  - Unmanned aerial vehicles
KW  - Trajectory
KW  - Real-time systems
KW  - Trajectory tracking
DO  - 10.1109/ICRA.2019.8794314
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work presents an online learning-based control method for improved trajectory tracking of unmanned aerial vehicles using both deep learning and expert knowledge. The proposed method does not require the exact model of the system to be controlled, and it is robust against variations in system dynamics as well as operational uncertainties. The learning is divided into two phases: offline (pre-)training and online (post-)training. In the former, a conventional controller performs a set of trajectories and, based on the input-output dataset, the deep neural network (DNN)-based controller is trained. In the latter, the trained DNN, which mimics the conventional controller, controls the system. Unlike the existing papers in the literature, the network is still being trained for different sets of trajectories which are not used in the training phase of DNN. Thanks to the rule-base, which contains the expert knowledge, the proposed framework learns the system dynamics and operational uncertainties in real-time. The experimental results show that the proposed online learning-based approach gives better trajectory tracking performance when compared to the only offline trained network.
ER  - 

TY  - CONF
TI  - Decentralized collaborative transport of fabrics using micro-UAVs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7734
EP  - 7740
AU  - R. Cotsakis
AU  - D. St-Onge
AU  - G. Beltrame
PY  - 2019
KW  - autonomous aerial vehicles
KW  - decentralised control
KW  - microrobots
KW  - mobile robots
KW  - remotely operated vehicles
KW  - microUAV
KW  - small unmanned aerial vehicles
KW  - Buzz swarm-specific scripting language
KW  - fully decentralized control infrastructure
KW  - task demands
KW  - unstructured environments
KW  - maximum flexibility
KW  - joint payload capacity
KW  - decentralized collaborative transport
KW  - Robots
KW  - Payloads
KW  - Springs
KW  - Force
KW  - Task analysis
KW  - Shock absorbers
KW  - Python
DO  - 10.1109/ICRA.2019.8793778
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Small unmanned aerial vehicles (UAVs) have generally little capacity to carry payloads. Through collaboration, the UAVs can increase their joint payload capacity and carry more significant loads. For maximum flexibility to dynamic and unstructured environments and task demands, we propose a fully decentralized control infrastructure based on a swarm-specific scripting language, Buzz. In this paper, we describe the control infrastructure and use it to compare two algorithms for collaborative transport: field potentials and spring-damper. We test the performance of our approach with a fleet of micro-UAVs, demonstrating the potential of decentralized control for collaborative transport.
ER  - 

TY  - CONF
TI  - Precision Stationary Flight of a Robotic Hummingbird*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7741
EP  - 7747
AU  - A. Roshanbin
AU  - E. Garone
AU  - A. Preumont
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - cascade control
KW  - compensation
KW  - mobile robots
KW  - robot dynamics
KW  - robot kinematics
KW  - torque control
KW  - trajectory control
KW  - robotic hummingbird project
KW  - flapping mechanism
KW  - wing trajectory
KW  - cascade control strategy
KW  - precision stationary flight
KW  - residual parasitic torques compensation
KW  - lift vector
KW  - autopilot
KW  - Bars
KW  - Robots
KW  - Acceleration
KW  - Aerodynamics
KW  - Harmonic analysis
KW  - Couplings
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8793841
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper describes recent developments of a robotic hummingbird project, aimed at achieving precision stationary hovering. To this end, the early version of our flapping mechanism is modified which, besides being more efficient, reduces significantly the asymmetry of the wing trajectory of the previous version. A cascade control strategy is used to compensate for the residual parasitic torques and the misalignment of the lift vector and the autopilot.
ER  - 

TY  - CONF
TI  - Robust attitude estimation using an adaptive unscented Kalman filter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7748
EP  - 7754
AU  - A. C. B. Chiella
AU  - B. O. S. Teixeira
AU  - G. A. S. Pereira
PY  - 2019
KW  - attitude control
KW  - attitude measurement
KW  - covariance matrices
KW  - Kalman filters
KW  - manipulators
KW  - nonlinear filters
KW  - robust control
KW  - UKF innovation
KW  - adaptive strategy
KW  - measurement covariance matrix online
KW  - outlier detection
KW  - robust attitude estimation
KW  - standard UKF
KW  - unit quaternion algebra
KW  - outlier detector algorithm
KW  - robust adaptive unscented Kalman filter
KW  - Quaternions
KW  - Estimation
KW  - Covariance matrices
KW  - Magnetometers
KW  - Kalman filters
KW  - Accelerometers
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793714
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the robust Adaptive unscented Kalman filter (RAUKF) for attitude estimation. Since the proposed algorithm represents attitude as a unit quaternion, all basic tools used, including the standard UKF, are adapted to the unit quaternion algebra. Additionally, the algorithm adopts an outlier detector algorithm to identify abrupt changes in the UKF innovation and an adaptive strategy based on covariance matching to tune the measurement covariance matrix online. Adaptation and outlier detection make the proposed algorithm robust to fast and slow perturbations such as magnetic field interference and linear accelerations. Experimental results with a manipulator robot suggest that our method overcomes other algorithms found in the literature.
ER  - 

TY  - CONF
TI  - One-Shot Learning of Multi-Step Tasks from Observation via Activity Localization in Auxiliary Video
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7755
EP  - 7761
AU  - W. Goo
AU  - S. Niekum
PY  - 2019
KW  - inference mechanisms
KW  - learning (artificial intelligence)
KW  - video signal processing
KW  - one-shot learning
KW  - multistep tasks
KW  - activity localization
KW  - reinforcement learning
KW  - action policies learning
KW  - reward functions inference
KW  - user-segmented demonstration
KW  - auxiliary video data
KW  - Task analysis
KW  - Reinforcement learning
KW  - Neural networks
KW  - Training
KW  - Robot sensing systems
KW  - Training data
DO  - 10.1109/ICRA.2019.8793515
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Due to burdensome data requirements, learning from demonstration often falls short of its promise to allow users to quickly and naturally program robots. Demonstrations are inherently ambiguous and incomplete, making correct generalization to unseen situations difficult without a large number of demonstrations in varying conditions. By contrast, humans are often able to learn complex tasks from a single demonstration (typically observations without action labels) by leveraging context learned over a lifetime. Inspired by this capability, our goal is to enable robots to perform one-shot learning of multi-step tasks from observation by leveraging auxiliary video data as context. Our primary contribution is a novel system that achieves this goal by: (1) using a single user-segmented demonstration to define the primitive actions that comprise a task, (2) localizing additional examples of these actions in unsegmented auxiliary videos via a metalearning-based approach, (3) using these additional examples to learn a reward function for each action, and (4) performing reinforcement learning on top of the inferred reward functions to learn action policies that can be combined to accomplish the task. We empirically demonstrate that a robot can learn multi-step tasks more effectively when provided auxiliary video, and that performance greatly improves when localizing individual actions, compared to learning from unsegmented videos.
ER  - 

TY  - CONF
TI  - LVIS: Learning from Value Function Intervals for Contact-Aware Robot Controllers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 7762
EP  - 7768
AU  - R. Deits
AU  - T. Koolen
AU  - R. Tedrake
PY  - 2019
KW  - concave programming
KW  - feedback
KW  - humanoid robots
KW  - integer programming
KW  - learning (artificial intelligence)
KW  - mechanical contact
KW  - mobile robots
KW  - neurocontrollers
KW  - optimal control
KW  - predictive control
KW  - robot dynamics
KW  - tree searching
KW  - LVIS
KW  - contact-aware robot controllers
KW  - guided policy search
KW  - high-dimensional systems
KW  - nonconvex trajectory optimization
KW  - local minima
KW  - optimal policy
KW  - independently-optimized samples
KW  - optimal value function
KW  - mixed-integer programs
KW  - global optimality
KW  - interval samples
KW  - terminal cost
KW  - feedback control
KW  - learning from value function intervals
KW  - controller training
KW  - global mixed-integer optimization
KW  - nonuniqueness issue
KW  - branch-and-bound algorithm
KW  - neural net training
KW  - learned cost-to-go
KW  - one-step model-predictive controller
KW  - piecewise affine models
KW  - cart-pole system
KW  - planar humanoid robot
KW  - Humanoid robots
KW  - Trajectory optimization
KW  - Neural networks
KW  - Force
KW  - Training
DO  - 10.1109/ICRA.2019.8794352
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Guided policy search is a popular approach for training controllers for high-dimensional systems, but it has a number of pitfalls. Non-convex trajectory optimization has local minima, and non-uniqueness in the optimal policy itself can mean that independently-optimized samples do not describe a coherent policy from which to train. We introduce LVIS, which circumvents the issue of local minima through global mixed-integer optimization and the issue of non-uniqueness through learning the optimal value function rather than the optimal policy. To avoid the expense of solving the mixed-integer programs to full global optimality, we instead solve them only partially, extracting intervals containing the true cost-to-go from early termination of the branch-and-bound algorithm. These interval samples are used to weakly supervise the training of a neural net which approximates the true cost-to-go. Online, we use that learned cost-to-go as the terminal cost of a one-step model-predictive controller, which we solve via a small mixed-integer optimization. We demonstrate LVIS on piecewise affine models of a cart-pole system with walls and a planar humanoid robot and show that it can be applied to a fundamentally hard problem in feedback control-control through contact.
ER  - 


