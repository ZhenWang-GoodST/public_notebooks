TY  - CONF
TI  - DSNet: Joint Learning for Scene Segmentation and Disparity Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2946
EP  - 2952
AU  - W. Zhan
AU  - X. Ou
AU  - Y. Yang
AU  - L. Chen
PY  - 2019
KW  - feature extraction
KW  - image coding
KW  - image matching
KW  - image segmentation
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - semantic features
KW  - deep disparity features
KW  - semantic labels
KW  - scene segmentation
KW  - disparity estimation
KW  - scene semantics
KW  - optical flow estimation
KW  - depth information
KW  - dense depth maps
KW  - image frames
KW  - deep semantic information
KW  - disparity feature maps
KW  - independent encoding modules
KW  - semantic disparity information
KW  - multitasking architecture DSNet
KW  - ResNet encoding module
KW  - Semantics
KW  - Estimation
KW  - Task analysis
KW  - Feature extraction
KW  - Optical imaging
KW  - Training
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793573
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recently, research works have attempted the joint prediction of scene semantics and optical flow estimation, which demonstrate the mutual improvement between both tasks. Besides, the depth information is also indispensable for the scene understanding, and disparity estimation is necessary for outputting dense depth maps. Such task shares a great similarity with the optical flow estimation since they can all be cast into a problem of capturing the difference at a location of two image frames. However, as far as we know, currently there are few networks for the joint learning of semantic and disparity. Moreover, since deep semantic information and disparity feature maps can learn from each other, we find it unnecessary with two independent encoding modules to separately extract semantic and disparity features. Therefore, we propose a unified multi-tasking architecture DSNet, for the simultaneous estimation of semantic and disparity information. In our model, semantic features, extracted by the encoding module ResNet from the left and right images, are used to obtain the deep disparity features via a novel matching module which performs pixel-to-pixel matching. In addition, we also use the disparity map to perform warp operation on deep features of the right image to deal with the problem of lacking of semantic labels. The effectiveness of our method is demonstrated by extensive experiments.
ER  - 

TY  - CONF
TI  - Spatial change detection using voxel classification by normal distributions transform
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2953
EP  - 2959
AU  - U. Katsura
AU  - K. Matsumoto
AU  - A. Kawamura
AU  - T. Ishigami
AU  - T. Okada
AU  - R. Kurazume
PY  - 2019
KW  - image classification
KW  - image colour analysis
KW  - image sensors
KW  - mobile robots
KW  - normal distribution
KW  - object detection
KW  - optical scanners
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - transforms
KW  - voxel classification
KW  - robotic applications
KW  - mobile robot
KW  - 3D laser scanner
KW  - grid data
KW  - ND voxels
KW  - normal distributions transform
KW  - spatial change detection
KW  - onboard RGB-D camera
KW  - stereo camera
KW  - real-time range sensors
KW  - real-time localization
KW  - Three-dimensional displays
KW  - Mobile robots
KW  - Cameras
KW  - Real-time systems
KW  - Measurement by laser beam
KW  - Sensors
DO  - 10.1109/ICRA.2019.8794173
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Detection of spatial change around a robot is indispensable in several robotic applications, such as search and rescue, security, and surveillance. The present paper proposes a fast spatial change detection technique for a mobile robot using an on-board RGB-D/stereo camera and a highly precise 3D map created by a 3D laser scanner. This technique first converts point clouds in a map and measured data to grid data (ND voxels) using normal distributions transform and classifies the ND voxels into three categories. The voxels in the map and the measured data are then compared according to the category and features of the ND voxels. Overlapping and voting techniques are also introduced in order to detect the spatial changes more robustly. We conducted experiments using a mobile robot equipped with real-time range sensors to confirm the performance of the proposed real-time localization and spatial change detection techniques in indoor and outdoor environments.
ER  - 

TY  - CONF
TI  - Set-based Inverse Kinematics Control of an Anthropomorphic Dual Arm Aerial Manipulator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2960
EP  - 2966
AU  - E. Cataldi
AU  - F. Real
AU  - A. Suarez
AU  - P. A. Di Lillo
AU  - F. Pierri
AU  - G. Antonelli
AU  - F. Caccavale
AU  - G. Heredia
AU  - A. Ollero
PY  - 2019
KW  - autonomous aerial vehicles
KW  - end effectors
KW  - helicopters
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - redundant manipulators
KW  - inverse kinematics control
KW  - anthropomorphic dual arm aerial manipulator
KW  - multiple task-priority inverse kinematics algorithm
KW  - dual-arm aerial manipulator
KW  - equality constraints
KW  - inequality constraints
KW  - singularity robust method
KW  - motion control
KW  - underactuated aerial hexarotor vehicle
KW  - manipulators
KW  - null-space based behavioral control
KW  - Task analysis
KW  - Kinematics
KW  - End effectors
KW  - Jacobian matrices
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8793470
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper presents a multiple task-priority inverse kinematics algorithm for a dual-arm aerial manipulator. Both tasks defined as equality constraints and inequality constraints are handled by means of a singularity robust method based on the Null-Space based Behavioral control. The proposed schema is constituted by the inverse kinematics control, that receives the desired behavior of the system and outputs the reference values for the motion variables, i.e. the UAV pose and the arm joints position, and a motion control, that computes the vehicle thrusts and the joint torques. The method has been experimentally validated on a system composed by an underactuated aerial hexarotor vehicle equipped with two lightweight 4-DOF manipulators, involved in operations requiring the coordination of the two arms and the vehicle.
ER  - 

TY  - CONF
TI  - Detection and Tracking of Small Objects in Sparse 3D Laser Range Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2967
EP  - 2973
AU  - J. Razlaw
AU  - J. Quenzel
AU  - S. Behnke
PY  - 2019
KW  - autonomous aerial vehicles
KW  - data structures
KW  - image segmentation
KW  - image sensors
KW  - laser ranging
KW  - median filters
KW  - mobile robots
KW  - object detection
KW  - object tracking
KW  - robot vision
KW  - solid modelling
KW  - autonomous behavior
KW  - microaerial vehicles
KW  - multiobject tracking
KW  - lightweight sensors
KW  - sparse point clouds
KW  - Velodyne VLP-16 sensor
KW  - MAV hardware
KW  - unlabeled data
KW  - sparse 3d laser range data
KW  - objects detection
KW  - median filters
KW  - data structure
KW  - Three-dimensional displays
KW  - Sensors
KW  - Target tracking
KW  - Object tracking
KW  - Real-time systems
KW  - Vehicle dynamics
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794204
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Detection and tracking of dynamic objects is a key feature for autonomous behavior in a continuously changing environment. With the increasing popularity and capability of micro aerial vehicles (MAVs) efficient algorithms have to be utilized to enable multi object tracking on limited hardware and data provided by lightweight sensors. We present a novel segmentation approach based on a combination of median filters and an efficient pipeline for detection and tracking of small objects within sparse point clouds generated by a Velodyne VLP-16 sensor. We achieve real-time performance on a single core of our MAV hardware by exploiting the inherent structure of the data. Our approach is evaluated on simulated and real scans of in- and outdoor environments, obtaining results comparable to the state of the art. Additionally, we provide an application for filtering the dynamic and mapping the static part of the data, generating further insights into the performance of the pipeline on unlabeled data.
ER  - 

TY  - CONF
TI  - GPS-Denied UAV Localization using Pre-existing Satellite Imagery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2974
EP  - 2980
AU  - H. Goforth
AU  - S. Lucey
PY  - 2019
KW  - artificial satellites
KW  - autonomous aerial vehicles
KW  - cameras
KW  - convolutional neural nets
KW  - distance measurement
KW  - Global Positioning System
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - flight location
KW  - UAV imagery
KW  - image capturing conditions
KW  - localization accuracy
KW  - adjacent UAV frames
KW  - satellite map
KW  - GPS-denied flight
KW  - average localization error
KW  - GPS-denied UAV localization
KW  - onboard GPS system
KW  - noisy GPS signal
KW  - unreliable GPS signal
KW  - monocular RGB camera
KW  - convolutional neural network representations
KW  - satellite data
KW  - satellite imagery
KW  - unmanned aerial vehicles
KW  - distance 0.85 km
KW  - distance 0.2 km
KW  - Satellites
KW  - Global Positioning System
KW  - Unmanned aerial vehicles
KW  - Training
KW  - Meters
KW  - Imaging
KW  - Buildings
DO  - 10.1109/ICRA.2019.8793558
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a method for localization of Unmanned Aerial Vehicles (UAVs) which is meant to replace an onboard GPS system in the event of a noisy or unreliable GPS signal. Our method requires only a downward-facing monocular RGB camera on the UAV, and pre-existing satellite imagery of the flight location to which the UAV imagery is compared and aligned. To overcome differences in the image capturing conditions between the satellite and UAV, such as seasonal and perspective changes, we propose the use of Convolutional Neural Network (CNN) representations trained on readily available satellite data. To increase localization accuracy, we also develop an optimization which jointly minimizes the error between adjacent UAV frames as well as the satellite map. We demonstrate how our method improves on recent systems from literature by achieving greater performance in flight environments with very few landmarks. For a GPS-denied flight at 0.2km altitude, over a flight distance of 0.85km, we achieve average localization error of less than 8 meters. We make our source code and datasets available to encourage further work on this emerging topic.
ER  - 

TY  - CONF
TI  - Adaptive View Planning for Aerial 3D Reconstruction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2981
EP  - 2987
AU  - C. Peng
AU  - V. Isler
PY  - 2019
KW  - autonomous aerial vehicles
KW  - image reconstruction
KW  - optimisation
KW  - trajectory control
KW  - aerial 3D reconstruction
KW  - aerial vehicles
KW  - high quality reconstruction
KW  - adaptive view planning method
KW  - coarse proxy
KW  - reconstruction error
KW  - 3D free space
KW  - Image reconstruction
KW  - Trajectory
KW  - Three-dimensional displays
KW  - Planning
KW  - Image resolution
KW  - Feature extraction
KW  - Drones
DO  - 10.1109/ICRA.2019.8793532
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - With the proliferation of small aerial vehicles, acquiring close up imagery for high quality reconstruction is gaining importance. We present an adaptive view planning method to collect such images in an automated fashion. We first start by sampling a small set of views to build a coarse proxy to the scene. We then present (i) a method that builds a set of adaptive viewing planes for efficient view selection and (ii) an algorithm to plan a trajectory that guarantees high reconstruction quality which does not deviate too much from the optimal one. The vehicle then follows the trajectory to cover the scene, and the procedure is repeated until reconstruction quality converges or a desired level of quality is achieved. The set of viewing planes provides an effective compromise between using the entire 3D free space and using a single view hemisphere to select the views. We compare our algorithm to existing methods in three challenging scenes. Our algorithm generates views which produce the least reconstruction error comparing to three different baseline approaches.
ER  - 

TY  - CONF
TI  - An Autonomous Loop-Closure Approach for Simultaneous Exploration and Coverage of Unknown Infrastructure Using MAVs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 2988
EP  - 2994
AU  - D. G. Vutetakis
AU  - J. Xiao
PY  - 2019
KW  - autonomous aerial vehicles
KW  - inspection
KW  - microrobots
KW  - mobile robots
KW  - spatial measurements
KW  - MAV motions
KW  - complete exploration
KW  - autonomous loop-closure approach
KW  - simultaneous exploration
KW  - unknown infrastructure
KW  - attractive means
KW  - critical infrastructure
KW  - autonomous tasks
KW  - precise spatial model
KW  - operational area
KW  - sensor measurements
KW  - autonomous inspection capabilities
KW  - autonomous MAV exploration
KW  - unknown structure
KW  - spatial information
KW  - high-fidelity 3D model
KW  - low-cost microaerial vehicles
KW  - Planning
KW  - Three-dimensional displays
KW  - Task analysis
KW  - Inspection
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2019.8794110
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The recent proliferation of low-cost Micro Aerial Vehicles (MAV) offers an attractive means for inspecting critical infrastructure autonomously. However, to enable such autonomous tasks requires a precise spatial model of the structure and operational area, typically constructed using sensor measurements obtained from the environment. To facilitate autonomous inspection capabilities, we address the problem of autonomous MAV exploration and coverage of an unknown structure to acquire the spatial information necessary for the development of a high-fidelity 3D model of the structure. Key to this problem is to not only cover the entire structure to acquire a complete set of spatial measurements, but also to minimize accumulative data errors during the exploration through direct planning of loop closures. We introduce a real-time waypoint planning approach to guide MAV motions to achieve complete exploration, coverage, and loop closure while respecting limited onboard resources.
ER  - 

TY  - CONF
TI  - Unsupervised Learning of Assistive Camera Views by an Aerial Co-robot in Augmented Reality Multitasking Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3003
EP  - 3009
AU  - W. Bentz
AU  - S. Dhanjal
AU  - D. Panagou
PY  - 2019
KW  - augmented reality
KW  - autonomous aerial vehicles
KW  - cameras
KW  - computer displays
KW  - mobile robots
KW  - unsupervised learning
KW  - unsupervised learning
KW  - assistive camera views
KW  - augmented reality multitasking environments
KW  - assistive aerial robot
KW  - task domain
KW  - head motion
KW  - anisotropic spherical sensor
KW  - expectation maximization solver
KW  - Gaussians
KW  - dynamic coverage control law
KW  - augmented reality display
KW  - human operator
KW  - assistive robot
KW  - reflex time
KW  - task completion time
KW  - aerial co-robot
KW  - Visualization
KW  - Task analysis
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793587
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel method by which an assistive aerial robot can learn the relevant camera views within a task domain through tracking the head motions of a human collaborator. The human's visual field is modeled as an anisotropic spherical sensor, which decays in acuity towards the periphery, and is integrated in time throughout the domain. This data is resampled and fed into an expectation maximization solver in order to estimate the environment's visual interest as a mixture of Gaussians. A dynamic coverage control law directs the robot to capture camera views of the peaks of these Gaussians which is broadcast to an augmented reality display worn by the human operator. An experimental study is presented that assesses the influence of the assistive robot on reflex time, head motion, and task completion time.
ER  - 

TY  - CONF
TI  - Visual Coverage Control for Teams of Quadcopters via Control Barrier Functions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3010
EP  - 3016
AU  - R. Funada
AU  - M. Santos
AU  - J. Yamauchi
AU  - T. Hatanaka
AU  - M. Fujita
AU  - M. Egerstedt
PY  - 2019
KW  - computational geometry
KW  - distributed control
KW  - gradient methods
KW  - mobile robots
KW  - multi-robot systems
KW  - position control
KW  - visual coverage control
KW  - quadcopters
KW  - control barrier functions
KW  - coverage control strategy
KW  - visual sensors
KW  - locational cost
KW  - cost function
KW  - distributed control law
KW  - gradient ascent control law
KW  - Space missions
KW  - Monitoring
KW  - Visualization
KW  - Robot sensing systems
KW  - Cameras
DO  - 10.1109/ICRA.2019.8793477
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a coverage control strategy for teams of quadcopters that ensures that no area is left unsurveyed in between the fields of view of the visual sensors mounted on the quadcopters. We present a locational cost that quantifies the team's coverage performance according to the sensors' performance function. Moreover, the cost function penalizes overlaps between the fields of view of the different sensors, with the objective of increasing the area covered by the team. A distributed control law is derived for the quadcopters so that they adjust their position and zoom according to the direction of ascent of the cost. Control barrier functions are implemented to ensure that, while executing the gradient ascent control law, no holes appear in between the fields of view of neighboring robots. The performance of the algorithm is evaluated in simulated experiments.
ER  - 

TY  - CONF
TI  - Robot Co-design: Beyond the Monotone Case
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3024
EP  - 3030
AU  - L. Carlone
AU  - C. Pinciroli
PY  - 2019
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - software aspects
KW  - robotic platform
KW  - robot design process
KW  - small-volumes low-cost applications
KW  - computational robot co-design problem
KW  - robotic modules
KW  - binary optimization formulation
KW  - co-design problems
KW  - autonomous drone racing platform
KW  - multirobot system
KW  - monotone case
KW  - miniaturized robotic hardware
KW  - inexpensive robots
KW  - disposable robots
KW  - scientific discovery
KW  - confined spaces
KW  - nanodrones
KW  - task-specific robots clashes
KW  - human experts
KW  - search-and-rescue
KW  - Robot sensing systems
KW  - Drones
KW  - Task analysis
KW  - Hardware
KW  - Legged locomotion
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793926
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent advances in 3D printing and manufacturing of miniaturized robotic hardware and computing are paving the way to build inexpensive and disposable robots. This will have a large impact on several applications including scientific discovery (e.g., hurricane monitoring), search-and-rescue (e.g., operation in confined spaces), and entertainment (e.g., nano drones). The need for inexpensive and task-specific robots clashes with the current practice, where human experts are in charge of designing hardware and software aspects of the robotic platform. This makes the robot design process expensive and time consuming, and ultimately unsuitable for small-volumes low-cost applications. This paper considers the computational robot co-design problem, which aims to create an automatic algorithm that selects the best robotic modules (sensing, actuation, computing) in order to maximize the performance on a task, while satisfying given specifications (e.g., maximum cost of the resulting design). We propose a binary optimization formulation of the co-design problem and show that such formulation generalizes previous work based on strong modeling assumptions. We show that the proposed formulation can solve relatively large co-design problems in seconds and with minimal human intervention. We demonstrate the proposed approach in two applications: the co-design of an autonomous drone racing platform and the co-design of a multi-robot system.
ER  - 

TY  - CONF
TI  - Multi-Vehicle Close Enough Orienteering Problem with Bézier Curves for Multi-Rotor Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3039
EP  - 3044
AU  - J. Faigl
AU  - P. Váňa
AU  - R. Pěnička
PY  - 2019
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - remotely operated vehicles
KW  - unsupervised learning
KW  - travel cost
KW  - travel budget
KW  - Bézier curves
KW  - multivehicle CEOP
KW  - multirotor aerial vehicles
KW  - maximal velocity
KW  - acceleration limits
KW  - rewarding target locations
KW  - multivehicle close enough orienteering problem
KW  - surveillance planning
KW  - unsupervised learning
KW  - Trajectory
KW  - Acceleration
KW  - Adaptive arrays
KW  - Planning
KW  - Unsupervised learning
KW  - Optimization
KW  - Surveillance
DO  - 10.1109/ICRA.2019.8794339
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces the Close Enough Orienteering Problem (CEOP) for planning missions with multi-rotor aerial vehicles considering their maximal velocity and acceleration limits. The addressed problem stands to select the most rewarding target locations and sequence to visit them in the given limited travel budget. The reward is collected within a non-zero range from a particular target location that allows saving the travel cost, and thus collect more rewards. Hence, we are searching for the fastest trajectories to collect the most valuable rewards such that the motion constraints are not violated, and the travel budget is satisfied. We leverage on existing trajectory parametrization based on Bézier curves recently deployed in surveillance planning using unsupervised learning, and we propose to employ the learning in a solution of the introduced multi-vehicle CEOP. Feasibility of the proposed approach is supported by empirical evaluation and experimental deployment using multi-rotor vehicles.
ER  - 

TY  - CONF
TI  - Critically fast pick-and-place with suction cups
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3045
EP  - 3051
AU  - H. Pham
AU  - Q. Pham
PY  - 2019
KW  - logistics
KW  - manipulator dynamics
KW  - manipulator kinematics
KW  - mechanical contact
KW  - path planning
KW  - stability
KW  - time optimal control
KW  - suction cup contacts
KW  - fast robotics pick-and-place
KW  - contact stability constraint
KW  - logistics
KW  - factory lines
KW  - object transport
KW  - object movement
KW  - contact handling
KW  - kinodynamic constraint
KW  - time-optimal parameterization
KW  - geometric paths
KW  - physical robot system
KW  - Stability analysis
KW  - Robots
KW  - Planning
KW  - Friction
KW  - Force
KW  - Computational modeling
KW  - Pipelines
DO  - 10.1109/ICRA.2019.8794081
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fast robotics pick-and-place with suction cups is a crucial component in the current development of automation in logistics (factory lines, e-commerce, etc.). By “critically fast” we mean the fastest possible movement for transporting an object such that it does not slip or fall from the suction cup. The main difficulties are: (i) handling the contact between the suction cup and the object, which fundamentally involves kinodynamic constraints; and (ii) doing so at a low computational cost, typically a few hundreds of milliseconds. To address these difficulties, we propose (a) a model for suction cup contacts, (b) a procedure to identify the contact stability constraint based on that model, and (c) a pipeline to parameterize, in a time-optimal manner, arbitrary geometric paths under the identified contact stability constraint. We experimentally validate the proposed pipeline on a physical robot system: the cycle time for a typical pick-and-place task was less than 5 seconds, planning and execution times included. The full pipeline is released as opensource for the robotics community.
ER  - 

TY  - CONF
TI  - Robust Link Position Tracking Control for Robot Manipulators with Series Elastic Actuators Using Time-delay Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3052
EP  - 3058
AU  - S. H. Park
AU  - J. Lee
AU  - K. Seo
AU  - M. Jin
PY  - 2019
KW  - closed loop systems
KW  - delay estimation
KW  - delays
KW  - manipulators
KW  - nonlinear dynamical systems
KW  - position control
KW  - robust control
KW  - variable structure systems
KW  - closed-loop stability
KW  - link inertia information
KW  - dynamic coupling terms
KW  - terminal sliding mode control
KW  - modified TDE
KW  - complicated nonlinear dynamics terms
KW  - SEA dynamics
KW  - SEA-driven manipulator
KW  - robust link position tracking control
KW  - robot manipulator
KW  - series elastic actuators
KW  - time-delay estimation technique
KW  - constant gain matrix
KW  - TDE framework
KW  - Robot sensing systems
KW  - Manipulator dynamics
KW  - Estimation
KW  - Service robots
KW  - Torque
DO  - 10.1109/ICRA.2019.8794083
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper aims to develop a controller for a robot manipulator equipped with series elastic actuators (SEAs) to precisely track the desired link position coping with deflections from the intrinsic compliance. The well-known time-delay estimation (TDE) technique is modified for devising the new controller. In this paper, we first report that the conventional use of a constant gain matrix for the TDE framework is insufficient for high accuracy tracking because the tracking accuracy is significantly deteriorated and the closed-loop stability may be threatened. Accordingly, the new controller employs link inertia information with dynamic coupling terms to define the gain for TDE and then employs terminal sliding mode (TSM) control to enhance robustness and convergence speed. Particularly, the modified TDE is applied in the two-staged manner which enables to compensate the complicated nonlinear dynamics terms in SEA dynamics. The TSM synergistically amalgamates the accuracy, robustness, and convergence in tracking. The proposed controller is numerically validated by comparative experiments with a SEA-driven manipulator.
ER  - 

TY  - CONF
TI  - A Simple but Robust Impedance Controller for Series Elastic Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3059
EP  - 3065
AU  - D. Kim
AU  - K. Koh
AU  - G. Cho
AU  - L. Zhang
PY  - 2019
KW  - actuators
KW  - control system synthesis
KW  - delay estimation
KW  - elasticity
KW  - force control
KW  - perturbation theory
KW  - robust control
KW  - robust impedance controller
KW  - series elastic actuators
KW  - singular perturbation theory
KW  - SP theory
KW  - TDE technique
KW  - time-delay estimation technique
KW  - numerical analysis
KW  - Impedance
KW  - Bandwidth
KW  - End effectors
KW  - Position control
KW  - Actuators
DO  - 10.1109/ICRA.2019.8793809
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study presents an impedance controller for series elastic actuators (SEAs), using the singular perturbation (SP) theory and time-delay estimation (TDE) technique. While the SP theory attenuates the requirement for states to be measured, the TDE technique eliminates the requirement for identifying system parameters. Through a numerical analysis and experimental validation, we demonstrate that the proposed controller produces satisfactory tracking performance while-at the same time-pursues wider operational bandwidth and lower driving-point impedance.
ER  - 

TY  - CONF
TI  - Robotic Cutting: Mechanics and Control of Knife Motion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3066
EP  - 3072
AU  - X. Mu
AU  - Y. Xue
AU  - Y. Jia
PY  - 2019
KW  - blades
KW  - dexterous manipulators
KW  - force sensors
KW  - mobile robots
KW  - motion control
KW  - position control
KW  - material toughness
KW  - blade-material friction
KW  - shape deformation
KW  - robotic arm
KW  - separate control strategy
KW  - Cartesian space
KW  - force constraints
KW  - smooth motions
KW  - robotic cutting
KW  - knife motion
KW  - material fracture
KW  - smooth knife movements
KW  - Force
KW  - Friction
KW  - Strain
KW  - Torque
KW  - Robot sensing systems
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8793880
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Effectiveness of cutting is measured by the ability to achieve material fracture with smooth knife movements. The work performed by a knife overcomes the material toughness, acts against the blade-material friction, and generates shape deformation. This paper studies how to control a 2-DOF robotic arm equipped with a force/torque sensor to cut through an object in a sequence of three moves: press, push, and slice. For each move, a separate control strategy in the Cartesian space is designed to incorporate contact and/or force constraints while following some prescribed trajectory. Experiments conducted over several types of natural foods have demonstrated smooth motions like would be commanded by a human hand.
ER  - 

TY  - CONF
TI  - A constrained control-planning strategy for redundant manipulators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3073
EP  - 3079
AU  - C. Barbalata
AU  - R. Vasudevan
AU  - M. Johnson-Roberson
PY  - 2019
KW  - adaptive control
KW  - control system synthesis
KW  - fuzzy control
KW  - path planning
KW  - redundant manipulators
KW  - constrained control-planning strategy
KW  - redundant manipulators
KW  - interconnected control-planning strategy
KW  - high-level planning components
KW  - adaptive control rule
KW  - multibody robotic system
KW  - Task analysis
KW  - Manipulators
KW  - Mathematical model
KW  - Optimal control
KW  - Planning
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793843
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents an interconnected control-planning strategy for redundant manipulators, subject to system and environmental constraints. The method incorporates low-level control characteristics and high-level planning components into a robust strategy for manipulators acting in complex environments, subject to joint limits. This strategy is formulated using an adaptive control rule, a computational efficient estimation of the robot's mathematical model and the nullspace of the constraints. A path is generated that takes into account the capabilities of the platform. The proposed method is computationally efficient, enabling its implementation on a real multi-body robotic system. Through experimental results with a 7 degree-of-freedom (DOF) manipulator, we demonstrate the performance of the method in real-world scenarios.
ER  - 

TY  - CONF
TI  - Reinforcement Learning on Variable Impedance Controller for High-Precision Robotic Assembly
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3080
EP  - 3087
AU  - J. Luo
AU  - E. Solowjow
AU  - C. Wen
AU  - J. A. Ojea
AU  - A. M. Agogino
AU  - A. Tamar
AU  - P. Abbeel
PY  - 2019
KW  - assembling
KW  - control engineering computing
KW  - force control
KW  - industrial robots
KW  - learning (artificial intelligence)
KW  - neural net architecture
KW  - position control
KW  - robotic assembly
KW  - wheels
KW  - high-precision robotic assembly
KW  - precise robotic manipulation skills
KW  - industrial settings
KW  - reinforcement learning methods
KW  - RL
KW  - perceived forces
KW  - high-precision tasks
KW  - proper operational space force controller
KW  - open-source Siemens Robot Learning Challenge
KW  - precise force-controlled behavior
KW  - delicate force-controlled behavior
KW  - variable impedance controller
KW  - Task analysis
KW  - Gears
KW  - Aerospace electronics
KW  - Robots
KW  - Reinforcement learning
KW  - Trajectory
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793506
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Precise robotic manipulation skills are desirable in many industrial settings, reinforcement learning (RL) methods hold the promise of acquiring these skills autonomously. In this paper, we explicitly consider incorporating operational space force/torque information into reinforcement learning; this is motivated by humans heuristically mapping perceived forces to control actions, which results in completing high-precision tasks in a fairly easy manner. Our approach combines RL with force/torque information by incorporating a proper operational space force controller; where we also exploit different ablations on processing this information. Moreover, we propose a neural network architecture that generalizes to reasonable variations of the environment. We evaluate our method on the open-source Siemens Robot Learning Challenge, which requires precise and delicate force-controlled behavior to assemble a tight-fit gear wheel set.
ER  - 

TY  - CONF
TI  - A Compliant and Precise Pneumatic Rotary Drive Using Pneumatic Artificial Muscles in a Swash Plate Design
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3088
EP  - 3094
AU  - J. T. Stoll
AU  - K. Schanz
AU  - A. Pott
PY  - 2019
KW  - design engineering
KW  - human-robot interaction
KW  - muscle
KW  - pneumatic actuators
KW  - position control
KW  - torque
KW  - mechanic design
KW  - pneumatic control system
KW  - electric control system
KW  - drive unit
KW  - adjustable stiffness
KW  - stick-slip phenomenon
KW  - high precision positioning
KW  - pneumatic systems
KW  - pneumatic rotary drive unit
KW  - human-robot collaboration
KW  - articulated robots
KW  - precise rotary drive units
KW  - compliant drive units
KW  - swash plate design
KW  - pneumatic artificial muscles
KW  - Shafts
KW  - Force
KW  - Muscles
KW  - Torque
KW  - Pneumatic systems
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794185
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Compliant and precise rotary drive units are essential for the design of articulated robots that are capable of safe human-robot collaboration. In this paper, we present a new pneumatic rotary drive unit that combines the compliance of pneumatic systems with the ability to perform high precision positioning. We use pneumatic artificial muscles (PAMs) pulling on a swash plate to avoid the stick-slip phenomenon and to realize adjustable stiffness. Furthermore, the presented drive unit can operate in 360° continuous rotation. These properties make the drive particularly suitable for the later use in human-robot collaboration. We explain the mechanic design as well as the pneumatic and electric control system that we use to operate the drive unit. We derive the equations to calculate the static torque distribution and compare the theoretical results to the data measured on the realized laboratory test stand, depicted in figure 1. The accuracy of the used 16-bit encoder is achieved and adjustable stiffness is realized and measured on the laboratory test stand. The measurements of the reaction to a step response are discussed based on a first and basic control strategy.
ER  - 

TY  - CONF
TI  - Passivity based Control of Antagonistic Tendon-Driven Mechanism
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3095
EP  - 3100
AU  - J. Park
AU  - G. Y. Hong
AU  - Y. Choi
AU  - D. Peng
AU  - Q. Lu
PY  - 2019
KW  - asymptotic stability
KW  - control system synthesis
KW  - end effectors
KW  - force control
KW  - manipulator dynamics
KW  - nonlinear control systems
KW  - torque control
KW  - antagonistic tendon-driven mechanism
KW  - passivity-based control law
KW  - passivity theorem
KW  - complex tendon-driven mechanism
KW  - control strategy
KW  - impedance control schemes
KW  - gravity compensation
KW  - interconnected subsystems
KW  - Tendons
KW  - Gravity
KW  - Torque
KW  - Asymptotic stability
KW  - Robots
KW  - Control systems
DO  - 10.1109/ICRA.2019.8794151
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The paper presents a passivity-based control law for an antagonistic tendon-driven mechanism. It is proven, by using the passivity theorem, that the proposed control law is able to achieve two properties such as the passivity of interconnected subsystems when the external torque is applied and the global asymptotic stability during free motion when the external force is absent. The proposed controller is simple to be implemented for a complex tendon-driven mechanism because it requires only gravity compensation. In addition, it brings a robustness to the entire control system. And finally, the control strategy can be treated as one of the impedance control schemes so as to achieve the desired performance efficiently.
ER  - 

TY  - CONF
TI  - Exact Modal Characterization of the Non Conservative Non Linear Radial Mass Spring System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3101
EP  - 3107
AU  - C. D. Santina
AU  - D. Lakatos
AU  - A. Bicchi
AU  - A. Albu-Schaeffer
PY  - 2019
KW  - damping
KW  - elasticity
KW  - linear systems
KW  - modal analysis
KW  - nonlinear dynamical systems
KW  - robot dynamics
KW  - shock absorbers
KW  - springs (mechanical)
KW  - vibration control
KW  - exact modal characterization
KW  - modal analysis
KW  - linear mechanical systems
KW  - nonlinear elastic robot
KW  - nonlinear normal modes
KW  - nonlinear oscillatory behaviors
KW  - dissipative effects
KW  - damping
KW  - nonconservative nonlinear radial mass spring damper system
KW  - Manifolds
KW  - Springs
KW  - Force
KW  - Damping
KW  - Soft robotics
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8793732
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Since the spread of robotic systems embedding in their mechanics purposefully designed elastic elements, the interest in characterizing and exploiting non-linear oscillatory behaviors has progressively grown. However, few works so far looked at the problem from the point of view of modal analysis. This is particularly surprising if considered the central role that modal theory had in the development of classic results in analysis and control of linear mechanical systems. With the aim of making a step toward translating and extending this powerful tool to the robotic field, we present the complete modal characterization of a simple yet representative non-linear elastic robot: the 2D planar mass-spring-damper system. Generic non-linear elastic forces and dissipative effects are considered. We provide here exact descriptions of the two non-linear normal modes of the system. We then extend the analysis to generic combinations of the modes in conservative case and for small damping. Simulations are provided to illustrate the theoretical results. This is one of the very firsts applications of normal mode theory to dynamically coupled non-linear systems, and the first exact result in the field.
ER  - 

TY  - CONF
TI  - Body Lift and Drag for a Legged Millirobot in Compliant Beam Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3108
EP  - 3114
AU  - C. Koc
AU  - C. Koc
AU  - B. Su
AU  - C. S. Casarez
AU  - R. S. Fearing
PY  - 2019
KW  - beams (structures)
KW  - drag
KW  - force sensors
KW  - legged locomotion
KW  - microrobots
KW  - shells (structures)
KW  - legged millirobots
KW  - body lift
KW  - robot locomotion
KW  - body-beam forces
KW  - body motion
KW  - light-weight legged robots
KW  - dense terrains
KW  - drag energy
KW  - drag forces increase
KW  - negative lift forces
KW  - VelociRoACH robotic platform
KW  - densely cluttered environment
KW  - compliant beams
KW  - hexapedal millirobot
KW  - interaction forces
KW  - body contact forces
KW  - terrain
KW  - granular media
KW  - foot traction forces
KW  - legged locomotion
KW  - compliant beam environment
KW  - Robot sensing systems
KW  - Legged locomotion
KW  - Drag
KW  - Shape
KW  - Force measurement
DO  - 10.1109/ICRA.2019.8793597
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Much current study of legged locomotion has rightly focused on foot traction forces, including on granular media. Future legged millirobots will need to go through terrain, such as brush or other vegetation, where the body contact forces significantly affect locomotion. In this work, a (previously developed) low-cost 6-axis force/torque sensing shell is used to measure the interaction forces between a hexapedal millirobot and a set of compliant beams, which act as a surrogate for a densely cluttered environment. Experiments with a VelociRoACH robotic platform are used to measure lift and drag forces on the tactile shell, where negative lift forces can increase traction, even while drag forces increase. The drag energy and specific resistance required to pass through dense terrains can be measured. Furthermore, some contact between the robot and the compliant beams can lower specific resistance of locomotion. For small, light-weight legged robots in the beam environment, the body motion depends on both legground and body-beam forces. A shell-shape which reduces drag but increases negative lift, such as the half-ellipsoid used, is suggested to be advantageous for robot locomotion in this type of environment.
ER  - 

TY  - CONF
TI  - Tightly Coupled 3D Lidar Inertial Odometry and Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3144
EP  - 3150
AU  - H. Ye
AU  - Y. Chen
AU  - M. Liu
PY  - 2019
KW  - distance measurement
KW  - image fusion
KW  - mobile robots
KW  - motion estimation
KW  - optical radar
KW  - pose estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - fast motion conditions
KW  - ego-motion estimation
KW  - mobile robotic applications
KW  - sensor fusion
KW  - stand-alone sensors
KW  - tightly coupled lidar-IMU fusion method
KW  - IMU measurements
KW  - lidarIMU odometry
KW  - lidar measurement
KW  - rotation-constrained refinement algorithm
KW  - LIO-mapping
KW  - sensor pair
KW  - IMU update rate
KW  - lidar pose estimation
KW  - Laser radar
KW  - Three-dimensional displays
KW  - Estimation
KW  - Robot sensing systems
KW  - Feature extraction
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793511
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Ego-motion estimation is a fundamental requirement for most mobile robotic applications. By sensor fusion, we can compensate the deficiencies of stand-alone sensors and provide more reliable estimations. We introduce a tightly coupled lidar-IMU fusion method in this paper. By jointly minimizing the cost derived from lidar and IMU measurements, the lidarIMU odometry (LIO) can perform well with considerable drifts after long-term experiment, even in challenging cases where the lidar measurement can be degraded. Besides, to obtain more reliable estimations of the lidar poses, a rotation-constrained refinement algorithm (LIO-mapping) is proposed to further align the lidar poses with the global map. The experiment results demonstrate that the proposed method can estimate the poses of the sensor pair at the IMU update rate with high precision, even under fast motion conditions or with insufficient features.
ER  - 

TY  - CONF
TI  - Expectation-Maximization for Adaptive Mixture Models in Graph Optimization
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3151
EP  - 3157
AU  - T. Pfeifer
AU  - P. Protzel
PY  - 2019
KW  - expectation-maximisation algorithm
KW  - Gaussian processes
KW  - optimisation
KW  - probability
KW  - sensor fusion
KW  - error distribution
KW  - multimodal Gaussian mixture model
KW  - sensor fusion problem
KW  - expectation-maximization
KW  - adaptive mixture algorithm
KW  - static parametrization
KW  - graph optimization
KW  - NonGaussian
KW  - multimodal distributions
KW  - robust cost functions
KW  - convergence properties
KW  - robust sensor fusion algorithms
KW  - Optimization
KW  - Estimation
KW  - Convergence
KW  - Global navigation satellite system
KW  - Adaptation models
KW  - Sensor fusion
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793601
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Non-Gaussian and multimodal distributions are an important part of many recent robust sensor fusion algorithms. In difference to robust cost functions, they are probabilistically founded and have good convergence properties. Since their robustness depends on a close approximation of the real error distribution, their parametrization is crucial. We propose a novel approach that allows to adapt a multi-modal Gaussian mixture model to the error distribution of a sensor fusion problem. By combining expectation-maximization and non-linear least squares optimization, we are able to provide a computationally efficient solution with well-behaved convergence properties. We demonstrate the performance of these algorithms on several real-world GNSS and indoor localization datasets. The proposed adaptive mixture algorithm outperforms state-of-the-art approaches with static parametrization. Source code and datasets are available under https://mytuc.org/libRSF.
ER  - 

TY  - CONF
TI  - Multi-Camera Visual-Inertial Navigation with Online Intrinsic and Extrinsic Calibration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3158
EP  - 3164
AU  - K. Eckenhoff
AU  - P. Geneva
AU  - J. Bloecker
AU  - G. Huang
PY  - 2019
KW  - calibration
KW  - cameras
KW  - image sensors
KW  - inertial navigation
KW  - interpolation
KW  - Kalman filters
KW  - extrinsic calibration
KW  - asynchronous cameras
KW  - standard multistate constraint Kalman Filter framework
KW  - IMU poses
KW  - single base camera
KW  - state vector
KW  - camera images
KW  - inertial measurements
KW  - tightly-coupled state estimation
KW  - online sensor calibration
KW  - mc-VINS algorithm
KW  - high-precision localization
KW  - multicamera visual-inertial navigation
KW  - online intrinsic calibration
KW  - pose interpolation
KW  - high-fidelity localization
KW  - sensor configurations
KW  - Cameras
KW  - Calibration
KW  - Navigation
KW  - Cloning
KW  - Interpolation
KW  - Estimation
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793886
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a general multi-camera visual-inertial navigation system (mc-VINS) with online instrinsic and extrinsic calibration, which is able to utilize all the information from an arbitrary number of asynchronous cameras. In particular, within the standard multi-state constraint Kalman Filter (MSCKF) framework, we only clone the IMU poses related to a single “base camera” (rather than all cameras) in the state vector, while the IMU poses corresponding to all other camera images are represented via an interpolation of the poses bounding the measuring time. By doing so, we can fuse all observations from all cameras with inertial measurements while allowing for efficient, tightly-coupled state estimation through parallelization and asynchrony. Moreover, we perform online sensor calibration of each camera's intrinsics as well as the spatial (transformation) and temporal (time offset) extrinsic parameters between all involved sensors (cameras and IMU), thus enabling high-fidelity localization. We validate the proposed mc-VINS algorithm in various real-world experiments with different sensor configurations, showing the ability to offer real-time high-precision localization and calibration results.
ER  - 

TY  - CONF
TI  - Joint Inference of Kinematic and Force Trajectories with Visuo-Tactile Sensing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3165
EP  - 3171
AU  - A. S. Lambert
AU  - M. Mukadam
AU  - B. Sundaralingam
AU  - N. Ratliff
AU  - B. Boots
AU  - D. Fox
PY  - 2019
KW  - biomimetics
KW  - force control
KW  - force sensors
KW  - graph theory
KW  - inference mechanisms
KW  - manipulator kinematics
KW  - optimisation
KW  - probability
KW  - robot vision
KW  - sensor fusion
KW  - state estimation
KW  - tactile sensors
KW  - trajectory control
KW  - biomimetic tactile sensor
KW  - force-torque sensor
KW  - probabilistic inference
KW  - vision sensors
KW  - multimodal sensor data
KW  - visuo-tactile sensing
KW  - robust state estimation
KW  - vision-based articulated model tracker
KW  - force trajectories
KW  - kinematic trajectories
KW  - robots
KW  - factor graphs
KW  - optimization
KW  - manipulation platforms
KW  - Force
KW  - Trajectory
KW  - Tactile sensors
KW  - Noise measurement
KW  - Estimation
DO  - 10.1109/ICRA.2019.8794048
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To perform complex tasks, robots must be able to interact with and manipulate their surroundings. One of the key challenges in accomplishing this is robust state estimation during physical interactions, where the state involves not only the robot and the object being manipulated, but also the state of the contact itself. In this work, within the context of planar pushing, we extend previous inference-based approaches to state estimation in several ways. We estimate the robot, object, and the contact state on multiple manipulation platforms configured with a vision-based articulated model tracker, and either a biomimetic tactile sensor or a force-torque sensor. We show how to fuse raw measurements from the tracker and tactile sensors to jointly estimate the trajectory of the kinematic states and the forces in the system via probabilistic inference on factor graphs, in both batch and incremental settings. We perform several benchmarks with our framework and show how performance is affected by incorporating various geometric and physics based constraints, occluding vision sensors, or injecting noise in tactile sensors. We also compare with prior work on multiple datasets and demonstrate that our approach can effectively optimize over multi-modal sensor data and reduce uncertainty to find better state estimates.
ER  - 

TY  - CONF
TI  - Every Hop is an Opportunity: Quickly Classifying and Adapting to Terrain During Targeted Hopping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3188
EP  - 3194
AU  - A. H. Chang
AU  - C. Hubicki
AU  - A. Ames
AU  - P. A. Vela
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mobile robots
KW  - pattern classification
KW  - robot programming
KW  - terrain properties
KW  - terrain-informed learning
KW  - low shot learning
KW  - targeted hopping
KW  - task-relevant objectives
KW  - hopping robot
KW  - control strategies
KW  - jumping task
KW  - closed-loop jumping
KW  - real-world jumping data
KW  - terrain classification
KW  - online learning experiments
KW  - Task analysis
KW  - Optimal control
KW  - Solids
KW  - Force
KW  - Robot sensing systems
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8793757
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Practical use of robots in diverse domains requires programming for, or adapting to, each domain and its unique characteristics. Failure to do so compromises the ability of the robot to achieve task-relevant objectives. Here we describe how the learned terrain reaction force profiles of a hopping robot serve the additional objectives of classifying terrain and quickly learning control strategies to accomplish a jumping task on novel terrain. We show that the reaction forces experienced during closed-loop jumping are sufficient to discriminate between three different terrain types (granular, trampoline, and rigid) when using the learned models as discriminators. Building on this, we show that applying the classification to unknown terrain types leads to faster task completion, where the task objective is to meet a specific jump height. The classification experiments, utilizing real-world jumping data, achieve 95% prediction accuracy. The online learning experiments leverage simulation as there is more control over the terrain properties. Terrain-informed learning achieves the target hop heights more than 2x faster than without terrain knowledge when the prediction is correct, and 1.5x faster when the prediction is incorrect. Thus, applying the closest approximately known terrain knowledge facilitates low shot learning when hopping on unknown terrain.
ER  - 

TY  - CONF
TI  - Semiparametrical Gaussian Processes Learning of Forward Dynamical Models for Navigating in a Circular Maze
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3195
EP  - 3202
AU  - D. Romeres
AU  - D. K. Jha
AU  - A. DallaLibera
AU  - B. Yerazunis
AU  - D. Nikovski
PY  - 2019
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - optimisation
KW  - regression analysis
KW  - robot dynamics
KW  - trajectory control
KW  - Gaussian process regression
KW  - semiparametrical Gaussian processes learning
KW  - robot learning
KW  - ball trajectories
KW  - physics first principles
KW  - motion dynamics
KW  - dry friction
KW  - nonlinear effects
KW  - degrees of freedom
KW  - circular maze environment
KW  - forward dynamical models
KW  - Computational modeling
KW  - Heuristic algorithms
KW  - Servomotors
KW  - Navigation
KW  - Cameras
KW  - Gaussian processes
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8794229
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a problem of model learning for the purpose of learning how to navigate a ball to a goal state in a circular maze environment with two degrees of freedom. The motion of the ball in the maze environment is influenced by several non-linear effects such as dry friction and contacts, which are difficult to model physically. We propose a semiparametric model to estimate the motion dynamics of the ball based on Gaussian Process Regression equipped with basis functions obtained from physics first principles. The accuracy of this semiparametric model is shown not only in estimation but also in prediction at n-steps ahead and its compared with standard algorithms for model learning. The learned model is then used in a trajectory optimization algorithm to compute ball trajectories. We propose the system presented in the paper as a benchmark problem for reinforcement and robot learning, for its interesting and challenging dynamics and its relative ease of reproducibility.
ER  - 

TY  - CONF
TI  - Semantic Predictive Control for Explainable and Efficient Policy Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3203
EP  - 3209
AU  - X. Pan
AU  - X. Chen
AU  - Q. Cai
AU  - J. Canny
AU  - F. Yu
PY  - 2019
KW  - image motion analysis
KW  - image representation
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - predictive control
KW  - visual explanation
KW  - policy decisions
KW  - SPC
KW  - future semantic segmentation
KW  - multiscale feature maps
KW  - guidance model
KW  - multiple simulation environments
KW  - model-based reinforcement
KW  - data efficiency
KW  - short time horizons
KW  - human-level performance
KW  - complex environments
KW  - driving policy learning framework
KW  - feature representations
KW  - sampling-based optimization
KW  - semantic predictive control framework
KW  - Semantics
KW  - Predictive models
KW  - Feature extraction
KW  - Visualization
KW  - Task analysis
KW  - Predictive control
KW  - Optimization
DO  - 10.1109/ICRA.2019.8794437
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual anticipation of ego and object motion over a short time horizons is a key feature of human-level performance in complex environments. We propose a driving policy learning framework that predicts feature representations of future visual inputs; our predictive model infers not only future events but also semantics, which provide a visual explanation of policy decisions. Our Semantic Predictive Control (SPC) framework predicts future semantic segmentation and events by aggregating multi-scale feature maps. A guidance model assists action selection and enables efficient sampling-based optimization. Experiments on multiple simulation environments show that networks which implement SPC can outperform existing model-based reinforcement learning algorithms in terms of data efficiency and total rewards while providing clear explanations for the policy's behavior.
ER  - 

TY  - CONF
TI  - Adaptive Variance for Changing Sparse-Reward Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3210
EP  - 3216
AU  - X. Lin
AU  - P. Guo
AU  - C. Florensa
AU  - D. Held
PY  - 2019
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - optimisation
KW  - robot programming
KW  - adaptive variance
KW  - sparse-reward environments
KW  - optimal exploration
KW  - Gaussian-parameterized policy
KW  - robots
KW  - Robots
KW  - Task analysis
KW  - Reinforcement learning
KW  - Training
KW  - Adaptation models
KW  - Friction
KW  - Navigation
DO  - 10.1109/ICRA.2019.8793650
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robots that are trained to perform a task in a fixed environment often fail when facing unexpected changes to the environment due to a lack of exploration. We propose a principled way to adapt the policy for better exploration in changing sparse-reward environments. Unlike previous works which explicitly model environmental changes, we analyze the relationship between the value function and the optimal exploration for a Gaussian-parameterized policy and show that our theory leads to an effective strategy for adjusting the variance of the policy, enabling fast adapt to changes in a variety of sparse-reward environments.
ER  - 

TY  - CONF
TI  - Combining Physical Simulators and Object-Based Networks for Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3217
EP  - 3223
AU  - A. Ajay
AU  - M. Bauza
AU  - J. Wu
AU  - N. Fazeli
AU  - J. B. Tenenbaum
AU  - A. Rodriguez
AU  - L. P. Kaelbling
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - object-based neural network
KW  - interacting objects
KW  - complex control tasks
KW  - object shapes
KW  - physical simulators
KW  - physics engine
KW  - robot planning
KW  - real-world control problems
KW  - complex contact dynamics
KW  - hybrid dynamics model
KW  - simulator-augmented interaction networks
KW  - Physics
KW  - Engines
KW  - Analytical models
KW  - Task analysis
KW  - Robots
KW  - Predictive models
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8794358
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Physics engines play an important role in robot planning and control; however, many real-world control problems involve complex contact dynamics that cannot be characterized analytically. Most physics engines therefore employ approximations that lead to a loss in precision. In this paper, we propose a hybrid dynamics model, simulator-augmented interaction networks (SAIN), combining a physics engine with an object-based neural network for dynamics modeling. Compared with existing models that are purely analytical or purely data-driven, our hybrid model captures the dynamics of interacting objects in a more accurate and data-efficient manner. Experiments both in simulation and on a real robot suggest that it also leads to better performance when used in complex control tasks. Finally, we show that our model generalizes to novel environments with varying object shapes and materials.
ER  - 

TY  - CONF
TI  - Using Data-Driven Domain Randomization to Transfer Robust Control Policies to Mobile Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3224
EP  - 3230
AU  - M. Sheckells
AU  - G. Garimella
AU  - S. Mishra
AU  - M. Kobilarov
PY  - 2019
KW  - automobiles
KW  - collision avoidance
KW  - mobile robots
KW  - motion control
KW  - probability
KW  - robust control
KW  - stochastic processes
KW  - trajectory control
KW  - deep stochastic dynamics model
KW  - collision avoidance
KW  - 1/5 scale agile ground vehicle
KW  - robust control policies
KW  - vehicle data
KW  - collision probability
KW  - trajectory tracking accuracy
KW  - stochasticity
KW  - simple analytic car model
KW  - high quality stochastic dynamics model
KW  - robot motion trajectories
KW  - mobile robots
KW  - data-driven domain randomization
KW  - Stochastic processes
KW  - Data models
KW  - Vehicle dynamics
KW  - Optimization
KW  - Robots
KW  - Uncertainty
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794343
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work develops a technique for using robot motion trajectories to create a high quality stochastic dynamics model that is then leveraged in simulation to train control policies with associated performance guarantees. We demonstrate the idea by collecting dynamics data from a 1/5 scale agile ground vehicle, fitting a stochastic dynamics model, and training a policy in simulation to drive around an oval track at up to 6.5 m/s while avoiding obstacles. We show that the control policy can be transferred back to the real vehicle with little loss in predicted performance. We compare this to an approach that uses a simple analytic car model to train a policy in simulation and show that using a model with stochasticity learned from data leads to higher performance in terms of trajectory tracking accuracy and collision probability. Furthermore, we show empirically that simulation-derived performance guarantees transfer to the actual vehicle when executing a policy optimized using a deep stochastic dynamics model fit to vehicle data.
ER  - 

TY  - CONF
TI  - Coordinating multi-robot systems through environment partitioning for adaptive informative sampling
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3231
EP  - 3237
AU  - N. Fung
AU  - J. Rogers
AU  - C. Nieto
AU  - H. I. Christensen
AU  - S. Kemna
AU  - G. Sukhatme
PY  - 2019
KW  - image segmentation
KW  - mobile robots
KW  - multi-robot systems
KW  - robot vision
KW  - sampling methods
KW  - coordinating multirobot systems
KW  - environment partitioning
KW  - adaptive informative sampling
KW  - robotic platforms
KW  - time sensitive applications
KW  - sensor measurements
KW  - highest expected information
KW  - multiple robots
KW  - system partitions
KW  - information rate adaptive sampling approach
KW  - simulation environment
KW  - region segmentation approach
KW  - adaptive information gain rate tasking
KW  - naïve closest point approach
KW  - region segmentation technique
KW  - real world robots
KW  - Robot kinematics
KW  - Robot sensing systems
KW  - Adaptation models
KW  - Entropy
KW  - Task analysis
KW  - Data models
DO  - 10.1109/ICRA.2019.8794103
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - As robotic platforms have become more capable and autonomous, they have increasingly been utilized in time sensitive applications such as search and rescue. To that end, we have developed a system for teams of robots to efficiently explore an environment while taking sensor measurements. The system utilizes an information seeking algorithm that generates high priority points of interest based on the highest expected information gained per distance travelled. In order to coordinate multiple robots, the system partitions the area into different regions according to the effort needed to explore each region. Robots are assigned different regions to measure in order to minimize repetition of work and reduce interference between each robot.We present an information rate adaptive sampling approach for tasking robots within an environment to gather sensor measurements. We evaluated our approach within a simulation environment with one to four robots. Multiple robots are coordinated through our region segmentation approach. The data shows efficiency gains through the use of adaptive information gain rate tasking above a naïve closest point approach. We also see positive results from using the region segmentation technique. We further the experimentation by testing the algorithm on real world robots and verify the results in real world experimentation.
ER  - 

TY  - CONF
TI  - A Fleet of Miniature Cars for Experiments in Cooperative Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3238
EP  - 3244
AU  - N. Hyldmar
AU  - Y. He
AU  - A. Prorok
PY  - 2019
KW  - automobiles
KW  - human factors
KW  - mobile robots
KW  - motion control
KW  - steering systems
KW  - trajectory control
KW  - vehicle dynamics
KW  - unique experimental testbed
KW  - trajectory planning
KW  - miniature robotic car
KW  - Cambridge Minicar
KW  - autonomous control strategies
KW  - physical multilane setup
KW  - miniature highway
KW  - large-fleet experimental research
KW  - driver models
KW  - multilane road topographies
KW  - miniature Ackermann-steering vehicles
KW  - Automobiles
KW  - Trajectory
KW  - Traffic control
KW  - DC motors
KW  - Servomotors
KW  - Robot kinematics
DO  - 10.1109/ICRA.2019.8794445
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We introduce a unique experimental testbed that consists of a fleet of 16 miniature Ackermann-steering vehicles. We are motivated by a lack of available low-cost platforms to support research and education in multi-car navigation and trajectory planning. This article elaborates the design of our miniature robotic car, the Cambridge Minicar, as well as the fleet's control architecture. Our experimental testbed allows us to implement state-of-the-art driver models as well as autonomous control strategies, and test their validity in a real, physical multi-lane setup. Through experiments on our miniature highway, we are able to tangibly demonstrate the benefits of cooperative driving on multi-lane road topographies. Our setup paves the way for indoor large-fleet experimental research.
ER  - 

TY  - CONF
TI  - Multi-robot Informative Path Planning with Continuous Connectivity Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3245
EP  - 3251
AU  - A. Dutta
AU  - A. Ghosh
AU  - O. P. Kreidl
PY  - 2019
KW  - graph theory
KW  - integer programming
KW  - mobile robots
KW  - multi-robot systems
KW  - path planning
KW  - collision-free informative locations
KW  - informative paths
KW  - base station performs
KW  - multirobot system
KW  - information collection
KW  - continuous connectivity constraints
KW  - multirobot informative path planning
KW  - time 0.75 s
KW  - Robot sensing systems
KW  - Base stations
KW  - Path planning
KW  - Collision avoidance
KW  - Entropy
KW  - Bipartite graph
DO  - 10.1109/ICRA.2019.8794090
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider the problem of information collection from a polygonal environment using a multi-robot system, subject to continuous connectivity constraints. In particular, the robots, having a common radius of communication range, must remain connected throughout the exploration maximizing the information collection. The information gained through the exploration of the terrain is wirelessly transmitted to a base station. The base station performs the centralized planning of informative paths for the robots based on the information collected by them and thereafter, the robots follow these paths. This paper formulates the problem of multi-robot informative path planning under continuous connectivity constraints as an integer program leveraging the ideas of bipartite graph matching and minimal node separators. Theoretical analysis of the proposed solution proves that the informative paths will be collision-free and will be free of both livelock and deadlock. Experimental results demonstrate the low computational requirements of our algorithm for planning the informative paths, taking only about 0.75 sec. for planning a joint set of collision-free informative locations for 10 robots.
ER  - 

TY  - CONF
TI  - Sensor Coverage Control Using Robots Constrained to a Curve
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3252
EP  - 3258
AU  - G. Notomista
AU  - M. Santos
AU  - S. Hutchinson
AU  - M. Egerstedt
PY  - 2019
KW  - approximation theory
KW  - convex programming
KW  - gradient methods
KW  - mobile robots
KW  - sensors
KW  - mobile robots
KW  - two-dimensional domain
KW  - unconstrained coverage problem
KW  - gradient descent
KW  - direct projection
KW  - unconstrained problem
KW  - sensor coverage control
KW  - robots constrained
KW  - constrained coverage control problem
KW  - locational cost minimization
KW  - spatial allocation
KW  - convex approximation
KW  - Robot sensing systems
KW  - Optimization
KW  - Density functional theory
KW  - Wires
KW  - Environmental monitoring
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794261
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper we consider a constrained coverage control problem for a team of mobile robots. The robots are asked to provide sensor coverage over a two-dimensional domain, while being constrained to only move on a curve. The unconstrained coverage problem can be effectively solved by defining a locational cost to be minimized by the robots, in a decentralized fashion, using gradient descent. However, a direct projection of the solution to the unconstrained problem onto the curve may result in a very poor spatial allocation of the team within the two-dimensional domain. Therefore, we propose a modification to the locational cost, which incorporates the constraints, and a convex relaxation that allows us to efficiently minimize a convex approximation of the cost using a decentralized strategy. The resulting algorithm is implemented on a team of mobile robots.
ER  - 

TY  - CONF
TI  - Coverage of an Environment Using Energy-Constrained Unmanned Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3259
EP  - 3265
AU  - K. Yu
AU  - J. M. O’Kane
AU  - P. Tokekar
PY  - 2019
KW  - approximation theory
KW  - autonomous aerial vehicles
KW  - computational complexity
KW  - mobile robots
KW  - path planning
KW  - travelling salesman problems
KW  - UGV
KW  - area coverage problem
KW  - energy-constrained unmanned aerial vehicle
KW  - unmanned ground vehicle
KW  - symbiotic UAV
KW  - NP-hard problem
KW  - generalized traveling salesperson problem
KW  - boustrophedon cells
KW  - limited battery capacity
KW  - Batteries
KW  - Unmanned aerial vehicles
KW  - Agriculture
KW  - Robot sensing systems
KW  - Strips
KW  - Routing
DO  - 10.1109/ICRA.2019.8794150
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We study the problem of covering an environment using an Unmanned Aerial Vehicle (UAV) with limited battery capacity. We consider a scenario where the UAV can land on an Unmanned Ground Vehicle (UGV) and recharge the onboard battery. The UGV can also recharge the UAV while transporting the UAV to the next take-off site. We present an algorithm to solve a new variant of the area coverage problem that takes into account this symbiotic UAV and UGV system. The input consists of a set of boustrophedon cells - rectangular strips whose width is equal to the field-of-view of the sensor on the UAV. The goal is to find a tour for the UAV that visits and covers all cells in minimum time. This includes flight time for visiting and covering all cells, recharging time, as well as the take-off and landing times. We show how to reduce this problem to a known NP-hard problem, Generalized Traveling Salesperson Problem (GTSP). Given an optimal GTSP solver, our approach finds the optimal coverage paths for the UAV and UGV. We evaluate our algorithm through simulations and proof-of-concept experiments.
ER  - 

TY  - CONF
TI  - Point Cloud Compression for 3D LiDAR Sensor using Recurrent Neural Network with Residual Blocks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3274
EP  - 3280
AU  - C. Tu
AU  - E. Takeuchi
AU  - A. Carballo
AU  - K. Takeda
PY  - 2019
KW  - computational geometry
KW  - data compression
KW  - image coding
KW  - iterative methods
KW  - mobile robots
KW  - octrees
KW  - optical radar
KW  - recurrent neural nets
KW  - SLAM (robots)
KW  - recurrent neural network
KW  - residual blocks
KW  - generic octree point cloud compression method
KW  - potential application scenarios
KW  - decompressed point cloud data
KW  - 3D LiDAR sensor
KW  - autonomous driving systems
KW  - 3D LiDAR data
KW  - raw D formatted LiDAR data
KW  - 2D formatted LiDAR data
KW  - Three-dimensional displays
KW  - Image coding
KW  - Laser radar
KW  - Two dimensional displays
KW  - Robot sensing systems
KW  - Decoding
KW  - Recurrent neural networks
DO  - 10.1109/ICRA.2019.8794264
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The use of 3D LiDAR, which has proven its capabilities in autonomous driving systems, is now expanding into many other fields. The sharing and transmission of point cloud data from 3D LiDAR sensors has broad application prospects in robotics. However, due to the sparseness and disorderly nature of this data, it is difficult to compress it directly into a very low volume. A potential solution is utilizing raw LiDAR data. We can rearrange the raw data from each frame losslessly in a 2D matrix, making the data compact and orderly. Due to the special structure of 3D LiDAR data, the texture of the 2D matrix is irregular, in contrast to 2D matrices of camera images. In order to compress this raw, 2D formatted LiDAR data efficiently, in this paper we propose a method which uses a recurrent neural network and residual blocks to progressively compress one frame's information from 3D LiDAR. Compared to our previous image compression based method and generic octree point cloud compression method, the proposed approach needs much less volume while giving the same decompression accuracy. Potential application scenarios for point cloud compression are also considered in this paper. We describe how decompressed point cloud data can be used with SLAM (simultaneous localization and mapping) as well as for localization using a given map, illustrating potential uses of the proposed method in real robotics applications.
ER  - 

TY  - CONF
TI  - Depth Completion with Deep Geometry and Context Guidance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3281
EP  - 3287
AU  - B. Lee
AU  - H. Jeon
AU  - S. Im
AU  - I. S. Kweon
PY  - 2019
KW  - computer vision
KW  - convolutional neural nets
KW  - feature extraction
KW  - learning (artificial intelligence)
KW  - object detection
KW  - bilateral weight
KW  - deep geometry
KW  - context guidance
KW  - geometry network
KW  - context network
KW  - single encoder-decoder network
KW  - initial propagated depth map
KW  - slanted surfaces
KW  - convolutional neural network
KW  - CNN-based depth completions
KW  - local feature extraction
KW  - global feature extraction
KW  - Three-dimensional displays
KW  - Geometry
KW  - Feature extraction
KW  - Image edge detection
KW  - Reliability
KW  - Laser radar
KW  - Convolution
DO  - 10.1109/ICRA.2019.8794161
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present an end-to-end convolutional neural network (CNN) for depth completion. Our network consists of a geometry network and a context network. The geometry network, a single encoder-decoder network, learns to optimize a multi-task loss to generate an initial propagated depth map and a surface normal. The complementary outputs allow it to correctly propagate initial sparse depth points in slanted surfaces. The context network extracts a local and a global feature of an image to compute a bilateral weight, which enables it to preserve edges and fine details in the depth maps. At the end, a final output is produced by multiplying the initially propagated depth map with the bilateral weight. In order to validate the effectiveness and the robustness of our network, we performed extensive ablation studies and compared the results against state-of-the-art CNN-based depth completions, where we showed promising results on various scenes.
ER  - 

TY  - CONF
TI  - Self-Supervised Sparse-to-Dense: Self-Supervised Depth Completion from LiDAR and Monocular Camera
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3288
EP  - 3295
AU  - F. Ma
AU  - G. V. Cavalheiro
AU  - S. Karaman
PY  - 2019
KW  - cameras
KW  - image colour analysis
KW  - image fusion
KW  - image sequences
KW  - optical radar
KW  - regression analysis
KW  - robot vision
KW  - semidense annotations
KW  - KITTI depth completion benchmark
KW  - self-supervised sparse-to-dense
KW  - self-supervised depth completion
KW  - dense depth image
KW  - sparse depth measurements
KW  - irregularly spaced pattern
KW  - multiple sensor modalities
KW  - dense level ground truth depth
KW  - pixel-level ground truth depth
KW  - self-supervised training framework
KW  - sparse depth images
KW  - color images
KW  - Laser radar
KW  - Training
KW  - Color
KW  - Robot sensing systems
KW  - Three-dimensional displays
KW  - Convolution
KW  - Extraterrestrial measurements
DO  - 10.1109/ICRA.2019.8793637
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Depth completion, the technique of estimating a dense depth image from sparse depth measurements, has a variety of applications in robotics and autonomous driving. However, depth completion faces 3 main challenges: the irregularly spaced pattern in the sparse depth input, the difficulty in handling multiple sensor modalities (when color images are available), as well as the lack of dense, pixel-level ground truth depth labels for training. In this work, we address all these challenges. Specifically, we develop a deep regression model to learn a direct mapping from sparse depth (and color images) input to dense depth prediction. We also propose a self-supervised training framework that requires only sequences of color and sparse depth images, without the need for dense depth labels. Our experiments demonstrate that the self-supervised framework outperforms a number of existing solutions trained with semi-dense annotations. Furthermore, when trained with semi-dense annotations, our network attains state-of-the-art accuracy and is the winning approach on the KITTI depth completion benchmark at the time of submission.
ER  - 

TY  - CONF
TI  - In-hand Object Scanning via RGB-D Video Segmentation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3296
EP  - 3302
AU  - F. Wang
AU  - K. Hauser
PY  - 2019
KW  - image colour analysis
KW  - image reconstruction
KW  - image segmentation
KW  - object detection
KW  - object tracking
KW  - video signal processing
KW  - video-segmentation-based object tracking algorithm
KW  - hand object scanning
KW  - RGB-D video segmentation
KW  - in-hand manipulation
KW  - video camera
KW  - multiple grasps
KW  - household objects
KW  - in-hand object tracking
KW  - video tracking algorithms
KW  - RGB-D in-hand object manipulation dataset
KW  - 3D object scanning
KW  - Three-dimensional displays
KW  - Pipelines
KW  - Image color analysis
KW  - Cameras
KW  - Solid modeling
KW  - Image segmentation
KW  - Proposals
DO  - 10.1109/ICRA.2019.8794467
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a technique for 3D object scanning via in-hand manipulation, in which an object reoriented in front of a video camera with multiple grasps and regrasps. In-hand object tracking is a significant challenge under fast movement, rapid appearance changes, and occlusions. This paper proposes a novel video-segmentation-based object tracking algorithm that tracks arbitrary in-hand objects more effectively than existing techniques. It also describes a novel RGB-D in-hand object manipulation dataset consisting of several common household objects. Experiments show that the new method achieves 6% increase in accuracy compared to top performing video tracking algorithms and results in noticeably higher quality reconstructed models. Moreover, testing with a novice user on a set of 200 objects demonstrates relatively rapid construction of complete 3D object models.
ER  - 

TY  - CONF
TI  - Multi-Modal Generative Models for Learning Epistemic Active Sensing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3319
EP  - 3325
AU  - T. Korthals
AU  - D. Rudolph
AU  - J. Leitner
AU  - M. Hesse
AU  - U. Rückert
PY  - 2019
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-agent systems
KW  - neural nets
KW  - statistical analysis
KW  - multimodal deep generative models
KW  - coordinated heterogeneous multiagent active sensing
KW  - joint latent representation
KW  - epistemic active sensing behavior
KW  - multimodal variational auto encoder
KW  - sensor modalities
KW  - multiagent deep reinforcement learning setup
KW  - direct reward signal
KW  - evidence lower bound
KW  - Robot sensing systems
KW  - Robot kinematics
KW  - Training
KW  - Feature extraction
KW  - Reinforcement learning
DO  - 10.1109/ICRA.2019.8794458
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel approach of multi-modal deep generative models and apply this to coordinated heterogeneous multi-agent active sensing. A major approach to achieve this objective is to train a multi-modal variational Auto Encoder (M2VAE) that integrates the information of different sensor modalities into a joint latent representation. Furthermore, we derive an objective from the M2VAE that enables the maximization of the evidence lower bound via selection of sensor modalities. Using this approach as a direct reward signal to a multi-modal and multi-agent deep reinforcement learning setup leads intuitively to an epistemic active sensing behavior that coordinately resolves the ambiguity of observations.
ER  - 

TY  - CONF
TI  - Decentralized Formation Coordination of Multiple Quadcopters under Communication Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3326
EP  - 3332
AU  - P. Abichandani
AU  - K. Levin
AU  - D. Bucci
PY  - 2019
KW  - autonomous aerial vehicles
KW  - collision avoidance
KW  - decentralised control
KW  - helicopters
KW  - integer programming
KW  - linear programming
KW  - mobile robots
KW  - multi-robot systems
KW  - nonlinear programming
KW  - robot dynamics
KW  - robot kinematics
KW  - RSSI
KW  - tree searching
KW  - outdoor formation coordination
KW  - multiple quadcopters
KW  - time-optimal speed profile
KW  - minimum snap spline path
KW  - quadcopter kinematics
KW  - wireless communication connectivity
KW  - geometric formations
KW  - maximum separation distance
KW  - minimum viable received signal strength
KW  - path loss attenuation
KW  - outdoor flight test
KW  - formation type
KW  - robin communication scheduling scheme
KW  - decentralized formation coordination
KW  - communication constraints
KW  - RH-MINLP
KW  - quadcopter dynamics
KW  - collision avoidance
KW  - outer-approximation branch and bound solver
KW  - warm-starting scheme
KW  - hardware-in-the-loop
KW  - HITL
KW  - average radio packet loss statistics
KW  - round robin communication scheduling scheme
KW  - receding horizon mixed-integer nonlinear program
KW  - Splines (mathematics)
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Planning
KW  - Optimization
KW  - Mobile ad hoc networks
DO  - 10.1109/ICRA.2019.8794246
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of decentralized, outdoor formation coordination with multiple quadcopters. The problem is formulated as a receding horizon, mixed-integer non-linear program (RH-MINLP). Each quadcopter solves this RH-MINLP to generate its time-optimal speed profile along a minimum snap spline path while coordinating its position in a desired formation with other quadcopters. Constraints on quadcopter kinematics, dynamics, collision avoidance, wireless communication connectivity, and geometric formations are modeled. Communication connectivity is modeled as a constraint on maximum separation distance based on a minimum viable received signal strength in the presence of path loss attenuation. The resulting RH-MINLP is non-convex, and is solved using an outer-approximation branch and bound solver with a warm-starting scheme. The framework is validated via Hardware-in-the-Loop (HITL) and outdoor flight test with up to 6 quadcopters. Results demonstrate the effect of number of quadcopters and formation type on total transit time. Average radio packet loss statistics during transit indicate robust network performance for a round robin communication scheduling scheme.
ER  - 

TY  - CONF
TI  - Online Plan Repair in Multi-robot Coordination with Disturbances
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3333
EP  - 3339
AU  - A. Coskun
AU  - J. M. O’Kane
PY  - 2019
KW  - collision avoidance
KW  - Gaussian processes
KW  - multi-robot systems
KW  - path planning
KW  - RMTRACK control law
KW  - Gaussian process
KW  - coordination space obstacle
KW  - disturbance probabilities
KW  - multirobot coordination
KW  - online plan repair
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Trajectory
KW  - Maintenance engineering
KW  - System recovery
KW  - Delays
DO  - 10.1109/ICRA.2019.8793522
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of multi-robot coordination in scenarios where the robots may experience unexpected delays in their movements. Prior work by Čáp, Gregoire, and Frazzołi introduced a control law, called RMTRACK, which enables robots in such scenarios to execute preplanned paths in spite of disturbances in the execution speed of each robot, while guaranteeing that each robot can reach its goal without collisions and without deadlocks. We extend that approach to handle scenarios in which the disturbance probabilities are unknown at the start and non-uniform across the environment. The key idea is to `repair' a plan on-the-fly, by swapping the order in which a pair of robots passes through a mutual collision region (i.e. a coordination space obstacle), when making such a change can be estimated to improve the overall performance of the system. We introduce a technique based on Gaussian Processes to estimate future disturbances, and propose two algorithms for testing, at appropriate times, whether a swap of a given obstacle would be beneficial. Tests in simulation demonstrate that our algorithm achieves significantly smaller average travel time than RMTRACK at only a modest computational expense.
ER  - 

TY  - CONF
TI  - Integrated Mapping and Path Planning for Very Large-Scale Robotic (VLSR) Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3356
EP  - 3362
AU  - J. Morelli
AU  - P. Zhu
AU  - B. Doerr
AU  - R. Linares
AU  - S. Ferrari
PY  - 2019
KW  - collision avoidance
KW  - control engineering computing
KW  - mobile robots
KW  - multi-robot systems
KW  - regression analysis
KW  - sensor fusion
KW  - decentralized approach
KW  - obstacle mapping
KW  - continuous probabilistic representation
KW  - mapping problem
KW  - binary classification task
KW  - kernel logistic regression
KW  - discriminative classifier online
KW  - individual robot maps
KW  - path planning algorithm
KW  - maximum information value
KW  - obstacle avoidance
KW  - VLSR system
KW  - prior obstacle information
KW  - robot paths
KW  - Hilbert map fusion method
KW  - large-scale robotic systems
KW  - onboard range sensors
KW  - Robot sensing systems
KW  - Entropy
KW  - Robot kinematics
KW  - Collision avoidance
KW  - Path planning
DO  - 10.1109/ICRA.2019.8793795
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper develops a decentralized approach for mapping and information-driven path planning for Very Large Scale Robotic (VLSR) systems. In this approach, obstacle mapping is performed using a continuous probabilistic representation known as a Hilbert map, which formulates the mapping problem as a binary classification task and uses kernel logistic regression to train a discriminative classifier online. A novel Hilbert map fusion method is presented that quickly and efficiently combines the information from individual robot maps. An integrated mapping and path planning algorithm is presented to determine paths of maximum information value, while simultaneously performing obstacle avoidance. Furthermore, the effect of how percentage communication failure effects the overall performance of the system is investigated. The approach is demonstrated on a VLSR system with hundreds of robots that must map obstacles collaboratively over a large region of interest using onboard range sensors and no prior obstacle information. The results show that, through fusion and decentralized processing, the entropy of the map decreases over time and robot paths remain collision-free.
ER  - 

TY  - CONF
TI  - Methodology of Designing Multi-agent Robot Control Systems Utilising Hierarchical Petri Nets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3363
EP  - 3369
AU  - M. Figat
AU  - C. Zieliński
PY  - 2019
KW  - finite state machines
KW  - multi-agent systems
KW  - multi-robot systems
KW  - Petri nets
KW  - multiagent robot system layer
KW  - agent layer
KW  - subsystem layer
KW  - communication layer
KW  - robotic system
KW  - robot controller code
KW  - multiagent robot control systems
KW  - embodied agent
KW  - cooperating subsystems
KW  - hierarchical finite state machines
KW  - hierarchical Petri nets
KW  - Petri nets
KW  - Tools
KW  - Data models
KW  - Systematics
KW  - Automation
KW  - Robot control
DO  - 10.1109/ICRA.2019.8794201
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A robot system is designed as a set of embodied agents. An embodied agent is decomposed into cooperating subsystems. In our previous work activities of subsystems were defined by hierarchical finite state machines. With their states activities were associated. In that approach communication between subsystems was treated as an implementation issue. This paper represents activities of a robot system using hierarchical Petri nets with conditions. Such net is created by specifying consecutive layers: multi-agent robot system layer, agent layer, subsystem layer, behaviour layer and communication layer. This decomposition not only organizes in a systematic manner the development of a robot system, but also introduces a comprehensive description of concurrently acting subsystems. Based on those theoretical considerations, a tool was created for producing hierarchical Petri nets defining the model of a robotic system and enabling automatic generation of the robot controller code, resulting in a significant acceleration of the implementation phase. The capabilities of the tool are presented by the development of a robot controller performing a rudimentary task.
ER  - 

TY  - CONF
TI  - Interaction-Aware Multi-Agent Reinforcement Learning for Mobile Agents with Individual Goals
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3370
EP  - 3376
AU  - A. Mohseni-Kabir
AU  - D. Isele
AU  - K. Fujimura
PY  - 2019
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - robot programming
KW  - interaction-aware multiagent reinforcement learning
KW  - mobile agents
KW  - individual goals
KW  - optimal policy
KW  - decentralized learning
KW  - mobile robot navigation
KW  - policy gradient algorithms
KW  - nonstationary policies
KW  - curriculum-based strategy
KW  - interactive policy learning
KW  - Training
KW  - Robots
KW  - Games
KW  - Markov processes
KW  - Reinforcement learning
KW  - Navigation
KW  - Autonomous vehicles
DO  - 10.1109/ICRA.2019.8793721
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In a multi-agent setting, the optimal policy of a single agent is largely dependent on the behavior of other agents. We investigate the problem of multi-agent reinforcement learning, focusing on decentralized learning in non-stationary domains for mobile robot navigation. We identify a cause for the difficulty in training non-stationary policies: mutual adaptation to sub-optimal behaviors, and we use this to motivate a curriculum-based strategy for learning interactive policies. The curriculum has two stages. First, the agent leverages policy gradient algorithms to learn a policy that is capable of achieving multiple goals. Second, the agent learns a modifier policy to learn how to interact with other agents in a multi-agent setting. We evaluated our approach on both an autonomous driving lane-change domain and a robot navigation domain.
ER  - 

TY  - CONF
TI  - Coverage Control for Multiple Event Types with Heterogeneous Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3377
EP  - 3383
AU  - A. Sadeghi
AU  - S. L. Smith
PY  - 2019
KW  - distributed algorithms
KW  - mobile robots
KW  - multi-robot systems
KW  - optimisation
KW  - continuous environments
KW  - discrete environments
KW  - locally optimal positions
KW  - density function
KW  - coverage control
KW  - multiple event types
KW  - heterogeneous robots
KW  - autonomous robots
KW  - total sensing quality
KW  - homogeneous problem
KW  - Robot sensing systems
KW  - Density functional theory
KW  - Distributed algorithms
KW  - Linear programming
KW  - Silicon
DO  - 10.1109/ICRA.2019.8793639
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper focuses on the problem of deploying a set of autonomous robots to efficiently monitor multiple types of events in an environment. There is a density function over the environment for each event type representing the weighted likelihood of the event at each location. The robots are heterogeneous in that each robot is equipped with a set of sensors and it is capable of sensing a subset of event types. The objective is to deploy the robots in the environment to minimize a linear combination of the total sensing quality of the events. We propose a new formulation for the problem which is a natural extension of the homogeneous problem. We propose distributed algorithms that drive the robots to locally optimal positions in both continuous environments that are obstacle-free, and in discrete environments that may contain obstacles. In both cases we prove convergence to locally optimal positions. We provide extension to the case where the density functions are unknown prior to the deployment in continuous environments. Finally, we present benchmarking results and physical experiments to characterize the solution quality.
ER  - 

TY  - CONF
TI  - Active Perception in Adversarial Scenarios using Maximum Entropy Deep Reinforcement Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3384
EP  - 3390
AU  - M. Shen
AU  - J. P. How
PY  - 2019
KW  - belief networks
KW  - entropy
KW  - learning (artificial intelligence)
KW  - multi-agent systems
KW  - neural nets
KW  - planning (artificial intelligence)
KW  - stochastic processes
KW  - partial observability
KW  - adversary agent
KW  - autonomous agent
KW  - belief space planning
KW  - generative adversary modeling
KW  - maximum entropy reinforcement learning
KW  - stochastic belief space policy
KW  - unmodeled adversarial strategies
KW  - maximum entropy deep reinforcement learning
KW  - active perception problem
KW  - potentially adversarial behaviors
KW  - uncertainty modeling
KW  - standard chance-constraint partially observable Markov decision
KW  - Uncertainty
KW  - Games
KW  - Autonomous agents
KW  - Reinforcement learning
KW  - Nash equilibrium
KW  - Planning
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8794389
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We pose an active perception problem where an autonomous agent actively interacts with a second agent with potentially adversarial behaviors. Given the uncertainty in the intent of the other agent, the objective is to collect further evidence to help discriminate potential threats. The main technical challenges are the partial observability of the agent intent, the adversary modeling, and the corresponding uncertainty modeling. Note that an adversary agent may act to mislead the autonomous agent by using a deceptive strategy that is learned from past experiences. We propose an approach that combines belief space planning, generative adversary modeling, and maximum entropy reinforcement learning to obtain a stochastic belief space policy. By accounting for various adversarial behaviors in the simulation framework and minimizing the predictability of the autonomous agent's action, the resulting policy is more robust to unmodeled adversarial strategies. This improved robustness is empirically shown against an adversary that adapts to and exploits the autonomous agent's policy when compared with a standard Chance-Constraint Partially Observable Markov Decision Process robust approach.
ER  - 

TY  - CONF
TI  - A Competitive Algorithm for Online Multi-Robot Exploration of a Translating Plume
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3391
EP  - 3397
AU  - Y. Sung
AU  - P. Tokekar
PY  - 2019
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - multi-robot systems
KW  - velocity control
KW  - arbitrary shape
KW  - plume shape
KW  - plume speed
KW  - robot speed
KW  - tour
KW  - aerial robots
KW  - translating plume
KW  - online multirobot exploration
KW  - competitive algorithm
KW  - Robot kinematics
KW  - Two dimensional displays
KW  - Approximation algorithms
KW  - Shape
KW  - Unmanned aerial vehicles
KW  - Binary trees
DO  - 10.1109/ICRA.2019.8793850
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we study the problem of exploring a translating plume with a team of aerial robots. The shape and the size of the plume are unknown to the robots. The objective is to find a tour for each robot such that they collectively explore the plume. Specifically, the tours must be such that each point in the plume must be visible from the field-of-view of some robot along its tour. We propose a recursive Depth-First Search (DFS)-based algorithm that yields a constant competitive ratio for the exploration problem. The competitive ratio is 2(Sr + Sp)(R+⌊log R⌋)/(Sr + Sp)(R+⌊log R⌋) where R is the number of robots, and Sr and Sp are the robot speed and the plume speed, respectively. We also consider a more realistic scenario where the plume shape is not restricted to grid cells but an arbitrary shape. We show our algorithm has 2(Sr + Sp)(18 R+⌊log R⌋)/(Sr + Sp)(1+⌊log R⌋) competitive ratio under the fat condition. We empirically verify our algorithm using simulations.
ER  - 

TY  - CONF
TI  - Online Estimation of Ocean Current from Sparse GPS Data for Underwater Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3443
EP  - 3449
AU  - K. M. B. Lee
AU  - C. Yoo
AU  - B. Hollings
AU  - S. Anstee
AU  - S. Huang
AU  - R. Fitch
PY  - 2019
KW  - expectation-maximisation algorithm
KW  - Gaussian processes
KW  - Global Positioning System
KW  - mobile robots
KW  - position control
KW  - regression analysis
KW  - underwater vehicles
KW  - online estimation
KW  - Gaussian process-based expectation-maximisation algorithm
KW  - dead-reckoned position estimates
KW  - specialised GP regression scheme
KW  - best-fitting ocean
KW  - ocean current field
KW  - underwater vehicles
KW  - underwater robots
KW  - Oceans
KW  - Sea measurements
KW  - Current measurement
KW  - Global Positioning System
KW  - Trajectory
KW  - Estimation
DO  - 10.1109/ICRA.2019.8794308
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Underwater robots are subject to position drift due to the effect of ocean currents and the lack of accurate localisation while submerged. We are interested in exploiting such position drift to estimate the ocean current in the surrounding area, thereby assisting navigation and planning. We present a Gaussian process (GP)-based expectation-maximisation (EM) algorithm that estimates the underlying ocean current using sparse GPS data obtained on the surface and dead-reckoned position estimates. We first develop a specialised GP regression scheme that exploits the incompressibility of ocean currents to counteract the underdetermined nature of the problem. We then use the proposed regression scheme in an EM algorithm that estimates the best-fitting ocean current in between each GPS fix. The proposed algorithm is validated in simulation and on a real dataset, and is shown to be capable of reconstructing the underlying ocean current field. We expect to use this algorithm to close the loop between planning and estimation for underwater navigation in unknown ocean currents.
ER  - 

TY  - CONF
TI  - Working towards Adaptive Sensing for Terrain-aided Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3450
EP  - 3456
AU  - M. Zhou
AU  - R. Bachmayer
AU  - B. de Young
PY  - 2019
KW  - adaptive signal processing
KW  - altimeters
KW  - autonomous underwater vehicles
KW  - Kalman filters
KW  - marine navigation
KW  - particle filtering (numerical methods)
KW  - sonar
KW  - underwater vehicles
KW  - velocity measurement
KW  - terrain-aided navigation
KW  - adaptive sensing method
KW  - pinging rate
KW  - localization accuracy
KW  - TAN
KW  - sonar pinging interval
KW  - local seafloor topography
KW  - modified Teager Kaiser energy operator
KW  - pinging interval
KW  - downward-looking sonar
KW  - autonomous underwater vehicle
KW  - particle filter
KW  - bias velocity estimator
KW  - Kalman filter
KW  - depth variation
KW  - Atmospheric measurements
KW  - Sea measurements
KW  - Particle measurements
KW  - Sonar navigation
KW  - Sensors
KW  - Sonar
DO  - 10.1109/ICRA.2019.8794149
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - An adaptive sensing method is presented to control the pinging interval of a downward-looking sonar on an Autonomous Underwater Vehicle. The goal is to conserve energy via adjusting the pinging rate automatically without reducing the localization accuracy when using terrain-aided navigation (TAN). In this paper, the TAN is implemented using a particle filter and a bias velocity estimator developed based on a Kalman filter. The adaptation on the sonar pinging interval is determined based on the depth variation of local seafloor topography which is quantified using a modified Teager Kaiser energy operator. As a result, more measurements are collected on high relief regions, and less measurements are obtained on relatively flat and smooth regions. We evaluated the adaptive sensing method in a simulated environment and applied it to a field data set. The results show that the adaptive sensing method produces an improved navigational accuracy compared to the missions with fixed sonar pinging rates. In the offline field missions, the energy consumed by the altimeter is reduced to about 30% in the adaptive sensing missions compared to continuously sensing missions where the altimeter is pinging consistently without switching off.
ER  - 

TY  - CONF
TI  - Non-Gaussian SLAM utilizing Synthetic Aperture Sonar
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3457
EP  - 3463
AU  - M. Y. Cheung
AU  - D. Fourie
AU  - N. R. Rypkema
AU  - P. V. Teixeira
AU  - H. Schmidt
AU  - J. Leonard
PY  - 2019
KW  - acoustic signal processing
KW  - array signal processing
KW  - graph theory
KW  - marine navigation
KW  - pose estimation
KW  - probability
KW  - sensor fusion
KW  - SLAM (robots)
KW  - synthetic aperture sonar
KW  - SLAM framework
KW  - beacon position
KW  - acoustic measurements
KW  - factor graph formulation
KW  - nonGaussian SLAM
KW  - spatial resolution
KW  - navigational measurements
KW  - underwater missions
KW  - synthetic aperture sonar
KW  - SAS
KW  - simultaneous localization and mapping
KW  - accurate pose estimation
KW  - hydrophones acoustic data
KW  - empirical probability distribution
KW  - conventional beamformer
KW  - autonomous surface vehicle
KW  - Acoustics
KW  - Synthetic aperture sonar
KW  - Array signal processing
KW  - Simultaneous localization and mapping
KW  - Apertures
KW  - Receivers
KW  - Sonar navigation
DO  - 10.1109/ICRA.2019.8793536
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Synthetic Aperture Sonar (SAS) is a technique to improve the spatial resolution from a moving set of receivers by extending the array in time, increasing the effective array length and aperture. This technique is limited by the accuracy of the receiver position estimates, necessitating highly accurate, typically expensive aided-inertial navigation systems for submerged platforms. We leverage simultaneous localization and mapping to fuse acoustic and navigational measurements and obtain accurate pose estimates even without the benefit of absolute positioning for lengthy underwater missions. We demonstrate a method of formulating the well-known SAS problem in a SLAM framework, using acoustic data from hydrophones to simultaneously estimate platform and beacon position. An empirical probability distribution is computed from a conventional beamformer to correctly account for uncertainty in the acoustic measurements. The non-parametric method relieves the familiar Gaussian-only assumption currently used in the localization and mapping discipline and fits effectively into a factor graph formulation with conventional factors such as ground-truth priors and odometry. We present results from field experiments performed on the Charles River with an autonomous surface vehicle which demonstrate simultaneous localization of an unknown acoustic beacon and vehicle positioning, and provide comparison to GPS ground truths.
ER  - 

TY  - CONF
TI  - Easily Deployable Underwater Acoustic Navigation System for Multi-Vehicle Environmental Sampling Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3464
EP  - 3470
AU  - A. Quraishi
AU  - A. Bahr
AU  - F. Schill
AU  - A. Martinoli
PY  - 2019
KW  - autonomous underwater vehicles
KW  - inertial navigation
KW  - lakes
KW  - mobile robots
KW  - path planning
KW  - underwater acoustic communication
KW  - clock synchronization
KW  - underwater robotics
KW  - autonomous underwater vehicles
KW  - GNSS
KW  - Lake Geneva
KW  - feature tracking
KW  - adaptive sampling
KW  - underwater environmental sensing
KW  - electromagnetic waves
KW  - radio communication
KW  - satellite based positioning
KW  - aerial robotics
KW  - multivehicle environmental sampling applications
KW  - acoustic navigation system
KW  - absolute time information
KW  - AUV position
KW  - underwater acoustic positioning system
KW  - inertial navigation
KW  - Acoustics
KW  - Global navigation satellite system
KW  - Acoustic measurements
KW  - Receivers
KW  - Clocks
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793699
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Water as a medium poses a number of challenges for robots, limiting the progress of research in underwater robotics vis-á-vis ground or aerial robotics. The primary challenges are satellite based positioning and radio communication being unusable due to high attenuation of electromagnetic waves in water. We have developed miniature, agile, easy to carry and deploy Autonomous Underwater Vehicles (AUVs) equipped with a suite of sensors for underwater environmental sensing. We previously demonstrated adaptive sampling and feature tracking, and gathered data from a lake for limnological research, with the AUV performing inertial navigation. In this paper, we demonstrate a new underwater acoustic positioning system, which allows on-board estimation of AUV position. Our system uses absolute time information from GNSS for initial clock synchronization and uses one-way-travel-time for range measurements, which makes it scalable in the number of robots. It is easily deployable and does not rely on any installed infrastructure in the environment. We describe various hardware and software components of our system, and present results from experiments in Lake Geneva.
ER  - 

TY  - CONF
TI  - Underwater Terrain Reconstruction from Forward-Looking Sonar Imagery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3471
EP  - 3477
AU  - J. Wang
AU  - T. Shan
AU  - B. Englot
PY  - 2019
KW  - feature extraction
KW  - Gaussian processes
KW  - graph theory
KW  - image reconstruction
KW  - mobile robots
KW  - remotely operated vehicles
KW  - SLAM (robots)
KW  - sonar imaging
KW  - terrain mapping
KW  - underwater vehicles
KW  - terrain reconstruction
KW  - forward-looking sonar imagery
KW  - underwater simultaneous localization
KW  - multibeam imaging sonar
KW  - 3D terrain mapping tasks
KW  - elevation angle information
KW  - data association
KW  - accurate 3D mapping
KW  - Euclidean space
KW  - optical flow
KW  - bearing-range images
KW  - subsea terrain
KW  - Gaussian Process random field
KW  - terrain factors
KW  - factor graph
KW  - terrain elevation estimate
KW  - variable-elevation tank environment
KW  - smooth height estimate
KW  - sonar images
KW  - Chow-Liu tree
KW  - extracted feature tracking
KW  - Feature extraction
KW  - Sonar measurements
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Gaussian processes
KW  - Imaging
DO  - 10.1109/ICRA.2019.8794473
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a novel approach for underwater simultaneous localization and mapping using a multibeam imaging sonar for 3D terrain mapping tasks. The high levels of noise and the absence of elevation angle information in sonar images present major challenges for data association and accurate 3D mapping. Instead of repeatedly projecting extracted features into Euclidean space, we apply optical flow within bearing-range images for tracking extracted features. To deal with degenerate cases, such as when tracking is interrupted by noise, we model the subsea terrain as a Gaussian Process random field on a Chow-Liu tree. Terrain factors are incorporated into the factor graph, aimed at smoothing the terrain elevation estimate. We demonstrate the performance of our proposed algorithm in a simulated environment, which shows that terrain factors effectively reduce estimation error. We also show ROV experiments performed in a variable-elevation tank environment, where we are able to construct a descriptive and smooth height estimate of the tank bottom.
ER  - 

TY  - CONF
TI  - Detect in RGB, Optimize in Edge: Accurate 6D Pose Estimation for Texture-less Industrial Parts
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3486
EP  - 3492
AU  - H. Zhang
AU  - Q. Cao
PY  - 2019
KW  - convolutional neural nets
KW  - edge detection
KW  - image colour analysis
KW  - manipulators
KW  - object recognition
KW  - pose estimation
KW  - robot vision
KW  - texture-less industrial parts
KW  - robotic bin-picking problem
KW  - industrial applications
KW  - single RGB image
KW  - discriminative local appearance descriptors
KW  - optimization stage
KW  - coarse initializations
KW  - surface texture
KW  - edge image
KW  - edge optimization
KW  - accurate 6D object pose estimation
KW  - 2D bounding box
KW  - tiny convolutional neural network
KW  - hypothesis-evaluation scheme
KW  - robotic manipulation platform
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA.2019.8794330
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In order to solve robotic bin-picking problem in many industrial applications, accurate 6D object pose estimation is one of fundamental technologies. This paper presents a method for accurate 6D pose estimation from a single RGB image for texture-less industrial parts. These objects are common but still challenging to deal with, due to the fact that poor surface texture and brightness makes difficult to compute discriminative local appearance descriptors. The proposed method mainly consists of two stages, which ranges from the detection stage to the optimization stage. Firstly, all known objects in the RGB image are detected with 2D bounding box via a tiny convolutional neural network. Then, the second stage will optimize the 6D pose in the Edge image given several coarse initializations. These coarse initializations are generated from the Edge image via a hypothesis-evaluation scheme. Furthermore, the proposed method is validated by achieving state-of-the-art results of texture-less industrial parts for RGB input. According to practical experiments, the proposed method is accurate and robust enough to be applied on the robotic manipulation platform to complete a simple assembly task.
ER  - 

TY  - CONF
TI  - POSEAMM: A Unified Framework for Solving Pose Problems using an Alternating Minimization Method
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3493
EP  - 3499
AU  - J. Campos
AU  - J. R. Cardoso
AU  - P. Miraldo
PY  - 2019
KW  - computer vision
KW  - minimisation
KW  - pose estimation
KW  - alternating minimization method
KW  - pose estimation
KW  - computer vision
KW  - camera models
KW  - pose problem
KW  - objective function
KW  - simple minimization problem
KW  - distinct pose problems
KW  - alternating minimization methods
KW  - pose problems
KW  - Cameras
KW  - Linear programming
KW  - Three-dimensional displays
KW  - Optimization
KW  - Minimization methods
KW  - Computer vision
DO  - 10.1109/ICRA.2019.8793694
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pose estimation is one of the most important problems in computer vision. It can be divided in two different categories - absolute and relative - and may involve two different types of camera models: central and non-central. State-of-the-art methods have been designed to solve separately these problems. This paper presents a unified framework that is able to solve any pose problem by alternating optimization techniques between two set of parameters, rotation and translation. In order to make this possible, it is necessary to define an objective function that captures the problem at hand. Since the objective function will depend on the rotation and translation it is not possible to solve it as a simple minimization problem. Hence the use of Alternating Minimization methods, in which the function will be alternatively minimized with respect to the rotation and the translation. We show how to use our framework in three distinct pose problems. Our methods are then benchmarked with both synthetic and real data, showing their better balance between computational time and accuracy.
ER  - 

TY  - CONF
TI  - Learning Object Localization and 6D Pose Estimation from Simulation and Weakly Labeled Real Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3500
EP  - 3506
AU  - J. Mercier
AU  - C. Mitash
AU  - P. Giguère
AU  - A. Boularias
PY  - 2019
KW  - image annotation
KW  - image classification
KW  - image segmentation
KW  - object detection
KW  - pose estimation
KW  - robot vision
KW  - unsupervised learning
KW  - 6D pose estimation
KW  - computer vision models
KW  - object localization
KW  - multiple domain classifiers
KW  - synthetic images
KW  - object poses
KW  - time-consuming annotations
KW  - occluded scenes
KW  - cluttered scenes
KW  - weak object detector
KW  - deep learning approaches
KW  - cluttered environments
KW  - robust robotic grasping
KW  - Feature extraction
KW  - Pose estimation
KW  - Training
KW  - Robots
KW  - Heating systems
KW  - Solid modeling
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794112
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate pose estimation is often a requirement for robust robotic grasping and manipulation of objects placed in cluttered, tight environments, such as a shelf with multiple objects. When deep learning approaches are employed to perform this task, they typically require a large amount of training data. However, obtaining precise 6 degrees of freedom for ground-truth can be prohibitively expensive. This work therefore proposes an architecture and a training process to solve this issue. More precisely, we present a weak object detector that enables localizing objects and estimating their 6D poses in cluttered and occluded scenes. To minimize the human labor required for annotations, the proposed detector is trained with a combination of synthetic and a few weakly annotated real images (as little as 10 images per object), for which a human provides only a list of objects present in each image (no time-consuming annotations, such as bounding boxes, segmentation masks and object poses). To close the gap between real and synthetic images, we use multiple domain classifiers trained adversarially. During the inference phase, the resulting class-specific heatmaps of the weak detector are used to guide the search of 6D poses of objects. Our proposed approach is evaluated on several publicly available datasets for pose estimation. We also evaluated our model on classification and localization in unsupervised and semi-supervised settings. The results clearly indicate that this approach could provide an efficient way toward fully automating the training process of computer vision models used in robotics.
ER  - 

TY  - CONF
TI  - STAMPEDE: A Discrete-Optimization Method for Solving Pathwise-Inverse Kinematics
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3507
EP  - 3513
AU  - D. Rakita
AU  - B. Mutlu
AU  - M. Gleicher
PY  - 2019
KW  - collision avoidance
KW  - dynamic programming
KW  - end effectors
KW  - graph theory
KW  - manipulator kinematics
KW  - motion control
KW  - nonlinear programming
KW  - search problems
KW  - trajectory control
KW  - adaptive sampling
KW  - search-space
KW  - input end-effector trace
KW  - nonlinear trajectory-optimization approach
KW  - discrete-optimization method
KW  - joint-angles
KW  - robot motion translation problem
KW  - discrete-space graph-search problem
KW  - nonlinear optimization
KW  - dynamic-programming algorithm
KW  - configuration space
KW  - diversity sampling
KW  - robot arm trajectories
KW  - Stampede
KW  - end-effector path function
KW  - pathwise-inverse kinematics
KW  - per-frame inverse kinematics
KW  - collision-free robot motions
KW  - 6-DOF Cartesian-space end-effector paths
KW  - End effectors
KW  - Kinematics
KW  - Robot motion
KW  - Planning
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793617
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a discrete-optimization technique for finding feasible robot arm trajectories that pass through provided 6-DOF Cartesian-space end-effector paths with high accuracy, a problem called pathwise-inverse kinematics. The output from our method consists of a path function of joint-angles that best follows the provided end-effector path function, given some definition of “best”. Our method, called Stampede, casts the robot motion translation problem as a discrete-space graph-search problem where the nodes in the graph are individually solved for using non-linear optimization; framing the problem in such a way gives rise to a well-structured graph that affords an effective best path calculation using an efficient dynamic-programming algorithm. We present techniques for sampling configuration space, such as diversity sampling and adaptive sampling, to construct the search-space in the graph. Through an evaluation, we show that our approach performs well in finding smooth, feasible, collision-free robot motions that match the input end-effector trace with very high accuracy, while alternative approaches, such as a state-of-the-art per-frame inverse kinematics solver and a global non-linear trajectory-optimization approach, performed unfavorably.
ER  - 

TY  - CONF
TI  - Reconstructing Human Hand Pose and Configuration using a Fixed-Base Exoskeleton
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3514
EP  - 3520
AU  - A. Pereira
AU  - G. Stillfried
AU  - T. Baker
AU  - A. Schmidt
AU  - A. Maier
AU  - B. Pleintinger
AU  - Z. Chen
AU  - T. Hulin
AU  - N. Y. Lii
PY  - 2019
KW  - augmented reality
KW  - biomechanics
KW  - biomedical MRI
KW  - image reconstruction
KW  - medical image processing
KW  - medical robotics
KW  - telemedicine
KW  - telerobotics
KW  - virtual reality
KW  - augmented reality
KW  - teleoperation
KW  - virtual reality
KW  - force-feedback
KW  - motion capture
KW  - MRI data
KW  - fixed-base hand exoskeleton
KW  - joint angles
KW  - dexterous haptic input device
KW  - fixed-base exoskeleton
KW  - human hand pose
KW  - Exoskeletons
KW  - Kinematics
KW  - Thumb
KW  - Robot kinematics
KW  - Magnetic resonance imaging
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8794059
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate real-time estimation of the pose and configuration of the human hand attached to a dexterous haptic input device is crucial to improve the interaction possibilities for teleoperation and in virtual and augmented reality. In this paper, we present an approach to reconstruct the pose of the human hand and the joint angles of the fingers when wearing a novel fixed-base (grounded) hand exoskeleton. Using a kinematic model of the human hand built from MRI data, we can reconstruct the hand pose and joint angles without sensors on the human hand, from attachment points on the first three fingers and the palm. We test the accuracy of our approach using motion capture as a ground truth. This reconstruction can be used to determine contact geometry and force-feedback from virtual or remote objects in virtual reality or teleoperation.
ER  - 

TY  - CONF
TI  - Learning Pose Estimation for High-Precision Robotic Assembly Using Simulated Depth Images
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3521
EP  - 3527
AU  - Y. Litvak
AU  - A. Biess
AU  - A. Bar-Hillel
PY  - 2019
KW  - CAD
KW  - cameras
KW  - convolutional neural nets
KW  - end effectors
KW  - industrial manipulators
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - production engineering computing
KW  - robot vision
KW  - robotic assembly
KW  - 3D CAD models
KW  - depth camera
KW  - deep convolutional neural networks
KW  - industrial robotic assembly tasks
KW  - depth images
KW  - pose estimation learning
KW  - two-stage pose estimation procedure
KW  - end-effector
KW  - Conferences
KW  - Automation
DO  - 10.1109/ICRA.2019.8794226
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Most of industrial robotic assembly tasks today require fixed initial conditions for successful assembly. These constraints induce high production costs and low adaptability to new tasks. In this work we aim towards flexible and adaptable robotic assembly by using 3D CAD models for all parts to be assembled. We focus on a generic assembly task - the Siemens Innovation Challenge - in which a robot needs to assemble a gear-like mechanism with high precision into an operating system. To obtain the millimeter-accuracy required for this task and industrial settings alike, we use a depth camera mounted near the robot's end-effector. We present a high-accuracy two-stage pose estimation procedure based on deep convolutional neural networks, which includes detection, pose estimation, refinement, and handling of near- and full symmetries of parts. The networks are trained on simulated depth images with means to ensure successful transfer to the real robot. We obtain an average pose estimation error of 2.16 millimeters and 0.64 degree leading to 91% success rate for robotic assembly of randomly distributed parts. To the best of our knowledge, this is the first time that the Siemens Innovation Challenge is fully addressed, with all the parts assembled with high success rates.
ER  - 

TY  - CONF
TI  - Aided Inertial Navigation: Unified Feature Representations and Observability Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3528
EP  - 3534
AU  - Y. Yang
AU  - G. Huang
PY  - 2019
KW  - inertial navigation
KW  - Jacobian matrices
KW  - Monte Carlo methods
KW  - observability
KW  - global yaw rotation
KW  - line features
KW  - closest point parameterization
KW  - observability properties
KW  - unified representations
KW  - closest point form
KW  - unified parameterizations
KW  - CP representations
KW  - EKF-based vision-aided INS
KW  - geometrical features
KW  - unified feature representations
KW  - aided inertial navigation systems
KW  - homogeneous geometric features
KW  - general aided INS
KW  - linearized aided INS
KW  - minimal representation
KW  - observability analysis
KW  - 4D Euclidean vector
KW  - analytically-computed Jacobians
KW  - Monte-Carlo simulations
KW  - Observability
KW  - Quaternions
KW  - Jacobian matrices
KW  - Noise measurement
KW  - Pollution measurement
KW  - Three-dimensional displays
KW  - Q measurement
DO  - 10.1109/ICRA.2019.8793507
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Extending our recent work [1] that focuses on the observability analysis of aided inertial navigation systems (INS) using homogeneous geometric features including points, lines and planes, in this paper, we complete the analysis for the general aided INS using different combinations of geometric features (i.e., points, lines and planes). We analytically show that the linearized aided INS with different feature combinations generally possesses the same observability properties as those with same features, i.e., 4 unobservable directions, corresponding to the global yaw rotation and the global position of the sensor platform. During the analysis, we particularly propose a novel minimal representation of line features, i.e., the “closest point” parameterization, which uses a 4D Euclidean vector to describe a line and is proved to preserve the same observability properties. Based on that, for the first time, we provide two sets of unified representations for points, lines and planes, i.e., the quaternion form and the closest point (CP) form, and perform extensive observability analysis with analytically-computed Jacobians for these unified parameterizations. We validate the proposed CP representations and observability analysis with Monte-Carlo simulations, in which EKF-based vision-aided INS (VINS) with combinations of geometrical features in CP form are developed and compared.
ER  - 

TY  - CONF
TI  - A Linear-Complexity EKF for Visual-Inertial Navigation with Loop Closures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3535
EP  - 3541
AU  - P. Geneva
AU  - K. Eckenhoff
AU  - G. Huang
PY  - 2019
KW  - computational complexity
KW  - correlation methods
KW  - inertial navigation
KW  - Kalman filters
KW  - mobile robots
KW  - nonlinear filters
KW  - robot vision
KW  - SLAM (robots)
KW  - Schmidt-MSCKF
KW  - real-time visual-inertial navigation
KW  - bounded-error performance
KW  - robotic applications
KW  - visual-inertial localization
KW  - loop closure constraints
KW  - long-term persistent navigation
KW  - Schmidt-Kalman formulation
KW  - multistate constraint Kalman filter framework
KW  - state vector
KW  - linear-complexity EKF
KW  - cross-correlations
KW  - navigation states
KW  - computational complexity
KW  - performance improvement
KW  - Navigation
KW  - Microsoft Windows
KW  - Standards
KW  - Current measurement
KW  - Real-time systems
KW  - Trajectory
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793836
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Enabling real-time visual-inertial navigation in unknown environments while achieving bounded-error performance holds great potentials in robotic applications. To this end, in this paper, we propose a novel linear-complexity EKF for visual-inertial localization, which can efficiently utilize loop closure constraints, thus allowing for long-term persistent navigation. The key idea is to adapt the Schmidt-Kalman formulation within the multi-state constraint Kalman filter (MSCKF) framework, in which we selectively include keyframes as nuisance parameters in the state vector for loop closures but do not update their estimates and covariance in order to save computations while still tracking their cross-correlations with the current navigation states. As a result, the proposed Schmidt-MSCKF has only O(n) computational complexity while still incorporating loop closures into the system. The proposed approach is validated extensively on large-scale real-world experiments, showing significant performance improvements when compared to the standard MSCKF, while only incurring marginal computational overhead.
ER  - 

TY  - CONF
TI  - Sensor-Failure-Resilient Multi-IMU Visual-Inertial Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3542
EP  - 3548
AU  - K. Eckenhoff
AU  - P. Geneva
AU  - G. Huang
PY  - 2019
KW  - calibration
KW  - inertial navigation
KW  - sensor fusion
KW  - sensor-failure-resilient multiIMU visual-inertial navigation
KW  - real-time multiIMU visual-inertial navigation system
KW  - multiple inertial measurement units
KW  - mi-VINS formulation
KW  - auxiliary sensors
KW  - base IMU failure
KW  - sensor failure
KW  - conventional VINS
KW  - multiple IMUs
KW  - Calibration
KW  - Cameras
KW  - Robot sensing systems
KW  - Navigation
KW  - Covariance matrices
KW  - Fuses
KW  - Visualization
DO  - 10.1109/ICRA.2019.8794295
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a real-time multi-IMU visual-inertial navigation system (mi-VINS) that utilizes the information from multiple inertial measurement units (IMUs) and thus is resilient to IMU sensor failures. In particular, in the proposed mi-VINS formulation, one of the IMUs serves as the “base” of the system, while the rest act as auxiliary sensors aiding in state estimation. A key advantage of this architecture is the ability to seamlessly “promote” an auxiliary IMU as a new base, for example, upon detection of the base IMU failure, thus being resilient to the single point of sensor failure as seen in conventional VINS. Moreover, in order to properly fuse the information of multiple IMUs, both the spatial (relative pose) and temporal (time offset) calibration parameters between each sensor and the base IMU are estimated online. The proposed miVINS with online spatial and temporal calibration is validated in both simulations and real-world experiments, and is shown to be able to provide accurate localization and calibration even in scenarios with IMU sensor failures.
ER  - 

TY  - CONF
TI  - Learning Monocular Visual Odometry through Geometry-Aware Curriculum Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3549
EP  - 3555
AU  - M. R. U. Saputra
AU  - P. P. B. de Gusmao
AU  - S. Wang
AU  - A. Markham
AU  - N. Trigoni
PY  - 2019
KW  - distance measurement
KW  - image sequences
KW  - learning (artificial intelligence)
KW  - pose estimation
KW  - recurrent neural nets
KW  - regression analysis
KW  - windowed composition layer
KW  - CL-VO
KW  - learning monocular visual odometry
KW  - optical flow network
KW  - geometry-aware objective function
KW  - complex geometry problems
KW  - geometry-aware Curriculum Learning
KW  - Training
KW  - Geometry
KW  - Cameras
KW  - Task analysis
KW  - Estimation
KW  - Feature extraction
KW  - Optical fiber networks
DO  - 10.1109/ICRA.2019.8793581
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Inspired by the cognitive process of humans and animals, Curriculum Learning (CL) trains a model by gradually increasing the difficulty of the training data. In this paper, we study whether CL can be applied to complex geometry problems like estimating monocular Visual Odometry (VO). Unlike existing CL approaches, we present a novel CL strategy for learning the geometry of monocular VO by gradually making the learning objective more difficult during training. To this end, we propose a novel geometry-aware objective function by jointly optimizing relative and composite transformations over small windows via bounded pose regression loss. A cascade optical flow network followed by recurrent network with a differentiable windowed composition layer, termed CL-VO, is devised to learn the proposed objective. Evaluation on three real-world datasets shows superior performance of CL-VO over state-of-the-art feature-based and learning-based VO.
ER  - 

TY  - CONF
TI  - Visual-Odometric Localization and Mapping for Ground Vehicles Using SE(2)-XYZ Constraints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3556
EP  - 3562
AU  - F. Zheng
AU  - Y. Liu
PY  - 2019
KW  - feature extraction
KW  - graph theory
KW  - mobile robots
KW  - motion control
KW  - object detection
KW  - path planning
KW  - road vehicles
KW  - robot vision
KW  - ground vehicle
KW  - odometric sensors
KW  - monocular visual sensors
KW  - stochastic constraint
KW  - odometric measurement processing
KW  - visual-odometric localization
KW  - mapping system
KW  - out-of SE(2) motion perturbation
KW  - SE(2)-XYZ constraint
KW  - image feature measurement
KW  - preintegration algorithm
KW  - graph optimization structure
KW  - Visualization
KW  - Optimization
KW  - Land vehicles
KW  - Perturbation methods
KW  - Robots
KW  - Jacobian matrices
KW  - Sensors
DO  - 10.1109/ICRA.2019.8793928
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper focuses on the localization and mapping problem on ground vehicles using odometric and monocular visual sensors. To improve the accuracy of vision based estimation on ground vehicles, researchers have exploited the constraint of approximately planar motion, and usually implemented it as a stochastic constraint on an SE(3) pose. In this paper, we propose a simpler algorithm that directly parameterizes the ground vehicle poses on SE(2). The out-of SE(2) motion perturbations are not neglected, but incorporated into an integrated noise term of a novel SE(2)-XYZ constraint, which associates an SE(2) pose and a 3D landmark via the image feature measurement. For odometric measurement processing, we also propose an efficient preintegration algorithm on SE(2). Utilizing these constraints, a complete visual-odometric localization and mapping system is developed, in a commonly used graph optimization structure. Its superior performance in accuracy and robustness is validated by real-world experiments in industrial indoor environments.
ER  - 

TY  - CONF
TI  - Keyframe-based Direct Thermal–Inertial Odometry
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3563
EP  - 3569
AU  - S. Khattak
AU  - C. Papachristos
AU  - K. Alexis
PY  - 2019
KW  - cameras
KW  - distance measurement
KW  - Global Positioning System
KW  - inertial navigation
KW  - measurement errors
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - radiometry
KW  - sensor fusion
KW  - temperature measurement
KW  - temperature sensors
KW  - keyframe-based direct thermal-inertial odometry
KW  - thermal camera
KW  - inertial measurements
KW  - airborne obscurants
KW  - fog
KW  - smoke
KW  - optimization based approach
KW  - inertial measurement errors
KW  - GPS
KW  - direct radiometric data fusion
KW  - aerial robotic capabilities
KW  - visually degraded environments
KW  - reprojection error minimisation
KW  - 3D landmark error
KW  - indoor laboratory setting
KW  - underground mine
KW  - Cameras
KW  - Robot vision systems
KW  - Radiometry
KW  - Estimation
KW  - Unmanned aerial vehicles
KW  - Optimization
DO  - 10.1109/ICRA.2019.8793927
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes an approach for fusing direct radiometric data from a thermal camera with inertial measurements to extend the robotic capabilities of aerial robots for navigation in GPS-denied and visually degraded environments in the conditions of darkness and in the presence of airborne obscurants such as dust, fog and smoke. An optimization based approach is developed that jointly minimizes the re-projection error of 3D landmarks and inertial measurement errors. The developed solution is extensively verified against both ground-truth in an indoor laboratory setting, as well as inside an underground mine under severely visually degraded conditions.
ER  - 

TY  - CONF
TI  - On Parameter Estimation of Space Manipulator Systems with Flexible Joints Using the Energy Balance*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3570
EP  - 3576
AU  - K. Nanos
AU  - E. Papadopoulos
PY  - 2019
KW  - aerospace robotics
KW  - damping
KW  - flexible manipulators
KW  - manipulator dynamics
KW  - mobile robots
KW  - motion control
KW  - parameter estimation
KW  - path planning
KW  - manipulators
KW  - joint flexibilities
KW  - path planning
KW  - tracking capabilities
KW  - system inertial parameters
KW  - damping parameters
KW  - space flexible-joint manipulator system
KW  - system full dynamics
KW  - space manipulator systems
KW  - flexible joints
KW  - stiffness parameters
KW  - parameter estimation
KW  - Mathematical model
KW  - Space vehicles
KW  - Manipulator dynamics
KW  - Parameter estimation
KW  - Damping
KW  - Estimation
DO  - 10.1109/ICRA.2019.8793960
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The parameter estimation of space manipulator systems on orbit is studied, whose manipulators are subject to joint flexibilities. To improve path planning and tracking capabilities, advanced control strategies that benefit from the knowledge of system parameters are required. These parameters include the system inertial parameters as well as the stiffness and damping parameters, which describe joint flexibilities. During operation some of these parameters may change or be unknown. Estimation methods based on the equations of motion are sensitive to noise, while methods based on the angular momentum conservation, while they are tolerant to noise, they cannot estimate the parameters that describe joint flexibilities. A parameter estimation method, based on the energy balance, applied during the motion of a space flexible-joint manipulator system in the free-floating mode, is developed. The method is tolerant to noise and can reconstruct the system full dynamics. It is shown that the parameters estimated by the proposed method can describe the system dynamics fully. The application of the developed method is valid for spatial systems; it is illustrated by a planar 7 degrees of freedom (DoF) example system.
ER  - 

TY  - CONF
TI  - Central Pattern Generators Control of Momentum Driven Compliant Structures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3585
EP  - 3591
AU  - S. Bonardi
AU  - J. Romanishin
AU  - D. Rus
AU  - T. Kubota
PY  - 2019
KW  - actuators
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - robot dynamics
KW  - co-evolved structures
KW  - control-only optimized equivalent
KW  - MDS
KW  - inertially actuated units
KW  - compliant elements
KW  - control method
KW  - bio-inspired concept
KW  - compliance distribution
KW  - locomotion performance
KW  - population based optimization techniques
KW  - momentum driven compliant structures
KW  - central pattern generator control
KW  - hardware complexity
KW  - CPG
KW  - rough environment exploration
KW  - Robots
KW  - Torque
KW  - Three-dimensional displays
KW  - Complexity theory
KW  - Generators
KW  - Aerospace electronics
KW  - Space exploration
DO  - 10.1109/ICRA.2019.8793806
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We introduce the concept of Momentum Driven Structures (MDS) made of inertially actuated units linked together by compliant elements as a potential solution for rough environments exploration. We propose a control method for MDS based on the bio-inspired concept of Central Pattern Generator (CPG) and study in simulation the impact of compliance distribution on locomotion performance using population based optimization techniques. Our results suggest that compliant structures outperform their rigid counterparts in terms of distance traveled. In addition, we show that co-evolved structures perform only marginally better than their control-only optimized equivalent, highlighting the fact that compliance modulation may not be a significant asset in such experiments, considering the related hardware complexity it introduces.
ER  - 

TY  - CONF
TI  - Contact-Event-Triggered Mode Estimation for Dynamic Rigid Body Impedance-Controlled Capture
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3600
EP  - 3606
AU  - H. Kato
AU  - D. Hirano
AU  - J. Ota
PY  - 2019
KW  - aerospace robotics
KW  - force control
KW  - mobile robots
KW  - particle filtering (numerical methods)
KW  - position control
KW  - sensors
KW  - contact-event-triggered mode estimation
KW  - dynamic rigid body impedance-controlled capture
KW  - contact-event-triggered filter
KW  - impedance control
KW  - particle filter
KW  - sliding contact mode cases
KW  - force-torque sensor
KW  - air bearing robotic system
KW  - time 8.3 ms
KW  - time 4.2 ms
KW  - Robot sensing systems
KW  - Estimation
KW  - Collision avoidance
KW  - Impedance
KW  - Robot kinematics
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793677
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a contact-event-triggered filter using only a force-torque sensor with impedance control for non-cooperative, rotating, heavy object capture. Contact events are modeled for prediction, and detected to trigger the particle filter's updating process. By combining these features, a computationally efficient, contact-event-triggered filter is proposed. For our purpose of capture using impedance control, expected contact events, collisions and sliding are defined for prediction and detection. This novel method is implemented in an air bearing robotic system, and has demonstrated its superiority with the highest success rate (100%) for sliding contact mode cases, whereas the previous method could only yield a success rate of 87.9%. The computation resource is demonstrated to be limited, with a computation time of 4.2 milliseconds on average and 8.3 milliseconds at worst.
ER  - 

TY  - CONF
TI  - Leveraging Contact Forces for Learning to Grasp
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3615
EP  - 3621
AU  - H. Merzić
AU  - M. Bogdanović
AU  - D. Kappler
AU  - L. Righetti
AU  - J. Bohg
PY  - 2019
KW  - grippers
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - grasp acquisition
KW  - model-free deep reinforcement learning
KW  - control policies
KW  - contact sensing
KW  - robust grasping
KW  - multifingered hand
KW  - complex finger coordination
KW  - learned policies
KW  - grasping policies
KW  - contact feedback
KW  - open problem
KW  - robotics research
KW  - noisy observations
KW  - sensor feedback
KW  - visual feedback
KW  - contact forces
KW  - Grasping
KW  - Robot sensing systems
KW  - Uncertainty
KW  - Visualization
KW  - Grippers
DO  - 10.1109/ICRA.2019.8793733
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Grasping objects under uncertainty remains an open problem in robotics research. This uncertainty is often due to noisy or partial observations of the object pose or shape. To enable a robot to react appropriately to unforeseen effects, it is crucial that it continuously takes sensor feedback into account. While visual feedback is important for inferring a grasp pose and reaching for an object, contact feedback offers valuable information during manipulation and grasp acquisition. In this paper, we use model-free deep reinforcement learning to synthesize control policies that exploit contact sensing to generate robust grasping under uncertainty. We demonstrate our approach on a multi-fingered hand that exhibits more complex finger coordination than the commonly used two-fingered grippers. We conduct extensive experiments in order to assess the performance of the learned policies, with and without contact sensing. While it is possible to learn grasping policies without contact sensing, our results suggest that contact feedback allows for a significant improvement of grasping robustness under object pose uncertainty and for objects with a complex shape.
ER  - 

TY  - CONF
TI  - Learning Latent Space Dynamics for Tactile Servoing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3622
EP  - 3628
AU  - G. Sutanto
AU  - N. Ratliff
AU  - B. Sundaralingam
AU  - Y. Chebotar
AU  - Z. Su
AU  - A. Handa
AU  - D. Fox
PY  - 2019
KW  - dexterous manipulators
KW  - feedback
KW  - haptic interfaces
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - tactile sensors
KW  - tactile servoing
KW  - tactile sensing information
KW  - tactile skin geometry
KW  - tactile finger
KW  - dexterous robotic manipulation
KW  - tactile feedback capability
KW  - latent space dynamics learning
KW  - contact point tracking
KW  - manifold learning
KW  - Robot sensing systems
KW  - Skin
KW  - Aerospace electronics
KW  - Two dimensional displays
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793520
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - To achieve a dexterous robotic manipulation, we need to endow our robot with tactile feedback capability, i.e. the ability to drive action based on tactile sensing. In this paper, we specifically address the challenge of tactile servoing, i.e. given the current tactile sensing and a target/goal tactile sensing - memorized from a successful task execution in the past - what is the action that will bring the current tactile sensing to move closer towards the target tactile sensing at the next time step. We develop a data-driven approach to acquire a dynamics model for tactile servoing by learning from demonstration. Moreover, our method represents the tactile sensing information as to lie on a surface - or a 2D manifold - and perform a manifold learning, making it applicable to any tactile skin geometry. We evaluate our method on a contact point tracking task using a robot equipped with a tactile finger.
ER  - 

TY  - CONF
TI  - PointNetGPD: Detecting Grasp Configurations from Point Sets
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3629
EP  - 3635
AU  - H. Liang
AU  - X. Ma
AU  - S. Li
AU  - M. Görner
AU  - S. Tang
AU  - B. Fang
AU  - F. Sun
AU  - J. Zhang
PY  - 2019
KW  - computational geometry
KW  - feature extraction
KW  - grippers
KW  - image colour analysis
KW  - learning (artificial intelligence)
KW  - PointNetGPD
KW  - end-to-end grasp evaluation
KW  - object grasping
KW  - 3D point cloud
KW  - grasp configuration detection
KW  - point sets
KW  - robot grasp configurations
KW  - complex geometric structure
KW  - gripper
KW  - 3D geometry information
KW  - deep neural network
KW  - RGB-D camera
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Measurement
KW  - Grippers
KW  - Grasping
KW  - Solid modeling
KW  - Geometry
DO  - 10.1109/ICRA.2019.8794435
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose an end-to-end grasp evaluation model to address the challenging problem of localizing robot grasp configurations directly from the point cloud. Compared to recent grasp evaluation metrics that are based on handcrafted depth features and a convolutional neural network (CNN), our proposed PointNetGPD is lightweight and can directly process the 3D point cloud that locates within the gripper for grasp evaluation. Taking the raw point cloud as input, our proposed grasp evaluation network can capture the complex geometric structure of the contact area between the gripper and the object even if the point cloud is very sparse. To further improve our proposed model, we generate a large-scale grasp dataset with 350k real point cloud and grasps with the YCB object set for training. The performance of the proposed model is quantitatively measured both in simulation and on robotic hardware. Experiments on object grasping and clutter removal show that our proposed model generalizes well to novel objects and outperforms state-of-the-art methods. Code and video are available at https://lianghongzhuo.github.io/PointNetGPD.
ER  - 

TY  - CONF
TI  - Learning Deep Visuomotor Policies for Dexterous Hand Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3636
EP  - 3643
AU  - D. Jain
AU  - A. Li
AU  - S. Singhal
AU  - A. Rajeswaran
AU  - V. Kumar
AU  - E. Todorov
PY  - 2019
KW  - dexterous manipulators
KW  - learning (artificial intelligence)
KW  - tactile sensors
KW  - touch sensing information
KW  - expert demonstration trajectories
KW  - high dimensional visual observations
KW  - manipulation tasks
KW  - imitation learning
KW  - on-board sensors
KW  - tactile sensors
KW  - external tracking
KW  - on-board sensing capabilities
KW  - in-hand manipulation
KW  - multifingered dexterous hands
KW  - dexterous hand manipulation
KW  - deep visuomotor policies
KW  - Task analysis
KW  - Visualization
KW  - Training
KW  - Tactile sensors
DO  - 10.1109/ICRA.2019.8794033
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Multi-fingered dexterous hands are versatile and capable of acquiring a diverse set of skills such as grasping, in-hand manipulation, and tool use. To fully utilize their versatility in real-world scenarios, we require algorithms and policies that can control them using on-board sensing capabilities, without relying on external tracking or motion capture systems. Cameras and tactile sensors are the most widely used on-board sensors that do not require instrumentation of the world. In this work, we demonstrate an imitation learning based approach to train deep visuomotor policies for a variety of manipulation tasks with a simulated five fingered dexterous hand. These policies directly control the hand using high dimensional visual observations of the world and propreoceptive observations from the robot, and can be trained efficiently with a few hundred expert demonstration trajectories. We also find that using touch sensing information enables faster learning and better asymptotic performance for tasks with high degree of occlusions. Video demonstration of our results are available at: https://sites.google.com/view/hand-vil/.
ER  - 

TY  - CONF
TI  - Learning to Identify Object Instances by Touch: Tactile Recognition via Multimodal Matching
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3644
EP  - 3650
AU  - J. Lin
AU  - R. Calandra
AU  - S. Levine
PY  - 2019
KW  - image recognition
KW  - object recognition
KW  - tactile sensors
KW  - visual modality
KW  - global observation
KW  - robotic manipulation
KW  - visual object identification
KW  - touch-based instance recognition
KW  - multimodal recognition
KW  - visual observation
KW  - tactile observation
KW  - multimodal instance recognition problem
KW  - GelSight touch sensors
KW  - autonomous data collection procedure
KW  - tactile observations
KW  - tactile recognition
KW  - robotic perception
KW  - Visualization
KW  - Cameras
KW  - Grippers
KW  - Tactile sensors
KW  - Data collection
DO  - 10.1109/ICRA.2019.8793885
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Much of the literature on robotic perception focuses on the visual modality. Vision provides a global observation of a scene, making it broadly useful. However, in the domain of robotic manipulation, vision alone can sometimes prove inadequate: in the presence of occlusions or poor lighting, visual object identification might be difficult. The sense of touch can provide robots with an alternative mechanism for recognizing objects. In this paper, we study the problem of touch-based instance recognition. We propose a novel framing of the problem as multi-modal recognition: the goal of our system is to recognize, given a visual and tactile observation, whether or not these observations correspond to the same object. To our knowledge, our work is the first to address this type of multi-modal instance recognition problem on such a large-scale with our analysis spanning 98 different objects. We employ a robot equipped with two GelSight touch sensors, one on each finger, and a self-supervised, autonomous data collection procedure to collect a dataset of tactile observations and images. Our experimental results show that it is possible to accurately recognize object instances by touch alone, including instances of novel objects that were never seen during training. Our learned model outperforms other methods on this complex task, including that of human volunteers.
ER  - 

TY  - CONF
TI  - Dexterous Manipulation with Deep Reinforcement Learning: Efficient, General, and Low-Cost
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3651
EP  - 3657
AU  - H. Zhu
AU  - A. Gupta
AU  - A. Rajeswaran
AU  - S. Levine
AU  - V. Kumar
PY  - 2019
KW  - control engineering computing
KW  - dexterous manipulators
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - robot programming
KW  - deep reinforcement learning
KW  - multifingered hands
KW  - contact-rich manipulation behavior
KW  - model-free deep RL algorithms
KW  - complex multifingered manipulation skills
KW  - direct deep RL training
KW  - model-based control
KW  - dexterous manipulation
KW  - dexterous multifingered robotic hands
KW  - general-purpose robotic manipulators
KW  - autonomous control
KW  - complex intermittent contact interactions
KW  - Task analysis
KW  - Valves
KW  - Acceleration
KW  - Reinforcement learning
KW  - Robot sensing systems
KW  - Hardware
DO  - 10.1109/ICRA.2019.8794102
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dexterous multi-fingered robotic hands can perform a wide range of manipulation skills, making them an appealing component for general-purpose robotic manipulators. However, such hands pose a major challenge for autonomous control, due to the high dimensionality of their configuration space and complex intermittent contact interactions. In this work, we propose deep reinforcement learning (deep RL) as a scalable solution for learning complex, contact rich behaviors with multi-fingered hands. Deep RL provides an end-to-end approach to directly map sensor readings to actions, without the need for task specific models or policy classes. We show that contact-rich manipulation behavior with multi-fingered hands can be learned by directly training with model-free deep RL algorithms in the real world, with minimal additional assumption and without the aid of simulation. We learn to perform a variety of tasks on two different low-cost hardware platforms entirely from scratch, and further study how the learning can be accelerated by using a small number of human demonstrations. Our experiments demonstrate that complex multi-fingered manipulation skills can be learned in the real world in about 4-7 hours for most tasks, and that demonstrations can decrease this to 2-3 hours, indicating that direct deep RL training in the real world is a viable and practical alternative to simulation and model-based control. https:// sites.google.com/view/deeprl-handmanipulation.
ER  - 

TY  - CONF
TI  - Inkjet Printable Actuators and Sensors for Soft-bodied Crawling Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3658
EP  - 3664
AU  - T. D. Ta
AU  - T. Umedachi
AU  - Y. Kawahara
PY  - 2019
KW  - actuators
KW  - angular measurement
KW  - ink jet printing
KW  - mobile robots
KW  - nanoparticles
KW  - nonlinear control systems
KW  - plastics
KW  - silver
KW  - temperature measurement
KW  - temperature sensors
KW  - thin film sensors
KW  - all-printed paper caterpillar robots
KW  - inkjet printable actuator
KW  - rigid sensor-actuators
KW  - soft-bodied crawling robot design
KW  - nanoparticle ink printing
KW  - flexible plastic film
KW  - bending sensors
KW  - thermal based actuators
KW  - home-commodity inkjet printers
KW  - Actuators
KW  - Heating systems
KW  - Ink
KW  - Silver
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793827
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft-bodied robots are getting attention from researchers as their potential in designing compliant and adaptive robots. However, soft-bodied robots also pose many challenges not only in non-linear controlling but also in design and fabrication. Especially, the non-compatibility between soft materials and rigid sensors/actuators makes it more difficult to design a fully compliant soft-bodied robot. In this paper, we propose an all-printed sensor and actuator for designing soft-bodied robots by printing silver nano-particle ink on top of a flexible plastic film. We can print bending sensors and thermal based actuators instantly with home-commodity inkjet printers without any pre/post-processing. We exemplify the application of this fabrication method with an all-printed paper caterpillar robots which can inch forward and sense its body bending angle.
ER  - 

TY  - CONF
TI  - Design and Evaluation of an Energy-Saving Drive for a Versatile Robotic Gripper
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3665
EP  - 3671
AU  - J. Neven
AU  - M. Baioumy
AU  - W. Wolfslag
AU  - M. Wisse
PY  - 2019
KW  - actuators
KW  - dexterous manipulators
KW  - energy conservation
KW  - energy consumption
KW  - grippers
KW  - motion control
KW  - path planning
KW  - energy-saving drive
KW  - robotic grippers
KW  - energy consumption
KW  - energy-savings
KW  - energy-neutral grippers
KW  - robotic energy-efficient drive
KW  - grip performance metric
KW  - nonbackdrivable mechanism
KW  - statically balanced force amplifier
KW  - SBFA
KW  - NBDM
KW  - Grippers
KW  - Force
KW  - Measurement
KW  - Robots
KW  - Energy consumption
KW  - Task analysis
KW  - Springs
DO  - 10.1109/ICRA.2019.8793723
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The main task of robotic grippers, holding an object, does not require work theoretically. Yet grippers consume significant amounts of energy in practice. This paper presents an approach for designing an energy-saving drive for robotic grippers employing a Statically Balanced Force Amplifier (SBFA) and a Non-backdrivable mechanism (NBDM). A novel metric (Grip Performance Metric) to systematically evaluate drives regarding their energy consumption, is used in the design phase; afterwards, the realization and testing of a prototype (REED, Robotic Energy-Efficient Drive) are presented. Results show that the actuation force can be reduced by 92%, resulting in energy-savings of 86% for an example task. This shows the potential of drives based on SBFAs and NBDMs to achieve energy-neutral grippers.
ER  - 

TY  - CONF
TI  - Generative Deformation: Procedural Perforation for Elastic Structures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3672
EP  - 3678
AU  - S. Transue
AU  - M. Choi
PY  - 2019
KW  - deformation
KW  - elasticity
KW  - finite element analysis
KW  - solid modelling
KW  - stress analysis
KW  - three-dimensional printing
KW  - generative deformation
KW  - procedural perforation
KW  - elastic structures
KW  - procedural generation
KW  - controlling designing 3D printed deformable object behaviors
KW  - generative algorithms
KW  - cohesive process
KW  - variable elasticity
KW  - automated method
KW  - simulated deformations
KW  - cohesive pipeline model
KW  - volumetric structures
KW  - stress analysis
KW  - consumer-level 3D printers
KW  - finite element analysis metrics
KW  - elastic 3D prints
KW  - design objectives
KW  - elastic material behaviors
KW  - heterogeneous geometric structure
KW  - 3D print deformations
KW  - automated pipeline
KW  - design environment
KW  - perforated deformation models
KW  - heterogeneous lattice structures
KW  - automated generation
KW  - 3D print procedure
KW  - elastic material capabilities
KW  - Three-dimensional displays
KW  - Strain
KW  - Deformable models
KW  - Stress
KW  - Pipelines
KW  - Solid modeling
KW  - Printers
DO  - 10.1109/ICRA.2019.8793883
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Procedural generation of elastic structures provides the fundamental basis for controlling and designing 3D printed deformable object behaviors. The automation through generative algorithms provides flexibility in how design and functionality can be seamlessly integrated into a cohesive process that generates 3D prints with variable elasticity. Generative deformation introduces an automated method for perforating existing volumetric structures, promoting simulated deformations, and integrating stress analysis into a cohesive pipeline model that can be used with existing consumer-level 3D printers with elastic material capabilities. In this work, we present a consolidated implementation of the design, simulate, refine, and 3D print procedure based on the automated generation of heterogeneous lattice structures. We utilize Finite Element Analysis (FEA) metrics to generate perforated deformation models that adhere to deformation behaviors created within our design environment. We present the core algorithms, automated pipeline, and 3D print deformations of various objects. Quantitative results illustrate how the heterogeneous geometric structure can influence elastic material behaviors towards design objectives. Our method provides an automated open-source tool for quickly prototyping elastic 3D prints.
ER  - 

TY  - CONF
TI  - Robotics Education and Research at Scale: A Remotely Accessible Robotics Development Platform
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3679
EP  - 3685
AU  - W. Wiedmeyer
AU  - M. Mende
AU  - D. Hartmann
AU  - R. Bischoff
AU  - C. Ledermann
AU  - T. Kroger
PY  - 2019
KW  - control engineering computing
KW  - educational robots
KW  - laboratories
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - research and development
KW  - telerobotics
KW  - remotely accessible robotics development platform
KW  - KUKA Robot Learning Lab
KW  - industrial lightweight robots
KW  - Service robots
KW  - Robot sensing systems
KW  - Robot learning
KW  - Mobile robots
KW  - Collision avoidance
KW  - Hardware
DO  - 10.1109/ICRA.2019.8793976
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces the KUKA Robot Learning Lab at KIT - a remotely accessible robotics testbed. The motivation behind the laboratory is to make state-of-the-art industrial lightweight robots more accessible for education and research. Such expensive hardware is usually not available to students or less privileged researchers to conduct experiments. This paper describes the design and operation of the Robot Learning Lab and discusses the challenges that one faces when making experimental robot cells remotely accessible. Especially safety and security must be ensured, while giving users as much freedom as possible when developing programs to control the robots. A fully automated and efficient processing pipeline for experiments makes the lab suitable for a large amount of users and allows a high usage rate of the robots.
ER  - 

TY  - CONF
TI  - Automated Seedling Height Assessment for Tree Nurseries Using Point Cloud Processing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3686
EP  - 3691
AU  - T. R. Wanasinghe
AU  - B. R. Dowden
AU  - O. D. Silva
AU  - G. K. I. Mann
AU  - C. Lundrigan
PY  - 2019
KW  - computer vision
KW  - forestry
KW  - height measurement
KW  - image sampling
KW  - solid modelling
KW  - stereo image processing
KW  - seedling measurement process
KW  - scanning laser profilometer
KW  - application specific point-cloud
KW  - point-cloud generation methods
KW  - 3D structured light sensing
KW  - light intensity detection
KW  - height measurement
KW  - measurement accuracy
KW  - measurement system
KW  - tree nurseries
KW  - point cloud processing
KW  - automated seedling height assessment system
KW  - offline identification
KW  - report generation
KW  - seedling development process
KW  - production optimization purposes
KW  - data samples
KW  - industrial scale operations
KW  - measurement sample size
KW  - measurement resolution
KW  - Centre for Agriculture and Forestry Development
KW  - Canada
KW  - Newfoundland and Labrador
KW  - Wooddale
KW  - Three-dimensional displays
KW  - Robot sensing systems
KW  - Measurement by laser beam
KW  - Control systems
KW  - Vegetation
KW  - Laser radar
DO  - 10.1109/ICRA.2019.8793790
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a prototype of an automated seedling height assessment system for tree nurseries. The proposed system can acquire and store real-time 3D point-cloud data of seedlings; and perform offline identification, measurement, and report generation of seedling heights with an overall system accuracy that meets a 5mm accuracy specification. Periodic growth information of seedlings allows quantifying effects of different factors on the overall seedling development process for research and production optimization purposes. However, current manual sampling approaches used at these facilities produce quite limited data samples, and the process is rather time-consuming and labor intensive for industrial scale operations. In contrast, the proposed system is capable of significantly increasing the measurement sample size, measurement resolution, and frequency of measurement by automating the seedling measurement process using a scanning laser profilometer and an application specific point-cloud processing algorithm. The performance of the proposed profilometry solution for point-cloud generation is compared with several other point-cloud generation methods such as a 3D structured light sensing, light intensity detection and ranging (LiDAR), stereovision, and photogrammetry. This comparison results demonstrate a superior performance of the laser-profilometer over other sensing solutions available for seedling height measurement. The proposed system is experimentally validated for its measurement accuracy and repeatability. The field-test of the measurement system was conducted at Centre for Agriculture and Forestry Development, Wooddale, Newfoundland and Labrador (NL), Canada, and the results demonstrate the practical applicability and technological readiness of the proposed system for field deployment.
ER  - 

TY  - CONF
TI  - Adsorption Pad using Capillary Force for Uneven Surface
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3692
EP  - 3697
AU  - A. Ichikawa
AU  - S. Kajino
AU  - A. Takeyama
AU  - Y. Adachi
AU  - K. Totsuka
AU  - Y. Ikemoto
AU  - K. Ohara
AU  - T. Oomichi
AU  - T. Fukuda
PY  - 2019
KW  - adsorption
KW  - capillarity
KW  - mobile robots
KW  - seals (stoppers)
KW  - porous part
KW  - capillary part
KW  - capillary force
KW  - uneven surface
KW  - irregular surface object
KW  - Super Wet Adsorption pad
KW  - wall climbing robot
KW  - SWA pad
KW  - salt reaching method
KW  - water sealing
KW  - Adsorption
KW  - Fabrication
KW  - Force
KW  - Robots
KW  - Wires
KW  - Business
KW  - Surface treatment
DO  - 10.1109/ICRA.2019.8793746
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a novel adsorption pad for wall climbing robot and irregular surface object using capillary force and water sealing. We call this adsorption pad as Super Wet Adsorption pad. The SWA pad has a porous part and a capillary part. The porous part is made by salt reaching method. When the SWA pad adsorbs to the wall which some sand and dust are attached, water comes from the porous part to avoid vacuum breaking. The capillary part is connected to the porous part to supply and stock the water. In this paper, we show the design of the porous part and the capillary part, fabrication process of each parts, and perform the evaluation experiment of the capillary force and adsorption of uneven surfaces, demonstration of wall climbing robot and adsorption of irregular surface foods.
ER  - 

TY  - CONF
TI  - Effects of Foot Stiffness and Damping on Walking Robot Performance
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3698
EP  - 3704
AU  - E. Schumann
AU  - N. Smit-Anseeuw
AU  - P. Zaytsev
AU  - R. Gleason
AU  - K. A. Shorter
AU  - C. D. Remy
PY  - 2019
KW  - damping
KW  - legged locomotion
KW  - robot dynamics
KW  - stability
KW  - foot stiffness
KW  - robot performance
KW  - damping properties
KW  - soft robotic feet
KW  - stability
KW  - energetic economy
KW  - bipedal robotic walking
KW  - hollow rubber
KW  - damping values
KW  - drop test rig
KW  - planar bipedal robot RAM
KW  - mechanical energy
KW  - walking speeds
KW  - foot properties
KW  - spherical feet
KW  - walking instability
KW  - Foot
KW  - Legged locomotion
KW  - Damping
KW  - Rubber
KW  - Soft robotics
KW  - Animals
DO  - 10.1109/ICRA.2019.8794050
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we investigated how the stiffness and damping properties of soft robotic feet affect the stability and energetic economy of bipedal robotic walking. To this end, we manufactured four different spherical feet from the following materials: hollow rubber, Sorbothane, Norsorex, and Neoprene. The materials were specifically chosen to cover a wide range of stiffness and damping values. The impact response of each design was first characterized in a drop test rig. We then evaluated the performance of each foot in an extensive series of walking experiments on the planar bipedal robot RAM one. Our results showed that, at low speeds, the feet with lower damping had a smaller energy cost of walking, possibly due to greater return of mechanical energy at lift-off. However, at speeds above 0.5m\s, the feet with lower damping started to exhibit a bouncing behaviour which led to higher walking instability and increased the energy cost of walking. Additionally, we found the feet with lower stiffness to be more economical across all walking speeds. Our results provide insight into the role of foot properties in bipedal walking and may help with the design of walking robots.
ER  - 

TY  - CONF
TI  - Dynamic Walking on Slippery Surfaces : Demonstrating Stable Bipedal Gaits with Planned Ground Slippage*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3705
EP  - 3711
AU  - W. Ma
AU  - Y. Or
AU  - A. D. Ames
PY  - 2019
KW  - legged locomotion
KW  - nonlinear control systems
KW  - optimisation
KW  - robot dynamics
KW  - stability
KW  - stick-slip
KW  - trajectory control
KW  - lubricated surface
KW  - rough no-slip surface
KW  - foot slippage
KW  - slippery surfaces
KW  - stable bipedal gaits
KW  - planned ground slippage
KW  - dynamic bipedal robot locomotion
KW  - trajectory generation
KW  - nonlinear control
KW  - stabilization
KW  - low-friction surfaces
KW  - outdoor terrains
KW  - trajectory optimization
KW  - stick-slip transitions
KW  - point foot contact
KW  - Coulomb's friction law
KW  - slippery walking gait
KW  - AMBER-3M planar biped robot
KW  - dynamic walking
KW  - robot stance foot
KW  - Legged locomotion
KW  - Foot
KW  - Friction
KW  - Dynamics
KW  - Rough surfaces
KW  - Surface roughness
DO  - 10.1109/ICRA.2019.8793761
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dynamic bipedal robot locomotion has achieved remarkable success due in part to recent advances in trajectory generation and nonlinear control for stabilization. A key assumption utilized in both theory and experiments is that the robot's stance foot always makes no-slip contact with the ground, including at impacts. This assumption breaks down on slippery low-friction surfaces, as commonly encountered in outdoor terrains, leading to failure and loss of stability. In this work, we extend the theoretical analysis and trajectory optimization to account for stick-slip transitions at point foot contact using Coulomb's friction law. Using AMBER-3M planar biped robot as an experimental platform, we demonstrate for the first time a slippery walking gait which can be stabilized successfully both on a lubricated surface and on a rough no-slip surface. We also study the influence of foot slippage on reducing the mechanical cost of transport, and compare energy efficiency in both numerical simulation and experimental measurement.
ER  - 

TY  - CONF
TI  - Torque and velocity controllers to perform jumps with a humanoid robot: theory and implementation on the iCub robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3712
EP  - 3718
AU  - F. Bergonti
AU  - L. Fiorio
AU  - D. Pucci
PY  - 2019
KW  - angular velocity control
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - optimisation
KW  - torque control
KW  - torque controller
KW  - velocity controller
KW  - velocity controllers
KW  - iCub robot
KW  - jumping
KW  - iCub humanoid robot
KW  - optimization
KW  - predefined CoM trajectory
KW  - centroidal angular momentum
KW  - Legged locomotion
KW  - Humanoid robots
KW  - Trajectory
KW  - Angular velocity
KW  - Optimization
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8794142
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Jumping can be an effective way of locomotion to overcome small terrain gaps or obstacles. In this paper we propose two different approaches to perform jumps with a humanoid robot. Specifically, starting from a pre-defined CoM trajectory we develop the theory for a velocity controller and for a torque controller based on an optimization technique for the evaluation of the joints input. The controllers have been tested both in simulation and on the humanoid robot iCub. In simulation the robot was able to jump using both controllers, while the real system jumped with the velocity controller only. The results highlight the importance of controlling the centroidal angular momentum and they suggest that the joint performances, namely maximum power, of the legs and torso joints, and the low level control performances are fundamental to achieve acceptable results.
ER  - 

TY  - CONF
TI  - Safe Adaptive Switching among Dynamical Movement Primitives: Application to 3D Limit-Cycle Walkers
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3719
EP  - 3725
AU  - S. Veer
AU  - I. Poulakakis
PY  - 2019
KW  - gait analysis
KW  - humanoid robots
KW  - legged locomotion
KW  - motion control
KW  - path planning
KW  - robot dynamics
KW  - safe adaptive switching
KW  - dynamical movement primitives
KW  - robot motion plans
KW  - 3D bipedal robot model
KW  - dynamic movement primitives
KW  - primitive movements
KW  - limit-cycle walking gait
KW  - control-theoretic tools
KW  - Switches
KW  - Limit-cycles
KW  - Safety
KW  - Task analysis
KW  - Legged locomotion
KW  - Dynamics
DO  - 10.1109/ICRA.2019.8793519
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Complex robot motions are frequently generated by composing simpler primitive movements. We use this approach to formulate robot motion plans as sequences of primitives to be executed one after the other. When dealing with dynamical movement primitives, besides accomplishing the high-level objective, planners must also reason about the effect of the plan's execution on the safety of the platform. This task is exacerbated by the presence of disturbances, such as non-vanishing external forces. To address this issue, we present a framework that builds on rigorous control-theoretic tools to generate safely executable motion plans for externally excited robotic systems. We illustrate the proposed framework on adapting the motion of a 3D bipedal robot model to persistent external forcing by switching among dynamic movement primitives, each corresponding to a limit-cycle walking gait.
ER  - 

TY  - CONF
TI  - Interactive Open-Ended Object, Affordance and Grasp Learning for Robotic Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3747
EP  - 3753
AU  - S. H. Kasaei
AU  - N. Shafii
AU  - L. S. Lopes
AU  - A. M. Tomé
PY  - 2019
KW  - dexterous manipulators
KW  - end effectors
KW  - humanoid robots
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - position control
KW  - robot vision
KW  - service robots
KW  - human-centric environments
KW  - end-effector positions
KW  - affordance category
KW  - grasp configuration
KW  - Bayesian approach
KW  - learning recognition
KW  - object categories
KW  - instance-based approach
KW  - robotic manipulation
KW  - service robots
KW  - object perception
KW  - grasp affordances
KW  - training data
KW  - batch learning
KW  - end-effector orientations
KW  - Task analysis
KW  - Three-dimensional displays
KW  - Education
KW  - Object detection
KW  - Object recognition
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794184
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Service robots are expected to autonomously and efficiently work in human-centric environments. For this type of robots, object perception and manipulation are challenging tasks due to need for accurate and real-time response. This paper presents an interactive open-ended learning approach to recognize multiple objects and their grasp affordances concurrently. This is an important contribution in the field of service robots since no matter how extensive the training data used for batch learning, a robot might always be confronted with an unknown object when operating in human-centric environments. The paper describes the system architecture and the learning and recognition capabilities. Grasp learning associates grasp configurations (i.e., end-effector positions and orientations) to grasp affordance categories. The grasp affordance category and the grasp configuration are taught through verbal and kinesthetic teaching, respectively. A Bayesian approach is adopted for learning and recognition of object categories and an instance-based approach is used for learning and recognition of affordance categories. An extensive set of experiments has been performed to assess the performance of the proposed approach regarding recognition accuracy, scalability and grasp success rate on challenging datasets and real-world scenarios.
ER  - 

TY  - CONF
TI  - A parallel low-impedance sensing approach for highly responsive physical human-robot interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3754
EP  - 3760
AU  - G. Boucher
AU  - T. Laliberté
AU  - C. Gosselin
PY  - 2019
KW  - dexterous manipulators
KW  - end effectors
KW  - human-robot interaction
KW  - human-robot interaction
KW  - serial robotic arm
KW  - macro-mini robot architecture
KW  - general multidegree-of-freedom serial robot
KW  - five-degree-of-freedom robotic arm
KW  - low-impedance sensing approach
KW  - impedance control scheme
KW  - Robot sensing systems
KW  - Impedance
KW  - Manipulators
KW  - Robot kinematics
KW  - Collision avoidance
DO  - 10.1109/ICRA.2019.8793849
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a novel sensing approach for the physical interaction between a human user and a serial robotic arm. The approach is inspired from the concept of macro-mini robot architecture. The framework is developed for a general multi-degree-of-freedom serial robot and a corresponding impedance control scheme is proposed. In order to illustrate the concept, a five-degree-of-freedom robotic arm was built as well as a six-degree-of-freedom low-impedance sensing device that is used to control the robot. Experimental results are provided.
ER  - 

TY  - CONF
TI  - Safe Human Robot Cooperation in Task Performed on the Shared Load
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3761
EP  - 3767
AU  - M. Anvaripour
AU  - M. Khoshnam
AU  - C. Menon
AU  - M. Saif
PY  - 2019
KW  - collision avoidance
KW  - human-robot interaction
KW  - industrial robots
KW  - motion control
KW  - neurocontrollers
KW  - robot dynamics
KW  - human-robot collaboration
KW  - safety framework
KW  - force myography data
KW  - human worker
KW  - human muscles
KW  - FMG signal
KW  - robot dynamics
KW  - robot motion
KW  - neural network
KW  - industrial settings
KW  - collision avoidance
KW  - Force
KW  - Robot kinematics
KW  - Muscles
KW  - Dynamics
KW  - Task analysis
KW  - Service robots
DO  - 10.1109/ICRA.2019.8794176
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Human-robot collaboration in industrial settings calls for implementing safety measures to ensure there is no risk to humans working in such an environment. In human-robot physical collaboration, an object or a load is handled by both human and the robot. Developing a safety framework for the robot is a requirement for preventing collisions during performing a task. In this paper, force myography (FMG) data are used to develop a control scheme for the robot such that it can work with the human worker while avoiding collisions. Force myography quantifies the activities of human muscles when applying forces to handle an object. A neural network-based approach is then used to select the most informative features of the FMG signal. The developed control scheme incorporates the FMG data and the robot dynamics to obtain a prediction about the next step of the cooperation task and to plan the robot motion accordingly. The proposed approach is evaluated experimentally in real time in a moving objects task which requires appropriate complementary actions from the robot and the human user. The results of this study show that the proposed scheme can successfully plan the robot motion based on the actions of the human user.
ER  - 

TY  - CONF
TI  - A Multi-modal Sensor Array for Safe Human-Robot Interaction and Mapping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3768
EP  - 3774
AU  - C. Abah
AU  - A. L. Orekhov
AU  - G. L. H. Johnston
AU  - P. Yin
AU  - H. Choset
AU  - N. Simaan
PY  - 2019
KW  - electric sensing devices
KW  - end effectors
KW  - force sensors
KW  - human-robot interaction
KW  - mobile robots
KW  - motion control
KW  - sensor arrays
KW  - multimodal sensor array
KW  - safe human-robot interaction
KW  - time-of-flight sensors
KW  - accidental contact detection
KW  - contact localization
KW  - force sensing
KW  - proximity sensing
KW  - proximity mapping
KW  - Hall effect
KW  - collaborative continuum robot
KW  - bracing constraint
KW  - admissible rolling motion
KW  - end effector
KW  - I2C communication network
KW  - Robot sensing systems
KW  - Force
KW  - Sensor arrays
KW  - Hall effect
KW  - Multiplexing
KW  - Robot perception
KW  - Collaborative robots
KW  - Continuum robots
KW  - Bracing
KW  - Mapping
DO  - 10.1109/ICRA.2019.8793466
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In the future, human-robot interaction will include collaboration in close-quarters where the environment geometry is partially unknown. As a means for enabling such interaction, this paper presents a multi-modal sensor array capable of contact detection and localization, force sensing, proximity sensing, and mapping. The sensor array integrates Hall effect and time-of-flight (ToF) sensors in an I2C communication network. The design, fabrication, and characterization of the sensor array for a future in-situ collaborative continuum robot are presented. Possible perception benefits of the sensor array are demonstrated for accidental contact detection, mapping of the environment, selection of admissible zones for bracing, and constrained motion control of the end effector while maintaining a bracing constraint with an admissible rolling motion.
ER  - 

TY  - CONF
TI  - Dynamic Primitives in Human Manipulation of Non-Rigid Objects
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3783
EP  - 3789
AU  - H. Guang
AU  - S. Bazzi
AU  - D. Sternad
AU  - N. Hogan
PY  - 2019
KW  - biomechanics
KW  - human-robot interaction
KW  - learning systems
KW  - manipulator dynamics
KW  - motion control
KW  - optimisation
KW  - pendulums
KW  - position control
KW  - sloshing
KW  - human manipulation
KW  - nonrigid objects
KW  - liquid sloshing
KW  - horizontal line
KW  - virtual environment
KW  - human subjects
KW  - robotic manipulandum
KW  - residual oscillations
KW  - humans simplified control
KW  - human movements
KW  - continuous optimization-based control
KW  - control model
KW  - flexible objects
KW  - motion profile
KW  - human profiles
KW  - robot control
KW  - input shaping model
KW  - cart-and-pendulum system
KW  - Task analysis
KW  - Mathematical model
KW  - Oscillators
KW  - Trajectory
KW  - Robots
KW  - Predictive models
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8793687
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This study examined strategies humans chose to manipulate an object with complex (nonlinear, underactuated) dynamics, such as liquid sloshing in a cup of coffee. The problem was simplified to the well-known cart-and-pendulum system moving on a horizontal line. This model was implemented in a virtual environment and human subjects manipulated the object via a robotic manipulandum. The task was to maneuver the system from rest to arrive at a target position such that no residual oscillations of the pendulum bob remained. Our goal was to test whether humans simplified control by employing dynamic primitives, specifically submovements. Experimental velocity profiles of the human movements were compared to those predicted by three different control models. Two models used continuous optimization-based control, the third control model was based on Input Shaping. Input Shaping is a method for controlling flexible objects by convolving a motion profile with impulses of appropriate amplitude and timing. To evaluate whether humans used Input Shaping, we decomposed the velocity profiles recorded from humans into submovements, as proxies for the convolved impulses. Comparing the motion profiles from the 3 models with the experimentally measured human profiles showed superior performance of the Input Shaping model. These initial results are consistent with our hypothesis that combining dynamic primitives, submovements, is a competent description of human performance and may provide a simpler alternative to computationally complex optimization-based methods of robot control.
ER  - 

TY  - CONF
TI  - State Estimation in Contact-Rich Manipulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3790
EP  - 3796
AU  - F. Wirnshofer
AU  - P. S. Schmitt
AU  - P. Meister
AU  - G. v. Wichert
AU  - W. Burgard
PY  - 2019
KW  - Bayes methods
KW  - manipulator dynamics
KW  - multi-robot systems
KW  - robot kinematics
KW  - robot vision
KW  - state estimation
KW  - torque control
KW  - complex manipulation scenario
KW  - state estimation
KW  - Bayesian state estimator
KW  - nonprehensile manipulation
KW  - industrial assembly
KW  - in-hand localization
KW  - contact dynamics
KW  - torque-based robot controller
KW  - robot kinematics
KW  - multiple robots
KW  - articulated objects
KW  - physical robot
KW  - freedom object
KW  - multimodal distributions
KW  - Dynamics
KW  - Computational modeling
KW  - Manipulators
KW  - Bayes methods
KW  - Estimation
KW  - Probabilistic logic
DO  - 10.1109/ICRA.2019.8793572
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper introduces a Bayesian state estimator for contact-rich manipulation tasks with application in non-prehensile manipulation, industrial assembly or in-hand localization. The core idea of our approach is to explicitly model both the contact dynamics and a torque-based robot controller as part of the underlying system model. Our approach is capable of estimating the state of movable objects for various robot kinematics and geometries of robots and objects. This includes complex scenarios with multiple robots, multiple objects and articulated objects. We have validated our approach in simulation and on a physical robot. The experiments show that multimodal distributions of six degrees of freedom object poses can be accurately tracked in real-time in a complex manipulation scenario.
ER  - 

TY  - CONF
TI  - Improved Proximity, Contact, and Force Sensing via Optimization of Elastomer-Air Interface Geometry
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3797
EP  - 3803
AU  - P. E. Lancaster
AU  - J. R. Smith
AU  - S. S. Srinivasa
PY  - 2019
KW  - distance measurement
KW  - elastomers
KW  - force measurement
KW  - force sensors
KW  - manipulators
KW  - object detection
KW  - optical sensors
KW  - optimisation
KW  - force sensing
KW  - elastomer-air interface geometry
KW  - robot manipulation
KW  - contact detection
KW  - signal-to-noise ratio
KW  - elastomer-air boundary
KW  - deformation measurement
KW  - distance measurement
KW  - contact force measurement
KW  - proximity sensor design
KW  - contact sensor design
KW  - optimization
KW  - single fingertip-mounted sensing system
KW  - optical time-of-flight range measurement modules
KW  - object detection
KW  - emitted light path control
KW  - Robot sensing systems
KW  - Receivers
KW  - Force
KW  - Force measurement
KW  - Optical sensors
DO  - 10.1109/ICRA.2019.8793959
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We describe a single fingertip-mounted sensing system for robot manipulation that provides proximity (pre-touch), contact detection (touch), and force sensing (post-touch). The sensor system consists of optical time-of-flight range measurement modules covered in a clear elastomer. Because the elastomer is clear, the sensor can detect and range nearby objects, as well as measure deformations caused by objects that are in contact with the sensor and thereby estimate the applied force. We examine how this sensor design can be improved with respect to invariance to object reflectivity, signal-to-noise ratio, and continuous operation when switching between the distance and force measurement regimes. By harnessing time-of-flight technology and optimizing the elastomer-air boundary to control the emitted light's path, we develop a sensor that is able to seamlessly transition between measuring distances of up to 50 mm and contact forces of up to 10 newtons. We demonstrate that our sensor improves manipulation accuracy in a block unstacking task. Thorough instructions for manufacturing the sensor from inexpensive, commercially available components are provided, as well as all relevant hardware design files and software sources.
ER  - 

TY  - CONF
TI  - Improving Haptic Adjective Recognition with Unsupervised Feature Learning
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3804
EP  - 3810
AU  - B. A. Richardson
AU  - K. J. Kuchenbecker
PY  - 2019
KW  - feature extraction
KW  - image classification
KW  - iterative methods
KW  - unsupervised learning
KW  - unsupervised feature learning
KW  - densely innervated skin
KW  - haptics researchers
KW  - haptic intelligence
KW  - concrete tasks
KW  - object recognition
KW  - feature learning methods
KW  - haptic adjectives
KW  - diverse interactions
KW  - abstract binary classification tasks
KW  - spatio-temporal hierarchical matching pursuit
KW  - haptic adjective recognition
KW  - Haptic interfaces
KW  - Feature extraction
KW  - Task analysis
KW  - Dictionaries
KW  - Matching pursuit algorithms
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793544
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Humans can form an impression of how a new object feels simply by touching its surfaces with the densely innervated skin of the fingertips. Many haptics researchers have recently been working to endow robots with similar levels of haptic intelligence, but these efforts almost always employ hand-crafted features, which are brittle, and concrete tasks, such as object recognition. We applied unsupervised feature learning methods, specifically K-SVD and Spatio-Temporal Hierarchical Matching Pursuit (ST-HMP), to rich multi-modal haptic data from a diverse dataset. We then tested the learned features on 19 more abstract binary classification tasks that center on haptic adjectives such as smooth and squishy. The learned features proved superior to traditional hand-crafted features by a large margin, almost doubling the average F1 score across all adjectives. Additionally, particular exploratory procedures (EPs) and sensor channels were found to support perception of certain haptic adjectives, underlining the need for diverse interactions and multi-modal haptic data.
ER  - 

TY  - CONF
TI  - Tactile Mapping and Localization from High-Resolution Tactile Imprints
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3811
EP  - 3817
AU  - M. Bauza
AU  - O. Canal
AU  - A. Rodriguez
PY  - 2019
KW  - haptic interfaces
KW  - manipulators
KW  - tactile sensors
KW  - high-resolution tactile imprints
KW  - shape reconstruction
KW  - object localization
KW  - vision-based tactile sensor
KW  - local shapes
KW  - reconstructed objects
KW  - tactile sensing
KW  - tactile feedback
KW  - online object identification
KW  - Shape
KW  - Image reconstruction
KW  - Tactile sensors
KW  - Three-dimensional displays
KW  - Estimation
DO  - 10.1109/ICRA.2019.8794298
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This work studies the problem of shape reconstruction and object localization using a vision-based tactile sensor, GelSlim. The main contributions are the recovery of local shapes from contact, an approach to reconstruct the tactile shape of objects from tactile imprints, and an accurate method for object localization of previously reconstructed objects. The algorithms can be applied to a large variety of 3D objects and provide accurate tactile feedback for in-hand manipulation. Results show that by exploiting the dense tactile information we can reconstruct the shape of objects with high accuracy and do on-line object identification and localization, opening the door to reactive manipulation guided by tactile sensing. We provide videos and supplemental information in the project's website web.mit.edu/mcube/research/tactile localization.html.
ER  - 

TY  - CONF
TI  - Maintaining Grasps within Slipping Bounds by Monitoring Incipient Slip
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3818
EP  - 3824
AU  - S. Dong
AU  - D. Ma
AU  - E. Donlon
AU  - A. Rodriguez
PY  - 2019
KW  - dexterous manipulators
KW  - force control
KW  - grippers
KW  - slip
KW  - tactile sensors
KW  - grasped object
KW  - sensor surface
KW  - 2D rigid-body motion
KW  - motion field
KW  - 2D planar rigid transformation
KW  - dense slip field
KW  - highly deformable objects
KW  - slip feedback
KW  - monitoring incipient slip
KW  - high-resolution vision-based tactile sensor
KW  - tactile imprints
KW  - detection accuracy
KW  - frequency 24.0 Hz
KW  - Force
KW  - Tactile sensors
KW  - Grasping
KW  - Cameras
DO  - 10.1109/ICRA.2019.8793538
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose an approach to detect incipient slip, i.e. predict slip, by using a high-resolution vision-based tactile sensor, GelSlim. The sensor dynamically captures the tactile imprints of the grasped object and their changes with a soft gel pad. The method assumes the object is mostly rigid and expects the motion of object's imprint on the sensor surface to be a 2D rigid-body motion. We use the deviation of the true motion field from that of a 2D planar rigid transformation as a measure of slip. The output is a dense slip field which we monitor in real time to detect when small areas of the contact patch start to slip (incipient slip). The method can detect incipient slip in any direction without any prior knowledge of the object at 24 Hz. We test the method on 10 objects for 240 times and achieve 86.25% detection accuracy with the vast majority of failure cases occurring when grasping highly deformable objects. We further show how the slip feedback can be used to adjust the gripping force to avoid slip with a closed-loop bottle-cap screwing and unscrewing experiment. The method can be used to enable many manipulation tasks in both structured and unstructured environments.
ER  - 

TY  - CONF
TI  - Road Detection through CRF based LiDAR-Camera Fusion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3832
EP  - 3838
AU  - S. Gu
AU  - Y. Zhang
AU  - J. Tang
AU  - J. Yang
AU  - H. Kong
PY  - 2019
KW  - cameras
KW  - convolutional neural nets
KW  - image colour analysis
KW  - image fusion
KW  - image sampling
KW  - object detection
KW  - optical radar
KW  - KITTI-Road dataset
KW  - CRF based LiDAR-camera fusion
KW  - road detection method
KW  - color information
KW  - camera image domain
KW  - CRF fusion method
KW  - conditional random field framework
KW  - binary road detection
KW  - dense road detection
KW  - LiDAR-camera calibration
KW  - height-difference based scanning strategy
KW  - convolutional network
KW  - Laser radar
KW  - Roads
KW  - Cameras
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Image segmentation
KW  - Transforms
DO  - 10.1109/ICRA.2019.8793585
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a road detection method with LiDAR-camera fusion in a novel conditional random field (CRF) framework to exploit both range and color information. In the LiDAR based part, a fast height-difference based scanning strategy is applied in the 2D LiDAR range-image domain and a dense road detection result in camera image domain can be obtained through geometric upsampling given the LiDAR-camera calibration parameters. In the camera based part, a fully convolutional network is applied in the camera image domain. Finally, we fuse the dense and binary road detection results from both LiDAR and camera in a single CRF framework. Experiments show that using a single thread of CPU, the proposed LiDAR based part can operate at a frequency of over 250Hz with sparse output in range image and 40Hz with dense result in camera image for the 64-beam Velodyne scanner. Our CRF fusion method achieves very promising road detection performance on the KITTI-Road dataset.
ER  - 

TY  - CONF
TI  - Semantic mapping extension for OpenStreetMap applied to indoor robot navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3839
EP  - 3845
AU  - L. Naik
AU  - S. Blumenthal
AU  - N. Huebel
AU  - H. Bruyninckx
AU  - E. Prassler
PY  - 2019
KW  - graph theory
KW  - mobile robots
KW  - path planning
KW  - OpenStreetMap
KW  - geometrical information
KW  - basic indoor structures
KW  - architectural principles
KW  - application-specific knowledge
KW  - graph-based map representation
KW  - hierarchical structure
KW  - semantic mapping extension
KW  - indoor robot navigation
KW  - grid-based motion planning algorithms
KW  - Robots
KW  - Semantics
KW  - Data models
KW  - Geometry
KW  - Navigation
KW  - Indoor environment
KW  - Tagging
DO  - 10.1109/ICRA.2019.8793641
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work a graph-based, semantic mapping approach for indoor robotics applications is presented, which is extending OpenStreetMap (OSM) with robotic-specific, semantic, topological, and geometrical information. Models are introduced for basic indoor structures such as walls, doors, corridors, elevators, etc. The architectural principles support composition with additional domain and application-specific knowledge. As an example, a model for an area is introduced, and it is explained how this can be used in navigation. A key advantage of the proposed graph-based map representation is that it allows exploiting the hierarchical structure of the graphs. Finally, the compatibility of the approach with existing, grid-based motion planning algorithms is shown.
ER  - 

TY  - CONF
TI  - Adaptive Probabilistic Vehicle Trajectory Prediction Through Physically Feasible Bayesian Recurrent Neural Network
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3846
EP  - 3852
AU  - C. Tang
AU  - J. Chen
AU  - M. Tomizuka
PY  - 2019
KW  - Bayes methods
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - probability
KW  - recurrent neural nets
KW  - stochastic processes
KW  - traffic engineering computing
KW  - Bayesian recurrent neural network
KW  - prediction horizon
KW  - target human driver
KW  - naturalistic car following data
KW  - multimodal stochastic feedback gain
KW  - particle-filter-based parameter adaptation algorithm
KW  - adopted gradient-based training method
KW  - embedded physical model
KW  - trajectory distribution
KW  - Bayesian-neural-network-based policy model
KW  - Bayesian recurrent neural network model
KW  - driving policy
KW  - predicted distribution
KW  - physical feasibility
KW  - long-term trajectory prediction
KW  - autonomous driving
KW  - robust safety
KW  - adaptive probabilistic vehicle trajectory prediction
KW  - Trajectory
KW  - Adaptation models
KW  - Probabilistic logic
KW  - Bayes methods
KW  - Vehicle dynamics
KW  - Vehicles
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8794130
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Probabilistic vehicle trajectory prediction is essential for robust safety of autonomous driving. Current methods for long-term trajectory prediction cannot guarantee the physical feasibility of predicted distribution. Moreover, their models cannot adapt to the driving policy of the predicted target human driver. In this work, we propose to overcome these two shortcomings by a Bayesian recurrent neural network model consisting of Bayesian-neural-network-based policy model and known physical model of the scenario. Bayesian neural network can ensemble complicated output distribution, enabling rich family of trajectory distribution. The embedded physical model ensures feasibility of the distribution. Moreover, the adopted gradient-based training method allows direct optimization for better performance in long prediction horizon. Furthermore, a particle-filter-based parameter adaptation algorithm is designed to adapt the policy Bayesian neural network to the predicted target online. Effectiveness of the proposed methods is verified with a toy example with multi-modal stochastic feedback gain and naturalistic car following data.
ER  - 

TY  - CONF
TI  - Optimizing Vehicle Distributions and Fleet Sizes for Shared Mobility-on-Demand
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3853
EP  - 3859
AU  - A. Wallar
AU  - J. Alonso-Mora
AU  - D. Rus
PY  - 2019
KW  - optimisation
KW  - road vehicles
KW  - traffic engineering computing
KW  - transportation
KW  - optimizing vehicle distributions
KW  - fleet sizes
KW  - urban transit
KW  - ride-sharing
KW  - vehicle congestion
KW  - multiple passengers
KW  - historical demand data
KW  - MoD systems
KW  - travel demand
KW  - taxi demand
KW  - shared mobility-on-demand systems
KW  - taxi requests
KW  - city's transportation infrastructure
KW  - four passenger vehicles
KW  - Schedules
KW  - Delays
KW  - Urban areas
KW  - Public transportation
KW  - Cost function
KW  - Automation
DO  - 10.1109/ICRA.2019.8793685
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mobility-on-demand (MoD) systems are revolutionizing urban transit with the introduction of ride-sharing. Such systems have the potential to reduce vehicle congestion and improve accessibility of a city's transportation infrastructure. Recently developed algorithms can compute routes for vehicles in real-time for a city-scale volume of requests while allowing vehicles to carry multiple passengers at the same time. However, these algorithms focus on optimizing the performance for a given fleet of vehicles and do not tell us how many vehicles are needed to service all the requests. In this paper, we present an offline method to optimize the vehicle distributions and fleet sizes on historical demand data for MoD systems that allow passengers to share vehicles. We present an algorithm to determine how many vehicles are needed, where they should be initialized, and how they should be routed to service all the travel demand for a given period of time. Evaluation using 23,529,740 historical taxi requests from one month in Manhattan shows that on average 2864 four passenger vehicles are needed to service all of the taxi demand in a day with an average added travel delay of 2.8 mins.
ER  - 

TY  - CONF
TI  - Global Vision-Based Reconstruction of Three-Dimensional Road Surfaces Using Adaptive Extended Kalman Filter
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3860
EP  - 3866
AU  - D. Li
AU  - T. Furukawa
PY  - 2019
KW  - adaptive Kalman filters
KW  - cameras
KW  - computer vision
KW  - image filtering
KW  - image reconstruction
KW  - nonlinear filters
KW  - pose estimation
KW  - road safety
KW  - traffic engineering computing
KW  - AEKF
KW  - local road surface reconstruction techniques
KW  - on-road test
KW  - global vision-based reconstruction
KW  - three-dimensional road surfaces
KW  - vision-based technique
KW  - adaptive extended Kalman filter
KW  - global camera pose estimation
KW  - real-world global 3D road surface reconstruction
KW  - Roads
KW  - Surface reconstruction
KW  - Cameras
KW  - Image reconstruction
KW  - Uncertainty
KW  - Global Positioning System
KW  - Kalman filters
DO  - 10.1109/ICRA.2019.8794039
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a vision-based technique and a system developed for the global reconstruction of three-dimensional (3-D) road surfaces. Using the system, the technique globally reconstructs 3-D road surfaces by estimating the global camera pose using the Adaptive Extended Kalman Filter (AEKF) and integrating it with existing local road surface reconstruction techniques. The AEKF adaptively updates the covariance of uncertainties such that the estimation works well even in environments with varying uncertainties. Numerical results show the efficacy of the proposed technique over the Extended Kalman Filter (EKF)-based technique by 50% in accuracy, and the on-road test has demonstrated the ability of the proposed technique for the real-world global 3-D road surface reconstruction.
ER  - 


