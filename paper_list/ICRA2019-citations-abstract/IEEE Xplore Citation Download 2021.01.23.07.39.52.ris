TY  - CONF
TI  - Autonomous Tissue Manipulation via Surgical Robot Using Learning Based Model Predictive Control
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3875
EP  - 3881
AU  - C. Shin
AU  - P. W. Ferguson
AU  - S. A. Pedram
AU  - J. Ma
AU  - E. P. Dutson
AU  - J. Rosen
PY  - 2019
KW  - biological tissues
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - medical robotics
KW  - mobile robots
KW  - predictive control
KW  - robot vision
KW  - surgery
KW  - autonomous tissue manipulation
KW  - soft tissue
KW  - AI learning
KW  - vision strategies
KW  - Raven IV surgical robotic system
KW  - predictive control algorithms
KW  - reinforcement learning
KW  - Robots
KW  - Heuristic algorithms
KW  - Prediction algorithms
KW  - Surgery
KW  - Neural networks
KW  - Task analysis
KW  - Aerospace electronics
KW  - Robotic Tissue Manipulation
KW  - Reinforcement Learning
KW  - Learning from Demonstration
KW  - Neural Networks
KW  - Simulation
KW  - Surgery
KW  - Automation
KW  - Machine Learning
KW  - Artificial Intelligence
KW  - AI
KW  - Raven Surgical Robot
KW  - Medical Robotics
DO  - 10.1109/ICRA.2019.8794159
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Tissue manipulation is a frequently used fundamental subtask of any surgical procedures, and in some cases it may require the involvement of a surgeon's assistant. The complex dynamics of soft tissue as an unstructured environment is one of the main challenges in any attempt to automate the manipulation of it via a surgical robotic system. Two AI learning based model predictive control algorithms using vision strategies are proposed and studied: (1) reinforcement learning and (2) learning from demonstration. Comparison of the performance of these AI algorithms in a simulation setting indicated that the learning from demonstration algorithm can boost the learning policy by initializing the predicted dynamics with given demonstrations. Furthermore, the learning from demonstration algorithm is implemented on a Raven IV surgical robotic system and successfully demonstrated feasibility of the proposed algorithm using an experimental approach. This study is part of a profound vision in which the role of a surgeon will be redefined as a pure decision maker whereas the vast majority of the manipulation will be conducted autonomously by a surgical robotic system. A supplementary video can be found at: http://bionics.seas.ucla.edu/research/surgeryproject17.html.
ER  - 

TY  - CONF
TI  - Robotic Control of a Multi-Modal Rigid Endoscope Combining Optical Imaging with All-Optical Ultrasound
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3882
EP  - 3888
AU  - G. Dwyer
AU  - R. J. Colchester
AU  - E. J. Alles
AU  - E. Maneas
AU  - S. Ourselin
AU  - T. Vercauteren
AU  - J. Deprest
AU  - E. V. Poorten
AU  - P. D. Coppi
AU  - A. E. Desjardins
AU  - D. Stoyanov
PY  - 2019
KW  - biomedical optical imaging
KW  - biomedical ultrasonics
KW  - cameras
KW  - endoscopes
KW  - medical robotics
KW  - optical sensors
KW  - phantoms
KW  - ultrasonic transducers
KW  - spiral scan
KW  - placenta phantom
KW  - white light stereo camera
KW  - robotic multimodal endoscope
KW  - low diameter endoscopes
KW  - dynamic environment
KW  - technically challenging surgery
KW  - fetoscopy
KW  - all-optical ultrasound
KW  - optical imaging
KW  - multimodal rigid endoscope
KW  - robotic control
KW  - surface visualisations
KW  - optical ultrasound sensor
KW  - Endoscopes
KW  - Ultrasonic imaging
KW  - Optical imaging
KW  - Optical sensors
KW  - Cameras
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794289
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fetoscopy is a technically challenging surgery, due to the dynamic environment and low diameter endoscopes often resulting in a limited field of view. In this paper, we report on the design and operation of a robotic multimodal endoscope with optical ultrasound and white light stereo camera. The manufacture and control of the endoscope is presented, along with large area (80 mm ×80 mm) surface visualisations of a placenta phantom using the optical ultrasound sensor. The repeatability of the surface visualisations was found to be 0. 446 ± 0.139 mm and 0. 267 ± 0.017 mm for a raster and spiral scan, respectively.
ER  - 

TY  - CONF
TI  - Enabling Technology for Safe Robot-Assisted Retinal Surgery: Early Warning for Unsafe Scleral Force
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3889
EP  - 3894
AU  - C. He
AU  - N. Patel
AU  - I. Iordachita
AU  - M. Kobilarov
PY  - 2019
KW  - calibration
KW  - eye
KW  - force sensors
KW  - manipulators
KW  - medical robotics
KW  - phantoms
KW  - surgery
KW  - manipulation task
KW  - early warning system
KW  - unsafe manipulation events
KW  - safe robot-assisted retinal surgery
KW  - unsafe scleral force
KW  - retinal microsurgery
KW  - high surgical skill
KW  - manipulation error
KW  - constant contact
KW  - unexpected manipulation
KW  - extreme tool-sclera contact force
KW  - robotic assistance
KW  - surgeon
KW  - potential intra-operative danger
KW  - robotic systems
KW  - imminent unsafe manipulation
KW  - sclera damage
KW  - force-sensing tool
KW  - unsafe events
KW  - steady hand eye robot
KW  - force safety status
KW  - Force
KW  - Surgery
KW  - Tools
KW  - Retina
KW  - Robot kinematics
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794427
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Retinal microsurgery is technically demanding and requires high surgical skill with very little room for manipulation error. During surgery the tool needs to be inserted into the eyeball while maintaining constant contact with the sclera. Any unexpected manipulation could cause extreme tool-sclera contact force (scleral force) thus damage the sclera. The introduction of robotic assistance could enhance and expand the surgeon's manipulation capabilities during surgery. However, the potential intra-operative danger from surgeon's mis-operations remains difficult to detect and prevent by existing robotic systems. Therefore, we propose a method to predict imminent unsafe manipulation in robot-assisted retinal surgery and generate feedback to the surgeon via auditory substitution. The surgeon could then react to the possible unsafe events in advance. This work specifically focuses on minimizing sclera damage using a force-sensing tool calibrated to measure small scleral forces. A recurrent neural network is designed and trained to predict the force safety status up to 500 milliseconds in the future. The system is implemented using an existing “steady hand” eye robot. A vessel following manipulation task is designed and performed on a dry eye phantom to emulate the retinal surgery and to analyze the proposed method. Finally, preliminary validation experiments are performed by five users, the results of which indicate that the proposed early warning system could help to reduce the number of unsafe manipulation events.
ER  - 

TY  - CONF
TI  - Robotic bronchoscopy drive mode of the Auris Monarch platform*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3895
EP  - 3901
AU  - C. F. Graetzel
AU  - A. Sheehy
AU  - D. P. Noonan
PY  - 2019
KW  - biomechanics
KW  - cancer
KW  - computerised tomography
KW  - endoscopes
KW  - lung
KW  - manipulators
KW  - medical image processing
KW  - medical robotics
KW  - physiological models
KW  - safety algorithms
KW  - robotic bronchoscopy drive mode
KW  - Auris Monarch platform
KW  - lung cancer
KW  - ten degree-of-freedom bronchoscope
KW  - three degree-of-freedom user input
KW  - paired driving concept
KW  - tension monitoring
KW  - lung porcine models
KW  - Robot sensing systems
KW  - Bronchoscopy
KW  - Lung
KW  - Manipulators
KW  - Cancer
DO  - 10.1109/ICRA.2019.8793704
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic bronchoscopy has the potential to improve the early detection of lung cancer. For the technology to be broadly adopted, the physician needs to be able to control the robotic bronchoscope in an instinctive and effective manner. In this paper, we describe the algorithms used to manipulate/drive the Auris Monarch Platform, a 10 degree-of-freedom bronchoscope and sheath, using a 3 degree-of-freedom user input. We introduce the concept of paired driving where the devices co-insert and co-articulate depending on their relative insertion. The paper presents safety algorithms such as auto-relax on retract and tension monitoring. The drive modes were developed, optimized, and clinically tested in lung models, human cadavers and live porcine models prior to their commercial release. Clinical studies show that the physician is able to reach significantly deeper in the lung than with classic bronchoscopes.
ER  - 

TY  - CONF
TI  - Using comanipulation with active force feedback to undistort stiffness perception in laparoscopy
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3902
EP  - 3908
AU  - F. Schmitt
AU  - J. Sulub
AU  - I. Avellino
AU  - J. D. Silva
AU  - L. Barbé
AU  - O. Piccin
AU  - B. Bayle
AU  - G. Morel
PY  - 2019
KW  - force feedback
KW  - force measurement
KW  - medical computing
KW  - medical robotics
KW  - surgery
KW  - laparoscopic surgery
KW  - undistort stiffness perception
KW  - comanipulation paradigm
KW  - fulcrum
KW  - lever effect
KW  - laparoscopy
KW  - stiffness perception
KW  - active force feedback
KW  - preliminary assessment experiment
KW  - lever ratio
KW  - tool tip
KW  - surgeon
KW  - robotic device
KW  - Tools
KW  - Force
KW  - Robot sensing systems
KW  - Surgery
KW  - Instruments
KW  - Laparoscopes
DO  - 10.1109/ICRA.2019.8793662
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Surgeons performing laparoscopic surgery experience distortion when perceiving the stiffness of a patient's tissues. This is due to the lever effect induced by the introduction of instruments in their patient's body through a fulcrum. To address this problem, we propose to use the comanipulation paradigm. A robotic device is connected to the handle of the instrument while simultaneously being held by the surgeon. This device applies a force on the handle that reflects the force measured at the tool tip, with a gain that depends on the lever ratio. The implementation of this method is presented on an experimental setup and a preliminary assessment experiment is presented.
ER  - 

TY  - CONF
TI  - Stiffness-Tuneable Limb Segment with Flexible Spine for Malleable Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3969
EP  - 3975
AU  - A. B. Clark
AU  - N. Rojas
PY  - 2019
KW  - bending
KW  - design engineering
KW  - elasticity
KW  - finite element analysis
KW  - flexible structures
KW  - humanoid robots
KW  - manipulator kinematics
KW  - motion control
KW  - structural engineering
KW  - multimaterial spine-inspired flexible structure
KW  - stiffness-controllable layer-jamming-based robotic links
KW  - spine mechanism
KW  - robotic link
KW  - layer jamming
KW  - hollow structure
KW  - light structure
KW  - flexible spine
KW  - link utilising
KW  - limb segments
KW  - granular jamming
KW  - bending angles
KW  - stiffness-tuneable limb segment
KW  - malleable robots
KW  - robotic arms
KW  - stiffness-adjustable
KW  - bending segments
KW  - revolute joints
KW  - mechanical architecture
KW  - degrees of freedom
KW  - suitable links
KW  - robotic manipulators
KW  - reduced performance
KW  - structural deformation
KW  - inner support structure
KW  - increased stiffening performance
KW  - stiffening mechanisms
KW  - Jamming
KW  - Manipulators
KW  - Strain
KW  - Ligaments
KW  - Force
KW  - Service robots
DO  - 10.1109/ICRA.2019.8793713
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robotic arms built from stiffness-adjustable, continuously bending segments serially connected with revolute joints have the ability to change their mechanical architecture and workspace, thus allowing high flexibility and adaptation to different tasks with less than six degrees of freedom, a concept that we call malleable robots. Known stiffening mechanisms may be used to implement suitable links for these novel robotic manipulators; however, these solutions usually show a reduced performance when bending due to structural deformation. By including an inner support structure this deformation can be minimised, resulting in an increased stiffening performance. This paper presents a new multi-material spine-inspired flexible structure for providing support in stiffness-controllable layer-jamming-based robotic links of large diameter. The proposed spine mechanism is highly movable with type and range of motions that match those of a robotic link using solely layer jamming, whilst maintaining a hollow and light structure. The mechanics and design of the flexible spine are explored, and a prototype of a link utilising it is developed and compared with limb segments based on granular jamming and layer jamming without support structure. Results of experiments verify the advantages of the proposed design, demonstrating that it maintains a constant central diameter across bending angles and presents an improvement of more than 203% of resisting force at 180°.
ER  - 

TY  - CONF
TI  - A Reconfigurable Variable Stiffness Manipulator by a Sliding Layer Mechanism
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3976
EP  - 3982
AU  - D. C. F. Li
AU  - Z. Wang
AU  - B. Ouyang
AU  - Y. Liu
PY  - 2019
KW  - actuators
KW  - compliance control
KW  - elastic constants
KW  - honeycomb structures
KW  - manipulator dynamics
KW  - mechanical stability
KW  - medical robotics
KW  - surgery
KW  - sliding layer mechanism
KW  - interlocking jamming layers
KW  - reconfigurable variable stiffness manipulator
KW  - soft robots
KW  - variable stiffness mechanism
KW  - structural stability
KW  - manipulator
KW  - laparoscopic surgeries
KW  - Jamming
KW  - Manipulators
KW  - Tendons
KW  - Strips
KW  - Friction
KW  - Soft robotics
DO  - 10.1109/ICRA.2019.8793571
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Inherent compliance plays an enabling role in soft robots, which rely on it to mechanically conform to the environment. However, it also limits the payload of the robots. Various variable stiffness approaches have been adopted to limit compliance and provide structural stability, but most of them can only achieve stiffening of discrete fixed regions which means compliance cannot be precisely adjusted for different needs. This paper offers an approach to enhance the payload with finely adjusted compliance for different needs. We have developed a manipulator that incorporates a novel variable stiffness mechanism and a sliding layer mechanism. The variable stiffness mechanism can achieve a 6.4 stiffness changing ratio with a miniaturized size (10 mm diameter for the testing prototype) through interlocking jamming layers with a honeycomb core. The sliding layer mechanism can actively shift the position of the stiffening regions through sliding of jamming layers. A model to predict the robot shape is derived with verifications via an experiment. The stiffening capacity of the variable stiffness mechanism is also empirically evaluated. A case study of a potential application in laparoscopic surgeries is showcased. The payload of the manipulator is investigated, and the prototype shows up to 57.8 percentage decrease of the vertical deflection due to an external load after reconfigurations.
ER  - 

TY  - CONF
TI  - A Novel Variable Stiffness Actuator Based on Pneumatic Actuation and Supercoiled Polymer Artificial Muscles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 3983
EP  - 3989
AU  - Y. Yang
AU  - Z. Kan
AU  - Y. Zhang
AU  - Y. A. Tse
AU  - M. Y. Wang
PY  - 2019
KW  - bending
KW  - control system synthesis
KW  - elastic constants
KW  - electroactive polymer actuators
KW  - pneumatic actuators
KW  - polymers
KW  - position control
KW  - pressure control
KW  - variable structure systems
KW  - supercoiled polymer artificial muscles
KW  - variable stiffness soft actuator
KW  - soft pneumatic actuation
KW  - muscle-like supercoiled polymer actuation
KW  - soft pneumatic actuator
KW  - SCP actuation
KW  - soft robot locomotion
KW  - soft robot manipulation
KW  - stiffness tuning
KW  - pressure control
KW  - SCP artificial muscle tension
KW  - Muscles
KW  - Pneumatic actuators
KW  - Soft robotics
KW  - Fabrication
KW  - Strain
DO  - 10.1109/ICRA.2019.8793844
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This article describes an innovative design of variable stiffness soft actuator, which can potentially be utilized for manipulation and locomotion of soft robots. The new actuator is a combination of two types of actuations: soft pneumatic actuation and muscle-like supercoiled polymer (SCP) actuation. Soft pneumatic actuator has two roles: first is to generate bending motions and second is to increase the stiffness of the whole actuator together with SCP artificial muscles. SCP artificial muscles are exploited to generate pre-load to resist the whole actuator from (excessive) deformation when external load is applied. These two types of actuations are arranged antagonistically to realize stiffness tuning of the whole actuator. At a given bending position, stiffness of the actuator could be tuned by controlling the pressure inside the air chamber and the tension on the SCP artificial muscles. In experimental section, tests are conducted to characterize the applied SCP artificial muscles before they are applied to the proposed actuator. Afterwards, tests of proposed actuator are performed to examine its variable stiffness capability. From experimental results, the proposed actuator can achieve 3.47 times stiffness variation ratio from 0.0312 N/mm(40kPa air pressure and no SCP actuation) to 0.1083 N/mm(82kPa air pressure and SCP actuation at 0.143 W/cm) at the same position (bending angle of 56 degree). This study exhibits the potential of applying SCP artificial muscles to promote the performance of soft robots.
ER  - 

TY  - CONF
TI  - A Novel Iterative Learning Model Predictive Control Method for Soft Bending Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4004
EP  - 4010
AU  - Z. Q. Tang
AU  - H. L. Heung
AU  - K. Y. Tong
AU  - Z. Li
PY  - 2019
KW  - actuators
KW  - bending
KW  - elasticity
KW  - iterative learning control
KW  - predictive control
KW  - robots
KW  - soft bending actuators
KW  - soft robots
KW  - pseudorigid-body model
KW  - bending behavior
KW  - learning curve
KW  - learning process
KW  - soft-elastic composite actuator
KW  - iterative learning model predictive control method
KW  - Mathematical model
KW  - Predictive models
KW  - Soft robotics
KW  - Actuators
KW  - Iterative methods
KW  - Predictive control
KW  - Computational modeling
KW  - Soft Material Robotics
KW  - Motion Control
KW  - Model Learning for Control
DO  - 10.1109/ICRA.2019.8793871
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Soft robots attract research interests worldwide. However, its control remains challenging due to the difficulty in sensing and accurate modeling. In this paper, we propose a novel iterative learning model predictive control (ILMPC) method for soft bending actuators. The uniqueness of our approach is the ability to improve model accuracy gradually. In this method, a pseudo-rigid-body model is used to take an initial guess of the bending behavior of the actuator and the model accuracy is improved with iterative learning. Compared with conventional model free iterative learning control (ILC), the proposed method significantly reduces the learning curve. Compared with the model predictive control (MPC), the proposed method does not rely on an accurate model and it will output a satisfactory model after the learning process. A soft-elastic composite actuator (SECA) is used to validate the proposed method. Both simulation and experimental results show that the proposed method outperforms the conventional MPC and ILC.
ER  - 

TY  - CONF
TI  - Design and Experimental Validation of a 2DOF Sidestick Powered by Hyper-Redundant Magnetorheological Actuators Providing Active Feedback
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4011
EP  - 4017
AU  - M. Bégin
AU  - M. Denninger
AU  - J. Plante
PY  - 2019
KW  - aerospace components
KW  - aerospace control
KW  - closed loop systems
KW  - clutches
KW  - control system synthesis
KW  - force control
KW  - force feedback
KW  - haptic interfaces
KW  - interactive devices
KW  - magnetic actuators
KW  - magnetorheology
KW  - man-machine systems
KW  - jam-free design
KW  - actuation strategy
KW  - tendon driven 2DOF MR powered manipulator
KW  - electromechanical actuators
KW  - human controlled machines
KW  - tendon-driven 2-degree-of-freedom spherical gimbal
KW  - hyper-redundant MR clutches
KW  - closed-loop force control
KW  - electromagnetic actuators
KW  - aerospace flight control
KW  - man-machine interaction
KW  - haptic joysticks
KW  - active feedback
KW  - hyper-redundant magnetorheological actuators
KW  - 2DOF sidestick
KW  - reliability requirements
KW  - system design
KW  - force density
KW  - Force
KW  - Torque
KW  - Reliability
KW  - Aerospace control
KW  - Electromagnetics
KW  - Actuators
KW  - Aircraft
DO  - 10.1109/ICRA.2019.8794346
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Haptic joysticks for man-machine interaction used in aerospace flight control have highly demanding requirements of reliability, force density, and high dynamics that can hardly be met with conventional electromagnetic actuators. This work explores the potential of using an alternative actuation strategy based on hyper-redundant MR clutches that modulate the force of a tendon-driven 2-degree-of-freedom spherical gimbal. A system design and its closed-loop force control scheme are proposed. Experimental results for an open-loop characterization, static force control and dynamic force control are set out and compared with typical requirements for such devices from the literature. Results show that the proposed architecture leads to one of the lightest systems reported in the literature that has the potential to meet reliability requirements by providing a jam-free design with duplex fault tolerance, and yet, can generate high force levels while providing enough force resolution. The approach is promising and can extend to high-performance collaborative robot applications.
ER  - 

TY  - CONF
TI  - A Lightweight Force-Controllable Wearable Arm Based on Magnetorheological-Hydrostatic Actuators
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4018
EP  - 4024
AU  - C. Véronneau
AU  - J. Denis
AU  - L. Lebel
AU  - M. Denninger
AU  - J. Plante
AU  - A. Girard
PY  - 2019
KW  - electromagnetic actuators
KW  - force control
KW  - friction
KW  - human-robot interaction
KW  - magnetorheology
KW  - manipulators
KW  - medical robotics
KW  - motion control
KW  - patient rehabilitation
KW  - robot dynamics
KW  - electromagnetic actuators
KW  - supernumerary robotic limbs
KW  - wearable robots
KW  - human arms
KW  - lightweight SRL
KW  - MR-hydrostatic actuation system
KW  - magnetorheological-hydrostatic actuators
KW  - human environment
KW  - force-control approaches
KW  - elbow joints
KW  - wearable robotic arm
KW  - force-controllable SRL
KW  - low-friction hydrostatic transmission
KW  - interaction forces
KW  - mechanical backdrivability
KW  - size 25.0 nm
KW  - frequency 25.0 Hz
KW  - Force
KW  - Manipulators
KW  - Bandwidth
KW  - Friction
KW  - Hydraulic systems
KW  - Task analysis
KW  - Supernumerary robotic limbs
KW  - Wearable robotic
KW  - Lightweight
KW  - Force-Control
KW  - Magnetorheological
KW  - Hydrostatic Transmission
KW  - High-Bandwidth
KW  - Backdrivability
DO  - 10.1109/ICRA.2019.8793978
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Supernumerary Robotic Limbs (SRLs) are wearable robots augmenting human capabilities by acting as a co-worker, reaching objects, support human arms, etc. However, existing SRLs lack the mechanical backdrivability and bandwidth required for tasks where the interaction forces must be controlled such as painting, drilling, manipulating fragile objects, etc. Being highly backdrivable with a high bandwidth while minimizing weight presents a major technological challenge imposed by the limited performances of conventional electromagnetic actuators. This paper studies the feasibility of using magnetorheological (MR) clutches coupled-to a low-friction hydrostatic transmission to provide a highly capable, but yet lightweight, force-controllable SRL. A 2.7 kg 2-DOFs wearable robotic arm is designed and built. Shoulder and elbow joints are designed to deliver 39 and 25 Nm, with 115 and 180° of range of motion. Experimental studies conducted on a one-DOF test bench and validated analytically demonstrate a high force bandwidth (>25 Hz) and a good ability to control interaction forces even when interacting with an external impedance. Furthermore, three force-control approaches are studied and demonstrated experimentally: open-loop, closed-loop on force, and closed-loop on pressure. All three methods are shown to be effective. Overall, the proposed MR-Hydrostatic actuation system is well-suited for a lightweight SRL interacting with both human and environment that add unpredictable disturbances.
ER  - 

TY  - CONF
TI  - Optical Force Sensing In Minimally Invasive Robotic Surgery
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4033
EP  - 4039
AU  - A. H. H. Hosseinabadi
AU  - M. Honarvar
AU  - S. E. Salcudean
PY  - 2019
KW  - beams (structures)
KW  - force measurement
KW  - force sensors
KW  - light emitting diodes
KW  - medical robotics
KW  - optical sensors
KW  - prototypes
KW  - shafts
KW  - surgery
KW  - invasive robotic surgery
KW  - bandwidth measurement
KW  - force measurement
KW  - infrared LED-bicell pair
KW  - 3D printed prototype
KW  - structural dynamics
KW  - sensor limitations
KW  - flexible beam model
KW  - differential photocurrent
KW  - instrument shaft
KW  - optical slit
KW  - daVinci EndoWrist instruments
KW  - optical force sensing
KW  - Conferences
KW  - Automation
KW  - Surgical Robotics: Laparoscopy
KW  - Force and Tactile Sensing
KW  - Haptics and Haptic Interfaces
DO  - 10.1109/ICRA.2019.8793589
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper evaluates the feasibility of a novel optical sensing concept to measure forces applied at the tip of daVinci EndoWrist instruments. An optical slit is clamped onto the instrument shaft, in-line with an infrared LED-bicell pair. Deflection of the shaft moves the slit with respect to the LED-bicell pair and modulates the light incident on each active element of the bicell. The differential photocurrent is conditioned and monitored to estimate the tip forces. The feasibility evaluation consists of a flexible beam model to quantify the required sensor performance, experimental results with a 3D printed prototype and estimation of the sensor limitations including the measurement bandwidth due to the structural dynamics. The proposed approach requires no modifications to the instrument, is adaptable to different instruments and robot platforms, and leads to high-resolution, high-dynamic range sensing without hysteresis.
ER  - 

TY  - CONF
TI  - Mechanical Framework Design with Experimental Verification of a Wearable Exoskeleton Chair
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4040
EP  - 4045
AU  - B. Han
AU  - Z. Du
AU  - T. Huang
AU  - T. Zhang
AU  - Z. Li
AU  - O. Bai
AU  - X. Chen
PY  - 2019
KW  - bending
KW  - biomechanics
KW  - electromyography
KW  - ergonomics
KW  - finite element analysis
KW  - medical signal processing
KW  - orthotics
KW  - solid modelling
KW  - HUST-EC
KW  - vastus lateralis
KW  - vastus medialis
KW  - biceps femoris
KW  - rectus femoris
KW  - muscle activation
KW  - chair height
KW  - bending angles
KW  - chair angles
KW  - MATLAB-based acquisition software
KW  - EMG sensors
KW  - electromyography test platform
KW  - finite element analysis program
KW  - solid models
KW  - prototype chair
KW  - wearable chair design
KW  - human-chair model
KW  - wearable exoskeleton chair
KW  - Conferences
KW  - Automation
KW  - exoskeleton
KW  - wearable chair
KW  - EMG
KW  - mechanism design
DO  - 10.1109/ICRA.2019.8794466
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this study, a human-chair model was developed as the basis for a wearable chair design. A prototype chair, HUST-EC, was fabricated and evaluated. Employing the optimization under an inner point penalty function, an optimized simulation of the operating mode with the lowest chair height was implemented. The solid models were established by using the finite element analysis program embedded in Solidworks, which revealed that the support from the designed chair was steady to the user. An electromyography (EMG) test platform has been developed, consisting of four EMG sensors, a MATLAB-based acquisition software, and a loaded vest. Four healthy subjects participated in the evaluation experiment, in which EMGs were collected from the muscle groups of rectus femoris, biceps femoris, vastus medialis, and vastus lateralis under different loads and chair angles. The experimental data demonstrate that (1) the HUST-EC can greatly reduce muscle activation at a variety of loads and bending angles; (2) under the same load, the muscle activation decreases slightly with an increased bending angle; and (3) at the same bending angle, muscle activation increases slightly with an increased load. The results show that the designed chair can effectively reduce the physical burden in workers and may improve work efficiency.
ER  - 

TY  - CONF
TI  - KO-Fusion: Dense Visual SLAM with Tightly-Coupled Kinematic and Odometric Tracking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4054
EP  - 4060
AU  - C. Houseago
AU  - M. Bloesch
AU  - S. Leutenegger
PY  - 2019
KW  - cameras
KW  - distance measurement
KW  - image colour analysis
KW  - image fusion
KW  - image texture
KW  - manipulator kinematics
KW  - mobile robots
KW  - motion estimation
KW  - robot vision
KW  - SLAM (robots)
KW  - stereo image processing
KW  - KO-fusion
KW  - dense visual SLAM methods
KW  - observer
KW  - visual information
KW  - SLAM systems
KW  - inertial measurements
KW  - dense RGB-D SLAM system
KW  - wheeled robot
KW  - kinematic data
KW  - odometric data
KW  - kinematic measurements
KW  - tightly-coupled kinematic
KW  - odometric tracking
KW  - manipulator
KW  - odometry measurements
KW  - motion estimation
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Robot vision systems
KW  - Kinematics
KW  - Manipulators
DO  - 10.1109/ICRA.2019.8793471
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Dense visual SLAM methods are able to estimate the 3D structure of an environment and locate the observer within them. They estimate the motion of a camera by matching visual information between consecutive frames, and are thus prone to failure under extreme motion conditions or when observing texture-poor regions. The integration of additional sensor modalities has shown great promise in improving the robustness and accuracy of such SLAM systems. In contrast to the popular use of inertial measurements we propose to tightly-couple a dense RGB-D SLAM system with kinematic and odometry measurements from a wheeled robot equipped with a manipulator. The system has real-time capability while running on GPU. It optimizes the camera pose by considering the geometric alignment of the map as well as kinematic and odometric data from the robot. Through experimentation in the real-world, we show that the system is more robust to challenging trajectories featuring fast and loopy motion than the equivalent system without the additional kinematic and odometric knowledge, whilst retaining comparable performance to the equivalent RGB-D only system on easy trajectories.
ER  - 

TY  - CONF
TI  - Diffraction-Aware Sound Localization for a Non-Line-of-Sight Source
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4061
EP  - 4067
AU  - I. An
AU  - D. Lee
AU  - J. Choi
AU  - D. Manocha
AU  - S. Yoon
PY  - 2019
KW  - acoustic signal processing
KW  - acoustic wave diffraction
KW  - acoustic wave propagation
KW  - particle filtering (numerical methods)
KW  - ray tracing
KW  - generated acoustic rays
KW  - estimated source position
KW  - static NLOS sound sources
KW  - dynamic NLOS sound sources
KW  - actual source locations
KW  - state-of-the-art localization method
KW  - nonline-of-sight source
KW  - sound localization algorithm
KW  - nonline-of-sight sound source
KW  - indoor environments
KW  - diffraction properties
KW  - sound waves
KW  - bending effects
KW  - virtual sound source
KW  - indoor scene
KW  - diffraction acoustic rays
KW  - ray tracing-based sound propagation
KW  - diffraction-aware sound localization
KW  - UTD
KW  - uniform theory of diffraction
KW  - wedge precomputing
KW  - reconstructed mesh
KW  - particle filter
KW  - size 7.0 m
KW  - size 3.0 m
KW  - Diffraction
KW  - Ray tracing
KW  - Three-dimensional displays
KW  - Computational modeling
KW  - Acoustic diffraction
KW  - Robots
DO  - 10.1109/ICRA.2019.8794093
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present a novel sound localization algorithm for a non-line-of-sight (NLOS) sound source in indoor environments. Our approach exploits the diffraction properties of sound waves as they bend around a barrier or an obstacle in the scene. We combine a ray tracing-based sound propagation algorithm with a Uniform Theory of Diffraction (UTD) model, which simulate bending effects by placing a virtual sound source on a wedge in the environment. We precompute the wedges of a reconstructed mesh of an indoor scene and use them to generate diffraction acoustic rays to localize the 3D position of the source. Our method identifies the convergence region of those generated acoustic rays as the estimated source position based on a particle filter. We have evaluated our algorithm in multiple scenarios consisting of static and dynamic NLOS sound sources. In our tested cases, our approach can localize a source position with an average accuracy error of 0.7m, measured by the L2 distance between estimated and actual source locations in a 7m×7m×3m room. Furthermore, we observe 37% to 130% improvement in accuracy over a state-of-the-art localization method that does not model diffraction effects, especially when a sound source is not visible to the robot.
ER  - 

TY  - CONF
TI  - DeepFusion: Real-Time Dense 3D Reconstruction for Monocular SLAM using Single-View Depth and Gradient Predictions
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4068
EP  - 4074
AU  - T. Laidlow
AU  - J. Czarnowski
AU  - S. Leutenegger
PY  - 2019
KW  - cameras
KW  - computerised instrumentation
KW  - graphics processing units
KW  - image fusion
KW  - image reconstruction
KW  - learning (artificial intelligence)
KW  - minimisation
KW  - neurocontrollers
KW  - photometry
KW  - probability
KW  - SLAM (robots)
KW  - stereo image processing
KW  - target tracking
KW  - depth cameras
KW  - CNN
KW  - DeepFusion
KW  - semidense multiview stereo algorithm
KW  - gradient predictions
KW  - monocular SLAM
KW  - single-view depth
KW  - keypoint-based maps
KW  - camera tracking
KW  - dense 3D reconstructions
KW  - convolutional neural network
KW  - sparse monocular simultaneous localisation and mapping systems
KW  - real-time dense 3D reconstruction system
KW  - photometric error minimization
KW  - GPU
KW  - probability
KW  - Image reconstruction
KW  - Uncertainty
KW  - Cameras
KW  - Simultaneous localization and mapping
KW  - Three-dimensional displays
KW  - Real-time systems
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793527
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While the keypoint-based maps created by sparse monocular Simultaneous Localisation and Mapping (SLAM) systems are useful for camera tracking, dense 3D reconstructions may be desired for many robotic tasks. Solutions involving depth cameras are limited in range and to indoor spaces, and dense reconstruction systems based on minimising the photometric error between frames are typically poorly constrained and suffer from scale ambiguity. To address these issues, we propose a 3D reconstruction system that leverages the output of a Convolutional Neural Network (CNN) to produce fully dense depth maps for keyframes that include metric scale. Our system, DeepFusion, is capable of producing real-time dense reconstructions on a GPU. It fuses the output of a semi-dense multiview stereo algorithm with the depth and gradient predictions of a CNN in a probabilistic fashion, using learned uncertainties produced by the network. While the network only needs to be run once per keyframe, we are able to optimise for the depth map with each new frame so as to constantly make use of new geometric constraints. Based on its performance on synthetic and real world datasets, we demonstrate that DeepFusion is capable of performing at least as well as other comparable systems.
ER  - 

TY  - CONF
TI  - Dynamic Hilbert Maps: Real-Time Occupancy Predictions in Changing Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4091
EP  - 4097
AU  - V. Guizilini
AU  - R. Senanayake
AU  - F. Ramos
PY  - 2019
KW  - Hilbert spaces
KW  - mobile robots
KW  - remotely operated vehicles
KW  - real-time occupancy predictions
KW  - static occupancy models
KW  - continuous occupancy map
KW  - high-dimensional feature space
KW  - data-efficient model
KW  - crowded unstructured outdoor environments
KW  - dynamic Hilbert maps
KW  - temporal dependencies
KW  - 3D laser data
KW  - 2D laser data
KW  - Vehicle dynamics
KW  - Predictive models
KW  - Uncertainty
KW  - Dynamics
KW  - Indexes
KW  - Real-time systems
KW  - Clustering algorithms
DO  - 10.1109/ICRA.2019.8793914
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of learning instantaneous occupancy levels of dynamic environments and predicting future occupancy levels. Due to the complexity of most real environments, such as urban streets or crowded areas, the efficient and robust incorporation of temporal dependencies into otherwise static occupancy models remains a challenge. We propose a method to capture the uncertainty of moving objects and incorporate this uncertainty information into a continuous occupancy map represented in a rich high-dimensional feature space. This data-efficient model not only allows us to learn the occupancy states incrementally, but also makes predictions about what the future occupancy states will be. Experiments performed using 2D and 3D laser data collected from crowded unstructured outdoor environments show that the proposed methodology can accurately predict occupancy states for areas of around 1000 m2 at 10 Hz, making the proposed framework ideal for online applications under real-time constraints.
ER  - 

TY  - CONF
TI  - Evaluating the Effectiveness of Perspective Aware Planning with Panoramas
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4098
EP  - 4103
AU  - D. Mox
AU  - A. Cowley
AU  - M. A. Hsieh
AU  - C. J. Taylor
PY  - 2019
KW  - image colour analysis
KW  - image sensors
KW  - object detection
KW  - path planning
KW  - robot vision
KW  - SLAM (robots)
KW  - binary coverage
KW  - goal selection strategy
KW  - image morphology
KW  - search space
KW  - CSQMI
KW  - perspective aware planning
KW  - information based exploration strategy
KW  - high resolution 3D maps
KW  - RGBD panoramas
KW  - angle enhanced occupancy grid
KW  - exploration strategy
KW  - maximal Cauchy-Schwarz quadratic mutual information
KW  - logging image control
KW  - Skeleton
KW  - Mutual information
KW  - Task analysis
KW  - Cameras
KW  - Robot vision systems
DO  - 10.1109/ICRA.2019.8793897
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we present an information based exploration strategy tailored for the generation of high resolution 3D maps. We employ RGBD panoramas because they have been shown to provide memory efficient high quality representations of space. Robots explore the environment by selecting locations with maximal Cauchy-Schwarz Quadratic Mutual Information (CSQMI) computed on an angle enhanced occupancy grid to collect these RGBD panoramas. By employing the angle enhanced occupancy grid, the resulting exploration strategy emphasizes perspective in addition to binary coverage. Furthermore, the goal selection strategy is improved by using image morphology to reduce the search space over which CSQMI is computed. We present experimental results demonstrating the improved performance in perception related tasks by capturing panoramas using this approach, near frontier exploration, and a control of logging images at regular intervals while teleoperating the robot through the workspace. Collect imagery was passed through an object detection library with our perspective aware approach yielding a greater number of successful detections compared to near frontier exploration.
ER  - 

TY  - CONF
TI  - Actively Improving Robot Navigation On Different Terrains Using Gaussian Process Mixture Models
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4104
EP  - 4110
AU  - L. Nardi
AU  - C. Stachniss
PY  - 2019
KW  - Gaussian processes
KW  - mixture models
KW  - mobile robots
KW  - navigation
KW  - path planning
KW  - robot navigation
KW  - outdoor environments
KW  - place-dependent model
KW  - aerial image
KW  - path planning
KW  - Gaussian process mixture model
KW  - Robots
KW  - Navigation
KW  - Vibrations
KW  - Mixture models
KW  - Energy consumption
KW  - Gaussian processes
KW  - Planning
DO  - 10.1109/ICRA.2019.8794079
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Robot navigation in outdoor environments is exposed to detrimental factors such as vibrations or power consumption due to the different terrains on which the robot navigates. In this paper, we address the problem of actively improving navigation by planning paths that aim at reducing over time phenomena such as vibrations during traversal. Our approach uses a Gaussian Process (GP) mixture model and an aerial image of the environment to learn and improve continuously a place-dependent model of such phenomena from the experiences of the robot. We use this model to plan paths that trade-off the exploration of unknown promising regions and the exploitation of known areas where the impact of the detrimental factors on navigation is low, leading to an improved navigation over time. We implemented our approach and thoroughly tested it using real-world data. Our experiments suggest that our approach with no initial information leads the robot, after few runs, to follow paths along which it experiences similar vibrations or energy consumption as if it was following the optimal path computed given the ground truth information.
ER  - 

TY  - CONF
TI  - Continuous Occupancy Map Fusion with Fast Bayesian Hilbert Maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4111
EP  - 4117
AU  - W. Zhi
AU  - L. Ott
AU  - R. Senanayake
AU  - F. Ramos
PY  - 2019
KW  - Bayes methods
KW  - image fusion
KW  - mobile robots
KW  - multi-robot systems
KW  - SLAM (robots)
KW  - multirobot Hilbert Map systems
KW  - individual Fast-BHMs
KW  - decentralised manner
KW  - continuous representation
KW  - robot autonomy
KW  - traditional occupancy grid maps
KW  - continuous nature
KW  - continuous occupancy map fusion
KW  - fused fast-BHMs
KW  - global fast-BHM models
KW  - Bayesian Hilbert map models
KW  - fast Bayesian Hilbert maps
KW  - Bayes methods
KW  - Robots
KW  - Covariance matrices
KW  - Merging
KW  - Time complexity
KW  - Real-time systems
KW  - Training
DO  - 10.1109/ICRA.2019.8793508
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mapping the occupancy of an environment is central for robot autonomy. Traditional occupancy grid maps discretise the environment into independent cells, neglecting important spatial correlations, and are unable to capture the continuous nature of the real world. With these drawbacks of grid maps in mind, Hilbert Maps (HM) and more recently Bayesian Hilbert Maps (BHMs), were introduced as a continuous representation of the environment. In this paper we propose a method to merge Bayesian Hilbert Maps built by a team of robots in a decentralised manner. The training of BHMs requires the inversion of a large covariance matrix, incurring cubic complexity. We introduce an approximation, Fast Bayesian Hilbert Maps (Fast-BHM), which reduces the time complexity to below quadratic. Such speed-ups allow the building and merging of Bayesian Hilbert Map models to be practical, opening the door for multi-robot Hilbert Map systems which can be much faster and more robust than an individual robot. By merging several individual Fast-BHMs in a decentralised manner we obtain a unified model of the environment which is itself a Fast-BHM. We conduct experiments to show that global Fast-BHM models do not deteriorate after repeated merging and training. We then empirically demonstrate, due to its the compact representation, fused Fast-BHMs outperform fusion methods involving discretising continuous representations, when the amount of information communicated is limited.
ER  - 

TY  - CONF
TI  - Fault-tolerant Flight Control of a VTOL Tailsitter UAV
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4134
EP  - 4140
AU  - S. Fuhrer
AU  - S. Verling
AU  - T. Stastny
AU  - R. Siegwart
PY  - 2019
KW  - actuators
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - fault tolerant control
KW  - remotely operated vehicles
KW  - minimalistic actuation
KW  - possible actuator failures
KW  - light-weight adaptations
KW  - nominal flight controller
KW  - tailsitter VTOL aircraft
KW  - fault-tolerant flight control
KW  - landing systems
KW  - moving parts
KW  - vertical take-off and landing systems
KW  - Propellers
KW  - Actuators
KW  - Aircraft
KW  - Aerospace electronics
KW  - Force
KW  - Fault tolerance
KW  - Fault tolerant systems
DO  - 10.1109/ICRA.2019.8793467
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Compared to other vertical take-off and landing (VTOL) systems, a tailsitter minimizes the number of actuators and moving parts necessary. The downside of having a minimalistic actuation is its inherent low fault-tolerance. The failure of an actuator usually results in a loss of controllability, resulting in a crash. In this paper we analyze possible actuator failures and the constraints they pose on the capabilities of the system. We further present light-weight adaptations to the nominal flight controller to make it fault-tolerant. The fault-tolerant controller is implemented on a small tailsitter VTOL aircraft and adjusted to the system by means of extensive experimental studies. Finally, the capabilities and performance under failures are demonstrated and analyzed.
ER  - 

TY  - CONF
TI  - Modeling and Control of a Passively-Coupled Tilt-Rotor Vertical Takeoff and Landing Aircraft
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4141
EP  - 4147
AU  - R. Chiappinelli
AU  - M. Cohen
AU  - M. Doff-Sotta
AU  - M. Nahon
AU  - J. R. Forbes
AU  - J. Apkarian
PY  - 2019
KW  - actuators
KW  - aerospace components
KW  - aircraft control
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - cascade control
KW  - control system synthesis
KW  - helicopters
KW  - hinges
KW  - mobile robots
KW  - propellers
KW  - rotors (mechanical)
KW  - three-term control
KW  - velocity control
KW  - quadrotor frame
KW  - fixed-wing aircraft
KW  - hover
KW  - forward flight
KW  - tilting actuators
KW  - coupled dynamics
KW  - aircraft frame
KW  - cascaded control architecture
KW  - control design
KW  - forward velocity control
KW  - passively-coupled tilt-rotor vertical takeoff and landing aircraft
KW  - differential thrust
KW  - propellers
KW  - inner-loop attitude
KW  - height control
KW  - constrained Lagrangian approach
KW  - P-PID controllers
KW  - unactuated hinged mechanism
KW  - equations of motion
KW  - unmanned aerial vehicles
KW  - UAVs
KW  - Aircraft
KW  - Mathematical model
KW  - Atmospheric modeling
KW  - Aerodynamics
KW  - Aerospace control
KW  - Rotors
KW  - Angular velocity
KW  - Vertical takeoff and landing aircraft
KW  - passively-coupled tilt-rotor
KW  - dynamic modeling
KW  - cascade PID control
KW  - PX4 autopilot
DO  - 10.1109/ICRA.2019.8793606
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the modeling and control of a passively-coupled tilt-rotor vertical takeoff and landing aircraft. The aircraft consists of a quadrotor frame attached to a fixed-wing aircraft by an unactuated hinged mechanism. The platform is capable of smooth transitions from hover to forward flight without the use of tilting actuators. The transition from hover to forward flight is made possible by differential thrust between the fore and aft propellers of the quadrotor frame. In this paper, the coupled dynamics between the quadrotor frame and the aircraft frame are modeled as a constrained multi-body system. The equations of motion are established using a constrained Lagrangian approach and the model developed is used to build a realistic simulation environment for control design purpose. A cascaded control architecture based on P/PID controllers is proposed to achieve inner-loop attitude, height and forward velocity control. Simulated and experimental results are obtained with a close match for hover, transitions, forward flight, and banked turn maneuvers.
ER  - 

TY  - CONF
TI  - Power-Minimizing Control of a Variable-Pitch Propulsion System for Versatile Unmanned Aerial Vehicles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4148
EP  - 4153
AU  - T. Henderson
AU  - N. Papanikolopoulos
PY  - 2019
KW  - aerospace propulsion
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - motion control
KW  - pitch control (position)
KW  - power consumption
KW  - power control
KW  - propellers
KW  - robot dynamics
KW  - propeller design
KW  - propeller-based propulsion mechanisms
KW  - variable-pitch propeller
KW  - versatile UAVs
KW  - quasisteady propulsive state
KW  - power-minimizing control
KW  - electrical power consumption
KW  - versatile unmanned aerial vehicles
KW  - variable-pitch propulsion system
KW  - Power demand
KW  - Propellers
KW  - Servomotors
KW  - Unmanned aerial vehicles
KW  - Brushless DC motors
DO  - 10.1109/ICRA.2019.8794357
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In response to an abundance of applications, Unmanned Aerial Vehicles are being called upon to perform missions of high difficulty for increasingly long periods of time. Traditional paradigms of propeller design and actuation are reaching a design ceiling, motivating creative approaches to the design of propeller-based propulsion mechanisms. Within the last decade, one particular kind of mechanism, the variable-pitch propeller, has been studied by researchers for its applications to the class of small UAVs. This paper pushes for new results in this area by exploring the use of Variable Pitch Propulsion (VPP) to minimize power consumption for small, versatile UAVs. A control algorithm is presented to minimize the consumed electrical power during a quasi-steady propulsive state. In particular, the algorithm is not confined to operation in limited regions of the state space, but it seeks to minimize power at whatever point in the state space a steady state is reached. Several experimental results are presented to validate the approach.
ER  - 

TY  - CONF
TI  - Rapid Inertial Reorientation of an Aerial Insect-sized Robot Using a Piezo-actuated Tail
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4154
EP  - 4160
AU  - A. Singh
AU  - T. Libby
AU  - S. B. Fuller
PY  - 2019
KW  - aerodynamics
KW  - aerospace robotics
KW  - feedforward
KW  - gears
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - open loop systems
KW  - piezoelectric actuators
KW  - stability
KW  - rapid inertial reorientation
KW  - aerial insect-sized robot
KW  - bio-inspired inertial tail
KW  - DC electric motor
KW  - geared motor system
KW  - piezo-tail system
KW  - resonant system
KW  - piezo-driven inertial reorientation
KW  - open-loop feedforward controller
KW  - rapid dynamic maneuvers
KW  - piezoactuator
KW  - mass 142.0 mg
KW  - Actuators
KW  - Robots
KW  - Analytical models
KW  - Torque
KW  - Fabrication
KW  - Aerodynamics
KW  - Prototypes
DO  - 10.1109/ICRA.2019.8793948
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We present the design, fabrication, and feedforward control of a insect-sized (142 mg) aerial robot that is equipped with a bio-inspired inertial tail. A tail allows the robot to perform rapid inertial reorientation as well as to shift weight to modulate aerodynamic torques on its body. Here we present the first analysis of inertial reorientation using a piezo actuator, departing from previous work to date that has focused exclusively on actuation by DC electric motor. The primary difference is that unlike a geared motor system, the piezo-tail system operates as a resonant system, exhibiting slowly-decaying oscillations. We present a dynamic model of piezo-driven inertial reorientation, along with an open-loop feedforward controller that reduces excitation of the resonant mode. We validate our approach on a tethered testbed as well as a flight-capable prototype. Our results indicate that incorporating a tail can allow for more rapid dynamic maneuvers and could stabilize the robot during flight.
ER  - 

TY  - CONF
TI  - Contact–based Navigation Path Planning for Aerial Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4161
EP  - 4167
AU  - N. Khedekar
AU  - F. Mascarich
AU  - C. Papachristos
AU  - T. Dang
AU  - K. Alexis
PY  - 2019
KW  - autonomous aerial vehicles
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - robot dynamics
KW  - robot kinematics
KW  - aerial robots
KW  - in-contact operation
KW  - contact missions
KW  - flying robot
KW  - navigation mode
KW  - cartwheel mode
KW  - navigation modalities
KW  - in-contact navigation
KW  - specialized contact mechanism
KW  - contact-based navigation path planning
KW  - Navigation
KW  - Task analysis
KW  - Unmanned aerial vehicles
KW  - Inspection
KW  - Path planning
KW  - Mobile robots
DO  - 10.1109/ICRA.2019.8793794
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper the problem of contact-based navigation path planning for aerial robots is considered with the goal of enabling the autonomous in-contact operation on surfaces that can be highly anomalous. Such a capacity can prove critical in inspection through contact missions, as well as when a flying robot is tasked to operate in very narrow environments rendering safe free-flight impossible. To achieve this objective, beyond sliding in contact, a new locomotion primitive is introduced, namely that of azimuth rotations perpendicular to the surface under consideration. This new navigation mode, called flying cartwheel mode, offers navigation resourcefulness and resilience when the system is tasked to move in contact with surfaces that are otherwise non-traversable. The designed path planning method exploits both navigation modalities and a traversability metric to decide when to switch from sliding to flying cartwheel mode, and overall provides cost-optimal trajectories for in-contact navigation. The proposed approach is verified both in simulation, as well as experimentally using a surface presenting complex anomalies. It is highlighted that the proposed method does not assume any specialized contact mechanism or a control law tailored to physical interaction tasks, and hence is applicable to almost any micro aerial vehicle integrating protective shrouds around its propellers.
ER  - 

TY  - CONF
TI  - Cargo Transportation Strategy using T3-Multirotor UAV
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4168
EP  - 4173
AU  - S. J. Lee
AU  - D. Lee
AU  - H. J. Kim
PY  - 2019
KW  - attitude control
KW  - autonomous aerial vehicles
KW  - freight handling
KW  - helicopters
KW  - motion control
KW  - servomechanisms
KW  - cargo transportation strategy
KW  - stable flight performance
KW  - constant flight performance
KW  - fuselage part
KW  - relative attitude control strategy
KW  - T3-multirotor UAV platform
KW  - thrust generating part
KW  - servomechanism
KW  - moment of inertia
KW  - motion control
KW  - Mathematical model
KW  - Servomechanisms
KW  - Attitude control
KW  - Torque
KW  - Transportation
KW  - Radio frequency
DO  - 10.1109/ICRA.2019.8794203
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we introduce a cargo transportation method with a new type of multi-rotor UAV platform known as T3-multirotor, to achieve stable and constant flight performance regardless of the type of cargo attached to the fuselage. The T3-multirotor, which consists of the `Thrust Generating Part' and the `Fuselage Part', can directly control the relative attitude between the two parts using the novel servomechanism. By utilizing the servomechanism with the proposed relative attitude control strategy, the T3-multirotor with cargo attached to the fuselage part can behave as a multi-rotor with only the moment of inertia of the thrust generating part during entire transportation. This allows the T3-multirotor to achieve the reliable performance in the event of any cargo being attached to the fuselage, achieving stable platform motion control. Detailed hardware description and dynamic analysis of T3-Multirotor is performed in this paper, and the validity of the proposed control strategy is also analyzed. The feasibility of the proposed control strategy is verified through experimental results with analysis.
ER  - 

TY  - CONF
TI  - Experimental Learning of a Lift-Maximizing Central Pattern Generator for a Flapping Robotic Wing
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 1997
EP  - 2003
AU  - Y. E. Bayiz
AU  - S. Hsu
AU  - A. N. Aguiles
AU  - Y. Shade-Alexander
AU  - B. Cheng
PY  - 2019
KW  - aerodynamics
KW  - aerospace components
KW  - autonomous aerial vehicles
KW  - control engineering computing
KW  - gradient methods
KW  - learning (artificial intelligence)
KW  - motion control
KW  - multi-agent systems
KW  - robot dynamics
KW  - robot kinematics
KW  - robot programming
KW  - experimental learning
KW  - lift-maximizing central pattern generator
KW  - flapping robotic wing
KW  - policy gradient algorithm
KW  - dynamically scaled robotic wing
KW  - constant Reynolds number
KW  - central pattern generator model
KW  - CPG
KW  - motion controller
KW  - rhythmic wing motion patterns
KW  - half-stroke symmetry constraint
KW  - learning agent
KW  - robotic learning
KW  - wing kinematic learning
KW  - Kinematics
KW  - Robots
KW  - Oscillators
KW  - Trajectory
KW  - Servomotors
KW  - Heuristic algorithms
KW  - Computational modeling
DO  - 10.1109/ICRA.2019.8794016
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we present an application of a policy gradient algorithm to a real-time robotic learning problem, where the goal is to maximize the average lift generation of a dynamically scaled robotic wing at a constant Reynolds number (Re). Compared to our previous work, the merit of this work is two-fold. First, a central pattern generator (CPG) model was used as the motion controller, which provided a smooth generation and transition of rhythmic wing motion patterns while the CPG was being updated by the policy gradient, thereby accelerating the sample generation and reducing the total learning time. Second, the kinematics included three degrees of freedom (stroke, deviation, pitching) and were also free of half-stroke symmetry constraint, together they yielded a larger kinematic space which later explored by the policy gradient to maximize the lift generation. The learned wing kinematics used the full range of stroke and deviation to maximize the lift generation, implying that the wing trajectories with larger disk area and lower frequencies were preferred for high lift generation at constant Re. Furthermore, the wing pitching amplitude converged to values between 45°-49° regardless of what the other parameters were. Notably, the learning agent was able to find two locally optimal wing motion patterns, which had distinct shapes of wing trajectory but generated similar cycle-averaged lift.
ER  - 

TY  - CONF
TI  - Toward Lateral Aerial Grasping & Manipulation Using Scalable Suction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4181
EP  - 4186
AU  - C. C. Kessens
AU  - M. Horowitz
AU  - C. Liu
AU  - J. Dotterweich
AU  - M. Yim
AU  - H. L. Edge
PY  - 2019
KW  - grippers
KW  - mobile robots
KW  - self-adjusting systems
KW  - stability
KW  - scalable suction
KW  - aerial robot
KW  - lateral physical work
KW  - ground-based robots
KW  - functional work
KW  - lateral force
KW  - hovering vehicle
KW  - environmental forces
KW  - self-sealing suction cup
KW  - flight vehicle
KW  - physical grasping demonstrations
KW  - suction-based gripper
KW  - Grippers
KW  - Force
KW  - Spirals
KW  - Propulsion
KW  - Electron tubes
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8793672
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper is an initial step toward the realization of an aerial robot that can perform lateral physical work, such as drilling a hole or fastening a screw in a wall. Aerial robots are capable of high maneuverability and can provide access to locations that would be difficult or impossible for ground-based robots to reach. However, to fully utilize this mobility, systems would ideally be able to perform functional work in those locations, requiring the ability to exert lateral forces. To substantially improve a hovering vehicle's ability to stably deliver large lateral forces, we propose the use of a versatile suction-based gripper that can establish pulling contact on featureless surfaces. Such contact enables access to environmental forces that can be used to further stabilize the vehicle and also increase the lateral force delivered to the surface through a possible secondary mechanism. This paper introduces the concept, describes the design of a new self-sealing suction cup based on a previous design, details the design of a gripper using those cups, and describes the arm and flight vehicle. It then evaluates the cup and gripper performance in several ways, culminating in physical grasping demonstrations using the arm and gripper, including one in the presence of simulated flight noise based on data from preliminary indoor flight experiments.
ER  - 

TY  - CONF
TI  - Design and Implementation of Computer Vision based In-Row Weeding System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4218
EP  - 4224
AU  - X. Wu
AU  - S. Aravecchia
AU  - C. Pradalier
PY  - 2019
KW  - agricultural robots
KW  - agrochemicals
KW  - cameras
KW  - crops
KW  - feature extraction
KW  - mobile robots
KW  - robot vision
KW  - spraying
KW  - sustainable development
KW  - computer vision
KW  - autonomous robotic weeding systems
KW  - precision farming
KW  - current dependency
KW  - herbicides
KW  - pesticides
KW  - selective spraying
KW  - mechanical weed removal modules
KW  - environmental pollution
KW  - real-time treatment
KW  - weeding control system
KW  - indeterminate classification delays
KW  - in-row weeding system design
KW  - sustainability
KW  - nonoverlapping multicamera system
KW  - terrain conditions
KW  - Cameras
KW  - Agriculture
KW  - Delays
KW  - Control systems
KW  - Robots
KW  - Three-dimensional displays
KW  - Tracking
DO  - 10.1109/ICRA.2019.8793974
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Autonomous robotic weeding systems in precision farming have demonstrated their full potential to alleviate the current dependency on herbicides or pesticides by introducing selective spraying or mechanical weed removal modules, thus reducing the environmental pollution and improving the sustainability. However, most previous works require fast weed detection system to achieve real-time treatment. In this paper, a novel computer vision based weeding control system is presented, where a non-overlapping multi-camera system is introduced to compensate the indeterminate classification delays, thus allowing for more complicated and advanced detection algorithms, e.g. deep learning based methods. The suitable tracking and control strategies are developed to achieve accurate and robust in-row weed treatment, and the performance of the proposed system is evaluated in different terrain conditions in the presence of various delays.
ER  - 

TY  - CONF
TI  - LSTM-based Network for Human Gait Stability Prediction in an Intelligent Robotic Rollator
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4225
EP  - 4232
AU  - G. Chalvatzaki
AU  - P. Koutras
AU  - J. Hadfield
AU  - X. S. Papageorgiou
AU  - C. S. Tzafestas
AU  - P. Maragos
PY  - 2019
KW  - adaptive control
KW  - control engineering computing
KW  - gait analysis
KW  - geriatrics
KW  - handicapped aids
KW  - image colour analysis
KW  - intelligent robots
KW  - Kalman filters
KW  - laser ranging
KW  - learning (artificial intelligence)
KW  - medical robotics
KW  - mobile robots
KW  - nonlinear filters
KW  - pose estimation
KW  - robust control
KW  - state estimation
KW  - legs positions
KW  - UKF
KW  - pose estimation
KW  - deep learning
KW  - laser range finder data
KW  - augmented gait state estimation
KW  - human gait stability predictor
KW  - user-adaptive control architecture
KW  - unscented Kalman filter
KW  - body center of mass
KW  - long short term memory networks
KW  - robust predictions
KW  - encoder-decoder sequence
KW  - LRF data
KW  - nonwearable sensors
KW  - multimodal RGB-D
KW  - elderly users
KW  - intelligent robotic rollator
KW  - LSTM-based network
KW  - Stability analysis
KW  - Legged locomotion
KW  - Laser stability
KW  - Robot sensing systems
KW  - Senior citizens
DO  - 10.1109/ICRA.2019.8793899
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work, we present a novel framework for on-line human gait stability prediction of the elderly users of an intelligent robotic rollator using Long Short Term Memory (LSTM) networks, fusing multimodal RGB-D and Laser Range Finder (LRF) data from non-wearable sensors. A Deep Learning (DL) based approach is used for the upper body pose estimation. The detected pose is used for estimating the body Center of Mass (CoM) using Unscented Kalman Filter (UKF). An Augmented Gait State Estimation framework exploits the LRF data to estimate the legs' positions and the respective gait phase. These estimates are the inputs of an encoder-decoder sequence to sequence model which predicts the gait stability state as Safe or Fall Risk walking. It is validated with data from real patients, by exploring different network architectures, hyperparameter settings and by comparing the proposed method with other baselines. The presented LSTM-based human gait stability predictor is shown to provide robust predictions of the human stability state, and thus has the potential to be integrated into a general user-adaptive control architecture as a fall-risk alarm.
ER  - 

TY  - CONF
TI  - Urban Swarms: A new approach for autonomous waste management
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4233
EP  - 4240
AU  - A. L. Alfeo
AU  - E. C. Ferrer
AU  - Y. L. Carrillo
AU  - A. Grignard
AU  - L. A. Pastor
AU  - D. T. Sleeper
AU  - M. G. C. A. Cimino
AU  - B. Lepri
AU  - G. Vaglini
AU  - K. Larson
AU  - M. Dorigo
AU  - A. Pentland
PY  - 2019
KW  - geographic information systems
KW  - mobile robots
KW  - multi-robot systems
KW  - navigation
KW  - path planning
KW  - refuse disposal
KW  - service robots
KW  - garbage collection scenarios
KW  - urban swarms
KW  - ecosystems
KW  - bio-inspired foraging methods
KW  - multiplace foraging
KW  - real-world GIS data
KW  - robot swarms
KW  - urban waste management system
KW  - stigmergy-based navigation
KW  - urban environment
KW  - swarm robotics system
KW  - autonomous waste management
KW  - Robots
KW  - Urban areas
KW  - Roads
KW  - Waste management
KW  - RFID tags
KW  - Swarm robotics
KW  - Batteries
DO  - 10.1109/ICRA.2019.8794020
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Modern cities are growing ecosystems that face new challenges due to the increasing population demands. One of the many problems they face nowadays is waste management, which has become a pressing issue requiring new solutions. Swarm robotics systems have been attracting an increasing amount of attention in the past years and they are expected to become one of the main driving factors for innovation in the field of robotics. The research presented in this paper explores the feasibility of a swarm robotics system in an urban environment. By using bio-inspired foraging methods such as multi-place foraging and stigmergy-based navigation, a swarm of robots is able to improve the efficiency and autonomy of the urban waste management system in a realistic scenario. To achieve this, a diverse set of simulation experiments was conducted using real-world GIS data and implementing different garbage collection scenarios driven by robot swarms. Results presented in this research show that the proposed system outperforms current approaches. Moreover, results not only show the efficiency of our solution, but also give insights about how to design and customize these systems.
ER  - 

TY  - CONF
TI  - Automated Aortic Pressure Regulation in ex vivo Heart Perfusion
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4241
EP  - 4246
AU  - L. Xin
AU  - W. Yao
AU  - Y. Peng
AU  - N. Qi
AU  - M. Badiwala
AU  - Y. Sun
PY  - 2019
KW  - adaptive control
KW  - blood vessels
KW  - cardiovascular system
KW  - haemodynamics
KW  - physiological models
KW  - automated aortic pressure regulation
KW  - physiological aerobic metabolism
KW  - ex vivo heart perfusion
KW  - aortic pressure regulation
KW  - isolated porcine heart
KW  - animal hearts
KW  - control parameters
KW  - adaptation algorithm
KW  - virtual controller forms
KW  - nonlinear equivalent circuit fluid flow model
KW  - perfusion system
KW  - mathematical model
KW  - AoP regulation
KW  - adaptive controller
KW  - Heart
KW  - Adaptation models
KW  - Integrated circuit modeling
KW  - Mathematical model
KW  - Biochemistry
KW  - Predictive models
KW  - Trajectory
DO  - 10.1109/ICRA.2019.8793745
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the first system for automated ex vivo perfusion of an isolated heart and regulating the heart's aortic pressure (AoP). An adaptive controller was developed for AoP regulation and maintained the heart's physiological aerobic metabolism. A mathematical model of the perfusion system was established based on a nonlinear equivalent circuit fluid flow model. The model combined with a virtual controller forms a reference model to generate the ideal trajectory of AoP. An adaptation algorithm tunes the control parameters based on the reference model and the isolated heart. Experiments were conducted using large animal hearts (55±5 kg porcine, n=6) to validate the adaptive controller's performance for stepwise and fast switching AoP references. The results confirmed that the the proposed controller is able to regulate the AoP of an isolated porcine heart in an accurate (mean error less than 2 mmHg) and fast (4~8 s of settling time) manner.
ER  - 

TY  - CONF
TI  - A Multi-Vehicle Trajectories Generator to Simulate Vehicle-to-Vehicle Encountering Scenarios
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4255
EP  - 4261
AU  - W. Ding
AU  - W. Wang
AU  - D. Zhao
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - position control
KW  - remotely operated vehicles
KW  - road traffic
KW  - road vehicles
KW  - vehicle-to-vehicle encountering scenarios
KW  - autonomous vehicle development
KW  - multivehicle trajectory generator
KW  - MTG
KW  - multivehicle interaction scenarios
KW  - driving encounter scenarios
KW  - multibranch decoder
KW  - vehicle-to-vehicle encounters
KW  - autonomous vehicles
KW  - Trajectory
KW  - Measurement
KW  - Decoding
KW  - Generators
KW  - Bidirectional control
KW  - Generative adversarial networks
KW  - Stability analysis
DO  - 10.1109/ICRA.2019.8793776
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Generating multi-vehicle trajectories from existing limited data can provide rich resources for autonomous vehicle development and testing. This paper introduces a multi-vehicle trajectory generator (MTG) that can encode multi-vehicle interaction scenarios (called driving encounters) into an interpretable representation from which new driving encounter scenarios are generated by sampling. The MTG consists of a bi-directional encoder and a multi-branch decoder. A new disentanglement metric is then developed for model analyses and comparisons in terms of model robustness and the independence of the latent codes. Comparison of our proposed MTG with β-VAE and InfoGAN demonstrates that the MTG has stronger capability to purposely generate rational vehicle-to-vehicle encounters through operating the disentangled latent codes. Thus the MTG could provide more data for engineers and researchers to develop testing and evaluation scenarios for autonomous vehicles.
ER  - 

TY  - CONF
TI  - Deep n-Shot Transfer Learning for Tactile Material Classification with a Flexible Pressure-Sensitive Skin
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4262
EP  - 4268
AU  - B. Bäuml
AU  - A. Tulbure
PY  - 2019
KW  - convolutional neural nets
KW  - haptic interfaces
KW  - learning (artificial intelligence)
KW  - pattern classification
KW  - 1-shot learning
KW  - knowledge transfer
KW  - deep n-shot transfer learning
KW  - tactile material classification
KW  - flexible pressure-sensitive skin
KW  - active sensing tasks
KW  - deep end-to-end transfer learning
KW  - deep convolutional neural network
KW  - superhuman tactile classification performance
KW  - Task analysis
KW  - Robot sensing systems
KW  - Feature extraction
KW  - Training
KW  - Skin
KW  - Learning systems
DO  - 10.1109/ICRA.2019.8794021
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - n-shot learning, i.e., learning a classifier from only few or even one training samples per class, is the ultimate goal in minimizing the cost of sample acquisition. This is esp. important for active sensing tasks like tactile material classification. Achieving high classification accuracy from only few samples is typically possible only when pre-knowledge is used. In n-shot transfer learning, knowledge from pre-training on a large knowledge set with many classes and samples per class has to be transferred to support the training for a given task set with only few samples per new class. In this paper, we show for the first time that deep end-to-end transfer learning is feasible for tactile material classification. Based on the previously presented (TactNet-II) [1], a deep convolutional neural network (CNN) which reaches superhuman tactile classification performance, we adapt state-of-the art deep transfer learning methods. We evaluate the resulting deep n-shot learning methods with a publicly available tactile material data set with 36 materials [1] in a 6-way n-shot learning task with 30 materials in the knowledge set. In 1-shot learning, our deep transfer learning method reaches 75.5% classification accuracy and in 10-shot more than 90%, outperforming classification without knowledge transfer by more than 40%. This results in an up to 15 time reduction in the number of samples needed to reach a desired accuracy level. We also provide insights of the inner workings of the derived deep transfer learning methods.
ER  - 

TY  - CONF
TI  - Towards Effective Tactile Identification of Textures using a Hybrid Touch Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4269
EP  - 4275
AU  - T. Taunyazov
AU  - H. F. Koh
AU  - Y. Wu
AU  - C. Cai
AU  - H. Soh
PY  - 2019
KW  - convolutional neural nets
KW  - feature extraction
KW  - humanoid robots
KW  - image classification
KW  - image texture
KW  - learning (artificial intelligence)
KW  - neurocontrollers
KW  - recurrent neural nets
KW  - robot vision
KW  - tactile sensors
KW  - hybrid touch approach
KW  - human sense
KW  - interacted objects
KW  - standard sensory modalities
KW  - sliding movements
KW  - tactile-based texture classification
KW  - machine-learning methods
KW  - surface textures
KW  - hand-engineered features
KW  - recurrent neural network layers
KW  - feature representations
KW  - tactile data
KW  - touch data
KW  - tactile identification
KW  - sense of touch
KW  - touch movements
KW  - convolutional neural network layers
KW  - iCub platform
KW  - Support vector machines
KW  - Robot sensing systems
KW  - Standards
KW  - Machine learning
KW  - Recurrent neural networks
DO  - 10.1109/ICRA.2019.8793967
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The sense of touch is arguably the first human sense to develop. Empowering robots with the sense of touch may augment their understanding of interacted objects and the environment beyond standard sensory modalities (e.g., vision). This paper investigates the effect of hybridizing touch and sliding movements for tactile-based texture classification. We develop three machine-learning methods within a framework to discriminate between surface textures; the first two methods use hand-engineered features, whilst the third leverages convolutional and recurrent neural network layers to learn feature representations from raw data. To compare these methods, we constructed a dataset comprising tactile data from 23 textures gathered using the iCub platform under a loosely constrained setup, i.e., with nonlinear motion. In line with findings from neuroscience, our experiments show that a good initial estimate can be obtained via touch data, which can be further refined via sliding; combining both touch and sliding data results in 98% classification accuracy over unseen test data.
ER  - 

TY  - CONF
TI  - “Touching to See” and “Seeing to Feel”: Robotic Cross-modal Sensory Data Generation for Visual-Tactile Perception
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4276
EP  - 4282
AU  - J. Lee
AU  - D. Bollegala
AU  - S. Luo
PY  - 2019
KW  - data visualisation
KW  - haptic interfaces
KW  - image texture
KW  - mobile robots
KW  - neural nets
KW  - robot vision
KW  - touch (physiological)
KW  - visual perception
KW  - robotic cross-modal sensory data generation
KW  - visual-tactile perception
KW  - visual-tactile stimulus
KW  - unimodal visual perception
KW  - robotic tasks
KW  - texture perception
KW  - conditional generative adversarial networks
KW  - pseudovisual images
KW  - tactile outputs
KW  - perception performance
KW  - sensory outputs
KW  - ViTac dataset
KW  - Robot sensing systems
KW  - Visualization
KW  - Task analysis
KW  - Image color analysis
KW  - Adaptation models
DO  - 10.1109/ICRA.2019.8793763
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The integration of visual-tactile stimulus is common while humans performing daily tasks. In contrast, using unimodal visual or tactile perception limits the perceivable dimensionality of a subject. However, it remains a challenge to integrate the visual and tactile perception to facilitate robotic tasks. In this paper, we propose a novel framework for the cross-modal sensory data generation for visual and tactile perception. Taking texture perception as an example, we apply conditional generative adversarial networks to generate pseudo visual images or tactile outputs from data of the other modality. Extensive experiments on the ViTac dataset of cloth textures show that the proposed method can produce realistic outputs from other sensory inputs. We adopt the structural similarity index to evaluate similarity of the generated output and real data and results show that realistic data have been generated. Classification evaluation has also been performed to show that the inclusion of generated data can improve the perception performance. The proposed framework has potential to expand datasets for classification tasks, generate sensory outputs that are not easy to access, and also advance integrated visual-tactile perception.
ER  - 

TY  - CONF
TI  - Shear-invariant Sliding Contact Perception with a Soft Tactile Sensor
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4283
EP  - 4289
AU  - K. Aquilina
AU  - D. A. W. Barton
AU  - N. F. Lepora
PY  - 2019
KW  - manipulators
KW  - principal component analysis
KW  - shear deformation
KW  - tactile sensors
KW  - continuous contact data
KW  - shear deformation
KW  - output path-dependent readings
KW  - contact readings
KW  - continuous-contact tasks
KW  - sensor signal
KW  - shear-invariant perception method
KW  - principal component analysis
KW  - sliding motion
KW  - compliant tactile sensor
KW  - continuous tactile contact
KW  - contour-following task
KW  - soft tactile sensor
KW  - manipulation tasks
KW  - tactile perception systems
KW  - shear-invariant sliding contact perception
KW  - Principal component analysis
KW  - Training
KW  - Tactile sensors
KW  - Task analysis
KW  - Feature extraction
DO  - 10.1109/ICRA.2019.8794307
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Manipulation tasks often require robots to be continuously in contact with an object. Therefore tactile perception systems need to handle continuous contact data. Shear deformation causes the tactile sensor to output path-dependent readings in contrast to discrete contact readings. As such, in some continuous-contact tasks, sliding can be regarded as a disturbance over the sensor signal. Here we present a shear-invariant perception method based on principal component analysis (PCA) which outputs the required information about the environment despite sliding motion. A compliant tactile sensor (the TacTip) is used to investigate continuous tactile contact. First, we evaluate the method offline using test data collected whilst the sensor slides over an edge. Then, the method is used within a contour-following task applied to 6 objects with varying curvatures; all contours are successfully traced. The method demonstrates generalisation capabilities and could underlie a more sophisticated controller for challenging manipulation or exploration tasks in unstructured environments.
ER  - 

TY  - CONF
TI  - Soft tactile sensing: retrieving force, torque and contact point information from deformable surfaces
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4290
EP  - 4296
AU  - S. Ciotti
AU  - T. Sun
AU  - E. Battaglia
AU  - A. Bicchi
AU  - H. Liu
AU  - M. Bianchi
PY  - 2019
KW  - force measurement
KW  - force sensors
KW  - iterative methods
KW  - surface topography measurement
KW  - tactile sensors
KW  - torque measurement
KW  - contact point information
KW  - geometric surface description
KW  - contact centroid
KW  - force-deformation characteristics
KW  - force-indentation behavior
KW  - intrinsic soft tactile sensing
KW  - ITS
KW  - iterative procedure
KW  - soft surface deformation characteristics
KW  - ellipsoid silicone specimens
KW  - ROS-based toolbox
KW  - Robot sensing systems
KW  - Force
KW  - Surface impedance
KW  - Mathematical model
KW  - Strain
DO  - 10.1109/ICRA.2019.8794087
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Intrinsic Tactile Sensing (ITS) is a well-established technique, relying on force/torque and geometric surface description to find contact centroids. The method works well for rigid surfaces. However, finding a solution for deformable surfaces is an open issue. This work presents two solutions to extend ITS to deformable surfaces, relying on force-deformation characteristics of the surface under exploration: (i) a closed-form approach that calculates the contact centroid using standard ITS, but on a shrunk geometry approximating the deformed surface; (ii) an iterative procedure that takes into account soft surface deformation, and force/torque equilibrium to minimize a cost function. We have tested both using ellipsoid silicone specimens, with different softness levels and indented along different directions. Both linear and quadratic fitting for the force-indentation behavior were employed. The two methods have distinct advantages and limitations. However, a combination of two methods, using one to produce the initial guess for the other, turns out to be very effective. Indeed, in our validation this solution showed convergence under 1ms, attaining errors lower than 1 mm. The proposed approaches were implemented in a ROS-based toolbox, integrating both solutions.
ER  - 

TY  - CONF
TI  - Miniaturization of multistage high dynamic range six-axis force sensor composed of resin material
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4297
EP  - 4302
AU  - D. Okumura
AU  - S. Sakaino
AU  - T. Tsuji
PY  - 2019
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - motion control
KW  - path planning
KW  - robot vision
KW  - mobile robots
KW  - learning (artificial intelligence)
KW  - robot vision
KW  - path planning
KW  - motion control
KW  - medical robotics
KW  - optimisation
KW  - object detection
KW  - position control
KW  - collision avoidance
KW  - Force sensors
KW  - Structural beams
KW  - Force
KW  - Robot sensing systems
KW  - Stress
KW  - Strain
KW  - Creep
DO  - 10.1109/ICRA.2019.8793929
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The following topics are dealt with: mobile robots; learning (artificial intelligence); robot vision; path planning; motion control; medical robotics; optimisation; object detection; position control; collision avoidance.
ER  - 

TY  - CONF
TI  - Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture Generation for Humanoid Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4303
EP  - 4309
AU  - Y. Yoon
AU  - W. Ko
AU  - M. Jang
AU  - J. Lee
AU  - J. Kim
AU  - G. Lee
PY  - 2019
KW  - gesture recognition
KW  - humanoid robots
KW  - human-robot interaction
KW  - knowledge based systems
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - neural nets
KW  - speech recognition
KW  - text analysis
KW  - TED talks
KW  - NAO robot
KW  - speech text understanding
KW  - end-to-end neural network model
KW  - learning-based co-speech gesture generation
KW  - human labor
KW  - rule-based speech-gesture association
KW  - humanoid robots
KW  - end-to-end learning
KW  - robots learn social skills
KW  - Robots
KW  - Videos
KW  - Decoding
KW  - Natural languages
KW  - Training
KW  - Recurrent neural networks
KW  - Principal component analysis
DO  - 10.1109/ICRA.2019.8793720
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Co-speech gestures enhance interaction experiences between humans as well as between humans and robots. Most existing robots use rule-based speech-gesture association, but this requires human labor and prior knowledge of experts to be implemented. We present a learning-based co-speech gesture generation that is learned from 52 h of TED talks. The proposed end-to-end neural network model consists of an encoder for speech text understanding and a decoder to generate a sequence of gestures. The model successfully produces various gestures including iconic, metaphoric, deictic, and beat gestures. In a subjective evaluation, participants reported that the gestures were human-like and matched the speech content. We also demonstrate a co-speech gesture with a NAO robot working in real time.
ER  - 

TY  - CONF
TI  - The Doctor will See You Now: Could a Robot Be a medical Receptionist?
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4310
EP  - 4316
AU  - C. J. Sutherland
AU  - B. K. Ahn
AU  - B. Brown
AU  - J. Lim
AU  - D. L. Johanson
AU  - E. Broadbent
AU  - B. A. MacDonald
AU  - H. S. Ahn
PY  - 2019
KW  - human computer interaction
KW  - human-robot interaction
KW  - interactive systems
KW  - medical administrative data processing
KW  - visual perception
KW  - personal friend
KW  - doctor
KW  - medical receptionist
KW  - robotic system
KW  - clinic visit
KW  - wizard-of-Oz study
KW  - friendly receptionist
KW  - people perceptions
KW  - Educational robots
KW  - Medical services
KW  - Service robots
KW  - Head
KW  - Task analysis
KW  - Software
DO  - 10.1109/ICRA.2019.8794439
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A robot cannot be warm and friendly - or can it? To explore whether a robot can be a medical receptionist, we developed a robotic system for interacting with patients at a doctor's clinic, including acting friendly. We designed the robot to interact naturally with patients at the start and finish of a clinic visit. We investigated people's perceptions to the robot in a wizard-of-Oz study, where the participants interacted with the robot over four interactions. 40 participants evaluated the robot. The results indicate the participants thought the robot could be a friendly receptionist, especially after repeated interactions with the robot. However, the participants mainly thought the robot was friendly in a “professional” way, rather than a personal friend.
ER  - 

TY  - CONF
TI  - Designing a Personality-Driven Robot for a Human-Robot Interaction Scenario
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4317
EP  - 4324
AU  - H. B. Mohammadi
AU  - N. Xirakia
AU  - F. Abawi
AU  - I. Barykina
AU  - K. Chandran
AU  - G. Nair
AU  - C. Nguyen
AU  - D. Speck
AU  - T. Alpay
AU  - S. Griffiths
AU  - S. Heinrich
AU  - E. Strahl
AU  - C. Weber
AU  - S. Wermter
PY  - 2019
KW  - control engineering computing
KW  - convolutional neural nets
KW  - game theory
KW  - humanoid robots
KW  - human-robot interaction
KW  - psychology
KW  - autonomous AI system
KW  - dice game scenario
KW  - competitive personality
KW  - humanoid robot
KW  - user interaction
KW  - turn-taking dice game
KW  - HRI scenario
KW  - human-robot interaction scenario
KW  - convolutional neural network
KW  - participants facial feedback
KW  - socially engaged personality
KW  - godspeed questionnaire
KW  - mind perception questionnaire
KW  - personality-driven robot
KW  - Robots
KW  - Games
KW  - Task analysis
KW  - Grasping
KW  - Natural languages
KW  - Face
KW  - Visualization
DO  - 10.1109/ICRA.2019.8793770
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present an autonomous AI system designed for a Human-Robot Interaction (HRI) study, set around a dice game scenario. We conduct a case study to answer our research question: Does a robot with a socially engaged personality lead to a higher acceptance than a competitive personality? The flexibility of our proposed system allows us to construct and attribute two different personalities to a humanoid robot: a socially engaged personality that maximizes its user interaction and a competitive personality that is focused on playing and winning the game. We evaluate both personalities in a user study, in which the participants play a turn-taking dice game with the robot. Each personality is assessed with four different evaluation tools: 1) the Godspeed Questionnaire, 2) the Mind Perception Questionnaire, 3) a custom questionnaire concerning the overall HRI experience, and 4) a Convolutional Neural Network analyzing the emotions on the participants' facial feedback throughout the game. Our results show that the socially engaged personality evokes stronger emotions among the participants and is rated higher in likability and animacy than the competitive one. We conclude that designing the robot with a socially engaged personality contributes to a higher acceptance within an HRI scenario.
ER  - 

TY  - CONF
TI  - How Shall I Drive? Interaction Modeling and Motion Planning towards Empathetic and Socially-Graceful Driving
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4325
EP  - 4331
AU  - Y. Ren
AU  - S. Elliott
AU  - Y. Wang
AU  - Y. Yang
AU  - W. Zhang
PY  - 2019
KW  - game theory
KW  - intelligent robots
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - path planning
KW  - predictive control
KW  - remotely operated vehicles
KW  - AV
KW  - human driver
KW  - social awareness
KW  - passive-aggressive motions
KW  - interaction modeling
KW  - socially-graceful driving
KW  - autonomous vehicles
KW  - two-player game
KW  - model predictive control
KW  - social gracefulness
KW  - intent inference
KW  - motion planning
KW  - Planning
KW  - Games
KW  - Vehicles
KW  - Adaptation models
KW  - Inference algorithms
KW  - Estimation
KW  - Loss measurement
DO  - 10.1109/ICRA.2019.8793835
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While intelligence of autonomous vehicles (AVs) has significantly advanced in recent years, accidents involving AVs suggest that these autonomous systems lack gracefulness in driving when interacting with human drivers. In the setting of a two-player game, we propose model predictive control based on social gracefulness, which is measured by the discrepancy between the actions taken by the AV and those that could have been taken in favor of the human driver. We define social awareness as the ability of an agent to infer such favorable actions based on knowledge about the other agent's intent, and further show that empathy, i.e., the ability to understand others' intent by simultaneously inferring others' understanding of the agent's self intent, is critical to successful intent inference. Lastly, through an intersection case, we show that the proposed gracefulness objective allows an AV to learn more sophisticated behavior, such as passive-aggressive motions that gently force the other agent to yield.
ER  - 

TY  - CONF
TI  - Detection-by-Localization: Maintenance-Free Change Object Detector
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4348
EP  - 4355
AU  - T. Kanji
PY  - 2019
KW  - feature extraction
KW  - image fusion
KW  - image retrieval
KW  - image segmentation
KW  - object detection
KW  - query processing
KW  - robot vision
KW  - object-level subimages
KW  - pixel-wise LoC maps
KW  - detection-by-localization scheme
KW  - ranking function
KW  - ranked list
KW  - ranking based self-localization model
KW  - unsupervised rank fusion
KW  - cross-season change detection
KW  - maintenance-free change object detector
KW  - likelihood-of-change
KW  - object-level change detection
KW  - generalized task
KW  - query image
KW  - subimagelevel pixel-wise LoC maps
KW  - publicly available North Campus Long-Term dataset
KW  - publicly available NCLT dataset
KW  - multimodal information retrieval
KW  - MMR
KW  - Image segmentation
KW  - Task analysis
KW  - Robots
KW  - Computational modeling
KW  - Visualization
KW  - Databases
KW  - Real-time systems
DO  - 10.1109/ICRA.2019.8793482
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Recent researches demonstrate that selflocalization performance is a very useful measure of likelihood-of-change (LoC) for change detection. In this paper, this “detection-by-localization” scheme is studied in a novel generalized task of object-level change detection. In our framework, a given query image is segmented into object-level subimages (termed “scene parts”), which are then converted to subimagelevel pixel-wise LoC maps via the detection-by-localization scheme. Our approach models a self-localization system as a ranking function, outputting a ranked list of reference images, without requiring relevance score. Thanks to this new setting, we can generalize our approach to a broad class of selflocalization systems. We further propose an aggregation of different self-localization results from different queries so as to achieve higher precision. Our ranking based self-localization model allows to fuse self-localization results from different modalities via an unsupervised rank fusion derived from a field of multi-modal information retrieval (MMR). Our framework does not rely on the raw-score-merging hypothesis. Challenging experiments of cross-season change detection using the publicly available North Campus Long-Term (NCLT) dataset validates the efficacy of our proposed method.
ER  - 

TY  - CONF
TI  - Customized Object Recognition and Segmentation by One Shot Learning with Human Robot Interaction
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4356
EP  - 4361
AU  - P. Guo
AU  - L. Zhang
AU  - L. Cao
AU  - Y. Shen
AU  - X. Shi
AU  - H. Ren
AU  - Y. Zhang
PY  - 2019
KW  - Big Data
KW  - human-robot interaction
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - neural nets
KW  - object detection
KW  - object recognition
KW  - human robot interaction
KW  - robotic applications
KW  - deep learning models
KW  - labeled training data
KW  - pre-defined big data
KW  - segmentation method
KW  - target object
KW  - data generation method
KW  - segmentation model
KW  - lightweight segmentation net
KW  - object recognition
KW  - one shot learning
KW  - Proposals
KW  - Robots
KW  - Adaptation models
KW  - Training data
KW  - Data models
KW  - Object recognition
KW  - Testing
DO  - 10.1109/ICRA.2019.8793845
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - There are two difficulties to utilize state-of-the-art object recognition/detection/segmentation methods to robotic applications. First, most of the deep learning models heavily depend on large amounts of labeled training data, which are expensive to obtain for each individual application. Second, the object categories must be pre-defined in the dataset, thus not practical to scenarios with varying object categories. To alleviate the reliance on pre-defined big data, this paper proposes a customized object recognition and segmentation method. It aims to recognize and segment any object defined by the user, given only one annotation. There are three steps in the proposed method. First, the user takes an exemplar video of the target object with the robot, defines its name, and mask its boundary on only one frame. Then the robot automatically propagates the annotation through the exemplar video based on a proposed data generation method. In the meantime, a segmentation model continuously updates itself on the generated data. Finally, only a lightweight segmentation net is required at testing stage, to recognize and segment the user-defined object in any scenes.
ER  - 

TY  - CONF
TI  - SEG-VoxelNet for 3D Vehicle Detection from RGB and LiDAR Data
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4362
EP  - 4368
AU  - J. Dou
AU  - J. Xue
AU  - J. Fang
PY  - 2019
KW  - image colour analysis
KW  - image segmentation
KW  - object detection
KW  - optical radar
KW  - SEG-VoxelNet
KW  - LiDAR data
KW  - RGB images
KW  - LiDAR point clouds
KW  - autonomous driving scenarios
KW  - semantic segmentation technique
KW  - 3D LiDAR point cloud based detection
KW  - image semantic segmentation network
KW  - SEG-Net
KW  - improved-VoxelNet
KW  - semantic segmentation map
KW  - point cloud data
KW  - image semantic feature
KW  - KITTI 3D vehicle detection benchmark
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Semantics
KW  - Vehicle detection
KW  - Feature extraction
KW  - Image segmentation
KW  - Two dimensional displays
DO  - 10.1109/ICRA.2019.8793492
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a SEG-VoxelNet that takes RGB images and LiDAR point clouds as inputs for accurately detecting 3D vehicles in autonomous driving scenarios, which for the first time introduces semantic segmentation technique to assist the 3D LiDAR point cloud based detection. Specifically, SEG-VoxelNet is composed of two sub-networks: an image semantic segmentation network (SEG-Net) and an improved-VoxelNet. The SEG-Net generates the semantic segmentation map which represents the probability of the category for each pixel. The improved-VoxelNet is capable of effectively fusing point cloud data with image semantic feature and generating accurate 3D bounding boxes of vehicles. Experiments on the KITTI 3D vehicle detection benchmark show that our approach outperforms the methods of state-of-the-art.
ER  - 

TY  - CONF
TI  - Object Classification Based on Unsupervised Learned Multi-Modal Features For Overcoming Sensor Failures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4369
EP  - 4375
AU  - J. Nitsch
AU  - J. Nieto
AU  - R. Siegwart
AU  - M. Schmidt
AU  - C. Cadena
PY  - 2019
KW  - driver information systems
KW  - feature extraction
KW  - image classification
KW  - image fusion
KW  - unsupervised learning
KW  - unsupervised learned multimodal features
KW  - autonomous driving applications
KW  - road users
KW  - road side infrastructure
KW  - autonomous cars
KW  - classification modules
KW  - unseen sensor noise
KW  - object classification module
KW  - total sensor failure
KW  - unsupervised feature training
KW  - uni-modal classifiers training
KW  - multimodal classifiers training
KW  - feature space
KW  - sensor modalities
KW  - decision module
KW  - unsupervised learned multi-modal features
KW  - Three-dimensional displays
KW  - Feature extraction
KW  - Robot sensing systems
KW  - Computer architecture
KW  - Training
KW  - Decoding
KW  - Convolutional codes
DO  - 10.1109/ICRA.2019.8793628
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - For autonomous driving applications it is critical to know which type of road users and road side infrastructure are present to plan driving manoeuvres accordingly. Therefore autonomous cars are equipped with different sensor modalities to robustly perceive its environment. However, for classification modules based on machine learning techniques it is challenging to overcome unseen sensor noise. This work presents an object classification module operating on unsupervised learned multi-modal features with the ability to overcome gradual or total sensor failure. A two stage approach composed of an unsupervised feature training and a uni-modal and multimodal classifiers training is presented. We propose a simple but effective decision module switching between uni-modal and multi-modal classifiers based on the closeness in the feature space to the training data. Evaluations on the ModelNet 40 data set show that the proposed approach has a 14% accuracy gain compared to a late fusion approach operating on a noisy point cloud data and a 6% accuracy gain when operating on noisy image data.
ER  - 

TY  - CONF
TI  - SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4376
EP  - 4382
AU  - B. Wu
AU  - X. Zhou
AU  - S. Zhao
AU  - X. Yue
AU  - K. Keutzer
PY  - 2019
KW  - image segmentation
KW  - object detection
KW  - optical radar
KW  - rendering (computer graphics)
KW  - unsupervised learning
KW  - LiDAR point cloud
KW  - deep-learning-based approaches
KW  - point cloud segmentation
KW  - SqueezeSetV2
KW  - data collection
KW  - domain-adaptation training pipeline
KW  - domain adaptation pipeline
KW  - unsupervised domain adaptation
KW  - road-object segmentation
KW  - domain-adaptation methods
KW  - Three-dimensional displays
KW  - Laser radar
KW  - Training
KW  - Adaptation models
KW  - Data models
KW  - Pipelines
KW  - Sensors
DO  - 10.1109/ICRA.2019.8793495
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Earlier work demonstrates the promise of deep-learning-based approaches for point cloud segmentation; however, these approaches need to be improved to be practically useful. To this end, we introduce a new model SqueezeSegV2. With an improved model structure, SqueezeSetV2 is more robust against dropout noises in LiDAR point cloud and therefore achieves significant accuracy improvement. Training models for point cloud segmentation requires large amounts of labeled data, which is expensive to obtain. To sidestep the cost of data collection and annotation, simulators such as GTA-V can be used to create unlimited amounts of labeled, synthetic data. However, due to domain shift, models trained on synthetic data often do not generalize well to the real world. Existing domain-adaptation methods mainly focus on images and most of them cannot be directly applied to point clouds. We address this problem with a domain-adaptation training pipeline consisting of three major components: 1) learned intensity rendering, 2) geodesic correlation alignment, and 3) progressive domain calibration. When trained on real data, our new model exhibits segmentation accuracy improvements of 6.0-8.6% over the original SqueezeSeg. When training our new model on synthetic data using the proposed domain adaptation pipeline, we nearly double test accuracy on real-world data, from 29.0% to 57.4%. Our source code and synthetic dataset are open sourced. https://github.com/xuanyuzhou98/SqueezeSegV2.
ER  - 

TY  - CONF
TI  - RoPose-Real: Real World Dataset Acquisition for Data-Driven Industrial Robot Arm Pose Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4389
EP  - 4395
AU  - T. Gulde
AU  - D. Ludl
AU  - J. Andrejtschik
AU  - S. Thalji
AU  - C. Curio
PY  - 2019
KW  - control engineering computing
KW  - convolutional neural nets
KW  - industrial manipulators
KW  - manipulator kinematics
KW  - pose estimation
KW  - production engineering computing
KW  - robot system
KW  - world robotic scenario
KW  - world dataset acquisition
KW  - data-driven industrial robot arm pose estimation
KW  - smart sensory systems
KW  - industrial robots
KW  - mobile platforms
KW  - convolutional neural network architecture
KW  - industrial robot arm system
KW  - automatically annotated datasets
KW  - extracted pose information
KW  - RoPose-system
KW  - Calibration
KW  - Robot kinematics
KW  - Cameras
KW  - Robot vision systems
KW  - Tools
DO  - 10.1109/ICRA.2019.8793900
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - It is necessary to employ smart sensory systems in dynamic and mobile workspaces where industrial robots are mounted on mobile platforms. Such systems should be aware of flexible and non-stationary workspaces and able to react autonomously to changing situations. Building upon our previously presented RoPose-system [1], which employs a convolutional neural network architecture that has been trained on pure synthetic data to estimate the kinematic chain of an industrial robot arm system, we now present RoPose-Real. RoPose-Real extends the prior system with a comfortable and targetless extrinsic calibration tool, to allow for the production of automatically annotated datasets for real robot systems. Furthermore, we use the novel datasets to train the estimation network with real world data. The extracted pose information is used to automatically estimate the observing sensor pose relative to the robot system. Finally we evaluate the performance of the presented subsystems in a real world robotic scenario.
ER  - 

TY  - CONF
TI  - A Framework for Self-Training Perceptual Agents in Simulated Photorealistic Environments
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4396
EP  - 4402
AU  - P. Mania
AU  - M. Beetz
PY  - 2019
KW  - computer games
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - robot vision
KW  - virtual reality
KW  - self-training perceptual agents
KW  - simulated photorealistic environments
KW  - high-performance perception
KW  - mobile robotic agents
KW  - gaming industry
KW  - game engines
KW  - perceptual agent
KW  - virtual environment
KW  - task-specific object distribution
KW  - description language
KW  - learning environments
KW  - object recognition
KW  - sensory input
KW  - robotic system
KW  - Task analysis
KW  - Robots
KW  - Training data
KW  - Engines
KW  - Virtual environments
KW  - Games
KW  - Data models
KW  - Self-Training Perception
KW  - Robotic Simulation
KW  - Unreal Engine
KW  - Scenario Description
DO  - 10.1109/ICRA.2019.8793474
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The development of high-performance perception for mobile robotic agents is still challenging. Learning appropriate perception models usually requires extensive amounts of labeled training data that ideally follows the same distribution as the data an agent will encounter in its target task. Recent developments in gaming industry led to game engines able to generate photorealistic environments in real-time, which can be used to realistically simulate the sensory input of an agent.We propose a novel framework which allows the definition of different learning scenarios and instantiates these scenarios in a high quality game engine where a perceptual agent can act and learn in. The scenarios are specified in a newly developed scenario description language that allows the parametrization of the virtual environment and the perceptual agent. New scenarios can be sampled from a task-specific object distribution that allows the automatic generation of extensive amounts of different learning environments for the perceptual agent.We will demonstrate the plausibility of the framework by conducting object recognition experiments on a real robotic system which has been trained within our framework.
ER  - 

TY  - CONF
TI  - Fast and Precise Detection of Object Grasping Positions with Eigenvalue Templates
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4403
EP  - 4409
AU  - K. Mano
AU  - T. Hasegawa
AU  - T. Yamashita
AU  - H. Fujiyoshi
AU  - Y. Domae
PY  - 2019
KW  - dexterous manipulators
KW  - eigenvalues and eigenfunctions
KW  - grippers
KW  - industrial robots
KW  - object detection
KW  - position control
KW  - singular value decomposition
KW  - hand templates
KW  - target object
KW  - optimum grasping posture
KW  - singular value decomposition
KW  - eigenvalue templates
KW  - parallel hands
KW  - three-finger hands
KW  - industrial robots
KW  - object grasping position detection
KW  - fast graspability evaluation
KW  - eigenfunctions
KW  - arbitrary parameters
KW  - Eigenvalues and eigenfunctions
KW  - Grasping
KW  - Convolution
KW  - Three-dimensional displays
KW  - Collision avoidance
KW  - Service robots
DO  - 10.1109/ICRA.2019.8793830
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fast Graspability Evaluation (FGE) has been proposed as a method for detecting grasping positions on objects and is now being used for industrial robots. FGE uses convolution of hand templates with regions on the target object to estimate the optimum grasping posture. However, the hand opening width and rotation angles must be set with high resolution to achieve highly accurate results and the computational load is high. To address that issue, we propose a method in which hand templates are represented in compact form for faster processing by using singular value decomposition. Applying singular value decomposition enables hand templates to be represented as linear combinations of a small number of eigenvalue templates and eigenfunctions. Eigenfunctions take discrete values, but response values can be calculated with arbitrary parameters by fitting a continuous function. Experimental results show that the proposed method reduces computation time by two thirds while maintaining the same detection accuracy as conventional FGE for both parallel hands and three-finger hands.
ER  - 

TY  - CONF
TI  - Improved Coverage Path Planning Using a Virtual Sensor Footprint: a Case Study on Demining
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4410
EP  - 4415
AU  - S. Dogru
AU  - L. Marques
PY  - 2019
KW  - mobile robots
KW  - optimisation
KW  - path planning
KW  - sensors
KW  - physical sensor
KW  - virtual footprint
KW  - optimization problem
KW  - energy performances
KW  - virtual sensor footprint
KW  - coverage path planning problem
KW  - robotic arm
KW  - larger areas
KW  - platform moves
KW  - larger footprint
KW  - metal detector
KW  - Robot sensing systems
KW  - Manipulators
KW  - Metals
KW  - Detectors
KW  - Trajectory
KW  - Shape
DO  - 10.1109/ICRA.2019.8793695
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Coverage performance in a coverage path planning problem depends both on the path created and on the footprint of the sensor used. The footprint can be increased either by increasing the size of the sensor, or by mounting the sensor on a robotic arm to allow scanning over larger areas as the platform moves, effectively creating a virtual sensor with a larger footprint than the physical sensor's. However, the virtual footprint comes at a cost requiring formulating an optimization problem for the area of interest. In this work, three common strategies to use a metal detector on a platform are discussed, their time and energy performances are formulated and the corresponding optima are found.
ER  - 

TY  - CONF
TI  - Model-Based Estimation of the Gravity-Loaded Shape and Scene Depth for a Slim 3-Actuator Continuum Robot with Monocular Visual Feedback
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4416
EP  - 4421
AU  - Y. Chen
AU  - S. Zhang
AU  - L. Zeng
AU  - X. Zhu
AU  - K. Xu
PY  - 2019
KW  - actuators
KW  - cameras
KW  - feedback
KW  - gravity
KW  - image filtering
KW  - Kalman filters
KW  - manipulator kinematics
KW  - motion control
KW  - nonlinear filters
KW  - robot vision
KW  - shape control
KW  - shape measurement
KW  - model-based estimation
KW  - slim 3-actuator continuum robot
KW  - separately modeled segments
KW  - actuated segments
KW  - gravity-loaded shape estimation
KW  - scene depth estimation
KW  - monocular visual feedback
KW  - robot movements
KW  - manipulation capabilities
KW  - confined spaces
KW  - robot control
KW  - constant curvature
KW  - variable curvature
KW  - spatial locations
KW  - robot shape
KW  - monocular camera
KW  - unscented Kalman filters
KW  - UKF
KW  - feature depth estimation
KW  - robot kinematics model
KW  - motion control
KW  - Cameras
KW  - Estimation
KW  - Conferences
KW  - Automation
KW  - IEEE members
KW  - Kinematics
KW  - Predictive models
DO  - 10.1109/ICRA.2019.8793861
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Fruitful developments on continuum robots have been witnessed in recent years due to their movements and manipulation capabilities in confined spaces. Due to the nature that a continuum robot has an infinite number of DoFs (Degrees of Freedom), majority of the existing systems deployed abundant actuators such that the robot can be controlled in separately modeled and actuated segments with constant or variable curvature. As the shape of a continuum robot is always jointly determined by its actuation and the interactions from the environment, it is hence worth exploring the opposite approach that how a task can be accomplished with a minimal number of actuators. This paper presents the first step of such an investigation where a slim 3-actuator continuum robot is actuated to reach different spatial locations under gravity. As the gravity greatly affects the robot's shape, a monocular camera, together with two UKFs (Unscented Kalman Filters), was used to concurrently estimate the robot's shape and the feature depth. Then the estimated shape can be used in updating the kinematics model of the robot to achieve motion control. Experiments were conducted to validate the effectiveness of the proposed shape estimation, which promises the motion control implementation in the near future work.
ER  - 

TY  - CONF
TI  - Design of a Modular Continuum Robot Segment for use in a General Purpose Manipulator*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4430
EP  - 4435
AU  - N. P. Castledine
AU  - J. H. Boyle
AU  - J. Kim
PY  - 2019
KW  - actuators
KW  - bending
KW  - control system synthesis
KW  - DC motors
KW  - manipulators
KW  - motion control
KW  - position control
KW  - three-dimensional printing
KW  - torsion
KW  - modular continuum robot segment
KW  - general purpose manipulator
KW  - tendon-driven continuum robot segment
KW  - modular design
KW  - continuous flexible core
KW  - rigid interlocking vertebrae
KW  - torsional movement
KW  - antagonistic tendon pairs
KW  - single geared DC motor
KW  - bulky actuation unit
KW  - torsional rigidity
KW  - rigid vertebrae
KW  - tendons
KW  - multimaterial 3D printing
KW  - Tendons
KW  - Manipulators
KW  - Actuators
KW  - Routing
KW  - Shafts
DO  - 10.1109/ICRA.2019.8794249
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents the development of a tendon-driven continuum robot segment with a modular design, simple construction and significant lifting capabilities. The segment features a continuous flexible core combined with rigid interlocking vertebrae evenly distributed along its length. This design allows bending in two degrees of freedom while minimising torsional movement. The segment is actuated by two antagonistic tendon pairs, each of which is driven by a single geared DC motor. Modularity is achieved by embedding these motors in one end of the segment, avoiding the need for a bulky actuation unit and allowing variable numbers of segments to be connected. The design features a large hollow central bore which could be used as a vacuum channel for suction-assisted gripping or to allow ingress and egress of fluids. The design process goes through four iterations, the final two of which are subjected to quantitative experiments to evaluate workspace, lifting capabilities and torsional rigidity. All iterations are fabricated using multi-material 3D printing, which allows the entire structure to be printed as a pre-assembled unit with the rigid vertebrae fused to the flexible core. Assembly is then a simple case of inserting the motors and connecting the tendons. This unconventional manufacturing approach is found to be efficient, effective and relatively cheap.
ER  - 

TY  - CONF
TI  - Reshaping Particle Configurations by Collisions with Rigid Objects
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4436
EP  - 4443
AU  - S. Shahrokhi
AU  - H. Zhao
AU  - A. T. Becker
PY  - 2019
KW  - actuators
KW  - collision avoidance
KW  - multi-robot systems
KW  - shear modulus
KW  - uniform global external field
KW  - magnetic fields
KW  - workspace obstacles
KW  - shape control
KW  - navigation
KW  - driving force
KW  - torque
KW  - rectangular rigid body
KW  - particle group
KW  - circular workspace
KW  - mean variance configurations
KW  - Shape
KW  - Force
KW  - Torque
KW  - Shape control
KW  - Magnetic resonance imaging
KW  - Magnetoacoustic effects
KW  - Correlation
DO  - 10.1109/ICRA.2019.8794405
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Consider many particles actuated by a uniform global external field (e.g. gravitational or magnetic fields). This paper presents analytical results using workspace obstacles and global inputs to reshape such a group of particles. Shape control of many particles is necessary for conveying information, construction, and navigation. First we show how the particles' characteristic angle of repose can be used to reshape the particles by controlling angle of attack and the magnitude of the driving force. These can then be used to control the force and torque applied to a rectangular rigid body. Next, we examine the full set of stable, achievable mean and variance configurations for the shape of a particle group in two canonical environments: a square and a circular workspace. Finally, we show how workspaces with linear boundary layers can be used to achieve a more rich set of mean and variance configurations.
ER  - 

TY  - CONF
TI  - Velocity Constrained Trajectory Generation for a Collinear Mecanum Wheeled Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4444
EP  - 4450
AU  - M. T. Watson
AU  - D. T. Gladwin
AU  - T. J. Prescott
AU  - S. O. Conran
PY  - 2019
KW  - mobile robots
KW  - path planning
KW  - trajectory control
KW  - velocity constrained trajectory generation
KW  - underactuated unstable aerial vehicles
KW  - linear accelerations
KW  - trajectory planner
KW  - trajectory timing characteristics
KW  - omnidirectional balancing robot
KW  - collinear Mecanum wheeled robot
KW  - ground based omnidirectional dynamically balancing robots
KW  - trajectory optimisation methods
KW  - differentially flat model
KW  - collinear Mecanum drive
KW  - Trajectory
KW  - Planning
KW  - Wheels
KW  - Mobile robots
KW  - Transmission line matrix methods
KW  - Acceleration
DO  - 10.1109/ICRA.2019.8794019
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - While much research has been conducted into the generation of smooth trajectories for underactuated unstable aerial vehicles such as quadrotors, less attention has been paid to the application of the same techniques to ground based omnidirectional dynamically balancing robots. These systems have more control authority over their linear accelerations than aerial vehicles, meaning trajectory smoothness is less of a critical design parameter. However, when operating in indoor environments these systems must often adhere to relatively low velocity constraints, resulting in very conservative trajectories when enforced using existing trajectory optimisation methods. This paper makes two contributions; this gap is bridged by the extension of these existing methods to create a fast velocity constrained trajectory planner, with trajectory timing characteristics derived from the optimal minimum-time solution of a simplified acceleration and velocity constrained model. Next, a differentially flat model of an omnidirectional balancing robot utilizing a collinear Mecanum drive is derived, which is used to allow an experimental prototype of this configuration to smoothly follow these velocity constrained trajectories.
ER  - 

TY  - CONF
TI  - Vibration Control for Manipulators on a Translationally Flexible Base
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4451
EP  - 4457
AU  - F. Beck
AU  - G. Garofalo
AU  - C. Ott
PY  - 2019
KW  - damping
KW  - flexible manipulators
KW  - Lyapunov methods
KW  - manipulator dynamics
KW  - numerical analysis
KW  - springs (mechanical)
KW  - stability
KW  - vibration control
KW  - vibration control
KW  - manipulators
KW  - translationally flexible base
KW  - fundamental oscillatory system
KW  - mass spring system
KW  - control strategy couples
KW  - n-link manipulator
KW  - linear translational stiffness
KW  - conditional stability argument
KW  - base vibrations
KW  - input transformation
KW  - coordinate transformation
KW  - semidefinite Lyapunov functions
KW  - Vibrations
KW  - Manipulator dynamics
KW  - Task analysis
KW  - Robot kinematics
KW  - Damping
DO  - 10.1109/ICRA.2019.8793904
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this contribution the problem of vibration control is studied on the basis of a fundamental oscillatory system consisting of a mass spring system and an additional mass. The proposed control strategy couples the orbits of the two masses such that both masses stop, while simultaneously stabilizing the second mass to a desired equilibrium. Using a coordinate and input transformation, the control strategy is directly transferred to an n-link manipulator mounted on a base with linear translational stiffness. Using semidefinite Lyapunov functions and a conditional stability argument, it is shown that the proposed control strategy damps out base vibrations, while additionally achieving a desired configuration in the task-space. Finally, the proposed method is compared to a state-of-the-art approach using numerical simulations.
ER  - 

TY  - CONF
TI  - Gaussian Processes Model-Based Control of Underactuated Balance Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4458
EP  - 4464
AU  - K. Chen
AU  - J. Yi
AU  - D. Song
PY  - 2019
KW  - control system synthesis
KW  - Gaussian processes
KW  - mobile robots
KW  - pendulums
KW  - predictive control
KW  - robot dynamics
KW  - robust control
KW  - trajectory control
KW  - control design
KW  - robot dynamics
KW  - underactuated balance robot
KW  - model predictive control
KW  - Gaussian process regression model
KW  - trajectory tracking
KW  - learning-based control
KW  - GP model
KW  - robustness
KW  - Furuta pendulum system
KW  - Trajectory
KW  - Mathematical model
KW  - Computational modeling
KW  - Robot kinematics
KW  - Predictive models
KW  - Trajectory tracking
DO  - 10.1109/ICRA.2019.8794097
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Control of underactuated balance robot requires external subsystem trajectory tracking and internal unstable subsystem balancing with limited control authority. We present a learning-based control approach for underactuated balance robots. The tracking and balancing control is designed the controller in fast- and slow-time scales. In the slow-time scale, model predictive control is adopted to plan desired internal state profile to achieve external trajectory tracking task. The internal state is then stabilized around the planned profile in the fast-time scale. The control design is based on a learned Gaussian process (GP) regression model without need of a priori knowledge about the robot dynamics. The controller also incorporates the GP model predicted variance to enhance robustness to modeling errors. Experiments are presented using a Furuta pendulum system.
ER  - 

TY  - CONF
TI  - Analysis of 3D Position Control for a Multi-Agent System of Self-Propelled Agents Steered by a Shared, Global Control Input
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4465
EP  - 4471
AU  - L. Huang
AU  - J. Leclerc
AU  - A. T. Becker
PY  - 2019
KW  - closed loop systems
KW  - controllability
KW  - matrix algebra
KW  - multi-agent systems
KW  - multi-robot systems
KW  - nonlinear control systems
KW  - position control
KW  - control laws
KW  - multiagent system
KW  - self-propelled agents
KW  - shared control input
KW  - global control input
KW  - 3D multiagent position control
KW  - control inputs
KW  - rotation commands
KW  - rotation matrix
KW  - controllability results
KW  - 2D case
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Orbits
KW  - Position control
KW  - Perturbation methods
KW  - Aerospace electronics
KW  - Robots
DO  - 10.1109/ICRA.2019.8793800
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper investigates strategies for 3D multi-agent position control using a shared control input and self-propelled agents. The only control inputs allowed are rotation commands that rotate all agents by the same rotation matrix. In the 2D case, only two degrees-of-freedom (DOF) in position are controllable. We review controllability results in 2D, and then show that interesting things happen in 3D. We provide control laws for steering up to nine DOF in position, which can be mapped in various ways, including to control the x, y, z position of three agents, make four agents meet, or reduce the spread of n agents.
ER  - 

TY  - CONF
TI  - A Heuristic for Task Allocation and Routing of Heterogeneous Robots while Minimizing Maximum Travel Cost
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4531
EP  - 4537
AU  - J. Bae
AU  - J. Lee
AU  - W. Chung
PY  - 2019
KW  - approximation theory
KW  - minimax techniques
KW  - path planning
KW  - robots
KW  - travelling salesman problems
KW  - task allocation
KW  - heterogeneous robots
KW  - path planning problem
KW  - min-max objective
KW  - min-max MDHTSP
KW  - travel cost
KW  - multiple depot heterogeneous traveling salesman problem
KW  - primal-dual technique
KW  - Robots
KW  - Task analysis
KW  - Routing
KW  - Resource management
KW  - Traveling salesman problems
KW  - Approximation algorithms
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794257
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The article proposes a new heuristic for task allocation and routing of heterogeneous robots. Specifically, we consider a path planning problem where there are two (structurally) heterogeneous robots that start from distinctive depots and a set of targets to visit. The objective is to find a tour for each robot in a manner that enables each target location to be visited at least once by one of the robots while minimizing the maximum travel cost. A solution for Multiple Depot Heterogeneous Traveling Salesman Problem (MDHTSP) with min-max objective is in great demand with many potential applications, because it can significantly reduce the job completion duration. However, there are still no reliable algorithms that can run in short amount of time. As an initial idea of solving min-max MDHTSP, we present a heuristic based on a primal-dual technique that solves for a case involving two robots while focusing on task allocation. Based on computational results of the implementation, we show that the proposed algorithm produces a good quality of feasible solution within a relatively short computation time.
ER  - 

TY  - CONF
TI  - Solving Methods for Multi-Robot Missions Planning with Energy Capacity Consideration
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4538
EP  - 4544
AU  - M. K. Habibi
AU  - C. Grand
AU  - C. Lesire
AU  - C. Pralet
PY  - 2019
KW  - autonomous aerial vehicles
KW  - iterative methods
KW  - matrix algebra
KW  - minimisation
KW  - multi-robot systems
KW  - path planning
KW  - distance matrix
KW  - multiphase heuristic
KW  - two-phase iterative heuristic
KW  - branch-and-cut algorithm
KW  - decomposition-based approximate methods
KW  - high quality solutions
KW  - heterogeneous vehicles
KW  - energy capacity consideration
KW  - multirobot missions planning
KW  - Robots
KW  - Iterative methods
KW  - Task analysis
KW  - Linear programming
KW  - Planning
KW  - Resource management
KW  - Routing
DO  - 10.1109/ICRA.2019.8793700
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We consider a problem minimizing the total duration of accomplishing missions performed by heterogeneous vehicles. The problem respects constraints related to vehicles' capabilities and energy capacities. The goal is to determine the best routes of each vehicle deployed by choosing which waypoints to pass and which observations to perform. Each vehicle has a particular distance matrix and a limited energy. In order to provide high quality solutions within reasonable computational time, two decomposition-based approximate methods were implemented: (i) the Multiphase heuristic, and (ii) the Two-Phase iterative heuristic. The performance of the methods is evaluated against the Branch-and-Cut algorithm using generated instances.
ER  - 

TY  - CONF
TI  - Salty-A Domain Specific Language for GR(1) Specifications and Designs
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4545
EP  - 4551
AU  - T. Elliott
AU  - M. Alshiekh
AU  - L. R. Humphrey
AU  - L. Pike
AU  - U. Topcu
PY  - 2019
KW  - autonomous aerial vehicles
KW  - control system synthesis
KW  - formal specification
KW  - mobile robots
KW  - path planning
KW  - program debugging
KW  - remotely operated vehicles
KW  - specification languages
KW  - sanity checking
KW  - high-level specifications
KW  - domain-specific language
KW  - specification optimization
KW  - robot controller design
KW  - specification patterns
KW  - Salty domain specific language
KW  - GR(1) specifications
KW  - correct-by-construction synthesis approach
KW  - generalized reactivity(1) specifications
KW  - Slugs synthesis tool
KW  - multiple unmanned air vehicles
KW  - UAV
KW  - Target tracking
KW  - Robot kinematics
KW  - Tools
KW  - Software
KW  - Unmanned aerial vehicles
KW  - Control systems
DO  - 10.1109/ICRA.2019.8793722
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Designing robot controllers that correctly react to changes in the environment is a time-consuming and error-prone process. An alternative is to use “correct-by-construction” synthesis approaches to automatically generate controller designs from high-level specifications. In particular, Generalized Reactivity(l) or GR(1) specifications are well-suited to express specifications for robots that must act in dynamic environments, and approaches to generate controller designs from GR(1) specifications are highly computationally efficient. Toward that end, this paper presents Salty, a domain-specific language for GR(1) specifications. While tools exist to synthesize system designs from GR(1) specifications, Salty makes such specifications easier to write and debug by supporting features such as richer input and output types, user-defined macros, common specification patterns, and specification optimization and sanity checking. Salty interfaces with the separately developed synthesis tool Slugs to produce a system or controller design, and Salty translates this design to a software implementation in a variety of languages. We demonstrate Salty on an application involving coordination of multiple unmanned air vehicles (UAVs) and provide a workflow for connecting synthesized UAV controllers to freely available UAV planning and simulation software suites UxAS and AMASE.
ER  - 

TY  - CONF
TI  - Persistent Multi-Robot Mapping in an Uncertain Environment
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4552
EP  - 4558
AU  - D. Mitchell
AU  - N. Michael
PY  - 2019
KW  - mobile robots
KW  - multi-agent systems
KW  - multi-robot systems
KW  - path planning
KW  - probability
KW  - multiagent spatio-temporal states
KW  - world model
KW  - persistent multirobot mapping
KW  - uncertain environment
KW  - constrained energy capacities
KW  - typical occupancy map approaches
KW  - static world
KW  - occupancy probability
KW  - grid cells
KW  - promotes revisitation
KW  - unchanging areas
KW  - naive planning
KW  - tractable subproblems
KW  - tractable computation time
KW  - Robots
KW  - Clustering algorithms
KW  - Indexes
KW  - Planning
KW  - Computational modeling
KW  - Sensors
KW  - Heuristic algorithms
DO  - 10.1109/ICRA.2019.8794469
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper proposes a method to deploy teams of robots with constrained energy capacities to persistently maintain a map of an uncertain environment. Typical occupancy map approaches assume a static world; however, we introduce a decay in confidence that degrades the occupancy probability of grid cells and promotes revisitation. Further, sections of the map whose occupancy differs between observations are visited more frequently, while unchanging areas are scheduled less frequently. While naive planning is intractable through the entire space of multi-agent spatio-temporal states, the proposed algorithm decouples planning such that constraints are resolved separately by solving tracTable subproblems. We evaluate this approach in simulation and show how the uncertainty of our world model is maintained below an acceptable threshold while the algorithm retains a tractable computation time.
ER  - 

TY  - CONF
TI  - A Fog Robotics Approach to Deep Robot Learning: Application to Object Recognition and Grasp Planning in Surface Decluttering
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4559
EP  - 4566
AU  - A. K. Tanwani
AU  - N. Mor
AU  - J. Kubiatowicz
AU  - J. E. Gonzalez
AU  - K. Goldberg
PY  - 2019
KW  - cloud computing
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object recognition
KW  - path planning
KW  - robot programming
KW  - robot vision
KW  - storage management
KW  - fog robotics
KW  - mobile robot
KW  - grasp planning model
KW  - nonpublic synthetic images
KW  - deep object recognition
KW  - nonprivate synthetic images
KW  - deep models
KW  - centralized Cloud Robotics model
KW  - surface decluttering
KW  - deep robot learning
KW  - Cloud computing
KW  - Robot sensing systems
KW  - Computational modeling
KW  - Adaptation models
KW  - Security
KW  - Data models
DO  - 10.1109/ICRA.2019.8793690
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - The growing demand of industrial, automotive and service robots presents a challenge to the centralized Cloud Robotics model in terms of privacy, security, latency, bandwidth, and reliability. In this paper, we present a `Fog Robotics' approach to deep robot learning that distributes compute, storage and networking resources between the Cloud and the Edge in a federated manner. Deep models are trained on non-private (public) synthetic images in the Cloud; the models are adapted to the private real images of the environment at the Edge within a trusted network and subsequently, deployed as a service for low-latency and secure inference/prediction for other robots in the network. We apply this approach to surface decluttering, where a mobile robot picks and sorts objects from a cluttered floor by learning a deep object recognition and a grasp planning model. Experiments suggest that Fog Robotics can improve performance by sim-to-real domain adaptation in comparison to exclusively using Cloud or Edge resources, while reducing the inference cycle time by 4× to successfully declutter 86% of objects over 213 attempts.
ER  - 

TY  - CONF
TI  - Streamlines for Motion Planning in Underwater Currents
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4619
EP  - 4625
AU  - K. Y. C. To
AU  - K. M. B. Lee
AU  - C. Yoo
AU  - S. Anstee
AU  - R. Fitch
PY  - 2019
KW  - autonomous underwater vehicles
KW  - motion control
KW  - path planning
KW  - reachability analysis
KW  - sampling methods
KW  - stream functions
KW  - control space
KW  - complicated flows
KW  - underwater currents
KW  - underwater vehicles
KW  - ocean currents
KW  - reachability
KW  - sampling-based motion planning
KW  - Australia
KW  - Aerospace electronics
KW  - Planning
KW  - Underwater vehicles
KW  - Two dimensional displays
KW  - Oceans
KW  - Australia
KW  - Level set
DO  - 10.1109/ICRA.2019.8793567
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Motion planning for underwater vehicles must consider the effect of ocean currents. We present an efficient method to compute reachability and cost between sample points in sampling-based motion planning that supports long-range planning over hundreds of kilometres in complicated flows. The idea is to search a reduced space of control inputs that consists of stream functions whose level sets, or streamlines, optimally connect two given points. Such stream functions are generated by superimposing a control input onto the underlying current flow. A streamline represents the resulting path that a vehicle would follow as it is carried along by the current given that control input. We provide rigorous analysis that shows how our method avoids exhaustive search of the control space, and demonstrate simulated examples in complicated flows including a traversal along the east coast of Australia, using actual current predictions, between Sydney and Brisbane.
ER  - 

TY  - CONF
TI  - A Distributed Predictive Control Approach for Cooperative Manipulation of Multiple Underwater Vehicle Manipulator Systems
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4626
EP  - 4632
AU  - S. Heshmati-alamdari
AU  - G. C. Karras
AU  - K. J. Kyriakopoulos
PY  - 2019
KW  - autonomous underwater vehicles
KW  - collision avoidance
KW  - distributed control
KW  - feedback
KW  - manipulator dynamics
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - multi-robot systems
KW  - nonlinear control systems
KW  - position control
KW  - predictive control
KW  - control input saturations
KW  - coupled dynamics
KW  - load sharing coefficients
KW  - distributed NMPC
KW  - object transportation
KW  - constrained workspace
KW  - static obstacles
KW  - kinematic representation singularities
KW  - joint limits
KW  - multiple underwater vehicle manipulator systems
KW  - nonlinear model predictive control approach
KW  - distributed predictive control approach
KW  - UVMS locally measurements
KW  - Task analysis
KW  - Kinematics
KW  - Robot sensing systems
KW  - Jacobian matrices
KW  - End effectors
KW  - Vehicle dynamics
DO  - 10.1109/ICRA.2019.8793476
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the problem of cooperative object transportation for multiple Underwater Vehicle Manipulator Systems (UVMSs) in a constrained workspace involving static obstacles. We propose a Nonlinear Model Predictive Control (NMPC) approach for a team of UVMSs in order to transport an object while avoiding significant constraints and limitations such as: kinematic and representation singularities, obstacles within the workspace, joint limits and control input saturations. More precisely, by exploiting the coupled dynamics between the robots and the object, and using certain load sharing coefficients, we design a distributed NMPC for each UVMS in order to cooperatively transport the object within the workspace's feasible region. Moreover, the control scheme adopts load sharing among the UVMSs according to their specific payload capabilities. Additionally, the feedback relies on each UVMS's locally measurements and no explicit data is exchanged online among the robots, thus reducing the required communication bandwidth. Finally, real-time simulation results conducted in UwSim dynamic simulator running in ROS environment verify the efficiency of the theoretical finding.
ER  - 

TY  - CONF
TI  - Coordinated Control of a Reconfigurable Multi-Vessel Platform: Robust Control Approach
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4633
EP  - 4639
AU  - S. Park
AU  - E. Kayacan
AU  - C. Ratti
AU  - D. Rus
PY  - 2019
KW  - control system synthesis
KW  - feedback
KW  - marine engineering
KW  - position control
KW  - propellers
KW  - robust control
KW  - coordinated robust control scheme
KW  - reconfigurable multivessel platform
KW  - feedback control system
KW  - control variables
KW  - control system design
KW  - propeller-driven vessels
KW  - trajectory tracking
KW  - disturbance attenuation performance
KW  - orientation tracking error
KW  - maximum tracking error-to-disturbance ratio
KW  - Trajectory tracking
KW  - Robust control
KW  - Feedback control
KW  - Attenuation
KW  - Uncertainty
KW  - Irrigation
DO  - 10.1109/ICRA.2019.8794075
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a feedback control system for a reconfigurable multi-vessel platform. The platform consists of N propeller-driven vessels each of which is capable of latching to another vessel to form a rigid body of connected vessels. The main technical challenges are that i) depending on configurations of the platform the dynamic model would be different, and ii) the number of control variables in control system design increases as does the total number of vessels in the platform. To address these challenges, we develop a coordinated robust control scheme. Through experiments we assess trajectory tracking and disturbance attenuation performance of the control scheme in various configurations of the platform. Experiment results yield that average position and orientation tracking error are approximately 0.09m and 3°, and the maximum tracking error-to-disturbance ratio is 1.12.
ER  - 

TY  - CONF
TI  - Ambient light based depth control of underwater robotic unit aMussel
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4640
EP  - 4645
AU  - G. Vasiljevic
AU  - B. Arbanas
AU  - S. Bogdan
PY  - 2019
KW  - autonomous underwater vehicles
KW  - mobile robots
KW  - pressure sensors
KW  - underwater robotic unit
KW  - 1DOF
KW  - ambient light sensor
KW  - aMussel holding depth
KW  - pressure sensor
KW  - one degree-of-freedom
KW  - weather conditions
KW  - acoustic communication
KW  - Robot sensing systems
KW  - Pressure sensors
KW  - Buoyancy
KW  - Pistons
KW  - Simulation
KW  - Force
DO  - 10.1109/ICRA.2019.8794440
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we present a method for depth control of one degree of freedom (1DOF) underwater robotic platform aMussel, based on the measurements from the ambient light sensor. Since ambient light values change during the day and depend on the weather conditions, references for the controller are acquired from other aMussel holding depth using pressure sensor based controller. Control inputs are transmitted using acoustic communication.
ER  - 

TY  - CONF
TI  - A Unified Closed-Loop Motion Planning Approach For An I-AUV In Cluttered Environment With Localization Uncertainty
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4646
EP  - 4652
AU  - H. Yu
AU  - W. Lu
AU  - D. Liu
PY  - 2019
KW  - autonomous underwater vehicles
KW  - closed loop systems
KW  - collision avoidance
KW  - cooperative systems
KW  - manipulators
KW  - mobile robots
KW  - motion control
KW  - optimisation
KW  - position control
KW  - remotely operated vehicles
KW  - cluttered environment
KW  - localization uncertainty
KW  - trajectory optimization problem
KW  - optimal trajectory
KW  - I-AUV trajectories
KW  - optimization solvers
KW  - quasiquadratic optimization problems
KW  - null space saturation controller
KW  - cluttered underwater environments
KW  - optimal collision-free
KW  - intervention autonomous underwater vehicle
KW  - linear-quadratic-Gaussian controller
KW  - base trajectories
KW  - unified closed-loop motion planning approach
KW  - Trajectory
KW  - Planning
KW  - Manipulators
KW  - Uncertainty
KW  - Optimization
KW  - Aerospace electronics
KW  - Task analysis
KW  - Intervention AUV
KW  - Motion planning
KW  - Uncertainty minimization
DO  - 10.1109/ICRA.2019.8794300
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper presents a unified motion planning approach for an Intervention Autonomous Underwater Vehicle (I-AUV) in a cluttered environment with localization uncertainty. With the uncertainty being propagated by an information filter, a trajectory optimization problem closed by a Linear-Quadratic-Gaussian controller is formulated for a coupled design of optimal trajectory, localization, and control. Due to the presence of obstacles or complexity of the cluttered environment, a set of feasible initial I-AUV trajectories covering multiple homotopy classes are required by optimization solvers. Parameterized through polynomials, the initial base trajectories are from solving quasi-quadratic optimization problems that are linearly constrained by waypoints from RRTconnect, while the initial trajectories of the manipulator are generated by a null space saturation controller. Simulations on an I-AUV with a 3 DOF manipulator in cluttered underwater environments demonstrated that initial trajectories are generated efficiently and that optimal and collision-free I-AUV trajectories with low state uncertainty are obtained.
ER  - 

TY  - CONF
TI  - A bio-robotic remora disc with attachment and detachment capabilities for reversible underwater hitchhiking
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4653
EP  - 4659
AU  - S. Wang
AU  - L. Li
AU  - Y. Chen
AU  - Y. Wang
AU  - W. Sun
AU  - J. Xiao
AU  - D. Wainwright
AU  - T. Wang
AU  - R. J. Wood
AU  - L. Wen
PY  - 2019
KW  - actuators
KW  - biomimetics
KW  - cables (mechanical)
KW  - elastic constants
KW  - mobile robots
KW  - motion control
KW  - polymers
KW  - underwater vehicles
KW  - bio-robotic remora disc
KW  - detachment capabilities
KW  - reversible underwater hitchhiking
KW  - remoras
KW  - adhesive discs
KW  - biological disc
KW  - multimaterial biomimetic disc
KW  - flexible cable-driven mechanism
KW  - silicone soft lip
KW  - internal pressure
KW  - disc lamellae
KW  - attached carbon fiber spinules
KW  - ambient underwater pressure
KW  - Lips
KW  - Hydraulic systems
KW  - Force
KW  - Substrates
KW  - Prototypes
KW  - Rough surfaces
KW  - Surface roughness
KW  - Attachment and detachment
KW  - soft robotics
KW  - underwater adhesion
DO  - 10.1109/ICRA.2019.8793703
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Remoras employ their adhesive discs to rapidly attach to and detach from a wide range of marine surfaces. By analyzing high-speed images of remoras' (Echeneis naucrates) hitchhiking behavior, we describe the fish's detachment mechanism as a lip curling up to break the seal between the disc and substrate. By mimicking the kinematic and morphological properties of the biological disc, we fabricated a multi-material biomimetic disc (whose stiffness spans four orders of magnitude) that is capable of both attachment and detachment. Detachment is realized by a flexible cable-driven mechanism that curls the anterior region of the silicone soft lip, allows leakage under the disc, and equalizes the internal pressure to the external pressure. The disc lamellae with attached carbon fiber spinules can be rotated by hydraulic soft actuators whose internal pressure is precisely tuned to the ambient underwater pressure. During attachment, increasing the rotational angle of the lamellae and the preload of the disc significantly enhanced the adhesive forces. We found that curling up the soft lip and folding down the lamellae rapidly reduced the pulling force of the disc by a factor of 254 compared to that under the attached state, which lead to detachment. Based on these mechanisms, underwater maneuvers involving repeated attachment and detachment were demonstrated with an integrated ROV unit that had a self-contained actuation and control system for the disc. This study lays a foundation for the development of fully untethered robotic systems for underwater hitchhiking in real-world marine environments.
ER  - 

TY  - CONF
TI  - Robot Communication Via Motion: Closing the Underwater Human-Robot Interaction Loop
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4660
EP  - 4666
AU  - M. Fulton
AU  - C. Edge
AU  - J. Sattar
PY  - 2019
KW  - control engineering computing
KW  - human-robot interaction
KW  - mobile robots
KW  - robot communication
KW  - underwater human-robot interaction loop
KW  - colored lights
KW  - underwater robots
KW  - robot-to-human communication methods
KW  - body language gestures
KW  - communication vector
KW  - Robots
KW  - Solids
KW  - Task analysis
KW  - Unmanned underwater vehicles
KW  - Communication systems
KW  - Human-robot interaction
KW  - Hardware
DO  - 10.1109/ICRA.2019.8793491
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we propose a novel method for underwater robot-to-human communication using the motion of the robot as “body language”. To evaluate this system, we develop simulated examples of the system's body language gestures, called kinemes, and compare them to a baseline system using flashing colored lights through a user study. Our work shows evidence that motion can be used as a successful communication vector which is accurate, easy to learn, and quick enough to be used, all without requiring any additional hardware to be added to our platform. We thus contribute to “closing the loop” for human-robot interaction underwater by proposing and testing this system, suggesting a library of possible body language gestures for underwater robots, and offering insight on the design of nonverbal robot-to-human communication methods.
ER  - 

TY  - CONF
TI  - Three-Dimensionally Maneuverable Robotic Fish Enabled by Servo Motor and Water Electrolyser
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4667
EP  - 4673
AU  - W. Zuo
AU  - A. Keow
AU  - Z. Chen
PY  - 2019
KW  - biomechanics
KW  - compressed air systems
KW  - design engineering
KW  - mobile robots
KW  - motion control
KW  - open loop systems
KW  - pistons
KW  - servomotors
KW  - tanks (containers)
KW  - underwater vehicles
KW  - servo motor
KW  - three-dimensionally maneuverable robotic fish
KW  - depth control mechanism
KW  - compressed air tank
KW  - on-board water electrolyzer
KW  - two-dimensionally planar motion
KW  - open-loop control experiments
KW  - underwater robot
KW  - pistons
KW  - asymmetric flapping motion
KW  - caudal fin
KW  - design engineering
KW  - forward velocity
KW  - turning rate
KW  - velocity 0.13 m/s
KW  - time 10.0 s
KW  - time 5.5 s
KW  - size 0.55 m
KW  - Robots
KW  - Buoyancy
KW  - Three-dimensional displays
KW  - Force
KW  - Dynamics
KW  - Two dimensional displays
KW  - Solid modeling
DO  - 10.1109/ICRA.2019.8793870
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Three-dimensionally (3D) maneuverable robotic fish are highly desirable due to their abilities to explore and survey the underwater environment. Existing depth control mechanism is focused on using compressed air or piston to generate volume change, which makes the system bulky and impractical in a small size underwater robot. In this paper, a small and compact 3D maneuverable robotic fish is developed. Instead of using a compressed air tank, the robot is equipped with an on-board water electrolyzer to generate the gases for depth change. The fabricated robotic fish shows fast diving and rising performance. A servo motor is used to generate asymmetric flapping motion on the caudal fin, which leads to a two-dimensionally (2D) planar motion. A 3D dynamic model is then derived for the fabricated robotic fish. Several open-loop control experiments have been conducted to validate the model as well as the design. It has been demonstrated in the experimental results that the robot is capable of generating 3D motion. The robot can achieve 0.13 m/s forward velocity, 30.6 degree/s turning rate, and it takes about 5.5 s to dive to 0.55 m and 10 s to rise.
ER  - 

TY  - CONF
TI  - A Multimodal Aerial Underwater Vehicle with Extended Endurance and Capabilities
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4674
EP  - 4680
AU  - D. Lu
AU  - C. Xiong
AU  - Z. Zeng
AU  - L. Lian
PY  - 2019
KW  - aerospace components
KW  - aircraft control
KW  - autonomous aerial vehicles
KW  - autonomous underwater vehicles
KW  - design engineering
KW  - motion control
KW  - pneumatic systems
KW  - three-term control
KW  - vehicle dynamics
KW  - multimodal hybrid aerial underwater vehicle
KW  - MHAUV
KW  - design concept
KW  - fixed-wing unmanned aerial vehicle
KW  - extended endurance
KW  - Newton-Euler formalism
KW  - multidomain simulation
KW  - underwater glide test
KW  - design principles
KW  - proportional-integral-derivative
KW  - multirotor
KW  - lightweight pneumatic buoyancy adjustment system
KW  - vehicle's physical parameters
KW  - gliding equilibrium points
KW  - vehicle's motion control
KW  - Buoyancy
KW  - Bladder
KW  - Underwater vehicles
KW  - Prototypes
KW  - Rotors
KW  - Unmanned aerial vehicles
KW  - Mathematical model
DO  - 10.1109/ICRA.2019.8793985
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A new solution to improving the poor endurance of the existing hybrid aerial underwater vehicle (HAUV) is proposed in this paper. The proposed multimodal hybrid aerial underwater vehicle (MHAUV) merges the design concept of the fixed-wing unmanned aerial vehicle (UAV), the multirotor, and the underwater glider (UG) and has a novel lightweight pneumatic buoyancy adjustment system. MHAUV is well suited for moving in distinct medium and can achieve extended endurance for long distance travel in both air and water. The mathematical model is given based on Newton-Euler formalism. Necessary design principles of the vehicle's physical parameters are obtained through different gliding equilibrium points. Then, a control scheme composed of two separate proportional-integral-derivative (PID) is employed for the vehicle's motion control in multi-domain simulation. The simulation results are presented to verify the multi-domain mobility and the mode switch ability of the proposed vehicle intuitively. Finally, a prototype, NEZHA, is introduced to be the experimental platform. The success of the flight test, the hovering test, the underwater glide test, and the medium transition test all contribute to prove the feasibility of the proposed concept of the novel MHAUV.
ER  - 

TY  - CONF
TI  - Design and Experiments of a Squid-Like Aquatic-Aerial Vehicle with Soft Morphing Fins and Arms
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4681
EP  - 4687
AU  - T. Hou
AU  - X. Yang
AU  - H. Su
AU  - B. Jiang
AU  - L. Chen
AU  - T. Wang
AU  - J. Liang
PY  - 2019
KW  - actuators
KW  - aircraft control
KW  - biomimetics
KW  - drag
KW  - hinges
KW  - legged locomotion
KW  - microrobots
KW  - mobile robots
KW  - motion control
KW  - numerical analysis
KW  - pneumatic control equipment
KW  - pneumatic systems
KW  - robot kinematics
KW  - soft morphable structures
KW  - soft morphing fins
KW  - aquatic-aerial multimodal vehicle
KW  - concept aircraft
KW  - natural organisms
KW  - multilocomotion
KW  - rigid link mechanisms
KW  - hinges
KW  - pneumatically-driven soft fins
KW  - flying squid
KW  - lift force
KW  - drag force
KW  - wind
KW  - water tunnel
KW  - squid-like aquatic-aerial vehicle
KW  - Prototypes
KW  - Force
KW  - Cavity resonators
KW  - Propulsion
KW  - Valves
KW  - Wind tunnels
KW  - Drag
DO  - 10.1109/ICRA.2019.8793702
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Aquatic-aerial multimodal vehicle is a new concept aircraft that can freely shuttle between water and air. Some of the natural organisms provide the inspiration to realize this multi-locomotion. Most of current prototypes use rigid link mechanisms or hinges to morph the structure thus to adapt to the aquatic-aerial environment, which is commonly complicated and bulky. In this paper, we present a novel prototype with pneumatically-driven soft fins and arms that can fold and spread just like the flying squid. The fins and arms can augment the lift force during flying by spreading and reduce drag force during swimming by folding. The performance of the morphable structures was investigated in wind and water tunnel. The results explain the tradeoff strategies of multimodal-locomotion between water and air, and verify the feasibility of the novel aquatic-aerial vehicle with soft morphable structures.
ER  - 

TY  - CONF
TI  - Nonlinear Orientation Controller for a Compliant Robotic Fish Based on Asymmetric Actuation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4688
EP  - 4694
AU  - C. Meurer
AU  - A. Simha
AU  - Ü. Kotta
AU  - M. Kruusmaa
PY  - 2019
KW  - actuators
KW  - mobile robots
KW  - motion control
KW  - nonlinear control systems
KW  - robot dynamics
KW  - underwater vehicles
KW  - nonlinear orientation controller
KW  - compliant robotic fish
KW  - asymmetric actuation
KW  - compliant fish-like robot
KW  - rigid tails
KW  - flexible tail
KW  - underactuated robotic fish
KW  - asymmetric velocity profiles
KW  - skewed triangle waves
KW  - nonlinear control law
KW  - simple actuation mechanism
KW  - underwater observation
KW  - sinusoidal tail actuation
KW  - turning motion
KW  - Robot sensing systems
KW  - Turning
KW  - Position control
KW  - Torque
KW  - Oscillators
KW  - Kinematics
DO  - 10.1109/ICRA.2019.8793892
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Compliant fish-like robots are being developed as efficient and dependable underwater observation platforms with low impact on the observed environment. Orientation control is an essential building block to achieve autonomy for those vehicles. So far, the major focus has been on rigid tails or on flexible tails with a high degree of actuation. We present a novel control strategy for an underactuated robotic fish with a flexible tail optimized for cruising. The basis for our approach is the generation of asymmetric velocity profiles of the robot's tail beats. To achieve such velocity profiles, the usual sinusoidal tail actuation is replaced with skewed triangle waves. We provide a simple formulation for such waves, where their skew is dependent on only one variable which we define as skew factor. Furthermore, a nonlinear control law is derived to achieve the desired turning motions. We implement the controller on a compliant fish-like robot with a simple actuation mechanism. The control scheme is experimentally validated, and its robustness is tested in field trials.
ER  - 

TY  - CONF
TI  - Project AutoVision: Localization and 3D Scene Perception for an Autonomous Vehicle with a Multi-Camera System
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4695
EP  - 4702
AU  - L. Heng
AU  - B. Choi
AU  - Z. Cui
AU  - M. Geppert
AU  - S. Hu
AU  - B. Kuan
AU  - P. Liu
AU  - R. Nguyen
AU  - Y. C. Yeo
AU  - A. Geiger
AU  - G. H. Lee
AU  - M. Pollefeys
AU  - T. Sattler
PY  - 2019
KW  - cameras
KW  - geometry
KW  - image reconstruction
KW  - mobile robots
KW  - path planning
KW  - remotely operated vehicles
KW  - robot vision
KW  - stereo image processing
KW  - video signal processing
KW  - sensor suite
KW  - autonomous vehicle
KW  - multicamera system
KW  - 3D scene perception capabilities
KW  - self-driving vehicle
KW  - autonomous navigation
KW  - urban environments
KW  - rural environments
KW  - exteroceptive sensors
KW  - AutoVision project
KW  - multiview geometry
KW  - Cameras
KW  - Sensors
KW  - Three-dimensional displays
KW  - Calibration
KW  - Laser radar
KW  - Autonomous vehicles
KW  - Lighting
DO  - 10.1109/ICRA.2019.8793949
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Project AutoVision aims to develop localization and 3D scene perception capabilities for a self-driving vehicle. Such capabilities will enable autonomous navigation in urban and rural environments, in day and night, and with cameras as the only exteroceptive sensors. The sensor suite employs many cameras for both 360-degree coverage and accurate multi-view stereo; the use of low-cost cameras keeps the cost of this sensor suite to a minimum. In addition, the project seeks to extend the operating envelope to include GNSS-less conditions which are typical for environments with tall buildings, foliage, and tunnels. Emphasis is placed on leveraging multi-view geometry and deep learning to enable the vehicle to localize and perceive in 3D space. This paper presents an overview of the project, and describes the sensor suite and current progress in the areas of calibration, localization, and perception.
ER  - 

TY  - CONF
TI  - Improving the Robustness of Visual-Inertial Extended Kalman Filtering
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4703
EP  - 4709
AU  - J. Jackson
AU  - J. Nielsen
AU  - T. McLain
AU  - R. Beard
PY  - 2019
KW  - drag
KW  - image filtering
KW  - inertial navigation
KW  - Kalman filters
KW  - Monte Carlo methods
KW  - nonlinear filters
KW  - observability
KW  - state estimation
KW  - observability
KW  - consistency problems
KW  - three-fold improvement
KW  - linear drag term
KW  - velocity dynamics
KW  - estimation accuracy
KW  - partial-update formulation
KW  - linearization errors
KW  - partially-observable states
KW  - sensor biases
KW  - normally unobservable position
KW  - heading states
KW  - visual-inertial state estimation problem
KW  - Monte Carlo simulation experiment
KW  - visual-inertial Kalman filters
KW  - visual-inertial extended Kalman filtering
KW  - visual-inertial navigation methods
KW  - global measurements
KW  - Cameras
KW  - Quaternions
KW  - Estimation
KW  - Kalman filters
KW  - Mathematical model
KW  - Robustness
KW  - Navigation
DO  - 10.1109/ICRA.2019.8794164
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Visual-inertial navigation methods have been shown to be an effective, low-cost way to operate autonomously without GPS or other global measurements, however most filtering approaches to VI suffer from observability and consistency problems. To increase robustness of the state-of-the-art methods, we propose a three-fold improvement. First, we propose the addition of a linear drag term in the velocity dynamics which improves estimation accuracy. Second, we propose the use of a partial-update formulation which limits the effect of linearization errors in partially-observable states, such as sensor biases. Finally, we propose the use of a keyframe reset step to enforce observability and consistency of the normally unobservable position and heading states. While all of these concepts have been used independently in the past, our experiments demonstrate additional strength when they are used simultaneously in a visual-inertial state estimation problem. In this paper, we derive the proposed filter and use a Monte Carlo simulation experiment to analyze the response of visual-inertial Kalman filters with the above described additions. The results of this study show that the combination of all of these features significantly improves estimation accuracy and consistency.
ER  - 

TY  - CONF
TI  - Towards Fully Dense Direct Filter-Based Monocular Visual-Inertial Odometry
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4710
EP  - 4716
AU  - A. Hardt-Stremayr
AU  - S. Weiss
PY  - 2019
KW  - covariance matrices
KW  - distance measurement
KW  - gradient methods
KW  - image filtering
KW  - image texture
KW  - matrix inversion
KW  - mobile robots
KW  - robot vision
KW  - smoothing methods
KW  - low-textured areas
KW  - smooth gradients
KW  - complexity reduction methods
KW  - direct filter-based monocular visual-inertial odometry
KW  - direct filter-based visual-inertial odometry method
KW  - Cameras
KW  - Integrated circuits
KW  - Uncertainty
KW  - Complexity theory
KW  - Estimation
KW  - Covariance matrices
KW  - Jacobian matrices
DO  - 10.1109/ICRA.2019.8793837
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose a fully dense direct filter-based visual-inertial odometry method estimating both pixel depth for all pixels and robot state simultaneously, having all uncertainties in the same state vector. Due to the fully dense method, our approach works even in low-textured areas with very low, smooth gradients (i.e. scenes where feature based or semi-dense approaches fail). Our algorithm performs in real-time on a CPU with a time complexity linearly dependent on the amount of pixels in the provided image. To achieve this, we propose complexity reduction methods for fast matrix inversion, exploiting specific structures of the covariance matrix. We provide both simulated and real-world results in low-textured areas with a smooth gradient.
ER  - 

TY  - CONF
TI  - Enhancing V-SLAM Keyframe Selection with an Efficient ConvNet for Semantic Analysis
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4717
EP  - 4723
AU  - I. Alonso
AU  - L. Riazuelo
AU  - A. C. Murillo
PY  - 2019
KW  - convolutional neural nets
KW  - microprocessor chips
KW  - mobile robots
KW  - neural net architecture
KW  - object detection
KW  - robot vision
KW  - SLAM (robots)
KW  - video signal processing
KW  - image quality
KW  - semantic information
KW  - robotic systems
KW  - V-SLAM keyframe selection
KW  - semantic analysis
KW  - semantic image analysis
KW  - visual information
KW  - ConvNet
KW  - video
KW  - Visual-SLAM
KW  - CNN architecture
KW  - onboard CPU
KW  - Robots
KW  - Semantics
KW  - Task analysis
KW  - Computer architecture
KW  - Visualization
KW  - Image segmentation
KW  - Standards
DO  - 10.1109/ICRA.2019.8793923
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Selecting relevant visual information from a video is a challenging task on its own and even more in robotics, due to strong computational restrictions. This work proposes a novel keyframe selection strategy based on image quality and semantic information, which boosts strategies currently used in Visual-SLAM (V-SLAM). Commonly used V-SLAM methods select keyframes based only on relative displacements and amount of tracked feature points. Our strategy to select more carefully these keyframes allows the robotic systems to make better use of them. With minimal computational cost, we show that our selection includes more relevant keyframes, which are useful for additional posterior recognition tasks, without penalizing the existing ones, mainly place recognition. A key ingredient is our novel CNN architecture to run a quick semantic image analysis at the onboard CPU of the robot. It provides sufficient accuracy significantly faster than related works. We demonstrate our hypothesis with several public datasets with challenging robotic data.
ER  - 

TY  - CONF
TI  - Unsupervised Learning of Monocular Depth and Ego-Motion Using Multiple Masks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4724
EP  - 4730
AU  - G. Wang
AU  - H. Wang
AU  - Y. Liu
AU  - W. Chen
PY  - 2019
KW  - cameras
KW  - image matching
KW  - image sequences
KW  - motion estimation
KW  - object detection
KW  - unsupervised learning
KW  - video signal processing
KW  - monocular depth
KW  - multiple masks
KW  - unsupervised learning method
KW  - depth estimation network
KW  - ego-motion estimation network
KW  - projection target imaging plane
KW  - fine masks
KW  - image pixel mismatch
KW  - repeated masking
KW  - KITTI dataset
KW  - low-quality uncalibrated bike video dataset
KW  - Image reconstruction
KW  - Estimation
KW  - Cameras
KW  - Unsupervised learning
KW  - Training
KW  - Simultaneous localization and mapping
DO  - 10.1109/ICRA.2019.8793622
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A new unsupervised learning method of depth and ego-motion using multiple masks from monocular video is proposed in this paper. The depth estimation network and the ego-motion estimation network are trained according to the constraints of depth and ego-motion without truth values. The main contribution of our method is to carefully consider the occlusion of the pixels generated when the adjacent frames are projected to each other, and the blank problem generated in the projection target imaging plane. Two fine masks are designed to solve most of the image pixel mismatch caused by the movement of the camera. In addition, some relatively rare circumstances are considered, and repeated masking is proposed. To some extent, the method is to use a geometric relationship to filter the mismatched pixels for training, making unsupervised learning more efficient and accurate. The experiments on KITTI dataset show our method achieves good performance in terms of depth and ego-motion. The generalization capability of our method is demonstrated by training on the low-quality uncalibrated bike video dataset and evaluating on KITTI dataset, and the results are still good.
ER  - 

TY  - CONF
TI  - Characterizing the Effects of Reduced Gravity on Rover Wheel-Soil Interactions using Computer Vision Techniques
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4739
EP  - 4745
AU  - P. Niksirat
AU  - K. Skonieczny
AU  - A. F. Nassiraei
PY  - 2019
KW  - computer vision
KW  - Mars
KW  - mobile robots
KW  - planetary rovers
KW  - planetary surfaces
KW  - soil
KW  - wheels
KW  - lower gravity
KW  - soil resistance
KW  - weaker soil bonding
KW  - rover mobility
KW  - reduced-mass rover
KW  - full-mass rover
KW  - rover wheel-soil interactions
KW  - computer vision techniques
KW  - planetary rovers
KW  - Martian soil simulant
KW  - rover-soil visualization technique
KW  - reduced gravity wheel-terrain interaction
KW  - ExoMars wheel prototype
KW  - simulated Martian gravity
KW  - wheel normal load
KW  - ExoMars space mission
KW  - Wheels
KW  - Soil
KW  - Gravity
KW  - Moon
KW  - Aircraft
KW  - Space vehicles
KW  - Earth
DO  - 10.1109/ICRA.2019.8793895
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Mitigating potential hazards for planetary rovers posed by soft soils requires testing in representative environments such as with Martian soil simulants in reduced gravity. This work describes the experimentation, methods, and results of a rover-soil visualization technique that produced rich datasets of reduced gravity wheel-terrain interaction. The activities are linked to the upcoming ExoMars space mission, through the use of ExoMars wheel prototype and Martian soil simulant in simulated Martian gravity produced in parabolic flights. The results indicate that, with wheel normal load held equal between experiments, the amount of soil mobilized by wheel-soil interaction increases as gravity decreases. Moreover, the amount of soil mobilized is more sensitive to slip in lower gravity. The results of the visualization analysis suggest a deterioration in the soil resistance and weaker soil bonding at lower gravities, which undermines the rover mobility by reducing the net traction. The results have important implications regarding the practice of using a reduced-mass rover on Earth to assess the performance of a full-mass rover in similar soil on an extraterrestrial surface.
ER  - 

TY  - CONF
TI  - Adaptive H∞ Controller for Precise Manoeuvring of a Space Robot
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4746
EP  - 4752
AU  - A. Seddaoui
AU  - C. M. Saaj
AU  - S. Eckersley
PY  - 2019
KW  - adaptive control
KW  - aerospace robotics
KW  - assembling
KW  - control system synthesis
KW  - H∞ control
KW  - manipulators
KW  - mirrors
KW  - motion control
KW  - nonlinear control systems
KW  - position control
KW  - robust control
KW  - space vehicles
KW  - space robot
KW  - precise manoeuvring
KW  - controlled-floating mode
KW  - in-orbit telescope assembly
KW  - robotic arm
KW  - slow manoeuvres
KW  - precise manoeuvres
KW  - orbital assembly missions
KW  - robustness
KW  - optical mirrors
KW  - nonlinear H∞ controller
KW  - adaptive H∞ controller
KW  - Space vehicles
KW  - Aerospace electronics
KW  - Robot kinematics
KW  - Manipulators
KW  - Uncertainty
KW  - Orbits
DO  - 10.1109/ICRA.2019.8794374
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - A space robot working in a controlled-floating mode can be used for performing in-orbit telescope assembly through simultaneously controlling the motion of the spacecraft base and its robotic arm. Handling and assembling optical mirrors requires the space robot to achieve slow and precise manoeuvres regardless of the disturbances and errors in the trajectory. The robustness offered by the nonlinear H∞ controller, in the presence of environmental disturbances and parametric uncertainties, makes it a viable solution. However, using fixed tuning parameters for this controller does not always result in the desired performance as the arm's trajectory is not known a priori for orbital assembly missions. In this paper, a complete study on the impact of the different tuning parameters is performed and a new adaptive H∞ controller is developed based on bounded functions. The simulation results presented show that the proposed adaptive H∞ controller guarantees robustness and precise tracking using a minimal amount of forces and torques for assembly operations using a small space robot.
ER  - 

TY  - CONF
TI  - Belief Space Planning for Reducing Terrain Relative Localization Uncertainty in Noisy Elevation Maps
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4753
EP  - 4759
AU  - E. Fang
AU  - P. M. Furlong
AU  - W. Whittaker
PY  - 2019
KW  - astronomical image processing
KW  - digital elevation models
KW  - Global Positioning System
KW  - mobile robots
KW  - path planning
KW  - planetary rovers
KW  - robot vision
KW  - solid modelling
KW  - terrain mapping
KW  - belief space planning
KW  - noisy map data
KW  - elevation data
KW  - lunar orbital imagery
KW  - terrain relative localization uncertainty
KW  - noisy elevation
KW  - accurate global localization
KW  - operational risk
KW  - initial exploration missions
KW  - global position
KW  - terrain relative navigation
KW  - TRN
KW  - planetary rover-perspective images
KW  - digital elevation models
KW  - absolute positioning
KW  - orbital data
KW  - terrain features
KW  - GPS
KW  - satellite orbital imagery
KW  - Uncertainty
KW  - Planning
KW  - Noise measurement
KW  - Space vehicles
KW  - Navigation
KW  - Planetary orbits
DO  - 10.1109/ICRA.2019.8793255
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate global localization is essential for planetary rovers to reach mission goals and mitigate operational risk. For initial exploration missions, it is inappropriate to deploy GPS or build other infrastructure for navigating. One way of determining global position is to use terrain relative navigation (TRN). TRN compares planetary rover-perspective images and 3D models to existing satellite orbital imagery and digital elevation models (DEMs) for absolute positioning. However, TRN is limited by the quality of orbital data and the presence and uniqueness of terrain features. This work presents a novel combination of belief space planning with terrain relative navigation. Additionally, we introduce a new method for increasing the robustness of belief space planning to noisy map data. The new algorithm provides a statistically significant reduction in localization uncertainty when tested on elevation data produced from lunar orbital imagery.
ER  - 

TY  - CONF
TI  - Soil Displacement Terramechanics for Wheel-Based Trenching with a Planetary Rover
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4760
EP  - 4766
AU  - C. Pavlov
AU  - A. M. Johnson
PY  - 2019
KW  - aerospace robotics
KW  - mobile robots
KW  - planetary rovers
KW  - soil
KW  - wheels
KW  - trenching
KW  - autonomous trenching
KW  - front wheel
KW  - rear wheel
KW  - deep trench
KW  - single wheel experiments
KW  - driving strategy
KW  - closed-form model
KW  - digging operations
KW  - wheel actuators
KW  - planetary exploration rovers
KW  - wheel-based trenching
KW  - soil displacement terramechanics
KW  - Wheels
KW  - Soil
KW  - Geometry
KW  - Deformable models
KW  - Mathematical model
KW  - Predictive models
KW  - Finite element analysis
DO  - 10.1109/ICRA.2019.8793645
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Planetary exploration rovers are expensive, weight constrained, and cannot be serviced once deployed. Here, we explore one way to increase their capabilities while avoiding the cost, mass, and complexity leading to these issues. We propose to re-use the large wheel actuators for trenching and other digging operations, which will enable a range of missions such as sampling deeper layers of soil. We present a new, closed-form model of the soil displaced by an angled, spinning wheel to analyze the trenching potential of a driving strategy and inform the control of the wheel. The model is demonstrated with single wheel experiments under different driving conditions. The model suggests: that a deep trench does not require large tractive efforts; that the shape of the trench can be controlled; and that a rear wheel has a lower risk of entrapment when trenching than a front wheel. Ultimately this model could be used in a nonprehensile manipulation planning or learning algorithm to enable autonomous trenching.
ER  - 

TY  - CONF
TI  - Experimental Evaluation of Teleoperation Interfaces for Cutting of Satellite Insulation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4775
EP  - 4781
AU  - W. Pryor
AU  - B. P. Vagvolgyi
AU  - W. J. Gallagher
AU  - A. Deguet
AU  - S. Leonard
AU  - L. L. Whitcomb
AU  - P. Kazanzides
PY  - 2019
KW  - aerospace robotics
KW  - artificial satellites
KW  - cameras
KW  - control engineering computing
KW  - data visualisation
KW  - medical robotics
KW  - robot vision
KW  - telerobotics
KW  - da Vinci master console
KW  - conventional control interface
KW  - conventional visualization
KW  - operator performance
KW  - cutting task
KW  - conventional teleoperation interface
KW  - da Vinci surgical robot
KW  - conventional camera-based visualization
KW  - augmented virtuality visualization
KW  - trained NASA robot teleoperators
KW  - ground-based experiments
KW  - available cameras
KW  - round-trip telemetry delay
KW  - human operator
KW  - servicing operation
KW  - protective thermal blanketing
KW  - satellite insulation
KW  - teleoperation interfaces
KW  - experimental evaluation
KW  - Satellites
KW  - Cameras
KW  - Visualization
KW  - Solid modeling
KW  - Robot vision systems
KW  - Three-dimensional displays
DO  - 10.1109/ICRA.2019.8793968
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - On-orbit servicing of satellites is complicated by the fact that almost all existing satellites were not designed to be serviced. This creates a number of challenges, one of which is to cut and partially remove the protective thermal blanketing that encases a satellite prior to performing the servicing operation. A human operator on Earth can perform this task telerobotically, but must overcome difficulties presented by the multi-second round-trip telemetry delay between the satellite and the operator and the limited, or even obstructed, views from the available cameras. This paper reports the results of ground-based experiments with trained NASA robot teleoperators to compare our recently-reported augmented virtuality visualization to the conventional camera-based visualization. We also compare the master console of a da Vinci surgical robot to the conventional teleoperation interface. The results show that, for the cutting task, the augmented virtuality visualization can improve operator performance compared to the conventional visualization, but that operators are more proficient with the conventional control interface than with the da Vinci master console.
ER  - 

TY  - CONF
TI  - OmniDRL: Robust Pedestrian Detection using Deep Reinforcement Learning on Omnidirectional Cameras*
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4782
EP  - 4789
AU  - G. Dias Pais
AU  - T. J. Dias
AU  - J. C. Nascimento
AU  - P. Miraldo
PY  - 2019
KW  - cameras
KW  - computerised instrumentation
KW  - image processing
KW  - learning (artificial intelligence)
KW  - robust pedestrian detection
KW  - omnidirectional cameras
KW  - computer vision
KW  - robotics
KW  - deep learning methods
KW  - omnidirectional imaging
KW  - OmniDRL
KW  - deep reinforcement learning
KW  - 3D bounding boxes
KW  - Cameras
KW  - Three-dimensional displays
KW  - Distortion
KW  - Image segmentation
KW  - Robot vision systems
KW  - Object detection
DO  - 10.1109/ICRA.2019.8794471
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Pedestrian detection is one of the most explored topics in computer vision and robotics. The use of deep learning methods allowed the development of new and highly competitive algorithms. Deep Reinforcement Learning has proved to be within the state-of-the-art in terms of both detection in perspective cameras and robotics applications. However, for detection in omnidirectional cameras, the literature is still scarce, mostly because of their high levels of distortion. This paper presents a novel and efficient technique for robust pedestrian detection in omnidirectional images. The proposed method uses deep Reinforcement Learning that takes advantage of the distortion in the image. By considering the 3D bounding boxes and their distorted projections into the image, our method is able to provide the pedestrian's position in the world, in contrast to the image positions provided by most state-of-the-art methods for perspective cameras. Our method avoids the need of pre-processing steps to remove the distortion, which is computationally expensive. Beyond the novel solution, our method compares favorably with the state-of-the-art methodologies that do not consider the underlying distortion for the detection task.
ER  - 

TY  - CONF
TI  - 2D3D-Matchnet: Learning To Match Keypoints Across 2D Image And 3D Point Cloud
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4790
EP  - 4796
AU  - M. Feng
AU  - S. Hu
AU  - M. H. Ang
AU  - G. H. Lee
PY  - 2019
KW  - cameras
KW  - feature extraction
KW  - image classification
KW  - image matching
KW  - image representation
KW  - image retrieval
KW  - image sensors
KW  - learning (artificial intelligence)
KW  - object recognition
KW  - pose estimation
KW  - solid modelling
KW  - visual databases
KW  - image-based counterpart
KW  - visual pose estimation
KW  - 2D-3D image
KW  - cloud correspondences
KW  - end-to-end deep network architecture
KW  - query image
KW  - 3D point cloud reference map
KW  - Oxford 2D-3D Patches dataset
KW  - Oxford Robotcar dataset
KW  - ground truth camera pose
KW  - Three-dimensional displays
KW  - Two dimensional displays
KW  - Pose estimation
KW  - Visualization
KW  - Cameras
KW  - Training
KW  - Detectors
DO  - 10.1109/ICRA.2019.8794415
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Large-scale point cloud generated from 3D sensors is more accurate than its image-based counterpart. However, it is seldom used in visual pose estimation due to the difficulty in obtaining 2D-3D image to point cloud correspondences. In this paper, we propose the 2D3D-MatchNet - an end-to-end deep network architecture to jointly learn the descriptors for 2D and 3D keypoint from image and point cloud, respectively. As a result, we are able to directly match and establish 2D-3D correspondences from the query image and 3D point cloud reference map for visual pose estimation. We create our Oxford 2D-3D Patches dataset from the Oxford Robotcar dataset with the ground truth camera poses and 2D-3D image to point cloud correspondences for training and testing the deep network. Experimental results verify the feasibility of our approach.
ER  - 

TY  - CONF
TI  - Teaching Robots To Draw
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4797
EP  - 4803
AU  - A. Kotani
AU  - S. Tellex
PY  - 2019
KW  - handwritten character recognition
KW  - manipulators
KW  - natural language processing
KW  - teaching
KW  - just-drawn handwritten characters
KW  - writing utensil
KW  - target stroke
KW  - continuous drawing motion
KW  - handcrafted rules
KW  - predefined paths
KW  - stroke-based drawing
KW  - teaching robots
KW  - manipulator robots
KW  - line drawings
KW  - Automation
KW  - Machine-to-machine communications
DO  - 10.1109/ICRA.2019.8793484
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this paper, we introduce an approach which enables manipulator robots to write handwritten characters or line drawings. Given an image of just-drawn handwritten characters, the robot infers a plan to replicate the image with a writing utensil, and then reproduces the image. Our approach draws each target stroke in one continuous drawing motion and does not rely on handcrafted rules or on predefined paths of characters. Instead, it learns to write from a dataset of demonstrations. We evaluate our approach in both simulation and on two real robots. Our model can draw handwritten characters in a variety of languages which are disjoint from the training set, such as Greek, Tamil, or Hindi, and also reproduce any stroke-based drawing from an image of the drawing.
ER  - 

TY  - CONF
TI  - Learning Probabilistic Multi-Modal Actor Models for Vision-Based Robotic Grasping
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4804
EP  - 4810
AU  - M. Yan
AU  - A. Li
AU  - M. Kalakrishnan
AU  - P. Pastor
PY  - 2019
KW  - Gaussian processes
KW  - learning (artificial intelligence)
KW  - manipulators
KW  - neural nets
KW  - robot vision
KW  - statistical distributions
KW  - inference time
KW  - probabilistic multimodal actor models
KW  - vision-based robotic grasping
KW  - neural density model
KW  - neural network
KW  - normalizing flows
KW  - complex probability distributions
KW  - Gaussian mixture
KW  - conditional distribution
KW  - 4 dimensional action space
KW  - Training
KW  - Grasping
KW  - Robots
KW  - Neural networks
KW  - Computational modeling
KW  - Predictive models
KW  - Probability distribution
DO  - 10.1109/ICRA.2019.8794024
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Many previous works approach vision-based robotic grasping by training a value network that evaluates grasp proposals. These approaches require an optimization process at run-time to infer the best action from the value network. As a result, the inference time grows exponentially as the dimension of action space increases. We propose an alternative method, by directly training a neural density model to approximate the conditional distribution of successful grasp poses from the input images. We construct a neural network that combines Gaussian mixture and normalizing flows, which is able to represent multi-modal, complex probability distributions. We demonstrate on both simulation and real robot that the proposed actor model achieves similar performance compared to the value network using the Cross-Entropy Method (CEM) for inference, on top-down grasping with a 4 dimensional action space. Our actor model reduces the inference time by 3 times compared to the state-of-the-art CEM method. We believe that actor models will play an important role when scaling up these approaches to higher dimensional action spaces.
ER  - 

TY  - CONF
TI  - Self-supervised Learning for Single View Depth and Surface Normal Estimation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4811
EP  - 4817
AU  - H. Zhan
AU  - C. S. Weerasekera
AU  - R. Garg
AU  - I. Reid
PY  - 2019
KW  - convolutional neural nets
KW  - natural scenes
KW  - stereo image processing
KW  - supervised learning
KW  - single view depth
KW  - surface normal estimation
KW  - self-supervised learning framework
KW  - surface normals
KW  - outdoor scenes
KW  - fronto-parallel planes
KW  - piece-wise smooth depth
KW  - surface orientation
KW  - natural scenes
KW  - piece-wise smooth normals
KW  - trained normal network
KW  - depth network
KW  - realistic smooth normal assumption
KW  - self-supervised depth prediction network
KW  - convolutional neural networks
KW  - depth-normal consistency
KW  - Training
KW  - Estimation
KW  - Geometry
KW  - Cameras
KW  - Sensors
KW  - Visual odometry
KW  - Neural networks
DO  - 10.1109/ICRA.2019.8793984
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - In this work we present a self-supervised learning framework to simultaneously train two Convolutional Neural Networks (CNNs) to predict depth and surface normals from a single image. In contrast to most existing frameworks which represent outdoor scenes as fronto-parallel planes at piece-wise smooth depth, we propose to predict depth with surface orientation while assuming that natural scenes have piece-wise smooth normals. We show that a simple depth-normal consistency as a soft-constraint on the predictions is sufficient and effective for training both these networks simultaneously. The trained normal network provides state-of-the-art predictions while the depth network, relying on much realistic smooth normal assumption, outperforms the traditional self-supervised depth prediction network by a large margin on the KITTI benchmark.
ER  - 

TY  - CONF
TI  - Learning to Drive from Simulation without Real World Labels
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4818
EP  - 4824
AU  - A. Bewley
AU  - J. Rigley
AU  - Y. Liu
AU  - J. Hawke
AU  - R. Shen
AU  - V. Lam
AU  - A. Kendall
PY  - 2019
KW  - cameras
KW  - closed loop systems
KW  - control engineering computing
KW  - learning (artificial intelligence)
KW  - learning systems
KW  - mobile robots
KW  - road vehicles
KW  - robot vision
KW  - traffic engineering computing
KW  - domain transfer
KW  - single-camera control policy
KW  - simulation control labels
KW  - driving performance
KW  - rural roads
KW  - urban roads
KW  - machine learning systems
KW  - simulated environment
KW  - vision-based lane
KW  - driving policy
KW  - rural road
KW  - image-to-image translation
KW  - autonomous vehicle
KW  - open-loop regression metric
KW  - Aerospace electronics
KW  - Image reconstruction
KW  - Task analysis
KW  - Semantics
KW  - Training
KW  - Roads
KW  - Measurement
DO  - 10.1109/ICRA.2019.8793668
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Simulation can be a powerful tool for under-standing machine learning systems and designing methods to solve real-world problems. Training and evaluating methods purely in simulation is often “doomed to succeed” at the desired task in a simulated environment, but the resulting models are incapable of operation in the real world. Here we present and evaluate a method for transferring a vision-based lane following driving policy from simulation to operation on a rural road without any real-world labels. Our approach leverages recent advances in image-to-image translation to achieve domain transfer while jointly learning a single-camera control policy from simulation control labels. We assess the driving performance of this method using both open-loop regression metrics, and closed-loop performance operating an autonomous vehicle on rural and urban roads.
ER  - 

TY  - CONF
TI  - Fabrication and Characterization of Muscle Rings Using Circular Mould and Rotary Electrical Stimulation for Bio-Syncretic Robots
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4825
EP  - 4830
AU  - C. Zhang
AU  - J. Shi
AU  - W. Wang
AU  - N. Xi
AU  - Y. Wang
AU  - L. Liu
PY  - 2019
KW  - actuators
KW  - biological tissues
KW  - biomechanics
KW  - cardiology
KW  - cellular biophysics
KW  - electromechanical actuators
KW  - medical robotics
KW  - muscle
KW  - physiological models
KW  - tissue engineering
KW  - circular mould
KW  - rotary electrical stimulation
KW  - bio-syncretic robots
KW  - high-quality muscle rings
KW  - living biological systems
KW  - electromechanical systems
KW  - natural biological entities
KW  - 3D skeletal muscles
KW  - contraction force
KW  - electrical pulses stimulation
KW  - control property
KW  - 3D muscle tissues
KW  - muscle tissue engineering
KW  - Muscles
KW  - Electrical stimulation
KW  - Electrodes
KW  - Service robots
KW  - Skeleton
DO  - 10.1109/ICRA.2019.8793903
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Bio-syncretic robots made up of living biological systems and electromechanical systems may have the potential excellent performance of natural biological entities. Therefore, the study of the bio-syncretic robots has got lots of attention in recent years. The 3D skeletal muscles have been used widely, due to the considerable contraction force and the controllability. However, the low differentiation quality of the C2C12 in the tissues hinders the broad application in the development of the skeleton muscle actuated bio-syncretic robots. In this work, an approach based on circular mould and rotary electrical stimulation to build high-quality muscle rings, which can be used to actuate various bio-syncretic robots, has been proposed. Firstly, the advantage of the proposed circular mould for the muscle rings culture has been shown by simulation. Then, the muscle rings have been fabricated with different moulds using the experiment-optimized compositions of the biological mixture. After that, the muscle rings in the circular moulds with different electrical stimulations have been cultured, to show the superiority of the proposed rotary electrical stimulation. Moreover, the contractility of the muscle rings have been measured under the different electrical pulses stimulation, for the study of the control property of the muscle rings. This work may be meaningful not only the development of bio-syncretic robots actuated by 3D muscle tissues but also the muscle tissue engineering.
ER  - 

TY  - CONF
TI  - Cell Injection Microrobot Development and Evaluation in Microfluidic Chip
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4831
EP  - 4836
AU  - L. Feng
AU  - D. Chen
AU  - Q. Zhou
AU  - B. Song
AU  - W. Zhang
PY  - 2019
KW  - bioMEMS
KW  - cellular biophysics
KW  - lab-on-a-chip
KW  - medical robotics
KW  - microfluidics
KW  - microrobots
KW  - membrane
KW  - cell suction
KW  - elastic forces
KW  - magnetic forces
KW  - ejection forces
KW  - microrobot body
KW  - mammalian oocyte
KW  - cell injection microrobot development
KW  - microfluidic chip
KW  - micronewton forces
KW  - cell nuclei
KW  - nozzle
KW  - Permanent magnets
KW  - Strain
KW  - Glass
KW  - Robots
KW  - Magnetic forces
KW  - Microfluidics
KW  - Biomembranes
DO  - 10.1109/ICRA.2019.8793799
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - We propose an innovative design of microrobot, which can achieve donor cell suction, delivery and injection in a mammalian oocyte on microfluidic chip. The microrobot body contains a hollow space that produces suction and ejection forces for injection of cell nuclei using a nozzle at the tip of the robot. Specifically, a controller changes the hollow volume by balancing the magnetic and elastic forces of the membrane, and along with motion of stages in the XY plane. A glass capillary attached at the tip of the robot contains the nozzle is able to absorb and inject cell nuclei. The microrobot provides three degrees of freedom and generates micronewton forces. We demonstrate the effectiveness of the proposed microrobot through an experiment of absorption and ejection of 20 μm particles from the nozzle using magnetic control in a microfluidic chip.
ER  - 

TY  - CONF
TI  - Orienting Oocytes using Vibrations for In-Vitro Fertilization Procedures
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4837
EP  - 4843
AU  - D. Meyer
AU  - M. L. P. Colon
AU  - H. V. Alizadeh
AU  - L. Su
AU  - B. Behr
AU  - D. B. Camarillo
PY  - 2019
KW  - biomedical equipment
KW  - bioMEMS
KW  - cellular biophysics
KW  - genetics
KW  - medical robotics
KW  - micromanipulators
KW  - patient diagnosis
KW  - vibrations
KW  - orienting oocytes
KW  - vibrations
KW  - assisted reproductive technologies
KW  - sperm injection
KW  - manual manipulation
KW  - error procedure
KW  - skilled embryologists
KW  - desired orientation
KW  - IVF clinics
KW  - extensive changes
KW  - standard equipment
KW  - surface transducer
KW  - pipette holder
KW  - pipette tip axis
KW  - vibration burst
KW  - polar body detection algorithm
KW  - system cause rotation
KW  - micropipettes
KW  - in-vitro fertilization procedures
KW  - 2D motion
KW  - Vibrations
KW  - Transducers
KW  - Automation
KW  - Subspace constraints
KW  - Glass
KW  - Cameras
KW  - Resonant frequency
DO  - 10.1109/ICRA.2019.8793498
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Accurate positioning of cells is a fundamental task for many procedures in assisted reproductive technologies (e.g. intracytoplasmic sperm injection or preimplantation genetic diagnosis) to extract or insert materials into and from the cell without causing damage to it. The current method of manual manipulation is based on a trial and error procedure performed by skilled embryologists, where they use two different micropipettes to rotate the cell and immobilize it in the desired orientation. This procedure is time consuming, inconsistent and has a low efficiency. Attempts to automate the process presented in the literature have not yet been implemented in IVF clinics because their high degree of automation requires extensive changes to the current systems used in the clinics. We designed a system that can easily be integrated into standard equipment of IVF clinics and allows automated as well as manual manipulation of cells. The system uses vibrations induced by a surface transducer at the pipette holder to rotate the cell around the pipette tip axis, resulting in 2D motion. To detect if the polar body is in the desired position after a vibration burst, we developed a polar body detection algorithm. We performed simulations and experiments to confirm that vibrations at the natural frequencies of the system cause rotation around the pipette tip axis. Experimental results show that the system is capable of positioning the polar body in plane in less than 5.41 seconds.
ER  - 

TY  - CONF
TI  - Vision-Based Automated Sorting of C. Elegans on a Microfluidic Device
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4844
EP  - 4849
AU  - X. Dong
AU  - P. Song
AU  - X. Liu
PY  - 2019
KW  - cellular biophysics
KW  - microfluidics
KW  - size measurement
KW  - sorting
KW  - valves
KW  - multiworm loading
KW  - body size measurement
KW  - size-based sorting
KW  - vision-based algorithms
KW  - double-layer microfluidic device
KW  - vision-based worm detection
KW  - active sorting
KW  - passive sorting mechanisms
KW  - conventional worm sorting
KW  - high-speed sorting
KW  - automated speed sorting
KW  - vision-based microfluidic system
KW  - vision-based automated sorting
KW  - sequential loading
KW  - computer-controlled pneumatic valves
KW  - worm body length measurement
KW  - worm body width measurement
KW  - vision-based worm size measurement
KW  - worm biology
KW  - automated on-chip worm manipulation
KW  - nematode worm C. elegans
KW  - Grippers
KW  - Sorting
KW  - Loading
KW  - Valves
KW  - Size measurement
KW  - Image processing
KW  - Length measurement
DO  - 10.1109/ICRA.2019.8793689
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper reports a vision-based microfluidic system for automated, high-speed sorting of the nematode worm C. elegans. Exceeding the capabilities of conventional worm sorting microfluidic devices purely relying on passive sorting mechanisms, our system is capable of accurate measurement of the worm body length/width and active sorting of worms with the desired sizes from a mixture of worms at different developmental stages. This feature is enabled by the combination of vision-based worm detection and sizing algorithms and automated on-chip worm manipulation. A double-layer microfluidic device with computer-controlled pneumatic valves is developed for sequential loading, trapping, imaging, and sorting of single worms based on vision-based worm size measurement results. To keep the system operation robust, vision-based algorithms for detecting multi-worm loading and worm size measurement failure have also been developed. We conducted sorting experiments on 319 worms and achieve an average sorting speed of 10.4 worms per minute (5.8 s/worm) with an operation success rate of 90.3%. This system will facilitate worm biology studies where body size measurement and size-based sorting of many worms are needed.
ER  - 

TY  - CONF
TI  - Asymmetric Local Metric Learning with PSD Constraint for Person Re-identification
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4862
EP  - 4868
AU  - Z. Wen
AU  - M. Sun
AU  - Y. Li
AU  - S. Ying
AU  - Y. Peng
PY  - 2019
KW  - approximation theory
KW  - image recognition
KW  - iterative methods
KW  - learning (artificial intelligence)
KW  - matrix algebra
KW  - video signal processing
KW  - visual databases
KW  - asymmetric local metric learning
KW  - machine learning
KW  - positive sample pairs
KW  - adaptive local metric learning method
KW  - single distance metric
KW  - smooth metric matrix function
KW  - linear combinations
KW  - learning process
KW  - positive semidefinite constraint
KW  - person reidentification
KW  - metric learning
KW  - PSD constraint
KW  - UCI databases
KW  - GRID database
KW  - VIPeR database
KW  - CUHK01 database
KW  - video monitor
KW  - approximation error bound
KW  - Measurement
KW  - Learning systems
KW  - Manifolds
KW  - Databases
KW  - Symmetric matrices
KW  - Machine learning
KW  - Machine learning algorithms
DO  - 10.1109/ICRA.2019.8794455
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Person re-identification is one of the key issues in both machine learning and video monitor application. In particular, defining an appropriate distance metric between the person images is very important. Existing metric learning approaches used in person re-identification either learn a single measure, or ignore the positive semi-definite (PSD) of measurement matrix, at the same time, since the number of negative sample pairs largely exceeds the number of positive sample pairs, some metric learning methods are largely influenced by the sample imbalance. Considering the above issues, we propose a new adaptive local metric learning method with positive semi-definite (PSD) constraint. Unlike existing metric learning methods which learn a single distance metric, we use an approximation error bound of a smooth metric matrix function over the data manifold to learn local metrics as linear combinations of basis metrics defined on anchor points over different regions of the instance space. Besides, we develop an efficient two stage algorithm that first learns the anchor points and the linear combinations of each instance, then learns the metric matrices of the anchor points. We employ the fast iterative shrinkage-thresholding algorithm which is a fast first-order optimization algorithm in the learning process of the linear combinations as well as the basis metrics of the anchor points. Our metric learning method has excellent performance. We firstly apply the proposed method on 5 UCI databases, which are widely used in machine learning, to test and evaluate the effectiveness of the proposed method. Then the proposed approach is applied for person re-identification, achieving better performance on three challenging databases (GRID, VIPeR, CUHK01) than the existing methods. The experimental results show that the proposed method can prvide the theoretical and practical support for the person re-identification problem.
ER  - 

TY  - CONF
TI  - Fast and Robust 3D Person Detector and Posture Estimator for Mobile Robotic Applications
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4869
EP  - 4875
AU  - B. Lewandowski
AU  - J. Liebner
AU  - T. Wengefeld
AU  - S. Müller
AU  - H. Gross
PY  - 2019
KW  - computer vision
KW  - learning (artificial intelligence)
KW  - mobile robots
KW  - object detection
KW  - pose estimation
KW  - high posture variance
KW  - real-time detection rates
KW  - 3D object detection domain
KW  - mobile application
KW  - 3D point clouds
KW  - robust 3D person detector
KW  - posture estimator
KW  - mobile robotic applications
KW  - computer vision domain
KW  - mobile robotics
KW  - standing postures
KW  - socially aware navigation
KW  - deep learning techniques
KW  - Kinect2 depth sensor
KW  - Three-dimensional displays
KW  - Detectors
KW  - Feature extraction
KW  - Robots
KW  - Histograms
KW  - Deep learning
KW  - Task analysis
DO  - 10.1109/ICRA.2019.8793712
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Due to recent deep learning techniques, person detection seems to be solved in the computer vision domain, however, it is still an issue in mobile robotics. On a robot only limited computing capacities are available. The challenge gets even more difficult when operating in an environment, with people in poses different from the standard upright ones. In this work the environment of a supermarket is considered. Unlike most scenarios targeted by the community, persons not only occur in standing postures, but also grasping into the shelves or squatting in front of them. Furthermore, people are heavily occluded, e.g. by shopping carts. In such a challenging environment, it is important to perceive people early enough and in real-time in order to enable a socially aware navigation. Classical person detectors often suffer from a high posture variance or do not achieve acceptable real-time detection rates. For this reason, different components from the 3D object detection domain have been used to create a new robust person detector for mobile application. Operating on 3D point clouds allows fast detections in real-time up to our goal distance of ten meters and above using the Kinect2 depth sensor. The detector can even differentiate between typical postures of customers who stand or squat in front of shelves.
ER  - 

TY  - CONF
TI  - Spatiotemporal and Kinetic Gait Analysis System Based on Multisensor Fusion of Laser Range Sensor and Instrumented Insoles
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4876
EP  - 4881
AU  - R. Eguchi
AU  - A. Yorozu
AU  - M. Takahashi
PY  - 2019
KW  - biomedical measurement
KW  - force sensors
KW  - gait analysis
KW  - Kalman filters
KW  - laser applications in medicine
KW  - optical sensors
KW  - sensor fusion
KW  - data association
KW  - Kalman filter
KW  - fusion algorithm
KW  - in-shoe devices
KW  - spatiotemporal gait analysis system
KW  - data association methods
KW  - tracked leg motions
KW  - motion capture cameras
KW  - gait disorders
KW  - elderly patients
KW  - movement function
KW  - human legs
KW  - laser range sensor
KW  - walking
KW  - motion models
KW  - gait phases
KW  - gait events
KW  - force sensors
KW  - multisensor fusion algorithm
KW  - instrumented insoles
KW  - kinetic gait analysis system
KW  - Legged locomotion
KW  - Tracking
KW  - Acceleration
KW  - Kalman filters
KW  - Instruments
KW  - Force
KW  - Robot sensing systems
DO  - 10.1109/ICRA.2019.8794271
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Tracking of human legs during walking are key technologies for gait analysis evaluating the movement function of the elderly and patients with gait disorders. Although the motion capture cameras are the gold standard method for gait analysis because of their high accuracy, they are not always accessible in clinical sites because of their cost, scale, and usability. In response, a laser range sensor (LRS), which is used for obstacle avoidance and human detection of mobile robots, has recently been employed for tracking of leg motions. Some previous studies set LRS at shin height and tracked leg motions during walking using three or five observation patterns and the Kalman filtering and data association methods. However, these systems had difficulty in tracking during walking along a circular trajectory including frequent overlaps and occlusions of legs. Therefore, this paper presents a spatiotemporal and kinetic gait analysis system using a single LRS and instrumented insoles and proposes a multisensor fusion algorithm for tracking leg motions. The instrumented insoles are in-shoe devices embedded force sensors and can detect accurate timings of gait events via force sensing. The system identifies gait phases by the fusion algorithm and switches acceleration input added to motion models of tracked legs for the Kalman filter and data association. The tracking performance of the proposed system was evaluated by measuring walking on a circular trajectory in experiments.
ER  - 

TY  - CONF
TI  - Part Segmentation for Highly Accurate Deformable Tracking in Occlusions via Fully Convolutional Neural Networks
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4882
EP  - 4888
AU  - W. Wan
AU  - A. Walsman
AU  - D. Fox
PY  - 2019
KW  - convolutional neural nets
KW  - image filtering
KW  - image segmentation
KW  - learning (artificial intelligence)
KW  - object tracking
KW  - pose estimation
KW  - robot vision
KW  - stereo image processing
KW  - visual perception
KW  - direct pose estimation
KW  - machine learning
KW  - direct estimation techniques
KW  - geometric tracking methods
KW  - robotic applications
KW  - observed point clouds
KW  - segmentation maps
KW  - Fast-FCN network architecture
KW  - convolutional neural networks
KW  - Three-dimensional displays
KW  - Semantics
KW  - Computational modeling
KW  - Robots
KW  - Image segmentation
KW  - Computer architecture
KW  - Pose estimation
DO  - 10.1109/ICRA.2019.8793656
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - Successfully tracking the human body is an important perceptual challenge for robots that must work around people. Existing methods fall into two broad categories: geometric tracking and direct pose estimation using machine learning. While recent work has shown direct estimation techniques can be quite powerful, geometric tracking methods using point clouds can provide a very high level of 3D accuracy which is necessary for many robotic applications. However these approaches can have difficulty in clutter when large portions of the subject are occluded. To overcome this limitation, we propose a solution based on fully convolutional neural networks (FCN). We develop an optimized Fast-FCN network architecture for our application which allows us to filter observed point clouds and improve tracking accuracy while maintaining interactive frame rates. We also show that this model can be trained with a limited number of examples and almost no manual labelling by using an existing geometric tracker and data augmentation to automatically generate segmentation maps. We demonstrate the accuracy of our full system by comparing it against an existing geometric tracker, and show significant improvement in these challenging scenarios.
ER  - 

TY  - CONF
TI  - Using Variable Natural Environment Brain-Computer Interface Stimuli for Real-time Humanoid Robot Navigation
T2  - 2019 International Conference on Robotics and Automation (ICRA)
SP  - 4889
EP  - 4895
AU  - N. K. N. Aznan
AU  - J. D. Connolly
AU  - N. A. Moubayed
AU  - T. P. Breckon
PY  - 2019
KW  - brain-computer interfaces
KW  - convolutional neural nets
KW  - electroencephalography
KW  - humanoid robots
KW  - medical robotics
KW  - medical signal processing
KW  - mobile robots
KW  - object detection
KW  - robot vision
KW  - telerobotics
KW  - video streaming
KW  - visual evoked potentials
KW  - specialised secondary CNN
KW  - teleoperation robot commands
KW  - SSVEP decoding model
KW  - real-time humanoid robot navigation
KW  - humanoid robot teleoperation
KW  - natural indoor environment
KW  - dry-EEG technology
KW  - cortical waveforms
KW  - on-board robot camera
KW  - onscreen object selection
KW  - variable steady state visual evoked potential
KW  - real-time video streaming
KW  - variable natural environment
KW  - brain-computer interface stimuli
KW  - deep convolutional neural network
KW  - dry-electroencephalography based human cortical brain bio-signals decoding
KW  - variable BCI stimuli
KW  - natural scene objects detection
KW  - dry-EEG enabled SSVEP methodology
KW  - Navigation
KW  - Electroencephalography
KW  - Real-time systems
KW  - Humanoid robots
KW  - Object detection
KW  - Headphones
DO  - 10.1109/ICRA.2019.8794060
JO  - 2019 International Conference on Robotics and Automation (ICRA)
IS  - 
SN  - 2577-087X
VO  - 
VL  - 
JA  - 2019 International Conference on Robotics and Automation (ICRA)
Y1  - 20-24 May 2019
AB  - This paper addresses the challenge of humanoid robot teleoperation in a natural indoor environment via a Brain-Computer Interface (BCI). We leverage deep Convolutional Neural Network (CNN) based image and signal understanding to facilitate both real-time object detection and dry-Electroencephalography (EEG) based human cortical brain bio-signals decoding. We employ recent advances in dry-EEG technology to stream and collect the cortical waveforms from subjects while they fixate on variable Steady State Visual Evoked Potential (SSVEP) stimuli generated directly from the environment the robot is navigating. To these ends, we propose the use of novel variable BCI stimuli by utilising the real-time video streamed via the on-board robot camera as visual input for SSVEP, where the CNN detected natural scene objects are altered and flickered with differing frequencies (10Hz, 12Hz and 15Hz). These stimuli are not akin to traditional stimuli - as both the dimensions of the flicker regions and their on-screen position changes depending on the scene objects detected. Onscreen object selection via such a dry-EEG enabled SSVEP methodology, facilitates the on-line decoding of human cortical brain signals, via a specialised secondary CNN, directly into teleoperation robot commands (approach object, move in a specific direction: right, left or back). This SSVEP decoding model is trained via a priori offline experimental data in which very similar visual input is present for all subjects. The resulting classification demonstrates high performance with mean accuracy of 85% for the real-time robot navigation experiment across multiple test subjects.
ER  - 


