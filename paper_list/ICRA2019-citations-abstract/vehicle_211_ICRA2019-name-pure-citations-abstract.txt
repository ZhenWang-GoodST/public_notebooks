total paper: 211
Title: Acting Is Seeing: Navigating Tight Space Using Flapping Wings
Key Words: aerospace robotics  biomimetics  control system synthesis  feedback  mobile robots  navigation  path planning  robust control  torque control  flapping-wing robot  wing loading feedback  instantaneous wing loading  bio-inspired robotic flyers  torque control  tight space navigation  Purdu Hummingbird  flight stability  robust controller design  Robot sensing systems  DC motors  Navigation  Loading  Aerodynamics 
Abstract: Wings of flying animals can not only generate lift and control torques but also can sense their surroundings. Such dual functions of sensing and actuation coupled in one element are particularly useful for small sized bio-inspired robotic flyers, whose weight, size, and power are under stringent constraint. In this work, we present the first flapping-wing robot using its flapping wings for environmental perception and navigation in tight space, without the need for any visual feedback. As the test platform, we introduce the Purdu Hummingbird, a flapping-wing robot with 17cm wingspan and 12 grams weight, with a pair of 30-40Hz flapping wings driven by only two actuators. By interpreting the wing loading feedback and its variations, the vehicle can detect the presence of environmental changes such as grounds, walls, stairs, obstacles and wind gust. The instantaneous wing loading can be obtained through the measurements and interpretation of the current feedback by the motors that actuate the wings. The effectiveness of the proposed approach is experimentally demonstrated on several challenging flight tasks without vision: terrain following, wall following and going through a narrow corridor. To ensure flight stability, a robust controller was designed for handling unforeseen disturbances during the flight. Sensing and navigating one's environment through actuator loading is a promising method for mobile robots, and it can serve as an alternative or complementary method to visual perception.


Title: Learning Extreme Hummingbird Maneuvers on Flapping Wing Robots
Key Words: aerodynamics  aerospace components  aerospace robotics  aircraft control  control engineering computing  learning (artificial intelligence)  mobile robots  nonlinear control systems  position control  robot dynamics  robot kinematics  stability  extreme aerobatic maneuvers  visual stimulus  180-degree yaw turn  wingbeat frequency  flight control strategy  hybrid control policy  model-based nonlinear control  model-free reinforcement learning policy  hummingbird-like fast evasive maneuvers  extreme hummingbird maneuvers  flapping wing robots  backward translation  posture stabilization  hummingbird robot  frequency 40.0 Hz  time 0.2 s  Aerodynamics  Vehicle dynamics  Uncertainty  Robots  Adaptation models  Torque  Actuators 
Abstract: Biological studies show that hummingbirds can perform extreme aerobatic maneuvers during fast escape. Given a sudden looming visual stimulus at hover, a hummingbird initiates a fast backward translation coupled with a 180-degree yaw turn, which is followed by instant posture stabilization in just under 10 wingbeats. Consider the wingbeat frequency of 40Hz, this aggressive maneuver is carried out in just 0.2 seconds. Inspired by the hummingbirds' near-maximal performance during such extreme maneuvers, we developed a flight control strategy and experimentally demonstrated that such maneuverability can be achieved by an at-scale 12-gram hummingbird robot equipped with just two actuators driving a pair of flapping wings up to 40Hz. The proposed hybrid control policy combines model-based nonlinear control with model-free reinforcement learning. We used the model-based nonlinear control for nominal flight conditions where dynamic models are relatively accurate. During extreme maneuvers when the modeling error becomes unmanageable, we use a model-free reinforcement learning policy trained and optimized in simulation to 'destabilize' the system for peak performance during maneuvering. The hybrid policy manifests a maneuver that is close to that observed in hummingbirds. Direct simulation-to-real transfer is achieved, demonstrating the hummingbird-like fast evasive maneuvers on the at-scale hummingbird robot.


Title: On-line 3D active pose-graph SLAM based on key poses using graph topology and sub-maps
Key Words: autonomous aerial vehicles  computational complexity  graph theory  mobile robots  optimisation  path planning  remotely operated vehicles  robot vision  SLAM (robots)  graph topology  pose-graph simultaneous localization  three-dimensional environments  D-optimality metrics  weighted node degree  T-optimality metric  sampling-based path  continuous-time trajectory optimization method  large-scale active SLAM problems  submap joining method  online 3D active pose-graph SLAM  Simultaneous localization and mapping  Measurement  Trajectory  Planning  Three-dimensional displays  Uncertainty 
Abstract: In this paper, we present an on-line active pose-graph simultaneous localization and mapping (SLAM) frame-work for robots in three-dimensional (3D) environments using graph topology and sub-maps. This framework aims to find the best trajectory for loop-closure by re-visiting old poses based on the T-optimality and D-optimality metrics of the Fisher information matrix (FIM) in pose-graph SLAM. In order to reduce computational complexity, graph topologies are introduced, including weighted node degree (T-optimality metric) and weighted tree-connectivity (D-optimality metric), to choose a candidate trajectory and several key poses. With the help of the key poses, a sampling-based path planning method and a continuous-time trajectory optimization method are combined hierarchically and applied in the whole framework. So as to further improve the real-time capability of the method, the sub-map joining method is used in the estimation and planning process for large-scale active SLAM problems. In simulations and experiments, we validate our approach by comparing against existing methods, and we demonstrate the on-line planning part using a quad-rotor unmanned aerial vehicle (UAV).


Title: Four-Wheeled Dead-Reckoning Model Calibration using RTS Smoothing
Key Words: automobiles  calibration  inertial navigation  Kalman filters  mobile robots  navigation  path planning  remotely operated vehicles  sensor fusion  smoothing methods  state estimation  RTS smoothing  autonomous vehicles  accurate dead-reckoning system  car-like vehicles  complementary sensors  redundant sensors  wheel encoders  yaw rate gyro  steering wheel measurements  ground truth  smoothing scheme  smoothed estimates  model parameters  experimental vehicle  public roads  dead-reckoning drift  commonly used calibration method  dead reckoning system  four-wheeled dead-reckoning model calibration  complex maneuvers  public traffic  Wheels  Sensors  Smoothing methods  Global navigation satellite system  Calibration  Dead reckoning  Radio frequency 
Abstract: Localization is one of the main challenges to be addressed to develop autonomous vehicles able to perform complex maneuvers on roads opened to public traffic. Having an accurate dead-reckoning system is an essential step to reach this objective. This paper presents a dead-reckoning model for car-like vehicles that performs the data fusion of complementary and redundant sensors: wheel encoders, yaw rate gyro and steering wheel measurements. In order to get an accurate dead-reckoning system with a drift reduced to the minimum, the parameters have to be well calibrated and the procedure has to be simple and efficient. We present a method able to accurately calibrate the parameters without knowing the ground truth by using a Rauch-Tung-Striebel smoothing scheme which enables to obtain state estimates as close to the ground truth as possible. The smoothed estimates are then used within a optimization process to calibrate the model parameters. The method has been tested using data recorded from an experimental vehicle on public roads. The results show a significant diminution of the dead-reckoning drift compared to a commonly used calibration method. We evaluate finally the average distance a vehicle can navigate without exteroceptive sensors by using the proposed four-wheeled dead reckoning system.


Title: ModQuad-Vi: A Vision-Based Self-Assembling Modular Quadrotor
Key Words: autonomous aerial vehicles  indoor radio  mobile robots  path planning  pose estimation  robot vision  self-assembly  relative pose estimation  local estimation  self-assembly process  external systems  ModQuad-Vi  flying modular robot  robot design  vision-based docking method  docking actions  aerial modular system  vision-based self-assembling modular quadrotor  temporary structures  indoor infrastructures  Robot kinematics  Acceleration  Rotors  Force  Trajectory  Navigation 
Abstract: Flying modular robots have the potential to rapidly form temporary structures. In the literature, docking actions rely on external systems and indoor infrastructures for relative pose estimation. In contrast to related work, we provide local estimation during the self-assembly process to avoid dependency on external systems. In this paper, we introduce ModQuad-Vi, a flying modular robot that is aimed to operate in outdoor environments. We propose a new robot design and vision-based docking method. Our design is based on a quadrotor platform with onboard computation and visual perception. Our control method is able to accurately align modules for docking actions. Additionally, we present the dynamics and a geometric controller for the aerial modular system. Experiments validate the vision-based docking method with successful results.


Title: A new Approach for an Adaptive Linear Quadratic Regulated Motion Cueing Algorithm for an 8 DoF Full Motion Driving Simulator
Key Words: linear quadratic control  minimisation  motion control  road vehicles  vehicle dynamics  8 DoF full motion driving simulator  Stuttgart Driving Simulator  state-flow chart  kinematic vehicle movements  motion driving simulator  adaptive motion cueing algorithm  adaptive linear quadratic regulated motion cueing algorithm  linear quadratic error minimization  Acceleration  Switches  Vehicles  Heuristic algorithms  Vehicle dynamics  Kinematics 
Abstract: In this contribution, a new adaptive motion cueing algorithm for a full motion driving simulator at the University of Stuttgart is presented, which allows kinematic vehicle movements to be taken into account. These are adequately processed via a state-flow chart and transferred to the motion cueing algorithm in such a way that the dynamic of the Stuttgart Driving Simulator can be used much more efficiently. Furthermore, a linear quadratic error minimization of the mentioned algorithm is presented. The primary objective is to provide a more realistic driving experience to the driver.


Title: Detecting Invasive Insects with Unmanned Aerial Vehicles
Key Words: agriculture  autonomous aerial vehicles  cameras  computer vision  mobile robots  pest control  robot vision  mark-release-recapture technique  invasive insect species migration patterns  unmanned aerial vehicles  computer vision algorithms  invasive insects detection  agriculture  Insects  Cameras  Unmanned aerial vehicles  Image color analysis  Data acquisition  Pipelines  Agriculture 
Abstract: A key aspect to controlling and reducing the effects invasive insect species have on agriculture is to obtain knowledge about the migration patterns of these species. Current state-of-the-art methods of studying these migration patterns involve a mark-release-recapture technique, in which insects are released after being marked and researchers attempt to recapture them later. However, this approach involves a human researcher manually searching for these insects in large fields and results in very low recapture rates. In this paper, we propose an automated system for detecting released insects using an unmanned aerial vehicle. This system utilizes ultraviolet lighting technology, digital cameras, and lightweight computer vision algorithms to more quickly and accurately detect insects compared to the current state of the art. The efficiency and accuracy that this system provides will allow for a more comprehensive understanding of invasive insect species migration patterns. Our experimental results demonstrate that our system can detect real target insects in field conditions with high precision and recall rates.


Title: Robust Object-based SLAM for High-speed Autonomous Navigation
Key Words: cameras  helicopters  image sequences  image texture  mobile robots  object detection  path planning  robot vision  SLAM (robots)  ROSHAN  object-level mapping  ellipsoid-based SLAM  object surface  autonomous quadrotor  bounding box detections  median shape error  forward-moving camera sequence  planar constraint  vehicle motions  semantic knowledge  robust object-based SLAM for high-speed autonomous navigation  Ellipsoids  Image edge detection  Semantics  Simultaneous localization and mapping  Cameras  Shape  Shape measurement 
Abstract: We present Robust Object-based SLAM for High-speed Autonomous Navigation (ROSHAN), a novel approach to object-level mapping suitable for autonomous navigation. In ROSHAN, we represent objects as ellipsoids and infer their parameters using three sources of information - bounding box detections, image texture, and semantic knowledge - to overcome the observability problem in ellipsoid-based SLAM under common forward-translating vehicle motions. Each bounding box provides four planar constraints on an object surface and we add a fifth planar constraint using the texture on the objects along with a semantic prior on the shape of ellipsoids. We demonstrate ROSHAN in simulation where we outperform the baseline, reducing the median shape error by 83% and the median position error by 72% in a forward-moving camera sequence. We demonstrate similar qualitative result on data collected on a fast-moving autonomous quadrotor.


Title: A Fault Diagnosis Framework for MAVLink-Enabled UAVs Using Structural Analysis
Key Words: aerospace components  aircraft control  autonomous aerial vehicles  fault diagnosis  telemetry  MAVLink-enabled UAVs  fixed-wing UAVs  MAVLink telemetry streams  residual generators  observable faults  FDI system  isolability analyses  real-life telemetry log  UAV crash  fault diagnosis framework  structural analysis  message protocol  unmanned aerial vehicles  fault detection and isolation framework  Mathematical model  Atmospheric modeling  Generators  Fault diagnosis  Telemetry  Batteries  Unmanned aerial vehicles 
Abstract: MAVLink is a popular message protocol for small Unmanned Aerial Vehicles (UAVs). In this work, we present a Fault Detection and Isolation (FDI) framework for fixed-wing UAVs which takes advantage of the information conveyed in MAVLink telemetry streams and produces a bank of residual generators. Structural Analysis is employed to systematically handle the varying set of available measurements, identify the observable faults and adjust the FDI system accordingly. Structural detectability and isolability analyses are carried out. A case-study on a real-life telemetry log of a UAV crash demonstrates the efficacy of the proposed approach.


Title: Beauty and the Beast: Optimal Methods Meet Learning for Drone Racing
Key Words: autonomous aerial vehicles  collision avoidance  Kalman filters  learning (artificial intelligence)  mobile robots  navigation  optimisation  predictive control  state estimation  robust flight  previously-unseen race tracks  optimal methods  fast maneuvers  agile maneuvers  dynamic environments  imperfect sensing  state estimation drift  human pilots  unseen track  practice runs  state-of-the-art autonomous navigation algorithms  precise metric map  training data  unseen environment  precise map  expensive data collection  global track layout  coarse gate locations  single demonstration flight  convolutional network  closest gates  extended Kalman filter  maximum-a-posteriori estimates  high-variance estimates  poor observability  visible gates  estimated gate poses  model predictive control  agile flight  autonomous microaerial vehicles  autonomous drone racing  IROS 2018 autonomous drone race competition  Logic gates  Drones  Navigation  Training data  Current measurement  Layout  Uncertainty 
Abstract: Autonomous micro aerial vehicles still struggle with fast and agile maneuvers, dynamic environments, imperfect sensing, and state estimation drift. Autonomous drone racing brings these challenges to the fore. Human pilots can fly a previously unseen track after a handful of practice runs. In contrast, state-of-the-art autonomous navigation algorithms require either a precise metric map of the environment or a large amount of training data collected in the track of interest. To bridge this gap, we propose an approach that can fly a new track in a previously unseen environment without a precise map or expensive data collection. Our approach represents the global track layout with coarse gate locations, which can be easily estimated from a single demonstration flight. At test time, a convolutional network predicts the poses of the closest gates along with their uncertainty. These predictions are incorporated by an extended Kalman filter to maintain optimal maximum-a-posteriori estimates of gate locations. This allows the framework to cope with misleading high-variance estimates that could stem from poor observability or lack of visible gates. Given the estimated gate poses, we use model predictive control to quickly and accurately navigate through the track. We conduct extensive experiments in the physical world, demonstrating agile and robust flight through complex and diverse previously-unseen race tracks. The presented approach was used to win the IROS 2018 Autonomous Drone Race Competition, outracing the second-placing team by a factor of two.


Title: Flight Testing Boustrophedon Coverage Path Planning for Fixed Wing UAVs in Wind
Key Words: aerospace components  autonomous aerial vehicles  mobile robots  path planning  remotely operated vehicles  wind  flight test results  model prediction  multirotor UAV  boustrophedon coverage path planning  flight path  aerial surveys  complex concave agricultural fields  flight time  wind prediction model  cost function  wind field measurements  fixed wing UAV  Wind  Aircraft  Robot sensing systems  Mathematical model  Atmospheric modeling  Path planning  Predictive models  Aerial Surveying  Coverage Path Planning  Remote Sensing  Boustrophedon paths  Wind  Trochoids 
Abstract: A method was previously developed by this author to optimise the flight path of a fixed wing UAV performing aerial surveys of complex concave agricultural fields. This relies heavily on a flight time in wind prediction model as its cost function. This paper aims to validate this model by comparing flight test results with the model prediction. There are a number of assumptions that this model relies on. The major assumption is that wind is steady and uniform over the small area and time scales involved in a survey. To show that this is reasonable, wind fields measurements will be taken from a multi rotor UAV with an ultrasonic windspeed sensor.


Title: Obstacle-aware Adaptive Informative Path Planning for UAV-based Target Search
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  Gaussian processes  mobile robots  object detection  robot vision  target occupancy  UAV-based target search  Gaussian process based model  flight time constraints  planning strategy  obstacle-aware adaptive informative path planning algorithm  target detection  unmanned aerial vehicles  collision avoidance  Planning  Search problems  Three-dimensional displays  Optimization  Trajectory  Unmanned aerial vehicles  Robot sensing systems 
Abstract: Target search with unmanned aerial vehicles (UAVs) is relevant problem to many scenarios, e.g., search and rescue (SaR). However, a key challenge is planning paths for maximal search efficiency given flight time constraints. To address this, we propose the Obstacle-aware Adaptive Informative Path Planning (OA-IPP) algorithm for target search in cluttered environments using UAVs. Our approach leverages a layered planning strategy using a Gaussian Process (GP)based model of target occupancy to generate informative paths in continuous 3D space. Within this framework, we introduce an adaptive replanning scheme which allows us to trade off between information gain, field coverage, sensor performance, and collision avoidance for efficient target detection. Extensive simulations show that our OA-IPP method performs better than state-of-the-art planners, and we demonstrate its application in a realistic urban SaR scenario.


Title: Real-Time Planning with Multi-Fidelity Models for Agile Flights in Unknown Environments
Key Words: autonomous aerial vehicles  collision avoidance  mobile robots  sensors  low-fidelity models  fast planner  planning framework  agile flights  replanning times  cluttered environments  multifidelity models  autonomous navigation  real-time localization  lightweight sensing  planning methodologies  hierarchical planning architecture  low-fidelity global planner  high-fidelity local planner  erratic behavior  unstable behavior  global plan  higher-order dynamics  real-time planning  sensor data  collision check  UAV  time 5.0 ms to 40.0 ms  Planning  Trajectory  Computational modeling  Vehicle dynamics  Robot sensing systems  Optimization 
Abstract: Autonomous navigation through unknown environments is a challenging task that entails real-time localization, perception, planning, and control. UAVs with this capability have begun to emerge in the literature with advances in lightweight sensing and computing. Although the planning methodologies vary from platform to platform, many algorithms adopt a hierarchical planning architecture where a slow, low-fidelity global planner guides a fast, high-fidelity local planner. However, in unknown environments, this approach can lead to erratic or unstable behavior due to the interaction between the global planner, whose solution is changing constantly, and the local planner; a consequence of not capturing higher-order dynamics in the global plan. This work proposes a planning framework in which multi-fidelity models are used to reduce the discrepancy between the local and global planner. Our approach uses high-, medium-, and low-fidelity models to compose a path that captures higher-order dynamics while remaining computationally tractable. In addition, we address the interaction between a fast planner and a slower mapper by considering the sensor data not yet fused into the map during the collision check. This novel mapping and planning framework for agile flights is validated in simulation and hardware experiments, showing replanning times of 5-40 ms in cluttered environments.


Title: Efficient Trajectory Planning for High Speed Flight in Unknown Environments
Key Words: aircraft control  autonomous aerial vehicles  closed loop systems  collision avoidance  inertial navigation  mobile robots  motion control  optimal control  predictive control  sampling methods  trajectory control  motion planning  motion capture systems  receding horizon planning architecture  reactive obstacle avoidance  closed-form trajectory generation method  spatial partitioning data structures  obstacle density  sampling-based motion planner  minimum-jerk trajectories  closed-loop tracking  high-speed flight  autonomous quadrotor flights  urban environment  trajectory planning  visual-inertial navigation  distance 22.0 km  Trajectory  Planning  Sensors  Three-dimensional displays  Cameras  Vehicle dynamics  Tracking 
Abstract: There has been considerable recent work in motion planning for UAVs to enable aggressive, highly dynamic flight in known environments with motion capture systems. However, these existing planners have not been shown to enable the same kind of flight in unknown, outdoor environments. In this paper we present a receding horizon planning architecture that enables the fast replanning necessary for reactive obstacle avoidance by combining three techniques. First, we show how previous work in computationally efficient, closed-form trajectory generation method can be coupled with spatial partitioning data structures to reason about the geometry of the environment in real-time. Second, we show how to maintain safety margins during fast flight in unknown environments by planning velocities according to obstacle density. Third, our receding-horizon, sampling-based motion planner uses minimum-jerk trajectories and closed-loop tracking to enable smooth, robust, high-speed flight with the low angular rates necessary for accurate visual-inertial navigation. We compare against two state-of-the-art, reactive motion planners in simulation and benchmark solution quality against an offline global planner. Finally, we demonstrate our planner over 80 flights with a combined distance of 22km of autonomous quadrotor flights in an urban environment at speeds up to 9.4ms $^{-1}$.


Title: Priority Maps for Surveillance and Intervention of Wildfires and other Spreading Processes
Key Words: autonomous aerial vehicles  optimisation  path planning  wildfires  priority maps  wildfires  knowledge reward function  dynamic spreading processes  surveillance  bushfire spreading dynamics  wildfire intervention  unmanned aerial vehicle  optimization framework  UAV path planning  Mathematical model  Surveillance  Stochastic processes  Unmanned aerial vehicles  Path planning  Vehicle dynamics  Computational modeling 
Abstract: Unmanned Aerial Vehicle (UAV) path planning algorithms often assume a knowledge reward function or priority map, indicating the most important areas to visit. In this paper we propose a method to create priority maps for monitoring or intervention of dynamic spreading processes such as wildfires. The presented optimization framework utilizes the properties of positive systems, in particular the separable structure of value (cost-to-go) functions, to provide scalable algorithms for surveillance and intervention. We present results obtained for a 16 and 1000 node example and convey how the priority map responds to changes in the dynamics of the system. The larger example of 1000 nodes, representing a fictional landscape, shows how the method can integrate bushfire spreading dynamics, landscape and wind conditions. Finally, we give an example of combining the proposed method with a travelling salesman problem for UAV path planning for wildfire intervention.


Title: Learning From Demonstration in the Wild
Key Words: cameras  learning (artificial intelligence)  object detection  traffic engineering computing  video signal processing  uncalibrated camera  learning from demonstration  ViBe  traffic intersection  knowledge expert  video to behaviour  natural behaviour  reward function  hand-coding behaviour  wild  raw videos  naturalistic behaviour  LfD  monocular camera  single camera  traffic scene  Cameras  Trajectory  Roads  Three-dimensional displays  Sensors  Training  Tracking 
Abstract: Learning from demonstration (LfD) is useful in settings where hand-coding behaviour or a reward function is impractical. It has succeeded in a wide range of problems but typically relies on manually generated demonstrations or specially deployed sensors and has not generally been able to leverage the copious demonstrations available in the wild: those that capture behaviours that were occurring anyway using sensors that were already deployed for another purpose, e.g., traffic camera footage capturing demonstrations of natural behaviour of vehicles, cyclists, and pedestrians. We propose video to behaviour (ViBe), a new approach to learn models of behaviour from unlabelled raw video data of a traffic scene collected from a single, monocular, initially uncalibrated camera with ordinary resolution. Our approach calibrates the camera, detects relevant objects, tracks them through time, and uses the resulting trajectories to perform LfD, yielding models of naturalistic behaviour. We apply ViBe to raw videos of a traffic intersection and show that it can learn purely from videos, without additional expert knowledge.


Title: Simulating Emergent Properties of Human Driving Behavior Using Multi-Agent Reward Augmented Imitation Learning
Key Words: behavioural sciences computing  convergence  learning (artificial intelligence)  multi-agent systems  traffic engineering computing  multiagent settings  multiagent imitation learning  human drivers  reward augmentation  imitation learning process  multiagent reward augmented imitation learning  traffic behaviors  imitation learning algorithms  human driving behavior modeling  prior knowledge specification  convergence guarantees  driving policies  Rails  Convergence  Biological system modeling  Trajectory  Computational modeling  Autonomous vehicles 
Abstract: Recent developments in multi-agent imitation learning have shown promising results for modeling the behavior of human drivers. However, it is challenging to capture emergent traffic behaviors that are observed in real-world datasets. Such behaviors arise due to the many local interactions between agents that are not commonly accounted for in imitation learning. This paper proposes Reward Augmented Imitation Learning (RAIL), which integrates reward augmentation into the multi-agent imitation learning framework and allows the designer to specify prior knowledge in a principled fashion. We prove that convergence guarantees for the imitation learning process are preserved under the application of reward augmentation. This method is validated in a driving scenario, where an entire traffic scene is controlled by driving policies learned using our proposed algorithm. Further, we demonstrate improved performance in comparison to traditional imitation learning algorithms both in terms of the local actions of a single agent and the behavior of emergent properties in complex, multi-agent settings.


Title: Dynamic Manipulation of Gear Ratio and Ride Height for a Novel Compliant Wheel using Pneumatic Actuators
Key Words: gears  mobile robots  pneumatic actuators  road vehicles  vehicle dynamics  wheels  dynamic manipulation  gear ratio  pneumatic actuators  configurable wheel  varied radius wheels  positional manipulation  centre hub  virtual wheels  physical system  outer rim  fast control  vehicle ride height  compliant wheel  off-road robotics  space exploration  Wheels  Mathematical model  Mobile robots  Two dimensional displays  Gears  Acceleration 
Abstract: This paper proposes a novel configurable wheel that exhibits desired properties of varied radius wheels. Positional manipulation of the centre hub is proposed and tested to achieve these desired characteristics of `virtual' wheels in a physical system. The centre hub is manipulated via the use of pneumatic actuators mounted to and constricted by the outer rim of the wheel, which allows for fast and accurate control to enable the vehicle ride height and gear ratio to be adjusted continuously and be maintained during the wheels' full rotation. Experiments are presented, validating this ability of the system. We envision uses for this system to extend from off-road robotics to space exploration as these wheels exhibit novel characteristics not demonstrated by other platforms.


Title: Feasible coordination of multiple homogeneous or heterogeneous mobile vehicles with various constraints
Key Words: algebra  mobile robots  motion control  multi-robot systems  path planning  nonholonomic motion constraints  holonomic coordination constraints  differential-algebraic equations  viability theory  coordinated motion control  heterogeneous vehicle dynamics  multivehicle coordination  control schemes  coordination control  heterogeneous mobile vehicles  Task analysis  Kinematics  Mathematical model  Vehicle dynamics  Trajectory  Tools 
Abstract: We consider the problem of feasible coordination control for multiple homogeneous or heterogeneous mobile vehicles subject to various constraints (nonholonomic motion constraints, holonomic coordination constraints, equality/inequality constraints etc). We develop a general framework involving differential-algebraic equations and viability theory to describe and determine coordination feasibility for a coordinated motion control under heterogeneous vehicle dynamics and various constraints. A heuristic algorithm is proposed for generating feasible trajectories for each individual vehicle. We show several application examples and simulation experiments on multi-vehicle coordination under various constraints to validate the theory and the effectiveness of the proposed algorithm and control schemes.


Title: Flexible collaborative transportation by a team of rotorcraft
Key Words: aerospace control  control system synthesis  helicopters  mobile robots  motion control  multi-robot systems  nonlinear control systems  position control  robot dynamics  suspensions (mechanical components)  flexible collaborative transportation  suspended payload  acceleration signals  maximum payload  incremental nonlinear dynamic inversion controller  distance-based formation-motion control algorithm  worst case conditions  open-source autopilot  rotorcraft team  Acceleration  Shape  Robot kinematics  Tracking  Payloads  Transportation 
Abstract: We propose a combined method for the collaborative transportation of a suspended payload by a team of rotorcraft. A recent distance-based formation-motion control algorithm based on assigning distance disagreements among robots generates the acceleration signals to be tracked by the vehicles. In particular, the proposed method does not need global positions nor tracking prescribed trajectories for the motion of the members of the team. The acceleration signals are followed accurately by an Incremental Nonlinear Dynamic Inversion controller designed for rotorcraft that measures and resists the tensions from the payload. Our approach allows us to analyze the involved accelerations and forces in the system so that we can calculate the worst case conditions explicitly to guarantee a nominal performance, provided that the payload starts at rest in the 2D centroid of the formation, and it is not under significant disturbances. For example, we can calculate the maximum safe deformation of the team with respect to its desired shape. We demonstrate our method with a team of four rotorcraft carrying a suspended object two times heavier than the maximum payload for an individual. Last but not least, our proposed algorithm is available for the community in the open-source autopilot Paparazzi.


Title: Model Reference Adaptive Control of a Two-Wheeled Mobile Robot
Key Words: adaptive control  control system synthesis  mobile robots  model reference adaptive control systems  nonlinear control systems  pendulums  two-wheeled mobile robot  dynamically unstable system  environmental conditions  loading conditions  nonlinear controller  control systems  fixed parameter controllers  single-input multioutput nature  adaptive controller  SIMO systems  hidden dynamic effects  model reference adaptive control  Vehicle dynamics  Adaptation models  Mathematical model  Control systems  Adaptive control  Mobile robots 
Abstract: The inverted pendulum is by nature a dynamically unstable system and may be subjected to severe disturbances due to its environmental or loading conditions. This paper formulates a design for a nonlinear controller to balance a two-wheeled mobile robot (TWMR) based on Model Reference Adaptive Control. The proposed solution overcomes the limitations of control systems that rely on fixed parameter controllers. Given the nonlinear single-input multi-output (SIMO) nature of the TWMR platform, the proposed adaptive controller can handle non-linearities without the need for linearization, and inherently dealing with SIMO systems. By studying the influence that hidden dynamic effects can cause, we show the preference of the proposed controller over other designs. Simulation results demonstrate the applicability and efficiency of our proposed design, and experimental results validate the effectiveness of the proposed scheme in guaranteeing asymptotic output tracking, even in the presence of unknown disturbances.


Title: Reconfigurable Network for Efficient Inferencing in Autonomous Vehicles
Key Words: feature extraction  mobile robots  remotely operated vehicles  road vehicles  robot vision  sensors  reconfigurable network  autonomous vehicles  multiple perception sensors  steering autonomous platforms  gating network  unmanned ground vehicle  UGV  feature extractors  experts  Feature extraction  Sensors  Training  Autonomous vehicles  Task analysis  Computational modeling  Cameras 
Abstract: We propose a reconfigurable network for efficient inference dedicated to autonomous platforms equipped with multiple perception sensors. The size of the network for steering autonomous platforms grows proportionally to the number of installed sensors eventually preventing the usage of multiple sensors in real-time applications due to an inefficient inference. Our approach hinges on the observation that multiple sensors provide a large stream of data, where only a fraction of the data is relevant for the performed task at any given moment in time. The architecture of the reconfigurable network that we propose contains separate feature extractors, called experts, for each sensor. The decisive block of our model is the gating network, which online decides which sensor provides the data that is most relevant for driving. It then reconfigures the network by activating only the relevant expert corresponding to that sensor and deactivating the remaining ones. As a consequence, the model never extracts features from data that are irrelevant for driving. The gating network takes the data from all inputs and thus to avoid explosion of computation time and memory space it has to be realized as a small and shallow network. We verify our model on the unmanned ground vehicle (UGV) comprising of the 1/6 scale remote control truck equipped with three cameras. We demonstrate that the reconfigurable network correctly chooses experts in real-time allowing the reduction of computations cost for the whole model without deteriorating its performance.


Title: Interactive Trajectory Prediction for Autonomous Driving via Recurrent Meta Induction Neural Network
Key Words: automobiles  estimation theory  learning (artificial intelligence)  mobile robots  recurrent neural nets  road safety  road traffic control  stochastic processes  traffic engineering computing  lane change trajectory  meta-learning framework  autonomous driving data collection  interactive trajectory prediction  interactive driving  autonomous cars  stochastic processes  driving behavior estimation  recurrent neural cell  recurrent meta induction neural network  human-driven cars behaviors  conditional neural process  Trajectory  Automobiles  Autonomous vehicles  Estimation  Generators  Task analysis  Stochastic processes 
Abstract: Interactive driving is challenging but essential for autonomous cars in dense traffic or urban areas. Proper interaction requires understanding and prediction of future trajectories of all neighboring cars around a target vehicle. Current solutions typically assume a certain distribution or stochastic process to approximate human-driven cars' behaviors. To relax this assumption, a Recurrent Meta Induction Network (RMIN) framework is developed. The original Conditional Neural Process (CNP) on which this is based does not consider the sequence of the conditions, due to the permutation invariance requirements for stochastic processes. However, the sequential information is important for the driving behavior estimation. Therefore, in the proposed method, a recurrent neural cell replaces the original demonstration sub-net. The behavior estimation is conditioned on the historical observations for all related cars, including the target car and its surrounding cars. The method is applied to predict the lane change trajectory of a target car in dense traffic areas. The proposed method achieves better results than previous methods and thanks to the meta-learning framework, it can use a smaller dataset, putting fewer demands on autonomous driving data collection.


Title: Exploiting Bistability for High Force Density Reflexive Gripping
Key Words: control system synthesis  force control  grippers  mobile robots  pneumatic control equipment  vehicles  robotic grasping  mobile vehicles  conventional manipulation  dynamic mobile robots  robotic gripper  mobile platforms  reflexive activation  reflexive gripper  high force density reflexive gripping  pneumatic design  Grippers  Robot sensing systems  Steel  Strain  Grasping 
Abstract: Robotic grasping can enable mobile vehicles to physically interact with the environment for delivery, repositioning, or landing. However, the requirements for grippers on mobile vehicles differ substantially from those used for conventional manipulation. Specifically, grippers for dynamic mobile robots should be capable of rapid activation, high force density, low power consumption, and minimal computation. In this work, we present a biologically-inspired robotic gripper designed specifically for mobile platforms. This design exploits a bistable shell to achieve “reflexive” activation based on contact with the environment. The mechanism can close its grasp within 0. 12s without any sensing or control. Electrical input power is not required for grasping or holding load. The reflexive gripper utilizes a novel pneumatic design to open its grasp with low power, and the gripper can carry slung loads up to 28 times its weight. This new mechanism, including the kinematics, static behavior, control structure, and fabrication, is described in detail. A proof of concept prototype is designed, built, and tested. Experimental results are used to characterize performance and demonstrate the potential of these methods.


Title: Compliant Bistable Gripper for Aerial Perching and Grasping
Key Words: aerospace control  aerospace robotics  autonomous aerial vehicles  grippers  helicopters  mobile robots  motion control  position control  compliant bistable gripper  aerial perching  aerial robots  onboard energy supply  flying robots  perching capability  power lines  monitoring-related tasks  energy-efficient perching mechanism  palm-size quadcopter  aerial grasping  robot weight  quadcopter perch  grasp objects  force  Grippers  Electron tubes  Force  Unmanned aerial vehicles  Springs  Mathematical model  Grasping 
Abstract: Small aerial robots usually face a common challenge: they can only fly for a short time due to their limited onboard energy supply. To tackle this issue, one promising solution is to endow flying robots with perching capability so that they can perch or land on walls, trees, or power lines to rest or recharge. Such perching capability is especially useful for monitoring-related tasks since the robot can maintain a desired height for monitoring without flying. One of the major challenges for perching is to design a light-weight and energy-efficient perching mechanism. In this paper, we present a 3D-printed compliant bistable gripper which is easy to close, stable to hold, and easy to adjust for a palm-size quadcopter to perch on cylindrical objects. If installed on the bottom of aerial robots, it can also be used for aerial grasping. The gripper can be directly activated by the impact force during contact to switch from open state to closed state. It can also hold the quadcopter safely since the required force to open the gripper is larger than the robot weight. We analyze the required forces for closing and opening to provide design guidelines for the mechanism. Experimental results show that the designed gripper can successful make the quadcopter perch on cylinders as well as grasp objects.


Title: LookUP: Vision-Only Real-Time Precise Underground Localisation for Autonomous Mining Vehicles
Key Words: cameras  image sensors  mining  mining industry  mobile robots  neural nets  robot vision  autonomous underground mining vehicles  neural-network-based pixel sampling strategy  visual based technique  real-time accurate localisation system  range sensor-based system  ceiling-facing cameras  Optical imaging  Cameras  Optical sensors  Adaptive optics  Heating systems  Optical network units  Real-time systems 
Abstract: A key capability for autonomous underground mining vehicles is real-time accurate localisation. While significant progress has been made, currently deployed systems have several limitations ranging from dependence on costly additional infrastructure to failure of both visual and range-sensor-based techniques in highly aliased or visually challenging environments. In our previous work, we presented a lightweight coarse vision-based localisation system that could map and then localise to within a few metres in an underground mining environment. However, this level of precision is insufficient for providing a cheaper, more reliable vision-based automation alternative to current range sensor-based systems. Here we present a new precision localisation system dubbed “LookUP”, which learns a neural-network-based pixel sampling strategy for estimating homographies based on ceiling-facing cameras without requiring any manual labelling. This new system runs in real time on limited computation resource and is demonstrated on two different underground mine sites, achieving real time performance at ~5 frames per second and a much improved average localisation error of ~1.2 metre.


Title: Analytic Collision Risk Calculation for Autonomous Vehicle Navigation
Key Words: collision avoidance  mobile robots  Monte Carlo methods  navigation  probability  road traffic control  road vehicles  autonomous vehicle navigation  Monte Carlo simulations  autonomous systems  self-driving car  Freie Universität Berlin  collision octagon  analytic collision risk calculation  trajectory prediction  ground vehicle navigation  autonomous driving  planning system  Trajectory  Integral equations  Autonomous vehicles  Monte Carlo methods  Uncertainty 
Abstract: Collision checking and avoidance is an import part of the perception and planning system for autonomous driving. We present a new analytic approach to calculate the probability of a future collision and extend another already known solution to be suitable for ground vehicle navigation. Our new concept of the collision octagon facilitates in both cases the derivation of an analytic solution. Both approaches are compared to each other using simulated and real world scenarios. By comparing the results of the analytic solutions to the corresponding Monte Carlo simulations, their accuracy and real-time capability is demonstrated. The suitability of the analytic solutions for real world autonomous systems is further proven by integrating them into the trajectory prediction and planning system of the self-driving car of the Freie Universität Berlin.


Title: A new approach to local navigation for autonomous driving vehicles based on the curvature velocity method
Key Words: collision avoidance  mobile robots  motion control  navigation  road traffic  local navigation  autonomous driving vehicles  curvature velocity method  car navigation system  road path  motion control  high-level planning  lower-level reactive control  beam curvature method  pure pursuit method  lane obstacle avoidance  elderly people  Navigation  Planning  Automobiles  Robot sensing systems  Vehicle dynamics  Computer architecture 
Abstract: This paper presents an approach for a car navigation system to follow a road path consisting on a sequence of lanelets. The motion control is divided into high-level planning that produces the road path and lower-level reactive control that safely follows the path. The approach presented here is the lower-level reactive control that combines the simple pure pursuit method to obtain a reference curvature with the beam curvature method (BCM) that keeps the car in the center of the free space in the lane avoiding obstacles that can partially block the lane. The whole system has been applied to an autonomous vehicle aimed for elderly or disable people.


Title: Robot Localization Based on Aerial Images for Precision Agriculture Tasks in Crop Fields
Key Words: autonomous aerial vehicles  crops  data visualisation  feature extraction  mobile robots  path planning  robot vision  SLAM (robots)  robot localization  aerial images  precision agriculture tasks  crop field environment  visual aliasing  localization system  aerial map  visual ambiguity problem  autonomous robots  Agriculture  Feature extraction  Cameras  Semantics  Visualization  Robot vision systems 
Abstract: Localization is a pre-requisite for most autonomous robots. For example, to carry out precision agriculture tasks effectively, a robot must be able to localize itself accurately in crop fields. The crop field environment presents unique challenges such as the highly repetitive structure of the crops leading to visual aliasing as well as the continuously changing appearance of the field, which makes it difficult to localize over time. In this paper, we present a localization system, which uses an aerial map of the field and exploits the semantic information of the crops, weeds, and their stem positions to resolve the visual ambiguity problem and to enable robot localization over extended periods of time. We evaluate our approach on a real field over multiple sessions spanning several weeks. Experiments suggest that our approach provides the necessary accuracy required by precision agriculture applications and works in cases where current techniques using typical visual features tend to fail.


Title: Visual Appearance Analysis of Forest Scenes for Monocular SLAM
Key Words: autonomous aerial vehicles  mobile robots  path planning  remotely operated vehicles  robot vision  SLAM (robots)  managed forests  tree health  SLAM research  structured human environments  unstructured forests  forest data  photorealistic simulated forest  straightforward forest terrain  forest scenes  natural scenes  visual appearance analysis  cheap energy efficient way  unmanned aerial vehicles  monocular SLAM systems  SLAM systems  visual appearance statistics  Forestry  Simultaneous localization and mapping  Cameras  Visualization  Vegetation  Feature extraction  Lighting 
Abstract: Monocular simultaneous localisation and mapping (SLAM) is a cheap and energy efficient way to enable Unmanned Aerial Vehicles (UAVs) to safely navigate managed forests and gather data crucial for monitoring tree health. SLAM research, however, has mostly been conducted in structured human environments, and as such is poorly adapted to unstructured forests. In this paper, we compare the performance of state of the art monocular SLAM systems on forest data and use visual appearance statistics to characterise the differences between forests and other environments, including a photorealistic simulated forest. We find that SLAM systems struggle with all but the most straightforward forest terrain and identify key attributes (lighting changes and in-scene motion) which distinguish forest scenes from “classic” urban datasets. These differences offer an insight into what makes forests harder to map and open the way for targeted improvements. We also demonstrate that even simulations that look impressive to the human eye can fail to properly reflect the difficult attributes of the environment they simulate, and provide suggestions for more closely mimicking natural scenes.


Title: UAV Pose Estimation using Cross-view Geolocalization with Satellite Imagery
Key Words: autonomous aerial vehicles  cameras  distance measurement  feature extraction  Kalman filters  neural nets  pose estimation  unseen images  visual odometry  trajectory estimation errors  UAV pose estimation  image-based cross-view geolocalization method  georeferenced satellite imagery  Siamese neural networks  UAV camera  satellite images  crossview geolocalization  Satellites  Geology  Cameras  Feature extraction  Training  Visual odometry  Google 
Abstract: We propose an image-based cross-view geolocalization method that estimates the global pose of a UAV with the aid of georeferenced satellite imagery. Our method consists of two Siamese neural networks that extract relevant features despite large differences in viewpoints. The input to our method is an aerial UAV image and nearby satellite images, and the output is the weighted global pose estimate of the UAV camera. We also present a framework to integrate our crossview geolocalization output with visual odometry through a Kalman filter. We build a dataset of simulated UAV images and satellite imagery to train and test our networks. We show that our method performs better than previous camera pose estimation methods, and we demonstrate our networks ability to generalize well to test datasets with unseen images. Finally, we show that integrating our method with visual odometry significantly reduces trajectory estimation errors.


Title: The Open Vision Computer: An Integrated Sensing and Compute System for Mobile Robots
Key Words: autonomous aerial vehicles  helicopters  microrobots  mobile robots  path planning  robot vision  Falcon 250 quadrotor platform  vision guided autonomous drone flight  mobile robots  integrated sensing  open vision computer  navigation operations  outdoor exploration  OVC system  computational performance  power consumption  relatively small-scale flying platforms  Field programmable gate arrays  Image sensors  Streaming media  Robot sensing systems  Aircraft navigation  Sensor arrays 
Abstract: In this paper we describe the Open Vision Computer (OVC) which was designed to support high speed, vision guided autonomous drone flight. In particular our aim was to develop a system that would be suitable for relatively small-scale flying platforms where size, weight, power consumption and computational performance were all important considerations. This manuscript describes the primary features of our OVC system and explains how they are used to support fully autonomous indoor and outdoor exploration and navigation operations on our Falcon 250 quadrotor platform.


Title: RaD-VIO: Rangefinder-aided Downward Visual-Inertial Odometry
Key Words: autonomous aerial vehicles  cameras  mobile robots  robot vision  common local planarity assumption  frame-to-frame visual-inertial odometry algorithm  downward facing cameras  RaD-VIO  cost function  rangefinder-aided downward visual-inertial odometry  complementary odometry algorithm  IMU regularisation term  homography based photometric cost  microaerial vehicles  Cameras  Optimization  Visualization  Laser beams  Reliability  Angular velocity 
Abstract: State-of-the-art forward facing monocular visual-inertial odometry algorithms are often brittle in practice, especially whilst dealing with initialisation and motion in directions that render the state unobservable. In such cases having a reliable complementary odometry algorithm enables robust and resilient flight. Using the common local planarity assumption, we present a fast, dense, and direct frame-to-frame visual-inertial odometry algorithm for downward facing cameras that minimises a joint cost function involving a homography based photometric cost and an IMU regularisation term. Via extensive evaluation in a variety of scenarios we demonstrate superior performance than existing state-of-the-art downward facing odometry algorithms for Micro Aerial Vehicles (MAVs).


Title: Learning to Capture a Film-Look Video with a Camera Drone
Key Words: autonomous aerial vehicles  collision avoidance  decision making  image capture  image sensors  image sequences  learning (artificial intelligence)  mobile robots  motion control  object tracking  robot vision  video cameras  video signal processing  film-look video  camera drone  intelligent drones  smarter assistant tools  autonomous aerial filming  camera motion planning  cinematic footages  film-look aerial footage  camera position  automatic filming onboard  data-driven planning approach  image composition  data-driven learning-based approach  professional cameramans intention  decision-making process  Cameras  Drones  Training  Skeleton  Streaming media  Two dimensional displays  Feature extraction 
Abstract: The development of intelligent drones has simplified aerial filming and provided smarter assistant tools for users to capture a film-look footage. Existing methods of autonomous aerial filming either specify predefined camera movements for a drone to capture a footage, or employ heuristic approaches for camera motion planning. However, both predefined movements and heuristically planned motions are hardly able to provide cinematic footages for various dynamic scenarios. In this paper, we propose a data-driven learning-based approach, which can imitate a professional cameraman's intention for capturing a film-look aerial footage of a single subject in real-time. We model the decision-making process of the cameraman with two steps: 1) we train a network to predict the future image composition and camera position, and 2) our system then generates control commands to achieve the desired shot framing. At the system level, we deploy our algorithm on the limited resources of a drone and demonstrate the feasibility of running automatic filming onboard in real-time. Our experiments show how our data-driven planning approach achieves film-look footages and successfully mimics the work of a professional cameraman.


Title: Design and Experiments for MultI-Section-Transformable (MIST)-UAV
Key Words: autonomous aerial vehicles  mobile robots  multiple sequential transformations  shape-shifting transformation  MIST-UAV  in-air transformation  multirotor  multisection-transformable-UAV  transformable vertical take off and landing UAV  transformable VTOL UAV  tail-sitter  fixed-wing operation  Fasteners  Propulsion  Mathematical model  Attitude control  Batteries  Actuators  Servomotors 
Abstract: Presented in this paper are the design and experiments for a transformable Vertical Take Off and Landing (VTOL) UAV. This work demonstrates shape-shifting transformation, building upon the conceptual designs put forth in [1] and [2], along with hardware prototyping and component testing from [3]. A deterministic model is presented to characterize the flight of the MIST-UAV in simulation. Experimental results from the platform demonstrate for the first time successful in-air transformation from multi-rotor, tail-sitter, and fixed-wing operation. Experiments also validated transformation repeatability, successfully testing multiple sequential transformations.


Title: Online Estimation of Geometric and Inertia Parameters for Multirotor Aerial Vehicles
Key Words: autonomous aerial vehicles  mobile robots  multi-robot systems  nonlinear control systems  observers  robust control  multirotor aerial vehicles  moment of inertia  center of mass  nonlinear observability analysis  load transportation  motor speed  aerial vehicles  robust control  precise control  inertia parameters  Rotors  Vehicle dynamics  Estimation  Quaternions  Real-time systems  Task analysis  Transportation 
Abstract: Accurate knowledge of geometric and inertia parameters are a necessity for precise and robust control of aerial vehicles. We propose a novel filter that is able to fuse motor speed, inertia, and pose measurements to estimate the vehicle's key dynamic properties online. The presented framework is able to estimate the multirotor's moment of inertia, mass, center of mass and each sensor module's relative position. Obtaining these estimates in-flight allow the multirotor to be precisely controlled even during tasks such as load transportation or after configuration changes on scene. We provide a nonlinear observability analysis, proving that the presented model is locally weakly observable. Experimental results validate the proposed approach, showing the ability to estimate the dynamic properties accurately and demonstrate its capability to do so even while additional loads are added. The framework is flexible and can easily be adapted to a wide range of applications, including self-calibration, object grasping, and single robot or multi-robot payload transportation.


Title: A Novel Development of Robots with Cooperative Strategy for Long-term and Close-proximity Autonomous Transmission-line Inspection
Key Words: automatic optical inspection  autonomous aerial vehicles  collision avoidance  inspection  laser ranging  mobile robots  power overhead lines  robot vision  sensors  service robots  close-proximity autonomous transmission-line inspection  power transmission lines inspection  overhead ground wire  OGW  sensor data collection  unmanned aerial vehicle  grabbing mechanism  mechanical structures  autonomous navigation  2D Laser Range Finder  LRF  CBR platforms  artificially constructed PTLs environment outdoors  high inspection accuracy  close-proximity inspection  long-term inspection  Inspection  Three-dimensional displays  Unmanned aerial vehicles  Microswitches  Delay effects  Robot sensing systems 
Abstract: We develop two cooperative robots for power transmission lines (PTLs) inspection - a light climbing robot (CBR) which can stably move on the overhead ground wire (OGW) for sensor data collection and an unmanned aerial vehicle (UAV) with a grabbing mechanism, which can automatically put the CBR on the OGW and take it off. In order to guarantee the safety, the mechanical structures of the connectors are designed in the shape of a trumpet. Further, a self-locked structure of the CBR is developed to automatically seize and release the OGW. For autonomous navigation, the UAV is equipped with a movable sliding rail and a 2D Laser Range Finder (LRF). The LRF can not only detect the position and orientation of the OGW but also detect the top beam of the CBR and the grabbing position in it. Furthermore, the action of the grabbing mechanism is automatically triggered by a microswitch. Finally, by the developed UAV and CBR platforms, we test the whole loading and unloading strategy in an artificially constructed PTLs environment outdoors and achieve an encouraging result1. Combining the flexible motion of the UAV and the high inspection accuracy of the CBR, the CBR can negotiate any obstacle by flying and abandon the traditional heavy obstacle crossing mechanism to effectively realize close-proximity inspection. Due to the light weight and low power consumption, the CBRs can be deployed once in many power corridors to conduct a long-term inspection.


Title: Hunting Drones with Other Drones: Tracking a Moving Radio Target
Key Words: aerospace communication  aerospace robotics  mobile radio  mobile robots  path planning  remotely operated vehicles  target tracking  telemetry  moving radio target  unauthorized drone flights  antennas  commodity radios  telemetry radio emissions  passenger safety  bystander safety  Drones  Antenna measurements  Telemetry  Target tracking  Antennas  Aircraft  Radio frequency 
Abstract: Unauthorized drone flights near aircraft, airports, and emergency operations compromise the safety of passengers and bystanders. A detection system that can quickly find and track drones could help mitigate the risk of unauthorized drone flights. In this work, we show how a consumer drone outfitted with antennas and commodity radios can autonomously localize another drone by its telemetry radio emissions. We show how a non-myopic planner improves tracking performance over traditionally used greedy, one-step planners. Improved tracking is validated with simulations and the system is demonstrated with real drones in flight tests.


Title: Multi-Vehicle Trajectory optimisation On Road Networks
Key Words: integer programming  linear programming  path planning  multivehicle trajectory optimisation  road networks  planning time-optimal trajectories  multiple cooperative agents  static road network  vehicle interactions  nontrivial decisions  complex flow-on effects  globally optimal time trajectory  minimum time trajectory  MILP  computational performance  binary variables  collision constraints  open-pit mining scenario  mixed integer linear programming  goal constraints  heuristic method  Roads  Trajectory  Planning  Automation  Optimization  Iterative methods  Mixed integer linear programming 
Abstract: This paper addresses the problem of planning time-optimal trajectories for multiple cooperative agents along specified paths through a static road network. Vehicle interactions at intersections create non-trivial decisions, with complex flow-on effects for subsequent interactions. A globally optimal, minimum time trajectory is found for all vehicles using Mixed Integer Linear Programming (MILP). Computational performance is improved by minimising binary variables using iteratively applied targeted collision constraints, and efficient goal constraints. Simulation results in an open-pit mining scenario compare the proposed method against a fast heuristic method and a reactive approach based on site practices. The heuristic is found to scale better with problem size while the MILP is able to avoid local minima.


Title: Disturbance Compensation Based Control for an Indoor Blimp Robot
Key Words: autonomous aerial vehicles  compensation  control system synthesis  feedback  mobile robots  nonlinear control systems  observers  robust control  uncertain systems  blimp disturbance compensation based controller  indoor blimp robot  robust controller  horizontal plane  slider-like nonlinear system  uncertain bounded disturbances  output feedback controller  disturbance evaluation  exogenous disturbances  control scheme  concrete blimp  homogeneous differentiator  observer  Mathematical model  Atmospheric modeling  Biological system modeling  Output feedback  Robot sensing systems  Robot kinematics 
Abstract: This paper presents design of a robust controller with disturbance compensation for an indoor blimp robot and its realization. The movement of blimp in horizontal plane is modeled as a slider-like nonlinear system complemented with uncertain bounded disturbances. To design the output feedback controller, a homogeneous differentiator is used as an observer. Then the method for disturbance evaluation is designed, the perturbation estimate is next used in the controller for cancellation of the influence of exogenous disturbances. Control scheme is implemented on a concrete blimp, finally, the performance of blimp disturbance compensation based controller is verified in experiments.


Title: Multimodal Trajectory Predictions for Autonomous Driving using Deep Convolutional Networks
Key Words: convolutional neural nets  driver information systems  feature extraction  image processing  mobile robots  probability  road accidents  road safety  road traffic  road vehicles  multimodal trajectory predictions  autonomous driving  deep convolutional networks  robotics  artificial intelligence communities  self-driving vehicles  SDVs  road accidents  human drivers  traffic behavior  safe operations  autonomous vehicle  raster image  probabilities  Trajectory  Predictive models  Roads  Hidden Markov models  Task analysis  Radar tracking 
Abstract: Autonomous driving presents one of the largest problems that the robotics and artificial intelligence communities are facing at the moment, both in terms of difficulty and potential societal impact. Self-driving vehicles (SDVs) are expected to prevent road accidents and save millions of lives while improving the livelihood and life quality of many more. However, despite large interest and a number of industry players working in the autonomous domain, there still remains more to be done in order to develop a system capable of operating at a level comparable to best human drivers. One reason for this is high uncertainty of traffic behavior and large number of situations that an SDV may encounter on the roads, making it very difficult to create a fully generalizable system. To ensure safe and efficient operations, an autonomous vehicle is required to account for this uncertainty and to anticipate a multitude of possible behaviors of traffic actors in its surrounding. We address this critical problem and present a method to predict multiple possible trajectories of actors while also estimating their probabilities. The method encodes each actor's surrounding context into a raster image, used as input by deep convolutional networks to automatically derive relevant features for the task. Following extensive offline evaluation and comparison to state-of-the-art baselines, the method was successfully tested on SDVs in closed-course tests.


Title: Learning to Predict the Wind for Safe Aerial Vehicle Planning
Key Words: autonomous aerial vehicles  convolutional neural nets  mobile robots  path planning  sampling methods  wind  safe aerial vehicle planning  local wind  unmanned aerial vehicles  wind environment  relatively low mass  high-resolution wind fields  terrain elevation model  deep convolutional neural network  sampling-based planner  strong wind scenarios  UAV  inflow conditions  prediction error  wind estimation techniques  Wind forecasting  Planning  Computational modeling  Wind speed  Predictive models  Data models 
Abstract: Obtaining an accurate estimate of the local wind remains a significant challenge for small unmanned aerial vehicles (UAVs). Small UAVs often operate at low altitudes near terrain, where the wind environment can be more complex than at higher altitudes. Combined with their relatively low mass, this makes small UAVs particularly susceptible to wind. In this paper we present an approach for predicting high-resolution wind fields based on a terrain elevation model and known inflow conditions. Our approach uses a deep convolutional neural network (CNN) to generate 3D wind estimates. We show that our approach produces wind estimates with lower prediction error than existing methods, and that inference can be performed on an on-board computer in less than two seconds. By providing the wind estimate to a sampling-based planner we show that the improved estimates allow the planner to generate safer paths in strong wind scenarios than with alternative wind estimation techniques.


Title: Training a Binary Weight Object Detector by Knowledge Transfer for Autonomous Driving
Key Words: computer vision  convolutional neural nets  learning (artificial intelligence)  object detection  road traffic  traffic engineering computing  binary weight object detector  autonomous driving  energy efficiency  on-board object detection  object detectors  low-precision neural networks  computation requirements  memory footprint  binary weight neural networks  BWNs  knowledge transfer method  full-precision teacher network  MobileNet-based binary weight YOLOv2 detectors  pedestrian  cyclist detection  KITTI benchmark  MobileNet-YOLO  DarkNet-YOLO  deep convolutional neural network  word length 1.0 bit  memory size 8.8 MByte to 257.0 MByte  memory size 7.9 MByte to 193.0 MByte  Training  Detectors  Neural networks  Quantization (signal)  Knowledge transfer  Task analysis  Autonomous vehicles 
Abstract: Autonomous driving has harsh requirements of small model size and energy efficiency, in order to enable the embedded system to achieve real-time on-board object detection. Recent deep convolutional neural network based object detectors have achieved state-of-the-art accuracy. However, such models are trained with numerous parameters and their high computational costs and large storage prohibit the deployment to memory and computation resource limited systems. Low-precision neural networks are popular techniques for reducing the computation requirements and memory footprint. Among them, binary weight neural networks (BWNs) are the extreme case which quantizes the float-point into just 1 bit. BWNs are difficult to train and suffer from accuracy deprecation due to the extreme low-bit representation. To address this problem, we propose a knowledge transfer (KT) method to aid the training of BWN using a full-precision teacher network. We built DarkNet- and MobileNet-based binary weight YOLOv2 detectors and conduct experiments on KITTI benchmark for car, pedestrian and cyclist detection. The experimental results show that the proposed method maintains high detection accuracy while reducing the model size of DarkNet-YOLO from 257 MB to 8.8 MB and MobileNet-YOLO from 193 MB to 7.9 MB.


Title: Environment Driven Underwater Camera-IMU Calibration for Monocular Visual-Inertial SLAM
Key Words: autonomous underwater vehicles  calibration  cameras  inertial navigation  mobile robots  SLAM (robots)  visual-inertial SLAM  shallow water  calibration errors  environmental indexes  underwater camera-inertial measurement unit  simultaneous localization and mapping  intrinsic parameters  extrinsic parameters  underwater monocular vision systems  environment driven underwater camera-IMU calibration  Cameras  Calibration  Atmospheric modeling  Simultaneous localization and mapping  Geometry  Mathematical model 
Abstract: Most state-of-the-art underwater vision systems are calibrated manually in shallow water and used in open seas without changing. However, the refractivity of the water is adaptively changed depending on the salinity, temperature, depth or other underwater environmental indexes, which inevitably generate the calibration errors and induces incorrectness e.g., for underwater Simultaneously Localization and Mapping (SLAM). To address this issue, in this paper, we propose a new underwater Camera-Inertial Measurement Unit (IMU) calibration model, which just needs to be calibrated once in the air, and then both the intrinsic parameters and extrinsic parameters between the camera and IMU could be automatically calculated depending on the environment indexes. To our best knowledge, this is the first work to consider the underwater Camera-IMU calibration via environmental indexes. We also build a verification platform to validate the effectiveness of our proposed method on real experiments, and use it for underwater monocular Visual-Inertial SLAM.


Title: Yaw Torque Authority for a Flapping-Wing Micro-Aerial Vehicle
Key Words: aerodynamics  aerospace components  aircraft control  control nonlinearities  microrobots  mobile robots  piezoelectric actuators  torque  reliable torque  controllable yaw torque  yaw torque authority  flapping-wing microaerial vehicle  high-frequency wing  reliable yaw control authority  split-cycle flapping  flapping frequency  flapping signal  Torque  Actuators  Harmonic analysis  Force  Power harmonic filters  Shape  Resonant frequency 
Abstract: Flapping-wing micro-aerial vehicles rely on subtle changes in the kinematics of high-frequency wing flapping to produce roll, pitch, and yaw torques. To generate yaw torque, the Harvard RoboBee changes the ratio of upstroke to downstroke speed (“split-cycling”) by applying a second harmonic to the fundamental flapping signal for each wing. However, since flapping typically occurs near resonance (for efficiency), these higher harmonics are filtered out by the transmission and actuator dynamics. Therefore, reliable yaw control authority has proven elusive. We propose a method to generate yaw torque sufficient for in-flight control by using split-cycle flapping in an “iso-lift” regime, to mitigate resonant filtering by decreasing the flapping frequency and increasing the drive voltage, which produces lift identical to typical flight conditions. We model the expected torque at iso-lift conditions and apply this method to the physical RoboBee, achieving reliable, controllable yaw torque. Finally, we demonstrate yaw control with a simple heading controller, achieving a step response with a time constant an order of magnitude faster than previous attempts.


Title: HD Map Change Detection with a Boosted Particle Filter
Key Words: image classification  learning (artificial intelligence)  object detection  particle filtering (numerical methods)  probability  road vehicles  traffic engineering computing  automated driving  landmark readings  probability distribution  HD map change detection  boosted particle filter  change detection algorithm  backend-based stream processing pipeline  floating car data  series-production vehicles  automotive high definition digital map  crowd-based approach  Roads  Global navigation satellite system  Measurement  Visualization  Automobiles  Robot sensing systems  Feature extraction 
Abstract: In this paper, we present a change detection algorithm that can run in real time as part of a backend-based stream processing pipeline. It can process the floating car data collected by series-production vehicles to detect changes in an automotive high definition digital (HD) map used for automated driving. The algorithm uses a particle filter approach with odometry, GNSS and landmark readings to localize the vehicle within the digital map. While all particles together represent the probability distribution for the vehicle's position at a given time, each individual particle also serves as a hypothesis about the vehicle's position. This is used to compute various metrics for how well the current sensor readings match the world model encoded in the HD map. The different metrics are evaluated by a number of weak classifiers that are used as input for a trained Adaboost classifier. The achievable detection rate of a single vehicle is then compared to that of a simple crowd-based approach, where each vehicle votes on whether or not the current section of the road has changed.


Title: Where Should We Place LiDARs on the Autonomous Vehicle? - An Optimal Design Approach
Key Words: ant colony optimisation  evolutionary computation  minimax techniques  object detection  optical radar  nondetectable subspace  min-max optimization problem  cuboid-based approach  VSR-based measure  object detection rate  tractable cost function computation  VSR measure  cost-effectiveness configuration  optimal design approach  autonomous vehicle manufacturers  accurate 3D views  precise distance measures  optimal LiDAR configuration problem  utility maximization  artificial bee colony evolutionary algorithm  uncertain driving conditions  bio-inspired measure  Laser radar  Laser beams  Cost function  Shape  Three-dimensional displays  Cameras 
Abstract: Autonomous vehicle manufacturers recognize that LiDAR provides accurate 3D views and precise distance measures under highly uncertain driving conditions. Its practical implementation, however, remains costly. This paper investigates the optimal LiDAR configuration problem to achieve utility maximization. We use the perception area and non-detectable subspace to construct the design procedure as solving a min-max optimization problem and propose a bio-inspired measure - volume to surface area ratio (VSR) - as an easy-to-evaluate cost function representing the notion of the size of the non-detectable subspaces of a given configuration. We then adopt a cuboid-based approach to show that the proposed VSR-based measure is a well-suited proxy for object detection rate. It is found that the Artificial Bee Colony evolutionary algorithm yields a tractable cost function computation. Our experiments highlight the effectiveness of our proposed VSR measure in terms of cost-effectiveness configuration as well as providing insightful analyses that can improve the design of AV systems.


Title: Set-based Inverse Kinematics Control of an Anthropomorphic Dual Arm Aerial Manipulator
Key Words: autonomous aerial vehicles  end effectors  helicopters  manipulator kinematics  mobile robots  motion control  position control  redundant manipulators  inverse kinematics control  anthropomorphic dual arm aerial manipulator  multiple task-priority inverse kinematics algorithm  dual-arm aerial manipulator  equality constraints  inequality constraints  singularity robust method  motion control  underactuated aerial hexarotor vehicle  manipulators  null-space based behavioral control  Task analysis  Kinematics  End effectors  Jacobian matrices  Robot kinematics 
Abstract: The paper presents a multiple task-priority inverse kinematics algorithm for a dual-arm aerial manipulator. Both tasks defined as equality constraints and inequality constraints are handled by means of a singularity robust method based on the Null-Space based Behavioral control. The proposed schema is constituted by the inverse kinematics control, that receives the desired behavior of the system and outputs the reference values for the motion variables, i.e. the UAV pose and the arm joints position, and a motion control, that computes the vehicle thrusts and the joint torques. The method has been experimentally validated on a system composed by an underactuated aerial hexarotor vehicle equipped with two lightweight 4-DOF manipulators, involved in operations requiring the coordination of the two arms and the vehicle.


Title: Detection and Tracking of Small Objects in Sparse 3D Laser Range Data
Key Words: autonomous aerial vehicles  data structures  image segmentation  image sensors  laser ranging  median filters  mobile robots  object detection  object tracking  robot vision  solid modelling  autonomous behavior  microaerial vehicles  multiobject tracking  lightweight sensors  sparse point clouds  Velodyne VLP-16 sensor  MAV hardware  unlabeled data  sparse 3d laser range data  objects detection  median filters  data structure  Three-dimensional displays  Sensors  Target tracking  Object tracking  Real-time systems  Vehicle dynamics  Heuristic algorithms 
Abstract: Detection and tracking of dynamic objects is a key feature for autonomous behavior in a continuously changing environment. With the increasing popularity and capability of micro aerial vehicles (MAVs) efficient algorithms have to be utilized to enable multi object tracking on limited hardware and data provided by lightweight sensors. We present a novel segmentation approach based on a combination of median filters and an efficient pipeline for detection and tracking of small objects within sparse point clouds generated by a Velodyne VLP-16 sensor. We achieve real-time performance on a single core of our MAV hardware by exploiting the inherent structure of the data. Our approach is evaluated on simulated and real scans of in- and outdoor environments, obtaining results comparable to the state of the art. Additionally, we provide an application for filtering the dynamic and mapping the static part of the data, generating further insights into the performance of the pipeline on unlabeled data.


Title: GPS-Denied UAV Localization using Pre-existing Satellite Imagery
Key Words: artificial satellites  autonomous aerial vehicles  cameras  convolutional neural nets  distance measurement  Global Positioning System  mobile robots  object detection  robot vision  flight location  UAV imagery  image capturing conditions  localization accuracy  adjacent UAV frames  satellite map  GPS-denied flight  average localization error  GPS-denied UAV localization  onboard GPS system  noisy GPS signal  unreliable GPS signal  monocular RGB camera  convolutional neural network representations  satellite data  satellite imagery  unmanned aerial vehicles  distance 0.85 km  distance 0.2 km  Satellites  Global Positioning System  Unmanned aerial vehicles  Training  Meters  Imaging  Buildings 
Abstract: We present a method for localization of Unmanned Aerial Vehicles (UAVs) which is meant to replace an onboard GPS system in the event of a noisy or unreliable GPS signal. Our method requires only a downward-facing monocular RGB camera on the UAV, and pre-existing satellite imagery of the flight location to which the UAV imagery is compared and aligned. To overcome differences in the image capturing conditions between the satellite and UAV, such as seasonal and perspective changes, we propose the use of Convolutional Neural Network (CNN) representations trained on readily available satellite data. To increase localization accuracy, we also develop an optimization which jointly minimizes the error between adjacent UAV frames as well as the satellite map. We demonstrate how our method improves on recent systems from literature by achieving greater performance in flight environments with very few landmarks. For a GPS-denied flight at 0.2km altitude, over a flight distance of 0.85km, we achieve average localization error of less than 8 meters. We make our source code and datasets available to encourage further work on this emerging topic.


Title: Adaptive View Planning for Aerial 3D Reconstruction
Key Words: autonomous aerial vehicles  image reconstruction  optimisation  trajectory control  aerial 3D reconstruction  aerial vehicles  high quality reconstruction  adaptive view planning method  coarse proxy  reconstruction error  3D free space  Image reconstruction  Trajectory  Three-dimensional displays  Planning  Image resolution  Feature extraction  Drones 
Abstract: With the proliferation of small aerial vehicles, acquiring close up imagery for high quality reconstruction is gaining importance. We present an adaptive view planning method to collect such images in an automated fashion. We first start by sampling a small set of views to build a coarse proxy to the scene. We then present (i) a method that builds a set of adaptive viewing planes for efficient view selection and (ii) an algorithm to plan a trajectory that guarantees high reconstruction quality which does not deviate too much from the optimal one. The vehicle then follows the trajectory to cover the scene, and the procedure is repeated until reconstruction quality converges or a desired level of quality is achieved. The set of viewing planes provides an effective compromise between using the entire 3D free space and using a single view hemisphere to select the views. We compare our algorithm to existing methods in three challenging scenes. Our algorithm generates views which produce the least reconstruction error comparing to three different baseline approaches.


Title: An Autonomous Loop-Closure Approach for Simultaneous Exploration and Coverage of Unknown Infrastructure Using MAVs
Key Words: autonomous aerial vehicles  inspection  microrobots  mobile robots  spatial measurements  MAV motions  complete exploration  autonomous loop-closure approach  simultaneous exploration  unknown infrastructure  attractive means  critical infrastructure  autonomous tasks  precise spatial model  operational area  sensor measurements  autonomous inspection capabilities  autonomous MAV exploration  unknown structure  spatial information  high-fidelity 3D model  low-cost microaerial vehicles  Planning  Three-dimensional displays  Task analysis  Inspection  Simultaneous localization and mapping 
Abstract: The recent proliferation of low-cost Micro Aerial Vehicles (MAV) offers an attractive means for inspecting critical infrastructure autonomously. However, to enable such autonomous tasks requires a precise spatial model of the structure and operational area, typically constructed using sensor measurements obtained from the environment. To facilitate autonomous inspection capabilities, we address the problem of autonomous MAV exploration and coverage of an unknown structure to acquire the spatial information necessary for the development of a high-fidelity 3D model of the structure. Key to this problem is to not only cover the entire structure to acquire a complete set of spatial measurements, but also to minimize accumulative data errors during the exploration through direct planning of loop closures. We introduce a real-time waypoint planning approach to guide MAV motions to achieve complete exploration, coverage, and loop closure while respecting limited onboard resources.


Title: Unsupervised Learning of Assistive Camera Views by an Aerial Co-robot in Augmented Reality Multitasking Environments
Key Words: augmented reality  autonomous aerial vehicles  cameras  computer displays  mobile robots  unsupervised learning  unsupervised learning  assistive camera views  augmented reality multitasking environments  assistive aerial robot  task domain  head motion  anisotropic spherical sensor  expectation maximization solver  Gaussians  dynamic coverage control law  augmented reality display  human operator  assistive robot  reflex time  task completion time  aerial co-robot  Visualization  Task analysis  Cameras  Robot vision systems 
Abstract: This paper presents a novel method by which an assistive aerial robot can learn the relevant camera views within a task domain through tracking the head motions of a human collaborator. The human's visual field is modeled as an anisotropic spherical sensor, which decays in acuity towards the periphery, and is integrated in time throughout the domain. This data is resampled and fed into an expectation maximization solver in order to estimate the environment's visual interest as a mixture of Gaussians. A dynamic coverage control law directs the robot to capture camera views of the peaks of these Gaussians which is broadcast to an augmented reality display worn by the human operator. An experimental study is presented that assesses the influence of the assistive robot on reflex time, head motion, and task completion time.


Title: Robot Co-design: Beyond the Monotone Case
Key Words: autonomous aerial vehicles  mobile robots  multi-robot systems  optimisation  software aspects  robotic platform  robot design process  small-volumes low-cost applications  computational robot co-design problem  robotic modules  binary optimization formulation  co-design problems  autonomous drone racing platform  multirobot system  monotone case  miniaturized robotic hardware  inexpensive robots  disposable robots  scientific discovery  confined spaces  nanodrones  task-specific robots clashes  human experts  search-and-rescue  Robot sensing systems  Drones  Task analysis  Hardware  Legged locomotion  Optimization 
Abstract: Recent advances in 3D printing and manufacturing of miniaturized robotic hardware and computing are paving the way to build inexpensive and disposable robots. This will have a large impact on several applications including scientific discovery (e.g., hurricane monitoring), search-and-rescue (e.g., operation in confined spaces), and entertainment (e.g., nano drones). The need for inexpensive and task-specific robots clashes with the current practice, where human experts are in charge of designing hardware and software aspects of the robotic platform. This makes the robot design process expensive and time consuming, and ultimately unsuitable for small-volumes low-cost applications. This paper considers the computational robot co-design problem, which aims to create an automatic algorithm that selects the best robotic modules (sensing, actuation, computing) in order to maximize the performance on a task, while satisfying given specifications (e.g., maximum cost of the resulting design). We propose a binary optimization formulation of the co-design problem and show that such formulation generalizes previous work based on strong modeling assumptions. We show that the proposed formulation can solve relatively large co-design problems in seconds and with minimal human intervention. We demonstrate the proposed approach in two applications: the co-design of an autonomous drone racing platform and the co-design of a multi-robot system.


Title: Multi-Vehicle Close Enough Orienteering Problem with Bézier Curves for Multi-Rotor Aerial Vehicles
Key Words: aircraft control  autonomous aerial vehicles  remotely operated vehicles  unsupervised learning  travel cost  travel budget  Bézier curves  multivehicle CEOP  multirotor aerial vehicles  maximal velocity  acceleration limits  rewarding target locations  multivehicle close enough orienteering problem  surveillance planning  unsupervised learning  Trajectory  Acceleration  Adaptive arrays  Planning  Unsupervised learning  Optimization  Surveillance 
Abstract: This paper introduces the Close Enough Orienteering Problem (CEOP) for planning missions with multi-rotor aerial vehicles considering their maximal velocity and acceleration limits. The addressed problem stands to select the most rewarding target locations and sequence to visit them in the given limited travel budget. The reward is collected within a non-zero range from a particular target location that allows saving the travel cost, and thus collect more rewards. Hence, we are searching for the fastest trajectories to collect the most valuable rewards such that the motion constraints are not violated, and the travel budget is satisfied. We leverage on existing trajectory parametrization based on Bézier curves recently deployed in surveillance planning using unsupervised learning, and we propose to employ the learning in a solution of the introduced multi-vehicle CEOP. Feasibility of the proposed approach is supported by empirical evaluation and experimental deployment using multi-rotor vehicles.


Title: Using Data-Driven Domain Randomization to Transfer Robust Control Policies to Mobile Robots
Key Words: automobiles  collision avoidance  mobile robots  motion control  probability  robust control  stochastic processes  trajectory control  deep stochastic dynamics model  collision avoidance  1/5 scale agile ground vehicle  robust control policies  vehicle data  collision probability  trajectory tracking accuracy  stochasticity  simple analytic car model  high quality stochastic dynamics model  robot motion trajectories  mobile robots  data-driven domain randomization  Stochastic processes  Data models  Vehicle dynamics  Optimization  Robots  Uncertainty  Computational modeling 
Abstract: This work develops a technique for using robot motion trajectories to create a high quality stochastic dynamics model that is then leveraged in simulation to train control policies with associated performance guarantees. We demonstrate the idea by collecting dynamics data from a 1/5 scale agile ground vehicle, fitting a stochastic dynamics model, and training a policy in simulation to drive around an oval track at up to 6.5 m/s while avoiding obstacles. We show that the control policy can be transferred back to the real vehicle with little loss in predicted performance. We compare this to an approach that uses a simple analytic car model to train a policy in simulation and show that using a model with stochasticity learned from data leads to higher performance in terms of trajectory tracking accuracy and collision probability. Furthermore, we show empirically that simulation-derived performance guarantees transfer to the actual vehicle when executing a policy optimized using a deep stochastic dynamics model fit to vehicle data.


Title: A Fleet of Miniature Cars for Experiments in Cooperative Driving
Key Words: automobiles  human factors  mobile robots  motion control  steering systems  trajectory control  vehicle dynamics  unique experimental testbed  trajectory planning  miniature robotic car  Cambridge Minicar  autonomous control strategies  physical multilane setup  miniature highway  large-fleet experimental research  driver models  multilane road topographies  miniature Ackermann-steering vehicles  Automobiles  Trajectory  Traffic control  DC motors  Servomotors  Robot kinematics 
Abstract: We introduce a unique experimental testbed that consists of a fleet of 16 miniature Ackermann-steering vehicles. We are motivated by a lack of available low-cost platforms to support research and education in multi-car navigation and trajectory planning. This article elaborates the design of our miniature robotic car, the Cambridge Minicar, as well as the fleet's control architecture. Our experimental testbed allows us to implement state-of-the-art driver models as well as autonomous control strategies, and test their validity in a real, physical multi-lane setup. Through experiments on our miniature highway, we are able to tangibly demonstrate the benefits of cooperative driving on multi-lane road topographies. Our setup paves the way for indoor large-fleet experimental research.


Title: Coverage of an Environment Using Energy-Constrained Unmanned Aerial Vehicles
Key Words: approximation theory  autonomous aerial vehicles  computational complexity  mobile robots  path planning  travelling salesman problems  UGV  area coverage problem  energy-constrained unmanned aerial vehicle  unmanned ground vehicle  symbiotic UAV  NP-hard problem  generalized traveling salesperson problem  boustrophedon cells  limited battery capacity  Batteries  Unmanned aerial vehicles  Agriculture  Robot sensing systems  Strips  Routing 
Abstract: We study the problem of covering an environment using an Unmanned Aerial Vehicle (UAV) with limited battery capacity. We consider a scenario where the UAV can land on an Unmanned Ground Vehicle (UGV) and recharge the onboard battery. The UGV can also recharge the UAV while transporting the UAV to the next take-off site. We present an algorithm to solve a new variant of the area coverage problem that takes into account this symbiotic UAV and UGV system. The input consists of a set of boustrophedon cells - rectangular strips whose width is equal to the field-of-view of the sensor on the UAV. The goal is to find a tour for the UAV that visits and covers all cells in minimum time. This includes flight time for visiting and covering all cells, recharging time, as well as the take-off and landing times. We show how to reduce this problem to a known NP-hard problem, Generalized Traveling Salesperson Problem (GTSP). Given an optimal GTSP solver, our approach finds the optimal coverage paths for the UAV and UGV. We evaluate our algorithm through simulations and proof-of-concept experiments.


Title: Decentralized Formation Coordination of Multiple Quadcopters under Communication Constraints
Key Words: autonomous aerial vehicles  collision avoidance  decentralised control  helicopters  integer programming  linear programming  mobile robots  multi-robot systems  nonlinear programming  robot dynamics  robot kinematics  RSSI  tree searching  outdoor formation coordination  multiple quadcopters  time-optimal speed profile  minimum snap spline path  quadcopter kinematics  wireless communication connectivity  geometric formations  maximum separation distance  minimum viable received signal strength  path loss attenuation  outdoor flight test  formation type  robin communication scheduling scheme  decentralized formation coordination  communication constraints  RH-MINLP  quadcopter dynamics  collision avoidance  outer-approximation branch and bound solver  warm-starting scheme  hardware-in-the-loop  HITL  average radio packet loss statistics  round robin communication scheduling scheme  receding horizon mixed-integer nonlinear program  Splines (mathematics)  Robot kinematics  Collision avoidance  Planning  Optimization  Mobile ad hoc networks 
Abstract: This paper addresses the problem of decentralized, outdoor formation coordination with multiple quadcopters. The problem is formulated as a receding horizon, mixed-integer non-linear program (RH-MINLP). Each quadcopter solves this RH-MINLP to generate its time-optimal speed profile along a minimum snap spline path while coordinating its position in a desired formation with other quadcopters. Constraints on quadcopter kinematics, dynamics, collision avoidance, wireless communication connectivity, and geometric formations are modeled. Communication connectivity is modeled as a constraint on maximum separation distance based on a minimum viable received signal strength in the presence of path loss attenuation. The resulting RH-MINLP is non-convex, and is solved using an outer-approximation branch and bound solver with a warm-starting scheme. The framework is validated via Hardware-in-the-Loop (HITL) and outdoor flight test with up to 6 quadcopters. Results demonstrate the effect of number of quadcopters and formation type on total transit time. Average radio packet loss statistics during transit indicate robust network performance for a round robin communication scheduling scheme.


Title: Interaction-Aware Multi-Agent Reinforcement Learning for Mobile Agents with Individual Goals
Key Words: gradient methods  learning (artificial intelligence)  mobile robots  multi-agent systems  multi-robot systems  navigation  path planning  robot programming  interaction-aware multiagent reinforcement learning  mobile agents  individual goals  optimal policy  decentralized learning  mobile robot navigation  policy gradient algorithms  nonstationary policies  curriculum-based strategy  interactive policy learning  Training  Robots  Games  Markov processes  Reinforcement learning  Navigation  Autonomous vehicles 
Abstract: In a multi-agent setting, the optimal policy of a single agent is largely dependent on the behavior of other agents. We investigate the problem of multi-agent reinforcement learning, focusing on decentralized learning in non-stationary domains for mobile robot navigation. We identify a cause for the difficulty in training non-stationary policies: mutual adaptation to sub-optimal behaviors, and we use this to motivate a curriculum-based strategy for learning interactive policies. The curriculum has two stages. First, the agent leverages policy gradient algorithms to learn a policy that is capable of achieving multiple goals. Second, the agent learns a modifier policy to learn how to interact with other agents in a multi-agent setting. We evaluated our approach on both an autonomous driving lane-change domain and a robot navigation domain.


Title: A Competitive Algorithm for Online Multi-Robot Exploration of a Translating Plume
Key Words: autonomous aerial vehicles  mobile robots  multi-robot systems  velocity control  arbitrary shape  plume shape  plume speed  robot speed  tour  aerial robots  translating plume  online multirobot exploration  competitive algorithm  Robot kinematics  Two dimensional displays  Approximation algorithms  Shape  Unmanned aerial vehicles  Binary trees 
Abstract: In this paper, we study the problem of exploring a translating plume with a team of aerial robots. The shape and the size of the plume are unknown to the robots. The objective is to find a tour for each robot such that they collectively explore the plume. Specifically, the tours must be such that each point in the plume must be visible from the field-of-view of some robot along its tour. We propose a recursive Depth-First Search (DFS)-based algorithm that yields a constant competitive ratio for the exploration problem. The competitive ratio is 2(Sr + Sp)(R+⌊log R⌋)/(Sr + Sp)(R+⌊log R⌋) where R is the number of robots, and Sr and Sp are the robot speed and the plume speed, respectively. We also consider a more realistic scenario where the plume shape is not restricted to grid cells but an arbitrary shape. We show our algorithm has 2(Sr + Sp)(18 R+⌊log R⌋)/(Sr + Sp)(1+⌊log R⌋) competitive ratio under the fat condition. We empirically verify our algorithm using simulations.


Title: Online Estimation of Ocean Current from Sparse GPS Data for Underwater Vehicles
Key Words: expectation-maximisation algorithm  Gaussian processes  Global Positioning System  mobile robots  position control  regression analysis  underwater vehicles  online estimation  Gaussian process-based expectation-maximisation algorithm  dead-reckoned position estimates  specialised GP regression scheme  best-fitting ocean  ocean current field  underwater vehicles  underwater robots  Oceans  Sea measurements  Current measurement  Global Positioning System  Trajectory  Estimation 
Abstract: Underwater robots are subject to position drift due to the effect of ocean currents and the lack of accurate localisation while submerged. We are interested in exploiting such position drift to estimate the ocean current in the surrounding area, thereby assisting navigation and planning. We present a Gaussian process (GP)-based expectation-maximisation (EM) algorithm that estimates the underlying ocean current using sparse GPS data obtained on the surface and dead-reckoned position estimates. We first develop a specialised GP regression scheme that exploits the incompressibility of ocean currents to counteract the underdetermined nature of the problem. We then use the proposed regression scheme in an EM algorithm that estimates the best-fitting ocean current in between each GPS fix. The proposed algorithm is validated in simulation and on a real dataset, and is shown to be capable of reconstructing the underlying ocean current field. We expect to use this algorithm to close the loop between planning and estimation for underwater navigation in unknown ocean currents.


Title: Working towards Adaptive Sensing for Terrain-aided Navigation
Key Words: adaptive signal processing  altimeters  autonomous underwater vehicles  Kalman filters  marine navigation  particle filtering (numerical methods)  sonar  underwater vehicles  velocity measurement  terrain-aided navigation  adaptive sensing method  pinging rate  localization accuracy  TAN  sonar pinging interval  local seafloor topography  modified Teager Kaiser energy operator  pinging interval  downward-looking sonar  autonomous underwater vehicle  particle filter  bias velocity estimator  Kalman filter  depth variation  Atmospheric measurements  Sea measurements  Particle measurements  Sonar navigation  Sensors  Sonar 
Abstract: An adaptive sensing method is presented to control the pinging interval of a downward-looking sonar on an Autonomous Underwater Vehicle. The goal is to conserve energy via adjusting the pinging rate automatically without reducing the localization accuracy when using terrain-aided navigation (TAN). In this paper, the TAN is implemented using a particle filter and a bias velocity estimator developed based on a Kalman filter. The adaptation on the sonar pinging interval is determined based on the depth variation of local seafloor topography which is quantified using a modified Teager Kaiser energy operator. As a result, more measurements are collected on high relief regions, and less measurements are obtained on relatively flat and smooth regions. We evaluated the adaptive sensing method in a simulated environment and applied it to a field data set. The results show that the adaptive sensing method produces an improved navigational accuracy compared to the missions with fixed sonar pinging rates. In the offline field missions, the energy consumed by the altimeter is reduced to about 30% in the adaptive sensing missions compared to continuously sensing missions where the altimeter is pinging consistently without switching off.


Title: Non-Gaussian SLAM utilizing Synthetic Aperture Sonar
Key Words: acoustic signal processing  array signal processing  graph theory  marine navigation  pose estimation  probability  sensor fusion  SLAM (robots)  synthetic aperture sonar  SLAM framework  beacon position  acoustic measurements  factor graph formulation  nonGaussian SLAM  spatial resolution  navigational measurements  underwater missions  synthetic aperture sonar  SAS  simultaneous localization and mapping  accurate pose estimation  hydrophones acoustic data  empirical probability distribution  conventional beamformer  autonomous surface vehicle  Acoustics  Synthetic aperture sonar  Array signal processing  Simultaneous localization and mapping  Apertures  Receivers  Sonar navigation 
Abstract: Synthetic Aperture Sonar (SAS) is a technique to improve the spatial resolution from a moving set of receivers by extending the array in time, increasing the effective array length and aperture. This technique is limited by the accuracy of the receiver position estimates, necessitating highly accurate, typically expensive aided-inertial navigation systems for submerged platforms. We leverage simultaneous localization and mapping to fuse acoustic and navigational measurements and obtain accurate pose estimates even without the benefit of absolute positioning for lengthy underwater missions. We demonstrate a method of formulating the well-known SAS problem in a SLAM framework, using acoustic data from hydrophones to simultaneously estimate platform and beacon position. An empirical probability distribution is computed from a conventional beamformer to correctly account for uncertainty in the acoustic measurements. The non-parametric method relieves the familiar Gaussian-only assumption currently used in the localization and mapping discipline and fits effectively into a factor graph formulation with conventional factors such as ground-truth priors and odometry. We present results from field experiments performed on the Charles River with an autonomous surface vehicle which demonstrate simultaneous localization of an unknown acoustic beacon and vehicle positioning, and provide comparison to GPS ground truths.


Title: Easily Deployable Underwater Acoustic Navigation System for Multi-Vehicle Environmental Sampling Applications
Key Words: autonomous underwater vehicles  inertial navigation  lakes  mobile robots  path planning  underwater acoustic communication  clock synchronization  underwater robotics  autonomous underwater vehicles  GNSS  Lake Geneva  feature tracking  adaptive sampling  underwater environmental sensing  electromagnetic waves  radio communication  satellite based positioning  aerial robotics  multivehicle environmental sampling applications  acoustic navigation system  absolute time information  AUV position  underwater acoustic positioning system  inertial navigation  Acoustics  Global navigation satellite system  Acoustic measurements  Receivers  Clocks  Robot sensing systems 
Abstract: Water as a medium poses a number of challenges for robots, limiting the progress of research in underwater robotics vis-á-vis ground or aerial robotics. The primary challenges are satellite based positioning and radio communication being unusable due to high attenuation of electromagnetic waves in water. We have developed miniature, agile, easy to carry and deploy Autonomous Underwater Vehicles (AUVs) equipped with a suite of sensors for underwater environmental sensing. We previously demonstrated adaptive sampling and feature tracking, and gathered data from a lake for limnological research, with the AUV performing inertial navigation. In this paper, we demonstrate a new underwater acoustic positioning system, which allows on-board estimation of AUV position. Our system uses absolute time information from GNSS for initial clock synchronization and uses one-way-travel-time for range measurements, which makes it scalable in the number of robots. It is easily deployable and does not rely on any installed infrastructure in the environment. We describe various hardware and software components of our system, and present results from experiments in Lake Geneva.


Title: Underwater Terrain Reconstruction from Forward-Looking Sonar Imagery
Key Words: feature extraction  Gaussian processes  graph theory  image reconstruction  mobile robots  remotely operated vehicles  SLAM (robots)  sonar imaging  terrain mapping  underwater vehicles  terrain reconstruction  forward-looking sonar imagery  underwater simultaneous localization  multibeam imaging sonar  3D terrain mapping tasks  elevation angle information  data association  accurate 3D mapping  Euclidean space  optical flow  bearing-range images  subsea terrain  Gaussian Process random field  terrain factors  factor graph  terrain elevation estimate  variable-elevation tank environment  smooth height estimate  sonar images  Chow-Liu tree  extracted feature tracking  Feature extraction  Sonar measurements  Simultaneous localization and mapping  Three-dimensional displays  Gaussian processes  Imaging 
Abstract: In this paper, we propose a novel approach for underwater simultaneous localization and mapping using a multibeam imaging sonar for 3D terrain mapping tasks. The high levels of noise and the absence of elevation angle information in sonar images present major challenges for data association and accurate 3D mapping. Instead of repeatedly projecting extracted features into Euclidean space, we apply optical flow within bearing-range images for tracking extracted features. To deal with degenerate cases, such as when tracking is interrupted by noise, we model the subsea terrain as a Gaussian Process random field on a Chow-Liu tree. Terrain factors are incorporated into the factor graph, aimed at smoothing the terrain elevation estimate. We demonstrate the performance of our proposed algorithm in a simulated environment, which shows that terrain factors effectively reduce estimation error. We also show ROV experiments performed in a variable-elevation tank environment, where we are able to construct a descriptive and smooth height estimate of the tank bottom.


Title: Visual-Odometric Localization and Mapping for Ground Vehicles Using SE(2)-XYZ Constraints
Key Words: feature extraction  graph theory  mobile robots  motion control  object detection  path planning  road vehicles  robot vision  ground vehicle  odometric sensors  monocular visual sensors  stochastic constraint  odometric measurement processing  visual-odometric localization  mapping system  out-of SE(2) motion perturbation  SE(2)-XYZ constraint  image feature measurement  preintegration algorithm  graph optimization structure  Visualization  Optimization  Land vehicles  Perturbation methods  Robots  Jacobian matrices  Sensors 
Abstract: This paper focuses on the localization and mapping problem on ground vehicles using odometric and monocular visual sensors. To improve the accuracy of vision based estimation on ground vehicles, researchers have exploited the constraint of approximately planar motion, and usually implemented it as a stochastic constraint on an SE(3) pose. In this paper, we propose a simpler algorithm that directly parameterizes the ground vehicle poses on SE(2). The out-of SE(2) motion perturbations are not neglected, but incorporated into an integrated noise term of a novel SE(2)-XYZ constraint, which associates an SE(2) pose and a 3D landmark via the image feature measurement. For odometric measurement processing, we also propose an efficient preintegration algorithm on SE(2). Utilizing these constraints, a complete visual-odometric localization and mapping system is developed, in a commonly used graph optimization structure. Its superior performance in accuracy and robustness is validated by real-world experiments in industrial indoor environments.


Title: Keyframe-based Direct Thermal–Inertial Odometry
Key Words: cameras  distance measurement  Global Positioning System  inertial navigation  measurement errors  mobile robots  optimisation  path planning  radiometry  sensor fusion  temperature measurement  temperature sensors  keyframe-based direct thermal-inertial odometry  thermal camera  inertial measurements  airborne obscurants  fog  smoke  optimization based approach  inertial measurement errors  GPS  direct radiometric data fusion  aerial robotic capabilities  visually degraded environments  reprojection error minimisation  3D landmark error  indoor laboratory setting  underground mine  Cameras  Robot vision systems  Radiometry  Estimation  Unmanned aerial vehicles  Optimization 
Abstract: This paper proposes an approach for fusing direct radiometric data from a thermal camera with inertial measurements to extend the robotic capabilities of aerial robots for navigation in GPS-denied and visually degraded environments in the conditions of darkness and in the presence of airborne obscurants such as dust, fog and smoke. An optimization based approach is developed that jointly minimizes the re-projection error of 3D landmarks and inertial measurement errors. The developed solution is extensively verified against both ground-truth in an indoor laboratory setting, as well as inside an underground mine under severely visually degraded conditions.


Title: On Parameter Estimation of Space Manipulator Systems with Flexible Joints Using the Energy Balance*
Key Words: aerospace robotics  damping  flexible manipulators  manipulator dynamics  mobile robots  motion control  parameter estimation  path planning  manipulators  joint flexibilities  path planning  tracking capabilities  system inertial parameters  damping parameters  space flexible-joint manipulator system  system full dynamics  space manipulator systems  flexible joints  stiffness parameters  parameter estimation  Mathematical model  Space vehicles  Manipulator dynamics  Parameter estimation  Damping  Estimation 
Abstract: The parameter estimation of space manipulator systems on orbit is studied, whose manipulators are subject to joint flexibilities. To improve path planning and tracking capabilities, advanced control strategies that benefit from the knowledge of system parameters are required. These parameters include the system inertial parameters as well as the stiffness and damping parameters, which describe joint flexibilities. During operation some of these parameters may change or be unknown. Estimation methods based on the equations of motion are sensitive to noise, while methods based on the angular momentum conservation, while they are tolerant to noise, they cannot estimate the parameters that describe joint flexibilities. A parameter estimation method, based on the energy balance, applied during the motion of a space flexible-joint manipulator system in the free-floating mode, is developed. The method is tolerant to noise and can reconstruct the system full dynamics. It is shown that the parameters estimated by the proposed method can describe the system dynamics fully. The application of the developed method is valid for spatial systems; it is illustrated by a planar 7 degrees of freedom (DoF) example system.


Title: Adaptive Probabilistic Vehicle Trajectory Prediction Through Physically Feasible Bayesian Recurrent Neural Network
Key Words: Bayes methods  gradient methods  learning (artificial intelligence)  probability  recurrent neural nets  stochastic processes  traffic engineering computing  Bayesian recurrent neural network  prediction horizon  target human driver  naturalistic car following data  multimodal stochastic feedback gain  particle-filter-based parameter adaptation algorithm  adopted gradient-based training method  embedded physical model  trajectory distribution  Bayesian-neural-network-based policy model  Bayesian recurrent neural network model  driving policy  predicted distribution  physical feasibility  long-term trajectory prediction  autonomous driving  robust safety  adaptive probabilistic vehicle trajectory prediction  Trajectory  Adaptation models  Probabilistic logic  Bayes methods  Vehicle dynamics  Vehicles  Predictive models 
Abstract: Probabilistic vehicle trajectory prediction is essential for robust safety of autonomous driving. Current methods for long-term trajectory prediction cannot guarantee the physical feasibility of predicted distribution. Moreover, their models cannot adapt to the driving policy of the predicted target human driver. In this work, we propose to overcome these two shortcomings by a Bayesian recurrent neural network model consisting of Bayesian-neural-network-based policy model and known physical model of the scenario. Bayesian neural network can ensemble complicated output distribution, enabling rich family of trajectory distribution. The embedded physical model ensures feasibility of the distribution. Moreover, the adopted gradient-based training method allows direct optimization for better performance in long prediction horizon. Furthermore, a particle-filter-based parameter adaptation algorithm is designed to adapt the policy Bayesian neural network to the predicted target online. Effectiveness of the proposed methods is verified with a toy example with multi-modal stochastic feedback gain and naturalistic car following data.


Title: Optimizing Vehicle Distributions and Fleet Sizes for Shared Mobility-on-Demand
Key Words: optimisation  road vehicles  traffic engineering computing  transportation  optimizing vehicle distributions  fleet sizes  urban transit  ride-sharing  vehicle congestion  multiple passengers  historical demand data  MoD systems  travel demand  taxi demand  shared mobility-on-demand systems  taxi requests  city's transportation infrastructure  four passenger vehicles  Schedules  Delays  Urban areas  Public transportation  Cost function  Automation 
Abstract: Mobility-on-demand (MoD) systems are revolutionizing urban transit with the introduction of ride-sharing. Such systems have the potential to reduce vehicle congestion and improve accessibility of a city's transportation infrastructure. Recently developed algorithms can compute routes for vehicles in real-time for a city-scale volume of requests while allowing vehicles to carry multiple passengers at the same time. However, these algorithms focus on optimizing the performance for a given fleet of vehicles and do not tell us how many vehicles are needed to service all the requests. In this paper, we present an offline method to optimize the vehicle distributions and fleet sizes on historical demand data for MoD systems that allow passengers to share vehicles. We present an algorithm to determine how many vehicles are needed, where they should be initialized, and how they should be routed to service all the travel demand for a given period of time. Evaluation using 23,529,740 historical taxi requests from one month in Manhattan shows that on average 2864 four passenger vehicles are needed to service all of the taxi demand in a day with an average added travel delay of 2.8 mins.


Title: Dynamic Hilbert Maps: Real-Time Occupancy Predictions in Changing Environments
Key Words: Hilbert spaces  mobile robots  remotely operated vehicles  real-time occupancy predictions  static occupancy models  continuous occupancy map  high-dimensional feature space  data-efficient model  crowded unstructured outdoor environments  dynamic Hilbert maps  temporal dependencies  3D laser data  2D laser data  Vehicle dynamics  Predictive models  Uncertainty  Dynamics  Indexes  Real-time systems  Clustering algorithms 
Abstract: This paper addresses the problem of learning instantaneous occupancy levels of dynamic environments and predicting future occupancy levels. Due to the complexity of most real environments, such as urban streets or crowded areas, the efficient and robust incorporation of temporal dependencies into otherwise static occupancy models remains a challenge. We propose a method to capture the uncertainty of moving objects and incorporate this uncertainty information into a continuous occupancy map represented in a rich high-dimensional feature space. This data-efficient model not only allows us to learn the occupancy states incrementally, but also makes predictions about what the future occupancy states will be. Experiments performed using 2D and 3D laser data collected from crowded unstructured outdoor environments show that the proposed methodology can accurately predict occupancy states for areas of around 1000 m2 at 10 Hz, making the proposed framework ideal for online applications under real-time constraints.


Title: Fault-tolerant Flight Control of a VTOL Tailsitter UAV
Key Words: actuators  aircraft control  autonomous aerial vehicles  control system synthesis  fault tolerant control  remotely operated vehicles  minimalistic actuation  possible actuator failures  light-weight adaptations  nominal flight controller  tailsitter VTOL aircraft  fault-tolerant flight control  landing systems  moving parts  vertical take-off and landing systems  Propellers  Actuators  Aircraft  Aerospace electronics  Force  Fault tolerance  Fault tolerant systems 
Abstract: Compared to other vertical take-off and landing (VTOL) systems, a tailsitter minimizes the number of actuators and moving parts necessary. The downside of having a minimalistic actuation is its inherent low fault-tolerance. The failure of an actuator usually results in a loss of controllability, resulting in a crash. In this paper we analyze possible actuator failures and the constraints they pose on the capabilities of the system. We further present light-weight adaptations to the nominal flight controller to make it fault-tolerant. The fault-tolerant controller is implemented on a small tailsitter VTOL aircraft and adjusted to the system by means of extensive experimental studies. Finally, the capabilities and performance under failures are demonstrated and analyzed.


Title: Modeling and Control of a Passively-Coupled Tilt-Rotor Vertical Takeoff and Landing Aircraft
Key Words: actuators  aerospace components  aircraft control  attitude control  autonomous aerial vehicles  cascade control  control system synthesis  helicopters  hinges  mobile robots  propellers  rotors (mechanical)  three-term control  velocity control  quadrotor frame  fixed-wing aircraft  hover  forward flight  tilting actuators  coupled dynamics  aircraft frame  cascaded control architecture  control design  forward velocity control  passively-coupled tilt-rotor vertical takeoff and landing aircraft  differential thrust  propellers  inner-loop attitude  height control  constrained Lagrangian approach  P-PID controllers  unactuated hinged mechanism  equations of motion  unmanned aerial vehicles  UAVs  Aircraft  Mathematical model  Atmospheric modeling  Aerodynamics  Aerospace control  Rotors  Angular velocity  Vertical takeoff and landing aircraft  passively-coupled tilt-rotor  dynamic modeling  cascade PID control  PX4 autopilot 
Abstract: This paper presents the modeling and control of a passively-coupled tilt-rotor vertical takeoff and landing aircraft. The aircraft consists of a quadrotor frame attached to a fixed-wing aircraft by an unactuated hinged mechanism. The platform is capable of smooth transitions from hover to forward flight without the use of tilting actuators. The transition from hover to forward flight is made possible by differential thrust between the fore and aft propellers of the quadrotor frame. In this paper, the coupled dynamics between the quadrotor frame and the aircraft frame are modeled as a constrained multi-body system. The equations of motion are established using a constrained Lagrangian approach and the model developed is used to build a realistic simulation environment for control design purpose. A cascaded control architecture based on P/PID controllers is proposed to achieve inner-loop attitude, height and forward velocity control. Simulated and experimental results are obtained with a close match for hover, transitions, forward flight, and banked turn maneuvers.


Title: Power-Minimizing Control of a Variable-Pitch Propulsion System for Versatile Unmanned Aerial Vehicles
Key Words: aerospace propulsion  attitude control  autonomous aerial vehicles  mobile robots  motion control  pitch control (position)  power consumption  power control  propellers  robot dynamics  propeller design  propeller-based propulsion mechanisms  variable-pitch propeller  versatile UAVs  quasisteady propulsive state  power-minimizing control  electrical power consumption  versatile unmanned aerial vehicles  variable-pitch propulsion system  Power demand  Propellers  Servomotors  Unmanned aerial vehicles  Brushless DC motors 
Abstract: In response to an abundance of applications, Unmanned Aerial Vehicles are being called upon to perform missions of high difficulty for increasingly long periods of time. Traditional paradigms of propeller design and actuation are reaching a design ceiling, motivating creative approaches to the design of propeller-based propulsion mechanisms. Within the last decade, one particular kind of mechanism, the variable-pitch propeller, has been studied by researchers for its applications to the class of small UAVs. This paper pushes for new results in this area by exploring the use of Variable Pitch Propulsion (VPP) to minimize power consumption for small, versatile UAVs. A control algorithm is presented to minimize the consumed electrical power during a quasi-steady propulsive state. In particular, the algorithm is not confined to operation in limited regions of the state space, but it seeks to minimize power at whatever point in the state space a steady state is reached. Several experimental results are presented to validate the approach.


Title: Contact–based Navigation Path Planning for Aerial Robots
Key Words: autonomous aerial vehicles  mobile robots  path planning  remotely operated vehicles  robot dynamics  robot kinematics  aerial robots  in-contact operation  contact missions  flying robot  navigation mode  cartwheel mode  navigation modalities  in-contact navigation  specialized contact mechanism  contact-based navigation path planning  Navigation  Task analysis  Unmanned aerial vehicles  Inspection  Path planning  Mobile robots 
Abstract: In this paper the problem of contact-based navigation path planning for aerial robots is considered with the goal of enabling the autonomous in-contact operation on surfaces that can be highly anomalous. Such a capacity can prove critical in inspection through contact missions, as well as when a flying robot is tasked to operate in very narrow environments rendering safe free-flight impossible. To achieve this objective, beyond sliding in contact, a new locomotion primitive is introduced, namely that of azimuth rotations perpendicular to the surface under consideration. This new navigation mode, called flying cartwheel mode, offers navigation resourcefulness and resilience when the system is tasked to move in contact with surfaces that are otherwise non-traversable. The designed path planning method exploits both navigation modalities and a traversability metric to decide when to switch from sliding to flying cartwheel mode, and overall provides cost-optimal trajectories for in-contact navigation. The proposed approach is verified both in simulation, as well as experimentally using a surface presenting complex anomalies. It is highlighted that the proposed method does not assume any specialized contact mechanism or a control law tailored to physical interaction tasks, and hence is applicable to almost any micro aerial vehicle integrating protective shrouds around its propellers.


Title: Cargo Transportation Strategy using T3-Multirotor UAV
Key Words: attitude control  autonomous aerial vehicles  freight handling  helicopters  motion control  servomechanisms  cargo transportation strategy  stable flight performance  constant flight performance  fuselage part  relative attitude control strategy  T3-multirotor UAV platform  thrust generating part  servomechanism  moment of inertia  motion control  Mathematical model  Servomechanisms  Attitude control  Torque  Transportation  Radio frequency 
Abstract: In this paper, we introduce a cargo transportation method with a new type of multi-rotor UAV platform known as T3-multirotor, to achieve stable and constant flight performance regardless of the type of cargo attached to the fuselage. The T3-multirotor, which consists of the `Thrust Generating Part' and the `Fuselage Part', can directly control the relative attitude between the two parts using the novel servomechanism. By utilizing the servomechanism with the proposed relative attitude control strategy, the T3-multirotor with cargo attached to the fuselage part can behave as a multi-rotor with only the moment of inertia of the thrust generating part during entire transportation. This allows the T3-multirotor to achieve the reliable performance in the event of any cargo being attached to the fuselage, achieving stable platform motion control. Detailed hardware description and dynamic analysis of T3-Multirotor is performed in this paper, and the validity of the proposed control strategy is also analyzed. The feasibility of the proposed control strategy is verified through experimental results with analysis.


Title: Experimental Learning of a Lift-Maximizing Central Pattern Generator for a Flapping Robotic Wing
Key Words: aerodynamics  aerospace components  autonomous aerial vehicles  control engineering computing  gradient methods  learning (artificial intelligence)  motion control  multi-agent systems  robot dynamics  robot kinematics  robot programming  experimental learning  lift-maximizing central pattern generator  flapping robotic wing  policy gradient algorithm  dynamically scaled robotic wing  constant Reynolds number  central pattern generator model  CPG  motion controller  rhythmic wing motion patterns  half-stroke symmetry constraint  learning agent  robotic learning  wing kinematic learning  Kinematics  Robots  Oscillators  Trajectory  Servomotors  Heuristic algorithms  Computational modeling 
Abstract: In this work, we present an application of a policy gradient algorithm to a real-time robotic learning problem, where the goal is to maximize the average lift generation of a dynamically scaled robotic wing at a constant Reynolds number (Re). Compared to our previous work, the merit of this work is two-fold. First, a central pattern generator (CPG) model was used as the motion controller, which provided a smooth generation and transition of rhythmic wing motion patterns while the CPG was being updated by the policy gradient, thereby accelerating the sample generation and reducing the total learning time. Second, the kinematics included three degrees of freedom (stroke, deviation, pitching) and were also free of half-stroke symmetry constraint, together they yielded a larger kinematic space which later explored by the policy gradient to maximize the lift generation. The learned wing kinematics used the full range of stroke and deviation to maximize the lift generation, implying that the wing trajectories with larger disk area and lower frequencies were preferred for high lift generation at constant Re. Furthermore, the wing pitching amplitude converged to values between 45°-49° regardless of what the other parameters were. Notably, the learning agent was able to find two locally optimal wing motion patterns, which had distinct shapes of wing trajectory but generated similar cycle-averaged lift.


Title: Toward Lateral Aerial Grasping & Manipulation Using Scalable Suction
Key Words: grippers  mobile robots  self-adjusting systems  stability  scalable suction  aerial robot  lateral physical work  ground-based robots  functional work  lateral force  hovering vehicle  environmental forces  self-sealing suction cup  flight vehicle  physical grasping demonstrations  suction-based gripper  Grippers  Force  Spirals  Propulsion  Electron tubes  Robot sensing systems 
Abstract: This paper is an initial step toward the realization of an aerial robot that can perform lateral physical work, such as drilling a hole or fastening a screw in a wall. Aerial robots are capable of high maneuverability and can provide access to locations that would be difficult or impossible for ground-based robots to reach. However, to fully utilize this mobility, systems would ideally be able to perform functional work in those locations, requiring the ability to exert lateral forces. To substantially improve a hovering vehicle's ability to stably deliver large lateral forces, we propose the use of a versatile suction-based gripper that can establish pulling contact on featureless surfaces. Such contact enables access to environmental forces that can be used to further stabilize the vehicle and also increase the lateral force delivered to the surface through a possible secondary mechanism. This paper introduces the concept, describes the design of a new self-sealing suction cup based on a previous design, details the design of a gripper using those cups, and describes the arm and flight vehicle. It then evaluates the cup and gripper performance in several ways, culminating in physical grasping demonstrations using the arm and gripper, including one in the presence of simulated flight noise based on data from preliminary indoor flight experiments.


Title: A Multi-Vehicle Trajectories Generator to Simulate Vehicle-to-Vehicle Encountering Scenarios
Key Words: mobile robots  path planning  position control  remotely operated vehicles  road traffic  road vehicles  vehicle-to-vehicle encountering scenarios  autonomous vehicle development  multivehicle trajectory generator  MTG  multivehicle interaction scenarios  driving encounter scenarios  multibranch decoder  vehicle-to-vehicle encounters  autonomous vehicles  Trajectory  Measurement  Decoding  Generators  Bidirectional control  Generative adversarial networks  Stability analysis 
Abstract: Generating multi-vehicle trajectories from existing limited data can provide rich resources for autonomous vehicle development and testing. This paper introduces a multi-vehicle trajectory generator (MTG) that can encode multi-vehicle interaction scenarios (called driving encounters) into an interpretable representation from which new driving encounter scenarios are generated by sampling. The MTG consists of a bi-directional encoder and a multi-branch decoder. A new disentanglement metric is then developed for model analyses and comparisons in terms of model robustness and the independence of the latent codes. Comparison of our proposed MTG with β-VAE and InfoGAN demonstrates that the MTG has stronger capability to purposely generate rational vehicle-to-vehicle encounters through operating the disentangled latent codes. Thus the MTG could provide more data for engineers and researchers to develop testing and evaluation scenarios for autonomous vehicles.


Title: How Shall I Drive? Interaction Modeling and Motion Planning towards Empathetic and Socially-Graceful Driving
Key Words: game theory  intelligent robots  learning (artificial intelligence)  mobile robots  path planning  predictive control  remotely operated vehicles  AV  human driver  social awareness  passive-aggressive motions  interaction modeling  socially-graceful driving  autonomous vehicles  two-player game  model predictive control  social gracefulness  intent inference  motion planning  Planning  Games  Vehicles  Adaptation models  Inference algorithms  Estimation  Loss measurement 
Abstract: While intelligence of autonomous vehicles (AVs) has significantly advanced in recent years, accidents involving AVs suggest that these autonomous systems lack gracefulness in driving when interacting with human drivers. In the setting of a two-player game, we propose model predictive control based on social gracefulness, which is measured by the discrepancy between the actions taken by the AV and those that could have been taken in favor of the human driver. We define social awareness as the ability of an agent to infer such favorable actions based on knowledge about the other agent's intent, and further show that empathy, i.e., the ability to understand others' intent by simultaneously inferring others' understanding of the agent's self intent, is critical to successful intent inference. Lastly, through an intersection case, we show that the proposed gracefulness objective allows an AV to learn more sophisticated behavior, such as passive-aggressive motions that gently force the other agent to yield.


Title: SEG-VoxelNet for 3D Vehicle Detection from RGB and LiDAR Data
Key Words: image colour analysis  image segmentation  object detection  optical radar  SEG-VoxelNet  LiDAR data  RGB images  LiDAR point clouds  autonomous driving scenarios  semantic segmentation technique  3D LiDAR point cloud based detection  image semantic segmentation network  SEG-Net  improved-VoxelNet  semantic segmentation map  point cloud data  image semantic feature  KITTI 3D vehicle detection benchmark  Three-dimensional displays  Laser radar  Semantics  Vehicle detection  Feature extraction  Image segmentation  Two dimensional displays 
Abstract: This paper proposes a SEG-VoxelNet that takes RGB images and LiDAR point clouds as inputs for accurately detecting 3D vehicles in autonomous driving scenarios, which for the first time introduces semantic segmentation technique to assist the 3D LiDAR point cloud based detection. Specifically, SEG-VoxelNet is composed of two sub-networks: an image semantic segmentation network (SEG-Net) and an improved-VoxelNet. The SEG-Net generates the semantic segmentation map which represents the probability of the category for each pixel. The improved-VoxelNet is capable of effectively fusing point cloud data with image semantic feature and generating accurate 3D bounding boxes of vehicles. Experiments on the KITTI 3D vehicle detection benchmark show that our approach outperforms the methods of state-of-the-art.


Title: Velocity Constrained Trajectory Generation for a Collinear Mecanum Wheeled Robot
Key Words: mobile robots  path planning  trajectory control  velocity constrained trajectory generation  underactuated unstable aerial vehicles  linear accelerations  trajectory planner  trajectory timing characteristics  omnidirectional balancing robot  collinear Mecanum wheeled robot  ground based omnidirectional dynamically balancing robots  trajectory optimisation methods  differentially flat model  collinear Mecanum drive  Trajectory  Planning  Wheels  Mobile robots  Transmission line matrix methods  Acceleration 
Abstract: While much research has been conducted into the generation of smooth trajectories for underactuated unstable aerial vehicles such as quadrotors, less attention has been paid to the application of the same techniques to ground based omnidirectional dynamically balancing robots. These systems have more control authority over their linear accelerations than aerial vehicles, meaning trajectory smoothness is less of a critical design parameter. However, when operating in indoor environments these systems must often adhere to relatively low velocity constraints, resulting in very conservative trajectories when enforced using existing trajectory optimisation methods. This paper makes two contributions; this gap is bridged by the extension of these existing methods to create a fast velocity constrained trajectory planner, with trajectory timing characteristics derived from the optimal minimum-time solution of a simplified acceleration and velocity constrained model. Next, a differentially flat model of an omnidirectional balancing robot utilizing a collinear Mecanum drive is derived, which is used to allow an experimental prototype of this configuration to smoothly follow these velocity constrained trajectories.


Title: Solving Methods for Multi-Robot Missions Planning with Energy Capacity Consideration
Key Words: autonomous aerial vehicles  iterative methods  matrix algebra  minimisation  multi-robot systems  path planning  distance matrix  multiphase heuristic  two-phase iterative heuristic  branch-and-cut algorithm  decomposition-based approximate methods  high quality solutions  heterogeneous vehicles  energy capacity consideration  multirobot missions planning  Robots  Iterative methods  Task analysis  Linear programming  Planning  Resource management  Routing 
Abstract: We consider a problem minimizing the total duration of accomplishing missions performed by heterogeneous vehicles. The problem respects constraints related to vehicles' capabilities and energy capacities. The goal is to determine the best routes of each vehicle deployed by choosing which waypoints to pass and which observations to perform. Each vehicle has a particular distance matrix and a limited energy. In order to provide high quality solutions within reasonable computational time, two decomposition-based approximate methods were implemented: (i) the Multiphase heuristic, and (ii) the Two-Phase iterative heuristic. The performance of the methods is evaluated against the Branch-and-Cut algorithm using generated instances.


Title: Salty-A Domain Specific Language for GR(1) Specifications and Designs
Key Words: autonomous aerial vehicles  control system synthesis  formal specification  mobile robots  path planning  program debugging  remotely operated vehicles  specification languages  sanity checking  high-level specifications  domain-specific language  specification optimization  robot controller design  specification patterns  Salty domain specific language  GR(1) specifications  correct-by-construction synthesis approach  generalized reactivity(1) specifications  Slugs synthesis tool  multiple unmanned air vehicles  UAV  Target tracking  Robot kinematics  Tools  Software  Unmanned aerial vehicles  Control systems 
Abstract: Designing robot controllers that correctly react to changes in the environment is a time-consuming and error-prone process. An alternative is to use “correct-by-construction” synthesis approaches to automatically generate controller designs from high-level specifications. In particular, Generalized Reactivity(l) or GR(1) specifications are well-suited to express specifications for robots that must act in dynamic environments, and approaches to generate controller designs from GR(1) specifications are highly computationally efficient. Toward that end, this paper presents Salty, a domain-specific language for GR(1) specifications. While tools exist to synthesize system designs from GR(1) specifications, Salty makes such specifications easier to write and debug by supporting features such as richer input and output types, user-defined macros, common specification patterns, and specification optimization and sanity checking. Salty interfaces with the separately developed synthesis tool Slugs to produce a system or controller design, and Salty translates this design to a software implementation in a variety of languages. We demonstrate Salty on an application involving coordination of multiple unmanned air vehicles (UAVs) and provide a workflow for connecting synthesized UAV controllers to freely available UAV planning and simulation software suites UxAS and AMASE.


Title: Streamlines for Motion Planning in Underwater Currents
Key Words: autonomous underwater vehicles  motion control  path planning  reachability analysis  sampling methods  stream functions  control space  complicated flows  underwater currents  underwater vehicles  ocean currents  reachability  sampling-based motion planning  Australia  Aerospace electronics  Planning  Underwater vehicles  Two dimensional displays  Oceans  Australia  Level set 
Abstract: Motion planning for underwater vehicles must consider the effect of ocean currents. We present an efficient method to compute reachability and cost between sample points in sampling-based motion planning that supports long-range planning over hundreds of kilometres in complicated flows. The idea is to search a reduced space of control inputs that consists of stream functions whose level sets, or streamlines, optimally connect two given points. Such stream functions are generated by superimposing a control input onto the underlying current flow. A streamline represents the resulting path that a vehicle would follow as it is carried along by the current given that control input. We provide rigorous analysis that shows how our method avoids exhaustive search of the control space, and demonstrate simulated examples in complicated flows including a traversal along the east coast of Australia, using actual current predictions, between Sydney and Brisbane.


Title: A Distributed Predictive Control Approach for Cooperative Manipulation of Multiple Underwater Vehicle Manipulator Systems
Key Words: autonomous underwater vehicles  collision avoidance  distributed control  feedback  manipulator dynamics  manipulators  mobile robots  motion control  multi-robot systems  nonlinear control systems  position control  predictive control  control input saturations  coupled dynamics  load sharing coefficients  distributed NMPC  object transportation  constrained workspace  static obstacles  kinematic representation singularities  joint limits  multiple underwater vehicle manipulator systems  nonlinear model predictive control approach  distributed predictive control approach  UVMS locally measurements  Task analysis  Kinematics  Robot sensing systems  Jacobian matrices  End effectors  Vehicle dynamics 
Abstract: This paper addresses the problem of cooperative object transportation for multiple Underwater Vehicle Manipulator Systems (UVMSs) in a constrained workspace involving static obstacles. We propose a Nonlinear Model Predictive Control (NMPC) approach for a team of UVMSs in order to transport an object while avoiding significant constraints and limitations such as: kinematic and representation singularities, obstacles within the workspace, joint limits and control input saturations. More precisely, by exploiting the coupled dynamics between the robots and the object, and using certain load sharing coefficients, we design a distributed NMPC for each UVMS in order to cooperatively transport the object within the workspace's feasible region. Moreover, the control scheme adopts load sharing among the UVMSs according to their specific payload capabilities. Additionally, the feedback relies on each UVMS's locally measurements and no explicit data is exchanged online among the robots, thus reducing the required communication bandwidth. Finally, real-time simulation results conducted in UwSim dynamic simulator running in ROS environment verify the efficiency of the theoretical finding.


Title: Ambient light based depth control of underwater robotic unit aMussel
Key Words: autonomous underwater vehicles  mobile robots  pressure sensors  underwater robotic unit  1DOF  ambient light sensor  aMussel holding depth  pressure sensor  one degree-of-freedom  weather conditions  acoustic communication  Robot sensing systems  Pressure sensors  Buoyancy  Pistons  Simulation  Force 
Abstract: In this paper, we present a method for depth control of one degree of freedom (1DOF) underwater robotic platform aMussel, based on the measurements from the ambient light sensor. Since ambient light values change during the day and depend on the weather conditions, references for the controller are acquired from other aMussel holding depth using pressure sensor based controller. Control inputs are transmitted using acoustic communication.


Title: A Unified Closed-Loop Motion Planning Approach For An I-AUV In Cluttered Environment With Localization Uncertainty
Key Words: autonomous underwater vehicles  closed loop systems  collision avoidance  cooperative systems  manipulators  mobile robots  motion control  optimisation  position control  remotely operated vehicles  cluttered environment  localization uncertainty  trajectory optimization problem  optimal trajectory  I-AUV trajectories  optimization solvers  quasiquadratic optimization problems  null space saturation controller  cluttered underwater environments  optimal collision-free  intervention autonomous underwater vehicle  linear-quadratic-Gaussian controller  base trajectories  unified closed-loop motion planning approach  Trajectory  Planning  Manipulators  Uncertainty  Optimization  Aerospace electronics  Task analysis  Intervention AUV  Motion planning  Uncertainty minimization 
Abstract: This paper presents a unified motion planning approach for an Intervention Autonomous Underwater Vehicle (I-AUV) in a cluttered environment with localization uncertainty. With the uncertainty being propagated by an information filter, a trajectory optimization problem closed by a Linear-Quadratic-Gaussian controller is formulated for a coupled design of optimal trajectory, localization, and control. Due to the presence of obstacles or complexity of the cluttered environment, a set of feasible initial I-AUV trajectories covering multiple homotopy classes are required by optimization solvers. Parameterized through polynomials, the initial base trajectories are from solving quasi-quadratic optimization problems that are linearly constrained by waypoints from RRTconnect, while the initial trajectories of the manipulator are generated by a null space saturation controller. Simulations on an I-AUV with a 3 DOF manipulator in cluttered underwater environments demonstrated that initial trajectories are generated efficiently and that optimal and collision-free I-AUV trajectories with low state uncertainty are obtained.


Title: A bio-robotic remora disc with attachment and detachment capabilities for reversible underwater hitchhiking
Key Words: actuators  biomimetics  cables (mechanical)  elastic constants  mobile robots  motion control  polymers  underwater vehicles  bio-robotic remora disc  detachment capabilities  reversible underwater hitchhiking  remoras  adhesive discs  biological disc  multimaterial biomimetic disc  flexible cable-driven mechanism  silicone soft lip  internal pressure  disc lamellae  attached carbon fiber spinules  ambient underwater pressure  Lips  Hydraulic systems  Force  Substrates  Prototypes  Rough surfaces  Surface roughness  Attachment and detachment  soft robotics  underwater adhesion 
Abstract: Remoras employ their adhesive discs to rapidly attach to and detach from a wide range of marine surfaces. By analyzing high-speed images of remoras' (Echeneis naucrates) hitchhiking behavior, we describe the fish's detachment mechanism as a lip curling up to break the seal between the disc and substrate. By mimicking the kinematic and morphological properties of the biological disc, we fabricated a multi-material biomimetic disc (whose stiffness spans four orders of magnitude) that is capable of both attachment and detachment. Detachment is realized by a flexible cable-driven mechanism that curls the anterior region of the silicone soft lip, allows leakage under the disc, and equalizes the internal pressure to the external pressure. The disc lamellae with attached carbon fiber spinules can be rotated by hydraulic soft actuators whose internal pressure is precisely tuned to the ambient underwater pressure. During attachment, increasing the rotational angle of the lamellae and the preload of the disc significantly enhanced the adhesive forces. We found that curling up the soft lip and folding down the lamellae rapidly reduced the pulling force of the disc by a factor of 254 compared to that under the attached state, which lead to detachment. Based on these mechanisms, underwater maneuvers involving repeated attachment and detachment were demonstrated with an integrated ROV unit that had a self-contained actuation and control system for the disc. This study lays a foundation for the development of fully untethered robotic systems for underwater hitchhiking in real-world marine environments.


Title: Robot Communication Via Motion: Closing the Underwater Human-Robot Interaction Loop
Key Words: control engineering computing  human-robot interaction  mobile robots  robot communication  underwater human-robot interaction loop  colored lights  underwater robots  robot-to-human communication methods  body language gestures  communication vector  Robots  Solids  Task analysis  Unmanned underwater vehicles  Communication systems  Human-robot interaction  Hardware 
Abstract: In this paper, we propose a novel method for underwater robot-to-human communication using the motion of the robot as “body language”. To evaluate this system, we develop simulated examples of the system's body language gestures, called kinemes, and compare them to a baseline system using flashing colored lights through a user study. Our work shows evidence that motion can be used as a successful communication vector which is accurate, easy to learn, and quick enough to be used, all without requiring any additional hardware to be added to our platform. We thus contribute to “closing the loop” for human-robot interaction underwater by proposing and testing this system, suggesting a library of possible body language gestures for underwater robots, and offering insight on the design of nonverbal robot-to-human communication methods.


Title: Three-Dimensionally Maneuverable Robotic Fish Enabled by Servo Motor and Water Electrolyser
Key Words: biomechanics  compressed air systems  design engineering  mobile robots  motion control  open loop systems  pistons  servomotors  tanks (containers)  underwater vehicles  servo motor  three-dimensionally maneuverable robotic fish  depth control mechanism  compressed air tank  on-board water electrolyzer  two-dimensionally planar motion  open-loop control experiments  underwater robot  pistons  asymmetric flapping motion  caudal fin  design engineering  forward velocity  turning rate  velocity 0.13 m/s  time 10.0 s  time 5.5 s  size 0.55 m  Robots  Buoyancy  Three-dimensional displays  Force  Dynamics  Two dimensional displays  Solid modeling 
Abstract: Three-dimensionally (3D) maneuverable robotic fish are highly desirable due to their abilities to explore and survey the underwater environment. Existing depth control mechanism is focused on using compressed air or piston to generate volume change, which makes the system bulky and impractical in a small size underwater robot. In this paper, a small and compact 3D maneuverable robotic fish is developed. Instead of using a compressed air tank, the robot is equipped with an on-board water electrolyzer to generate the gases for depth change. The fabricated robotic fish shows fast diving and rising performance. A servo motor is used to generate asymmetric flapping motion on the caudal fin, which leads to a two-dimensionally (2D) planar motion. A 3D dynamic model is then derived for the fabricated robotic fish. Several open-loop control experiments have been conducted to validate the model as well as the design. It has been demonstrated in the experimental results that the robot is capable of generating 3D motion. The robot can achieve 0.13 m/s forward velocity, 30.6 degree/s turning rate, and it takes about 5.5 s to dive to 0.55 m and 10 s to rise.


Title: A Multimodal Aerial Underwater Vehicle with Extended Endurance and Capabilities
Key Words: aerospace components  aircraft control  autonomous aerial vehicles  autonomous underwater vehicles  design engineering  motion control  pneumatic systems  three-term control  vehicle dynamics  multimodal hybrid aerial underwater vehicle  MHAUV  design concept  fixed-wing unmanned aerial vehicle  extended endurance  Newton-Euler formalism  multidomain simulation  underwater glide test  design principles  proportional-integral-derivative  multirotor  lightweight pneumatic buoyancy adjustment system  vehicle's physical parameters  gliding equilibrium points  vehicle's motion control  Buoyancy  Bladder  Underwater vehicles  Prototypes  Rotors  Unmanned aerial vehicles  Mathematical model 
Abstract: A new solution to improving the poor endurance of the existing hybrid aerial underwater vehicle (HAUV) is proposed in this paper. The proposed multimodal hybrid aerial underwater vehicle (MHAUV) merges the design concept of the fixed-wing unmanned aerial vehicle (UAV), the multirotor, and the underwater glider (UG) and has a novel lightweight pneumatic buoyancy adjustment system. MHAUV is well suited for moving in distinct medium and can achieve extended endurance for long distance travel in both air and water. The mathematical model is given based on Newton-Euler formalism. Necessary design principles of the vehicle's physical parameters are obtained through different gliding equilibrium points. Then, a control scheme composed of two separate proportional-integral-derivative (PID) is employed for the vehicle's motion control in multi-domain simulation. The simulation results are presented to verify the multi-domain mobility and the mode switch ability of the proposed vehicle intuitively. Finally, a prototype, NEZHA, is introduced to be the experimental platform. The success of the flight test, the hovering test, the underwater glide test, and the medium transition test all contribute to prove the feasibility of the proposed concept of the novel MHAUV.


Title: Design and Experiments of a Squid-Like Aquatic-Aerial Vehicle with Soft Morphing Fins and Arms
Key Words: actuators  aircraft control  biomimetics  drag  hinges  legged locomotion  microrobots  mobile robots  motion control  numerical analysis  pneumatic control equipment  pneumatic systems  robot kinematics  soft morphable structures  soft morphing fins  aquatic-aerial multimodal vehicle  concept aircraft  natural organisms  multilocomotion  rigid link mechanisms  hinges  pneumatically-driven soft fins  flying squid  lift force  drag force  wind  water tunnel  squid-like aquatic-aerial vehicle  Prototypes  Force  Cavity resonators  Propulsion  Valves  Wind tunnels  Drag 
Abstract: Aquatic-aerial multimodal vehicle is a new concept aircraft that can freely shuttle between water and air. Some of the natural organisms provide the inspiration to realize this multi-locomotion. Most of current prototypes use rigid link mechanisms or hinges to morph the structure thus to adapt to the aquatic-aerial environment, which is commonly complicated and bulky. In this paper, we present a novel prototype with pneumatically-driven soft fins and arms that can fold and spread just like the flying squid. The fins and arms can augment the lift force during flying by spreading and reduce drag force during swimming by folding. The performance of the morphable structures was investigated in wind and water tunnel. The results explain the tradeoff strategies of multimodal-locomotion between water and air, and verify the feasibility of the novel aquatic-aerial vehicle with soft morphable structures.


Title: Nonlinear Orientation Controller for a Compliant Robotic Fish Based on Asymmetric Actuation
Key Words: actuators  mobile robots  motion control  nonlinear control systems  robot dynamics  underwater vehicles  nonlinear orientation controller  compliant robotic fish  asymmetric actuation  compliant fish-like robot  rigid tails  flexible tail  underactuated robotic fish  asymmetric velocity profiles  skewed triangle waves  nonlinear control law  simple actuation mechanism  underwater observation  sinusoidal tail actuation  turning motion  Robot sensing systems  Turning  Position control  Torque  Oscillators  Kinematics 
Abstract: Compliant fish-like robots are being developed as efficient and dependable underwater observation platforms with low impact on the observed environment. Orientation control is an essential building block to achieve autonomy for those vehicles. So far, the major focus has been on rigid tails or on flexible tails with a high degree of actuation. We present a novel control strategy for an underactuated robotic fish with a flexible tail optimized for cruising. The basis for our approach is the generation of asymmetric velocity profiles of the robot's tail beats. To achieve such velocity profiles, the usual sinusoidal tail actuation is replaced with skewed triangle waves. We provide a simple formulation for such waves, where their skew is dependent on only one variable which we define as skew factor. Furthermore, a nonlinear control law is derived to achieve the desired turning motions. We implement the controller on a compliant fish-like robot with a simple actuation mechanism. The control scheme is experimentally validated, and its robustness is tested in field trials.


Title: Project AutoVision: Localization and 3D Scene Perception for an Autonomous Vehicle with a Multi-Camera System
Key Words: cameras  geometry  image reconstruction  mobile robots  path planning  remotely operated vehicles  robot vision  stereo image processing  video signal processing  sensor suite  autonomous vehicle  multicamera system  3D scene perception capabilities  self-driving vehicle  autonomous navigation  urban environments  rural environments  exteroceptive sensors  AutoVision project  multiview geometry  Cameras  Sensors  Three-dimensional displays  Calibration  Laser radar  Autonomous vehicles  Lighting 
Abstract: Project AutoVision aims to develop localization and 3D scene perception capabilities for a self-driving vehicle. Such capabilities will enable autonomous navigation in urban and rural environments, in day and night, and with cameras as the only exteroceptive sensors. The sensor suite employs many cameras for both 360-degree coverage and accurate multi-view stereo; the use of low-cost cameras keeps the cost of this sensor suite to a minimum. In addition, the project seeks to extend the operating envelope to include GNSS-less conditions which are typical for environments with tall buildings, foliage, and tunnels. Emphasis is placed on leveraging multi-view geometry and deep learning to enable the vehicle to localize and perceive in 3D space. This paper presents an overview of the project, and describes the sensor suite and current progress in the areas of calibration, localization, and perception.


Title: Characterizing the Effects of Reduced Gravity on Rover Wheel-Soil Interactions using Computer Vision Techniques
Key Words: computer vision  Mars  mobile robots  planetary rovers  planetary surfaces  soil  wheels  lower gravity  soil resistance  weaker soil bonding  rover mobility  reduced-mass rover  full-mass rover  rover wheel-soil interactions  computer vision techniques  planetary rovers  Martian soil simulant  rover-soil visualization technique  reduced gravity wheel-terrain interaction  ExoMars wheel prototype  simulated Martian gravity  wheel normal load  ExoMars space mission  Wheels  Soil  Gravity  Moon  Aircraft  Space vehicles  Earth 
Abstract: Mitigating potential hazards for planetary rovers posed by soft soils requires testing in representative environments such as with Martian soil simulants in reduced gravity. This work describes the experimentation, methods, and results of a rover-soil visualization technique that produced rich datasets of reduced gravity wheel-terrain interaction. The activities are linked to the upcoming ExoMars space mission, through the use of ExoMars wheel prototype and Martian soil simulant in simulated Martian gravity produced in parabolic flights. The results indicate that, with wheel normal load held equal between experiments, the amount of soil mobilized by wheel-soil interaction increases as gravity decreases. Moreover, the amount of soil mobilized is more sensitive to slip in lower gravity. The results of the visualization analysis suggest a deterioration in the soil resistance and weaker soil bonding at lower gravities, which undermines the rover mobility by reducing the net traction. The results have important implications regarding the practice of using a reduced-mass rover on Earth to assess the performance of a full-mass rover in similar soil on an extraterrestrial surface.


Title: Adaptive H∞ Controller for Precise Manoeuvring of a Space Robot
Key Words: adaptive control  aerospace robotics  assembling  control system synthesis  H∞ control  manipulators  mirrors  motion control  nonlinear control systems  position control  robust control  space vehicles  space robot  precise manoeuvring  controlled-floating mode  in-orbit telescope assembly  robotic arm  slow manoeuvres  precise manoeuvres  orbital assembly missions  robustness  optical mirrors  nonlinear H∞ controller  adaptive H∞ controller  Space vehicles  Aerospace electronics  Robot kinematics  Manipulators  Uncertainty  Orbits 
Abstract: A space robot working in a controlled-floating mode can be used for performing in-orbit telescope assembly through simultaneously controlling the motion of the spacecraft base and its robotic arm. Handling and assembling optical mirrors requires the space robot to achieve slow and precise manoeuvres regardless of the disturbances and errors in the trajectory. The robustness offered by the nonlinear H∞ controller, in the presence of environmental disturbances and parametric uncertainties, makes it a viable solution. However, using fixed tuning parameters for this controller does not always result in the desired performance as the arm's trajectory is not known a priori for orbital assembly missions. In this paper, a complete study on the impact of the different tuning parameters is performed and a new adaptive H∞ controller is developed based on bounded functions. The simulation results presented show that the proposed adaptive H∞ controller guarantees robustness and precise tracking using a minimal amount of forces and torques for assembly operations using a small space robot.


Title: Belief Space Planning for Reducing Terrain Relative Localization Uncertainty in Noisy Elevation Maps
Key Words: astronomical image processing  digital elevation models  Global Positioning System  mobile robots  path planning  planetary rovers  robot vision  solid modelling  terrain mapping  belief space planning  noisy map data  elevation data  lunar orbital imagery  terrain relative localization uncertainty  noisy elevation  accurate global localization  operational risk  initial exploration missions  global position  terrain relative navigation  TRN  planetary rover-perspective images  digital elevation models  absolute positioning  orbital data  terrain features  GPS  satellite orbital imagery  Uncertainty  Planning  Noise measurement  Space vehicles  Navigation  Planetary orbits 
Abstract: Accurate global localization is essential for planetary rovers to reach mission goals and mitigate operational risk. For initial exploration missions, it is inappropriate to deploy GPS or build other infrastructure for navigating. One way of determining global position is to use terrain relative navigation (TRN). TRN compares planetary rover-perspective images and 3D models to existing satellite orbital imagery and digital elevation models (DEMs) for absolute positioning. However, TRN is limited by the quality of orbital data and the presence and uniqueness of terrain features. This work presents a novel combination of belief space planning with terrain relative navigation. Additionally, we introduce a new method for increasing the robustness of belief space planning to noisy map data. The new algorithm provides a statistically significant reduction in localization uncertainty when tested on elevation data produced from lunar orbital imagery.


Title: Learning to Drive from Simulation without Real World Labels
Key Words: cameras  closed loop systems  control engineering computing  learning (artificial intelligence)  learning systems  mobile robots  road vehicles  robot vision  traffic engineering computing  domain transfer  single-camera control policy  simulation control labels  driving performance  rural roads  urban roads  machine learning systems  simulated environment  vision-based lane  driving policy  rural road  image-to-image translation  autonomous vehicle  open-loop regression metric  Aerospace electronics  Image reconstruction  Task analysis  Semantics  Training  Roads  Measurement 
Abstract: Simulation can be a powerful tool for under-standing machine learning systems and designing methods to solve real-world problems. Training and evaluating methods purely in simulation is often “doomed to succeed” at the desired task in a simulated environment, but the resulting models are incapable of operation in the real world. Here we present and evaluate a method for transferring a vision-based lane following driving policy from simulation to operation on a rural road without any real-world labels. Our approach leverages recent advances in image-to-image translation to achieve domain transfer while jointly learning a single-camera control policy from simulation control labels. We assess the driving performance of this method using both open-loop regression metrics, and closed-loop performance operating an autonomous vehicle on rural and urban roads.


Title: Autonomous Cooperative Flight of Rigidly Attached Quadcopters
Key Words: adaptive control  aircraft control  autonomous aerial vehicles  helicopters  learning (artificial intelligence)  parameter estimation  quadcopter inertial measurement units  IMU  plug and play assembly  reinforcement learning  quadcopters stable operation  autonomous flight  controller parameters  adaptive controller architecture  estimated physical attachment  short online experiments  physical structure  automatic control  online parameter estimation  rigidly attached quadcopters  autonomous cooperative flight  Propellers  Estimation  Acceleration  Parameter estimation  Adaptation models  Force  Measurement units 
Abstract: In this paper, a method for online parameter estimation and automatic control of a system of rigidly attached quadcopters is introduced. First, the method performs an estimation of the physical structure attaching the quadcopters by relying solely on information from the quadcopters' Inertial Measurement Units (IMU). This information is obtained via simple and short online experiments, allowing their plug and play assembly without any human intervention. Then, given the estimated physical attachment's parameters, a stable operation of the quadcopters is achieved via an adaptive controller architecture, where the controller parameters are obtained using Reinforcement Learning. Finally, experimental results validate the proposed method, showing that a correct estimation of the physical structure is obtained allowing the autonomous flight of a pair of attached quadcopters.


Title: Energy Optimal Control Allocation in a Redundantly Actuated Omnidirectional UAV
Key Words: autonomous aerial vehicles  convex programming  motion control  optimal control  propellers  trajectory control  energy optimal control allocation  redundantly actuated omnidirectional UAV  actuation model  control allocation strategy  redundantly-actuated multirotor unmanned aerial vehicle  omnicopter  actuation redundancy  inverse actuator model  propeller airflows  convex constrained optimization problem  propellers thrusts  propeller thrust limits  underactuated multirotors  motion trajectories  Propellers  Actuators  Atmospheric modeling  Aerodynamics  Pulse width modulation  Resource management 
Abstract: This paper presents a novel actuation model and control allocation strategy for a redundantly-actuated multirotor unmanned aerial vehicle (UAV), referred to as the omnicopter. With an unconventional configuration, the omnicopter's eight propellers are able to produce all the six components of net force/torque, with two degrees of actuation redundancy. This enables the vehicle to execute motion trajectories unattainable with conventional underactuated multi-rotors. A new inverse actuator model is proposed that accounts for the significant interactions between propeller airflows by relating their output thrust forces to their input motor commands. Actuation redundancy is resolved by solving a convex constrained optimization problem. Its solution yields the most power efficient set of propellers thrusts that would produce a required net force/torque, while respecting the propeller thrust limits. When the required force/torque is infeasible due to the thrust limits, the solution would minimize the norm of the error between the desired and actual net force/torque vectors. Experimental results demonstrate the effectiveness of the proposed model and control allocation strategy.


Title: The Phoenix Drone: An Open-Source Dual-Rotor Tail-Sitter Platform for Research and Education
Key Words: aerodynamics  aerospace components  aerospace robotics  aircraft control  autonomous aerial vehicles  educational robots  helicopters  microrobots  mobile robots  rotors  educational purposes  design methodology  open-source Phoenix reference design  software design  Phoenix drone  open-source dual-rotor tail-sitter platform  open-source tail-sitter microaerial vehicle platform  dual-rotor design  open-source release  design documents  high-performance tail-sitter  testing  open-source materials  aerodynamics  flight control  state estimation  Open source software  Propellers  Aerodynamics  Vehicle dynamics  Attitude control  Drones  Atmospheric modeling 
Abstract: In this paper, we introduce the Phoenix drone: the first completely open-source tail-sitter micro aerial vehicle (MAV) platform. The vehicle has a highly versatile, dual-rotor design and is engineered to be low-cost and easily extensible/modifiable. Our open-source release includes all of the design documents, software resources, and simulation tools needed to build and fly a high-performance tail-sitter for research and educational purposes.The drone has been developed for precision flight with a high degree of control authority. Our design methodology included extensive testing and characterization of the aerodynamic properties of the vehicle. The platform incorporates many off-the-shelf components and 3D-printed parts, in order to keep the cost down. Nonetheless, the paper includes results from flight trials which demonstrate that the vehicle is capable of very stable hovering and accurate trajectory tracking.Our hope is that the open-source Phoenix reference design will be useful to both researchers and educators. In particular, the details in this paper and the available open-source materials should enable learners to gain an understanding of aerodynamics, flight control, state estimation, software design, and simulation, while experimenting with a unique aerial robot.


Title: Probably Unknown: Deep Inverse Sensor Modelling Radar
Key Words: image segmentation  learning (artificial intelligence)  neural nets  object detection  optical radar  probability  radar computing  radar imaging  autonomous vehicle applications  weather conditions  raw radar power returns  sensor noise  occlusion  Inverse Sensor Model  grid map  grid cell  heteroscedastic uncertainty  deep Inverse Sensor modelling radar  sensor observation  model formulation  standard CFAR filtering approaches  dynamic urban environment  world occupancy  lidar  partial occupancy labels  deep neural network  occupancy probabilities  Uncertainty  Robot sensing systems  Laser radar  Training  Spaceborne radar  Neural networks 
Abstract: Radar presents a promising alternative to lidar and vision in autonomous vehicle applications, able to detect objects at long range under a variety of weather conditions. However, distinguishing between occupied and free space from raw radar power returns is challenging due to complex interactions between sensor noise and occlusion. To counter this we propose to learn an Inverse Sensor Model (ISM) converting a raw radar scan to a grid map of occupancy probabilities using a deep neural network. Our network is selfsupervised using partial occupancy labels generated by lidar, allowing a robot to learn about world occupancy from past experience without human supervision. We evaluate our approach on five hours of data recorded in a dynamic urban environment. By accounting for the scene context of each grid cell our model is able to successfully segment the world into occupied and free space, outperforming standard CFAR filtering approaches. Additionally by incorporating heteroscedastic uncertainty into our model formulation, we are able to quantify the variance in the uncertainty throughout the sensor observation. Through this mechanism we are able to successfully identify regions of space that are likely to be occluded.


Title: Empty Cities: Image Inpainting for a Dynamic-Object-Invariant Space
Key Words: augmented reality  convolutional neural nets  image classification  image restoration  image segmentation  learning (artificial intelligence)  mobile robots  object detection  object recognition  robot vision  augmented reality  static structure  image inpainting  dynamic-object-invariant space  vehicles  pedestrians  plausible imagery  multiclass semantic segmentation  inpainting methods  deep learning  generative adversarial model  convolutional network  vision-based robot localization  visual place recognition  Vehicle dynamics  Semantics  Task analysis  Image segmentation  Deep learning  Image reconstruction  Training 
Abstract: In this paper we present an end-to-end deep learning framework to turn images that show dynamic content, such as vehicles or pedestrians, into realistic static frames. This objective encounters two main challenges: detecting all the dynamic objects, and inpainting the static occluded background with plausible imagery. The former challenge is addressed by the use of a convolutional network that learns a multiclass semantic segmentation of the image. The second problem is approached with a conditional generative adversarial model that, taking as input the original dynamic image and its dynamic/static binary mask, is capable of generating the final static image. These generated images can be used for applications such as augmented reality or vision-based robot localization purposes. To validate our approach, we show both qualitative and quantitative comparisons against other state-of-the-art inpainting methods by removing the dynamic objects and hallucinating the static structure behind them. Furthermore, to demonstrate the potential of our results, we carry out pilot experiments that show the benefits of our proposal for visual place recognition.


Title: Goal-oriented Object Importance Estimation in On-road Driving Videos
Key Words: driver information systems  feature extraction  object detection  road traffic  road vehicles  video signal processing  on-road driving videos  OIE  driving scene  visual model  object importance estimation  ego-vehicles driver  driving control  binary brake prediction  Vehicles  Feature extraction  Videos  Roads  Visualization  Task analysis  Vehicle dynamics 
Abstract: We formulate a new problem as Object Importance Estimation (OIE) in on-road driving videos, where the road users are considered as important objects if they have influence on the control decision of the ego-vehicle's driver. The importance of a road user depends on both its visual dynamics, e.g., appearance, motion and location, in the driving scene and the driving goal, e.g., the planned path, of the ego vehicle. We propose a novel framework that incorporates both visual model and goal representation to conduct OIE. To evaluate our framework, we collect an on-road driving dataset at traffic intersections in the real world and conduct human-labeled annotation of the important objects. Experimental results show that our goal-oriented method outperforms baselines and has much more improvement on the left-turn and right-turn scenarios. Furthermore, we explore the possibility of using object importance for driving control prediction and demonstrate that binary brake prediction can be improved with the information of object importance.


Title: Design and Formal Verification of a Safe Stop Supervisor for an Automated Vehicle*
Key Words: Global Positioning System  mobile robots  remotely operated vehicles  road safety  road vehicles  model-based approach  model checking  demonstration vehicle  formal verification  safe stop supervisor  automated vehicle  autonomous vehicles  pertinent planning  control algorithms  mode switch  nominal planners  safe fallback routine  safe position  nominal operational conditions  system failure  mode switching  safe stop trajectory planner  research concept vehicle  Trajectory  Planning  Automation  Global Positioning System  Software  Switches  Roads 
Abstract: Autonomous vehicles apply pertinent planning and control algorithms under different driving conditions. The mode switch between these algorithms should also be autonomous. On top of the nominal planners, a safe fallback routine is needed to stop the vehicle at a safe position if nominal operational conditions are violated, such as for a system failure. This paper describes the design and formal verification of a supervisor to manage all requirements for mode switching between nominal planners, and additional requirements for switching to a safe stop trajectory planner that acts as the fallback routine. The supervisor is designed via a model-based approach and its abstraction is formally verified by model checking. The supervisor is implemented and integrated with the Research Concept Vehicle, an experimental research and demonstration vehicle developed at the KTH Royal Institute of Technology. Simulations and experiments show that the vehicle is able to autonomously drive in a safe manner between two parking lots and can successfully come to a safe stop upon GPS sensor failure.


Title: Optimization-Based Terrain Analysis and Path Planning in Unstructured Environments
Key Words: data structures  graph theory  mobile robots  navigation  optimisation  path planning  position control  remotely operated vehicles  terrain mapping  trees (mathematics)  path planning  environment representation  terrain modeling  graph edge expansions  optimization-based terrain analysis  unmanned ground vehicle  hierarchical model  local terrain map  graph search algorithms  vertex positions  compact data structure  space-dividing tree  environment model  rough environments  real-time optimization-based approach  unstructured environments  autonomous ground vehicle navigation  Optimization  Path planning  Planning  Data structures  Collision avoidance  Navigation  Robots 
Abstract: Accurate environment representation is one of the key challenges in autonomous ground vehicle navigation in unstructured environments. We propose a real-time optimization-based approach to terrain modeling and path planning in off-road and rough environments. Our method uses an irregular, hierarchical, graph-like environment model. A space-dividing tree is used to define a compact data structure capturing vertex positions and establishing connectivity. The same unique underlying data structure is used for both terrain modeling and path planning without memory reallocation. Local plans are generated by graph search algorithms and are continuously regenerated for on-the-fly obstacle avoidance inside the scope of the local terrain map. We show that implementing a hierarchical model over a regular space division reduces graph edge expansions by up to 84%. We illustrate the applicability of the method through experiments with an unmanned ground vehicle in both structured and unstructured environments.


Title: Pedestrian Dominance Modeling for Socially-Aware Robot Navigation
Key Words: collision avoidance  human-robot interaction  mobile robots  socially-aware robot navigation  dominance characteristics  PDM models  perceived dominance levels  dominance-based collision-avoidance  pedestrian dominance model  robot navigation  autonomous vehicle navigation  Robots  Navigation  Trajectory  Psychology  Computational modeling  Prediction algorithms  Collision avoidance 
Abstract: We present a Pedestrian Dominance Model (PDM) to identify the dominance characteristics of pedestrians for robot navigation. Through a perception study on a simulated dataset of pedestrians, PDM models the perceived dominance levels of pedestrians with varying motion behaviors corresponding to trajectory, speed, and personal space. At runtime, we use PDM to identify the dominance levels of pedestrians to facilitate socially-aware navigation for the robots. PDM can predict dominance levels from trajectories with ~85% accuracy. Prior studies in psychology literature indicate that when interacting with humans, people are more comfortable around people that exhibit complementary movement behaviors. Our algorithm leverages this by enabling the robots to exhibit complementing responses to pedestrian dominance. We also present an application of PDM for generating dominance-based collision-avoidance behaviors in the navigation of autonomous vehicles among pedestrians. We demonstrate the benefits of our algorithm for robots navigating among tens of pedestrians in simulated environments.


Title: Dynamic Traffic Scene Classification with Space-Time Coherence
Key Words: feature extraction  image classification  image motion analysis  object detection  road safety  road traffic  road vehicles  traffic engineering computing  video signal processing  space-time variations  dynamic traffic scene classification  road scenes  space-time coherence  San Francisco Bay area  semantic context  feature extraction  tactical driver behavior understanding  driving behavior detection  vehicle ego-motion  time 80.0 hour  Roads  Meteorology  Vehicle dynamics  Semantics  Heuristic algorithms  Task analysis  Cameras 
Abstract: This paper examines the problem of dynamic traffic scene classification under space-time variations in viewpoint that arise from video captured on-board a moving vehicle. Solutions to this problem are important for realization of effective driving assistance technologies required to interpret or predict road user behavior. Currently, dynamic traffic scene classification has not been adequately addressed due to a lack of benchmark datasets that consider spatiotemporal evolution of traffic scenes resulting from a vehicle's ego-motion. This paper has three main contributions. First, an annotated dataset is released to enable dynamic scene classification that includes 80 hours of diverse high quality driving video data clips collected in the San Francisco Bay area. The dataset includes temporal annotations for road places, road types, weather, and road surface conditions. Second, we introduce novel and baseline algorithms that utilize semantic context and temporal nature of the dataset for dynamic classification of road scenes. Finally, we showcase algorithms and experimental results that highlight how extracted features from scene classification serve as strong priors and help with tactical driver behavior understanding. The results show significant improvement from previously reported driving behavior detection baselines in the literature.


Title: Towards the Design of Robotic Drivers for Full-Scale Self-Driving Racing Cars
Key Words: automobiles  control system synthesis  mobile robots  nonlinear control systems  path planning  predictive control  full-scale self-driving racing cars  autonomous vehicles  planning  control methods  autonomous racing cars  electric full scale autonomous racing car  control system architecture  localization methods  nonlinear model predictive control  pre-planned racing line  robotic driver design  Automobiles  Planning  Real-time systems  Computer architecture  Optimization  Vehicle dynamics 
Abstract: Autonomous vehicles are undergoing a rapid development thanks to advances in perception, planning and control methods and technologies achieved in the last two decades. Moreover, the lowering costs of sensors and computing platforms are attracting industrial entities, empowering the integration and development of innovative solutions for civilian use. Still, the development of autonomous racing cars has been confined mainly to laboratory studies and small to middle scale vehicles. This paper tackles the development of a planning and control framework for an electric full scale autonomous racing car, which is an absolute novelty in the literature, upon which we report our preliminary experiments and perspectives on future work. Our system leverages real time Nonlinear Model Predictive Control to track a pre-planned racing line. We describe the whole control system architecture including the mapping and localization methods employed.


Title: Model-free Online Motion Adaptation for Optimal Range and Endurance of Multicopters
Key Words: adaptive control  aerodynamics  autonomous aerial vehicles  helicopters  motion control  optimal control  path planning  position control  quadcopter  on-board power measurement  power consumption  energy-efficient loitering strategy  model-free online motion adaptation  extremum seeking control  aerodynamic disturbances  Power demand  Aerodynamics  Payloads  Propellers  Robots  Batteries  Adaptation models 
Abstract: In this work we introduce an approach that allows a quadcopter to find the velocity which maximizes its flight time (endurance) or flight distance (range) while moving along a given path, using on-board power measurement. The proposed strategy is based on Extremum Seeking control and (a) does not require any model of the power consumption of the system, (b) can be executed on-line, and (c) guarantees adaptation to unknown disturbances. We show experimentally that hovering is not the most energy-efficient loitering strategy, and we demonstrate the proposed method's ability to adapt to different aerodynamic disturbances, such as payloads. The method may be especially useful in applications where a quadcopter carries an unknown payload, allowing it to adapt for improved range.


Title: Multi-view Reconstruction of Wires using a Catenary Model
Key Words: autonomous aerial vehicles  cameras  extrapolation  image reconstruction  image segmentation  inspection  object detection  power cables  power engineering computing  robot vision  stereo image processing  multiview reconstruction  catenary model  UAV community  wire avoidance capabilities  powerline corridor inspection  multiview algorithm  catenary curve  partial wire detections  bundle-adjustment approaches  binarized wire segmentation images  approximate extrapolation  Wires  Image reconstruction  Three-dimensional displays  Cameras  Transforms  Computational modeling  Atmospheric modeling 
Abstract: Reliable detection and reconstruction of wires is one of the hardest problems in the UAV community, with a wide ranging impact in the industry in terms of wire avoidance capabilities and powerline corridor inspection. In this work, we introduce a real-time, model-based, multi-view algorithm to reconstruct wires from a set of images with known camera poses, while exploiting their natural shape - the catenary curve. Using a model-based approach helps us deal with partial wire detections in images, which may occur due to natural occlusion and false negatives. In addition, using a parsimonious model makes our algorithm efficient as we only need to optimize for 5 model parameters, as opposed to hundreds of 3D points in bundle-adjustment approaches. Our algorithm obviates the need for pixel correspondences by computing the reprojection error via the distance transform of binarized wire segmentation images. Further, we make our algorithm robust to arbitrary initializations by introducing an on-demand, approximate extrapolation of the distance transform based objective. We demonstrate the effectiveness of our algorithm against false negatives and random initializations in simulation, and show qualitative results with real data collected from a small UAV.


Title: Real-time Optimal Planning and Model Predictive Control of a Multi-rotor with a Suspended Load
Key Words: aerospace robotics  collision avoidance  convex programming  helicopters  mobile robots  nonlinear control systems  path planning  predictive control  high-dimensional nonlinear system  differential flatness property  nonconvex constraints  convex optimization problem  optimal trajectory  semifeasible trajectory  model predictive control  suspended load  control algorithms  multirotor dynamics  real-time trajectory generation  collision-free trajectories  collision-free trajectory  dynamic coupling  real-time optimal planning  concave obstacle-avoidance constraints  sequential linear quadratic solver  Trajectory  Real-time systems  Planning  Convex functions  Vehicle dynamics  Nonlinear dynamical systems  Load modeling 
Abstract: This paper presents planning and control algorithms for a multi-rotor with a suspended load. The suspended load cannot be controlled easily by the multi-rotor due to severe dynamic coupling between them. Difficulties are exacerbated by under-actuated, highly nonlinear nature of multi-rotor dynamics. Although many studies have been proposed to plan trajectories and control this system, there exist only a few reports on real-time trajectory generation. With this in mind, we propose a planning method which is capable of generating collision-free trajectories real-time and applicable to a high-dimensional nonlinear system. Using a differential flatness property, the system can be linearized entirely with elaborately chosen flat outputs. Convexification of non-convex constraints is carried out, and concave obstacle-avoidance constraints are converted to convex ones. After that, a convex optimization problem is solved to generate an optimal trajectory, but semi-feasible trajectory which considers only some parts of the initial state. We apply model predictive control with a sequential linear quadratic solver to compute a feasible collision-free trajectory and to control the system. Performance of the algorithm is validated by flight experiment.


Title: Bioinspired Direct Visual Estimation of Attitude Rates with Very Low Resolution Images using Deep Networks
Key Words: autonomous aerial vehicles  cameras  data visualisation  image resolution  image sensors  learning (artificial intelligence)  mobile robots  neural nets  robot vision  light source direction  artificial neural networks  deep networks  bioinspired visual system sensor  low resolution images  attitude rates  bioinspired direct visual estimation  source code  classical computer vision based method  learning approach  low resolution cameras  Drosophila's ocellar system  hardware setup  UAV  unmanned aerial vehicles  angular rates  Cameras  Robot sensing systems  Visualization  Estimation  Neural networks  Computer vision  Image resolution 
Abstract: In this work we present a bioinspired visual system sensor to estimate angular rates in unmanned aerial vehicles (UAV) using Neural Networks. We have conceived a hardware setup to emulate Drosophila's ocellar system, three simple eyes related to stabilization. This device is composed of three low resolution cameras with a similar spatial configuration as the ocelli. There have been previous approaches based on this ocellar system, most of them considering assumptions such as known light source direction or a punctual light source. In contrast, here we present a learning approach using Artificial Neural Networks in order to recover the system's angular rates indoors and outdoors without previous knowledge. A classical computer vision based method is also derived to be used as a benchmark for the learning approach. The method is validated with a large dataset of images (more than half a million samples) including synthetic and real data. The source code of the algorithms and the datasets used in this paper have been released in an open repository.


Title: Automatic Real-time Anomaly Detection for Autonomous Aerial Vehicles
Key Words: actuators  aerospace components  aerospace simulation  aircraft testing  autonomous aerial vehicles  fault diagnosis  fault tolerant control  least squares approximations  mobile robots  recursive least squares method  anomaly detection method  aircraft model  fault detection research  fixed-wing flights  ground truth  mid-flight actuator failures  fault detection open dataset  autonomous aircraft  correlated input-output pairs  autonomous aerial vehicles  Aircraft  Atmospheric modeling  Fault detection  Actuators  Reliability  Computational modeling  Safety 
Abstract: The recent increase in the use of aerial vehicles raises concerns about the safety and reliability of autonomous operations. There is a growing need for methods to monitor the status of these aircraft and report any faults and anomalies to the safety pilot or to the autopilot to deal with the emergency situation. In this paper, we present a real-time approach using the Recursive Least Squares method to detect anomalies in the behavior of an aircraft. The method models the relationship between correlated input-output pairs online and uses the model to detect the anomalies. The result is an easy-to-deploy anomaly detection method that does not assume a specific aircraft model and can detect many types of faults and anomalies in a wide range of autonomous aircraft. The experiments on this method show a precision of 88.23%, recall of 88.23% and 86.36% accuracy for over 22 flight tests. The other contribution is providing a new fault detection open dataset for autonomous aircraft, which contains complete data and the ground truth for 22 fixed-wing flights with eight different types of mid-flight actuator failures to help future fault detection research for aircraft.


Title: Finding divers with SCUBANet
Key Words: autonomous underwater vehicles  convolutional neural nets  gesture recognition  human-robot interaction  learning (artificial intelligence)  mobile robots  robot vision  diver-diver communication  diver-robot communication  underwater detection dataset  standard diver gestures  diver recognition  diver body-head-hand localization  CNN-based approach  SCUBANet dataset  human-robot communication  diver component recognition  robot-diver communication  human operators  divers finding  RF signal attenuation  gesture visual recognition  per-instance bounding boxes  crowd sourcing  transfer learning  Web-based interface  Standards  Training  Object detection  Robot sensing systems  Computer vision  Human-robot interaction  computer vision  object detection  dataset  underwater  robotics 
Abstract: Robot-diver communication underwater is complicated by the attenuation of RF signals, the complexities of the environment in terms of deploying interaction devices, and issues related to the cognitive loading of human operators. Humans operating underwater have developed a simple yet effective strategy for diver-diver communication based on the visual recognition of gestures. Can a similar approach be effective for diver-robot communication? Here we present experiments with SCUBANet, an underwater detection dataset of body parts associated with diver-robot communication. Given the nature of standard diver gestures, here we concentrate on diver recognition and in particular on diver body-head-hand localization and examine the feasibility of using a CNN-based approach to address this problem. Such data-driven approaches typically require an appropriately annotated dataset. The SCUBANet dataset contains images of object classes commonly encountered during human-robot communication underwater. Object classes are labeled using per-instance bounding boxes. Annotations were created through crowd sourcing via a web-based interface to ease deployment. We provide baseline performance on diver and diver component recognition and localization using transfer learning on three widely available pre-trained models.


Title: Robotic Detection of Marine Litter Using Deep Visual Detection Models
Key Words: autonomous underwater vehicles  convolutional neural nets  learning (artificial intelligence)  marine engineering  marine pollution  mobile robots  neural net architecture  object detection  robotic detection  marine litter  deep visual detection models  trash deposits  aquatic environments  marine ecosystems  autonomous underwater vehicles  AUV  deep-learning algorithms  convolutional neural network architectures  object detection  trained networks  underwater trash removal  Plastics  Training  Oceans  Data models  Object detection  Visualization  Biological system modeling 
Abstract: Trash deposits in aquatic environments have a destructive effect on marine ecosystems and pose a long-term economic and environmental threat. Autonomous underwater vehicles (AUVs) could very well contribute to the solution of this problem by finding and eventually removing trash. This paper evaluates a number of deep-learning algorithms performing the task of visually detecting trash in realistic underwater environments, with the eventual goal of exploration, mapping, and extraction of such debris by using AUVs. A large and publicly-available dataset of actual debris in open-water locations is annotated for training a number of convolutional neural network architectures for object detection. The trained networks are then evaluated on a set of images from other portions of that dataset, providing insight into approaches for developing the detection capabilities of an AUV for underwater trash removal. In addition, the evaluation is performed on three different platforms of varying processing power, which serves to assess these algorithms' fitness for real-time applications.


Title: A Dual-Bladder Buoyancy Engine for a Cephalopod-Inspired AUV
Key Words: actuators  asymptotic stability  autonomous underwater vehicles  feedback  flow sensors  gears  Lyapunov methods  mobile robots  nonlinear control systems  pressure measurement  pressure sensors  pumps  remotely operated vehicles  robot dynamics  dual-bladder buoyancy engine  cephalopod-inspired AUV  nonlinear depth  backstepping depth  pitch controller  flow-rate feedback  custom flow sensor  differential pressure sensor  3D-printed attachment  depth control capability  single-bladder buoyancy engine  depth controller  autonomous underwater vehicle  Buoyancy  Engines  Bladder  Backstepping  Force  Vehicle dynamics  Pressure sensors 
Abstract: This paper presents a nonlinear, backstepping depth and pitch controller for a dual-bladder buoyancy engine actuated by gear pumps. Flow-rate feedback is obtained using a custom flow sensor comprised of a differential pressure sensor and a small, 3D-printed attachment. The controller is simulated using a model of the CephaloBot, our in-house developed autonomous underwater vehicle (AUV). Its depth control capability is also experimentally validated using a single-bladder buoyancy engine on-board a smaller-scale test cylinder. Lyapunov stability analysis shows global, asymptotic stability, which is exhibited in our simulation. Our experiments verify that this buoyancy engine is a feasible and effective depth controller for AUVs.


Title: Real-time Model Based Path Planning for Wheeled Vehicles
Key Words: electric vehicles  image colour analysis  image sensors  mobile robots  path planning  pose estimation  road safety  road vehicles  robot vision  search problems  wheels  model based traversability analysis method  complex environments  vehicles 3D pose  chassis collision  elevation map  reactive planning  safe paths  wheeled mobile robots  real world environment setups  real-time model  real-time path planning  simulated world environment setups  wheeled vehicles  vehicle model  scoring function  A*-like search strategy  RGB-D sensor  frequency 30.0 Hz  Wheels  Path planning  Robot sensing systems  Planning  Mobile robots  Real-time systems 
Abstract: This work presents a model based traversability analysis method which employs a detailed vehicle model to perform real-time path planning in complex environments. The vehicle model represents the vehicle's wheels and chassis, allowing it to accurately predict the vehicles 3D pose, detailed contact information for each wheel and the occurrence of a chassis collision given a 2D pose on an elevation map. These predictions are weighted, depending on the safety requirements of the vehicle, to provide a scoring function for an A*-like search strategy. The proposed method is designed to run at frame rates of 30Hz on data from a RGB-D sensor to provide reactive planning of safe paths. For evaluation, two wheeled mobile robots in different simulated and real world environment setups were tested to show the reliability and performance of the proposed method.


Title: What lies in the shadows? Safe and computation-aware motion planning for autonomous vehicles using intent-aware dynamic shadow regions
Key Words: inference mechanisms  mobile robots  path planning  road safety  road vehicles  sensor fusion  autonomous driving safety  inference planning  passive safety  sensor observations  intent-aware dynamic shadow regions  computation-aware motion planning  driving behaviour  autonomous vehicle  Robot sensing systems  Planning  Safety  Automobiles  Autonomous vehicles  Trajectory 
Abstract: One of the challenges of developing autonomous vehicles is planning in an inhabited environment under sensing uncertainty as well as limited perception and computational resources. Besides reasoning about the behaviour of traffic participants that are within the vehicles' field of view, safe autonomous driving also requires the vehicle to reason about possible traffic participants that might exist beyond its sensing horizon, and to adapt its driving behaviour accordingly. This paper describes an inference and motion planning pipeline that is able to guarantee passive safety (collisions are possible, but the autonomous vehicle will be at rest) with respect to hypothetical hidden agents that have not been observed yet. We also incorporate the vehicle's reaction time due to sensing and computational delays into the planning process; for example, we show how having a fast reaction time due to the availability of more computational resources leads to more aggressive trajectories, while a car with a larger reaction time will choose more relaxed trajectories that require less attention.


Title: Dynamic Risk Density for Autonomous Navigation in Cluttered Environments without Object Detection
Key Words: collision avoidance  handicapped aids  object detection  path planning  wheelchairs  dynamic risk density  congestion density  cost function  occupancy risk  velocity fields  object-based congestion cost  cluttered environments  autonomous navigation  object detection  object tracking  autonomous wheelchair  Navigation  Cost function  Wheelchairs  Dynamics  Vehicle dynamics  Planning  Level set 
Abstract: In this paper, we examine the problem of navigating cluttered environments without explicit object detection and tracking. We introduce the dynamic risk density to map the congestion density and spatial flow of the environment to a cost function for the agent to determine risk when navigating that environment. We build upon our prior work, wherein the agent maps the density and motion of objects to an occupancy risk, then navigate the environment over a specified risk level set. Here, the agent does not need to identify objects to compute the occupancy risk, and instead computes this cost function using the occupancy density and velocity fields around them. Simulations show how this dynamic risk density encodes movement information for the ego agent and closely models the object-based congestion cost. We implement our dynamic risk density on an autonomous wheelchair and show how it can be used for navigating unstructured, crowded and cluttered environments.


Title: DFNet: Semantic Segmentation on Panoramic Images with Dynamic Loss Weights and Residual Fusion Block
Key Words: feature extraction  image fusion  image segmentation  neural nets  object detection  roads  traffic engineering computing  visual perception  sight images  DFNet  dynamic loss weights  fusion layer  boundary information loss  semantic segmentation  automatic parking  lane markings  parking slots  pavement information  pixel multiplication  PSV dataset  residual fusion block  RFB  Image segmentation  Semantics  Feature extraction  Deep learning  Convolution  Training  Vehicle dynamics 
Abstract: For the domain of self-driving and automatic parking, perception is a basic and critical technique, moreover, the detection of lane markings and parking slots is an important part of visual perception. Compared with front sight images, panoramic images(PI) can capture more comprehensive pavement information. However, the imbalance of different classes in PI is even more serious. Additionally, the judgment of boundary information between areas is a hard problem in deep models. Therefore, we propose a new model named DFNet to solve these problems. The proposed model has two main contributions, one is dynamic loss weights, and the other is residual fusion block(RFB). DFNet use dynamic loss weights to overcome the negative effect of imbalance dataset, which are calculated according to the pixel number of each class in a batch. RFB is composed of several convolutional layers, a pooling layer, and a fusion layer to combine the feature maps by pixel multiplication, which can reduce boundary information loss. We evaluate our method on PSV dataset, and the achieved advanced results demonstrate the effectiveness of the proposed model.


Title: Improved Generalization of Heading Direction Estimation for Aerial Filming Using Semi-Supervised Regression
Key Words: autonomous aerial vehicles  cinematography  image sequences  regression analysis  robot vision  unsupervised learning  video signal processing  improved generalization  semisupervised regression  visual input  data distributions  semisupervised algorithm  generalization ability  autonomous aerial filming  heading direction estimation problem  temporal continuity  unsupervised signal  testing performance  unlabeled sequences  performance improvement  labeled loss  unlabeled loss  moving actor filming  Task analysis  Drones  Training  Estimation  Data models  Cameras  Feature extraction 
Abstract: In the task of Autonomous aerial filming of a moving actor (e.g. a person or a vehicle), it is crucial to have a good heading direction estimation for the actor from the visual input. However, the models obtained in other similar tasks, such as pedestrian collision risk analysis and human-robot interaction, are very difficult to generalize to the aerial filming task, because of the difference in data distributions. Towards improving generalization with less amount of labeled data, this paper presents a semi-supervised algorithm for heading direction estimation problem. We utilize temporal continuity as the unsupervised signal to regularize the model and achieve better generalization ability. This semi-supervised algorithm is applied to both training and testing phases, which increases the testing performance by a large margin. We show that by leveraging unlabeled sequences, the amount of labeled data required can be significantly reduced. We also discuss several important details on improving the performance by balancing labeled and unlabeled loss, and making good combinations. Experimental results show that our approach robustly outputs the heading direction for different types of actor. The aesthetic value of the video is also improved in the aerial filming task.


Title: Simulated Annealing-optimized Trajectory Planning within Non-Collision Nominal Intervals for Highway Autonomous Driving
Key Words: acceleration control  collision avoidance  mobile robots  predictive control  road traffic control  simulated annealing  time-varying systems  trajectory control  sigmoid trajectory  collision-free intervals  nominal conditions  velocity-space representation  highway autonomous driving  near-optimal trajectory generation  autonomous vehicles  highways  predictive reference trajectory  free evolution space  pre-calculated set  candidate trajectories  decoupling path  velocity optimizations  multicriteria functions  decision evaluation function  trajectory generator  simulated annealing approach  noncollision nominal intervals  simulated annealing-optimized trajectory planning  Trajectory  Roads  Acceleration  Vehicle dynamics  Autonomous vehicles  Decision making 
Abstract: This article considers the problem of near-optimal trajectory generation for autonomous vehicles on highways. The goal is to select a predictive reference trajectory in the free evolution space, while avoiding both generating a pre-calculated set of candidate trajectories and decoupling path and velocity optimizations. Moreover, this trajectory aims at optimizing a decision process based on multi-criteria functions, which are not straightforward to design and can have a blackbox formulation. The main idea of this article is to use the decision evaluation function in the trajectory generator with a Simulated Annealing (SA) approach. The parameters of a sigmoid trajectory are optimized within Non-Collision Nominal Intervals (NCNI), which are defined as collision-free intervals under nominal conditions using a velocity-space representation.


Title: Localization with Sliding Window Factor Graphs on Third-Party Maps for Automated Driving
Key Words: optimisation  particle filtering (numerical methods)  pose estimation  position measurement  window factor graphs  third-party maps  robotic applications  window optimization  odometry measurements  fast vehicle localization  accurate vehicle localization  estimation problem  sliding window formulation  factor graph  landmark detections  automated car  automated driving applications  Microsoft Windows  Optimization  Simultaneous localization and mapping  Global navigation satellite system  Laser radar  Measurement uncertainty 
Abstract: Localizing a vehicle in a map is essential for automated driving and various other robotic applications. This paper addresses the problem of vehicle localization in urban environments. Our approach performs a graph-based sliding window optimization over a set of recent landmark and odometry measurements for fast and accurate vehicle localization on third-party maps. Our work incorporates landmark priors from third-party maps into the estimation problem and shows how to exploit the sliding window formulation for revising data associations. We describe how to construct our factor graph and derive its necessary factors to model the information from the map as a prior over the landmark detections. We implemented our approach on an automated car and thoroughly tested it on real-world data. The experiments suggest that the approach provides highly accurate pose estimates, is fast enough for automated driving applications, and outperforms localization using particle filters.


Title: Efficient 2D-3D Matching for Multi-Camera Visual Localization
Key Words: cameras  distance measurement  feature extraction  image matching  motion estimation  pose estimation  autonomous driving  multicamera visual inertial localization algorithm  prioritized feature matching scheme  multicamera systems  monocular cameras  prioritization function  multicamera setup  matching efforts  pose priors  localization system  motion estimates  multicamera visual inertial odometry pipeline  large scale environments  pose estimation stages  pre-built global 3D map  Cameras  Three-dimensional displays  Pose estimation  Visualization  Feature extraction  Pipelines  Reliability 
Abstract: Visual localization, i.e., determining the position and orientation of a vehicle with respect to a map, is a key problem in autonomous driving. We present a multi-camera visual inertial localization algorithm for large scale environments. To efficiently and effectively match features against a pre-built global 3D map, we propose a prioritized feature matching scheme for multi-camera systems. In contrast to existing works, designed for monocular cameras, we (1) tailor the prioritization function to the multi-camera setup and (2) run feature matching and pose estimation in parallel. This significantly accelerates the matching and pose estimation stages and allows us to dynamically adapt the matching efforts based on the surrounding environment. In addition, we show how pose priors can be integrated into the localization system to increase efficiency and robustness. Finally, we extend our algorithm by fusing the absolute pose estimates with motion estimates from a multi-camera visual inertial odometry pipeline (VIO). This results in a system that provides reliable and drift-less pose estimation. Extensive experiments show that our localization runs fast and robust under varying conditions, and that our extended algorithm enables reliable real-time pose estimation.


Title: Generalization through Simulation: Integrating Simulated and Real Data into Deep Reinforcement Learning for Vision-Based Autonomous Flight
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  data analysis  helicopters  learning (artificial intelligence)  mobile robots  robot vision  vision-based autonomous flight  fragile scale quadrotors  small-scale quadrotors  complex physics  air currents  hybrid deep reinforcement learning algorithm  generalizable perception system  nanoaerial vehicle collision avoidance task  real data  simulated data  Data models  Robots  Task analysis  Predictive models  Neural networks  Reinforcement learning  Collision avoidance 
Abstract: Deep reinforcement learning provides a promising approach for vision-based control of real-world robots. However, the generalization of such models depends critically on the quantity and variety of data available for training. This data can be difficult to obtain for some types of robotic systems, such as fragile, small-scale quadrotors. Simulated rendering and physics can provide for much larger datasets, but such data is inherently of lower quality: many of the phenomena that make the real-world autonomous flight problem challenging, such as complex physics and air currents, are modeled poorly or not at all, and the systematic differences between simulation and the real world are typically impossible to eliminate. In this work, we investigate how data from both simulation and the real world can be combined in a hybrid deep reinforcement learning algorithm. Our method uses real-world data to learn about the dynamics of the system, and simulated data to learn a generalizable perception system that can enable the robot to avoid collisions using only a monocular camera. We demonstrate our approach on a real-world nano aerial vehicle collision avoidance task, showing that with only an hour of real-world data, the quadrotor can avoid collisions in new environments with various lighting conditions and geometry. Code, instructions for building the aerial vehicles, and videos of the experiments can be found at github.com/gkahn13/GtS.


Title: A Reinforcement Learning Approach for Control of a Nature-Inspired Aerial Vehicle
Key Words: autonomous aerial vehicles  function approximation  gradient methods  learning (artificial intelligence)  neural nets  position control  three-term control  nature-inspired aerial vehicle  position controller  UAV  fixed-wing aircraft  neural network function approximators  reinforcement learning agent  learned controller  deep deterministic policy gradients  PID controller  Ape-X distributed prioritized experience replay  multi-rotors  underactuated nature-inspired unmanned aerial vehicle  body contrary  Training  Aerodynamics  Neural networks  Mathematical model  Reinforcement learning  Drag  Prototypes 
Abstract: In this work, reinforcement learning is used to develop a position controller for an underactuated nature-inspired Unmanned Aerial Vehicle (UAV). This particular configuration of UAVs achieves lift by spinning its entire body contrary to standard multi-rotors or fixed-wing aircraft. Deep Deterministic Policy Gradients (DDPG) with Ape-X Distributed Prioritized Experience Replay was used to train neural network function approximators that were implemented as the final control policy. The reinforcement learning agent was trained in simulations and directly ported over to real-life hardware. Position control tests were performed on the learned control policy and compared to a baseline PID controller. The learned controller was found to exhibit better control over the inherent oscillations that arise from the non-linear dynamics of the platform.


Title: Real-Time Dense Mapping for Self-Driving Vehicles using Fisheye Cameras
Key Words: cameras  image capture  image fusion  image resolution  image sensors  mobile robots  object detection  robot vision  stereo image processing  visual perception  fisheye cameras  real-time dense geometric mapping algorithm  pinhole cameras  visual-inertial odometry  visual localization  vision-only 3D scene perception  depth map  reference camera  plane-sweeping stereo  fast object detection framework  YOLOv3  fisheye depth images  computer vision applications  angular resolution  image resolutions  in-vehicle PC  truncated signed distance function  TSDF volume  3D map  self-driving vehicles  Cameras  Three-dimensional displays  Real-time systems  Image resolution  Vehicle dynamics  Estimation  Object detection 
Abstract: We present a real-time dense geometric mapping algorithm for large-scale environments. Unlike existing methods which use pinhole cameras, our implementation is based on fisheye cameras whose large field of view benefits various computer vision applications for self-driving vehicles such as visual-inertial odometry, visual localization, and object detection. Our algorithm runs on in-vehicle PCs at approximately 15 Hz, enabling vision-only 3D scene perception for self-driving vehicles. For each synchronized set of images captured by multiple cameras, we first compute a depth map for a reference camera using plane-sweeping stereo. To maintain both accuracy and efficiency, while accounting for the fact that fisheye images have a lower angular resolution, we recover the depths using multiple image resolutions. We adopt the fast object detection framework, YOLOv3, to remove potentially dynamic objects. At the end of the pipeline, we fuse the fisheye depth images into the truncated signed distance function (TSDF) volume to obtain a 3D map. We evaluate our method on large-scale urban datasets, and results show that our method works well in complex dynamic environments.


Title: FastDepth: Fast Monocular Depth Estimation on Embedded Systems
Key Words: autonomous aerial vehicles  cameras  computational complexity  embedded systems  estimation theory  image colour analysis  image segmentation  image sensors  learning (artificial intelligence)  microrobots  mobile robots  neural nets  object detection  robot vision  low-latency decoder  NYU Depth v2 dataset  real-time monocular depth estimation  deep neural network  embedded platform  microaerial vehicle  embedded systems  robotic tasks  obstacle detection  single RGB image  monocular cameras  lightweight encoder-decoder network architecture  computational complexity  FastDepth  fast monocular depth estimation  depth sensing  deep neural networks  Estimation  Decoding  Neural networks  Runtime  Convolution  Complexity theory  Task analysis 
Abstract: Depth sensing is a critical function for robotic tasks such as localization, mapping and obstacle detection. There has been a significant and growing interest in depth estimation from a single RGB image, due to the relatively low cost and size of monocular cameras. However, state-of-the-art single-view depth estimation algorithms are based on fairly complex deep neural networks that are too slow for real-time inference on an embedded platform, for instance, mounted on a micro aerial vehicle. In this paper, we address the problem of fast depth estimation on embedded systems. We propose an efficient and lightweight encoder-decoder network architecture and apply network pruning to further reduce computational complexity and latency. In particular, we focus on the design of a low-latency decoder. Our methodology demonstrates that it is possible to achieve similar accuracy as prior work on depth estimation, but at inference speeds that are an order of magnitude faster. Our proposed network, FastDepth, runs at 178 fps on an NVIDIA Jetson TX2 GPU and at 27 fps when using only the TX2 CPU, with active power consumption under 10 W. FastDepth achieves close to state-of-the-art accuracy on the NYU Depth v2 dataset. To the best of the authors' knowledge, this paper demonstrates real-time monocular depth estimation using a deep neural network with the lowest latency and highest throughput on an embedded platform that can be carried by a micro aerial vehicle.


Title: Magnetic-Field-Inspired Navigation for Quadcopter Robot in Unknown Environments
Key Words: autonomous aerial vehicles  collision avoidance  control engineering computing  helicopters  mobile robots  navigation  robot vision  flying robots  local sensory information  quadcopter robot  magnetic-field-inspired robot navigation  under-actuated quad-copter  arbitrary-shaped convex obstacles  magnetic field interaction  reactive navigation algorithms  unknown environments  motion commands  local minima configurations  dynamic model  commercial AscTec Pelican microaerial vehicle  Collision avoidance  Robot sensing systems  Navigation  Wires  Force 
Abstract: In this paper, a magnetic-field-inspired robot navigation is used to navigate an under-actuated quad-copter towards the desired position amidst previously-unknown arbitrary-shaped convex obstacles. Taking inspiration from the phenomena of magnetic field interaction with charged particles observed in nature, the algorithm outperforms previous reactive navigation algorithms for flying robots found in the literature as it is able to reactively generate motion commands relying only on a local sensory information without prior knowledge of the obstacles' shape or location and without getting trapped in local minima configurations. The application of the algorithm in a dynamic model of quadcopter system and in the realistic model of the commercial AscTec Pelican micro-aerial vehicle confirm the superior performance of the algorithm.


Title: Energy Tank-Based Wrench/Impedance Control of a Fully-Actuated Hexarotor: A Geometric Port-Hamiltonian Approach
Key Words: autonomous aerial vehicles  control system synthesis  controllability  end effectors  feedback  force control  helicopters  mobile robots  nonlinear control systems  observers  stability  trajectory control  fully-actuated hexarotor  geometrically consistent manner  wrench observer  geometric port-Hamiltonian approach  aerial robot  port-Hamiltonian framework  special Euclidean group  UAV nonlinear geometric structure  energy tanks concept  contact stability  Unmanned aerial vehicles  Impedance  Robots  Springs  Propellers  Mathematical model  Observers 
Abstract: In this work, we show how the interactive behavior of an aerial robot can be modeled and controlled effectively and elegantly in the port-Hamiltonian framework. We present an observer-based wrench/impedance controller for a fully-actuated hexarotor. The analysis and control are performed in a geometrically consistent manner on the configuration manifold of the special Euclidean group SE (3) such that the UAV's nonlinear geometric structure is exploited. The controller uses a wrench observer to estimate the interaction wrench without the use of a force/torque sensor. Moreover, the concept of energy tanks is used to guarantee the system's overall contact stability to arbitrary passive environments. The reliability and robustness of the proposed approach is validated through simulation and experiment.


Title: Integral Backstepping Position Control for Quadrotors in Tunnel-Like Confined Environments
Key Words: aerodynamics  aerospace robotics  helicopters  Kalman filters  mechanical stability  mobile robots  pose estimation  position control  robot dynamics  robot vision  SLAM (robots)  tunnels  vision-based localisation  cross-sectional localisation system  integral backstepping controller  quadrotors  tunnel-like confined environments  integral backstepping position control  kinematic Kalman filter  semiautonomous system  flying robots  aerodynamic disturbances  Backstepping  Aerodynamics  Kinematics  Kalman filters  Navigation  Rail transportation  Sensors 
Abstract: There are many potential applications that require flying robots to navigate through tunnel-like environments, such as inspections of small railway culverts and mineral mappings of mining tunnels. Nevertheless, those environments present many challenges for quadrotors to navigate through. The aerodynamic disturbances created from the fluid interaction between the propellers' downwash and the surrounding surfaces of the environment, as well as longitudinal wind gusts, add hardship in stabilising the vehicle while the restricted narrow space increases the risk of collision. Furthermore, poor visibility and dust blown by the downwash make vision-based localisation extremely difficult. This paper presents a cross-sectional localisation system using Hough Scan Matching and a simple kinematic Kalman filter. Using the estimated state information, an integral backstepping controller is implemented which enables quadrotors to robustly fly in tunnel-like confined environments. A semi-autonomous system is proposed with self-stabilisation in the vertical and lateral axes while a pilot provides commands in the longitudinal direction. The results of a series of experiments in a simulated tunnel show that the proposed system successfully hovered itself and tracked various trajectories in a cross-sectional area without the aid of any external sensing or computing system.


Title: Control and Configuration Planning of an Aerial Cable Towed System
Key Words: autonomous aerial vehicles  cables (mechanical)  feedback  helicopters  linearisation techniques  manipulator dynamics  manipulator kinematics  manipulators  mobile robots  path planning  robust control  trajectory control  aerial cable towed system  robot configuration  kinematic models  centralized feedback linearization controller  optimal configurations  dynamic trajectories  ACTS  quadrotors manipulating  robustness  Payloads  Kinematics  Vehicle dynamics  Dynamics  Mathematical model  Trajectory  Propulsion  Aerial Systems  Multi-Robot Systems  Quadrotors  Control  Reconfiguration  Cable-Driven Parallel Robots 
Abstract: This paper investigates the effect of the robot configuration on the performance of an aerial cable towed system (ACTS) composed of three quadrotors manipulating a point mass payload. The kinematic and dynamic models of the ACTS are derived in a minimal set of geometric coordinates, and a centralized feedback linearization controller is developed. Independent to the payload trajectory, the configuration of the ACTS is controlled and is evaluated using a robustness index named the capacity margin. Experiments are performed with optimal, suboptimal, and wrench infeasible configurations. It is shown that configurations near the point of zero capacity margin allow the ACTS to hover but not to follow dynamic trajectories, and that the ACTS cannot fly with a negative capacity margin. Dynamic tests of the ACTS show the effects of the configuration on the achievable accelerations.


Title: Adaptive Control of Aerobatic Quadrotor Maneuvers in the Presence of Propeller-Aerodynamic-Coefficient and Torque-Latency Time-Variations
Key Words: adaptive control  aerodynamics  aerospace propulsion  aircraft control  autonomous aerial vehicles  control nonlinearities  control system synthesis  helicopters  least squares approximations  linear systems  momentum  time-varying systems  torque control  aerobatic flight  time-varying torque generation  propeller-aerodynamic-coefficient  torque-latency time-variations  momentum-theory-based analysis  dynamic linear time-varying description  flyer  backstepping controller  time-varying dynamics  aerobatic quadrotor  adaptive control  robot  LTV  recursive least-squares estimation  Pugachev's Cobras  triple flips  aerial vehicle  Rotors  Aerodynamics  Vehicle dynamics  Torque  Propellers  Analytical models  Robots 
Abstract: We present a study of the dynamics and control of a 28-gram quadrotor during the execution of aerobatic maneuvers in the presence of propeller-aerodynamic-coefficient and torque-latency time-variations. First, through a momentum-theory-based analysis of the flow field surrounding the robot during aerobatic flight, we develop a dynamic linear time-varying (LTV) description of the torque acting on the flyer in which both considered effects explicitly appear as distinct mathematical terms. Then, an adaptive control scheme, composed of a backstepping controller and a modified recursive least-squares (RLS) estimator, is designed to counteract the negative effects produced by the time-varying dynamics of the torque that drives the flyer. The suitability and efficacy of the proposed methods are demonstrated through real-time flight experiments in which the quadrotor autonomously performs three different types of aerobatic maneuvers: triple flips, Pugachev's Cobras and mixed flips. Furthermore, analyses of the experimental data compellingly show that the proposed control scheme consistently improves the performance of the aerial vehicle during aerobatic flight, compared to those achieved by using a high-performance linear time-invariant (LTI) controller that does not account for time-varying torque generation.


Title: Fast Terminal Sliding Mode Super Twisting Controller For Position And Altitude Tracking of the Quadrotor
Key Words: attitude control  autonomous aerial vehicles  closed loop systems  control system synthesis  helicopters  Lyapunov methods  nonlinear control systems  position control  stability  variable structure systems  fast terminal sliding mode super twisting controller  altitude tracking  nonlinear fast terminal sliding manifold  super twisting reaching law  quadrotor position  FTSMSTC design  chattering phenomena  Lyapunov stability theory  MATLAB simulation  DJI Matrice M100  complete closed loop system stability  Convergence  Manifolds  Attitude control  Stability analysis  Sliding mode control  Trajectory  Backstepping 
Abstract: This paper proposes a fast terminal sliding mode super twisting controller (FTSMSTC) design for quadrotor position and altitude tracking in the presence of bounded disturbances. A nonlinear fast terminal sliding manifold has been proposed for fast convergence of the tracking error to zero in finite time unlike the conventional sliding mode control (CSMC) that guarantee only asymptotic convergence of the tracking error. The super twisting reaching law has been proposed to deal with the chattering phenomena, which is inherent in the CSMC. The finite time stability of the complete closed loop system is investigated using Lyapunov stability theory and an analytical expression for the convergence time has also been derived. The effectiveness of the designed controller is checked against the CSMC using MATLAB simulation. The controller has been experimentally validated using the DJI Matrice M100 as a proof of utility in real time applications.


Title: Multirotor dynamics based online scale estimation for monocular SLAM
Key Words: autonomous aerial vehicles  cameras  helicopters  image sensors  Kalman filters  mobile robots  nonlinear filters  observability  robot vision  SLAM (robots)  observability  online scale estimation  extended Kalman filter framework  multirotor dynamics model  monocular camera  metric sensor  conventional scale estimation methods  monocular SLAM  monocular vision  Cameras  Observability  Drag  Estimation  Force  Mathematical model  Vehicle dynamics 
Abstract: This paper proposes a novel method to estimate the scale online for monocular SLAM. Unlike conventional scale estimation methods that require a metric sensor such as an IMU and apriori knowledge of its biases, this approach estimates the scale online by solely using the monocular camera and multirotor dynamics model in an extended Kalman Filter framework. Further, we discuss the observability of scale and theoretically show that the scale becomes observable when multirotor dynamics model and monocular vision are used in conjunction. We validate our proposition with extensive experimentation on the local as well as on the standard datasets and compare the same with other state of the art methods.


Title: Vision-based Control of a Quadrotor in User Proximity: Mediated vs End-to-End Learning Approaches
Key Words: autonomous aerial vehicles  helicopters  learning (artificial intelligence)  robot vision  state estimation  vision-based control  quadrotor  onboard camera  control signals  high-level state estimation  learning approaches  Task analysis  Drones  Robot sensing systems  Training  Cameras  Computer architecture 
Abstract: We consider the task of controlling a quadrotor to hover in front of a freely moving user, using input data from an onboard camera. On this specific task we compare two widespread learning paradigms: a mediated approach, which learns a high-level state from the input and then uses it for deriving control signals; and an end-to-end approach, which skips high-level state estimation altogether. We show that despite their fundamental difference, both approaches yield equivalent performance on this task. We finally qualitatively analyze the behavior of a quadrotor implementing such approaches.


Title: Parity-Based Diagnosis in UAVs: Detectability and Robustness Analyses
Key Words: autonomous aerial vehicles  fault diagnosis  particle swarm optimisation  robust control  real flight data  parity-based methodologies  parity-based diagnosis  particle swarm optimization  static residuals  robustness metrics  robustness analyses  detectability  nonlinear residual generators  fault diagnosis  UAV model  fault detection system  dynamic residuals  Mathematical model  Robustness  Generators  Measurement  Numerical models  Atmospheric modeling  Unmanned aerial vehicles 
Abstract: Parity-Based methodologies for fault diagnosis in UAVs often result in nonlinear residual generators. Still, a systematic framework to perform detectability and robustness analyses of residual generators does not exist. In this work, detectability and robustness metrics for static and dynamic residuals are presented, while numerical methods, specifically Particle Swarm Optimization, are employed to calculate them. The results are used to characterize the performance of a fault detection system. An application on a UAV model is shown, based on real flight data.


Title: Group Surfing: A Pedestrian-Based Approach to Sidewalk Robot Navigation
Key Words: collision avoidance  edge detection  human-robot interaction  mobile robots  navigation  pedestrians  traffic engineering computing  pedestrian-based approach  sidewalk robot navigation  mobile robots  pedestrian-rich sidewalk environments  pedestrian-shared space  indoor spaces  pedestrian movement  linear flows  opposing directions  pedestrians  random movements  safe navigation  sidewalk space  natural human motion  socially-compliant manner  group surfing method  optimal pedestrian group  pedestrian-sparse environments  sidewalk edge detection  following method  integrated navigation stack  Navigation  Collision avoidance  Robot kinematics  Roads  Legged locomotion 
Abstract: In this paper, we propose a novel navigation system for mobile robots in pedestrian-rich sidewalk environments. Sidewalks are unique in that the pedestrian-shared space has characteristics of both roads and indoor spaces. Like vehicles on roads, pedestrian movement often manifests as linear flows in opposing directions. On the other hand, pedestrians also form crowds and can exhibit much more random movements than vehicles. Classical algorithms are insufficient for safe navigation around pedestrians and remaining on the sidewalk space. Thus, our approach takes advantage of natural human motion to allow a robot to adapt to sidewalk navigation in a safe and socially-compliant manner. We developed a group surfing method which aims to imitate the optimal pedestrian group for bringing the robot closer to its goal. For pedestrian-sparse environments, we propose a sidewalk edge detection and following method. Underlying these two navigation methods, the collision avoidance scheme is human-aware. The integrated navigation stack is evaluated and demonstrated in simulation. A hardware demonstration is also presented.


Title: Build your own hybrid thermal/EO camera for autonomous vehicle
Key Words: cameras  image colour analysis  image motion analysis  image registration  image resolution  image sensors  image sequences  object detection  remotely operated vehicles  single hybrid camera  hybrid camera array  disparity images  spatial-alignment  autonomous vehicle  thermal RGB frames  thermal EO cameras  pixel-wise spatial registration  visible-light camera  hybrid thermal/EO camera  RGB frames  constant homography warping  image modalities  Cameras  Layout  Technological innovation  Tuners  Optical sensors  Autonomous vehicles 
Abstract: In this work, we propose a novel paradigm to design a hybrid thermal/EO (Electro-Optical or visible-light) camera, whose thermal and RGB frames are pixel-wisely aligned and temporally synchronized. Compared with the existing schemes, we innovate in three ways in order to make it more compact in dimension, and thus more practical and extendable for real-world applications. The first is a redesign of the structure layout of the thermal and EO cameras. The second is on obtaining a pixel-wise spatial registration of the thermal and RGB frames by a coarse mechanical adjustment and a fine alignment through a constant homography warping. The third innovation is on extending one single hybrid camera to a hybrid camera array, through which we can obtain wide-view spatially aligned thermal, RGB and disparity images simultaneously. The experimental results show that the average error of spatial-alignment of two image modalities can be less than one pixel.


Title: Redundant Perception and State Estimation for Reliable Autonomous Racing
Key Words: automobiles  driver information systems  image colour analysis  learning (artificial intelligence)  particle filtering (numerical methods)  pose estimation  SLAM (robots)  state estimation  vehicle dynamics  reliable autonomous racing  sensor failure  critical consequences  state estimation approaches  autonomous race car  track delimiting objects  sensor modalities  learning-based approaches  camera data  redundant perception inputs  probabilistic failure detection algorithm  real-world racing conditions  slip dynamics  particle filter based SLAM algorithm  pose estimates  velocity 90.0 km/h  Robot sensing systems  Cameras  Three-dimensional displays  Automobiles  Image color analysis  Laser radar  Reliability 
Abstract: In autonomous racing, vehicles operate close to the limits of handling and a sensor failure can have critical consequences. To limit the impact of such failures, this paper presents the redundant perception and state estimation approaches developed for an autonomous race car. Redundancy in perception is achieved by estimating the color and position of the track delimiting objects using two sensor modalities independently. Specifically, learning-based approaches are used to generate color and pose estimates, from LiDAR and camera data respectively. The redundant perception inputs are fused by a particle filter based SLAM algorithm that operates in real-time. Velocity is estimated using slip dynamics, with reliability being ensured through a probabilistic failure detection algorithm. The sub-modules are extensively evaluated in real-world racing conditions using the autonomous race car gotthard driverless, achieving lateral accelerations up to 1. 7G and a top speed of 90km/h.


Title: Steering Co-centered and Co-directional Optical and Acoustic Beams with a Water-immersible MEMS Scanning Mirror for Underwater Ranging and Communication*
Key Words: beam steering  integrated optics  laser beams  laser ranging  micromechanical devices  micromirrors  microsensors  optical communication equipment  photodetectors  remotely operated vehicles  underwater optics  underwater vehicles  Hall effect  reception modes  transmission modes  underwater ranging and communication  steering co-directional optical beams  steering co-directional acoustic beams  steering co-centered laser beams  steering co-centered ultrasonic beams  steering co-directional ultrasonic beams  steering co-directional laser beams  steering co-centered acoustic beams  steering co-centered optical beams  bi-modal communication  scan position sensors  ultrasound beams  water-immersible MEMS scanning mirror  Laser beams  Ultrasonic imaging  Mirrors  Acoustic beams  Optical beams  Optical sensors 
Abstract: This paper reports the development of a compact optical-acoustic frontend module for underwater communication and ranging. The module is enabled by a new water-immersible MEMS scanning mirror (WIMSM). It is capable of transmitting, receiving and steering co-centered and co-directional laser and ultrasound beams under water. To monitor its rotating angle in real time, scan position sensors based on Hall effect have been integrated into the WIMSM. The angular alignment of the laser and ultrasound beams in both transmission and reception modes has been examined. The experimental results show that the laser and ultrasound beams can remain aligned with less than 2.1 degrees under envelope of pan and tilt rotations. This capability is critical for the continuing development of the new bi-modal communication and ranging underwater Vehicles (AUVs).


Title: Uncertainty Estimation for Projecting Lidar Points onto Camera Images for Moving Platforms
Key Words: calibration  cameras  distance measurement  optical radar  radar imaging  heterogeneous sensors  lidar sensors  precise range information  visual image data  context based algorithms  intrinsic calibration  extrinsic calibration  lidar measurements  consistent odometry frame  image frame  moving platforms  projection error  motion correction algorithm  extended uncertainty model  real-world data  wide-angle cameras  16-beam scanning lidar  uncertainty estimation  lidar points  camera images  advanced perception  crucial requirement  autonomous vehicle navigation  sensor frames  Laser radar  Cameras  Calibration  Uncertainty  Sensors  Distortion  Three-dimensional displays 
Abstract: Combining multiple sensors for advanced perception is a crucial requirement for autonomous vehicle navigation. Heterogeneous sensors are used to obtain rich information about the surrounding environment. The combination of the camera and lidar sensors enables precise range information that can be projected onto the visual image data. This gives a high level understanding of the scene which can be used to enable context based algorithms such as collision avoidance and navigation. The main challenge when combining these sensors is aligning the data into a common domain. This can be difficult due to the errors in the intrinsic calibration of the camera, extrinsic calibration between the camera and the lidar and errors resulting from the motion of the platform. In this paper, we examine the algorithms required to provide motion correction for scanning lidar sensors. The error resulting from the projection of the lidar measurements into a consistent odometry frame is not possible to remove entirely, and as such it is essential to incorporate the uncertainty of this projection when combining the two different sensor frames. This work proposes a novel framework for the prediction of the uncertainty of lidar measurements (in 3D) projected in to the image frame (in 2D) for moving platforms. The proposed approach fuses the uncertainty of the motion correction with uncertainty resulting from errors in the extrinsic and intrinsic calibration. By incorporating the main components of the projection error, the uncertainty of the estimation process is better represented. Experimental results for our motion correction algorithm and the proposed extended uncertainty model are demonstrated using real-world data collected on an electric vehicle equipped with wide-angle cameras covering a 180-degree field of view and a 16-beam scanning lidar.


Title: Modeling and Analysis of Motion Data from Dynamically Positioned Vessels for Sea State Estimation
Key Words: convolutional neural nets  data analysis  fast Fourier transforms  feature extraction  learning (artificial intelligence)  marine engineering  position control  recurrent neural nets  sensitivity analysis  sensor fusion  ships  state estimation  time series  long dependency  ship motion data  convolutional neural network  frequency features  feature fusion layer  raw time series data  hand-engineered features  sensitivity analysis method  data preprocessing  ship motion dataset  SeaStateNet  sea state estimation  dynamically positioned vessels  autonomous ship  deep neural network model  time-invariant feature extraction  long-short-term memory recurrent neural network  fast Fourier transform block  Sea state  Marine vehicles  Time series analysis  Estimation  Sensors  Feature extraction  Data models 
Abstract: Developing a reliable model to identify the sea state is significant for the autonomous ship. This paper introduces a novel deep neural network model (SeaStateNet) to estimate the sea state based on the ship motion data from dynamically positioned vessels. The SeaStateNet mainly consists of three components: an Long-Short-Term Memory (LSTM) recurrent neural network to capture the long dependency in the ship motion data; a convolutional neural network (CNN) to extract time-invariant features; and a Fast Fourier Transform (FFT) block to extract frequency features. A feature fusion layer is designed to learn the degree affected by each component. The proposed model is applied directly to the raw time series data, without needing of any hand-engineered features. A sensitivity analysis (SA) method is applied to assess the influence of data preprocessing. Through benchmark test and experiment on ship motion dataset, SeaStateNet is verified effective for sea state estimation. The investigation on real-time test further shows the practicality of the proposed model.


Title: Visual Localization at Intersections with Digital Maps
Key Words: computer vision  feature extraction  image reconstruction  image segmentation  neural nets  object detection  pose estimation  road vehicles  stereo image processing  traffic engineering computing  ego-vehicle localization  autonomous road driving  online vision-based method  digital map service  pixel-level semantic segmentation  intersection approaches  visual localization  deep neural networks  coarse street-level pose estimation  Roads  Three-dimensional displays  Semantics  Image segmentation  Pipelines  Geometry  Task analysis 
Abstract: This paper deals with the task of ego-vehicle localization at intersections, a significant task in autonomous road driving. We propose an online vision-based method that can hence be applied if the intersection is visible. It relies on stereo images and on a coarse street-level pose estimate, used to retrieve intersection data from a digital map service. Pixel-level semantic segmentation, and 3D reconstruction from state-of-the art Deep Neural Networks are coupled with an intersection model; this allows good positioning accuracy compared to the state-of-the-art in this task. To demonstrate the effectiveness of the method and make it possible to compare it with other methods, an extensive activity has been conducted in order to set up a dataset of approaches to an intersection, which has then been used to benchmark the proposed method. The dataset is made available to the community, and it currently includes more than forty intersection approaches, from KITTI. Another important contribution of the paper is the definition of criteria for the comparison of different methods, on recorded datasets. The proposed method achieves nearly sub-meter accuracy in difficult real conditions.


Title: Interaction-aware Multi-agent Tracking and Probabilistic Behavior Prediction via Adversarial Learning
Key Words: decision making  interactive systems  learning (artificial intelligence)  multi-agent systems  neural nets  probability  hyperparameter values  adversarial learning  interaction-aware multiagent tracking  probabilistic behavior prediction  motion planning  intelligent systems  multiple interactive agents  distribution learning  decision making  generative adversarial network  Generators  Gallium nitride  Predictive models  Training  Generative adversarial networks  State estimation  Optimization 
Abstract: In order to enable high-quality decision making and motion planning of intelligent systems such as robotics and autonomous vehicles, accurate probabilistic predictions for surrounding interactive objects is a crucial prerequisite. Although many research studies have been devoted to making predictions on a single entity, it remains an open challenge to forecast future behaviors for multiple interactive agents simultaneously. In this work, we take advantage of the Generative Adversarial Network (GAN) due to its capability of distribution learning and propose a generic multi-agent probabilistic prediction and tracking framework which takes the interactions among multiple entities into account, in which all the entities are treated as a whole. However, since GAN is very hard to train, we make an empirical research and present the relationship between training performance and hyperparameter values with a numerical case study. The results imply that the proposed model can capture both the mean, variance and multi-modalities of the groundtruth distribution. Moreover, we apply the proposed approach to a real-world task of vehicle behavior prediction to demonstrate its effectiveness and accuracy. The results illustrate that the proposed model trained by adversarial learning can achieve a better prediction performance than other state-of-the-art models trained by traditional supervised learning which maximizes the data likelihood. The well-trained model can also be utilized as an implicit proposal distribution for particle filtered based Bayesian state estimation.


Title: Model Predictive Control of Ride-sharing Autonomous Mobility-on-Demand Systems
Key Words: predictive control  road traffic control  model predictive control approach  self-driving vehicles  on-demand mobility  time-expanded network flow model  real-time MPC algorithm  customer-carrying vehicles  social welfare  RAMoD system  ride-sharing autonomous mobility-on-demand systems  empty vehicle  customer-carrying vehicle  San Francisco  CA  Roads  Automobiles  Prediction algorithms  Artificial neural networks  Analytical models  Optimization  Predictive models 
Abstract: This paper presents a model predictive control (MPC) approach to optimize routes for Ride-sharing Autonomous Mobility-on-Demand (RAMoD) systems, whereby self-driving vehicles provide coordinated on-demand mobility, possibly allowing multiple customers to share a ride. Specifically, we first devise a time-expanded network flow model for RAMoD. Second, leveraging this model, we design a real-time MPC algorithm to optimize the routes of both empty and customer-carrying vehicles, with the goal of optimizing social welfare, namely, a weighted combination of customers' travel time and vehicles' mileage. Finally, we present a real-world case study for the city of San Francisco, CA, by using the micro-scopic traffic simulator MATSim. The simulation results show that a RAMoD system can significantly improve social welfare with respect to a single-occupancy Autonomous Mobility-on-Demand (AMoD) system, and that the predictive structure of the proposed MPC controller allows it to outperform existing reactive ride-sharing coordination algorithms for RAMoD.


Title: BLVD: Building A Large-scale 5D Semantics Benchmark for Autonomous Driving
Key Words: image segmentation  object detection  robot vision  stereo image processing  autonomous driving community  large-scale dataset platform  large-scale 5D semantics benchmark  3D+temporal  4D+interactive  5D interactive event recognition  5D intention prediction  dynamic 4D tracking  Three-dimensional displays  Benchmark testing  Trajectory  Roads  Task analysis  Semantics  Legged locomotion 
Abstract: In autonomous driving community, numerous benchmarks have been established to assist the tasks of 3D/2D object detection, stereo vision, semantic/instance segmentation. However, the more meaningful dynamic evolution of the surrounding objects of ego-vehicle is rarely exploited, and lacks a large-scale dataset platform. To address this, we introduce BLVD, a large-scale 5D semantics benchmark which does not concentrate on the static detection or semantic/instance segmentation tasks tackled adequately before. Instead, BLVD aims to provide a platform for the tasks of dynamic 4D (3D+temporal) tracking, 5D (4D+interactive) interactive event recognition and intention prediction. This benchmark will boost the deeper understanding of traffic scenes than ever before. We totally yield 249, 129 3D annotations, 4, 902 independent individuals for tracking with the length of overall 214, 922 points, 6, 004 valid fragments for 5D interactive event recognition, and 4, 900 individuals for 5D intention prediction. These tasks are contained in four kinds of scenarios depending on the object density (low and high) and light conditions (daytime and nighttime). The benchmark can be downloaded from our project site https://github.com/VCCIV/BLVD/.


Title: Characterizing Visual Localization and Mapping Datasets
Key Words: motion estimation  rendering (computer graphics)  SLAM (robots)  Wasserstein distance  motion estimation algorithm  robotics SLAM benchmarking  visual localization  mapping algorithms  real-world trajectories  high-quality scenes  synthetic datasets  dense map  key SLAM applications  ground robotics  mapping datasets  motion estimation algorithms  computer vision  Simultaneous localization and mapping  Trajectory  Time measurement  Visualization  Benchmark testing 
Abstract: Benchmarking mapping and motion estimation algorithms is established practice in robotics and computer vision. As the diversity of datasets increases, in terms of the trajectories, models, and scenes, it becomes a challenge to select datasets for a given benchmarking purpose. Inspired by the Wasserstein distance, this paper addresses this concern by developing novel metrics to evaluate trajectories and the environments without relying on any SLAM or motion estimation algorithm. The metrics, which so far have been missing in the research community, can be applied to the plethora of datasets that exist. Additionally, to improve the robotics SLAM benchmarking, the paper presents a new dataset for visual localization and mapping algorithms. A broad range of real-world trajectories is used in very high-quality scenes and a rendering framework to create a set of synthetic datasets with ground-truth trajectory and dense map which are representative of key SLAM applications such as virtual reality (VR), micro aerial vehicle (MAV) flight, and ground robotics.


Title: Are We Ready for Autonomous Drone Racing? The UZH-FPV Drone Racing Dataset
Key Words: helicopters  image capture  image sensors  image sequences  motion estimation  remotely operated vehicles  video cameras  UZH-FPV Drone Racing dataset  first-person-view racing quadrotor  state estimation algorithms  autonomous Drone Racing  visual-inertial state estimation  motion estimation  Drones  Optical imaging  Cameras  Trajectory  Optical sensors  Measurement  High-speed optical techniques 
Abstract: Despite impressive results in visual-inertial state estimation in recent years, high speed trajectories with six degree of freedom motion remain challenging for existing estimation algorithms. Aggressive trajectories feature large accelerations and rapid rotational motions, and when they pass close to objects in the environment, this induces large apparent motions in the vision sensors, all of which increase the difficulty in estimation. Existing benchmark datasets do not address these types of trajectories, instead focusing on slow speed or constrained trajectories, targeting other tasks such as inspection or driving. We introduce the UZH-FPV Drone Racing dataset, consisting of over 27 sequences, with more than 10 km of flight distance, captured on a first-person-view (FPV) racing quadrotor flown by an expert pilot. The dataset features camera images, inertial measurements, event-camera data, and precise ground truth poses. These sequences are faster and more challenging, in terms of apparent scene motion, than any existing dataset. Our goal is to enable advancement of the state of the art in aggressive motion estimation by providing a dataset that is beyond the capabilities of existing state estimation algorithms.


Title: Discontinuity-Sensitive Optimal Control Learning by Mixture of Experts
Key Words: approximation theory  function approximation  iterative methods  learning (artificial intelligence)  neural nets  nonlinear control systems  optimal control  optimisation  discontinuity-sensitive optimal control learning  machine learning method  parametric input  problem parameters  optimal solutions  problem-optimum map  discrete homotopy classes  control switching  MoE  standard neural networks  dynamic vehicle control problems  nonlinear optimal control problems  function approximators  mixture of experts model  trajectory prediction  Trajectory  Training  Optimal control  Neural networks  Optimization  Standards  Predictive models 
Abstract: This paper proposes a machine learning method to predict the solutions of related nonlinear optimal control problems given some parametric input, such as the initial state. The map between problem parameters to optimal solutions is called the problem-optimum map, and is often discontinuous due to nonconvexity, discrete homotopy classes, and control switching. This causes difficulties for traditional function approximators such as neural networks, which assume continuity of the underlying function. This paper proposes a mixture of experts (MoE) model composed of a classifier and several regressors, where each regressor is tuned to a particular continuous region. A novel training approach is proposed that trains classifier and regressors independently. MoE greatly outperforms standard neural networks, and achieves highly reliable trajectory prediction (over 99.5% accuracy) in several dynamic vehicle control problems.


Title: Streaming Scene Maps for Co-Robotic Exploration in Bandwidth Limited Environments
Key Words: autonomous underwater vehicles  geophysical image processing  image representation  object detection  oceanographic techniques  probability  robot vision  SLAM (robots)  unsupervised learning  co-robotic exploration  bandwidth tunable technique  real-time probabilistic scene modeling  communication constrained environments  deep sea  scene complexity  bandwidth requirements  underwater robot  high-level semantic scene constructs  artificially constructed tank environment  science interests  unsupervised scene model impact  resulting scene model  coral reef  bandwidth constraints  scene maps streaming  Robot sensing systems  Bandwidth  Oceans  Data models  Visualization  Bayes methods 
Abstract: This paper proposes a bandwidth tunable technique for real-time probabilistic scene modeling and mapping to enable co-robotic exploration in communication constrained environments such as the deep sea. The parameters of the system enable the user to characterize the scene complexity represented by the map, which in turn determines the bandwidth requirements. The approach is demonstrated using an underwater robot that learns an unsupervised scene model of the environment and then uses this scene model to communicate the spatial distribution of various high-level semantic scene constructs to a human operator. Preliminary experiments in an artificially constructed tank environment as well as simulated missions over a 10m×10m coral reef using real data show the tunability of the maps to different bandwidth constraints and science interests. To our knowledge this is the first paper to quantity how the free parameters of the unsupervised scene model impact both the scientific utility of and bandwidth required to communicate the resulting scene model.


Title: Design and Parameter Optimization of a 3-PSR Parallel Mechanism for Replicating Wave and Boat Motion
Key Words: autonomous aerial vehicles  boats  marine safety  motion control  optimisation  pitch control (position)  ball joint mounting angle  experimental testing  boat motion replication  parameter optimization  3-PSR parallel mechanism  three-degree-of-freedom  prismatic-spherical-revolute parallel mechanism  unmanned aerial vehicle  unmanned surface vehicle  lookup table  geometric constraints  wave replication  three actuated linear rails  UAV winch payload  inertial measurement unit  Boats  Fasteners  Testing  Rails  Sea state  Kinematics  Unmanned aerial vehicles 
Abstract: We present a low-cost, three-degree-of-freedom (3-DOF) prismatic-spherical-revolute (PSR) parallel mechanism used as a testing platform for an unmanned aerial vehicle (UAV) tethered to an unmanned surface vehicle (USV). The mechanism has three actuated linear rails kinematically linked to a platform which replicates boat motion up to 2.5 m vertical heave (sea state 4, Douglas Sea Scale). A lookup table relating relative slider heights to platform roll and pitch was developed numerically leveraging geometric constraints. A design parameter study optimized the arm length, platform size, and ball joint mounting angle relative to the overall radius to maximize the workspace. For this design, a maximum roll and pitch range from -32° to 32° and -25° to 35°, respectively, is achievable. A prototype was manufactured to carry the tethered UAV winch payload. Experimental testing confirmed the workspace and demonstrated boat motion replication, validated using an inertial measurement unit (IMU).


Title: A Framework for On-line Learning of Underwater Vehicles Dynamic Models
Key Words: marine navigation  mobile robots  regression analysis  robot dynamics  support vector machines  tracking  underwater vehicles  vehicle dynamics  on-line learning  underwater vehicles dynamic models  accurate tracking controllers  navigation algorithms  high fidelity performance  robot dynamics  incremental support vector regression method  Robots  Vehicle dynamics  Adaptation models  Computational modeling  Heuristic algorithms  Support vector machines  Data models 
Abstract: Learning the dynamics of robots from data can help achieve more accurate tracking controllers, or aid their navigation algorithms. However, when the actual dynamics of the robots change due to external conditions, on-line adaptation of their models is required to maintain high fidelity performance. In this work, a framework for on-line learning of robot dynamics is developed to adapt to such changes. The proposed framework employs an incremental support vector regression method to learn the model sequentially from data streams. In combination with the incremental learning, strategies for including and forgetting data are developed to obtain better generalization over the whole state space. The framework is tested in simulation and real experimental scenarios demonstrating its adaptation capabilities to changes in the robot's dynamics.


Title: Security-Aware Synthesis of Human-UAV Protocols
Key Words: autonomous aerial vehicles  command and control systems  control engineering computing  formal verification  learning (artificial intelligence)  military aircraft  stochastic games  security-aware synthesis  human-UAV protocols  collaboration protocols  human-unmanned aerial vehicle  geolocation task  stochastic game-based model  stealthy false-data injection attacks  collected experimental data  human-UAV coalition  H-UAV protocol synthesis  human operators  UAV hidden-information constraint  RESCHU-SA testbed  geolocation strategies  model checkers  command and control systems  Games  Task analysis  Protocols  Geology  Stochastic processes  Security  Global Positioning System 
Abstract: In this work, we synthesize collaboration protocols for human-unmanned aerial vehicle (H-UAV) command and control systems, where the human operator aids in securing the UAV by intermittently performing geolocation tasks to confirm its reported location. We first present a stochastic game-based model for the system that accounts for both the operator and an adversary capable of launching stealthy false-data injection attacks, causing the UAV to deviate from its path. We also describe a synthesis challenge due to the UAV's hidden-information constraint. Next, we perform human experiments using a developed RESCHU-SA testbed to recognize the geolocation strategies that operators adopt. Furthermore, we deploy machine learning techniques on the collected experimental data to predict the correctness of a geolocation task at a given location based on its geographical features. By representing the model as a delayed-action game and formalizing the system objectives, we utilize off-the-shelf model checkers to synthesize protocols for the human-UAV coalition that satisfy these objectives. Finally, we demonstrate the usefulness of the H-UAV protocol synthesis through a case study where the protocols are experimentally analyzed and further evaluated by human operators.


Title: UAV/UGV Autonomous Cooperation: UAV assists UGV to climb a cliff by attaching a tether
Key Words: autonomous aerial vehicles  collision avoidance  inertial navigation  mobile robots  off-road vehicles  robot vision  SLAM (robots)  Unmanned Aerial Vehicle  Unmanned Ground Vehicle  tether attachment device  steep terrain  tether anchoring  UGV autonomous cooperation  UAV autonomous cooperation  visual inertial navigation  collaborative navigation  3D voxel mapping  obstacle avoidance planning  traversability analysis  Robot sensing systems  Navigation  Three-dimensional displays  Unmanned aerial vehicles  Trajectory  Attitude control 
Abstract: This paper proposes a novel cooperative system for an Unmanned Aerial Vehicle (UAV) and an Unmanned Ground Vehicle (UGV) which utilizes the UAV not only as a flying sensor but also as a tether attachment device. Two robots are connected with a tether, allowing the UAV to anchor the tether to a structure located at the top of a steep terrain, impossible to reach for UGVs. Thus, enhancing the poor traversability of the UGV by not only providing a wider range of scanning and mapping from the air, but also by allowing the UGV to climb steep terrains with the winding of the tether. In addition, we present an autonomous framework for the collaborative navigation and tether attachment in an unknown environment. The UAV employs visual inertial navigation with 3D voxel mapping and obstacle avoidance planning. The UGV makes use of the voxel map and generates an elevation map to execute path planning based on a traversability analysis. Furthermore, we compared the pros and cons of possible methods for the tether anchoring from multiple points of view. To increase the probability of successful anchoring, we evaluated the anchoring strategy with an experiment. Finally, the feasibility and capability of our proposed system were demonstrated by an autonomous mission experiment in the field with an obstacle and a cliff.


Title: Air-to-Ground Surveillance Using Predictive Pursuit
Key Words: autonomous aerial vehicles  Markov processes  mobile robots  object tracking  path planning  surveillance  target tracking  air-to-ground surveillance  predictive pursuit  Markov decision process  tracking time  location detection accuracy  air-to-ground robot surveillance scenario  surveillance algorithms  camera  unmanned ground vehicle  UGV  observed path  pursuit algorithm  target localization  high predictive accuracy  Planning  Surveillance  Markov processes  Prediction algorithms  Trajectory  Measurement  Drones 
Abstract: This paper introduces a probabilistic prediction model with a novel variant of the Markov decision process to improve tracking time and location detection accuracy in an air-to-ground robot surveillance scenario. While most surveillance algorithms focus mainly on controls of an unmanned aerial vehicle (UAV) and camera for faster tracking of an unmanned ground vehicle (UGV), this paper proposes a way of minimizing detection and tracking time by applying a prediction model to the first observed path taken by the UGV. We present a pursuit algorithm that addresses the problem of target (UGV) localization by combining prediction of used planning algorithm by the target, and application of the same planning algorithm to predict future trajectories. Our results show a high predictive accuracy based on a final position attained by the target and the location predicted by our model.


Title: Learning to Drive in a Day
Key Words: learning (artificial intelligence)  mobile robots  road safety  road traffic control  road vehicles  robot vision  autonomous driving tasks  single monocular image  safety driver  model-free deep reinforcement learning algorithm  lane following  on-vehicle  Reinforcement learning  Autonomous vehicles  Task analysis  Markov processes  Global Positioning System  Sensors  Training 
Abstract: We demonstrate the first application of deep reinforcement learning to autonomous driving. From randomly initialised parameters, our model is able to learn a policy for lane following in a handful of training episodes using a single monocular image as input. We provide a general and easy to obtain reward: the distance travelled by the vehicle without the safety driver taking control. We use a continuous, model-free deep reinforcement learning algorithm, with all exploration and optimisation performed on-vehicle. This demonstrates a new framework for autonomous driving which moves away from reliance on defined logical rules, mapping, and direct supervision. We discuss the challenges and opportunities to scale this approach to a broader range of autonomous driving tasks.


Title: Generating Adversarial Driving Scenarios in High-Fidelity Simulators
Key Words: automobile industry  Bayes methods  computer vision  control engineering computing  learning (artificial intelligence)  mobile robots  optimisation  program testing  road traffic  road vehicles  traffic engineering computing  transportation  self-driving policy  simulated pedestrians  self-driving behavior  high-fidelity simulators  public roads  software tests  self-driving software  adversarial self-driving scenarios  self-driving vehicles  transportation systems  simulated driving scenarios  driving scenario generation  self-driving car industry  Bayesian optimization  vision-based imitation learning  Optimization  Accidents  Rendering (computer graphics)  Bayes methods  Reinforcement learning  Roads  Trajectory 
Abstract: In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems. Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on high-fidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle. It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios. The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1]. In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with simulated pedestrians and vehicles. We show that by incorporating the generated scenarios into the training set of the self-driving policy, and by fine-tuning the policy using vision-based imitation learning we obtain safer self-driving behavior.


Title: Force-based Heterogeneous Traffic Simulation for Autonomous Vehicle Testing
Key Words: computer simulation  control engineering computing  driver information systems  mobile robots  road safety  road traffic control  road vehicles  traffic engineering computing  self-driving tests  force-based concept  heterogenous traffic simulation  realistic urban environment  personal mobility devices  pedestrians  autonomous vehicles  traffic control  high-fidelity driving simulator  autonomous vehicle testing  force-based heterogeneous traffic simulation  Force  Autonomous vehicles  Roads  Acceleration  Bicycles  Testing  Urban areas 
Abstract: Recent failures in real-world self-driving tests have suggested a paradigm shift from directly learning in real-world roads to building a high-fidelity driving simulator as an alternative, effective, and safe tool to handle intricate traffic environments in urban areas. To date, traffic simulation can construct virtual urban environments with various weather conditions, day and night, and traffic control for autonomous vehicle testing. However, mutual interactions between autonomous vehicles and pedestrians are rarely modeled in existing simulators. Besides vehicles and pedestrians, the usage of personal mobility devices is increasing in congested cities as an alternative to the traditional transport system. A simulator that considers all potential road-users in a realistic urban environment is urgently desired. In this work, we propose a novel, extensible, and microscopic method to build heterogenous traffic simulation using the force-based concept. This force-based approach can accurately replicate the sophisticated behaviors of various road users and their interactions through a simple and unified way. Furthermore, we validate our approach through simulation experiments and comparisons to the popular simulators currently used for research and development of autonomous vehicles.


Title: Distant Vehicle Detection Using Radar and Vision
Key Words: cameras  computer vision  convolutional neural nets  image capture  object detection  road vehicle radar  distant vehicle detection  autonomous vehicles  convolutional neural networks  image-based object detectors  radar data  vision  KITTI  cameras  focal lengths  Cameras  Radar imaging  Detectors  Object detection  Doppler radar  Training 
Abstract: For autonomous vehicles to be able to operate successfully they need to be aware of other vehicles with sufficient time to make safe, stable plans. Given the possible closing speeds between two vehicles, this necessitates the ability to accurately detect distant vehicles. Many current image-based object detectors using convolutional neural networks exhibit excellent performance on existing datasets such as KITTI. However, the performance of these networks falls when detecting small (distant) objects. We demonstrate that incorporating radar data can boost performance in these difficult situations. We also introduce an efficient automated method for training data generation using cameras of different focal lengths.


Title: Real-Time Vehicle Detection from Short-range Aerial Image with Compressed MobileNet
Key Words: feature extraction  mobile computing  motorcycles  neural nets  object detection  road vehicles  traffic engineering computing  MobileNet family network engineering  compressed MobileNet  feature map downsampling stage  feature map plateau stage  reduced inference time  vehicle categories  crowded bicycles  high detection accuracy  real-time detection speed  real time vehicle detection  object interference  short-range aerial image  crowded motorcycles  truck  car  bus  Convolution  Neural networks  Proposals  Vehicle detection  Object detection  Computational modeling  Feature extraction 
Abstract: Vehicle detection from short-range aerial image faces challenges including vehicle blocking, irrelevant object interference, motion blurring, color variation etc., leading to the difficulty to achieve high detection accuracy and real-time detection speed. In this paper, benefiting from the recent development in MobileNet family network engineering, we propose a compressed MobileNet which is not only internally resistant to the above listed challenges but also gains the best detection accuracy/speed tradeoff when comparing with the original MobileNet. In a nutshell, we reduce the bottleneck architecture number during the feature map downsampling stage but add more bottlenecks during the feature map plateau stage, neither extra FLOPs nor parameters are thus involved but reduced inference time and better accuracy are expected. We conduct experiment on our collected 5-k short-range aerial images, containing six vehicle categories: truck, car, bus, bicycle, motorcycle, crowded bicycles and crowded motorcycles. Our proposed compressed MobileNet achieves 110 FPS (GPU), 31 FPS (CPU) and 15 FPS (mobile phone), 1.2 times faster and 2% more accurate (mAP) than the original MobileNet.


Title: Risk Averse Robust Adversarial Reinforcement Learning
Key Words: learning (artificial intelligence)  optimisation  probability  risk averse robust adversarial reinforcement learning  deep reinforcement learning  computer games  robotic control  automotive accidents  optimization  probability  RARARL  self-driving vehicle controller  Reinforcement learning  Training  Mathematical model  Robustness  Autonomous vehicles  Task analysis  Accidents 
Abstract: Deep reinforcement learning has recently made significant progress in solving computer games and robotic control tasks. A known problem, though, is that policies overfit to the training environment and may not avoid rare, catastrophic events such as automotive accidents. A classical technique for improving the robustness of reinforcement learning algorithms is to train on a set of randomized environments, but this approach only guards against common situations. Recently, robust adversarial reinforcement learning (RARL) was developed, which allows efficient applications of random and systematic perturbations by a trained adversary. A limitation of RARL is that only the expected control objective is optimized; there is no explicit modeling or optimization of risk. Thus the agents do not consider the probability of catastrophic events (i.e., those inducing abnormally large negative reward), except through their effect on the expected objective. In this paper we introduce risk-averse robust adversarial reinforcement learning (RARARL), using a risk-averse protagonist and a risk-seeking adversary. We test our approach on a self-driving vehicle controller. We use an ensemble of policy networks to model risk as the variance of value functions. We show through experiments that a risk-averse agent is better equipped to handle a risk-seeking adversary, and experiences substantially fewer crashes compared to agents trained without an adversary. Supplementary materials are available at https://sites.google.com/view/rararl.


Title: Early Failure Detection of Deep End-to-End Control Policy by Reinforcement Learning
Key Words: belief networks  control engineering computing  convolutional neural nets  learning (artificial intelligence)  learning systems  observability  predictive control  learned control policies  reinforcement learning  end-to-end imitation  predictive uncertainty  model predictive controller  fully-observable vision-based partially-observable systems  deep convolutional Bayesian neural networks  deep end-to-end control policy  Bayesian networks  mean value  corrective action  partial state observability  Uncertainty  Bayes methods  Task analysis  Neural networks  Safety  Training  Autonomous vehicles 
Abstract: We propose the use of Bayesian networks, which provide both a mean value and an uncertainty estimate as output, to enhance the safety of learned control policies under circumstances in which a test-time input differs significantly from the training set. Our algorithm combines reinforcement learning and end-to-end imitation learning to simultaneously learn a control policy as well as a threshold over the predictive uncertainty of the learned model, with no hand-tuning required. Corrective action, such as a return of control to the model predictive controller or human expert, is taken before the failure of tasks, when the uncertainty threshold is exceeded. We validate our method on fully-observable and vision-based partially-observable systems using cart-pole and autonomous driving simulations using deep convolutional Bayesian neural networks. We demonstrate that our method is robust to uncertainty resulting from varying system dynamics as well as from partial state observability.


Title: Trajectory Planning for a Tractor with Multiple Trailers in Extremely Narrow Environments: A Unified Approach*
Key Words: agricultural machinery  optimal control  path planning  sampling methods  search problems  vehicle dynamics  trajectory planning  multiple trailers  extremely narrow environments  unified approach  vehicle kinematics  underactuated constraints  nonholonomic constraints  prevalent sampling-based  rigid-body vehicles  tractor-trailer vehicle cases  generic n-trailer cases  tiny environments  adaptively homotopic warm-starting approach  numerical solution process  extremely tiny scenarios  online planning opportunities  Trajectory  Planning  Agricultural machinery  Kinematics  Optimal control  Wheels  Dispersion 
Abstract: Trajectory planning for a tractor-trailer vehicle is challenging because the vehicle kinematics consists of underactuated and nonholonomic constraints that are highly coupled. Prevalent sampling-based or search-based planners suitable for rigid-body vehicles are not capable of handling the tractor-trailer vehicle cases. This work aims to deal with generic n-trailer cases in the tiny environments. To this end, an optimal control problem is formulated, which is beneficial in being accurate, straightforward, and unified. An adaptively homotopic warm-starting approach is proposed to facilitate the numerical solution process of the formulated optimal control problem. Compared with the existing sequential warm starting strategies, our proposal can adaptively define the subproblems with the purpose of making the gaps between adjacent subproblems “pleasant” for the solver. Unification and efficiency of the proposed adaptively homotopic warm-starting approach have been investigated in several extremely tiny scenarios. Our planner finds solutions that other existing planners cannot. Online planning opportunities are briefly discussed as well.


Title: Predictive Collision Avoidance for the Dynamic Window Approach
Key Words: collision avoidance  mobile robots  motion control  predictive collision avoidance  dynamic window approach  foresighted navigation  mobile robots  factory floor installations  dynamic collision model  nonholonomic vehicles  Trajectory  Vehicle dynamics  Dynamics  Acceleration  Collision avoidance  Robot sensing systems 
Abstract: Foresighted navigation is an essential skill for robots to rise from rigid factory floor installations to much more versatile mobile robots that partake in our everyday environment. The current state of the art that provides this mobility to some extent is the Dynamic Window Approach combined with a global start-to-target path planner. However, neither the Dynamic Window Approach nor the path planner are equipped to predict the motion of other objects in the environment. We propose a change in the Dynamic Window Approach-a dynamic collision model-that is capable of predicting future collisions with the environment by also taking into account the motion of other objects. We show in simulated experiments that our new way of computing the Dynamic Window Approach significantly reduces the number of collisions in a dynamic setting with nonholonomic vehicles while still being computationally efficient.


Title: Kinematic Constraints Based Bi-directional RRT (KB-RRT) with Parameterized Trajectories for Robot Path Planning in Cluttered Environment
Key Words: collision avoidance  mobile robots  path planning  robot dynamics  robot kinematics  Bi-RRT algorithm  parameterized trajectories  robot path planning  complex missions  navigation capability  autonomous mobile robots  robust path planning algorithms  bidirectional-RRT  kinodynamic constraints  bidirectional RRT  trajectory planning  memory utilization  kinematic constraints  KB-RRT algorithm  Kinematics  Trajectory  Mobile robots  Navigation  Planning 
Abstract: Optimal path planning and smooth trajectory planning are critical for effective navigation of mobile robots working towards accomplishing complex missions. For autonomous, real time and extended operations of mobile robots, the navigation capability needs to be executed at the edge. Thus, efficient compute, minimum memory utilization and smooth trajectory are the key parameters that drive the successful operation of autonomous mobile robots. Traditionally, navigation solutions focus on developing robust path planning algorithms which are complex and compute/memory intensive. Bidirectional-RRT(Bi-RRT) based path planning algorithms have gained increased attention due to their effectiveness and computational efficiency in generating feasible paths. However, these algorithms neither optimize memory nor guarantee smooth trajectories. To this end, we propose a kinematically constrained Bi-RRT (KB-RRT) algorithm, which restricts the number of nodes generated without compromising on the accuracy and incorporates kinodynamic constraints for generating smooth trajectories, together resulting in efficient navigation of autonomous mobile robots. The proposed algorithm is tested in a highly cluttered environment on an Ackermannsteering vehicle model with severe kinematic constraints. The experimental results demonstrate that KB-RRT achieves three times (3 X) better performance in terms of convergence rate and memory utilization compared to a standard Bi-RRT algorithm.


Title: Predicting Vehicle Behaviors Over An Extended Horizon Using Behavior Interaction Network
Key Words: recurrent neural nets  road vehicles  traffic engineering computing  recurrent neural network  interaction modeling  vehicle behaviors  autonomous vehicles  behavior detection  long-term future rewards  vehicle behavior interaction network  observation encoding  Planning  Trajectory  Vehicle dynamics  Encoding  Autonomous vehicles  Recurrent neural networks  Prediction methods 
Abstract: Anticipating possible behaviors of traffic participants is an essential capability of autonomous vehicles. Many behavior detection and maneuver recognition methods only have a very limited prediction horizon that leaves inadequate time and space for planning. To avoid unsatisfactory reactive decisions, it is essential to count long-term future rewards in planning, which requires extending the prediction horizon. In this paper, we uncover that clues to vehicle behaviors over an extended horizon can be found in vehicle interaction, which makes it possible to anticipate the likelihood of a certain behavior, even in the absence of any clear maneuver pattern. We adopt a recurrent neural network (RNN) for observation encoding, and based on that, we propose a novel vehicle behavior interaction network (VBIN) to capture the vehicle interaction from the hidden states and connection feature of each interaction pair. The output of our method is a probabilistic likelihood of multiple behavior classes, which matches the multimodal and uncertain nature of the distant future. A systematic comparison of our method against two state-of-the-art methods and another two baseline methods on a publicly available real highway dataset is provided, showing that our method has superior accuracy and advanced capability for interaction modeling.


Title: Multimodal Spatio-Temporal Information in End-to-End Networks for Automotive Steering Prediction
Key Words: cameras  driver information systems  image sequences  road safety  steering systems  visual input data  onboard vehicle camera  empirical comparison  spatial spatio-temporal  real-life driver  predicted steering command  recurrent multimodal model  steering correction concept  multimodal spatio-temporal information  end-to-end networks  automotive steering prediction  end-to-end steering problem  Optical imaging  Adaptive optics  Computational modeling  Kernel  Training  Roads  Cameras  Autonomous steering  deep learning  spatio-temporal model  multimodal input  optical flow  RNN-LSTM 
Abstract: We study the end-to-end steering problem using visual input data from an onboard vehicle camera. An empirical comparison between spatial, spatio-temporal and multimodal models is performed assessing each concept's performance from two points of evaluation. First, how close the model is in predicting and imitating a real-life driver's behavior, second, the smoothness of the predicted steering command. The latter is a newly proposed metric. Building on our results, we propose a new recurrent multimodal model. The suggested model has been tested on a custom dataset recorded by BMW, as well as the public dataset provided by Udacity. Results show that it outperforms previously released scores. Further, a steering correction concept from off-lane driving through the inclusion of correction frames is presented. We show that our suggestion leads to promising results empirically.


Title: OVPC Mesh: 3D Free-space Representation for Local Ground Vehicle Navigation
Key Words: computational geometry  mesh generation  mobile robots  navigation  path planning  remotely operated vehicles  robot vision  stereo image processing  OVPC Mesh  3D free-space representation  local ground vehicle navigation  autonomous unmanned ground vehicle  Visible Point Clouds Mesh  local point cloud data  UGV navigation  on visible point clouds mesh  watertight 3D mesh generation  trajectory planning  robot  Three-dimensional displays  Navigation  Robot sensing systems  Planning  Laser radar  Real-time systems 
Abstract: This paper presents a novel approach for local 3D environment representation for autonomous unmanned ground vehicle (UGV) navigation called On Visible Point Clouds Mesh (OVPC Mesh). Our approach represents the surrounding of the robot as a watertight 3D mesh generated from local point cloud data in order to represent the free space surrounding the robot. It is a conservative estimation of the free space and provides a desirable trade-off between representation precision and computational efficiency, without having to discretize the environment into a fixed grid size. Our experiments analyze the usability of the approach for UGV navigation in rough terrain, both in simulation and in a fully integrated real-world system. Additionally, we compare our approach to well-known state-of the-art solutions, such as Octomap and Elevation Mapping and show that OVPC Mesh can provide reliable 3D information for trajectory planning while fulfilling real-time constraints.


Title: Attention-based Lane Change Prediction
Key Words: path planning  recurrent neural nets  road vehicles  traffic engineering computing  function estimation problem  model understandability  lane change prediction model  attention-based recurrent model  prediction quality  attention-based lane change prediction  path planning  driver discomfort  Automobiles  Predictive models  Hidden Markov models  Task analysis  Vehicle dynamics  Bayes methods 
Abstract: Lane change prediction of surrounding vehicles is a key building block of path planning. The focus has been on increasing the accuracy of prediction by posing it purely as a function estimation problem at the cost of model understandability. However, the efficacy of any lane change prediction model can be improved when both corner and failure cases are humanly understandable. We propose an attention-based recurrent model to tackle both understandability and prediction quality. We also propose metrics which reflect the discomfort felt by the driver. We show encouraging results on a publicly available dataset and proprietary fleet data.


Title: Deep Object-Centric Policies for Autonomous Driving
Key Words: computer games  convolutional neural nets  data visualisation  learning (artificial intelligence)  traffic engineering computing  object-centric models  object instances  end-to-end learning  Grand Theft Auto V simulator  object-agnostic methods  object-centric policies  autonomous driving  visuomotor skills  deep neural networks  robotics tasks  intuitive visualization  Berkeley DeepDrive Video dataset  Task analysis  Training  Taxonomy  Automobiles  Autonomous vehicles  Feature extraction  Robots 
Abstract: While learning visuomotor skills in an end-to-end manner is appealing, deep neural networks are often uninterpretable and fail in surprising ways. For robotics tasks, such as autonomous driving, models that explicitly represent objects may be more robust to new scenes and provide intuitive visualizations. We describe a taxonomy of “object-centric” models which leverage both object instances and end-to-end learning. In the Grand Theft Auto V simulator, we show that object-centric models outperform object-agnostic methods in scenes with other vehicles and pedestrians, even with an imperfect detector. We also demonstrate that our architectures perform well on real-world environments by evaluating on the Berkeley DeepDrive Video dataset, where an object-centric model outperforms object-agnostic models in the low-data regimes.


Title: Neural Autonomous Navigation with Riemannian Motion Policy
Key Words: collision avoidance  geometry  learning (artificial intelligence)  mobile robots  neurocontrollers  optimal control  predictive control  robot vision  image-based autonomous navigation technique  Riemannian motion policy framework  vehicular control  deep learning  policy structure  data complexity  modeling error  end-to-end learning  neural autonomous navigation  local geometry  RMP representation  indoor obstacle avoidance  Gibson environment  optimal control commands  visual images  control point RMPs  deep neural network  Acceleration  Geometry  Autonomous robots  Measurement  Neural networks  Kinematics 
Abstract: End-to-end learning for autonomous navigation has received substantial attention recently as a promising method for reducing modeling error. However, its data complexity, especially around generalization to unseen environments, is high. We introduce a novel image-based autonomous navigation technique that leverages in policy structure using the Riemannian Motion Policy (RMP) framework for deep learning of vehicular control. We design a deep neural network to predict control point RMPs of the vehicle from visual images, from which the optimal control commands can be computed analytically. We show that our network trained in the Gibson environment can be used for indoor obstacle avoidance and navigation on a real RC car, and our RMP representation generalizes better to unseen environments than predicting local geometry or predicting control commands directly.


Title: Online Multilayered Motion Planning with Dynamic Constraints for Autonomous Underwater Vehicles
Key Words: autonomous underwater vehicles  collision avoidance  mobile robots  trajectory control  vehicle dynamics  underwater robot  online multilayered motion planning  autonomous underwater vehicles  loosely coupled multilayered planning design  motion planner  hydro-dynamic forces  trajectory planning  robots onboard computer  AUVs  inevitable collision states  Planning  Trajectory  Lead  Vehicle dynamics  Robots  Dynamics  Unmanned underwater vehicles 
Abstract: Underwater robots are subject to complex hydro-dynamic forces. These forces define how the vehicle moves, so it is important to consider them when planning trajectories. However, performing motion planning considering the dynamics on the robot's onboard computer is challenging due to the limited computational resources available. In this paper an efficient motion planning framework for autonomous underwater vehicles (AUVs) is presented. By introducing a loosely coupled multilayered planning design, our framework is able to generate dynamically feasible trajectories while keeping the planning time low enough for online planning. First, a fast path planner operating in a lower-dimensional projected space computes a lead path from the start to the goal configuration. Then, the lead path is used to bias the sampling of a second motion planner, which takes into account all the dynamic constraints. Furthermore, we propose a strategy for online planning that saves computational resources by generating the final trajectory only up to a finite horizon. By using the finite horizon strategy together with the multilayered approach, the sampling of the second planner focuses on regions where good quality solutions are more likely to be found, significantly reducing the planning time. To provide strong safety guarantees our framework also incorporates the conservative approximations of inevitable collision states (icss). finally, we present simulations and experiments using a real underwater robot to demonstrate the capabilities of our framework.


Title: Variational End-to-End Navigation and Localization
Key Words: cameras  Global Positioning System  learning (artificial intelligence)  mobile robots  navigation  path planning  probability  variational techniques  point-topoint navigation algorithms  full-scale autonomous vehicle  localization algorithm  variational end-to-end navigation  deep learning  autonomous vehicle control  raw sensory data  navigation instruction  end-to-end driving networks  point-to-point navigation  probabilistic localization  noisy GPS data  raw camera data  higher level roadmaps  probability distribution  deterministic control command  rough localization  real-world driving data  variational network  Navigation  Roads  Cameras  Robot sensing systems  Visualization  Partitioning algorithms 
Abstract: Deep learning has revolutionized the ability to learn “end-to-end” autonomous vehicle control directly from raw sensory data. While there have been recent extensions to handle forms of navigation instruction, these works are unable to capture the full distribution of possible actions that could be taken and to reason about localization of the robot within the environment. In this paper, we extend end-to-end driving networks with the ability to perform point-to-point navigation as well as probabilistic localization using only noisy GPS data. We define a novel variational network capable of learning from raw camera data of the environment as well as higher level roadmaps to predict (1) a full probability distribution over the possible control commands; and (2) a deterministic control command capable of navigating on the route specified within the map. Additionally, we formulate how our model can be used to localize the robot according to correspondences between the map and the observed visual road topology, inspired by the rough localization that human drivers can perform. We test our algorithms on real-world driving data that the vehicle has never driven through before, and integrate our point-topoint navigation algorithms onboard a full-scale autonomous vehicle for real-time performance. Our localization algorithm is also evaluated over a new set of roads and intersections to demonstrates rough pose localization even in situations without any GPS prior.


Title: Design and Control of a Passively Morphing Quadcopter
Key Words: aerospace components  design engineering  helicopters  hinges  nonlinear dynamical systems  position control  propellers  passively morphing quadcopter  passive rotary joints  rapid aerial morphing  sprung hinges  nonmorphing quadcopter  quadcopter controllers  trajectory generation algorithms  control inputs  gap traversal maneuvers  rigid connections  quadcopter design  propellers  nonlinear dynamics  Propellers  Vehicle dynamics  Springs  Force  Fasteners  Dynamics  Actuators 
Abstract: This paper presents a novel quadcopter design that uses passive rotary joints to enable rapid aerial morphing without the use of additional actuators. The normally rigid connections between the arms of the quadcopter and the central body are replaced by sprung hinges that allow for the arms of the quadcopter to fold downward when low thrusts are produced by the propellers, resulting in a reduction of the largest dimension of the vehicle by approximately 50%. The ability of the vehicle to reduce its size during flight allows, e.g., for the traversal of gaps through which a non-morphing quadcopter could not pass. The vehicle is designed such that existing quadcopter controllers and trajectory generation algorithms can be used, provided that some additional constraints on the control inputs are met. The nonlinear dynamics of the system are presented, and design rules are given that minimize transition time between configurations and maximize the available range of control inputs. A method for performing gap traversal maneuvers is proposed and validated experimentally.


Title: Search-based 3D Planning and Trajectory Optimization for Safe Micro Aerial Vehicle Flight Under Sensor Visibility Constraints
Key Words: aerospace safety  collision avoidance  graph theory  navigation  search problems  trajectory optimisation (aerospace)  trajectory optimization  sensor visibility constraints  obstacle-free flight paths  Velodyne Puck Lite 3D laser scanner  flight dynamics  navigation safety  allocentric complete planning  microaerial vehicle flight safety  search-based 3D planning  collision avoidance  graph search  Planning  Robot sensing systems  Three-dimensional displays  Trajectory optimization  Vehicle dynamics 
Abstract: Safe navigation of Micro Aerial Vehicles (MAVs) requires not only obstacle-free flight paths according to a static environment map, but also the perception of and reaction to previously unknown and dynamic objects. This implies that the onboard sensors cover the current flight direction. Due to the limited payload of MAVs, full sensor coverage of the environment has to be traded off with flight time. Thus, often only a part of the environment is covered. We present a combined allocentric complete planning and trajectory optimization approach taking these sensor visibility constraints into account. The optimized trajectories yield flight paths within the apex angle of a Velodyne Puck Lite 3D laser scanner enabling low-level collision avoidance to perceive obstacles in the flight direction. Furthermore, the optimized trajectories take the flight dynamics into account and contain the velocities and accelerations along the path. We evaluate our approach with a DJI Matrice 600 MAV and in simulation employing hardware-in-the-loop.


Title: Fast and In Sync: Periodic Swarm Patterns for Quadrotors
Key Words: autonomous aerial vehicles  helicopters  mobile robots  motion control  multi-robot systems  path planning  motion delays  drones  periodic swarm patterns  quadrotor swarm performances  integrated unit  coordinated unit  swarm motion primitives  flexible framework  choreography design  trajectory generation algorithms  periodic motion pattern  Drones  Trajectory  Vehicle dynamics  Surface waves  Planning  Aerodynamics 
Abstract: This paper aims to design quadrotor swarm performances, where the swarm acts as an integrated, coordinated unit embodying moving and deforming objects. We divide the task of creating a choreography into three basic steps: designing swarm motion primitives, transitioning between those movements, and synchronizing the motion of the drones. The result is a flexible framework for designing choreographies comprised of a wide variety of motions. The motion primitives can be intuitively designed using a few parameters, providing a rich library for choreography design. Moreover, we combine and adapt existing goal assignment and trajectory generation algorithms to maximize the smoothness of the transitions between motion primitives. Finally, we propose a correction algorithm to compensate for motion delays and synchronize the motion of the drones to a desired periodic motion pattern. The proposed methodology was validated experimentally by generating and executing choreographies on a swarm of 25 quadrotors.


Title: Robust 3D Distributed Formation Control With Collision Avoidance And Application To Multirotor Aerial Vehicles
Key Words: aircraft control  autonomous aerial vehicles  collision avoidance  distributed control  helicopters  mobile robots  position control  position measurement  robust control  distributed control strategy  local relative position measurements  collision avoidance strategy  robust 3D distributed formation control  3D formation  multirotor aerial vehicles  quadrotors  Three-dimensional displays  Collision avoidance  Shape  Vehicle dynamics  Position measurement  Sensors  Topology  Multi-robot systems  distributed robotic systems  3D formation control  distributed collision avoidance 
Abstract: We present a distributed control strategy for a team of agents to autonomously achieve a desired 3D formation. Our approach is based on local relative position measurements and can be applied to multirotor aerial vehicles. We assume that agents have a common sense of direction, which is used to align the z-axes of their local coordinate frames. However, this assumption is not crucial, and our approach is provably robust to misalignments in the local coordinate frames or measurement inaccuracies. In particular, agents can move along any direction that projects positively onto the desired direction of motion. This property is exploited to design a fully-distributed collision avoidance strategy. We validate the proposed approach experimentally and show that a team of quadrotors can achieve a desired 3D formation without collisions.


Title: Networked Operation of a UAV Using Gaussian Process-Based Delay Compensation and Model Predictive Control
Key Words: autonomous aerial vehicles  compensation  control nonlinearities  delays  Gaussian processes  mobile robots  networked control systems  nonlinear control systems  path planning  predictive control  stability  state estimation  state feedback  time-varying systems  Gaussian process-based delay compensation  model predictive control  time-varying network delay  UAV control system  delayed state feedback  multirotor-type UAVs  networked control system  UAV networked operation  path planning  state estimation  Delays  Servers  Uplink  Downlink  Predictive models  Unmanned aerial vehicles  Mathematical model 
Abstract: This study addresses an operation of unmanned aerial vehicles (UAVs) in a network environment where there is time-varying network delay. The network delay entails undesirable effects on the stability of the UAV control system due to delayed state feedback and outdated control input. Although several networked control algorithms have been proposed to deal with the network delay, most existing studies have assumed that the plant dynamics is known and simple, or the network delay is constant. These assumptions are improper to multirotor-type UAVs because of their nonlinearity and time-sensitive characteristics. To deal with these problems, we propose a networked control system using model predictive control (MPC) designed under the consideration of multirotor characteristics. We also apply a Gaussian process (GP) to learn an unknown nonlinear model, which increases the accuracy of path planning and state estimation. Flight experiments show that the proposed algorithm successfully compensates the network delay and Gaussian process learning improves the UAV's path tracking performance.


Title: Flappy Hummingbird: An Open Source Dynamic Simulation of Flapping Wing Robots and Animals
Key Words: aerodynamics  aerospace components  aerospace robotics  aircraft control  autonomous aerial vehicles  closed loop systems  control system synthesis  learning (artificial intelligence)  microrobots  mobile robots  motion control  nonlinear control systems  robot dynamics  robot kinematics  stability  vehicle dynamics  flappy hummingbird  open source dynamic simulation  flapping Wing robots  hummingbirds  extraordinary flight performance  stable hovering maneuvering  aggressive maneuvering  conventional small scale man-made vehicles  FWMAVs  performance gap  open source high fidelity dynamic simulation  optimization  flight control  at-scale hummingbird robot  system identification  dynamic response  open-loop  loop systems  simulated flights  experimental flights  highly nonlinear flight dynamics  control problems  control algorithms  linear controller  control policy  simulation-to-real transfer  physical robot  flapping wing microair vehicles  Aerodynamics  Robots  Vehicle dynamics  Force  Torque  Animals 
Abstract: Insects and hummingbirds exhibit extraordinary flight performance and can simultaneously master seemingly conflicting goals: stable hovering and aggressive maneuvering, which are unmatched by conventional small scale man-made vehicles. Flapping Wing Micro Air Vehicles (FWMAVs) hold great promise for closing this performance gap. However, design and control of such systems remain challenging. Here, we present an open source high fidelity dynamic simulation for FWMAVs. The simulator serves as a testbed for the design, optimization and flight control of FWMAVs. To validate the simulation, we recreated the at-scale hummingbird robot developed in our lab in the simulation. System identification was performed to obtain the model parameters. Force generation and dynamic response of open-loop and closed loop systems between simulated and experimental flights were compared. The unsteady aerodynamics and the highly nonlinear flight dynamics present challenging control problems for conventional and learning control algorithms such as Reinforcement Learning. The interface of the simulation is fully compatible with OpenAI Gym environment. As a benchmark study, we present a linear controller for hovering stabilization and a Deep Reinforcement Learning control policy for goal-directed maneuvering. Finally, we demonstrate direct simulation-to-real transfer of both control policies onto the physical robot, further demonstrating the fidelity of the simulation.


Title: Long-Term Occupancy Grid Prediction Using Recurrent Neural Networks
Key Words: convolutional neural nets  learning (artificial intelligence)  Monte Carlo methods  neural net architecture  optical radar  recurrent neural nets  long-term occupancy grid prediction  recurrent neural networks  scene evolution  automated driving  Lidar grid fusion  birds eye view  RNNs  CNN architecture  convolutional long short-term memories  ConvLSTMs  Monte Carlo approach  Vehicle dynamics  Training  Predictive models  Task analysis  Computer architecture  Recurrent neural networks  Correlation 
Abstract: We tackle the long-term prediction of scene evolution in a complex downtown scenario for automated driving based on Lidar grid fusion and recurrent neural networks (RNNs). A bird's eye view of the scene, including occupancy and velocity, is fed as a sequence to a RNN which is trained to predict future occupancy. The nature of prediction allows generation of multiple hours of training data without the need of manual labeling. Thus, the training strategy and loss function are designed for long sequences of real-world data (unbalanced, continuously changing situations, false labels, etc.). The deep CNN architecture comprises convolutional long short-term memories (ConvLSTMs) to separate static from dynamic regions and to predict dynamic objects in future frames. Novel recurrent skip connections show the ability to predict small occluded objects, i.e. pedestrians, and occluded static regions. Spatio-temporal correlations between grid cells are exploited to predict multimodal future paths and interactions between objects. Experiments also quantity improvements to our previous network, a Monte Carlo approach, and literature.


Title: Removing Leaking Corners to Reduce Dimensionality in Hamilton-Jacobi Reachability
Key Words: collision avoidance  game theory  mobile robots  nonlinear dynamical systems  optimal control  reachability analysis  safety  dimensionality reduction  HJ computation  Hamilton-Jacobi reachability  robotic systems  nonlinear system dynamics  safety-preserving controllers  computational scalability  continuous state dimensions  computational burden  system decomposition methods  coupled HJ formulation  leaking corners removal  safety verification  computational scalability limits  vehicle obstacle avoidance problem  5D car model  Safety  Dimensionality reduction  Optimal control  Level set  Collision avoidance  Trajectory 
Abstract: Hamilton-Jacobi (HJ) reachability provides a flexible framework for the verification of safety in robotic systems: it accounts for nonlinear system dynamics and provides safety-preserving controllers. However, computational scalability limits its direct application to systems of less than five continuous state dimensions. To alleviate this computational burden, system decomposition methods have been proposed; however, safety guarantees are lost in situations involving “leaking corners which arise when there are conflicting controls between subsystems. In this paper, a coupled HJ formulation is presented, which addresses leaking corners and guarantees safety, while incorporating dimensionality reduction. We demonstrate our method in two examples, one of which is a vehicle obstacle avoidance problem with a 5D car model, whose HJ computation was previously considered to be intractable.


Title: Building a Winning Self-Driving Car in Six Months
Key Words: automobiles  closed loop systems  mobile robots  multi-robot systems  robot vision  basic autonomy features  robust algorithms  multisensor visual localization solution  winning self-driving car  SAE AutoDrive Challenge  Level 4 autonomous vehicle  Yuma  Arizona  Zeus' complete system architecture  CPU  closed-loop performance  Cameras  Real-time systems  Navigation  Computer architecture  Laser radar  Visualization  Systems architecture 
Abstract: The SAE AutoDrive Challenge is a three-year competition to develop a Level 4 autonomous vehicle by 2020. The first set of challenges were held in April of 2018 in Yuma, Arizona. Our team (aUToronto/Zeus) placed first. In this paper, we describe Zeus' complete system architecture and specialized algorithms that enabled us to win. We show that it is possible to develop a vehicle with basic autonomy features in just six months relying on simple, robust algorithms. We do not make use of a prior map. Instead, we have developed a multi-sensor visual localization solution. All the algorithms in the paper run in real-time using CPUs only. We also highlight the closed-loop performance of the system in detail in several experiments.


Title: Hierarchical Game-Theoretic Planning for Autonomous Vehicles
Key Words: decision making  game theory  path planning  remotely operated vehicles  road traffic control  road vehicles  trajectory control  game-theoretic trajectory planning algorithm  trajectory optimization  dynamic games  autonomous driving technology  drivers  dynamic game theory  hierarchical game-theoretic planning  human driver  autonomous vehicle  planning horizon  simplified information structure  short-horizon tactical game  long-horizon strategic game  Vehicle dynamics  Autonomous vehicles  Planning  Games  Trajectory  Computational modeling 
Abstract: The actions of an autonomous vehicle on the road affect and are affected by those of other drivers, whether overtaking, negotiating a merge, or avoiding an accident. This mutual dependence, best captured by dynamic game theory, creates a strong coupling between the vehicle's planning and its predictions of other drivers' behavior, and constitutes an open problem with direct implications on the safety and viability of autonomous driving technology. Unfortunately, dynamic games are too computationally demanding to meet the real-time constraints of autonomous driving in its continuous state and action space. In this paper, we introduce a novel game-theoretic trajectory planning algorithm for autonomous driving, that enables real-time performance by hierarchically decomposing the underlying dynamic game into a long-horizon “strategic” game with simplified dynamics and full information structure, and a short-horizon “tactical” game with full dynamics and a simplified information structure. The value of the strategic game is used to guide the tactical planning, implicitly extending the planning horizon, pushing the local trajectory optimization closer to global solutions, and, most importantly, quantitatively accounting for the autonomous vehicle and the human driver's ability and incentives to influence each other. In addition, our approach admits non-deterministic models of human decision-making, rather than relying on perfectly rational predictions. Our results showcase richer, safer, and more effective autonomous behavior in comparison to existing techniques.


Title: IceVisionSet: lossless video dataset collected on Russian winter roads with traffic sign annotations
Key Words: cameras  computer vision  driver information systems  image recognition  road traffic  visual perception  camera settings  weather conditions  traffic sign images  Russian winter roads  Russian traffic code  IceVisionSet  lossless video dataset  traffic sign annotations  autonomous vehicles  traffic signs  image data  computer vision systems  Cameras  Image coding  Tools  Roads  Automobiles  Autonomous vehicles  Computer vision 
Abstract: Ability of autonomous vehicles to operate in complex dynamic environments requires, among other things, fast and accurate perception of surroundings, which includes recognition and tracking of traffic signs.For development and testing of modern sophisticated computer vision systems large and diverse datasets are of the major importance. To test the robustness of algorithms, image data with different moving speeds, camera settings, lighting and weather conditions are especially important.In this work we present a comprehensive, lifelike dataset of traffic sign images collected on the Russian winter roads in varying conditions, which include different weather, camera exposure, illumination and moving speeds. The dataset was annotated in accordance with the Russian traffic code. Annotation results and images are published under open CC BY 4.0 license and can be downloaded from the project website: http://oscar.skoltech.ru/.


Title: Integrated UWB-Vision Approach for Autonomous Docking of UAVs in GPS-denied Environments
Key Words: autonomous aerial vehicles  computer vision  displacement measurement  Global Positioning System  mobile robots  robot vision  unmanned aerial vehicles  ultrawideband ranging sensor  approaching phase  autonomous approaching landing capabilities  vision-based techniques  GPS-denied environments  autonomous docking  integrated UWB-vision approach  vision-derived poses  UWB measurements  onboard vision system  relative displacement measurements  UAV relative  Displacement measurement  Unmanned aerial vehicles  Distance measurement  Visualization  Optical variables measurement  Optical feedback  Optical saturation 
Abstract: Though vision-based techniques have become quite popular for autonomous docking of Unmanned Aerial Vehicles (UAVs), due to limited field of view (FOV), the UAV must rely on other methods to detect and approach the target before vision can be used. In this paper we propose a method combining Ultra-wideband (UWB) ranging sensor with vision-based techniques to achieve both autonomous approaching and landing capabilities in GPS-denied environments. In the approaching phase, a robust and efficient recursive least-square optimization algorithm is proposed to estimate the position of the UAV relative to the target by using the distance and relative displacement measurements. Using this estimate, UAV is able to approach the target until the landing pad is detected by an onboard vision system, then UWB measurements and vision-derived poses are fused with onboard sensor of UAV to facilitate an accurate landing maneuver. Real-world experiments are conducted to demonstrate the efficiency of our method.


Title: Online Vehicle Trajectory Prediction using Policy Anticipation Network and optimization-based Context Reasoning
Key Words: inference mechanisms  optimisation  regression analysis  road traffic control  traffic engineering computing  ubiquitous computing  online vehicle trajectory prediction  two-level vehicle trajectory prediction framework  urban autonomous driving  complex contextual factors  traffic regulations  moving agents  high-level policy anticipation  low-level context reasoning  short-term memory network  sequential history observations  low-level optimization-based context reasoning process  optimization-based reasoning process  two-level reasoning process  continuous trajectory  regression-based trajectory prediction methods  vehicle motions  Trajectory  Cognition  Optimization  Hidden Markov models  Predictive models  Geometry  Adaptation models 
Abstract: In this paper, we present an online two-level vehicle trajectory prediction framework for urban autonomous driving where there are complex contextual factors, such as lane geometries, road constructions, traffic regulations and moving agents. Our method combines high-level policy anticipation with low-level context reasoning. We leverage a long short-term memory (LSTM) network to anticipate the vehicle's driving policy (e.g., forward, yield, turn left, turn right, etc.) using its sequential history observations. The policy is then used to guide a low-level optimization-based context reasoning process. We show that it is essential to incorporate the prior policy anticipation due to the multimodal nature of the future trajectory. Moreover, contrary to existing regression-based trajectory prediction methods, our optimization-based reasoning process can cope with complex contextual factors. The final output of the two-level reasoning process is a continuous trajectory that automatically adapts to different traffic configurations and accurately predicts future vehicle motions. The performance of the proposed framework is analyzed and validated in an emerging autonomous driving simulation platform (CARLA).


Title: Adaptive motor control and learning in a spiking neural network realised on a mixed-signal neuromorphic processor
Key Words: control engineering computing  feedback  learning (artificial intelligence)  mobile robots  neural chips  neurocontrollers  adaptive motor control  mixed-signal neuromorphic processor  neuromorphic computing  biological neural networks  spiking neural network architecture  sensory feedback  control rotational velocity  robotic vehicle  correct motor command  miniature mobile vehicle  two-layer spiking neural network  neuromorphic chip  purely neuromorphic motor control  spiking neurons  neuromorphic device  on-chip plastic synaptic weights  Neuromorphics  Neurons  Biological neural networks  Computer architecture  Robot sensing systems  Sociology 
Abstract: Neuromorphic computing is a new paradigm for design of both the computing hardware and algorithms inspired by biological neural networks. The event-based nature and the inherent parallelism make neuromorphic computing a promising paradigm for building efficient neural network based architectures for control of fast and agile robots. In this paper, we present a spiking neural network architecture that uses sensory feedback to control rotational velocity of a robotic vehicle. When the velocity reaches the target value, the mapping from the target velocity of the vehicle to the correct motor command, both represented in the spiking neural network on the neuromorphic device, is autonomously stored on the device using on-chip plastic synaptic weights. We validate the controller using a wheel motor of a miniature mobile vehicle and inertia measurement unit as the sensory feedback and demonstrate online learning of a simple “inverse model” in a two-layer spiking neural network on the neuromorphic chip. The prototype neuromorphic device that features 256 spiking neurons allows us to realise a simple proof of concept architecture for the purely neuromorphic motor control and learning. The architecture can be easily scaled-up if a larger neuromorphic device is available.


Title: Adaptive Genomic Evolution of Neural Network Topologies (AGENT) for State-to-Action Mapping in Autonomous Agents
Key Words: autonomous aerial vehicles  collision avoidance  genetic algorithms  learning (artificial intelligence)  neurocontrollers  autonomous agents  neural networks  NN  evolutionary algorithm  state-to-action mapping model  neuroevolution process  population diversity  unmanned aerial vehicle collision avoidance problem  adaptive genomic evolution  neural network topologies  augmented topologies formalism  Open AI platform  UAV collision avoidance problem  Genomics  Topology  Sociology  Statistics  Artificial neural networks  Network topology 
Abstract: Neuroevolution is a process of training neural networks (NN) through an evolutionary algorithm, usually to serve as a state-to-action mapping model in control or reinforcement learning-type problems. This paper builds on the Neuro Evolution of Augmented Topologies (NEAT) formalism that allows designing topology and weight evolving NNs. Fundamental advancements are made to the neuroevolution process to address premature stagnation and convergence issues, central among which is the incorporation of automated mechanisms to control the population diversity and average fitness improvement within the neuroevolution process. Insights into the performance and efficiency of the new algorithm is obtained by evaluating it on three benchmark problems from the Open AI platform and an Unmanned Aerial Vehicle (UAV) collision avoidance problem.


Title: DeepSignals: Predicting Intent of Drivers Through Visual Signals
Key Words: alarm systems  belief networks  image sequences  learning (artificial intelligence)  neural nets  psychology  traffic engineering computing  video signal processing  driver intention detection  emergency flashers  turn signals  stops  lane changes  sudden events  visual signals  DeepSignals  temporal information  spatial information  deep neural network  video sequences  potentially critical reaction time  Feature extraction  Convolution  Vehicles  Visualization  Streaming media  Computer architecture  Logic gates 
Abstract: Detecting the intention of drivers is an essential task in self-driving, necessary to anticipate sudden events like lane changes and stops. Turn signals and emergency flashers communicate such intentions, providing seconds of potentially critical reaction time. In this paper, we propose to detect these signals in video sequences by using a deep neural network that reasons about both spatial and temporal information. Our experiments on more than a million frames show high per-frame accuracy in very challenging scenarios.


Title: Real-time Intent Prediction of Pedestrians for Autonomous Ground Vehicles via Spatio-Temporal DenseNet
Key Words: cameras  control engineering computing  image colour analysis  image sequences  mobile robots  object detection  object tracking  pedestrians  road traffic  traffic engineering computing  pedestrians  complex environments  vulnerable road users  intent action prediction  urban traffic environments  monocular RGB camera  tracking-by-detection technique  spatio-temporal DenseNet model  autonomous ground vehicles  image sequences  real-time intent prediction  Real-time systems  Task analysis  Predictive models  Two dimensional displays  Image sequences  Cameras  Activity recognition 
Abstract: Understanding the behaviors and intentions of humans are one of the main challenges autonomous ground vehicles still faced with. More specifically, when it comes to complex environments such as urban traffic scenes, inferring the intentions and actions of vulnerable road users such as pedestrians become even harder. In this paper, we address the problem of intent action prediction of pedestrians in urban traffic environments using only image sequences from a monocular RGB camera. We propose a real-time framework that can accurately detect, track and predict the intended actions of pedestrians based on a tracking-by-detection technique in conjunction with a novel spatio-temporal DenseNet model. We trained and evaluated our framework based on real data collected from urban traffic environments. Our framework has shown resilient and competitive results in comparison to other baseline approaches. Overall, we achieved an average precision score of 84.76% with real-time performance at 20 FPS.


Title: Egocentric Vision-based Future Vehicle Localization for Intelligent Driving Assistance Systems
Key Words: driver information systems  image coding  image sequences  recurrent neural nets  road vehicles  egocentric vision-based future vehicle localization  intelligent driving assistance systems  safety-critical applications  autonomous driving  target vehicles  first-person view  ego-vehicle  multistream recurrent neural network encoder-decoder model  object location  pixel-level observations  future motion  prediction accuracy  intelligent vehicles  automated vehicles  motion planning capability  vehicle trajectories  dense optical flow  Trajectory  Cameras  Optical imaging  Decoding  Videos  Predictive models  Advanced driver assistance systems 
Abstract: Predicting the future location of vehicles is essential for safety-critical applications such as advanced driver assistance systems (ADAS) and autonomous driving. This paper introduces a novel approach to simultaneously predict both the location and scale of target vehicles in the first-person (egocentric) view of an ego-vehicle. We present a multi-stream recurrent neural network (RNN) encoder-decoder model that separately captures both object location and scale and pixel-level observations for future vehicle localization. We show that incorporating dense optical flow improves prediction results significantly since it captures information about motion as well as appearance change. We also find that explicitly modeling future motion of the ego-vehicle improves the prediction accuracy, which could be especially beneficial in intelligent and automated vehicles that have motion planning capability. To evaluate the performance of our approach, we present a new dataset of first-person videos collected from a variety of scenarios at road intersections, which are particularly challenging moments for prediction because vehicle trajectories are diverse and dynamic. Code and dataset have been made available at: https://usa.honda-ri.com/hevi.


Title: Uncertainty-Aware Driver Trajectory Prediction at Urban Intersections
Key Words: driver information systems  neural nets  road safety  road traffic  road vehicles  variational neural network approach  multiple sensors  conditional variational distribution  confidence estimate  different time horizons  additional predictors  variational predictor  physics-based predictor  confidence estimations  system performance  vehicle autonomy  real-world urban driving data  prediction error  physics-based model  uncertainty-aware driver trajectory prediction  urban intersections  advanced driving systems  shared control  automation systems  uncertain situations  driver trajectory distributions  Trajectory  Vehicles  Predictive models  Sensors  Uncertainty  Autonomous systems  Task analysis 
Abstract: Predicting the motion of a driver's vehicle is crucial for advanced driving systems, enabling detection of potential risks towards shared control between the driver and automation systems. In this paper, we propose a variational neural network approach that predicts future driver trajectory distributions for the vehicle based on multiple sensors. Our predictor generates both a conditional variational distribution of future trajectories, as well as a confidence estimate for different time horizons. Our approach allows us to handle inherently uncertain situations, and reason about information gain from each input, as well as combine our model with additional predictors, creating a mixture of experts. We show how to augment the variational predictor with a physics-based predictor, and based on their confidence estimations, improve overall system performance. The resulting combined model is aware of the uncertainty associated with its predictions, which can help the vehicle autonomy to make decisions with more confidence. The model is validated on real-world urban driving data collected in multiple locations. This validation demonstrates that our approach improves the prediction error of a physics-based model by 25% while successfully identifying the uncertain cases with 82% accuracy.


Title: Neural Lander: Stable Drone Landing Control Using Learned Dynamics
Key Words: aerodynamics  aircraft control  autonomous aerial vehicles  control system synthesis  feedback  helicopters  learning (artificial intelligence)  linearisation techniques  neurocontrollers  nonlinear control systems  robust control  trajectory control  cross-table trajectory tracking cases  Neural Lander  stable drone landing control  learned dynamics  precise near-ground trajectory control  multirotor drones  complex aerodynamic effects  multirotor airflow  complex effects  smooth landing  robust nonlinear controller  control performance  nominal dynamics model  Deep Neural Network  high-order interactions  Lipschitz constant  Lipschitz property  nonlinear feedback linearization controller  DNN-based nonlinear feedback controller  arbitrarily large neural nets  Baseline Nonlinear Tracking Controller  Aerodynamics  Stability analysis  Rotors  Neural networks  Trajectory tracking  Training  Vehicle dynamics 
Abstract: Precise near-ground trajectory control is difficult for multi-rotor drones, due to the complex aerodynamic effects caused by interactions between multi-rotor airflow and the environment. Conventional control methods often fail to properly account for these complex effects and fall short in accomplishing smooth landing. In this paper, we present a novel deep-learning-based robust nonlinear controller (Neural-Lander) that improves control performance of a quadrotor during landing. Our approach combines a nominal dynamics model with a Deep Neural Network (DNN) that learns high-order interactions. We apply spectral normalization (SN) to constrain the Lipschitz constant of the DNN. Leveraging this Lipschitz property, we design a nonlinear feedback linearization controller using the learned model and prove system stability with disturbance rejection. To the best of our knowledge, this is the first DNN-based nonlinear feedback controller with stability guarantees that can utilize arbitrarily large neural nets. Experimental results demonstrate that the proposed controller significantly outperforms a Baseline Nonlinear Tracking Controller in both landing and cross-table trajectory tracking cases. We also empirically show that the DNN generalizes well to unseen data outside the training domain.


Title: Distributional Deep Reinforcement Learning with a Mixture of Gaussians
Key Words: Gaussian processes  learning (artificial intelligence)  statistical distributions  discrete distribution  softmax parametrization  KL divergence loss  discretization hyperparameters  Atari games  distributional deep reinforcement learning  mixture density network  return distribution  mixtures of Gaussians  Jensen-Tsallis distance  autonomous vehicle driving  Measurement  Reinforcement learning  Games  Approximation algorithms  Neural networks  Autonomous vehicles  Stochastic processes 
Abstract: In this paper, we propose a novel distributional reinforcement learning (RL) method which models the distribution of the sum of rewards using a mixture density network. Recently, it has been shown that modeling the randomness of the return distribution leads to better performance in Atari games and control tasks. Despite the success of the prior work, it has limitations which come from the use of a discrete distribution. First, it needs a projection step and softmax parametrization for the distribution, since it minimizes the KL divergence loss. Secondly, its performance depends on discretization hyperparameters such as the number of atoms and bounds of the support which require domain knowledge. We mitigate these problems with the proposed parameterization, a mixture of Gaussians. Furthermore, we propose a new distance metric called the Jensen-Tsallis distance, which allows the computation of the distance between two mixtures of Gaussians in a closed form. We have conducted various experiments to validate the proposed method, including Atari games and autonomous vehicle driving.


Title: Visual Diver Recognition for Underwater Human-Robot Collaboration
Key Words: autonomous underwater vehicles  convolutional neural nets  human-robot interaction  mobile robots  multi-robot systems  object detection  pattern clustering  visual diver recognition  underwater human-robot collaboration  autonomous underwater robot  visual scene  human leader  detected bounding boxes  mobile robot  k-means clustering algorithm  feature vector  frequency domain descriptors  spatial domain descriptors  region proposal network  faster R-CNN algorithm  diver identification  multihuman-robot teams  multiple divers detection  Feature extraction  Robots  Image color analysis  Image edge detection  Visualization  Target tracking 
Abstract: This paper presents an approach for autonomous underwater robots to visually detect and identify divers. The proposed approach enables an autonomous underwater robot to detect multiple divers in a visual scene and distinguish between them. Such methods are useful for robots to identify a human leader, for example, in multi-human/robot teams where only designated individuals are allowed to command or lead a team of robots. Initial diver identification is performed using the Faster R-CNN algorithm with a region proposal network which produces bounding boxes around the divers' locations. Subsequently, a suite of spatial and frequency domain descriptors are extracted from the bounding boxes to create a feature vector. A K-Means clustering algorithm, with k set to the number of detected bounding boxes, thereafter identifies the detected divers based on these feature vectors. We evaluate the performance of the proposed approach on video footage of divers swimming in front of a mobile robot and demonstrate its accuracy.


Title: An Integrated Approach to Navigation and Control in Micro Underwater Robotics using Radio-Frequency Localization
Key Words: autonomous underwater vehicles  marine navigation  microrobots  mobile robots  position control  radio-frequency localization  microautonomous underwater vehicles  μAUVs  integrated navigation  control architecture  low-cost embedded localization module  integrated approach  underwater localization systems  microunderwater robotics  underwater way-point tracking controller  Robots  Attenuation  Navigation  Acoustics  Computer architecture  Noise measurement  Measurement uncertainty 
Abstract: Navigation and control are a largely unsolved problems for micro autonomous underwater vehicles (μAUVs). The main challenges are due to the lack of accurate underwater localization systems, which fit on-board of μAUVs. In this work, we present an integrated navigation and control architecture consisting of a low-cost embedded localization module and an underwater way-point tracking controller, which fulfills the requirements of μAUVs. The performance of the navigation and control system is benchmarked in two different experimental scenarios.


Title: Online Utility-Optimal Trajectory Design for Time-Varying Ocean Environments
Key Words: convex programming  energy consumption  gradient methods  marine engineering  mobile robots  time-varying systems  trajectory control  online utility-optimal trajectory design  time-varying ocean environments  time-varying environments  energy-efficient trajectories  strong disturbances  uncertain disturbances  time-varying goal location  constrained online convex optimization formalism  gradient descent algorithm  vehicle locations  energy consumption  regional ocean modelling system  ocean velocity measurements  Trajectory  Oceans  Planning  Convex functions  Delays  Energy consumption  Optimization 
Abstract: This paper considers the problem of online optimal trajectory design under time-varying environments. Of particular interest is the design of energy-efficient trajectories under strong and uncertain disturbances in ocean environments and time-varying goal location. We formulate the problem within the constrained online convex optimization formalism, and a modified online gradient descent algorithm is motivated. The mobility constraints are met using a carefully chosen stepsize, and the proposed algorithm is shown to incur sublinear regret. Different from the state-of-the-art algorithms that entail planning and re-planning the full trajectory using forecast data at each time instant, the proposed algorithm is entirely online and relies mostly on the current ocean velocity measurements at the vehicle locations. The trade-off between excess delay incurred in reaching the goal and the overall energy consumption is examined via numerical tests carried out on real data obtained from the regional ocean modelling system. As compared to the state-of-the-art algorithms, the proposed algorithm is not only energy-efficient but also several orders of magnitude computationally efficient.


Title: Flight, Camera, Action! Using Natural Language and Mixed Reality to Control a Drone
Key Words: aerospace computing  autonomous aerial vehicles  control engineering computing  human-robot interaction  Markov processes  mobile robots  natural language processing  user interfaces  natural language commands  Markov decision process framework  web interface  MR interface  exploratory user study  fully autonomous language grounding  autonomous drone  natural language grounding  goal-oriented setting  mixed reality  radio-controlled controller  users control  Drones  Natural languages  Virtual reality  Robots  Task analysis  Planning  Grounding 
Abstract: With increasing autonomy, robots like drones are increasingly accessible to untrained users. Most users control drones using a low-level interface, such as a radio-controlled (RC) controller. For a wider adoption of these technologies by the public, a much higher-level interface, such as natural language or mixed reality (MR), allows the automation of the control of the agent in a goal-oriented setting. We present an interface that uses natural language grounding within an MR environment to solve high-level task and navigational instructions given to an autonomous drone. To the best of our knowledge, this is the first work to perform fully autonomous language grounding in an MR setting for a robot. Given a map, our interface first grounds natural language commands to reward specifications within a Markov Decision Process (MDP) framework. Then, it passes the reward specification to an MDP solver. Finally, the drone performs the desired operations in the real world while planning and localizing itself. Our approach uses MR to provide a set of known virtual landmarks, enabling the drone to understand commands referring to objects without being equipped with object detectors for multiple novel objects or a predefined environment model. We conducted an exploratory user study to assess users' experience of our MR interface with and without natural language, as compared to a web interface. We found that users were able to command the drone more quickly via both MR interfaces as compared to the web interface, with roughly equal system usability scores across all three interfaces.


Title: Safe and Fast Path Planning in Cluttered Environment using Contiguous Free-space Partitioning
Key Words: convex programming  graph theory  mobile robots  path planning  random processes  cluttered environment  contiguous free-space partitioning  convex optimization  convex navigable free-spaces  contiguous convex free-spaces  random-walk based seed generation method  contiguous navigable geometry  graph search problem  multiple query planning algorithm  fast path planning  undirected graph  safe path planning  Path planning  Planning  Ellipsoids  Robots  Data structures  Iris 
Abstract: The paper proposes a path planning algorithm for cluttered environment and maze. The proposed planning algorithm exploits the merit of convex optimization while forming the convex navigable free-spaces, ensuring safety of the vehicle. The contiguous convex free-spaces are iteratively computed from a random-walk based seed generation method to create a contiguous navigable geometry. Inside this contiguous navigable geometry an undirected graph is then created, whose each node and edge belong to at least one convex region which boils down the path planning problem into a graph search problem. In addition, the proposed multiple query planning algorithm can merge the user provided feasible initial and goal configuration with the existing undirected graph in each plan, without deteriorating the planning performance in terms of run-time and path length. Simulation and experimental results confirm the superiority of the proposed planning algorithm jointly in terms of both path length and run-time by a significant margin.


Title: Safely Probabilistically Complete Real-Time Planning and Exploration in Unknown Environments
Key Words: approximation theory  collision avoidance  mobile robots  predictive control  probability  reachability analysis  robot dynamics  robust control  safe backward reachable set  real-time simulation  safely probabilistically complete real-time planning  motion planning  kinodynamic planners  a priori unknown  static environments  collision avoidance  robust controller  reachability analysis  motion plans  robot operating system software environment  Planning  Trajectory  Safety  Computational modeling  Real-time systems  Vehicle dynamics  Probabilistic logic 
Abstract: We present a new framework for motion planning that wraps around existing kinodynamic planners and guarantees recursive feasibility when operating in a priori unknown, static environments. Our approach makes strong guarantees about overall safety and collision avoidance by utilizing a robust controller derived from reachability analysis. We ensure that motion plans never exit the safe backward reachable set of the initial state, while safely exploring the space. This preserves the safety of the initial state, and guarantees that that we will eventually find the goal if it is possible to do so while exploring safely. We implement our framework in the Robot Operating System (ROS) software environment and demonstrate it in a real-time simulation.


Title: Nonlinear Tire Cornering Stiffness Observer for a Double Steering Off-Road Mobile Robot
Key Words: linear quadratic control  mobile robots  nonlinear control systems  observers  off-road vehicles  path planning  predictive control  steering systems  tyres  vehicle dynamics  open environments  rear contact cornering stiffnesses  soil proprieties  steering angles  LQR controller  nonlinear tire cornering stiffness observer  double steering off-road mobile robot  path tracking controllers  autonomous vehicle  dynamic model  wheel-ground contact  Kalman-Bucy observer  ground parameter estimation  Observers  Tires  Mobile robots  Vehicle dynamics  Wheels  Nonlinear optics 
Abstract: Path tracking controllers for an autonomous vehicle are often designed by using either a dynamic model or a kinematic one and some models are related to wheel-ground contact, that makes the efficiency of the controller highly dependent on the ground parameters estimation, especially for off-road mobile robots intended to navigate in open environments. This paper proposes a new nonlinear observer designed to estimate the front and rear contact cornering stiffnesses in real time, that are related both on tire and soil proprieties. The latter is estimated using steering angles as well as yaw rate and lateral velocity, which are provided by a preliminary Kalman-Bucy observer. The performance of the proposed nonlinear observer combined with the LQR controller is evaluated by both advanced simulations and experiments in real conditions at different speeds.


Title: A Predictive Reward Function for Human-Like Driving Based on a Transition Model of Surrounding Environment
Key Words: decision making  image processing  learning (artificial intelligence)  mobile robots  neural nets  road traffic  road vehicles  robot vision  traffic engineering computing  autonomous driving vehicles  deep predictive network  predictive reward function  human-like driving  decision making  vehicle control  traffic flow  occupancy grid image  prediction network training  real driving data  reinforcement learning agent training  deep neural networks  Autonomous vehicles  Roads  Predictive models  Reinforcement learning  Decision making  Object detection  Autonomous driving  Prediction  Reward  Deep Learning  Reinforcement Learning  naturalistic Driving Data 
Abstract: Driving is a complex task that requires the perception of the surrounding environment, decision making and control of the vehicle. Human drivers predict how surrounding objects move and decide an appropriate driving behavior. As with human drivers, autonomous driving vehicles should consider the condition of the surrounding environment and behave naturally so as not to disturb the traffic flow. We propose a reward function for learning how natural the driving is based on the hypothesis that the movement of surrounding vehicles becomes unpredictable when the ego vehicle takes an unnatural driving behavior. The reward function is based on the prediction error of a deep predictive network that models the transition of the surrounding environment. Occupancy grid image is used to perceive the surrounding environment and the predictions up to two seconds are used to calculate the reward function. We evaluated the reward function using both simulated and the real world data. We trained the prediction network using real driving data and trained a reinforcement learning agent based on the reward function. Then we compared the speed planned by the agent and a human driver, which showed a correlation of 0.52. We also confirmed the benefit of taking prediction into account by observing the behavior of the agent in a specific traffic scenario.


Title: ADAPS: Autonomous Driving Via Principled Simulations
Key Words: hierarchical systems  remotely operated vehicles  road traffic control  robust control  ADAPS  autonomous driving  robust control policy  autonomous vehicles  simulation platforms  learning mechanism  hierarchical control policy  DAGGER method  Task analysis  Training  Accidents  Autonomous vehicles  Training data  Trajectory  Learning systems 
Abstract: Autonomous driving has gained significant advancements in recent years. However, obtaining a robust control policy for driving remains challenging as it requires training data from a variety of scenarios, including rare situations (e.g., accidents), an effective policy architecture, and an efficient learning mechanism. We propose ADAPS for producing robust control policies for autonomous vehicles. ADAPS consists of two simulation platforms in generating and analyzing accidents to automatically produce labeled training data, and a memoryenabled hierarchical control policy. Additionally, ADAPS offers a more efficient online learning mechanism that reduces the number of iterations required in learning compared to existing methods such as DAGGER [1]. We present both theoretical and experimental results. The latter are produced in simulated environments, where qualitative and quantitative results are generated to demonstrate the benefits of ADAPS.


Title: Experimental Assessment of Plume Mapping using Point Measurements from Unmanned Vehicles
Key Words: air pollution  air quality  autonomous aerial vehicles  environmental monitoring (geophysics)  Gaussian processes  interpolation  mobile robots  Monte Carlo methods  regression analysis  point measurements  autonomous robots  mapping algorithms  piecewise linear interpolation  steady state ground truth  unmanned aerial vehicle  Gaussian process regression  polynomial interpolation  plume mapping  neural networks  Robot sensing systems  Interpolation  Gaussian processes  Dispersion  Noise measurement  Neural networks 
Abstract: This paper presents experiments to assess the plume mapping performance of autonomous robots. The paper compares several mapping algorithms including Gaussian Process regression, Neural networks and polynomial and piecewise linear interpolation. The methods are compared in Monte Carlo simulations using a well known plume model and in indoor experiments using a ground robot. Unlike previous work on mapping using unmanned vehicles, the indoor experiments were performed in a controlled and repeatable manner where a steady state ground truth could be obtained in order to properly assess the various regression methods using data from a real dispersive source and sensor. The effect of sampling time during data collection was assessed with regards to the mapping accuracy, and the data collected during the experiments have been made available. Overall, the Gaussian Process method was found to perform the best among the regression algorithms, showing more robustness to the noisy measurements obtained from short sampling periods, enabling an accurate map to be produced in significantly less time. Finally, plume mapping results are presented in uncontrolled outdoor conditions, using an unmanned aerial vehicle, to demonstrate the system in a realistic uncontrolled environment.


Title: Online Deep Learning for Improved Trajectory Tracking of Unmanned Aerial Vehicles Using Expert Knowledge
Key Words: autonomous aerial vehicles  learning (artificial intelligence)  neurocontrollers  trajectory control  input-output dataset  deep neural network-based controller  trained DNN  expert knowledge  learning-based approach  trajectory tracking performance  online deep learning  unmanned aerial vehicles  online learning-based control method  trajectory tracking  Training  Fuzzy logic  Unmanned aerial vehicles  Trajectory  Real-time systems  Trajectory tracking 
Abstract: This work presents an online learning-based control method for improved trajectory tracking of unmanned aerial vehicles using both deep learning and expert knowledge. The proposed method does not require the exact model of the system to be controlled, and it is robust against variations in system dynamics as well as operational uncertainties. The learning is divided into two phases: offline (pre-)training and online (post-)training. In the former, a conventional controller performs a set of trajectories and, based on the input-output dataset, the deep neural network (DNN)-based controller is trained. In the latter, the trained DNN, which mimics the conventional controller, controls the system. Unlike the existing papers in the literature, the network is still being trained for different sets of trajectories which are not used in the training phase of DNN. Thanks to the rule-base, which contains the expert knowledge, the proposed framework learns the system dynamics and operational uncertainties in real-time. The experimental results show that the proposed online learning-based approach gives better trajectory tracking performance when compared to the only offline trained network.


Title: Decentralized collaborative transport of fabrics using micro-UAVs
Key Words: autonomous aerial vehicles  decentralised control  microrobots  mobile robots  remotely operated vehicles  microUAV  small unmanned aerial vehicles  Buzz swarm-specific scripting language  fully decentralized control infrastructure  task demands  unstructured environments  maximum flexibility  joint payload capacity  decentralized collaborative transport  Robots  Payloads  Springs  Force  Task analysis  Shock absorbers  Python 
Abstract: Small unmanned aerial vehicles (UAVs) have generally little capacity to carry payloads. Through collaboration, the UAVs can increase their joint payload capacity and carry more significant loads. For maximum flexibility to dynamic and unstructured environments and task demands, we propose a fully decentralized control infrastructure based on a swarm-specific scripting language, Buzz. In this paper, we describe the control infrastructure and use it to compare two algorithms for collaborative transport: field potentials and spring-damper. We test the performance of our approach with a fleet of micro-UAVs, demonstrating the potential of decentralized control for collaborative transport.


Title: Precision Stationary Flight of a Robotic Hummingbird*
Key Words: aerodynamics  aerospace components  aircraft control  autonomous aerial vehicles  cascade control  compensation  mobile robots  robot dynamics  robot kinematics  torque control  trajectory control  robotic hummingbird project  flapping mechanism  wing trajectory  cascade control strategy  precision stationary flight  residual parasitic torques compensation  lift vector  autopilot  Bars  Robots  Acceleration  Aerodynamics  Harmonic analysis  Couplings  Kinematics 
Abstract: This paper describes recent developments of a robotic hummingbird project, aimed at achieving precision stationary hovering. To this end, the early version of our flapping mechanism is modified which, besides being more efficient, reduces significantly the asymmetry of the wing trajectory of the previous version. A cascade control strategy is used to compensate for the residual parasitic torques and the misalignment of the lift vector and the autopilot.


